{"id": "50333", "revid": "50324240", "url": "https://en.wikipedia.org/wiki?curid=50333", "title": "Utrecht", "text": "City and municipality in Utrecht, Netherlands\nUtrecht ( ; ; ) is the fourth-largest city of the Netherlands, as well as the capital and the most populous city of the province of Utrecht. The municipality of Utrecht is located in the eastern part of the Randstad conurbation, in the very centre of mainland Netherlands, and includes Haarzuilens, Vleuten and De Meern. It has a population of 376,435 as of January\u00a02025[ [update]].\nUtrecht's ancient city centre features many buildings and structures, several dating as far back as the High Middle Ages. It has been the religious centre of the Netherlands since the 8th century. In 1579, the Union of Utrecht was signed in the city to lay the foundations for the Dutch Republic. Utrecht was the most important city in the Netherlands until the Dutch Golden Age, when it was surpassed by Amsterdam as the country's cultural centre and most populous city.\nUtrecht is home to Utrecht University, the largest university in the Netherlands, as well as several other institutions of higher education. Due to its central position within the country, it is an important hub for both rail and road transport; it has the busiest railway station in the Netherlands, Utrecht Centraal. It has the second-highest number of cultural events in the Netherlands, after Amsterdam. In 2012, Lonely Planet included Utrecht in the top 10 of the world's unsung places.\nHistory.\nOrigins (before 650 CE).\nAlthough there is some evidence of earlier inhabitation in the region of Utrecht, dating back to the Stone Age (app. 2200 BCE) and settling in the Bronze Age (app. 1800\u2013800\u00a0BCE), the founding date of the city is usually related to the construction of a Roman fortification (\"castellum\"), probably built in around 50 CE. A series of such fortresses were built after the Roman emperor Claudius decided the empire should not expand further north. To consolidate the border, the Limes Germanicus defense line was constructed along the main branch of the river Rhine, which at that time traversed a more northern route (now known as the Kromme Rijn, \"Crooked Rhine\") compared to today's Rhine flow. These fortresses were designed to house a cohort of about 500 Roman soldiers. Near the fort, settlements grew that housed artisans, traders and soldiers' wives and children.\nIn Roman times, the name of the Utrecht fortress was simply \"Traiectum\", denoting its location at a possible Rhine crossing. Traiectum became Dutch Trecht; with the U from Old Dutch \"uut\" (downriver) added to distinguish U-trecht from Maas-tricht, on the river Meuse. In 11th-century official documents, it was Latinized as Ultra Traiectum. Around the year 200, the wooden walls of the fortification were replaced by sturdier tuff stone walls, remnants of which are still to be found below the buildings around Dom Square.\nFrom the middle of the 3rd century, Germanic tribes regularly invaded the Roman territories. After around 275 the Romans could no longer maintain the northern border, and Utrecht was abandoned. Little is known about the period from 270 to 650. Utrecht is first spoken of again several centuries after the Romans left. Under the influence of the growing realms of the Franks, during Dagobert I's reign in the 7th century, a church was built within the walls of the Roman fortress. In ongoing border conflicts with the Frisians, this first church was destroyed.\nCentre of Christianity in the Netherlands (650\u20131579).\nBy the mid-7th century, British, English and Irish missionaries set out to convert the Frisians. Pope Sergius I appointed their leader, Saint Willibrordus, as bishop of the Frisians. The tenure of Willibrordus is generally considered to be the beginning of the Bishopric of Utrecht. In 723, the Frankish leader Charles Martel bestowed the fortress in Utrecht and the surrounding lands as the base of the bishops. From then on Utrecht became one of the most influential seats of power for the Catholic Church in the Netherlands. The archbishops of Utrecht were based at the uneasy northern border of the Carolingian Empire. In addition, the city of Utrecht had competition from the nearby trading centre Dorestad. After the fall of Dorestad around 850, Utrecht became one of the most important cities in the Netherlands. The importance of Utrecht as a centre of Christianity is illustrated by the election of the Utrecht-born Adriaan Florenszoon Boeyens as pope in 1522 (the last non-Italian pope before John Paul II).\nPrince-bishops.\nWhen the Frankish rulers established the system of feudalism, the Bishops of Utrecht came to exercise worldly power as prince-bishops. The territory of the bishopric not only included the modern province of Utrecht (Nedersticht, 'lower Sticht'), but also extended to the northeast. The feudal conflict of the Middle Ages heavily affected Utrecht. The prince-bishopric was involved in almost continuous conflicts with the Counts of Holland and the Dukes of Guelders. The Veluwe region was seized by Guelders, but large areas in the modern province of Overijssel remained as the Oversticht.\nReligious buildings.\nSeveral churches and monasteries were built inside, or close to, the city of Utrecht. The most dominant of these was the Cathedral of Saint Martin, inside the old Roman fortress. The construction of the present Gothic building was begun in 1254 after an earlier romanesque construction had been badly damaged by fire. The choir and transept were finished from 1320 and were followed then by the ambitious Dom tower. The last part to be constructed was the central nave, from 1420. By that time, however, the age of the great cathedrals had come to an end and declining finances prevented the ambitious project from being finished, the construction of the central nave being suspended before the planned flying buttresses could be finished. Besides the cathedral there were four collegiate churches in Utrecht: St. Salvator's Church (demolished in the 16th century), on the Dom square, dating back to the early 8th century. Saint John (Janskerk), originating in 1040; Saint Peter, building started in 1039 and Saint Mary's church building started around 1090 (demolished in the early 19th century, cloister survives). Besides these churches, the city housed St. Paul's Abbey, the 15th-century beguinage of St. Nicholas, and a 14th-century chapter house of the Teutonic Knights.\nBesides these buildings which belonged to the bishopric, an additional four parish churches were constructed in the city: the Jacobikerk (dedicated to Saint James), founded in the 11th century, with the current Gothic church dating back to the 14th century; the Buurkerk (Neighbourhood-church) of the 11th-century parish in the centre of the city; Nicolaichurch (dedicated to Saint Nicholas), from the 12th century, and the 13th-century Geertekerk (dedicated to Saint Gertrude of Nivelles).\nCity of Utrecht.\nIts location on the banks of the river Rhine allowed Utrecht to become an important trade centre in the Northern Netherlands. The growing town was granted city rights by Henry V at Utrecht on 2 June 1122. When the main flow of the Rhine moved south, the old bed which still flowed through the heart of the town became ever more canalized; and the wharf system was built as an inner city harbour system. On the wharfs, storage facilities (\"werfkelders\") were built, on top of which the main street, including houses, was constructed. The wharfs and the cellars are accessible from a platform at water level with stairs descending from the street level to form a unique structure. The relations between the bishop, who controlled many lands outside of the city, and the citizens of Utrecht was not always easy. The bishop, for example dammed the Kromme Rijn at Wijk bij Duurstede to protect his estates from flooding. This threatened shipping for the city and led the city of Utrecht to commission a canal to ensure access to the town for shipping trade: the Vaartse Rijn, connecting Utrecht to the Hollandse IJssel at IJsselstein.\nThe end of independence.\nIn 1528 the bishop lost secular power over both Neder- and Oversticht\u2014which included the city of Utrecht\u2014to Charles V, Holy Roman Emperor. Charles V combined the Seventeen Provinces (the current Benelux and the northern parts of France) as a personal union. This ended the prince-bishopric of Utrecht, as the secular rule was now the lordship of Utrecht, with the religious power remaining with the bishop, although Charles V had gained the right to appoint new bishops. In 1559 the bishopric of Utrecht was raised to archbishopric to make it the religious centre of the Northern ecclesiastical province in the Seventeen Provinces.\nThe transition from independence to a relatively minor part of a larger union was not easily accepted. To quell uprisings, Charles V struggled to exert his power over the city's citizens who had struggled to gain a certain level of independence from the bishops and were not willing to cede this to their new lord. The heavily fortified castle Vredenburg was built to house a large garrison whose main task was to maintain control over the city. The castle would last less than 50\u00a0years before it was demolished in an uprising in the early stages of the Dutch Revolt.\nRepublic of the Netherlands (1579\u20131806).\nIn 1579 the northern seven provinces signed the Union of Utrecht treaty (Dutch: Unie van Utrecht), in which they decided to join forces against Spanish rule. The Union of Utrecht is seen as the beginning of the Dutch Republic. In 1580, the new and predominantly Protestant state abolished the bishoprics, including the archbishopric of Utrecht. The stadtholders disapproved of the independent course of the Utrecht bourgeoisie and brought the city under much more direct control of the republic, shifting the power towards its dominant province Holland. This was the start of a long period of stagnation of trade and development in Utrecht. Utrecht remained an atypical city in the new republic being about 40% Catholic in the mid-17th century, and even more so among the elite groups, who included many rural nobility and gentry with town houses there.\nThe fortified city temporarily fell to the French invasion in 1672 (the Disaster Year, Dutch: Rampjaar). The French invasion was stopped just west of Utrecht at the Old Hollandic Waterline. In 1674, only two years after the French left, the centre of Utrecht was struck by a tornado. The halt to building before construction of flying buttresses in the 15th century now proved to be the undoing of the cathedral of St Martin church's central section which collapsed, creating the current Dom square between the tower and choir. In 1713, Utrecht hosted one of the first international peace negotiations when the Treaty of Utrecht settled the War of the Spanish Succession. Beginning in 1723, Utrecht became the centre of the non-Roman Old Catholic Churches.\nModern history (1815\u2013present).\nIn the early 19th century, the role of Utrecht as a fortified town had become obsolete. The fortifications of the Nieuwe Hollandse Waterlinie were moved east of Utrecht. The town walls could now be demolished to allow for expansion. The moats remained intact and formed an important feature of the Zocher plantsoen, an English style landscape park that remains largely intact today. Growth of the city increased when, in 1843, a railway connecting Utrecht to Amsterdam was opened. After that, Utrecht gradually became the main hub of the Dutch railway network. With the Industrial Revolution finally gathering speed in the Netherlands and the ramparts taken down, Utrecht began to grow far beyond its medieval centre. When the Dutch government allowed the bishopric of Utrecht to be reinstated by Rome in 1853, Utrecht became the centre of Dutch Catholicism once more. From the 1880s onward, neighbourhoods such as Oudwijk, Wittevrouwen, Vogelenbuurt to the East, and Lombok to the West were developed. New middle-class residential areas, such as Tuindorp and Oog in Al, were built in the 1920s and 1930s. During this period, several Jugendstil houses and office buildings were built, followed by Rietveld who built the Rietveld Schr\u00f6der House (1924), and Dudok's construction of the city theatre (1941).\nDuring World War II, Utrecht was held by German forces until the general German surrender of the Netherlands on 5 May 1945. British and Canadian troops that had surrounded the city entered it after that surrender, on 7 May 1945. Following the end of World War II, the city grew considerably when new neighbourhoods such as Overvecht, Kanaleneiland, Hoograven and Lunetten were built. Around 2000, the Leidsche Rijn area was developed as an extension of the city to the west.\nThe area surrounding Utrecht Centraal railway station and the station itself were developed following modernist ideas of the 1960s, in a brutalist style. This development led to the construction of the shopping mall Hoog Catharijne, the music centre Vredenburg (Hertzberger, 1979), and conversion of part of the ancient canal structure into a highway (Catherijnebaan). Protest against further modernisation of the city centre followed even before the last buildings were finalised. In the early 21st century, the whole area is undergoing change again. The redeveloped music centre TivoliVredenburg opened in 2014 with the original Vredenburg and Tivoli concert and rock and jazz halls brought together in a single building. \nGeography.\nClimate.\nUtrecht experiences a temperate oceanic climate (K\u00f6ppen: \"Cfb\") similar to all of the Netherlands.\nPopulation.\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nUtrecht city had a population of 361,924 in 2022. It is a growing municipality and projections are that the population will surpass 392,000 by 2025.\nUtrecht has a young population, with many inhabitants in the age category from 20 and 30\u00a0years, due to the presence of a large university. About 52% of the population is female, 48% is male. The majority of households (52.5%) in Utrecht are single-person households. About 29% of people living in Utrecht are either married, or have another legal partnership. About 3% of the population of Utrecht is divorced.\nInhabitants by origin.\nFor 62.8% of the population of Utrecht both parents were born in the Netherlands. Approximately 12.4% of the population consists of people with a recent migration background from Western countries, while 24.8% of the population has at least one parent who is of 'non-Western origin' (8.8% from Morocco, 4% Turkey, 3% Surinam and Dutch Caribbean and 9.1% of other countries). \nReligion.\nUtrecht has been the religious centre of the Netherlands since the 8th century. Currently it is the see of the Metropolitan Archbishop of Utrecht, the most senior Dutch Roman Catholic leader. His ecclesiastical province covers the whole kingdom.\nUtrecht is also the see of the archbishop of the Old Catholic Church, titular head of the Union of Utrecht, and the location of the offices of the Protestant Church in the Netherlands, the main Dutch Protestant church.\nAs of 2013, the largest religion is Christianity with 28% of the population being Christian, followed by Islam with 9.9% in 2016 and Hinduism with 0.8%.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nPopulation centres and agglomeration.\nThe city of Utrecht is subdivided into 10 city quarters, all of which have their own neighbourhood council and service centre for civil affairs.\nUtrecht is the centre of a densely populated area, a fact which makes concise definitions of its agglomeration difficult, and somewhat arbitrary. The smaller Utrecht agglomeration of continuously built-up areas counts some 420,000 inhabitants and includes Nieuwegein, IJsselstein and Maarssen. It is sometimes argued that the close by municipalities De Bilt, Zeist, Houten, Vianen, Driebergen-Rijsenburg (Utrechtse Heuvelrug), and Bunnik should also be counted towards the Utrecht agglomeration, bringing the total to 640,000 inhabitants. The larger region, including slightly more remote cities such as Woerden and Amersfoort, counts up to 820,000 inhabitants.\nCityscape.\nUtrecht's cityscape is dominated by the Dom Tower, the tallest belfry in the Netherlands and originally part of the Cathedral of Saint Martin. An ongoing debate is over whether any building in or near the centre of town should surpass the Dom Tower in height (). Nevertheless, some tall buildings are now being constructed that will become part of the skyline of Utrecht. The second-tallest building of the city, the Rabobank-tower, was completed in 2010 and stands tall. Two antennas will increase that height to . Two other buildings were constructed around the Nieuw Galgenwaard stadium (2007). These buildings, the 'Kantoortoren Galghenwert' and 'Apollo Residence', stand and high, respectively.\nThe former Utrecht Main Post Office, built in 1924, is still in the city centre at Neude square, but is now serving as library, see also Utrecht Post Office.\nAnother landmark is the old centre and the canal structure in the inner city. The Oudegracht is a curved canal, partly following the ancient main branch of the Rhine. It is lined with the unique wharf-basement structures that create a two-level street along the canals. The inner city has largely retained its medieval structure, and the moat ringing the old town is largely intact. In the 1970s part of the moat was converted into a motorway. It was then converted back into a waterway, the work being finished in 2020.\nBecause of the role of Utrecht as a fortified city, construction outside the medieval centre and its city walls was restricted until the 19th century. Surrounding the medieval core there is a ring of late-19th- and early-20th-century neighbourhoods, with newer neighbourhoods positioned farther out. The eastern part of Utrecht remains fairly open. The Dutch Water Line, moved east of the city in the early 19th century, required open lines of fire, thus prohibiting all permanent constructions until the middle of the 20th century on the east side of the city.\nDue to the past importance of Utrecht as a religious centre, several monumental churches were erected, many of which have survived. Most prominent is the Dom Church. Other notable churches include the romanesque St Peter's and St John's churches; the gothic churches of St James and St Nicholas; and the Buurkerk, now converted into a museum for automatically playing musical instruments.\nTransport.\nPublic transport.\nBecause of its central location, Utrecht is well connected to the rest of the Netherlands and has a well-developed public transport network.\nHeavy rail.\nUtrecht Centraal is the main railway station of Utrecht and is the largest in the country. There are regular intercity services to all major Dutch cities, including direct services to Schiphol Airport. Utrecht Centraal is a station on the night service, providing an all-night service to (among others) Schiphol Airport, Amsterdam and Rotterdam, seven days a week. International InterCityExpress (ICE) services to Germany through Arnhem call at Utrecht Centraal. Regular local trains to all areas surrounding Utrecht also depart from Utrecht Centraal; and service several smaller stations: Utrecht Lunetten; Utrecht Vaartsche Rijn; Utrecht Overvecht; Utrecht Leidsche Rijn; Utrecht Terwijde; Utrecht Zuilen and Vleuten. A former station Utrecht Maliebaan closed in 1939 and has since been converted into the Dutch Railway Museum.\nUtrecht is the location of the headquarters of Nederlandse Spoorwegen (English: \"Dutch Railways\"), the largest rail operator in the Netherlands, and ProRail, the state-owned company responsible for the construction and maintenance of the country's rail infrastructure.\nLight rail.\nThe Utrecht sneltram is a light rail system with three routes connecting Utrecht Centraal railway station to the suburbs of IJsselstein and Nieuwegein, as well as the Uithof district. The sneltram began operations in 1983 and is currently operated under the U-OV brand by the private transport company Qbuzz. The system has a total length of 18.3 km and 54 trainsets, carrying over 9 million riders in 2023.\nUtrecht is the only city among the four largest in the Netherlands (the others being Amsterdam, The Hague, and Rotterdam) to award a public transportation concession by tender. Qbuzz will hold the current concession until December 2025, after which Transdev will assume operations until 2035.\nBus transport.\nUtrecht Centraal railway station also serves local and regional buses at its west side (Centrumzijde) and at its east side (Jaarbuursplein), where both sides have connections to the Utrecht sneltram. Fifty local bus routes are operated by Qbuzz under the U-OV brand until December 2025 when Transdev will take over the concession. The local bus fleet is one of Europe's cleanest, using only buses compliant with the Euro-VI standard as well as electric buses for inner-city transport. The plan is that all buses be zero-emission by 2028. Regional buses from the city are operated by Arriva.\nThe Utrecht Centraal railway station is also served by the pan-European services of Eurolines. Furthermore, it acts as departure and arrival place of many coach companies serving holiday resorts in Spain and France\u2014and during winter in Austria and Switzerland.\nCycling.\nLike most Dutch cities, Utrecht has an extensive network of cycle paths, making cycling safe and popular. 51% of journeys within the city are by bicycle, more than any other mode of transport. Bicycles are used by young and old people, and by individuals and families. They are mostly traditional, upright, steel-framed bicycles, with few gears. There are also bucket bikes for carrying cargo such as groceries or small children. Thanks in part to the access provided by bicycles, 100% of the population lives in a 15-minute city and more than 90% can get to the major destination types within 10 minutes. \nIn 2014, the city council decided to build the world's largest bicycle parking station, near the Central Railway Station. This three-floor construction cost over \u20ac30\u00a0million and can hold 12,500 bicycles. The bicycle parking station was built in stages, with the first part opening in August 2017, and the final section (after some delay) being opened on 19 August 2019.\nRoad transport.\nUtrecht is well-connected to the Dutch road network. Two of the most important major roads serve the city of Utrecht: the A12 and A2 motorways connect Amsterdam, Arnhem, The Hague and Maastricht, as well as Belgium and Germany. Other major motorways in the area are the Almere\u2013Breda A27 and the Utrecht\u2013Groningen A28. Due to the increasing traffic and the ancient city plan, traffic congestion is a common phenomenon in and around Utrecht, causing elevated levels of air pollutants. This has led to a passionate debate in the city about the best way to improve the city's air quality.\nShipping.\nUtrecht has an industrial port located on the Amsterdam-Rijnkanaal. The container terminal has a capacity of 80,000 containers a year. In 2003, the port facilitated the transport of four million tons of cargo; mostly sand, gravel, fertiliser and fodder. Additionally, some tourist boat trips are organised from various places on the Oudegracht; and the city is connected to touristic shipping routes through sluices.\nEconomy.\nProduction industry constitutes a small part of the economy of Utrecht. The economy of Utrecht depends for a large part on the several large institutions located in the city. It is the centre of the Dutch railway network and the location of the head office of Nederlandse Spoorwegen. ProRail is headquartered in \"De Inktpot\" (The Inkwell), the largest brick building in the Netherlands (the \"UFO\" featured on its fa\u00e7ade stems from an art program in 2000). Rabobank, a large bank, has its headquarters in Utrecht.\nUtrecht is also informally considered the \"capital\" of the Dutch games industry. It was named by Business Finland in 2023 as one of several capitals for the European games industry as a whole. Utrecht's influence in this field was caused by video game development courses at its universities, which were the first such courses in Europe when launched in 2002. Since 2008 Utrecht has also been home to the studio incubator program Dutch Game Garden, which has launched a number of studios in the area. By 2014 the program had created 200 jobs. Utrecht is also home to Nixxes Software (a PlayStation Studios subsidiary) as well as Sokpop Collective.\nEducation.\nUtrecht hosts several large institutions of higher education. The most prominent of these is Utrecht University (est. 1636), the largest university of the Netherlands with 30,449 students (as of 2012[ [update]]). The university is partially based in the inner city as well as in the Uithof campus area, on the east side of the city. According to Shanghai Jiaotong University's university ranking in 2014, it is the 57th-best university in the world. Utrecht also houses the much smaller University of Humanistic Studies, which houses about 400 students.\nUtrecht is home of one of the locations of TIAS School for Business and Society, focused on post-experience management education and the largest management school of its kind in the Netherlands. In 2008, its executive MBA program was rated the 24th best program in the world by the \"Financial Times\".\nUtrecht is also home to two other large institutions of higher education: the vocational university Hogeschool Utrecht (37,000 students), with locations in the city and the Uithof campus; and the HKU Utrecht School of the Arts (3,000 students).\nThere are many schools for primary and secondary education, allowing parents to select from different philosophies and religions in the school as is inherent in the Dutch school system.\nCulture.\nUtrecht city has an active cultural life, and in the Netherlands is second only to Amsterdam. There are several theatres and theatre companies. The 1941 main city theatre was built by Dudok. In addition to theatres, there is a large number of cinemas including three arthouse cinemas. Utrecht is host to the international Early Music Festival (Festival Oude Muziek, for music before 1800) and the Netherlands Film Festival. The city has an important classical music hall Vredenburg (1979 by Herman Hertzberger). Its acoustics are considered among the best of the 20th-century original music halls. The original Vredenburg music hall has been redeveloped as part of the larger station area redevelopment plan and in 2014 gained additional halls that allowed its merger with the rock club Tivoli and the SJU jazzpodium. There are several other venues for music throughout the city. Young musicians are educated in the conservatory, a department of the Utrecht School of the Arts. There is a specialised museum of automatically playing musical instruments.\nThere are many art galleries in Utrecht. There are also several foundations to support art and artists. Training of artists is done at the Utrecht School of the Arts. The Centraal Museum has many exhibitions on the arts, including a permanent exhibition on the works of Utrecht resident illustrator Dick Bruna, who is best known for creating Miffy (\"Nijntje\", in Dutch). BAK, [Dutch: \"Basis voor Actuele Kunst,\" Basis for Contemporary Art] offers contemporary art exhibitions and public events, as well as a Fellowship program for practitioners involved in contemporary arts, theory and activisms. Although street art is illegal in Utrecht, the Utrechtse Kabouter, a picture of a gnome with a red hat, became a common sight in 2004. Utrecht also houses one of the landmarks of modern architecture, the 1924 Rietveld Schr\u00f6der House, which is listed on UNESCO's World Heritage Sites.\nEvery Saturday, a paviour adds another letter to \"The Letters of Utrecht\", an endless poem in the cobblestones of the Oude Gracht in Utrecht. With the \"Letters\", Utrecht has a social sculpture as a growing monument created for the benefit of future people.\nTo promote culture, Utrecht city organizes cultural Sundays. During a thematic Sunday, several organisations create a program which is open to everyone without, or with a substantially reduced, admission fee. There are also initiatives for amateur artists. The city subsidises an organisation for amateur education in arts aimed at all inhabitants (Utrechts Centrum voor de Kunsten), as does the university for its staff and students. Additionally there are also several private initiatives. The city council provides coupons for discounts to inhabitants who receive welfare to be used with many of the initiatives.\nIn 2017, Utrecht was named as a UNESCO City of Literature. In 2025 the national literature museum will move from the Hague to Utrecht.\nSports.\nUtrecht is home to the premier league (professional) football club FC Utrecht, which plays in Stadium Nieuw Galgenwaard. It is also the home of Kampong, the largest (amateur) sportsclub in the Netherlands (4,500 members), SV Kampong. Kampong features field hockey, association football, cricket, tennis, squash and boules. Kampong's men and women top hockey squads play in the highest Dutch hockey league, the Rabohoofdklasse. Utrecht is also home to baseball and softball club UVV, which plays in the highest Dutch baseball league: de Hoofdklasse. The rugby culture in Utrecht is carried by the USRS, that has been playing in the highest leagues of the Dutch rugby pyramid since 1967. Utrecht's waterways are used by several rowing clubs. Viking is a large club open to the general public, and the student clubs Orca and Triton compete in the Varsity each year.\nIn July 2013, Utrecht hosted the European Youth Olympic Festival, in which more than 2,000 young athletes competed in nine Olympic sports. In July 2015, Utrecht hosted the Grand D\u00e9part and first stage of the Tour de France.\nMuseums.\nUtrecht has several smaller and larger museums. Many of those are located in the southern part of the old town, the Museumkwartier.\nMusic and events.\nThe city has several music venues such as TivoliVredenburg, Tivoli De Helling, ACU, Moira, EKKO, dB's and RASA. Utrecht hosts the yearly Utrecht Early Music Festival (Festival Oude Muziek). Several Editions of the Thunderdome, a large gabber music event, have been held in Jaarbeurs Utrecht. The city also hosts Trance Energy there. Every summer there used to be the \"Summer Darkness\" festival, which celebrated goth culture and music. In November the Le Guess Who? festival, focused on indie rock, art rock and experimental rock, takes place in many of the city's venues.\nTheatre.\nThere are two main theatres in the city, the Theater Kikker and the Stadsschouwburg Utrecht. De Parade, a travelling theatre festival, performs in Utrecht in summer. The city also hosts the yearly Festival aan de Werf which offers a selection of contemporary international theatre, together with visual arts, public art and music.\n\"See also the category \"\nNotable people from Utrecht.\nOver the ages famous people have been born or raised in Utrecht.\nAmong the most famous Utrechters are:\nInternational relations.\nTwin towns.\nUtrecht is twinned with:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50335", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=50335", "title": "John Polkinghorne", "text": "Physicist and priest (1930\u20132021)\nJohn Charlton Polkinghorne (16 October 1930 \u2013 9 March 2021) was a Cornish theoretical physicist, theologian, and Anglican priest. A prominent and leading voice explaining the relationship between science and religion, he was professor of mathematical physics at the University of Cambridge from 1968 to 1979, when he resigned his chair to study for the priesthood, becoming an ordained Anglican priest in 1982. He served as the president of Queens' College, Cambridge, from 1988 until 1996.\nPolkinghorne was the author of five books on physics and twenty-six on the relationship between science and religion; his publications include \"The Quantum World\" (1989), \"Quantum Physics and Theology: An Unexpected Kinship\" (2005), \"Exploring Reality: The Intertwining of Science and Religion\" (2007), and \"Questions of Truth\" (2009). \"The Polkinghorne Reader\" (edited by Thomas Jay Oord) provides key excerpts from Polkinghorne's most influential books. He was knighted in 1997 and in 2002 received the \u00a31-million Templeton Prize, awarded for exceptional contributions to affirming life's spiritual dimension.\nEarly life and education.\nPolkinghorne was born in Weston-super-Mare in Somerset on 16 October 1930 to Dorothy Charlton, the daughter of a groom and George Polkinghorne, who worked for the post office. John was the couple's third child. He had a brother, Peter, and a sister, Ann, who died when she was six, one month before John's birth. Peter died in 1942 while flying for the Royal Air Force during the Second World War. Polkinghorne's father was from a large Cornish family but John's parents became estranged from his grandparents before he was born. Despite being born in Somerset he identified himself as Cornish, rather than English, part of the Celtic fringe.\nHe was educated at the local primary school in Street, Somerset, then was taught by a friend of the family at home, and later at a Quaker school. When he was 11 he went to Elmhurst Grammar School in Street, and when his father was promoted to head postmaster in Ely in 1945, Polkinghorne was transferred to The Perse School, Cambridge. Following National Service in the Royal Army Educational Corps from 1948 to 1949, he read mathematics at Trinity College, Cambridge, graduating in 1952 as Senior Wrangler, then earned his PhD in physics in 1955, supervised by the Nobel laureate Abdus Salam in the group led by Paul Dirac.\nCareer.\nPhysics.\nPolkinghorne joined the Christian Union of UCCF while at Cambridge and met his future wife, Ruth Martin, another member of the union and also a mathematics student. They married on 26 March 1955, and at the end of that year sailed from Liverpool to New York. Polkinghorne accepted a postdoctoral Harkness Fellowship with the California Institute of Technology, where he worked with Murray Gell-Mann. Toward the end of the fellowship he was offered a position as lecturer at the University of Edinburgh, which he took up in 1956.\nAfter two years in Scotland, he returned to teach at Cambridge in 1958. He was promoted to reader in 1965, and in 1968 was offered a professorship in mathematical physics, a position he held until 1979, his students including Brian Josephson and Martin Rees. For 25 years, he worked on theories about elementary particles, played a role in the discovery of the quark, and researched the analytic and high-energy properties of Feynman integrals and the foundations of S-matrix theory. While employed by Cambridge, he also spent time at Princeton, Berkeley, Stanford, and at CERN in Geneva. He was elected a Fellow of the Royal Society in 1974.\nPriesthood and Queens' College.\nPolkinghorne decided to train for the priesthood in 1977. He said in an interview that he felt he had done his bit for science after 25 years, and that his best mathematical work was probably behind him; Christianity had always been central to his life, so ordination offered an attractive second career. He resigned his chair in 1979 to study at Westcott House, Cambridge, an Anglican theological college, becoming an ordained priest on 6 June 1982 (Trinity Sunday). The ceremony was held at Trinity College, Cambridge, and presided over by Bishop John A.\u00a0T. Robinson. He worked for five years as a curate in south Bristol, then as vicar in Blean, Kent, before returning to Cambridge in 1986 as dean of chapel at Trinity Hall. He became the president of Queens' College that year, a position he held until his retirement in 1996. He served as canon theologian of Liverpool Cathedral from 1994 to 2005. Polkinghorne died on 9 March 2021 at the age of 90.\nAwards.\nIn 1997 Polkinghorne was made a Knight Commander of the Order of the British Empire (KBE), although as an ordained priest in the Church of England, he was not styled as \"Sir John Polkinghorne\". He was an honorary fellow of St Chad's College, Durham, and was awarded an honorary doctorate by the University of Durham in 1998; and in 2002 was awarded the Templeton Prize for his contributions to research at the interface between science and religion. He spoke on \"The Universe as Creation\" at the Trotter Prize ceremony in 2003.\nHe has been a member of the BMA Medical Ethics Committee, the General Synod of the Church of England, the Doctrine Commission, and the Human Genetics Commission. He served as chairman of the governors of The Perse School from 1972 to 1981. He was a fellow of Queens' College, Cambridge, and was for 10 years a canon theologian of Liverpool Cathedral. He was a founding member of the Society of Ordained Scientists and also of the International Society for Science and Religion, of which he was the first president. He was selected to give the prestigious Gifford Lectures in 1993\u20131994, which he later published as \"The Faith of a Physicist\".\nIn 2006 he was awarded an honorary doctorate by the Hong Kong Baptist University as part of their 50-year celebrations. This included giving a public lecture on \"The Dialogue between Science and Religion and Its Significance for the Academy\" and an \"East\u2013West Dialogue\" with Yang Chen-Ning, a Nobel laureate in physics. He was a member of staff of the Psychology and Religion Research Group at Cambridge University. He was an honorary fellow of St Edmund's College, Cambridge.\nIdeas.\nPolkinghorne said in an interview that he believes his move from science to religion has given him binocular vision, though he understands that it has aroused the kind of suspicion \"that might follow the claim to be a vegetarian butcher.\" He describes his position as critical realism and believes that science and religion address aspects of the same reality. It is a consistent theme of his work that when he \"turned his collar around\" he did not stop seeking truth. He argues there are five points of comparison between the ways in which science and theology pursue truth: moments of enforced radical revision, a period of unresolved confusion, new synthesis and understanding, continued wrestling with unresolved problems, deeper implications.\nHe suggests that the mechanistic explanations of the world that have continued from Laplace to Richard Dawkins should be replaced by an understanding that most of nature is cloud-like rather than clock-like. He regards the mind, soul and body as different aspects of the same underlying reality\u2014\"dual aspect monism\"\u2014writing that \"there is only one stuff in the world (not two\u2014the material and the mental), but it can occur in two contrasting states (material and mental phases, a physicist might say) which explain our perception of the difference between mind and matter.\" He believes that standard physical causation cannot adequately describe the manifold ways in which things and people interact, and uses the phrase \"active information\" to describe how, when several outcomes are possible, there may be higher levels of causation that choose which one occurs.\nSometimes Christianity seems to him to be just too good to be true, but when this sort of doubt arises he says to himself, \"All right then, deny it\", and writes that he knows this is something he could never do.\nOn the existence of God.\nPolkinghorne considers that \"the question of the existence of God is the single most important question we face about the nature of reality\" and quotes, with approval, Sir Anthony Kenny: \"After all, if there is no God, then God is incalculably the greatest single creation of the human imagination.\" He addresses the questions of \"Does the concept of God make sense? If so, do we have reason for believing in such a thing?\" He is \"cautious about our powers to assess coherence\", pointing out that in 1900 a \"competent... undergraduate could have demonstrated the 'incoherence'\" of quantum ideas. He suggests that \"the nearest analogy in the physical world [to God] would be... the Quantum Vacuum.\"\nHe suggests that God is the ultimate answer to Leibniz's great question \"why is there something rather than nothing?\" The atheist's \"plain assertion of the world's existence\" is a \"grossly impoverished view of reality... [arguing that] theism explains more than a reductionist atheism can ever address.\". \nHe is very doubtful of St Anselm's Ontological Argument. Referring to G\u00f6del's incompleteness theorem, he said: \"If we cannot prove the consistency of arithmetic it seems a bit much to hope that God's existence is easier to deal with,\" concluding that God is \"ontologically necessary, but not logically necessary.\" He \"does not assert that God's existence can be demonstrated in a logically coercive way (any more than God's non-existence can) but that theism makes more sense of the world, and of human experience, than does atheism.\" He cites in particular:\nOn free will.\nPolkinghorne believes that \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The well-known free will defence in relation to moral evil asserts that a world with a possibility of sinful people is better than one with perfectly programmed machines. The tale of human evil is such that one cannot make that assertion without a quiver, but I believe that it is true nevertheless. I have added to it the free-process defence, that a world allowed to make itself is better than a puppet theatre with a Cosmic Tyrant. I think that these two defences are opposite sides of the same coin, that our nature is inextricably linked with that of the physical world which has given us birth.\nOn creationism.\nFollowing the resignation of Michael Reiss, the director of education at the Royal Society\u2014who had controversially argued that school pupils who believed in creationism should be used by science teachers to start discussions, rather than be rejected \"per se\"\u2014Polkinghorne argued in \"The Times\" that \"As a Christian believer I am, of course, a creationist in the proper sense of the term, for I believe that the mind and the purpose of a divine Creator lie behind the fruitful history and remarkable order of the universe which science explores. But I am certainly not a creationist in that curious North American sense, which implies interpreting Genesis 1 in a flat-footed literal way and supposing that evolution is wrong.\"\nCritical reception.\nNancy Frankenberry, Professor of Religion at Dartmouth College, has described Polkinghorne as the finest British theologian/scientist of our time, citing his work on the possible relationship between chaos theory and natural theology. Owen Gingerich, an astronomer and former Harvard professor, has called him a leading voice on the relationship between science and religion.\nThe British philosopher Simon Blackburn has criticized Polkinghorne for using primitive thinking and rhetorical devices instead of engaging in philosophy. When Polkinghorne argues that the minute adjustments of cosmological constants for life points towards an explanation beyond the scientific realm, Blackburn argues that this relies on a natural preference for explanation in terms of agency. Blackburn writes that he finished Polkinghorne's books in \"despair at humanity's capacity for self-deception.\" Against this, Freeman Dyson called Polkinghorne's arguments on theology and natural science \"polished and logically coherent.\" The novelist Simon Ings, writing in the \"New Scientist\", said Polkinghorne's argument for the proposition that God is real is cogent and his evidence elegant.\nRichard Dawkins, formerly Professor for Public Understanding of Science at Oxford, writes that the same three names of British scientists who are also sincerely religious crop up with the \"likable familiarity of senior partners in a firm of Dickensian lawyers\": Arthur Peacocke, Russell Stannard, and John Polkinghorne, all of whom have either won the Templeton Prize or are on its board of trustees. Dawkins writes that he is not so much bewildered by their belief in a cosmic lawgiver, but by their beliefs in the minutiae of Christianity, such as the resurrection and forgiveness of sins, and that such scientists, in Britain and in the US, are the subject of bemused bafflement among their peers. Polkinghorne responded that \"debating with Dawkins is hopeless, because there's no give and take. He doesn't give you an inch. He just says no when you say yes.\" Nicholas Beale writes in \"Questions of Truth\", which he co-authored with Polkinghorne, that he hopes Dawkins will be a bit less baffled once he reads it.\nA.\u00a0C. Grayling criticized the Royal Society for allowing its premises to be used in connection with the launch of \"Questions of Truth\", describing it as a scandal, and suggesting that Polkinghorne had exploited his fellowship there to publicize a \"weak, casuistical and tendentious pamphlet.\" After implying that the book's publisher, Westminster John Knox, was a self-publisher, Grayling went on to write that Polkinghorne and others were eager to see the credibility accorded to scientific research extended to religious perspectives through association.\nIn contrast to Grayling, science historian Edward B. Davis praises \"Questions of Truth\", saying the book provides \"the kind of technical information... that scientifically trained readers will appreciate\u2014yet they can be read profitably by anyone interested in science and Christianity.\" Davis concludes, \"It hasn't been easy to steer a middle course between fundamentalism and modernism, particularly on issues involving science. Polkinghorne has done that very successfully for a generation, and for this he ought to be both appreciated and emulated.\"\nPublished works.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nPolkinghorne wrote 34 books, translated into 18 languages; 26 concern science and religion, often for a popular audience.\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50337", "revid": "44763467", "url": "https://en.wikipedia.org/wiki?curid=50337", "title": "Fructose", "text": "Simple ketonic monosaccharide found in many plants\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nFructose (), or fruit sugar, is a common monosaccharide, i.e. a simple sugar. It is classified as a reducing hexose, more specifically a ketonic simple sugar found in many plants, where it is often bonded to glucose to form the disaccharide sucrose. In terms of structure, it is a C-4 epimer of glucose. A white, water-soluble solid,It is one of the three dietary monosaccharides, along with glucose and galactose.\nFructose is found in honey, tree and vine fruits, flowers, berries, and most root vegetables.\nHistory.\nFructose was discovered by French chemist Augustin-Pierre Dubrunfaut in 1847. The name \"fructose\" was coined in 1857 by the English chemist William Allen Miller. Pure, dry fructose is a sweet, white, odorless, crystalline solid, and is the most water-soluble of all the sugars.\nEtymology.\nThe word \"fructose\" was coined in 1857 from the Latin for \"fructus\" (fruit) and the generic chemical suffix for sugars, \"-ose\". It is also called fruit sugar and levulose or laevulose, due to its ability to rotate plane polarised light in a laevorotary fashion (anti-clockwise/to the left) when a beam is shone through it in solution. Likewise, dextrose (an isomer of glucose) is given its name due to its ability to rotate plane polarised light in a dextrorotary fashion (clockwise/to the right).\nChemical structure.\nFructose adopts both cyclic six- and five-membered structure, The six membered ring can exist as either the \u03b2-d-fructopyranose and \u03b1-d-fructopyranose. The five-membered rings exists as either of two isomers \u03b2-d-fructofuranose and \u03b1-d-fructofuranose. Additionally, an acyclic (open-chain) form exists: \"keto\"-d-fructose. At 70% and 22% respectively, fructopyranose and fructofuranose are the dominant species in aqueous solution.\nChemical reactions.\nFructose and fermentation.\nFructose may be anaerobically fermented by yeast and bacteria. Yeast enzymes convert sugar (sucrose, glucose, and fructose, but not lactose) to ethanol and carbon dioxide. Some of the carbon dioxide produced during fermentation will remain dissolved in water, where it will reach equilibrium with carbonic acid. The dissolved carbon dioxide and carbonic acid produce the carbonation in some fermented beverages, such as champagne.\nFructose and Maillard reaction.\nFructose undergoes the Maillard reaction, non-enzymatic browning, with amino acids. Because fructose exists to a greater extent in the open-chain form than does glucose, the initial stages of the Maillard reaction occur more rapidly than with glucose. Therefore, fructose has potential to contribute to changes in food palatability, as well as other nutritional effects, such as excessive browning, volume and tenderness reduction during cake preparation, and formation of mutagenic compounds.\nDehydration.\nFructose can be dehydrated to give hydroxymethylfurfural (\"HMF\", C6H6O3), which can be processed into liquid dimethylfuran (C6H8O).\nThis conversion has long been proposed, not implemented, as a route to green fuels.\nPhysical and functional properties.\nSweetness of fructose.\nThe primary reason that fructose is used commercially in foods and beverages, besides its low cost, is its high relative sweetness. It is the sweetest of all naturally occurring carbohydrates. The relative sweetness of fructose has been reported in the range of 1.2\u20131.8 times that of sucrose. However, it is the 6-membered ring form of fructose that is sweeter; the 5-membered ring form tastes about the same as usual table sugar. Warming fructose leads to formation of the 5-membered ring form. Therefore, the relative sweetness decreases with increasing temperature. However, it has been observed that the absolute sweetness of fructose is identical at 5\u00a0\u00b0C as 50\u00a0\u00b0C and thus the relative sweetness to sucrose is not due to anomeric distribution but a decrease in the absolute sweetness of sucrose at higher temperatures.\nThe sweetness of fructose is perceived earlier than that of sucrose or glucose, and the taste sensation reaches a peak (higher than that of sucrose), and diminishes more quickly than that of sucrose. Fructose can also enhance other flavors in the system.\nFructose exhibits a sweetness synergy effect when used in combination with other sweeteners. The relative sweetness of fructose blended with sucrose, aspartame, or saccharin is perceived to be greater than the sweetness calculated from individual components.\nFructose solubility and crystallization.\nFructose has higher water solubility than other sugars, as well as other sugar alcohols. Fructose is, therefore, difficult to crystallize from an aqueous solution. Sugar mixes containing fructose, such as candies, are softer than those containing other sugars because of the greater solubility of fructose.\nFructose hygroscopicity and humectancy.\nFructose is quicker to absorb moisture and slower to release it to the environment than sucrose, glucose, or other nutritive sweeteners. Fructose is an excellent humectant and retains moisture for a long period of time even at low relative humidity (RH). Therefore, fructose can contribute a more palatable texture, and longer shelf life to the food products in which it is used.\nFreezing point.\nFructose has a greater effect on freezing point depression than disaccharides or oligosaccharides, which may protect the integrity of cell walls of fruit by reducing ice crystal formation. However, this characteristic may be undesirable in soft-serve or hard-frozen dairy desserts.\nFructose and starch functionality in food systems.\nFructose increases starch viscosity more rapidly and achieves a higher final viscosity than sucrose because fructose lowers the temperature required during gelatinizing of starch, causing a greater final viscosity.\nAlthough some artificial sweeteners are not suitable for home baking, many traditional recipes use fructose.\nSources.\nCommercial production.\nFructose is produced on an industrial scale from three precursors: starch, sucrose, and inulin. \nSucrose is an organic compound with one molecule of glucose covalently linked to one molecule of fructose. All forms of fructose, including those found in fruits and juices, are commonly added to foods and drinks for palatability and taste enhancement, and for browning of some foods, such as baked goods.\nFructose is found in honey, tree and vine fruits, flowers, berries, and most root vegetables.\nStarch is hydrolyzed to glucose, which is converted to fructose by the enzyme glucose isomerase. This mixture is high-fructose corn syrup. At 60 \u00b0C, the conversion gives a 1:1 mixture of glucose and fructose. Sucrose is hydrolyzed to give its monomeric precursors glucose and fructose. Inulin is also converted to fructose on a commercial scale. As of 2004[ [update]], about 240,000 tonnes of crystalline fructose were being produced annually.Commercially, maize is a major source of starch. Sugar cane and sugar beets are sources of sucrose is a compound with one molecule of glucose covalently linked to one molecule of fructose. Inulin is found in chicory, \nAll forms of fructose, including those found in fruits and juices, are commonly added to foods and drinks for palatability and taste enhancement, and for browning of some foods, such as baked goods.\nNatural sources.\nNatural sources of fructose include fruits, vegetables (including sugar cane), and honey. Fructose is often further concentrated from these sources. The highest dietary sources of fructose, besides pure crystalline fructose, are foods containing white sugar (sucrose), high-fructose corn syrup, agave nectar, honey, molasses, maple syrup, fruit and fruit juices, as these have the highest percentages of fructose (including fructose in sucrose) per serving compared to other common foods and ingredients. Fructose exists in foods either as a free monosaccharide or bound to glucose as sucrose, a disaccharide. Fructose, glucose, and sucrose may all be present in food; however, different foods will have varying levels of each of these three sugars.\nThe sugar contents of common fruits and vegetables are presented in Table 1. In general, in foods that contain free fructose, the ratio of fructose to glucose is approximately 1:1; that is, foods with fructose usually contain about an equal amount of free glucose. A value that is above 1 indicates a higher proportion of fructose to glucose and below 1 a lower proportion. Some fruits have larger proportions of fructose to glucose compared to others. For example, apples and pears contain more than twice as much free fructose as glucose, while for apricots the proportion is less than half as much fructose as glucose.\nApple and pear juices are of particular interest to pediatricians because the high concentrations of free fructose in these juices can cause diarrhea in children. The cells (enterocytes) that line children's small intestines have less affinity for fructose absorption than for glucose and sucrose. Unabsorbed fructose creates higher osmolarity in the small intestine, which draws water into the gastrointestinal tract, resulting in osmotic diarrhea. This phenomenon is discussed in greater detail in the Health Effects section.\nTable 1 also shows the amount of sucrose found in common fruits and vegetables. Sugarcane and sugar beet have a high concentration of sucrose, and are used for commercial preparation of pure sucrose. Extracted cane or beet juice is clarified, removing impurities; and concentrated by removing excess water. The end product is 99.9%-pure sucrose. Sucrose-containing sugars include common white sugar and powdered sugar, as well as brown sugar.\n &lt;templatestyles src=\"Citation/styles.css\"/&gt;^A The carbohydrate figure is calculated in FoodData Central and does not always correspond to the sum of the sugars, the starch, and the \"dietary fiber\".\nAll data with a unit of g (gram) are based on 100\u00a0g of a food item.\nThe fructose/glucose ratio is calculated by dividing the sum of free fructose plus half sucrose by the sum of free glucose plus half sucrose.\nFructose is also found in the manufactured sweetener, high-fructose corn syrup (HFCS), which is produced by treating corn syrup with enzymes, converting glucose into fructose. The common designations for fructose content, HFCS-42 and HFCS-55, indicate the percentage of fructose present in HFCS. HFCS-55 is commonly used as a sweetener for soft drinks, whereas HFCS-42 is used to sweeten processed foods, breakfast cereals, bakery foods, and some soft drinks.\nCarbohydrate content of commercial sweeteners (percent on dry basis).\n for HFCS, and USDA for fruits and vegetables and the other refined sugars.\nCane and beet sugars have been used as the major sweetener in food manufacturing for centuries. However, with the development of HFCS, a significant shift occurred in the type of sweetener consumption in certain countries, particularly the United States. Contrary to the popular belief, however, with the increase of HFCS consumption, the total fructose intake relative to the total glucose intake has not dramatically changed. Granulated sugar is 99.9%-pure sucrose, which means that it has equal ratio of fructose to glucose. The most commonly used forms of HFCS, HFCS-42, and HFCS-55, have a roughly equal ratio of fructose to glucose, with minor differences. HFCS has simply replaced sucrose as a sweetener. Therefore, despite the changes in the sweetener consumption, the ratio of glucose to fructose intake has remained relatively constant.\nNutritional information.\nProviding 368 kcal per 100 grams of dry powder (table), fructose has 95% the caloric value of sucrose by weight. Fructose powder is 100% carbohydrates and supplies no other nutrients in significant amount (table).\nFructose digestion and absorption in humans.\nFructose exists in foods either as a monosaccharide (free fructose) or as a unit of a disaccharide (sucrose). Free fructose is a ketonic simple sugar and one of the three dietary monosaccharides absorbed directly by the intestine. When fructose is consumed in the form of sucrose, it is digested (broken down) and then absorbed as free fructose. As sucrose comes into contact with the membrane of the small intestine, the enzyme sucrase catalyzes the cleavage of sucrose to yield one glucose unit and one fructose unit, which are then each absorbed. After absorption, it enters the hepatic portal vein and is directed toward the liver.\nThe mechanism of fructose absorption in the small intestine is not completely understood. Some evidence suggests active transport, because fructose uptake has been shown to occur against a concentration gradient. However, the majority of research supports the claim that fructose absorption occurs on the mucosal membrane via facilitated transport involving GLUT5 transport proteins. Since the concentration of fructose is higher in the lumen, fructose is able to flow down a concentration gradient into the enterocytes, assisted by transport proteins. Fructose may be transported out of the enterocyte across the basolateral membrane by either GLUT2 or GLUT5, although the GLUT2 transporter has a greater capacity for transporting fructose, and, therefore, the majority of fructose is transported out of the enterocyte through GLUT2.\nCapacity and rate of absorption.\nThe absorption capacity for fructose in monosaccharide form ranges from less than 5\u00a0g to 50\u00a0g (per individual serving) and adapts with changes in dietary fructose intake. Studies show the greatest absorption rate occurs when glucose and fructose are administered in equal quantities. When fructose is ingested as part of the disaccharide sucrose, absorption capacity is much higher because fructose exists in a 1:1 ratio with glucose. It appears that the GLUT5 transfer rate may be saturated at low levels, and absorption is increased through joint absorption with glucose. One proposed mechanism for this phenomenon is a glucose-dependent cotransport of fructose.\nIn addition, fructose transfer activity increases with dietary fructose intake. The presence of fructose in the lumen causes increased mRNA transcription of GLUT5, leading to increased transport proteins. High-fructose diets (&gt;2.4 g/kg body wt) increase the transport proteins within three days of intake.\nMalabsorption.\nSeveral studies have measured the intestinal absorption of fructose using the hydrogen breath test. These studies indicate that fructose is not completely absorbed in the small intestine. When fructose is not absorbed in the small intestine, it is transported into the large intestine, where it is fermented by the colonic flora. Hydrogen is produced during the fermentation process and dissolves into the blood of the portal vein. This hydrogen is transported to the lungs, where it is exchanged across the lungs and is measurable by the hydrogen breath test. The colonic flora also produces carbon dioxide, short-chain fatty acids, organic acids, and trace gases in the presence of unabsorbed fructose. The presence of gases and organic acids in the large intestine causes gastrointestinal symptoms such as bloating, diarrhea, flatulence, and gastrointestinal pain. Exercise immediately after consumption can exacerbate these symptoms by decreasing transit time in the small intestine, resulting in a greater amount of fructose emptied into the large intestine.\nFructose metabolism.\nThe liver converts most fructose and galactose into glucose for distribution in the bloodstream or deposition into glycogen.\nAll three dietary monosaccharides are transported into the liver by the GLUT2 transporter. Fructose and galactose are phosphorylated in the liver by fructokinase (Km= 0.5 mM) and galactokinase (Km = 0.8 mM), respectively. By contrast, glucose tends to pass through the liver (Km of hepatic glucokinase = 10 mM) and can be metabolised anywhere in the body. Uptake of fructose by the liver is not regulated by insulin. However, insulin is capable of increasing the abundance and functional activity of GLUT5, fructose transporter, in skeletal muscle cells.\nFructolysis.\nThe initial catabolism of fructose is sometimes referred to as fructolysis, in analogy with glycolysis, the catabolism of glucose. In fructolysis, the enzyme fructokinase initially produces fructose 1-phosphate, which is split by aldolase B to produce the trioses dihydroxyacetone phosphate (DHAP) and glyceraldehyde. Unlike glycolysis, in fructolysis the triose glyceraldehyde lacks a phosphate group. A third enzyme, triokinase, is therefore required to phosphorylate glyceraldehyde, producing glyceraldehyde 3-phosphate. The resulting trioses are identical to those obtained in glycolysis and can enter the gluconeogenic pathway for glucose or glycogen synthesis, or be further catabolized through the lower glycolytic pathway to pyruvate.\nMetabolism of fructose to DHAP and glyceraldehyde.\nThe first step in the metabolism of fructose is the phosphorylation of fructose to fructose 1-phosphate by fructokinase, thus trapping fructose for metabolism in the liver. Fructose 1-phosphate then undergoes hydrolysis by aldolase B to form DHAP and glyceraldehydes; DHAP can either be isomerized to glyceraldehyde 3-phosphate by triosephosphate isomerase or undergo reduction to glycerol 3-phosphate by glycerol 3-phosphate dehydrogenase. The glyceraldehyde produced may also be converted to glyceraldehyde 3-phosphate by glyceraldehyde kinase or further converted to glycerol 3-phosphate by glycerol 3-phosphate dehydrogenase. The metabolism of fructose at this point yields intermediates in the gluconeogenic pathway leading to glycogen synthesis as well as fatty acid and triglyceride synthesis.\nSynthesis of glycogen from DHAP and glyceraldehyde 3-phosphate.\nThe resultant glyceraldehyde formed by aldolase B then undergoes phosphorylation to glyceraldehyde 3-phosphate. Increased concentrations of DHAP and glyceraldehyde 3-phosphate in the liver drive the gluconeogenic pathway toward glucose and subsequent glycogen synthesis. It appears that fructose is a better substrate for glycogen synthesis than glucose and that glycogen replenishment takes precedence over triglyceride formation. Once liver glycogen is replenished, the intermediates of fructose metabolism are primarily directed toward triglyceride synthesis.\nSynthesis of triglyceride from DHAP and glyceraldehyde 3-phosphate.\nCarbons from dietary fructose are found in both the free fatty acid and glycerol moieties of plasma triglycerides. High fructose consumption can lead to excess pyruvate production, causing a buildup of Krebs cycle intermediates. Accumulated citrate can be transported from the mitochondria into the cytosol of hepatocytes, converted to acetyl CoA by citrate lyase and directed toward fatty acid synthesis. In addition, DHAP can be converted to glycerol 3-phosphate, providing the glycerol backbone for the triglyceride molecule. Triglycerides are incorporated into very-low-density lipoproteins (VLDL), which are released from the liver destined toward peripheral tissues for storage in both fat and muscle cells.\nPotential health effects.\nIn 2022, the European Food Safety Authority stated that there is research evidence that fructose and other added free sugars may be associated with increased risk of several chronic diseases: the risk is moderate for obesity and dyslipidemia (more than 50%), and low for non-alcoholic fatty liver disease, type 2 diabetes (from 15% to 50%) and hypertension. EFSA further stated that clinical research did \"not support a positive relationship between the intake of dietary sugars, in isocaloric exchange with other macronutrients, and any of the chronic metabolic diseases or pregnancy-related endpoints assessed\" but advised \"the intake of added and free sugars should be as low as possible in the context of a nutritionally adequate diet.\"\nObesity.\nExcessive consumption of sugars, including fructose, contributes to insulin resistance, obesity, elevated LDL cholesterol and triglycerides, leading to metabolic syndrome. The European Food Safety Authority (EFSA) stated in 2011 that fructose may be preferable over sucrose and glucose in sugar-sweetened foods and beverages because of its lower effect on postprandial blood sugar levels, while also noting the potential downside that \"high intakes of fructose may lead to metabolic complications such as dyslipidaemia, insulin resistance, and increased visceral adiposity\". The UK's Scientific Advisory Committee on Nutrition in 2015 disputed the claims of fructose causing metabolic disorders, stating that \"there is insufficient evidence to demonstrate that fructose intake, at levels consumed in the normal UK diet, leads to adverse health outcomes independent of any effects related to its presence as a component of total and free sugars.\"\nCardiometabolic diseases.\nWhen fructose is consumed in excess as a sweetening agent in foods or beverages, it may be associated with increased risk of obesity, diabetes, and cardiovascular disorders that are part of metabolic syndrome. \nCompared with sucrose.\nFructose was found to increase triglycerides in type-2 but not type-1 diabetes, and moderate use of it has previously been considered acceptable as a sweetener for diabetics, possibly because it does not trigger the production of insulin by pancreatic \u03b2 cells. For a 50 gram reference amount, fructose has a glycemic index of 23, compared with 100 for glucose and 60 for sucrose. Fructose is also 73% sweeter than sucrose at room temperature, allowing diabetics to use less of it per serving. Fructose consumed before a meal may reduce the glycemic response of the meal. Fructose-sweetened food and beverage products cause less of a rise in blood glucose levels than do those manufactured with either sucrose or glucose.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50338", "revid": "15881234", "url": "https://en.wikipedia.org/wiki?curid=50338", "title": "'s-Hertogenbosch", "text": "City in North Brabant, Netherlands\n's-Hertogenbosch (), colloquially known as Den Bosch (), is a city and municipality in the Netherlands with a population of 160,783. It is the capital of the province of North Brabant and its fourth largest city by population. The city is directly south of the Maas river and near the Waal.\nHistory.\nThe city's official name is a contraction of the (archaic) Dutch \u00a0\u2014 'the forest of the duke'. The duke in question was Henry\u00a0I, Duke of Brabant, whose family had owned a large estate at nearby Orthen for at least four centuries. He founded a new town located on some forested dunes in the middle of a marsh. At age 26, he granted 's-Hertogenbosch city rights and the corresponding trade privileges in 1185. This is the traditional date given by later chroniclers; the first mention in contemporaneous sources is 1196. The original charter has been lost. His reason for founding the city was to protect his own interests against encroachment from Gelre and Holland; from its first days, he conceived of the city as a fortress. It was destroyed in 1203 in a joint expedition of Gelre and Holland, but was soon rebuilt. Some remnants of the original city walls remain.\nIn the late 14th century, a much larger wall was erected to protect the greatly expanded settled area. Artificial waterways were dug to serve as a city moat, through which the rivers Dommel and Aa were diverted. 's-Hertogenbosch became the birthplace and home of northern Renaissance painter Hieronymus Bosch.\nUntil 1520, the city flourished, becoming the second largest population centre in the territory of the present Netherlands, after Utrecht. The city was also a center of music, and composers, such as Jheronimus Clibano, received their training at its churches. Others held positions there: Matthaeus Pipelare was musical director at the Confraternity of Our Lady; and renowned Habsburg copyist and composer Pierre Alamire did much of his work at 's-Hertogenbosch.\nEighty Years' War.\nThe wars of the Reformation changed the course of the city's history. It became an independent bishopric. During the Eighty Years' War, the city took the side of the Habsburg (Catholic) authorities and thwarted a Calvinist coup. It was besieged several times by Prince Maurice of Orange, stadtholder of most of the Dutch Republic, who wanted to bring 's-Hertogenbosch under the rule of the rebel United Provinces. The city was successfully defended against Prince Maurice in 1601 and again in 1603, but it eventually fell in the 1629 siege led by his brother Frederick Henry.\nThirty Years' War.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nIn the years of Truce, before the renewed fighting after 1618, the fortifications were greatly expanded. The surrounding marshes made a siege of the conventional type impossible, and the fortress, deemed impregnable, was nicknamed \"moerasdraak\", or the Swamp Dragon. The town was nevertheless finally conquered by Frederik Hendrik of Orange in 1629 in a typically Dutch stratagem: he diverted the rivers Dommel and Aa, created a polder by constructing a forty-kilometre (25 mile) dyke and then pumped out the water by mills. After a siege of three months, the city had to surrender\u2014an enormous blow to Habsburg geo-political strategy during the Thirty Years' War. This surrender cut the town off from the rest of the duchy and the area was treated by the Republic as an occupation zone without political liberties (see also Generality Lands).\nLouis XIV to Bonaparte.\nAfter the Peace of Westphalia, the fortifications were again expanded. In 1672, the Dutch \"rampjaar\", the city held against the army of Louis XIV of France. In 1794 French revolutionary troops under the command of Charles Pichegru attacked the city. It was only weakly defended, and fell after a short siege. Pichegru then crossed the rivers and put an end to the Dutch Republic.\nUnder the new Batavian Republic, established in 1795, both Catholics and \"Brabanders\" at last gained equal rights. From 1806, the city became part of the Kingdom of Holland and from 1810, it was incorporated into the First French Empire. It was captured by the Prussians in 1814.\nKingdom of the Netherlands.\nThe next year, 1815, when the United Kingdom of the Netherlands was established, it became the capital of North Brabant. Many newer and more modern fortresses were created in the vicinity of the city. A new canal was built, the 'Zuid-Willemsvaart', which gave the city an economic impulse. Trade, manufacturing and industry grew. Until 1878, it was forbidden to build outside the ramparts. That led to overcrowding and the highest infant mortality in the kingdom.\nAt the end of the 19th century, the very conservative city government prevented industrial investment to avoid an increase in the number of workers and the establishment of educational institutions: students were regarded as disorderly. As a result, the relative importance of the city diminished.\nWorld War II and after.\nOne of the few official Nazi concentration camp complexes in Western Europe outside Germany and Austria was named after 's-Hertogenbosch. It operated from January 1943, to September 1944 and was known to the Germans as Herzogenbusch (see List of subcamps of Herzogenbusch). About 30,000 inmates were interned in the complex during this time, of whom about 12,000\u00a0were Jews. In the Netherlands, this camp is known as 'Kamp Vught', because the concentration camp was actually located at a heath near Vught, a village a few kilometres south of 's-Hertogenbosch.\nThe city was occupied by German forces during World War II from 1940 to 1944. The railway station was bombed by planes of the Royal Air Force on 16 September 1944. The city was liberated between 24 and 27\u00a0October 1944\u00a0during Operation Pheasant by British soldiers of Major-General Robert Knox Ross's 53rd (Welsh) Infantry Division following the victory of the 1st Battalion, East Lancashire Regiment, of 158th Infantry Brigade over the enemy on 23\u201324 October.\nAfter the war, 's-Hertogenbosch was modernized, like many other cities in the Netherlands. It was possible that it was only the geography that shielded the old town from rigorous reconstruction in those early years. Just in time, the pendulum swung back to protecting the history of the city. In 1956, the council wanted to demolish the Moriaan, the oldest brick building in the Netherlands, to give traffic better access to the market square. The permit was refused by the government and instead the building was restored, starting in 1963. Later, city councils became much more aware of the value of historic buildings and from about the turn of the millennium, the historic fortifications are also given much attention by the authorities.\nGeography.\nPopulation centres.\nThe population centres in the municipality are: Bokhoven, Crevecoeur, Deuteren (former village), Dieskant, Empel, Engelen, Gewande, 's-Hertogenbosch, Hintham, Kruisstraat, Maliskamp, Meerwijk, Orthen (former village), Oud-Empel, and Rosmalen.\nClimate.\nClimate in this area has mild differences between highs and lows, and there is adequate rainfall year-round. The K\u00f6ppen Climate Classification subtype for this climate is \"\" (Marine West Coast Climate/Oceanic climate).\nEconomy.\nThe city of 's-Hertogenbosch has become a center of industry, education, administration and culture. It is currently the fourth city of North Brabant. It is home to many national and international businesses such as Heineken, Epic, Tyco International, SAP and many others. The Jeroen Bosch Hospital is the biggest employer in the area, with over 4,000 employees.\nCulture.\n's-Hertogenbosch is home to a variety of events such as the theatre festival \"Boulevard\", \"Jazz in Duketown\", and hip hop in duketown, the start of the Tour de France (1996), Tour Feminin (1997), the International Vocal Competition, November Music (a contemporary music festival) and the UNICEF Open (formerly the Ordina Open) grass court tennis tournament (in the nearby town of Rosmalen). There are also over 350 restaurants, pubs and caf\u00e9s to be found in the city.\n's-Hertogenbosch is also home to the European Ceramic Work Centre. This is a juried international ceramic residency where they invite artists, designers and architects from around to the world to explore the medium of Ceramics. This program was initially started in 1991 and continues to this day.\nThe city has its own food speciality, the Bossche Bol \u2014 effectively a giant profiterole, somewhat larger than a tennis ball, which is filled with whipped cream and coated with chocolate.\nThe spoken language is Maaslands (the variant spoken in 's-Hertogenbosch is called \"Bosch\" which is placed among the Central North Brabantian dialects, although other classification systems also describe it as East Brabantian), which is very similar to colloquial Dutch.\nDe Toonzaal is a music venue for chamber music, improvised music, and experimental music. For popular music there is the venue W2 (or Willem II).\nMuseums.\nThe Noordbrabants Museum is a provincial museum with an overview of works that Vincent van Gogh made in Brabant. The Design Museum Den Bosch is a modern art museum. The Jheronimus Bosch Art Center, is dedicated to the work of Hieronymus Bosch. Other museums include the Swan Brothers' House and Museum Slager. Also the National (Dutch) Carnavalsmuseum Oeteldonks gemintemuzejum is located in the city. In the near future a new museum will be opened about the fortresses of the town and in general in Europe. The house where the famous painter Hieronymus produced his paintings can be visited on the market square.\nCarnival celebrations.\n's-Hertogenbosch has a strong carnival tradition. In its current form the story and symbolism dates from 1881 to 1883. In these years some citizens created the legend of \"Oeteldonk\", whereby the city was renamed to Oeteldonk for the three day carnival. \"Donk\" is a reference to a dry place in the marsh. The frog is widely used as a symbol during the 's-Hertogenbosch Carnival. It is also a symbol of the Oeteldonk marsh. It was also a remark aimed at Bishop Godschalk from Den Dungen, where 'Van den Oetelaar' was a common family name. He had wanted to forbid the traditional festivities of Shrove Tuesday that often led to excesses.\nOeteldonk is a village and therefore every inhabitant is a farmer or a \" (a girl or young woman), eliminating class differences. The village is headed by the Mayor \"Peer vaan den Muggenheuvel tot den Bobberd\". Each year the mayor of 's-Hertogenbosch hands over his authority to the Mayor of Oeteldonk. On Sunday at 11:11 AM the Mayor of Oeteldonk then receives Prince Carnaval \"Prince Amadeiro XXVI\" at Oeteldonk central station. From there a parade of all carnival clubs escorts the company to the town hall.\nThe citizens of 's-Hertogenbosch wear traditional outfits throughout these days. A so-called \"boerenkiel\" is worn and every year patches are designed according to that years theme which can then be stitched onto the outfit. The \"boerenkiel\" is often combined with a traditional farmers bandana and a long scarf in the colors of Oeteldonk. The tradition of the Boerenkiel and / or Bandana is very different from the carnival traditions in the rest of the Netherlands. Other aspects like the parade, the temporary name and the temporary flag (for Oeteldonk red, white and yellow) are very similar.\nAttractions.\n's-Hertogenbosch was founded as a fortified city and that heritage can still be seen today. After World War II, plans were made to modernise the old city, by filling in the canals, removing or modifying some ramparts and redeveloping historic neighbourhoods. Before these plans could come to effect, the central government declared the city a protected townscape. Most historic elements have been preserved. In contrast to cities like Rotterdam, 's-Hertogenbosch also survived the Second World War relatively unscathed. Much of its historic heritage remains intact, and today there are always renovations going on in the city to preserve the many old buildings, fortifications, churches and statues for later generations.\nCity center.\nThe city center has a cosy atmosphere because of the almost continuous ramparts that still surround it. It has been molded by the multiple rivers that convene on 's-Hertogenbosch, giving the center its strange street plan so different from the usual grid plan where streets meet at right angles. The center is dominated by Saint John's Cathedral (\"Sint-Janskathedraal\" in Dutch), which dates from c. 1220 and is best known for its Brabantine Gothic design and the many sculptures of craftsmen that are sitting on almost every arc and rim along the outside of the cathedral. In 2010 an extensive restoration was completed, undoing the damage of many years of wear-and-tear and acid rain.\nOn the central square is the oldest remaining brick house of the Netherlands, 'de Moriaan', which was built at the beginning of the 13th century. In the 1960s, de Moriaan was renovated to its former glory based on a famous 16th-century Dutch painting called 'De Lakenmarkt van 's-Hertogenbosch' ('The fabric market of 's-Hertogenbosch'). The town hall is an original 14th-century Gothic building. After the town was conquered by the Dutch Republic in 1629, it received a new facade in the style of Dutch Baroque architecture. It showcased the authority of the new masters, just like the new town hall in Maastricht would.\nHidden below the old city is a canal network called the Binnendieze, which once spanned . It started out as a regular river, the Dommel, running through the city in medieval times. Due to a lack of space in the city, people started building their houses and roads over the river. Later, the Binnendieze functioned as a sewer and fell into disrepair. In recent decades, the remaining sixth part of the old waterway system has been renovated, and it is possible to take several guided subterranean boat trips through it.\nFortifications.\n's-Hertogenbosch has an extensive and almost complete fifteenth-to-seventeenth-century city fortification. It was made to profit from the city's strong defensive position, lying on a sandy hill in the center of a large swamp fed by many rivers. This also caused the main ramparts to be preserved, because they were crucial in keeping out the water. In 2004 the city was awarded the title \"European Fortress City of the year\". In the years that followed it restored many of the city defenses to much of their old glory.\nApart from small sections of medieval walls, the main structure of the fortification is a late-medieval (fifteenth-century) wall. The upper sections were removed when cannon became more powerful, and polygonal bastions were added, some after the conquest by the republic. Most of these have not been restored to their original height, but do maintain their brick walls. The citadel in the north west of the city does retain its original height. Around the city itself many other fortresses can still be seen.\nIn the north east of the old city, the hexagonal gunpowder magazine, called is located close to the citadel. It is one of only a handful that still exist in the Netherlands, and was built when the city was still part of the Spanish Netherlands. It is planned to become the museum of fortress 's-Hertogenbosch. One of the bastions of the fortress now houses the mini museum Bastionder. It has been dug out in a bastion of the south side. On the inside it shows a unique wrought iron cannon, and an older bastion that was walled in by the current one.\nNature.\nOn the south side of the city, the city center and walls still border the Bossche Broek, an old polder that could never be made dry. In 1995 the dyke of the Dommel broke and an enormous amount of water entered the polder. It also flooded and blocked the main Dutch highway A2. In order to prevent this in the future, the area was rearranged to store excess water in case of emergencies. In 2006 the area had been furnished with higher dikes and locks that allowed a controlled flooding of the polder and some adjacent areas in case of emergency.\nThe Bossche Broek is now a nature reserve, that stretches all the way to Vught. It is connected to the Moerputten and Vlijmens Ven, with which it forms a Natura 2000 area. Rare species in the area are the scarce large blue and the European weather loach. The Moerputten sports the Moerputten Bridge, a 600-metre (650 yard) long nineteenth century railway bridge and engineering feat. What is unique about the area is its close proximity to the city center.\nMiscellaneous.\nThe city is also the location of the \"Bolwoningen\" complex, an array of fifty experimental spherical houses designed by Dries Kreijkamp.\nThe Lutheran Church, 's-Hertogenbosch is no longer used as a church.\nSport.\nThe city has one professional football club, FC Den Bosch. It is the 1967 successor of the professional branches of BVV (Bossche Voetbal Vereniging) and Wilhelmina. Both of them still exist as amateur football clubs. As a successor of BVV FC Den Bosch can claim the national championship of 1948. This championship led to the construction of stadium De Vliert, which at one time had a capacity of 30,000. Due to the less successful years that followed, the capacity is now only 8,500 visitors. FC Den Bosch was the first club of Dutch international player Ruud van Nistelrooy.\n's-Hertogenbosch is more successful in field hockey. It is home to top club HC Den Bosch. The women's team in particular is a dominant force in the Dutch field hockey competition. The professional basketball club Heroes Den Bosch is also very successful. The city's rugby club is called The Dukes and dates from 1974. It is located at a very scenic location at the foot of the city walls. Because of the limited space, the club plays on artificial turf and part of the accommodation is subterranean. The Dukes has the most junior members. It became the national rugby champion in 2008.\nAs regards events the city is host to the Rosmalen Grass Court Championships, a combined ATP Tour and WTA Tour grass court tennis event played two weeks before the Wimbledon Championships. The World Archery Championships and World Para Archery Championship were held here in June 2019. During these combined World Championships two separate venues were used: the Parade and the rugby fields of The Dukes. All finals took place in the arena at the Parade. The Parade is a historic square surrounded by high trees, situated at the foot of the nearly seven-hundred-year-old Saint John's Cathedral in the attractive center of 's-Hertogenbosch.\nTransport.\nThe Zuid-Willemsvaart runs from the Meuse just north of the city towards Maastricht via Helmond and Weert. In 's-Hertogenbosch it runs through the city proper, south east from where a bastion has been cut off from the citadel. Because of this route it was impossible to widen it further than for ships of CEMT class II. Therefore, the M\u00e1xima Canal of 8\u00a0km (5 miles) was dug just east of the city, creating a shortcut from the canal to the Meuse suitable for ships of CEMT class IV. On the remaining part of the Zuid-Willemsvaart west of the city is the industrial harbor of 's-Hertogenbosch. A marina is located in the center.\n's-Hertogenbosch is situated on the busy A2 motorway, the most important north\u2013south connection of the Netherlands. This connection was established with the opening of the Dieze Bridge in 1942. From 1961 the Utrecht-'s-Hertogenbosch section was 2 times 2 lanes. In 1970 the A2 was rerouted to the east of the city. In 1989 it finally became a controlled-access highway. In 1996 the section between 's-Hertogenbosch and Eindhoven became a controlled-access highway. The situation in Maastricht was only solved in 2016, when the Koning Willem-Alexandertunnel was opened. On the east\u2013west axis 's-Hertogenbosch is on the A59 motorway. The A65 motorway between 's-Hertogenbosch and Tilburg is a regional highway, but is not completely access-controlled.\n's-Hertogenbosch railway station is on the Utrecht\u2013Boxtel part of the railway stretch between Amsterdam and the Dutch industrial/tech center near Eindhoven. As a consequence north\u2013south trains depart every ten minutes. On the Tilburg\u2013Nijmegen railway trains run on a more modest schedule. 's-Hertogenbosch railway station is also a major station for Arriva buslines that serve the city and most of its suburbs. Other stations within the limits of the municipality are 's-Hertogenbosch Oost railway station and Rosmalen railway station. Vught railway station is actually closer to the city center than that in Rosmalen.\n's-Hertogenbosch has attempted to adapt to the growing popularity of the bicycle in Dutch cities. A reasonable amount of bike paths has so far been constructed in the town. In 2011, the city was chosen as \"Fietsstad 2011\"\u2014the top bike city of the Netherlands for 2011. The details of the report were less jubilant and showed that it was really a prize meant to stimulate 's-Hertogenbosch to take further action; Hugo van der Steenhoven of the Fietsersbond: \"In the past years Den Bosch has spent much energy, ambition, creativity and money to give cycling an enormous boost. This is a big achievement for a city where bicycle use is lower than in the rest of the Netherlands\" (cyclist union).\nEducation.\n's-Hertogenbosch has multiple vocational universities called \"Hogeschool\" in Dutch. The HAS Hogeschool of about 3,500 students is focused on agricultural and food technology. Avans Hogeschool is located in 's-Hertogenbosch and two nearby cities. The AKV St. Joost is an art academy that is now part of Avans and dates back to 1812. Fontys Hogeschool also offers some education in the city. The Jheronimus Academy of Data Science (JADS), located at the Mari\u00ebnburg Campus in the center of 's-Hertogenbosch, and provides a number of data science programs at graduate (MSc) and post-graduate level (PhD). It is a department of the Eindhoven University of Technology and Tilburg University.\nIn secondary education the City Gymnasium is a gymnasium (school) that originated from the Latin school of the city. It is comparable to a grammar school and can trace its origin back 1274. The same type of education and all other types of secondary education are offered by a number of large institutes.\nReligion.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nRoman Catholicism is the dominant religion in 's-Hertogenbosch, with somewhat more than 40% of the population counting themselves as belonging to it. Even so, attendance at mass is significantly lower than 40%. Three churches in the city center are still in use by the Catholic church: Saint John's Cathedral, Saint Catherine and the Monastery Church of the Franciscans nearby the railway station. Smaller churches in use by the Roman Catholic church are: Saint Anne's Church in Hintham, Saint Landoline Church in Empel, Saint Willibrord Church in Maaspoort, Saint Lambert Church (Rosmalen), etc.\nThe Protestant religion has seen its share of believers in the city fall from 20% to about 4%. It is based in the Great Church. The Eastern Orthodox Church is a new church in town. It is based at Saint Catherine's Church where Catholic worship services have been held again since 2021.\nThe Arrahma Mosque has been built by the Moroccan community. The Turkish community has the Orhan Gazi Mosque.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50339", "revid": "7304691", "url": "https://en.wikipedia.org/wiki?curid=50339", "title": "Rauni", "text": "Rauni may mean:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "50342", "revid": "64853", "url": "https://en.wikipedia.org/wiki?curid=50342", "title": "Thomas Harrison (soldier)", "text": "English lawyer and military officer (1616\u20131660)\nMajor-General Thomas Harrison (baptised 16 July 1616 - executed 13 October 1660) was a prominent member of the radical religious sect known as the Fifth Monarchists, and a soldier who fought for Parliament and the Commonwealth in the Wars of the Three Kingdoms. One of those who approved the Execution of Charles I in January 1649, he was a strong supporter of Oliver Cromwell before the two fell out when The Protectorate was established in 1653. Following the 1660 Stuart Restoration, he was arrested, found guilty of treason as a regicide, and sentenced to death. He was hanged, drawn and quartered on 13 October 1660, facing his execution with a courage noted by various observers, including the diarist Samuel Pepys.\nPersonal details.\nThomas Harrison was baptised 16 July 1616, second of four children and only son of Richard Harrison, four times mayor of Newcastle-under-Lyme, and his wife Mary. In 1646, he married his cousin Catherine Harrison; they had three children, all of whom died as infants.\nCareer.\nHarrison was probably educated at a local Grammar school before moving to London, where he became clerk to a lawyer based in Clifford's Inn. When the First English Civil War began in August 1642, the Earl of Essex was appointed commander of the Parliamentarian army, and Harrison enlisted in his personal troop of Lifeguards, which was recruited almost exclusively from the Inns of Court. Other members included Charles Fleetwood, Edmund Ludlow and Nathaniel Rich, all of whom played important roles in the political and religious conflicts that followed. This unit fought in two of the earliest battles of the war, Powick Bridge in September and Edgehill in October 1642. \nIn summer 1643, he transferred to the army of the Eastern Association as captain of a cavalry troop in the Earl of Manchester's regiment. He had reached the rank of lieutenant-colonel by the time it took part in the decisive Battle of Marston Moor in July 1644. \nHe fought in many of the major battles of the war and joined the New Model Army in 1645. By the end of the conflict he had risen to the rank of major-general and was a noted friend and supporter of Oliver Cromwell.\nHe was elected to the Long Parliament for Wendover in 1646. His regiment maintained strong Leveller sympathies, mutinying in 1647.\nSecond English Civil War.\nWhen conflict resumed he was wounded at Appleby in July 1648. He had to return to London but was well enough to command the escort that brought the King to London in January 1649. Harrison sat as a commissioner (judge) at the trial and was the seventeenth of fifty-nine commissioners to sign the death warrant of King Charles I.\nIn 1650, Harrison was appointed to a military command in Wales where he was apparently extremely severe. He was promoted to the rank of Major-General in 1651 and commanded the army in England during . He fought at the battle of Knutsford in August and at Worcester in September 1651.\nBy the early 1650s Harrison was associated with the radical Fifth Monarchists and became one of their key speakers. He still supported Cromwell and aided in the dissolution of the Rump Parliament in April 1653. He opposed the parliament on the basis that it was blocking more stringent religious reforms \u2013 he wanted a more \"godly\" parliament. Harrison was a radical member of the Nominated Assembly (Barebones Parliament) that replaced Parliament. When the assembly was dissolved, Harrison and others refused to leave and had to be forced out by soldiers. Harrison was dismissed from the Army in December.\nLike many, he was outraged by the formation of the Protectorate and the elevation of Cromwell to Lord Protector. Under the Protectorate (1653\u201360) Harrison was imprisoned four times.\nArrest and trial.\nAfter Cromwell's death Harrison remained quietly in his home, supporting none of the contenders for power. Following the Stuart Restoration, Harrison declined to flee and was arrested in May 1660.\nHe was tried on 11 October 1660. Edmond Ludlow described the trial in his memoirs, &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...(Harrison) not only pleaded not guilty, but justified the sentence passed upon the King (Charles I), and the authority of those who had commissioned him to act as one of his judges. He plainly told them, when witnesses were produced against him, that he came not thither with an intention to deny anything he had done, but rather to bring it to light, owning his name subscribed to the warrant for executing the King, to be written by himself; charging divers of those who sat on the Bench, as his judges, to have been formerly as active for the cause, in which he had engaged, as himself or any other person; affirming that he had not acted by any other motive than the principles of conscience and justice; for proof of which he said it was well known, he had chosen to be separated from his family, and to suffer a long imprisonment rather than to comply with those who had abused the power they had assumed to the oppression of the people. He insisted that having done nothing, in relation to the matter in question, otherwise than by the authority of the Long Parliament, he was not justly accountable to this or any other inferior Court; which being a point of law, he desired to have council assigned upon that head; but the Court over-ruled; and by interrupting him frequently, and not permitting him to go on in this defense, they clearly manifested a resolution of gratifying the resentments of the Court upon any terms. So that a hasty verdict was brought in against him, and the question being asked, if he had anything to say, why judgement should not pass, he only said, that since the Court had refused to hear what was fit for him to speak in his defense, he had no more to say; upon which Bridgeman pronounced the sentence. And that the inhumanity of these men may the better appear, I (Edmond Ludlow) must not omit, that the executioner in an ugly dress, with a halter in his hand, was placed near the Major-General, and continued there during the whole time of his trial, which action I doubt whether it was ever equaled by the most barbarous nations. But having learned to condemn such baseness, after the sentence had been pronounced against him, he (Major-General Harrison) said aloud as he was withdrawn from the Court, that he had no reason to be ashamed of the cause in which he had been engaged.\nHarrison's sentence was \"That you be led to the place from whence you came, and from thence be drawn upon a hurdle to the place of execution, and then you shall be hanged by the neck and, being alive, shall be cut down, and your privy members to be cut off, and your entrails be taken out of your body and, you living, the same to be burnt before your eyes, and your head to be cut off, your body to be divided into four-quarters, and head and quarters to be disposed of at the pleasure of the King's majesty. And the Lord have mercy on your soul.\"\nExecution.\nMajor-General Harrison was the first of the regicides to be executed by being hanged, drawn and quartered on 13 October 1660. Harrison, after being hanged for several minutes and then cut open, was reported to have leaned across and hit his executioner\u2014resulting in the swift removal of his head. His entrails were thrown onto a nearby fire. His head adorned the sledge that drew fellow regicide John Cook to his execution, before being displayed in Westminster Hall; his quarters were fastened to the city gates.\nSamuel Pepys wrote an eyewitness account of the execution at Charing Cross, in which Major General Harrison was drily reported to be \"looking as cheerful as any man could do in that condition\". This account is also quoted on a plaque on the wall of the Hung, Drawn and Quartered public house near Pepys Street, where the diarist lived and worked in the Navy Office. In his final moments, as he was being led up the scaffold, the hangman asked for his forgiveness. Upon hearing his request, Thomas Harrison replied, \"I do forgive thee with all my heart... Alas poor man, thou doith it ignorantly, the Lord grant that this sin may be not laid to thy charge.\" Thomas Harrison then gave all of the money that remained in his pockets to his executioner and was thereafter executed.\nEdmond Ludlow also provided an account of the execution at Charing Cross: \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The sentence which had been pronounced in consequence of the verdict was executed upon Major-General Harrison at the place where Charing Cross formerly stood, that the King might have the pleasure of the spectacle, and inure himself to blood.\" According to Ludlow, \"On the fifteenth (15 October 1660), Mr. John Carew suffered there also, even their enemies confessing that more steadiness of mind, more contempt of death, and more magnanimity could not be expressed. To all who were present with them either in prison or at the place where the sentence was executed, they owned that having engaged in the cause of God and their country, they were not at all ashamed to suffer in the manner their enemies thought fit, openly avowing the inward satisfaction of their minds when they reflected upon the actions for which they had been condemned, not doubting the revival of the same cause; and that a time should come when men would have better thoughts of their persons and proceedings.\"\nIn his book \"The Better Angels of Our Nature\", Steven Pinker wrote about the execution:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Even when they were not actively enjoying torture, people showed a chilling insouciance to it. Samuel Pepys, presumably one of the more refined men of his day, made the following entry in his diary for October 13, 1660: Out to Charing Cross, to see Major-general Harrison hanged, drawn, and quartered; which was done there, he looking as cheerful as any man could do in that condition. He was presently cut down, and his head and heart shown to the people, at which there was great shouts of joy. \u2026 From thence to my Lord's, and took Captain Cuttance and Mr. Sheply to the Sun Tavern, and did give them some oysters. Pepys's cold joke about Harrison's \"looking as cheerful as any man could do in that condition\" referred to his being partly strangled, disemboweled, castrated, and shown his organs being burned before being decapitated.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50343", "revid": "45789152", "url": "https://en.wikipedia.org/wiki?curid=50343", "title": "Ranching", "text": ""}
{"id": "50344", "revid": "40721479", "url": "https://en.wikipedia.org/wiki?curid=50344", "title": "Frontier", "text": "Area near or beyond a boundary\nA frontier is a political and geographical term referring to areas near or beyond a boundary.\nAustralia.\nThe term \"frontier\" was frequently used in colonial Australia in the meaning of country that borders the unknown or uncivilised, the boundary, border country, the borders of civilisation, or as the land that forms the furthest extent of what was frequently termed \"the inside\" or \"settled\" districts. The \"outside\" was another term frequently used in colonial Australia, this term seemingly covered not only the frontier but the districts beyond. Settlers at the frontier thus frequently referred to themselves as \"the outsiders\" or \"outside residents\" and to the area in which they lived as \"the outside districts\". At times one might hear the \"frontier\" described as \"the outside borders\". However the term \"frontier districts\" was seemingly used predominantly in the early Australian colonial newspapers whenever dealing with skirmishes between black and white in northern New South Wales and Queensland, and in newspaper reports from South Africa, whereas it was seemingly not so commonly used when dealing with affairs in Victoria, South Australia and southern New South Wales. The use of the word \"frontier\" was thus frequently connected to descriptions of frontier violence, as in a letter printed in the \"Sydney Morning Herald\" in December 1850 which described murder and carnage at the northern frontier and calling for the protection of the settlers saying: \"...nothing but a strong body of Native Police will restore and keep order in the frontier districts, and as the squatters are taxed for the purpose of such protection\".\nSouth America.\nArgentina.\nThe southern indigenous frontier of the Viceroyalty of the R\u00edo de la Plata was the southern limit into which the Viceroyalty could exert its rule. Beyond this lay territories \"de facto\" controlled by indigenous peoples who inhabited the Pampas and Patagonia. These group were mainly the Tehuelche, Pehuenche, Mapuche, and the Ranqueles. \nVarious military campaigns and peace treaties were arranged by the Spanish in order to either stop indigenous incursions in Spanish lands or to advance the frontier into indigenous territory. In the 1870s, to counter the cattle raids (and the native peoples on horseback), Argentina constructed a deep trench, called Zanja de Alsina, to prevent cattle from being driven west and establish a boundary to the raiding tribes in the Pampas. \nUnder General Julio Argentino Roca, the Conquest of the Desert extended Argentine power into Patagonia.\nBolivia.\nFor long time a frontier existed east of Tarija in southeastern Bolivia. Starting in the late 16th century the Spanish saw the tribes inhabiting the eastern jungles, and the \"Chiriguanos\" in particular, as a threat. This frontier attracted Maroons and indigenous individuals who escaped Spanish rule in the Real Audiencia of Charcas. The frontier remained remarkably stable until the late 18th century when the Spanish made some advances into the Chiriguano territory. Later, in the second half of the 19th century a more definitive advance begun on the Chiriguano lands with the last resistance being crushed in the early 20th century.\nChile.\nThe Destruction of the Seven Cities (1599\u20131604) led to the formation of a frontier called La Frontera, with the Spanish ruling north of Biob\u00edo River and Mapuche retaining independence south of the said river. Within this frontier the city of Concepci\u00f3n assumed the role of \"military capital\" of Spanish-ruled Chile. This informal role was given by the establishment of the Spanish Army of Arauco in the city which was financed by a payments of silver from Potos\u00ed called Real Situado. Santiago located at some distance from the war zone remained the political capital since 1578.\nFollowing the Mapuche uprising of 1655 and abolition of Mapuche slavery in 1683 in the Spanish Empire trade across the frontier increased. Mapuche-Spanish and later Mapuche-Chilean trade increased further in the second half of the 18th century as hostilities decreased. Mapuches obtained goods from Chile and some dressed in \"Spanish\" clothing. Despite close contacts Chileans and Mapuches remained socially, politically and economically distinct. Spanish and later Chilean officials with the titles of comisario de naciones and capit\u00e1n de amigos acted as intermediaries between the Mapuche and colonial and republican authorities.\nDuring the Occupation of Araucan\u00eda the Republic of Chile advanced the frontier south from B\u00edo B\u00edo River to Malleco River where a well defended line of forts was established between 1861 and 1871.\nHaving decisively defeated Peru in the battles of Chorrillos and Miraflores in January 1881 Chilean authorities turned their attention to the southern frontier in Araucan\u00eda seeking to defend the previous advances that had been so difficult to establish. The idea was not only to defend forts and settlements but also to advance the frontier all the way from Malleco River to Caut\u00edn River.\nUnited States.\nIn the United States, the frontier was the term applied by scholars to the impact of the zone of land beyond the region of existing European occupation. That is, as pioneers moved into the frontier zone they were changed significantly by the encounter. That is what Frederick Jackson Turner called \"the significance of the frontier.\" For example, Turner argued in 1893, one change was that unlimited free land in the zone was available and thus offered the psychological sense of unlimited opportunity, which in turn had many consequences, such as optimism, future orientation, shedding of restraints caused by land scarcity, and wastefulness of natural resources.\nOperating in tandem with the doctrine of \"manifest destiny\", the \"frontier\" concept also had a massive impact on Native Americans like the declaration of \"terra nullius\" enacted by the British around 1835 to legitimize their colonization of Australia. The idea implicitly negated any recognition of legitimate pre-existing occupation and embodied a blank denial of land rights to the indigenous peoples whose territories were being annexed by European colonists.\nThroughout American history, the expansion of settlement was largely from the east to the west and so the frontier is often identified with \"the West.\" On the Pacific Coast, settlement moved eastward. In New England, it moved north.\n\"Frontier\" was borrowed into English from French in the 15th century with the meaning \"borderland,\" the region of a country that fronts on another country (see also marches). The use of frontier to mean \"a region at the edge of a settled area\" is a special North American development. (Compare the Australian \"outback\".) In the Turnerian sense, \"frontier\" was a technical term that was explicated by hundreds of scholars.\nColonial North America.\nIn the earliest days of European settlement of the Atlantic Coast, the frontier was essentially any part of the forested interior of the continent beyond the fringe of existing settlements along the coast and the great rivers such as the St. Lawrence, Connecticut, Hudson, Delaware, Susquehanna River and James.\nBritish, French, Spanish, and Dutch patterns of expansion and settlement were quite different from one another. Only a few thousand French migrated to Canada; the habitants settled in villages along the St. Lawrence River, built communities that remained stable for long stretches, and did not leapfrog west the way that the Americans would. Although French fur traders ranged widely through the Great Lakes and Mississippi River watershed, as far as the Rocky Mountains, they did not usually settle down. Actual French settlement in those areas was limited to a few very small villages on the lower Mississippi and in the Illinois Country.\nLikewise, the Dutch set up fur trading posts in the Hudson River Valley, followed by large grants of land to patroons, who brought in tenant farmers who created compact permanent villages but did not push westward.\nIn contrast, the British colonies generally pursued a more systematic policy of widespread settlement of the New World for cultivation and exploitation of the land, a practice that required the extension of European property rights to the new continent. The typical British settlements were quite compact and small: under a square mile. Conflict with the Native Americans arose out of political issues on who would rule. Early frontier areas east of the Appalachian Mountains included the Connecticut River Valley. The French and Indian Wars of the 1760s resulted in a complete victory for the British, who took over the French colonial territory west of the Appalachians to the Mississippi River. The Americans began moving across the Appalachians into areas such the Ohio Country and the New River Valley.\nAmerican frontier.\nAfter victory the American Revolutionary War and the signing Treaty of Paris in 1783, the United States gained formal, if not actual, control of the British lands west of the Appalachians. Many thousands of settlers, typified by Daniel Boone, had already reached Kentucky and Tennessee and adjacent areas. Some areas, such as the Virginia Military District and the Connecticut Western Reserve (both in Ohio), were used by the states as rewards to veterans of the war. How to formally include the new frontier areas into the nation was an important issue in the Continental Congress in the 1780s and was partly resolved by the Northwest Ordinance (1787). The Southwest Territory saw a similar pattern of settlement pressure.\nFor the next century, the expansion of the nation into those areas, as well as the subsequently-acquired Louisiana Purchase, Oregon Country, and Mexican Cession, attracted hundreds of thousands of settlers. The question of whether the Kansas Territory would become \"slave\" or \"free\" helped to spark the American Civil War. In general before 1860, Northern Democrats promoted easy land ownership, and Whigs and Southern Democrats resisted the Homestead Acts for supporting the growth of a free farmer population that might oppose slavery and for depopulating the East.\nWhen the Republican Party came to power in 1860, it promoted a policy of a free land, notably the Homestead Act of 1862, coupled with railroad land grants that opened cheap (but not free) lands for settlers. In 1890, the frontier line had broken up; census maps defined the frontier line as a line beyond which the population was under 2 persons per square mile.\nThe impact of the frontier in popular culture was enormous, as shown in dime novels, Wild West shows, and after 1910 Western films that were set on the frontier.\nThe American frontier was generally the edge of settlement in the West and typically was more democratic and free-spirited in nature than the East because of the lack of social and political institutions. The idea that the frontier provided the core defining quality of the United States was elaborated by the great historian Frederick Jackson Turner, who built his Frontier Thesis in 1893 around the notion.\nCanadian frontier.\nA Canadian frontier thesis was developed by the Canadian historians Harold Adams Innis and J. M. S. Careless, who emphasized the relationship between the center and periphery. Katerberg argues that \"in Canada the imagined West must be understood in relation to the mythic power of the North\" (Katerberg 2003). Innis's 1930 work \"The Fur Trade in Canada\" expounded on what became known as the Laurentian thesis: the most creative and major developments in Canadian history occurred in the metropolitan centres of Central Canada, and the civilization of North America is the civilization of Europe. Innis considered place to be critical in the development of the Canadian West and wrote of the importance of metropolitan areas, settlements, and indigenous people in the creation of markets. Turner and Innis have continued to exert influence over the historiography of the American and Canadian Wests. The Quebec frontier showed little of the individualism or democracy that Turner ascribed to the American zone to the south. The Nova Scotia and Ontario frontiers were more democratic than the rest of Canada, but whether that was caused by the need to be self-reliant on the frontier itself or the presence of large numbers of American immigrants is debated.\nThe Canadian political thinker Charles Blattberg has argued that such events ought to be seen as part of a process in which Canadians advanced a \"border,\" as distinct from a \"frontier,\" from east to west. According to Blattberg, a border assumes a significantly sharper contrast between the civilized and the uncivilized since unlike a frontier process in which the civilizing force is not supposed to be shaped by what it civilizes. Blattberg criticizes both the frontier and the border \"civilizing\" processes.\nCanadian Prairies.\nThe pattern of settlement of the Canadian Prairies began in 1896, when the American Prairies had already achieved statehood. Pioneers then headed north to the \"Last Best West.\" \nBefore the settlers began to arrive, the North West Mounted Police had been dispatched to the region. When the settlers began to arrive, a system of law and order was already in place, and the Dakotas' lawlessness that was famous for the American \"Wild West\" did not occur in Canada. The federal government had also sent teams of negotiators to meet with the indigenous peoples of the region. In a series of treaties, the basis for peaceful relations was established, and the long wars with the Natives that occurred in the United States largely did not spread to Canada.\nLike their American counterparts, the Canadian Prairies supported populist and democratic movements in the early 20th century.\nRussia.\nThe expansion of Russia to the north, south (Wild Fields) and east (Siberia, the Russian Far East and Russian Alaska) exploited ever-changing frontier regions over several centuries and often involved the development and settlement of Cossack communities.\nChina.\nXinjiang.\nXinjiang in Chinese literally means \"New Frontier\" or \"New Territory\" (), and its previous full name was \"Xiyu Xinjiang\" (), after Qing China conquered the region in 1759.\nThe transformation of Xinjiang into a Chinese frontier was decisively shaped by the Qing Empire\u2019s military conquest of the Dzungar Khanate in the 18th century, a series of campaigns often referred to as the Dzungar Wars (1687\u20131757). These brutal wars against the Mongol Buddhist Dzungars\u2014who had built a powerful steppe polity stretching from the Altai to the Ili River\u2014culminated in the near-total destruction of the Dzungar population through warfare, famine, disease, and state-sanctioned mass killings, which some historians characterize as genocidal. Following the conquest, the Qing initiated a large-scale demographic, military, and administrative reordering of the region. Vacated Dzungar lands in the north (Zhunbu) were repopulated with Manchus, Han Chinese, Mongols, and especially Uyghur Muslims from the south (Hui Muslims), laying the foundation for the modern ethno-geographic landscape of Xinjiang. This moment marks the beginning of Xinjiang as an imperial frontier\u2014not just a militarized buffer against Central Asia and Russia, but a zone of active settler colonization, resource extraction, and frontier governance. The Qing\u2019s establishment of garrisons, banner systems, and dual administration over Muslim and nomadic populations illustrates the imperial strategy of managing diversity while extending sovereignty.\nGuizhou.\nThe northeastern part of Guizhou Province was called \"Liangyou Xinjiang\" () in early Qing Dynasty. During the reign of the Yongzheng Emperor (1722\u20131735), the Qing state undertook a more assertive and systematic effort to incorporate and develop Guizhou, a rugged, mountainous frontier province inhabited largely by non-Han ethnic groups such as the Miao and Buyi. This campaign reflected the broader Qing ambition to solidify imperial authority across its southwestern periphery. Yongzheng implemented the policy of \"gaitu guiliu\" (), replacing hereditary native chieftains (tusi) with centrally appointed officials in order to strengthen bureaucratic control and undermine semi-autonomous indigenous governance.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50345", "revid": "49402000", "url": "https://en.wikipedia.org/wiki?curid=50345", "title": "Urban design", "text": "Designing and shaping of human settlements\nUrban design is an approach to the design of buildings and the spaces between them that focuses on specific design processes and outcomes based on geographical location. In addition to designing and shaping the physical features of towns, cities, and regional spaces, urban design considers 'bigger picture' issues of economic, social and environmental value and social design. The scope of a project can range from a local street or public space to an entire city and surrounding areas. Urban designers connect the fields of architecture, landscape architecture and urban planning to better organize local and community environments' dependent upon geographical location.\nSome important focuses of urban design on this page include its historical impact, paradigm shifts, its interdisciplinary nature, and issues related to urban design.\nTheory.\nUrban design deals with the larger scale of groups of buildings, infrastructure, streets, and public spaces, entire neighbourhoods and districts, and entire cities, with the goal of making urban environments that are equitable, beautiful, performative, and sustainable.\nUrban design is an interdisciplinary field that utilizes the procedures and the elements of architecture and other related professions, including landscape design, urban planning, civil engineering, and municipal engineering, while extenuating to the Spatial Sciences. It borrows substantive and procedural knowledge from public administration, sociology, law, urban geography, urban economics and other related disciplines from the social and behavioral sciences, as well as from the natural sciences. In more recent times different sub-subfields of urban design have emerged such as strategic urban design, landscape urbanism, water-sensitive urban design, and sustainable urbanism. Urban design demands an understanding of a wide range of subjects from physical geography to social science, and an appreciation for disciplines, such as real estate development, urban economics, political economy, and social theory.\nUrban design theory deals primarily with the design and management of public space (i.e. the 'public environment', 'public realm' or 'public domain'), and the way public places are used and experienced. Public space includes the totality of spaces used freely on a day-to-day basis by the general public, such as streets, plazas, parks, and public infrastructure. Some aspects of privately owned spaces, such as building facades or domestic gardens, also contribute to public space and are therefore also considered by urban design theory. Important writers on urban design theory include Christopher Alexander, Peter Calthorpe, Gordon Cullen, Andr\u00e9s Duany, Jane Jacobs, Jan Gehl, Allan B. Jacobs, Kevin Lynch, Aldo Rossi, Colin Rowe, Robert Venturi, William H. Whyte, Camillo Sitte, Bill Hillier (space syntax), and Elizabeth Plater-Zyberk.\nHistory.\nAlthough contemporary professional use of the term 'urban design' dates from the mid-20th century, urban design as such has been practiced throughout history. Ancient examples of carefully planned and designed cities exist in Asia, Africa, Europe, and the Americas, and are particularly well known within Classical Chinese, Roman, and Greek cultures. Specifically, Hippodamus of Miletus was a famous ancient Greek architect and urban planner, and all around academic that is often considered to be a \"father of European urban planning\", and the namesake of the \"Hippodamian plan\", also known as the grid plan of a city layout.\nEuropean Medieval cities are often, and often erroneously, regarded as exemplars of undesigned or 'organic' city development. There are many examples of considered urban design in the Middle Ages. In England, many of the towns listed in the 9th-century Burghal Hidage were designed on a grid, examples including Southampton, Wareham, Dorset and Wallingford, Oxfordshire, having been rapidly created to provide a defensive network against Danish invaders. 12th century western Europe brought renewed focus on urbanisation as a means of stimulating economic growth and generating revenue. The burgage system dating from that time and its associated burgage plots brought a form of self-organising design to medieval towns. \nThroughout history, the design of streets and deliberate configuration of public spaces with buildings have reflected contemporaneous social norms or philosophical and religious beliefs. Yet the link between designed urban space and the human mind appears to be bidirectional. Indeed, the reverse impact of urban structure upon human behaviour and upon thought is evidenced by both observational study and historical records. There are clear indications of impact through Renaissance urban design on the thought of Johannes Kepler and Galileo Galilei. Already Ren\u00e9 Descartes in his \"Discourse on the Method\" had attested to the impact Renaissance planned new towns had upon his own thought, and much evidence exists that the Renaissance streetscape was also the perceptual stimulus that had led to the development of coordinate geometry.\nEarly modern era.\nThe beginnings of modern urban design in Europe are associated with the Renaissance but, especially, with the Age of Enlightenment. Spanish colonial cities were often planned, as were some towns settled by other imperial cultures. These sometimes embodied utopian ambitions as well as aims for functionality and good governance, as with James Oglethorpe's plan for Savannah, Georgia. In the Baroque period the design approaches developed in French formal gardens such as Versailles were extended into urban development and redevelopment. In this period, when modern professional specializations did not exist, urban design was undertaken by people with skills in areas as diverse as sculpture, architecture, garden design, surveying, astronomy, and military engineering. In the 18th and 19th centuries, urban design was perhaps most closely linked with surveyors engineers and architects. The increase in urban populations brought with it problems of epidemic disease, the response to which was a focus on public health, the rise in the UK of municipal engineering and the inclusion in British legislation of provisions such as minimum widths of street in relation to heights of buildings in order to ensure adequate light and ventilation.\nMuch of Frederick Law Olmsted's work was concerned with urban design, and the newly formed profession of landscape architecture also began to play a significant role in the late 19th century.\nModern urban design.\nIn the 19th century, cities were industrializing and expanding at a tremendous rate. Private businesses largely dictated the pace and style of this development. The expansion created many hardships for the working poor and concern for public health increased. However, the laissez-faire style of government, in fashion for most of the Victorian era, was starting to give way to a New Liberalism. This gave more power to the public. The public wanted the government to provide citizens, especially factory workers, with healthier environments. Around 1900, modern urban design emerged from developing theories on how to mitigate the consequences of the industrial age.\nThe first modern urban planning theorist was Sir Ebenezer Howard. His ideas, although utopian, were adopted around the world because they were highly practical. He initiated the garden city movement. in 1898.\nHis garden cities were intended to be planned, self-contained communities surrounded by parks. Howard wanted the cities to be proportional with separate areas of residences, industry, and agriculture. Inspired by the Utopian novel \"Looking Backward\" and Henry George's work \"Progress and Poverty\", Howard published his book \"Garden Cities of To-morrow\" in 1898. His work is an important reference in the history of urban planning. He envisioned the self-sufficient garden city to house 32,000 people on a site of . He planned on a concentric pattern with open spaces, public parks, and six radial boulevards, wide, extending from the center. When it reached full population, Howard wanted another garden city to be developed nearby. He envisaged a cluster of several garden cities as satellites of a central city of 50,000 people, linked by road and rail. His model for a garden city was first created at Letchworth and Welwyn Garden City in Hertfordshire. Howard's movement was extended by Sir Frederic Osborn to regional planning.\n20th century.\nIn the early 1900s, urban planning became professionalized. With input from utopian visionaries, civil engineers, and local councilors, new approaches to city design were developed for consideration by decision-makers such as elected officials. In 1899, the Town and Country Planning Association was founded. In 1909, the first academic course on urban planning was offered by the University of Liverpool. Urban planning was first officially embodied in the Housing and Town Planning Act of 1909 Howard's 'garden city' compelled local authorities to introduce a system where all housing construction conformed to specific building standards. In the United Kingdom following this Act, surveyor, civil engineers, architects, and lawyers began working together within local authorities. In 1910, Thomas Adams became the first Town Planning Inspector at the Local Government Board and began meeting with practitioners. In 1914, The Town Planning Institute was established. The first urban planning course in America was not established until 1924 at Harvard University. Professionals developed schemes for the development of land, transforming town planning into a new area of expertise.\nIn the 20th century, urban planning was changed by the automobile industry. Car-oriented design impacted the rise of 'urban design'. City layouts now revolved around roadways and traffic patterns.\nIn June 1928, the International Congresses of Modern Architecture (CIAM) was founded at the Chateau de la Sarraz in Switzerland, by a group of 28 European architects organized by Le Corbusier, H\u00e9l\u00e8ne de Mandrot, and Sigfried Giedion. The CIAM was one of many 20th century manifestos meant to advance the cause of \"architecture as a social art\".\nPostwar.\nTeam X was a group of architects and other invited participants who assembled starting in July 1953 at the 9th Congress of the International Congresses of Modern Architecture (CIAM) and created a schism within CIAM by challenging its doctrinaire approach to urbanism.\nIn 1956, the term \"Urban design\" was first used at a series of conferences hosted by Harvard University. The event provided a platform for Harvard's Urban Design program. The program also utilized the writings of famous urban planning thinkers: Gordon Cullen, Jane Jacobs, Kevin Lynch, and Christopher Alexander.\nIn 1961, Gordon Cullen published \"The Concise Townscape\". He examined the traditional artistic approach to city design of theorists including Camillo Sitte, Barry Parker, and Raymond Unwin. Cullen also created the concept of 'serial vision'. It defined the urban landscape as a series of related spaces.\nAlso in 1961, Jane Jacobs published \"The Death and Life of Great American Cities\". She critiqued the modernism of CIAM (International Congresses of Modern Architecture). Jacobs also claimed crime rates in publicly owned spaces were rising because of the Modernist approach of 'city in the park'. She argued instead for an 'eyes on the street' approach to town planning through the resurrection of main public space precedents (e.g. streets, squares).\nIn the same year, Kevin Lynch published \"The Image of the City\". He was seminal to urban design, particularly with regards to the concept of legibility. He reduced urban design theory to five basic elements: paths, districts, edges, nodes, landmarks. He also made the use of mental maps to understand the city popular, rather than the two-dimensional physical master plans of the previous 50 years.\nOther notable works:\nThe popularity of these works resulted in terms that become everyday language in the field of urban planning. Aldo Rossi introduced 'historicism' and 'collective memory' to urban design. Rossi also proposed a 'collage metaphor' to understand the collection of new and old forms within the same urban space. Peter Calthorpe developed a manifesto for sustainable urban living via medium-density living. He also designed a manual for building new settlements in his concept of Transit Oriented Development (TOD). Bill Hillier and Julienne Hanson introduced Space Syntax to predict how movement patterns in cities would contribute to urban vitality, anti-social behaviour, and economic success. 'Sustainability', 'livability', and 'high quality of urban components' also became commonplace in the field.\nCurrent trends.\nToday, urban design seeks to create sustainable urban environments with long-lasting structures, buildings, and overall livability. Walkable urbanism is another approach to practice that is defined within the \"Charter of New Urbanism\". It aims to reduce environmental impacts by altering the built environment to create smart cities that support sustainable transport. Compact urban neighborhoods encourage residents to drive less. These neighborhoods have significantly lower environmental impacts when compared to sprawling suburbs. To prevent urban sprawl, Circular flow land use management was introduced in Europe to promote sustainable land use patterns.\nAs a result of the recent New Classical Architecture movement, sustainable construction aims to develop smart growth, walkability, architectural tradition, and classical design. It contrasts with modernist and globally uniform architecture. In the 1980s, urban design began to oppose the increasing solitary housing estates and suburban sprawl.\nManaged Urbanisation with the view to making the urbanising process completely culturally and economically, and environmentally sustainable, and as a possible solution to the urban sprawl, Frank Reale has submitted an interesting concept of https:// that integrates many urban designs and ecological principles, to design and build smaller rural hubs with high-grade connecting freeways, rather than adding more expensive infrastructure to existing big cities and the resulting congestion.\nParadigm shifts.\nThroughout the young existence of the Urban Design discipline, many paradigm shifts have occurred that have affected the trajectory of the field regarding theory and practice. These paradigm shifts cover multiple subject areas outside of the traditional design disciplines.\nNew approaches.\nThere have been many different theories and approaches applied to the practice of urban design.\nNew Urbanism is an approach that began in the 1980s as a place-making initiative to combat suburban sprawl. Its goal is to increase density by creating compact and complete towns and neighborhoods. The 10 principles of new urbanism are walkability, connectivity, mixed-use and diversity, mixed housing, quality architecture and urban design, traditional neighborhood structure, increased density, smart transportation, sustainability, and quality of life. New urbanism and the developments that it has created are sources of debates within the discipline, primarily with the landscape urbanist approach but also due to its reproduction of idyllic architectural tropes that do not respond to the context. Andres Duany, Elizabeth Plater-Zyberk, Peter Calthorpe, and Jeff Speck are all strongly associated with New Urbanism and its evolution over the years.\nLandscape Urbanism is a theory that first surfaced in the 1990s, arguing that the city is constructed of interconnected and ecologically rich horizontal field conditions, rather than the arrangement of objects and buildings. Charles Waldheim, Mohsen Mostafavi, James Corner, and Richard Weller are closely associated with this theory. Landscape urbanism theorises sites, territories, ecosystems, networks, and infrastructures through landscape practice according to Corner, while applying a dynamic concept to cities as ecosystems that grow, shrink or change phases of development according to Waldheim.\nEveryday Urbanism is a concept introduced by Margaret Crawford and influenced by Henry Lefebvre that describes the everyday lived experience shared by urban residents including commuting, working, relaxing, moving through city streets and sidewalks, shopping, buying, eating food, and running errands. Everyday urbanism is not concerned with aesthetic value. Instead, it introduces the idea of eliminating the distance between experts and ordinary users and forces designers and planners to contemplate a 'shift of power' and address social life from a direct and ordinary perspective.\nTactical Urbanism (also known as DIY Urbanism, Planning-by-Doing, Urban Acupuncture, or Urban Prototyping) is a city, organizational, or citizen-led approach to neighborhood-building that uses short-term, low-cost, and scalable interventions and policies to catalyze long term change.\nTop-up Urbanism is the theory and implementation of two techniques in urban design: top-down and bottom-up. Top-down urbanism is when the design is implemented from the top of the hierarchy - normally the government or planning department. Bottom-up or grassroots urbanism begins with the people or the bottom of the hierarchy. Top-up means that both methods are used together to make a more participatory design, so it is sure to be comprehensive and well regarded in order to be as successful as possible.\nInfrastructural Urbanism is the study of how the major investments that go into making infrastructural systems can be leveraged to be more sustainable for communities. Instead of the systems being solely about efficiency in both cost and production, infrastructural urbanism strives to utilize these investments to be more equitable for social and environmental issues as well. Linda Samuels is a designer investigating how to accomplish this change in infrastructure in what she calls \"next-generation infrastructure\" which is \"multifunctional; public; visible; socially productive; locally specific, flexible, and adaptable; sensitive to the eco-economy; composed of design prototypes or demonstration projects; symbiotic; technologically smart; and developed collaboratively across disciplines and agencies\".\nSustainable Urbanism is the study from the 1990s of how a community can be beneficial for the ecosystem, the people, and the economy for which it is associated. It is based on Scott Campbell's planner's triangle which tries to find the balance between economy, equity, and the environment. Its main concept is to try and make cities as self-sufficient as possible while not damaging the ecosystem around them, today with an increased focus on climate stability. A key designer working with sustainable urbanism is Douglas Farr.\nFeminist Urbanism is the study and critique of how the built environment affects genders differently because of patriarchal social and political structures in society. Typically, the people at the table making design decisions are men, so their conception about public space and the built environment relates to their life perspectives and experiences, which do not reflect the same experiences of women or children. Dolores Hayden is a scholar who has researched this topic from 1980 to the present day. Hayden's writing says, \u201cwhen women, men, and children of all classes and races can identify the public domain as the place where they feel most comfortable as citizens, Americans will finally have homelike urban space.\u201d\nRecently, \"New Contextualism\" has emerged as a philosophy in architecture and urban design, primarily coined and propagated by Bangladeshi architect and academic Mohammad Habib Reza. This approach advocates for creating built environments that are profoundly informed by both historical precedents and future predictions, while embracing a holistic understanding of context. Unlike universalist or purely modernist perspectives, New Contextualism emphasizes the deep integration of a design within its specific setting, considering not only the immediate site but also broader universal values, regional characteristics, and the socio-cultural fabric of a place. It stresses the importance of equity, social justice, and the revitalization of vernacular building traditions to achieve sustainable and inclusive designs. The philosophy encourages the use of data analytics and scenario planning to anticipate future needs and challenges, aiming for timeless yet adaptable architectural solutions. \nEducational Urbanism is an emerging discipline, at the crossroads of urban planning, educational planning, and pedagogy. An approach that tackles the notion that economic activities, the need for new skills at the workplace, and the spatial configuration of the workplace rely on the spatial reorientation in the design of educational spaces and the urban dimension of educational planning.\nBlack Urbanism is an approach in which black communities are active creators, innovators, and authors of the process of designing and creating the neighborhoods and spaces of the metropolitan areas they have done so much to help revive over the past half-century. The goal is not to build black cities for black people but to explore and develop the creative energy that exists in so-called black areas: that has the potential to contribute to the sustainable development of the whole city.\nDebates in urbanism.\nUnderlying the practice of urban design are the many theories about how to best design the city. Each theory makes a unique claim about how to effectively design thriving, sustainable urban environments. Debates over the efficacy of these approaches fill the urban design discourse. Landscape Urbanism and New Urbanism are commonly debated as distinct approaches to addressing suburban sprawl. While Landscape Urbanism proposes landscape as the basic building block of the city and embraces horizontality, flexibility, and adaptability, New Urbanism offers the neighborhood as the basic building block of the city and argues for increased density, mixed uses, and walkability. Opponents of Landscape Urbanism point out that most of its projects are urban parks, and as such, its application is limited. Opponents of New Urbanism claim that its preoccupation with traditional neighborhood structures is nostalgic, unimaginative, and culturally problematic. Everyday Urbanism argues for grassroots neighborhood improvements rather than master-planned, top-down interventions. Each theory elevates the roles of certain professions in the urban design process, further fueling the debate. In practice, urban designers often apply principles from many urban design theories. Emerging from the conversation is a universal acknowledgement of the importance of increased interdisciplinary collaboration in designing the modern city.\nUrban design as an integrative profession.\nUrban designers work with architects, landscape architects, transportation engineers, urban planners, and industrial designers to reshape the city. Cooperation with public agencies, authorities and the interests of nearby property owners is necessary to manage public spaces. Users often compete over the spaces and negotiate across a variety of spheres. Input is frequently needed from a wide range of stakeholders. This can lead to different levels of participation as defined in Arnstein's Ladder of Citizen Participation.\nWhile there are some professionals who identify themselves specifically as urban designers, a majority have backgrounds in urban planning, architecture, or landscape architecture. Many collegiate programs incorporate urban design theory and design subjects into their curricula. There is an increasing number of university programs offering degrees in urban design at the post-graduate level.\nUrban design considers:\nRelationships with other related disciplines.\nThe original urban design was thought to be separated from architecture and urban planning. Urban Design has developed to a certain extent, and comes from the foundation of engineering. In Anglo-Saxon countries, it is often considered as a branch under the architecture, urban planning, and landscape architecture and limited as the construction of the urban physical environment. However Urban Design is more integrated into the social science-based, cultural, economic, political, and other aspects. Not only focus on space and architectural group, but also look at the whole city from a broader and more holistic perspective to shape a better living environment. Compared to architecture, the spatial and temporal scale of Urban Design processing is much larger. It deals with neighborhoods, communities, and even the entire city.\nThe urban design education.\nThe University of Liverpool's Department of Civic Design is the first urban design school in the world founded in 1909. Following the 1956 Urban Design conference, Harvard University established the first graduate program with urban design in its title, The Master of Architecture in Urban Design, although as a subject taught in universities its history in Europe is far older. Urban design programs explore the built environment from diverse disciplinary backgrounds and points of view. The pedagogically innovative combination of interdisciplinary studios, lecture courses, seminars, and independent study creates an intimate and engaging educational atmosphere in which students thrive and learn. Soon after in 1961, Washington University in St. Louis founded their Master of Urban Design program. Today, twenty urban design programs exist in the United States:\nIn the United Kingdom, Master's programmes in Urban Design at University of Manchester or University of Sheffield and Cardiff University or London South Bank University and City Design at the Royal College of Art or Queen's University Belfast are offered.\nIssues.\nThe field of urban design holds enormous potential for helping us address today's biggest challenges: an expanding population, mass urbanization, rising inequality, and climate change. In its practice as well as its theories, urban design attempts to tackle these pressing issues. As climate change progresses, urban design can mitigate the results of flooding, temperature changes, and increasingly detrimental storm impacts through a mindset of sustainability and resilience. In doing so, the urban design discipline attempts to create environments that are constructed with longevity in mind, such as zero-carbon cities. Cities today must be designed to minimize resource consumption, waste generation, and pollution while also withstanding the unprecedented impacts of climate change. To be truly resilient, our cities need to be able to not just bounce back from a catastrophic climate event but to bounce forward to an improved state.\nAnother issue in this field is that it is often assumed that there are no mothers of planning and urban design. However, this is not the case, many women have made proactive contributions to the field, including the work of Mary Kingsbury Simkhovitch, Florence Kelley, and Lillian Wald, to name a few of whom were prominent leaders in the City Social movement. The City Social was a movement that steamed between the commonly known City Practical and City Beautiful movements. It was a movement mainly concerning lay with the economic and social equalities regarding urban issues.\nJustice is and will always be a key issue in urban design. As previously mentioned, past urban strategies have caused injustices within communities incapable of being remedied via simple means. As urban designers tackle the issue of justice, they often are required to look at the injustices of the past and must be careful not to overlook the nuances of race, place, and socioeconomic status in their design efforts. This includes ensuring reasonable access to basic services, transportation, and fighting against gentrification and the commodification of space for economic gain. Organizations such as the Divided Cities Initiatives at Washington University in St. Louis and the Just City Lab at Harvard work on promoting justice in urban design.\nUntil the 1970s, the design of towns and cities took little account of the needs of people with disabilities. At that time, disabled people began to form movements demanding recognition of their potential contribution if social obstacles were removed. Disabled people challenged the 'medical model' of disability which saw physical and mental problems as an individual 'tragedy' and people with disabilities as 'brave' for enduring them. They proposed instead a 'social model' which said that barriers to disabled people result from the design of the built environment and attitudes of able-bodied people. 'Access Groups' were established composed of people with disabilities who audited their local areas, checked planning applications, and made representations for improvements. The new profession of 'access officer' was established around that time to produce guidelines based on the recommendations of access groups and to oversee adaptations to existing buildings as well as to check on the accessibility of new proposals. Many local authorities now employ access officers who are regulated by the Access Association. A new chapter of the Building Regulations (Part M) was introduced in 1992. Although it was beneficial to have legislation on this issue the requirements were fairly minimal but continue to be improved with ongoing amendments. The Disability Discrimination Act 1995 continues to raise awareness and enforce action on disability issues in the urban environment.\nThe issue of walkability has gained prominence in recent years, not only with the concerns of the aforementioned climate change, but also the health outcomes of residents. Car-centric urban design has an invariably negative effect on such outcomes. With proximity to internal combustion engines, residents tend to suffer from dangerous levels of air pollution which lead to cardiovascular complications ranging from the acute, in hypertension and alterations in heart rate, and the chronic, the outright development of atherosclerosis. More people die from air pollution each year than from car accidents. This issue has been used to fuel movements for alternative forms of long to mid range transportation such as trains and bicycles, with walking as the primary means of short-range travel. This would bring benefits from two simultaneous avenues. The physical activity from walking, and the lack of particulate matter (carbon dioxide, sulfur dioxide, nitrogen dioxide, etc.) has shown to alleviate and lower the risk of many maladies such as diabetes, hypertension and cardiovascular disease. Physical activity levels from walking are closely related to the abundance of open public spaces, commercial shops, greenery, among others. These attributes also have been stated to contribute to stronger social and emotional health as the open public spaces facilitate more social interaction within communities. This issue is most prevalent in the United States, where the rise of neoliberalism directly and intentionally caused the car-centric infrastructure.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50346", "revid": "31831", "url": "https://en.wikipedia.org/wiki?curid=50346", "title": "Museum of Science and Industry (Chicago)", "text": "The Museum of Science and Industry (MSI; formally Kenneth C. Griffin Museum of Science and Industry since 2024) is a private, non-profit science museum located in Jackson Park, the Hyde Park neighborhood, Chicago, Illinois. It is adjacent to Lake Michigan and the University of Chicago campus.\nThe museum is housed in the Palace of Fine Arts from the 1893 World's Columbian Exposition. Initially endowed by Sears, Roebuck and Company president and philanthropist Julius Rosenwald and supported by the Commercial Club of Chicago, it opened in 1933 during the Century of Progress Exposition. It was renamed for benefactor and financier Kenneth C. Griffin on May 19, 2024.\nAmong the museum's most popular exhibits are the actual captured during World War II, a United Airlines Boeing 727, the \"Pioneer Zephyr\" (the first streamlined diesel-powered passenger train in the US); the command module of the Apollo 8 spacecraft, a full-size replica coal mine, and a model railroad. Permanent or special exhibits cover manufacturing, environmental science, chemistry, physics, computers, the brain, mechanics of the human body, and agricultural science, among other subjects. \n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nWorld's Columbian Exposition and aftermath.\nThe building which houses the Museum was constructed as the Palace of Fine Arts, built for the 1893 World's Columbian Exposition and designed by Charles B. Atwood for D. H. Burnham &amp; Company. During the fair, the palace displayed paintings, prints, drawing, sculpture, and metalwork from around the world. Unlike the other \"White City\" buildings, which were primarily temporary, it was constructed with a permanent brick substructure under its plaster facade.\nAfter the World's Fair, the palace initially housed the Columbian Museum, largely displaying collections left from the fair, which evolved into the Field Museum of Natural History. When the Field Museum moved to a new building five miles north in the Near South Side in 1920, the palace was left vacant.\nSchool of the Art Institute of Chicago professor Lorado Taft led a public campaign to restore the building and turn it into another art museum, one devoted to sculpture. The South Park Commissioners (now part of the Chicago Park District) won approval in a referendum to sell $5 million in bonds to pay for restoration costs, hoping to turn the building into a sculpture museum, a technical trade school, and other things. However, after a few years, the building was selected as the site for a new science museum.\nMuseum formation.\nAt this time, the Commercial Club of Chicago was interested in establishing a science museum in Chicago. Julius Rosenwald, philanthropist and Sears, Roebuck and Company president, energized his fellow club members by pledging to pay $3 million towards the cost of converting the Palace of Fine Arts (Rosenwald eventually contributed more than $5 million to the project). During its conversion into the MSI, the building's exterior was re-cast in limestone to retain its 1893 Beaux Arts look. The interior was replaced with a new one in Art Moderne style designed by Alfred P. Shaw.\nRosenwald established the museum organization in 1926 but declined to have his name on the building. For the first two years of development, the museum was often referred to as the \"Rosenwald Industrial Museum\". In 1928, the name of the museum officially became the Museum of Science and Industry. Rosenwald's vision was to create a museum in the style of the Deutsches Museum of science and technology in Munich, which he had visited in 1911 while in Germany with his family.\nSewell Avery, another businessman, had supported the museum within the Commercial Club and was selected as its first president of the board of directors. The museum conducted a nationwide search for the first director. MSI's Board of Directors selected Waldemar Kaempffert, then the science editor of \"The New York Times\", because he shared Rosenwald's vision.\nHe assembled the museum's curatorial staff and directed the organization and construction of the exhibits. In order to prepare the museum, Kaempffert and his staff visited the Deutsches Museum in Munich, the Science Museum in Kensington, and the Technical Museum in Vienna, all of which served as models. Kaempffert was instrumental in developing close ties with the science departments of the University of Chicago, which supplied much of the scholarship for the exhibits. Kaempffert resigned in early 1931 amid growing disputes with the second president of the board of directors; they disagreed over the objectivity and neutrality of the exhibits and Kaempffert's management of the staff.\nOpening.\nThe museum underwent renovation work, including the installation of a Ludowici tile roof on the central dome in 1930, before opening to the public in three stages between 1933 and 1940. The first opening ceremony took place during the Century of Progress Exposition. Two of the museum's presidents, a number of curators and other staff members, and exhibits came to MSI from the Century of Progress event.\nIn 1992, the museum began planning a series of renovations as part of the \"MSI2000\" plan. This included an underground three-level parking deck beneath the front lawn. Construction of the underground parking deck was finished in July 1998. These renovations also eventually incorporated a new subterranean main entrance hall which visitors descend into before re-ascending into the main building, similar to the entryway beneath the Louvre Pyramid in Paris.\nFor the first 5 decades of its operation, general admission to the MSI was free, although certain exhibits (such as the \"Coal Mine\" and \"U-505\") required small fees. General entrance fees were first charged in the early 1990s, with general admission rates increasing from $13 in 2008 to $18 in 2015 and $25.95 in 2024. Many \"free days\"\u2014for Illinois residents only\u2014are offered throughout the year.\nRenaming.\nOn October 3, 2019, the museum announced that it intended to change its name to the Kenneth C. Griffin Museum of Science and Industry, after a donation of $125 million from billionaire Kenneth C. Griffin. It is the largest single gift in the museum's history, effectively doubling its endowment. However, president and chief executive officer David Mosena said the formal name change could take some time, due to the legal complexity of the process. He also said part of the gift will go into funding \"a state-of-the-art digital gallery and performance space that will be the only experience of its kind in North America.\" Chevy Humphrey became president and CEO of the private, non-profit museum in January 2021. The new name was officially unveiled on May 19, 2024, alongside an updated logo. Due to Griffin\u2019s conservative political views, the name change drew criticism from some in the community. Specifically, some were upset that Griffin had offloaded many of his Chicago properties and moved his family to Miami due to the city of Chicago's politics and crime rates.\nIn 2025, the Driehaus Foundation, which has interests in preserving neo-classical architecture, announced its largest capital grant to date of $10 million to help fund the renovation of the museum's south entrance accessibility and new public amenity spaces. The south portico with platforms and steps down to the Jackson Park lagoon was the building's main entrance during the world's fair when it was built in the 1890s. The south entrance also faces toward the nearby Barack Obama Presidential Center part of the Museum Campus South.\nExhibits.\nThe museum has over 2,000 exhibits, displayed in 75 major halls. Many of the major exhibits are permanent or semi-permanent. Access to the \"Coal Mine\", \"U-505\" on-board tour, and other special exhibits requires an additional fee, while other exhibits require a free timed-entry ticket. In keeping with Rosenwald's vision for the museum, many of the exhibits are interactive.\nEntry Hall.\n\"Pioneer Zephyr\".\nThe first diesel-powered, streamlined stainless-steel passenger train, the \"Pioneer Zephyr\", is on permanent display in the Entry Hall (previously the Great Hall, renamed in 2008). The train was previously displayed outdoors, before being relocated indoors during the construction of the museum's underground parking lot in the 1990s.\n\"NASCAR Next Gen 2023 Ford Mustang\".\nAdded to the Entry Hall to coincide with the first NASCAR Chicago Street Race, the Next Gen Ford Mustang is painted by local Chicago artists Paint The City, and showcases modern race-car engineering. It is set to remain at the museum through 2026.\nLower level.\n\"U-505\".\n is one of just six German submarines captured by the Allies during World War II, and, since its arrival in 1954, the only one on display in the Western Hemisphere. The \"U-505\" exhibit was dedicated as a permanent war memorial by the museum in 1954, and the submarine was designated a National Historic Landmark in 1989.\nFor its first 50 years at the museum, \"U-505\" was displayed outdoors. Starting in 2004, the U-boat was newly restored and moved into its current indoor exhibit, which opened as \"The New U-505 Experience\" on June 5, 2005. The submarine itself is located in a large concrete bunker at the end of the multi-floor exhibit alongside various artifacts found aboard, as well as interactive games related to the operation of a submarine. Guided tours of the submarine's interior are offered for an additional fee.\nLocated outside the entrance to the exhibit, there is both a Mold-A-Rama machine and a penny flattening device with \"U-505\" designs.\nHenry Crown Space Center.\nMSI's Henry Crown Space Center is located in its own connected wing on the building's southeast side. It opened in 1986, and was extensively renovated and reopened in 2024.\nThe Space Center includes the Apollo 8 command module, which flew the first human beings around the Moon; the Mercury-Atlas 7 capsule which flew the second American to orbit the Earth; a NASA lunar module trainer used to test procedures for the Apollo lunar landings, and a SpaceX Dragon 1 cargo spacecraft.\nLocated in the Henry Crown Space Center is the Giant Dome Theater, a domed theater which shows movies on a 5-story wrap-around screen of perforated aluminum (allowing the speakers to be mounted behind the screen and heard throughout the theater).\n\"FarmTech\".\nThe \"FarmTech\" exhibit showcases modern agricultural techniques and how farmers use modern technology like GPS systems to improve work on the farm, and includes a tractor and a combine harvester from John Deere. The exhibit also showcases a greenhouse, a mock-up of a kitchen showcasing how much of the food we eat comes from soybeans, and how we use cows, from energy to what we drink.\nOther.\nThe west wing of the museum's lower level includes two transportation exhibits, one displaying models of \"Ships Through the Ages\" and the other a collection of historic racing cars.\nThe lower level includes a number of single-room exhibits. \"Black Creativity: Architecture\" covers the history of Black architects, as part of the museum's wider \"Black Creativity\" initiative. \"Mold-A-Rama\"\u2122\": Molded for the Future\" showcases several Mold-A-Rama machines and the history and mechanics of injection-molded plastics manufacturing. Colleen Moore's Fairy Castle, an intricate miniature fantasy house with decorations inspired by folklore and fairy tales, is also on display, having been at the museum since 1949. \"90 and Beyond\" opened in 2023 to celebrate MSI's 90th anniversary, and showcases objects from each of the 9 decades in the museum's history.\nThere are multiple exhibits on the lower level aimed at younger children, including the \"Swiss Jollyball\", a kinetic art piece built by a British man from Switzerland using nothing but salvaged junk which showcases a metal ball moving on a track (described by the museum as a \"pinball machine\", for which it holds a Guinness World Record as the largest); the \"Idea Factory\", a toddler water table play area; and the \"Eye Spy\" gallery, a hallway with humorous tableaus behind windows.\nFirst level.\nTransportation Gallery.\nThe Transportation Gallery, located in the east wing of the museum on the first and second levels, contains several permanent exhibits.\nIn the middle of the wing is \"The Great Train Story\", a HO-scale model railroad which recreates an embellished version of the \"Empire Builder\" rail line from Chicago to Seattle, with sections depicting downtown Chicago, the Chicago suburbs, the Great Plains, the Rocky Mountains and the Cascades, and downtown Seattle with a cargo port.\nIn the main level of the gallery is NYC &amp; HRR Locomotive No. 999, known as the \"Empire State Express\", which is alleged by some sources to have been the first steam locomotive in the world to exceed 100 miles per hour (160km/h). It was donated to the museum in 1962, and displayed outside until being moved indoors and restored in 1993.\nThe first level of the Transportation Gallery also includes a replica of Stephenson's Rocket, which was the first steam locomotive to exceed 25 miles per hour; as well as several carriages and cars showcasing historic and modern road vehicles.\nThe second level of the Transportation Gallery consists of the \"Take Flight\" exhibit, which features the first Boeing 727 jet plane in commercial service, donated by United Airlines, with one wing removed and holes cut on the fuselage to facilitate visitor access. A formerly-working replica of the Wright Brothers' first airplane, the Wright Flyer, is also on display.\nTwo World War II warplanes are also exhibited, both donated by the British government: a German Ju 87 R-2/Trop. Stuka dive-bomber\u2014one of only two fully-intact Stukas left in the world\u2014and a British Mark 1A Supermarine Spitfire.\n\"Science Storms\".\nOpened in March 2010, \"Science Storms\" is a permanent multi-level exhibit which occupies the Allstate Court on the west side of the museum. On the first level it features a 40-foot (12-meter) water vapor tornado vortex, a rotating sand avalanche disk, a Foucault pendulum suspended from the ceiling, a tsunami wave tank, tethered hot air balloons, a heliostat system with solar panel-powered cars, and a section about light and color; on the second level it features a Tesla coil mounted to the ceiling which fires approximately every 30 minutes, a Wimshurst machine built by James Wimshurst in the late 19th century, a giant Newton's cradle, and sections on fire, chemistry, and magnetism.\n\"Coal Mine\".\nLocated in and beneath the south end of the museum's Central Pavilion, The \"Coal Mine\" re-creates a working deep-shaft bituminous coal mine, using original equipment from Old Ben #17, a mine in Johnston City, Illinois which closed in 1923. It is the museum's oldest exhibit, opening with MSI in 1933. Visitors are led through the exhibit by one or more \"coal miner\" guides, including a ride on a genuine mine train, and learn the history of unions and the science of coal mining and other types of energy production. The experience takes around 30 minutes and requires an additional fee.\nGriffin Studio &amp; \"Notes to Neurons\".\nOpened in 2024, the Kenneth C. Griffin Studio (or simply Griffin Studio) is an \"immersive multimedia experience\" with projections, sound, and movement recognition, intended to rotate presentations throughout its life. Its first and current presentation is entitled \"Notes to Neurons\", and examines how music interacts with the human mind and body.\n\"Numbers in Nature: A Mirror Maze\".\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\n\"Numbers in Nature: A Mirror Maze\" contains interactive stations to learn about patterns in nature, including the Golden Ratio, spirals, fractal branching, and Voronoi patterns. It also contains a mirror maze as a demonstration of geometric patterns. The exhibit requires a free timed entry ticket.\n\"The Blue Paradox\".\n\"The Blue Paradox\" is an immersive exhibit discussing the ocean plastics crisis which opened on July 1, 2023. Before being relocated to MSI, it was originally a pop-up experience in London, and is sponsored by S.C. Johnson.\n\"Genetics: Decoding Life\".\n\"Genetics: Decoding Life\" looks at how genetics affect human and animal development, as well as containing a chick hatchery composed of an incubator where baby chickens hatch from their eggs and a chick pen for those that have already hatched, as well as housing genetically modified frogs, mice, and drought resistant plants.\nThe chick hatchery has been part of the museum since 1956. About 20 chicks are hatched a day, around 140 hatch in a week, and up to 8000 hatch in a year. At one time, chicks would be collected by Lincoln Park Zoo to be fed to various animals, including lions, crocodiles, snakes, vultures, owls and tigers. This partnership between the museum and the zoo operated for decades, with about 7000 chicks being sent to the zoo each year. Some of the chicks hatched are of the Java species of chicken, and these are sent to a farm in La Fox, Illinois that works to preserve the rare breed. There have been numerous efforts to shut down the exhibit, as early as 1998 and as recent as 2017.\n\"Yesterday's Main Street\".\n\"Yesterday's Main Street\" is a mock-up of a Chicago street from the early 20th century, complete with a cobblestone roadway, old-fashioned light fixtures, fire hydrants, and several shops, including the precursors to several Chicago-based businesses. Included are:\nUnlike the other shops, the Nickelodeon Cinema can be entered and is functional, and plays silent films throughout the day.\n\"ToyMaker 3000\".\n\"ToyMaker 3000\" is a working assembly line which lets visitors order a \"Gravitron\" spinning top toy and watch as it is assembled. It is often closed for maintenance.\nWanger Family Fab Lab.\nThe Wanger Family Fab Lab (or simply \"Fab Lab\") is a digital fabrication facility with 3D-printers, laser-cutters, and various other tools and technologies used to create \"almost anything you can imagine.\" It is visible through windows, but not accessible to the general public, and is used by museum-sponsored workshops and summer camps.\nOther.\n\"Extreme Ice\" is an exhibit showcasing the effect of climate change on Earth's polar ice caps, including climate survey equipment, interactive screens, and a large ice wall which visitors can touch.\nOpened in spring 2013, \"The Art of the Bicycle\" showcases the history of bicycles, and how modern bikes continue to evolve.\n\"Earth Revealed\" centers around a \"Science on a Sphere\" holographic projection globe, and has presentations about planetary science, space exploration, and movies about rising sea levels and water use.\nThe Whispering Gallery, which opened in 1938, is a room shaped to reflect sound.\nSecond level.\n\"YOU! The Experience\".\n\"YOU! The Experience\" is an exhibit about life science and the mechanics of the body, featuring a , interactive, 3D heart, various motion-tracking interactive screens, a human-sized hamster wheel, and plastinated human remains showcasing anatomy.\nPeriodic Table.\nThe Regenstein Hall of Chemistry includes a giant periodic table of the elements with samples of each element as well as cases displaying food and materials science.\nMystery Ship.\nOn display hanging above the \"Coal Mine\" exhibit is the Travel Air Type R Mystery Ship, nicknamed \"Texaco 13\", an airplane which set many world records in flying.\nSimulators.\nLocated in the rear of the \"Take Flight\" exhibit is a series of flight simulators that allow visitors to fly historic fighter aircraft, and motion simulators that simulate journeys through the sky and space.\nFormer exhibits.\nAn F-104 Starfighter on loan to MSI from the US Air Force since 1978 was sent to the Mid-America Air Museum in Liberal, Kansas, in 1993.\nIn March 1995, Santa Fe Steam Locomotive 2903 was moved from outside the museum to the Illinois Railway Museum.\n\"Telefun Town\", a hall dedicated to the wonders of telephone communication, sponsored by the company then known as the Bell Telephone Company, no longer exists.\nOne well-known past exhibit was a walk-through model of the human heart, which was removed in 2009 for the construction of \"YOU! the Experience\".\n\"Fast Forward... Inventing the Future\", an exhibit about \"cutting-edge\" technologies such as hydroponics, space manufacturing and telerobotics, closed in 2022 to make way for the Griffin Studio and \"Notes to Neurons\". It was intended as a \"rotating gallery\", with sections being changed throughout its run at the museum to reflect new technological developments.\n\"Out of the Vault\", an exhibit showcasing various objects from MSI's collections, closed in 2022 to make way for \"The Blue Paradox\". The Spaceport, an exhibit about the fantasy and reality of space exploration with uniforms from \"\" and models of spacecraft on display, also closed in 2022 to make way for \"The Blue Paradox\".\n\"Future Energy Chicago\" was an exhibit showcasing alternative resources and energy production with a focus on energy use in the future. It officially closed in August 2022.\nSpecial exhibitions.\nIn addition to its three floors of standing exhibits, the museum hosts temporary and traveling exhibitions. Exhibitions typically last for less than 1 year and usually require a separate paid admission fee.\nPast exhibitions at MSI have included:\nYearly, from late November to early January, the museum hosts its \"Christmas Around the World\" and \"Holidays of Light\" exhibitions, featuring Christmas trees from different cultures from around the world and displays about various other cultural holiday celebrations. Started in 1942 with just one tree to honor soldiers fighting in World War Two, the tradition spawned into more than 50 trees.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50347", "revid": "19814917", "url": "https://en.wikipedia.org/wiki?curid=50347", "title": "Multivariate normal distribution", "text": "Generalization of the one-dimensional normal distribution to higher dimensions\nIn probability theory and statistics, the multivariate normal distribution, multivariate Gaussian distribution, or joint normal distribution is a generalization of the one-dimensional (univariate) normal distribution to higher dimensions. One definition is that a random vector is said to be \"k\"-variate normally distributed if every linear combination of its \"k\" components has a univariate normal distribution. Its importance derives mainly from the multivariate central limit theorem. The multivariate normal distribution is often used to describe, at least approximately, any set of (possibly) correlated real-valued random variables, each of which clusters around a mean value.\nDefinitions.\nNotation and parametrization.\nThe multivariate normal distribution of a \"k\"-dimensional random vector formula_1 can be written in the following notation:\n formula_2\nor to make it explicitly known that formula_3 is \"k\"-dimensional,\n formula_4\nwith \"k\"-dimensional mean vector\nformula_5\nand formula_6 covariance matrix\nformula_7\nsuch that formula_8 and formula_9. The inverse of the covariance matrix is called the precision matrix, denoted by formula_10.\nStandard normal random vector.\nA real random vector formula_1 is called a standard normal random vector if all of its components formula_12 are independent and each is a zero-mean unit-variance normally distributed random variable, i.e. if formula_13 for all formula_14.\nCentered normal random vector.\nA real random vector formula_1 is called a centered normal random vector if there exists a formula_16 matrix formula_17 such that formula_18 has the same distribution as formula_3 where formula_20 is a standard normal random vector with formula_21 components.\nNormal random vector.\nA real random vector formula_1 is called a normal random vector if there exists a random formula_21-vector formula_20, which is a standard normal random vector, a formula_25-vector formula_26, and a formula_16 matrix formula_17, such that formula_29.\nFormally:\nformula_30\nHere the covariance matrix is formula_31.\nIn the degenerate case where the covariance matrix is singular, the corresponding distribution has no density; see the section below for details. This case arises frequently in statistics; for example, in the distribution of the vector of residuals in the ordinary least squares regression. The formula_12 are in general \"not\" independent; they can be seen as the result of applying the matrix formula_17 to a collection of independent Gaussian variables formula_20.\nEquivalent definitions.\nThe following definitions are equivalent to the definition given above. A random vector formula_35 has a multivariate normal distribution if it satisfies one of the following equivalent conditions.\nThe spherical normal distribution can be characterised as the unique distribution where components are independent in any orthogonal coordinate system.\nDensity function.\nNon-degenerate case.\nThe multivariate normal distribution is said to be \"non-degenerate\" when the symmetric covariance matrix formula_41 is positive definite. In this case the distribution has density\nformula_45\nwhere formula_46 is a real \"k\"-dimensional column vector and formula_47 is the determinant of formula_41, also known as the generalized variance. The equation above reduces to that of the univariate normal distribution if formula_41 is a formula_50 matrix (i.e., a single real number).\nThe circularly symmetric version of the complex normal distribution has a slightly different form.\nEach iso-density locus \u2014 the locus of points in \"k\"-dimensional space each of which gives the same particular value of the density \u2014 is an ellipse or its higher-dimensional generalization; hence the multivariate normal is a special case of the elliptical distributions.\nThe quantity formula_51 is known as the Mahalanobis distance, which represents the distance of the test point formula_46 from the mean formula_53. \nThe squared Mahalanobis distance\nformula_54 is decomposed into a sum of \"k\" terms, each term being a product of three meaningful components.\nNote that in the case when formula_55, the distribution reduces to a univariate normal distribution and the Mahalanobis distance reduces to the absolute value of the standard score. See also Interval below.\nBivariate case.\nIn the 2-dimensional nonsingular case (formula_56), the probability density function of a vector formula_57 is:\nformula_58\nwhere formula_59 is the correlation between formula_60 and formula_61 and\nwhere formula_62 and formula_63. In this case,\n formula_64\nIn the bivariate case, the first equivalent condition for multivariate reconstruction of normality can be made less restrictive as it is sufficient to verify that a countably infinite set of distinct linear combinations of formula_60 and formula_61 are normal in order to conclude that the vector of formula_57 is bivariate normal.\nThe bivariate iso-density loci plotted in the formula_68-plane are ellipses, whose principal axes are defined by the eigenvectors of the covariance matrix formula_41 (the major and minor semidiameters of the ellipse equal the square-root of the ordered eigenvalues).\nAs the absolute value of the correlation parameter formula_59 increases, these loci are squeezed toward the following line :\n formula_71\nThis is because this expression, with formula_72 (where sgn is the sign function) replaced by formula_59, is the best linear unbiased prediction of formula_61 given a value of formula_60.\nDegenerate case.\nIf the covariance matrix formula_41 is not full rank, then the multivariate normal distribution is degenerate and does not have a density. More precisely, it does not have a density with respect to \"k\"-dimensional Lebesgue measure (which is the usual measure assumed in calculus-level probability courses). Only random vectors whose distributions are absolutely continuous with respect to a measure are said to have densities (with respect to that measure). To talk about densities but avoid dealing with measure-theoretic complications it can be simpler to restrict attention to a subset of formula_77 of the coordinates of formula_78 such that the covariance matrix for this subset is positive definite; then the other coordinates may be thought of as an affine function of these selected coordinates.\nTo talk about densities meaningfully in singular cases, then, we must select a different base measure. Using the disintegration theorem we can define a restriction of Lebesgue measure to the formula_77-dimensional affine subspace of formula_80 where the Gaussian distribution is supported, i.e. formula_81. With respect to this measure the distribution has the density of the following motif:\nformula_82\nwhere formula_83 is the generalized inverse and formula_84 is the pseudo-determinant.\nCumulative distribution function.\nThe notion of cumulative distribution function (cdf) in dimension 1 can be extended in two ways to the multidimensional case, based on rectangular and ellipsoidal regions.\nThe first way is to define the cdf formula_85 of a random vector formula_3 as the probability that all components of formula_3 are less than or equal to the corresponding values in the vector formula_78:\nformula_89\nThough there is no closed form for formula_85, there are a number of algorithms that estimate it numerically.\nAnother way is to define the cdf formula_91 as the probability that a sample lies inside the ellipsoid determined by its Mahalanobis distance formula_92 from the Gaussian, a direct generalization of the standard deviation.\nIn order to compute the values of this function, closed analytic formula exist, as follows.\nInterval.\nThe interval for the multivariate normal distribution yields a region consisting of those vectors x satisfying\nformula_93\nHere formula_46 is a formula_25-dimensional vector, formula_53 is the known formula_25-dimensional mean vector, formula_41 is the known covariance matrix and formula_99 is the quantile function for probability formula_100 of the chi-squared distribution with formula_25 degrees of freedom.\nWhen formula_102 the expression defines the interior of an ellipse and the chi-squared distribution simplifies to an exponential distribution with mean equal to two (rate equal to half).\nComplementary cumulative distribution function (tail distribution).\nThe complementary cumulative distribution function (ccdf) or the tail distribution \nis defined as formula_103. \nWhen formula_104, then\nthe ccdf can be written as a probability the maximum of dependent Gaussian variables:\nformula_105\nWhile no simple closed formula exists for computing the ccdf, the maximum of dependent Gaussian variables can \nbe estimated accurately via the Monte Carlo method.\nProperties.\nMoments.\nThe \"k\"th-order moments of x are given by\nformula_106\nwhere \"r\"1 + \"r\"2 + \u22ef + \"rN\" \n \"k\".\nThe \"k\"th-order central moments are as follows\nwhere the sum is taken over all allocations of the set formula_107 into \"\u03bb\" (unordered) pairs. That is, for a \"k\"th (\n 2\"\u03bb\" \n 6) central moment, one sums the products of \"\u03bb\" \n 3 covariances (the expected value \u03bc is taken to be 0 in the interests of parsimony):\n formula_108\nThis yields formula_109 terms in the sum (15 in the above case), each being the product of \"\u03bb\" (in this case 3) covariances. For fourth order moments (four variables) there are three terms. For sixth-order moments there are 3 \u00d7 5 \n 15 terms, and for eighth-order moments there are 3 \u00d7 5 \u00d7 7 \n 105 terms.\nThe covariances are then determined by replacing the terms of the list formula_110 by the corresponding terms of the list consisting of \"r\"1 ones, then \"r\"2 twos, etc.. To illustrate this, examine the following 4th-order central moment case:\n formula_111\nwhere formula_112 is the covariance of \"Xi\" and \"Xj\". With the above method one first finds the general case for a \"k\"th moment with \"k\" different \"X\" variables, formula_113, and then one simplifies this accordingly. For example, for formula_114, one lets \"Xi\" \n \"X\"\"j\" and one uses the fact that formula_115.\nFunctions of a normal vector.\nA quadratic form of a normal vector formula_116, formula_117 (where formula_118 is a matrix, formula_119 is a vector, and formula_120 is a scalar), is a generalized chi-squared variable. The direction of a normal vector follows a projected normal distribution.\nIf formula_121 is a general scalar-valued function of a normal vector, its probability density function, cumulative distribution function, and inverse cumulative distribution function can be computed with the numerical method of ray-tracing (https://).\nLikelihood function.\nIf the mean and covariance matrix are known, the log likelihood of an observed vector formula_116 is simply the log of the probability density function:\nformula_123,\nThe circularly symmetric version of the noncentral complex case, where formula_124 is a vector of complex numbers, would be\nformula_125\ni.e. with the conjugate transpose (indicated by formula_126) replacing the normal transpose (indicated by formula_127). This is slightly different than in the real case, because the circularly symmetric version of the complex normal distribution has a slightly different form for the normalization constant.\nA similar notation is used for multiple linear regression.\nSince the log likelihood of a normal vector is a quadratic form of the normal vector, it is distributed as a generalized chi-squared variable.\nDifferential entropy.\nThe differential entropy of the multivariate normal distribution is\nformula_128 \nwhere the bars denote the matrix determinant, \"k\" is the dimensionality of the vector space, and the result has units of nats.\nKullback\u2013Leibler divergence.\nThe Kullback\u2013Leibler divergence from formula_129 to formula_130, for non-singular matrices \u03a31 and \u03a30, is:\nformula_131\nwhere formula_132 denotes the matrix determinant, formula_133 is the trace, formula_134 is the natural logarithm and formula_25 is the dimension of the vector space.\nThe logarithm must be taken to base \"e\" since the two terms following the logarithm are themselves base-\"e\" logarithms of expressions that are either factors of the density function or otherwise arise naturally. The equation therefore gives a result measured in nats. Dividing the entire expression above by log\"e\"\u00a02 yields the divergence in bits.\nWhen formula_136,\nformula_137\nMutual information.\nThe mutual information of two multivariate normal distribution is a special case of the Kullback\u2013Leibler divergence in which formula_138 is the full formula_25 dimensional multivariate distribution and formula_140 is the product of the formula_141 and formula_142 dimensional marginal distributions formula_60 and formula_61, such that formula_145. The mutual information between formula_60 and formula_61 is given by:\nformula_148\nwhere \nformula_149\nIf formula_140 is product of formula_25 one-dimensional normal distributions, then in the notation of the Kullback\u2013Leibler divergence section of this article, formula_152 is a diagonal matrix with the diagonal entries of formula_153, and formula_136. The resulting formula for mutual information is:\nformula_155\nwhere formula_156 is the correlation matrix constructed from formula_157.\nIn the bivariate case the expression for the mutual information is:\nformula_158\nJoint normality.\nNormally distributed and independent.\nIf formula_60 and formula_61 are normally distributed and independent, this implies they are \"jointly normally distributed\", i.e., the pair formula_161 must have multivariate normal distribution. However, a pair of jointly normally distributed variables need not be independent (would only be so if uncorrelated, formula_162 ).\nTwo normally distributed random variables need not be jointly bivariate normal.\nThe fact that two random variables formula_60 and formula_61 both have a normal distribution does not imply that the pair formula_161 has a joint normal distribution. A simple example is one in which X has a normal distribution with expected value 0 and variance 1, and formula_166 if formula_167 and formula_168 if formula_169, where formula_170. There are similar counterexamples for more than two random variables. In general, they sum to a mixture model.\nCorrelations and independence.\nIn general, random variables may be uncorrelated but statistically dependent. But if a random vector has a multivariate normal distribution then any two or more of its components that are uncorrelated are independent. This implies that any two or more of its components that are pairwise independent are independent. But, as pointed out just above, it is \"not\" true that two random variables that are (\"separately\", marginally) normally distributed and uncorrelated are independent.\nConditional distributions.\nIf \"N\"-dimensional x is partitioned as follows\nformula_171\nand accordingly \u03bc and \u03a3 are partitioned as follows\nformula_172\nformula_173\nthen the distribution of x1 conditional on x2 = a is multivariate normal (x1\u00a0|\u00a0x2 \n a) ~ \"N\"(\u03bc, \u03a3) where\nformula_174\nand covariance matrix\nformula_175\nHere formula_176 is the generalized inverse of formula_177. The matrix formula_178 is the Schur complement of \u03a322 in \u03a3. That is, the equation above is equivalent to inverting the overall covariance matrix, dropping the rows and columns corresponding to the variables being conditioned upon, and inverting back to get the conditional covariance matrix.\nNote that knowing that x2 \n a alters the variance, though the new variance does not depend on the specific value of a; perhaps more surprisingly, the mean is shifted by formula_179; compare this with the situation of not knowing the value of a, in which case x1 would have distribution\nformula_180.\nAn interesting fact derived in order to prove this result, is that the random vectors formula_181 and formula_182 are independent.\nThe matrix \u03a312\u03a322\u22121 is known as the matrix of regression coefficients.\nBivariate case.\nIn the bivariate case where x is partitioned into formula_183 and formula_184, the conditional distribution of formula_183 given formula_184 is\n formula_187\nwhere formula_188 is the correlation coefficient between formula_183 and formula_184.\nformula_191\nBivariate conditional expectation.\nIn the general case.\nThe conditional expectation of X1 given X2 is:\n formula_192\nProof: the result is obtained by taking the expectation of the conditional distribution formula_193 above.\nformula_194\nIn the centered case with unit variances.\nThe conditional expectation of \"X\"1 given \"X\"2 is\n formula_195\nand the conditional variance is\n formula_196\nthus the conditional variance does not depend on \"x\"2.\nThe conditional expectation of \"X\"1 given that \"X\"2 is smaller/bigger than \"z\" is:\nformula_197\nformula_198\nwhere the final ratio here is called the inverse Mills ratio.\nProof: the last two results are obtained using the result formula_195, so that\nformula_200 and then using the properties of the expectation of a truncated normal distribution.\nMarginal distributions.\nTo obtain the marginal distribution over a subset of multivariate normal random variables, one only needs to drop the irrelevant variables (the variables that one wants to marginalize out) from the mean vector and the covariance matrix. The proof for this follows from the definitions of multivariate normal distributions and linear algebra.\n\"Example\"\nLet X \n [\"X\"1, \"X\"2, \"X\"3] be multivariate normal random variables with mean vector \u03bc \n [\"\u03bc\"1, \"\u03bc\"2, \"\u03bc\"3] and covariance matrix \u03a3 (standard parametrization for multivariate normal distributions). Then the joint distribution of X\u2032 \n [\"X\"1, \"X\"3] is multivariate normal with mean vector \u03bc\u2032 \n [\"\u03bc\"1, \"\u03bc\"3] and covariance matrix\nformula_201.\nAffine transformation.\nIf Y \n c + BX is an affine transformation of formula_202 where c is an formula_203 vector of constants and B is a constant formula_204 matrix, then Y has a multivariate normal distribution with expected value c + B\u03bc and variance B\u03a3BT i.e., formula_205. In particular, any subset of the \"Xi\" has a marginal distribution that is also multivariate normal.\nTo see this, consider the following example: to extract the subset (\"X\"1, \"X\"2, \"X\"4)T, use\nformula_206\nwhich extracts the desired elements directly.\nAnother corollary is that the distribution of Z \n b \u00b7 X, where b is a constant vector with the same number of elements as X and the dot indicates the dot product, is univariate Gaussian with formula_207. This result follows by using\nformula_208\nObserve how the positive-definiteness of \u03a3 implies that the variance of the dot product must be positive.\nAn affine transformation of X such as 2X is not the same as the sum of two independent realisations of X.\nGeometric interpretation.\nThe equidensity contours of a non-singular multivariate normal distribution are ellipsoids (i.e. affine transformations of hyperspheres) centered at the mean. Hence the multivariate normal distribution is an example of the class of elliptical distributions. The directions of the principal axes of the ellipsoids are given by the eigenvectors of the covariance matrix formula_41. The squared relative lengths of the principal axes are given by the corresponding eigenvalues.\nIf \u03a3 \n U\u039bUT \n U\u039b1/2(U\u039b1/2)T is an eigendecomposition where the columns of U are unit eigenvectors and \u039b is a diagonal matrix of the eigenvalues, then we have\nformula_210\nMoreover, U can be chosen to be a rotation matrix, as inverting an axis does not have any effect on \"N\"(0, \u039b), but inverting a column changes the sign of U's determinant. The distribution \"N\"(\u03bc, \u03a3) is in effect \"N\"(0, I) scaled by \u039b1/2, rotated by U and translated by \u03bc.\nConversely, any choice of \u03bc, full rank matrix U, and positive diagonal entries \u039b\"i\" yields a non-singular multivariate normal distribution. If any \u039b\"i\" is zero and U is square, the resulting covariance matrix U\u039bUT is singular. Geometrically this means that every contour ellipsoid is infinitely thin and has zero volume in \"n\"-dimensional space, as at least one of the principal axes has length of zero; this is the degenerate case.\n\"The radius around the true mean in a bivariate normal random variable, re-written in polar coordinates (radius and angle), follows a Hoyt distribution.\"\nIn one dimension the probability of finding a sample of the normal distribution in the interval formula_211 is approximately 68.27%, but in higher dimensions the probability of finding a sample in the region of the standard deviation ellipse is lower.\nStatistical inference.\nParameter estimation.\nThe derivation of the maximum-likelihood estimator of the covariance matrix of a multivariate normal distribution is straightforward.\nIn short, the probability density function (pdf) of a multivariate normal is\nformula_212\nand the ML estimator of the covariance matrix from a sample of \"n\" observations is \nformula_213\nwhich is simply the sample covariance matrix. This is a biased estimator whose expectation is\nformula_214\nAn unbiased sample covariance is\nformula_215 (matrix form; formula_216 is the formula_217 identity matrix, J is a formula_218 matrix of ones; the term in parentheses is thus the formula_218 centering matrix)\nThe Fisher information matrix for estimating the parameters of a multivariate normal distribution has a closed form expression. This can be used, for example, to compute the Cram\u00e9r\u2013Rao bound for parameter estimation in this setting. See Fisher information for more details.\nBayesian inference.\nIn Bayesian statistics, the conjugate prior of the mean vector is another multivariate normal distribution, and the conjugate prior of the covariance matrix is an inverse-Wishart distribution formula_220 . Suppose then that \"n\" observations have been made\nformula_221\nand that a conjugate prior has been assigned, where\nformula_222\nwhere\nformula_223\nand\nformula_224\nThen\nformula_225\nwhere\nformula_226\nMultivariate normality tests.\nMultivariate normality tests check a given set of data for similarity to the multivariate normal distribution. The null hypothesis is that the data set is similar to the normal distribution, therefore a sufficiently small \"p\"-value indicates non-normal data. Multivariate normality tests include the Cox\u2013Small test\nand Smith and Jain's adaptation of the Friedman\u2013Rafsky test created by Larry Rafsky and Jerome Friedman.\nMardia's test.\nMardia's test is based on multivariate extensions of skewness and kurtosis measures. For a sample {x1, ..., x\"n\"} of \"k\"-dimensional vectors we compute\n formula_227\nUnder the null hypothesis of multivariate normality, the statistic \"A\" will have approximately a chi-squared distribution with \u22c5\"k\"(\"k\" + 1)(\"k\" + 2) degrees of freedom, and \"B\" will be approximately standard normal \"N\"(0,1).\nMardia's kurtosis statistic is skewed and converges very slowly to the limiting normal distribution. For medium size samples formula_228, the parameters of the asymptotic distribution of the kurtosis statistic are modified For small sample tests (formula_229) empirical critical values are used. Tables of critical values for both statistics are given by Rencher for \"k\"\u00a0=\u00a02,\u00a03,\u00a04.\nMardia's tests are affine invariant but not consistent. For example, the multivariate skewness test is not consistent against\nsymmetric non-normal alternatives.\nBHEP test.\nThe BHEP test computes the norm of the difference between the empirical characteristic function and the theoretical characteristic function of the normal distribution. Calculation of the norm is performed in the L2(\"\u03bc\") space of square-integrable functions with respect to the Gaussian weighting function formula_230. The test statistic is\n formula_231\nThe limiting distribution of this test statistic is a weighted sum of chi-squared random variables.\nA detailed survey of these and other test procedures is available.\nComputational methods.\nDrawing values from the distribution.\nA widely used method for drawing (sampling) a random vector x from the \"N\"-dimensional multivariate normal distribution with mean vector \u03bc and covariance matrix \u03a3 works as follows:\n \u03a3. When \u03a3 is positive-definite, the Cholesky decomposition is typically used because it is widely available, computationally efficient, and well known. If a rank-revealing (pivoted) Cholesky decomposition such as LAPACK's dpstrf() is available, it can be used in the general positive-semidefinite case as well. A slower general alternative is to use the matrix A = U\u039b1/2 obtained from a spectral decomposition \u03a3 = U\u039bU\u22121 of \u03a3.\n (\"z\"1, ..., \"zN\")T be a vector whose components are \"N\" independent standard normal variates (which can be generated, for example, by using the Box\u2013Muller transform).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nLiterature.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50350", "revid": "49765849", "url": "https://en.wikipedia.org/wiki?curid=50350", "title": "Ella Fitzgerald", "text": "American jazz singer (1917\u20131996)\nElla Jane Fitzgerald (April25, 1917\u00a0\u2013 June15, 1996) was an American singer, songwriter and composer, sometimes referred to as the \"First Lady of Song\", \"Queen of Jazz\", and \"Lady Ella\". She was noted for her purity of tone, impeccable diction, phrasing, timing, intonation, absolute pitch, and a \"horn-like\" improvisational ability, particularly in her scat singing.\nAfter a tumultuous adolescence, Fitzgerald found stability in musical success with the Chick Webb Orchestra, performing across the country but most often associated with the Savoy Ballroom in Harlem. Her rendition of the nursery rhyme \"A-Tisket, A-Tasket\" helped boost both her and Webb to national fame. After taking over the band when Webb died, Fitzgerald left it behind in 1942 to start her solo career. Her manager was Moe Gale, co-founder of the Savoy, until she turned the rest of her career over to Norman Granz, who founded Verve Records to produce new records by Fitzgerald. With Verve, she recorded some of her more widely noted works, particularly her interpretations of the Great American Songbook.\nFitzgerald also appeared in films and as a guest on popular television shows in the second half of the twentieth century. Outside her solo career, she created music with Louis Armstrong, Duke Ellington, and The Ink Spots. These partnerships produced songs such as \"Dream a Little Dream of Me\", \"Cheek to Cheek\", \"Into Each Life Some Rain Must Fall\", and \"It Don't Mean a Thing (If It Ain't Got That Swing)\". In 1993, after a career of nearly sixty years, she gave her last public performance. Three years later, she died at age 79 after years of declining health. Her accolades included 14 Grammy Awards, the National Medal of Arts, the NAACP's inaugural President's Award, and the Presidential Medal of Freedom.\nEarly life and family.\nElla Jane Fitzgerald was born on April 25, 1917, in Newport News, Virginia. She was the daughter of William Ashland Fitzgerald, a transfer wagon driver from Blackstone, Virginia, and Temperance Fitzgerald, both described as mulatto in the 1920 census. Her parents were unmarried but lived together in the East End section of Newport News for at least two and a half years after she was born. In the early 1920s, Fitzgerald's mother and her new partner, a Portuguese immigrant named Joseph da Silva, moved to Yonkers, New York. Her half-sister, Frances da Silva, was born in 1923. By 1925, Fitzgerald and her family had moved to nearby School Street, a poor Italian area. She began her formal education at the age of six and was an outstanding student, moving through a variety of schools before attending Benjamin Franklin Junior High School in 1929.\nShe and her family were Methodists and were active in the Bethany African Methodist Episcopal Church, where she attended worship services, Bible study, and Sunday school. The church provided Fitzgerald with her earliest experiences in music. Starting in third grade, Fitzgerald loved dancing and admired Earl Snakehips Tucker. She performed for her peers on the way to school and at lunchtime.\nFitzgerald listened to jazz recordings by Louis Armstrong, Bing Crosby, and The Boswell Sisters. She loved the Boswell Sisters' lead singer Connee Boswell, later saying: \"My mother brought home one of her records, and I fell in love with it...I tried so hard to sound just like her.\"\nIn 1932, when Fitzgerald was 15 years old, her mother died from injuries sustained in a car accident. Fitzgerald's stepfather took care of her until April 1933 when she moved to Harlem to live with her aunt. This seemingly swift change in her circumstances, reinforced by what Fitzgerald biographer Stuart Nicholson describes as rumors of \"ill treatment\" by her stepfather, leaves him to speculate that Da Silva might have abused her.\nFitzgerald began skipping school, and her grades suffered. She worked as a lookout at a bordello and with a Mafia-affiliated numbers runner. She never talked publicly about this time in her life. When the authorities caught up with her, she was placed in the Colored Orphan Asylum in Riverdale in The Bronx. When the orphanage proved too crowded, she was moved to the New York Training School for Girls, a state reformatory school in Hudson, New York.\nCareer.\nEarly career.\nWhile she seems to have survived during 1933 and 1934 in part by singing on the streets of Harlem, Fitzgerald debuted at the age of 17 on November 21, 1934, in one of the earliest Amateur Nights at the Apollo Theater. She had intended to go on stage and dance, but she was intimidated by a local dance duo called the Edwards Sisters and opted to sing instead. Performing in the style of Connee Boswell, she sang \"Judy\" and \"The Object of My Affection\" and won first prize. She won the chance to perform at the Apollo for a week but, seemingly because of her disheveled appearance, the theater never gave her that part of her prize.\nIn January 1935, Fitzgerald won the chance to perform for a week with the Tiny Bradshaw band at the Harlem Opera House. Later that year, she was introduced to drummer and bandleader Chick Webb by Bardu Ali. Although \"reluctant to sign her...because she was gawky and unkempt, a 'diamond in the rough,'\" after some convincing by Ali, Webb offered her the opportunity to test with his band at a dance at Yale University.\nMet with approval by both audiences and her fellow musicians, Fitzgerald was asked to join Webb's orchestra and gained acclaim as part of the group's performances at Harlem's Savoy Ballroom. Fitzgerald recorded several hit songs, including \"Love and Kisses\" and \"(If You Can't Sing It) You'll Have to Swing It (Mr. Paganini)\". But it was her 1938 version of the nursery rhyme, \"A-Tisket, A-Tasket\", a song she co-wrote, that brought her public acclaim. \"A-Tisket, A-Tasket\" became a major hit on the radio and was also one of the biggest-selling records of the decade.\nWebb died of spinal tuberculosis on June 16, 1939, and his band was renamed Ella Fitzgerald and Her Famous Orchestra, with Fitzgerald taking on the role of bandleader. Ella and the band recorded for Decca and appeared at the Roseland Ballroom, where they received national exposure on NBC radio broadcasts.\nShe recorded nearly 150 songs with Webb's orchestra between 1935 and 1942. In addition to her work with Webb, Fitzgerald performed and recorded with the Benny Goodman Orchestra. She had her own side project, too, known as Ella Fitzgerald and Her Savoy Eight.\nDecca years.\nIn 1942, with increasing dissent and money concerns in Fitzgerald's band, Ella Fitzgerald and Her Famous Orchestra, she started to work as lead singer with The Three Keys, and in July her band played their last concert at Earl Theatre in Philadelphia. While working for Decca Records, she had hits with Bill Kenny &amp; the Ink Spots, Louis Jordan, and the Delta Rhythm Boys. Producer Norman Granz became her manager in the mid-1940s after she began singing for Jazz at the Philharmonic, a concert series begun by Granz.\nWith the demise of the swing era and the decline of the great touring big bands, a major change in jazz music occurred. The advent of bebop led to new developments in Fitzgerald's vocal style, influenced by her work with Dizzy Gillespie's big band. It was in this period that Fitzgerald started including scat singing as a major part of her performance repertoire. While singing with Gillespie, Fitzgerald recalled: \"I just tried to do [with my voice] what I heard the horns in the band doing.\"\nHer 1945 scat recording of \"Flying Home\" arranged by Vic Schoen would later be described by \"The New York Times\" as \"one of the most influential vocal jazz records of the decade...Where other singers, most notably Louis Armstrong, had tried similar improvisation, no one before Miss Fitzgerald employed the technique with such dazzling inventiveness.\" Her bebop recording of \"Oh, Lady Be Good!\" (1947) was similarly popular and increased her reputation as one of the leading jazz vocalists.\nVerve years.\nFitzgerald made her first tour of Australia in July 1954 for the Australian-based American promoter Lee Gordon. This was the first of Gordon's famous \"Big Show\" promotions and the \"package\" tour also included Buddy Rich, Artie Shaw and comedian Jerry Colonna.\nAlthough the tour was a big hit with audiences and set a new box office record for Australia, it was marred by an incident of racial discrimination that caused Fitzgerald to miss the first two concerts in Sydney, and Gordon had to arrange two later free concerts to compensate ticket holders. Although the four members of Fitzgerald's entourage \u2013 Fitzgerald, her pianist John Lewis, her assistant (and cousin) Georgiana Henry, and manager Norman Granz \u2013 all had first-class tickets on their scheduled Pan-American Airlines flight from Honolulu to Australia, they were ordered to leave the aircraft after they had already boarded and were refused permission to re-board the aircraft to retrieve their luggage and clothing. As a result, they were stranded in Honolulu for three days before they could get another flight to Sydney. Although a contemporary Australian press report quoted an Australian Pan-Am spokesperson who denied that the incident was racially based, Fitzgerald, Henry, Lewis and Granz filed a civil suit for racial discrimination against Pan-Am in December 1954, which they won on appeal in January 1956. In a 1970 television interview Fitzgerald said they received what she described as a \"nice settlement\".\nFitzgerald was still performing at Granz's Jazz at the Philharmonic (JATP) concerts by 1955. She left Decca, and Granz, now her manager, created Verve Records around her. She later described the period as strategically crucial, saying: \"I had gotten to the point where I was only singing be-bop. I thought be-bop was 'it', and that all I had to do was go some place and sing bop. But it finally got to the point where I had no place to sing. I realized then that there was more to music than bop. Norman ... felt that I should do other things, so he produced \"Ella Fitzgerald Sings the Cole Porter Song Book\" with me. It was a turning point in my life.\"\nOn March 15, 1955, Ella Fitzgerald opened her initial engagement at the Mocambo nightclub in Hollywood, after Marilyn Monroe lobbied the owner for the booking. The booking was instrumental in Fitzgerald's career. Bonnie Greer dramatized the incident as the musical drama, \"Marilyn and Ella\", in 2008. It had previously been widely reported that Fitzgerald was the first black performer to play the Mocambo, following Monroe's intervention, but this is not true. African-American singers Herb Jeffries, Eartha Kitt, and Joyce Bryant all played the Mocambo in 1952 and 1953, according to stories published at the time in \"Jet\" magazine and \"Billboard\".\n\"Ella Fitzgerald Sings the Cole Porter Song Book\", released in 1956, was the first of eight \"Song Book\" sets Fitzgerald would record for Verve at irregular intervals from 1956 to 1964. The composers and lyricists spotlighted on each set, taken together, represent the greatest part of the cultural canon known as the \"Great American Songbook\". Her song selections ranged from standards to rarities and represented an attempt by Fitzgerald to cross over into a non-jazz audience. The sets are the most well-known items in her discography and by 1956 Fitzgerald's recordings were showcased nationally by Ben Selvin within the RCA Thesaurus transcription library. \n\"Ella Fitzgerald Sings the Duke Ellington Song Book\" was the only Song Book on which the composer she interpreted played with her. Duke Ellington and his longtime collaborator Billy Strayhorn both appeared on exactly half the set's 38 tracks and wrote two new pieces of music for the album: \"The E and D Blues\" and a four-movement musical portrait of Fitzgerald. The Song Book series ended up becoming Fitzgerald's most critically acclaimed and commercially successful work, and probably her most significant offering to American culture. \"The New York Times\" wrote in 1996: \"These albums were among the first pop records to devote such serious attention to individual songwriters, and they were instrumental in establishing the pop album as a vehicle for serious musical exploration.\"\nDays after Fitzgerald's death, \"The New York Times\" columnist Frank Rich wrote that in the Song Book series Fitzgerald \"performed a cultural transaction as extraordinary as Elvis' contemporaneous integration of white and African-American soul. Here was a black woman popularizing urban songs often written by immigrant Jews to a national audience of predominantly white Christians.\" Frank Sinatra, out of respect for Fitzgerald, prohibited Capitol Records from re-releasing his own recordings in separate albums for individual composers in the same way.\nFitzgerald also recorded albums exclusively devoted to the songs of Porter and Gershwin in 1972 and 1983; the albums being, respectively, \"Ella Loves Cole\" and \"Nice Work If You Can Get It\". A later collection devoted to a single composer was released during her time with Pablo Records, \"Ella Abra\u00e7a Jobim\", featuring the songs of Ant\u00f4nio Carlos Jobim.\nWhile recording the Song Books and the occasional studio album, Fitzgerald toured 40 to 45 weeks per year in the United States and internationally, under the tutelage of Norman Granz. Granz helped solidify her position as one of the leading live jazz performers. In 1961, Fitzgerald bought a house in the Klampenborg district of Copenhagen, Denmark, after she began a relationship with a Danish man. Though the relationship ended after a year, Fitzgerald regularly returned to Denmark over the next three years and even considered buying a jazz club there. The house was sold in 1963, and Fitzgerald permanently returned to the United States.\nThere are several live albums on Verve that are highly regarded by critics. \"At the Opera House\" shows a typical Jazz at the Philharmonic set from Fitzgerald. ' and \"Twelve Nights in Hollywood\" display her vocal jazz canon. ' is still one of her best-selling albums; it includes a Grammy-winning performance of \"Mack the Knife\" in which she forgets the lyrics but improvises to compensate.\nVerve Records was sold to MGM in 1960 for $3 million and in 1967 MGM failed to renew Fitzgerald's contract. Over the next five years, she flitted between Atlantic, Capitol and Reprise. Her material at this time represented a departure from her typical jazz repertoire. For Capitol she recorded \"Brighten the Corner\", an album of hymns, \"Ella Fitzgerald's Christmas\", an album of traditional Christmas carols, \"Misty Blue\", a country and western-influenced album, and \"30 by Ella\", a series of six medleys that fulfilled her obligations for the label. During this period, she had her last US chart single with a cover of Smokey Robinson's \"Get Ready\", previously a hit for the Temptations, and some months later a top-five hit for Rare Earth.\nThe surprise success of the 1972 album \"Jazz at Santa Monica Civic '72\" led Granz to found Pablo Records, his first record label since the sale of Verve. Fitzgerald recorded some 20 albums for the label. \"Ella in London\" recorded live in 1974 with pianist Tommy Flanagan, guitarist Joe Pass, bassist Keter Betts and drummer Bobby Durham, was considered by many to be some of her best work. The following year she again performed with Joe Pass on German television station NDR in Hamburg. Her years with Pablo Records also documented the decline in her voice. \"She frequently used shorter, stabbing phrases, and her voice was harder, with a wider vibrato\", one biographer wrote. Plagued by health problems, Fitzgerald made her last recording in 1991 and her last public performances in 1993.\nFilm and television.\nFitzgerald played the part of singer Maggie Jackson in Jack Webb's 1955 jazz film \"Pete Kelly's Blues\". The film costarred Janet Leigh and singer Peggy Lee. Even though she had already worked in the movies (she sang two songs in the 1942 Abbott and Costello film \"Ride 'Em Cowboy\"), she was \"delighted\" when Norman Granz negotiated the role for her, and, \"at the time ... considered her role in the Warner Brothers movie the biggest thing ever to have happened to her.\" Amid \"The New York Times\" pan of the film when it opened in August 1955, the reviewer wrote, \"About five minutes (out of ninety-five) suggest the picture this might have been. Take the ingenious prologue ... [or] take the fleeting scenes when the wonderful Ella Fitzgerald, allotted a few spoken lines, fills the screen and sound track with her strong mobile features and voice.\"\nAfter \"Pete Kelly's Blues\", she appeared in sporadic movie cameos, in \"St. Louis Blues\" (1958) and \"Let No Man Write My Epitaph\" (1960).\nShe made numerous guest appearances on television shows, singing on \"The Frank Sinatra Show\", \"The Carol Burnett Show\", \"The Andy Williams Show\", \"The Pat Boone Chevy Showroom\u200a\", and alongside other greats Nat King Cole, Dean Martin, Mel Torm\u00e9, and many others. She was also frequently featured on \"The Ed Sullivan Show\". Perhaps her most unusual and intriguing performance was of the \"Three Little Maids\" song from Gilbert and Sullivan's comic operetta \"The Mikado\" alongside Joan Sutherland and Dinah Shore on Shore's weekly variety series in 1963. A performance at Ronnie Scott's Jazz Club in London was filmed and shown on the BBC. Fitzgerald also made a one-off appearance alongside Sarah Vaughan and Pearl Bailey on a 1979 television special honoring Bailey. In 1980, she performed a medley of standards in a duet with Karen Carpenter on the Carpenters' television special .\nFitzgerald also appeared in TV commercials, including an ad for Memorex. In the commercials, she sang a note that shattered a glass while being recorded on a Memorex cassette tape. The tape was played back and the recording also broke another glass, asking: \"Is it live, or is it Memorex?\" She also appeared in a number of commercials for Kentucky Fried Chicken, singing and scatting to the fast-food chain's longtime slogan: \"We do chicken right!\" Her last commercial campaign was for American Express, in which she was photographed by Annie Leibovitz.\n\"Ella Fitzgerald Just One of Those Things\" is a film about her life including interviews with many famous singers and musicians who worked with her and her son. It was directed by Leslie Woodhead and produced by Reggie Nadelson. It was released in the UK in 2019.\nCollaborations.\nFitzgerald's most famous collaborations were with the vocal quartet Bill Kenny &amp; the Ink Spots, trumpeter Louis Armstrong, the guitarist Joe Pass, and the bandleaders Count Basie and Duke Ellington.\nFitzgerald had a number of famous jazz musicians and soloists as sidemen over her long career. The trumpeters Roy Eldridge and Dizzy Gillespie, the guitarist Herb Ellis, and the pianists Tommy Flanagan, Oscar Peterson, Lou Levy, Paul Smith, Jimmy Rowles, and Ellis Larkins all worked with Fitzgerald mostly in live, small group settings.\nPersonal life.\nFitzgerald married at least twice, and there is evidence that suggests that she may have married a third time. Her first marriage was in 1941, to Benny Kornegay, a convicted drug dealer and local dockworker. The marriage was annulled in 1942. Her second marriage was in December 1947, to the famous bass player Ray Brown, whom she had met while on tour with Dizzy Gillespie's band a year earlier. Together they adopted a child born to Fitzgerald's half-sister, Frances, whom they christened Ray Brown Jr. With Fitzgerald and Brown often busy touring and recording, the child was largely raised by his mother's aunt, Virginia. Fitzgerald and Brown divorced in 1953, due to the various career pressures both were experiencing at the time, though they would continue to perform together.\nIn July 1957, Reuters reported that Fitzgerald had secretly married Thor Einar Larsen, a young Norwegian, in Oslo. She had even gone as far as furnishing an apartment in Oslo, but the affair was quickly forgotten when Larsen was sentenced to five months' hard labor in Sweden for stealing money from a young woman to whom he had previously been engaged.\nFitzgerald was notoriously shy. Trumpet player Mario Bauz\u00e1, who played behind Fitzgerald in her early years with Chick Webb, remembered that \"she didn't hang out much. When she got into the band, she was dedicated to her music...She was a lonely girl around New York, just kept herself to herself, for the gig.\" When, later in her career, the Society of Singers named an award after her, Fitzgerald explained, \"I don't want to say the wrong thing, which I always do but I think I do better when I sing.\"\nFrom 1949 to 1956, Fitzgerald resided in the St. Albans neighborhood of Queens, New York, an enclave of prosperous African Americans where she counted among her neighbors Illinois Jacquet, Count Basie, Lena Horne, and other jazz luminaries.\nFitzgerald was a civil rights activist. She was awarded the National Association for the Advancement of Colored People Equal Justice Award and the American Black Achievement Award. In 1949, Norman Granz recruited Fitzgerald for the Jazz at the Philharmonic tour. The Jazz at the Philharmonic tour would specifically target segregated venues. Granz required promoters to ensure that there was no \"colored\" or \"white\" seating. He ensured Fitzgerald was to receive equal pay and accommodations regardless of her sex and race. If the conditions were not met shows were cancelled.\nBill Reed, author of \"Hot from Harlem: Twelve African American Entertainers\", referred to Fitzgerald as the \"Civil Rights Crusader\", facing discrimination throughout her career. In 1954 on her way to one of her concerts in Australia she was unable to board the Pan American flight because of racial discrimination. Although she faced several obstacles and racial barriers, she was recognized as a \"cultural ambassador\", receiving the National Medal of Arts in 1987 and America's highest non-military honor, the Presidential Medal of Freedom.\nIn 1993, Fitzgerald established the Ella Fitzgerald Charitable Foundation focusing on charitable grants for four major categories: academic opportunities for children, music education, basic care needs for the less fortunate, medical research revolving around diabetes, heart disease, and vision impairment. Her goals were to give back and provide opportunities for those \"at risk\" and less fortunate. In addition, she supported several nonprofit organizations like the American Heart Association, City of Hope, and the Retina Foundation.\nIllness and death.\nFitzgerald had diabetes for several years of her later life, which led to numerous complications. She was hospitalized in 1985 briefly for respiratory problems, in 1986 for congestive heart failure, and in 1990 for exhaustion. In March 1990, she appeared at the Royal Albert Hall in London, England, with the Count Basie Orchestra for the launch of Jazz FM, plus a gala dinner at the Grosvenor House Hotel at which she performed. In 1993, both her legs were amputated below the knee due to the effects of diabetes, a condition which also damaged her eyesight.\nFitzgerald died in her home from a stroke on June 15, 1996, at the age of 79. A few hours after her death, the Playboy Jazz Festival was launched at the Hollywood Bowl. In tribute, the marquee read: \"Ella We Will Miss You.\" Her funeral was private, and she was buried at Inglewood Park Cemetery in Inglewood, California.\nDiscography and collections.\nThe primary collections of Fitzgerald's media and memorabilia reside at and are shared between the Smithsonian Institution and the US Library of Congress.\nAwards, citations and honors.\nFitzgerald won 13 Grammy Awards, and received the Grammy Lifetime Achievement Award in 1967.\nIn 1958 Fitzgerald became the first African-American woman to win at the inaugural show.\nOther major awards and honors she received during her career were the Kennedy Center for the Performing Arts Medal of Honor Award, National Medal of Art, first Society of Singers Lifetime Achievement Award (named \"Ella\" in her honor), Presidential Medal of Freedom, and the George and Ira Gershwin Award for Lifetime Musical Achievement, UCLA Spring Sing, and the UCLA Medal (1987). Across town at the University of Southern California, she received the USC \"Magnum Opus\" Award, which hangs in the office of the Ella Fitzgerald Charitable Foundation. In 1986, she received an honorary doctorate of music from Yale University. In 1990, she received an honorary doctorate of Music from Harvard University.\nTributes and legacy.\nThe career history and archival material from Fitzgerald's long career are housed in the Archives Center at the Smithsonian's National Museum of American History, while her personal music arrangements are at the Library of Congress. Her extensive cookbook collection was donated to the Schlesinger Library at Harvard University, and her extensive collection of published sheet music was donated to UCLA. Harvard gave her an honorary degree in music in 1990.\nIn 1997, Newport News, Virginia, created a week-long music festival with Christopher Newport University to honor Fitzgerald in her birth city.\nAnn Hampton Callaway, Dee Dee Bridgewater, and Patti Austin have all recorded albums in tribute to Fitzgerald. Callaway's album \"To Ella with Love\" (1996) features 14 jazz standards made popular by Fitzgerald, and the album also features the trumpeter Wynton Marsalis. Bridgewater's album \"Dear Ella\" (1997) featured many musicians that were closely associated with Fitzgerald during her career, including the pianist Lou Levy, the trumpeter Benny Powell, and Fitzgerald's second husband, double bassist Ray Brown. Bridgewater's following album, \"Live at Yoshi's\", was recorded live on April 25, 1998, what would have been Fitzgerald's 81st birthday.\nAustin's album, \"For Ella\" (2002) features 11 songs most immediately associated with Fitzgerald, and a twelfth song, \"Hearing Ella Sing\" is Austin's tribute to Fitzgerald. The album was nominated for a Grammy. In 2007, \"\", was released, a tribute album recorded for Fitzgerald's 90th birthday. It featured artists such as Michael Bubl\u00e9, Natalie Cole, Chaka Khan, Gladys Knight, Diana Krall, k.d. lang, Queen Latifah, Ledisi, Dianne Reeves, Linda Ronstadt, and Lizz Wright, collating songs most readily associated with the \"First Lady of Song\". Folk singer Odetta's album \"To Ella\" (1998) is dedicated to Fitzgerald, but features no songs associated with her. Her accompanist Tommy Flanagan affectionately remembered Fitzgerald on his album \"Lady be Good ... For Ella\" (1994).\n\"Ella, elle l'a\", a tribute to Fitzgerald written by Michel Berger and performed by French singer France Gall, was a hit in Europe in 1987 and 1988. Fitzgerald is also referred to in the 1976 Stevie Wonder hit \"Sir Duke\" from his album \"Songs in the Key of Life\", and the song \"I Love Being Here With You\", written by Peggy Lee and Bill Schluger. Sinatra's 1986 recording of \"Mack the Knife\" from his album \"L.A. Is My Lady\" (1984) includes a homage to some of the song's previous performers, including 'Lady Ella' herself. She is also honored in the song \"First Lady\" by Canadian artist Nikki Yanofsky.\nIn 2008, the Downing-Gross Cultural Arts Center in Newport News named its new 276-seat theater the Ella Fitzgerald Theater. The theater is located several blocks away from her birthplace on Marshall Avenue. The Grand Opening performers (October 11 and 12, 2008) were Roberta Flack and Queen Esther Marrow.\nIn 2012, Rod Stewart performed a \"virtual duet\" with Ella Fitzgerald on his Christmas album \"Merry Christmas, Baby\", and his television special of the same name.\nThere is a bronze sculpture of Fitzgerald in Yonkers, the city in which she grew up, created by American artist Vinnie Bagwell. It is located southeast of the main entrance to the Amtrak/Metro-North Railroad station in front of the city's old trolley barn. The statue's location is one of 14 tour stops on the African American Heritage Trail of Westchester County. A bust of Fitzgerald is on the campus of Chapman University in Orange, California. Ed Dwight created a series of more thann 70 bronze sculptures at the St. Louis Arch Museum at the request of the National Park Service; the series, \"Jazz: An American Art Form\", depicts the evolution of jazz and features various jazz performers, including Fitzgerald.\nOn January 9, 2007, the United States Postal Service announced that Fitzgerald would be honored with her own postage stamp. The stamp was released in April 2007 as part of the Postal Service's Black Heritage series.\nIn April 2013, she was featured in Google Doodle, depicting her performing onstage. It celebrated what would have been her 96th birthday.\nOn April 25, 2017, the centenary of her birth, the UK's BBC Radio 2 broadcast three programs as part of an \"Ella at 100\" celebration: \"Ella Fitzgerald Night\", introduced by Jamie Cullum; \"Remembering Ella\"; introduced by Leo Green; and \"Ella Fitzgerald \u2013 the First Lady of Song\", introduced by Petula Clark.\nIn 2019, \"Ella Fitzgerald: Just One of Those Things\", a documentary by Leslie Woodhead, was released in the UK. It featured rare footage, radio broadcasts and interviews with Jamie Cullum, Andre Previn, Johnny Mathis, and other musicians, plus a long interview with Fitzgerald's son, Ray Brown Jr.\nIn 2023, \"Rolling Stone\" ranked Fitzgerald at No. 45 on their list of the 200 Greatest Singers of All Time.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50351", "revid": "164773", "url": "https://en.wikipedia.org/wiki?curid=50351", "title": "Disk format", "text": ""}
{"id": "50352", "revid": "40958506", "url": "https://en.wikipedia.org/wiki?curid=50352", "title": "Lexington, Kentucky", "text": "City in Kentucky, United States\nLexington is a consolidated city coterminous with Fayette County, Kentucky, United States, of which it is also the county seat. As of the 2020 census the city's population was 322,570, making it the second-most populous city in Kentucky (after Louisville), the 14th-most populous city in the Southeast, and the 59th-most populous city in the United States. By area, it is the country's 33rd-largest city.\nLexington is known as the \"Horse Capital of the World\" due to the hundreds of horse farms in the region, as well as the Kentucky Horse Park, The Red Mile and Keeneland race courses. It is within the state's Bluegrass region. Notable locations within the city include venues Rupp Arena and Central Bank Center, colleges and universities such as the University of Kentucky, Transylvania University, and Bluegrass Community and Technical College, and the National Thoroughbred Racing Association (NTRA) Headquarters.\nThe city anchors the Lexington\u2013Fayette metropolitan area of 516,811 people and the greater Lexington\u2013Fayette\u2013Richmond\u2013Frankfort combined statistical area of 747,919 people. It has been consolidated entirely within Fayette County since 1974 and has a nonpartisan mayor-council form of government, with 12 council districts and three members elected at large, with the highest vote-getter designated vice mayor.\nHistory.\nLexington was named in June 1775, in what was then considered Fincastle County, Virginia, 17 years before Kentucky became a state. A party of frontiersmen, led by William McConnell, camped on the Middle Fork of Elkhorn Creek (now known as Town Branch and rerouted under Vine Street) at the site of the present-day McConnell Springs. Upon hearing of the colonists' victory in the Battles of Lexington and Concord on April 19, 1775, they named the site Lexington. It was the first of many American places to be named after the Massachusetts town.\nOn January 25, 1780, 45 original settlers signed the Lexington Compact, known also as the \"Articles of Agreement, made by the inhabitants of the town of Lexington, in the County of Kentucky.\" The settlement at Lexington at this time was also known as Fort Lexington, as it was surrounded by fortifications to protect from potential attacks from British-allied Indians. The Articles allocated land by granting \"In\" lots of 1/2 acre to each share, along with \"Out\" lots of 5 acres for each share. Presumably the \"In\" lots were for the family dwelling inside the fortifications, while the \"Out\" lots were to be \"cleared\" for farming. (Corn is the only crop specifically mentioned in the Articles.) It is known that several of these original settlers (perhaps many of them) served under General George Rogers Clark in the Illinois campaign (also called the Northwestern campaign) against the British in 1778\u201379. While the ostensible founder of Lexington, William McConnell, is not one of the signees, an Alexander McConnell is. Within two years of signing the Agreement, both John and Jacob Wymore were killed by Indians in separate incidents outside the walls of \"Fort Lexington\".\nIn December 1781, a huge caravan of around 600 pioneers from Spotsylvania County, Virginia\u2014dubbed \"The Travelling Church\"\u2014arrived in the Lexington area. Led by the preacher Lewis Craig and Captain William Ellis, the Travelling Church established numerous churches, including the South Elkhorn Christian Church in Lexington. On May 6, 1782, the town of Lexington was chartered by an act of the Virginia General Assembly. Around 1790, the First African Baptist Church was founded in Lexington by Peter Durrett, a Baptist preacher and slave held by Joseph Craig. Durrett had helped guide \"The Travelling Church\" on its trek to Kentucky. This church is the oldest black Baptist congregation in Kentucky and the third-oldest in the United States.\nIn the early 1800s, Lexington was a rising city of the vast territory to the west of the Appalachian Mountains; Josiah Espy described it in a published version of his notes as he toured Ohio and Kentucky:{\nIn the early 19th century, Lexington planter John Wesley Hunt became the first millionaire west of the Alleghenies. Henry Clay, a lawyer who married into one of the wealthiest families of Kentucky and served as Speaker of the United States House of Representatives in 1812, helped to lead the War Hawks, pushing for war with Britain to bolster the markets of American products. Six companies of volunteers came from Lexington, with a rope-walk on James Erwin's farm on the Richmond Road used as a recruiting office and barracks until the war ended. Several Lexingtonians served with prominence as officers in the war. For example, Captain Nathaniel G.S. Hart commanded the Lexington Light Infantry (also known as the \"Silk Stocking Boys\") and was killed while a captive after the Battle of the River Raisin. Henry Clay also served as a negotiator at the Treaty of Ghent in 1814.\nThe growing town was devastated by a cholera epidemic in 1833, which had spread throughout the waterways of the Mississippi and Ohio valleys: 500 of 7,000 Lexington residents died within two months, including nearly one-third of the congregation of Christ Church Episcopal. London Ferrill, second preacher of First African Baptist, was one of three clergy who stayed in the city to serve the suffering victims.\nFarmers in the areas around Lexington held slaves for use as field hands, laborers, artisans, and domestic servants. In the city, slaves worked primarily as domestic servants and artisans, although they also worked with merchants, shippers, and in a wide variety of trades. Farms raised commodity crops of tobacco and hemp, and thoroughbred horse breeding and racing became established in this part of the state. By 1850, Lexington had the highest concentration of enslaved people in the entire state. The city also had a significant population of free blacks, who were often of mixed race. By 1850, First African Baptist Church, led by London Ferrill, a free black from Virginia, had a congregation of 1,820 persons. At that time, First African Baptist Church had the largest congregation of any church, black or white, in the state of Kentucky.\n20th century to present.\nCity school superintendent Massillon Alexander Cassidy (1886\u20131928) implemented Progressive Era reforms. He focused on upgrading the buildings and setting up teacher-training. He emphasized the need to improve literacy rates and expand access to public schooling. Cassidy's own philosophy stressed the use of science, business, and expertise. He also had a paternalistic attitude toward blacks, who were in segregated public schools.\nAmidst the tensions between black and white populations over the lack of affordable housing in the city, a race riot broke out on September 1, 1917. At the time, the Colored A. &amp; M. Fair (one of the largest African American fairs in the South) on Georgetown Pike had attracted more African Americans from the surrounding area into the city. Also during this time, some United States National Guard troops were camping on the edge of the city. Three troops passed in front of an African American restaurant and shoved some people on the sidewalk. A fight broke out, reinforcements for the troops and civilians both appeared, and soon a riot began. The Kentucky National Guard was summoned, and once the riot had ended, armed soldiers and police patrolled the streets. All other National Guard troops were barred from the city streets until the fair ended.\nOn February 9, 1920, tensions flared up again, this time over the trial of Will Lockett, a black man who murdered Geneva Hardman, a 10-year-old white girl. When a large mob gathered outside the courthouse where Lockett's trial was underway, Kentucky Governor Edwin P. Morrow massed the National Guard troops into the streets to work alongside local law enforcement. As the mob advanced on the courthouse, the National Guard opened fire, killing six and wounding 50 others. Fearing further retaliation from the mob, Morrow urged the United States Army to provide assistance. Led by Brigadier General Francis C. Marshall, approximately 1,200 federal troops from nearby Camp Zachary Taylor moved into the city the same day to assist National Guard forces and local police in bringing order and peace. Marshall declared martial law in the city and had soldiers positioned throughout the area for two weeks. Lockett was eventually executed on March 11 at the Kentucky State Penitentiary in Eddyville, after being found guilty of murdering Hardman.\nIn 1935, during the Great Depression, the Addiction Research Center (ARC) was created as a small research unit at the United States Public Health Service hospital in Lexington. Founded as one of the first drug rehabilitation clinics in the nation, the ARC was affiliated with a federal prison. Expanded as the first alcohol and drug rehabilitation hospital in the United States, it was known as \"Narco\" of Lexington. The hospital was later converted to operate as part of the federal prison system; it is known as the Federal Medical Center, Lexington and serves a variety of health needs for prisoners. Lexington also served as the headquarters for a pack horse library in the late 1930s and early 1940s.\nGeography.\nThe Lexington-Fayette metro area includes five additional counties: Clark, Jessamine, Bourbon, Woodford, and Scott. This is the second-largest metro area in Kentucky after Louisville. According to the United States Census Bureau, the city has a total area of , of which is land and , or 0.35%, is covered by water.\nCityscape.\nLexington features a diverse cityscape.\nPlanning.\nLexington has had to manage a rapidly growing population while working to maintain the character of the surrounding horse farms that give the region its identity. In 1958, Lexington enacted the nation's first urban growth boundary, restricting new development to an urban service area (USA). It set a minimum area requirement of to maintain open space for landholdings in the rural service area.\nIn 1980, the comprehensive plan was updated: the USA was modified to include urban activity centers (UACs) and rural activity centers (RACs). The UACs were commercial and light-industrial districts in urbanized areas, while RACs were retail trade and light-industrial centers clustered around the Interstate 64/Interstate 75 interchanges. In 1996, the USA was expanded when of the RSA were acquired through the expansion area master plan (EAMP). This was controversial: this first major update to the comprehensive plan in over a decade was accompanied by arguments among residents about the future of Lexington and the Thoroughbred farms.\nThe EAMP included new concepts of impact fees, assessment districts, neighborhood design concepts, design overlays, mandatory greenways, major roadway improvements, storm water management, and open-space mitigation for the first time. It also included a draft of the rural land management plan, which included large-lot zoning and traffic-impact controls. A pre-zoning of the entire expansion area was refuted in the plan. A minimum proposal was defeated. Discussion of this proposal appeared to stimulate the development of numerous subdivisions in the RSAs.\nThree years after the expansion was initiated, the RSA land management plan was adopted, which increased the minimum lot size in the agricultural rural zones to . In 2000, a purchase of development rights plan was adopted, granting the city the power to purchase the development rights of existing farms; in 2001, $40\u00a0million was allocated to the plan from a $25\u00a0million local, $15\u00a0million state grant.\nClimate.\nLexington is in the northern periphery of the humid subtropical climate zone (K\u00f6ppen: \"Cfa\"), with hot, humid summers and moderately cold winters with occasional mild periods; it falls in USDA hardiness zone 6b. The city and the surrounding Bluegrass region have four distinct seasons that include cool plateau breezes; moderate nights in the summer; and no prolonged periods of heat, cold, rain, wind, or snow. The monthly daily average temperature ranges from in January to in July, while the annual mean temperature is . On average, 25\u00a0days at or above occur annually and 23\u00a0days per winter where the high is at or below freezing. Annual precipitation is , with the late spring and summer being slightly wetter; snowfall averages per season. Extreme temperatures range from on January 24, 1963, to on July 10 and 15, 1936.\nLexington is recognized as a high allergy area by the Asthma and Allergy Foundation of America.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nThe Lexington-Fayette Metropolitan Statistical Area (MSA) includes Bourbon, Clark, Fayette, Jessamine, Scott, and Woodford Counties. The MSA population is 516,811 as of the 2020 census.\nThe Lexington\u2013Fayette\u2013Richmond\u2013Frankfort combined statistical area had a population of 747,919 in 2020. This includes the metro area and an additional seven counties.\n2020.\nAs of the 2020 census, there were 322,570 people, 129,784 households, and 74,761 families within the city. The population density was . The racial makeup of the city was 70.7% non-Hispanic White, 15.6% Black or African American, 0.3% Native American, 4.1% Asian, 0.1% Pacific Islander, and 2.7% from two or more races. Hispanic or Latino residents of any race were 7.4% of the population.\nThe most common spoken language in Lexington is English with the Southern American English dialect being the native and most common of the city and region, but there are approximately 196 languages from all parts of the world spoken in Lexington. The non-English language spoken by the largest group is Spanish followed by Swahili. Other more common non-English languages in the city are Arabic, Nepali, Japanese, French, Mandarin, Kinyarwanda, Korean and Portuguese. Local estimates drawn from English Language Learner enrollment in Fayette County Public Schools estimates that approximately 23% of the total Lexington population speaks a language other than English at home.\nOf the 131,929 households reported in the 2019 American Community Survey, 52% were married couples living together, 15% had a female householder with no husband present, and 27% were non-families. 28.4% of households were home to children under the age of 18. The average household size was 2.37, and the average family size was 2.99. 31.6% of all households were made up of individuals, and 9.4% had someone living alone who was 65 years of age or older.\nIn 2019, 20.9% of residents were under the age of 18, 14.2% were from 18 to 24, 28.6% from 25 to 44, 23.4% from 45 to 64, and 13.0% were 65 years of age or older. The median age was 34.6 years. For every 100 females, there were 96.2 males.\nThe median income for a household in the city was $57,291 in 2019, slightly below the national average of $62,843, and for a family it was $53,264. Males living alone had a median income of $36,268 versus $30,811 for females. The per capita income for the city was $34,442. About 8.7% of families and 14.6% of the population were below the poverty line, including 17.6% of those under the age of 18 and 9.4% of those ages 65 and older.\nThe table below illustrates the population growth of Fayette County since the first U.S. Census in 1790. Lexington city limits became coterminous with Fayette County in 1974.\nSources:\nEconomy.\nLexington has one of the nation's most stable economies. Lexington describes itself as having \"a fortified economy, strong in manufacturing, technology, and entrepreneurial support, benefiting from a diverse, balanced business base\". The Lexington Metro Area had an unemployment rate of 3.7% in August 2015, lower than many cities of similar size.\nThe city is home to several large corporations. Sizable employment is generated by four \"Fortune\" 500 companies: Xerox (which acquired Affiliated Computer Services), Lexmark International, Lockheed-Martin, and IBM, employing 3,000, 2,800, 1,705, and 552, respectively. United Parcel Service, Trane, and Amazon.com, Inc. have large operations in the city, and Toyota Motor Manufacturing Kentucky is within the Lexington CSA, located in adjoining Georgetown. A Jif peanut butter plant located in the city produces more peanut butter than any other factory in the world.\nNotable corporate headquarters include Lexmark International, a manufacturer of printers and enterprise software; Link-Belt Construction Equipment, a designer and manufacturer of telescopic and lattice boom crawler cranes; Big Ass Fans, a manufacturer of large ceiling fans and lighting fixtures for industrial, commercial, agricultural, and residential use; A&amp;W Restaurants, a restaurant chain known for root beer; and Fazoli's, an Italian-American fast-food chain.\nThe city's largest employer, the University of Kentucky, employed 16,743 as of 2020.\nOther sizable employers include the Lexington-Fayette County government and other hospital facilities. The Fayette County Public Schools employ 5,374, and the Lexington-Fayette Urban County Government employs 2,699. Central Baptist Hospital, Saint Joseph Hospital, Saint Joseph East, and the Veterans Administration Hospital employ 7,000 persons in total.\nArts and culture.\nAnnual cultural events and fairs.\nJune has two popular music festivals: Bluegrass and Broadway. The Festival of the Bluegrass, Kentucky's oldest bluegrass music festival, is in early June; it includes three stages for music and a \"bluegrass music camp\" for school children. For more than two decades, during the second and third weekends, UK Opera Theatre presents a Broadway medley \"It's A Grand Night for Singing!\"\nLater in June, the Gay and Lesbian Services Organization hosts the Lexington Pride Festival, which celebrates pride of the LGBTQIA+ community and welcomes allies. The festival offers live music, crafts, food, and informational booths from diverse service organizations. Lexington Mayor Jim Gray, elected in 2010 and openly gay, proclaimed June 29, 2013, as Pride Day. Lexington has one of the highest concentrations of gay and lesbian couples in the United States for a city its size.\nArea residents gather downtown for the Fourth of July festivities, which extend for several days. On July 3, the Gratz Park Historic District is transformed into an outdoor music hall, when the Patriotic Music Concert is held on the steps of Morrison Hall at Transylvania University. The Lexington Singers and the Lexington Philharmonic Orchestra perform at this event. On the Fourth, events include a reading of the Declaration of Independence on the steps of the Old Courthouse, a 10K run, a parade, street vendors for wares and food, and fireworks. The Woodland Arts Fair, an outdoor art fair hosted by the Lexington Art League in the summer, is almost five decades old and attracts over 70,000 attendees.\n\"Southern Lights: Spectacular Sights on Holiday Nights\", which takes place from November 18 to December 31, is held at the Kentucky Horse Park. It includes a drive through the park, showcasing numerous displays, many in character with the horse industry and history of Lexington. The \"Mini-Train Express\", an indoor petting zoo featuring exotic animals, the International Museum of the Horse, an exhibit showcasing the Bluegrass Railway Club's model train, and Santa Claus are other major highlights.\nOther events and fares include:\nHistorical structures and museums.\nAdditional historic sites include:\nThe University of Kentucky Art Museum is the premier art museum for Lexington and the only accredited museum in the region. Its collection of over 4,000 objects ranges from Old Masters to Contemporary. It regularly hosts special exhibitions.\nThe local Woolworth's building was listed on the National Register of Historic Places for its significance as a site of protests during the Civil Rights Movement against segregation during the 1960s. Activists conducted sit-ins to gain integrated lunch service, full access to facilities, and more employment. However, in 2004, the building was demolished by its owner, and the area was paved for use as a parking lot until further development.\nPablo Eskobear, the American black bear that overdosed on cocaine that was dropped from smuggler Andrew C. Thornton II's airplane\u2014an incident which inspired the 2023 movie \"Cocaine Bear\"\u2014has been stuffed and can be visited at the Kentucky for Kentucky Fun Mall.\nSports.\nCollege athletics.\nThe Kentucky Wildcats, the athletic program of the University of Kentucky, is Lexington's most popular sports entity. The school fields 22 varsity sports teams, most of which compete in the Southeastern Conference as a founding member. The men's basketball team is one of the winningest programs in NCAA history, having won eight national championships. The basketball program was also the first to reach 2000 wins.\nProfessional sports.\nLexington is home to the Lexington Legends, a member of the Atlantic League of Professional Baseball, an independent MLB Partner league. The minor league team plays home games at The Ballpark at 207 Legends Lane. In 2020, the team lost MLB affiliation under a new plan by the MLB.\nThe city also hosts Lexington SC, which fields a men's team in the USL Championship and a women's team in the USL Super League. The club was founded in 2021 and currently plays at Lexington SC Stadium.\nFormer professional sport teams based in Lexington were the Kentucky Thoroughblades, Lexington Men O' War, Lexington Bluegrass Bandits, Kentucky Horsemen, Bluegrass Warhorses, Bluegrass Stallions, Lexington Colts, and Lexington Counter Clocks.\nHorse racing and equestrian events.\nThe city is home to two horse-racing tracks, Keeneland and The Red Mile harness track. Keeneland, sporting live races in April and October, is steeped in tradition; little has changed since the track's opening in 1936. Keeneland hosted the 2015 Breeders' Cup, with the event's signature race, the Breeders' Cup Classic, won by Triple Crown winner American Pharoah. This track also has the world's largest Thoroughbred auction house; 19 Kentucky Derby winners, 21 Preakness Stakes winners, and 18 Belmont Stakes winners were purchased at Keeneland sales. Its most notable race is the Blue Grass Stakes, which is considered an important preparation for the Kentucky Derby. The Red Mile is the oldest horse racing track in the city and the second-oldest in the nation. It runs live harness races, in which horses pull two-wheeled carts called sulkies. The two tracks announced a partnership in 2014.\nThe Kentucky Horse Park, located along scenic Iron Works Pike in northern Fayette County, is a comparative latecomer to Lexington, opening in 1978. Although commonly known as a tourist attraction and museum, it is also a working horse farm with a farrier and famous retired horses such as 2003 Kentucky Derby winner Funny Cide. Since its opening in April 1978, the Kentucky Horse Park has hosted the Rolex Kentucky Three Day Event, which is one of the top-three annual equestrian eventing competitions in the world and is held immediately before the Kentucky Derby at Churchill Downs in Louisville. In September and October 2010, Lexington was the first city outside of Europe to host the World Equestrian Games.\nOther sports.\nLexington is home to Roller Derby of Central Kentucky and Lexington Bike Polo League. In 2017, Lexington hosted the World Hardcourt Bike Polo Championship, the most competitive bike polo tournament in the world, at facilities in Coolavin Park. Two years prior the city hosted the North American Hardcourt Bike Polo Championship for teams from across Canada, Mexico, and the United States. In 2023, Roller Derby of Central Kentucky returned to competitive play at Central Bank Center after a three-year hiatus.\nThe Dirt Bowl is a long-standing local basketball tournament held by Lexington Parks and Recreation at Douglass Park. The league has been around since the early 1970s. Sports Illustrated covered it in 1983 and called it one of the premier summer leagues in the country at the time. The basketball courts at Douglass Park were originally dirt, giving the tournament its \"Dirt Bowl\" name. The courts have since been paved.\nParks and recreation.\nCity parks and facilities.\nLexington has over 100 parks, ranging in size from the Smith Street Park to the Masterson Station Park. Many Lexington parks recently received improvements as part of a $25,183,270.63 investment from the American Rescue Plan Act. Lexington's parks include:\nNatural areas.\nThe city is home to Raven Run Nature Sanctuary, a nature preserve along the Kentucky River Palisades.\nThe Arboretum is a preserve adjacent to the University of Kentucky.\nThe city also plays host to the historic McConnell Springs, a park within the industrial confines off Old Frankfort Pike.\nGovernment.\nMayor.\nLexington-Fayette elects a mayor on a nonpartisan basis every four years. The current mayor, Linda Gorton, is a registered Republican and is in her second term. She defeated former councilmember David Kloiber in the November 2022 General Election by a 71% to 14% margin. Gorton, 75, is eligible to run for one additional term in 2026. The mayor may serve up to three consecutive terms.\nUrban County Council.\nThe city's legislative branch is the 15-member Urban County Council. Twelve of the members represent specific districts and serve two-year terms; three are \"at-large\" members elected citywide and serve four-year terms. The at-large member receiving the highest number of votes in the general election automatically becomes the vice mayor, who acts as the presiding officer of the council when the mayor is absent.\nGovernment meetings.\nMost Lexington-Fayette Urban County Government meetings are open to the public. Council meetings are held Thursdays at 6 p.m. at the LFUCG Government Center at 200 East Main Street.\nJudicial.\nLexington has three main active judicial courts in its downtown district. It is served by Fayette Circuit Court, Fayette District Court, and US District Court, Eastern District of Kentucky Lexington Division.\nEducation.\nAccording to the United States Census, among Lexington's population over the age of 25, 22.4% hold a bachelor's degree, 11.4% hold a master's degree, 3.1% hold a professional degree, and 2.6% hold a doctoral degree.\nThe city is served by the Fayette County Public Schools. The system currently consists of six district high schools, along with multiple smaller multidistrict high schools, 12 middle schools, one combined middle/high school, and 37 elementary schools, and is supplemented with many private schools. FCPS opened two new elementary schools in August 2016, and opened a new high school in August 2017. Fayette County Public Schools' Fiscal Year 2023 \u2013 2024 general fund budget is $677,440,375.\nThe two traditional colleges are the University of Kentucky, which is the state's flagship public university, and Transylvania University, which is the state's oldest four-year university and the first university west of the Alleghenies.\nMedia.\nLexington's largest daily circulating newspaper is the \"Lexington Herald-Leader\". \"Business Lexington\" is a monthly business newspaper. The \"Chevy Chaser Magazine\" and \"Southsider Magazine\" are two community publications.\nThe region is also served by eight primary television stations, including WLEX, WKYT, WDKY, WTVQ, WLJC, WUPX, WKLE, WKON. The state's public television network, Kentucky Educational Television, is headquartered in Lexington and is one of the nation's largest public networks, reaching all 1.6\u00a0million television households in the state.\nInfrastructure.\nTransportation.\nHighways.\nI-75 runs north\u2013south on the edge of Lexington. I-64 runs east\u2013west on the northern edge of the city. Lexington itself is at the confluence of Route 25, Route 27, Route 60, Route 68 and Route 421.\nLexington suffers considerable traffic congestion for a city of its size due to the lack of freeways, the proximity of the University of Kentucky to downtown, and the substantial number of commuters from outlying towns. For traffic relief on northern New Circle Road, Citation Boulevard is planned.\nRailroads.\nThe Southern Railway, well into the 1960s, ran passenger trains through its Lexington station on a Cincinnati-Florida route: the \"Ponce de Leon\" and the \"Royal Palm\". The last remnant of the \"Royal Palm\" left Lexington in 1970. Union Station, open from 1907 and demolished in March 1960, hosted the Chesapeake &amp; Ohio Railway and the Louisville and Nashville. The C&amp;O's Louisville-Ashland connector train to the company's \"George Washington\" ran until 1970.\nAirport.\nThe Blue Grass Airport is on the west side of Lexington on US Route 60. It has passenger flights by four carriers: Allegiant, American, Delta and United.\nModal characteristics.\nIn 2019, 79.3% of working Lexingtonians commuted by driving alone, 9.3% carpooled, 2.0% used public transportation, and 3.0% walked. 1.9% of commuters used all other forms of transportation, including taxi, bicycle, and motorcycle. About 4.4% worked from home.\nIn 2015, 7.2 percent of city of Lexington households were without a car, which increased slightly to 7.4 percent in 2016. The national average was 8.7 percent in 2016. Lexington averaged 1.7 cars per household in 2016, compared to a national average of 1.8 per household.\nLaw enforcement.\nPrimary law enforcement duties within Lexington-Fayette County are the responsibility of the Lexington-Fayette Urban County Government Division of Police. As of July 1, 2021, the Division of Police (also called Lexington Police Department) is authorized for 639 sworn police officers and 16 traffic safety officers. The Division of Police resulted from the merger of the Lexington Police Department with the Fayette County Patrol in 1974. The Fayette County Sheriff's Office is responsible for court service, including court security, prisoner transport, process and warrant service, and property tax collection. The 1974 merger also consolidated the office of city jailer into the office of county jailer, a constitutional position. In 1992 (effective 1993), the Kentucky General Assembly enabled a correctional services division to be established by ordinance, making employees civil-service employees rather than political appointees.\nFire protection.\nAll fire/rescue protection within Lexington-Fayette County (with the exception of the Blue Grass Airport) is provided by the Lexington Fire Department. The current department was formed with the merger of the county and city fire departments in 1973. Lexington Fire Department is the largest single fire department in Kentucky with over 600 personnel and 24 individual fire stations broken into five districts (battalions).\nSister cities.\nLexington has four sister cities, as designated by Sister Cities International:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50354", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=50354", "title": "Precautionary principle", "text": "Risk management strategy\nThe precautionary principle (or precautionary approach) is a broad epistemological, philosophical and legal approach to innovations with potential for causing harm when extensive scientific knowledge on the matter is lacking. It emphasizes caution, pausing and review before leaping into new innovations that may prove disastrous. Critics argue that it is vague, self-cancelling, unscientific and an obstacle to progress.\nIn an engineering context, the precautionary principle manifests itself as the factor of safety. It was apparently suggested, in civil engineering, by Belidor in 1729. Interrelation between safety factor and reliability is extensively studied by engineers and philosophers.\nThe principle is often used by policy makers in situations where there is the possibility of harm from making a certain decision (e.g. taking a particular course of action) and conclusive evidence is not yet available. For example, a government may decide to limit or restrict the widespread release of a medicine or new technology until it has been thoroughly tested. The principle acknowledges that while the progress of science and technology has often brought great benefit to humanity, it has also contributed to the creation of new threats and risks. It implies that there is a social responsibility to protect the public from exposure to such harm, when scientific investigation has found a plausible risk. These protections should be relaxed only if further scientific findings emerge that provide sound evidence that no harm will result.\nThe principle has become an underlying rationale for a large and increasing number of international treaties and declarations in the fields of sustainable development, environmental protection, health, trade, and food safety, although at times it has attracted debate over how to accurately define it and apply it to complex scenarios with multiple risks. In some legal systems, as in law of the European Union, the application of the precautionary principle has been made a statutory requirement in some areas of law.\nOrigins and theory.\nThe concept \"precautionary principle\" is generally considered to have arisen in English from a translation of the German term \"\" in the 1970s in response to forest degradation and sea pollution, where German lawmakers adopted clean air act banning use of certain substances suspected in causing the environmental damage even though evidence of their impact was inconclusive at that time. The concept was introduced into environmental legislation along with other innovative (at that time) mechanisms such as \"polluter pays\", principle of pollution prevention and responsibility for survival of future ecosystems.\nThe precautionary principle was promulgated in philosophy by Hans Jonas in his 1979 text, \"The Imperative of Responsibility\", wherein Jonas argued that technology had altered the range of the impact of human action and, as such, ethics must be modified so that the far distant effects of one's actions should now be considered. His maxim is designed to embody the precautionary principle in its prescription that one should \"Act so that the effects of your action are compatible with the permanence of genuine human life\" or, stated conversely, \"Do not compromise the conditions for an indefinite continuation of humanity on earth.\" To achieve this Jonas argued for the cultivation of a cautious attitude toward actions that may endanger the future of humanity or the biosphere that supported it.\nIn 1988, Konrad von Moltke described the German concept for a British audience, which he translated into English as the precautionary principle.\nIn economics, the Precautionary Principle has been analyzed in terms of \"the effect on rational decision-making\", of \"the interaction of irreversibility\" and \"uncertainty\". Authors such as Epstein (1980) and Arrow and Fischer (1974) show that \"irreversibility of possible future consequences\" creates a \"quasi-option effect\" which should induce a \"risk-neutral\" society to favour current decisions that allow for more flexibility in the future. Gollier et al. conclude that \"more scientific uncertainty as to the distribution of a future risk \u2013 that is, a larger variability of beliefs \u2013 should induce society to take stronger prevention measures today.\"\nThe principle was also derived from religious beliefs that particular areas of science and technology should be restricted as they \"belong to the realm of God\", as postulated by Prince Charles and Pope Benedict XVI.\nFormulations.\nMany definitions of the precautionary principle exist: \"precaution\" may be defined as \"caution in advance\", \"caution practiced in the context of uncertainty\", or informed prudence. Two ideas lie at the core of the principle:\nOne of the primary foundations of the precautionary principle, and globally accepted definitions, results from the work of the Rio Conference, or \"Earth Summit\" in 1992. Principle 15 of the Rio Declaration notes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In order to protect the environment, the precautionary approach shall be widely applied by States according to their capabilities. Where there are threats of serious or irreversible damage, lack of full scientific certainty shall not be used as a reason for postponing cost-effective measures to prevent environmental degradation.\u2014\u200a\nIn 1998, the Wingspread Conference on the Precautionary Principle was convened by the Science and Environmental Health Network and concluded with the following formulation, described by Stewart Brand as \"the clearest and most frequently cited\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When an activity raises threats of harm to human health or the environment, precautionary measures should be taken even if some cause and effect relationships are not fully established scientifically. In this context the proponent of an activity, rather than the public, should bear the burden of proof.\nIn February 2000, the Commission of the European Communities noted in a \"Communication from the Commission on the Precautionary Principle\" that \"The precautionary principle is not defined in the Treaties of the European Union, which prescribes it [the Precautionary Principle] only once \u2013 to protect the environment. But in practice, its scope is much wider, and specifically where preliminary-objective-scientific-evaluation indicates that there are reasonable grounds for concern that potentially dangerous effects on the environment, human, animal or [and] plant health may be inconsistent with the high level of protection [for what] chosen for the Community.\"\nThe January 2000 Cartagena Protocol on Biosafety says, in regard to controversies over GMOs: \"Lack of scientific certainty due to insufficient relevant scientific information ... shall not prevent the Party of [I]mport, in order to avoid or minimize such potential adverse effects, from taking a decision, as appropriate, with regard to the import of the living modified organism in question.\"\nPope Francis makes reference to the principle and the Rio Declaration in his 2015 encyclical letter, \"Laudato si\"', noting that alongside its environmental significance, the precautionary principle \"makes it possible to protect those who are most vulnerable and whose ability to defend their interests and to assemble incontrovertible evidence is limited\".\nApplication.\nVarious interests being represented by various groups proposing the principle resulted in great variability of its formulation: one study identified 14 different formulations of the principle in treaties and non-treaty declarations. R.B. Stewart (2002) reduced the precautionary principle to four basic versions:\nCarolyn Raffensperger of the Wingspread convention placed the principle in opposition to approaches based on risk management and cost-benefit analysis. Dave Brower (Friends of the Earth) concluded that \"all technology should be assumed guilty until proven innocent\". Freeman Dyson described the application of precautionary principle as \"deliberately one-sided\", for example when used as justification to destroy genetic engineering research plantations and threaten researchers in spite of scientific evidence demonstrating lack of harm:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Precautionary Principle says that if some course of action carries even a remote chance of irreparable damage to the ecology, then you shouldn't do it, no matter how great the possible advantages of the action may be. You are not allowed to balance costs against benefits when deciding what to do.\u2014\u200a\nAs noted by Rupert and O'Riordan, the challenge in application of the principle is \"in making it clear that absence of certainty, or there being insufficient evidence-based analysis, were not impediments to innovation, so long as there was no reasonable likelihood of serious harm\". Lack of this nuanced application makes the principle \"self-cancelling\" according to Stewart Brand, because \"nothing is fully established\" in science, starting from the precautionary principle itself and including \"gravity or Darwinian evolution\". A balanced application should ensure that \"precautionary measures should be\" only taken \"during early stages\" and as \"relevant scientific evidence becomes established\", regulatory measures should only respond to that evidence.\nStrong vs. weak.\n\"Strong precaution\" holds that regulation is required whenever there is a possible risk to health, safety, or the environment, even if the supporting evidence is speculative and even if the economic costs of regulation are high. In 1982, the United Nations World Charter for Nature gave the first international recognition to the strong version of the principle, suggesting that when \"potential adverse effects are not fully understood, the activities should not proceed\". The widely publicised Wingspread Declaration, from a meeting of environmentalists in 1998, is another example of the strong version. Strong precaution can also be termed as a \"no-regrets\" principle, where costs are not considered in preventative action.\n\"Weak precaution\" holds that lack of scientific evidence does not preclude action if damage would otherwise be serious and irreversible. Humans practice weak precaution every day, and often incur costs, to avoid hazards that are far from certain: we do not walk in moderately dangerous areas at night, we exercise, we buy smoke detectors, we buckle our seatbelts.\nAccording to a publication by the New Zealand Treasury Department:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; The weak version [of the Precautionary Principle] is the least restrictive and allows preventive measures to be taken in the face of uncertainty, but does not require them (e.g., Rio Declaration 1992; United Nations Framework Convention of Climate Change 1992). To satisfy the threshold of harm, there must be some evidence relating to both the likelihood of occurrence and the severity of consequences. Some, but not all, require consideration of the costs of precautionary measures. Weak formulations do not preclude weighing benefits against the costs. Factors other than scientific uncertainty, including economic considerations, may provide legitimate grounds for postponing action. Under weak formulations, the requirement to justify the need for action (the burden of proof) generally falls on those advocating precautionary action. No mention is made of assignment of liability for environmental harm.\n Strong versions justify or require precautionary measures and some also establish liability for environmental harm, which is effectively a strong form of \"polluter pays\". For example, the Earth Charter states: \"When knowledge is limited apply a precautionary approach ... Place the burden of proof on those who argue that a proposed activity will not cause significant harm, and make the responsible parties liable for environmental harm.\" Reversal of proof requires those proposing an activity to prove that the product, process or technology is sufficiently \"safe\" before approval is granted. Requiring proof of \"no environmental harm\" before any action proceeds implies the public is not prepared to accept any environmental risk, no matter what economic or social benefits may arise (Peterson, 2006). At the extreme, such a requirement could involve bans and prohibitions on entire classes of potentially threatening activities or substances (Cooney, 2005). Over time, there has been a gradual transformation of the precautionary principle from what appears in the Rio Declaration to a stronger form that arguably [by whom] acts as restraint on development in the absence of firm evidence that it will do no harm. \nInternational agreements and declarations.\n\"Principle\" vs. \"approach\".\nNo introduction to the precautionary principle would be complete without brief reference to the difference between the precautionary \"principle\" and the precautionary \"approach\". Principle 15 of the Rio Declaration 1992 states that: \"in order to protect the environment, the precautionary approach shall be widely applied by States according to their capabilities. Where there are threats of serious or irreversible damage, lack of full scientific certainty shall be not used as a reason for postponing cost-effective measures to prevent environmental degradation.\" As Garcia (1995) pointed out, \"the wording, largely similar to that of the principle, is subtly different in that: it recognizes that there may be differences in local capabilities to apply the approach, and it calls for cost-effectiveness in applying the approach, e.g., taking economic and social costs into account.\" The \"approach\" is generally considered a softening of the \"principle\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;As Recuerda has noted, the distinction between the precautionary principle and a precautionary approach is diffuse and, in some contexts, controversial. In the negotiations of international declarations, the United States has opposed the use of the term \"principle\" because this term has special connotations in legal language, due to the fact that a \"principle of law\" is a source of law. This means that it is compulsory, so a court can quash or confirm a decision through the application of the precautionary principle. In this sense, the precautionary principle is not a simple idea or a desideratum but a source of law. This is the legal status of the precautionary principle in the European Union. On the other hand, an 'approach' usually does not have the same meaning, although in some particular cases an approach could be binding. A precautionary approach is a particular \"lens\" used to identify risk that every prudent person possesses (Recuerda, 2008)\nEuropean Union.\nOn 2 February 2000, the European Commission issued a Communication on the precautionary principle, in which it adopted a procedure for the application of this concept, but without giving a detailed definition of it. Paragraph 2 of article 191 of the Lisbon Treaty states that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nAfter the adoption of the European Commission's communication on the precautionary principle, the principle has come to inform much EU policy, including areas beyond environmental policy. As of 2006 it had been integrated into EU laws \"in matters such as general product safety, the use of additives for use in animal nutrition, the incineration of waste, and the regulation of genetically modified organisms\". Through its application in case law, it has become a \"general principle of EU law\".\nIn Case T-74/00 \"Artegodan\", the General Court (then Court of First Instance) appeared willing to extrapolate from the limited provision for the precautionary principle in environmental policy in article 191(2) TFEU to a general principle of EU law.\nFrance.\nIn France, the Charter for the Environment contains a formulation of the precautionary principle (article 5):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When the occurrence of any damage, albeit unpredictable in the current state of scientific knowledge, may seriously and irreversibly harm the environment, public authorities shall, with due respect for the principle of precaution and the areas within their jurisdiction, ensure the implementation of procedures for risk assessment and the adoption of temporary measures commensurate with the risk involved in order to preclude the occurrence of such damage.\nUnited States.\nOn 18 July 2005, the City of San Francisco passed a precautionary principle purchasing ordinance, which requires the city to weigh the environmental and health costs of its $600\u00a0million in annual purchases \u2013 for everything from cleaning supplies to computers. Members of the Bay Area Working Group on the Precautionary Principle contributed to drafting the Ordinance.\nAustralia.\nThe most important Australian court case so far, due to its exceptionally detailed consideration of the precautionary principle, is Telstra Corporation Limited v Hornsby Shire Council.\nThe principle was summarised by reference to the NSW \"Protection of the Environment Administration Act 1991\", which itself provides a good definition of the principle:\n\"If there are threats of serious or irreversible environmental damage, lack of full scientific certainty should not be used as a reasoning for postponing measures to prevent environmental degradation. In the application of the principle... decisions should be guided by:\n(i) careful evaluation to avoid, wherever practicable, serious or irreversible damage to the environment; and\n(ii) an assessment of risk-weighted consequence of various options\".\nThe most significant points of Justice Preston's decision are the following findings:\nPhilippines.\nA petition filed 17 May 2013 by environmental group Greenpeace Southeast Asia and farmer-scientist coalition Masipag (\"Magsasaka at Siyentipiko sa Pagpapaunlad ng Agrikultura\") asked the appellate court to stop the planting of Bt eggplant in test fields, saying the impacts of such an undertaking to the environment, native crops and human health are still unknown. The Court of Appeals granted the petition, citing the precautionary principle stating \"when human activities may lead to threats of serious and irreversible damage to the environment that is scientifically plausible but uncertain, actions shall be taken to avoid or diminish the threat.\"\nRespondents filed a motion for reconsideration in June 2013 and on 20 September 2013 the Court of Appeals chose to uphold their May decision saying the \"bt talong\" field trials violate the people's constitutional right to a \"balanced and healthful ecology.\" The Supreme Court on 8 December 2015 permanently stopped the field testing for Bt (Bacillus thuringiensis) talong (eggplant), upholding the decision of the Court of Appeals which stopped the field trials for the genetically modified eggplant. The court is the first in the world to adopt the precautionary principle regarding GMO products in its decision. The Supreme Court decision was later reversed following an appeal by researchers at the University of the Philippines Los Ba\u00f1os.\nCorporate.\nBody Shop International, a UK-based cosmetics company, included the precautionary principle in their 2006 chemicals strategy.\nEnvironment and health.\nFields typically concerned by the precautionary principle are the possibility of:\nThe precautionary principle is often applied to biological fields because changes cannot be easily contained and have the potential of being global. The principle has less relevance to contained fields such as aeronautics, where the few people undergoing risk have given informed consent (e.g., a test pilot). In the case of technological innovation, containment of impact tends to be more difficult if that technology can self-replicate. Bill Joy emphasised the dangers of replicating genetic technology, nanotechnology, and robotic technology in his article in \"Wired\", \"Why the future doesn't need us\", though he does not specifically cite the precautionary principle. The application of the principle can be seen in the public policy of requiring pharmaceutical companies to carry out clinical trials to show that new medications are safe.\nOxford based philosopher Nick Bostrom discusses the idea of a future powerful superintelligence, and the risks should it attempt to gain atomic level control of matter.\nApplication of the principle modifies the status of innovation and risk assessment: it is not the risk that must be avoided or amended, but a potential risk that must be prevented. Thus, in the case of regulation of scientific research, there is a third party beyond the scientist and the regulator: the consumer.\nIn an analysis concerning application of the precautionary principle to nanotechnology, Chris Phoenix and Mike Treder posit that there are \"two forms\" of the principle, which they call the \"strict form\" and the \"active form\". The former \"requires inaction when action might pose a risk\", while the latter means \"choosing less risky alternatives when they are available, and [...] taking responsibility for potential risks.\" Thomas Alured Faunce has argued for stronger application of the precautionary principle by chemical and health technology regulators particularly in relation to Ti02 and ZnO nanoparticles in sunscreens, biocidal nanosilver in waterways and products whose manufacture, handling or recycling exposes humans to the risk of inhaling multi-walled carbon nanotubes.\nAnimal sentience precautionary principle.\nAppeals to the precautionary principle have often characterized the debates concerning animal sentience \u2013 that is, the question of whether animals are able to feel \"subjective experiences with an attractive or aversive quality\", such as pain, pleasure, happiness, or joy \u2013 in relation to the question of whether we should legally protect sentient animals. A version of the precautionary principle suitable for the problem of animal sentience has been proposed by LSE philosopher Jonathan Birch: \"The idea is that when the evidence of sentience is inconclusive, we should 'give the animal the benefit of doubt' or 'err on the side of caution' in formulating animal protection legislation.\" Since we cannot reach absolute certainty with regards to the fact that some animals are sentient, the precautionary principle has been invoked in order to grant potentially sentient animals \"basic legal protections\". Birch's formulation of the animal sentience precautionary principle runs as follows:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This version of the precautionary principle consists of an epistemic and a decision rule. The former concerns the \"evidential bar\" that should be required for animal sentience. In other words, how much evidence of sentience is necessary before one decides to apply precautionary measures? According to Birch, only \"some\" evidence would be sufficient, which means that the evidential bar should be set at low levels. Birch proposes to consider the evidence that certain animals are sentient sufficient whenever \"statistically significant evidence ... of the presence of at least one credible indicator of sentience in at least one species of that order\" has been obtained. For practical reasons, Birch says, the evidence of sentience should concern the order, so that if one species meets the conditions of sentience, then all the species of the same order should be considered sentient and should be thus legally protected. This is due to the fact that, on the one hand, \"to investigate sentience separately in different orders\" is feasible, whereas on the other hand, since some orders include thousands of species, it would be unfeasible to study their sentience separately.\nWhat is more, the evidential bar should be so low that only \"one\" indicator of sentience in the species of a specific order will be sufficient in order for the precautionary principle to be applied. Such indicator should be \"an observable phenomenon that experiments can be designed to detect, and it must be credible that the presence of this indicator is explained by sentience\". Lists of such criteria already exist for detecting animal pain. The aim is to create analogous lists for other criteria of sentience, such as happiness, fear, or joy. The presence of one of these criteria should be demonstrated by means of experiments which must meet \"the normal scientific standards\".\nRegarding the second part of the animal sentience precautionary principle, the decision rule concerns the requirement that we have to act once there is sufficient evidence of a seriously bad outcome. According to Birch, \"we should aim to include within the scope of animal protection legislation all animals for which the evidence of sentience is sufficient, according to the standard of sufficiency outlined [above]\". In other words, the decision rule states that once the aforementioned low evidential bar is met, then we \"should\" act in a precautionary way. Birch's proposal also \"deliberately leaves open the question of how, and to what extent, the treatment of these animals should be regulated\", thus also leaving open the content of the regulations, as this will largely depend on the animal in question.\nCriticisms.\nCritics of the principle use arguments similar to those against other formulations of technological conservatism.\nInternal inconsistency: applying strong PP risks causing harm.\nStrong formulations of the precautionary principle, without regard to its most basic provisions (i.e., that it is to be applied only where risks are potentially catastrophic \"and\" not easily calculable), when applied to the principle itself as a policy decision, beats its own purpose of reducing risk. The reason suggested is that preventing innovation from coming to market means that only current technology may be used, and current technology itself may cause harm or leave needs unmet; there is a risk of causing harm by blocking innovation. As Michael Crichton wrote in his novel \"State of Fear\": \"The 'precautionary principle', properly applied, forbids the precautionary principle.\"\nFor example, forbidding nuclear power plants based on concerns about low-probability high-impact risks means continuing to rely on power plants that burn fossil fuels, which continue to release greenhouse gases and thousands of certain deaths from air pollution.\nIn 2021 in response to early reports about rare blood clots seen in 25 patients out of 20 million vaccinated by Astra-Zeneca COVID-19 vaccine a number of European Union member states suspended the use of the vaccine, quoting the \"precautionary principle\". This was criticized by other EU states who refused to suspend the vaccination program, declaring that the \"precautionary\" decisions are focusing on the wrong risk, as delay in a vaccination program results in a larger number of certain deaths than any yet unconfirmed complications.\nIn another example, the Hazardous Air Pollutant provisions in the 1990 amendments to the US Clean Air Act are an example of the Precautionary Principle where the onus is now on showing a listed compound is harmless. Under this rule no distinction is made between those air pollutants that provide a higher or lower risk, so operators tend to choose less-examined agents that are not on the existing list.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The very basis of the Precautionary Principle is to imagine the worst without supporting evidence... those with the darkest imaginations become the most influential.\u2014\u200a\nBlocking innovation and progress generally.\nBecause applications of strong formulations of the precautionary principle can be used to block innovation, a technology which brings advantages may be banned by precautionary principle because of its potential for negative impacts, leaving the positive benefits unrealised.\nThe precautionary principle has been ethically questioned on the basis that its application could block progress in developing countries.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The precautionary principle presents a serious hazard to our health which extends way beyond the generation of unnecessary neuroses. The biggest correlate of our health and well being is our standard of living, as measured in conventional economic and physical terms. People in technologically advanced societies suffer fewer diseases and live longer than those in less developed nations. The biggest killer in the world is not genetically modified soya, pesticide residues or even tobacco. It is something which is given the code Z59.5 in the International Classification of Disease Handbook and accounts for more deaths world-wide than any other single factor. It is defined as 'Extreme Poverty'.\u2014\u200a\nVagueness and plausibility.\nThe precautionary principle calls for action in the face of scientific uncertainty, but some formulations do not specify the minimal threshold of plausibility of risk that acts as a \"triggering\" condition, so that any indication that a proposed product or activity might harm health or the environment is sufficient to invoke the principle. In \"Sancho vs. DOE\", Helen Gillmor, Senior District Judge, wrote in a dismissal of Wagner's lawsuit which included a popular worry that the LHC could cause \"destruction of the earth\" by a black hole:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Injury in fact requires some \"credible threat of harm.\" \"Cent. Delta Water Agency v. United States\", 306 F.3d 938, 950 (9th Cir. 2002). At most, Wagner has alleged that experiments at the Large Hadron Collider (the \"Collider\") have \"potential adverse consequences.\" Speculative fear of future harm does not constitute an injury in fact sufficient to confer standing. \"Mayfield\", 599 F.3d at 970.\nThe precautionary dilemma.\nThe most commonly pressed objection to the precautionary principle ties together two of the above objections into the form of a dilemma. This maintains that, of the two available interpretations of the principle, neither are plausible: weak formulations (which hold that precaution in the face of uncertain harms is permissible) are trivial, while strong formulations (which hold that precaution in the face of uncertain harms is \"required\") are incoherent. On the first horn of the dilemma Cass Sunstein states:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; If all that the (weak) principle states is that it is permissible to act in a precautionary manner where there is a possible risk of harm, then it constitutes a trivial truism and thus fails to be useful.\nIf we formulate the principle in the stronger sense however, it looks like it rules out \"all\" courses of action, including the precautionary measures it is intended to advocate. This is because, if we stipulate that precaution is \"required\" in the face of uncertain harms, and precautionary measures also carry a risk of harm, the precautionary principle can both demand and prohibit action at the same time. The risk of a policy resulting in catastrophic harm is always \"possible\". For example: prohibiting genetically modified crops risks significantly reduced food production; placing a moratorium on nuclear power risks an over-reliance on coal that could lead to more air pollution; implementing extreme measures to slow global warming risks impoverishment and bad health outcomes for some people. The strong version of the precautionary principle, in that \"[i]t bans the very steps that it requires\", thus fails to be coherent. As Sunstein states, it is not protective, it is \"paralyzing\".\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50355", "revid": "8565473", "url": "https://en.wikipedia.org/wiki?curid=50355", "title": "Informed consent", "text": "Ethical principle\nInformed consent is an applied ethics principle that a person must have sufficient information and understanding before making decisions about accepting risk. Pertinent information may include risks and benefits of treatments, alternative treatments, the patient's role in treatment, and their right to refuse treatment. In most systems, healthcare providers have a legal and ethical responsibility to ensure that a patient's consent is informed. This principle applies more broadly than healthcare intervention, for example to conduct research, to disclose a person's medical information, or to participate in high risk sporting and recreational activities.\nWithin the United States, definitions of informed consent vary, and the standard required is generally determined by the state. As of 2016, nearly half of the states adopted a reasonable patient standard, in which the informed consent process is viewed from the patient's perspective. These standards in medical contexts are formalized in the requirement for decision-making capacity and professional determinations in these contexts have legal authority. This requirement can be summarized in brief to presently include the following conditions, all of which must be met in order for one to qualify as possessing decision-making capacity:\nImpairments to reasoning and judgment that may preclude informed consent include intellectual or emotional immaturity, high levels of stress such as post-traumatic stress disorder or a severe intellectual disability, severe mental disorder, intoxication, severe sleep deprivation, dementia, or coma.\nObtaining informed consent is not always required. If an individual is considered unable to give informed consent, another person is generally authorized to give consent on the individual's behalf\u2014for example, the parents or legal guardians of a child (though in this circumstance the child may be required to provide informed assent) and conservators for the mentally disordered. Alternatively, the doctrine of implied consent permits treatment in limited cases, for example when an unconscious person will die without immediate intervention. Cases in which an individual is provided insufficient information to form a reasoned decision raise serious ethical issues. When these issues occur, or are anticipated to occur, in a clinical trial, they are subject to review by an ethics committee or institutional review board.\nInformed consent is codified in both national and international law. 'Free consent' is a cognate term in the International Covenant on Civil and Political Rights, adopted in 1966 by the United Nations, and intended to be in force by 23 March 1976. Article 7 of the covenant prohibits experiments conducted without the \"free consent to medical or scientific experimentation\" of the subject. As of \u00a02019[ [update]], the covenant has 173 parties and six more signatories without ratification.\nAssessment.\nInformed consent can be complex to evaluate, because neither expressions of consent, nor expressions of understanding of implications, necessarily mean that full adult consent was in fact given, nor that full comprehension of relevant issues is internally digested. Consent may be implied within the usual subtleties of human communication, rather than explicitly negotiated verbally or in writing. For example, if a doctor asks a patient to take their blood pressure, a patient may demonstrate consent by offering their arm for a blood pressure cuff. In some cases consent cannot legally be possible, even if the person protests he does indeed understand and wish. There are also structured instruments for evaluating capacity to give informed consent, although no ideal instrument presently exists.\nThus, there is always a degree to which informed consent must be assumed or inferred based upon observation, or knowledge, or legal reliance. This especially is the case in sexual or relational issues. In medical or formal circumstances, explicit agreement by means of signature\u2014normally relied on legally\u2014regardless of actual consent, is the norm. This is the case with certain procedures, such as a \"do not resuscitate\" directive that a patient signed before onset of their illness.\nBrief examples of each of the above:\nValid elements.\nFor an individual to give valid informed consent, three components must be present: disclosure, capacity and voluntariness.\nPatient understanding.\nAn often-overlooked aspect of valid informed consent is the patient's understanding of terminology and outcomes. The physician must explain the procedure, benefits, risks, and alternatives in words the patient can understand, as well as ensure that the patient does understand the information being relayed. The process of explanation is meant to ensure the patient has considered the options carefully and grasps the possible risks associated without feeling pressured or rushed to agree to the procedure. Exceptions to the typical consent process are only made during severe emergencies.\nFrom children.\nAs children often lack the decision-making ability or legal power (competence) to provide true informed consent for medical decisions, it often falls on parents or legal guardians to provide \"informed permission\" for medical decisions. This \"consent by proxy\" usually works reasonably well, but can lead to ethical dilemmas when the judgment of the parents or guardians and the medical professional differ with regard to what constitutes appropriate decisions \"in the best interest of the child\". Children who are legally emancipated, and certain situations such as decisions regarding sexually transmitted diseases or pregnancy, or for unemancipated minors who are deemed to have medical decision making capacity, may be able to provide consent without the need for parental permission depending on the laws of the jurisdiction the child lives in. The American Academy of Pediatrics encourages medical professionals also to seek the assent of older children and adolescents by providing age appropriate information to these children to help empower them in the decision-making process.\nResearch on children has benefited society in many ways. The only effective way to establish normal patterns of growth and metabolism is to do research on infants and young children. When addressing the issue of informed consent with children, the primary response is parental consent. This is valid, although only legal guardians are able to consent for a child, not adult siblings. Additionally, parents may not order the termination of a treatment that is required to keep a child alive, even if they feel it is in the best interest. Guardians are typically involved in the consent of children, however a number of doctrines have developed that allow children to receive health treatments without parental consent. For example, emancipated minors may consent to medical treatment, and minors can also consent in an emergency. Information provided to parents/guardians, and to children themselves, as part of clinical research is often written in ways that make them difficult to understand.\nWaiver of requirement.\nWaiver of the consent requirement may be applied in certain circumstances where no foreseeable harm is expected to result from the study or when permitted by law, federal regulations, or if an ethical review committee has approved the non-disclosure of certain information.\nBesides studies with minimal risk, waivers of consent may be obtained in a military setting. According to 10 USC 980, the United States Code for the Armed Forces, Limitations on the Use of Humans as Experimental Subjects, a waiver of advanced informed consent may be granted by the Secretary of Defense if a research project would:\nWhile informed consent is a basic right and should be carried out effectively, if a patient is incapacitated due to injury or illness, it is still important that patients benefit from emergency experimentation. The Food and Drug Administration (FDA) and the Department of Health and Human Services (DHHS) joined to create federal guidelines to permit emergency research, without informed consent. However, they can only proceed with the research if they obtain a waiver of informed consent (WIC) or an emergency exception from informed consent (EFIC).\n21st Century Cures Act.\nThe 21st Century Cures Act enacted by the 114th United States Congress in December 2016 allows researchers to waive the requirement for informed consent when clinical testing \"poses no more than minimal risk\" and \"includes appropriate safeguards to protect the rights, safety, and welfare of the human subject.\"\nMedical sociology.\nMedical sociologists have studied informed consent as well as bioethics more generally. Oonagh Corrigan, looking at informed consent for research in patients, argues that much of the conceptualization of informed consent comes from research ethics and bioethics with a focus on patient autonomy, and notes that this aligns with a neoliberal worldview. Corrigan argues that a model based solely around individual decision making does not accurately describe the reality of consent because of social processes: a view that has started to be acknowledged in bioethics. She feels that the liberal principles of informed consent are often in opposition with autocratic medical practices such that norms values and systems of expertise often shape an individuals ability to apply choice.\nPatients who agree to participate in trials often do so because they feel that the trial was suggested by a doctor as the best intervention. Patients may find being asked to consent within a limited time frame a burdensome intrusion on their care when it arises because a patient has to deal with a new condition. Patients involved in trials may not be fully aware of the alternative treatments, and an awareness that there is uncertainty in the best treatment can help make patients more aware of this. Corrigan notes that patients generally expect that doctors are acting exclusively in their interest in interactions and that this combined with \"clinical equipose\" where a healthcare practitioner does not know which treatment is better in a randomized control trial can be harmful to the doctor-patient relationship.\nMedical procedures.\nThe doctrine of informed consent relates to professional negligence and establishes a breach of the duty of care owed to the patient (see duty of care, breach of the duty, and respect for persons). The doctrine of informed consent also has significant implications for medical trials of medications, devices, or procedures.\nRequirements of the professional.\nUntil 2015 in the United Kingdom and in countries such as Malaysia and Singapore, informed consent in medical procedures requires proof as to the standard of care to expect as a recognised standard of acceptable professional practice (the Bolam Test), that is, what risks would a medical professional usually disclose in the circumstances. Arguably, this is \"sufficient consent\" rather than \"informed consent.\" The UK has since departed from the Bolam test for judging standards of informed consent, due to the landmark ruling in \"Montgomery v Lanarkshire Health Board\". This moves away from the concept of a reasonable physician and instead uses the standard of a reasonable patient, and what risks an individual would attach significance to.\nMedicine in the United States, Australia, and Canada takes this patient-centric approach to \"informed consent.\" Informed consent in these jurisdictions requires healthcare providers to disclose significant risks, as well as risks of particular importance to that patient. This approach combines an objective (a hypothetical reasonable patient) and subjective (this particular patient) approach.\nOptimal establishment of an informed consent requires adaptation to cultural or other individual factors of the patient. As of 2011, for example, people from Mediterranean and Arab backgrounds appeared to rely more on the context of the delivery of the information, with the information being carried more by who is saying it and where, when, and how it is being said, rather than \"what\" is said, which is of relatively more importance in typical \"Western\" countries.\nThe informed consent doctrine is generally implemented through good healthcare practice: pre-operation discussions with patients and the use of medical consent forms in hospitals. However, reliance on a signed form should not undermine the basis of the doctrine in giving the patient an opportunity to weigh and respond to the risk. In one British case, a doctor performing routine surgery on a woman noticed that she had cancerous tissue in her womb. He took the initiative to remove the woman's womb; however, as she had not given informed consent for this operation, the doctor was judged by the General Medical Council to have acted negligently. The council stated that the woman should have been informed of her condition, and allowed to make her own decision.\nObtaining informed consents.\nTo document that informed consent has been given for a procedure, healthcare organisations have traditionally used paper-based consent forms on which the procedure and its risks and benefits are noted, and is signed by both patient and clinician. In a number of healthcare organisations consent forms are scanned and maintained in an electronic document store. The paper consent process has been demonstrated to be associated with significant errors of omission, and therefore increasing numbers of organisations are using digital consent applications where the risk of errors can be minimised, a patient's decision making and comprehension can be supported by additional lay-friendly and accessible information, consent can be completed remotely, and the process can become paperless. One form of digital consent is dynamic consent, which invites participants to provide consent in a granular way, and makes it easier for them to withdraw consent if they wish.\nPatient satisfaction in the context of novel forms of informed consent has been a topic in scientific research. Visual and auditory components in video-assisted informed consent and digital informed consent have proved to lead to higher patient satisfaction. Integrating patients into treatment decisions (shared decision-making) and increasing transparency leads to better overall treatment adherence.\nElectronic consent methods have been used to support indexing and retrieval of consent data, thus enhancing the ability to honor to patient intent and identify willing research participants. More recently, Health Sciences South Carolina, a statewide research collaborative focused on transforming healthcare quality, health information systems and patient outcomes, developed an open-source system called Research Permissions Management System (RPMS).\nCompetency of the patient.\nThe ability to give informed consent is governed by a general requirement of competency. In common law jurisdictions, adults are presumed competent to consent. This presumption can be rebutted, for instance, in circumstances of mental illness or other incompetence. This may be prescribed in legislation or based on a common-law standard of inability to understand the nature of the procedure. In cases of incompetent adults, a health care proxy makes medical decisions. In the absence of a proxy, the medical practitioner is expected to act in the patient's best interests until a proxy can be found.\nBy contrast, 'minors' (which may be defined differently in different jurisdictions) are generally presumed incompetent to consent, but depending on their age and other factors may be required to provide Informed assent. In some jurisdictions (e.g. much of the U.S.), this is a strict standard. In other jurisdictions (e.g. England, Australia, Canada), this presumption may be rebutted through proof that the minor is 'mature' (the 'Gillick standard'). In cases of incompetent minors, informed consent is usually required from the parent (rather than the 'best interests standard') although a parens patriae order may apply, allowing the court to dispense with parental consent in cases of refusal.\nDeception.\nResearch involving deception is controversial given the requirement for informed consent. Deception typically arises in social psychology, when researching a particular psychological process requires that investigators deceive subjects. For example, in the Milgram experiment, researchers wanted to determine the willingness of participants to obey authority figures despite their personal conscientious objections. They had authority figures demand that participants deliver what they thought was an electric shock to another research participant. For the study to succeed, it was necessary to deceive the participants so they believed that the subject was a peer and that their electric shocks caused the peer actual pain.\nNonetheless, research involving deception prevents subjects from exercising their basic right of autonomous informed decision-making and conflicts with the ethical principle of respect for persons.\nThe Ethical Principles of Psychologists and Code of Conduct set by the American Psychological Association says that psychologists may conduct research that includes a deceptive compartment only if they can both justify the act by the value and importance of the study's results and show they could not obtain the results by some other way. Moreover, the research should bear no potential harm to the subject as an outcome of deception, either physical pain or emotional distress. Finally, the code requires a debriefing session in which the experimenter both tells the subject about the deception and gives subject the option of withdrawing the data.\nAbortion.\nIn some U.S. states, informed consent laws (sometimes called \"right to know\" laws) require that a woman seeking an elective abortion receive information from the abortion provider about her legal rights, alternatives to abortion (such as adoption), available public and private assistance, and other information specified in the law, before the abortion is performed. Other countries with such laws (e.g. Germany) require that the information giver be properly certified to make sure that no abortion is carried out for the financial gain of the abortion provider and to ensure that the decision to have an abortion is not swayed by any form of incentive.\nSome informed consent laws have been criticized for allegedly using \"loaded language in an apparently deliberate attempt to 'personify' the fetus,\" but those critics acknowledge that \"most of the information in the [legally mandated] materials about abortion comports with recent scientific findings and the principles of informed consent\", although \"some content is either misleading or altogether incorrect.\"\nWithin research.\nMedicine.\nInformed consent is part of ethical clinical research as well, in which a human subject voluntarily confirms his or her willingness to participate in a particular clinical trial, after having been informed of all aspects of the trial that are relevant to the subject's decision to participate. This includes information about potential harms as well as potential benefits of clinical trial treatments. Informed consent is documented by means of a written, signed, and dated informed consent form.\nIn medical research, the Nuremberg Code set a base international standard in 1947, in response to the ethical violation in the Holocaust. Standards continued to develop. Nowadays, medical research is overseen by an ethics committee that also oversees the informed consent process.\nSocial sciences.\nAs the medical guidelines established in the Nuremberg Code were imported into the ethical guidelines for the social sciences, informed consent became a common part of the research procedure. However, while informed consent is the default in medical settings, it is not always required in the social sciences. Here, firstly, research often involves low or no risk for participants, unlike in many medical experiments. Secondly, the mere knowledge that they participate in a study can cause people to alter their behavior, as in the Hawthorne Effect: \"In the typical lab experiment, subjects enter an environment in which they are keenly aware that their behavior is being monitored, recorded, and subsequently scrutinized.\"\nIn such cases, seeking informed consent directly interferes with the ability to conduct the research, because the very act of revealing that a study is being conducted is likely to alter the behavior studied. Author J.A. List explains the potential dilemma that can result: \"if one were interested in exploring whether, and to what extent, race or gender influences the prices that buyers pay for used cars, it would be difficult to measure accurately the degree of discrimination among used car dealers who know that they are taking part in an experiment.\" In a case where such interference is likely, and after careful consideration, a researcher may forgo the informed consent process. This may be done after the researcher(s) and an Ethics Committee and/or Institutional Review Board (IRB) weigh the risk to study participants against the benefits to society and whether participants participate voluntarily and are to be treated fairly.\nThe birth of new online media, such as social media, has complicated the idea of informed consent. In an online environment people pay little attention to Terms of Use agreements and can subject themselves to research without thorough knowledge. This issue came to the public light following a study conducted by Facebook in 2014, and published by that company and Cornell University. Facebook conducted a study without consulting an Ethics Committee or IRB where they altered the Facebook News Feeds of roughly 700,000 users to reduce either the amount of positive or negative posts they saw for a week. The study then analyzed if the users' status updates changed during the different conditions. The study was published in the Proceedings of the National Academy of Sciences. The lack of informed consent led to outrage among many researchers and users. Many believed that by potentially altering the mood of users by altering what posts they see, Facebook put at-risk individuals at higher dangers for depression and suicide. However, supporters of Facebook claim that Facebook details that they have the right to use information for research in their terms of use. Others say the experiment is just a part of Facebook's current work, which alters News Feeds algorithms continually to keep people interested and coming back to the site. Others pointed out that this specific study is not unique but rather news organizations constantly try out different headlines using algorithms to elicit emotions and garner clicks or Facebook shares. They say this Facebook study is no different from things people already accept. Still, others say that Facebook broke the law when conducting the experiment on users that did not give informed consent. The Facebook study controversy raises numerous questions about informed consent and the differences in the ethical review process between publicly and privately funded research. Some say Facebook was within its limits and others see the need for more informed consent and/or the establishment of in-house private review boards.\nDuty to share findings.\nSome researchers and ethicists advocate for researchers to share experimental results with their subjects in a way they can understand, both as an ethical obligation and as a way to encourage more participation. In 2023, the government of the United Kingdom proposed making this a requirement. The Ethical, Legal, and Social Implications research program of the National Human Genome Research Institute in the United States has provided some funding for researchers to do this.\nConflicts of interest.\nOther, long-standing controversies underscore the role for conflicts of interest among medical school faculty and researchers. For example, in 2014 coverage of University of California (UC) medical school faculty members has included news of ongoing corporate payments to researchers and practitioners from companies that market and produce the very devices and treatments they recommend to patients. Robert Pedowitz, the former chairman of UCLA's orthopedic surgery department, reported concern that his colleague's financial conflicts of interest could negatively affect patient care or research into new treatments. In a subsequent lawsuit about whistleblower retaliation, the university provided a $10 million settlement to Pedowitz while acknowledging no wrongdoing. Consumer Watchdog, an oversight group, observed that University of California policies were \"either inadequate or unenforced...Patients in UC hospitals deserve the most reliable surgical devices and medication\u2026and they shouldn't be treated as subjects in expensive experiments.\" Other UC incidents include taking the eggs of women for implantation into other women without consent and injecting live bacteria into human brains, resulting in potentially premature deaths.\nHistory.\n\"Informed consent\" is a technical term first used by attorney, Paul G. Gebhard, in the \"Salgo v. Leland Stanford Jr. University Board of Trustees\" court case in 1957. In tracing its history, some scholars have suggested tracing the history of checking for any of these practices:\nThese practices are part of what constitutes informed consent, and their history is the history of informed consent. They combine to form the modern concept of informed consent\u2014which rose in response to particular incidents in modern research. Whereas various cultures in various places practiced informed consent, the modern concept of informed consent was developed by people who drew influence from Western tradition.\nMedical history.\nHistorians cite a series of medical guidelines to trace the history of informed consent in medical practice.\nThe Hippocratic Oath, a Greek text dating to 500 B.C.E., was the first set of Western writings giving guidelines for the conduct of medical professionals. Consent by patients as well as several other, now considered fundamental issues, is not mentioned. The Hippocratic Corpus advises that physicians conceal most information from patients to give the patients the best care. The rationale is a beneficence model for care\u2014the doctor knows better than the patient, and therefore should direct the patient's care, because the patient is not likely to have better ideas than the doctor.\nHenri de Mondeville, a French surgeon who in the 14th century, wrote about medical practice. He traced his ideas to the Hippocratic Oath. Among his recommendations were that doctors \"promise a cure to every patient\" in hopes that the good prognosis would inspire a good outcome to treatment. Mondeville never mentioned getting consent, but did emphasize the need for the patient to have confidence in the doctor. He also advised that when deciding therapeutically unimportant details the doctor should meet the patients' requests \"so far as they do not interfere with treatment\".\nIn Ottoman Empire records there exists an agreement from 1539 in which negotiates details of a surgery, including fee and a commitment not to sue in case of death. This is the oldest identified written document in which a patient acknowledges risk of medical treatment and writes to express their willingness to proceed.\nBenjamin Rush was an 18th-century United States physician who was influenced by the Age of Enlightenment cultural movement. Because of this, he advised that doctors ought to share as much information as possible with patients. He recommended that doctors educate the public and respect a patient's informed decision to accept therapy. There is no evidence that he supported seeking a consent from patients. In a lecture titled \"On the duties of patients to their physicians\", he stated that patients should be strictly obedient to the physician's orders; this was representative of much of his writings. John Gregory, Rush's teacher, wrote similar views that a doctor could best practice beneficence by making decisions for the patients without their consent.\nThomas Percival was a British physician who published a book called \"Medical Ethics\" in 1803. Percival was a student of the works of Gregory and various earlier Hippocratic physicians. Like all previous works, Percival's \"Medical Ethics\" makes no mention of soliciting for the consent of patients or respecting their decisions. Percival said that patients have a right to truth, but when the physician could provide better treatment by lying or withholding information, he advised that the physician do as he thought best.\nWhen the American Medical Association was founded they in 1847 produced a work called the first edition of the \"American Medical Association Code of Medical Ethics\". Many sections of this book are verbatim copies of passages from Percival's \"Medical Ethics\". A new concept in this book was the idea that physicians should fully disclose all patient details truthfully when talking to other physicians, but the text does not also apply this idea to disclosing information to patients. Through this text, Percival's ideas became pervasive guidelines throughout the United States as other texts were derived from them.\nWorthington Hooker was an American physician who in 1849 published \"Physician and Patient\". This medical ethics book was radical demonstrating understanding of the AMA's guidelines and Percival's philosophy and soundly rejecting all directives that a doctor should lie to patients. In Hooker's view, benevolent deception is not fair to the patient, and he lectured widely on this topic. Hooker's ideas were not broadly influential.\nThe principle of informed consent was not legally binding until first recorded in the \"Salgo v. Leland Stanford Jr University Board of Trustees\" case of 1957. Salgo underwent a procedure to evaluate his aortic arteriosclerosis; a contrast (which is a substance used in medical imaging to differentiate internal structures) was injected into his aorta to find blockages, but his legs ended up permanently paralyzed; however, Salgo had not been informed of this risk. This case was one of the first to draw attention to the need for patients to understand the risks and benefits of their procedures, since at that time a lack of informed consent was not considered negligence.\nThe US \"Canterbury v. Spence\" case in 1972 officially established the principle of informed consent in US law. Canterbury underwent a laminectomy to relieve back pain but was not informed of the risk of paralysis. While left by himself, he fell off his bed and was later paralyzed from the waist down; he required further surgeries but was never completely relieved of paralysis in his bowels and bladder. Earlier legal cases had created the underpinnings for informed consent, but his judgment gave a detailed and thought through discourse on the matter. The judgment cites cases going back to 1914 as precedent for informed consent.56\nResearch history.\nHistorians cite a series of human subject research experiments to trace the history of informed consent in research.\nThe U.S. Army Yellow Fever Commission \"is considered the first research group in history to use consent forms.\" In 1900, Major Walter Reed was appointed head of the four man U.S. Army Yellow Fever Commission in Cuba that determined mosquitoes were the vector for yellow fever transmission. His earliest experiments were probably done without formal documentation of informed consent. In later experiments he obtained support from appropriate military and administrative authorities. He then drafted what is now \"one of the oldest series of extant informed consent documents.\" The three surviving examples are in Spanish with English translations; two have an individual's signature and one is marked with an X.\n\"Tearoom Trade\" is the name of a book by American psychologist Laud Humphreys. In it he describes his research into male homosexual acts. In conducting this research he never sought consent from his research subjects and other researchers raised concerns that he violated the right to privacy for research participants.\nOn January 29, 1951, shortly after the birth of her son Joseph, Henrietta Lacks entered Johns Hopkins Hospital in Baltimore with profuse bleeding. She was diagnosed with aggressive cervical cancer and was treated with inserts of radium tubes. During her radiation treatments for the tumor, two samples\u2014one of healthy cells, the other of malignant cells\u2014were removed from her cervix without her knowledge or permission. There is no evidence that the doctor checked the cells for other conditions before passing them on for research. Later that year, 31-year-old Henrietta Lacks died from the cancer. Her cells were capable of surviving and dividing indefinitely when cultured, creating HeLa cells, but the family, which was living in poverty, was not informed until 1973; the family learned the truth when scientists asked for DNA samples after finding that HeLa had contaminated other samples. In 2013, researchers published the genome without the Lacks family's consent. As a result of this incident, pushes were made for major changes in the US's process for informed consent in biospecimen research.\nThe Milgram experiment is the name of a 1961 experiment conducted by American psychologist Stanley Milgram. In the experiment Milgram had an authority figure order research participants to commit a disturbing act of harming another person. After the experiment he would reveal that he had deceived the participants and that they had not hurt anyone, but the research participants were upset at the experience of having participated in the research. The experiment raised broad discussion on the ethics of recruiting participants for research without giving them full information about the nature of the research.\nChester M. Southam used HeLa cells to inject into cancer patients and Ohio State Penitentiary inmates without informed consent to determine if people could become immune to cancer and if cancer could be transmitted.\nNew areas.\nWith the growth of bioethics in the 21st century to include environmental sustainability, some authors, such as Cristina Richie have proposed a \"green consent\". This would include information and education about the climate impact of pharmaceuticals (carbon cost of medications) and climate change health hazards.\nArtificial intelligence (AI) became widespread in the 21st century. It raises many ethical concerns in the medical field, such as the patients\u2019 awareness that they may be interacting with an AI system, as it is being gradually integrated into scanning, surgery, and diagnoses. A number of companies, inspired by the ChatGPT3 system that was released in December 2022, developed AI therapists, which are mental health chatbots that can provide treatment information and perform mental health therapy. Patients must be educated about AI usage to promote trust in the systems.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50356", "revid": "2300502", "url": "https://en.wikipedia.org/wiki?curid=50356", "title": "975", "text": "Calendar year\nYear 975 (CMLXXV) was a common year starting on Friday of the Julian calendar.\nEvents.\n&lt;onlyinclude&gt;\nBy topic.\nReligion.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50357", "revid": "45266726", "url": "https://en.wikipedia.org/wiki?curid=50357", "title": "Larva", "text": "Juvenile form of distinct animals before metamorphosis\nA larva (; pl.: larvae ) is a distinct juvenile form many animals undergo before metamorphosis into their next life stage. Animals with indirect development such as insects, some arachnids, amphibians, or cnidarians typically have a larval phase of their life cycle.\nA larva's appearance is generally very different from the adult form (\"e.g.\" caterpillars and butterflies) including different unique structures and organs that do not occur in the adult form. Their diet may also be considerably different. In the case of smaller primitive arachnids, the larval stage differs by having three instead of four pairs of legs.\nLarvae are frequently adapted to different environments than adults. For example, some larvae such as tadpoles live almost exclusively in aquatic environments but can live outside water as adult frogs. By living in a distinct environment, larvae may be given shelter from predators and reduce competition for resources with the adult population.\nAnimals in the larval stage will consume food to fuel their transition into the adult form. In some organisms like polychaetes and barnacles, adults are immobile but their larvae are mobile, and use their mobile larval form to distribute themselves. These larvae used for dispersal are either planktotrophic (feeding) or lecithotrophic (non-feeding).\nSome larvae are dependent on adults to feed them. In many eusocial Hymenoptera species, the larvae are fed by female workers. In \"Ropalidia marginata\" (a paper wasp) the males are also capable of feeding larvae but they are much less efficient, spending more time and getting less food to the larvae.\nThe larvae of some organisms (for example, some newts) can become pubescent and do not develop further into the adult form. This is a type of neoteny.\nIt is a misunderstanding that the larval form always reflects the group's evolutionary history. This could be the case, but often the larval stage has evolved secondarily, as in insects. In these cases, the larval form may differ more than the adult form from the group's common origins.\nInsect larvae.\nWithin Insects, only Endopterygotes show complete metamorphosis, including a distinct larval stage. Several classifications have been suggested by many entomologists, and the following classification is based on Antonio Berlese classification in 1913. There are four main types of endopterygote larvae types:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50359", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=50359", "title": "Masculinism", "text": ""}
{"id": "50361", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=50361", "title": "Yosemite", "text": ""}
{"id": "50363", "revid": "4513618", "url": "https://en.wikipedia.org/wiki?curid=50363", "title": "Indigo dye", "text": "Chemical compound, food additive and dye\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nIndigo dye is an organic compound with a distinctive blue color. Indigo is a natural dye obtained from the leaves of some plants of the \"Indigofera\" genus, in particular \"Indigofera tinctoria\". Dye-bearing \"Indigofera\" plants were once common throughout the world. It is now produced via chemical routes from aniline. Blue colorants are rare. Since indigo is insoluble, it is also referred to as a pigment (C.I. Pigment Blue 66, C.I.).\nMost indigo dye produced today is synthetic, constituting around 80,000 tonnes each year, as of 2023. It is most commonly associated with the production of denim cloth and blue jeans, where its properties allow for effects such as stone washing and acid washing to be applied quickly.\nUses.\nThe primary use for indigo is as a dye for cotton yarn, mainly used in the production of denim cloth suitable for blue jeans; on average, a pair of blue jeans requires of dye. Smaller quantities are used in the dyeing of wool and silk.\nIndigo carmine, also known as indigo, is an indigo derivative which is also used as a colorant. About 20,000 tonnes are produced annually, again mainly for the production of blue jeans.\nIndigo is also used to dye the skin in Egypt, Kurdistan, and West Africa.\nSources.\nNatural sources.\nA variety of plants have provided indigo throughout history, but most natural indigo was obtained from those in the genus \"Indigofera\", which are native to the tropics, notably the Indian Subcontinent. The primary commercial indigo species in Asia was true indigo (\"Indigofera tinctoria\", also known as \"I. sumatrana\"). A common alternative used in the relatively colder subtropical locations such as Japan's Islands and Taiwan is \"Strobilanthes cusia\".\nUntil the introduction of \"Indigofera\" species from the south, \"Persicaria tinctoria\" (dyer's knotweed) was the most important blue dyestuff in East Asia; however, the crop produced less dyestuff than the average crop of indigo, and was quickly surpassed in favour of the more economical \"Indigofera tinctoria\" plant. In Central and South America, the species grown is \"Indigofera suffruticosa\", also known as \"anil\", and in India, an important species was \"Indigofera arrecta\", Natal indigo. In Europe, \"Isatis tinctoria\", commonly known as woad, was used for dyeing fabrics blue, containing the same dyeing compounds as indigo, also referred to as indigo.\nSeveral plants contain indigo, which, when exposed to an oxidizing source such as atmospheric oxygen, reacts to produce indigo dye; however, the relatively low concentrations of indigo in these plants make them difficult to work with, with the color more easily tainted by other dye substances also present in these plants, typically leading to a greenish tinge.\nThe precursor to indigo is indican, a colorless, water-soluble derivative of the amino acid tryptophan, and \"Indigofera\" leaves contain as much as 0.2\u20130.8% of this compound. Pressing cut leaves into a vat and soaking hydrolyzes the indican, releasing \u03b2-D-glucose and indoxyl. The indoxyl dimerizes in the mixture, and after 12\u201315 hours of fermentation yields the yellow, water-soluble leucoindigo. Subsequent exposure to air forms the blue, water-insoluble indigo dye. The dye precipitates from the fermented leaf solution upon oxidation, but may also be precipitated when mixed with a strong base such as lye. The solids are filtered, pressed into cakes, dried, and powdered. The powder is then mixed with various other substances to produce different shades of blue and purple.\nNatural sources of indigo also include mollusks: the \"Murex\" genus of sea snails produces a mixture of indigo and 6,6'-dibromoindigo (red), which together produce a range of purple hues known as Tyrian purple. Light exposure during part of the dyeing process can convert the dibromoindigo into indigo, resulting in blue hues known as royal blue, hyacinth purple, or tekhelet.\nChemical synthesis.\nGiven its economic importance, indigo has been prepared by many methods. The Baeyer\u2013Drewsen indigo synthesis dates back to 1882. It involves an aldol condensation of o-nitrobenzaldehyde with acetone, followed by cyclization and oxidative dimerization to indigo. This route was highly useful for obtaining indigo and many of its derivatives on the laboratory scale, but proved impractical for industrial-scale synthesis. Johannes Pfleger and Karl Heumann eventually came up with industrial mass production synthesis from aniline by using mercury as a catalyst. The method was discovered by an accident by Karl Heumann in Zurich which involved a broken thermometer.\nThe first commercially practical route of producing indigo is credited to Pfleger in 1901. In this process, \"N\"-phenylglycine is treated with a molten mixture of sodium hydroxide, potassium hydroxide, and sodamide. This highly sensitive melt produces indoxyl, which is subsequently oxidized in air to form indigo. Variations of this method are still in use today. An alternative and also viable route to indigo is credited to Heumann in 1897. It involves heating \"N\"-(2-carboxyphenyl)glycine to in an inert atmosphere with sodium hydroxide. The process is easier than the Pfleger method, but the precursors are more expensive. Indoxyl-2-carboxylic acid is generated. This material readily decarboxylates to give indoxyl, which oxidizes in air to form indigo. The preparation of indigo dye is practised in college laboratory classes according to the original Baeyer\u2013Drewsen route.\nHistory.\nThe oldest known fabric dyed indigo, dated to 6,000 years ago, was discovered in Huaca Prieta, Peru. Many Asian countries, such as India, China, Japan, and Southeast Asian nations have used indigo as a dye (particularly for silk) for centuries. The dye was also known to ancient civilizations in Mesopotamia, Egypt, Britain, Mesoamerica, Peru, Iran, and West Africa. Indigo was also cultivated in India, which was also the earliest major center for its production and processing. The \"Indigofera tinctoria\" species was domesticated in India. Indigo, used as a dye, made its way to the Greeks and the Romans, where it was valued as a luxury product.\nIn Mesopotamia, a neo-Babylonian cuneiform tablet of the seventh century BC gives a recipe for the dyeing of wool, where lapis-colored wool (\"uqnatu\") is produced by repeated immersion and airing of the cloth. Indigo was most probably imported from India. The Romans used indigo as a pigment for painting and for medicinal and cosmetic purposes. It was a luxury item imported to the Mediterranean from India by Arab merchants.\nIndia was a primary supplier of indigo to Europe as early as the Greco-Roman era. The association of India with indigo is reflected in the Greek word for the dye, \"indik\u00f3n\" (, Indian). The Romans Latinized the term to \"indicum\", which passed into Italian dialect and eventually into English as the word indigo.\nIn Bengal indigo cultivators revolted against exploitative working conditions created by European merchants and planters in what became known as the Indigo revolt in 1859. The Bengali play \"Nil Darpan\" by Indian playwright Dinabandhu Mitra was a fictionalized retelling of the revolt.\nThe demand for indigo in the 19th century is indicated by the fact that in 1897, were dedicated to the cultivation of indican-producing plants, mainly in India. By comparison, the country of Luxembourg is .\nIn Europe, indigo remained a rare commodity throughout the Middle Ages. A chemically identical dye derived from the woad plant \"(Isatis tinctoria)\" was used instead. In the late 15th century, the Portuguese explorer Vasco da Gama discovered a sea route to India. This led to the establishment of direct trade with India, the Spice Islands, China, and Japan. Importers could now avoid the heavy duties imposed by Persian, Levantine, and Greek middlemen and the lengthy and dangerous land routes which had previously been used. Consequently, the importation and use of indigo in Europe rose significantly. Much European indigo from Asia arrived through ports in Portugal, the Netherlands, and England. Many indigo plantations were established by European powers in tropical climates. Spain imported the dye from its colonies in Central and South America, and it was a major crop in Haiti and Jamaica, with much or all of the labor performed by enslaved Africans and African Americans. In the Spanish colonial era, intensive production of indigo for the world market in the region of modern El Salvador entailed such unhealthy conditions that the local indigenous population, forced to labor in pestilential conditions, was decimated. Indigo plantations also thrived in the Virgin Islands. However, France and Germany outlawed imported indigo in the 16th century to protect the local woad dye industry. In central Europe, indigo resist dyeing is a centuries-old skill that has received UNESCO Intangible Cultural Heritage of Humanity recognition.\nNewton used \"indigo\" to describe one of the two new primary colors he added to the five he had originally named, in his revised account of the rainbow in \"Lectiones Opticae\" of 1675.\nBecause of its high value as a trading commodity, indigo was often referred to as blue gold.\nIn the early days of Islam, Christians were expected to wear a blue turban or mantle to identify them. In Egypt, which was majority Christian and remained so for generations, this created a high demand for blue dye, particularly indigo. Even though regulation of the distinguishing dress relaxed from the 10-16th centuries, indigo remained a significant part of the Egyptian economy. It lost its Christian connotations and became the color of the people's dress, because it was plentiful and cheap. It remained so until the 19th century. The British taxed farmers who grew indigo to encourage people to grow cotton, and restricted water use in favor of cotton. This also affected flax, which had been a popular local fiber for indigo dyers. This, paired with the import of cheap black cotton fabrics from Britain, caused blue to fall out of favor in Egyptian women's dress in the early 20th century. Egyptian men continued to wear indigo for some time, but the total preference for the dye waned as well. Blue was also a mourning color, and mourning women would dye their faces, arms, and hands blue for the week after the death and periodic grave visitations. Blue cloths were worn and waved around at these times as well to accompany the women's wailing.\nThroughout West Africa, Indigo was the foundation of centuries-old textile traditions. From the Tuareg nomads of the Sahara to Cameroon, clothes dyed with indigo signified wealth. Women dyed the cloth in most areas, with the Yoruba of Nigeria and the Mandinka of Mali particularly well known for their expertise. Among the Hausa male dyers, working at communal dye pits was the basis of the wealth of the ancient city of Kano, and they can still be seen plying their trade today at the same pits. The Tuareg are sometimes called the \"Blue People\" because the indigo pigment in the cloth of their traditional robes and turbans stained their skin dark blue.\nPalestine and Iran also historically produced large amounts of indigo. In Palestine, it was a major industry since at least the 17th century. It was used to dye southern women's dresses, coats in Galilee, pants all over, and men's cloaks. A similar blue-to-black shift occurred due to British colonialism, though blue is still seen on traditional Palestinian dresses with some frequency in synthetic form. Widows would dye their dresses with indigo to cover the other colors, and wear blue veils and belts. Blue was also associated with unmarried girls, whose dresses were embroidered with it.\nIn Japan, indigo became especially important during the Edo period. This was due to a growing textiles industry, and because commoners had been banned from wearing silk, leading to the increasing cultivation of cotton, and consequently indigo \u2013 one of the few substances that could dye it.\nIn North America, indigo was introduced into colonial South Carolina by Eliza Lucas, where it became the colony's second-most important cash crop (after rice). As a major export crop, indigo supported plantation slavery there. In the May and June 1755 issues of \"The Gentleman's Magazine,\" there appeared a detailed account of the cultivation of indigo, accompanied by drawings of necessary equipment and a prospective budget for starting such an operation, authored by South Carolina planter Charles Woodmason. It later appeared as a book. By 1775, indigo production in South Carolina exceeded 1,222,000 pounds. When Benjamin Franklin sailed to France in November 1776 to enlist France's support for the American Revolutionary War, 35 barrels of indigo were on board the \"Reprisal\", the sale of which would help fund the war effort. In colonial North America, three commercially important species are found: the native \"I. caroliniana\", and the introduced \"I. tinctoria\" and \"I. suffruticosa\".\nSynthetic development.\nIn 1865 the German chemist Adolf von Baeyer began working on the synthesis of indigo. He described his first synthesis of indigo in 1878 (from isatin) and a second synthesis in 1880 (from 2-nitrobenzaldehyde). (It was not until 1883 that Baeyer finally determined the structure of indigo.) The synthesis of indigo remained impractical, so the search for alternative starting materials at Badische Anilin- und Soda-Fabrik (BASF) and Hoechst continued. Johannes Pfleger and eventually came up with industrial mass production synthesis.\nThe synthesis of N-(2-carboxyphenyl)glycine from the easy to obtain aniline provided a new and economically attractive route. BASF developed a commercially feasible manufacturing process that was in use by 1897, at which time 19,000 tons of indigo were being produced from plant sources. This had dropped to 1,000 tons by 1914 and continued to contract. By 2011, 50,000 tons of synthetic indigo were being produced worldwide.\nDyeing technology.\nIndigo white.\nIndigo is a challenging dye because it is not soluble in water. To be dissolved, it must undergo a chemical change (reduction). Reduction converts indigo into \"white indigo\" (leuco-indigo). When a submerged fabric is removed from the dyebath, the white indigo quickly combines with oxygen in the air and reverts to the insoluble, intensely colored indigo. When it first became widely available in Europe in the 16th century, European dyers and printers struggled with indigo because of this distinctive property. It also required several chemical manipulations, some involving toxic materials, and presented many opportunities to injure workers. In the 19th century, English poet William Wordsworth referred to the plight of indigo dye workers of his hometown of Cockermouth in his autobiographical poem \"The Prelude\". Speaking of their dire working conditions and the empathy that he felt for them, he wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nA pre-industrial process for production of indigo white, used in Europe, was to dissolve the indigo in stale urine, which contains ammonia. A more convenient reductive agent is zinc. Another pre-industrial method, used in Japan, was to dissolve the indigo in a heated vat in which a culture of thermophilic, anaerobic bacteria was maintained. Some species of such bacteria generate hydrogen as a metabolic product, which convert insoluble indigo into soluble indigo white. Cloth dyed in such a vat was decorated with the techniques of \"shibori\" (tie-dye), \"kasuri\", \"katazome\", and \"tsutsugaki\". Examples of clothing and banners dyed with these techniques can be seen in the works of Hokusai and other artists.\nDirect printing.\nTwo different methods for the direct application of indigo were developed in England in the 18th century and remained in use well into the 19th century. The first method, known as 'pencil blue' because it was most often applied by pencil or brush, could be used to achieve dark hues. Arsenic trisulfide and a thickener were added to the indigo vat. The arsenic compound delayed the oxidation of the indigo long enough to paint the dye onto fabrics.\nThe second method was known as 'China blue' due to its resemblance to Chinese blue-and-white porcelain. Instead of using an indigo solution directly, the process involved printing the insoluble form of indigo onto the fabric. The indigo was then reduced in a sequence of baths of iron(II) sulfate, with air oxidation between each immersion. The China blue process could make sharp designs, but it could not produce the dark hues possible with the pencil blue method.\nAround 1880, the 'glucose process' was developed. It finally enabled the direct printing of indigo onto fabric and could produce inexpensive dark indigo prints unattainable with the China blue method.\nSince 2004, freeze-dried indigo, or instant indigo, has become available. In this method, the indigo has already been reduced, and then freeze-dried into a crystal. The crystals are added to warm water to create the dye pot. As in a standard indigo dye pot, care has to be taken to avoid mixing in oxygen. Freeze-dried indigo is simple to use, and the crystals can be stored indefinitely as long as they are not exposed to moisture.\nChemical properties.\nIndigo dye is a dark blue crystalline powder that sublimes at . It is insoluble in water, alcohol, or ether, but soluble in DMSO, chloroform, nitrobenzene, and concentrated sulfuric acid. The chemical formula of indigo is C16H10N2O2.\nThe molecule absorbs light in the orange part of the spectrum (\"\u03bb\"max=613\u00a0nm). The compound owes its deep color to the conjugation of the double bonds, i.e. the double bonds within the molecule are adjacent and the molecule is planar. In indigo white, the conjugation is interrupted because the molecule is non-planar.\nIndigo derivatives.\nThe benzene rings in indigo can be modified to give a variety of related dyestuffs. Thioindigo, where the two NH groups are replaced by S atoms, is deep red. Tyrian purple is a dull purple dye that is secreted by a common Mediterranean snail. It was highly prized in antiquity. In 1909, its structure was shown to be 6,6'-dibromoindigo (red). 6-bromoindigo (purple) is a component as well. It has never been produced on a commercial basis. The related Ciba blue (5,7,5',7'-tetrabromoindigo) is, however, of commercial value.\nIndigo and its derivatives featuring intra- and intermolecular hydrogen bonding have very low solubility in organic solvents. They can be made soluble using transient protecting groups such as the tBOC group, which suppresses intermolecular bonding. Heating of the tBOC indigo results in efficient thermal deprotection and regeneration of the parent H-bonded pigment.\nTreatment with sulfuric acid converts indigo into a blue-green derivative called indigo carmine (sulfonated indigo). It became available in the mid-18th century. It is used as a colorant for food, pharmaceuticals, and cosmetics as FD&amp;C Blue No. 2.\nIndigo as an organic semiconductor.\nIndigo and some of its derivatives are known to be ambipolar organic semiconductors when deposited as thin films by vacuum evaporation.\nSafety and the environment.\nIndigo has a low oral toxicity, with an LD50 of 5\u00a0g/kg (0.5% of total mass) in mammals. In 2009, large spills of blue dyes had been reported downstream of a blue jeans manufacturer in Lesotho.\nThe compound has been found to act as an agonist of the aryl hydrocarbon receptor.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50365", "revid": "432220019", "url": "https://en.wikipedia.org/wiki?curid=50365", "title": "Romanov Dynasty", "text": ""}
{"id": "50366", "revid": "7417578", "url": "https://en.wikipedia.org/wiki?curid=50366", "title": "Marie Romanov", "text": ""}
{"id": "50367", "revid": "4460044", "url": "https://en.wikipedia.org/wiki?curid=50367", "title": "Byzantine emperors", "text": ""}
{"id": "50368", "revid": "50283045", "url": "https://en.wikipedia.org/wiki?curid=50368", "title": "Lambert Simnel", "text": "Pretender to the throne of King Henry VII of England\nLambert Simnel (c. 1477 \u2013 after 1534) was a pretender to the throne of England. In 1487, his claim to be Edward Plantagenet, 17th Earl of Warwick, threatened the newly established reign of Henry VII (1485\u20131509). Simnel became the figurehead of a Yorkist rebellion organised by John de la Pole, Earl of Lincoln. The rebellion was crushed in 1487. Simnel was pardoned because of his tender years, and was thereafter employed by the royal household as a scullion.\nEarly life.\nSimnel was born around 1477. His real name is not known\u2014contemporary records call him John, not Lambert, and even his surname is suspect. Different sources have different claims of his parentage, from a baker and tradesman to an organ builder. Most definitely, he was of humble origin. At the age of about ten, he was taken as a pupil by an Oxford-trained priest named Richard Simon (or Richard Symonds / Richard Simons / William Symonds) who apparently decided to become a kingmaker. He tutored the boy in courtly manners and contemporaries described the boy as handsome. He was taught the necessary etiquette and was well educated by Simon.\nPretender.\nSimon noticed a striking resemblance between Lambert and the sons of King Edward IV, so he initially intended to present Simnel as Richard, Duke of York, son of Edward IV, the younger of the vanished Princes in the Tower. However, when he heard rumours (at the time false) that the Earl of Warwick had died during his imprisonment in the Tower of London, he changed his mind. The real Warwick was a boy of about the same age, having been born in 1475, and had a claim to the throne as the son of George Plantagenet, Duke of Clarence, King Edward IV's executed brother. Warwick was a touchstone for Yorkist affections, and people still wore his badge of the bear and ragged staff.\nAccording to James A. Williamson, Simnel was merely a figurehead for a rebellion that was already being planned by the Yorkists:\nHe was merely a commonplace tool to be used for important ends, and the attempt to overthrow Henry VII would have taken place had Simnel never existed. The Yorkist leaders were determined on a serious push, rising of their party in England supported by as great a force as possible from overseas.\nSimon spread a rumour that Warwick had actually escaped from the Tower and was under his guardianship. He gained some support from Yorkists. He took Simnel to Ireland where there was still support for the Yorkist cause, and presented him to the Lord Deputy of Ireland, the Earl of Kildare. Kildare was willing to support the story and invade England to overthrow King Henry. Simnel was paraded through the streets, carried on the shoulders of \"the tallest man of the time\", an individual called D'Arcy of Platten (this was evidently Sir William Darcy, an ally of Kildare, who is known to have been exceptionally tall). When Henry heard about what was going on, he arranged for the real Earl of Warwick to be taken from the tower and paraded through London, presumably to disprove the rumours of his death or escape. This did not prevent the rebellion, likely because insufficient infrastructure and methods of transport meant news spread slowly. \n\"Coronation\".\nOn 24 May 1487 Simnel was crowned in Christ Church Cathedral in Dublin as \"King Edward VI\". He was about 10 years old. Lord Kildare collected an army of Irish soldiers under the command of his younger brother, Thomas FitzGerald of Laccagh.\nJohn de la Pole, 1st Earl of Lincoln, formerly the designated successor of his uncle the late King Richard III, joined the conspiracy against Henry VII. He fled to Burgundy, where Warwick's aunt Margaret of York, the Dowager Duchess of Burgundy, kept her court. Lincoln claimed that he had taken part in young Warwick's supposed escape. He also met Viscount Lovell, who had supported a failed Yorkist uprising in 1486. Margaret collected 2,000 Flemish mercenaries and shipped them to Ireland under the command of Martin Schwartz, a noted military leader of the time. They arrived in Ireland on 5 May. King Henry was informed of this and began to gather troops.\nBattle of Stoke Field.\nOn 5 June 1487 Simnel's army\u2014mainly Flemish and Irish troops\u2014landed on Piel Island in the Furness area of Lancashire and were joined by some English supporters. However, most local nobles, with the exception of Sir Thomas Broughton, did not join them. Henry had been receiving information about events in Ireland, although it was vague and conflicting. Thanks to existing plans to invade Ireland he was able to react speedily to the invasion and had begun mustering troops as early as February. A lack of English support led Simnel's army to change their plans, deciding their only chance of success was one swift and decisive battle. On 15 June 1487, they set up camp near the small village of East Stoke, Nottinghamshire, near Newark-on-Trent. The royal army of 12,000 set up camp away.\nOn 16 June 1487 the rebels clashed with the King's army, at the Battle of Stoke Field in Nottinghamshire, and were defeated. Lincoln and Thomas FitzGerald were killed. Lovell went missing and was rumoured to have escaped to Scotland with Sir Thomas Broughton and hidden to avoid retribution.\nSimons avoided execution due to his priestly status, but was imprisoned for life. Kildare, who had remained in Ireland, was pardoned.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50371", "revid": "46326867", "url": "https://en.wikipedia.org/wiki?curid=50371", "title": "Photios I of Constantinople", "text": "Ecumenical Patriarch of Constantinople from 858 to 867 and from 877 to 886\nPhotios I of Constantinople (, \"Ph\u014dtios\"; c. 815\u20146 February 893),[a] also spelled \"Photius\" (), was the Ecumenical Patriarch of Constantinople from 858 to 867 and from 877 to 886. He is recognized in the Eastern Orthodox Church as 'Saint Photius the Great'.\nPhotios I is widely regarded as the most powerful and influential church leader of Constantinople subsequent to John Chrysostom's archbishopric around the turn of the fifth century. He is also viewed as the most important intellectual of his time\u2014\"the leading light of the ninth-century renaissance\". He was a central figure in both the conversion of the Slavs to Christianity and the Photian schism, and is considered \"[t]he great systematic compiler of the Eastern Church, who occupies a similar position to that of Gratian in the West,\" and whose \"collection in two parts... formed and still forms the classic source of ancient Church Law for the Greek Church\".\nPhotios was a well-educated man from a noble Constantinopolitan family. His mother was the sister of the previous patriarch of Constantinople John VII of Constantinople, and his great-granduncle was another previous patriarch of Constantinople, Saint Tarasius. He intended to be a monk but chose to be a scholar and statesman instead. In 858, Emperor Michael III (r. 842\u2013867) decided to confine Patriarch Ignatius in order to force him into resignation, and Photius, still a layman, was appointed to replace him. Amid power struggles between the pope and the Byzantine emperor, Ignatius was reinstated. Photios I resumed the position when Ignatius died (877), by order of the Byzantine emperor. The new Pope John VIII, approved Photios's reinstatement. Catholics regard as legitimate a Fourth Council of Constantinople (Catholic Church) anathematising Photios I, while Eastern Orthodox regard as legitimate a subsequent Fourth Council of Constantinople (Eastern Orthodox), reversing the former. The contested councils mark the end of unity represented by the first seven Ecumenical Councils.\nSecular life.\nMost of the popular sources treating Photios's life are written by persons hostile to him. The chief contemporary authority for the life of Photios is his bitter enemy, Niketas David Paphlagon, the biographer of his rival Ignatius. Modern scholars are thus cautious when assessing the accuracy of the information these sources provide.[b] Little is known of Photios's origin and early years. It is known that he was born into a notable family and that his uncle Saint Tarasius had been the patriarch of Constantinople from 784\u2013806 under both Empress Irene of Athens (r. 797\u2013802) and Emperor Nikephoros I (r. 802\u2013811). During the second Iconoclasm, which began in 814, his family suffered persecution since his father, Sergios, was a prominent iconophile. Sergios's family returned to favor only after the restoration of the icons in 842. Certain scholars assert that Photius was, at least in part, of Armenian descent,[c] while others merely refer to him as a \"Greek Byzantine\". Byzantine writers also report that Emperor Michael III (r. 842\u2013867) once angrily called Photios \"Khazar-faced\", but whether this was a generic insult or a reference to his ethnicity is unclear.\nAlthough Photios had an excellent education, we have no information about how he received this education. The famous library he possessed attests to his enormous erudition (theology, history, grammar, philosophy, law, the natural sciences, and medicine). Most scholars believe that he never taught at Magnaura or at any other university; Vasileios N. Tatakes asserts that, even while he was patriarch, Photios taught \"young students passionately eager for knowledge\" at his home, which \"was a center of learning\". He was a friend of the renowned Byzantine scholar and teacher Leo the Mathematician.[d]\nPhotios I says that, when he was young, he had an inclination for the monastic life, but instead he started a secular career. The way to public life was probably opened for him by (according to one account) the marriage of his brother Sergios to Irene, a sister of Empress Theodora, who upon the death of her husband Emperor Theophilos (r. 829\u2013842) in 842, had assumed the regency of the Byzantine Empire. Photius became a captain of the guard (\"protospatharios\") and subsequently chief imperial secretary (\"Protasekretis\"). At an uncertain date, Photios participated in an embassy to the Abbasids of Baghdad.\nPhotios achieved a dazzling reputation as a scholar. In a feud with Patriarch Ignatius, Photios invented a fanciful theory that people have two souls, for the sole purpose of tricking Ignatius into embarrassing himself by being seen to take it seriously, whereupon Photios withdrew his proposal and admitted he had not been serious. The historian John Julius Norwich described this as \"perhaps the only really satisfactory practical joke in the whole history of theology\".\nPatriarch of Constantinople.\nPhotios's ecclesiastical career took off spectacularly after \"Caesar\" Bardas and his nephew, the youthful Emperor Michael III, put an end to the administration of the regent Theodora and the Logothetes tou dromou Theoktistos in 856. In 858, Bardas found himself opposed by the then Patriarch Ignatius of Constantinople, who refused to admit him into Hagia Sophia, since it was believed that he was having an affair with his widowed daughter-in-law. In response, Bardas and Michael engineered Ignatius's confinement and removal on the charge of treason, thus leaving the patriarchal throne empty. The throne was soon filled with a kinsman of Bardas, Photios himself, who was tonsured a monk on 20 December 858, and on the four following days was successively ordained lector, sub-deacon, deacon and priest, and then on Christmas Day, the patronal feast of Constantinople's cathedral, Hagia Sophia, Photios I was consecrated a bishop and installed as patriarch.\nThe confinement and removal of Ignatius and the speedy promotion of Photius at first caused only internal controversy within the Church of Constantinople, and in 859 a local council was held, examining the issue and confirming the removal of Ignatius and election of Photios. In the same time, partisans of Ignatius decided to appeal to the Holy Roman and Catholic Church, thus initiating ecclesiastical controversy on an ecumenical scale as the Pope and the rest of the western bishops took up the cause of Ignatius. The latter's confinement and removal without a formal ecclesiastical trial meant that Photios's election was uncanonical, and eventually Pope Nicholas I sought to involve himself in determining the legitimacy of the succession. His legates were dispatched to Constantinople with instructions to investigate, but finding Photios well ensconced, they acquiesced in the confirmation of his election at a synod in 861. On their return to Rome, they discovered that this was not at all what Nicholas had intended, and in 863 at a synod in Rome, the Supreme Pontiff deposed Photios I, and reappointed Ignatius as the rightful patriarch, triggering a schism. Four years later, Photios I was to respond on his own part by calling a Council and attempting to excommunicate the Holy Father on grounds of heresy\u2014over the question of the double procession of the Holy Spirit. The situation was additionally complicated by the question of papal authority over the entire Church and by disputed jurisdiction over newly converted Bulgaria.\nThis state of affairs changed with the murder of Photios's patron Bardas in 866 and of Emperor Michael III in 867, by his colleague Basil I, who now usurped the throne. Photios I was deposed as patriarch, not so much because he was a prot\u00e9g\u00e9 of Bardas and Michael, but because Basil I was seeking an alliance with the Pope and the Western emperor. Photios I was removed from his office and banished about the end of September 867, and Ignatius was reinstated on 23 November. Photios I was condemned by the Council of 869\u2013870, thus putting an end to the schism. During his second patriarchate, however, Ignatius followed a policy not very different from that of Photios I.\nNot long after his condemnation, Photios I had reingratiated himself with Basil I and became tutor to the Byzantine emperor's children. From surviving letters of Photios I written during his exile at the Skepi monastery, it appears that the ex-patriarch brought pressure to bear on the Byzantine emperor to restore him. Ignatius' biographer argues that Photios forged a document relating to the genealogy and rule of Basil I's family, and had it placed in the imperial library where a friend of his was a librarian. According to this document, the Byzantine emperor's ancestors were not mere peasants as everyone believed but descendants of the Arsacid dynasty of Armenia. True or not, this story does reveal Basil I's dependence on Photios I for literary and ideological matters. Following Photios I's recall, Ignatius and the ex-patriarch met and publicly expressed their reconciliation. When Ignatius died on 23 October 877, it was a matter of course that his old opponent replaced him on the patriarchal throne three days later. Shaun Tougher asserts that from this point on Basil I no longer simply depended on Photios, but in fact he was dominated by him.\nPhotios I now obtained the formal recognition of the Christian world in a council convened at Constantinople in November 879. The legates of Pope John VIII attended, prepared to acknowledge Photios I as legitimate patriarch, a concession for which the pope was much censured by Latin opinion. The patriarch stood firm on the main points contested between the Eastern and Western Churches: the demand of an apology to the Pope, the ecclesiastical jurisdiction over Bulgaria, and the addition of the \"Filioque\" to the Nicene Creed by the Western church. Eventually, Photios refused to apologize or accept the \"Filioque\", and the papal legates made do with his return of Bulgaria to Rome. This concession, however, was purely nominal, as Bulgaria's return to the Byzantine rite in 870 had already secured for it an autocephalous church. Without the consent of Boris I of Bulgaria (r. 852\u2013889), the papacy was unable to enforce its claims. Pope Adrian III chose a policy of appeasement and sent between 884 and 885 bishop Theodosius of Oria to transmit notice of his election and a synodal letter to Photios about faith and the \"Filioque\".\nPhotios I also promoted a policy of religious reconciliation with the Armenian kingdom to the east of the empire. He sought to bridge the confessional differences between the Greek Orthodox and Armenian churches on two separate occasions, once in 862 and again in 877, but his efforts ultimately proved unsuccessful.\nDuring the altercations between Emperor Basil I and his heir Leo VI the Wise, Photios took the side of the Byzantine emperor. In 883, Basil I accused Leo VI of conspiracy and confined the prince to the palace; he would have even had Leo VI blinded had he not been dissuaded by Photios I and Stylianos Zaoutzes, the father of Zoe Zaoutzaina, Leo's mistress. In 886, Basil I discovered and punished a conspiracy by the domestic of the \"Hikanatoi\" John Kourkouas and many other officials. In this conspiracy, Leo VI was not implicated, but Photios I was possibly one of the conspirators against Basil I's authority.\nBasil I died in 886 injured while hunting, according to the official story. Warren Treadgold believes that this time the evidence points to a plot on behalf of Leo VI, who became emperor, and deposed Photios I, although the latter had been his tutor. Photios I was replaced by the Byzantine emperor's brother Stephen I of Constantinople and sent into exile to the monastery of Bordi in Armenia. It is confirmed from letters to and from Pope Stephen V that Leo VI extracted a resignation from Photios I. In 887, Photios I and his prot\u00e9g\u00e9, Theodore Santabarenos, were put on trial for treason before a tribunal headed by senior officials, headed by Andrew the Scythian. Although the sources sympathetic to Photios I give the impression that the trial ended without a conviction, the chronicle of Pseudo-Simeon clearly states that Photios was banished to the monastery of Gordon, where he later died. Latin sources confirm that while he did not die in a state of complete excommunication, having been reinstated by a council which was approved by Pope John VIII, his ecclesiastical career was viewed in utter disgrace by Catholic authorities and many of his theological opinions were condemned posthumously. Yet it appears that he did not remain reviled for the remainder of his life.\nPhotios I continued his career as a writer throughout his exile, and Leo VI probably rehabilitated his reputation within the next few years; in his \"Epitaphios\" on his brothers, a text probably written in 888, the Emperor presents Photios I favorably, portraying him as the legitimate archbishop, and the instrument of ultimate unity, an image that jars with his attitude to the patriarch in the previous year. Confirmation that Photios was rehabilitated comes upon his death\u2014according to some chronicles, his body was permitted to be buried in Constantinople. In addition, according to the anti-Photian biographer of Ignatius, partisans of the ex-patriarch after his death endeavored to claim for him the \"honor of sainthood\". Furthermore, a leading member of Leo VI's court, Leo Choirosphaktes, wrote poems commemorating the memory of several prominent contemporary figures, such as Leo the Mathematician and the Patriarch Stephen I, and he also wrote one on Photius. Shaun Tougher notes, however, that \"yet Photius I's passing does seem rather muted for a great figure of Byzantine history [...] Leo VI [...] certainly did not allow him back into the sphere of politics, and it is surely his absence from this arena that accounts for his quiet passing.\"\nVeneration.\nAfter his death, Photios began to be venerated as saint in environs of Constantinople. His name features in a manuscript of the Typicon of the Great Church of Constantinople dated to the middle of the tenth century, where he is referred to a saint with a day of commemoration of February 6. According to Francis Dvornik, Photios I must have been venerated as a saint in the second half of the tenth century at the very latest.\nThe contemporary Eastern Orthodox Church venerates Photios I as a saint, with his feast day being 6 February.\nAssessments.\nPhotios I is one of the most famous figures not only of 9th-century Byzantium but of the entire history of the Byzantine Empire. One of the most learned men of his age, and revered\u2014even by some of his opponents and detractors\u2014as the most prolific theologian of his time, he has earned his fame due to his part in ecclesiastical conflicts, and also for his intellect and literary works.\nAnalyzing his intellectual work, Tatakes regards Photios as \"mind turned more to practice than to theory\". He believes that thanks to Photios I, humanism was added to Orthodoxy as a basic element of the national consciousness of the medieval Byzantines, returning it to the place it had had in the early Byzantine period. Tatakes also argues that having understood this national consciousness, Photios I emerged as a defender of the Greek nation and its spiritual independence in his debates with the Western Church. Adrian Fortescue regards him as \"one of the most wonderful men of all the Middle Ages\", and stresses that \"had [he] not given his name to the great schism, he would always be remembered as the greatest scholar of his time\". Yet, Fortescue is equally adamant of his condemnation of Photios I's involvement in the Schism: \"And yet the other side of his character is no less evident. His insatiable ambition, his determination to obtain and keep the patriarchal see, led him to the extreme of dishonesty. His claim was worthless. That Ignatius was the rightful patriarch as long as he lived, and Photius an intruder, cannot be denied by any one who does not conceive the Church as merely the slave of a civil government. And to keep this place Photios I descended to the lowest depth of deceit\".\nWritings.\n\"Bibliotheca\".\nThe most important of the works of Photios I is his \"Bibliotheca\" or \"Myriobiblon\", a collection of extracts and abridgements of 280 volumes of previous authors (usually cited as Codices), the originals of which are now to a great extent lost. The work is especially rich in extracts from historical writers.\nTo Photios I, we are indebted for almost all we possess of Ctesias, Memnon of Heraclea, Conon, the lost books of Diodorus Siculus, and the lost writings of Arrian. Theology and ecclesiastical history are also very fully represented, but poetry and ancient philosophy are almost entirely ignored. It seems that he did not think it necessary to deal with those authors with whom every well-educated man would naturally be familiar. The literary criticisms, generally distinguished by keen and independent judgment, and the excerpts vary considerably in length. The numerous biographical notes are probably taken from the work of Hesychius of Miletus.\nSome older scholarship speculated that the \"Bibliotheca\" was compiled in Baghdad at the time of Photios's embassy to the Abbasid court since many of the mentioned works were rarely cited during the so-called Byzantine Dark Ages c. 630\u2014c. 800, and it was known that the Abbasids were interested in works of Greek science and philosophy. However, specialists of this period of Byzantine history, such as Paul Lemerle, have shown that Photios I could not have compiled his \"Bibliotheca\" in Baghdad because he clearly states in both his introduction and his postscript that when he learned of his appointment to the embassy, he sent his brother a summary of books that he read \"previously\", \"since the time I learned how to understand and evaluate literature\" i.e. since his youth. Moreover, the Abbasids were interested only in Greek science, philosophy and medicine; they did not have Greek history, rhetoric, or other literary works translated; nor did they have Christian patristic writers translated. Yet the majority of works in \"Bibliotheca\" are by Christian patristic authors, and most of the secular texts in \"Bibliotheca\" are histories, grammars or literary works, usually rhetoric, rather than science, medicine or philosophy. This further indicates that the majority of the works cannot have been read while Photios I was in the Abbasid empire.\nOther works.\nThe \"Lexicon\" (\u039b\u03ad\u03be\u03b5\u03c9\u03bd \u03a3\u03c5\u03bd\u03b1\u03b3\u03c9\u03b3\u03ae), published later than the \"Bibliotheca\", was probably in the main the work of some of his pupils. It was intended as a book of reference to facilitate the reading of old classical and sacred authors, whose language and vocabulary were out of date. For a long time, the only manuscripts of the \"Lexicon\" were the \"Codex Galeanus\", which passed into the library of Trinity College, Cambridge and Berolinensis grace., 22 October, both of which were incomplete. But in 1959, Linos Politis of the University of Thessaloniki discovered a complete manuscript, codex Zavordensis 95, in the Zavorda Monastery (Greek: \u0396\u03ac\u03b2\u03bf\u03c1\u03b4\u03b1) in Grevena, Greece, where it still resides.\nHis most important theological work is the \"Amphilochia\", a collection of some 300 questions and answers on difficult points in Scripture, addressed to Amphilochius, archbishop of Cyzicus. Other similar works are his treatise in four books against the Manichaeans and Paulicians, and his controversy with the Latins on the Procession of the Holy Spirit. Photius also addressed a long letter of theological advice to the newly converted Boris I of Bulgaria. Numerous other \"Epistles\" also survive.\nPhotios I is also the writer of two \"mirrors of princes\", addressed to Boris-Michael of Bulgaria (Epistula 1, ed. Terzaghi) and to Leo VI the Wise (Admonitory Chapters of Basil I).\nPhotios I's epitome of Philostorgius' \"Church History\" is the principal source for the work, which is now lost.\nThe first English translation, by Holy Transfiguration Monastery, of the \"Mystagogy of the Holy Spirit\" by Photios was published in 1983. Another translation was published in 1987 with a preface by Archimandrite (now Archbishop) Chrysostomos of Etna.\nNotes and references.\nNotes.\n^\u00a0a:\u00a0The exact dates of Photios's birth and death are not known. Most sources list circa 810 and others circa 820 as his year of birth. He died some time between 890 and 895 (probably 891 or 893).\n^\u00a0b:\u00a0The case of pseudo-Simeon's \"Chronicle\" is characteristic: the author argues that Photios was educated after an agreement he concluded with a Jewish magician who offered him knowledge and secular recognition, in case he renounced his faith.\n^\u00a0c:\u00a0David Marshall Lang argues that \"Photius, John the Grammarian and Leo the Mathematician, was only one of many Byzantine scholars of Armenian descent\". Peter Charanis notes that \"John the Grammarian, Photius, Caesar Bardas and Leo the Philosopher seem to have been the prime movers. All four were, at least in part, of Armenian descent [...] as for Photius, the fact is that his mother Irene was the sister of Arshavir, the Arshavir who had married Calomaria the sister of Bardas and the empress Theodora.\" Nicholas Adontz stresses that \"Arshavir, Photius' uncle, must not be confused with Arshavir, the brother of John the Grammarian\".\n^\u00a0d:\u00a0N. G. Wilson regards Leo the Mathematician as Photios's teacher, but Paul Lemerle notes that Leo was not one of the persons with whom Photios had a correspondence.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\nPrimary sources.\nRecent years have seen the first translations into English of a number of primary sources about Photios and his times:"}
{"id": "50372", "revid": "915833", "url": "https://en.wikipedia.org/wiki?curid=50372", "title": "Paul Revere", "text": "American silversmith and military officer (1735\u20131818)\nPaul Revere (; December 21, 1734 O.S. (January 1, 1735 N.S.)\u00a0\u2013 May 10, 1818) was an American silversmith, military officer and industrialist who played a major role during the opening months of the American Revolutionary War in Massachusetts, engaging in a midnight ride in 1775 to alert nearby minutemen of the approach of British troops prior to the battles of Lexington and Concord. \nBorn in the North End of Boston, Revere eventually became a prosperous and prominent Bostonian, deriving his income from silversmithing and engraving. During the American Revolution, he was a strong supporter of the Patriot cause and joined the Sons of Liberty. His midnight ride transformed him into an American folk hero, being dramatized in Henry Wadsworth Longfellow's 1861 poem, \"Paul Revere's Ride\". He also helped to organize an intelligence and alarm system to keep watch on the movements of British forces. Revere later served as an officer in the Massachusetts Militia, though his service ended after the Penobscot Expedition, one of the most disastrous American campaigns of the American Revolutionary War, for which he was absolved of blame.\nFollowing the war, Revere returned to his silversmith trade. He used the profits from his expanding business to finance his work in iron casting, bronze bell and cannon casting, and the forging of copper bolts and spikes. In 1800, he became the first American to successfully roll copper into sheets for use as sheathing on naval vessels.\nEarly life and education.\nRevere was born in the North End, Boston, on December 21, 1734, according to the Old Style calendar then in use, or January 1, 1735, in the modern calendar. His father, Apollos Rivoire, a French Huguenot who came to Boston at the age of 13, had been apprenticed to the silversmith John Coney. By the time he married Deborah Hitchborn, a member of a long-standing Boston family that owned a small shipping wharf, in 1729, Rivoire had anglicized his name to Paul Revere. The Hitchborn family was of English origin; Deborah's maternal great grandparents, David and Catherine Hitchbourn, arrived in Boston, Massachusetts, in 1641 from Boston, England. Their son, Paul Revere, was the third of 12 children and eventually the eldest surviving son. Revere grew up in the environment of the extended Hitchborn family, and never learned his father's native language.\nAt the age of thirteen, Paul Revere left school and became an apprentice to his father. Silversmithing afforded young Paul connections with a cross-section of Boston society; these would serve him well when he became active in the American Revolution. \nIn 1750, aged 15, Revere was part of the first group of change ringers to ring the new bells (cast in 1744) at Christ Church, in the north of Boston (the Old North Church). Revere eventually began attending the services of the political and provocative Jonathan Mayhew at the West Church. His father, who had raised him in the Calvinist New Brick Church, did not approve, and as a result father and son came to blows on one occasion. Revere relented and returned to his father's church, although he did become friends with Mayhew, and returned to the West Church in the late 1760s.\nRevere's father died in 1754, when Paul was legally too young to officially be the master of the family silver shop. In February 1756, during the French and Indian War (the North American theater of the Seven Years' War), he enlisted in the provincial army. Possibly he made this decision because of the weak economy, since army service promised consistent pay. Commissioned a second lieutenant in a provincial artillery regiment, he spent the summer at Fort William Henry at the southern end of Lake George in New York as part of an abortive plan for the capture of Fort St. Fr\u00e9d\u00e9ric. He did not stay long in the army, but returned to Boston and assumed control of the silver shop in his own name. On August 4, 1757, he married Sarah Orne (1736\u20131773); their first child was born eight months later. He and Sarah had eight children, but two died young, and only one, Mary, survived her father.\n1765\u20131774: the gathering storm of revolution.\nRevere's business began to suffer when the British economy entered a recession in the years following the Seven Years' War, and declined further when the Stamp Act of 1765 resulted in a further downturn in the Massachusetts economy. Business was so poor that an attempt was made to seize his property in late 1765. To help make ends meet he even took up dentistry, a skill set he was taught by a practicing surgeon who lodged at a friend's house. One client was Joseph Warren, a local physician and political opposition leader with whom Revere formed a close friendship. Revere and Warren, in addition to having common political views, were also both active in the same local Masonic lodges.\nAlthough Revere was not one of the \"Loyal Nine\"\u2014organizers of the earliest protests against the Stamp Act\u2014he was well connected with its members, who were laborers and artisans. Revere did not participate in some of the more raucous protests, such as the attack on the home of Lieutenant Governor Thomas Hutchinson. In 1765, a group of militants who would become known as the Sons of Liberty formed, of which Revere was a member. From 1765 on, in support of the dissident cause, he produced engravings and other artifacts with political themes. Among these engravings are a depiction of the arrival of British troops in 1768 (which he termed \"an insolent parade\") and a bowl commemorating the Massachusetts assembly's refusal to retract the Massachusetts Circular Letter. (This letter, adopted in response to the 1767 Townshend Acts, called for united colonial action against the acts. King George III had issued a demand for its retraction.)\nProbably most famous, is his depiction of the March 1770 Boston Massacre (see illustration), engraved by Revere from Henry Pelham's drawing without permission. It was colored by a third man and printed by a fourth but none was credited. It stated \"Engraved, Printed, &amp; Sold by Paul Revere Boston\". On March 29, 1770, Pelham wrote \"When I heard that you was cutting a plate...I thought it impossible, as I knew you was not capable of doing it unless you coppied it from mine...\" He said he thought his drawing entrusted to someone honourable who wouldn't take undue advantage. Further, he felt himself robbed \"as truly as if you had plundered me on the highway\". His letter to Revere ended with the hope that the World would be aware of Revere's dishonourable actions.\nIn 1770 Revere purchased a house, now a museum on North Square in Boston's North End. The house provided space for his growing family while he continued to maintain his shop at nearby Clark's Wharf. Sarah died in 1773, and on October 10 of that year, Revere married Rachel Walker (1745\u20131813). They had eight children, three of whom died young.\nIn November 1773 the merchant ship \"Dartmouth\" arrived in Boston harbor carrying the first shipment of tea made under the terms of the Tea Act. This act authorized the British East India Company to ship tea (of which it had huge surpluses due to colonial boycotts organized in response to the Townshend Acts) directly to the colonies, bypassing colonial merchants. Passage of the act prompted calls for renewed protests against the tea shipments, on which Townshend duties were still levied. Revere and Warren, as members of the informal North End Caucus, organized a watch over the \"Dartmouth\" to prevent the unloading of the tea. Revere took his turns on guard duty, and was one of the ringleaders in the Boston Tea Party of December 16, when colonists dumped tea from the \"Dartmouth\" and two other ships into the harbor.\nFrom December 1773 to November 1775, Revere served as a courier for the Boston Committee of Public Safety, traveling to New York and Philadelphia to report on the political unrest in Boston. Research has documented 18 such rides. Notice of some of them was published in Massachusetts newspapers, and British authorities received further intelligence of them from Loyalist Americans. In 1774, his cousin John on the island of Guernsey wrote to Paul that John had seen reports of Paul's role as an \"express\" (courier) in London newspapers.\nIn 1774, the military governor of Massachusetts, General Thomas Gage, dissolved the provincial assembly on orders from Great Britain. Governor Gage also closed the port of Boston and all over the city forced private citizens to quarter (provide lodging for) soldiers in their homes.\nDuring this time, Revere and a group of 30 \"mechanics\" began meeting in secret at his favorite haunt, the \"Green Dragon\", to coordinate the gathering and dissemination of intelligence by \"watching the Movements of British Soldiers\". Around this time Revere regularly contributed politically charged engravings to the recently founded Patriot monthly, \"Royal American Magazine\".\nHe rode to Portsmouth, New Hampshire, in December 1774 upon rumors of an impending landing of British troops there, a journey known in history as the Portsmouth Alarm. Although the rumors were false, his ride sparked a rebel success by provoking locals to raid Fort William and Mary, defended by just six soldiers, for its gunpowder supply.\nWar years.\nBecause Boston was besieged after the battles of Lexington and Concord, Revere could not return to the city, which was now firmly in British hands. He boarded in Watertown, where he was eventually joined by Rachel and most of his children (Paul Jr., then 15, remained in Boston to mind the family properties). After he was denied a commission in the Continental Army, he tried to find other ways to be useful to the rebel cause. He was retained by the provincial congress as a courier, and he printed local currency which the congress used to pay the troops around Boston.\nSince there was a desperate shortage of gunpowder, the provincial congress decided in November 1775 to send him to Philadelphia to study the working of the only powder mill in the colonies, in the hopes that he might be able to build a second one in Massachusetts. Revere called on the mill's owner, Oswald Eve, armed with a letter from Continental Congressmen Robert Morris and John Dickinson asking Eve to \"Chearfully &amp; from Public Spirited Motives give Mr. Revere such information as will inable him to Conduct the business on his return home.\" Eve showed Revere around the mill, but refused to give him detailed drawings unless he was first paid a substantial bribe. Despite this chilly reception, Revere was able to discern useful information from the visit. He also acquired, through the work of Samuel Adams, plans for another powder mill. This information enabled Revere to set up a powder mill at Stoughton (present-day Canton). The mill produced tons of gunpowder for the Patriot cause.\nRevere's friend and compatriot Joseph Warren was killed in the Battle of Bunker Hill on June 17, 1775. Because soldiers killed in battle were often buried in mass graves without ceremony, Warren's grave was unmarked. On March 21, 1776, several days after the British army left Boston, Revere, Warren's brothers, and a few friends went to the battlefield and found a grave containing two bodies. After being buried for nine months, Warren's face was unrecognizable, but Revere was able to identify Warren's body because he had placed a false tooth in Warren's mouth, and recognized the wire he had used for fastening it. Warren was given a proper funeral and reburied in a marked grave.\nMilitia service.\nUpon returning to Boston in 1776, Revere was commissioned a major of infantry in the Massachusetts militia in that April, and transferred to the artillery a month later. In November he was promoted to lieutenant colonel, and was stationed at Castle William, defending Boston harbor. He was generally second or third in the chain of command, and on several occasions he was given command of the fort. He applied his engineering skills to maintaining the fort's armaments, even designing and building a caliper to accurately measure cannonballs and cannon bore holes. The service at Castle William was relatively isolated, and personality friction prompted some men to file complaints against Revere. The boredom was alleviated in late August 1777 when Revere was sent with a troop of soldiers to escort prisoners taken in the Battle of Bennington to Boston, where they were confined on board prison ships, and again in September when he was briefly deployed to Rhode Island.\nIn August 1778 Revere's regiment served in a combined Franco-American expedition whose objective was to capture the British base at Newport, Rhode Island. His regiment was responsible for erecting and maintaining artillery batteries on Aquidneck Island. The attempt was abandoned by the French when their fleet was scattered in a storm, and Revere's regiment returned to Boston before the British sortied from Newport to force the Battle of Rhode Island.\nPenobscot disaster.\nThe British in June 1779 established a new base on Penobscot Bay in present-day Maine (which was then part of Massachusetts). Massachusetts authorities called out the militia, pressed into service available shipping, and organized a major expedition to dislodge the British. The expedition was a complete fiasco: its land and naval commanders squabbled over control of the expedition, and could not agree on strategy or tactics. The arrival of British reinforcements led to the destruction of the entire Massachusetts fleet. Revere commanded the artillery units for the expedition, and was responsible for organizing the artillery train. He participated in the taking of Bank's Island, from which artillery batteries could reach the British ships anchored before Fort George. He next oversaw the transport of the guns from Bank's Island to a new position on the heights of the Bagaduce Peninsula that commanded the fort. Although Revere was in favor of storming the fort, Brigadier General Solomon Lovell opted for a siege instead. After further disagreements on how to proceed between Lovell and fleet commander Dudley Saltonstall, Lovell decided to return to the transports on August 12, a decision supported by Revere.\nLate the next day British sails were spotted. A mad scramble ensued, and on the 14th the fleet was in retreat heading up the Penobscot River. Revere and his men were put ashore with their stores, and their transports destroyed. At one point Brigadier General Peleg Wadsworth ordered Revere to send his barge in an attempt to recover a ship drifting toward the enemy position. Revere at first resisted, but eventually complied, and Wadsworth told him to expect formal charges over the affair. The incident separated Revere from his men. Moving overland, he eventually managed to regroup most of his troops, and returned to Boston on August 26. A variety of charges were made against Revere, some of which were exaggerated assignments of blame made by enemies he had made in his command at Castle William. The initial hearings on the matter in September 1779 were inconclusive, but he was asked to resign his post. He repeatedly sought a full court-martial to clear his name, but it was not until February 1782 that a court martial heard the issue, exonerating him.\nBusiness and social connections.\nDuring the Revolutionary War, Revere continued his efforts to move upwards in society into the gentry. After his failed efforts to become a military officer he attempted to become a merchant, but was hindered by a number of factors: while he was a fairly well-off member of the artisan class, he did not have the resources to afford the goods he would have sold as a merchant, nor were lenders in England willing to lend him the required startup capital. Other American merchants of the time were able to continue their business with colleagues in England. However, Revere's inexperience as a merchant meant that he had not yet established such relationships and was not able to communicate as effectively on unfamiliar matters. Another factor preventing Revere's success as a merchant was the economic climate of the time period after the war known as the Confederation Period; while the colonies had seen a time of economic growth before the war, the colonies experienced a severe post-war depression, constraining the overall success of his business.\nWhile Revere struggled as a merchant, his success as a silversmith enabled him to pursue and leverage more advanced technological developments for the purposes of mass production. For example, rolling mills greatly improved the productivity of his silver shop and enabled his business to move further away from manufacturing high-end customized products in order to focus instead on the production of a more standardized set of goods. In the 18th century, the standard of living continuously improved in America, as genteel goods became increasingly available to the masses. Revere responded particularly well to this trend because his business was not solely manufacturing custom, high end purchases. Smaller products like teaspoons and buckles accounted for the majority of his work, allowing him to build a broad customer base.\nRevere's increased efficiency left financial and human resources available for the exploration of other products, which was essential to overcoming the fluctuating post-war economic climate. In addition to increasing production, the flatting mill enabled Revere to move towards a more managerial position.\nLater years: entrepreneurship, manufacturing, and politics.\nAfter the war, Revere became interested in metal work beyond gold and silver. By 1788 he had invested some of the profits from his growing silverworking trade to construct a large furnace, which would allow him to work with larger quantities of metals at higher temperatures. He soon opened an iron foundry in Boston's North End that produced utilitarian cast iron items such as stove backs, fireplace tools, and sash-window weights, marketed to a broad segment of Boston's population. Many of Revere's business practices changed when he expanded his practice into ironworking, because he transitioned from just being an artisan to also being an entrepreneur and a manager. In order to make this transition successfully, Revere had to invest substantial quantities of capital and time in his foundry.\nTechnological practices.\nThe quasi-industrialization of his practice set Revere apart from his competition. \"Revere's rapid foundry success resulted from fortuitous timing, innate technical aptitude, thorough research, and the casting experience he gained from silverworking.\" This technical proficiency allowed Revere to optimize his work and adapt to a new technological and entrepreneurial model. Revere's location also benefited his endeavors. Revere was entering the field of iron casting in a time when New England cities were becoming centers of industry. The nature of technological advancement was such that many skilled entrepreneurs in a number of fields worked together, in what is known by Nathan Rosenberg as technological convergence, by which a number of companies work together on challenges in order to spur advances. By accessing the knowledge of other nearby metal workers, Revere was able to successfully explore and master new technologies throughout his career.\nLabor practices.\nOne of the biggest changes for Revere in his new business was organization of labor. In his earlier days, Revere primarily utilized the apprenticeship model standard for artisan shops at this time, but as his business expanded he hired employees (wage laborers) to work for his foundry. Many manufacturers of the era found this transition from master to employer difficult because many employees at the onset of the Industrial Revolution identified themselves as skilled workers, and thus wanted to be treated with the respect and autonomy accorded to artisans. An artisan himself, Revere managed to avoid many of these labor conflicts by adopting a system of employment that still held trappings of the craft system in the form of worker freedoms such as work hour flexibility, wages in line with skill levels, and liquor on the job.\nManufacturing: church bells, cannon, and copper products.\nAfter mastering the iron casting process and realizing substantial profits from this new product line, Revere identified a burgeoning market for church bells in the religious revival known as the Second Great Awakening that followed the war. Beginning in 1792 he became one of America's best-known bell casters, working with sons Paul Jr. and Joseph Warren Revere in the firm Paul Revere &amp; Sons. This firm cast the first bell made in Boston and ultimately produced hundreds of bells, a number of which remain in operation.\nIn 1794, Revere decided to take the next step in the evolution of his business, expanding his bronze casting work by learning to cast cannon for the federal government, state governments, and private clients. Although the government often had trouble paying him on time, its large orders inspired him to deepen his contracting and seek additional product lines of interest to the military.\nBy 1795, a growing percentage of his foundry's business came from a new product, copper bolts, spikes, and other fittings that he sold to merchants and the Boston naval yard for ship construction. In 1801, Revere became a pioneer in the production of rolled copper, opening North America's first copper mill south of Boston in Canton. Copper from the Revere Copper Company was used to cover the original wooden dome of the Massachusetts State House in 1802. His copper and brass works eventually grew, through sale and corporate merger, into a large corporation, Revere Copper and Brass, Inc.\nSteps towards standardized production.\nDuring his earlier days as an artisan, especially when working with silver products, Revere produced \"bespoke\" or customized goods. As he shifted to ironworking, he found the need to produce more standardized products, because this made production cheaper. To achieve the beginnings of standardization, Revere used identical molds for casting, especially in the fabrication of mass-produced items such as stoves, ovens, frames, and chimney backs. However, Revere did not totally embrace uniform production. For example, his bells and cannons were all unique products: these large objects required extensive fine-tuning and customization, and the small number of bells and cannon minimized the potential benefits of standardizing them. In addition, even the products that he made in large quantities could not be truly standardized due to technological and skill limitations. His products were rarely (if ever) identical, but his processes were well systematized. \"He came to realize that the foundry oven melded the characteristics of tools and machines: it required skilled labor and could be used in a flexible manner to produce different products, but an expert could produce consistent output by following a standard set of production practices.\"\nFreemasonry.\nRevere was a Freemason as a member of Lodge St. Andrews, No. 81, in Boston, Massachusetts. The Lodge continues to meet in Boston with the No. 4 under and the jurisdiction of the Grand Lodge of Massachusetts. The date he joined the Lodge is not known but was sometime after the inauguration of the Lodge on St Andrew's Day, November 30, 1756, and before May 15, 1769, when he is recorded in the Grand Lodge of Scotland membership register as the Lodge Secretary. Joseph Warren and William Palfrey are also recorded, on the same page, as members of the Lodge as being Master and Senior Warden respectively. (see image)\nHe subsequently became the Grand Master of the Freemasons of Massachusetts from 1795 to 1797. During his tenure, Revere, along with Governor Samuel Adams and Deputy Grand Master, Colonel William Scollay, deposited a box containing an assemblage of commemorative items under the cornerstone of the Massachusetts State House on July 4, 1795.\nPolitics and final years.\nRevere remained politically active throughout his life. His business plans in the late 1780s were often stymied by a shortage of adequate money in circulation. Alexander Hamilton's national policies regarding banks and industrialization exactly matched his dreams, and he became an ardent Federalist committed to building a robust economy and a powerful nation. Of particular interest to Revere was the question of protective tariffs; he and his son sent a petition to Congress in 1808 asking for protection for his sheet copper business. He continued to participate in local discussions of political issues even after his retirement in 1811, and in 1814 circulated a petition offering the government the services of Boston's artisans in protecting Boston during the War of 1812. Revere died on May 10, 1818, at the age of 83, at his home on Charter Street in Boston. He is buried in the Granary Burying Ground on Tremont Street.\nLegacy.\nAfter Revere's death, the family business was taken over by his oldest surviving son, Joseph Warren Revere. The copper works founded in 1801 continues today as the Revere Copper Company, with manufacturing divisions in Rome, New York, and New Bedford, Massachusetts.\nRevere's original silverware, engravings, and other works are highly regarded today, and can be found on display in museums including the Museum of Fine Arts, Boston and the Metropolitan Museum of Art. The Revere Bell, presented in 1843 to the Church of St. Andrew in Singapore by his daughter, Mrs. Maria Revere Balestier, wife of American consul Joseph Balestier, is now displayed in the National Museum of Singapore. This is the only bell cast by the Revere foundry that is outside the United States. For a time, it was displayed behind velvet ropes in the foyer of the United States Embassy in Singapore.\nThe communities of Revere, Massachusetts, and Revere, Minnesota, bear his name, as do Revere Beach in Revere, Massachusetts; Revere Avenue in The Bronx, New York City; Paul Revere Road in Arlington, Massachusetts; and Paul Revere Apartments in Seattle.\nA 25-cent 1958 U.S. postage stamp in the Liberty Series honors Paul Revere, featuring the portrait by Gilbert Stuart. He also appears on the $5,000 Series EE U.S. Savings Bond.\nRyan Reynolds released a Mint Mobile commercial that features Avery Revere, a direct descent of Paul Revere.\nPaul Revere Mall is a corridor located in Boston's North End behind Old North Church. It features the Equestrian statue of Paul Revere by Cyrus Edwin Dallin. \nIn popular culture.\nIn episode 8 of the 2nd season of the US TV show \"The West Wing\" (1999\u20132006), Paul Revere is named as the manufacturer of president Bartlet's knife-set he presents to Charlie, his personal aide.\nRevere appears in the 2012 video game \"Assassin's Creed III\" and is portrayed by Bruce Dinsmore. He is fictitiously depicted riding alongside the game's protagonist, , to alert the colonial militias.\nIn Harry Chapin's 14 minute song \"There Only Was One Choice\" (1977), Paul Revere is referenced in the line: \"His voice was Chicken Little's, but he's hearing Paul Revere.\" The lyric draws a contrast between the panicked alarmism of the fictional Chicken Little and Revere's historical role as a measured and heroic messenger, emphasizing Revere as a figure who communicates urgent warning responsibly rather than through fear.\nSylvester Stallone voiced Revere in the animated series \"Liberty's Kids.\"\nMichael Raymond-James portrayed Revere on the 2015 History miniseries \"Sons of Liberty.\"\nRevere is mentioned in the lyrics of Bob Dylan's 1965 song \"Tombstone Blues\".\nRevere is mentioned numerous times in the lyrics of Noah Kahan's 2023 song \"Paul Revere\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50373", "revid": "8598366", "url": "https://en.wikipedia.org/wiki?curid=50373", "title": "Type B Cipher Machine", "text": "Japanese diplomatic code named Purple by the US\nThe \"System 97 Typewriter for European Characters\" (\u4e5d\u4e03\u5f0f\u6b27\u6587\u5370\u5b57\u6a5f \"ky\u016bnana-shiki \u014dbun injiki\") or \"Type B Cipher Machine\", codenamed Purple by the United States, was an encryption machine used by the Japanese Foreign Office from February 1939 to the end of World War II. The machine was an electromechanical device that used stepping-switches to encrypt the most sensitive diplomatic traffic. All messages were written in the 26-letter English alphabet, which was commonly used for telegraphy. Any Japanese text had to be transliterated or coded. The 26-letters were separated using a plug board into two groups, of six and twenty letters respectively. The letters in the sixes group were scrambled using a 6 \u00d7 25 substitution table, while letters in the twenties group were more thoroughly scrambled using three successive 20 \u00d7 25 substitution tables.\nThe cipher codenamed \"Purple\" replaced the Type A Red machine previously used by the Japanese Foreign Office. The sixes and twenties division was familiar to U.S. Army Signals Intelligence Service (SIS) cryptographers from their work on the Type A cipher and it allowed them to make early progress on the sixes portion of messages. The twenties cipher proved much more difficult, but a breakthrough in September 1940 allowed the Army cryptographers to construct an \"analog\" machine that duplicated the behavior of the Japanese machines, even though no one in the U.S. had any description of one.\nThe Japanese also used stepping-switches in systems, codenamed Coral and Jade, that did not divide their alphabets. American forces referred to information gained from decryptions as \"Magic\".\nDevelopment of Japanese cipher machines.\nThe Imperial Japanese Navy (IJN) did not fully cooperate with the Army in pre-war cipher machine development, and that lack of cooperation continued into World War II. The Navy believed the IJN's Purple machine was sufficiently difficult to break that it did not attempt to revise it to improve security. This seems to have been on the advice of a mathematician, Teiji Takagi, who lacked a background in cryptanalysis. The Ministry of Foreign Affairs was supplied Red and Purple by the Navy. No one in Japanese authority noticed the weak points in both machines.\nPrototype of Red.\nJapanese diplomatic communications at negotiations for the Washington Naval Treaty were broken by the American Black Chamber in 1922, and when this became publicly known, there was considerable pressure to improve their security. The Japanese Navy had already planned to develop their first cipher machine for the following London Naval Treaty; Japanese Navy Captain Risaburo Ito, of Section 10 (cipher &amp; code) of the Japanese Navy General Staff Office was selected to supervise the work.\nThe development of the machine was the responsibility of the Japanese Navy Institute of Technology, Electric Research Department, Section 6. In 1928, the chief designer Kazuo Tanabe and Navy Commander Genichiro Kakimoto developed a prototype of Red, \"Roman-typewriter cipher machine\".\nThe prototype used the same principle as the Kryha cipher machine, having a plugboard, and was used by the Japanese Navy and Ministry of Foreign Affairs at negotiations for the London Naval Treaty in 1930.\nRed.\nThe prototype machine was finally completed as \"Type 91 Typewriter\" in 1931. The year 1931 was year 2591 in the Japanese Imperial calendar. Thus it was prefixed \"91-shiki\" from the year it was developed.\nThe \"91-shiki injiki\" Roman-letter model was also used by the Ministry of Foreign Affairs as \"Type A Cipher Machine\", codenamed \"Red\" by United States cryptanalysts.\nThe Red machine was unreliable unless the contacts in its half-rotor switch were cleaned every day. A significant weak point was that it enciphered vowels (AEIOUY) and consonants separately, perhaps to reduce telegram costs. The Navy also used the \"91-shiki injiki\" Kana-letter model at its bases and on its vessels.\nPurple.\nIn 1937, the Japanese completed the next generation \"Type 97 Typewriter\". The Ministry of Foreign Affairs machine was the \"Type B Cipher Machine\", codenamed Purple by United States cryptanalysts.\nThe chief designer of Purple was Kazuo Tanabe. His engineers were Masaji Yamamoto and Eikichi Suzuki. Eikichi Suzuki suggested the use of a stepping switch instead of the more troublesome half-rotor switch.\nClearly, the Purple machine was more secure than Red, but the Navy did not recognize that Red had already been broken. The Purple machine inherited a weakness from the Red machine that six letters of the alphabet were encrypted separately. It differed from Red in that the group of letters was changed and announced every nine days, whereas in Red they were permanently fixed as the Latin vowels AEIOUY. Thus US Army SIS was able to break the cipher used for the six letters before it was able to break the one used for the 20 others.\nDesign.\n \nThe Type B Cipher Machine consisted of several components. As reconstructed by the US Army, there were electric typewriters at either end, similar to those used with the Type A Machine. The Type B was organized for encryption as follows:\nFor decryption, the data flow is reversed. The keyboard on the second typewriter becomes the input and the twenties letters pass through the stepping switch stages in the opposite order.\nStepping switches.\nA stepping switch is a multi-layer mechanical device that was commonly used at the time in telephone switching systems. Each layer has a set of electrical connects, 25 in the Type B, arranged in a semicircular arc. These do not move and are called the stator. A wiper arm on a rotor at the focus of the semicircle connects with one stator contact at a time. The rotors on each layer are attached to a single shaft that advances from one stator contact to the next whenever an electromagnet connected to a ratchet is pulsed. There are actually two wiper arms on each level, connected together, so that when one wiper advances past the last contact in the semicircle, the other engages the first contact. This allows the rotor connections to keep cycling through all 25 stator contacts as the electromagnet is pulsed.\nTo encrypt the twenties letters, a 20-layer stepping switch was needed in each of the three stages. Both the Japanese version and the early American analog constructed each stage from several smaller stepping switches of the type used in telephone central offices. The American analog used four 6-level switches to create one 20-layer switch. The four switches in each stage were wired to step synchronously. The fragment of a Type 97 Japanese machine on display at the National Cryptologic Museum, the largest piece known in existence, has three 7-layer stepping switches (see photo). The U.S. Army developed an improved analog in 1944 that has all the layers needed for each stage on a single shaft. An additional layer was used in the improved analog to automatically set each switch bank to the initial position specified in the key.\nHowever implemented, the 20-layer stepping switch in each stage had 20 rotor connections and 500 stator connections, one wiper and 25 stator contacts on each layer. Each stage must have exactly 20 connections on each end to connect with the adjacent stage or plugboard. On the rotor side, that is not a problem as there are 20 rotors. On the stator end of a stage, every column of stator contacts corresponding to the same rotor position on each of the 20 layers is connected to the 20 output wires (\"leads\" in the diagram) in a scrambled order, creating a permutation of the 20 inputs. This is done differently for each of the rotor positions. Thus each stator output wire has 25 connections, one from each rotor position, though from different levels. The connections needed to do this created a \"rats nest\" of wires in the early U.S. analog. The improved analog organized the wiring more neatly with three matrices of soldering terminals visible above each stepping switch in the photograph.\nStepping order.\nThe stages were bi-directional. Signals went through each stage in one direction for encryption and in the other direction for decryption. Unlike the system in the German Enigma machine, the order of the stages was fixed and there was no reflector. However the stepping arrangement could be changed.\nThe sixes switches stepped one position for each character encrypted or decrypted. The motions of the switches in the twenties stages were more complex. The three stages were assigned to step fast, medium or slow. There were six possible ways to make this assignment and the choice was determined by a number included at the beginning of each message called the message indicator. The U.S. improved analog has a six-position switch for making this assignment, see photo. The message indicator also specified the initial positions of the twenties switches. The indicator was different for each message or part of a message, when multi-part messages were sent. The final part of the key, the alphabet plugboard arrangement, was changed daily.\nThe twenties switch stepping was controlled in part by the sixes switch. Exactly one of the three switches stepped for each character. The fast switch stepped for each character except when the sixes switch was in its 25th position. Then the medium switch stepped, unless it too was in its 25th position, in which case the slow switch stepped.\nWeaknesses and cryptanalysis.\nThe SIS learned in 1938 of the forthcoming introduction of a new diplomatic cipher from decoded messages. Type B messages began to appear in February 1939.\nThe Type B had several weaknesses, some in its design, others in the way it was used. Frequency analysis could often make 6 of the 26 letters in the ciphertext alphabet letters stand out from the other 20 letters, which were more uniformly distributed. This suggested the Type B used a similar division of plaintext letters as used in the Type A. The weaker encryption used for the \"sixes\" was easier to analyze. The sixes cipher turned out to be polyalphabetic with 25 fixed permuted alphabets, each used in succession. The only difference between messages with different indicators was the starting position in the list of alphabets. The SIS team recovered the 25 permutations by 10 April 1939. The frequency analysis was complicated by the presence of romanized Japanese text and the introduction in early May of a Japanese version of the Phillips Code.\nKnowing the plaintext of 6 out of 26 letters scattered throughout the message sometimes enabled parts of the rest of the message to be guessed, especially when the writing was highly stylized. Some diplomatic messages included the text of letters from the U.S. government to the Japanese government. The English text of such messages could usually be obtained. Some diplomatic stations did not have the Type B, especially early in its introduction, and sometimes the same message was sent in Type B and in the Type A Red cipher, which the SIS had broken. All these provided cribs for attacking the twenties cipher.\nWilliam F. Friedman was assigned to lead the group of cryptographers attacking the B system in August 1939. Even with the cribs, progress was difficult. The permutations used in the twenties cipher were \"brilliantly\" chosen, according to Friedman, and it became clear that periodicities would be unlikely to be discovered by waiting for enough traffic encrypted on a single indicator, since the plugboard alphabets changed daily. The cryptographers developed a way to transform messages sent on different days with the same indicator into homologous messages that would appear to have been sent on the same day. This provided enough traffic based on the identical settings (6 messages with indicator 59173) to have a chance of finding some periodicity that would reveal the inner workings of the twenties cipher.\nAround 2 pm on 20 September 1940 Genevieve Grotjan carried a set of work sheets up to a group of men engrossed in conversation and politely attempted to get Frank Rowlett's attention. She had found evidence of cycles in the twenties cipher. Celebration ensued at this first break in the 20s cipher and it soon enabled a replica machine to be built. A pair of other messages using indicator 59173 were decrypted by 27 September, coincidentally the date that the Tripartite Agreement between Nazi Germany, Fascist Italy, and Imperial Japan was announced. There was still a lot of work to do to recover the meaning of the other 119 possible indicators. As of October 1940, one third of the indicator settings had been recovered. From time to time the Japanese instituted new operating procedures to strengthen the Type B system, but these were often described in messages to diplomatic outputs in the older system, giving the Americans warning.\nReconstruction of the Purple machine was based on ideas of Larry Clark. Advances into the understanding of Purple keying procedures were made by Navy Lieutenant Francis Raven. After the initial break, Raven discovered that the Japanese had divided the month into three 10-day periods, and, within each period, they used the keys of the first day, with small, predictable changes.\nThe Japanese believed Type B to be unbreakable throughout the war, and even for some time after the war, even though they had been informed otherwise by the Germans. In April 1941, Hans Thomsen, a diplomat at the German embassy in Washington, D.C., sent a message to Joachim von Ribbentrop, the German foreign minister, informing him that \"an absolutely reliable source\" had told Thomsen that the Americans had broken the Japanese diplomatic cipher (that is, Purple). That source apparently was Konstantin Umansky, the Soviet ambassador to the US, who had deduced the leak based upon communications from U.S. Undersecretary of State Sumner Welles. The message was duly forwarded to the Japanese; but use of the code continued and American cryptographers continued to read Japanese messages through the war.\nAmerican analogs.\nThe SIS built its first machine that could decrypt Purple messages in late 1940. A second Purple analog was built by the SIS for the US Navy. A third was sent to England in January 1941 on , which had brought Ambassador Halifax to the U.S. That Purple analog was accompanied by a team of four American cryptologists, two Army, two Navy, who received information on British successes against German ciphers in exchange. This machine was subsequently sent to Singapore, and after Japanese moves south through Malaya, on to India. A fourth Purple analog was sent to the Philippines and a fifth was kept by the SIS. A sixth, originally intended for Hawaii, was also sent to England for use there. The Purple intercepts proved important in the European theater due to the detailed reports on German plans sent in that cipher by the Japanese ambassador in Berlin.\nFragmentary recovery of Japanese machines.\nThe United States obtained portions of a Purple machine from the Japanese Embassy in Germany following Germany's defeat in 1945 (see image above) and discovered that the Japanese had used a stepping switch almost identical in its construction to the one Leo Rosen of SIS had chosen when building a duplicate (or Purple analog machine) in Washington in 1939 and 1940. The stepping switch was a uniselector; a standard component used in large quantities in automatic telephone exchanges in countries like America, Britain, Canada, Germany and Japan, with extensive dial-telephone systems. The U.S. used four 6-level switches in each stage of its Purple analogs, the Japanese used three 7-level switches. Both represented the 20s cipher identically. However, these were not two-motion or Strowger switches as sometimes claimed: \"twenty-five Strolger-type (sic) stepper switches ...\".\nApparently, all other Purple machines at Japanese embassies and consulates around the world (e.g. in Axis countries, Washington, London, Moscow, and in neutral countries) and in Japan itself, were destroyed beyond recognition by the Japanese. American occupation troops in Japan in 1945\u201352 searched for any remaining units. A complete Jade cipher machine, built on similar principles but without the sixes and twenties separation, was captured and is on display at NSA's National Cryptologic Museum.\nImpact of Allied decryption.\nThe Purple machine itself was first used by Japan in June 1938, but American and British cryptanalysts had broken some of its messages well before Japan's December 1941 attack on Pearl Harbor. US cryptanalysts decrypted and translated Japan's 14-part message to its Washington embassy to break off negotiations with the United States at 1 p.m., Washington time on 7 December before the Japanese Embassy in Washington had done so. Decryption and typing difficulties at the embassy, coupled with ignorance of the importance of it being on time, were major reasons for the \"Nomura Note\" to be delivered late.\nDuring World War II, the Japanese ambassador to Nazi Germany, General Hiroshi Oshima, was well-informed on German military affairs. His reports went to Tokyo in Purple-enciphered radio messages. One had a comment that Hitler told him on 3 June 1941 that \"in every probability war with Russia cannot be avoided.\" In July and August 1942, he toured the Eastern Front, and in 1944, he toured the Atlantic Wall fortifications against invasion along the coasts of France and Belgium. On 4 September, Hitler told him that Germany would strike in the West, probably in November.\nSince those messages were being read by the Allies, they provided valuable intelligence about German military preparations against the forthcoming invasion of Western Europe. He was described by General George Marshall as \"our main basis of information regarding Hitler's intentions in Europe.\"\nThe decrypted Purple traffic and Japanese messages generally were the subject of acrimonious hearings in Congress after World War II in connection with an attempt to decide who, if anyone, had allowed the attack at Pearl Harbor to happen and so should be blamed. It was during those hearings that the Japanese for the first time learned that the Purple cipher machine had indeed been broken. (See the Pearl Harbor advance-knowledge conspiracy theory article for additional detail on the controversy and the investigations.)\nThe Soviets also succeeded in breaking the Purple system in late 1941, and together with reports from Richard Sorge, learned that Japan was not going to attack the Soviet Union. Instead, its targets were southward, toward Southeast Asia and American and British interests there. That allowed Stalin to move considerable forces from the Far East to Moscow in time to help stop the December 1941 German push to Moscow as part of the Reich's Operation Barbarossa invasion of the Soviet Union.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50375", "revid": "50478703", "url": "https://en.wikipedia.org/wiki?curid=50375", "title": "Internet relationship", "text": "Relationship between people who have met online\nAn internet relationship is a relationship between people who have met online, and in many cases know each other only via the Internet. Online relationships are similar in many ways to pen pal relationships. This relationship can be romantic, platonic, or based on business affairs. An internet relationship (or online relationship) is generally sustained for a certain amount of time before being titled a relationship, just as in-person relationships. The major difference here is that an internet relationship is sustained via computer or online service, and the individuals in the relationship may or may not ever meet each other in person. Otherwise, the term is quite broad and can include relationships based upon text, video, audio, or even virtual character. This relationship can be between people in different regions, different countries, different sides of the world, or even people who reside in the same area but do not communicate in person.\nTechnological advances.\nAccording to J. Michael Jaffe, author of \"Gender, Pseudonyms, and CMC: Masking Identities and Baring Souls\", \"the Internet was originally established to expedite communication between governmental scientists and defense experts, and was not at all intended to be the popular 'interpersonal mass medium' it has become\", yet new and revolutionary devices enabling the mass public to communicate online are constantly being developed and released.\nRather than having many devices for different uses and ways of interacting, communicating online is more accessible and cheaper by having an Internet function built into one device, such as mobile phones, tablets, laptops, and smartphones. Other ways of communicating online with these devices are via services and applications such as Email, Skype, iChat, instant messaging programs, social networking services, asynchronous discussion groups, online games, virtual worlds and the World Wide Web.\nSome of these ways of communicating online are asynchronous (meaning not in real time), such as YouTube and some are synchronous (immediate communication), such as Twitter. Synchronous communication occurs when two or more participants are interacting in real time via voice or text chat.\nDigital Boundaries and Online Relationship Conflict.\nInternet-based relationships\u2014those that begin or are primarily maintained through digital communication\u2014have become increasingly common, making digital boundaries and online conflict key topics of research. Because most interactions occur through messaging apps, social media platforms, or other online tools, partners must negotiate how frequently they communicate, which platforms they prefer, and how available they expect one another to be. Interpreting digital cues such as response timing, read receipts, and written tone also plays a major role in shaping trust, emotional closeness, and overall satisfaction.\nDifferences in communication expectations can easily create tension. One partner may want quick replies or daily video calls, while the other prefers slower, less frequent contact. The lack of nonverbal cues\u2014such as facial expressions or vocal tone\u2014can make misunderstandings more likely and allow minor issues to escalate more quickly.\nSocial media behavior is another frequent source of conflict. Partners may disagree about posting their relationship online, interacting with others on social platforms, sharing private content, or deciding how visible their relationship should be. Actions such as liking posts, commenting, or replying late can be interpreted differently depending on each partner\u2019s expectations. These issues tend to be especially significant in long-distance or online-first relationships, where social media often functions as a key source of reassurance and emotional visibility.\nRole of Cultural, Personal, and Contextual Differences.\nCultural Differences.\nCultural norms play a major role in shaping how individuals manage digital boundaries. Expectations related to privacy, emotional expression, and online openness differ widely across cultures. In collectivist societies, frequent communication may be seen as a sign of care and loyalty, whereas in individualistic cultures the same behavior may be viewed as intrusive or overbearing. Understanding these cultural differences can reduce misinterpretation in cross-cultural online relationships.\nPersonal Differences.\nDifferences in personality, emotional needs, and past experiences also influence digital boundary preferences. Individuals who value independence may prefer limited or selective communication, while those seeking emotional closeness may desire frequent contact or reassurance. When these preferences do not align, misunderstandings or emotional strain may occur. Clear communication about response expectations and personal boundaries can help maintain trust and stability.\nContextual Differences.\nThe context of a relationship\u2014such as long-distance arrangements, time-zone differences, or work schedules\u2014can further influence communication patterns. Long-distance partners often rely heavily on digital tools to remain emotionally connected, making online presence and response timing particularly meaningful. Additionally, norms vary across platforms: public posts may signal commitment, whereas private messages may carry more intimate meaning.\nImpact on Emotional Well-Being and Relationship Satisfaction.\nResearch shows that couples who openly negotiate their digital boundaries tend to experience fewer misunderstandings and lower levels of jealousy. Conversely, unclear or repeatedly disregarded boundaries can contribute to feelings of anxiety, mistrust, and emotional exhaustion.\nAlthough digital communication can strengthen social support networks, it does not always replicate the emotional benefits of face-to-face interactions. A Canadian study found that in-person friendships were more strongly associated with subjective well-being than the size of one\u2019s online network.\nStudies on adolescents similarly indicate that high-quality friendships\u2014whether online or offline\u2014support emotional health. However, excessive social media use may be associated with internalizing symptoms such as anxiety or sadness, suggesting that the quality of interactions is more important than quantity.\nDigital Literacy and Respectful Online Communication.\nDigital literacy and respectful communication are increasingly important as technology shapes online relationships. This includes awareness of one\u2019s online habits, understanding emotional needs, and clearly communicating expectations. Respecting each other\u2019s digital boundaries can prevent misunderstandings, reduce conflict, and strengthen trust in internet-mediated relationships.\nTypes of relationships.\nMany types of internet relationships are possible in today's world of technology.\nInternet dating.\nInternet dating is very relevant in the lives of many individuals worldwide. A major benefit in the rise of Internet dating is the decrease in prostitution. People no longer need to search on the streets to find casual relationships. They can find them online if that is what they desire. Internet dating websites offer matchmaking services for people to find love or whatever else they may be looking for. The creation of the internet and its progressive innovations have opened up doors for people to meet other people who they may very well have never met otherwise.\nDating website innovations.\nAlthough the availability of uploading videos to the internet is not a new innovation, it has been made easier since 2008 thanks to YouTube. YouTube began the surge of video streaming sites in 2005 and within three years, smaller web developers started implementing video sharing on their sites. Internet dating sites have benefitted greatly since the surge in easiness and accessibility of picture and video uploading. Videos and pictures are equally important for most personal profiles. These profiles can be found on sites used for interpersonal relationships other than dating as well. \"The body, although graphically absent, does not have to be any less present.\" Older and less advanced sites usually still allow, and often require, each user to upload a picture. Newer and more advanced sites offer the possibility of streaming media live via the user's profile for the site. The inclusion of videos and pictures has become almost a necessity for sexual social networking sites to maintain the loyalty of their members. It is appealing to internet users to be able to view and share videos, especially when forming relationships or friendships.\nUsers.\nAccording to an article in the \"New York Times\", mediated matchmaking has been around since the mid-1800s. Online dating was made available in the mid-1990s, with the creation of the first dating sites. These dating sites create a space for liberation of sexuality. According to Sam Yagan of OkCupid, \"the period between New Year's Day and Valentine's Day is [our] busiest six weeks of the year\". Changes that online dating companies have created include not only the increase of pickiness in singles, but the rise in interracial marriages and spread the acceptance of homosexual individuals. Dating sites \"are a place where sexual minorities, inter-sexed people and gay people are enjoying a newly found freedom\". Several studies have shown the availability of online dating to produce a greater closeness and intimacy between individuals because it circumvents barriers that face-to-face interactions might have. \"Participating in personal relationships online allow for almost full freedom from power relations in the offline/real world.\"\nA plethora of virtual sexual identities are represented in online profiles. The amount of personal information users are being asked to provide is constantly increasing. More and more online users are starting to explore and experiment with aspects of their sexual identities, whereas before, they may have felt uncomfortable due to social constraints or fear of possible repercussions. Most internet sites containing personal profiles require individuals to fill in \"personal information\" sections. Often these sections include a series of multiple choice questions. Due to the anonymity of these virtual profiles, individuals are more frequent to 'role'-play at being one of the predefined 'types', although offline, reservations may inhibit the individual from sharing true answers.\nThere have also been many studies done to observe online daters and their reason for turning to the internet to look for romantic partners. According to Robert J. Brym and Rhonda L. Lenton, users of online games, websites, and other virtual communities are encouraged to conceal their identities and learn things about themselves that they never knew before. With a concealed identity, an online user can be whoever they want to be at that exact moment. They have the ability to venture outside of their comfort zone and act as someone completely different.\nThe \"Journal of Computer-Mediated Communication\" reports the results of a study conducted by Robert J. Stephure, Susan D. Boon, Stacy L. MacKinnon, and Vicki L. Deveau on types of relationships online participants were seeking. They concluded that \"when asked what they were looking for in an online relationship, the considerable majority of participants expressed interest in seeking fun, companionship, and someone to talk to. Most also reported interests in developing casual friendships and dating relationships with online partners. Substantially fewer reported using the Internet for the specific purposes of identifying potential sexual or marital partners.\"\nHowever, a study published in the journal Proceedings of the National Academy of Sciences in 2012, looked at about 19,000 married people and those who met their spouse online said their marriage was more satisfying than those who met their spouse offline. Plus, marriages that began online were less likely to end in separation or divorce.\nFaye Mishna, Alan McLuckie, and Michael Saini, co-authors of the \"Social Work Research\" article \"Real-World Dangers in an Online Reality: A Qualitative Study Examining Online Relationships and Cyber Abuse\", reported the results of their research and observation of over 35,000 individuals between the ages of 6 and 24 who have been or currently are a part of an internet relationship about which they had concerns, and consequently contacted an organization that provided online support. Of the final 346 posts chosen to be included in the study, the average age of online users sharing information about their online relationship(s) was 14 years old. The overwhelming result was that children and youth consider their online relationships to be just as \"real\" as their offline relationships. The study also showed that the internet plays a crucial role in sexual and romantic experiences of this population of adolescent users.\nSuccess of dating websites and social networks.\nCanaan Partners have reported that the dating industry brings in an estimate of 3-4 billion dollars yearly from membership fees and advertisements. The range of dating sites has expanded vastly over the past two decades. There are dating websites that focus on the matchmaking of certain groups of people based on religion, sexual preference, race, etc.\nThe average life expectancy has been on a rise, leaving many young singles feeling as if they have plenty of time to find a life partner. This opens up time to travel and experience things without the burden of a relationship. As of 1996, more than 20% of Canadians \"were not living in the same census subdivision as they were five years earlier\" and as of 1998, more than half of employed Canadians worried \"they [did] not have enough time to spend with their family and friends\". Due to an increase in many businesses requiring their employees to travel, singles, often young professionals, find online dating websites to be the perfect answer to their \"problem\", states Brym and Lenton.\nErik Shipmon, author of \"Why Do People Date Online?\", exclaims, \"the Internet is the ultimate singles' bar\u2014without the noise, the drunks, and the high cost of all those not-so-happy hours. Nor, thanks to online dating membership sites, do you have to depend on your friends and family to hook you up with people they think would be perfect for you\u2014and who wouldn't be perfect for, well, anyone, which is why they are still unattached\".\nCybersex.\nSome people who are in an online relationship also participate in cybersex, which is a virtual sex encounter in which two or more individuals who are connected remotely via computer network send each other sexually explicit messages describing a sexual experience. This can also include individuals communicating sexually via video or audio. Some websites offer a cybersex service, where a patron pays the website owner in exchange for an online sexual experience with another person.\nCybersex sometimes includes real life masturbation. The quality of a cybersex encounter typically depends upon the participants' abilities to evoke a vivid, visceral mental picture in the minds of their partners. Imagination and suspension of disbelief are also critically important. Cybersex can occur either within the context of existing or intimate relationships, e.g. among lovers who are geographically separated, or among individuals who have no prior knowledge of one another and meet in virtual spaces or cyberspaces and may even remain anonymous to one another. In some contexts cybersex is enhanced by the use of a webcam to transmit real-time video of the partners.\nSocial networking relationships.\nSocial networking has enabled people to connect with each other via the internet. Sometimes, members of a social networking service do know all, or many of their \"friends\" (Facebook) or \"connections\" (LinkedIn) etc. in person. However, sometimes internet relationships are formed through these services, including but not limited to: Facebook, Myspace, Google Plus, LinkedIn, Twitter, Instagram, DeviantArt, Xanga and Discord.\n\"Social networking service\" is a very broad term, branching out to websites based on many different aspects. One aspect that is possible on all social networking sites is the possibility of an internet relationship. These sites enable users to search for new connections based on location, education, experiences, hobbies, age, gender, and more. This allows individuals meeting each other to already have some characteristic in common. These sites usually allow for people who do not know each other to \"add\" each other as a connection or friend and to send each other messages. This connection can lead to more communication between two individuals. An immense amount of information about the individuals can be found directly on their social network profile. Proving those individuals include plentiful and accurate information about themselves, people in online relationships can find out much about each other by viewing profiles and \"about me's\". Communication between individuals can become more frequent, thus forming some type of relationship via the internet. This relationship can turn into an acquaintance, a friendship, a romantic relationship, or even a business partnership.\nOnline gaming.\nOnline gaming elicits the introduction of many different types of people in one interface. A common type of online game where individuals form relationships is the MMORPG, or a massively multiplayer online role-playing game. Some examples of MMORPGs are World of Warcraft, EverQuest, SecondLife, Final Fantasy Online, and Minecraft (see List of massively multiplayer online role-playing games.) These games enable individuals to create a character that represents them and interact with other characters played by real individuals, while at the same time carrying out the tasks and goals of the actual game.\nOnline games other than MMORPGs can elicit internet relationships as well. Card games such as poker and board games like Pictionary have been transformed into virtual interfaces that allow an individual to play against people across the internet, as well as chatting with them. Virtual pet sites such as Webkinz and Neopets are another type of popular online game that allow individuals to socialize with other players.\nGames create social spaces for people of various ages, with userbases often crossing age brackets. Most of these games enable individuals to chat with each other, as well as form groups and clans. This interaction can lead to further communication, turning into a friendship or romantic relationship.\nDigital anthropologist Bonnie Nardi emphasizes the significance of online relationships in the video game \"World of Warcraft\". Based on participant observation, she observes players that meets on the internet and ended up developing a relationship throughout the process of playing the video game. People from all across the world can meet up in a virtual platform, and even starting a relationship. Technologies has really brought people closer with one another, and creating a great environment. Nardi talks about one of her guild members named Zeke who was engaged to Malore that they met in a dungeon run. \"I had not seen that there might be anything other than emoting going on, and told him I was married. Zeke then revealed that he was engaged to Malore (whom he had met in World of Warcraft) but that the relationship was not going well.\" (Nardi, Page 165) Zeke's relationship Malore happened due to the fact that Zeke had several accounts in the game and apparently he was able to flirt with Malore while using different characters to run down the dungeon with her.\nOnline forums and chatrooms.\nAn Internet forum is a website that includes conversations in the form of posted messages. Forums can be for general chatting or can be broken down into categories and topics. They can be used to ask questions, post opinions, or debate topics. Forums include their own jargon, for example a conversation is a \"thread\". Different forums also have different lingo and styles of communicating.\nThere are religion forums, music forums, car forums, and countless other topics. These forums elicit communication between individuals no matter the location, gender, ethnicity, etc. although some do include age restrictions. Through these forums people may comment on each other's topics or threads, and with further communication form a friendship, partnership, or romantic relationship.\nProfessional relationships.\nEven in work settings, the introduction of the internet has established easier and sometimes more practical forms of communicating. The internet is often referred to as a vehicle for investor relations or the \"electronic highway\" for business transactions in the United States. The Internet has increased organizational involvement by facilitating the flow of information between face-to-face meetings and allowing for people to arrange meetings at virtually any given time. Socially, it has stimulated positive change in people's lives by creating new forms of online interaction and enhancing offline relationships worldwide, allowing for better and more efficient business communication.\nInternet relationships and Law.\nThe Russian scientist I.M. Rassolov defines internet relations as a type of information relationship that arises, changes and terminates in [cyberspace], with participants acting as bearers of subjective rights and obligations on the Internet.\nIn his opinion, the specifics of internet relationships are as follows:\n1. They cannot exist without complex technical and programming resources, such as information technologies and networks. They have informational content, i.e. they are formed around social information on the Internet.\n2. These relationships arise, change and terminate in cyberspace.\n3. The participants may be traditional intermediaries of information and commercial information. They may also arise between entities with industry-specific legal personality, such as service providers, domain name registrars and digital platform operators.\n4. These relations may be complicated by a foreign element and be formed between citizens of different countries (i.e. they may be transboundary). The persons involved in such relations may be located in different jurisdictions and their activities may be regulated by different legislation.\n5. They may involve artificial intelligence, with 'electronic persons' and robots participating indirectly (i.e. acting as \u201cco-participants\u201d or \u201cco-conspirators\u201d).\n6. These relations emerge at a certain stage in the development of society, the state and technology, with the aim of automating management.\nAdvantages.\nFor more intimate relationships, research has shown that personal disclosures create a greater sense of intimacy. This gives a sense of trust and equality, which people search for in a relationship, and this is often easier to achieve online than face to face, although not all disclosures are responded to positively. Individuals are able to engage in more self-disclosure than an average interaction, because a person can share their inner thoughts, feelings and beliefs and be met with less disapproval and fewer sanctions online than is the case in face-to-face encounters. Researcher Cooper termed this type of relationship as a \"Triple A Engine\" implying that internet relationships are accessible, affordable, and anonymous.\nOnline, barriers that might stand in the way of a potential relationship such as physical attractiveness, social anxiety and stuttering do not exist. Whereas those could hinder an individual in face-to-face encounters, an Internet interaction negates this and allows the individual freedom. Research has shown that stigmas such as these can make a large impact on first impressions in face-to-face meeting, and this does not apply with an online relationship. Furthermore, as the internet has become a worldwide phenomenon, many people can interact with others around the world, or find someone who fits their radar or their type, if there is no one who they find physically or emotionally attractive in their own area. The internet allows for interaction of many different people so there is greater chance of finding someone more attractive. The Internet \"enhances face-to-face and telephone communication as network members become more aware of each others' needs and stimulate their relationships through more frequent contact\".\nAccording to Joseph Walter's social information processing theory, computer-mediated communications can work for people. While online interactions take roughly four times longer than face-to-face interactions, this gives users the opportunity to evaluate and the time to think, making sure they say the perfect response. Thus, chronemics is the only verbal clue available to digital communications. With the focus on conversation and not appearance, digital interactions over time will develop higher levels of intimacy than face-to-face interactions.\nIn \"The Forms of Capital\" Pierre Bourdieu defines social capital as \"the aggregate of the actual or potential resources which are linked to possession of a durable network of more or less institutionalized relationships of mutual acquaintance and recognition.\"\nSocial capital researchers have found that \"various forms of social capital, including ties with friends and neighbors, are related to indices of psychological well-being, such as self-esteem and satisfaction with life\". Then, the use of a social networking service could help to improve the social capital.\nMore than helping to improve the social capital, the use of a social networking service could help to retain it. For instance, Cummings, Lee and Kraut have shown that communication services like instant messaging \"help college students to remain close to their high school friends after they leave home for college\".\nDisadvantages.\nThe Internet provides the opportunity for misrepresentation, particularly in the early stages of a relationship when commitment is low, and self-presentation and enhancement agendas are paramount. After receiving many complaints about his social networking site Ashley Madison, founder Noel Biderman responded to accusations that his and other similar cyber-dating sites are at fault for the \"rising divorce rates and growth in casual dating\". Biderman argued that the idea for Ashleymadison.com came to him when he realized the growing number of people on \"mainstream dating sites\" were married or in a relationship but posing as singles in order to start an affair.\nIn an empirical study of commitment and misrepresentation on the Internet, Cornwell and Lundgren (2001) surveyed 80 chat-room users. Half about their 'realspace' relationships, and half about their cyberspace relationships. They found that 'realspace' relationships were considered to be more serious, with greater feelings of commitment, than the cyber-relationship participants. Both groups, however, reported similar levels of satisfaction and potential for 'emotional growth' with regard to romantic relationships. Cornwell and Lundgren went on to ask about whether the participants had misrepresented themselves to their partner in a number of areas: their interests (e.g. hobbies, musical tastes); their age; their background; their appearance and 'mis-presentation of yourself in any other way' (p.\u00a0203). Participants responded using either yes or no to each question, and their score was summed into a misrepresentation measure. The results can be found below:\nDangers of internet relationships.\nAn oft-forgotten aspect of online interactions is the possible danger present. The option for an individual to conceal their identity may be harmless in many cases, but it can also lead to extremely dangerous situations. Hidden identities are often used in cases of cyberbullying and cyberstalking. Concealing one's true identity is also a technique that can be used to manipulate the person's new online friend or lover into convincing them that they are someone completely different. This is something most online predators do in order to prey on victims. Despite the awareness of dangers, Mishna et al. found children and youth to still partake in online relationships with little care or concern for negative effects. Brym and Lenton also claim that \"although [their] true identities are usually concealed, they sometimes decide to meet and interact in real life\".\nEngaging in internet relationships is also risky because the information placed online about an individual does not have to be accurate. An individual can formulate an entirely different persona and pose as this person as long as they desire. This can be hurtful to individuals who are honest about their identities and believe that they are in a positive relationship or friendship with the individual. This concept has been most recently illustrated on the television show, \"\".\nInternet affairs.\nInternet affairs offer a new perspective on the definition of an affair. Some people consider internet relationships to be classified as an affair while others claim contact affairs are much more serious. Trent Parker and Karen Wampler conducted a qualitative study to discover the different perceptions of internet relationships based on gender differences. Through their study they found internet affairs were considered less of an affair than a physical relationship. Through the results from the same study Parker and Wampler also concluded that women considered sexual internet activities such as internet porn much more severe than the men did. Internet affairs and physical contact affairs are similar because they both involve another partner. \"The primary difference between an internet affair and an affair is that in an affair, the couple meet to engage in the relationship. With internet affairs, on the other hand, the couple rarely meet. This offers a unique advantage to internet affairs.\"\nEffects on face-to-face interactions.\nSince the creation of the Internet, communication has become one of its prime uses. It has become a ubiquitous force in people's everyday lives due to the increase in the regularity and quality of interaction. The internet has also created a new approach to human relationships, and it has changed the way people connect to one another in their social worlds. Online relationships have also changed which effective strategies we use to perform maintenance on our relationships, depending on the exclusivity of the internet the relationship. In the past, postal services made communication possible without the necessity of physical presence, and the invention of the telephone allowed synchronous communication between people across long distances. The internet combined the advantages of both mail and telephone, unifying the speed of the telephone with the written character of the mail service. The evolution of communication within the Internet has arguably changed the nature of individuals' relationships with one another.\nSome see a major negative impact resulting in an increased use of internet communication is of its diversion of true community because online interaction via computers is often regarded as a more impersonal communication medium than face-to-face communication. Others consider the incorporation of the internet allowing online activities to be \"viewed as an extension of offline activities\". The multiple techniques that humans use to communicate, such as taking turns or nodding in agreement, are absent in these settings. Without the body language cues present in a face-to-face conversation, such as pauses or gestures, participants in instant messaging may type over one another's messages without necessarily waiting for a cue to talk. Also, with or without the correct grammar, tone and context can be misunderstood. Recently people who already adapted internet-based communication have missed face-to-face interactions because this traditional way of communication is able to offer advancement in our relationships.\nEarly positive view.\nIn 1991, Stone argued that when virtual communities began forming, this process generated a new type of social space where people could still apparently meet face-to-face, but this required a redefinition of the terms \"meet\" and \"face-to-face.\" These virtual communities allowed people to effortlessly access others, and in many ways to feel better connected, feel that they receive greater support from others, and to obtain emotional satisfaction from their families, communities and society. However, it does have several obvious problems for people to communicate with others. The representative limitation of this way of communications is that it cannot contain people's diverse emotions completely, so it can cause diverse misunderstanding between people.\nPseudocommunity theory.\nIn 1987, this understanding of social spaces was challenged by scholars such as James R. Beniger. Beniger questioned whether these virtual communities were \"real\" or were pseudo communities, \"a pattern relating that, while looking highly interpersonal interaction, is essentially impersonal.\" He put forward the idea that in a society within the virtual world, participants lack the necessary honesty it would take to create a \"real\" virtual community.\nWeakening of social ties.\nIn many cases the introduction of the Internet as a social instigator may cause a repercussion leading to a weakening of social ties. In a study conducted in 1998, Robert Kraut et al. discovered that Internet users were becoming less socially involved. They linked this to an increase in loneliness and depression in relation to use of the Internet. Though these findings may have been sound, in a later study, Kraut et al. revisited his original study with the idea of expanding his current initial sample and correlating it with new subsequently collected longitudinal data. This synthesis produced a different outcome than the one that Kraut had originally presented. The studies like Sexual Addiction and Compulsivity report (2000) indicate that people who are constantly practicing virtual sexual stimulation losing the social stigma and approval that they experience problems \nIn this newer paper, Kraut stated that there were fewer negative affects than he had originally found, and in some cases the negative effect had vanished. In the second study he saw that small positive effects began to appear in social involvement and psychological well-being. Assessing the effect of the Internet over a period of time, he saw people's use of the Internet increase in sophistication.\nDuring the Kraut et al. study, the researchers asked reclusive people if they use the Internet to counteract the loss of social skills that are needed in face-to-face encounters. They also asked people with strong social skills whether they use the Internet to amplify their abilities to network amongst people. The study discovered that these people who already possessed strong social skills were the ones who received the most beneficial outcome to using the Internet. The concluding analysis was, that rather than helping to decrease the difference between those who already had social skills compared with those lacking in social skills, internet use had actually exacerbated the differences in the skill level needed for social interaction.\nAssisting reclusive people.\nThis theory was later challenged in a study, by McKenna et al., that indicated that people who are more socially inept use the internet to create an initial contact which allows them to explore their \"true self\" within these interactions. These social interactions within cyberspace tend to lead to closer and high quality relationships which influence face-to-face encounters. In essence, these findings meant that although it is not clear whether the internet helps reclusive people develop better social skills, it does allow reclusive people to form relationships that may not have existed otherwise because of their lack of comfort with interpersonal situations in general. When these relationships emerge into face-to-face relationships it is hard to distinguish these relationships from those that started as face-to-face interactions. Future studies on this topic may allow scholars to define whether or not society is becoming too dependent on the Internet as a social tool. Those relationships are also found for people suffering from depression, suicidal ideation and other mental health problems. For example, suicidal people were more likely to go online in search of new interpersonal relationships and to seek interpersonal help. Similar findings were found for suicidal LGBT. These studies show that people who have trouble meeting similar others, not only the 'socially inept', are using the internet to create stronger and more extensive interpersonal relationships.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50376", "revid": "15893532", "url": "https://en.wikipedia.org/wiki?curid=50376", "title": "Dragonflight (novel)", "text": "1968 novel by Anne McCaffrey\nDragonflight is a science fiction novel by the American-Irish author Anne McCaffrey. It is the first book in the \"Dragonriders of Pern\" series. First published by Ballantine Books in July 1968, it was a fix-up of two novellas which between them had made McCaffrey the first woman writer to win a Hugo and a Nebula Award.\nIn 1987, \"Locus\" ranked \"Dragonflight\" at number nine among the 33 \"All-Time Best Fantasy Novels\", based on a poll of subscribers.\nOrigins.\nTwo components of \"Dragonflight\" were award-winning novellas published by \"Analog\" science fiction magazine. The first segment, \"Weyr Search\", illustrated by John Schoenherr, had been the cover story for the October 1967 issue. The second segment, \"Dragonrider\", appeared in two parts, beginning in December 1967, and was also a cover story illustrated by Schoenherr.\n\"Weyr Search\" features a young woman named Lessa being recruited to establish a telepathic bond with a queen dragon at its hatching, thus becoming a dragonrider, and the leader of a Weyr community on the fictional planet Pern. \"Dragonrider\" features the growth of Lessa's queen dragon, Ramoth, and their training together. \"Analog\" editor John W. Campbell asked \"to see dragons fighting Thread\", Pern's menace from space, and he also suggested time travel. In response, McCaffrey wrote a third story titled \"Crack Dust, Black Dust\", which was not published separately, but provided crucial material for the novel.\nPlot introduction.\n\"Dragonflight\" takes place in the far future on Pern, a planet colonized by humans. The colonists had originally intended to gradually adopt a low-technology agrarian lifestyle, but were forced to move more quickly after they encountered the deadly Thread raining down from the sky. By harnessing and riding the indigenous, flying, fire-breathing dragons (with genetic alterations to make them larger and telepathic), the colonists destroyed the Thread in the skies over Pern, creating pockets of safety over its surface, before it was able to burrow into the land and breed. Humanity finally managed to find equilibrium and began to create a thriving culture, society, and economy, eventually expanding right across Pern's northern continent. However, when this narrative begins, an unusually long interval between Thread attacks has caused the general population to dismiss the threat as myth and gradually withdraw support from the Weyrs where dragons are bred and trained. By the time of this narrative, only one Weyr remains (the other five having mysteriously disappeared at the same time in the last quiet interval), maintaining a precarious existence.\nDragons are telepathic and are capable of forming a lifelong bond with one particular human in a process called \"Impression\". Tradition, established thousands of years before the narrative, dictates that selected young humans with empathetic and telepathic talents are taken to the Hatching Grounds as candidates for Impression. The dragons come in several colors which generally correlate with their sizes; blue males, green females, brown males, bronze males, and golden females\u00a0\u2013 queens. Bronzes, the largest males, are by tradition the only ones who compete to win the queens in their mating flights. The green females are banned from breeding as they produce only small, less talented dragons. The golden queens are not only the largest dragons, they also hold a subtle control over their dragon communities Weyrs. The Queen sets out on a Mating Flight, pursued by several bronze males; the one who wins and mates with her assumes a leading position among the dragons, and his rider automatically becomes the leader of the human dragon riders. The passion of the male dragon and queen mating up in the air can telepathically transfer itself to their male and female human partners, inducing them to a passionate human lovemaking.\nPlot summary.\n\"Dragonflight\" is the story of Lessa, the sole survivor of the noble ruling family of Ruatha Hold on the northern continent of Pern. When the rest of her family is killed by a cruel usurper, Fax, she survives by disguising herself as a drudge (a menial servant), partly through simply adopting a slovenly appearance, but also by using her hereditary telepathic abilities to make others see her as far older and less attractive than she actually is. Her only friend is a watch-wher, a somewhat telepathic animal related to dragons, that guards the Hold. Lessa psychically influences other Hold workers to do less than their best work, or to become clumsy or inefficient, in order to sabotage Ruatha as part of her strategy to make it economically unproductive, so that Fax will renounce it and she can retake her Hold.\nF'lar, wingleader at Benden Weyr, and rider of the bronze dragon Mnementh, finds Lessa while searching for candidates to impress a new queen dragon. The current queen has a batch of eggs due to hatch shortly, including a crucial golden egg. After killing Fax in single combat, following the rules of the Pernese code duello, he realises that she manipulated him emotionally to kill Fax and engineered Fax's renouncement. F'lar recognizes that Lessa possesses both unusually strong psychic abilities and great strength of will. He recognizes her potential to be the strongest Weyrwoman in recent history, and the path to his own leadership at Benden Weyr. F'lar convinces a reluctant Lessa to give up her birthright as Lord Holder of Ruatha Hold for the larger domain of the dragonweyr and she agrees to pass the title on to Fax's newborn son (who later features in \"The White Dragon\"). F'lar takes Lessa to Benden Weyr, where she Impresses the queen hatchling Ramoth and becomes the Weyrwoman, the new co-leader of the last active Weyr. On Ramoth's first mating flight, Mnementh catches her, and by Weyr tradition, this makes F'lar the Weyrleader.\nOne Weyr by itself is not enough to defend the planet; there had been six, but the other five Weyrs are now empty, deserted since the last Pass centuries before. In a desperate attempt to increase their numbers, a new queen, Prideth, and her rider, Kylara, are sent back \"between\" times (a recently rediscovered skill) ten turns, to allow Prideth time to mature and reproduce. Lessa travels four hundred turns into the past to bring the five 'missing' Weyrs forward to her present. This is a huge strain for both her and Ramoth. She convinces the dragonriders of the five Weyrs to go with her to their future, and they use the Red Star as a guide to make smaller, less strenuous hops forward in time. This not only provides much needed skilled reinforcements in the battle against Thread, but explains how and why the five Weyrs were abandoned: they came forward in time.\nAwards.\n\"Dragonflight\" includes the novellas \"Weyr Search\", which won the 1968 Hugo Award for Best Novella (voted by members of the annual World Science Fiction Convention) and \"Dragonrider\", which won the Nebula Award for Best Novella (voted annually by the Science Fiction Writers of America) in 1969. McCaffrey was the first woman writer to win either award.\nIn 1999, the American Library Association cited the two early Pern trilogies (\"Dragonriders\" and \"Harper Hall\"), along with \"The Ship Who Sang\", when McCaffrey received the annual Margaret A. Edwards Award for her lifetime contribution in writing for teens.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50378", "revid": "32538593", "url": "https://en.wikipedia.org/wiki?curid=50378", "title": "High-speed rail", "text": "Fastest rail-based transport systems \nHigh-speed rail (HSR) is a type of rail transport network utilizing trains that run significantly faster than those of traditional rail, using an integrated system of specialized rolling stock and dedicated tracks. While there is no single definition or standard that applies worldwide, lines built to handle speeds of at least or upgraded lines of at least are generally considered to be high-speed.\nThe first high-speed rail system, the T\u014dkaid\u014d Shinkansen, began operations in Honshu, Japan, in 1964. Due to the streamlined spitzer-shaped nose cone of the trains, the system also became known by its English nickname bullet train. Japan's example was followed by several European countries, initially in Italy with the Direttissima line, followed shortly thereafter by France, Germany, and Spain. Today, much of Europe has an extensive network with numerous international connections. Construction since the 21st century has led to China taking a leading role in high-speed rail. As of 2023[ [update]], China's HSR network accounted for over two-thirds of the world's total.\nIn addition to these, many other countries have developed high-speed rail infrastructure to connect major cities, including: Austria, Belgium, Denmark, Finland, Greece, Indonesia, Morocco, the Netherlands, Norway, Poland, Portugal, Russia, Saudi Arabia, Serbia, South Korea, Sweden, Switzerland, Taiwan, Turkey, the United Kingdom, the United States, and Uzbekistan. Only in continental Europe and Asia does high-speed rail cross international borders.\nHigh-speed trains mostly operate on standard gauge tracks of continuously welded rail on grade-separated rights of way with large radii. However, certain regions with wider legacy railways, including Russia and Uzbekistan, have sought to develop a high-speed railway network in Russian gauge. There are no narrow gauge high-speed railways. Countries whose legacy network is entirely or mostly of a different gauge than \u2013 including Japan and Spain \u2013 have often opted to build their high speed lines to standard gauge instead of the legacy railway gauge.\nHigh-speed rail is the fastest and most efficient ground-based method of commercial transport. Due to requirements for large track curves, gentle gradients and grade separated track the construction of high-speed rail is costlier than conventional rail and therefore does not always present an economical advantage over conventional speed rail.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nDefinitions.\nMultiple definitions for high-speed rail are in use worldwide, with various international organisations and regional bodies establishing different standards. Several countries have also developed their own legal definitions and technical standards for high-speed rail.\nInternational Union of Railways definition.\nThe International Union of Railways (UIC) identifies three categories of high-speed rail:\nA third definition of high-speed and very high-speed rail requires simultaneous fulfilment of the following two conditions:\nThe International Union of Railways prefers to use \"definitions\" (plural) because they consider that there is no single standard definition of high-speed rail, nor even standard usage of the terms (\"high speed\", or \"very high speed\"). They make use of the European EC Directive 96/48, stating that high speed is a combination of all the elements which constitute the system: infrastructure, rolling stock and operating conditions. The International Union of Railways states that high-speed rail is a set of unique features, not merely a train travelling above a particular speed. Many conventionally hauled trains are able to reach in commercial service but are not considered to be high-speed trains. These include the French SNCF Intercit\u00e9s and German DB IC.\nThe criterion of is selected for several reasons; above this speed, the impacts of geometric defects are intensified, track adhesion is decreased, aerodynamic resistance is greatly increased, pressure fluctuations within tunnels cause passenger discomfort, and it becomes difficult for drivers to identify trackside signalling. Standard signaling equipment is often limited to speeds below , with the traditional limits of in the US, in Germany and in Britain. Above those speeds positive train control or the European Train Control System becomes necessary or legally mandatory.\nEuropean Union definition.\nThe European Union Directive 96/48/EC, Annex 1 (see also Trans-European high-speed rail network) defines high-speed rail in terms of:\nNational legal definitions.\nSome national legal definitions of high-speed rail include:\nAustralia.\nAccording to the High Speed Rail Authority Act 2022, high-speed rail in Australia is defined as a railway capable of supporting trains that can travel at speeds exceeding 250\u00a0km/h. As of 2025, Australia does not have any railways which meet this definition.\nChina.\nAccording to China's Ministry of Railways \"Order No. 34 (2013)\", high-speed rail refers to new passenger rail lines designed to operate at speeds of 250\u00a0km/h or higher, with initial service running at least 200\u00a0km/h.\nJapan.\nThe first law defining high-speed rail was Japan's \"\"Law number 71 for Construction of Nation-Wide High-Speed Railways\",\" adopted on May 18, 1970.\nArticle 2 of this law provided the following definition: \"An artery railway that is capable of operating at the speed of 200km/h or more in its predominating section.\" \nThis law formalised the definition of high-speed railways in Japan and established a framework for the Shinkansen network, which had started in operation since 1964.\nSouth Korea.\nSouth Korea defines high-speed rail through the Railway Service Act (2004), which categorises railway lines and trains into three types:\nThe Act also categorises trains into corresponding types based on their maximum speeds.\nUnited States.\nUnited States federal law defines high-speed rail as intercity passenger rail service expected to reach speeds of at least .\nHistory.\nRailways were the first form of rapid land transport and had an effective monopoly on long-distance passenger traffic until the development of the motor car and airliners in the early to mid-20th century. Speed had always been an important factor for railways and they constantly tried to achieve higher speeds and decrease journey times. Rail transport in the late 19th century was not much slower than non-high-speed trains today, and many railways regularly operated relatively fast express trains which averaged speeds of around .\nEarly research.\nFirst experiments.\nHigh-speed rail development began in Germany in 1899 when the Prussian state railway joined with ten electrical and engineering firms and electrified of military owned railway between Marienfelde and Zossen. The line used three-phase current at 10 kilovolts and 45 Hz.\nThe Van der Zypen &amp; Charlier company of Deutz, Cologne built two railcars, one fitted with electrical equipment from Siemens-Halske, the second with equipment from \"Allgemeine Elektricit\u00e4ts-Gesellschaft\" (AEG), that were tested on the Marienfelde\u2013Zossen line during 1902 and 1903 (see Experimental three-phase railcar).\nOn 23 October 1903, the S&amp;H-equipped railcar achieved a speed of and on 27 October the AEG-equipped railcar achieved . These trains demonstrated the feasibility of electric high-speed rail; however, regularly scheduled electric high-speed rail travel was still more than 30 years away.\nHigh-speed aspirations.\nAfter the breakthrough of electric railroads, it was clearly the infrastructure \u2013 especially the cost of it \u2013 which hampered the introduction of high-speed rail. Several disasters happened \u2013 derailments, head-on collisions on single-track lines, collisions with road traffic at grade crossings, etc. The physical laws were well-known, i.e. if the speed was doubled, the curve radius should be quadrupled; the same was true for the acceleration and braking distances.\nIn 1891, engineer K\u00e1roly Zipernowsky proposed a high-speed line from Vienna to Budapest for electric railcars at . In 1893 Wellington Adams proposed an air-line from Chicago to St. Louis of , at a speed of only .\nAlexander C. Miller had greater ambitions. In 1906, he launched the \"Chicago-New York Electric Air Line Railroad\" project to reduce the running time between the two big cities to ten hours by using electric locomotives. After seven years of effort, less than of straight track was finished. A part of the line is still used as one of the last interurbans in the US.\nHigh-speed interurbans.\nIn the US, some of the interurbans (i.e. trams or streetcars which run from city to city) of the early 20th century were very high-speed for their time (also Europe had and still does have some interurbans). Several high-speed rail technologies have their origin in the interurban field.\nIn 1903 \u2013 30 years before the conventional railways started to streamline their trains \u2013 the officials of the Louisiana Purchase Exposition organised the Electric Railway Test Commission to conduct a series of tests to develop a carbody design that would reduce wind resistance at high speeds. A long series of tests was carried. In 1905, St. Louis Car Company built a railcar for the traction magnate Henry E. Huntington, capable of speeds approaching . Once it ran between Los Angeles and Long Beach in 15 minutes, an average speed of . However, it was too heavy for much of the tracks, so Cincinnati Car Company, J. G. Brill and others pioneered lightweight constructions, use of aluminium alloys, and low-level bogies which could operate smoothly at extremely high speeds on rough interurban tracks. Westinghouse and General Electric designed motors compact enough to be mounted on the bogies. From 1930 on, the Red Devils from Cincinnati Car Company and a some other interurban rail cars reached about in commercial traffic. The Red Devils weighed only 22 tons though they could seat 44 passengers.\nExtensive wind tunnel research \u2013 the first in the railway industry \u2013 was done before J. G. Brill in 1931 built the Bullet cars for Philadelphia and Western Railroad (P&amp;W). They were capable of running at . Some of them were almost 60 years in service. P&amp;W's Norristown High Speed Line is still in use, almost 110 years after P&amp;W in 1907 opened their double-track Upper Darby\u2013Strafford line without a single grade crossing with roads or other railways. The entire line was governed by an absolute block signal system.\nEarly German high-speed network.\nOn 15 May 1933, the Deutsche Reichsbahn-Gesellschaft company introduced the diesel-powered \"Fliegender Hamburger\" in regular service between Hamburg and Berlin (), thereby achieving a new top speed for a regular service, with a top speed of . This train was a streamlined multi-powered unit, albeit diesel, and used Jakobs bogies.\nFollowing the success of the Hamburg line, the steam-powered Henschel-Wegmann Train was developed and introduced in June 1936 for service from Berlin to Dresden, with a regular top speed of . Incidentally no train service since the cancelation of this express train in 1939 has traveled between the two cities in a faster time as of 2018[ [update]]. In August 2019, the travel time between Dresden-Neustadt and Berlin-S\u00fcdkreuz was 102 minutes. See Berlin\u2013Dresden railway.\nFurther development allowed the usage of these \"Fliegenden Z\u00fcge\" (flying trains) on a rail network across Germany.\nThe \"Diesel-Schnelltriebwagen-Netz\" (diesel high-speed-vehicle network) had been in the planning since 1934 but it never reached its envisaged size.\nAll high-speed service stopped in August 1939 shortly before the outbreak of World War II.\nAmerican Streamliners.\nOn 26 May 1934, one year after Fliegender Hamburger introduction, the Burlington Railroad set an average speed record on long distance with their new streamlined train, the Zephyr, at with peaks at . The Zephyr was made of stainless steel and, like the Fliegender Hamburger, was diesel powered, articulated with Jacobs bogies, and could reach as commercial speed.\nThe new service was inaugurated 11 November 1934, traveling between Kansas City and Lincoln, but at a lower speed than the record, on average speed .\nIn 1935, the Milwaukee Road introduced the Morning Hiawatha service, hauled at by steam locomotives. In 1939, the largest railroad of the world, the Pennsylvania Railroad introduced a duplex steam engine Class S1, which was designed to be capable of hauling 1200 tons passenger trains at . The S1 engine was assigned to power the popular all-coach overnight premier train the Trail Blazer between New York and Chicago since the late 1940s and it consistently reached in its service life. These were the last \"high-speed\" trains to use steam power. In 1936, the Twin Cities Zephyr entered service, from Chicago to Minneapolis, with an average speed of .\nMany of these streamliners posted travel times comparable to or better than their modern Amtrak successors, which are limited to top speed on most of the network.\nItalian electric and the last steam record.\nThe German high-speed service was followed in Italy in 1938 with an electric-multiple-unit ETR 200, designed for , between Bologna and Naples. It too reached in commercial service, and achieved a world mean speed record of between Florence and Milan in 1938.\nIn Great Britain in the same year, the streamlined steam locomotive \"Mallard\" achieved the official world speed record for steam locomotives at . The external combustion engines and boilers on steam locomotives were large, heavy and time and labor-intensive to maintain, and the days of steam for high speed were numbered.\nIntroduction of the Talgo system.\nIn 1945, a Spanish engineer, Alejandro Goicoechea, developed a streamlined, articulated train that was able to run on existing tracks at higher speeds than contemporary passenger trains. This was achieved by providing the locomotive and cars with a unique axle system that used one axle set per car end, connected by a Y-bar coupler. Amongst other advantages, the centre of mass was only half as high as usual. This system became famous under the name of Talgo (\"Tren Articulado Ligero Goicoechea Oriol\"), and for half a century was the main Spanish provider of high-speed trains.\nFirst above 300\u00a0km/h developments.\nIn the early 1950s, the French National Railway started to receive their new powerful CC 7100 electric locomotives, and began to study and evaluate running at higher speeds. In 1954, the CC 7121 hauling a full train achieved a record during a test on standard track. The next year, two specially tuned electric locomotives, the CC 7107 and the prototype BB 9004, broke previous speed records, reaching respectively and , again on standard track. For the first time, was surpassed, allowing the idea of higher-speed services to be developed and further engineering studies commenced. Especially, during the 1955 records, a dangerous hunting oscillation, the swaying of the bogies which leads to dynamic instability and potential derailment was discovered. This problem was solved by yaw dampers which enabled safe running at high speeds today. Research was also made about \"current harnessing\" at high-speed by the pantographs, which was solved 20 years later by the Z\u00e9bulon TGV's prototype.\nBreakthrough: Shinkansen.\nJapanese research and development.\nWith some 45 million people living in the densely populated Tokyo\u2013Osaka corridor (Taiheiy\u014d Belt), congestion on road and rail became a serious problem after World War II, and the Japanese government began thinking about ways to transport people in and between cities. Because Japan was resource limited and did not want to import petroleum for security reasons, energy-efficient high-speed rail was an attractive potential solution.\nJapanese National Railways (JNR) engineers began to study the development of a high-speed regular mass transit service. In 1955, they were present at the Lille's Electrotechnology Congress in France, and during a 6-month visit, the head engineer of JNR accompanied the deputy director Marcel Tessier at the DETE (SNCF Electric traction study department). JNR engineers returned to Japan with a number of ideas and technologies they would use on their future trains, including alternating current for rail traction, and international standard gauge.\nFirst narrow-gauge Japanese high-speed service.\nIn 1957, the engineers at the private Odakyu Electric Railway in Greater Tokyo Area launched the Odakyu 3000 series SE EMU. This EMU set a world record for narrow gauge trains at , giving the Odakyu engineers confidence they could safely and reliably build even faster trains at standard gauge. Conventional Japanese railways up until that point had largely been built in the Cape gauge, however widening the tracks to standard gauge () would make very high-speed rail much simpler due to improved stability of the wider rail gauge, and thus standard gauge was adopted for high-speed service. With the sole exceptions of Russia, Finland, and Uzbekistan all high-speed rail lines in the world are still standard gauge, even in countries where the preferred gauge for legacy lines is different.\nA new train on a new line.\nThe new service, named Shinkansen (meaning \"new main line\") would provide a new alignment, 25% wider standard gauge utilising continuously welded rails between Tokyo and Osaka with new rolling stock, designed for . However, the World Bank, whilst supporting the project, considered the design of the equipment as unproven for that speed, and set the maximum speed to .\nAfter initial feasibility tests, the plan was fast-tracked and construction of the first section of the line started on 20 April 1959. In 1963, on the new track, test runs hit a top speed of . Five years after the beginning of the construction work, in October 1964, just in time for the Olympic Games, the first modern high-speed rail, the T\u014dkaid\u014d Shinkansen, was opened between the two cities; a line between Tokyo and \u014csaka. As a result of its speeds, the Shinkansen earned international publicity and praise, and it was dubbed the \"bullet train.\"\nThe first Shinkansen trains, the 0 Series Shinkansen, built by Kawasaki Heavy Industries\u00a0\u2013 in English often called \"Bullet Trains\", after the original Japanese name \u00a0\u2013 outclassed the earlier fast trains in commercial service. They traversed the distance in 3 hours 10 minutes, reaching a top speed of and sustaining an average speed of with stops at Nagoya and Kyoto.\nHigh-speed rail for the masses.\nSpeed was not only a part of the Shinkansen revolution: the Shinkansen offered high-speed rail travel to the masses. The first \"Bullet trains\" had 12 cars and later versions had up to 16, and double-deck trains further increased the capacity.\nAfter three years, more than 100 million passengers had used the trains, and the milestone of the first one billion passengers was reached in 1976. In 1972, the line was extended a further , and further construction has resulted in the network expanding to of high speed lines as of 2024, with a further of extensions currently under construction and due to open in 2038. The cumulative patronage on the entire system since 1964 is over 10 billion, the equivalent of approximately 140% of the world's population, without a single train passenger fatality. (Suicides, passengers falling off the platforms, and industrial accidents have resulted in fatalities.)\nSince their introduction, Japan's Shinkansen systems have been undergoing constant improvement, not only increasing line speeds. Over a dozen train models have been produced, addressing diverse issues such as tunnel boom noise, vibration, aerodynamic drag, lines with lower patronage (\"Mini shinkansen\"), earthquake and typhoon safety, braking distance, problems due to snow, and energy consumption (newer trains are twice as energy-efficient as the initial ones despite greater speeds).\nFuture developments of Shinkansen.\nAfter decades of research and successful testing on a test track, in 2014 JR Central began constructing a Maglev Shinkansen line, which is known as the Ch\u016b\u014d Shinkansen. These Maglev trains still have the traditional underlying tracks and the cars have wheels. This serves a practical purpose at stations and a safety purpose out on the lines in the event of a power failure. However, in normal operation, the wheels are raised up into the car as the train reaches certain speeds where the magnetic levitation effect takes over. It is proposed to link Tokyo and Osaka by 2037, with the section from Tokyo to Nagoya expected to be operational by 2034. Maximum speed is anticipated at . The first generation train can be ridden by tourists visiting the test track.\nEurope and North America in 1960s and 1970s.\nFirst demonstrations at.\nIn Europe, high-speed rail began during the International Transport Fair in Munich in June 1965, when Dr \u00d6pfering, the director of Deutsche Bundesbahn (German Federal Railways), performed 347 demonstrations at between Munich and Augsburg by DB Class 103 hauled trains. The same year the A\u00e9rotrain, a French hovercraft monorail train prototype, reached within days of operation.\n\"Le Capitole\".\nAfter the successful introduction of the Japanese Shinkansen in 1964, at , the German demonstrations up to in 1965, and the proof-of-concept jet-powered A\u00e9rotrain, SNCF ran its fastest trains at .\nIn 1966, French Infrastructure Minister Edgard Pisani consulted engineers and gave the French National Railways twelve months to raise speeds to . The classic line Paris\u2013Toulouse was chosen, and fitted, to support rather than . Some improvements were set, notably the signals system, development of on board \"in-cab\" signalling system, and curve revision.\nThe next year, in May 1967, a regular service at was inaugurated by the TEE \"Le Capitole\" between Paris and Toulouse, with specially adapted SNCF Class BB 9200 locomotives hauling classic UIC cars, and a full red livery. It averaged over the .\nAt the same time, the A\u00e9rotrain prototype 02 reached on a half-scale experimental track. In 1969, it achieved on the same track. On 5 March 1974, the full-scale commercial prototype A\u00e9rotrain I80HV, jet powered, reached .\nUS Metroliner trains.\nIn the United States, following the creation of Japan's first high-speed Shinkansen, President Lyndon B. Johnson as part of his Great Society infrastructure building initiatives asked the Congress to devise a way to increase speeds on the railroads. Congress delivered the High Speed Ground Transportation Act of 1965 which passed with overwhelming bipartisan support and helped to create regular Metroliner service between New York City, Philadelphia, and Washington, D.C. The new service was inaugurated in 1969, with top speeds of and averaging along the route, with the travel time as little as 2 hours 30 minutes. In a 1967 competition with a GE powered Metroliner on Penn Central's mainline, the United Aircraft Corporation TurboTrain set a record of .\nUnited Kingdom, Italy and Germany.\nIn 1976 British Rail introduced a high-speed service able to reach using the InterCity 125 diesel-electric trainsets under the brand name of High Speed Train (HST). It was the fastest diesel-powered train in regular service and it improved upon its forerunners in speed and acceleration. As of 2025 it is still in regular service as the fastest diesel-powered train. The train is a reversible multi-car set having driving power-cars at both ends and a fixed formation of passenger cars between them. Journey times were reduced by an hour for example on the East Coast Main Line, and passenger numbers increased. Prior to COVID-19, ridership of the UK's High Speed Intercity Services had exceeded 40 million journeys per annum.\nIn 1977 Germany introduced a new service at , on the Munich\u2013Augsburg line. That same year, Italy inaugurated the first European High-Speed line, the \"Direttissima\" between Rome and Florence, designed for , but used by FS E444 hauled train at . In France this year also saw the abandonment for political reasons of the A\u00e9rotrain project, in favour of the TGV.\nEvolution in Europe.\nItaly.\nThe earliest European high-speed railway to be built was the Italian Florence\u2013Rome high-speed railway (also called \"Direttissima\") in 1977. High-speed trains in Italy were developed during the 1960s. E444 locomotives were the first standard locomotives capable of , while an ALe 601 electrical multiple unit (EMU) reached a speed of during a test. Other EMUs, such as the ETR 220, ETR 250 and ETR 300, were also updated for speeds up to . The braking systems of cars were updated to match the increased speeds.\nOn 25 June 1970, work was started on the Rome\u2013Florence \"Direttissima\", the first high-speed line in Italy and in Europe. It included the bridge on the Paglia river, then the longest in Europe. Works were completed in the early 1990s.\nIn 1975, a program for a widespread updating of rolling stock was launched. As it was decided to put more emphasis on local traffic, this caused a shifting of resources from the ongoing high-speed projects, with their subsequent slowing or, in some cases, total abandonment. Therefore, 160 E.656 electric and 35 D.345 locomotives for short-medium range traffic were acquired, together with 80 EMUs of the ALe 801/940 class, 120 ALn 668 diesel railcars. Some 1,000 much-needed passenger and 7,000 freight cars were also ordered.\nIn the 1990s, work started on the Treno Alta Velocit\u00e0 (\"TAV\") project, which involved building a new high-speed network on the routes Milan \u2013 (Bologna\u2013Florence\u2013Rome\u2013Naples) \u2013 Salerno, Turin \u2013 (Milan\u2013Verona\u2013Venice) \u2013 Trieste and Milan\u2013Genoa. Most of the planned lines have already been opened, while international links with France, Switzerland, Austria and Slovenia are underway.\nMost of the Rome\u2013Naples line opened in December 2005, the Turin\u2013Milan line partially opened in February 2006 and the Milan\u2013Bologna line opened in December 2008. The remaining sections of the Rome\u2013Naples and the Turin\u2013Milan lines and the Bologna\u2013Florence line were completed in December 2009. All these lines are designed for speeds up to . Since then, it is possible to travel from Turin to Salerno () in less than 5 hours. More than 100 trains per day are operated.\nOther proposed high-speed lines are Salerno-Reggio Calabria (connected to Sicily with the future bridge over the Strait of Messina), Palermo-Catania and Naples\u2013Bari.\nThe main public operator of high-speed trains (\"alta velocit\u00e0 AV\", formerly Eurostar Italia) is Trenitalia, part of FSI. Trains are divided into three categories (called \"Le Frecce\"): \"Frecciarossa\" (\"Red arrow\") trains operate at a maximum of on dedicated high-speed tracks; \"Frecciargento\" (Silver arrow) trains operate at a maximum of on both high-speed and mainline tracks; \"Frecciabianca\" (White arrow) trains operate at a maximum of on mainline tracks only.\nSince 2012, a new and Italy's first private train operator, NTV (branded as Italo), runs high-speed services in competition with Trenitalia. Italy is the only country in Europe with a private high-speed train operator.\nConstruction of the Milan-Venice high-speed line began in 2013 and in 2016 the Milan-Treviglio section has been opened to passenger traffic; the Milan-Genoa high-speed line (Terzo Valico dei Giovi) is also under construction.\nToday it is possible to travel from Rome to Milan in less than 3 hours with the Frecciarossa 1000 high-speed train. There is a train every 30 minutes.\nFrance.\nFollowing the 1955 records, two divisions of the SNCF began to study high-speed services. In 1964, the DETMT (petrol-engine traction studies department of SNCF) investigated the use of gas turbines: a diesel-powered railcar was modified with a gas-turbine, and was called \"TGV\" (Turbotrain Grande Vitesse). It reached in 1967, and served as a basis for the future Turbotrain and the real TGV. At the same time, the new \"SNCF Research Department\", created in 1966, was studying various projects, including one code-named \"C03: Railways possibilities on new infrastructure (tracks)\".\nIn 1969, the \"C03 project\" was transferred to public administration while a contract with Alstom was signed for the construction of two gas-turbine high-speed train prototypes, named \"TGV 001\". The prototype consisted of a set of five carriages, plus a power car at each end, both powered by two gas-turbine engines. The sets used Jacobs bogies, which reduce drag and increase safety.\nIn 1970, the DETMT's Turbotrain began operations on the Paris\u2013Cherbourg line, and operated at despite being designed for usage at . It used gas-turbine powered multiple elements and was the basis for future experimentation with TGV services, including shuttle services and regular high rate schedules.\nIn 1971, the \"C03\" project, now known as \"TGV Sud-Est\", was validated by the government, against Bertin's Aerotrain. Until this date, there was a rivalry between the French Land Settlement Commission (DATAR), supporting the A\u00e9rotrain, and the SNCF and its ministry, supporting conventional rail. The \"C03 project\" included a new High-Speed line between Paris and Lyon, with new multi-engined trains running at . At that time, the classic Paris-Lyon line was already congested and a new line was required; this busy corridor, neither too short (where high speeds give limited reductions in end to end times) nor too long (where planes are faster in city center to city center travel time), was the best choice for the new service.\nThe 1973 oil crisis substantially increased oil prices. In the continuity of the De Gaulle \"energy self-sufficiency\" and nuclear-energy policy (Pierre Messmer then French Prime Minister announced an ambitious buildout of nuclear power in France in 1974), a ministry decision switched the future TGV from now costly gas-turbine to full electric energy in 1974. An electric railcar named \"Z\u00e9bulon\" was developed for testing at very high speeds, reaching a speed of . It was used to develop pantographs capable of withstanding speeds of over .\nAfter intensive tests with the gas-turbine \"TGV 001\" prototype, and the electric \"Z\u00e9bulon\", in 1977, the SNCF placed an order to the group Alstom\u2013Francorail\u2013MTE for 87 TGV Sud-Est trainsets.\nThey used the \"TGV 001\" concept, with a permanently coupled set of eight cars, sharing Jacobs bogies, and hauled by two electric-power cars, one at each end.\nIn 1981, the first section of the new Paris\u2013Lyon High-Speed line was inaugurated, with a top speed (then soon after). Being able to use both dedicated high-speed and conventional lines, the TGV offered the ability to join every city in the country at shorter journey times. After the introduction of the TGV on some routes, air traffic on these routes decreased and in some cases disappeared. The TGV set a publicised speed records in 1981 at , in 1990 at , and then in 2007 at , although these were test speeds, rather than operation train speeds.\nGermany.\nFollowing the ETR 450 and Direttissima in Italy and French TGV, in 1991 Germany was the third country in Europe to inaugurate a high-speed rail service, with the launch of the Intercity-Express (ICE) on the new Hanover\u2013W\u00fcrzburg high-speed railway, operating at a top speed of . The German ICE train was similar to the TGV, with dedicated streamlined power cars at both ends, but a variable number of trailers between them. Unlike the TGV, the trailers had two conventional bogies per car, and could be uncoupled, allowing the train to be lengthened or shortened. This introduction was the result of ten years of study with the ICE-V prototype, originally called Intercity Experimental, which broke the world speed record in 1988, reaching .\nSpain.\nIn 1992, just in time for the Barcelona Olympic Games and Seville Expo '92, the Madrid\u2013Seville high-speed rail line opened in Spain with 25 kV AC electrification, and standard gauge, differing from all other Spanish lines which used Iberian gauge. This allowed the AVE rail service to begin operations using Class 100 trainsets built by Alstom, directly derived in design from the French TGV trains. The service was very popular and development continued on high-speed rail in Spain.\nIn 2005, the Spanish government announced an ambitious plan, (PEIT 2005\u20132020) envisioning that by 2020, 90 percent of the population would live within of a station served by AVE. Spain began building the largest HSR network in Europe: as of 2011[ [update]], five of the new lines have opened (Madrid\u2013Zaragoza\u2013Lleida\u2013Tarragona\u2013Barcelona, C\u00f3rdoba\u2013Malaga, Madrid\u2013Toledo, Madrid\u2013Segovia\u2013Valladolid, Madrid\u2013Cuenca\u2013Valencia) and another were under construction. Opened in early 2013, the Perpignan\u2013Barcelona high-speed rail line provides a link with neighbouring France with trains running to Paris, Lyon, Montpellier and Marseille.\nAs of January\u00a02025[ [update]], the Spanish high-speed rail network is the longest HSR network in Europe with and the second longest in the world, after China's.\nTurkey.\nIn 2009, Turkey inaugurated a high-speed service between Ankara and Eski\u015fehir. This has been followed up by an Ankara \u2013 Konya route, and the Eskisehir line has been extended to Istanbul (European part). In this extension, Europe and Asia were connected by an undersea tunnel, Marmaray in the Bosphorus. The first connection between two continents in the world as a high-speed train line was made in Istanbul. The last station of this line in Europe is Halkal\u0131 station. An extension to Sivas was opened in April 2023.\nNorth America.\nUnited States.\nIn 1992, the United States Congress passed the Amtrak Authorization and Development Act that authorised Amtrak to start working on service improvements on the segment between Boston and New York City of the Northeast Corridor. The primary objectives were to electrify the line north of New Haven, Connecticut, to eliminate grade crossings and replace the then 30-year-old Metro liners with new trains, so that the distance between Boston and New York City could be covered in 3 hours or less.\nAmtrak started testing two trains, the Swedish X2000 and the German ICE 1, in the same year along its fully electrified segment between New York City and Washington, D.C. The officials favored the X2000 as it had a tilting mechanism. However, the Swedish manufacturer never bid on the contract as the burdensome United States railroad regulations required them to heavily modify the train resulting in added weight, among other things. Eventually, a custom-made tilting train derived from TGV, manufactured by Alstom and Bombardier, won the contract and was put into service in December 2000.\nThe new service was named \"Acela Express\" and linked Boston, New York City, Philadelphia, Baltimore, and Washington, D.C. The service did not meet the 3-hour travel time objective between Boston and New York City. The time was 3 hours and 24 minutes as it partially ran on regular lines, limiting its average speed, with a maximum speed of being reached on a section of its route through Rhode Island and Massachusetts.\nAs of November 2021, the U.S. has one high-speed rail line under construction (California High-Speed Rail) in California, and advanced planning by a company called Texas Central Railway in Texas, higher-speed rail projects in the Pacific Northwest, Midwest and Southeast, as well as upgrades on the high-speed Northeast Corridor. The private higher speed rail venture Brightline in Florida started operations along part of its route in early 2018. The top speed is but most of the line still runs at .\nExpansion in East, Southeast, and South Asia.\nFor four decades since its opening in 1964, the Japanese Shinkansen was the only high-speed rail service outside of Europe. In the 2000s a number of new high-speed rail services started operating in East Asia. Southeast Asia also saw, and South Asia will see their first high-speed rail service in the 2020s.\nChina.\nHigh-speed rail was introduced to China in 2003 with the Qinhuangdao\u2013Shenyang high-speed railway.\nThe Chinese government made high-speed rail construction a cornerstone of the Chinese economic stimulus program to mitigate the effects of the 2008 financial crisis and the result has been a rapid development of the Chinese rail system into the world's most extensive high-speed rail network. By 2013 the system had of operational track, accounting for about half of the world's total at the time.\nBy the end of 2018, the total high-speed railway (HSR) in China had risen to over .\nOver 1.71 billion trips were made in 2017, more than half of China's total railway passenger delivery, making it the world's busiest network.\nState planning for high-speed railway began in the early 1990s, and the country's first high-speed rail line, the Qinhuangdao\u2013Shenyang Passenger Railway, was built in 1999 and opened to commercial operation in 2003. This line could accommodate commercial trains running at up to . Planners also considered Germany's Transrapid maglev technology and built the Shanghai maglev train, which runs on a track linking the Pudong, the city's financial district, and the Pudong International Airport.\nThe maglev train service began operating in 2004 with trains reaching a top speed of , and remains the fastest high-speed service in the world. Maglev, however, was not adopted nationally and all subsequent expansion features high-speed rail on conventional tracks.\nIn the 1990s, China's domestic train production industry designed and produced a series of high-speed train prototypes but few were used in commercial operation and none were mass-produced. The Chinese Ministry of Railways (MOR) then arranged for the purchase of foreign high-speed trains from French, German, and Japanese manufacturers along with certain technology transfers and joint ventures with domestic trainmakers. In 2007, the MOR introduced the China Railways High-speed (CRH) service, also known as \"Harmony Trains\", a version of the German Siemens Velaro high-speed train.\nIn 2008, high-speed trains began running at a top speed of on the Beijing\u2013Tianjin intercity railway, which opened during the 2008 Summer Olympics in Beijing. The following year, trains on the newly opened Wuhan\u2013Guangzhou high-speed railway set a world record for average speed over an entire trip, at over .\nA collision of high-speed trains on 23 July 2011 in Zhejiang province killed 40 and injured 195, raising concerns about operational safety. This fatal accident, which happened in the midst of corruption investigations into railway officials, led to greater scrutiny in the Chinese press concerning HSR safety, high ticket prices, financial sustainability, and environmental impact. Following the accident, top train speeds were lowered to . \nA credit crunch later that year slowed the construction of new lines. But by 2012, the high-speed rail boom had renewed with new lines and new rolling stock by domestic producers that had indigenised foreign technology. On 26 December 2012, China opened the Beijing\u2013Guangzhou\u2013Shenzhen\u2013Hong Kong high-speed railway, the world's longest high-speed rail line, which runs from Beijing West railway station to Shenzhen North Railway Station.\nThe network set a target to create the 4+4 National high-speed rail Grid by 2015, and continues to rapidly expand with the July 2016 announcement of the 8+8 National high-speed rail Grid. In 2017, services resumed on the Beijing\u2013Shanghai high-speed railway, once again refreshing the world record for average speed with select services running between Beijing South to Nanjing South reaching average speeds of .\nLike Japan, China is also developing maglev system to run trains with even higher speeds. Currently there are two separate high-speed maglev systems being developed in China: \nThere are concerns over China's high-speed rail's cost, debt and profitability. The system lost around $25 billion from 2020 to 2022 during the COVID-19 pandemic. As of the end of 2023 the system has an accumulated debt of $839 billion due to opaque financing by local governments. In terms of annual operating revenues and expenditures, only six lines break even while the rest have huge losses due to low passenger volumes. Many of the stations on the newest lines are located well outside centers of metro areas and without direct local highway nor light rail connections, as officials have used high-speed rail construction primarily to drive up land value for land sales (especially in third and fourth-tier cities), instead of prioritizing convenience and affordability of ordinary travelers. A Paulson Institute research argued that the net benefit of the high-speed rail is $378 billion and the return on investment is 6.5%. A World Bank study found \"a broad range of travelers of different income levels choose HSR for its comfort, convenience, safety and punctuality.\"\nSouth Korea.\nIn South Korea, construction of the high-speed line from Seoul to Busan began in 1992. The Seoul\u2013Busan corridor is Korea's busiest running between the two largest cities. In 1982, it represented 65.8% of South Korea's population, a number that grew to 73.3% by 1995, along with 70% of freight traffic and 66% of passenger traffic. With both the Gyeongbu Expressway and Korail's Gyeongbu Line congested as of the late 1970s, the government saw the pressing need for another form of transportation.\nThe line known as Gyeongbu high-speed railway, better known with the Korea Train Express (KTX) service operating on it, was launched on 1 April 2004, using primarily TGV technology from France. Top speed for trains in regular service is currently , though the infrastructure is designed for . In 2015 and 2016, high-speed rail services were extended to other parts of the country, with the Honam high-speed railway connecting Gwangju, and Suseo\u2013Pyeongtaek high-speed railway as the second link from Seoul, entered operation. Super Rapid Train, an open-access operator, started joining the market to operate services on the latter in the same year. Some existing conventional lines, including Gyeonggang Line and Jungang Line, are also upgraded to semi-high-speed standard, further expanded the KTX network.\nThe initial rolling stock was based on Alstom's TGV R\u00e9seau, and was partly built in Korea. The domestically developed HSR-350x, which achieved in tests, resulted in a second type of high-speed trains now operated by Korail, the KTX-Sancheon, which entered into commercial service in 2010. The next generation experimental EMU prototype, HEMU-430X, achieved in 2013, making South Korea the world's fourth country after France, Japan, and China to develop a high-speed train running on conventional rail above . It was further developed into commercialised variants, namely KTX-Eum and KTX-Cheongryong, with respective maximum service speeds of and , which entered into KTX services in 2021 and 2024, respectively.\nTaiwan.\nTaiwan High Speed Rail's first and only HSR line opened for service on 5 January 2007, using Japanese trains with a top speed of . The service traverses from to in as little as 105 minutes. While it contains only one line, its route covers Western Taiwan where over 90% of Taiwan's population live; connecting most major cities of Taiwan: Taipei, New Taipei, Taoyuan, Hsinchu, Taichung, Chiayi, Tainan, and Kaohsiung. Once THSR began operations, almost all passengers switched from airlines flying parallel routes while road traffic was also reduced. Extension from both of current ends are being studied, and it was announced in December 2024 that the end from Zuoying will be extended to Kaohsiung city centre and Pingtung.\nIndonesia.\nIndonesia is the first country in Southeast Asia to operate high-speed rail. The concept was first seriously considered in 2008, leading to discussions at the Asian Investment Summit in 2013, and detailed plans were established in 2015. Plans to begin construction of the Jakarta-Bandung HSR were announced by the Indonesian government in July 2015, after the Chinese President and other world leaders visited the Bandung Conference.\nBoth Japan and China expressed interest in high-speed rail projects in Indonesia, which highlighted the rivalry between them in their race for Asian infrastructure projects. In mid-September 2015, China announced it would fully meet the Indonesian government's demands and offered a new proposal that did not require Indonesia to assume any fiscal burden or debt guarantee in proceeding with the project. Later that month, Indonesia selected China for the $5 billion project.\nThe construction of the first high-speed rail service, linking two major cities of Jakarta and Bandung with a distance of , started in August 2018, with the cost of $7.3 billion to build. The line began trial operation with passengers on 7 September 2023 and commercial operations on 17 October 2023. It is operated with a maximum operating speed of by Kereta Cepat Indonesia China, a joint venture of Indonesian and Chinese state-owned enterprises. This route also serves as an initial project for future development plans.\nMiddle East and Central Asia.\nUzbekistan.\nUzbekistan opened the Afrosiyob service from Tashkent to Samarkand in 2011, which was upgraded in 2013 to an average operational speed of and peak speed of . The Talgo 250 service has been extended to Karshi as of August 2015 whereby the train travels in 3 hours. As of August 2016, the train service was extended to Bukhara, and the extension will take 3 hours and 20 minutes down from 7 hours.\nAfrica.\nEgypt.\nAs of 2022[ [update]], there are no operational high-speed rail lines in Egypt. Plans have been announced for three lines, aiming to connect the Nile river valley, the Mediterranean coast, and the Red Sea. Construction had started on at least two lines.\nMorocco.\nIn November 2007, the Moroccan government decided to undertake the construction of a high-speed rail line between the economic capital Casablanca and Tangier, one of the largest harbour cities on the Strait of Gibraltar. The line will also serve the capital Rabat and Kenitra. The first section of the line, the Kenitra\u2013Tangier high-speed rail line, was completed in 2018. Future projects include expansions south to Marrakech and Agadir, and east to Meknes, Fes and Oujda.\nNetwork.\nTechnologies.\nContinuous welded rail is generally used to reduce track vibrations and misalignment. Almost all high-speed lines are electrically driven via overhead lines, have in-cab signalling, and use advanced switches using very low entry and frog angles. HSR tracks may also be designed to reduce vibrations originating from high speed rail use.\nRoad-rail parallel layout.\nThe road-rail parallel layout uses land beside highways for railway lines. Examples include Paris/Lyon and K\u00f6ln\u2013Frankfurt in which 15% and 70% of the track runs beside highways, respectively. There are synergies to be achieved from such a setup as noise mitigation measures for the road benefit the railway and vice versa and furthermore less land must be taken through expropriation as land may have already been acquired for the construction of the other infrastructure. In addition to that, habitats of local wildlife are disrupted only once (by the combined rail/road right of way) instead of at multiple points. However, downsides include the fact that roads usually allow steeper grades and sharper turns than high-speed rail lines and thus co-locating them may not always be suitable. Moreover, both roads and railways often make use of narrow river valleys or mountain passes which do not allow a lot of infrastructure to be sited next to each other.\nTrack sharing.\nIn China, high-speed lines at speeds between may carry freight or passengers, while lines operating at speeds over are used only by passenger CRH/CR trains.\nIn the United Kingdom, HS1 is also used by regional trains run by Southeastern at speeds of up to , and occasionally freight trains that run to central Europe.\nIn Germany, some lines are shared with Inter-City and regional trains at day and freight trains at night.\nIn France, some lines are shared with regional trains that travel at , for example TER Nantes-Laval.\nMixing trains of vastly different speeds and/or stopping patterns on the same tracks drastically reduces capacity, so usually a temporal separation (e.g. freight trains use the high-speed line only at night when no or only a few passenger trains operate) is employed or the slower train has to wait at a station or passing siding for the faster train to overtake - even if the faster train is delayed, thus delaying the slower train, too.\nCost.\nThe cost per kilometre in Spain was estimated at between \u20ac9 million (Madrid\u2013Andaluc\u00eda) and \u20ac22 million (Madrid\u2013Valladolid). \nIn Italy, the cost was between \u20ac24 million (Roma\u2013Napoli) and \u20ac68 million (Bologna\u2013Firenze).\nIn the 2010s, costs per kilometre in France ranged from \u20ac18 million (BLP Brittany) to \u20ac26 million (Sud Europe Atlantique). The World Bank estimated in 2019 that the Chinese HSR network was built at an average cost of $17\u201321 million per km.\nFreight high-speed rail.\nAll high-speed trains have been designed to carry passengers only. There are very few high-speed freight services in the world; they all use trains that were originally designed to carry passengers.\nDuring the planning of the Tokaido Shinkansen, the Japanese National Railways were planning for freight services along the route. This plan was discarded before the line opened, but since 2019 light freight has been carried on some Shinkansen services.\nThe French TGV La Poste was for a long time the sole very high-speed train service, transporting mail in France for La Poste at a maximum top speed of , between 1984 and 2015. The trainsets were either specifically adapted and built, or converted, passenger TGV Sud-Est trainsets.\nIn Italy, Mercitalia Fast is a high-speed freight service launched in October 2018 by Mercitalia. It uses converted passenger ETR 500 trainsets to carry goods at average speeds of , at first between Caserta and Bologna, with plans to extend the network throughout Italy.\nIn some countries, high-speed rail is integrated with courier services to provide fast door-to-door intercity deliveries. For example, China Railways has partnered with SF Express for high-speed cargo deliveries and offers express deliveries within Germany as well as to some major cities outside the country on the ICE network. Rather than using dedicated freight trains, these use luggage racks and other unused space in passenger trains.\nNon-high-speed freight trains running on high-speed lines is much more common; for example, High Speed 1 sees weekly freight services. However, high speed lines tend to be steeper than regular (non-mountain) railways, which poses a problem for most freight trains as they have a lower power to weight ratio and thus more difficulty climbing steep slopes. For example, the Frankfurt Cologne high speed line has inclines up to 40\u2030. If a high-speed line through even somewhat hilly terrain is to be usable for freight, expensive engineered structures will need to be built, as is the case with the Hannover W\u00fcrzburg high-speed line which contains the longest and the second longest mainline rail tunnel in Germany and altogether runs on tunnels or bridges for roughly half of its length.\nRolling stock.\nKey technologies used in high-speed train rolling stock include tilting trainsets, aerodynamic designs (to reduce drag, lift, and noise), air brakes, regenerative braking, engine technology and dynamic weight shifting. Notable high-speed train manufacturers include Alstom, Hitachi, Kawasaki, Siemens, Stadler Rail, Hyundai Rotem, and CRRC.\nComparison with other modes of transport.\nOptimal distance.\nWhile commercial high-speed trains have lower maximum speeds than jet aircraft, they offer shorter total trip times than air travel for short distances. They typically connect city centre rail stations to each other, while air transport connects airports that are typically farther from city centres.\nHigh-speed rail (HSR) is best suited for journeys of 1 to &lt;templatestyles src=\"Fraction/styles.css\" /&gt;4+1\u20442 hours (about ), for which the train can beat air and car trip time. For trips under about , the process of checking in and going through airport security, as well as travelling to and from the airport, makes the total air journey time equal to or slower than HSR. European authorities treat HSR as competitive with passenger air for HSR trips under &lt;templatestyles src=\"Fraction/styles.css\" /&gt;4+1\u20442 hours.\nHSR eliminated air transport from routes such as Paris\u2013Lyon, Paris\u2013Brussels, Cologne\u2013Frankfurt, Nanjing\u2013Wuhan, Chongqing\u2013Chengdu, Taipei\u2013Kaohsiung, Tokyo\u2013Nagoya, Tokyo\u2013Sendai and Tokyo\u2013Niigata, while also greatly reducing air traffic on routes such as Amsterdam\u2013Brussels, Barcelona-Madrid and Naples\u2013Rome\u2013Milan.\nChina Southern Airlines, China's largest airline, expects the construction of China's high-speed railway network to impact (through increased competition and falling revenues) 25% of its route network in the coming years.\nMarket shares.\nEuropean data indicate that air traffic is more sensitive than road traffic (car and bus) to competition from HSR, at least on journeys of and more. TGV Sud-Est reduced the travel time Paris\u2013Lyon from almost four to about two hours. Market share rose from 40 to 72%. Air and road market shares shrunk from 31 to 7% and from 29 to 21%, respectively. On the Madrid\u2013Seville link, the AVE connection increased share from 16 to 52%; air traffic shrunk from 40 to 13%; road traffic from 44 to 36%, hence the rail market amounted to 80% of combined rail and air traffic. This figure increased to 89% in 2009, according to Spanish rail operator Renfe.\nAccording to Peter Jorritsma, the rail market share \"s\", as compared to planes, can be computed approximately as a function of the travelling time in minutes \"t\" by the logistic formula\nformula_1\nAccording to this formula, a journey time of three hours yields a 65% market share, not taking into account any price differential in tickets.\nIn Japan, there is a so-called \"4-hour wall\" in high-speed rail's market share: If the high-speed rail journey time exceeds 4 hours, then people likely choose planes over high-speed rail. For instance, from Tokyo to Osaka, a 2h22m-journey by Shinkansen, high-speed rail has an 85% market share whereas planes have 15%. From Tokyo to Hiroshima, a 3h44m-journey by Shinkansen, high-speed rail has a 67% market share whereas planes have 33%. The situation is the reverse on the Tokyo to Fukuoka route where high-speed rail takes 4h47m and rail only has 10% market share and planes 90%.\nIn Taiwan, China Airlines cancelled all flights to Taichung Airport within a year of Taiwan high-speed rail starting operations. Completion of the high-speed railway in 2007 led to drastically fewer flights along the island's west coast, with flights between Taipei and Kaohsiung ceasing altogether in 2012.\nEnergy efficiency.\nTravel by rail is more competitive in areas of higher population density or where gasoline is expensive because conventional trains are more fuel-efficient than cars when ridership is high, similar to other forms of mass transit. Very few high-speed trains consume diesel or other fossil fuels but the power stations that provide electric trains with electricity can consume fossil fuels. In Japan (prior to the Fukushima Daiichi nuclear disaster) and France, with very extensive high-speed rail networks, a large proportion of electricity comes from nuclear power. On the Eurostar, which primarily runs off the French grid, emissions from traveling by train from London to Paris are 90% lower than by flying. In Germany 38.5% of all electricity was produced from renewable sources in 2017, however railways run on their own grid partially independent from the general grid and relying in part on dedicated power plants. Even using electricity generated from coal, fossil gas or oil, high-speed trains are significantly more fuel-efficient per passenger per kilometer traveled (despite the greater resistance to motion of the railcars at higher speeds) than the typical automobile because of economies of scale in generator technology and trains themselves, as well as lower air friction and rolling resistance at the same speed.\nAutomobiles and buses.\nHigh-speed rail can accommodate more passengers at far higher speeds than automobiles. Generally, the longer the journey, the better the time advantage of rail over the road if going to the same destination. However, high-speed rail can be competitive with cars on shorter distances, , for example for commuting, especially if the car users experience road congestion or expensive parking fees. In Norway, the Gardermoen Line has made the rail market share for passengers from Oslo to the airport (42\u00a0km) rise to 51% in 2014, compared to 17% for buses and 28% for private cars and taxis. On such short lines\u2212particularly services which call at stations close to one another\u2212the acceleration capabilities of the trains may be more important than their maximum speed. Extreme commuting has been enabled by high-speed rail with commuters covering distances by rail daily that they would not usually by car. Furthermore, stations in less densely populated areas within the larger conurbation of larger cities, like Montabaur railway station and Limburg S\u00fcd railway station between Frankfurt and Cologne, are attractive for commuters as the housing prices are more affordable than in the central cities - even when taking into account the price of a yearly ticket for the train. Consequently, Montabaur has the highest per capita rate of Bahn Card 100 in Germany \u2014 a ticket that allows unlimited travel on all trains in Germany for a fixed yearly price.\nMoreover, a typical passenger rail carries 2.83 times as many passengers per hour per meter width as a road. A typical capacity is the Eurostar, which provides capacity for 12 trains per hour and 800 passengers per train, totaling 9,600 passengers per hour in each direction. By contrast, the Highway Capacity Manual gives a maximum capacity of 2,250 passenger cars per hour per lane, excluding other vehicles, assuming an average vehicle occupancy of 1.57\u00a0people. A standard twin track railway has a typical capacity 13% greater than a 6-lane highway (3 lanes each way), while requiring only 40% of the land (1.0/3.0 versus 2.5/7.5 hectares per kilometre of direct/indirect land consumption). The Tokaido Shinkansen line in Japan, has a much higher ratio (with as many as 20,000 passengers per hour per direction). Similarly, commuter roads tend to carry fewer than 1.57 persons per vehicle (Washington State Department of Transportation, for instance, uses 1.2 persons per vehicle) during commute times. Compare this to the capacity of typical small to mid-sized airliners like the Airbus A320 which in a high-density arrangement has 186 seats or the Boeing 737-800 which has an absolute maximum seated capacity of 189 in a high-density single-class layout - as employed for example by Ryanair. If a business or first class section is provided, those airliners will have lower seating capacities than that.\nAir travel.\nPollution.\nHigh-speed rail usually implements electric power and therefore its energy sources can be distant or renewable. The usage of electric power in high-speed rails can thereby result in a reduction of air pollutants as shown in a case study on China's high-speed railways throughout its development. This is an advantage over air travel, which currently uses fossil fuels and is a major source of pollution. Studies regarding busy airports such as LAX, have shown that over an area of about downwind of the airport, where hundreds of thousands of people live or work, the particle number concentration was at least twice that of nearby urban areas, showing that airplane pollution far exceeded road pollution, even from heavy freeway traffic.\nSafety.\nHSR is much simpler to control due to its predictable course. High-speed rail systems reduce (but do not eliminate) collisions with automobiles or people, by using non-grade level track and eliminating grade-level crossings. To date, the only three deadly accidents involving a high-speed train on high-speed tracks in revenue service were the 1998 Eschede train disaster, the 2011 Wenzhou train collision (in which speed was not a factor), and the 2020 Livraga derailment. Shinkansen trains have anti-derailment devices installed under passenger cars, which do not strictly prevent derailment, but prevent the train from travelling a large distance away from train tracks in case a derailment occurs.\nAccidents.\nIn general, travel by high-speed rail has been demonstrated to be remarkably safe. The first high-speed rail network, the Japanese Shinkansen has not had any fatal accidents involving passengers since it began operating in 1964.\nNotable major accidents involving high-speed trains include the following.\n1998 Eschede accident.\nIn 1998, after over thirty years of high-speed rail operations worldwide without fatal accidents, the Eschede accident occurred in Germany: a poorly designed ICE 1 wheel fractured at a speed of near Eschede, resulting in the derailment and destruction of almost the entire set of 16 cars, and the deaths of 101 people. The derailment began at a switch; the accident was made worse when the derailed cars travelling at high speed struck and collapsed a road bridge located just past the switch.\n2011 Wenzhou accident.\nOn 23 July 2011, 13 years after the Eschede train accident, a Chinese CRH2 travelling at collided with a CRH1 which was stopped on a viaduct in the suburbs of Wenzhou, Zhejiang province, China. The two trains derailed, and four cars fell off the viaduct. Forty people were killed and at least 192 were injured, 12 of them severely.\nThe disaster led to a number of changes in management and exploitation of high-speed rail in China. Despite the fact that speed itself was not a factor in the cause of the accident, one of the major changes was to further lower the maximum speeds in high-speed and higher-speed railways in China, the remaining becoming , becoming 200, and becoming 160. Six years later they started to be restored to their original high speeds.\n2013 Santiago de Compostela accident.\nIn July 2013, a high-speed train in Spain travelling at attempted to negotiate a curve whose speed limit is . The train derailed and overturned, resulting in 78 fatalities. Normally high-speed rail has automatic speed limiting restrictions, but this track section is a conventional section and in this case the automatic speed limit was said to be disabled by the driver several kilometers before the station. A few days later, the train worker's union claimed that the speed limiter did not work properly because of lack of proper funding, acknowledging the budget cuts made by the current government. Two days after the accident, the driver was provisionally charged with homicide by negligence. This is the first accident that occurred with a Spanish high-speed train, but it occurred in a section that was not high speed and as mentioned safety equipment mandatory on high-speed track would have prevented the accident.\n2015 Eckwersheim accident.\nOn 14 November 2015, a specialised TGV EuroDuplex was performing commissioning tests on the unopened second phase of the LGV Est high-speed line in France, when it entered a curve, overturned, and struck the parapet of a bridge over the Marne\u2013Rhine Canal. The rear power car came to a rest in the canal, while the remainder of the train came to a rest in the grassy median between the northern and southern tracks. Approximately 50 people were on board, consisting of SNCF technicians and, reportedly, some unauthorised guests. Eleven were killed and 37 were injured. The train was performing tests at 10 percent above the planned speed limit for the line and should have slowed from to before entering the curve. Officials have indicated that excessive speed may have caused the accident. During testing, some safety features that usually prevent accidents like this one are switched off.\n2018 Ankara train collision.\nOn 13 December 2018, a high-speed passenger train travelling at and a locomotive collided near Yenimahalle in Ankara Province, Turkey. Three cars (carriages/coaches) of the passenger train derailed in the collision. Three railroad engineers and five passengers were killed at the scene, and 84 people were injured. Another injured passenger died later, and 34 passengers, including two in critical condition, were treated in several hospitals.\n2020 Livraga derailment.\nOn 6 February 2020, a high-speed train travelling at derailed at Livraga, Lombardy, Italy. The two drivers were killed and a number of passengers were injured. The cause as reported by investigators was that a faulty set of junction points was in the reverse position, but was reported by the signaling system as being in the normal \u2013 i.e. straight \u2013 position.\nRidership.\nHigh-speed rail ridership has been increasing rapidly since 2000. At the beginning of the century, the largest share of ridership was on the Japanese Shinkansen network. In 2000, the Shinkansen was responsible for about 85% of the cumulative world ridership up to that point.\nThis has been progressively surpassed by the Chinese high-speed rail network, which has been the largest contributor of global ridership growth since its inception. As of 2018, annual ridership of the Chinese high-speed rail network is over five times larger than that of the Shinkansen.\nRecords.\nSpeed.\nThere are several definitions of \"maximum speed\":\nAbsolute speed record.\nOverall rail record.\nThe speed record for a pre-production unconventional passenger train was set by a seven-car L0 series manned maglev train at on 21 April 2015 in Yamanashi Prefecture, Japan.\nConventional rail.\nSince the 1955 record, where France recorded a world record of speed of 331\u00a0km/h, France has nearly continuously held the absolute world speed record. The latest record is held by a TGV POS trainset, which reached in 2007, on the newly constructed LGV Est high-speed line. This run was for proof of concept and engineering, not to test normal passenger service.\nMaximum speed in service.\nAs of 2022[ [update]], the fastest trains currently in commercial operation are:\nMany of these trains and their networks are technically capable of higher speeds but they are capped out of economic and commercial considerations (cost of electricity, increased maintenance, resulting ticket price, etc.)\nLevitation trains.\nThe Shanghai Maglev Train reaches during its daily service on its dedicated line, holding the speed record for commercial train service. \nConventional rail.\nThe fastest operating conventional trains are the Chinese CR400A and CR400B running on Beijing\u2013Shanghai HSR, after China relaunched its 350\u00a0km/h class service on select services effective 21 September 2017. In China, from July 2011 until September 2017, the maximum speed was officially , but a tolerance was acceptable, and trains often reached . Before that, from August 2008 to July 2011, China Railway High-speed trains held the highest commercial operating speed record with on some lines such as the Wuhan\u2013Guangzhou high-speed railway.\nThe speed of the service was reduced in 2011 due to high costs and safety concerns the top speeds in China were reduced to on 1 July 2011. Six years later they started to be restored to their original high speeds.\nOther fast conventional trains are the French TGV POS, German ICE 3, and Japanese E5 and E6 Series Shinkansen with a maximum commercial speed of , the former two on some French high-speed lines, and the latter on a part of Tohoku Shinkansen line.\nIn Spain, on the Madrid\u2013Barcelona HSL, maximum speed is .\nService distance.\nThe China Railway G403/4, G405/6 and D939/40 Beijing\u2013Kunming train (, 10 hours 43 minutes to 14 hours 54 minutes), which began service on 28 December 2016, are the longest high-speed rail services in the world.\nExisting systems by country and region.\nThe early high-speed lines, built in France, Japan, Italy and Spain, were between pairs of large cities. In France, this was Paris\u2013Lyon, in Japan, Tokyo\u2013Osaka, in Italy, Rome\u2013Florence, in Spain, Madrid\u2013Seville (then Barcelona). In European and East Asian countries, dense networks of urban subways and railways provide connections with high-speed rail lines.\nAsia.\nChina.\nChina has the largest network of high-speed railways in the world. As of 2022[ [update]] it encompassed over of high-speed rail or over two-thirds of the world's total. It is also the world's busiest with an annual ridership of over 1.44 billion in 2016 and 2.01 billion in 2018, more than 60% of total passenger rail volume. By the end of 2018, cumulative passengers delivered by high-speed railway trains was reported to be over 9 billion. According to \"Railway Gazette International\", select trains between Beijing South to Nanjing South on the Beijing\u2013Shanghai high-speed railway have the fastest average operating speed in the world at as of July\u00a02019[ [update]].\nThe improved mobility and interconnectivity created by these new high-speed rail lines has generated a whole new high-speed commuter market around some urban areas. Commutes via high-speed rail to and from surrounding Hebei and Tianjin into Beijing have become increasingly common, likewise are between the cities surrounding Shanghai, Shenzhen and Guangzhou.\nHong Kong.\nA , entirely underground express rail link connects Hong Kong West Kowloon railway station near Kwun Chung to the border with Chinese mainland, where the railway continues onwards to Shenzhen's Futian station. A depot and the stabling sidings are located in Shek Kong. Parts of the West Kowloon station are not under the jurisdiction of Hong Kong to facilitate co-location of border clearance.\nIndonesia.\nIndonesia operates a high-speed rail line connecting its two largest cities in Western Java, the Whoosh HSR with an operational speed of . Operations commenced in October 2023. It is the first high-speed rail in Southeast Asia and the Southern Hemisphere.\nJapan.\nIn Japan, the Shinkansen was the first high-speed train and has a cumulative ridership of 10+\u00a0billion passengers with zero passenger fatalities due to operational accidents in its 60+ years of operation. It is the second largest high-speed rail system in Asia with of high-speed lines.\nSaudi Arabia.\nPlans in Saudi Arabia to begin service on a high-speed line consist of a phased opening starting with the route from Medina to King Abdullah Economic City followed up with the rest of the line to Mecca the following year. The Haramain high-speed railway opened in 2018.\nSouth Korea.\nSince its opening in 2004, KTX has transferred over 1 billion passengers as of August 2023, and now Asia's third largest with \n of rail lines. In 2013, for any transportation involving travel above , the KTX secured a market share of 57% over other modes of transport, which is by far the largest.\nTaiwan.\nTaiwan has a single north\u2013south high-speed line, Taiwan high-speed rail. It is approximately long, along the west coast of Taiwan from the national capital Taipei to the southern city of Kaohsiung. The construction was managed by Taiwan high-speed rail Corporation and the total cost of the project was US$18\u00a0billion. The private company operates the line fully, and the system is based primarily on Japan's Shinkansen technology.\nEight initial stations were built during the construction of the high-speed rail system: Taipei, Banqiao, Taoyuan, Hsinchu, Taichung, Chiayi, Tainan, and Zuoying (Kaohsiung). The line now has 12 total stations (Nangang, Taipei, Banqiao, Taoyuan, Hsinchu, Miaoli, Taichung, Changhua, Yunlin, Chiayi, Tainan and Zuoying) as of August 2018. There is a planned and approved extension to Yilan and Pingtung, which are set to enter service by 2030.\nUzbekistan.\nUzbekistan has a single high-speed rail line, the Tashkent\u2013Samarkand high-speed rail line, which allows trains to reach up to with of rail lines. There are also electrified extensions at lower speeds to Bukhara and Dehkanabad.\nAfrica.\nMorocco.\nIn November 2007, the Moroccan government decided to undertake the construction of a high-speed rail line between the economic capital Casablanca and Tangier, one of the largest harbour cities on the Strait of Gibraltar. The line will also serve the capital Rabat and Kenitra. The first section of the line, the Kenitra\u2013Tangier high-speed rail line, was completed in 2018.\nEurope.\nIn Europe, several nations are interconnected with cross-border high-speed rail, such as London-Paris, Paris-Brussel-Rotterdam, Madrid-Perpignan, and other future connecting projects exist.\nFrance.\nFrance has of high-speed rail lines, making it one of the largest networks in Europe and the world. Market segmentation has principally focused on the business travel market. The French original focus on business travellers is reflected by the early design of the TGV trains. Pleasure travel was a secondary market; now many of the French extensions connect with vacation beaches on the Atlantic and Mediterranean, as well as major amusement parks and also the ski resorts in France and Switzerland. Friday evenings are the peak time for TGVs (\"train \u00e0 grande vitesse\"). The system lowered prices on long-distance travel to compete more effectively with air services, and as a result some cities within an hour of Paris by TGV have become commuter communities, increasing the market while restructuring land use.\nOn the Paris\u2013Lyon service, the number of passengers grew sufficiently to justify the introduction of double-decker coaches. Later high-speed rail lines, such as the LGV Atlantique, the LGV Est, and most high-speed lines in France, were designed as feeder routes branching into conventional rail lines, serving a larger number of medium-sized cities.\nGermany.\nGermany's first high-speed lines ran north\u2013south, for historical reasons, and later developed east\u2013west after German unification. In the early 1900s, Germany became the first country to run a prototype electric train at speeds in excess of 200\u00a0km/h, and during the 1930s several steam and diesel trains achieved revenue speeds of 160\u00a0km/h in daily service. The InterCityExperimental briefly held the world speed record for a steel-wheel-on-steel-rails vehicle during the 1980s. The InterCityExpress entered revenue service in 1991 and serves purpose-built high-speed lines (), upgraded legacy lines (), and unmodified legacy lines. Lufthansa, Germany's flag carrier, has entered into a codeshare agreement with where ICEs run as \"feeder flights\" bookable with a Lufthansa flight number under the AIRail program.\nGreece.\nIn 2022, Greece's first high-speed train began operations between Athens and Thessaloniki. The 512\u00a0km (318 miles) route is covered in 3 to 4 hours with trains reaching speeds of up to 250\u00a0km/h (160 miles/h). The 180\u00a0km (112 mile) line from Athens to Patras is also being upgraded to high speed with an expected completion by 2026. The route between Athens and Thessaloniki was previously among the busiest passenger air routes in Europe.\nItaly.\nDuring the 1920s and 1930s, Italy was one of the first countries to develop the technology for high-speed rail. The country constructed the \"Direttissime\" railways connecting major cities on dedicated electrified high-speed track (although at speeds lower to what today would be considered high-speed rail) and developed the fast ETR 200 trainset. After the Second World War and the fall of the fascist regime, interest in high-speed rail dwindled, with the successive governments considering it too costly and developing the tilting Pendolino, to run at medium-high speed (up to ) on conventional lines, instead.\nA true dedicated high-speed rail network was developed during the 1980s and the 1990s, and of high-speed rail were fully operational by 2010. Frecciarossa services are operated with ETR 500 and ETR1000 non-tilting trains at 25kVAC, 50\u00a0Hz power. The operational speed of the service is .\nOver 100 million passengers used the Frecciarossa from the service introduction up to the first months of 2012. The high-speed rail system serves about 20 billion passenger-km per year as of 2016.\nItalian high-speed services are profitable without government funding.\nNuovo Trasporto Viaggiatori, the world's first private open-access operator of high-speed rail, is operative in Italy since 2012.\nNorway.\nAs of 2015, Norway's fastest trains have a commercial top speed of and the FLIRT trains may attain , However the train type 78 which have a top speed of 245 km/h. A velocity of is permitted on the Gardermoen Line, which links the Gardermoen airport to Oslo and a part of the main line northwards to Trondheim.\nSome parts of the trunk railways around Oslo are renewed and built for :\nRussia.\nThe existing Saint Petersburg\u2013Moscow Railway can operate at maximum speeds of 250\u00a0km/h; the Helsinki\u2013Saint Petersburg railway, dismantled after the 2022 Russian invasion of Ukraine, was capable of a maximum of 200\u00a0km/h. A new Moscow\u2013Saint Petersburg high-speed railway, designed specifically for high-speed rail, is currently under construction: once completed, it is expected to have the maximum speed of 400\u00a0km/h. Future areas include freight lines, such as the Trans-Siberian Railway in Russia, which would allow 3-day Far East to Europe service for freight, potentially fitting in between the months by ship and hours by air.\nSerbia.\nA high-speed line of \"SOKO\" (, meaning \"falcon\") trains connects the country's two most populous cities: Belgrade, the capital of the country, and Novi Sad, the capital of Vojvodina. In contrast to the slower Stadler FLIRT trains used for the \"Regio\" lines, the Stadler KISS-es take 36 minutes to go across two cities. In addition to the two main stations, the trains only stop in New Belgrade. In 2025 the line was extended to reach Subotica, Serbia's northernmost city, the anticipated travel time between Belgrade and Subotica is around 70 minutes.\nSpain.\nSpain has built an extensive high-speed rail network, with a length of (2024), the longest in Europe. It uses standard gauge as opposed to the Iberian gauge used in most of the national railway network, meaning that the high-speed tracks are separated and not shared with local trains or freight. Although standard gauge is the norm for Spanish high-speed rail, since 2011 there exists a regional high-speed service running on Iberian gauge with special trains that connects the cities of Ourense, Santiago de Compostela, A Coru\u00f1a, and Vigo in northwestern Spain. Connections to the French network exist since 2013, with direct trains from Paris to Barcelona. Although on the French side, conventional speed tracks are used from Perpignan to Montpellier.\nSweden.\nIn Sweden many trains run at 200 km/h (125 mph). Train types which currently attain this speed include the X 2000 tilting trains for long distances, the Regina widebody trains, the X40 double-decker regional trains, the Arlanda Airport Express X3, the MTRX-trains and the Stadler KISS-inspired double-decker regional trains. Since both the X2 and X3 are allowed to run at 205 km/h (127 mph) in case of delay, they can technically be considered as high-speed trains. The X2 runs between many cities in Sweden including Stockholm, Gothenburg, and Malm\u00f6. The Arlanda Express trains connect Stockholm and Stockholm-Arlanda Airport.\nIn December 2021, SJ announced that they are ordering twenty-five SJ 250 trainsets (based on the Zefiro Express platform) which would be capable of going 250 km/h (155 mph). They are expected to go into service in 2026, and will complement the X2000 service on the busiest lines (Stockholm\u2014Gothenburg/Malm\u00f6) as well as cross-border traffic with Denmark and Norway.\nSwitzerland.\nHigh-speed north\u2013south freight lines in Switzerland are under construction, avoiding slow mountainous truck traffic, and lowering labour costs. The new lines, in particular the Gotthard Base Tunnel, are built for . But the short high-speed parts and the mix with freight will lower the average speeds. The limited size of the country gives fairly short domestic travel times anyway. Switzerland is investing money in lines on French and German soil to enable better access to the high-speed rail networks of those countries from Switzerland.\nTurkey.\nThe Turkish State Railways started building high-speed rail lines in 2003. The first section of the line, between Ankara and Eski\u015fehir, was inaugurated on 13 March 2009. It is a part of the Istanbul to Ankara high-speed rail line. A subsidiary of Turkish State Railways, Y\u00fcksek H\u0131zl\u0131 Tren is the sole commercial operator of high-speed trains in Turkey.\nThe construction of three separate high-speed lines from Ankara to Istanbul, Konya and Sivas, as well as taking an Ankara\u2013\u0130zmir line to the launch stage, form part of the Turkish Ministry of Transport's strategic aims and targets.\nUnited Kingdom.\nThe UK's fastest high-speed line (High Speed 1) connects London St Pancras with Brussels, Paris and Amsterdam through the Channel Tunnel. At speeds of up to , it is the only high-speed line in Britain with an operating speed of more than .\nThe Great Western Main Line, South Wales Main Line, West Coast Main Line, Midland Main Line, Cross Country Route and East Coast Main Line all have maximum speed limits of . Attempts to increase speeds to on both the West Coast Main Line and East Coast Main Line were abandoned in the 1980s, due to trains operating on those lines not being capable of cab signalling, which was made a legal requirement in the UK for tracks permitted to operate any service at speeds greater than , due to the impracticality of observing lineside signals at such speeds.\nNorth America.\nUnited States.\nThe United States has domestic definitions for high-speed rail varying between jurisdictions.\nAmtrak's \"Acela\" (reaching ), \"Northeast Regional\", \"Keystone Service\", \"Silver Star\", \"Vermonter\" and certain MARC Penn Line express trains (the three reaching ) are currently the only high-speed services on the American continent according to the American definition, although they are not considered high-speed by international standards (except for the Avelia Liberty). These services are all limited to the Northeast Corridor. The \"Acela Express\" links Boston, New York City, Philadelphia, Baltimore, and Washington, D.C., and while \"Northeast Regional\" trains travel the whole of the same route, but make more station stops. All other high-speed rail services travel over portions of the route.\nAs of 2024, there are two high-speed rail projects under construction in the United States. The California High-Speed Rail project, eventually linking the 5 largest cities in California, is planned to have its first operating segment, between Merced and Bakersfield, begin passenger service as soon as 2030. The Brightline West project is planned to be privately operated and link the Las Vegas Valley and Rancho Cucamonga in the Greater Los Angeles area, with service set to begin in as soon as 2028.\nInter-city effects.\nWith high-speed rail there has been an increase in accessibility within cities. It allows for urban regeneration, accessibility in cities near and far, and efficient inter-city relationships. Better inter-city relationships lead to high-level services to companies, advanced technology, and marketing. The most important effect of HSR is the increase of accessibility due to shorter travel times. HSR lines have been used to create long-distance routes which in many cases cater to business travellers. However, there have also been short-distance routes that have revolutionised the concepts of HSR. They create commuting relationships between cities opening up more opportunities. Using both longer distance and shorter distance rail in one country allows for the best case of economic development, widening the labor and residential market of a metropolitan area and extending it to smaller cities. Therefore, HSR is highly related to urban development, it attracts offices and start-ups, induces industrial displacement, and promotes firm innovation.\nClosures.\nThe KTX Incheon International Airport to Seoul Line (operates on Incheon AREX) was closed in 2018, due to a mix of issues, including poor ridership and track sharing. The AREX was not constructed as high-speed rail, resulting a cap of 150 km/h on KTX service in its section.\nIn China, many conventional lines upgraded up to 200\u00a0km/h had high-speed services shifted to parallel high-speed lines. These lines, often passing through towns and having level crossings, are still used for local trains and freight trains. For example, all (passenger) EMU services on the Hankou\u2013Danjiangkou railway were routed over the Wuhan\u2013Shiyan high-speed railway on its opening to free up capacity for freight trains on the slower railway.\nIn India, the Regional Rapid Transit System (RRTS) network is being newly constructed to provide semi-high-speed rail connectivity between major cities and suburban areas. The RRTS corridors are designed for a maximum speed of 180\u00a0km/h, with an operational speed of up to 160\u00a0km/h. As these new corridors open, certain existing slower regional services, such as conventional EMU and MEMU trains, are planned for rerouting, rationalization, or reduction to prioritize the faster RRTS services. For example, after the opening of the Delhi\u2013Meerut RRTS corridor, some regional services between Delhi and Meerut are expected to be scaled back to optimize operations on the new high-speed corridor.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50379", "revid": "4796325", "url": "https://en.wikipedia.org/wiki?curid=50379", "title": "Illinois and Michigan Canal", "text": "Canal system in Illinois (1848\u20131933)\nThe Illinois and Michigan Canal connected the Great Lakes to the Mississippi River. In Illinois, it ran from the Chicago River in Bridgeport, Chicago to the Illinois River at LaSalle-Peru. The canal crossed the Chicago Portage, and helped establish Chicago as the transportation hub of the United States, before the railroad era. It was opened in 1848. Its function was partially replaced by the wider and deeper Chicago Sanitary and Ship Canal in 1900, and it ceased transportation operations with the completion of the Illinois Waterway in 1933.\nIllinois and Michigan Canal Locks and Towpath, a collection of eight engineering structures and segments of the canal between Lockport and LaSalle-Peru, was designated a National Historic Landmark in 1964.\nPortions of the canal have been filled in. Much of the former canal, near the Heritage Corridor transit line, has been preserved as part of the Illinois and Michigan Canal National Heritage Corridor.\nSignificance.\nIn the 19th century, canals were an important mode of transportation. The Illinois and Michigan Canal connected the Mississippi Basin to the Great Lakes Basin. The potential canal route influenced Illinois's north border. The Erie Canal and the Illinois and Michigan Canal cemented cultural and trade ties to the Northeast rather than the South. Before the canal, agriculture in the region was limited to subsistence farming. The canal made agriculture in northern Illinois profitable by opening connections to eastern markets.\nHistory.\nConception.\nThe first known Europeans to travel the area, Father Marquette and Louis Joliet, went through the Chicago Portage on their return trip. Joliet remarked that with a canal they could remove the need to portage and the French could create an empire spanning the continent.\nThe first quantitative survey of the portage was performed in 1816 by Stephen H. Long. It was on the basis of these measurements that he was able to make a specific proposal for a canal.\nWith several slave states recently admitted to the Union, Nathaniel Pope and Ninian Edwards saw the opportunity to make Illinois a state. They proposed moving the border northward from the southern tip of Lake Michigan to allow the canal to be within a single state. They believed that the canal would firmly align Illinois with the free states and so Congress granted them statehood even though Illinois did not meet the population requirements.\nConstruction.\nIn 1824, Samuel D. Lockwood, one of the first commissioners of the canal, was given the authorization to hire contractors to survey a route for the canal to follow.\nConstruction on the canal began in 1836, although it was stopped for several years due to an Illinois state financial crisis related to the Panic of 1837. The Canal Commission had a grant of of federal land which it sold at to finance the construction. Still, money had to be borrowed from Eastern United States and British investors to finish the canal.\nMost of the canal work was done by Irish immigrants who previously worked on the Erie Canal. The work was considered dangerous and many workers died, although no official records exist to indicate how many. The Irish immigrants who toiled to build the canal were often derided as a sub-class and were treated very poorly by other citizens of the city.\nThe canal was finished in 1848 at a total cost of $6,170,226. Chicago Mayor James Hutchinson Woodworth presided over the opening ceremony. Pumps were used to draw water to fill the canal near Chicago, which was soon supplemented by water from the Calumet Feeder Canal. The feeder was supplied by water from the Calumet River and originated in Blue Island, Il. The DuPage River provided water farther south. In 1871 the canal was deepened to speed up the current and to improve sewage disposal.\nCompletion.\nThe canal was eventually wide and deep, with towpaths constructed along each edge to permit mules to be harnessed to tow barges along the canal. Towns were planned out along the path of the canal spaced at intervals corresponding to the length that the mules could haul the barges. It had seventeen locks and four aqueducts to cover the height difference between Lake Michigan and the Illinois River. From 1848 to 1852 the canal was a popular passenger route, but passenger service ended in 1853 with the opening of the Chicago, Rock Island and Pacific Railroad that ran parallel to the canal. The canal had its peak shipping year in 1882 and remained in use until 1933.\nExperiencing a remarkable recovery from the devastating Great Chicago Fire of 1871, Chicago rebuilt rapidly along the shores of the Chicago River. The river was especially important to the development of the city since all wastes from houses, farms, the stockyards, and other industries could be dumped into the river and carried out into Lake Michigan.\nDecline and replacement.\nThe lake, however, was also the source of drinking water. During a tremendous storm in 1885, the rainfall washed refuse from the river, especially from the highly polluted Bubbly Creek, far out into the lake (the city water intakes are located offshore). Although no epidemics occurred, the Chicago Sanitary District (now The Metropolitan Water Reclamation District) was created by the Illinois legislature in 1889 in response to this close call.\nThis new agency devised a plan to construct channels and canals to reverse the flow of the rivers away from Lake Michigan and divert the contaminated water downstream where it could be diluted as it flowed into the Des Plaines River and eventually the Mississippi.\nIn 1892, the direction of part of the Chicago River was reversed by the Army Corps of Engineers with the result that the river and much of Chicago's sewage flowed into the canal instead of into Lake Michigan. The complete reversal of the river's flow was accomplished when the Sanitary and Ship Canal was opened in 1900.\nIt was replaced in 1933 by the Illinois Waterway, which remains in use.\nRejuvenation.\nThe actual origin site of the Illinois and Michigan Canal has been converted into a nature park that integrates history, ecology and art to communicate the Canal's importance in the development of Chicago. In 2003 the Chicago Park District, in cooperation with the I &amp; M Canal Association, hired Conservation Design Forum to develop plans to convert the brownfield site into a landscape that provided for passive recreational uses in a landscape setting with native plant species. Interpretive panels built into a wall along a bike trail were designed by local high school art students. The plans also called on landscape stabilization techniques to repair a significantly degraded shoreline (water levels can fluctuate as much as 5 feet).\nToday much of the canal is a long, thin linear park with canoeing and a hiking and biking trail (constructed on the alignment of the mule tow paths). It also includes museums and historical canal buildings. It was designated the first National Heritage Corridor by US Congress in 1984.\nAdjacent communities.\nMany towns in Northern Illinois owe their existence directly to the Illinois and Michigan Canal. Lockport, Morris, Ottawa, and LaSalle were platted by the Canal Commissioners to raise funds for the canal's construction. From east to west the towns along the path of the canal include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50380", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=50380", "title": "Alliance for Therapeutic Choice and Scientific Integrity", "text": "Former US organization promoting conversion therapy\nThe Alliance for Therapeutic Choice and Scientific Integrity (ATCSI), which until 2014 was known as the National Association for Research &amp; Therapy of Homosexuality (NARTH), also known as the NARTH Institute, is a US organization that promotes conversion therapy, a pseudoscientific practice used in attempts to change the sexual orientation of people with same-sex attraction. NARTH was founded in 1992 by Joseph Nicolosi, Benjamin Kaufman, and Charles Socarides. Its headquarters were in Encino, California, at its Thomas Aquinas Psychological Clinic. NARTH has not been recognized by any major United States\u2013based professional association. NARTH's promotion of conversion therapy as a scientifically supported therapeutic method is contradicted by overwhelming scientific consensus.\nHistory.\nNARTH was founded in 1992 by Benjamin Kaufman, Charles Socarides, and Joseph Nicolosi. In an article titled \"In Defense of the Need for Honest Dialogue\", Kaufman wrote that the three of them founded NARTH because the American Psychiatric Association and similar professional organizations \"had totally stifled the scientific inquiry that would be necessary to stimulate a discussion\" about homosexuality.\nThe organization had 501(c)(3) tax exempt status, which was revoked by the Internal Revenue Service in September 2012 due to ongoing failure to file required paperwork.\nActivities.\nNARTH claimed to be a secular organization, differentiating it from other ex-gay groups that were primarily religious in nature. Nevertheless, NARTH often partnered with religious groups, such as Jews Offering New Alternatives for Healing, , and Evergreen International in Positive Alternatives to Homosexuality.\nIn July 2011, NARTH failed to pay its dues to the California Board for Behavioral Sciences and was removed from the list of groups that provide continuing education credits to therapists in California. NARTH had been an approved continuing education provider since 1998.\nNo schools, universities or professional programs currently train counselors in reparative therapy.\nAffiliations.\nNARTH had several connections to Evergreen International and the Church of Jesus Christ of Latter-day Saints. The Evergreen website referenced the therapeutic methods of NARTH founder Joseph Nicolosi as \"beneficial\". Nicolosi worked with A. Dean Byrd (an Evergreen Board member, Director of Clinical Training for LDS Social Services, Brigham Young University professor, and founder of the Foundation for Attraction Research) to author several papers on reparative therapy. Byrd also served as president of NARTH and also published an article in the LDS church's September 1999 Ensign.\nIn 2003, the leaders of Positive Alternatives to Homosexuality (PATH) made NARTH a member.\nControversy.\nStances on the etiology and mutability of homosexuality.\nThe founders held that homosexuality is a treatable mental illness and that a person's sexual orientation can be changed through therapy. Such conversion therapy is pseudoscientific, harmful, and unethical according to major medical and psychological organisations in the United States and elsewhere. Socarides in particular said in the mid-1990s that he had treated about a thousand homosexual patients, and cured over a third by dealing with the parental causes of an absent father and overbearing mother.\nClaims that pathologize homosexuality and state that it can be changed through therapy have been denounced by almost every major US medical association, including the American Medical Association and the American Psychiatric Association. In 2006 the American Psychological Association declared that NARTH created \"an environment in which prejudice and discrimination can flourish\". The Southern Poverty Law Center (SPLC) singled the group out as a main source of junk science used by hate groups to justify anti-gay rhetoric. NARTH was accused of employing abusive methods to attempt to change sexual orientation by the Human Rights Campaign and Truth Wins Out.\nAbba Goldberg.\nIn 2010, NARTH\u2019s executive secretary Abba Goldberg disclosed a 1991 criminal conviction for conspiracy and fraud, for which he served 18 months in prison.\nGeorge Rekers.\nGeorge Rekers was a former officer and scientific advisor of the NARTH. Rekers has testified in court that homosexuality is destructive, and against parenthood by gay and lesbian people in a number of court cases involving organizations and state agencies working with children. In May 2010, Rekers employed a male prostitute as a travel companion for a two-week vacation in Europe. Rekers denied any inappropriate conduct and suggestions that he was gay. The male escort told CNN he had given Rekers \"sexual massages\" while traveling together in Europe. Rekers subsequently resigned from the board of NARTH.\nGerald Schoenewolf.\nIn April 2005, NARTH published on its website an essay titled \"Gay Rights and Political Correctness: A Brief History\", written by Gerald Schoenewolf, a member of NARTH's Science Advisory Committee. The essay made several controversial claims, including that the civil rights and gay rights movements are \"destructive\", that the American Psychological Association \"has been taken over by extremist gays\", and that Africans were fortunate to have been sold into slavery. The SPLC called it an angry polemic that made outrageous historical claims and criticised both NARTH and Schoenewolf. The essay drew little attention until a letter of protest was presented to NARTH by the National Black Justice Coalition in mid-September 2006. Truth Wins Out then called on Focus on the Family to cancel a planned appearance by Nicolosi at their conference. Nicolosi appeared as planned but the Schoenewolf essay was removed from the NARTH website the same day. On October 6, 2006, NARTH published a statement: \"NARTH regrets the comments made by Dr. Schoenewolf about slavery which have been misconstrued by some of our readers.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50381", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=50381", "title": "NARTH", "text": ""}
{"id": "50383", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=50383", "title": "Quiz-bowl", "text": ""}
{"id": "50384", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=50384", "title": "Quizbowl.", "text": ""}
{"id": "50385", "revid": "32156510", "url": "https://en.wikipedia.org/wiki?curid=50385", "title": "Space transport", "text": ""}
{"id": "50386", "revid": "41833184", "url": "https://en.wikipedia.org/wiki?curid=50386", "title": "Water transport", "text": ""}
{"id": "50387", "revid": "7770027", "url": "https://en.wikipedia.org/wiki?curid=50387", "title": "Containerization", "text": "Intermodal freight transport system\nContainerization is a system of intermodal freight transport using intermodal containers (also called shipping containers, or ISO containers). Containerization, also referred as container stuffing or container loading, is the process of unitization of cargoes in exports. Containerization is the predominant form of unitization of export cargoes today, as opposed to other systems such as the barge system or palletization. The containers have standardized dimensions. They can be loaded and unloaded, stacked, transported efficiently over long distances, and transferred from one mode of transport to another\u2014container ships, rail transport flatcars, and semi-trailer trucks\u2014without being opened. The handling system is mechanized so that all handling is done with cranes and special forklift trucks. All containers are numbered and tracked using computerized systems.\nContainerization originated several centuries ago but was not well developed or widely applied until after World War II, when it dramatically reduced the costs of transport, supported the post-war boom in international trade, and was a major element in globalization. Containerization eliminated manual sorting of most shipments and the need for dock front warehouses, while displacing many thousands of dock workers who formerly simply handled break bulk cargo. Containerization reduced congestion in ports, significantly shortened shipping time, and reduced losses from damage and theft.\nContainers can be made from a wide range of materials such as steel, fibre-reinforced polymer, aluminum or a combination. Containers made from weathering steel are used to minimize maintenance needs.\nOrigin.\nBefore containerization, goods were usually handled manually as break bulk cargo. Typically, goods would be loaded onto a vehicle from the factory and taken to a port warehouse where they would be offloaded and stored awaiting the next vessel. When the vessel arrived, they would be moved to the side of the ship along with other cargo to be lowered or carried into the hold and packed by dock workers. The ship might call at several other ports before off-loading a given consignment of cargo. Each port visit would delay the delivery of other cargo. Delivered cargo might then have been offloaded into another warehouse before being picked up and delivered to its destination. Multiple handling and delays made transport costly, time-consuming and unreliable.\nContainerization has its origins in early coal mining regions in England beginning in the late 18th century. In 1766 James Brindley designed the \"starvationer\" box boat with ten wooden containers, to transport coal from Worsley Delph (quarry) to Manchester by Bridgewater Canal. In 1795, Benjamin Outram opened the Little Eaton Gangway, upon which coal was carried in wagons built at his Butterley Ironwork. The horse-drawn wheeled wagons on the gangway took the form of containers, which, loaded with coal, could be transshipped from canal barges on the Derby Canal, which Outram had also promoted.\nBy the 1830s, railroads were carrying containers that could be transferred to other modes of transport. The Liverpool and Manchester Railway in the UK was one of these, making use of \"simple rectangular timber boxes\" to convey coal from Lancashire collieries to Liverpool, where a crane transferred them to horse-drawn carriages. Originally used for moving coal on and off barges, \"loose boxes\" were used to containerize coal from the late 1780s, at places like the Bridgewater Canal. By the 1840s, iron boxes were in use as well as wooden ones. The early 1900s saw the adoption of closed container boxes designed for movement between road and rail.\nTwentieth century.\nOn 17 May 1917, Louisville, Kentucky, native Benjamin Franklin \"B. F.\" Fitch (1877\u20131956) launched commercial use of \"demountable bodies\" in Cincinnati, Ohio, which he had designed as transferable containers. In 1919, his system was extended to over 200 containers serving 21 railway stations with 14 freight trucks.\nIn 1919, engineer Stanis\u0142aw Rodowicz developed the first draft of the container system in Poland. In 1920, he built a prototype of the biaxial wagon. The Polish-Bolshevik War stopped development of the container system in Poland.\nThe U.S. Post Office contracted with the New York Central Railroad to move mail via containers in May 1921. In 1930, the Chicago &amp; Northwestern Railroad began shipping containers between Chicago and Milwaukee. Their efforts ended in the spring of 1931 when the Interstate Commerce Commission disallowed the use of a flat rate for the containers.\nIn 1926, a regular connection of the luxury passenger train from London to Paris, Golden Arrow/Fleche d'Or, by Southern Railway and French Northern Railway, began. For transport of passengers' baggage four containers were used. These containers were loaded in London or Paris and carried to ports, Dover or Calais, on flat cars in the UK and \"CIWL Pullman Golden Arrow Fourgon of CIWL\" in France. At the Second World Motor Transport Congress in Rome, September 1928, Italian senator Silvio Crespi proposed the use of containers for road and railway transport systems, using collaboration rather than competition. This would be done under the auspices of an international organ similar to the Sleeping Car Company, which provided international carriage of passengers in sleeping wagons. In 1928 Pennsylvania Railroad (PRR) started regular container service in the northeast U.S. After the Wall Street crash of 1929 in New York and the subsequent Great Depression, many countries were without any means to transport cargo. The railroads were sought as a possibility to transport cargo, and there was an opportunity to bring containers into broader use. In February 1931 the first container ship was launched. It was called the Autocarrier, owned by Southern Railway UK. It had 21 slots for containers of Southern Railway.&lt;ref name=\"S/S AUTOCARRIER\"&gt;&lt;/ref&gt; Under auspices of the International Chamber of Commerce in Paris in Venice on September 30, 1931, on one of the platforms of the Maritime Station (Mole di Ponente), practical tests assessed the best construction for European containers as part of an international competition.\nIn 1931, in the U.S., B. F. Fitch designed the two largest and heaviest containers in existence. One measured by by with a capacity of in , and a second measured by by , with a capacity of in .\nIn November 1932, in Enola, Pennsylvania, the first container terminal in the world was opened by the Pennsylvania Railroad. The Fitch hooking system was used for reloading of the containers.\nThe development of containerization was created in Europe and the U.S. as a way to revitalize rail companies after the Wall Street crash of 1929, which had caused economic collapse and reduction in use of all modes of transport.\nIn 1933 in Europe, under the auspices of the International Chamber of Commerce, the International Container Bureau (French: \"Bureau International des Conteneurs\", B.I.C.) was established. In June 1933, the B.I.C. decided on obligatory parameters for containers used in international traffic. Containers handled by means of lifting gear, such as cranes, overhead conveyors, etc. for traveling elevators (group I containers), constructed after July 1, 1933. Obligatory Regulations:\nIn April 1935 BIC established a second standard for European containers:\nFrom 1926 to 1947 in the U.S., the Chicago North Shore and Milwaukee Railway carried motor carrier vehicles and shippers' vehicles loaded on flatcars between Milwaukee, Wisconsin, and Chicago, Illinois. Beginning in 1929, Seatrain Lines carried railroad boxcars on its sea vessels to transport goods between New York and Cuba.\nIn the mid-1930s, the Chicago Great Western Railway and then the New Haven Railroad began \"piggyback\" service (transporting highway freight trailers on flatcars) limited to their own railroads. The Chicago Great Western Railway filed a U.S. patent in 1938 on their method of securing trailers to a flatcars using chains and turnbuckles. Other components included wheel chocks and ramps for loading and unloading the trailers from the flatcars. By 1953, the Chicago, Burlington and Quincy, the Chicago and Eastern Illinois, and the Southern Pacific railroads had joined the innovation. Most of the rail cars used were surplus flatcars equipped with new decks. By 1955, an additional 25 railroads had begun some form of piggyback trailer service.\nWorld War II.\nDuring World War II, the Australian Army used containers to more easily deal with various breaks of gauge in the railroads. These non-stackable containers were about the size of the later 20-foot ISO container and perhaps made mainly of wood.\nDuring the same time, the United States Army started to combine items of uniform size, lashing them onto a pallet, unitizing cargo to speed the loading and unloading of transport ships. In 1947 the Transportation Corps developed the \"Transporter\", a rigid, corrugated steel container with a carrying capacity, for shipping household goods of officers in the field. It was long, , and high, with double doors on one end, mounted on skids, and had lifting rings on the top four corners. During the Korean War the Transporter was evaluated for handling sensitive military equipment and, proving effective, was approved for broader use. Theft of material and damage to wooden crates convinced the army that steel containers were needed.\nMid-twentieth century.\nIn April 1951, at Z\u00fcrich Tiefenbrunnen railway station, the Swiss Museum of Transport and \"Bureau International des Containers\" (BIC) held demonstrations of container systems, with the aim of selecting the best solution for Western Europe. Present were representatives from France, Belgium, the Netherlands, Germany, Switzerland, Sweden, Great Britain, Italy and the United States. The system chosen for Western Europe was based on the Netherlands' system for consumer goods and waste transportation called \"Laadkisten\" (literally, \"loading bins\"), in use since 1934. This system used roller containers that were moved by rail, truck and ship, in various configurations up to a capacity of , and up to size. This became the first post World War\u00a0II European railway standard UIC 590, known as \"pa-Beh\u00e4lter.\" It was implemented in the Netherlands, Belgium, Luxembourg, West Germany, Switzerland, Sweden and Denmark.\nWith the popularization of the larger ISO containers, support for pa containers was phased out by the railways. In the 1970s they began to be widely used for transporting waste.\nIn 1952 the U.S. Army developed the Transporter into the CONtainer EXpress or CONEX box system. The size and capacity of the CONEXes were about the same as the Transporter, but the system was made \"modular\", by the addition of a smaller, half-size unit of long, wide and high. CONEXes could be stacked three high, and protected their contents from the elements.\nThe first major shipment of CONEXes, containing engineering supplies and spare parts, was made by rail from the Columbus General Depot in Georgia to the Port of San Francisco, then by ship to Yokohama, Japan, and then to Korea, in late 1952. Transit times were almost halved. By the time of the Vietnam War the majority of supplies and materials were shipped by CONEX. By 1965 the U.S. military used some 100,000 CONEX boxes, and more than 200,000 in 1967. making this the first worldwide application of intermodal containers. After the US Department of Defense standardized an cross section container in multiples of lengths for military use, it was rapidly adopted for shipping purposes.\nIn 1955, former trucking company owner Malcom McLean worked with engineer Keith Tantlinger to develop the modern intermodal container. All the containerization pioneers who came before McLean had thought in terms of optimizing particular modes of transport. McLean's \"fundamental insight\" which made the intermodal container possible was that the core business of the shipping industry \"was moving cargo, not sailing ships\". He visualized and helped to bring about a world reoriented around that insight, which required not just standardization of the metal containers themselves, but drastic changes to \"every\" aspect of cargo handling.\nIn 1955, McLean and Tantlinger's immediate challenge was to design a shipping container that could efficiently be loaded onto ships and would hold securely on sea voyages. The result was an by box in units constructed from corrugated steel. The design incorporated a twistlock mechanism atop each of the four corners, allowing the container to be easily secured and lifted using cranes. Several years later, as a Fruehauf executive, Tantlinger went back to McLean and convinced him to relinquish control of their design to help stimulate the container revolution. On January 29, 1963, McLean's company SeaLand released its patent rights, so that Tantlinger's inventions could become \"the basis for a standard corner fitting and twist lock\". Tantlinger was deeply involved in the debates and negotiations which in back-to-back votes in September 1965 (on September 16 and 24, respectively) led to the adoption of a modified version of the Sea-Land design as the American and then the international standard for corner fittings for shipping containers. This began international standardization of shipping containers.\nPurpose-built ships.\nThe first vessels purpose-built to carry containers had begun operation in 1926 for the regular connection of the luxury passenger train between London and Paris, the Golden Arrow/Fleche d'Or. Four containers were used for the conveyance of passengers' baggage. These containers were loaded in London or Paris and carried to the ports of Dover or Calais. In February 1931 the first container ship in the world was launched. It was called the Autocarrier, owned by the UK's Southern Railway. It had 21 slots for containers of Southern Railway.\nThe next step was in Europe after World War II. Vessels purpose-built to carry containers were used between UK and Netherlands and also in Denmark in 1951. In the United States, ships began carrying containers in 1951, between Seattle, Washington, and Alaska. None of these services was particularly successful. First, the containers were rather small, with 52% of them having a volume of less than . Almost all European containers were made of wood and used canvas lids, and they required additional equipment for loading into rail or truck bodies.\nThe world's first purpose-built container vessel was \"Clifford J. Rodgers\", built in Montreal in 1955 and owned by the White Pass and Yukon Corporation. Her first trip carried 600 containers between North Vancouver, British Columbia, and Skagway, Alaska, on November 26, 1955. In Skagway, the containers were unloaded to purpose-built railroad cars for transport north to Yukon, in the first intermodal service using trucks, ships, and railroad cars. Southbound containers were loaded by shippers in Yukon and moved by rail, ship, and truck to their consignees without opening. This first intermodal system operated from November 1955 until 1982.\nThe first truly successful container shipping company dates to April 26, 1956, when American trucking entrepreneur McLean put 58 \"trailer vans\" later called containers, aboard a refitted tanker ship, the , and sailed them from Newark, New Jersey, to Houston, Texas. Independently of the events in Canada, McLean had the idea of using large containers that never opened in transit and that were transferable on an intermodal basis, among trucks, ships, and railroad cars. McLean had initially favored the construction of \"trailerships\"\u2014taking trailers from large trucks and stowing them in a ship's cargo hold. This method of stowage, referred to as roll-on/roll-off, was not adopted because of the large waste in potential cargo space on board the vessel, known as broken stowage. Instead, McLean modified his original concept into loading just the containers, not the chassis, onto the ship; hence the designation \"container ship\" or \"box\" ship. (See also pantechnicon van and trolley and lift van.)\nToward standards.\nDuring the first 20 years of containerization, many container sizes and corner fittings were used. There were dozens of incompatible container systems in the US alone. Among the biggest operators, the Matson Navigation Company had a fleet of containers, while Sea-Land Service, Inc used containers. The standard sizes and fitting and reinforcement norms that now exist evolved out of a lengthy and complex series of compromises among international shipping companies, European railroads, US railroads, and US trucking companies. Everyone had to sacrifice something. For example, to McLean's frustration, Sea-Land's 35-foot container was not adopted as one of the standard container sizes. In the end, four important ISO (International Organization for Standardization) recommendations standardized containerization globally:\nBased on these standards, the first TEU container ship was the Japanese \"Hakone Maru\" from shipowner NYK, which started sailing in 1968 and could carry 752 TEU containers.\nIn the US, containerization and other advances in shipping were impeded by the Interstate Commerce Commission (ICC), which was created in 1887 to keep railroads from using monopolist pricing and rate discrimination, but fell victim to regulatory capture. By the 1960s, ICC approval was required before any shipper could carry different items in the same vehicle or change rates. The fully integrated systems in the US today became possible only after the ICC's regulatory oversight was cut back (and abolished in 1995). Trucking and rail were deregulated in the 1970s and maritime rates were deregulated in 1984.\nDouble-stacked rail transport, where containers are stacked two high on railway cars, was introduced in the US. The concept was developed by Sea-Land and the Southern Pacific railroad. The first standalone double-stack container car (or single-unit COFC well car) was delivered in July 1977. The five-unit well car, the industry standard, appeared in 1981. Initially, these double-stack railway cars were deployed in regular train service. Ever since American President Lines initiated in 1984 a dedicated double-stack container train service between Los Angeles and Chicago, transport volumes increased rapidly.\nEffects.\nContainerization greatly reduced the expense of international trade and increased its speed, especially of consumer goods and commodities. It also dramatically changed the character of port cities worldwide. Prior to highly mechanized container transfers, crews of 20 to 22 longshoremen would pack individual cargoes into the hold of a ship. After containerization, large crews of longshoremen were not necessary at port facilities, and the profession changed drastically.\nMeanwhile, the port facilities needed to support containerization changed. One effect was the decline of some ports and the rise of others. At the Port of San Francisco, the former piers used for loading and unloading were no longer required, but there was little room to build the vast holding lots needed for storing and sorting containers in transit between different transport modes. As a result, the Port of San Francisco essentially ceased to function as a major commercial port, but the neighboring Port of Oakland emerged as the second largest on the US West Coast. A similar fate occurred with the relationship between the ports of Manhattan and New Jersey. In the UK, the Port of London and Port of Liverpool declined in importance. Meanwhile, Britain's Port of Felixstowe and Port of Rotterdam in the Netherlands emerged as major ports.\nIn general, containerization caused inland ports on waterways incapable of receiving deep-draft ship traffic to decline in favor of seaports, which then built vast container terminals next to deep oceanfront harbors in lieu of the dockfront warehouses and finger piers that had formerly handled break bulk cargo. With intermodal containers, the jobs of packing, unpacking, and sorting cargoes could be performed far from the point of embarkation. Such work shifted to so-called \"dry ports\" and gigantic warehouses in rural inland towns, where land and labor were much cheaper than in oceanfront cities. This fundamental transformation of where warehouse work was performed freed up valuable waterfront real estate near the central business districts of port cities around the world for redevelopment and led to a plethora of waterfront revitalization projects (such as warehouse districts).\nThe effects of containerization rapidly spread beyond the shipping industry. Containers were quickly adopted by trucking and rail transport industries for cargo transport not involving sea transport. Manufacturing also evolved to adapt to take advantage of containers. Companies that once sent small consignments began grouping them into containers. Many cargoes are now designed to precisely fit containers. The reliability of containers made just in time manufacturing possible as component suppliers could deliver specific components on regular fixed schedules.\nIn 2004, global container traffic was 354 million TEUs, of which 82 percent were handled by the world's top 100 container ports.\nTwenty-first century.\nAs of 2009[ [update]], approximately 90% of non-bulk cargo worldwide is moved by containers stacked on transport ships; 26% of all container transshipment is carried out in China. For example, in 2009 there were 105,976,701 transshipments in China (both international and coastal, excluding Hong Kong), 21,040,096 in Hong Kong (which is listed separately), and only 34,299,572 in the United States. In 2005, some 18 million containers made over 200 million trips per year. Some ships can carry over 14,500\u00a0twenty-foot equivalent units\u00a0(TEU), such as the \"Emma M\u00e6rsk\", long, launched in August 2006. It has been predicted that, at some point, container ships will be constrained in size only by the depth of the Straits of Malacca, one of the world's busiest shipping lanes, linking the Indian Ocean to the Pacific Ocean. This so-called Malaccamax size constrains a ship to dimensions of in length and wide.\nFew foresaw the extent of the influence of containerization on the shipping industry. In the 1950s, Harvard University economist Benjamin Chinitz predicted that containerization would benefit New York by allowing it to ship its industrial goods more cheaply to the Southern US than other areas, but he did not anticipate that containerization might make it cheaper to import such goods from abroad. Most economic studies of containerization merely assumed that shipping companies would begin to replace older forms of transportation with containerization, but did not predict that the process of containerization itself would have a more direct influence on the choice of producers and increase the total volume of trade.\nThe widespread use of ISO standard containers has driven modifications in other freight-moving standards, gradually forcing removable truck bodies or swap bodies into standard sizes and shapes (though without the strength needed to be stacked), and changing completely the worldwide use of freight pallets that fit into ISO containers or into commercial vehicles.\nImproved cargo security is an important benefit of containerization. Once the cargo is loaded into a container, it is not touched again until it reaches its destination. The cargo is not visible to casual viewers, and thus is less likely to be stolen. Container doors are usually sealed so that tampering is more evident. Some containers are fitted with electronic monitoring devices and can be remotely monitored for changes in air pressure, which happens when the doors are opened. This reduced thefts that had long plagued the shipping industry. Recent developments have focused on the use of intelligent logistics optimization to further enhance security.\nThe use of the same basic sizes of containers across the globe has lessened the problems caused by incompatible rail gauge sizes. The majority of the rail networks in the world operate on a gauge track known as standard gauge, but some countries (such as Russia, India, Finland, and Lithuania) use broader gauges, while others in Africa and South America use narrower gauges. The use of container trains in all these countries makes transshipment between trains of different gauges easier.\nContainers have become a popular way to ship private cars and other vehicles overseas using 20- or 40-foot containers. Unlike roll-on/roll-off vehicle shipping, personal effects can be loaded into the container with the vehicle, allowing easy international relocation.\nIn July, 2020, The Digital Container Shipping Association (DCSA), a non-profit group established to further digitalisation of container shipping technology standards, published standards for the digital exchange of operational vessel schedules (OVS).\nContrary to ocean shipping containers owned by the shippers, a persisting trend in the industry is for (new) units to be purchased by leasing companies. Leasing business accounted for 55% of new container purchases in 2017, with their box fleet growing at 6.7%, compared to units of transport operators growing by just 2.4% more TEU, said global shipping consultancy Drewry in their 'Container Census &amp; Leasing and Equipment Insight', leading to a leased share of the global ocean container fleet reaching 54% by 2020.\nIn 2021, the average time to unload a container in Asia was 27 seconds, the average time in Northern Europe was 46 seconds, and the average time in North America was 76 seconds.\nContainer standards.\nISO standard.\nThere are five common standard lengths:\nUS domestic standard containers are generally and (rail and truck). Container capacity is often expressed in twenty-foot equivalent units (TEU, or sometimes \"teu\"). An equivalent unit is a measure of containerized cargo capacity equal to one standard (length) \u00d7 (width) container. As this is an approximate measure, the height of the box is not considered. For instance, the \"high cube\" and the \"half height\" containers are also called one TEU. 48' containers have been phased out over the last ten years in favor of 53' containers.\nThe maximum gross mass for a dry cargo container was initially set at , and for a container (including the high cube) . Allowing for the tare mass of the container, the maximum payload mass is therefore reduced to approximately for , and for containers.\nIt was increased to 30,480\u00a0kg for the 20' in 2005, then further increased to a max of 36,000\u00a0kg for all sizes by the amendment 2 (2016) of the ISO standard 668 (2013).\nThe original choice of height for ISO containers was made in part to suit a large proportion of railway tunnels, though some had to be modified. The current standard is high. With the arrival of even taller hi-cube containers at and double stacking rail cars, further enlargement of the rail loading gauge is proving necessary.\nAir freight containers.\nWhile major airlines use containers that are custom designed for their aircraft and associated ground handling equipment the IATA has created a set of standard aluminium container sizes of up to in volume.\nOther container system standards.\nSome other container systems (in date order) are:\nContainer loading.\nFull container load.\nA full container load (FCL) is an ISO standard container that is loaded and unloaded under the risk and account of one shipper and one consignee. In practice, it means that the whole container is intended for one consignee. FCL container shipment tends to have lower freight rates than an equivalent weight of cargo in bulk. FCL is intended to designate a container loaded to its allowable maximum weight or volume, but FCL in practice on ocean freight does not always mean a full payload or capacity \u2013 many companies will prefer to keep a 'mostly' full container as a single container load to simplify logistics and increase security compared to sharing a container with other goods.\nLess-than-container load.\nLess-than-container load (LCL) is a shipment that is not large enough to fill a standard cargo container. The abbreviation LCL formerly applied to \"less than (railway) car load\" for quantities of material from different shippers or for delivery to different destinations carried in a single railway car for efficiency. LCL freight was often sorted and redistributed into different railway cars at intermediate railway terminals en route to the final destination. It can also be defined as \"a quantity of cargo less than that which fills the visible or rated capacity of an inter-modal container\", or \"a consignment of cargo which is inefficient to fill a shipping container. It is grouped with other consignments for the same destination in a container at a container freight station\".\nGroupage is the process of forming a full container load by combining multiple shipments for efficiency and to save costs. A groupage operator, consolidator or freight forwarder is able to undertake this role.\nIssues.\nHazards.\nContainers are actively used for smuggling and trafficking illicit goods and people. Drugs, antiques, weapons, undeclared merchandise, jewellery, human beings, wildlife, counterfeit products, as well as chemical, radioactive and biological materials, are illegally transported via containers. Additionally, there are concerns about terrorists using containers to transport weapons of mass destruction (WMD). However, these concerns remain hypothetical.\nThere are several ways in which illicit goods are smuggled. One method involves forging documents to make a container appear as legal cargo. Another method is inserting illegal goods into a legitimate shipment, mixing legal and illegal items together. For example, in 2024, several shipments of drugs, either disguised as banana cargo or mixed with legal banana shipments, were discovered in Germany, Greece, Spain and Great Britain. Criminal groups use legitimate fruit businesses as fronts for their narcotics operations, making fruit cargo a common method for concealing drugs. Trafficking in wildlife parts, such as ivory, frequently involves altering the appearance of the goods. For instance, ivory has been known to be cut into the shape of chocolate bars or painted the colour of wood to avoid detection during X-ray inspections. Additionally, containers can be physically modified to hide illegal parcels, such as through the use of fake walls, secret compartments, hollowed-out rails, support beams and doors.\nThe lack of capacity at ports to inspect containers increases the likelihood of smuggled goods going undetected. In African ports, especially West Africa, where most drug routes converge, only about 2% of all containers are inspected. Similarly, European ports check just 2\u201310% of incoming containers, leaving the majority unscreened and creating opportunities for trafficking.\nNevertheless, there are a number of security measures in place, notably the Container Security Initiative (CSI), a post-9/11 US-led programme. This initiative aims to pre-screen high-risk cargo before it reaches US territory. One of its primary goals is to prevent the smuggling of weapons of mass destruction (WMD).\nAlthough the programme was initiated by the United States, by 2007, some 20 countries had signed a Memorandum of Understanding with the US, leading to the implementation of CSI measures at 58 ports around the world. The CSI system includes non-intrusive pre-screening methods, such as X-ray and radiation screening, for high-risk cargo destined for the United States. As a result, more than 80% of containerised cargo bound for the United States is pre-screened.\nEmpty containers.\nContainers are intended to be used constantly, being loaded with new cargo for a new destination soon after emptied of previous cargo. This is not always possible, and in some cases, the cost of transporting an empty container to a place where it can be used is considered to be higher than the worth of the used container. Shipping lines and container leasing companies have become expert at repositioning empty containers from areas of low or no demand, such as the US West Coast, to areas of high demand, such as China. Repositioning within the port hinterland has also been the focus of recent logistics optimization work. Damaged or retired containers may be recycled in the form of shipping container architecture, or the steel content salvaged. In the summer of 2010, a worldwide shortage of containers developed as shipping increased after the recession, while new container production had largely ceased.\nLoss at sea.\nContainers occasionally fall from ships, usually during storms. According to media sources, between 2,000 and 10,000 containers are lost at sea each year. The World Shipping Council states in a survey among freight companies that this claim is grossly excessive and calculated an average of 350 containers to be lost at sea each year, or 675 if including catastrophic events. For instance, on November 30, 2006, a container washed ashore on the Outer Banks of North Carolina, along with thousands of bags of its cargo of Doritos Chips. Containers lost in rough waters are smashed by cargo and waves, and often sink quickly. Although not all containers sink, they seldom float very high out of the water, making them a shipping hazard that is difficult to detect. Freight from lost containers has provided oceanographers with unexpected opportunities to track global ocean currents, notably a cargo of Friendly Floatees.\nIn 2007 the International Chamber of Shipping and the World Shipping Council began work on a code of practice for container storage, including crew training on parametric rolling, safer stacking, the marking of containers, and security for above-deck cargo in heavy swell.\nIn 2011, the MV Rena ran aground off the coast of New Zealand. As the ship listed, some containers were lost, while others were held on board at a precarious angle.\nTrade union challenges.\nSome of the biggest battles in the container revolution were waged in Washington, D.C.. Intermodal shipping got a huge boost in the early 1970s, when carriers won permission to quote combined rail-ocean rates. Later, non-vessel-operating common carriers won a long court battle with a US Supreme Court decision against contracts that attempted to require that union labor be used for stuffing and stripping containers at off-pier locations.\nAs pest vector.\nContainers are often infested with pests. Pest introductions are significantly clustered around ports, and containers are a common source of such successful pest transfers. The IPPC Sea Container Task Force (SCTF) promulgates the Cargo Transport Units Code (CTU), prescribed pesticides and other standards (see ) and recommendations for use in container decontamination, inspection and quarantine. The SCTF also provides the English translation of the National Standard of China (GB/T 39919-2021).\nOther uses for containers.\nShipping container architecture is the use of containers as the basis for housing and other functional buildings for people, either as temporary or a permanent housing, and either as a main building or as a cabin or as a workshop. Containers can also be used as sheds or storage areas in industry and commerce.\nTempo Housing in Amsterdam stacks containers for individual housing units.\nContainers are also beginning to be used to house computer data centers, although these are normally specialized containers.\nThere is now a high demand for containers to be converted in the domestic market to serve specific purposes. As a result, a number of container-specific accessories have become available for a variety of applications, such as racking for archiving, lining, heating, lighting, powerpoints to create purpose-built secure offices, canteens and drying rooms, condensation control for furniture storage, and ramps for storage of heavier objects. Containers are also converted to provide equipment enclosures, pop-up cafes, exhibition stands, security huts and more.\nPublic containerised transport is the concept, not yet implemented, of modifying motor vehicles to serve as personal containers in non-road passenger transport.\nThe ACTS roller container standards have become the basis of containerized firefighting equipment throughout Europe.\nContainers have also been used for weapon systems, such as the Russian Club-K, which allow the conversion of an ordinary container system into a missile boat, capable of attacking surface and ground targets, and the CWS (Containerized Weapon System) developed for the US Army that allow for the rapid deployment of a remote controlled machine gun post from a container.\nBBC tracking project.\nOn September 5, 2008, the BBC embarked on a year-long project to study international trade and globalization by tracking a shipping container on its journey around the world.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50392", "revid": "47614224", "url": "https://en.wikipedia.org/wiki?curid=50392", "title": "Georg Joachim Rheticus", "text": "Austrian astronomer and mathematician (1514\u20131576)\nGeorg Joachim de Porris, also known as Rheticus (; 16 February 1514 \u2013 4 December 1574), was a mathematician, astronomer, cartographer, navigational-instrument maker, medical practitioner, and teacher. He is perhaps best known for his trigonometric tables and as Nicolaus Copernicus's sole pupil. He facilitated the publication of his master's \"De revolutionibus orbium coelestium\" (\"On the Revolutions of the Heavenly Spheres\").\nSurname.\nRheticus was born at Feldkirch in the Archduchy of Austria. Both his parents, Georg Iserin and Thomasina de Porris, were of Italian heritage and possessed considerable wealth, his father being the town physician as well as a government official. He was educated by his father until the age of 14 when Georg (Iserin) abused the trust of many of his patients, stealing belongings and money from their homes. In 1528 he was convicted and executed for his crimes, and as a result his family was stripped of their surname.\nThe family adopted the mother's maiden name: de Porris. Later as a student at the University of Wittenberg, Georg Joachim adopted the toponym Rheticus, a form of the Latin name for his home region, Rhaetia, a Roman province that had included parts of Austria, Switzerland and Germany. In the matriculation list for the University of Leipzig his family name, de Porris, is translated into German as von Lauchen. The lunar crater \"Rhaeticus\" as well as asteroid 15949 Rhaeticus were named for him.\nPatrons.\nAfter Georg Iserin's death, Achilles Gasser took over his medical practice, helping Rheticus to continue his studies and supporting him, eventually going so far as to furnish him with a letter of introduction to Philipp Melanchthon, a theologian and educator who would become a major patron, having reorganized the whole educational system of the Lutheran Protestant parts of Germany, reforming and founding several new universities during the Reformation. This relationship in particular would soon serve him well as Melanchton possibly chose him specifically for the University of Wittenberg. Rheticus studied at Feldkirch, Z\u00fcrich and Wittenberg where he received his M.A. in 1536, after which Melanchthon appointed Rheticus as professor of the lower mathematics, arithmetic and astronomy, at the Wittenberg University.\nTwo years later, Melanchthon arranged a two-year leave for Rheticus to study with noted astronomers. Leaving Wittenberg in October 1538, he first went to Nuremberg to visit the professor of mathematics at the Eigidien Oberschule, Johannes Sch\u00f6ner. In Nuremberg he also made the acquaintance of other mathematicians such as Georg Hartmann and Thomas Venatorius as well as the printer-publisher Johannes Petreius. During his journey, probably in Nuremberg, Rheticus heard of Copernicus and decided to seek him out. It is unknown whether he had access to Copernicus' Commentariolus, an unsigned, unpublished outline of Copernicus' revolutionary heliocentric theory that Copernicus distributed to friends and colleagues three decades before he published \"De revolutionibus\", prior to this or perhaps on consulting Sch\u00f6ner who is believed to have persuaded him. From Johannes Petreius Rheticus was given works by Regiomontanus and others, intended as presents for Copernicus. He went on to Peter Apian at the University of Ingolstadt and Joachim Camerarius at the University of T\u00fcbingen, then to his hometown when Rheticus would present Gasser with an edition of Sacrobosco. From Feldkirch he set out on his journey to visit Copernicus in Frombork.\nCopernicus.\nIn May 1539, Rheticus arrived in Frauenburg (Frombork), where he spent two years with Copernicus. Despite the effort invested thus far, Copernicus had not finished a manuscript of his work, apparently choosing to not seek publication, presumably due to issues reconciling such findings with the historically held religious attitudes at the time. Eventually though, he would be swayed to allow Rheticus to author an abstract on his research despite being well aware of the criticism and controversy it could bring. Only following its reception, widely considered the best introduction to Copernicus' work, would he then give Rheticus further permission to edit and publish his work in full. In this, Rheticus would prove integral in utilizing previously forged social connections as well as strategically cultivating new ones just to bring it to publication. It was thus only because of this fortuitous meeting that the heliocentric theory, a concept that would still not be accepted for decades to come, would ultimately be brought to light.\nIn September 1539, Rheticus went to Danzig (Gda\u0144sk) to visit the mayor, who gave him financial assistance to publish his \"Narratio Prima\" (\"First Report\") of Copernicus' forthcoming treatise. Rhode in Danzig published \"Narratio Prima\" in 1540. Unexpectedly, it also contains a eulogy of Prussia. In it, the origins, flora, and fauna of the country are discussed as well as descriptions for several of its cities, regarding their commerce and history, demonstrating that his travels frequently served a twin purpose. While in Danzig, Rheticus interviewed maritime pilots to learn about their problems in navigation. Rheticus also visited Copernicus' friend Tiedemann Giese, who was Bishop of Che\u0142mno (Culm) and further encouraged him to publish the former's work. At some point, he would additionally become a patron.\nIn August 1541, Rheticus presented both a copy of \"Chorographia\" (containing a systematic approach to the preparation of maps, distinguishing chorography from geography, discussing various methods of cartographic survey by the use of the compass as well as improvements to the aforementioned instrument) and \"Tabula chorographica auff Preussen und etliche umbliegende lender\" (\"Map of Prussia and Neighboring Lands\") to Albert, Duke of Prussia. Knowing the duke had been trying to compute the exact time of sunrise, Rheticus made an instrument that determined the length of the day, and through this favor obtained from him a recommendation to Wittenberg that \"De revolutionibus\" be published. Albrecht asked Rheticus to end his travels and return to his teaching position. Rheticus returned to the University of Wittenberg in October 1541, then elected dean of the Faculty of Arts as well as joining the theological faculty. In May 1542, he traveled to N\u00fcrnberg to supervise the printing by Johannes Petreius of the first edition of \"De revolutionibus\" in which he included tables of trigonometric functions he had calculated in further support of Copernicus' work, but had to leave in fall to take a position at the University of Leipzig, and Andreas Osiander replaced him. A theologian, Osiander would use this role to add an unauthorized preface in a would-be attempt to avoid censorship, explicitly describing the theory discussed therein as a model of pure hypothesis predicated on assumptions that are coincidentally consistent with the calculations. Towards this, Rheticus would allegedly deface every such copy he came across. Copernicus' major work would eventually be published shortly before his death in 1543.\nIn a work now properly attributed to Rheticus tentatively titled \"Epistolae de Terrae Motu\" (Letter on the Motion of the Earth), he attempts to reconcile Copernicanism with scripture by employing St. Augustine's principle of accommodation. According to historian Robert Westman, the \"Epistolae\" or also known as the \"Opusculum\", published posthumously and anonymously in 1651, demonstrates that Copernicus and Rheticus recognized the problem of conflict between their finding of earthly motion and biblical scripture, and had therefore developed a systematic defense of compatibility. Written in a moderate tone, he would suggest that the bible only contains that which is necessary for salvation, in doctrine and ethical instruction. Considering this tenet, scripture would then lack reference to any specific matter that may be studied by science, such as the movement of the earth with respect to the sun, with the exception being those facts of nature outside mankind's ability to investigate. Rheticus would further argue that biblical language was written in terms meant to be readily comprehensible to a wide audience:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It borrows a kind of discourse, a habit of speech, and a method of teaching from popular usage.\u2014\u200a\nWhile relying heavily upon citations to appease religious authorities, Rheticus may have nevertheless refrained from publishing the work in his life in order to avoid angering more conservative Protestants such as Melanchthon.\nCriminal history.\nIn 1542, Rheticus on the recommendation of Joachim Camerarius in conjunction with Melanchthon was then appointed professor of higher mathematics at Leipzig. Rheticus ended up taking another leave of absence in 1545, departing for Italy although the specifics of his itinerary remain unknown. In 1546\u201347, he would suffer from some unspecified severe mental disorder in Lindau, but recovered enough to return to teaching at Constance towards the latter. By 1551, he would publish some of his work in mathematics, trigonometric tables containing all six functions defined directly in terms of right triangles instead of circles, the first of its kind. While serving in this position, he simultaneously pursued other scholarly interests such as releasing a calendar and ephemeris in 1552 as well as the subsequent year. Then in 1552, Rheticus was found guilty of raping the son of Hans Meusel, a merchant, though the exact nature of this encounter has been called into question. According to Meusel, Rheticus \"plied him with a strong drink, until he was inebriated; and finally did with violence overcome him and practice upon him the shameful and cruel vice of sodomy\". He fled following this accusation, for a time residing in Chemnitz before eventually moving on to Prague. Rheticus was then found guilty in his trial in absentia and consequently exiled from Leipzig for 101 years as well as having his possessions impounded. As a result, he would come to lose the support of many long-time benefactors including Melanchthon.\nLater years.\nOften overshadowed by the facilitative role he played in Copernicus' publications, Rheticus would continue to pursue other scientific endeavors following his exile. 1551\u201352 found him studying medicine at the University of Prague, primarily applying his skills toward treatment of patients without any appreciable contributions to the field. Then in 1553, he was offered a position in mathematics at Vienna where he would travel to ultimately decline the appointment, instead relocating to Krak\u00f3w in 1554 for the next 20 years as a practicing doctor. While there, he continued his work within mathematics and astronomy, further compiling his calculations of trigonomic functions with funding from Emperor Maximilian II with the aid of numerous assistants. The canon of Warmia Georg Donner and the bishop of Warmia Johannes Dantiscus were both patrons of Rheticus. Rheticus was also commissioned to make a staff for King Sigismund II of Poland, while he held a position as teacher in Krak\u00f3w for many years. From there he went to Ko\u0161ice in the Kingdom of Hungary, where he died.\nTrigonometry.\nFor much of his life, Rheticus displayed a passion for the study of triangles, the branch of mathematics now called trigonometry. In 1542 he had the trigonometric sections of Copernicus' \"De revolutionibis\" published separately under the title \"De lateribus et angulis triangulorum\" (\"On the Sides and Angles of Triangles\"). In 1551 Rheticus produced a tract titled \"Canon of the Science of Triangles,\" the first publication of six-function trigonometric tables (although the word \"trigonometry\" was not yet coined). This pamphlet was to be an introduction to Rheticus' greatest work, a full set of tables to be used in angular astronomical measurements.\nAt his death, the \"Science of Triangles\" was still unfinished. However, paralleling his own relationship with Copernicus, Rheticus had acquired a student from Wittenberg who sought him out. Valentinus Otho, devoted to completing his teacher's work, oversaw the hand computation of approximately 100,000 ratios to at least ten decimal places. When completed in 1596, the volume, \"Opus palatinum de triangulis,\" filled nearly 1,500 pages. Its tables were accurate enough to be used in astronomical computation into the early twentieth century.\nIn popular culture.\nRheticus narrates the third part of John Banville's 1975 novel \"Doctor Copernicus\", relating how he convinced Copernicus to publish the book. The novel itself is less about Copernicus's work than about his life and the 16th century world in which he lived.\nThe episode \"Claudia\" of the U.S. science fiction series \"Warehouse 13\" references a teleportation device in the form of a compass said to have been built by Rheticus.\nRheticus is referenced several times in the song \"Like Rheticus\" on the 2004 album \"Place\" by British songwriter Owen Tromans.\nDava Sobel's 2011 book \"\" features a fictional play about Rheticus' visit to Copernicus, sandwiched between chapters about the visit's pre-history and post-history.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50395", "revid": "41195652", "url": "https://en.wikipedia.org/wiki?curid=50395", "title": "Kernel (mathematics)", "text": ""}
{"id": "50397", "revid": "5846", "url": "https://en.wikipedia.org/wiki?curid=50397", "title": "Cerebellum", "text": "Structure at the rear of the vertebrate brain, beneath the cerebrum\nThe cerebellum (pl.: cerebella or cerebellums; Latin for 'little brain') is a major feature of the hindbrain of all vertebrates. Although usually smaller than the cerebrum, in some animals such as the mormyrid fishes it may be as large as it or even larger. In humans, the cerebellum plays an important role in motor control and cognitive functions such as attention and language as well as emotional control such as regulating fear and pleasure responses, but its movement-related functions are the most solidly established. The human cerebellum does not initiate movement, but contributes to coordination, precision, and accurate timing: it receives input from sensory systems of the spinal cord and from other parts of the brain, and integrates these inputs to fine-tune motor activity. Cerebellar damage produces disorders in fine movement, equilibrium, posture, and motor learning in humans.\nAnatomically, the human cerebellum has the appearance of a separate structure attached to the bottom of the brain, tucked underneath the cerebral hemispheres. Its cortical surface is covered with finely spaced parallel grooves, in striking contrast to the broad irregular convolutions of the cerebral cortex. These parallel grooves conceal the fact that the cerebellar cortex is actually a thin, continuous layer of tissue tightly folded in the style of an accordion. Within this thin layer are several types of neurons with a highly regular arrangement, the most important being Purkinje cells and granule cells. This complex neural organization gives rise to a massive signal-processing capability, but almost all of the output from the cerebellar cortex passes through a set of small deep nuclei lying in the white matter interior of the cerebellum.\nIn addition to its direct role in motor control, the cerebellum is necessary for several types of motor learning, most notably learning to adjust to changes in sensorimotor relationships. Several theoretical models have been developed to explain sensorimotor calibration in terms of synaptic plasticity within the cerebellum. These models derive from those formulated by David Marr and James Albus, based on the observation that each cerebellar Purkinje cell receives two dramatically different types of input: one comprises thousands of weak inputs from the parallel fibers of the granule cells; the other is an extremely strong input from a single climbing fiber. The basic concept of the Marr\u2013Albus theory is that the climbing fiber serves as a \"teaching signal\", which induces a long-lasting change in the strength of parallel fiber inputs. Observations of long-term depression in parallel fiber inputs have provided some support for theories of this type, but their validity remains controversial.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nStructure.\nAt the level of gross anatomy, the cerebellum consists of a tightly folded layer of cortex, with white matter underneath and a fluid-filled ventricle at the base. Four deep cerebellar nuclei are embedded in the white matter. Each part of the cortex consists of the same small set of neuronal elements, laid out in a highly stereotyped geometry. At an intermediate level, the cerebellum and its auxiliary structures can be separated into several hundred or thousand independently functioning modules called \"microzones\" or \"microcompartments\".\nGross anatomy.\nThe cerebellum is located in the posterior cranial fossa. The fourth ventricle, pons and medulla are in front of the cerebellum. It is separated from the overlying cerebrum by a layer of leathery dura mater, the cerebellar tentorium; all of its connections with other parts of the brain travel through the pons. Anatomists classify the cerebellum as part of the metencephalon, which also includes the pons; the metencephalon is the upper part of the rhombencephalon or \"hindbrain\". Like the cerebral cortex, the cerebellum is divided into two cerebellar hemispheres; it also contains a narrow midline zone (the vermis). A set of large folds is, by convention, used to divide the overall structure into 10 smaller \"lobules\". Because of its large number of tiny granule cells, the cerebellum contains more neurons than the total from the rest of the brain, but takes up only 10% of the total brain volume. The number of neurons in the cerebellum is related to the number of neurons in the neocortex. There are about 3.6 times as many neurons in the cerebellum as in the neocortex, a ratio that is conserved across many different mammalian species.\nThe unusual surface appearance of the cerebellum conceals the fact that most of its volume is made up of a very tightly folded layer of gray matter: the cerebellar cortex. Each ridge or gyrus in this layer is called a folium. High\u2011resolution MRI finds the adult human cerebellar cortex has an area of 730\u00a0square cm, packed within a volume of dimensions 6\u00a0cm \u00d7 5\u00a0cm \u00d7 10\u00a0cm. Underneath the gray matter of the cortex lies white matter, made up largely of myelinated nerve fibers running to and from the cortex. Embedded within the white matter\u2014which is sometimes called the \"arbor vitae\" (tree of life) because of its branched, tree-like appearance in cross-section\u2014are four deep cerebellar nuclei, composed of gray matter.\nConnecting the cerebellum to different parts of the nervous system are three paired cerebellar peduncles. These are the superior cerebellar peduncle, the middle cerebellar peduncle and the inferior cerebellar peduncle, named by their position relative to the vermis. The superior cerebellar peduncle is mainly an output to the cerebral cortex, carrying efferent fibers via thalamic nuclei to upper motor neurons in the cerebral cortex. The fibers arise from the deep cerebellar nuclei. The middle cerebellar peduncle is connected to the pons and receives all of its input from the pons mainly from the pontine nuclei. The input to the pons is from the cerebral cortex and is relayed from the pontine nuclei via transverse pontine fibers to the cerebellum. The middle peduncle is the largest of the three and its afferent fibers are grouped into three separate fascicles taking their inputs to different parts of the cerebellum. The inferior cerebellar peduncle receives input from afferent fibers from the vestibular nuclei, spinal cord and the tegmentum. Output from the inferior peduncle is via efferent fibers to the vestibular nuclei and the reticular formation. The whole of the cerebellum receives modulatory input from the inferior olivary nucleus via the inferior cerebellar peduncle.\nSubdivisions.\nBased on the surface appearance, three lobes can be distinguished within the cerebellum: the anterior lobe (above the primary fissure), the posterior lobe (below the primary fissure), and the flocculonodular lobe (below the posterior fissure). These lobes divide the cerebellum from rostral to caudal (in humans, top to bottom). In terms of function, however, there is a more important distinction along the medial-to-lateral dimension. Leaving out the flocculonodular lobe, which has distinct connections and functions, the cerebellum can be parsed functionally into a medial sector called the spinocerebellum and a larger lateral sector called the cerebrocerebellum. A narrow strip of protruding tissue along the midline is called the cerebellar vermis. (\"Vermis\" is Latin for \"worm\".)\nThe smallest region, the flocculonodular lobe, is often called the vestibulocerebellum. It is the oldest part in evolutionary terms (archicerebellum) and participates mainly in balance and spatial orientation; its primary connections are with the vestibular nuclei, although it also receives visual and other sensory input. Damage to this region causes disturbances of balance and gait.\nThe medial zone of the anterior and posterior lobes constitutes the spinocerebellum, also known as paleocerebellum. This sector of the cerebellum functions mainly to fine-tune body and limb movements. It receives proprioceptive input from the dorsal columns of the spinal cord (including the spinocerebellar tract) and from the cranial trigeminal nerve, as well as from visual and auditory systems. It sends fibers to deep cerebellar nuclei that, in turn, project to both the cerebral cortex and the brain stem, thus providing modulation of descending motor systems.\nThe lateral zone, which in humans is by far the largest part, constitutes the cerebrocerebellum, also known as neocerebellum. It receives input exclusively from the cerebral cortex (especially the parietal lobe) via the pontine nuclei (forming cortico-ponto-cerebellar pathways), and sends output mainly to the ventrolateral thalamus (in turn connected to motor areas of the premotor cortex and primary motor area of the cerebral cortex) and to the red nucleus. There is disagreement about the best way to describe the functions of the lateral cerebellum: It is thought to be involved in planning movement that is about to occur, in evaluating sensory information for action, and in a number of purely cognitive functions, such as determining the verb which best fits with a certain noun (as in \"sit\" for \"chair\").\nMicroanatomy.\nTwo types of neuron play dominant roles in the cerebellar circuit: Purkinje cells and granule cells. Three types of axons also play dominant roles: mossy fibers and climbing fibers (which enter the cerebellum from outside), and parallel fibers (which are the axons of granule cells). There are two main pathways through the cerebellar circuit, originating from mossy fibers and climbing fibers, both eventually terminating in the deep cerebellar nuclei.\nMossy fibers project directly to the deep nuclei, but also give rise to the following pathway: mossy fibers \u2192 granule cells \u2192 parallel fibers \u2192 Purkinje cells \u2192 deep nuclei. Climbing fibers project to Purkinje cells and also send collaterals directly to the deep nuclei. The mossy fiber and climbing fiber inputs each carry fiber-specific information; the cerebellum also receives dopaminergic, serotonergic, noradrenergic, and cholinergic inputs that presumably perform global modulation.\nThe cerebellar cortex is divided into three layers. At the bottom lies the thick granular layer, densely packed with granule cells, along with interneurons, mainly Golgi cells but also including Lugaro cells and unipolar brush cells. In the middle lies the Purkinje layer, a narrow zone that contains the cell bodies of Purkinje cells and Bergmann glial cells. At the top lies the molecular layer, which contains the flattened dendritic trees of Purkinje cells, along with the huge array of parallel fibers penetrating the Purkinje cell dendritic trees at right angles. This outermost layer of the cerebellar cortex also contains two types of inhibitory interneuron: stellate cells and basket cells. Both stellate and basket cells form GABAergic synapses onto Purkinje cell dendrites.\nLayers of the cerebellar cortex.\nMolecular layer.\nThe top, outermost layer of the cerebellar cortex is the molecular layer. This layer contains the flattened dendritic trees of Purkinje cells, and the huge array of parallel fibers, from the granular layer, that penetrate the Purkinje cell dendritic trees at right angles. The molecular layer also contains two types of inhibitory interneuron: stellate cells and basket cells. Both stellate and basket cells form GABAergic synapses onto Purkinje cell dendrites.\nPurkinje layer.\nPurkinje cells are among the most distinctive neurons in the brain, and one of the earliest types to be recognized\u2014they were first described by the Czech anatomist Jan Evangelista Purkyn\u011b in 1837. They are distinguished by the shape of their dendritic tree: the dendrites branch very profusely, but are severely flattened in a plane perpendicular to the cerebellar folds. Thus, the dendrites of a Purkinje cell form a dense planar net, through which parallel fibers pass at right angles. The dendrites are covered with dendritic spines, each of which receives synaptic input from a parallel fiber. Purkinje cells receive more synaptic inputs than any other type of cell in the brain\u2014estimates of the number of spines on a single human Purkinje cell run as high as 200,000. The large, spherical cell bodies of Purkinje cells are packed into a narrow layer (one cell thick) of the cerebellar cortex, called the \"Purkinje layer\". After emitting collaterals that affect nearby parts of the cortex, their axons travel into the deep cerebellar nuclei, where they make on the order of 1,000 contacts each with several types of nuclear cells, all within a small domain. Purkinje cells use GABA as their neurotransmitter, and therefore exert inhibitory effects on their targets.\nPurkinje cells form the heart of the cerebellar circuit, and their large size and distinctive activity patterns have made it relatively easy to study their response patterns in behaving animals using extracellular recording techniques. Purkinje cells normally emit action potentials at a high rate even in the absence of the synaptic input. In awake, behaving animals, mean rates averaging around 40\u00a0Hz are typical. The spike trains show a mixture of what are called simple and complex spikes. A simple spike is a single action potential followed by a refractory period of about 10\u00a0ms; a complex spike is a stereotyped sequence of action potentials with very short inter-spike intervals and declining amplitudes. Physiological studies have shown that complex spikes (which occur at baseline rates around 1\u00a0Hz and never at rates much higher than 10\u00a0Hz) are reliably associated with climbing fiber activation, while simple spikes are produced by a combination of baseline activity and parallel fiber input. Complex spikes are often followed by a pause of several hundred milliseconds during which simple spike activity is suppressed.\nA specific, recognizable feature of Purkinje neurons is the expression of calbindin. Calbindin staining of rat brain after unilateral chronic sciatic nerve injury suggests that Purkinje neurons may be newly generated in the adult brain, initiating the organization of new cerebellar lobules.\nGranular layer.\nCerebellar granule cells, in contrast to Purkinje cells, are among the smallest neurons in the brain. They are also the most numerous neurons in the brain: In humans, estimates of their total number average around 50 billion, which means that about 3/4 of the brain's neurons are cerebellar granule cells. Their cell bodies are packed into a thick layer at the bottom of the cerebellar cortex. A granule cell emits only four to five dendrites, each of which ends in an enlargement called a \"dendritic claw\". These enlargements are sites of excitatory input from mossy fibers and inhibitory input from Golgi cells.\nThe thin, unmyelinated axons of granule cells rise vertically to the upper (molecular) layer of the cortex, where they split in two, with each branch traveling horizontally to form a parallel fiber; the splitting of the vertical branch into two horizontal branches gives rise to a distinctive \"T\" shape. A human parallel fiber runs for an average of 3\u00a0mm in each direction from the split, for a total length of about 6\u00a0mm (about 1/10 of the total width of the cortical layer). As they run along, the parallel fibers pass through the dendritic trees of Purkinje cells, contacting one of every 3\u20135 that they pass, making a total of 80\u2013100 synaptic connections with Purkinje cell dendritic spines. Granule cells use glutamate as their neurotransmitter, and therefore exert excitatory effects on their targets.\nGranule cells receive all of their input from mossy fibers, but outnumber them by 200 to 1 (in humans). Thus, the information in the granule cell population activity state is the same as the information in the mossy fibers, but recoded in a much more expansive way. Because granule cells are so small and so densely packed, it is difficult to record their spike activity in behaving animals, so there is little data to use as a basis for theorizing. The most popular concept of their function was proposed in 1969 by David Marr, who suggested that they could encode combinations of mossy fiber inputs. The idea is that with each granule cell receiving input from only 4\u20135 mossy fibers, a granule cell would not respond if only a single one of its inputs were active, but would respond if more than one were active. This combinatorial coding scheme would potentially allow the cerebellum to make much finer distinctions between input patterns than the mossy fibers alone would permit.\nMossy fibers.\nMossy fibers enter the granular layer from their points of origin, many arising from the pontine nuclei, others from the spinal cord, vestibular nuclei etc. In the human cerebellum, the total number of mossy fibers has been estimated at 200 million. These fibers form excitatory synapses with the granule cells and the cells of the deep cerebellar nuclei. Within the granular layer, a mossy fiber generates a series of enlargements called \"rosettes\". The contacts between mossy fibers and granule cell dendrites take place within structures called glomeruli. Each glomerulus has a mossy fiber rosette at its center, and up to 20 granule cell dendritic claws contacting it. Terminals from Golgi cells infiltrate the structure and make inhibitory synapses onto the granule cell dendrites. The entire assemblage is surrounded by a sheath of glial cells. Each mossy fiber sends collateral branches to several cerebellar folia, generating a total of 20\u201330 rosettes; thus a single mossy fiber makes contact with an estimated 400\u2013600 granule cells.\nClimbing fibers.\nPurkinje cells also receive input from the inferior olivary nucleus on the contralateral side of the brainstem via climbing fibers. Although the inferior olive lies in the medulla oblongata and receives input from the spinal cord, brainstem and cerebral cortex, its output goes entirely to the cerebellum. A climbing fiber gives off collaterals to the deep cerebellar nuclei before entering the cerebellar cortex, where it splits into about 10 terminal branches, each of which gives input to a single Purkinje cell. In striking contrast to the 100,000-plus inputs from parallel fibers, each Purkinje cell receives input from exactly one climbing fiber; but this single fiber \"climbs\" the dendrites of the Purkinje cell, winding around them and making a total of up to 300 synapses as it goes. The net input is so strong that a single action potential from a climbing fiber is capable of producing an extended complex spike in the Purkinje cell: a burst of several spikes in a row, with diminishing amplitude, followed by a pause during which activity is suppressed. The climbing fiber synapses cover the cell body and proximal dendrites; this zone is devoid of parallel fiber inputs.\nClimbing fibers fire at low rates, but a single climbing fiber action potential induces a burst of several action potentials in a target Purkinje cell (a complex spike). The contrast between parallel fiber and climbing fiber inputs to Purkinje cells (over 100,000 of one type versus exactly one of the other type) is perhaps the most provocative feature of cerebellar anatomy, and has motivated much of the theorizing. In fact, the function of climbing fibers is the most controversial topic concerning the cerebellum. There are two schools of thought, one following Marr and Albus in holding that climbing fiber input serves primarily as a teaching signal, the other holding that its function is to shape cerebellar output directly. Both views have been defended in great length in numerous publications. In the words of one review, \"In trying to synthesize the various hypotheses on the function of the climbing fibers, one has the sense of looking at a drawing by Escher. Each point of view seems to account for a certain collection of findings, but when one attempts to put the different views together, a coherent picture of what the climbing fibers are doing does not appear. For the majority of researchers, the climbing fibers signal errors in motor performance, either in the usual manner of discharge frequency modulation or as a single announcement of an 'unexpected event'. For other investigators, the message lies in the degree of ensemble synchrony and rhythmicity among a population of climbing fibers.\"\nDeep nuclei.\nThe deep nuclei of the cerebellum are clusters of gray matter lying within the white matter at the core of the cerebellum. They are, with the minor exception of the nearby vestibular nuclei, the sole sources of output from the cerebellum. These nuclei receive collateral projections from mossy fibers and climbing fibers as well as inhibitory input from the Purkinje cells of the cerebellar cortex. The four nuclei (dentate, globose, emboliform, and fastigial) each communicate with different parts of the brain and cerebellar cortex. (The globose and the emboliform nuclei are also referred to as combined in the interposed nucleus). The fastigial and interposed nuclei belong to the spinocerebellum. The dentate nucleus, which in mammals is much larger than the others, is formed as a thin, convoluted layer of gray matter, and communicates exclusively with the lateral parts of the cerebellar cortex. The flocculus of the flocculonodular lobe is the only part of the cerebellar cortex that does not project to the deep nuclei\u2014its output goes to the vestibular nuclei instead.\nThe majority of neurons in the deep nuclei have large cell bodies and spherical dendritic trees with a radius of about 400\u00a0\u03bcm, and use glutamate as their neurotransmitter. These cells project to a variety of targets outside the cerebellum. Intermixed with them are a lesser number of small cells, which use GABA as a neurotransmitter and project exclusively to the inferior olivary nucleus, the source of climbing fibers. Thus, the nucleo-olivary projection provides an inhibitory feedback to match the excitatory projection of climbing fibers to the nuclei. There is evidence that each small cluster of nuclear cells projects to the same cluster of olivary cells that send climbing fibers to it; there is strong and matching topography in both directions.\nWhen a Purkinje cell axon enters one of the deep nuclei, it branches to make contact with both large and small nuclear cells, but the total number of cells contacted is only about 35 (in cats). Conversely, a single deep nuclear cell receives input from approximately 860 Purkinje cells (again in cats).\nCompartments.\nFrom the viewpoint of gross anatomy, the cerebellar cortex appears to be a homogeneous sheet of tissue, and, from the viewpoint of microanatomy, all parts of this sheet appear to have the same internal structure. There are, however, a number of respects in which the structure of the cerebellum is compartmentalized. There are large compartments that are generally known as \"zones\"; these can be divided into smaller compartments known as \"microzones\".\nThe first indications of compartmental structure came from studies of the receptive fields of cells in various parts of the cerebellar cortex. Each body part maps to specific points in the cerebellum, but there are numerous repetitions of the basic map, forming an arrangement that has been called \"fractured somatotopy\". A clearer indication of compartmentalization is obtained by immunostaining the cerebellum for certain types of protein. The best-known of these markers are called \"zebrins\", because staining for them gives rise to a complex pattern reminiscent of the stripes on a zebra. The stripes generated by zebrins and other compartmentalization markers are oriented perpendicular to the cerebellar folds\u2014that is, they are narrow in the mediolateral direction, but much more extended in the longitudinal direction. Different markers generate different sets of stripes, the widths and lengths vary as a function of location, but they all have the same general shape.\nOscarsson in the late 1970s proposed that these cortical zones can be partitioned into smaller units called microzones. A microzone is defined as a group of Purkinje cells all having the same somatotopic receptive field. Microzones were found to contain on the order of 1000 Purkinje cells each, arranged in a long, narrow strip, oriented perpendicular to the cortical folds. Thus, as the adjoining diagram illustrates, Purkinje cell dendrites are flattened in the same direction as the microzones extend, while parallel fibers cross them at right angles.\nIt is not only receptive fields that define the microzone structure: The climbing fiber input from the inferior olivary nucleus is equally important. The branches of a climbing fiber (usually numbering about 10) usually activate Purkinje cells belonging to the same microzone. Moreover, olivary neurons that send climbing fibers to the same microzone tend to be coupled by gap junctions, which synchronize their activity, causing Purkinje cells within a microzone to show correlated complex spike activity on a millisecond time scale. Also, the Purkinje cells belonging to a microzone all send their axons to the same small cluster of output cells within the deep cerebellar nuclei. Finally, the axons of basket cells are much longer in the longitudinal direction than in the mediolateral direction, causing them to be confined largely to a single microzone. The consequence of all this structure is that cellular interactions within a microzone are much stronger than interactions between different microzones.\nIn 2005, Richard Apps and Martin Garwicz summarized evidence that microzones themselves form part of a larger entity they call a multizonal microcomplex. Such a microcomplex includes several spatially separated cortical microzones, all of which project to the same group of deep cerebellar neurons, plus a group of coupled olivary neurons that project to all of the included microzones as well as to the deep nuclear area.\nBlood supply.\nThe cerebellum is provided with blood from three paired major arteries: the superior cerebellar artery (SCA), the anterior inferior cerebellar artery (AICA), and the posterior inferior cerebellar artery (PICA). The SCA supplies the upper region of the cerebellum. It divides at the upper surface and branches into the pia mater where the branches anastomose with those of the anterior and posterior inferior cerebellar arteries. The AICA supplies the front part of the undersurface of the cerebellum. The PICA arrives at the undersurface, where it divides into a medial branch and a lateral branch. The medial branch continues backward to the cerebellar notch between the two hemispheres of the cerebellum; while the lateral branch supplies the under surface of the cerebellum, as far as its lateral border, where it anastomoses with the AICA and the SCA.\nFunction.\nThe strongest clues to the function of the cerebellum have come from examining the consequences of damage to it. Animals and humans with cerebellar dysfunction show, above all, problems with motor control, on the same side of the body as the damaged part of the cerebellum. They continue to be able to generate motor activity but lose precision, producing erratic, uncoordinated, or incorrectly timed movements. A standard test of cerebellar function is to reach with the tip of the finger for a target at arm's length: A healthy person will move the fingertip in a rapid straight trajectory, whereas a person with cerebellar damage will reach slowly and erratically, with many mid-course corrections. Deficits in non-motor functions are more difficult to detect. Thus, the general conclusion reached decades ago is that the basic function of the cerebellum is to calibrate the detailed form of a movement, not to initiate movements or to decide which movements to execute.\nPrior to the 1990s the function of the cerebellum was mostly believed to be purely motor-related, but later research has pointed to an expanded role of cerebellar connectivity beyond basic motoric functions. Functional imaging studies have shown cerebellar activation in relation to language, attention, and mental imagery; correlation studies have shown interactions between the cerebellum and non-motor areas of the cerebral cortex; and a variety of non-motor symptoms have been recognized in people with damage that appears to be confined to the cerebellum. In particular, the cerebellar cognitive affective syndrome or Schmahmann's syndrome has been described in adults and children. Estimates based on functional mapping of the cerebellum using functional MRI suggest that more than half of the cerebellar cortex is interconnected with association zones of the cerebral cortex.\nKenji Doya has argued that the cerebellum's function is best understood not in terms of the behaviors it affects, but the neural computations it performs; the cerebellum consists of a large number of more or less independent modules, all with the same geometrically regular internal structure, and therefore all, it is presumed, performing the same computation. If the input and output connections of a module are with motor areas (as many are), then the module will be involved in motor behavior; but, if the connections are with areas involved in non-motor cognition, the module will show other types of behavioral correlates. Thus the cerebellum has been implicated in the regulation of many differing functional traits such as affection, emotion including emotional body language perception and behavior. The cerebellum, Doya proposes, is best understood as predictive action selection based on \"internal models\" of the environment or a device for supervised learning, in contrast to the basal ganglia, which perform reinforcement learning, and the cerebral cortex, which performs unsupervised learning. Three decades of brain research have led to the proposal that the cerebellum generates optimized mental models and interacts closely with the cerebral cortex, where updated internal models are experienced as creative intuition (\"a ha\") in working memory.\nPrinciples.\nThe comparative simplicity and regularity of the cerebellar anatomy led to an early hope that it might imply a similar simplicity of computational function, as expressed in one of the first books on cerebellar electrophysiology, \"The Cerebellum as a Neuronal Machine\" by John C. Eccles, Masao Ito, and J\u00e1nos Szent\u00e1gothai. Although a full understanding of cerebellar function has remained elusive, at least four principles have been identified as important: (1) feedforward processing, (2) divergence and convergence, (3) modularity, and (4) plasticity.\nLearning.\nThere is considerable evidence that the cerebellum plays an essential role in some types of motor learning. The tasks where the cerebellum most clearly comes into play are those in which it is necessary to make fine adjustments to the way an action is performed. There has, however, been much dispute about whether learning takes place within the cerebellum itself, or whether it merely serves to provide signals that promote learning in other brain structures. Most theories that assign learning to the circuitry of the cerebellum are derived from the ideas of David Marr and James Albus, who postulated that climbing fibers provide a teaching signal that induces synaptic modification in parallel fiber\u2013Purkinje cell synapses. Marr assumed that climbing fiber input would cause synchronously activated parallel fiber inputs to be strengthened. Most subsequent cerebellar-learning models, however, have followed Albus in assuming that climbing fiber activity would be an error signal, and would cause synchronously activated parallel fiber inputs to be weakened. Some of these later models, such as the \"Adaptive Filter\" model of Fujita made attempts to understand cerebellar function in terms of optimal control theory.\nThe idea that climbing fiber activity functions as an error signal has been examined in many experimental studies, with some supporting it but others casting doubt. In a pioneering study by Gilbert and Thach from 1977, Purkinje cells from monkeys learning a reaching task showed increased complex spike activity\u2014which is known to reliably indicate activity of the cell's climbing fiber input\u2014during periods when performance was poor. Several studies of motor learning in cats observed complex spike activity when there was a mismatch between an intended movement and the movement that was actually executed. Studies of the vestibulo-ocular reflex (which stabilizes the visual image on the retina when the head turns) found that climbing fiber activity indicated \"retinal slip\", although not in a very straightforward way.\nOne of the most extensively studied cerebellar learning tasks is the eyeblink conditioning paradigm, in which a neutral conditioned stimulus (CS) such as a tone or a light is repeatedly paired with an unconditioned stimulus (US), such as an air puff, that elicits a blink response. After such repeated presentations of the CS and US, the CS will eventually elicit a blink before the US, a conditioned response or CR. Experiments showed that lesions localized either to a specific part of the interposed nucleus (one of the deep cerebellar nuclei) or to a few specific points in the cerebellar cortex would abolish learning of a conditionally timed blink response. If cerebellar outputs are pharmacologically inactivated while leaving the inputs and intracellular circuits intact, learning takes place even while the animal fails to show any response, whereas, if intracerebellar circuits are disrupted, no learning takes place\u2014these facts taken together make a strong case that the learning, indeed, occurs inside the cerebellum.\nTheories and computational models.\nThe large base of knowledge about the anatomical structure and behavioral functions of the cerebellum have made it a fertile ground for theorizing\u2014there are perhaps more theories of the function of the cerebellum than of any other part of the brain. The most basic distinction among them is between \"learning theories\" and \"performance theories\"\u2014that is, theories that make use of synaptic plasticity within the cerebellum to account for its role in learning, versus theories that account for aspects of ongoing behavior on the basis of cerebellar signal processing. Several theories of both types have been formulated as mathematical models and simulated using computers. The Kalman filter theory fits with 2 major requirements: the cerebellum is involved in predictions and in sequencing.\nPerhaps the earliest \"performance\" theory was the \"delay line\" hypothesis of Valentino Braitenberg. The original theory put forth by Braitenberg and Roger Atwood in 1958 proposed that slow propagation of signals along parallel fibers imposes predictable delays that allow the cerebellum to detect time relationships within a certain window. Experimental data did not support the original form of the theory, but Braitenberg continued to argue for modified versions. The hypothesis that the cerebellum functions essentially as a timing system has also been advocated by Richard Ivry. Another influential \"performance\" theory is the Tensor network theory of Pellionisz and Llin\u00e1s, which provided an advanced mathematical formulation of the idea that the fundamental computation performed by the cerebellum is to transform sensory into motor coordinates.\nTheories in the \"learning\" category almost all derive from publications by Marr and Albus. Marr's 1969 paper proposed that the cerebellum is a device for learning to associate elemental movements encoded by climbing fibers with mossy fiber inputs that encode the sensory context. Albus proposed in 1971 that a cerebellar Purkinje cell functions as a perceptron, a neurally inspired abstract learning device. The most basic difference between the Marr and Albus theories is that Marr assumed that climbing fiber activity would cause parallel fiber synapses to be strengthened, whereas Albus proposed that they would be weakened. Albus also formulated his version as a software algorithm he called a CMAC (Cerebellar Model Articulation Controller), which has been tested in a number of applications.\nClinical significance.\nDamage to the cerebellum often causes motor-related symptoms, the details of which depend on the part of the cerebellum involved and how it is damaged. Damage to the flocculonodular lobe may show up as a loss of equilibrium and in particular an altered, irregular walking gait, with a wide stance caused by difficulty in balancing. Damage to the lateral zone typically causes problems in skilled voluntary and planned movements which can cause errors in the force, direction, speed and amplitude of movements. Other manifestations include hypotonia (decreased muscle tone), dysarthria (problems with speech articulation), dysmetria (problems judging distances or ranges of movement), dysdiadochokinesia (inability to perform rapid alternating movements such as walking), impaired check reflex or rebound phenomenon, and intention tremor (involuntary movement caused by alternating contractions of opposing muscle groups). Damage to the midline portion may disrupt whole-body movements, whereas damage localized more laterally is more likely to disrupt fine movements of the hands or limbs. Damage to the upper part of the cerebellum tends to cause gait impairments and other problems with leg coordination; damage to the lower part is more likely to cause uncoordinated or poorly aimed movements of the arms and hands, as well as difficulties in speed. This complex of motor symptoms is called \"ataxia\".\nTo identify cerebellar problems, neurological examination includes assessment of gait (a broad-based gait being indicative of ataxia), finger-pointing tests and assessment of posture. If cerebellar dysfunction is indicated, a magnetic resonance imaging scan can be used to obtain a detailed picture of any structural alterations that may exist.\nThe list of medical problems that can produce cerebellar damage is long, including stroke, hemorrhage, swelling of the brain (cerebral edema), tumors, alcoholism, physical trauma such as gunshot wounds or explosives, and chronic degenerative conditions such as olivopontocerebellar atrophy. Some forms of migraine headache may also produce temporary dysfunction of the cerebellum, of variable severity. Infection can result in cerebellar damage in such conditions as the prion diseases and Miller Fisher syndrome, a variant of Guillain\u2013Barr\u00e9 syndrome.\nAging.\nThe human cerebellum changes with age. These changes may differ from those of other parts of the brain.\nThe cerebellum is the youngest brain region (and body part) in centenarians according to an epigenetic biomarker of tissue age known as epigenetic clock: it is about 15 years younger than expected in a centenarian. Further, gene expression patterns in the human cerebellum show less age-related alteration than that in the cerebral cortex.\nSome studies have reported reductions in numbers of cells or volume of tissue, but the amount of data relating to this question is not very large.\nDevelopmental and degenerative disorders.\nCongenital malformation, hereditary disorders, and acquired conditions can affect cerebellar structure and, consequently, cerebellar function. Unless the causative condition is reversible, the only possible treatment is to help people live with their problems. Visualization of the fetal cerebellum by ultrasound scan at 18 to 20 weeks of pregnancy can be used to screen for fetal neural tube defects with a sensitivity rate of up to 99%.\nIn normal development, endogenous sonic hedgehog signaling stimulates rapid proliferation of cerebellar granule neuron progenitors (CGNPs) in the external granule layer (EGL). Cerebellar development occurs during late embryogenesis and the early postnatal period, with CGNP proliferation in the EGL peaking during early development (postnatal day 7 in the mouse). As CGNPs terminally differentiate into cerebellar granule cells (also called cerebellar granule neurons, CGNs), they migrate to the internal granule layer (IGL), forming the mature cerebellum (by post-natal day 20 in the mouse). Mutations that abnormally activate Sonic hedgehog signaling predispose to cancer of the cerebellum (medulloblastoma) in humans with Gorlin Syndrome and in genetically engineered mouse models.\nCongenital malformation or underdevelopment (hypoplasia) of the cerebellar vermis is a characteristic of both Dandy\u2013Walker syndrome and Joubert syndrome. In very rare cases, the entire cerebellum may be absent. The inherited neurological disorders Machado\u2013Joseph disease, ataxia telangiectasia, and Friedreich's ataxia cause progressive neurodegeneration linked to cerebellar loss. Congenital brain malformations outside the cerebellum can, in turn, cause herniation of cerebellar tissue, as seen in some forms of Arnold\u2013Chiari malformation.\nOther conditions that are closely linked to cerebellar degeneration include the idiopathic progressive neurological disorders multiple system atrophy and Ramsay Hunt syndrome type I, and the autoimmune disorder paraneoplastic cerebellar degeneration, in which tumors elsewhere in the body elicit an autoimmune response that causes neuronal loss in the cerebellum. Cerebellar atrophy can result from an acute deficiency of vitamin B1 (thiamine) as seen in beriberi and in Wernicke\u2013Korsakoff syndrome, or vitamin E deficiency.\nCerebellar atrophy has been observed in many other neurological disorders including Huntington's disease, multiple sclerosis, essential tremor, progressive myoclonus epilepsy, and Niemann\u2013Pick disease. Cerebellar atrophy can also occur as a result of exposure to toxins including heavy metals or pharmaceutical or recreational drugs.\nPain.\nThere is a general consensus that the cerebellum is involved in pain processing. The cerebellum receives pain input from both descending cortico-cerebellar pathways and ascending spino-cerebellar pathways, through the pontine nuclei and inferior olives. Some of this information is transferred to the motor system inducing a conscious motor avoidance of pain, graded according to pain intensity.\nThese direct pain inputs, as well as indirect inputs, are thought to induce long-term pain avoidance behavior that results in chronic posture changes and consequently, in functional and anatomical remodeling of vestibular and proprioceptive nuclei. As a result, chronic neuropathic pain can induce macroscopic anatomical remodeling of the hindbrain, including the cerebellum. The magnitude of this remodeling and the induction of neuron progenitor markers suggest the contribution of adult neurogenesis to these changes.\nComparative anatomy and evolution.\nThe circuits in the cerebellum are similar across all classes of vertebrates, including fish, reptiles, birds, and mammals. There is also an analogous brain structure in cephalopods with well-developed brains, such as octopuses. This has been taken as evidence that the cerebellum performs functions important to all animal species with a brain.\nThere is considerable variation in the size and shape of the cerebellum in different vertebrate species. In amphibians, it is little developed, and in lampreys, and hagfish, the cerebellum is barely distinguishable from the brain-stem. Although the spinocerebellum is present in these groups, the primary structures are small, paired-nuclei corresponding to the vestibulocerebellum. The cerebellum is a bit larger in reptiles, considerably larger in birds, and larger still in mammals. The large paired and convoluted lobes found in humans are typical of mammals, but the cerebellum is, in general, a single median lobe in other groups, and is either smooth or only slightly grooved. In mammals, the neocerebellum is the major part of the cerebellum by mass, but, in other vertebrates, it is typically the spinocerebellum.\nThe cerebellum of cartilaginous and bony fishes is extraordinarily large and complex. In at least one important respect, it differs in internal structure from the mammalian cerebellum: The fish cerebellum does not contain discrete deep cerebellar nuclei. Instead, the primary targets of Purkinje cells are a distinct type of cell distributed across the cerebellar cortex, a type not seen in mammals. In mormyrid fish (a family of weakly electrosensitive freshwater fish), the cerebellum is considerably larger than the rest of the brain. The largest part of it is a special structure called the \"valvula\", which has an unusually regular architecture and receives much of its input from the electrosensory system.\nThe hallmark of the mammalian cerebellum is an expansion of the lateral lobes, whose main interactions are with the neocortex. As monkeys evolved into great apes, the expansion of the lateral lobes continued, in tandem with the expansion of the frontal lobes of the neocortex. In ancestral hominids, and in \"Homo sapiens\" until the middle Pleistocene period, the cerebellum continued to expand, but the frontal lobes expanded more rapidly. The most recent period of human evolution, however, may actually have been associated with an increase in the relative size of the cerebellum, as the neocortex reduced its size somewhat while the cerebellum expanded. The size of the human cerebellum, compared to the rest of the brain, has been increasing in size while the cerebrum decreased in size. With both the development and implementation of motor tasks, visual-spatial skills and learning taking place in the cerebellum, the growth of the cerebellum is thought to have some form of correlation to greater human cognitive abilities. The lateral hemispheres of the cerebellum are now 2.7 times greater in both humans and apes than they are in monkeys. These changes in the cerebellum size cannot be explained by greater muscle mass. They show that either the development of the cerebellum is tightly linked to that of the rest of the brain or that neural activities taking place in the cerebellum were important during Hominidae evolution. Due to the cerebellum's role in cognitive functions, the increase in its size may have played a role in cognitive expansion.\nCerebellum-like structures.\nMost vertebrate species have a cerebellum and one or more cerebellum-like structures, brain areas that resemble the cerebellum in terms of cytoarchitecture and neurochemistry. The only cerebellum-like structure found in mammals is the dorsal cochlear nucleus (DCN), one of the two primary sensory nuclei that receive input directly from the auditory nerve. The DCN is a layered structure, with the bottom layer containing granule cells similar to those of the cerebellum, giving rise to parallel fibers that rise to the superficial layer and travel across it horizontally. The superficial layer contains a set of GABAergic neurons called cartwheel cells that resemble Purkinje cells anatomically and chemically\u2014they receive parallel fiber input, but do not have any inputs that resemble climbing fibers. The output neurons of the DCN are pyramidal cells. They are glutamatergic, but also resemble Purkinje cells in some respects\u2014they have spiny, flattened superficial dendritic trees that receive parallel fiber input, but they also have basal dendrites that receive input from auditory nerve fibers, which travel across the DCN in a direction at right angles to the parallel fibers. The DCN is most highly developed in rodents and other small animals, and is considerably reduced in primates. Its function is not well understood; the most popular speculations relate it to spatial hearing in one way or another.\nMost species of fish and amphibians possess a lateral line system that senses pressure waves in water. One of the brain areas that receives primary input from the lateral line organ, the medial octavolateral nucleus, has a cerebellum-like structure, with granule cells and parallel fibers. In electrosensitive fish, the input from the electrosensory system goes to the dorsal octavolateral nucleus, which also has a cerebellum-like structure. In ray-finned fishes (by far the largest group), the optic tectum has a layer\u2014the marginal layer\u2014that is cerebellum-like.\nAll of these cerebellum-like structures appear to be primarily sensory-related rather than motor-related. All of them have granule cells that give rise to parallel fibers that connect to Purkinje-like neurons with modifiable synapses, but none have climbing fibers comparable to those of the cerebellum\u2014instead they receive direct input from peripheral sensory organs. None has a demonstrated function, but the most influential speculation is that they serve to transform sensory inputs in some sophisticated way, perhaps to compensate for changes in body posture. In fact, James M. Bower and others have argued, partly on the basis of these structures and partly on the basis of cerebellar studies, that the cerebellum itself is fundamentally a sensory structure, and that it contributes to motor control by moving the body in a way that controls the resulting sensory signals. Despite Bower's viewpoint, there is also strong evidence that the cerebellum directly influences motor output in mammals.\nHistory.\nDescriptions.\nEven the earliest anatomists were able to recognize the cerebellum by its distinctive appearance. Aristotle and Herophilus (quoted in Galen) called it the \u03c0\u03b1\u03c1\u03b5\u03b3\u03ba\u03b5\u03c6\u03b1\u03bb\u03af\u03c2 (\"parenkephalis\"), as opposed to the \u1f10\u03b3\u03ba\u03ad\u03c6\u03b1\u03bb\u03bf\u03c2 (\"enkephalos\") or brain proper. Galen's extensive description is the earliest that survives. He speculated that the cerebellum was the source of motor nerves.\nFurther significant developments did not come until the Renaissance. Vesalius discussed the cerebellum briefly, and the anatomy was described more thoroughly by Thomas Willis in 1664. More anatomical work was done during the 18th century, but it was not until early in the 19th century that the first insights into the function of the cerebellum were obtained. Luigi Rolando in 1809 established the key finding that damage to the cerebellum results in motor disturbances. Jean Pierre Flourens in the first half of the 19th century carried out detailed experimental work, which revealed that animals with cerebellar damage can still move, but with a loss of coordination (strange movements, awkward gait, and muscular weakness), and that recovery after the lesion can be nearly complete unless the lesion is very extensive. By the beginning of the 20th century, it was widely accepted that the primary function of the cerebellum relates to motor control; the first half of the 20th century produced several detailed descriptions of the clinical symptoms associated with cerebellar disease in humans.\nEtymology.\nThe name \"cerebellum\" is a diminutive of \"cerebrum\" (brain); it can be translated literally as \"little brain\". The Latin name is a direct translation of the Ancient Greek \u03c0\u03b1\u03c1\u03b5\u03b3\u03ba\u03b5\u03c6\u03b1\u03bb\u03af\u03c2 (\"parenkephalis\"), which was used in the works of Aristotle, the first known writer to describe the structure. No other name is used in the English-language literature, but historically a variety of Greek or Latin-derived names have been used, including \"cerebrum parvum\", \"encephalion\", \"encranion\", \"cerebrum posterius\", and \"parencephalis\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50399", "revid": "50962566", "url": "https://en.wikipedia.org/wiki?curid=50399", "title": "Kiss", "text": "Touch with the lips, usually to express love, affection or greeting\nA kiss is the touching or pressing of one's lips against another person, animal or object. Cultural connotations of kissing vary widely; depending on the culture and context, a kiss can express sentiments of love, passion, romance, sexual attraction, sexual activity, sexual intercourse, sexual arousal, affection, respect, greeting, peace, or good luck, among many others. In some situations, a kiss is a ritual, formal or symbolic gesture indicating devotion, respect, or a sacramental.\nThe word comes from Old English ('to kiss'), in turn from \"\" ('a kiss').\nHistory.\nAnthropologists disagree on whether kissing is an instinctual or learned behaviour. Those who believe kissing to be an instinctual behaviour cite similar behaviours in other animals such as bonobos, which are known to kiss after fighting - possibly to restore peace. Others believe that it is a learned behaviour, having evolved from activities such as suckling or premastication in early human cultures passed on to modern humans. Another theory posits that the practice originated in males during the Paleolithic era tasting the saliva of females to test their health in order to determine whether they would make a good partner for procreation. The fact that not all human cultures kiss is used as an argument against kissing being an instinctual behaviour in humans; only around 90% of the human population is believed to practice kissing.\nThe earliest reference to kissing-like behavior comes from the Vedas, Sanskrit scriptures that informed Hinduism, Buddhism, and Jainism, around 3,500 years ago, according to Vaughn Bryant, an anthropologist at Texas A&amp;M University who specialized in the history of the kiss. However, recent studies challenge the belief that kissing originated in South Asia around 1500 BCE, arguing that there is no single point of origin in historical times. Figurines have been found that indicate kissing may have been practiced in prehistory. It's been suggested that Neandertals and humans kissed. Evidence from ancient Mesopotamia and Egypt suggests that kissing was documented as early as 2500 BCE. Kissing was present in both romantic and familial contexts in ancient Mesopotamia, but it was subject to social regulation, and public display of the sexual aspect of kissing was discouraged. Kissing also had a role in rituals. The act of kissing may have unintentionally facilitated the transmission of orally transmitted microorganisms, potentially leading to disease. Advances in ancient DNA extraction have revealed pathogen genomes in human remains, including those transmitted through saliva. The shift in dominant lineages of the herpes simplex virus 1 (HSV-1) during the Bronze Age implies that cultural practices like romantic-sexual kissing could have contributed to its transmission. Ancient Mesopotamian medical texts mention a disease called bu'shanu, which may have been related to HSV-1 infection. While kissing itself was not directly associated with disease transmission in Mesopotamia, certain cultural and religious factors governed its practice.\nBoth lip and tongue kissing are mentioned in Sumerian poetry:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;My lips are too small, they know not to kiss.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;My precious sweet, lying by my heart,one by one \"tonguemaking,\" one by one.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nKissing is described in the surviving ancient Egyptian love poetry from the New Kingdom, found on papyri excavated at Deir el-Medina:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Finally I will drink life from your lips and wake up from this ever lasting sleep.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The wisdom of the earth in a kiss and everything else in your eyes.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I kiss her before everyone that they all may see my love.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;And when her lips are pressed to mine I am made drunk and need not wine.When we kiss, and her warm lips half open,I fly cloud-high without beer!\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;His kisses on my lips, my breast, my hair...Come! Come! Come! And kiss me when I die,For life, compelling life, is in thy breath;And at that kiss, though in the tomb I lie,I will arise and break the bands of Death.\nThe earliest reference to kissing in the Old Testament is in , when Jacob deceives his father to obtain his blessing:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;And his father Isaac said unto him, Come near now, and kiss me, my son.\n features the first man-woman kiss in the Bible, when Jacob flees from Esau and goes to the house of his uncle Laban:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;And Jacob kissed Rachel, and lifted up his voice, and wept.\nMuch later, there is the oft-quoted verse from :\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;May he kiss me with the kisses of his mouth,for your love is better than wine.\nIn \"Cyropaedia\" (370 BC), Xenophon wrote about the Persian custom of kissing in the lips upon departure while narrating the departure of Cyrus the Great (c.\u2009600 BC) as a boy from his Median kinsmen. According to Herodotus (5th century BC), when two Persians meet, the greeting formula expresses their equal or inequal status. They do not speak; rather, equals kiss each other on the mouth, and in the case where one is a little inferior to the other, the kiss is given on the cheek.\nDuring the later Classical period, affectionate mouth-to-mouth kissing was first described in the Hindu epic the \"Mahabharata\".\nAnthropologist Vaughn Bryant argues kissing spread from India to Europe after Alexander the Great conquered parts of Punjab in northern India in 326 BCE.\nThe Romans were passionate about kissing and talked about several types of kissing. Kissing the hand or cheek was called an . Kissing on the lips with mouth closed was called a , which was used between relatives. A kiss of passion was called a .\nKissing was not always an indication of \"eros\", or love, but also could show respect and rank as it was used in Medieval Europe.\nThe study of kissing started sometime in the nineteenth century and is called philematology, which has been studied by people including Cesare Lombroso, Ernest Crawley, Charles Darwin, Edward Burnett Tylor and modern scholars such as Elaine Hatfield.\nTypes.\nKristoffer Nyrop identified a number of types of kisses, including kisses of love, affection, peace, respect, and friendship. He notes, however, that the categories are somewhat contrived and overlapping, and some cultures have more kinds, including the French with twenty and the Germans with thirty.\nExpression of affection.\nKissing another person's lips has become a common expression of affection or warm greeting in many cultures worldwide. Yet in certain cultures, kissing was introduced only through European settlement, before which it was not a routine occurrence. Such cultures include certain indigenous peoples of Australia, the Tahitians, and many tribes in Africa.\nA kiss can also be used to express feelings without an erotic element but can be nonetheless \"far deeper and more lasting\", writes Nyrop. He adds that such kisses can be expression of love \"in the widest and most comprehensive meaning of the word, bringing a message of loyal affection, gratitude, compassion, sympathy, intense joy, and profound sorrow.\"\nNyrop writes that the most common example is the \"intense feeling which knits parents to their offspring\", but he adds that kisses of affection are not only common between parents and children, but also between other members of the same family, which can include those outside the immediate family circle, \"everywhere where deep affection unites people.\" The tradition is written of in the Bible, as when Esau met Jacob after a long separation, he ran towards him, fell on his neck, and kissed him (), Moses greeted his father-in-law and kissed him (), and Orpah kissed her mother-in-law before leaving her (). The family kiss was traditional with the Romans and kisses of affection are often mentioned by the early Greeks, as when Odysseus, on reaching his home, meets his faithful shepherds.\nAffection can be a cause of kissing \"in all ages in grave and solemn moments,\" notes Nyrop, \"not only among those who love each other, but also as an expression of profound gratitude. When the Apostle Paul took leave of the elders of the congregation at Ephesus, \"they all wept sore, and fell on Paul's neck and kissed him\" (Acts 20:37).\" Kisses can also be exchanged between total strangers, as when there is a profound sympathy with or the warmest interest in another person.\nFolk poetry has been the source of affectionate kisses where they sometimes played an important part, as when they had the power to cast off spells or to break bonds of witchcraft and sorcery, often restoring a man to his original shape. Nyrop notes the poetical stories of the \"redeeming power of the kiss are to be found in the literature of many countries, especially, for example, in the Old French Arthurian romances (Lancelot, Guiglain) in which the princess is changed by evil arts into a dreadful dragon, and can only resume her human shape in the case of a knight being brave enough to kiss her.\" In the reverse situation, in the tale of \"Beauty and the Beast\", a transformed prince then told the girl that he had been bewitched by a wicked fairy, and could not be recreated into a man unless a maid fell in love with him and kissed him, despite his ugliness.\nA kiss of affection can also take place after death. In , it is written that when Jacob was dead, \"Joseph fell upon his father's face and wept upon him and kissed him.\" And it is told of Abu Bakr, Muhammad's first disciple, father-in-law, and successor, that, when the prophet was dead, he went into the latter's tent, uncovered his face, and kissed his forehead. Nyrop writes that \"the kiss is the last tender proof of love bestowed on one we have loved, and was believed, in ancient times, to follow mankind to the nether world.\"\nKissing on the lips can be a physical expression of affection or love between two people in which the sensations of touch, taste, and smell are involved. According to the psychologist Menachem Brayer, although many \"mammals, birds, and insects exchange caresses\" which appear to be kisses of affection, they are not kisses in the human sense.\nSurveys indicate that kissing is the second most common form of physical intimacy among United States adolescents (after holding hands), and that about 85% of 15 to 16-year-old adolescents in the US have experienced it.\nKiss on the lips.\nThe kiss on the lips can be performed between two friends or family. This move aims to express affection for a friend. Unlike kissing for love, a friendly kiss has no sexual connotation. The kiss on the lips is a practice that can be found in the time of patriarchs (Bible). In Ancient Greece, the kiss on the mouth was used to express a concept of equality between people of the same rank. In the Middle Ages, the kiss of peace was recommended by the Catholic Church. The kiss on the lips was also common among knights. The gesture has again become popular with young people, particularly in England.\nRomantic kiss.\nIn many cultures, it is considered a harmless custom for teenagers to kiss on a date or to engage in kissing games with friends. These games serve as icebreakers at parties and may be some participants' first exposure to sexuality. There are many such games, including truth or dare, seven minutes in heaven (or the variation \"two minutes in the closet\"), spin the bottle, post office, and wink.\nThe psychologist William Cane notes that kissing in Western society is often a romantic act and describes a few of its attributes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It's not hard to tell when two people are in love. Maybe they're trying to hide it from the world, still they cannot conceal their inner excitement. Men will give themselves away by a certain excited trembling in the muscles of the lower jaw upon seeing their beloved. Women will often turn pale immediately of seeing their lover and then get slightly red in the face as their sweetheart draws near. This is the effect of physical closeness upon two people who are in love.Romantic kissing in Western cultures is a fairly recent development and is rarely mentioned even in ancient Greek literature. In the Middle Ages it became a social gesture and was considered a sign of refinement of the upper classes. Other cultures have different definitions and uses of kissing, notes Brayer. In China, for example, a similar expression of affection consists of rubbing one's nose against the cheek of another person. In other Eastern cultures kissing is not common. In South East Asian countries the \"sniff kiss\" is the most common form of affection and Western mouth to mouth kissing is often reserved for sexual foreplay.\nThe kiss can be an important expression of love and erotic emotions. In his book \"The Kiss and its History\", Kristoffer Nyrop describes the kiss of love as an \"exultant message of the longing of love, love eternally young, the burning prayer of hot desire, which is born on the lovers' lips, and 'rises,' as Charles Fuster has said, 'up to the blue sky from the green plains,' like a tender, trembling thank-offering.\" Nyrop adds that the love kiss, \"rich in promise, bestows an intoxicating feeling of infinite happiness, courage, and youth, and therefore surpasses all other earthly joys in sublimity.\" He also compares it to achievements in life: \"Thus even the highest work of art, yet, the loftiest reputation, is nothing in comparison with the passionate kiss of a woman one loves.\"\nThe power of a kiss is not minimized when he writes that \"we all yearn for kisses and we all seek them; it is idle to struggle against this passion. No one can evade the omnipotence of the kiss ...\" Kissing, he implies, can lead one to maturity: \"It is through kisses that a knowledge of life and happiness first comes to us. Runeberg says that the angels rejoice over the first kiss exchanged by lovers,\" and can keep one feeling young: \"It carries life with it; it even bestows the gift of eternal youth.\" The importance of the lover's kiss can also be significant, he notes: \"In the case of lovers a kiss is everything; that is the reason why a man stakes his all for a kiss,\" and \"man craves for it as his noblest reward.\"\nAs a result, kissing as an expression of love is contained in much of literature, old and new. Nyrop gives a vivid example in the classic love story of Daphnis and Chloe. As a reward \"Chloe has bestowed a kiss on Daphnis\u2014an innocent young-maid's kiss, but it has on him the effect of an electrical shock\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Ye gods, what are my feelings. Her lips are softer than the rose's leaf, her mouth is sweet as honey, and her kiss inflicts on me more pain than a bee's sting. I have often kissed my kids, I have often kissed my lambs, but never have I known aught like this. My pulse is beating fast, my heart throbs, it is as if I were about to suffocate, yet, nevertheless, I want to have another kiss. Strange, never-suspected pain! Has Chloe, I wonder, drunk some poisonous draught ere she kissed me? How comes it that she herself has not died of it?\nRomantic kissing \"requires more than simple proximity,\" notes Cane. It also needs \"some degree of intimacy or privacy, ... which is why you'll see lovers stepping to the side of a busy street or sidewalk.\" Psychologist Wilhelm Reich \"lashed out at society\" for not giving young lovers enough privacy and making it difficult to be alone. However, Cane describes how many lovers manage to attain romantic privacy despite being in a public setting, as they \"lock their minds together\" and thereby create an invisible sense of \"psychological privacy.\" He adds, \"In this way they can kiss in public even in a crowded plaza and keep it romantic.\" Nonetheless, when Cane asked people to describe the most romantic places they ever kissed, \"their answers almost always referred to this ends-of-the-earth isolation, ... they mentioned an apple orchard, a beach, out in a field looking at the stars, or at a pond in a secluded area ...\"\nFrench kiss.\nA \"French kiss\", also known as \"cataglottism\" or a \"tongue kiss\", is an amorous kiss in which the participants' tongues extend to touch each other's lips or tongue. A \"kiss with the tongue\" stimulates the partner's lips, tongue and mouth, which are sensitive to the touch and induce sexual arousal. The sensation when two tongues touch\u2014also known as \"tongue touching\"\u2014has been proven to stimulate endorphin release and reduce acute stress levels. Extended French kissing may be part of making out. The term originated at the beginning of the 20th century, in America and Great Britain, as the French had acquired a reputation for more adventurous and passionate sex practices.\nFrench kissing may be a mode for disease transmission, particularly if there are open wounds.\nKiss as ritual.\nThroughout history, a kiss has been a ritual, formal, symbolic or social gesture indicating devotion, respect or greeting. It appears as a ritual or symbol of religious devotion. For example, in the case of kissing a temple floor, or a religious book or icon. Besides devotion, a kiss has also indicated subordination or, nowadays, respect.\nIn modern times the practice continues, as in the case of a bride and groom kissing at the conclusion of a wedding ceremony or national leaders kissing each other in greeting, and in many other situations.\nReligion.\nA kiss in a religious context is common. In earlier periods of Christianity or Islam, kissing became a ritual gesture, and is still treated as such in certain customs, as when \"kissing... relics, or a bishop's ring.\" In Judaism, the kissing of the Torah scroll, a prayer book, and a prayer shawl is also common. Crawley notes that it was \"very significant of the affectionate element in religion\" to give so important a part to the kiss as part of its ritual. In the early Church the baptized were kissed by the celebrant after the ceremony, and its use was even extended as a salute to saints and religious heroes, with Crawley adding, \"Thus Joseph kissed Jacob, and his disciples kissed Paul. Joseph kissed his dead father, and the custom was retained in our civilization\", as the farewell kiss on dead relatives, although certain sects prohibit this today.\nA distinctive element in the Christian liturgy was noted by Justin in the 2nd century, now referred to as the \"kiss of peace,\" and once part of the rite in the primitive Mass. Conybeare has stated that this act originated within the ancient Hebrew synagogue, and Philo, the ancient Jewish philosopher called it a \"kiss of harmony\", where, as Crawley explains, \"the Word of God brings hostile things together in concord and the kiss of love.\" Saint Cyril also writes, \"this kiss is the sign that our souls are united, and that we banish all remembrance of injury.\"\nKiss of peace.\nNyrop notes that the kiss of peace was used as an expression of deep, spiritual devotion in the early Christian Church. Christ said, for instance, \"Peace be with you, my peace I give you,\" and the members of Christ's Church gave each other peace symbolically through a kiss. St Paul repeatedly speaks of the \"holy kiss,\" and, in his Epistle to the Romans, writes: \"Salute one another with an holy kiss\" and his first Epistle to the Thessalonians (1 Thessalonians 5:26), he says: \"Greet all the brethren with an holy kiss.\"\nThe kiss of peace was also used in secular festivities. During the Middle Ages, for example, Nyrop points out that it was the custom to \"seal the reconciliation and pacification of enemies by a kiss.\" Even knights gave each other the kiss of peace before proceeding to the combat, and forgave one another all real or imaginary wrongs. The holy kiss was also found in the ritual of the Church on solemn occasions, such as baptism, marriage, confession, ordination, or obsequies. However, toward the end of the Middle Ages the kiss of peace disappears as the official token of reconciliation.\nKiss of respect.\nThe kiss of respect is of ancient origin, notes Nyrop. He writes that \"from the remotest times we find it applied to all that is holy, noble, and worshipful\u2014to the gods, their statues, temples, and altars, as well as to kings and emperors; out of reverence, people even kissed the ground, and both sun and moon were greeted with kisses.\"\nHe notes some examples, as \"when the prophet Hosea laments over the idolatry of the children of Israel, he says that they make molten images of calves and kiss them\" (). In classical times similar homage was often paid to the gods, and people were known to kiss the hands, knees, feet, and the mouths, of their idols. Cicero writes that the lips and beard of the famous statue of Hercules at Agrigentum were worn away by the kisses of devotees.\nPeople kissed the cross with the image of Jesus, and such kissing of the cross is always considered a holy act. In many countries it is required, on taking an oath, as the highest assertion that the witness would be speaking the truth. Nyrop notes that \"as a last act of charity, the image of the Redeemer is handed to the dying or death-condemned to be kissed.\" Kissing the cross brings blessing and happiness; people kiss the image of Mary and the pictures and statues of saints\u2014not only their pictures, \"but even their relics are kissed,\" notes Nyrop. \"They make both soul and body whole.\" There are legends innumerable of sick people regaining their health by kissing relics, he points out.\nThe kiss of respect has also represented a mark of fealty, humility and reverence. Its use in ancient times was widespread, and Nyrop gives examples: \"people threw themselves down on the ground before their rulers, kissed their footprints, literally 'licked the dust,' as it is termed.\" \"Nearly everywhere, wheresoever an inferior meets a superior, we observe the kiss of respect. The Roman slaves kissed the hands of their masters; pupils and soldiers those of their teachers and captains respectively.\" People also kissed the earth for joy on returning to their native land after a lengthened absence, as when Agamemnon returned from the Trojan War.\nKiss of friendship.\nThe kiss is also commonly used in American and European culture as a salutation between friends or acquaintances. The friendly kiss until recent times usually occurred only between ladies, but today it is also common between men and women, especially if there is a great difference in age. According to Nyrop, up until the 20th century, \"it seldom or never takes place between men, with the exception, however, of royal personages,\" although he notes that in former times the \"friendly kiss was very common with us between man and man as well as between persons of opposite sexes.\" In guilds, for example, it was customary for the members to greet each other \"with hearty handshakes and smacking kisses,\" and, on the conclusion of a meal, people thanked and kissed both their hosts and hostesses.\nCultural significance.\nIn approximately 10% of the world population, kissing does not take place, for a variety of reasons, including that they find it dirty or because of superstitious reasons. For example, in parts of Sudan it is believed that the mouth is the portal to the soul, so they do not want to invite death or have their spirit taken. Psychology professor Elaine Hatfield noted that \"kissing was far from universal and even seen as improper by many societies.\" The romantic\u2013sexual kiss is present in only about half of the global cultures.\nDespite kissing being widespread, in some parts of the world it is still taboo to kiss publicly and is often banned in films or in other media.\nSouth Asia.\nOn-screen lip-kissing was not a regular occurrence in Bollywood until the 1990s, although it has been present from the time of the inception of Bollywood. This can appear contradictory since the culture of kissing is believed to have originated and spread from India.\nMiddle East.\nThere are also taboos as to whom one can kiss in some Muslim-majority societies governed by religious law. In the Islamic Republic of Iran, a man who kisses or touches a woman who is not his wife or relative can be punished such as getting whipped up to 100 times or go to jail.\nResearch from May 2023 found texts from ancient people in Mesopotamia that indicates that kissing was a well-established practice 4,500 years ago. According to Dr Troels Pank Arb\u00f8ll, one of the authors of this study:\n\"In ancient Mesopotamia, which is the name for the early human cultures that existed between the Euphrates and Tigris rivers in present-day Iraq and Syria, people wrote in cuneiform script on clay tablets. Many thousands of these clay tablets have survived to this day, and they contain clear examples that kissing was considered a part of romantic intimacy in ancient times, just as kissing could be part of friendships and family members' relations.\"\nEast Asia.\nDonald Richie comments that in Japan, as in China, although kissing took place in erotic situations, in public \"the kiss was invisible\", and the \"touching of the lips never became the culturally encoded action it has for so long been in Europe and America.\" The early Edison film, \"The Widow Jones\u00a0\u2013 the May Irwin-John Rice Kiss\" (1896), created a sensation when it was shown in Tokyo, and people crowded to view the enormity. Likewise, Rodin's sculpture \"The Kiss\" was not displayed in Japan until after the Pacific War. Also, in the 1900s, Manchu tribes along the Amur River regarded public kissing between adults with revulsion. In a similar situation in Chinese tradition, when Chinese men saw Western women kissing men in public, they thought the women were prostitutes.\nContemporary practices.\nIn modern Western culture, kissing on the lips is commonly an expression of romantic affection or a warm greeting. When lips are pressed together for an extended period, usually accompanied with an embrace, it is an expression of romantic and sexual desire. The practice of kissing with an open mouth, to allow the other to suck their lips or move their tongue into their mouth, is called French kissing. \"Making out\" is often an adolescent's first experience of their sexuality and games which involve kissing, such as spin the bottle, facilitate the experience. People may kiss children on the forehead to comfort them or the cheek or lips to show affection.\nIn modern Eastern culture, the etiquette vary depending on the region. In West Asia, kissing on the lips between both men and women is a common form of greeting. In South and Eastern Asia, it might often be a greeting between women, however, between men, it is unusual. Kissing a baby on the cheeks is a common form of affection. Most kisses between men and women are on the cheeks and not on the lips unless they are romantically involved. Sexual forms of kissing between lovers encompass the whole range of global practices.\nKissing in films.\nThe first romantic kiss on screen was in American silent films in 1896, beginning with the film \"The Kiss\". The kiss lasted 18 seconds and caused many to rail against decadence in the new medium of silent film. Writer Louis Black writes that \"it was the United States that brought kissing out of the Dark Ages.\" However, it met with severe disapproval by defenders of public morality, especially in New York. One critic proclaimed that \"it is absolutely disgusting. Such things call for police interference.\"\nYoung moviegoers began emulating romantic stars on the screen, such as Ronald Colman and Rudolph Valentino, the latter known for ending his passionate scenes with a kiss. Valentino also began his romantic scenes with women by kissing her hand, traveling up her arm, and then kissing her on the back of her neck. Actresses were often turned into stars based on their screen portrayals of passion. Actresses like Nazimova, Pola Negri, Vilma B\u00e1nky and Greta Garbo, became screen idols as a result.\nEventually, the film industry began to adopt the dictates of the Production Code established in 1934, overseen by Will Hays and influenced by Christian religious leaders in America. According to the new code, \"Excessive and lustful kissing, lustful embraces, suggestive postures and gestures, are not to be shown.\" As a result, kissing scenes were shortened, with scenes cut away, leaving the imagination of the viewer to take over. Under the code, actors kissing had to keep their feet on the ground and had to be either standing or sitting.\nThe heyday of romantic kissing on the screen took place in the early sound era, during the Golden Age of Hollywood in the 1930s and 1940s. Body language began to be used to supplement romantic scenes, especially with the eyes, a talent that added to Greta Garbo's fame. Author Lana Citron writes that \"men were perceived as the kissers and women the receivers. Should the roles ever be reversed, women were regarded as vamps . . .\" According to Citron, Mae West and Anna May Wong were the only Hollywood actresses never to have been kissed on screen. Among the films rated for having the most romantic kisses are \"Gone with the Wind\", \"From Here to Eternity\", \"Casablanca\", and \"To Have and Have Not\".\nSociologist Eva Illouz notes that surveys taken in 1935 showed that \"love was the most important theme represented in movies. Similar surveys during the 1930s found the 95% of films had romance as one of their plot lines, what film critics called \"the romantic formula.\"\nIn early Japanese films, kissing and sexual expression were controversial. In 1931, a director slipped a kissing scene past the censor (who was a friend), but when the film opened in a downtown Tokyo theater, the screening was stopped and the film confiscated. During the American occupation of Japan, in 1946, an American censor required a film to include a kissing scene. One scholar says that the censor suggested \"we believe that even Japanese do something like kissing when they love each other. Why don't you include that in your films?\" Americans encouraged such scenes to force the Japanese to express publicly actions and feelings that had been considered strictly private. Since Pearl Harbor, Americans had felt that the Japanese were \"sneaky\", claiming that \"if Japanese kissed in private, they should do it in public too.\"\nNon-sexual kisses.\nIn some Western cultures, it is considered good luck to kiss someone on Christmas or on New Year's Eve, especially beneath a sprig of mistletoe. Newlyweds usually kiss at the end of a wedding ceremony.\nFemale friends and relations and close acquaintances commonly offer reciprocal kisses on the cheek as a greeting or farewell.\nWhere cheek kissing is used, in some countries a single kiss is the custom, while in others a kiss on each cheek is the norm, or even three or four kisses on alternating cheeks. In the United States, an air kiss is becoming more common. This involves kissing in the air near the cheek, with the cheeks touching or not. After a first date, it is common for the couple to give each other a quick kiss on the cheek (or lips where that is the norm) on parting, to indicate that a good time was had and perhaps to indicate an interest in another meeting.\nA symbolic kiss is frequent in Western cultures. A kiss can be \"blown\" to another by kissing the fingertips and then blowing the fingertips, pointing them in the direction of the recipient. This is used to convey affection, usually when parting or when the partners are physically distant but can view each other. Blown kisses are also used when a person wishes to convey affection to a large crowd or audience. The term \"flying kiss\" is used in India to describe a blown kiss. In written correspondence a kiss has been represented by the letter \"X\" since at least 1763. A stage or screen kiss may be performed by actually kissing, or faked by using the thumbs as a barrier for the lips and turning so the audience is unable to fully see the act.\nSome literature suggests that a significant percentage of humanity does not kiss. It has been claimed that in Sub-Saharan African, Asiatic, Polynesian and possibly in some Native American cultures, kissing was relatively unimportant until European colonization. Historically however, the culture of kissing is thought to have begun and spread from the Eastern World, specifically India.\nWith the Andamanese, kissing was only used as a sign of affection towards children and had no sexual undertones.\nIn traditional Islamic cultures, kissing is not permitted between a man and woman who are not married or closely related by blood or marriage. A kiss on the cheek is a very common form of greeting among members of the same sex in most Islamic countries, much like the Southern European pattern.\nLegality of public kissing.\nIn 2007, two people were fined and jailed for a month after kissing and hugging in public in Dubai.\nIn India, public display of affection is a criminal offence under Section 294 of the Indian Penal Code, 1860 with a punishment of imprisonment of up to three months, or a fine, or both. This law was used by police to prosecute couples engaging in intimate acts, such as kissing in public. However, in a number of landmark cases, the higher courts dismissed assertions that kissing in public is obscene.\nLegality of unwanted kissing.\nIn New York in the United States, an unwanted kiss constitutes the sex offense of forcible touching. In Italy, the Supreme Court of Cassation has upheld sexual violence convictions for forced kisses. In Australia, unwanted kissing is sexual assault. In the Netherlands, forced-tongue-kissing was prosecuted as rape from 1998 until 2017, when the Dutch Supreme Court ruled that it should instead (while still deemed illegal) be viewed as a potential form of sexual assault, carrying a maximum eight-year prison sentence.\nIn religion.\nKissing was a custom during the Biblical period mentioned in the , when Isaac kissed his son Jacob. The kiss is used in numerous other contexts in the Bible: the kiss of homage, in Esther 5:2; of subjection, in 1 Samuel 10:1; of reconciliation, in 2 Samuel 14:33; of valediction, in Ruth 1:14; of approbation, in Psalms 2:12; of humble gratitude, in Luke 7:38; of welcome, in Exodus 18:7; of love and joy, in Genesis 20:11. There are also spiritual kisses, as in Song of Songs 1:2; sensual kisses, as in Proverbs 7:13; and hypocritical kisses, as in 2 Samuel 15:5. It was customary to kiss the mouth in biblical times, and also the beard, which is still practiced in Arab culture. Kissing the hand is not biblical, according to Tabor. The kiss of peace was an apostolic custom, and continues to be one of the rites in the Eucharistic services of Roman Catholics.\nIn the Roman Catholic Order of Mass, the bishop or priest celebrant bows and kisses the altar, reverencing it, upon arriving at the altar during the entrance procession before Mass and upon leaving at the recessional at the closing of Mass; if a deacon is assisting, he bows low before the altar but does not kiss it.\nAmong primitive cultures, it was usual to throw kisses to the sun and to the moon, as well as to the images of the gods. Kissing the hand is first heard of among the Persians. According to Tabor, the kiss of homage\u2014the character of which is not indicated in the Bible\u2014was probably upon the forehead, and was expressive of high respect.\nBiology and evolution.\nWithin the natural world of other animals, there are numerous analogies to kissing, notes Crawley, such as \"the billing of birds, the cataglottism of pigeons and the antennal play of some insects.\" Even among mammals such as the dog, cat and bear, similar behavior is noted.\nAnthropologists have not reached a conclusion as to whether kissing is learned or a behavior from instinct. It may be related to grooming behavior also seen between other animals, or arising as a result of mothers premasticating food for their children. Non-human primates also exhibit kissing behavior. Dogs, cats, birds and other animals display licking, nuzzling, and grooming behavior among themselves, and also towards humans or other species. This is sometimes interpreted by observers as a type of kissing.\nKissing in humans was argued by ethologist Eibl-Eibesfeldt to have evolved from the direct mouth-to-mouth regurgitation of food (kiss-feeding) from parent to offspring or male to female (courtship feeding) and has been observed in numerous mammals. The similarity in the methods between kiss-feeding and deep human kisses (e.g. French kiss) is quite pronounced; in the former, the tongue is used to push food from the mouth of the mother to the child with the child receiving both the mother's food and tongue in sucking movements, and the latter is the same but forgoes the premasticated food. In fact, through observations across various species and cultures, it can be confirmed that the act of kissing and premastication has most likely evolved from the similar relationship-based feeding behaviours.\nA 2025 study published in \"Evolution and Human Behavior\" found evidence that kissing first occurred in human ancestors between 21.5\u201316.9 million years ago.\nPhysiology.\nKissing is a complex behavior that requires significant muscular coordination involving a total of 34\u00a0facial muscles and 112\u00a0postural muscles. The most important muscle involved is the orbicularis oris muscle, which is used to pucker the lips and informally known as the \"kissing muscle\". In the case of the French kiss, the tongue is also an important component. Lips have many nerve endings which make them sensitive to touch and bite.\nHealth benefits.\nKissing stimulates the production of hormones responsible for a good mood: oxytocin, which releases the feeling of love and strengthens the bond with the partner, endorphins \u2013 hormones responsible for the feeling of happiness \u2013, and dopamine, which stimulates the pleasure center in the brain. Affection in general has stress-reducing effects. Kissing in particular has been studied in a controlled experiment and it was found that increasing the frequency of kissing in marital and cohabiting relationships results in a reduction of perceived stress, an increase in relationship satisfaction, and a lowering of cholesterol levels.\nDisease transmission.\nKissing on the lips can result in the transmission of some diseases, including infectious mononucleosis (known as the \"kissing disease\") and herpes simplex when the infectious viruses are present in saliva. Research indicates that contraction of HIV via kissing is extremely unlikely, although there was a documented case in 1997 of an HIV infection by kissing. Both the woman and infected man had gum disease, so transmission was through the man's blood, not through saliva.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50400", "revid": "23483242", "url": "https://en.wikipedia.org/wiki?curid=50400", "title": "Dream interpretation", "text": "Assigning of meaning to dreams\nDream interpretation is the process of assigning meaning to dreams. In many ancient societies, such as those of Egypt and Greece, dreaming was considered a supernatural communication or a means of divine intervention, whose message could be interpreted by people with these associated spiritual powers. In the modern era, various schools of psychology and neurobiology have offered theories about the meaning and purpose of dreams.\nHistory.\nEarly civilizations.\nThe ancient Sumerians in Mesopotamia have left evidence of dream interpretation dating back to at least 3100 BC. Throughout Mesopotamian history, dreams were always held to be extremely important for divination and Mesopotamian kings paid close attention to them. Gudea, the king of the Sumerian city-state of Lagash (reigned c. 2144\u20132124 BC), rebuilt the temple of Ningirsu as a result of a dream in which he was told to do so. The standard Akkadian \"Epic of Gilgamesh\" contains numerous accounts of the prophetic power of dreams. First, Gilgamesh himself has two dreams foretelling the arrival of Enkidu. In one of these dreams, Gilgamesh sees an axe fall from the sky. The people gather around it in admiration and worship. Gilgamesh throws the axe in front of his mother Ninsun and then embraces it like a wife. Ninsun interprets the dream to mean that someone powerful will soon appear. Gilgamesh will struggle with him and try to overpower him, but he will not succeed. Eventually, they will become close friends and accomplish great things. She concludes, \"That you embraced him like a wife means he will never forsake you. Thus your dream is solved.\" Later in the epic, Enkidu dreams about the heroes' encounter with the giant Humbaba. Dreams were also sometimes seen as a means of seeing into other worlds and it was thought that the soul, or some part of it, moved out of the body of the sleeping person and actually visited the places and persons the dreamer saw in his or her sleep. In Tablet VII of the epic, Enkidu recounts to Gilgamesh a dream in which he saw the gods Anu, Enlil, and Shamash condemn him to death. He also has a dream in which he visits the Underworld.\nThe Assyrian king Ashurnasirpal II (reigned 883\u2013859 BC) built a temple to Mamu, possibly the god of dreams, at Imgur-Enlil, near Kalhu. The later Assyrian king Ashurbanipal (reigned 668\u2013c. 627 BC) had a dream during a desperate military situation in which his divine patron, the goddess Ishtar, appeared to him and promised that she would lead him to victory. The Babylonians and Assyrians divided dreams into \"good,\" which were sent by the gods, and \"bad,\" sent by demons. A surviving collection of dream omens entitled \"I\u0161kar Zaq\u012bqu\" records various dream scenarios as well as prognostications of what will happen to the person who experiences each dream, apparently based on previous cases. Some list different possible outcomes, based on occasions in which people experienced similar dreams with different results. Dream scenarios mentioned include a variety of daily work events, journeys to different locations, family matters, sex acts, and encounters with human individuals, animals, and deities.\nIn ancient Egypt, priests acted as dream interpreters. Hieroglyphics depicting dreams and their interpretations are evident. Dreams have been held in considerable importance throughout history by most cultures.\nClassical Antiquity.\nThe ancient Greeks constructed temples they called Asclepieions, where sick people were sent to be cured. It was believed that cures would be effected through divine grace by incubating dreams within the confines of the temple. Dreams were also considered prophetic or omens of particular significance. Artemidorus of Daldis, who lived in the 2nd century AD, wrote a comprehensive text \"Oneirocritica\" (\"The Interpretation of Dreams\"). Although Artemidorus believed that dreams can predict the future, he presaged many contemporary approaches to dreams. He thought that the meaning of a dream image could involve puns and could be understood by decoding the image into its component words. For example, Alexander, while waging war against the Tyrians, dreamt that a satyr was dancing on his shield. Artemidorus reports that this dream was interpreted as follows: satyr = \"sa tyros\" (\"Tyre will be thine\"), predicting that Alexander would be triumphant. Freud acknowledged this example of Artemidorus when he proposed that dreams be interpreted like a rebus.\nMiddle Ages.\nIn medieval Islamic psychology, certain hadiths indicate that dreams consist of three parts, and early Muslim scholars recognized three kinds of dreams: false, pathogenic, and true. Ibn Sirin (654\u2013728) was renowned for his \"Ta'bir al-Ru'ya\" and \"Muntakhab al-Kalam fi Tabir al-Ahlam\", a book on dreams. The work is divided into 25 sections on dream interpretation, from the etiquette of interpreting dreams to the interpretation of reciting certain Surahs of the Qur'an in one's dream. He writes that it is important for a layperson to seek assistance from an alim (Muslim scholar) who could guide in the interpretation of dreams with a proper understanding of the cultural context and other such causes and interpretations. Al-Kindi (Alkindus) (801\u2013873) also wrote a treatise on dream interpretation: \"On Sleep and Dreams\". In consciousness studies, Al-Farabi (872\u2013951) wrote the \"On the Cause of Dreams\", which appeared as chapter 24 of his \"Book of Opinions of the people of the Ideal City\". It was a treatise on dreams, in which he was the first to distinguish between dream interpretation and the nature and causes of dreams. In \"The Canon of Medicine\", Avicenna extended the theory of temperaments to encompass \"emotional aspects, mental capacity, moral attitudes, self-awareness, movements and dreams.\" Ibn Khaldun's \"Muqaddimah\" (1377) states that \"confused dreams\" are \"pictures of the imagination that are stored inside by perception and to which the ability to think is applied, after (man) has retired from sense perception.\"\nIbn Shaheen states: \"Interpretations change their foundations according to the different conditions of the seer (of the vision), so seeing handcuffs during sleep is disliked but if a righteous person sees them it can mean stopping the hands from evil\". Ibn Sirin said about a man who saw himself giving a sermon from the mimbar: \"He will achieve authority and if he is not from the people who have any kind of authority it means that he will be crucified\".\nChina.\nA standard traditional Chinese book on dream-interpretation is the \"Lofty Principles of Dream Interpretation\" (\u5922\u5360\u9038\u65e8) compiled in the 16th century by Chen Shiyuan (particularly the \"Inner Chapters\" of that opus). Chinese thinkers also raised profound ideas about dream interpretation, such as the question of how we know we are dreaming and how we know we are awake. It is written in the Chuang-tzu: \"Once Chuang Chou dreamed that he was a butterfly. He fluttered about happily, quite pleased with the state that he was in, and knew nothing about Chuang Chou. Presently he awoke and found that he was very much Chuang Chou again. Now, did Chou dream that he was a butterfly or was the butterfly now dreaming that he was Chou?\"\nModern Europe.\nIn the 17th century, the English physician and writer Sir Thomas Browne wrote a short tract upon the interpretation of dreams. Dream interpretation became an important part of psychoanalysis at the end of the 19th century with Sigmund Freud's seminal work \"The Interpretation of Dreams\" (\"Die Traumdeutung\"; literally \"dream-interpretation\").\nPsychology.\nFreud.\nIn \"The Interpretation of Dreams\", Sigmund Freud argued that all dream content is disguised wish-fulfillment (later in \"Beyond the Pleasure Principle\", Freud would discuss dreams which do not appear to be wish-fulfillment). According to Freud, the instigation of a dream is often to be found in the events of the day preceding the dream, which he called the \"day residue.\" In very young children, this can be easily seen, as they dream quite straightforwardly of the fulfillment of wishes that were aroused in them the previous day (the \"dream day\"). In adults the situation is more complicated since, in Freud's analysis, the dreams of adults have been subjected to distortion, with the dream's so-called \"manifest content\" being a heavily disguised derivative of the \"latent dream-thoughts\" present in the unconscious. The dream's real significance is thus concealed: dreamers are no more capable of recognizing the actual meaning of their dreams than hysterics are able to understand the connection and significance of their neurotic symptoms.\nIn Freud's original formulation, the latent dream-thought was described as having been subject to an intra-psychic force referred to as \"the censor\"; in the terminology of his later years, however, discussion was in terms of the super-ego and the work of the ego's defence mechanisms. In waking life, he asserted, these \"resistances\" prevented the repressed wishes of the unconscious from entering consciousness, and though these wishes were to some extent able to emerge due to the lowered vigilance of the sleep state, the resistances were still strong enough to force them to take on a disguised or distorted form. Freud's view was that dreams are \"compromises\" which ensure that sleep is not interrupted: as \"a \"disguised\" fulfilment of \"repressed\" wishes,\" they succeed in representing wishes as fulfilled which might otherwise disturb and waken the sleeper.\nOne of Freud's early dream analyses is \"Irma's injection\", a dream he himself had. In the dream a former patient of his, Irma, complains of pains and Freud's colleague gives her an unsterile injection. Freud provides pages of associations to the elements in his dream, using it to demonstrate his technique of decoding the latent dream thoughts from the manifest content of the dream.\nFreud suggests that the true meaning of a dream must be \"weeded out\" from the dream as recalled:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;You entirely disregard the apparent connections between the elements in the manifest dream and collect the ideas that occur to you in connection with each separate element of the dream by free association according to the psychoanalytic rule of procedure. From this material you arrive at the latent dream-thoughts, just as you arrived at the patient's hidden complexes from his associations to his symptoms and memories... The true meaning of the dream, which has now replaced the manifest content, is always clearly intelligible. [Freud, \"Five Lectures on Psycho-Analysis\" (1909); Lecture Three]\nFreud listed the distorting operations that he claimed were applied to repressed wishes in forming the dream as recollected: it is because of these distortions (the so-called \"dream-work\") that the manifest content of the dream differs so greatly from the latent dream thought reached through analysis\u2014and it is by \"reversing\" these distortions that the latent content is approached.\nThe operations included:\nTo these might be added \"secondary elaboration\"\u2014the outcome of the dreamer's natural tendency to make some sort of \"sense\" or \"story\" out of the various elements of the manifest content as recollected. Freud stressed that it was not merely futile but actually misleading to attempt to explain one part of the manifest content with reference to another part, as if the manifest dream somehow constituted some unified or coherent conception.\nFreud considered that the experience of anxiety dreams and nightmares was the result of failures in the dream-work: rather than contradicting the \"wish-fulfillment\" theory, such phenomena demonstrated how the ego reacted to the awareness of repressed wishes that were too powerful and insufficiently disguised. Traumatic dreams (where the dream merely repeats the traumatic experience) were eventually admitted as exceptions to the theory.\nFreud famously described psychoanalytic dream-interpretation as \"the royal road to a knowledge of the unconscious activities of the mind\". However, he expressed regret and dissatisfaction at the way his ideas on the subject were misrepresented or simply not understood:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The assertion that all dreams require a sexual interpretation, against which critics rage so incessantly, occurs nowhere in my \"Interpretation of Dreams\" ... and is in obvious contradiction to other views expressed in it.\nJung.\nAlthough not dismissing Freud's model of dream interpretation wholesale, Carl Jung believed Freud's notion of dreams as representations of unfulfilled wishes to be limited. Jung argued that Freud's procedure of collecting associations to a dream would bring insights into the dreamer's mental complex\u2014a person's associations to anything will reveal the mental complexes, as Jung had shown experimentally\u2014but not necessarily closer to the meaning of the dream. Jung was convinced that the scope of dream interpretation was larger, reflecting the richness and complexity of the entire unconscious, both personal and collective. Jung believed the psyche to be a self-regulating organism in which conscious attitudes were likely to be compensated for unconsciously (within the dream) by their opposites. And so the role of dreams is to lead a person to wholeness through what Jung calls \"a dialogue between ego and the self\". The self aspires to tell the ego what it does not know, but it should. This dialogue involves fresh memories, existing obstacles, and future solutions.\nJung proposed two basic approaches to analyzing dream material: the objective and the subjective. In the objective approach, every person in the dream refers to the person they are: mother is mother, girlfriend is girlfriend, etc. In the subjective approach, every person in the dream represents an aspect of the dreamer. Jung argued that the subjective approach is much more difficult for the dreamer to accept, but that in most good dream-work, the dreamer will come to recognize that the dream characters can represent an unacknowledged aspect of the dreamer. Thus, if the dreamer is being chased by a crazed killer, the dreamer may come eventually to recognize his own homicidal impulses. Gestalt therapists extended the subjective approach, claiming that even the inanimate objects in a dream can represent aspects of the dreamer.\nJung believed that archetypes such as the animus, the anima, the shadow, and others manifested themselves in dreams, as dream symbols or figures. Such figures could take the form of an old man, a young maiden, or a giant spider as the case may be. Each represents an unconscious attitude that is largely hidden to the conscious mind. Although an integral part of the dreamer's psyche, these manifestations were largely autonomous and were perceived by the dreamer to be external personages. Acquaintance with the archetypes as manifested by these symbols serve to increase one's awareness of unconscious attitudes, integrating seemingly disparate parts of the psyche and contributing to the process of holistic self-understanding he considered paramount.\nJung believed that material repressed by the conscious mind, postulated by Freud to comprise the unconscious, was similar to his own concept of the shadow, which in itself is only a small part of the unconscious.\nJung cautioned against blindly ascribing meaning to dream symbols without a clear understanding of the client's personal situation. He described two approaches to dream symbols: the causal approach and the final approach. In the causal approach, the symbol is reduced to certain fundamental tendencies. Thus, a sword may symbolize a penis, as may a snake. In the final approach, the dream interpreter asks, \"Why this symbol and not another?\" Thus, a sword representing a penis is hard, sharp, inanimate, and destructive. A snake representing a penis is alive, dangerous, perhaps poisonous, and slimy. The final approach will tell additional things about the dreamer's attitudes.\nTechnically, Jung recommended stripping the dream of its details and presenting the gist of the dream to the dreamer. This was an adaptation of a procedure described by Wilhelm Stekel, who recommended thinking of the dream as a newspaper article and writing a headline for it. Harry Stack Sullivan also described a similar process of \"dream distillation.\"\nAlthough Jung acknowledged the universality of archetypal symbols, he contrasted this with the concept of a sign\u2014images having a one-to-one connotation with their meaning. His approach was to recognize the dynamism and fluidity that existed between symbols and their ascribed meaning. Symbols must be explored for their personal significance to the patient, instead of having the dream conform to some predetermined idea. This prevents dream analysis from devolving into a theoretical and dogmatic exercise that is far removed from the patient's own psychological state. In the service of this idea, he stressed the importance of \"sticking to the image\"\u2014exploring in depth a client's association with a particular image. This may be contrasted with Freud's free associating which he believed was a deviation from the salience of the image. He describes for example the image \"deal table.\" One would expect the dreamer to have some associations with this image, and the professed lack of any perceived significance or familiarity whatsoever should make one suspicious. Jung would ask a patient to imagine the image as vividly as possible and to explain it to him as if he had no idea as to what a \"deal table\" was. Jung stressed the importance of context in dream analysis.\nJung stressed that the dream was not merely a devious puzzle invented by the unconscious to be deciphered, so that the \"true\" causal factors behind it may be elicited. Dreams were not to serve as lie detectors, with which to reveal the insincerity behind conscious thought processes. Dreams, like the unconscious, had their own language. As representations of the unconscious, dream images have their own primacy and mechanics.\nJung believed that dreams may contain ineluctable truths, philosophical pronouncements, illusions, wild fantasies, memories, plans, irrational experiences, and even telepathic visions. Just as the psyche has a diurnal side which we experience as conscious life, it has an unconscious nocturnal side which we apprehend as dreamlike fantasy. Jung would argue that just as we do not doubt the importance of our conscious experience, then we ought not to second guess the value of our unconscious lives.\nHall.\nIn 1953, Calvin S. Hall developed a theory of dreams in which dreaming is considered to be a cognitive process. Hall argued that a dream was simply a thought or sequence of thoughts that occurred during sleep, and that dream images are visual representations of personal conceptions. For example, if one dreams of being attacked by friends, this may be a manifestation of fear of friendship; a more complicated example, which requires a cultural metaphor, is that a cat within a dream symbolizes a need to use one's intuition. For English speakers, it may suggest that the dreamer must recognize that there is \"more than one way to skin a cat,\" or in other words, more than one way to do something. He was also critical of Sigmund Freud's psychoanalytic theory of dream interpretation, particularly Freud's notion that the dream of being attacked represented a fear of castration. Hall argued that this dream did not necessarily stem from castration anxiety, but rather represented the dreamer's perception of themselves as weak, passive, and helpless in the face of danger. In support of his argument, Hall pointed out that women have this dream more frequently than men, yet women do not typically experience castration anxiety. Additionally, he noted that there were no significant differences in the form or content of the dream of being attacked between men and women, suggesting that the dream likely has the same meaning for both genders. Hall's work in dream research also provided evidence to support one of Sigmund Freud's theories, the Oedipus Complex. Hall studied the dreams of males and females ages two through twenty-six. He found that young boys frequently dreamed of aggression towards their fathers and older male siblings, while girls dreamed of hostility towards their mothers and older female siblings. These dreams often involved themes of conflict and competition for the affection of the opposite-sex parent, providing empirical support for Freud's theory of the Oedipus Complex.\nFaraday, Clift, et al..\nIn the 1970s, Ann Faraday and others helped bring dream interpretation into the mainstream by publishing books on do-it-yourself dream interpretation and forming groups to share and analyze dreams. Faraday focused on the application of dreams to situations occurring in one's life. For instance, some dreams are warnings of something about to happen\u2014e.g. a dream of failing an examination, if one is a student, may be a literal warning of unpreparedness. Outside of such context, it could relate to failing some other kind of test. Or it could even have a \"punny\" nature, e.g. that one has failed to examine some aspect of his life adequately.\nFaraday noted that \"one finding has emerged pretty firmly from modern research, namely that the majority of dreams seem in some way to reflect things that have preoccupied our minds during the previous day or two.\"\nIn the 1980s and 1990s, Wallace Clift and Jean Dalby Clift further explored the relationship between images produced in dreams and the dreamer's waking life. Their books identified patterns in dreaming, and ways of analyzing dreams to explore life changes, with particular emphasis on moving toward healing and wholeness.\nNeurobiological theory.\nAllan Hobson and colleagues developed what they called the activation-synthesis hypothesis which proposes that dreams are simply the side effects of the neural activity in the brain that produces beta brain waves during REM sleep that are associated with wakefulness. According to this hypothesis, neurons fire periodically during sleep in the lower brain levels and thus send random signals to the cortex. The cortex then synthesizes a dream in reaction to these signals in order to try to make sense of why the brain is sending them. Although the hypothesis downplays the role that emotional factors play in determining dreams, it does not state that dreams are meaningless.\nPresent-day popular attitudes.\nMost people currently appear to interpret dream content according to Freudian psychoanalysis in the United States, India, and South Korea, according to one study conducted in those countries. People appear to believe dreams are particularly meaningful: they assign more meaning to dreams than to similar waking thoughts. For example, people report they would be more likely to cancel a trip they had planned that involved a plane flight if they dreamt of their plane crashing the night before than if the Department of Homeland Security issued a federal warning. However, people do not attribute equal importance to all dreams. People appear to use motivated reasoning when interpreting their dreams. They are more likely to view dreams confirming their waking beliefs and desires to be more meaningful than dreams that contradict their waking beliefs and desires.\nA paper in 2009 by Carey Morewedge and Michael Norton in the \"Journal of Personality and Social Psychology\" found that most people believe that \"their dreams reveal meaningful hidden truths.\" In one study they found that 74% of Indians, 65% of South Koreans and 56% of Americans believed their dream content provided them with meaningful insight into their unconscious beliefs and desires. This Freudian view of dreaming was endorsed significantly more than theories of dreaming that attribute dream content to memory consolidation, problem solving, or random brain activity. This belief appears to lead people to attribute more importance to dream content than to similar thought content that occurs while they are awake. People were more likely to view a positive dream about a friend to be meaningful than a positive dream about someone they disliked, for example, and were more likely to view a negative dream about a person they disliked as meaningful than a negative dream about a person they liked.\nLayne Dalfen, a contemporary dream analyst and educator, has significantly contributed to the modern understanding of dream interpretation. She developed the \"Six Points of Entry\" method, which provides practical tools for analyzing dreams. This method helps individuals uncover the emotional significance and potential solutions that dreams may offer, emphasizing their role in personal growth and problem-solving. Through her Dream Interpretation Center, media appearances, online course and books, Dalfen has made dream analysis accessible to a broader audience.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50405", "revid": "48535834", "url": "https://en.wikipedia.org/wiki?curid=50405", "title": "Clergy", "text": "Formal leaders within established religions\nClergy are formal leaders within established religions. Their roles and functions vary in different religious traditions, but usually involve presiding over specific rituals and teaching their religion's doctrines and practices. Some of the terms used for individual clergy are clergyman, clergywoman, clergyperson, churchman, cleric, ecclesiastic, and vicegerent while clerk in holy orders has a long history but is rarely used.\nIn Christianity, the specific names and roles of the clergy vary by denomination and there is a wide range of formal and informal clergy positions, including deacons, elders, priests, bishops, cardinals, preachers, pastors, presbyters, ministers, and the pope.\nIn Islam, a religious leader is often formally or informally known as an imam, caliph, qadi, mufti, sheikh, mullah, muezzin, and ulema.\nIn the Jewish tradition, a religious leader is often a rabbi (teacher) or hazzan (cantor).\nEtymology.\nThe word \"cleric\" comes from the ecclesiastical Latin \"Clericus\", for those belonging to the priestly class. In turn, the source of the Latin word is from the Ecclesiastical Greek \"Klerikos\" (\u03ba\u03bb\u03b7\u03c1\u03b9\u03ba\u03cc\u03c2), meaning appertaining to an inheritance, in reference to the fact that the Levitical priests of the Old Testament had no inheritance except the Lord. \"Clergy\" is from two Old French words, \"clergi\u00e9\" and \"clergie\", which refer to those with learning and derive from Medieval Latin \"clericatus\", from Late Latin \"clericus\" (the same word from which \"cleric\" is derived). \"Clerk\", which used to mean one ordained to the ministry, also derives from \"clericus\". In the Middle Ages, reading and writing were almost exclusively the domain of the priestly class, and this is the reason for the close relationship of these words. Within Christianity, especially in Eastern Christianity and formerly in Western Roman Catholicism, the term \"cleric\" refers to any individual who has been ordained, including deacons, priests, and bishops. In Latin Catholicism, the tonsure was a prerequisite for receiving any of the minor orders or major orders before the tonsure, minor orders, and the subdiaconate were abolished following the Second Vatican Council. Now, the clerical state is tied to reception of the diaconate. Minor Orders are still given in the Eastern Catholic Churches, and those who receive those orders are 'minor clerics.'\nThe use of the word \"cleric\" is also appropriate for Eastern Orthodox minor clergy who are tonsured in order not to trivialize orders such as those of Reader in the Eastern Church, or for those who are tonsured yet have no minor or major orders. It is in this sense that the word entered the Arabic language, most commonly in Lebanon from the French, as \"kleriki\" (or, alternatively, \"cleriki\") meaning \"seminarian\". This is all in keeping with Eastern Orthodox concepts of clergy, which still include those who have not yet received, or do not plan to receive, the diaconate.\nA priesthood is a body of priests, shamans, or oracles who have special religious authority or function. The term priest is derived from the Greek presbyter (\u03c0\u03c1\u03b5\u03c3\u03b2\u03cd\u03c4\u03b5\u03c1\u03bf\u03c2, \"presb\u00fdteros\", elder or senior), but is often used in the sense of sacerdos in particular, i.e., for clergy performing ritual within the sphere of the sacred or numinous communicating with the gods on behalf of the community.\nBuddhism.\nBuddhist clergy are often collectively referred to as the Sangha, and consist of various orders of male and female monks (originally called bhikshus and bhikshunis respectively). This diversity of monastic orders and styles was originally one community founded by Gautama Buddha during the 5th century BC living under a common set of rules (called the Vinaya). According to scriptural records, these celibate monks and nuns in the time of the Buddha lived an austere life of meditation, living as wandering beggars for nine months out of the year and remaining in retreat during the rainy season (although such a unified condition of Pre-sectarian Buddhism is questioned by some scholars). However, as Buddhism spread geographically over time\u2014encountering different cultures, responding to new social, political, and physical environments\u2014this single form of Buddhist monasticism diversified. The interaction between Buddhism and Tibetan Bon led to a uniquely Tibetan Buddhism, within which various sects, based upon certain teacher-student lineages arose. Similarly, the interaction between Indian Buddhist monks (particularly of the Southern Madhyamika School) and Chinese Confucian and Taoist monks from c200-c900AD produced the distinctive Ch'an Buddhism. Ch'an, like the Tibetan style, further diversified into various sects based upon the transmission style of certain teachers (one of the most well known being the 'rapid enlightenment' style of Linji Yixuan), as well as in response to particular political developments such as the An Lushan Rebellion and the Buddhist persecutions of Emperor Wuzong. In these ways, manual labour was introduced to a practice where monks originally survived on alms; layers of garments were added where originally a single thin robe sufficed; etc. This adaptation of form and roles of Buddhist monastic practice continued after the transmission to Japan. For example, monks took on administrative functions for the Emperor in particular secular communities (registering births, marriages, deaths), thereby creating Buddhist 'priests'. Again, in response to various historic attempts to suppress Buddhism (most recently during the Meiji Era), the practice of celibacy was relaxed and Japanese monks allowed to marry. This form was then transmitted to Korea, during later Japanese occupation, where celibate and non-celibate monks today exist in the same sects. (Similar patterns can also be observed in Tibet during various historic periods multiple forms of monasticism have co-existed such as \"ngagpa\" lamas, and times at which celibacy was relaxed). As these varied styles of Buddhist monasticism are transmitted to Western cultures, still more new forms are being created.\nIn general, the Mahayana schools of Buddhism tend to be more culturally adaptive and innovative with forms, while Theravada schools (the form generally practiced in Thailand, Burma, Cambodia, and Sri Lanka) tend to take a much more conservative view of monastic life, and continue to observe precepts that forbid monks from touching women or working in certain secular roles. This broad difference in approach led to a major schism among Buddhist monastics in about the 4th century BCE, creating the Early Buddhist Schools.\nWhile female monastic (\"bhikkhuni\") lineages existed in most Buddhist countries at one time, the Theravada lineages of Southeast Asia died out during the 14th-15th Century AD. As there is some debate about whether the bhikkhuni lineage (in the more expansive Vinaya forms) was transmitted to Tibet, the status and future of female Buddhist clergy in this tradition is sometimes disputed by strict adherents to the Theravadan style. Some Mahayana sects, notably in the United States (such as San Francisco Zen Center) are working to reconstruct the female branches of what they consider a common, interwoven lineage.\nThe diversity of Buddhist traditions makes it difficult to generalize about Buddhist clergy. In the United States, Pure Land priests of the Japanese diaspora serve a role very similar to Protestant ministers of the Christian tradition. Meanwhile, reclusive Theravada forest monks in Thailand live a life devoted to meditation and the practice of austerities in small communities in rural Thailand- a very different life from even their city-dwelling counterparts, who may be involved primarily in teaching, the study of scripture, and the administration of the nationally organized (and government sponsored) Sangha. In the Zen traditions of China, Korea and Japan, manual labor is an important part of religious discipline; meanwhile, in the Theravada tradition, prohibitions against monks working as laborers and farmers continue to be generally observed.\nCurrently in North America, there are both celibate and non-celibate clergy in a variety of Buddhist traditions from around the world. In some cases, they are forest dwelling monks of the Theravada tradition; in other cases, they are married clergy of a Japanese Zen lineage and may work a secular job in addition to their role in the Buddhist community. There is also a growing realization that traditional training in ritual and meditation as well as philosophy may not be sufficient to meet the needs and expectations of American lay people. Some communities have begun exploring the need for training in counseling skills as well. Along these lines, at least two fully accredited Master of Divinity programs are currently available: one at Naropa University in Boulder, CO and one at the University of the West in Rosemead, CA.\nTitles for Buddhist clergy include:\nIn Theravada:\nIn Mahayana:\nIn Vajrayana:\nChristianity.\nIn general, Christian clergy are ordained; that is, they are set apart for specific ministry in religious rites. Others who have definite roles in worship but who are not ordained (e.g., laypeople acting as acolytes) are generally not considered clergy, even though they may require some sort of official approval to exercise these ministries.\nTypes of clerics are distinguished from offices, even when the latter are commonly or exclusively occupied by clerics. A Roman Catholic cardinal, for instance, is almost without exception a cleric, but a cardinal is not a type of cleric. An archbishop is not a distinct type of cleric, but is simply a bishop who occupies a particular position with special authority. Conversely, a youth minister at a parish may or may not be a cleric. Different churches have different systems of clergy, though churches with similar polity have similar systems.\nAnglicanism.\nIn Anglicanism, clergy consist of the orders of deacons, priests (presbyters), and bishops in ascending order of seniority. \"Canon\", \"archdeacon\", \"archbishop\" and the like are specific positions within these orders. Bishops are typically overseers, presiding over a diocese composed of many parishes, with an archbishop presiding over a province in most, which is a group of dioceses. A parish (generally a single church) is looked after by one or more priests, although one priest may be responsible for several parishes. New clergy are first ordained as deacons. Those seeking to become priests are usually ordained to the priesthood around a year later. Since the 1960s some Anglican churches have reinstituted the permanent diaconate, in addition to the transitional diaconate, as a ministry focused on bridges the church and the world, especially ministry to those on the margins of society.\nFor a short period of history before the ordination of women as deacons, priests and bishops began within Anglicanism, women could be deaconesses. Although they were usually considered having a ministry distinct from deacons they often had similar ministerial responsibilities.\nIn Anglicanism all clergy are permitted to marry. In most national churches women may become deacons or priests, but while fifteen out of 38 national churches allow for the consecration of women as bishops, only five have ordained any. Celebration of the Eucharist is reserved for priests and bishops.\nNational Anglican churches are presided over by one or more primates or metropolitans (archbishops or presiding bishops). The senior archbishop of the Anglican Communion is the Archbishop of Canterbury, who acts as leader of the Church of England and 'first among equals' of the primates of all Anglican churches.\nBeing a deacon, priest or bishop is considered a function of the person and not a job. When priests retire they are still priests even if they no longer have any active ministry. However, they only hold the basic rank after retirement. Thus a retired archbishop can only be considered a bishop (though it is possible to refer to \"Bishop John Smith, the former Archbishop of York\"), a canon or archdeacon is a priest on retirement and does not hold any additional honorifics.\nFor the forms of address for Anglican clergy, see Forms of address in the United Kingdom.\nBaptist.\nThe Baptist tradition only recognizes two ordained positions in the church as being the elders (pastors) and deacons as outlined in the third chapter of I Timothy in the Bible.\nCatholic Church.\nOrdained clergy in the Catholic Church are either deacons, priests, or bishops belonging to the diaconate, the presbyterate, or the episcopate, respectively. Among bishops, some are metropolitans, archbishops, or patriarchs. The pope is the bishop of Rome, the supreme and universal hierarch of the Church, and his authorization is now required for the ordination of all Roman Catholic bishops. With rare exceptions, cardinals are bishops, although it was not always so; formerly, some cardinals were people who had received clerical tonsure, but not Holy Orders. Secular clergy are ministers, such as deacons and priests, who do not belong to a religious institute and live in the world at large, rather than a religious institute (\"saeculum\"). The Holy See supports the activity of its clergy by the Congregation for the Clergy (https://), a dicastery of Roman curia.\nCanon Law indicates (canon 207) that \"[b]y divine institution, there are among the Christian faithful in the Church sacred ministers who in law are also called clerics; the other members of the Christian faithful are called lay persons\". This distinction of a separate ministry was formed in the early times of Christianity; one early source reflecting this distinction, with the three ranks or orders of bishop, priest and deacon, is the writings of Saint Ignatius of Antioch.\nHoly Orders is one of the Seven Sacraments, enumerated at the Council of Trent, that the Magisterium considers to be of divine institution. In the Catholic Church, only men are permitted to be clerics.\nIn the Latin Church before 1972, tonsure admitted someone to the clerical state, after which he could receive the four minor orders (ostiary, lectorate, order of exorcists, order of acolytes) and then the major orders (subdiaconate, diaconate, presbyterate, and finally the episcopate), which according to Roman Catholic doctrine is \"the fullness of Holy Orders\". Since 1972 the minor orders and the subdiaconate have been replaced by lay ministries and clerical tonsure no longer takes place, except in some Traditionalist Catholic groups, and the clerical state is acquired, even in those groups, by Holy Orders. In the Latin Church the initial level of the three ranks of Holy Orders is that of the diaconate. In addition to these three orders of clerics, some Eastern Catholic, or \"Uniate\", Churches have what are called \"minor clerics\".\nMembers of institutes of consecrated life and societies of apostolic life are clerics only if they have received Holy Orders. Thus, unordained monks, friars, nuns, and religious brothers and sisters are not part of the clergy.\nThe Code of Canon Law and the Code of Canons of the Eastern Churches prescribe that every cleric must be enrolled or \"incardinated\" in a diocese or its equivalent (an apostolic vicariate, territorial abbey, personal prelature, etc.) or in a religious institute, society of apostolic life or secular institute. The need for this requirement arose because of the trouble caused from the earliest years of the Church by unattached or vagrant clergy subject to no ecclesiastical authority and often causing scandal wherever they went.\nCurrent canon law prescribes that to be ordained a priest, an education is required of two years of philosophy and four of theology, including study of dogmatic and moral theology, the Holy Scriptures, and canon law have to be studied within a seminary or an ecclesiastical faculty at a university.\nClerical celibacy is a requirement for almost all clergy in the predominant Latin Church, with the exception of deacons who do not intend to become priests. Exceptions are sometimes admitted for ordination to transitional diaconate and priesthood on a case-by-case basis for married clergymen of other churches or communities who become Catholics, but consecration of already married men as bishops is excluded in both the Latin and Eastern Catholic Churches (see personal ordinariate). Clerical marriage is not allowed and therefore, if those for whom in some particular Church celibacy is optional (such as permanent deacons in the Latin Church) wish to marry, they must do so before ordination. Eastern Catholic Churches while allowing married men to be ordained, do not allow clerical marriage after ordination: their parish priests are often married, but must marry before being ordained to the priesthood. Eastern Catholic Churches require celibacy only for bishops.\nEastern Orthodoxy.\nThe Eastern Orthodox Church has three ranks of holy orders: bishop, priest, and deacon. These are the same offices identified in the New Testament and found in the Early Church, as testified by the writings of the Holy Fathers. Each of these ranks is ordained through the Sacred Mystery (sacrament) of the laying on of hands (called \"cheirotonia\") by bishops. Priests and deacons are ordained by their own diocesan bishop, while bishops are consecrated through the laying on of hands of at least three other bishops.\nWithin each of these three ranks there are found a number of titles. Bishops may have the title of archbishop, metropolitan, and patriarch, all of which are considered honorifics. Among the Orthodox, all bishops are considered equal, though an individual may have a place of higher or lower honor, and each has his place within the order of precedence. Priests (also called presbyters) may (or may not) have the title of archpriest, protopresbyter (also called \"protopriest\", or \"protopope\"), hieromonk (a monk who has been ordained to the priesthood) archimandrite (a senior hieromonk) and hegumen (abbot). Deacons may have the title of hierodeacon (a monk who has been ordained to the deaconate), archdeacon or protodeacon.\nThe lower clergy are not ordained through \"cheirotonia\" (laying on of hands) but through a blessing known as \"cheirothesia\" (setting-aside). These clerical ranks are subdeacon, reader and altar server (also known as taper-bearer). Some churches have a separate service for the blessing of a cantor.\nOrdination of a bishop, priest, deacon or subdeacon must be conferred during the Divine Liturgy (Eucharist)\u2014though in some churches it is permitted to ordain up through deacon during the Liturgy of the Presanctified Gifts\u2014and no more than a single individual can be ordained to the same rank in any one service. Numerous members of the lower clergy may be ordained at the same service, and their blessing usually takes place during the Little Hours prior to Liturgy, or may take place as a separate service. The blessing of readers and taper-bearers is usually combined into a single service. Subdeacons are ordained during the Little Hours, but the ceremonies surrounding his blessing continue through the Divine Liturgy, specifically during the Great Entrance.\nBishops are usually drawn from the ranks of the archimandrites, and are required to be celibate; however, a non-monastic priest may be ordained to the episcopate if he no longer lives with his wife (following Canon XII of the Quinisext Council of Trullo) In contemporary usage such a non-monastic priest is usually tonsured to the monastic state, and then elevated to archimandrite, at some point prior to his consecration to the episcopacy. Although not a formal or canonical prerequisite, at present bishops are often required to have earned a university degree, typically but not necessarily in theology.\nUsual titles are \"Your Holiness\" for a patriarch (with \"Your All-Holiness\" reserved for the Ecumenical Patriarch of Constantinople), \"Your Beatitude\" for an archbishop/metropolitan overseeing an autocephalous Church, \"Your Eminence\" for an archbishop/metropolitan generally, \"Master\" or \"Your Grace\" for a bishop and \"Father\" for priests, deacons and monks, although there are variations between the various Orthodox Churches. For instance, in Churches associated with the Greek tradition, while the Ecumenical Patriarch is addressed as \"Your All-Holiness\", all other Patriarchs (and archbishops/metropolitans who oversee autocephalous Churches) are addressed as \"Your Beatitude\".\nOrthodox priests, deacons, and subdeacons must be either married or celibate (preferably monastic) prior to ordination, but may not marry after ordination. \"Re\"marriage of clergy following divorce or widowhood is forbidden. Married clergy are considered as best-suited to staff parishes, as a priest with a family is thought better qualified to counsel his flock. It has been common practice in the Russian tradition for unmarried, non-monastic clergy to occupy academic posts.\nMethodism.\nIn the Methodist churches, candidates for ordination are \"licensed\" to the ministry for a period of time (typically one to three years) prior to being ordained. This period typically is spent performing the duties of ministry under the guidance, supervision, and evaluation of a more senior, ordained minister. In some denominations, however, licensure is a permanent, rather than a transitional state for ministers assigned to certain specialized ministries, such as music ministry or youth ministry.\nLatter-day Saints.\nThe Church of Jesus Christ of Latter-day Saints (LDS Church) has no dedicated clergy, and is governed instead by a system of lay priesthood leaders. Locally, unpaid and part-time priesthood holders lead the church; the worldwide church is supervised by full-time general authorities, some of whom receive modest living allowances. No formal theological training is required for any position. The church believes that all of its leaders are called by revelation and the laying on of hands by one who holds authority. The church also believes that Jesus Christ stands at the head of the church and leads the church through revelation given to the President of the Church, the First Presidency, and Twelve Apostles, all of whom are recognized as prophets, seers, and revelators and have lifetime tenure. Below these men in the hierarchy are quorums of seventy, which are assigned geographically over the areas of the church. Locally, the church is divided into stakes; each stake has a president, who is assisted by two counselors and a high council. The stake is made up of several individual congregations, which are called \"wards\" or \"branches\". Wards are led by a bishop and his counselors and branches by a president and his counselors. Local leaders serve in their positions until released by their supervising authorities.\nGenerally, all worthy males age 12 and above receive the priesthood. Youth age 12 to 18 are ordained to the Aaronic priesthood as deacons, teachers, or priests, which authorizes them to perform certain ordinances and sacraments. Adult males are ordained to the Melchizedek priesthood, as elders, seventies, high priests, or patriarchs in that priesthood, which is concerned with spiritual leadership of the church. Although the term \"clergy\" is not typically used in the LDS Church, it would most appropriately apply to local bishops and stake presidents. Merely holding an office in the priesthood does not imply authority over other church members or agency to act on behalf of the entire church.\nLutheranism.\nFrom a religious standpoint there is only one order of clergy in the Lutheran church, namely the office of pastor. This is stated in the Augsburg Confession, article 14. Some Lutheran churches, like the state churches of Scandinavia, refer to this office as priest.\nHowever, for practical and historical reasons, Lutheran churches tend to have different roles of pastors or priests, and a clear hierarchy. Some pastors are functioning as deacons or provosts, others as parish priests and yet some as bishops and even archbishops. Lutherans have no principal aversion against having a pope as the leading bishop. But the Roman Catholic view of the papacy is considered antichristian.\nIn many European churches where Lutheranism was the state religion, the clergy were also civil servants, and their responsibilities extended well beyond spiritual leadership, encompassing government administration, education, and the implementation of government policies. Government administration was organized around the church's parishes. In rural parishes the parish priest tended to be the foremost government official. In more important parishes or cities a bishop or governor would outrank parish priests.\nThe Book of Concord, a compendium of doctrine for the Lutheran Churches allows ordination to be called a sacrament.\nReformed.\nThe Presbyterian Church (USA) ordains two types of presbyters or elders, teaching (pastor) and ruling (leaders of the congregation which form a council with the pastors). Teaching elders are seminary trained and ordained as a presbyter and set aside on behalf of the whole denomination to the ministry of Word and Sacrament. Ordinarily, teaching elders are installed by a presbytery as pastor of a congregation. Ruling elders, after receiving training, may be commissioned by a presbytery to serve as a pastor of a congregation, as well as preach and administer sacraments.\nIn Congregationalist churches, local churches are free to hire (and often ordain) their own clergy, although the parent denominations typically maintain lists of suitable candidates seeking appointment to local church ministries and encourage local churches to consider these individuals when filling available positions.\nHinduism.\nA Hindu priest may refer to either of the following:\nTraditionally, priests have predominantly come from the Brahmana class, whose male members are designated for the function in the Hindu texts.\nHindu priests are known to perform prayer services, often referred to as \"puja\". Priests are identified as \"pandits\" or \"pujaris\" amongst the devotees. Braja Kishore Goswami \"Yuvaaraj\" is one such famous spiritual leader of the Hindu religion.\nIslam.\nIslam, like Judaism, has no clergy in the sacerdotal sense; there is no institution resembling the Christian priesthood. Islamic religious leaders do not \"serve as intermediaries between mankind and God\", have \"process of ordination\", nor \"sacramental functions\". They have been said to resemble more rabbis, serving as \"exemplars, teachers, judges, and community leaders\", providing religious rules to the pious on \"even the most minor and private\" matters.\nThe title \"mullah\" (a Persian variation of the Arabic \"maula\", \"master\"), commonly translated \"cleric\" in the West and thought to be analogous to \"priest\" or \"rabbi\", is a title of address for any educated or respected figure, not even necessarily (though frequently) religious. The title \"sheikh\" (\"elder\") is used similarly.\nMost of the religious titles associated with Islam are scholastic or academic in nature: they recognize the holder's exemplary knowledge of the theory and practice of \"ad-d\u00edn\" (religion), and do not confer any particular spiritual or sacerdotal authority. The most general such title is \"`alim\" (pl. \"`ulamah\"), or \"scholar\". This word describes someone engaged in advanced study of the traditional Islamic sciences \"(`ulum)\" at an Islamic university or \"madrasah jami`ah\". A scholar's opinions may be valuable to others because of his/her knowledge in religious matters; but such opinions should not generally be considered binding, infallible, or absolute, as the individual Muslim is directly responsible to God for their own religious beliefs and practice.\nThere is no sacerdotal office corresponding to the Christian priest or Jewish \"kohen\", as there is no sacrificial rite of atonement comparable to the Eucharist or the Korban. Ritual slaughter or \"dhabihah\", including the \"qurban\" at \"`Idu l-Ad'ha,\" may be performed by any adult Muslim who is physically able and properly trained. Professional butchers may be employed, but they are not necessary; in the case of the \"qurban\", it is especially preferable to slaughter one's own animal if possible.\nSunni.\nThe nearest analogue among Sunni Muslims to the parish priest or pastor, or to the \"pulpit rabbi\" of a synagogue, is called the \"imam khatib.\" This compound title is merely a common combination of two elementary offices: leader \"(imam)\" of the congregational prayer, which in most mosques is performed at the times of all daily prayers; and preacher \"(khatib)\" of the sermon or \"khutba\" of the obligatory congregational prayer at midday every Friday. Although either duty can be performed by anyone who is regarded as qualified by the congregation, at most well-established mosques \"imam khatib\" is a permanent part-time or full-time position. He may be elected by the local community, or appointed by an outside authority\u2014e.g., the national government, or the waqf that sustains the mosque. There is no ordination as such; the only requirement for appointment as an \"imam khatib\" is recognition as someone of sufficient learning and virtue to perform both duties on a regular basis, and to instruct the congregation in the basics of Islam.\nThe title \"hafiz\" (lit. \"preserver\") is awarded to one who has memorized the entire Qur'an, often by attending a special course for the purpose; the \"imam khatib\" of a mosque is frequently (though not always) a \"hafiz.\"\nThere are several specialist offices pertaining to the study and administration of Islamic law or \"shari`ah.\" A scholar with a specialty in \"fiqh\" or jurisprudence is known as a \"faqih\". A \"qadi\" is a judge in an Islamic court. A \"mufti\" is a scholar who has completed an advanced course of study which qualifies him to issue judicial opinions or \"fatawah\".\nShia.\nIn modern Shia Islam, scholars play a more prominent role in the daily lives of Muslims than in Sunni Islam; and there is a hierarchy of higher titles of scholastic authority, such as \"Ayatollah\". Traditionally a more complex title has been used in Twelver Shi`ism, namely \"marja\u02bf at-taqlid\". \"Marja\u02bf\" (pl. \"maraji\u02bf\"\u200a) means \"source\", and \"taqlid\" refers to religious emulation or imitation. Lay Shi`ah must identify a specific \"marja\u02bf\" whom they emulate, according to his legal opinions \"(fatawah)\" or other writings. On several occasions, the \"Marja\u02bfiyyat\" (community of all \"maraji\u02bf\u200a\") has been limited to a single individual, in which case his rulings have been applicable to all those living in the Twelver Shi'ah world. Of broader importance has been the role of the \"mujtahid\", a cleric of superior knowledge who has the authority to perform \"ijtihad\" (independent judgment). Mujtahids are few in number, but it is from their ranks that the \"maraji\u02bf at-taqlid\" are drawn. However these titles are more related to scholarly rank and piety than a hierarchy like that of a priesthood.\nSufism.\nThe spiritual guidance function known in many Christian denominations as \"pastoral care\" is fulfilled for many Muslims by a \"murshid\" (\"guide\"), a master of the spiritual sciences and disciplines known as \"tasawuf\" or Sufism. Sufi guides are commonly styled \"Shaikh\" in both speaking and writing; in North Africa they are sometimes called \"marabouts\". They are traditionally appointed by their predecessors, in an unbroken teaching lineage reaching back to Muhammad. (The lineal succession of guides bears a superficial similarity to Christian ordination and apostolic succession, or to Buddhist dharma transmission; but a Sufi guide is regarded primarily as a specialized teacher and Islam denies the existence of an earthly hierarchy among believers.)\nMuslims who wish to learn Sufism dedicate themselves to a \"murshid\"'s guidance by taking an oath called a \"bai'ah\". The aspirant is then known as a \"murid\" (\"disciple\" or \"follower\"). A \"murid\" who takes on special disciplines under the guide's instruction, ranging from an intensive spiritual retreat to voluntary poverty and homelessness, is sometimes known as a dervish.\nDuring the Islamic Golden Age, it was common for scholars to attain recognized mastery of both the \"exterior sciences\" \"(`ulum az-zahir)\" of the madrasahs as well as the \"interior sciences\" \"(`ulum al-batin)\" of Sufism. Al-Ghazali and Rumi are two notable examples.\nAhmadiyya.\nThe highest office an Ahmadi can hold is that of \"Khalifatu l-Masih\". Such a person may appoint amirs who manage regional areas. The consultative body for Ahmadiyya is called the \"Majlis-i-Shura\", which ranks second in importance to the \"Khalifatu l-Masih\". However, the Ahmadiyya community is declared as non-Muslims by many mainstream Muslims and they reject the messianic claims of Mirza Ghulam Ahmad.\nJudaism.\nRabbinic Judaism does not have clergy as such, although according to the Torah there is a tribe of priests known as the Kohanim who were leaders of the religion up to the destruction of the Temple of Jerusalem in 70 AD when most Sadducees were wiped out; each member of the tribe, a Kohen had priestly duties, many of which centered around the sacrificial duties, atonement and blessings of the Israelite nation. Today, Jewish Kohanim know their status by family tradition, and still offer the priestly blessing during certain services in the synagogue and perform the \"Pidyon haben\" (redemption of the first-born son) ceremony.\nSince the time of the destruction of the Temple of Jerusalem, the religious leaders of Judaism have often been rabbis, who are technically scholars in Jewish law empowered to act as judges in a rabbinical court. All types of Judaism except Orthodox Judaism allow women as well as men to be ordained as rabbis and cantors. The leadership of a Jewish congregation is, in fact, in the hands of the laity: the president of a synagogue is its actual leader and any adult male Jew (or adult Jew in non-traditional congregations) can lead prayer services. The rabbi is not an occupation found in the Torah; the first time this word is mentioned is in the Mishnah. The modern form of the rabbi developed in the Talmudic era. Rabbis are given authority to make interpretations of Jewish law and custom. Traditionally, a man obtains one of three levels of Semicha (rabbinic ordination) after the completion of an arduous learning program in Torah, Tanakh (Hebrew Bible), Mishnah and Talmud, Midrash, Jewish ethics and lore, the codes of Jewish law and responsa, theology and philosophy.\nSince the early medieval era an additional communal role, the \"Hazzan\" (cantor) has existed as well. Cantors have sometimes been the only functionaries of a synagogue, empowered to undertake religio-civil functions like witnessing marriages. Cantors do provide leadership of actual services, primarily because of their training and expertise in the music and prayer rituals pertaining to them, rather than because of any spiritual or \"sacramental\" distinction between them and the laity. Cantors as much as rabbis have been recognized by civil authorities in the United States as clergy for legal purposes, mostly for awarding education degrees and their ability to perform weddings, and certify births and deaths.\nAdditionally, Jewish authorities license \"mohalim\", people specially trained by experts in Jewish law and usually also by medical professionals to perform the ritual of circumcision. Traditional Orthodox Judaism does not generally license women as mohelot, unless a Jewish male expert is absent, but other movements of Judaism do. They are appropriately called \"mohelot\" (pl. of \"mohelet,\" f. of mohel). As the \"j., the Jewish News Weekly of Northern California\", states, \"...there is no halachic prescription against female mohels, [but] none exist in the Orthodox world, where the preference is that the task be undertaken by a Jewish man\". In many places, mohalim are also licensed by civil authorities, as circumcision is technically a surgical procedure. Kohanim, who must avoid contact with dead human body parts (such as the removed foreskin) for ritual purity, cannot act as mohalim, but some mohalim are also either rabbis or cantors.\nAnother licensed cleric in Judaism is the \"shochet\", who are trained and licensed by religious authorities for kosher slaughter according to ritual law. A Kohen may be a shochet. Most shochetim are ordained rabbis.\nThen there is the \"mashgiach/mashgicha\". \"Mashgichim\" are observant Jews who supervise the \"kashrut\" status of a kosher establishment. The \"mashgichim\" must know the Torah laws of \"kashrut\", and how they apply in the environment they are supervising. This can vary. In many instances, the \"mashgiach\"/\"mashgicha\" is a rabbi. This helps, since rabbinical students learn the laws of kosher as part of their syllabus. However, not all \"mashgichim\" are rabbis, and not all rabbis are qualified to be \"mashgichim\".\nOrthodox Judaism.\nIn contemporary Orthodox Judaism, women are usually forbidden from becoming rabbis or cantors. Most Orthodox rabbinical seminaries or yeshivas also require dedication of many years to education, but few require a formal degree from a civil education institution that often define Christian clergy. Training is often focused on Jewish law, and some Orthodox Yeshivas forbid secular education.\nIn Hasidic Judaism, generally understood as a branch of Orthodox Judaism, there are dynastic spiritual leaders known as \"Rebbes\", often translated in English as \"Grand Rabbi\". The office of Rebbe is generally a hereditary one, but may also be passed from Rebbe to student or by recognition of a congregation conferring a sort of coronation to their new Rebbe. Although one does not need to be an ordained Rabbi to be a Rebbe, most Rebbes today are ordained Rabbis. Since one does not need to be an ordained rabbi to be a Rebbe, at some points in history there were female Rebbes as well, particularly the Maiden of Ludmir.\nConservative Judaism.\nIn Conservative Judaism, both men and women are ordained as rabbis and cantors. Conservative Judaism differs with Orthodoxy in that it sees Jewish Law as binding but also as subject to many interpretations, including more liberal interpretations. Academic requirements for becoming a rabbi are rigorous. First earn a bachelor's degree before entering rabbinical school. Studies are mandated in pastoral care and psychology, the historical development of Judaism and most importantly the academic study of Bible, Talmud and rabbinic literature, philosophy and theology, liturgy, Jewish history, and Hebrew literature of all periods.\nReconstructionist and Reform Judaism.\nReconstructionist Judaism and Reform Judaism do not maintain the traditional requirements for study as rooted in Jewish Law and traditionalist text. Both men and women may be rabbis or cantors. The rabbinical seminaries of these movements hold that one must first earn a bachelor's degree before entering the rabbinate. In addition studies are mandated in pastoral care and psychology, the historical development of Judaism; and academic biblical criticism. Emphasis is placed not on Jewish law, but rather on sociology, modern Jewish philosophy, theology and pastoral care.\nSikhism.\nSikh clergy consists of five \"Jathedars\", one each from five \"takhts\" or sacred seats. The \"Jathedars\" are appointed by the Shiromani Gurdwara Parbandhak Committee (SGPC), an elected body of the Sikhs sometimes called the \"Parliament of Sikhs\". The highest seat of the Sikh religion is called \"Akal Takht\" and the \"Jathedar\" of \"Akal Takht\" makes all the important decisions after consultations with the \"Jathedars\" of the other four \"takhts\" and the SGPC.\nZoroastrianism.\nMobad and Magi are the clergy of Zoroastrianism. Kartir was one of the powerful and influential of them.\nTraditional religions.\nHistorically traditional (or \"pagan\") religions typically combine religious authority and political power. What this means is that the sacred king or queen is therefore seen to combine both kingship and priesthood within their person, even though he or she is often aided by an actual high priest or priestess (see, for example, the Maya priesthood). When the functions of political ruler and religious leader are combined in this way, deification could be seen to be the next logical stage of their social advancement within their native environment, as is found in the case of the Egyptian Pharaohs. The Vedic priesthood of India is an early instance of a structured body of clergy organized as a separate and hereditary caste, one that occupied the highest social rung of its nation. A modern example of this phenomenon the priestly monarchs of the Yoruba holy city of Ile-Ife in Nigeria, whose reigning Onis have performed ritual ceremonies for centuries for the sustenance of the entire planet and its people.\nHealth risks for ministry in the United States.\nIn recent years, studies have suggested that American clergy in certain Protestant, Evangelical and Jewish traditions are more at risk than the general population of obesity, hypertension and depression. Their life expectancies have fallen as of 2010, and their use of antidepressants has risen. Several religious bodies in the United States (Methodist, Episcopal, Baptist and Lutheran) have implemented measures to address the issue, through wellness campaigns, for example\u2014but also by simply ensuring that clergy take more time off.\nIt is unclear whether similar symptoms affect American Muslim clerics, although an anecdotal comment by one American imam suggested that leaders of mosques may also share these problems.\nOne exception to the findings of these studies is the case of American Catholic priests, who are required by canon law to take a spiritual retreat each year, and four weeks of vacation. Sociological studies at the University of Chicago have confirmed this exception; the studies also took the results of several earlier studies into consideration and included Roman Catholic priests nationwide. It remains unclear whether American clergy in other religious traditions experience the same symptoms, or whether clergy outside the United States are similarly affected.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50406", "revid": "50912741", "url": "https://en.wikipedia.org/wiki?curid=50406", "title": "Post-Keynesian economics", "text": "School of economic thought\nPost-Keynesian economics is a school of economic thought with its origins in \"The General Theory\" of John Maynard Keynes, with subsequent development influenced to a large degree by Micha\u0142 Kalecki, Joan Robinson, Nicholas Kaldor, Sidney Weintraub, Paul Davidson, Piero Sraffa, Jan Kregel and Marc Lavoie. Historian Robert Skidelsky argues that the post-Keynesian school has remained closest to the spirit of Keynes' original work. It is a heterodox approach to economics based on a non-equilibrium approach.\nIntroduction.\nThe term \"post-Keynesian\" was first used to refer to a distinct school of economic thought by Eichner and Kregel (1975) and by the establishment of the \"Journal of Post Keynesian Economics\" in 1978. Prior to 1975, and occasionally in more recent work, \"post-Keynesian\" could simply mean economics carried out after 1936, the date of Keynes's \"General Theory\".\nPost-Keynesian economists are united in maintaining that Keynes' theory is seriously misrepresented by the two other principal Keynesian schools: neo-Keynesian economics, which was orthodox in the 1950s and 60s, and new Keynesian economics, which together with various strands of neoclassical economics has been dominant in mainstream macroeconomics since the 1980s. Post-Keynesian economics can be seen as an attempt to rebuild economic theory in the light of Keynes' ideas and insights. However, even in the early years, post-Keynesians such as Joan Robinson sought to distance themselves from Keynes, and much current post-Keynesian thought cannot be found in Keynes. Some post-Keynesians took a more progressive view than Keynes himself, with greater emphases on worker-friendly policies and redistribution. Robinson, Paul Davidson and Hyman Minsky emphasized the effects on the economy of practical differences between different types of investments, in contrast to Keynes' more abstract treatment.\nThe theoretical foundation of post-Keynesian economics is the principle of effective demand that demand matters in the long as well as the short run, so that a competitive market economy has no natural or automatic tendency towards full employment. Contrary to the views of new Keynesian economists working in the neoclassical tradition, post-Keynesians do not accept that the theoretical basis of the market's failure to provide full employment is rigid or sticky prices or wages. Post-Keynesians typically reject the IS\u2013LM model of John Hicks, which is very influential in neo-Keynesian economics, because they argue endogenous bank lending to be more significant than central banks' money supply for the interest rate.\nThe contribution of post-Keynesian economics has extended beyond the theory of aggregate employment to theories of income distribution, growth, trade and development in which money demand plays a key role, whereas in neoclassical economics these are determined by the forces of technology, preferences and endowment. In the field of monetary theory, post-Keynesian economists were among the first to emphasise that money supply responds to the demand for bank credit, so that a central bank cannot control the quantity of money, but only manage the interest rate by managing the quantity of monetary reserves.\nThis view has largely been incorporated into mainstream economics and monetary policy, which now targets the interest rate as an instrument, rather than attempting to accurately control the quantity of money. In the field of finance, Hyman Minsky put forward a theory of financial crisis based on financial fragility, which has received renewed attention.\nMain features.\nIn 2009 Marc Lavoie listed the main features of post-Keynesian economics:\nHe also lists 5 auxiliary features:\nStrands.\nThere are a number of strands to post-Keynesian theory with different emphases. Joan Robinson regarded Micha\u0142 Kalecki's theory of effective demand to be superior to Keynes' theories. Kalecki's theory is based on a class division between workers and capitalists and imperfect competition. Robinson also led the critique of the use of aggregate production functions based on homogeneous capital \u2013 the Cambridge capital controversy \u2013 winning the argument but not the battle. The writings of Piero Sraffa were a significant influence on the post-Keynesian position in this debate, though Sraffa and his neo-Ricardian followers drew more inspiration from David Ricardo than Keynes. Much of Nicholas Kaldor's work was based on the ideas of increasing returns to scale, path dependence, and the key differences between the primary and industrial sectors.\nPaul Davidson follows Keynes closely in placing time and uncertainty at the centre of theory, from which flow the nature of money and of a monetary economy. Monetary circuit theory, originally developed in continental Europe, places particular emphasis on the distinctive role of money as means of payment. Each of these strands continues to see further development by later generations of economists. An important method is stock-flow consistent models, which enable a consistent description of receivables and liabilities as well as cash flows.\nModern Monetary Theory is a relatively recent offshoot independently pioneered by Warren Mosler that models the currency itself as a public monopoly as the micro foundation of macro economics, thereby augmenting the theory of effective demand, recognizing that coercive taxation drives the currency (the tax credit) and that the price level is necessarily a function of prices paid by the state. Subsequent MMT associated academics have used macroeconomic modelling of Wynne Godley and incorporated some of Hyman Minsky's ideas on the labour market, as well as chartalism and functional finance.\nRecent work in post-Keynesian economics has attempted to provide micro-foundations for capacity underutilization as a coordination failure, justifying government intervention in the form of aggregate demand stimulus.\nCurrent work.\nJournals.\nMuch post-Keynesian research is published in the \"Review of Keynesian Economics\" (ROKE), the \"Journal of Post Keynesian Economics\" (founded by Sidney Weintraub and Paul Davidson), the \"Cambridge Journal of Economics\", the \"Review of Political Economy\", and the \"Journal of Economic Issues\" (JEI).\nUnited Kingdom.\nThere is also a United Kingdom academic association, the http:// (PKES). It was founded by Philip Arestis and Victoria Chick in 1988 as the Post-Keynesian Economics Study Group (PKSG) and changed its name in 2018. In the UK, post-Keynesian economists can be found in:\nWorking on post-Keynesian economic foundations, the UK-based global economics consultancy, Cambridge Econometrics, developed a computer-based \"Energy-Environment-Economy Model for Europe\" (E3ME) economic model. It is used by European Commission to analyse medium and long-term effects of its environmental and economic policies.\nUnited States.\nIn the United States, there are several universities with a post-Keynesian bent:\nCanada.\nIn Canada, post-Keynesians can be found at the University of Ottawa and Laurentian University.\nGermany.\nIn Germany, post-Keynesianism is very strong at the Berlin School of Economics and Law and its master's degree courses: International Economics [M.A.] and Political Economy of European Integration [M.A.]. Many German Post-Keynesians are organized in the Forum Macroeconomics and Macroeconomic Policies.\nAustralia.\nUniversity of Newcastle.\nThe University of Newcastle in New South Wales, Australia, houses the post-Keynesian think-tank the Centre of Full Employment and Equity (CFFE). New Life - Blind Melon.\nMajor post-Keynesian economists.\nMajor post-Keynesian economists of the first and second generations after Keynes include:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50408", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=50408", "title": "Computer engineering", "text": "Engineering discipline specializing in the design of computer hardware\nComputer engineering (CE, CoE, CpE, or CompE) is a branch of engineering specialized in developing computer hardware and software. \nIt integrates several fields of electrical engineering, electronics engineering and computer science. Computer engineering may be referred to as \"Electrical and Computer Engineering\" or \"Computer Science and Engineering\" at some universities.\nComputer engineers require training in hardware-software integration, software design, and software engineering. It can encompass areas such as electromagnetism, artificial intelligence (AI), robotics, computer networks, computer architecture and operating systems. Computer engineers are involved in many hardware and software aspects of computing, from the design of individual microcontrollers, microprocessors, personal computers, and supercomputers, to circuit design. This field of engineering not only focuses on how computer systems themselves work, but also on how to integrate them into the larger picture. Robotics are one of the applications of computer engineering.\nComputer engineering usually deals with areas including writing software and firmware for embedded microcontrollers, designing VLSI chips, analog sensors, mixed signal circuit boards, thermodynamics and control systems. Computer engineers are also suited for robotics research, which relies heavily on using digital systems to control and monitor electrical systems like motors, communications, and sensors.\nIn many institutions of higher learning, computer engineering students are allowed to choose areas of in-depth study in their junior and senior years because the full breadth of knowledge used in the design and application of computers is beyond the scope of an undergraduate degree. Other institutions may require engineering students to complete one or two years of general engineering before declaring computer engineering as their primary focus.\nHistory.\nComputer engineering began in 1939 when John Vincent Atanasoff and Clifford Berry began developing the world's first electronic digital computer through physics, mathematics, and electrical engineering. John Vincent Atanasoff was once a physics and mathematics teacher for Iowa State University and Clifford Berry a former graduate under electrical engineering and physics. Together, they created the Atanasoff\u2013Berry computer, also known as the ABC which took five years to complete.\nWhile the original ABC was dismantled and discarded in the 1940s, a tribute was made to the late inventors; a replica of the ABC was made in 1997, where it took a team of researchers and engineers four years and $350,000 to build.\nThe modern personal computer emerged in the 1970s, after several breakthroughs in semiconductor technology. These include the first working transistor by William Shockley, John Bardeen and Walter Brattain at Bell Labs in 1947, in 1955, silicon dioxide surface passivation by Carl Frosch and Lincoln Derick, the first planar silicon dioxide transistors by Frosch and Derick in 1957, planar process by Jean Hoerni, the monolithic integrated circuit chip by Robert Noyce at Fairchild Semiconductor in 1959, the metal\u2013oxide\u2013semiconductor field-effect transistor (MOSFET, or MOS transistor) demonstrated by a team at Bell Labs in 1960 and the single-chip microprocessor (Intel 4004) by Federico Faggin, Marcian Hoff, Masatoshi Shima and Stanley Mazor at Intel in 1971.\nHistory of computer engineering education.\nThe first computer engineering degree program in the United States was established in 1971 at Case Western Reserve University in Cleveland, Ohio. As of 2015[ [update]], there were 250 ABET-accredited computer engineering programs in the U.S. In Europe, accreditation of computer engineering schools is done by a variety of agencies as part of the EQANIE network. Due to increasing job requirements for engineers who can concurrently design hardware, software, firmware, and manage all forms of computer systems used in industry, some tertiary institutions around the world offer a bachelor's degree generally called computer engineering. Both computer engineering and electronic engineering programs include analog and digital circuit design in their curriculum. As with most engineering disciplines, having a sound knowledge of mathematics and science is necessary for computer engineers.\nEducation.\nComputer engineering is referred to as computer science and engineering at some universities. Most entry-level computer engineering jobs require at least a bachelor's degree in computer engineering, electrical engineering or computer science. Typically one must learn an array of mathematics such as calculus, linear algebra and differential equations, along with computer science. Degrees in electronic or electric engineering also suffice due to the similarity of the two fields. Because hardware engineers commonly work with computer software systems, a strong background in computer programming is necessary. According to BLS, \"a computer engineering major is similar to electrical engineering but with some computer science courses added to the curriculum\". Some large firms or specialized jobs require a master's degree.\nIt is also important for computer engineers to keep up with rapid advances in technology. Therefore, many continue learning throughout their careers. This can be helpful, especially when it comes to learning new skills or improving existing ones. For example, as the relative cost of fixing a bug increases the further along it is in the software development cycle, there can be greater cost savings attributed to developing and testing for quality code as soon as possible in the process, particularly before release.\nApplications and practice.\nThere are two major focuses in computer engineering: hardware and software.\nComputer hardware engineering.\nAccording to the United States BLS, the current job outlook employment for computer hardware engineers, the expected ten-year growth from 2024 to 2034 is 7%. However, 2019 to 2029 for computer hardware engineering was an estimated 2% and a total of 71,100 jobs. (\"Slower than average\" in their own words when compared to other occupations)\". This is a decrease from the 2014 to 2024 BLS computer hardware engineering estimate of 3% and a total of 77,700 jobs; \"and is down from 7% for the 2012 to 2022 BLS estimate and is further down from 9% in the BLS 2010 to 2020 estimate.\" Today, computer hardware is somewhat equal to electronic and computer engineering (ECE) and has been divided into many subcategories, the most significant being embedded system design.\nComputer software engineering.\nAccording to the U.S. Bureau of Labor Statistics (BLS), \"computer applications software engineers and computer systems software engineers are projected to be among the faster than average growing occupations\". The expected ten-year growth as of 2014[ [update]] for computer software engineering was an estimated 17% and there was a total of 1,114,000 jobs that same year. This is down from the 2012 to 2022 BLS estimate of 22% for software developers. And, further down from the 30% 2010 to 2020 BLS estimate. In addition, growing concerns over cybersecurity add up to put computer software engineering high above the average rate of increase for all fields. However, some of the work will be outsourced in foreign countries. Due to this, job growth will not be as fast as during the last decade, as jobs that would have gone to computer software engineers in the United States would instead go to computer software engineers in countries such as India. In addition, the BLS job outlook for Computer Programmers, 2014\u201324 has an \u22128% (a decline, in their words), then a job outlook, 2019-29 of -9% (Decline), then a 10% decline for 2021-2031 and now an 11% decline for 2022-2032 for those who program computers (i.e. embedded systems) who are not computer application developers. Furthermore, women in software fields has been declining over the years even faster than other engineering fields.\nSpecialty areas.\nThere are many specialty areas in the field of computer engineering.\nProcessor design.\nProcessor design process involves choosing an instruction set and a certain execution paradigm (e.g. VLIW or RISC) and results in a microarchitecture, which might be described in e.g. VHDL or Verilog. CPU design is divided into design of the following components: datapaths (such as ALUs and pipelines), control unit: logic which controls the datapaths, memory components such as register files, caches, clock circuitry such as clock drivers, PLLs, clock distribution networks, pad transceiver circuitry, logic gate cell library which is used to implement the logic.\nCoding, cryptography, and information protection.\nComputer engineers work in coding, applied cryptography, and information protection to develop new methods for protecting various information, such as digital images and music, fragmentation, copyright infringement and other forms of tampering by, for example, digital watermarking.\nCommunications and wireless networks.\nThose focusing on communications and wireless networks, work advancements in telecommunications systems and networks (especially wireless networks), modulation and error-control coding, and information theory. High-speed network design, interference suppression and modulation, design, and analysis of fault-tolerant system, and storage and transmission schemes are all a part of this specialty.\nCompilers and operating systems.\nThis specialty focuses on compilers and operating systems design and development. Engineers in this field develop new operating system architecture, program analysis techniques, and new techniques to assure quality. Examples of work in this field include post-link-time code transformation algorithm development and new operating system development.\nComputational science and engineering.\nComputational science and engineering is a relatively new discipline. According to the Sloan Career Cornerstone Center, individuals working in this area, \"computational methods are applied to formulate and solve complex mathematical problems in engineering and the physical and the social sciences. Examples include aircraft design, the plasma processing of nanometer features on semiconductor wafers, VLSI circuit design, radar detection systems, ion transport through biological channels, and much more\".\nComputer networks, mobile computing, and distributed systems.\nIn this specialty, engineers build integrated environments for computing, communications, and information access. Examples include shared-channel wireless networks, adaptive resource management in various systems, and improving the quality of service in mobile and ATM environments. Some other examples include work on wireless network systems and fast Ethernet cluster wired systems.\nComputer systems: architecture, parallel processing, and dependability.\nEngineers working in computer systems work on research projects that allow for reliable, secure, and high-performance computer systems. Projects such as designing processors for multithreading and parallel processing are included in this field. Other examples of work in this field include the development of new theories, algorithms, and other tools that add performance to computer systems.\nComputer architecture includes CPU design, cache hierarchy layout, memory organization, and load balancing.\nComputer vision and robotics.\nIn this specialty, computer engineers focus on developing visual sensing technology to sense an environment, representation of an environment, and manipulation of the environment. The gathered three-dimensional information is then implemented to perform a variety of tasks. These include improved human modeling, image communication, and human-computer interfaces, as well as devices such as special-purpose cameras with versatile vision sensors.\nEmbedded systems.\nIndividuals working in this area design technology for enhancing the speed, reliability, and performance of systems. Embedded systems are found in many devices from a small FM radio to the space shuttle. According to the Sloan Cornerstone Career Center, ongoing developments in embedded systems include \"automated vehicles and equipment to conduct search and rescue, automated transportation systems, and human-robot coordination to repair equipment in space.\" As of 2018[ [update]], computer embedded systems specializations include system-on-chip design, the architecture of edge computing and the Internet of things.\nIntegrated circuits, VLSI design, testing and CAD.\nThis specialty of computer engineering requires adequate knowledge of electronics and electrical systems. Engineers working in this area work on enhancing the speed, reliability, and energy efficiency of next-generation very-large-scale integrated (VLSI) circuits and microsystems. An example of this specialty is work done on reducing the power consumption of VLSI algorithms and architecture.\nSignal, image and speech processing.\nComputer engineers in this area develop improvements in human\u2013computer interaction, including speech recognition and synthesis, medical and scientific imaging, or communications systems. Other work in this area includes computer vision development such as recognition of human facial features.\nQuantum computing.\nThis area integrates the quantum behaviour of small particles such as superposition, interference and entanglement, with classical computers to solve complex problems and formulate algorithms much more efficiently. Individuals focus on fields like Quantum cryptography, physical simulations and quantum algorithms.\nNotes and references.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50409", "revid": "49976099", "url": "https://en.wikipedia.org/wiki?curid=50409", "title": "Cistercians", "text": "Catholic religious order\nThe Cistercians (), officially the Order of Cistercians (, abbreviated as OCist or SOCist), are a Catholic religious order of monks and nuns that branched off from the Benedictines and follow the Rule of Saint Benedict, as well as the contributions of the highly influential Bernard of Clairvaux, known as the Latin Rule. They are also known as Bernardines, after Saint Bernard, or as White Monks, in reference to the colour of their cowl, as opposed to the black cowl worn by Benedictines.\nThe term \"Cistercian\" derives from \"Cistercium,\" the Latin name for the locale of C\u00eeteaux, near Dijon in eastern France. It was here that a group of Benedictine monks from the monastery of Molesme founded C\u00eeteaux Abbey in 1098. The first three abbots were Robert of Molesme, Alberic of C\u00eeteaux and Stephen Harding. Bernard helped launch a new era when he entered the monastery in the early 1110s with 30 companions. By the end of the 12th century, the order had spread throughout most of Europe.\nThe keynote of Cistercian life was a return to literal observance of the Benedictine Rule. The reform-minded monks tried to live monastic life as they thought it had been in Benedict's time; at various points they went beyond it in austerity. They returned to manual labour, especially agricultural work in the fields. The Cistercians made major contributions to culture and technology: Cistercian architecture has been recognized as a notable form of medieval architecture, and the Cistercians were the main force of technological diffusion in fields such as agriculture and hydraulic engineering.\nOver the centuries, education and scholarship came to dominate the life of many monasteries. A reform movement seeking a simpler lifestyle began in 17th-century France at La Trappe Abbey, and became known as the Trappists. They were eventually consolidated in 1892 into a new order called the Order of Cistercians of the Strict Observance, abbreviated as OCSO. The Cistercians who remained within the Order of Cistercians are called the Cistercians of the Common Observance (OCist).\nApart from Catholicism, Cistercian spirituality is present in certain monastic houses of Evangelical Lutheranism and Anglicanism.\nCistercian practices.\nThe abbot general is the leader of the \"administrative machinery\" of a Cistercian order.\nThe burial practices for Cistercian monks involve complex rituals, and monks may be buried with or without shrouds.\nNo vow of silence.\nCistercian monks and nuns have a reputation of cultivating solitude and silence; the great monastics have explained silence as \"the language of liberation, enlightenment, or union with God.\" Some observers deduced, incorrectly, that Cistercians take a vow of silence. Watching over one's tongue is a general theme in the Rule of St. Benedict which, however, never required a vow of silence.\nOrigins and early expansion.\nFoundation.\nIn 1098, a Benedictine abbot, Robert of Molesme, left Molesme Abbey in Burgundy with around 20 supporters, who felt that the Cluniac communities had abandoned the rigours and simplicity of the Rule of St. Benedict. Chief among Robert's followers included Alberic, a former hermit from the nearby forest of Colan, and Stephen Harding, a young monk from England. Stephen had experienced the monastic traditions of the Camaldolese and Vallombrosians before joining Molesme Abbey.\nOn 21 March 1098, Robert's small group acquired a plot of marshland just south of Dijon called C\u00eeteaux (\"Latin:\" \"Cistercium\". \"Cisteaux\" means reeds in Old French), given to them expressly for the purpose of founding their \"Novum Monasterium\". During the first year, the monks set about constructing lodging areas and farming the lands of C\u00eeteaux, making use of a nearby chapel for Mass. In Robert's absence from Molesme, however, the abbey had gone into decline, and Pope Urban II, a former Cluniac monk, ordered him to return.\nThe remaining monks of C\u00eeteaux elected Alberic as their abbot, under whose leadership the abbey would find its grounding. Robert had been the idealist of the order, and Alberic was their builder. Upon assuming the role of abbot, Alberic moved the site of the fledgling community near a brook a short distance away from the original site. Alberic discontinued the use of Benedictine black garments in the abbey and clothed the monks in white habits of undyed wool. Alberic forged an alliance with the Dukes of Burgundy, working out a deal with Duke Odo I of Burgundy concerning the donation of a vineyard (Meursault) as well as materials for building the abbey church, which was consecrated on 16 November 1106 by the Bishop of Chalon sur Sa\u00f4ne.\nOn 26 January 1108, Alberic died and was succeeded by Stephen Harding, the man responsible for carrying the order into its crucial phase.\nCistercian reform.\nHarding framed the original version of the Cistercian constitution, soon to be called the \"Carta Caritatis\" (\"Charter of Charity\"). Although it was revised on several occasions to meet contemporary needs, from the outset it emphasised a simple life of work, love, prayer and self-denial. The Cistercians soon came to distinguish themselves from Benedictines by wearing white or grey tunics instead of black; white habits are common for reform movements. Much of Cistercian reform took place against the rivalry with the famous Benedictine abbey of Cluny, where wealth and excess were said to have set in.\nHarding acquired land for the abbey to develop to ensure its survival and ethic. As to grants of land, the order would normally accept only undeveloped land, which the monks then developed by their own labour. For this they developed over time a very large component of uneducated lay brothers known as \"conversi\". In some cases, the order accepted developed land and relocated the serfs elsewhere.\nCharter of Charity.\nThe outlines of the Cistercian reform were adumbrated by Alberic, but it received its final form in the \"Carta caritatis\" (\"Charter of Charity\"), which was the defining guide on how the reform was to be lived. This document governed the relations between the various houses of the Cistercian order, and exercised a great influence also upon the future course of western monachism. From one point of view, it may be regarded as a compromise between the primitive Benedictine system, in which each abbey was autonomous and isolated, and the centralization of Cluny.\nThe Cistercians maintained the independence of individual houses: each abbey had its own abbot, elected by its own monks, and its own property and finances administered without outside interference. On the other hand, all the abbeys were subjected to the General Chapter, the constitutional body which exercised vigilance over the order. Made up of all the abbots, the General Chapter met annually in mid-September at C\u00eeteaux. Attendance was compulsory, with the abbot of C\u00eeteaux presiding. He was to enforce conformity to C\u00eeteaux in all details of monastic observance, liturgy, and customs. C\u00eeteaux was always to be the model to which all the other houses had to conform.\nCistercian nuns.\nThe first community of Cistercian nuns, Tart, was founded 1125 in the Diocese of Langres. Their number rose so quickly in the course of the next century that the historian and cardinal Jacques de Vitry wrote: \"Cistercian nunneries multiplied like stars in the sky.\" At their most populous point, there may have been over 900 women's monasteries, but not all were officially integrated into the order. One of the best known of Cistercian women's communities was the Abbey of Port-Royal, associated with the Jansenist controversy. In Spain and France, a number of Cistercian abbesses had extraordinary privileges.\nInternational expansion.\nIn the 1130s and 1140s, the Cistercians expanded into \"an order of immense size\" by incorporating independent religious communities.\nFrance.\nIn 1113, Bernard joined the C\u00eeteaux monastery along with 35 relatives and friends. Bernard's charisma greatly expanded the size of the order. In 1115, Count Hugh of Champagne gifted the order a tract of forested land located forty miles east of Troyes. At the age of 25, Bernard founded the Abbey of Clairvaux with twelve other monks. At this time, C\u00eeteaux had four daughter houses: Pontigny, Morimond, La Fert\u00e9 and Clairvaux.\nThe most foundations made by any Cistercian monastery came from Clairvaux.\nAustria.\nRein Abbey was founded in 1129 from Ebrach Abbey in Bavaria, which had been founded from Morimond Abbey in France. In 1129 Margrave Leopold the Strong of Styria granted the Bavarian monks an area of land just north of what is today the provincial capital Graz, where they founded Rein Abbey. At the time, it was the 38th Cistercian monastery founded; as of 2024, it is the oldest surviving Cistercian house in the world. In 1133, Heiligenkreuz Abbey was founded near Vienna by Morimond monks; it is (as of 2024) the largest men's abbey in Europe.\nBritain.\nThe order entrusted the oversight of the English, Welsh and (intermittently) Irish abbeys to two or more abbots-commissary, thereby abrogating the famous Cistercian system of filiation: not the mother abbeys, but the abbots-commisary had full powers of visitation. This variation on the original vertical descent of authority produced \"a system of centralized national control\" much closer to that of the Premonstratensians or mendicants. The first Cistercian house to be established in Britain, a monastery at Waverley Abbey, Surrey, was founded by William Gifford, Bishop of Winchester in 1128. It was founded with 12 monks and an abbot from L'Aum\u00f4ne Abbey, in the South of France. By 1187 there were 70 monks and 120 lay brothers in residence.\nThirteen Cistercian monasteries, all in remote locations, were founded in Wales between 1131 and 1226. The first of these was Tintern Abbey, which was sited in a remote river valley, and depended largely on its agricultural and pastoral activities for survival. Other abbeys, such as at Neath, Strata Florida, Conwy and Valle Crucis became among the most hallowed names in the history of religion in medieval Wales. Their austere discipline seemed to echo the ideals of the Celtic saints, and the emphasis on pastoral farming fit well into the Welsh stock-rearing economy.\nIn Yorkshire, Rievaulx Abbey was founded from Clairvaux in 1131, on a small, isolated property donated by Walter Espec, with the support of Thurstan, Archbishop of York. By 1143, three hundred monks had entered Rievaulx, including the famous St \u00c6lred. It was from Rievaulx that a foundation was made at Melrose, which became the earliest Cistercian monastery in Scotland. Located in Roxburghshire, it was built in 1136 by King David I of Scotland, and completed in less than ten years. Another important offshoot of Rievaulx was Revesby Abbey in Lincolnshire.\nFountains Abbey was founded in 1132 by discontented Benedictine monks from St. Mary's Abbey, York, who desired a return to the austere Rule of St Benedict. After many struggles and great hardships, St Bernard agreed to send a monk from Clairvaux to instruct them, and in the end they prospered. Already by 1152, Fountains had many offshoots, including Newminster Abbey (1137) and Meaux Abbey (1151).\nIreland.\nIn the spring of 1140, Saint Malachy, the archbishop of Armagh, visited Clairvaux, becoming a personal friend of Abbot Bernard and an admirer of Cistercian life. He left four of his companions to be trained as Cistercians, and returned to Ireland to introduce Cistercian monasticism there. Mellifont Abbey was founded in County Louth in 1142 and from it daughter houses of Bective Abbey in County Meath (1147), Inislounaght Abbey in County Tipperary (1147\u20131148), Baltinglass in County Wicklow (1148), Monasteranenagh in County Limerick (1148), Kilbeggan in County Westmeath (1150) and Boyle Abbey in County Roscommon (1161).\nFollowing the Anglo-Norman invasion of Ireland in the 1170s, the English improved the standing of the Cistercian Order in Ireland with nine foundations: Dunbrody Abbey, Inch Abbey, Grey Abbey, Comber Abbey, Duiske Abbey, Abington, Abbeylara and Tracton. This last abbey was founded in 1225 from Whitland Abbey in Wales, and at least in its earliest years, its monks were Welsh-speaking. By this time, another ten abbeys had been founded by Irishmen since the invasion, bringing the total number of Cistercian houses in Ireland to 31. This was almost half the number of those in England, but it was about thrice the number in each of Scotland and Wales. Most of these monasteries enjoyed either noble, episcopal or royal patronage. In 1269, the Archbishop of Cashel joined the order and established a Cistercian house at the foot of the Rock of Cashel in 1272. Similarly, the Irish-establishment of Abbeyknockmoy in County Galway was founded by King of Connacht, Cathal Crobhdearg Ua Conchobair, who died a Cistercian monk and was buried there in 1224.\nBy 1152, there were 54 Cistercian monasteries in England, few of which had been founded directly from the Continent. Overall, there were 333\u00a0Cistercian abbeys in Europe, so many that a halt was put to this expansion. Nearly half of these houses had been founded, directly or indirectly, from Clairvaux, so great was St Bernard's influence and prestige. He later came popularly to be regarded as the founder of the Cistercians, who have often been called Bernardines. Bernard died in 1153, one month after his pupil Eugene III.\nThe Iberian Peninsula.\nIn 1153, the first King of Portugal, D. Afonso Henriques (Afonso, I), founded Alcoba\u00e7a Monastery. The original church was replaced by the present construction from 1178. The abbey's church was consecrated in 1223. Two further building phases followed in order to complete the nave, leading to the final consecration of the medieval church building in 1252.\nAs a consequence of the wars between the Christians and Moors on the Iberian Peninsula, the Cistercians established a military branch of the order in Castile in 1157: the Order of Calatrava. Membership of the Cistercian Order had included a large number of men from knightly families, and when King Alfonso VII began looking for a military order to defend the Calatrava, which had been recovered from the Moors a decade before, the Cistercian Abbot Raymond of Fitero offered his help. Lay brothers were to be employed as \"soldiers of the Cross\" to defend Calatrava. The initial successes of the new order in the Spanish Reconquista were convincing, and the arrangement was approved by the General Chapter at C\u00eeteaux and successive popes; the Knights of Calatrava were given a definitive rule in 1187, modeled upon the Cistercian rule for lay brothers, which included the evangelical counsels of poverty, chastity, and obedience; specific rules of silence; abstinence on four days a week; the recitation of a fixed number of Pater Nosters daily; to sleep in their armour; and to wear, as their full dress, the Cistercian white mantle with the scarlet cross \"fleurdelis\u00e9e\".\nCalatrava was not subject to C\u00eeteaux, but to Fitero's mother-house, the Abbey of Morimond in Burgundy. By the end of the 13th century, the knights had become a major autonomous power within the Castilian state, subject only to Morimond and the pope. They had abundant resources of men and wealth, lands and castles scattered along the borders of Castile, and feudal lordship over thousands of peasants and vassals. On more than one occasion, the Order of Calatrava brought to the field a force of 1200 to 2000 knights \u2013 considerable in medieval terms. Over time, as the Reconquista neared completion, the canonical bond between Calatrava and Morimond relaxed more and more, and the knights of the order became virtually secularized, finally undergoing dissolution in the 18th\u201319th centuries.\nThe first Cistercian abbey in Bohemia was founded in Sedlec near Kutn\u00e1 Hora in 1142. In the late 13th century and early 14th century, the Cistercian order played an essential role in the politics and diplomacy of the late P\u0159emyslid and early Luxembourg state, as reflected in the \"Chronicon Aulae Regiae\". This chronicle was written by Otto and Peter of Zittau, abbots of the Zbraslav abbey (Latin: \"Aula Regia\", \"Royal Hall\"), founded in 1292 by the King of Bohemia and Poland, Wenceslas II. The order also played the main role in the early Gothic art of Bohemia; one of the outstanding pieces of Cistercian architecture is the Alt-neu Shul, Prague. The first abbey in the present day Romania was founded in 1179, at Igris (Egres), and the second in 1204, the C\u00e2r\u021ba Monastery.\nBy the end of the 13th century, the Cistercian houses numbered 500. In this period, the monks performed pastoral tasks in and outside of the monastery and began preaching and teaching, even though their movement originally forbade schools and parishes. At the order's height in the 15th century, it would have nearly 750 houses.\nIt often happened that the number of lay brothers became excessive and out of proportion to the resources of the monasteries, there being sometimes as many as 200, or even 300, in a single abbey. On the other hand, in some countries, the system of lay brothers in course of time worked itself out; thus in England by the close of the 14th century it had shrunk to relatively small proportions, and in the 15th century the regimen of the English Cistercian houses tended to approximate more and more to that of the Black Monks.\nInfluence with popes and kings.\nCistercian influence more than kept pace with the material expansion. Bernard had become mentor to popes and kings, and in 1145, King Louis VII's brother, Henry of France, entered Clairvaux. That same year, Bernard saw one of his monks elected pope as Pope Eugene III. Eugene was an Italian of humble background, who had first been drawn to monasticism at Clairvaux by the magnetism of Bernard. At the time of his election, he was Abbot of Saints Vincenzo and Anastasio outside Rome.\nA considerable reinforcement to the Order was the merger of the Savigniac houses with the Cistercians, at the insistence of Eugene III. Thirteen English abbeys, of which the most famous were Furness Abbey and Jervaulx Abbey, thus adopted the Cistercian formula. In Dublin, the two Savigniac houses of Erenagh and St Mary's became Cistercian. It was in the latter case that medieval Dublin acquired a Cistercian monastery in the very unusual suburban location of Oxmantown, with its own private harbour called The Pill.\nDecline and attempted reforms.\nFor a hundred years, until the first quarter of the 13th century, the Cistercians supplanted Cluny as the most powerful order and the chief religious influence in western Europe. But then in turn their influence began to wane, as the initiative passed to the mendicant orders, in Ireland, Wales and elsewhere.\nRelaxations were gradually introduced into Cistercian life with regard to diet and simplicity of life. Also, they began accepting the traditional sources of income that monks in comparable orders used: like rents, tolls, and benefices. The agricultural operations were blessed by success. Wealth and splendour characterized the monasteries, so that by 1300, the standard of living in most abbeys was comparable, if not higher, than the standards middling nobles enjoyed. Two important papal bulls tried to introduce reforms: Clement IV's \"Parvus fons\" and Benedict XII's \"Fulgens sicut stella matutina\". The General Chapter continued to battle against abuses.\nIn Ireland, the information on the Cistercian Order after the Anglo-Norman invasion gives a rather gloomy impression. Absenteeism among Irish abbots at the General Chapter became a persistent and much criticised problem in the 13th century, and escalated into the \"conspiratio Mellifontis\", a \"rebellion\" by the abbeys of the Mellifont filiation. Visitors were appointed to reform Mellifont on account of the \"multa enormia\" that had arisen there, but in 1217 the abbot refused their admission and had lay brothers bar the abbey gates. There was also trouble at Jerpoint, and alarmingly, the abbots of Baltinglass, Killenny, Kilbeggan and Bective supported the actions of the \"revolt\".\nIn 1228, the General Chapter sent the Abbot of Stanley in Wiltshire, Stephen of Lexington, on a well-documented visitation to reform the Irish houses. A graduate of both Oxford and Paris, and a future Abbot of Clairvaux (to be appointed in 1243), Stephen was one of the outstanding figures in 13th-century Cistercian history, having founded the College of St. Bernard in Paris in 1244. He found his life threatened as a result of the Irish visitations: his representatives were attacked and his party harassed, while the three key houses of Mellifont, Suir and Maigue had been fortified by monks to hold out against him. However, with the help of his assistants, the core of obedient Irish monks and the aid of both English and Irish secular powers, he was able to envisage the reconstruction of the Cistercian province in Ireland. Stephen dissolved the Mellifont filiation altogether, and subjected 15 monasteries to houses outside Ireland. In breadth and depth, his instructions constituted a radical reform programme: \"They were intended to put an end to abuses, restore the full observance of the Cistercian way of life, safeguard monastic properties, initiate a regime of benign paternalism to train a new generation of religious, isolate trouble-makers and institute an effective visitation system.\" The arrangement lasted almost half a century, and in 1274, the filiation of Mellifont was reconstituted.\nIn Germany the Cistercians were instrumental in the spread of Christianity east of the Elbe. They developed grants of territories of 180,000 acres where they would drain land, build monasteries and plan villages. Many towns near Berlin owe their origins to this order, including Heiligengrabe and Chorin; its Chorin Abbey was the first brick-built monastery in the area. By this time, however, \"the Cistercian order as a whole had experienced a gradual decline and its central organisation was noticeably weakened.\"\nIn 1335, the French cardinal Jacques Fournier, a Cistercian monk, was elected and consecrated Pope Benedict XII. He was devoted to reducing the culture of nepotism at the Vatican. He promulgated a series of regulations to restore the spirit of reform in the Cistercian Order.\nBy the 15th century, however, the Cistercians had fallen on dark days. The General Chapter lost virtually all its power to enforce its decrees, and the strength of the order which derived from this uniformity declined. Wars, among them the Hundred Years' War, and a lack of leadership did damage. Many of the monasteries were controlled by dynasties who appointed their relatives to leadership positions, and pocketed the abbeys' profits. The system of placing abbeys \"in commendam\" was widespread and led to the spiritual and material decline of many abbeys.\nProtestant Reformation.\nEvangelical Lutheranism.\nGermany became the scene of violence and destabilization following Martin Luther's efforts to separate from the Vatican. Though some abbeys lost monks who left religious life to marry, other Cistercian monasteries, such as Loccum Abbey and Amelungsborn Abbey, adopted the Evangelical Lutheran faith and continued religious life under solemn vows, being active in the present-day. For example, the Evangelical-Lutheran Cistercian Monastery of Amelungsborn has nine religious and a number of tertiaries. \nAnglicanism.\nDuring the English Reformation, Henry VIII's Dissolution of the Monasteries saw the confiscation of every single monastery in that country, a disaster not only for the Cistercians. Some historians believe that the suppression of the English monasteries may have stamped out an industrial revolution.\nA revival of religious orders took place under the Oxford Movement in the Anglican tradition. As such, there are Anglican Cistercian communities that remain active in the present day.\nAfter the Reformation.\nThe reformed Congregation of the Feuillants spread widely in France and Italy in the 16th century. The French congregation of Sept-Fontaines (1654) also deserves mention. In 1663 Jean de Ranc\u00e9 reformed La Trappe (see Trappists).\nIn the 17th century another great effort at a general reform was made, promoted by the pope and the king of France; the general chapter elected Richelieu to be (commendatory) abbot of C\u00eeteaux, thinking he would protect them from the threatened reform. In this they were disappointed, for he threw himself wholly on the side of reform. A formidable battle ensued, making it clear that Italian and Central European abbeys did not want to go the way of the Trappists. Civic politics also played a role in the conflict.\nThe Protestant Reformation, the ecclesiastical policy of Emperor Joseph II, the French Revolution, and the revolutions of the 18th century almost wholly destroyed the Cistercians. But some survived, and from the beginning of the last half of the 19th century there was a considerable recovery.\nIn 1892, the Trappists left the Cistercians and founded a new order, named the Order of Cistercians of the Strict Observance. The Cistercians that remained within the original order thus came to be known as the \"Common Observance\".\nInfluence.\nArchitecture.\nCistercian architecture has made an important contribution to European civilisation. Cistercian foundations were primarily constructed in Romanesque and Gothic architecture during the Middle Ages; although later abbeys were also constructed in Renaissance and Baroque. The Cistercian order had no fixed building rules but rather Cistercian prohibitions regarding building practices, including the prohibition of decoration as signs of poverty and simplicity, as seen in early Cistercian architecture. Furthermore, the order itself was receptive to the technical improvements of Gothic principles of construction and played an important role in its spread across Europe.\nBernard condemned excessive decoration of monastic buildings as a distraction for monks. \nCistercian architecture embodied the ideals of the order, and was in theory at least utilitarian and without ornamentation. The same \"rational, integrated scheme\" was used across Europe to meet the largely homogeneous needs of the order. Various buildings, including the chapter-house to the east and the dormitories above, were grouped around a cloister, and were sometimes linked to the transept of the church itself by a night stair. Usually Cistercian churches are cruciform, with a short presbytery to meet the liturgical needs of the brethren, small chapels in the transepts for private prayer, and an aisled nave that was divided roughly in the middle by a screen to separate the monks from the lay brothers.\nEngineering and construction.\nThe building projects of the Church in the High Middle Ages showed that the era encourage colossal architecture, with vast amounts of stone being quarried; the same was true of the Cistercian projects. Foigny Abbey was long, and Vaucelles Abbey was long. Monastic buildings came to be constructed entirely of stone, right down to the most humble of buildings. In the 12th and 13th centuries, even Cistercian barns consisted had stone exteriors.\nThe Cistercians acquired a reputation as masters in administering ecclesial construction projects. Bernard's own brother, Achard, is known to have supervised the construction of many abbeys, such as Himmerod Abbey in the Rhineland. On one occasion the abbot of La Trinit\u00e9 at Vend\u00f4me loaned a monk named John to the Bishop of Le Mans, Hildebert de Lavardin, for the building of a cathedral; after the project was completed, John refused to return to his monastery. However, the monks did not construct their edifices alone. As early as 1133, Bernard was hiring workers to help the monks erect new buildings at Clairvaux. An illustration from the 16th century shows monks working alongside other craftsmen at Sch\u00f6nau Abbey.\nWorld Heritage Sites.\nThe Cistercian abbeys of Fontenay in France, Fountains in England, Alcoba\u00e7a in Portugal, Poblet in Spain and Maulbronn in Germany are today recognised as UNESCO World Heritage Sites.\nIn the purity of architectural style, the beauty of materials and the care with which the Alcoba\u00e7a Monastery was built, Portugal possesses one of the most outstanding and best preserved examples of Early Gothic. Poblet Monastery, one of the largest in Spain, is considered similarly impressive for its austerity, majesty, and the fortified royal residence within. The fortified Maulbronn Abbey in Germany is considered \"the most complete and best-preserved medieval monastic complex north of the Alps\". The Transitional Gothic style of its church had a major influence in the spread of Gothic architecture over much of northern and central Europe, and the abbey's elaborate network of drains, irrigation canals and reservoirs has since been recognised as having \"exceptional\" cultural interest.\nArt.\nThe mother house of the order, C\u00eeteaux, had developed an advanced style of painting in illuminated manuscripts during the first decades of the 12th century. However, as Bernard of Clairvaux's influence increased, decoration gradually diminished in Cistercian manuscripts. He had a strong aversion to the extensive use of imagery. Decorations were finally banned altogether in the order. Any wall paintings that may have existed were presumably destroyed. Crucifixes were allowed, and later some painting and decoration crept back in. Bernard criticized abbey churches for their \"immoderate length, their superfluous breadth, the costly polishings, the curious carvings and paintings which attract the worshipper's gaze and hinder his attention.\" He loathed the fantastical, often deformed beasts used in medievial church decoration. Weaker monks would be tempted \"to spend the whole day in wondering at these things rather than in meditating the law of God.\"\nNonetheless, many Cistercian abbey churches housed the tombs of royal or noble patrons, and these were often elaborately carved and painted. Notable dynastic burial places were Alcoba\u00e7a for the Kings of Portugal, C\u00eeteaux for the Dukes of Burgundy, and Poblet for the Kings of Aragon. Corcomroe in Ireland contains one of only two surviving examples of Gaelic royal effigies from 13th and 14th century Ireland.\nAgriculture, technology, and commerce.\nSuccessful farmers, the white monks introduced and propagated many improvements in medieval agriculture. They developed an organised system for selling produce, cattle and horses, and notably contributed to commercial progress in Western Europe. To the wool and cloth trade, which was especially fostered by the Cistercians, England was largely indebted for the beginnings of her commercial prosperity.\nFrom the beginning, the monks used a system of lay brothers and employees to operate their farms; monks and priests were busy with their liturgical and sacramental duties. The lay brothers formed a body of men who lived alongside of the choir monks, but separate from them, not taking part in the canonical office, but having their own fixed round of prayer and religious exercises. They were not ordained, nor did they have a voice in the monks' chapter.\nOne Cistercian monk claims that, until the Industrial Revolution, most of the technological advances in Europe were made in the monasteries. According to the medievalist Jean Gimpel, their high level of industrial technology facilitated the diffusion of new techniques: \"Every monastery had a model factory, often as large as the church and only several feet away, and waterpower drove the machinery of the various industries located on its floor.\" Waterpower was used for crushing wheat, sieving flour, fulling cloth and tanning \u2013 a technological achievement in use in practically all of the order's monasteries. The monks used their own numbering system, which could express all the numbers from 0 to 9999 in a single sign.\nThe Cistercian order was innovative in developing techniques of hydraulic engineering for monasteries established in remote valleys. In Spain, one of the earliest surviving Cistercian houses, the Real Monasterio de Nuestra Senora de Rueda in Aragon, is a good example of such early hydraulic engineering, using a large waterwheel for power and an elaborate water circulation system for central heating.\nThe Cistercians are known to have been skilled metallurgists, and knowledge of their technological advances was transmitted by the order. Iron ore deposits were often donated to the monks along with forges to extract the iron, and within time surpluses were being offered for sale. The Cistercians became the leading iron producers in Champagne, from the mid-13th century to the 17th century, also using the phosphate-rich slag from their furnaces as an agricultural fertiliser. The forge at Fontenay abbey, for instance, is not on the margins of the abbey grounds, but within the monastic enclosure itself. Cistercian innovations may have shaped the very course of Gothic architecture.\nTheology.\nBy far the most influential of the early Cistercians was Bernard of Clairvaux. He attracted vocations, served as a papal envoy, and attracted international attention to the movement: he was \"one of the most influential churchmen of his time.\" Bernard was an ascetic and intellectual, which he demonstrated in his sermons on Grace, Free will and the Song of Songs. He was quick to recognise heretical ideas, and in 1141 and 1145 respectively, he accused the celebrated scholastic theologian Peter Abelard and the popular preacher Henry of Lausanne of heresy. He was also charged with the task of promulgating Pope Eugene's bull, \"Quantum praedecessores\", and his eloquence in preaching the Second Crusade recruited many to the cause.\nAlthough Bernard's \"De laude novae militiae\" was in favour of the Knights Templar, the English Cistercian Abbot Isaac of Stella, near Poitiers, preached against the very same group as a \"new monstrosity.\" In the course of the 12th and 13th centuries, many Cistercian authors wrote on spiritual topics. The \"four evangelists\" of the movement are: Bernard, William of Saint Thierry, Aelred of Rievaulx, and Guerric of Igny. During the Middle Ages, they were often read by monks from other orders, for example the Carthusians. Besides Bernard, the others were only re-discovered in the 20th century.\nCistercians today.\nMany Cistercian monasteries make produce goods such as cheese, bread, and craft products. In the United States, some abbeys support themselves through agriculture, forestry and real estate. European Trappist monasteries are known for their beer.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50410", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=50410", "title": "Coup d'etat", "text": ""}
{"id": "50411", "revid": "12202748", "url": "https://en.wikipedia.org/wiki?curid=50411", "title": "Cistercian", "text": ""}
{"id": "50413", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=50413", "title": "Sierra Nevada", "text": "Mountain range in the United States\nThe Sierra Nevada ( ) is a mountain range in the Western United States, between the Central Valley of California and the Great Basin. The vast majority of the range lies in the state of California, although the Carson Range spur lies primarily in Nevada. The Sierra Nevada is part of the American Cordillera, an almost continuous chain of mountain ranges that forms the western \"backbone\" of the Americas.\nThe Sierra runs north-south, and its width ranges from to across east\u2013west. Notable features include the General Sherman Tree, the largest tree in the world by volume; Lake Tahoe, the largest alpine lake in North America; Mount Whitney at , the highest point in the contiguous United States; and Yosemite Valley sculpted by glaciers from one-hundred-million-year-old granite, containing high waterfalls. The Sierra is home to three national parks, twenty-six wilderness areas, ten national forests, and two national monuments. These areas include Yosemite, Sequoia, and Kings Canyon National Parks, as well as Devils Postpile National Monument.\nMore than one hundred million years ago during the Nevadan orogeny, granite formed deep underground. The range started to uplift less than five million years ago, and erosion by glaciers exposed the granite and formed the light-colored mountains and cliffs that make up the range. The uplift caused a wide range of elevations and climates in the Sierra Nevada, which are reflected by the presence of five life zones (areas with similar plant and animal communities). Uplift continues due to faulting caused by tectonic forces, creating spectacular fault block escarpments along the eastern edge of the southern Sierra.\nThe Sierra Nevada has played an important role in the history of California and the United States. The California gold rush occurred in the western foothills from 1848 through 1855. Due to its inaccessibility, the range was not fully explored until 1912.\nName and etymology.\nUsed in 1542 by Juan Rodr\u00edguez Cabrillo to describe a Pacific Coast Range (Santa Cruz Mountains), the term \"Sierra Nevada\" was a general identification of less familiar ranges toward the interior. In 1776, Pedro Font's map applied the name to the range currently known as the Sierra Nevada.\nThe literal translation is \"snowy mountains\", from \"sierra\" \"a range of mountains\", 1610s, from Spanish \"jagged mountain range\", lit. \"saw\", from Latin \"a saw\"; and from the Spanish adjective \"snowy\".\nWhile many mountain ranges are unanimously referred to in the plural (Smokies, Rockies, Cascades, etc.), some locals who live in \"the Sierra\" are not hesitant to admonish those who refer to the area as \"the Sierras\". However, there are historical and literary references that use the plural, such as the 1871 collection of Joaquin Miller poems, \"Songs of the Sierras\". Ansel Adams, in response to a publication of his photographs under the title \"Parmelian Prints of the High Sierras\", commented, \"To add an \"s\" is a linguistic, Californian, and mountaineering sin.\"\nGeography.\nThe Sierra Nevada lies primarily in Central and Eastern California, with the Carson Range, a small but historically important spur, extending into Nevada. West-to-east, the Sierra Nevada's elevation increases gradually from in the Central Valley to more than atop the highest peaks of its crest to the east. The east slope forms the steep Sierra Escarpment. Unlike its surroundings, the range receives a substantial amount of snowfall and precipitation due to orographic lift.\nSetting.\nThe Sierra Nevada's irregular northern boundary stretches from the Susan River and Fredonyer Pass to the North Fork Feather River. It represents where the granitic bedrock of the Sierra Nevada dives below the southern extent of Cenozoic igneous surface rock from the Cascade Range. The range is bounded on the west by California's Central Valley, on the east by the Basin and Range Province, and on the southeast by the Mojave Desert. The southern boundary is at Tehachapi Pass.\nPhysiographically, the Sierra is a section of the Cascade\u2013Sierra Mountains province, which in turn is part of the larger Pacific Mountain System physiographic division. The California Geological Survey states that \"the northern Sierra boundary is marked where bedrock disappears under the Cenozoic volcanic cover of the Cascade Range.\"\nWatersheds.\nThe range is drained on its western slope by the Central Valley watershed, which discharges into the Pacific Ocean at San Francisco. The northern third of the western Sierra is part of the Sacramento River watershed (including the Feather, Yuba, and American River tributaries), and the middle third is drained by the San Joaquin River (including the Mokelumne, Stanislaus, Tuolumne, and Merced River tributaries). The southern third of the range is drained by the Kings, Kaweah, Tule, and Kern rivers, which flow into the endorheic basin of Tulare Lake, which rarely overflows into the San Joaquin during wet years.\nThe eastern slope watershed of the Sierra is much narrower; its rivers flow out into the endorheic Great Basin of eastern California and western Nevada. From north to south, the Susan River flows into intermittent Honey Lake, the Truckee River flows from Lake Tahoe into Pyramid Lake, the Carson River runs into Carson Sink, the Walker River into Walker Lake; Rush, Lee Vining and Mill Creeks flow into Mono Lake; and the Owens River into dry Owens Lake. Although none of the eastern rivers reach the sea, many of the streams from Mono Lake southwards are diverted into the Los Angeles Aqueduct which provides water to Southern California.\nElevation.\nThe height of the mountains in the Sierra Nevada increases gradually from north to south. Between Fredonyer Pass and Lake Tahoe, the peaks range from to more than . The crest near Lake Tahoe is roughly high, with several peaks approaching the height of Freel Peak (). Farther south, the highest peak in Yosemite National Park is Mount Lyell (). The Sierra rises to almost with Mount Humphreys near Bishop, California. Finally, near Lone Pine, Mount Whitney is at , the highest point in the contiguous United States.\nSouth of Mount Whitney, the elevation of the range quickly dwindles. The crest elevation is almost near Lake Isabella, but south of the lake, the peaks reach only a modest .\nNotable features.\nThere are several notable geographical features in the Sierra Nevada:\nCommunities.\nCommunities in the Sierra Nevada include Paradise, South Lake Tahoe, Truckee, Grass Valley, Lee Vining, Mammoth Lakes, Sonora, Nevada City, Placerville, Pollock Pines, Portola, Auburn, Colfax, Kennedy Meadows and Shaver Lake.\nProtected areas.\nMuch of the Sierra Nevada consists of federal lands and is either protected from development or strictly managed. The mountain range is home to three National Parks\u00a0\u2013 Yosemite, Kings Canyon, and Sequoia\u00a0\u2013 and two national monuments\u00a0\u2013 Devils Postpile and Giant Sequoia. Ten national forests span much of the mountain range's remaining area. Within these national parks, monuments, and forests lie 26 wilderness areas, which together protect 15.4% of the Sierra's from logging, development, and wheeled vehicle use.\nThe United States Forest Service and the Bureau of Land Management currently control 52% of the land in the Sierra Nevada. Logging and grazing are generally allowed on land controlled by these agencies, under federal regulations that balance recreation and development on the land.\nThe California Bighorn Sheep Zoological Area near Mount Williamson in the southern Sierra was established to protect the endangered Sierra Nevada bighorn sheep. Starting in 1981, hikers were unable to enter the Area from May 15 through December 15, in order to protect the sheep. As of 2010, the restriction has been lifted and access to the Area is open for the whole year.\nGeologic history.\nThe earliest rocks in the Sierra Nevada are metamorphic roof pendants of Paleozoic age, the oldest being metasedimentary rocks from the Cambrian in the Mount Morrison region. These dark-colored hornfels, slates, marbles, and schists are found in the western foothills (notably around Coarsegold, west of the Tehachapi Pass) and east of the Sierra Crest. The earliest granite of the Sierra started to form in the Triassic period. This granite is mostly found east of the crest and north of 37.2\u00b0N. In the Triassic and into the Jurassic, an island arc collided with the west coast of North America and raised a chain of volcanoes, in an event called the Nevadan orogeny. Nearly all subaerial Sierran Arc volcanoes have since disappeared; their remains were redeposited during the Great Valley Sequence and the subsequent Cenozoic filling of the Great Valley, which is the source of much of the sedimentary rock in California.\nIn the Cretaceous, a subduction zone formed at the edge of the continent. This means that an oceanic plate started to dive beneath the North American Plate. Magma, formed through the subduction of the ancient Farallon Plate, rose in plumes (plutons) deep underground, their combined mass forming what is called the Sierra Nevada batholith. These plutons formed at various times, from 115\u00a0Ma to 87\u00a0Ma. The earlier plutons formed in the western half of the Sierra, while the later plutons formed in the eastern half of the Sierra. At this time, the Sierra Nevada formed the western ramp of a high plateau to the east, the Nevadaplano. During this period, rivers cut deep canyons into the range, generating topographic relief similar to the modern Sierra Nevada. This period of incision was halted approximately 30 million years ago by vast outpourings of pyroclastic flows from Nevada which filled the northern Sierran valleys with volcanic deposits. These pyroclastic flows, which continued for about 10 million years, were followed by andesitic lahars which nearly completely buried the northern Sierran landscape such that only the tallest peaks emerged above a volcanic plain. This second period of volcanism appears to have been triggered by crustal extension associated with extension of the Basin and Range Province. As this andesitic volcanism began waning about five million years ago, the rivers were able to begin eroding away the 100s of meters of volcanic deposits and resume the incision that had been halted by the first period of volcanism.\nSome studies have argued that this recent incision is a sign of recent tectonic uplift. Other geologists claim that the elevations of many of the modern rivers flowing down the range are only lower than their ancient counterparts from 30\u201340\u00a0million years ago and the overall elevation and bedrock topography of the northern Sierra Nevada has changed little since at least 30\u201340\u00a0million years ago.\nAbout 2.5\u00a0Ma, the Earth's climate cooled, and ice ages started. Glaciers carved out characteristic U-shaped canyons throughout the Sierra. The combination of river and glacier erosion exposed the uppermost portions of the plutons emplaced millions of years before, leaving only a remnant of metamorphic rock on top of some Sierra peaks.\nExtension of the Basin and Range continues today, leading to downdropping of crustal blocks just east of the Sierra Nevada during large earthquakes, such as the Lone Pine earthquake of 1872.\nClimate and meteorology.\nThe climate of the Sierra Nevada is influenced by the Mediterranean climate of California. During the fall, winter and spring, precipitation in the Sierra ranges from where it occurs mostly as snow above . Precipitation is highest on the central and northern portions of the western slope between elevation, due to orographic lift. Above , precipitation diminishes on the western slope up to the crest, since most of the precipitation has been wrung out at lower elevations. Most parts of the range east of the crest are in a rain shadow, and receive less than 25 inches of precipitation per year. While most summer days are dry, afternoon thunderstorms are common, particularly during the North American Monsoon in mid and late summer. Some of these summer thunderstorms drop over an inch of rain in a short period, and the lightning can start fires. Summer high temperatures average . Winters are comparatively mild, and the temperature is usually only just low enough to sustain a heavy snowpack. For example, Tuolumne Meadows, at elevation, has winter daily highs about with daily lows about . The growing season lasts 20 to 230 days, strongly dependent on elevation. The highest elevations of the Sierra have an alpine climate.\nThe Sierra Nevada snowpack is the major source of water and a significant source of electric power generation in California. Many reservoirs were constructed in the canyons of the Sierra throughout the 20th century, Several major aqueducts serving both agriculture and urban areas distribute Sierra water throughout the state. However, the Sierra casts a rain shadow, which greatly affects the climate and ecology of the central Great Basin. This rain shadow is largely responsible for Nevada being the driest state in the United States.\nPrecipitation varies substantially from year to year. It is not uncommon for some years to receive precipitation totals far above or below normal.\nThe height of the range and the steepness of the Sierra Escarpment, particularly at the southern end of the range, produces a wind phenomenon known as the \"Sierra Rotor\". This is a horizontal rotation of the atmosphere just east of the crest of the Sierra, set in motion as an effect of strong westerly winds.\nThe Sierra Nevada is home to the Mono winds, strong, dry downslope winds that primarily affect the western slopes, especially in the central region, and are most common from late fall to spring. With gusts reaching over 80 miles per hour, these winds can cause widespread disruption, uprooting trees, damaging infrastructure, and making mountain passes hazardous for drivers.\nBecause of the large number of airplanes that have crashed in the Sierra Nevada, primarily due to the complex weather and atmospheric conditions such as downdrafts and microbursts caused by geography there, a portion of the area, a triangle whose vertices are Reno, Nevada; Fresno, California; and Las Vegas, Nevada, has been dubbed the \"Nevada Triangle\", in reference to the Bermuda Triangle. Some counts put the number of crashes in the triangle at 2,000, including millionaire and record-breaking flyer Steve Fossett. Hypotheses that the crashes are related in some way to the United States Air Force's Area 51, or to the activities of extra-terrestrial aliens, have no evidence to support them.\nEcology.\nThe Sierra Nevada is divided into a number of biotic zones, each of which is defined by its climate and supports a number of interdependent species. Life in the higher elevation zones adapted to colder weather, and to most of the precipitation falling as snow. The rain shadow of the Sierra causes the eastern slope to be warmer and drier: each life zone is higher in the east. A list of biotic zones, and corresponding elevations, is presented below:\nHistory.\nNative Americans.\nArchaeological excavations placed Martis people of Paleo-Indians in northcentral Sierra Nevada during the period of 3,000\u00a0BCE to 500\u00a0CE. The earliest identified sustaining indigenous people in the Sierra Nevada were the Northern Paiute tribes on the east side, with the Mono tribe and Sierra Miwok tribe on the western side, and the Kawaiisu and T\u00fcbatulabal tribes in the southern Sierra. Today, some historic intertribal trade route trails over mountain passes are known artifact locations, such as Duck Pass with its obsidian arrowheads. The California and Sierra Native American tribes were predominantly peaceful, with occasional territorial disputes between the Paiute and Sierra Miwok tribes in the mountains. Washo and Maidu were also in this area prior to the era of European exploration and displacement.\nInitial European-American exploration.\nAmerican exploration of the mountain range started in 1827. Although prior to the 1820s there were Spanish missions, \"pueblos\" (towns), \"presidios\" (forts), and \"ranchos\" along the coast of California, no Spanish explorers visited the Sierra Nevada. The first Americans to visit the mountains were amongst a group led by fur trapper Jedediah Smith, crossing north of the Yosemite area in May 1827, at Ebbetts Pass.\nIn 1833, a subgroup of the Bonneville Expedition led by Joseph Reddeford Walker was sent westward to find an overland route to California. Eventually the party discovered a route along the Humboldt River across present-day Nevada, ascending the Sierra Nevada, starting near present-day Bridgeport and descending between the Tuolumne and Merced River drainage. The group may have been the first non-indigenous people to see Yosemite Valley. The Walker Party probably visited either the Tuolumne or Merced Groves of giant sequoia, becoming the first non-indigenous people to see the giant trees, but journals relating to the Walker party were destroyed in 1839, in a print shop fire in Philadelphia.\nStarting in 1841, emigrants from the United States started to move to California via Sonora and Walker Passes.\nIn the winter of 1844, Lt. John C. Fr\u00e9mont, accompanied by Kit Carson, was the first European American to see Lake Tahoe. The Fr\u00e9mont party camped at .\nGold rush.\nThe California Gold Rush began at Sutter's Mill, near Coloma, in the western foothills of the Sierra. On January 24, 1848, James W. Marshall, a foreman working for Sacramento pioneer John Sutter, found shiny metal in the tailrace of a lumber mill Marshall was building for Sutter on the American River. Rumors soon started to spread and were confirmed in March 1848 by San Francisco newspaper publisher and merchant Samuel Brannan. Brannan strode through the streets of San Francisco, holding aloft a vial of gold, shouting \"Gold! Gold! Gold from the American River!\"\nOn August 19, 1848, the \"New York Herald\" was the first major newspaper on the East Coast to report the discovery of gold. On December 5, 1848, President James Polk confirmed the discovery of gold in an address to Congress. Soon, waves of immigrants from around the world, later called the \"forty-niners\", invaded the Gold Country of California or \"Mother Lode\". Miners lived in tents, wood shanties, or deck cabins removed from abandoned ships. Wherever gold was discovered, hundreds of miners would collaborate to put up a camp and stake their claims.\nBecause the gold in the California gravel beds was so richly concentrated, the early forty-niners simply panned for gold in California's rivers and streams. However, panning cannot take place on a large scale, and miners and groups of miners graduated to more complex placer mining. Groups of prospectors would divert the water from an entire river into a sluice alongside the river, and then dig for gold in the newly exposed river bottom.\nBy 1853, most of the easily accessible gold had been collected, and attention turned to extracting gold from more difficult locations. Hydraulic mining was used on ancient gold-bearing gravel beds on hillsides and bluffs in the gold fields. In hydraulic mining, a high-pressure hose directed a powerful stream or jet of water at gold-bearing gravel beds. It is estimated that by the mid-1880s, 11\u00a0million troy ounces (340 metric tons) of gold (worth approximately US$16\u00a0billion in 2020 prices) had been recovered by \"hydraulicking\". A consequence of these extraction methods was that large amounts of gravel, silt, heavy metals, and other pollutants were washed into streams and rivers. As of 1999[ [update]], many areas still bear the scars of hydraulic mining, since the resulting exposed earth and downstream gravel deposits do not support plant life.\nIt is estimated that by 1855, at least 300,000 gold-seekers, merchants, and other immigrants had arrived in California from around the world. The huge numbers of newcomers brought by the Gold Rush drove Native Americans out of their traditional hunting, fishing and food-gathering areas. To protect their homes and livelihood, some Native Americans responded by attacking the miners, provoking counter-attacks on native villages. The Native Americans, out-gunned, were often slaughtered.\nThorough exploration.\nThe Gold Rush populated the western foothills of the Sierra Nevada, but even by 1860, most of the Sierra was unexplored. The state legislature authorized the California Geological Survey to officially explore the Sierra (and survey the rest of the state). Josiah Whitney was appointed to head the survey. Men of the survey, including William H. Brewer, Charles F. Hoffmann and Clarence King, explored the backcountry of what would become Yosemite National Park in 1863. In 1864, they explored the area around Kings Canyon. In 1869, John Muir started his wanderings in the Sierra Nevada range, and in 1871, King was the first to climb Mount Langley, mistakenly believing he had summited Mount Whitney, the highest peak in the range. In 1873, Mount Whitney was climbed for the first time by 3 men from Lone Pine, California, on a fishing trip. From 1892 to 1897 Theodore Solomons made the first attempt to map a route along the crest of the Sierra.\nOther people finished exploring and mapping the Sierra. Bolton Coit Brown explored the Kings River watershed in 1895\u20131899. Joseph N. LeConte mapped the area around Yosemite National Park and what would become Kings Canyon National Park. James S. Hutchinson, a noted mountaineer, climbed the Palisades (1904) and Mount Humphreys (1905). By 1912, the USGS published a set of maps of the Sierra Nevada, and the era of exploration was over.\nLogging.\nLogging in the Sierra Nevada has significantly impacted the landscape. The logging industry in the Sierra Nevada started in the early 1800s, when settlers relied on hand tools and ox-teams. Before the California Gold Rush, the industry was relatively small, and most of the lumber used in the state was imported. However, as the demand for lumber to support the mining industry increased, logging became a major industry in the region.\nInitially, most of the lumber produced in California was used in mining. The Comstock Lode was a major center for logging, with operations supplying lumber for the construction of mine structures, such as tunnels, shafts, and buildings, as well as fuel for the mines. Dan DeQuille observed in 1876, \"the Comstock Lode may truthfully be said to be the tomb of the forests of the Sierra. Millions upon millions of feet of lumber are annually buried in the mines, nevermore to be resurrected.\"\nIn the late 1800s, the logging industry moved westward due to the depletion of white pine forests in the upper Midwest. This shift was encouraged by the positive portrayal of the Sierra Nevada as a promising timber region. In 1859, Horace Greely marveled, \"I never saw anything so much like good timber in the course of any seventy-five miles' travel as I saw in crossing the Sierra Nevada.\"\nThe logging industry experienced significant growth in the late 1800s due to several factors. The Timber and Stone Act of 1878 allowed individuals to claim ownership of old-growth timber tracts, which were later consolidated under joint-stock companies, such as those founded by Midwestern lumber magnates. These companies had the financial resources to transport timber from remote locations and build sawmills near the tracks of the Southern Pacific railroad which connected the San Joaquin Valley to the rest of the state in the 1870s. This facilitated the nationwide distribution of lumber. In addition, technological advancements, such as the shay locomotive and the v-shaped log flume, made it easier to transport lumber across mountainous terrain.\nConservation.\nThe tourism potential of the Sierra Nevada was recognized early in the European history of the range. Yosemite Valley was first protected by the federal government in 1864. The Valley and Mariposa Grove were ceded to California in 1866 and turned into a state park. John Muir perceived overgrazing by sheep and logging of giant sequoia to be a problem in the Sierra. Muir successfully lobbied for the protection of the rest of Yosemite National Park: Congress created an Act to protect the park in 1890. The Valley and Mariposa Grove were added to the Park in 1906. In the same year, Sequoia National Park was formed to protect the Giant Sequoia: all logging of the Sequoia ceased at that time.\nIn 1903, the city of San Francisco proposed building a hydroelectric dam to flood Hetch Hetchy Valley. The city and the Sierra Club argued over the dam for 10 years, until the U.S. Congress passed the Raker Act in 1913 and allowed dam building to proceed. O'Shaughnessy Dam was completed in 1923.\nBetween 1912 and 1918, Congress debated three times to protect Lake Tahoe in a national park. None of these efforts succeeded, and after World War II, towns such as South Lake Tahoe grew around the shores of the lake. By 1980, the permanent population of the Lake Tahoe area grew to 50,000, while the summer population grew to 90,000. The development around Lake Tahoe affected the clarity of the lake water. In order to preserve the lake's clarity, construction in the Tahoe basin is currently regulated by the Tahoe Regional Planning Agency.\nAs the 20th century progressed, more of the Sierra became available for recreation; other forms of economic activity decreased. The John Muir Trail, a trail that followed the Sierra crest from Yosemite Valley to Mount Whitney, was funded in 1915 and finished in 1938. Kings Canyon National Park was formed in 1940 to protect the deep canyon of the Kings River.\nIn the 1920s, automobile clubs and nearby towns started to lobby for trans-Sierra highways over Piute Pass (which would have closed the gap in SR 168) and other locations. However, by end of the 1920s, the Forest Service and the Sierra Club decided that roadless wilderness in the Sierra was valuable, and fought the proposal. The Piute Pass proposal faded out by the early 1930s, with the Forest Service proposing a route over Minaret Summit in 1933. The Minaret Summit route was lobbied against by California's Governor Ronald Reagan in 1972. The expansion of the John Muir and Ansel Adams Wildernesses in the 1980s sealed off the Minaret Summit route.\nA trans-Sierra route between Porterville and Lone Pine was proposed by local businessmen in 1923. Eventually, a circuitous route across the Sierra was built across Sherman Pass by 1976.\nBy 1964, the Wilderness Act protected portions of the Sierra as primitive areas where humans are simply temporary visitors. Gradually, 20 wilderness areas were established to protect scenic backcountry of the Sierra. These wilderness areas include the John Muir Wilderness (protecting the eastern slope of the Sierra and the area between Yosemite and Kings Canyon Parks), and wilderness within each of the National Parks.\nThe Sierra Nevada still faces a number of issues that threaten its conservation. Logging occurs on both private and public lands, including controversial clearcut methods and thinning logging on private and public lands. Grazing occurs on private lands as well as on National Forest lands, which include Wilderness areas. Overgrazing can alter hydrologic processes and vegetation composition, remove vegetation that serves as food and habitat for native species, and contribute to sedimentation and pollution in waterways. A recent increase in large wildfires, like the Rim Fire in Yosemite National Park and the Stanislaus National Forest and the King Fire on the Eldorado National Forest, has prompted concerns. A 2015 study indicated that the increase in fire risk in California may be attributable to human-induced climate change. A study looking back over 8,000 years found that warmer climate periods experienced severe droughts and more stand-replacing fires and concluded that as climate is such a powerful influence on wildfires, trying to recreate presettlement forest structure may be difficult in a warmer future.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50415", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=50415", "title": "Cryptographic", "text": ""}
{"id": "50416", "revid": "12336988", "url": "https://en.wikipedia.org/wiki?curid=50416", "title": "Differential calculus", "text": "Area of mathematics; subarea of calculus\nIn mathematics, differential calculus is a subfield of calculus that studies the rates at which quantities change. It is one of the two traditional divisions of calculus, the other being integral calculus\u2014the study of the area beneath a curve.\nThe primary objects of study in differential calculus are the derivative of a function, related notions such as the differential, and their applications. The derivative of a function at a chosen input value describes the rate of change of the function near that input value. The process of finding a derivative is called differentiation. Geometrically, the derivative at a point is the slope of the tangent line to the graph of the function at that point, provided that the derivative exists and is defined at that point. For a real-valued function of a single real variable, the derivative of a function at a point generally determines the best linear approximation to the function at that point.\nDifferential calculus and integral calculus are connected by the fundamental theorem of calculus. This states that differentiation is the reverse process to integration.\nDifferentiation has applications in nearly all quantitative disciplines. In physics, the derivative of the displacement of a moving body with respect to time is the velocity of the body, and the derivative of the velocity with respect to time is acceleration. The derivative of the momentum of a body with respect to time equals the force applied to the body; rearranging this derivative statement leads to the famous F \n ma equation associated with Newton's second law of motion. The reaction rate of a chemical reaction is a derivative. In operations research, derivatives determine the most efficient ways to transport materials and design factories.\nDerivatives are frequently used to find the maxima and minima of a function. Equations involving derivatives are called differential equations and are fundamental in describing natural phenomena. Derivatives and their generalizations appear in many fields of mathematics, such as complex analysis, functional analysis, differential geometry, measure theory, and abstract algebra.\nDerivative.\nThe derivative of formula_1 at the point formula_2 is the slope of the tangent to formula_3. In order to gain an intuition for this, one must first be familiar with finding the slope of a linear equation, written in the form formula_4. The slope of an equation is its steepness. It can be found by picking any two points and dividing the change in formula_5 by the change in formula_6, meaning that formula_7. For, the graph of formula_8 has a slope of formula_9, as shown in the diagram below:\nformula_10\nFor brevity, formula_11 is often written as formula_12, with formula_13 being the Greek letter delta, meaning 'change in'. The slope of a linear equation is constant, meaning that the steepness is the same everywhere. However, many graphs such as formula_14 vary in their steepness. This means that you can no longer pick any two arbitrary points and compute the slope. Instead, the slope of the graph can be computed by considering the tangent line\u2014a line that 'just touches' a particular point. The slope of a curve at a particular point is equal to the slope of the tangent to that point. For example, formula_14 has a slope of formula_16 at formula_17 because the slope of the tangent line to that point is equal to formula_16:\nThe derivative of a function is then simply the slope of this tangent line. Even though the tangent line only touches a single point at the point of tangency, it can be approximated by a line that goes through two points. This is known as a secant line. If the two points that the secant line goes through are close together, then the secant line closely resembles the tangent line, and, as a result, its slope is also very similar:\nThe advantage of using a secant line is that its slope can be calculated directly. Consider the two points on the graph formula_19 and formula_20, where formula_21 is a small number. As before, the slope of the line passing through these two points can be calculated with the formula formula_22. This gives\nformula_23\nAs formula_21 gets closer and closer to formula_25, the slope of the secant line gets closer and closer to the slope of the tangent line. This is formally written as\nformula_26\nThe above expression means 'as formula_21 gets closer and closer to 0, the slope of the secant line gets closer and closer to a certain value'. The value that is being approached is the derivative of formula_1; this can be written as formula_29. If formula_30, the derivative can also be written as formula_31, with formula_32 representing an infinitesimal change. For example, formula_33 represents an infinitesimal change in x. In summary, if formula_30, then the derivative of formula_1 is\nformula_36\nprovided such a limit exists. We have thus succeeded in properly defining the derivative of a function, meaning that the 'slope of the tangent line' now has a precise mathematical meaning. Differentiating a function using the above definition is known as differentiation from first principles. Here is a proof, using differentiation from first principles, that the derivative of formula_14 is formula_38:\nformula_39\nAs formula_21 approaches formula_25, formula_42 approaches formula_38. Therefore, formula_44. This proof can be generalised to show that formula_45 if formula_46 and formula_47 are constants. This is known as the power rule. For example, formula_48. However, many other functions cannot be differentiated as easily as polynomial functions, meaning that sometimes further techniques are needed to find the derivative of a function. These techniques include the chain rule, product rule, and quotient rule. Other functions cannot be differentiated at all, giving rise to the concept of differentiability.\nA closely related concept to the derivative of a function is its differential. When \"x\" and \"y\" are real variables, the derivative of \"f\" at \"x\" is the slope of the tangent line to the graph of \"f\" at \"x\". Because the source and target of \"f\" are one-dimensional, the derivative of \"f\" is a real number. If \"x\" and \"y\" are vectors, then the best linear approximation to the graph of \"f\" depends on how \"f\" changes in several directions at once. Taking the best linear approximation in a single direction determines a partial derivative, which is usually denoted . The linearization of \"f\" in all directions at once is called the total derivative.\nHistory of differentiation.\nThe concept of a derivative in the sense of a tangent line is a very old one, familiar to ancient Greek mathematicians such as Euclid (c. 300 BC), Archimedes (c. 287\u2013212 BC), and Apollonius of Perga (c. 262\u2013190 BC). Archimedes also made use of indivisibles, although these were primarily used to study areas and volumes rather than derivatives and tangents (see \"The Method of Mechanical Theorems\"). \nThe use of infinitesimals to compute rates of change was developed significantly by Bh\u0101skara II (1114\u20131185); indeed, it has been argued that many of the key notions of differential calculus can be found in his work, such as \"Rolle's theorem\".\nThe mathematician, Sharaf al-D\u012bn al-T\u016bs\u012b (1135\u20131213), in his \"Treatise on Equations\", established conditions for some cubic equations to have solutions, by finding the maxima of appropriate cubic polynomials. He obtained, for example, that the maximum (for positive x) of the cubic \"ax\"2 \u2013 \"x\"3 occurs when \"x\" \n 2\"a\" / 3, and concluded therefrom that the equation \"ax\"2 \n \"x\"3 + c has exactly one positive solution when \"c\" \n 4\"a\"3 / 27, and two positive solutions whenever 0 &lt; \"c\" &lt; 4\"a\"3 / 27. The historian of science, Roshdi Rashed, has argued that al-T\u016bs\u012b must have used the derivative of the cubic to obtain this result. Rashed's conclusion has been contested by other scholars, however, who argue that he could have obtained the result by other methods which do not require the derivative of the function to be known.\nThe modern development of calculus is usually credited to Isaac Newton (1643\u20131727) and Gottfried Wilhelm Leibniz (1646\u20131716), who provided independent and unified approaches to differentiation and derivatives. The key insight, however, that earned them this credit, was the fundamental theorem of calculus relating differentiation and integration: this rendered obsolete most previous methods for computing areas and volumes. For their ideas on derivatives, both Newton and Leibniz built on significant earlier work by mathematicians such as Pierre de Fermat (1607-1665), Isaac Barrow (1630\u20131677), Ren\u00e9 Descartes (1596\u20131650), Christiaan Huygens (1629\u20131695), Blaise Pascal (1623\u20131662) and John Wallis (1616\u20131703). Regarding Fermat's influence, Newton once wrote in a letter that \"I had the hint of this method [of fluxions] from Fermat's way of drawing tangents, and by applying it to abstract equations, directly and invertedly, I made it general.\" Isaac Barrow is generally given credit for the early development of the derivative. Nevertheless, Newton and Leibniz remain key figures in the history of differentiation, not least because Newton was the first to apply differentiation to theoretical physics, while Leibniz systematically developed much of the notation still used today.\nSince the 17th century many mathematicians have contributed to the theory of differentiation. In the 19th century, calculus was put on a much more rigorous footing by mathematicians such as Augustin Louis Cauchy (1789\u20131857), Bernhard Riemann (1826\u20131866), and Karl Weierstrass (1815\u20131897). It was also during this period that the differentiation was generalized to Euclidean space and the complex plane.\nThe 20th century brought two major steps towards our present understanding and practice of derivation : Lebesgue integration, besides extending integral calculus to many more functions, clarified the relation between derivation and integration with the notion of absolute continuity. Later the theory of distributions (after Laurent Schwartz) extended derivation to generalized functions (e.g., the Dirac delta function previously introduced in Quantum Mechanics) and became fundamental to nowadays applied analysis especially by the use of weak solutions to partial differential equations.\nApplications of derivatives.\nOptimization.\nIf \"f\" is a differentiable function on \u211d (or an open interval) and \"x\" is a local maximum or a local minimum of \"f\", then the derivative of \"f\" at \"x\" is zero. Points where \"f'\"(\"x\") \n 0 are called \"critical points\" or \"stationary points\" (and the value of \"f\" at \"x\" is called a critical value). If \"f\" is not assumed to be everywhere differentiable, then points at which it fails to be differentiable are also designated critical points.\nIf \"f\" is twice differentiable, then conversely, a critical point \"x\" of \"f\" can be analysed by considering the second derivative of \"f\" at \"x\" :\n \"x\"3 has a critical point at \"x\" \n 0, but it has neither a maximum nor a minimum there, whereas \"f\"(\"x\") \n \u00b1 \"x\"4 has a critical point at \"x\" \n 0 and a minimum and a maximum, respectively, there.)\nThis is called the second derivative test. An alternative approach, called the first derivative test, involves considering the sign of the \"f'\" on each side of the critical point.\nTaking derivatives and solving for critical points is therefore often a simple way to find local minima or maxima, which can be useful in optimization. By the extreme value theorem, a continuous function on a closed interval must attain its minimum and maximum values at least once. If the function is differentiable, the minima and maxima can only occur at critical points or endpoints.\nThis also has applications in graph sketching: once the local minima and maxima of a differentiable function have been found, a rough plot of the graph can be obtained from the observation that it will be either increasing or decreasing between critical points.\nIn higher dimensions, a critical point of a scalar valued function is a point at which the gradient is zero. The second derivative test can still be used to analyse critical points by considering the eigenvalues of the Hessian matrix of second partial derivatives of the function at the critical point. If all of the eigenvalues are positive, then the point is a local minimum; if all are negative, it is a local maximum. If there are some positive and some negative eigenvalues, then the critical point is called a \"saddle point\", and if none of these cases hold (i.e., some of the eigenvalues are zero) then the test is considered to be inconclusive.\nCalculus of variations.\nOne example of an optimization problem is: Find the shortest curve between two points on a surface, assuming that the curve must also lie on the surface. If the surface is a plane, then the shortest curve is a line. But if the surface is, for example, egg-shaped, then the shortest path is not immediately clear. These paths are called geodesics, and one of the most fundamental problems in the calculus of variations is finding geodesics. Another example is: Find the smallest area surface filling in a closed curve in space. This surface is called a minimal surface and it, too, can be found using the calculus of variations.\nPhysics.\nCalculus is of vital importance in physics: many physical processes are described by equations involving derivatives, called differential equations. Physics is particularly concerned with the way quantities change and develop over time, and the concept of the \"time derivative\" \u2014 the rate of change over time \u2014 is essential for the precise definition of several important concepts. In particular, the time derivatives of an object's position are significant in Newtonian physics:\nFor example, if an object's position on a line is given by\n formula_49\nthen the object's velocity is\n formula_50\nand the object's acceleration is\n formula_51\nwhich is constant.\nDifferential equations.\nA differential equation is a relation between a collection of functions and their derivatives. An ordinary differential equation is a differential equation that relates functions of one variable to their derivatives with respect to that variable. A partial differential equation is a differential equation that relates functions of more than one variable to their partial derivatives. Differential equations arise naturally in the physical sciences, in mathematical modelling, and within mathematics itself. For example, Newton's second law, which describes the relationship between acceleration and force, can be stated as the ordinary differential equation\nformula_52\nThe heat equation in one space variable, which describes how heat diffuses through a straight rod, is the partial differential equation\nformula_53\nHere \"u\"(\"x\",\"t\") is the temperature of the rod at position \"x\" and time \"t\" and \"\u03b1\" is a constant that depends on how fast heat diffuses through the rod.\nMean value theorem.\nThe mean value theorem gives a relationship between values of the derivative and values of the original function. If \"f\"(\"x\") is a real-valued function and \"a\" and \"b\" are numbers with \"a\" &lt; \"b\", then the mean value theorem says that under mild hypotheses, the slope between the two points (\"a\", \"f\"(\"a\")) and (\"b\", \"f\"(\"b\")) is equal to the slope of the tangent line to \"f\" at some point \"c\" between \"a\" and \"b\". In other words,\nformula_54\nIn practice, what the mean value theorem does is control a function in terms of its derivative. For instance, suppose that \"f\" has derivative equal to zero at each point. This means that its tangent line is horizontal at every point, so the function should also be horizontal. The mean value theorem proves that this must be true: The slope between any two points on the graph of \"f\" must equal the slope of one of the tangent lines of \"f\". All of those slopes are zero, so any line from one point on the graph to another point will also have slope zero. But that says that the function does not move up or down, so it must be a horizontal line. More complicated conditions on the derivative lead to less precise but still highly useful information about the original function.\nTaylor polynomials and Taylor series.\nThe derivative gives the best possible linear approximation of a function at a given point, but this can be very different from the original function. One way of improving the approximation is to take a quadratic approximation. That is to say, the linearization of a real-valued function \"f\"(\"x\") at the point \"x\"0 is a linear polynomial \"a\" + \"b\"(\"x\" \u2212 \"x\"0), and it may be possible to get a better approximation by considering a quadratic polynomial \"a\" + \"b\"(\"x\" \u2212 \"x\"0) + \"c\"(\"x\" \u2212 \"x\"0)2. Still better might be a cubic polynomial \"a\" + \"b\"(\"x\" \u2212 \"x\"0) + \"c\"(\"x\" \u2212 \"x\"0)2 + \"d\"(\"x\" \u2212 \"x\"0)3, and this idea can be extended to arbitrarily high degree polynomials. For each one of these polynomials, there should be a best possible choice of coefficients \"a\", \"b\", \"c\", and \"d\" that makes the approximation as good as possible.\nIn the neighbourhood of \"x\"0, for \"a\" the best possible choice is always \"f\"(\"x\"0), and for \"b\" the best possible choice is always \"f'\"(\"x\"0). For \"c\", \"d\", and higher-degree coefficients, these coefficients are determined by higher derivatives of \"f\". \"c\" should always be , and \"d\" should always be . Using these coefficients gives the Taylor polynomial of \"f\". The Taylor polynomial of degree \"d\" is the polynomial of degree \"d\" which best approximates \"f\", and its coefficients can be found by a generalization of the above formulas. Taylor's theorem gives a precise bound on how good the approximation is. If \"f\" is a polynomial of degree less than or equal to \"d\", then the Taylor polynomial of degree \"d\" equals \"f\".\nThe limit of the Taylor polynomials is an infinite series called the Taylor series. The Taylor series is frequently a very good approximation to the original function. Functions which are equal to their Taylor series are called analytic functions. It is impossible for functions with discontinuities or sharp corners to be analytic; moreover, there exist smooth functions which are also not analytic.\nImplicit function theorem.\nSome natural geometric shapes, such as circles, cannot be drawn as the graph of a function. For instance, if \"f\"(\"x\", \"y\") \n \"x\"2 + \"y\"2 \u2212 1, then the circle is the set of all pairs (\"x\", \"y\") such that \"f\"(\"x\", \"y\") \n 0. This set is called the zero set of \"f\", and is not the same as the graph of \"f\", which is a paraboloid. The implicit function theorem converts relations such as \"f\"(\"x\", \"y\") \n 0 into functions. It states that if \"f\" is continuously differentiable, then around most points, the zero set of \"f\" looks like graphs of functions pasted together. The points where this is not true are determined by a condition on the derivative of \"f\". The circle, for instance, can be pasted together from the graphs of the two functions . In a neighborhood of every point on the circle except (\u22121, 0) and (1, 0), one of these two functions has a graph that looks like the circle. (These two functions also happen to meet (\u22121, 0) and (1, 0), but this is not guaranteed by the implicit function theorem.)\nThe implicit function theorem is closely related to the inverse function theorem, which states when a function looks like graphs of invertible functions pasted together.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50417", "revid": "41195652", "url": "https://en.wikipedia.org/wiki?curid=50417", "title": "Integral calculus", "text": ""}
{"id": "50419", "revid": "19569748", "url": "https://en.wikipedia.org/wiki?curid=50419", "title": "Form of government", "text": ""}
{"id": "50420", "revid": "31831", "url": "https://en.wikipedia.org/wiki?curid=50420", "title": "Billie Holiday", "text": "American jazz singer (1915\u20131959)\nBillie Holiday (born Eleanora Fagan; April 7, 1915 \u2013 July 17, 1959) was an American jazz and swing music singer. Nicknamed \"Lady Day\" by her friend and music partner, Lester Young, Holiday made significant contributions to jazz music and pop singing. Her vocal style, strongly influenced by jazz instrumentalists, inspired a new way of manipulating phrasing and tempo. Holiday was known for her vocal delivery and improvisational skills.\nAfter a turbulent childhood, Holiday began singing in nightclubs in Harlem where she was heard by producer John Hammond, who liked her voice. Holiday signed a recording contract with Brunswick in 1935. Her collaboration with Teddy Wilson produced the hit \"What a Little Moonlight Can Do\", which became a jazz standard. Throughout the 1930s and 1940s, Holiday had mainstream success on labels such as Columbia and Decca. However, by the late 1940s, she was beset with legal troubles and drug abuse. After a short prison sentence, Holiday performed a sold-out concert at Carnegie Hall.\nShe was a successful concert performer throughout the 1950s, with two further sold-out shows at Carnegie Hall. Because of personal struggles and an altered voice, Holiday's final recordings were met with mixed reaction, but were mild commercial successes. Her final album, \"Lady in Satin\", was released in 1958. Holiday died of cirrhosis and heart failure on July 17, 1959, at age 44.\nHoliday won four Grammy Awards, all of them posthumously, for Best Historical Album. She was inducted into the Grammy Hall of Fame and the National Rhythm &amp; Blues Hall of Fame. In 2000, Holiday was also inducted into the Rock and Roll Hall of Fame as an early influence; their website states that \"Billie Holiday changed jazz forever\". She was named one of the 50 Great Voices by NPR and was ranked fourth on the \"Rolling Stone\" list of \"200 Greatest Singers of All Time\" (2023). Several films about Holiday's life have been released, most recently \"The United States vs. Billie Holiday\" (2021).\nLife and career.\n1915\u20131929: Childhood.\nEleanora Fagan was born on April 7, 1915, in Philadelphia to African American unwed teenage couple Clarence Halliday and Sarah Julia \"Sadie\" Fagan (n\u00e9e Harris). Her mother moved to Philadelphia at age 19, after being evicted from her parents' home in the Sandtown-Winchester neighborhood of Baltimore, Maryland, for becoming pregnant. With no support from her parents, Sarah made arrangements with her older married half-sister, Eva Miller, for Holiday to stay with her in Baltimore. \nShortly after Holiday was born, her father abandoned his family to pursue a career as a jazz banjo player and guitarist. Some historians have disputed Holiday's paternity, as a copy of her birth certificate in the Baltimore archives lists her father as \"Frank DeViese\". Other historians consider this an anomaly, probably inserted by a hospital or government worker. DeViese lived in Philadelphia, and Sadie, then known by her maiden name Harris, may have met him through her work. Harris married Philip Gough in 1920, but the marriage only lasted a few years.\nHoliday grew up in Baltimore and had a very difficult childhood. Her mother often took what were then known as \"transportation jobs\", serving on passenger railroads. Holiday was raised largely by Eva Miller's mother-in-law, Martha Miller, and suffered from her mother's absences and being in others' care for her first decade of life. Holiday's autobiography, \"Lady Sings the Blues\", published in 1956, is inconsistent regarding details of her early life, but much was confirmed by Stuart Nicholson in his 1995 biography of the singer.\nAt the age of nine Holiday attended school at Saint Frances Academy in Baltimore, frequently skipping classes, which resulted in her being brought before the juvenile court at age nine. She was sent to the House of the Good Shepherd, a Catholic reform school for girls, where the nuns locked her in a room with a dead girl overnight as punishment for misbehavior. The experience traumatized her, and for years she would \"dream about it and wake up hollering and screaming\". After nine months, she was released on October 3, 1925, to her mother. Sadie had opened a restaurant, the East Side Grill, and they worked long hours there. She dropped out of school at age 11.\nOn December 24, 1926, Harris came home to discover a neighbor attempting to rape Holiday. She successfully fought back, and he was arrested. Officials sent Holiday back to the House of the Good Shepherd under protective custody as a state witness in the rape case. Holiday was released in February 1927, when she was nearly 12. She found a job running errands in a brothel, and she scrubbed marble steps as well as kitchen and bathroom floors of neighborhood homes. Around this time, she first heard the records of Louis Armstrong and Bessie Smith. In particular, Holiday cited \"West End Blues\" as an intriguing influence, pointing specifically to the scat section duet with the clarinet as her favorite part. By the end of 1928, Holiday's mother moved to Harlem, New York, again leaving Holiday with Martha Miller. By early 1929, Holiday had joined her mother in Harlem.\n1929\u20131935: Early career.\nAs a young teenager, Holiday started singing in nightclubs in Harlem. She took her professional pseudonym from Billie Dove, an actress she admired, and Clarence Halliday, her father. At the outset of her career, she spelled her last name \"Halliday\", her father's birth surname, but eventually changed it to \"Holiday\", his performing name. The young singer teamed up with a neighbor, tenor saxophone player Kenneth Hollan. They were a team from 1929 to 1931, performing at clubs such as the Grey Dawn, Pod's and Jerry's on 133rd Street, and the Brooklyn Elks Club. Benny Goodman recalled hearing Holiday in 1931 at the Bright Spot. As her reputation grew, she played in many clubs, including the Mexico's and the Alhambra Bar and Grill, where she met Charles Linton, a vocalist who later worked with Chick Webb. It was also during this period that she connected with her father, who was playing in Fletcher Henderson's band.\nLate in 1932, 17-year-old Holiday replaced the singer Monette Moore at Covan's, a club on West 132nd Street. Producer John Hammond, who loved Moore's singing and had come to hear her, first heard Holiday there in early 1933. Hammond arranged for Holiday to make her recording debut at age 18, in November 1933, with Benny Goodman. She recorded two songs: \"Your Mother's Son-In-Law\" and \"Riffin' the Scotch\", the latter being her first hit. \"Son-in-Law\" sold 300 copies, and \"Riffin' the Scotch\", released on November 11, sold 5,000 copies. Hammond was impressed by Holiday's singing style and said of her, \"Her singing almost changed my music tastes and my musical life, because she was the first girl singer I'd come across who actually sang like an improvising jazz genius.\" Hammond compared Holiday favorably to Armstrong and said she had a good sense of lyric content at a young age.\nIn 1935, Holiday had a small role as a woman abused by her lover in Duke Ellington's musical short film \"Symphony in Black: A Rhapsody of Negro Life\". She sang \"Saddest Tale\" in her scene.\n1935\u20131938: Recordings with Teddy Wilson.\nIn 1935, Holiday was signed to Brunswick by John Hammond to record pop tunes with pianist Teddy Wilson in the swing style for the growing jukebox trade. They were allowed to improvise on the material. Holiday's improvisation of melody to fit the emotion was highly skillful. Their first collaboration included \"What a Little Moonlight Can Do\" and \"Miss Brown to You\". \"What a Little Moonlight Can Do\" has been deemed her \"claim to fame\". Brunswick did not favor the recording session because producers wanted Holiday to sound more like Cleo Brown. However, after \"What a Little Moonlight Can Do\" was successful, the company began considering Holiday an artist in her own right. She began recording under her own name a year later for Vocalion in sessions produced by Hammond and Bernie Hanighen. Hammond said the Wilson-Holiday records from 1935 to 1938 were a great asset to Brunswick. According to Hammond, Brunswick was broke and unable to record many jazz tunes. Wilson, Holiday, Young, and other musicians came into the studio without written arrangements, reducing the recording cost. Brunswick paid Holiday a flat fee rather than royalties, which saved the company money. \"I Cried for You\" sold 15,000 copies, which Hammond called \"a giant hit for Brunswick... Most records that made money sold around three to four thousand.\"\nAnother frequent accompanist was tenor saxophonist Lester Young, who had been a boarder at her mother's house in 1934 and with whom Holiday had a rapport. Young said, \"I think you can hear that on some of the old records, you know. Some time I'd sit down and listen to 'em myself, and it sound like two of the same voices\u00a0... or the same mind, or something like that.\" Young nicknamed her \"Lady Day\", and she called him \"Prez\".\n1937\u20131938: Working for Count Basie and Artie Shaw.\nIn late 1937, Holiday had a brief stint as a big-band vocalist with Count Basie. The traveling conditions of the band were often poor; they performed many one-nighters in clubs, moving from city to city with little stability. Holiday chose the songs she sang and had a hand in the arrangements, choosing to portray her developing persona of a woman unlucky in love. Her tunes included \"I Must Have That Man\", \"Travelin' All Alone\", \"I Can't Get Started\", and \"Summertime\", a hit for Holiday in 1936, originating in George Gershwin's \"Porgy and Bess\" the year before. Basie became used to Holiday's heavy involvement in the band. He said, \"When she rehearsed with the band, it was really just a matter of getting her tunes like she wanted them, because she knew how she wanted to sound and you couldn't tell her what to do.\" Some of the songs Holiday performed with Basie were recorded. \"I Can't Get Started\", \"They Can't Take That Away from Me\", and \"Swing It Brother Swing\" are all commercially available. Holiday was unable to record in the studio with Basie, but she included many of his musicians in her recording sessions with Teddy Wilson.\nHoliday found herself in direct competition with the popular singer Ella Fitzgerald. The two later became friends. Fitzgerald was the vocalist for the Chick Webb Band, which was in competition with the Basie band. On January 16, 1938, the same day that Benny Goodman performed his legendary Carnegie Hall jazz concert, the Basie and Webb bands had a battle at the Savoy Ballroom. Webb and Fitzgerald were declared winners by \"Metronome\" magazine, while \"DownBeat\" magazine pronounced Holiday and Basie the winners. Fitzgerald won a straw poll of the audience by a three-to-one margin.\nBy February 1938, Holiday was no longer singing for Basie. Various reasons have been given for why she was fired. Jimmy Rushing, Basie's male vocalist, called her unprofessional. According to All Music Guide, Holiday was fired for being \"temperamental and unreliable\". She complained of low pay and poor working conditions and may have refused to sing the songs requested of her or change her style. Holiday was hired by Artie Shaw a month after being fired from the Count Basie Band. This association placed her among the first black women to work with a white orchestra, an unusual arrangement at that time. This was also the first time a black female singer employed full-time toured the segregated U.S. South with a white bandleader. When Holiday faced racism, Shaw would often stick up for his vocalist. In her autobiography, Holiday describes an incident in which she was not permitted to sit on the bandstand with other vocalists because of racist policies. Shaw said to her, \"I want you on the band stand like Helen Forrest, Tony Pastor and everyone else.\" When touring the South, Holiday would sometimes be heckled by members of the audience. In Louisville, Kentucky, a man called her a \"nigger wench\" and requested she sing another song. Holiday lost her temper and had to be escorted off the stage.\nBy March 1938, Shaw and Holiday had been broadcast on New York City's powerful radio station WABC (the original WABC, now WCBS). Because of their success, they were given an extra time slot to broadcast in April, which increased their exposure. The \"New York Amsterdam News\" reviewed the broadcasts and reported an improvement in Holiday's performance. \"Metronome\" reported that the addition of Holiday to Shaw's band put it in the \"top brackets\". Holiday could not sing as often during Shaw's shows as she could in Basie's; the repertoire was more instrumental, with fewer vocals. Shaw was also pressured to hire a white singer, Nita Bradley, with whom Holiday did not get along but had to share a bandstand. In May 1938, Shaw won band battles against Tommy Dorsey and Red Norvo, with the audience favoring Holiday. Although Shaw admired Holiday's singing in his band, saying she had a \"remarkable ear\" and a \"remarkable sense of time\", her tenure with the band was nearing an end. In November 1938, Holiday was asked to use the service elevator at the Lincoln Hotel in New York City, instead of the one used by hotel guests, because white patrons of the hotels complained. This may have been the last straw for her. She left the band shortly after. Holiday spoke about the incident weeks later, saying, \"I was never allowed to visit the bar or the dining room as did other members of the band ... [and] I was made to leave and enter through the kitchen.\" There are no surviving live recordings of Holiday with Shaw's band. Because she was under contract to a different record label and possibly because of her race, Holiday was able to make only one record with Shaw, \"Any Old Time\". However, Shaw played clarinet on four songs she recorded in New York on July 10, 1936: \"Did I Remember?\", \"No Regrets\", \"Summertime\" and \"Billie's Blues\".\nBy the late 1930s, Holiday had toured with Count Basie and Artie Shaw, scored a string of radio and retail hits with Teddy Wilson, and became an established artist in the recording industry. Her songs \"What a Little Moonlight Can Do\" and \"Easy Living\" were imitated by singers across America and were quickly becoming jazz standards. In September 1938, Holiday's single \"I'm Gonna Lock My Heart\" ranked sixth as the most-played song that month. Her record label, Vocalion, listed the single as its fourth-best seller for the same month, and it peaked at number 2 on the pop charts, according to Joel Whitburn's \"Pop Memories: 1890\u20131954\".\n1939: \"Strange Fruit\" and Commodore Records.\nHoliday was in the middle of recording for Columbia in the late 1930s when she was introduced to \"Strange Fruit\", a song by Abel Meeropol based on his poem about lynching. Meeropol, a Jewish schoolteacher from the Bronx, used the pseudonym \"Lewis Allan\" for the poem, which was set to music and performed at teachers' union meetings. It was eventually heard by Barney Josephson, the proprietor of Caf\u00e9 Society, an integrated nightclub in Greenwich Village, who introduced it to Holiday. She performed it at the club in 1939, with some trepidation, fearing possible retaliation. She later said that the imagery of the song reminded her of her father's death and that this played a role in her resistance to performing it.\nFor her performance of \"Strange Fruit\" at the Caf\u00e9 Society, she had waiters silence the crowd when the song began. During the song's long introduction, the lights dimmed and all movement had to cease. As Holiday began singing, only a small spotlight illuminated her face. On the final note, all lights went out, and when they came back on, Holiday was gone. Holiday said her father, Clarence Holiday, was denied medical treatment for a fatal lung disorder because of racial prejudice, and that singing \"Strange Fruit\" reminded her of the incident. \"It reminds me of how Pop died, but I have to keep singing it, not only because people ask for it, but because twenty years after Pop died the things that killed him are still happening in the South\", she wrote in her autobiography. When Holiday's producers at Columbia found the subject matter too sensitive, Milt Gabler agreed to record it for his Commodore Records label on April 20, 1939. \"Strange Fruit\" remained in her repertoire for 20 years. She recorded it again for Verve. The Commodore release did not get any airplay, but the controversial song sold well, though Gabler attributed that mostly to the record's other side, \"Fine and Mellow\", which was a jukebox hit. \"The version I recorded for Commodore\", Holiday said of \"Strange Fruit\", \"became my biggest-selling record\". \"Strange Fruit\" was the equivalent of a top-twenty hit in the 1930s, selling a million records.\nHoliday's popularity increased after \"Strange Fruit\". She received a mention in \"Time\" magazine. \"I open Caf\u00e9 Society as an unknown\", Holiday said. \"I left two years later as a star. I needed the prestige and publicity all right, but you can't pay rent with it.\" She soon demanded a raise from her manager, Joe Glaser. Holiday returned to Commodore in 1944, recording songs she made with Teddy Wilson in the 1930s, including \"I Cover the Waterfront\", \"I'll Get By\", and \"He's Funny That Way\". She also recorded new songs that were popular at the time, including, \"My Old Flame\", \"How Am I to Know?\", \"I'm Yours\", and \"I'll Be Seeing You\", a number one hit for Bing Crosby. She also recorded her version of \"Embraceable You\", which was inducted into the Grammy Hall of Fame in 2005.\n1940\u20131947: Commercial success.\nHoliday's mother Sadie, nicknamed \"The Duchess\", opened a restaurant called Mom Holiday's. She used money from her daughter while playing dice with members of the Count Basie band, with whom she toured in the late 1930s. \"It kept Mom busy and happy and stopped her from worrying and watching over me\", Holiday said. Fagan began borrowing large amounts from Holiday to support the restaurant. Holiday obliged but soon fell on hard times herself. \"I needed some money one night and I knew Mom was sure to have some\", she said. \"So I walked in the restaurant like a stockholder and asked. Mom turned me down flat. She wouldn't give me a cent.\" The two argued, and Holiday shouted angrily, \"God bless the child that's got his own\", and stormed out. With Arthur Herzog Jr., a pianist, she wrote a song based on the lyric, \"God Bless the Child\", and added music. \"God Bless the Child\" became Holiday's most popular and most covered record. It reached number 25 on the charts in 1941 and was third in \"Billboard\"'s songs of the year, selling over a million records. In 1976, the song was added to the Grammy Hall of Fame. Herzog claimed Holiday contributed only a few lines to the lyrics. He said she came up with the line \"God bless the child\" from a dinner conversation the two had had.\nOn June 12, 1942, in Los Angeles, Holiday recorded \"Trav'lin Light\" with Paul Whiteman for a new label, Capitol Records. Because she was under contract to Columbia, she used the pseudonym \"Lady Day\". The song reached number 23 on the pop charts and number one on the R&amp;B charts, then called the Harlem Hit Parade. On October 11, 1943, \"Life\" magazine wrote, \"She has the most distinctive style of any popular vocalist, [and] is imitated by other vocalists.\"\nMilt Gabler, in addition to owning Commodore Records, became an A&amp;R man for Decca Records. He signed Holiday to Decca on August 7, 1944, when she was 29. Her first Decca recording was \"Lover Man\" (number 16 Pop, number 5 R&amp;B), one of her biggest hits. The success and distribution of the song made Holiday a staple in the pop community, leading to solo concerts, rare for jazz singers in the late 1940s. Gabler said, \"I made Billie a real pop singer. That was right in her. Billie loved those songs.\" Jimmy Davis and Roger \"Ram\" Ramirez, the song's writers, had tried to interest Holiday in the song. In 1943, a flamboyant male torch singer, Willie Dukes, began singing \"Lover Man\" on 52nd Street. Because of his success, Holiday added it to her shows. The record's flip side was \"No More\", one of her favorites. Holiday asked Gabler for strings on the recording. Such arrangements were associated with Frank Sinatra and Ella Fitzgerald. \"I went on my knees to him\", Holiday said. \"I didn't want to do it with the ordinary six pieces. I begged Milt and told him I had to have strings behind me.\" On October 4, 1944, Holiday entered the studio to record \"Lover Man\", saw the string ensemble and walked out. The musical director, Toots Camarata, said Holiday was overwhelmed with joy. She may also have wanted strings to avoid comparisons between her commercially successful early work with Teddy Wilson and everything produced afterwards. Her 1930s recordings with Wilson used a small jazz combo; recordings for Decca often involved strings. A month later, in November, Holiday returned to Decca to record \"That Ole Devil Called Love\", \"Big Stuff\", and \"Don't Explain\". She wrote \"Don't Explain\" after she caught her husband, Jimmy Monroe, with lipstick on his collar.\nHoliday did not make any more records until August 1945, when she recorded \"Don't Explain\" for a second time, changing the lyrics \"I know you raise Cain\" to \"Just say you'll remain\" and changing \"You mixed with some dame\" to \"What is there to gain?\" Other songs recorded were \"Big Stuff\", \"What Is This Thing Called Love?\", and \"You Better Go Now\". Ella Fitzgerald named \"You Better Go Now\" her favorite recording of Holiday's. \"Big Stuff\" and \"Don't Explain\" were recorded again but with additional strings and a viola. In 1946, Holiday recorded \"Good Morning Heartache\". Although the song failed to chart, she sang it in live performances; three live recordings are known.\nIn September 1946, Holiday began her only major film, \"New Orleans\", in which she starred opposite Louis Armstrong and Woody Herman. Plagued by racism and McCarthyism, producer Jules Levey and script writer Herbert Biberman were pressed to lessen Holiday's and Armstrong's roles to avoid the impression that black people created jazz. The attempts failed because in 1947 Biberman was listed as one of the Hollywood Ten and sent to jail. Several scenes were deleted from the film. \"They had taken miles of footage of music and scenes\", Holiday said, but \"none of it was left in the picture. And very damn little of me. I know I wore a white dress for a number I did... and that was cut out of the picture.\" She recorded \"The Blues Are Brewin'\" for the film's soundtrack. Other songs included in the movie are \"Do You Know What It Means to Miss New Orleans?\" and \"Farewell to Storyville\". Holiday's drug addictions were a problem on the set. She earned more than one thousand dollars per week from club ventures but spent most of it on heroin. Her lover, Joe Guy, traveled to Hollywood while Holiday was filming and supplied her with drugs. Guy was banned from the set when he was found there by Holiday's manager, Joe Glaser.\nBy the late 1940s, Holiday had begun recording a number of slow, sentimental ballads. \"Metronome\" expressed its concerns in 1946 about \"Good Morning Heartache\", saying, \"there's a danger that Billie's present formula will wear thin, but up to now it's wearing well.\" The \"New York Herald Tribune\" reported of a concert in 1946 that her performance had little variation in melody and no change in tempo.\n1947\u20131952: Legal issues and Carnegie Hall concert.\nBy 1947, Holiday was at her commercial peak, having made $250,000 in the three previous years. She was ranked second in the \"DownBeat\" poll for 1946 and 1947, her highest ranking in that poll. She was ranked fifth in \"Billboard\"'s annual college poll of \"girl singers\" on July 6, 1947 (Jo Stafford was first). In 1946, Holiday won the \"Metronome\" magazine popularity poll.\nOn May 16, 1947, Holiday was arrested for possession of narcotics in her New York apartment. On May 27, she was in court. \"It was called 'The United States of America versus Billie Holiday'. And that's just the way it felt\", she recalled. During the trial, she heard that her lawyer would not come to the trial to represent her. \"In plain English, that meant no one in the world was interested in looking out for me,\" she said. Dehydrated and unable to hold down food, she pleaded guilty and asked to be sent to the hospital. The district attorney spoke in her defense, saying, \"If your honor please, this is a case of a drug addict, but more serious, however, than most of our cases, Miss Holiday is a professional entertainer and among the higher rank as far as income was concerned.\" She was sentenced to Alderson Federal Prison Camp in West Virginia. The drug possession conviction caused her to lose her New York City Cabaret Card, preventing her from working anywhere that sold alcohol; thereafter, she performed in concert venues and theaters.\nAccording to writer and journalist Johann Hari, the Federal Bureau of Narcotics\u2013under Harry J. Anslinger\u2013had been targeting Holiday since at least 1939, when she started to perform \"Strange Fruit\". However, according to author Lewis Porter, there was no federal campaign to stop Holiday from singing the song. Porter writes that Johann Hari's 2015 book, \"Chasing the Scream: The First and Last Days of the War on Drugs\", is where the allegation that Holiday was targeted for singing \"Strange Fruit\" originated and that this claim did not appear anywhere else before that. Narcotics police went to her hospital room, claiming they had found heroin in her bedroom. A grand jury was summoned to indict her. Holiday was subsequently arrested, handcuffed to her bed, and placed under police guard.\nHoliday was released early (on March 16, 1948) because of good behavior. When she arrived at Newark, her pianist Bobby Tucker and her dog Mister were waiting. The dog leaped at Holiday, knocking off her hat, and tackling her to the ground. \"He began lapping me and loving me like crazy\", she said. A woman thought the dog was attacking Holiday. She screamed, a crowd gathered, and reporters arrived. \"I might just as well have wheeled into Penn Station and had a quiet little get-together with the Associated Press, United Press, and International News Service\", she said.\nEd Fishman (who had competed with Joe Glaser to be Holiday's manager) thought of a comeback concert at Carnegie Hall. Holiday hesitated, unsure audiences would accept her after the arrest. She gave in and agreed to appear. On March 27, 1948, Holiday played Carnegie Hall to a sold-out crowd. Two thousand seven hundred tickets were sold in advance, a record at the time for the venue. Her popularity was unusual because she did not have a current hit record. Her last record to reach the charts was \"Lover Man\" in 1945. Holiday sang 32 songs at the Carnegie concert by her count, including Cole Porter's \"Night and Day\" and her 1930s hit, \"Strange Fruit\". During the show, someone sent her a box of gardenias. \"My old trademark\", Holiday said. \"I took them out of box and fastened them smack to the side of my head without even looking twice.\" There was a hatpin in the gardenias and Holiday unknowingly stuck it into the side of her head. \"I didn't feel anything until the blood started rushing down in my eyes and ears\", she said. After the third curtain call, she passed out.\nOn April 27, 1948, Bob Sylvester and her promoter Al Wilde arranged a Broadway show for her. Titled \"Holiday on Broadway\", it sold out. \"The regular music critics and drama critics came and treated us like we were legit\", she said. But it closed after three weeks.\nHoliday was arrested again on January 22, 1949, in her room at the Hotel Mark Twain in San Francisco by George Hunter White. Holiday said she began using hard drugs in the early 1940s. She married trombonist Jimmy Monroe on August 25, 1941. While still married, she became involved with trumpeter Joe Guy who was also her drug dealer. She divorced Monroe in 1947 and also split with Guy.\nIn October 1949, Holiday recorded \"Crazy He Calls Me\", which was inducted into the Grammy Hall of Fame in 2010. Gabler said the hit was her most successful recording for Decca after \"Lover Man\". The charts of the 1940s did not list songs outside the top 30, making it impossible to recognize minor hits. By the late 1940s, despite her popularity and concert power, her singles were infrequently played on radio, perhaps because of her reputation.\nIn 1948, Holiday played at the Ebony Club, which was against the law. Her manager, John Levy, was convinced he could get her card back and allowed her to open without one. \"I opened scared\", Holiday said, \"[I was] expecting the cops to come in any chorus and carry me off. But nothing happened. I was a huge success.\"\nHoliday recorded Gershwin's \"I Loves You, Porgy\" in 1948. In 1950, Holiday appeared in the Universal short film \"Sugar Chile Robinson, Billie Holiday, Count Basie and His Sextet\", singing \"God Bless the Child\" and \"Now, Baby or Never\".\nThe loss of her cabaret card reduced Holiday's earnings. She had not received proper record royalties until she joined Decca, so her main revenue was club concerts. The problem worsened when Holiday's records went out of print in the 1950s. She seldom received royalties in her later years. In 1958, she received a royalty of only $11. Her lawyer in the late 1950s, Earle Warren Zaidins, registered with BMI only two songs she had written or co-written, costing her revenue.\n1952\u20131959: \"Lady Sings the Blues\".\nBy the 1950s, Holiday's drug use, drinking, and relationships with abusive men caused her health to deteriorate. She appeared on the ABC reality series \"The Comeback Story\" to discuss attempts to overcome her addictions.\nHoliday first toured Europe in 1954 as part of a Leonard Feather package. The Swedish impresario Nils Hellstrom initiated the \"Jazz Club U.S.A.\" (after the Leonard Feather radio show) tour starting in Stockholm in January 1954 and then Germany, Netherlands, Paris and Switzerland. The tour party was Holiday, Buddy DeFranco, Red Norvo, Carl Drinkard, Elaine Leighton (1926\u20132012), Sonny Clark, Beryl Booker, Jimmy Raney and Red Mitchell. A recording of a live set in Germany was released as \"Lady Love \u2013 Billie Holiday\".\nHoliday's autobiography, \"Lady Sings the Blues\", was ghostwritten by William Dufty and published in 1956. Dufty, a \"New York Post\" writer and editor then married to Holiday's close friend Maely Dufty, wrote the book quickly from a series of conversations with the singer in the Duftys' 93rd Street apartment. He also drew on the work of earlier interviewers and intended to let Holiday tell her story in her own way. In his 2015 study, \"Billie Holiday: The Musician and the Myth\", John Szwed argued that \"Lady Sings the Blues\" is a generally accurate account of her life, but that co-writer Dufty was forced to water down or suppress material by the threat of legal action. According to the reviewer Richard Brody, \"Szwed traces the stories of two important relationships that are missing from the book\u2014with Charles Laughton, in the 1930s, and with Tallulah Bankhead, in the late 1940s\u2014and of one relationship that's sharply diminished in the book, her affair with Orson Welles around the time of 'Citizen Kane'\". The film version of the book was released in 1972, with Diana Ross playing the role of Holiday.\nTo accompany her autobiography, Holiday released the LP \"Lady Sings the Blues\" in June 1956. The album featured four new tracks, \"Lady Sings the Blues\", \"Too Marvelous for Words\", \"Willow Weep for Me\", and \"I Thought About You\", and eight new recordings of her biggest hits to date. The re-recordings included \"Trav'lin' Light\", \"Strange Fruit\", and \"God Bless the Child\". A review of the album was published by \"Billboard\" magazine on December 22, 1956, calling it a worthy musical complement to her autobiography. \"Holiday is in good voice now\", wrote the reviewer, \"and these new readings will be much appreciated by her following\". \"Strange Fruit\" and \"God Bless the Child\" were called classics, and \"Good Morning Heartache\", another reissued track on the LP, was also noted favorably.\nOn November 10, 1956, Holiday performed two concerts before packed audiences at Carnegie Hall. Live recordings of the second Carnegie Hall concert were released on a Verve/His Master's Voice album in the UK in late 1961 called \"\". The 13 tracks included on this album featured her own songs \"I Love My Man\", \"Don't Explain\" and \"Fine and Mellow\", together with other songs closely associated with her, including \"Body and Soul\", \"My Man\", and \"Lady Sings the Blues\" (her lyrics accompanied a tune by pianist Herbie Nichols). The liner notes for this album were written partly by Gilbert Millstein of \"The New York Times\", who, according to these notes, served as narrator of the Carnegie Hall concerts. Interspersed among Holiday's songs, Millstein read aloud four lengthy passages from her autobiography, \"Lady Sings the Blues\". He later wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The narration began with the ironic account of her birth in Baltimore \u2013 'Mom and Pop were just a couple of kids when they got married. He was eighteen, she was sixteen, and I was three' \u2013 and ended, very nearly shyly, with her hope for love and a long life with 'my man' at her side. It was evident, even then, that Miss Holiday was ill. I had known her casually over the years and I was shocked at her physical weakness. Her rehearsal had been desultory; her voice sounded tinny and trailed off; her body sagged tiredly. But I will not forget the metamorphosis that night. The lights went down, the musicians began to play and the narration began. Miss Holiday stepped from between the curtains, into the white spotlight awaiting her, wearing a white evening gown and white gardenias in her black hair. She was erect and beautiful; poised and smiling. And when the first section of narration was ended, she sang \u2013 with strength undiminished \u2013 with all of the art that was hers. I was very much moved. In the darkness, my face burned and my eyes. I recall only one thing. I smiled.\"\nThe critic Nat Hentoff of \"DownBeat\" magazine, who attended the Carnegie Hall concert, wrote the remainder of the sleeve notes on the 1961 album. He wrote of Holiday's performance:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Throughout the night, Billie was in superior form to what had sometimes been the case in the last years of her life. Not only was there assurance of phrasing and intonation; but there was also an outgoing warmth, a palpable eagerness to reach and touch the audience. And there was mocking wit. A smile was often lightly evident on her lips and her eyes as if, for once, she could accept the fact that there were people who did dig her. The beat flowed in her uniquely sinuous, supple way of moving the story along; the words became her own experiences; and coursing through it all was Lady's sound \u2013 a texture simultaneously steel-edged and yet soft inside; a voice that was almost unbearably wise in disillusion and yet still childlike, again at the centre. The audience was hers from before she sang, greeting her and saying good-bye with heavy, loving applause. And at one time, the musicians too applauded. It was a night when Billie was on top, undeniably the best and most honest jazz singer alive.\nHer performance of \"Fine and Mellow\" on CBS's \"The Sound of Jazz\" program is memorable for her interplay with her long-time friend Lester Young. Both were less than two years from death. Young died in March 1959. Holiday wanted to sing at his funeral, but her request was denied. Also in 1957, she sang as a headliner with Dinah Washington and others in \"Jazz Under the Stars\", a summer concert series that took place at the Wollman Memorial Theater in New York City's Central Park.\nWhen Holiday returned to Europe almost five years later, in 1959, she made one of her last television appearances for Granada television's British Cabaret show, \"Chelsea at Nine,\" in London. The show taped what is believed to be the only existing filmed version of Holiday singing \"Strange Fruit\". Her final studio recordings were made for MGM Records in 1959, with lush backing from Ray Ellis and his Orchestra, who had also accompanied her on the Columbia album \"Lady in Satin\" the previous year (see below). The MGM sessions were released posthumously on a self-titled album, later retitled and re-released as \"Last Recording\".\nOn March 28, 1957, Holiday married Louis McKay, a mob enforcer. McKay, like most of the men in her life, was abusive. They were separated at the time of her death, but McKay had plans to start a chain of Billie Holiday vocal studios, on the model of the Arthur Murray dance schools. Holiday was childfree, but she had two godchildren: singer Billie Lorraine Feather (the daughter of Leonard Feather) and Bevan Dufty (the son of William Dufty).\nIllness and death.\nBy early 1959, Holiday was diagnosed with cirrhosis. Although she had initially stopped drinking on her doctor's orders, it was not long before Holiday relapsed. By May 1959, she had lost . Holiday's manager Joe Glaser, jazz critic Leonard Feather, photojournalist Allan Morrison, and the singer's own friends all tried in vain to persuade her to go to a hospital. On May 31, 1959, Holiday was finally taken to Metropolitan Hospital in New York for treatment of both liver and heart disease. While in the hospital, special agents of the Federal Bureau of Narcotics (FBN) came to her hospital room and placed her under house arrest, handcuffing her to the bed, for narcotics possession. On July 15, Holiday received last rites. Two days later, she died at age 44 at 3:10 a.m., of pulmonary edema and heart failure caused by cirrhosis.\nIn her final years, Holiday had been progressively swindled out of her earnings by McKay and she died with $0.70 in the bank ($7.40 in 2023). The story of her burial plot and how it was managed by her estranged husband was documented on NPR in 2012. Her funeral was held on July 21, 1959, at the Church of St. Paul the Apostle in Manhattan. She was buried at Saint Raymond's Cemetery in the Bronx. Michael P. Grace ll, a songwriter and theater producer based in Manhattan, paid for the funeral.\nGilbert Millstein of \"The New York Times\", who was the announcer at Holiday's 1956 Carnegie Hall concerts and wrote parts of the sleeve notes for the album \"The Essential Billie Holiday\", described her death in these sleeve notes, dated 1961:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Billie Holiday died in Metropolitan Hospital, New York, on Friday, July 17, 1959, in the bed in which she had been arrested for illegal possession of narcotics a little more than a month before, as she lay mortally ill; in the room from which a police guard had been removed \u2013 by court order \u2013 only a few hours before her death. She had been strikingly beautiful, but her talent was wasted. The worms of every kind of excess \u2013 drugs were only one \u2013 had eaten her. The likelihood exists that among the last thoughts of this cynical, sentimental, profane, generous and greatly talented woman of 44 was the belief that she was to be arraigned the following morning. She would have been, eventually, although possibly not that quickly. In any case, she removed herself finally from the jurisdiction of any court here below. When Holiday died, \"The New York Times\" published a short obituary on page 15 without a byline. She left an estate of $1,000 ($11,046.91 in 2025), and her best recordings from the 1930s were mostly out of print.\nHoliday's public stature grew in the following years. In 1961, she was voted to the Down Beat Hall Of Fame, and soon after Columbia reissued nearly one hundred of her early records. In 1972, Diana Ross's portrayal of Holiday in \"Lady Sings the Blues\" was nominated for an Oscar and won a Golden Globe. Holiday was posthumously nominated for 23 Grammy awards.\nSinger Adelaide Hall made a secret visit to Holiday's bedside at the Metropolitan Hospital, on or around June 12, 1959. Hall's spoken account of her visit was captured on tape by the journalist Max Jones in 1988. Hall's long-time friend, Iain Cameron Williams, and author of Hall's biography, also had direct knowledge of the visit. However, he refrained from releasing the information as he only had Hall's one-to-one spoken account and no further backup. In July 2022, after finding transcripts of Max Jones's tape, Williams wrote an article for \"The Syncopated Times\" about Hall's secret visit.\nGeorge Jacobs claims Sinatra also visited Holiday on her death bed, and promised to supply her with the heroin she desperately wanted.\nArtistry.\nHoliday's vocal delivery made her performances instantly recognizable throughout her career. Her improvisational prowess compensated for her lack of formal musical education. Holiday stated that she had always wanted her voice to sound like an instrument, and some of her influences included trumpeter Louis Armstrong and singer Bessie Smith. Early in her career, she was said to have had her accompanying instrumentalists stop and repeat an improvised line if she believed she could use it for a vocal line.\nHoliday's last major recording, a 1958 album titled \"Lady in Satin\", features the backing of a 40-piece orchestra conducted and arranged by Ray Ellis. The conductor said of the album in 1997:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I would say that the most emotional moment was her listening to the playback of \"I'm a Fool to Want You\". There were tears in her eyes\u00a0... After we finished the album I went into the control room and listened to all the takes. I must admit I was unhappy with her performance, but I was just listening musically instead of emotionally. It wasn't until I heard the final mix a few weeks later that I realized how great her performance really was.\nFrank Sinatra was influenced during his youth by Holiday's performances on 52nd Street. He told \"Ebony\" magazine in 1958 about her impact:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;With few exceptions, every major pop singer in the US during her generation has been touched in some way by her genius. It is Billie Holiday who was, and still remains, the greatest single musical influence on me. Lady Day is unquestionably the most important influence on American popular singing in the last twenty years.\nScholarly Interpretations.\nSeveral scholars have written about the broader social and political meanings of Holiday\u2019s music. Angela Y. Davis argues that some of Holiday\u2019s performances reflected themes of personal autonomy and emotional independence for Black women. In her book \"Blues Legacies and Black Feminism\", Davis points to songs such as \u201cT\u2019ain\u2019t Nobody\u2019s Bizness If I Do\u201d as examples of Holiday presenting a narrative voice that challenged expectations about respectability and gender roles.\nDavis also writes about Holiday\u2019s interpretation of \u201cStrange Fruit,\u201d describing it as one of the earliest and most influential musical statements against racial violence in the United States. Scholars have noted that Holiday continued to perform the song despite professional and legal pressure, and that her delivery helped bring national attention to the issue of lynching. These interpretations place Holiday among a longer tradition of African American musical protest and have shaped how later writers understand her artistic and political legacy.\nLegacy.\nIn the book \"The NPR Curious Listener's Guide to Jazz\", jazz historian Loren Schoenberg asserted that \"no one would dispute that Billie Holiday is the definitive Jazz Singer.\"\nBillie Holiday received several \"Esquire\" Magazine awards during her lifetime. Her posthumous awards also include being inducted into the Grammy Hall of Fame, Ertegun Jazz Hall of Fame, Rock and Roll Hall of Fame, and the ASCAP Jazz Wall of Fame. In 1985, a statue of Billie Holiday was erected in Baltimore; the statue was completed in 1993 with additional panels of images inspired by her seminal song \"Strange Fruit\". The Billie Holiday Monument is located at Pennsylvania and West Lafayette avenues in Baltimore's Upton neighborhood. Holiday is also featured in a Romare Bearden mosaic at the Upton metro station. In 2019, Chirlane McCray announced that New York City would build a statue honoring Holiday near Queens Borough Hall.\nFrank O'Hara's poem from 1959, \"The Day Lady Died\", concludes with an impression of Holiday performing at the Five Spot Caf\u00e9 at the end of her career, and the impact of that performance on her listeners.\nThe song \"Angel of Harlem\" by Irish rock band U2, released as a single in December 1988, was written as a homage to Holiday. In 1994, as part of the \"Legends of American Music\" series, the United States Postal Service issued commemorative stamps bearing Holiday's image.\nFilms and plays about Holiday.\nThe biographical film \"Lady Sings the Blues\", loosely based on Holiday's autobiography, was released in 1972 and was nominated for five Academy Awards, including Best Actress for Diana Ross, who also won a Golden Globe Award for her performance. \nAnother film, \"The United States vs. Billie Holiday\", starred Andra Day and was released in 2021. It is based on the book \"Chasing the Scream\" by Johann Hari. Director Lee Daniels saw how Holiday was portrayed in the 1972 biopic, and wanted to show her legacy as \"a civil rights leader [ ... ] not just a drug addict or a jazz singer\". The film also depicts Holiday's bisexuality and relationship with Tallulah Bankhead. Day was also nominated for the Academy Award for Best Actress but did not win. However, she won a Golden Globe in 2021.\nHoliday is the primary character in the play \"Lady Day at Emerson's Bar and Grill\", with music by Lanie Robertson. It takes place in South Philadelphia in March 1959. It premiered in 1986 at the Alliance Theatre and has been revived several times. A Broadway production starring Audra McDonald was filmed and broadcast on HBO in 2016; McDonald received an Emmy Award nomination. In 2014, she received a Tony Award win. \"Billie\" is a 2019 documentary film based on interviews in the 1970s by Linda Lipnack Kuehl, who was researching a book on Holiday that was never completed.\nHoliday was portrayed by actress Paula Jai Parker in the episode \"God Bless the Child\" of CBS television series \"Touched by an Angel\".\nDiscography.\nBillie Holiday recorded extensively for four labels: Columbia Records, which issued her recordings on its subsidiary labels Brunswick Records, Vocalion Records and OKeh Records, from 1933 through 1942; Commodore Records in 1939 and 1944; Decca Records from 1944 through 1950; briefly for Aladdin Records in 1951; Verve Records and on its earlier imprint Clef Records from 1952 through 1957, then again for Columbia Records from 1957 to 1958 and finally for MGM Records in 1959. Many of Holiday's recordings appeared on 78-rpm records prior to the long-playing vinyl record era, and only Clef, Verve, and Columbia issued albums during her lifetime that were not compilations of previously released material. Many compilations have been issued since her death, as well as comprehensive box sets and live recordings.\nHit records.\nIn 1986, Joel Whitburn's company Record Research compiled information on the popularity of recordings released from the era predating rock and roll and created pop charts dating back to the beginning of the commercial recording industry. The company's findings were published in the book \"Pop Memories 1890\u20131954\". Several of Holiday's records are listed on the pop charts Whitburn created.\nHoliday began her recording career on a high note with her first major release, \"Riffin' the Scotch\", of which 5,000 copies were sold. It was released under the name \"Benny Goodman &amp; His Orchestra\" in 1933.\nMost of Holiday's early successes were released under the name \"Teddy Wilson &amp; His Orchestra\". During her stay in Wilson's band, Holiday would sing a few bars and then other musicians would have a solo. Wilson, one of the most influential jazz pianists of the swing era, accompanied Holiday more than any other musician. He and Holiday issued 95 recordings together.\nIn July 1936, Holiday began releasing sides under her own name. These songs were released under the band name \"Billie Holiday &amp; Her Orchestra\". Most noteworthy, the popular jazz standard \"Summertime\" sold well and was listed on the pop charts of the time at number 12, the first time the jazz standard charted. Only Billy Stewart's R&amp;B version of \"Summertime\" reached a higher chart placement than Holiday's, charting at number 10 thirty years later in 1966.\nHoliday had 16 best-selling songs in 1937, making the year her most commercially successful. It was in this year that Holiday scored her sole number one hit as a featured vocalist on the available pop charts of the 1930s, \"Carelessly\". The hit \"I've Got My Love to Keep Me Warm\", was also recorded by Ray Noble, Glen Gray and Fred Astaire, whose rendering was a bestseller for weeks. Holiday's version ranked 6 on the year-end single chart available for 1937.\nIn 1939, Holiday recorded her biggest selling record, \"Strange Fruit\" for Commodore, charting at number 16 on the available pop chart for the 1930s.\nIn 1940, \"Billboard\" began publishing its modern pop charts, which included the Best Selling Retail Records chart, the precursor to the Hot 100. None of Holiday's songs placed on the modern pop charts, partly because \"Billboard\" only published the first ten slots of the charts in some issues. Minor hits and independent releases had no way of being spotlighted.\n\"God Bless the Child\", which went on to sell over a million copies, ranked number 3 on \"Billboard\"'s year-end top songs of 1941.\nOn October 24, 1942, \"Billboard\" began issuing its R&amp;B charts. Two of Holiday's songs placed on the chart, \"Trav'lin' Light\" with Paul Whiteman, which topped the chart, and \"Lover Man\", which reached number 5. \"Trav'lin' Light\" also reached 18 on \"Billboard\"'s year-end chart.\nStudio LPs.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFilmography.\nTelevision appearances.\n(1) = Available on audio\n(2) = Available on DVD\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\nBooks, journals, magazines, newspapers, and blogs\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nThe date and attribution for this article is unclear; tho' a phrase from it has been published on two earlier dates, 2008 and 2002: \"Holiday's unique diction, inimitable phrasing and acute dramatic intensity made her the outstanding jazz singer of her day.\"\n Side A:\n Side B:\nPhoto caption: \"Billie Holiday sings 'Fine and Mellow,' a blues recorded for the Commadore label. She has the most distinctive style of any popular vocalist, is imitated by other vocalists.\"\nNews media\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50421", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=50421", "title": "Corporate police state", "text": ""}
{"id": "50422", "revid": "1650522", "url": "https://en.wikipedia.org/wiki?curid=50422", "title": "Bernardo Bertolucci", "text": "Italian film director and screenwriter (1941\u20132018)\nBernardo Bertolucci ( ; ; 16 March 1941 \u2013 26 November 2018) was an Italian film director and screenwriter with a career that spanned 50 years. Considered one of the greatest directors in the history of cinema, Bertolucci's work achieved international acclaim. With \"The Last Emperor\" (1987) he became the first Italian filmmaker to win the Academy Award for Best Director, and he received many other accolades including a BAFTA Award, a C\u00e9sar Award, two Golden Globes, a Golden Lion in 2007, and an Honorary Palme d'Or at Cannes in 2011.\nA prot\u00e9g\u00e9 of Pier Paolo Pasolini, Bertolucci made his directorial debut at 22. His second film, \"Before the Revolution\" (1964), earned strong international reviews and has since gained classic status, being called a \"masterpiece of Italian cinema\" by Film4. His 1970 film \"The Conformist\", an adaptation of the Alberto Moravia novel, is considered a classic of international cinema, and was nominated for an Academy Award for Best Adapted Screenplay and the prestigious Berlin Golden Bear. His 1972 erotic drama \"Last Tango in Paris\" was controversial due to its rape scene and comments made by actress Maria Schneider about her treatment on set. Bertolucci's later films such as the historical epic \"1900\" (1976), the family drama \"La Luna\" (1979), and the darkly comedic \"Tragedy of a Ridiculous Man\" (1981), were also controversial but acclaimed.\nHis 1987 film \"The Last Emperor\", a biopic of Chinese monarch Puyi, was a critical and commercial success, earning rave reviews and sweeping the 60th Academy Awards (including Best Picture and Best Director). This was the start of what has since been described as his \"Oriental Trilogy,\" a trio of films including \"The Sheltering Sky\", an adaptation of the novel of the same name, and \"Little Buddha\", a Buddhist religious epic, all three of which feature scores by Ryuichi Sakamoto. His 1996 film, \"Stealing Beauty\", brought him his second of two Palme d'Or nominations. He continued directing well into the 21st century, releasing his final film, \"Me and You\", in 2012.\nBertolucci's films often deal with themes of politics, sexuality, history, class conflict and social taboos, and his style has influenced several filmmakers. Several of his films have appeared on lists of the greatest films of all time. Critics have remarked that what makes Bertolucci different than other directors is his masterful combination of \"visual richness and visual freedom.\"\nEarly life.\nBertolucci was born in the Italian city of Parma, in the region of Emilia-Romagna. He was the elder son of Ninetta (Giovanardi), a teacher, and Attilio Bertolucci, who was a poet, a reputed art historian, anthologist and film critic. His mother was born in Australia, to an Italian father and an Australian mother (of Irish and Scottish descent).\nHaving been raised in an artistic environment, Bertolucci began writing at the age of 15, and soon after received several prestigious literary prizes, including the \"Premio Viareggio\" for his first book. His father's background helped his career: the elder Bertolucci had helped the Italian filmmaker Pier Paolo Pasolini publish his first novel, and Pasolini reciprocated by hiring Bertolucci as his first assistant in Rome on \"Accattone\" (1961).\nBertolucci had one brother, the theatre director and playwright Giuseppe (27 February 1947 \u2013 16 June 2012). His cousin was the film producer Giovanni Bertolucci (24 June 1940 \u2013 17 February 2005), with whom he worked on a number of films.\nCareer.\nDirectorial breakthrough.\nBertolucci initially wished to become a poet like his father. With this goal in mind, he attended the Faculty of Modern Literature of the University of Rome from 1958 to 1961, where his film career as an assistant director to Pasolini began. Shortly after, Bertolucci left the university without graduating. In 1962, at the age of 22, he directed his first feature film, produced by Tonino Cervi with a screenplay by Pasolini, called \"La commare secca\" (1962). The film is a murder mystery, following a prostitute's homicide. Bertolucci uses flashbacks to piece together the crime and the person who committed it. The film which shortly followed was his acclaimed \"Before the Revolution\" (\"Prima della rivoluzione\", 1964).\nThe boom of Italian cinema, which gave Bertolucci his start, slowed in the 1970s as directors were forced to co-produce their films with several of the American, Swedish, French, and German companies and actors due to the effects of the global economic recession on the Italian film industry. Bertolucci entered film making already working at a big scale.\nIn 1971, film critic for \"The New Yorker,\" Pauline Kael called Bertolucci a prodigy. \nBertolucci caused controversy in 1972 with the film \"Last Tango in Paris\", starring Marlon Brando, Maria Schneider, Jean-Pierre L\u00e9aud and Massimo Girotti. The film presents Brando's character, Paul, as he copes with his wife's suicide by emotionally and physically dominating a young woman, Jeanne (Schneider). The depictions of Schneider, then 19 years old, have been criticized as exploitive. In one scene, Paul anally rapes Jeanne using butter as a lubricant. Bertolucci said use of butter was not in the script; Bertolucci and Brando had discussed it, but they did not tell Schneider. According to Schneider, the rape scene was not in the script at all. She said in 2007 that she had cried \"real tears\" during the scene and had felt humiliated and \"a little raped\". In 2013 Bertolucci said that he had withheld the information from Schneider to generate a real \"reaction of frustration and rage\". Brando alleged that Bertolucci had wanted the characters to have real sex, but Brando and Schneider both said it was simulated. In 2016 Bertolucci released a statement where he clarified that Schneider had known of the violence to be depicted in the scene, but had not been told about the use of butter.\nFollowing the \u201cmedia glare\u201d and her fame after the film's release, Schneider became a drug addict and suicidal. Criminal proceedings were brought against Bertolucci in Italy for obscenity; the film was sequestered by the censorship commission and all copies were ordered destroyed. An Italian court revoked Bertolucci's civil rights for five years and gave him a four-month suspended prison sentence. In 1978, the Appeals Court of Bologna ordered three copies of the film to be preserved in the national film library with the stipulation that they could not be viewed, until Bertolucci was later able to re-submit it for general distribution with no cuts.\nBertolucci increased his fame with his next few films, from \"1900\" (1976), an epic depiction of the struggles of farmers in Emilia-Romagna from the beginning of the 20th century up to World War II with an international cast (Robert De Niro, G\u00e9rard Depardieu, Donald Sutherland, Sterling Hayden, Burt Lancaster, Dominique Sanda) to \"La Luna\", set in Rome and in Emilia-Romagna, in which Bertolucci deals with the thorny issue of drugs and incest, and finally \"La tragedia di un uomo ridicolo\" (1981), with Ugo Tognazzi.\nHe then wrote two screenplays based on Dashiell Hammett's \"Red Harvest\". He hoped this would be his first film set in America, but nothing came of it.\n\"The Last Emperor\" and later career.\nIn 1987, Bertolucci directed the epic \"The Last Emperor\", a biographical film telling the life story of Aisin-Gioro Puyi, the last emperor of China. The film was independently produced by British producer Jeremy Thomas, with whom Bertolucci worked almost exclusively from then on. The film was independently financed and three years in the making. Bertolucci, who co-wrote the film with Mark Peploe, won the Academy Award for Best Director. The film uses Puyi's life as a mirror that reflects China's passage from feudalism through revolution to its current state.\nAt the 60th Academy Awards, \"The Last Emperor\" won all nine Oscars for which it was nominated: Best Picture, Best Director, Best Writing, Screenplay Based on Material from Another Medium, Best Cinematography, Best Film Editing, Best Costume Design, Best Art Direction-Set Decoration, Best Music, Original Score and Best Sound.\n\"The Last Emperor\" was the first feature film ever authorized by the government of the People's Republic of China to film in the Forbidden City. Bertolucci had proposed the film to the Chinese government as one of two possible projects. The other film was \"La Condition Humaine\" by Andr\u00e9 Malraux. The Chinese government preferred \"The Last Emperor\".\nAfter \"The Last Emperor\", \"The Sheltering Sky\" and \"Little Buddha\", Bertolucci returned to Italy to film, and to revisit his old themes but with varying results from both critics and the public. He filmed \"Stealing Beauty\" in 1996, then \"The Dreamers\" in 2003, which describes the political passions and sexual revolutions of two siblings in Paris in 1968.\nIn 2007, Bertolucci received the Golden Lion Award at the Venice Film Festival for his life's work, and in 2011 he also received the Palme d'Or at the Cannes Film Festival.\nIn 2012, his final film, \"Me and You\", was screened out of competition at the 2012 Cannes Film Festival and was released early in 2013 in the UK. The film is an adaptation of Niccol\u00f2 Ammaniti's young adult book \"Me and You\". The screenplay for the movie was written by Bertolucci, Umberto Contarello and Niccol\u00f2 Ammaniti. Bertolucci originally intended to shoot the film in 3D but was forced to abandon this plan due to cost.\nBertolucci appeared on the Radio Four programme \"Start the Week\" on 22 April 2013, and on \"Front Row\" on 29 April 2013, where he chose \"La Dolce Vita\", a film directed by Federico Fellini, for the \"Cultural Exchange\".\nIn the spring of 2018, in an interview with the Italian edition of \"Vanity Fair\", Bertolucci announced that he was preparing a new film. He stated, \"The theme will be love, let's call it that. In reality, the theme is communication and therefore also incommunicability. The favorite subject of Michelangelo Antonioni and the condition I found myself facing when I moved on from my films for the few, those of the sixties, to a broader cinema ready to meet a large audience.\"\nAs a screenwriter, producer and actor.\nBertolucci wrote many screenplays, both for his own films and for films directed by others, two of which he also produced.\nHe was an actor in the film \"Golem: The Spirit of Exile\", directed by Amos Gitai in 1992.\nPolitics and personal beliefs.\nBertolucci was an atheist, though he was fascinated by Buddhism.\nBertolucci's films are often very political. He was a professed Marxist and, like Luchino Visconti, who similarly employed many foreign artists during the late 1960s, Bertolucci used his films to express his political views. His political films were preceded by others re-evaluating history. \"The Conformist\" (1970) criticised fascism, touched upon the relationship between nationhood and nationalism, as well as issues of popular taste and collective memory, all amid an international plot by Benito Mussolini to assassinate a politically active leftist professor of philosophy in Paris. \"1900\" also analyses the struggle of Left and Right.\nOn 27 September 2009, Bertolucci was one of the signatories of the appeal to the Swiss government to release Roman Polanski, who was being held awaiting extradition to the United States.\nOn Twitter on 24 April 2015, Bertolucci participated in #whomademyclothes, Fashion Revolution's anti-sweatshop campaign commemorating the 2013 Savar building collapse, the deadliest accident in the history of the garment industry.\nBertolucci advocated the practice of Transcendental Meditation: \"We want to evoke the present and it is difficult to do it all together, we can only meditate, as in transcendental meditation. One of the most powerful experiences. Either you meditate or watch a good movie, then the two things start to touch ... \".\nDeath.\nBertolucci died of lung cancer in Rome on 26 November 2018, at the age of 77.\nFilmography.\nFeature film.\nProducer\nDocumentary works.\nShort film\nFilm\nTelevision\nAwards and nominations.\nOther awards\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50424", "revid": "754619", "url": "https://en.wikipedia.org/wiki?curid=50424", "title": "536 BC", "text": "Calendar year\n \nThe year 536 BC was a year of the pre-Julian Roman calendar. In the Roman Empire, it was known as year 218 \" Ab urbe condita\". The denomination 536 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50425", "revid": "50499759", "url": "https://en.wikipedia.org/wiki?curid=50425", "title": "Quantum Hall effect", "text": "Electromagnetic effect in physics\nThe quantum Hall effect (or integer quantum Hall effect) is a quantized version of the Hall effect which is observed in two-dimensional electron systems subjected to low temperatures and strong magnetic fields, in which the Hall resistance \"R\"xy exhibits steps that take on the quantized values\n formula_1\nwhere \"V\"Hall is the Hall voltage, \"I\"channel is the channel current, \"e\" is the elementary charge and \"h\" is the Planck constant. The divisor \"\u03bd\" can take on either integer (\"\u03bd\" \n 1, 2, 3...) or fractional (\"\u03bd\" \n , , , , , , , , , ...) values. Here, \"\u03bd\" is roughly but not exactly equal to the filling factor of Landau levels. The quantum Hall effect is referred to as the integer or fractional quantum Hall effect depending on whether \"\u03bd\" is an integer or fraction, respectively.\nThe striking feature of the integer quantum Hall effect is the persistence of the quantization (i.e. the Hall plateau) as the electron density is varied. Since the electron density remains constant when the Fermi level is in a clean spectral gap, this situation corresponds to one where the Fermi level is an energy with a finite density of states, though these states are localized (see Anderson localization).\nThe fractional quantum Hall effect is more complicated and still considered an open research problem. Its existence relies fundamentally on electron\u2013electron interactions. In 1988, it was proposed that there was a quantum Hall effect without Landau levels. This quantum Hall effect is referred to as the quantum anomalous Hall (QAH) effect. There is also a new concept of the quantum spin Hall effect which is an analogue of the quantum Hall effect, where spin currents flow instead of charge currents.\nApplications.\nElectrical resistance standards.\nThe quantization of the Hall conductance (formula_2) has the important property of being exceedingly precise. Actual measurements of the Hall conductance have been found to be integer or fractional multiples of to better than one part in a billion. It has allowed for the definition of a new practical standard for electrical resistance, based on the resistance quantum given by the von Klitzing constant \"R\"K. This is named after Klaus von Klitzing, the discoverer of exact quantization. The quantum Hall effect also provides an extremely precise independent determination of the fine-structure constant, a quantity of fundamental importance in quantum electrodynamics.\nIn 1990, a fixed conventional value \"R\"K-90 \n was defined for use in resistance calibrations worldwide. Later, the 2019 revision of the SI fixed exact values of \"h\" and \"e\", resulting in an exact \"R\"K \n .\nResearch status.\nThe fractional quantum Hall effect is considered part of \"exact quantization\". Exact quantization in full generality is not completely understood but it has been explained as a very subtle manifestation of the combination of the principle of gauge invariance together with another symmetry (see Anomalies). The integer quantum Hall effect instead is considered a solved research problem and understood in the scope of TKNN formula and Chern\u2013Simons Lagrangians.\nThe fractional quantum Hall effect is still considered an open research problem. The fractional quantum Hall effect can be also understood as an integer quantum Hall effect, although not of electrons but of charge\u2013flux composites known as composite fermions. Other models to explain the fractional quantum Hall effect also exists.\nCurrently it is considered an open research problem because no single, confirmed and agreed list of fractional quantum numbers exists, neither a single agreed model to explain all of them, although there are such claims in the scope of composite fermions and Non Abelian Chern\u2013Simons Lagrangians.\nHistory.\nThe MOSFET (metal\u2013oxide\u2013semiconductor field-effect transistor), invented by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959, enabled physicists to study electron behavior in a nearly ideal two-dimensional gas.\nIn a MOSFET, conduction electrons travel in a thin surface layer, and a \"gate\" voltage controls the number of charge carriers in this layer. This allows researchers to explore quantum effects by operating high-purity MOSFETs at liquid helium temperatures.\nThe integer quantization of the Hall conductance was originally predicted by University of Tokyo researchers Tsuneya Ando, Yukio Matsumoto and Yasutada Uemura in 1975, on the basis of an approximate calculation which they themselves did not believe to be true. In 1978, the Gakushuin University researchers Jun-ichi Wakabayashi and Shinji Kawaji subsequently observed the effect in experiments carried out on the inversion layer of MOSFETs.\nIn 1980, Klaus von Klitzing, working at the high magnetic field laboratory in Grenoble with silicon-based MOSFET samples developed by Michael Pepper and Gerhard Dorda, made the unexpected discovery that the Hall resistance was \"exactly\" quantized. For this finding, von Klitzing was awarded the 1985 Nobel Prize in Physics. A link between exact quantization and gauge invariance was subsequently proposed by Robert Laughlin, who connected the quantized conductivity to the quantized charge transport in a Thouless charge pump. Most integer quantum Hall experiments are now performed on gallium arsenide heterostructures, although many other semiconductor materials can be used. In 2007, the integer quantum Hall effect was reported in graphene at temperatures as high as room temperature, and in the magnesium zinc oxide ZnO\u2013Mg\"x\"Zn1\u2212\"x\"O.\nInteger quantum Hall effect.\nLandau levels.\nIn two dimensions, when classical electrons are subjected to a magnetic field they follow circular cyclotron orbits. When the system is treated quantum mechanically, these orbits are quantized. To determine the values of the energy levels the Schr\u00f6dinger equation must be solved.\nSince the system is subjected to a magnetic field, it has to be introduced as an electromagnetic vector potential in the Schr\u00f6dinger equation. The system considered is an electron gas that is free to move in the x and y directions, but is tightly confined in the z direction. Then, a magnetic field is applied in the z direction and according to the Landau gauge the electromagnetic vector potential is formula_3 and the scalar potential is formula_4. Thus the Schr\u00f6dinger equation for a particle of charge formula_5 and effective mass formula_6 in this system is:\n formula_7\nwhere formula_8 is the canonical momentum, which is replaced by the operator formula_9 and formula_10 is the total energy.\nTo solve this equation it is possible to separate it into two equations since the magnetic field just affects the movement along x and y axes. The total energy becomes then, the sum of two contributions formula_11. The corresponding equations in z axis is:\n formula_12\nTo simplify things, the solution formula_13 is considered as an infinite well. Thus the solutions for the z direction are the energies formula_14, formula_15 and the wavefunctions are sinusoidal. For the formula_16 and formula_17 directions, the solution of the Schr\u00f6dinger equation can be chosen to be the product of a plane wave in formula_17-direction with some unknown function of formula_16, i.e., formula_20. This is because the vector potential does not depend on formula_17 and the momentum operator formula_22 therefore commutes with the Hamiltonian. By substituting this Ansatz into the Schr\u00f6dinger equation one gets the one-dimensional harmonic oscillator equation centered at formula_23.\n formula_24\nwhere formula_25 is defined as the cyclotron frequency and formula_26 the magnetic length. The energies are:\n formula_27, formula_28\nAnd the wavefunctions for the motion in the formula_29 plane are given by the product of a plane wave in formula_17 and Hermite polynomials attenuated by the gaussian function in formula_16, which are the wavefunctions of a harmonic oscillator.\nFrom the expression for the Landau levels one notices that the energy depends only on formula_32, not on formula_33. States with the same formula_32 but different formula_33 are degenerate.\nDensity of states.\nAt zero field, the density of states per unit surface for the two-dimensional electron gas taking into account degeneration due to spin is independent of the energy\n formula_36.\nAs the field is turned on, the density of states collapses from the constant to a Dirac comb, a series of Dirac formula_37 functions, corresponding to the Landau levels separated formula_38. At finite temperature, however, the Landau levels acquire a width formula_39 being formula_40 the time between scattering events. Commonly it is assumed that the precise shape of Landau levels is a Gaussian or Lorentzian profile.\nAnother feature is that the wave functions form parallel strips in the formula_17-direction spaced equally along the formula_16-axis, along the lines of formula_43. Since there is nothing special about any direction in the formula_29-plane if the vector potential was differently chosen one should find circular symmetry.\nGiven a sample of dimensions formula_45 and applying the periodic boundary conditions in the formula_17-direction formula_47 being formula_48 an integer, one gets that each parabolic potential is placed at a value formula_49.\nThe number of states for each Landau Level and formula_50 can be calculated from the ratio between the total magnetic flux that passes through the sample and the magnetic flux corresponding to a state.\n formula_51\nThus the density of states per unit surface is \n formula_52.\nNote the dependency of the density of states with the magnetic field. The larger the magnetic field is, the more states are in each Landau level. As a consequence, there is more confinement in the system since fewer energy levels are occupied.\nRewriting the last expression as formula_53 it is clear that each Landau level contains as many states as in a 2DEG in a formula_54.\nGiven the fact that electrons are fermions, for each state available in the Landau levels it corresponds to two electrons, one electron with each value for the spin formula_55. However, if a large magnetic field is applied, the energies split into two levels due to the magnetic moment associated with the alignment of the spin with the magnetic field. The difference in the energies is formula_56 being formula_57 a factor which depends on the material (formula_58 for free electrons) and formula_59 the Bohr magneton. The sign formula_60 is taken when the spin is parallel to the field and formula_61 when it is antiparallel. This fact called spin splitting implies that the density of states for each level is reduced by a half. Note that formula_62 is proportional to the magnetic field so, the larger the magnetic field is, the more relevant is the split.\nIn order to get the number of occupied Landau levels, one defines the so-called filling factor formula_63 as the ratio between the density of states in a 2DEG and the density of states in the Landau levels.\n formula_64\nIn general the filling factor formula_63 is not an integer. It happens to be an integer when there is an exact number of filled Landau levels. Instead, it becomes a non-integer when the top level is not fully occupied. In actual experiments, one varies the magnetic field and fixes electron density (and not the Fermi energy!) or varies the electron density and fixes the magnetic field. Both cases correspond to a continuous variation of the filling factor formula_63 and one cannot expect formula_63 to be an integer. Since formula_68, by increasing the magnetic field, the Landau levels move up in energy and the number of states in each level grow, so fewer electrons occupy the top level until it becomes empty. If the magnetic field keeps increasing, eventually, all electrons will be in the lowest Landau level (formula_69) and this is called the magnetic quantum limit.\nLongitudinal resistivity.\nIt is possible to relate the filling factor to the resistivity and hence, to the conductivity of the system. When formula_63 is an integer, the Fermi energy lies in between Landau levels where there are no states available for carriers, so the conductivity becomes zero (it is considered that the magnetic field is big enough so that there is no overlap between Landau levels, otherwise there would be few electrons and the conductivity would be approximately formula_71). Consequently, the resistivity becomes zero too (At very high magnetic fields it is proven that longitudinal conductivity and resistivity are proportional).\nWith the conductivity formula_72 one finds\n formula_73\nIf the longitudinal resistivity is zero and transversal is finite, then formula_74. Thus both the longitudinal conductivity and resistivity become zero.\nInstead, when formula_63 is a half-integer, the Fermi energy is located at the peak of the density distribution of some Landau Level. This means that the resistivity will have a maximum due to increased scattering.\nThis distribution of minimums and maximums corresponds to \u00a8quantum oscillations\u00a8 called \"Shubnikov\u2013de Haas oscillations\" which become more relevant as the magnetic field increases. Obviously, the height of the peaks are larger as the magnetic field increases since the density of states increases with the field, so there are more carriers which contribute to the resistivity. It is interesting to notice that if the magnetic field is very small, the longitudinal resistivity is a constant which means that the classical result is reached.\nTransverse resistivity.\nFrom the classical relation of the transverse resistivity formula_76 and substituting formula_77 one finds out the quantization of the transverse resistivity and conductivity:\n formula_78\nOne concludes then, that the transverse resistivity is a multiple of the inverse of the so-called conductance quantum formula_79 if the filling factor is an integer. In experiments, however, plateaus are observed for whole plateaus of filling values formula_63, which indicates that there are in fact electron states between the Landau levels. These states are localized in, for example, impurities of the material where they are trapped in orbits so they can not contribute to the conductivity. That is why the resistivity remains constant in between Landau levels. Again if the magnetic field decreases, one gets the classical result in which the resistivity is proportional to the magnetic field.\nPhotonic quantum Hall effect.\nThe quantum Hall effect, in addition to being observed in two-dimensional electron systems, can be observed in photons. Photons do not possess inherent electric charge, but through the manipulation of discrete optical resonators and coupling phases or on-site phases, an artificial magnetic field can be created. This process can be expressed through a metaphor of photons bouncing between multiple mirrors. By shooting the light across multiple mirrors, the photons are routed and gain additional phase proportional to their angular momentum. This creates an effect like they are in a magnetic field.\nTopological classification.\nThe integers that appear in the Hall effect are examples of topological quantum numbers. They are known in mathematics as the first Chern numbers and are closely related to Berry's phase. A striking model of much interest in this context is the Azbel\u2013Harper\u2013Hofstadter model whose quantum phase diagram is the Hofstadter butterfly shown in the figure. The vertical axis is the strength of the magnetic field and the horizontal axis is the chemical potential, which fixes the electron density. The colors represent the integer Hall conductances. Warm colors represent positive integers and cold colors negative integers. Note, however, that the density of states in these regions of quantized Hall conductance is zero; hence, they cannot produce the plateaus observed in the experiments. The phase diagram is fractal and has structure on all scales. In the figure there is an obvious self-similarity. In the presence of disorder, which is the source of the plateaus seen in the experiments, this diagram is very different and the fractal structure is mostly washed away. Also, the experiments control the filling factor and not the Fermi energy. If this diagram is plotted as a function of filling factor, all the features are completely washed away, hence, it has very little to do with the actual Hall physics.\nConcerning physical mechanisms, impurities and/or particular states (e.g., edge currents) are important for both the 'integer' and 'fractional' effects. In addition, Coulomb interaction is also essential in the fractional quantum Hall effect. The observed strong similarity between integer and fractional quantum Hall effects is explained by the tendency of electrons to form bound states with an even number of magnetic flux quanta, called \"composite fermions\".\nBohr atom interpretation of the von Klitzing constant.\nThe value of the von Klitzing constant may be obtained already on the level of a single atom within the Bohr model while looking at it as a single-electron Hall effect. While during the cyclotron motion on a circular orbit the centrifugal force is balanced by the Lorentz force responsible for the transverse induced voltage and the Hall effect, one may look at the Coulomb potential difference in the Bohr atom as the induced single atom Hall voltage and the periodic electron motion on a circle as a Hall current. Defining the single atom Hall current as a rate a single electron charge formula_81 is making Kepler revolutions with angular frequency formula_82\n formula_83\nand the induced Hall voltage as a difference between the hydrogen nucleus Coulomb potential at the electron orbital point and at infinity:\n formula_84\nOne obtains the quantization of the defined Bohr orbit Hall resistance in steps of the von Klitzing constant as\n formula_85\nwhich for the Bohr atom is linear but not inverse in the integer \"n\".\nRelativistic analogs.\nRelativistic examples of the integer quantum Hall effect and quantum spin Hall effect arise in the context of lattice gauge theory.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50427", "revid": "8", "url": "https://en.wikipedia.org/wiki?curid=50427", "title": "Zhou En-lai", "text": ""}
{"id": "50429", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=50429", "title": "Leonid Ilych Brezhnev", "text": ""}
{"id": "50430", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=50430", "title": "Mao Tse Tung", "text": ""}
{"id": "50431", "revid": "35126782", "url": "https://en.wikipedia.org/wiki?curid=50431", "title": "Dystopian", "text": ""}
{"id": "50432", "revid": "1287832825", "url": "https://en.wikipedia.org/wiki?curid=50432", "title": "Colloquial Finnish", "text": "Spoken form of the Finnish language\nColloquial or spoken Finnish () is the unstandardized spoken variety of the Finnish language, in contrast with the standardized form of the language (). It is used primarily in personal communication and varies somewhat between the different dialects.\nThis article focuses on the variety of spoken Finnish that is predominant in the Helsinki metropolitan area and urbanized areas in the Tavastian and Central Finland dialectal areas, such as the cities of Tampere, Jyv\u00e4skyl\u00e4, Lahti, Hyvink\u00e4\u00e4, and H\u00e4meenlinna \u2013 as well as in coastal cities such as Vaasa and Porvoo, which have been traditionally Swedish-speaking and have experienced an influx of Finnish speakers from a variety of dialectal areas.\nThe standard language takes most of its features from these dialects, i.e. most \"dialectal\" features are reductions with respect to this form of language. The combination of the common spoken Finnish and a dialect gives a regional variant (), which has some local idiosyncrasies but is essentially similar to the common spoken Finnish.\nThe basics of Finnish needed to fully understand this article can be found in pages about Finnish phonology and Finnish grammar.\nIntroduction.\nAs in any language, the spoken version(s) of Finnish often vary from the written form. Some of the latter's constructs are either too arbitrary (e.g. \"soft d\", cf. Finnish phonology), or too dialectal, e.g. (see below), for use in the spoken language. Furthermore, some very common and \"accentless\" sound changes are not reflected in the standard language, particularly fusion, liaison and some diphthong reductions.\nThere is also the problem that purists want to avoid irregularity regardless of actual usage. This has left some sound changes common in spoken language out from the standard language. There is a tendency to favor \"more logical\" constructs over easily pronounceable ones. This ideal does reflect spoken Finnish usage to a degree, as Finnish is demonstrably a conservative language with few reduction processes, but it is not entirely accurate. The problem of avoiding \"irregularity\" is most evident in spelling, where internal sandhi is not transcribed, because there is the idea that morphemes should be immutable. For example, the \"correct\" spelling is (\"I eat\" with emphasis), even though the pronunciation is usually . The explanation is that and are in different morphemes just like the explanation that English \"boys\" is not spelled with a \"z\" is that they are in different morphemes.\nThere are also a number of grammatical forms which are used in written Finnish, but only very rarely in spoken. For example, there are a number of constructions using participles which are usually rendered analytically in speech. Some cases and moods are rarely constructive in spoken Finnish, e.g. the instructive and comitative cases and the potential mood. Some survive only in expressions.\nOn the other hand, spoken language has its own features rarely or never found in formal language. Most importantly, there is very common external sandhi, and some assimilatory sound changes. (On the contrary, there is no vowel reduction.) In some variants (e.g. Vaasa, Kymenlaakso) of spoken Finnish (\"with [something]\") is abbreviated into a clitic that is effectively a comitative case, e.g. or .\nPronunciation.\nReflexes of dental fricatives.\nThe most common reflexes for old Finnish dental fricatives are for , and or for . For example, or \u2190 \"forest, of the forest\" and &lt; \"ours\". Loss of also occurs, e.g. . These are seen as \"accent-free\" pronunciations. Dialects generally have different reflexes \u2014 in fact, the different reflexes are used as a distinguishing feature between different dialects. For more details, see Finnish phonology.\nWord-final \"n\".\nOne important sound change, which has gone to completion in Estonian but occurs idiosyncratically in Finnish, is mutation of word-final into a glottal stop , orthographically represented by an apostrophe. In some dialects, such as Savo, word-final is systematically replaced by , e.g. \u2190 \"father's voice\". Both pronunciations can be heard in the Helsinki area. This means that the genitive/accusative form , which is very common in any form of Finnish, is simply noted by a glottal stop. However, this glottal stop undergoes sandhi whenever followed by consonant, or more often than not (see below).\nFinal vowels.\nCertain wordforms that end in in Standard Finnish occur without the word-final in the spoken language. This includes the base form of certain word stems as well as inflectional endings. In nouns this affects the translative case ending and the 2nd person singular possessive suffix . In verbs, loss of \"i\" affects the conditional mood ending and, in certain verb inflection classes where it is preceded by an \"s\", the preterite ending . These endings occur word-finally in 3rd person forms.\nIn many dialects loss of final \"i\" is commonplace not only in these cases but also elsewhere.\nParticularly in Helsinki, deletion of or , spelt \u00ab\u00e4\u00bb and \u00aba\u00bb, respectively, in highly frequent words is common. This is a feature of Western Finnish dialects, found also in Savonian dialects and Estonian. \n \u2014 'but'\n \u2014 'yes'\n \u2014 elative case, 'out of / away from the inside of'\nVowel clusters and diphthongs.\nWord-final vowel clusters ending in or have much variation in dialects of Finnish. Especially in Helsinki they assimilate, where only the resulting chroneme marks the partitive in many words.\n \u2014 \"I speak Finnish\"\n \u2014 \"(some) long (things)\"; partitive plural of , long\nAn or cluster also appears in many adjectives:\n \u2014 \"dark\"\nIn other areas of Finland, these clusters may have a different fate. Another common dialectal variant is the raising of to in the adjectives: . (Partitives are unaffected by this.) Some rarer versions of this suffix include , , and even .\nSimilar to the diphthongization of older to (unchanged in standard Estonian), many eastern dialects of Finnish diphthongize also the long vowels to . In Savonian dialects, these have shifted further on to .\n can become when in contact with another vowel. In many cases this results from colloquial deletion of . For example:\nSandhi.\nA related phenomenon is the final consonant sandhi. When two words co-occur in the same prosodic unit, the consonant beginning the second word assimilates to the word-final consonant in the first word, creating a long consonant. This is not commonly written down, except in dialectal transcriptions. For example, \nPersonal pronouns.\nSome dialects have the full-length personal pronouns and , but most people use shorter forms, like these found in the Helsinki metropolitan area region:\n \u2192 \nNote: these do differ depending on where the speaker is from. For example can also be , , etc.\nThe root words are also shorter:\n \u2192 , e.g. \u2192 \"my\"\n \u2192 , e.g. \u2192 \"yours\"\nThe third-person pronouns ('he', 'she', singular 'they') and (plural 'they'), are rarely used in the spoken language outside of Southwestern Finland and are getting rare there, as well. Elsewhere, they are usually replaced by and , which in the standard language do not refer to people.\n \u2192 \nFor example, the sentence \"Did he mistake me for you?\" has these forms:\n or \nSimilarly, non-personal demonstrative pronouns are often used in place of or , meaning people may be referred to as 'that' and 'those'. This also does not carry any pejorative meaning. The words are also changed from their written form.\n \u2192 \u2192 \nFor example, when pointing out a culprit, the sentence \"He broke it.\" has these forms:\n or \nNumerals.\nNumerals 1\u201310 in colloquial spoken Finnish:\nNumbers 11-19 are formed by appending , which can be shortened to . Numbers 20-90 are formed by appending , which can be shortened to or even . , and can be abbreviated to , and with , but not independently, as in \"33\" or \"74\".\nWhen counting out loud, even shorter forms are used, mostly one-syllable words with long vowels:\n becomes , or even . becomes , with 20-60 typically retaining their longer numeral forms (e.g. rather than for 20). 70 is typically or , while 80 and 90 do with and .\nThe numerals 1\u20139 have their own names, different from the cardinal numbers used in counting. Numbers that have longer names are often shortened in speech. This may be problematic for a foreigner to understand, if they have learnt words by book:\n (number one)\n (number two)\n (number three)\n (number four)\n (number five) \u2192 , (Helsinki slang)\n (number six) \u2192 \n (number seven) \u2192 \n / (number eight) \u2192 / \n / (number nine) \u2192 / \n \u2192 , (Helsinki slang)\nThe suffix normally denotes a group of x people, but on 8 and 9, it doubles as a synonym for the numeral's name. is also used to describe a figure eight shape.\nThe regular / forms can additionally be used of objects with an ID number. For example, bus 107 is called , and a competition winner is an (not or .)\nVerbs.\nPronoun usage.\nPersonal pronouns are used extensively in spoken Finnish whereas in formal forms the pronoun is often optional (indicated in brackets in this article). Furthermore, the pronouns themselves in spoken Finnish are different from those used in formal Finnish.\nPersonal pronouns and are used extensively in colloquial Finnish in place of and ('I' and singular 'you'). The pronouns and , which in the formal language are used only as non-human personal pronouns meaning ('it' and plural 'they'), are used in the spoken language as personal pronouns (which in the formal language would be ('he', 'she' and singular 'they') and (plural 'they').\nSee the tables below for examples.\nVerb forms.\nOne striking difference between colloquial Finnish and formal Finnish is use of the passive form in the first person plural. Thus for example:\n (formal language)\n (colloquial Finnish)\nWe're in Helsinki\nAnother is that the third person plural suffix or is not used in the spoken language; instead, the third person \"singular\" form is used with plural meaning being conveyed by the pronoun ()\nTherefore, the full present-tense paradigm of \"to speak\" in everyday speech is:\n (spoken) \u2014 (standard)\n \u2014 \n \u2014 \nSome \"e\"-stem verbs have abbreviated (irregular) oblique forms, where or is elided. This class includes only four frequently used verbs. In Finnish, verbs have an infinitive form, marked with and used in the infinitive, and an oblique form, which is used in personal forms. Consonant gradation and assimilation of the 't' in may be applied. In the standard language, the correspondence between the two is always regular. In spoken language, some verbs have assimilated oblique forms, while retaining the regular infinitive:\nFor example, these forms, as such, are represented by the imperatives:\n (standard)\n (word-by-word) \"Go or come, but put the door closed and be quiet.\"\nTo demonstrate the use of the personal form, the reply is:\n (\"I go or come, (I) put the door closed and (I) am quiet\").\nThe infinitives are unchanged, as in:\n (\"To go or to come, to put the door closed and to be quiet\").\nAs are participles, despite their using the oblique stem:\n (\"Going or coming, door closed-putting and quiet-being\").\nThe 't' at the end of participles ending (or etc.) is often dropped when no consonant follows, or replaced by gemination of the following consonant:\n (formal)\n (colloquial)\nI didn't speak\nbut:\n (colloquial)\nI didn't speak to anyone\nis actually pronounced as if it were:\n (with examples of gemination)\nIn the formal language some pronouns are considered optional, but in spoken language the pronoun is usually enunciated but may be optional when answering questions (which puts the person in the proper context).\n or (\"We are going to Oulu\") (formal language)\n (\"We are off to Oulu\") (informal language)\nIn the latter example, dropping would change the meaning from a statement to a suggestion:\n (\"Let's go to Oulu\") (informal or spoken language suggestion)\nCompare the conjugation of in the formal language (Table 1) and in the spoken or colloquial language (Table 2). Table 2 shows in highlights the areas where there are differences in the structures between formal and informal. Optional pronouns are in brackets. English equivalent is in Table 3.\nQuestions.\nIn everyday speech, the suffix has the clitic added, becoming , which in turn reduces to :\n \u2192 \"am I alive?\"\n \u2192 or \"do you (sg.) speak English?\"\n \u2192 (via ) \"did he/she come yet?\"\nThe choice of morphemes or is not always purely dialectal or accidental. Many Finns regularly use more than one variation in their speech. The choice might depend among others on the rhythm of the sentence or the (wished) tempo of the discussion. Sometimes it has other clearly communicational purposes e.g. the longer variation might be used to soften an intruding question.\nThe clitic is also found in imperatives, e.g. \"(I expect you to) go!\" It can also be, that the elides not to , but before a 's', e.g. ? . Because this is identical to except for the word order, questions are indicated by word order.\nPossessive suffix.\nSpoken language has a different grammar for the possessive suffix. In contrast to the literary language, the suffix is optional and typically omitted. Compare English in which, e.g., \"The house to which this door belongs\" would be the correct written form even though \"the house whose door this is\" would be the more common spoken version.\nHere, the pronoun of the literary form is also shown.\nNotice that Finnish has no possessive adjectives. The pronouns are regularly inflected, like if \"I's house\", \"you's house\", \"we's house\".\nHowever, the suffixes , and are used to avoid repeating a pronoun, e.g. \"He took his hat and left\" is (The translation from English * would mean \"He took his/her hat and left\" or \"He took the (specific) hat and left\").\nOmission of the negative verb.\nWhen a negative sentence is formed, the main verb goes into the connegative form, which is identical to the imperative mood, and gives all of its inflections to the negative verb , e.g. \u2192 . Usually the word (\"anything\") and an expletive is added to the sentence. This means that even if the negative verb is left out, the meaning is indicated by this context. For example:\n \"He doesn't know anything.\"\n \"He know anything.\" (\"doesn't\" omitted)\nThis omission of the negative verb is considered one of the most recent changes in Finnish. Usually this construction indicates mistrust or frustration. (A parody article by Jaakko H\u00e4kkinen calls this , see aggressive mood.) However, it can be a neutral negative statement: (From this article, you don't learn anything).\nRegional variation.\nLinguists such as Mielik\u00e4inen argue that the dialects of Finnish have been considerably homogenized by 20th century developments of urbanization and other internal population movements to the point that \"pure\" dialects have disappeared. \"Local spoken languages\" have developed from standard Finnish to give variety with essentially standard Finnish structure but with some local features. Considerable stigma has been associated with dialects (accurately or not) perceived as rural in the 20th century. People who have moved to the city have adopted a variety resembling standard Finnish, which has been imposed upon dialect speakers by the school, the military and the employers.\nBreaking up some consonant clusters on syllable boundaries with an epenthetic vowel is a feature of several dialects, such as South Ostrobothnian dialect and Savo dialects: The neutral vowel is the same as the preceding vowel. For example, \u2192 \"celebration\", \u2192 \"strait\", \u2192 \"service\", \u2192 \"cheap\", \u2192 (via ) \"letter F\". Pairs of dissimilar consonants with or (in Savo, also ) as the first consonant are subject to epenthesis; other clusters or geminates are not. However, a strong epenthetic vowel is seen as dialectal, and in Helsinki and urbanized areas, indicates origins \"in the countryside\" (since for Helsinki people, everything but Helsinki is rural).\nTavastian dialects.\nTavastian dialects are diverse because other, surrounding dialects have influenced them. The following features are all found in Finnish spoken in Helsinki, and many of them occur also in some other Tavastian dialects.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50433", "revid": "34458314", "url": "https://en.wikipedia.org/wiki?curid=50433", "title": "Finnish phonology", "text": "System of sounds of the Finnish language\nUnless otherwise noted, statements in this article refer to Standard Finnish, which is based on the dialect spoken in the former H\u00e4me Province in central south Finland. Standard Finnish is used by professional speakers, such as reporters and news presenters on television.\nVowels.\nFinnish has a phonological contrast between single () and double () vowels. Phonetically long vowels are single continuous sounds () where the extra duration of the hold phase of the vowel signals that they count as two successive vowel phonemes rather than one. Long mid vowels are more common in unstressed syllables.\nDiphthongs.\nThe table below lists the conventionally postulated diphthongs in Finnish. In speech (i.e. phonetically speaking) a diphthong does not sound like a sequence of two different vowels; instead, the sound of the first vowel gradually glides into the sound of the second one with full vocalization lasting through the whole sound. That is to say, the two portions of the diphthong are not broken by a pause or stress pattern. In Finnish, diphthongs contrast with both long vowels and short vowels. Phonologically, however, Finnish diphthongs are usually analyzed as sequences of two vowels (this in contrast to languages like English, where the diphthongs are best analyzed as independent phonemes).\nDiphthongs ending in can occur in any syllable, but those ending in rounded vowels usually occur only in initial syllables, and rising diphthongs are confined to that syllable. It is usually taught that diphthongization occurs only with the combinations listed. However, there are recognized situations in which other vowel pairs diphthongize. For example, in rapid speech the word ('upper part', from , 'upper' + , 'part') can be pronounced (with the diphthong ). The usual pronunciation is (with those vowels belonging to separate syllables).\nThe diphthongs and are quite rare and mostly found in derivative words, where a derivational affix starting with (or properly the vowel harmonic archiphoneme ) fuses with the preceding vowel, e.g. 'darkness' from 'dark' + '-ness' and 'to tidy up oneself' from 'tidy' + (a kind of middle voice) + (infinitive suffix). Older and in initial syllables have been shifted to and .\nOpening diphthongs are in standard Finnish only found in root-initial syllables like in words 'to know', 'rear wheel' (from 'back, rear' + 'wheel'; the latter part is secondarily stressed) or 'towards'. This might make them easier to pronounce as true opening diphthongs (in some accents even wider opening ) and not as centering diphthongs , which are more common in the world's languages. The opening diphthongs come from earlier doubled mid vowels: . Since that time new doubled mid vowels have come to the language from various sources.\nAmong the phonological processes operating in Finnish dialects are diphthongization and diphthong reduction. For example, Savo Finnish has the phonemic contrast of vs. vs. instead of standard language contrast of vs. vs. .\nVowel harmony.\nFinnish, like many other Uralic languages, has the phenomenon called vowel harmony, which restricts the cooccurrence in a word of vowels belonging to different articulatory subgroups. Vowels within a word \"harmonize\" to be either all front or all back. In particular, no native noncompound word can contain vowels from the group {\"a\", \"o\", \"u\"} together with vowels from the group {\"\u00e4\", \"\u00f6\", \"y\"}. Vowel harmony affects inflectional suffixes and derivational suffixes, which have two forms, one for use with back vowels, and the other with front vowels. Compare, for example, the following pair of abstract nouns: 'government' (from , 'to reign') versus 'health' (from , healthy).\nThere are exceptions to the constraint of vowel harmony. For one, there are two front vowels that lack back counterparts: and . Therefore, words like 'clock' (with a front vowel in a non-final syllable) and 'wind' (with a front vowel in the final syllable), which contain or together with a back vowel, count as back vowel words; and are effectively neutral in regard to vowel harmony in such words. and yield the inflectional forms 'in a clock' and 'in a wind'. In words containing only neutral vowels, front vowel harmony is used, e.g. \u2013 ('road' \u2013 'on the road'). For another, compound words do not have vowel harmony across the compound boundary; e.g. 'wall clock' (from , 'wall' and , 'clock') has back cooccurring with front . In the case of compound words, the choice between back and front suffix alternants is determined by the immediately-preceding element of the compound; e.g. 'in a wall clock' is , not .\nA particular exception appears in a standard Finnish word, ('this kind of'). Although by definition a singular word, it was originally a compound word that transitioned over time to a more compact and easier form: (from , 'of this' and , 'kind') \u2192 \u2192 , and in colloquial speech sometimes further to .\nNew loan words may exhibit vowel disharmony; for example, ('Olympic games') and ('secondary') have both front and back vowels. In standard Finnish, these words are pronounced as they are spelled, but many speakers apply vowel harmony \u2013 , and or .\nConsonants.\n does not appear in native phonology; however, it exists in the variation between foreign-origin geminate and native consonant cluster in many loanwords, retrogradely occurring also in the native word \"ahven\" 'perch' in some southwestern dialects (dialectal as \"ahvena\" ~ \"affena\" ). Generally, is reliably distinguished by Finnish speakers, but other foreign fricatives are not. or appears only in non-native words, sometimes pronounced , although most speakers make a distinction between e.g. 'chess' and 'a gang (of people)'. The orthography also includes the letters and , although their use is marginal, and they have no phonemic status. For example, and may be pronounced and without fear of confusion. The letter , found mostly in foreign words and names such as Zulu, may also be pronounced as following the influence of German, thus .\nVoiced plosives.\nTraditionally, and were not counted as Finnish phonemes, since they appear only in loanwords. However, these borrowings being relatively common, they are nowadays considered part of the educated norm. The failure to use them correctly is often ridiculed in the media, e.g. if a news reporter or a high official consistently and publicly realises ('Belgium') as . Even many educated speakers, however, still make no distinction between voiced and voiceless plosives in regular speech if there is no fear of confusion. Minimal pairs do exist: 'a bus' vs. 'a bag', 'a gorilla' vs. 'on a basket'.\nThe status of is somewhat different from and , since it also appears in native Finnish words, as a regular 'weak' correspondence of the voiceless (see Consonant gradation below). Historically, this sound was a fricative, , varyingly spelled as or in Old Literary Finnish (which is based on southwestern dialects), and realised in native dialects with significantly large allophony of frontal consonants or even completely degraded depending on the dialectal gradation features. Its realization as a plosive originated as a spelling pronunciation, in part because when mass elementary education was instituted in Finland, the spelling in Finnish texts was mispronounced as a plosive, under the influence of how Swedish speakers would pronounce this letter. Initially, few native speakers of Finnish acquired the foreign plosive realisation of the native phoneme. As for loanwords, was often assimilated to as a strong grade consonant. Even well into the 20th century it was not entirely exceptional to hear loanwords like ('a deodorant') pronounced as , while native Finnish words with a were pronounced in the usual dialectal way. Due to diffusion of the standard language through mass media and basic education, and due to the dialectal prestige of the capital area, the plosive can now be heard in all parts of the country, at least in loanwords and in formal speech.\nConsonant gradation.\nConsonant gradation in Finnish involves alternations between a \"strong grade\" and a \"weak grade\" of consonants, influenced by both phonological and grammatical factors. Historically, a consonant would shift to its weak grade if it was part of a closed syllable. However, due to language evolution, there are now instances where the weak grade may or may not appear regardless of the syllable being open or closed, such as in \"Turkuun\" where the strong grade appears in a closed syllable. Grammatically, the weak grade typically shows up in nouns, pronouns, and adjectives before case suffixes, and in verbs before person agreement suffixes.\nThe following is a general list of strong\u2013weak correspondences.\nOther consonant alternations.\nMany of the remaining \"irregular\" patterns of Finnish noun and verb inflection are explained by a change of a historical to . The change from to , a type of assibilation, is unconnected to consonant gradation, and dates back as early as Proto-Finnic. In modern Finnish the alternation is not productive, due to new cases of the sequence having been introduced by later sound changes and loanwords, and assibilation therefore occurs only in certain morphologically defined positions.\nWords having this particular alternation are still subject to consonant gradation in forms that lack assibilation. Thus Finnish nouns of this type could be seen as having up to five distinct stems: a word such as 'water (sg. nom.)' has the forms (sg. gen.), (sg. part.), (sg. ill.) (pl. part.); as can be seen from the examples the change from to has only occurred in front of . When a vowel other than occurs, words like inflect just like other nouns with a single alternating with the consonant gradated . Alternatively, Kiparsky proposes that all Finnish stems must end in a vowel, which in the case of polysyllabic stems may then be deleted when adding certain affixes and certain other conditions are fulfilled. For he proposes the stem /vete/ (with stem final -e), which when combined with the partitive singular affix -t\u00e4/-ta drops the -e to become (sg. part.).\nThis pattern has, however, been reverted in some cases. Variation appears in particular in past tense verb forms, e.g. , ('to deny', 'denied') but , ('to adjust', 'adjusted'). Both alternate forms ( and ) can also be found in dialects. Apparently this was caused by word pairs such as , ('bring') and , ('rise'), which were felt important enough to keep them contrastive.\nAssibilation occurred prior to the change of the original consonants cluster to , which can be seen in the inflection of the numerals , and , .\nIn many recent loanwords, there is vacillation between representing an original voiceless consonant as single or geminate: this is the case for example (~ ) and (~ ). The orthography generally favors the single form, if it exists. (More completely assimilated loans such as , , generally have settled on geminates.)\nLength.\nAll phonemes except and can occur doubled phonemically as a phonetic increase in length. Consonant doubling always occurs at the boundary of a syllable in accordance with the rules of Finnish syllable structure.\nSome example sets of words:\n 'fire'/'s/he came', 'wind', 'customs'\n 'mud', 'other' (partitive sg.), 'but', 'to change' or 'to move'\nA double is rare in standard Finnish, but possible, e.g. , a derogatory term for a religious fanatic. In some dialects, e.g. Savo, it is common: , or standard Finnish 'money' (in the partitive case). The distinction between and is found only in foreign words; natively 'd' occurs only in the short form. While and may appear as geminates when spoken (e.g. , ), this distinction is not phonemic, and is not indicated in spelling.\nPhonotactics.\nThe phonemic template of a syllable in Finnish is (C)V(C)(C), in which C can be an obstruent or a liquid consonant. V can be realized as a doubled vowel or a diphthong. A final consonant of a Finnish word, though not a syllable, must be a coronal one; Standard Finnish does not allow final clusters of two consonants.\nOriginally Finnish syllables could not start with two consonants but many loans containing these have added this to the inventory. This is observable in older loans such as &lt; Swedish ('French') contrasting newer loans &lt; Swedish ('president'). In past decades, it was common to hear these clusters simplified in speech (), particularly, though not exclusively, by either rural Finns or Finns who knew little or no Swedish or English. Even then, the Southwestern dialects formed an exception: consonant clusters, especially those with plosives, trills or nasals, are common: examples include place names and near the town Pori, or town ('Kristinestad'). Nowadays the overwhelming majority of Finns have adopted initial consonant clusters in their speech.\nConsonant phonotactics.\nConsonant phonotactics are as follows.\nWord-final consonants\nWord-initial consonants\nWord-initial consonant clusters\nWord-final consonant clusters\nWord-medial consonant clusters\nVowel phonotactics.\nVowel phonotactics are as follows.\nWord-final and word-initial vowels\nVowel sequences\n, and are allowed by phonotactics, but they are rare because they underwent a sound change in Proto-Finnic to , and . They have been reintroduced in loanwords (e.g. \"peesata\", \"hoonata\", \"amat\u00f6\u00f6ri\").\nProsody.\nStress.\nStress in Finnish is non-phonemic. Like Hungarian and Icelandic, Finnish primary stress always occurs on the first syllable of a word. Secondary stress normally falls on odd-numbered syllables. Contrary to primary stress, Finnish secondary stress is quantity sensitive. Thus, if secondary stress would normally fall on a light (CV.) syllable but this is followed by a heavy syllable (CVV. or CVC.), the secondary stress moves one syllable further (\"to the right\") and the preceding foot (syllable group) therefore contains three syllables. Thus, (\"as my apple\") contains light syllables only and has primary stress on the first syllable and secondary on the third, as expected: \"\u00f3men\u00e0nani\". On the other hand, ('as our apple') has a light third syllable () and a heavy fourth syllable (), so secondary stress falls on the fourth syllable: \"\u00f3menan\u00e0mme\".\nCertain Finnish dialects also have quantity-sensitive main stress pattern, but instead of moving the initial stress, they geminate the consonant, so that e.g. light-heavy CV.CVV becomes heavy-heavy CVCCVV, e.g. the partitive form of \"fish\" is pronounced in the quantity-insensitive dialects but in the quantity-sensitive ones (cf. also the examples under the \"Length\" section).\nSecondary stress falls on the first syllable of non-initial parts of compounds, for example the compound , meaning \"wooden face\" (from , 'tree' and , 'face'), is pronounced but , meaning \"which was cleaned\" (preceded by an agent in the genitive, \"by someone\"), is pronounced .\nTiming.\nFinnish is not really isochronic at any level. For example, ('shouting') and ('flushing') are distinct words, where the initial syllables and are of different length. Additionally, acoustic measurements show that the first syllable of a word is longer in duration than other syllables, in addition to its phonological doubling, unless it is an open syllable containing a short vowel in which case the second syllable has a longer duration.\nSandhi.\nFinnish sandhi is extremely frequent, appearing between many words and morphemes, in formal standard language and in everyday spoken language. In most registers, it is never written down; only dialectal transcriptions preserve it, the rest settling for a morphemic notation. There are two processes. The first is simple assimilation with respect to place of articulation (e.g. &gt; ). The second is predictive gemination of initial consonants on morpheme boundaries.\nSimple phonetic incomplete assimilations include:\nGemination of a morpheme-initial consonant occurs when the morpheme preceding it ends in a vowel and belongs to one of certain morphological classes. Gemination or a tendency of a morpheme to cause gemination is sometimes indicated with an apostrophe or a superscripted \"x\", e.g. . Examples of gemination:\n e.g. ('open-box bed for wood chips')\n e.g. ('buy a boat')\n ('actually, don't do it')\n ('it will not be taken after all', colloquially 'we won't take it after all')\n ('I probably will not do it (after all)', formal or poetic speech)\n e.g. \nThe gemination can occur between morphemes of a single word as in + \u2192 ('to me too'; orthographically ), between parts of a compound word as in + \u2192 ('family meeting'; orthographically ), or between separate words as in + \u2192 ('come here!'). In elaborate standard language, the gemination affects even morphemes with a vowel beginning: + \u2192 or ('take an apple!'). In casual speech, this is however often rendered as without a glottal stop.\nThese rules are generally valid for the standard language, although many Southwestern dialects, for instance, do not recognise the phenomenon at all. Even in the standard language there is idiolectal variation (disagreement between different speakers); e.g. whether ('three') should cause a gemination of the following initial consonant or not: or ('three crows'). Both forms occur and neither one of them is standardised, since in any case it does not affect writing. In some dictionaries compiled for foreigners or linguists, however, the tendency of geminating the following consonant is marked by a superscript as in .\nHistorically, morpheme-boundary gemination is the result of regressive assimilation. The preceding word originally ended in or . For instance, the modern Finnish word for 'boat' used to be (a form still existing in the closely related Karelian language). At some point in time, these and s were assimilated by the initial consonant of a following word, e.g. ' ('the boat is moving'). Here we get the modern Finnish form (orthographically ), even though the independent form has no sign of the old final consonant .\nIn many Finnish dialects, including that of Helsinki, the gemination at morpheme boundaries has become more widespread due to the loss of additional final consonants, which appear only as gemination of the following consonant, cf. French liaison. For example, the standard word for 'now' has lost its and become in Helsinki speech. However, + ('now it [does something]') is pronounced and not (although the latter would be permissible in the dialect of Turku).\nSimilar remnants of a lost word-final can be seen in dialects, where e.g. the genitive form of the first singular pronoun is regularly (standard language ): + + \u2192 ('it is mine'). Preceding an approximant, the is completely assimilated: ('my wife'). Preceding a vowel, however, the however appears in a different form: + \u2192 or even ('my own').\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
