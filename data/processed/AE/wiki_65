{"id": "52622", "revid": "31696229", "url": "https://en.wikipedia.org/wiki?curid=52622", "title": "2002 FIFA World Cup", "text": "Association football tournament in South Korea and Japan\nInternational football competition\nThe 2002 FIFA World Cup, also branded as Korea Japan 2002, was the 17th FIFA World Cup, the quadrennial football world championship for men's national teams organized by FIFA. It was held from 31 May to 30 June 2002 at sites in South Korea and Japan, with its final match hosted by Japan at International Stadium in Yokohama.\nA field of 32 teams qualified for this World Cup, which was the first to be held in Asia, the first to be held outside of the Americas or Europe, as well as the first to be jointly hosted by more than one nation. Four teams (China, Ecuador, Senegal, and Slovenia) made their World Cup debuts, with Senegal being the only debutant to advance from the Group Stages and make it to the quarter-finals.\nThe tournament had several upsets and surprise results, which included the defending champions France being eliminated in the group stage after earning a single point without scoring a goal, and second favorites Argentina also being eliminated in the group stage. South Korea managed to reach the semi-finals, beating Poland, Portugal, Italy and Spain en route. They became the first team from outside of the UEFA, CONMEBOL, and CONCACAF regions to reach the semi-finals of a World Cup. Along with South Korea, Turkey made its first appearance in the semi-finals as well. However, the most potent team at the tournament, Brazil, prevailed, winning the final against Germany 2\u20130, making them the first and only country to have won the World Cup five times. In the third-place match against South Korea, Turkey won 3\u20132, taking third place in only their second ever FIFA World Cup, and scored the fastest goal in the FIFA World Cup history (10.8 seconds after kick-off).\nThe 2002 World Cup was also the last one to use the golden goal rule and the last one to use the same ball for all matches. Starting in 2006 and continuing to the present, a ball with the same technical specifications but different colors has been used in the final.\nHost selection.\nSouth Korea and Japan were selected as hosts by FIFA on 31 May 1996. Initially, South Korea, Japan and Mexico presented three rival bids. South Korea's entry into the race was seen by some as a response to the bid of political and sporting rival Japan. FIFA leaders were split on whom to favor as host as politics within the world governing body held sway. With Mexico regarded as a long shot, the battle to host the tournament came down to South Korea and Japan. The two Asian rivals went on a massive and expensive PR blitz around the world, prompting Sultan Ahmad Shah, the head of the Asian Football Confederation, to step in. FIFA boss Jo\u00e3o Havelange had long backed the Japanese bid, but his rival in FIFA, UEFA chief Lennart Johansson, sought to undermine Havelange's plans. UEFA and the AFC viewed co-hosting between the two Asian rivals as the best option. South Korea and Japan were finally faced with a choice of having no World Cup or a shared World Cup and they reluctantly chose to go along with co-hosting. South Korea and Japan were chosen unanimously as co-hosts in preference to Mexico. This was the first World Cup to be hosted by more than one country, the second being the 2026 World Cup, which will be hosted by the United States, Mexico and Canada. This is also the first ever World Cup to be hosted in Asia, the other being the 2022 World Cup hosted by Qatar twenty years later and the first World Cup to be held outside of Europe and the Americas. The general secretary of South Korea's bidding committee, Song Young-shik, stated that FIFA was interested in staging some matches in North Korea in order to aid Korean reunification, but it was ruled out. Though co-hosting the World Cup allowed Japan and South Korea to collaborate, the event did not significantly alter relations between the two countries, which have historically been strained. Even so, the World Cup promoted a global vision of cooperation between Japan and South Korea. After being prevented from hosting along with South Korea, North Korea decided to host their own sports event, the Arirang Mass Games, at the same time as the World Cup. This is not unlike their course of action during the 1988 Seoul Olympics, where they decided to host the 13th World Festival of Youth and Students simultaneously.\nAt the time the decision was made, Japan had never qualified for a World Cup final (although the Japanese did subsequently qualify for the 1998 competition). The only other countries to have been awarded a World Cup without previously having competed in a final tournament are Italy in 1934 and Qatar in 2022 (Uruguay hosted the first World Cup in 1930 so there was no prior tournament; they were defending Olympic champions from 1928).\nQualification.\n199 teams attempted to qualify for the 2002 World Cup. The qualification process began with the preliminary draw held in Tokyo on 7 December 1999. Defending champions France and co-hosts South Korea and Japan qualified automatically and did not have to play any qualification matches. This was the final World Cup in which the defending champions qualified automatically.\n14 places were contested by UEFA teams (Europe), five by CAF teams (Africa), four by CONMEBOL teams (South America), four by AFC teams (Asia) and three by CONCACAF teams (North and Central America and the Caribbean). The remaining two places were decided by playoffs between AFC and UEFA and between CONMEBOL and OFC (Oceania). Four nations qualified for the finals for the first time: China, Ecuador, Senegal and Slovenia.\nTurkey qualified for the first time since 1954, Poland and Portugal both qualified for the first time since 1986 and Costa Rica and Uruguay qualified for the first time since 1990. Sweden, Russia and the Republic of Ireland also returned after missing the 1998 World Cup. South Korea became the first nation from outside Europe or the Americas to appear five successive finals tournaments.\nAll seven previous World Cup-winning nations (Argentina, Brazil, England, France, Germany, Italy, and Uruguay) qualified, which broke the record of most previous champions at a tournament before the record was broken again in 2014.\nThe lowest ranked team that qualified was China PR (ranked 50th).\nList of qualified teams.\nThe following 32 teams, shown with final pre-tournament rankings, qualified for the final tournament:\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nVenues.\nSouth Korea and Japan each provided 10 venues, the vast majority of them newly built for the tournament. Groups A\u2013D played all their matches in South Korea and Groups E\u2013H played all their matches in Japan. The stadiums in Daegu, Suwon, Yokohama and Saitama all hosted 4 matches each, while the other 16 stadiums hosted 3 matches each. Notably, no matches were played in Tokyo, making it the second capital of a host country not to have a World Cup venue after Bonn of West Germany in 1974, but the cities of Saitama and Yokohama which are part of the Greater Tokyo Area did host matches.\nMatch officials.\nThere was much controversy over the refereeing in the tournament. Questionable decisions in the match between Italy and South Korea resulted in 400,000 complaints, and featured in ESPN's 10 most fabled World Cup controversies. The match between Spain and South Korea featured two controversially disallowed Spanish goals, which Iv\u00e1n Helguera referred to as \"a robbery\" and led to Spanish press brandishing the officials \"thieves of dreams\", though FIFA dismissed the incident as human error.\nSquads.\nThis was the first World Cup that featured squads of 23 players, an increase from 22 previously. Of the 23 players, three must be goalkeepers.\nDraw.\nThe FIFA Organising Committee announced the eight seeded teams on 28 November 2001. The historic tradition to seed the hosts (Japan and South Korea) and holders (France) was upheld while the remaining five seeds were granted to the other five of the top six teams\u2014ranked by their results in the last three FIFA World Cups (ratio 3:2:1) and their FIFA World Ranking position in the last month of the past three years (equal ratio).\nFor the draw, the 32 teams were allocated into four pots; the eight top-seeded teams, were allocated in pot 1 and would be drawn/selected into the first position of the eight groups playing in the group stage. The remaining 24 unseeded teams, were allocated into three pots based on geographical sections, with the: 11 European teams in pot 2; two Asian teams and three South American teams in pot 3; three North American teams and five African teams in pot 4.\nThe general principle was to draw one team from each pot into the eight groups, although with special combined procedures for pot 2 and pot 3, due to comprising more/less than eight teams - but sixteen teams in total. At the same time, the draw also needed to respect the geographical limitation, that each group cannot feature more than one team from each confederation, except for the European teams where the limitation was maximum two per group. Finally, special limitations were also stipulated to evenly distribute the presence of teams from each confederation between the groups playing respectively in Korea (group A-D) and Japan (group E-H); however, for political considerations, China could only be drawn for one of the groups playing in Korea.\nThe FIFA Organising Committee decided ahead of the draw to place the defending champions (France) in Group A while the co-hosts South Korea and Japan were placed in Group D and Group H respectively. The procedure for the draw comprised the following six steps:\nBesides of drawing the teams, the event also featured American vocalist Anastacia giving a debut public performance of the official song of the World Cup, \"Boom\". The draw was conducted by at the time FIFA general secretary Michel Zen-Ruffinen, and many celebrities helped with the draw such as former players Pel\u00e9, Johan Cruyff, Michel Platini, Enrique Borja and Roger Milla, players of the time like Hong Myung-bo and Masami Ihara, women's football player Sun Wen, women's football referee Im Eun-ju, mountain climber Park Young-seok, actress Song Hye-kyo and chess player Cho Hoon-hyun.\nDraw results and group fixtures.\nThe draw resulted in the following eight groups:\n&lt;br&gt;\nIn each group, the teams played three matches, one against each of the other teams. Victories were granted 3 points, while a draw was equal to 1 point. After completion of the group stage, the best two teams of each group advanced to the Round of 16 in the knockout stage, in a way so all group winners started out meeting a runner-up from one of the other groups. This format was identical with the tournament structure being used in 1998. A total of 64 games were played, including the final and a match for third place between the two semi-final losers.\nGroup F was considered the group of death as it brought together Argentina, England, Nigeria and Sweden.\nThe fixtures for the group stage were decided based on the draw results, as follows:\nGroup stage.\n\"All times are Korea Standard Time and Japan Standard Time ()\"\nGroups A, B, C and D based in South Korea. Groups E, F, G and H based in Japan.\nIn the following tables:\nThe teams in the group play were ranked upon\nIn the original version of the rules for the final tournament, the ranking criteria were in a different order, with head-to-head results taking precedence over total goal difference. The rules were changed to the above in advance of the tournament, but older versions were still available on the FIFA and UEFA websites, causing some confusion among those trying to identify the correct criteria.\nKnockout stage.\nFor the second round, quarter-finals, and semi-finals, the qualifiers from Groups A, C, F, and H played their games in Japan while the qualifiers from Groups B, D, E, and G played their games in South Korea. Daegu, South Korea, hosted the third-place match while Yokohama, Japan, hosted the final.\nRound of 16.\nIn the round of 16, Germany beat Paraguay 1\u20130 with a late goal by Oliver Neuville in Seogwipo. England defeated Denmark in Niigata 3\u20130, with all goals occurring in the first half of the game. Sweden and Senegal faced off in \u014cita and finished 1\u20131 in regular time and it took a golden goal from Henri Camara in extra time to settle the game for Senegal 2\u20131, which led to Senegal becoming only the second African team to reach the last eight (after Cameroon in 1990). Spain and the Republic of Ireland played in Suwon, where Spain led most of the match 1\u20130 until a late penalty kick scored by Robbie Keane made the match go to extra time, where Spain emerged victorious in a penalty shoot-out. The United States beat CONCACAF rivals Mexico 2\u20130 in Jeonju with Brian McBride and Landon Donovan scoring the goals. Brazil defeated Belgium 2\u20130 in Kobe, with an amazing volley by Rivaldo and a splendid counter-attack goal by Ronaldo. Turkey ended co-hosts Japan's run with a 1\u20130 win in Miyagi, thanks to an \u00dcmit Davala goal in the 12th minute. The other co-hosts, South Korea, defeated Italy 2\u20131 in extra time in Daejeon with a goal by Ahn Jung-hwan in the 117th minute. South Korea's win ensured that, for the very first time in the Cup's history, teams from five continents \u2013 Europe, North America, South America, Africa and Asia \u2013 reached the quarter-finals of the same tournament.\nQuarter-finals.\nIn the quarter-finals, England and Brazil squared off in Shizuoka, where Ronaldinho scored a free-kick goal over England's David Seaman early in the second half as Brazil won 2\u20131. The United States lost to Germany 1\u20130 in Ulsan by a Michael Ballack goal in the 39th minute, but controversy surrounded the game when United States demanded the referee give a penalty for a goal-line handball by Torsten Frings in the 49th minute, but the referee did not award the penalty. South Korea got another success in Gwangju in a controversial manner, overcoming Spain 5\u20133 on penalties after a 0\u20130 draw in which the Spaniards twice thought they had scored while onside; however, the efforts were disallowed by the referee with controversial decisions. The hosts became the first team in the Asian Football Confederation to reach the semi-finals of the World Cup, eclipsing the record of their North Korean counterparts who reached the quarter-finals in 1966. They also became the first World Cup semi-final team not from UEFA or CONMEBOL since the United States did it in the first World Cup in 1930. Turkey defeated Senegal 1\u20130 in Osaka, with a golden goal scored by \u0130lhan Mans\u0131z in the 94th minute.\nSemi-finals.\nThe semi-finals saw two 1\u20130 games; the first semi-final, played in Seoul, saw Michael Ballack's goal suffice for Germany to eliminate South Korea. However, Ballack had already received a yellow card during the match before, which forced him to miss the final based on accumulated yellow cards. The next day in Saitama saw Ronaldo score a goal early in the second half, his sixth of the competition for Brazil, to defeat Turkey in a replay of their Group C encounter.\nThird place play-off.\nIn the third-place match in Daegu, Turkey beat the South Koreans 3\u20132, their first goal coming from Hakan \u015e\u00fck\u00fcr straight from the opening kick-off (even though South Korea kicked off) in 10.8 seconds, the fastest ever goal in World Cup history.\nFinal.\nIn the final match held in Yokohama, Japan, two goals from Ronaldo secured the World Cup for Brazil as they claimed victory over Germany. Ronaldo scored twice in the second half and, after the game, won the Golden Shoe award for the tournament's leading scorer with eight goals. This was the fifth time Brazil had won the World Cup, cementing their status as the most successful national team in the history of the competition. Brazil became the only team since Argentina in 1986 to win the trophy without needing to win a penalty shoot-out at some stage during the knockout phase and the total number of penalty shoot-outs (2) was the lowest since the four-round knockout format was introduced in 1986. Brazil also became the first team to win every match at a World Cup since 1970 and set a new record for highest aggregate goal difference (+14) for a World Cup winner. Brazil's captain Cafu, who became the first player to appear in three successive World Cup finals, accepted the trophy on behalf of the team.\nStatistics.\nGoalscorers.\nRonaldo won the Golden Shoe after scoring eight goals. In total, 161 goals were scored by 109 players, with three of them credited as own goals. Two of those own goals were in the same match, marking the first time in FIFA World Cup history that own goals had been scored by both teams in the same match.\nDisciplinary statistics.\n for Senegal against Uruguay, Jes\u00fas Arellano\n for Mexico against Italy *Fastest yellow card after coming on as a substitute: 3 minutes Alberto Garc\u00eda Aspe\n for Mexico against United States (introduced in the 78th minute) *Latest yellow card in a match without extra time: 90+4 minutes Pape Thiaw\n for Senegal against Sweden *Latest yellow card in a match with extra time: 115 minutes Choi Jin-cheul\n for South Korea against Italy *Fastest dismissal from kick off: 22nd minute Carlos Paredes\n for Paraguay against Slovenia *Fastest dismissal of a substitute: 12 minutes Shao Jiayi\n for China against Turkey (introduced in the 46th minute) *Latest dismissal in a match without extra time: 90+4 minutes Hakan \u00dcnsal\n for Turkey against Brazil *Latest dismissal in a match with extra time: 103 minutes Francesco Totti\n for Italy against South Korea *Shortest time difference between two yellow cards given to the same player: 3 minutes Carsten Ramelow\n for Germany against Cameroon (booked in the 37th minute and again in the 40th minute) *Most yellow cards (team): 19 Turkey *Most red cards (team): 2 Paraguay, Portugal, Turkey *Fewest yellow cards (team): 2 Nigeria *Most yellow cards (player): 3 Michael Ballack, Emre Bel\u00f6zo\u011flu, Beto, Tugay Kerimo\u011flu, Francesco Totti *Most red cards (player): 1 Roberto Acu\u00f1a, Beto, Claudio Caniggia, Nastja \u010ceh, Salif Diao, Thierry Henry, Rafael M\u00e1rquez, Alpay \u00d6zalan, Carlos Paredes, Jo\u00e3o Pinto, Carsten Ramelow, Ronaldinho, Shao Jiayi, Patrick Suffo, Francesco Totti, Hakan \u00dcnsal, Boris \u017divkovi\u0107 *Most yellow cards (match): 16 Cameroon vs Germany *Most red cards (match): 2 Brazil vs Turkey, Cameroon vs Germany, Slovenia vs Paraguay, Portugal vs South Korea *Fewest yellow cards (match): 0 Croatia vs Mexico, Germany vs Republic of Ireland, Nigeria vs England *Most cards in one match: 16 yellow cards and 2 red cards Cameroon vs Germany\nAwards.\n1Oliver Kahn is the only goalkeeper to have won the Golden Ball in FIFA World Cup history.\nFinal standings.\nAfter the tournament, FIFA published a ranking of all teams that competed in the 2002 World Cup finals based on progress in the competition, overall results and quality of the opposition.\nMarketing.\nSponsorship.\nThe sponsors of the 2002 FIFA World Cup are divided into three categories: FIFA World Cup Sponsors and South Korea and Japan Supporters.\nTicket sales problem.\nThe original domestic ticket allocation had fully sold out and the organising committee completed sales of tickets returned from the international allocation by the end of April. However, there were a significant number of empty seats at the opening matches. It was gradually revealed that the World Cup Ticketing Bureau (WCTB) still had unsold tickets in its possession. After FIFA agreed to sell this inventory, JAWOC undertook sales over telephone and WCTB handled the internet sales. For the second round Japan vs. Turkey match in Miyagi in particular, although it was reported by both parties that all tickets had been sold, some 700 seats remained empty.\nSymbols.\nMascot.\nThe official mascots of the 2002 World Cup were Ato, Kaz and Nik (the Spheriks), orange, purple and blue (respectively) futuristic CGI creatures. Playing their own version of soccer called Atmoball, Ato is the coach while Kaz and Nik are players. The three individual names were selected from shortlists by users on the Internet and at McDonald's outlets in the host countries.\nMatch ball.\nThe official match ball was the Fevernova, manufactured by Adidas.\nMusic.\nThe official song was \"Boom\". The official local song of this World Cup was \"Let's Get Together Now\". The official anthem was \"Anthem\".\nCultural event.\nThe official FIFA cultural event of the 2002 World Cup was a flag festival called \"Poetry of the Winds\". Held in Nanjicheon Park, an area of the World Cup Park close to Seoul World Cup Stadium, \"Poetry of the Winds\" was exhibited from 29 May to 25 June in order to wish success upon the World Cup and promote a festive atmosphere. During the flag art festival, hand-painted flags from global artists were displayed as a greeting to international guests in a manner that was designed to promote harmony.\nConcerns.\nThe World Cup was originally going to be hosted either in Japan or in South Korea, but in the end both rivals had decided to share the hosting duties thus making this World Cup the first to have multiple host nations. However, there were concerns regarding the selection of hosts due to logistical issues caused by fans traveling across two separate sovereign nations as well as whether some of the 20 stadiums to be constructed for the World Cup would be ready in time for it or not. While political and infrastructural problems were eventually overcome, there still remained the issue of East Asia's wet season which could disrupt the play. The timing of the tournament thus had been altered to mitigate as much as possible against such issues, with the tournament kicking off on May 31 and due to run until June 30, the earliest date for a World Cup final since 1986. \nThe time difference caused issues for fans worldwide especially in Europe, where people had to go to work when matches were played and were used to games taking place at other times. With games taking place in the European morning, some schools and businesses chose to open late on match days or set up communal watching events before the start of work.\nAftermath and legacy.\nThe tournament had a major economic impact on both South Korea and Japan, generating an estimated US$1.3\u00a0billion in revenue. Spending from World Cup tourists in South Korea created US$307\u00a0million in direct income and US$713\u00a0million in valued added. Japan spent an estimated US$5.6\u00a0billion on preparations for the event, which had a US$24.8\u00a0billion impact on the Japanese economy and accounted for 0.6% of their GDP in 2002.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52623", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=52623", "title": "Paleontologist", "text": ""}
{"id": "52624", "revid": "31", "url": "https://en.wikipedia.org/wiki?curid=52624", "title": "Altas Shrugged", "text": ""}
{"id": "52625", "revid": "8480552", "url": "https://en.wikipedia.org/wiki?curid=52625", "title": "Arab League", "text": "Regional organization\nThe Arab League (, ' ), officially the League of Arab States (, '), is a regional organization in the Arab world. The Arab League was formed in Cairo on 22 March 1945, initially with seven members: Egypt, Iraq, Transjordan, Lebanon, Saudi Arabia, Syria, and North Yemen. Currently, the League has 22 members.\nThe League's main goal is to \"draw closer the relations between member states and co-ordinate collaboration between them, to safeguard their independence and sovereignty, and to consider in a general way the affairs and interests of the Arab countries\". The organization has received a relatively low level of cooperation throughout its history.\nThrough institutions, notably the Arab League Educational, Cultural and Scientific Organization (ALECSO) and the Economic and Social Council of its Council of Arab Economic Unity (CAEU), the League facilitates political, economic, cultural, scientific, and social programmes designed to promote the interests of the Arab world. It has served as a forum for the member states to coordinate policy, arrange studies of and committees as to matters of common concern, settle inter-state disputes and limit conflicts such as the 1958 Lebanon crisis. The League has served as a platform for the drafting and conclusion of many landmark documents promoting economic integration. One example is the Joint Arab Economic Action Charter, which outlines the principles for economic activities in the region.\nEach member state has one vote in the Council of the Arab League, and decisions are binding only for those states that have voted for them. The aims of the league in 1945 were to strengthen and coordinate the political, cultural, economic and social programs of its members and to mediate disputes among them or between them and third parties. Furthermore, the signing of an agreement on \"Joint Defence and Economic Cooperation\" on 13 April 1950 committed the signatories to coordination of military defence measures. In March 2015, the Arab League General Secretary announced the establishment of a Joint Arab Force with the aim of counteracting extremism and other threats to the Arab States. The decision was reached while Operation Decisive Storm was intensifying in Yemen. Participation in the project is voluntary, and the army intervenes only at the request of one of the member states. Existing military cooperation between Arab league states and regional civil wars and terrorist threats were the impetuses for JAF's establishment.\nIn the early 1970s, the Economic Council put forward a proposal to create the Joint Arab Chambers of Commerce across international states. That led to the setting up of mandates to promote, encourage and facilitate bilateral trade between the Arab world and significant trading partners.\nHistory.\nFollowing adoption of the Alexandria Protocol in 1944, the Arab League was founded on 22 March 1945. The official headquarters of the League was the Boustan Palace in Cairo. It aimed to be a regional organisation of Arab states with a focus to developing the economy, resolving disputes and coordinating political aims. Other countries later joined the league. Each country was given one vote in the council. The first major action was joint intervention to keep Palestine from being divided into two states in keeping with the decision of the United Nations General Assembly. When Transjordan agreed to this proposal, Egypt intervened to prevent this from happening. It was followed by the creation of a mutual defence treaty two years later. A common market was established in 1965.\nThe Arab League has not achieved much cooperation throughout its history. According to Michael Barnett and Etel Solingen, the design of the Arab League reflects Arab leaders' individual concerns for regime survival: \"the politics of Arab nationalism and a shared identity led Arab states to embrace the rhetoric of Arab unity in order to legitimize their regimes, and to fear Arab unity in practice because it would impose greater restrictions on their sovereignty.\" The Arab League was \"specifically designed to fail at producing the kind of greater collaboration and integration that might have weakened political leaders at home.\"\nGeography.\nThe Arab League member states cover over and straddles two continents: Africa and Asia. The area largely consists of arid deserts, such as the Sahara. Nevertheless, it also contains several highly fertile lands like the Nile Valley, the Jubba Valley and Shebelle Valley in the Horn of Africa, the Atlas Mountains in the Maghreb, and the Fertile Crescent that stretches over Mesopotamia and the Levant. The area comprises deep forests in southern Arabia and parts of the world's longest river, the Nile.\nMembership.\nThe Charter of the Arab League, also known as the Pact of the League of Arab States, is the founding treaty of the Arab League. Adopted in 1945, it stipulates that \"the League of Arab States shall be composed of the independent Arab States that have signed this Pact.\"\nIn 1945, there were seven members, but the Arab League now has 22 members, including 10 African countries:\nand 7 observer states (note: the observer states below have been invited to participate during select Arab League sessions but do not hold voting privileges):\nSuspensions.\nEgypt was suspended from the Arab League on 26 March 1979 due to the Egypt\u2013Israel peace treaty, with the League's headquarters moving from Cairo to Tunis, Tunisia. In 1987, Arab League states restored diplomatic relations with Egypt, the country was readmitted to the League in May 1989 and the League's headquarters were moved back to Cairo in September 1990.\nLibya was suspended on 22 February 2011, following the outbreak of the first Libyan civil war. The Arab League voted to restore Libya's membership on 27 August 2011 by accrediting a representative of the National Transitional Council, which was the partially recognised interim government of the country.\nSyria was suspended on 16 November 2011 in the aftermath of the outbreak of the Syrian civil war. On 6 March 2013, the Arab League gave Syria's seat in the Arab League to the Syrian National Coalition, the largest opposition group. On 9 March 2014, secretary general Nabil Elaraby stated that Syria's seat would remain vacant until the opposition completed the formation of its institutions. In 2021, the Arab League initiated a process of normalisation between the Syrian Ba'athist government and other Arab nations. On 7 May 2023, at the meeting of the Council of the Arab League in Cairo, it was agreed to reinstate Syria's membership.\nPolitics and administration.\nThe Arab League is a political organization which tries to help integrate its members economically, and solve conflicts involving member states without asking for foreign assistance. It possesses elements of a state representative parliament while foreign affairs are often conducted under UN supervision.\nThe Charter of the Arab League endorsed the principle of an Arab nation-state while respecting the sovereignty of the individual member states. The internal regulations of the Council of the League and the committees were agreed in October 1951. Those of the Secretariat-General were agreed in May 1953.\nSince then, governance of the Arab League has been based on the duality of supra-national institutions and the sovereignty of the member states. Preservation of individual statehood derived its strengths from the natural preference of ruling elites to maintain their power and independence in decision making. Moreover, the fear of the richer that the poorer may share their wealth in the name of Arab nationalism, the feuds among Arab rulers, and the influence of external powers that might oppose Arab unity can be seen as obstacles towards a deeper integration of the league.\nMindful of their previous announcements in support of the Arabs of Palestine the framers of the Pact were determined to include them within the League from its inauguration. This was done by means of an annex that declared:\nIn September 1963, the Arab League appointed Ahmad Shukeiri as Representative of Palestine at the Arab League.xxviii At the Cairo Summit of 1964, the Arab League initiated the creation of an organisation representing the Palestinian people. The first Palestinian National Council convened in East Jerusalem on 29 May 1964. The Palestine Liberation Organization was founded during this meeting on 2 June 1964. Palestine was shortly admitted in to the Arab League, represented by the PLO. Today, State of Palestine is a full member of the Arab League.\nAt the Beirut Summit on 28 March 2002, the league adopted the Arab Peace Initiative, a Saudi-inspired peace plan for the Arab\u2013Israeli conflict. The initiative offered full normalisation of the relations with Israel. In exchange, Israel was required to withdraw from all occupied territories, including the Golan Heights, to recognise Palestinian independence in the West Bank and Gaza Strip, with East Jerusalem as its capital, as well as a \"just solution\" for the Palestinian refugees. The Peace Initiative was again endorsed at 2007 in the Riyadh Summit. In July 2007, the Arab League sent a mission, consisting of the Jordanian and Egyptian foreign ministers, to Israel to promote the initiative. Following Venezuela's move to expel Israeli diplomats amid the 2008\u20132009 Israel\u2013Gaza conflict, Kuwaiti member of parliament Waleed Al-Tabtabaie proposed moving Arab League headquarters to Caracas, Venezuela. On 13 June 2010, Amr Mohammed Moussa, Secretary-General of the Arab League, visited the Gaza Strip, the first visit by an official of the Arab League since Hamas' armed takeover in 2007.\nThe Arab League is a member of the China-Arab States Cooperation Forum (CASCF), which was formed in 2004. CASCF is the Arab League's earliest participation in a cooperation forum with another country or region. CASCF is the primarily multi-lateral coordination mechanism between the Arab states and China and within CASCF the Arab League represents its member states as a relatively unified force. The Arab League's coordination allows Arab states to negotiate actively for collective projects involving multiple states, such as railway projects, nuclear power projects, and Dead Sea initiatives.\nIn 2015, the Arab League voiced support for Saudi Arabian-led military intervention in Yemen against the Shia Houthis and forces loyal to former President Ali Abdullah Saleh, who was deposed in the 2011 uprising.\nOn 15 April 2018, in response to the Turkish invasion of northern Syria aimed at ousting U.S.-backed Syrian Kurds from the enclave of Afrin, the Arab League passed a resolution calling on Turkish forces to withdraw from Afrin.\nIn September 2019, the Arab League condemned Benjamin Netanyahu's plans to annex the eastern portion of the occupied West Bank known as the Jordan Valley.\nThe Arab League met in Cairo on 12 October 2019 to discuss Turkish offensive into north-eastern Syria. Upon meeting, its member states voted to condemn the Turkish offensive, dubbing it both an 'invasion' and an 'aggression' against an Arab state, adding that the organization saw it as a violation of international law.\nOn 9 September 2020, the Arab League refused to condemn the UAE's decision to normalize ties with Israel. Nevertheless, \"The goal all our Arab countries seek, without exception, is to end the occupation and establish an independent Palestinian state on the 1967 borders with East Jerusalem as its capital,\" Aboul Gheit said. In January 2024, the Arab League expressed support for South Africa's ICJ genocide case against Israel.\nList of summits.\nEmergency summits.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nMilitary.\nThe Joint Defence Council of the Arab League is one of the Institutions of the Arab League. It was established under the terms of the Joint Defence and Economic Co-operation Treaty of 1950 to coordinate the joint defence of the Arab League member states.\nThe Arab League as an organisation has no military Force, similar to the UN, but at the 2007 summit, the Leaders decided to reactivate their joint defence and establish a peacekeeping force to deploy in South Lebanon, Darfur, Iraq, and other hot spots.\nAt a 2015 summit in Egypt, member states agreed in principle to form a joint military force.\nEconomic resources.\nThe Arab League is rich in resources, such as enormous oil and natural gas resources in certain member states.\nEconomic achievements initiated by the League amongst member states have been less impressive than those achieved by smaller Arab organisations such as the Gulf Cooperation Council (GCC). Among them is the Arab Gas Pipeline, that will transport Egyptian and Iraqi gas to Jordan, Syria, Lebanon, and Turkey. As of 2013, a significant difference in economic conditions exist between the developed oil states of Algeria, Qatar, Kuwait and the UAE, and developing countries like the Comoros, Djibouti, Mauritania, Somalia, Sudan and Yemen.\nThe Arab League also includes great fertile lands in the southern part of Sudan. It is referred to as the food basket of the Arab World, the region's instability including the independence of South Sudan has not affected its tourism industry, that is considered the fastest growing industry in the region, with Egypt, UAE, Lebanon, Tunisia, and Jordan leading the way. Another industry that is growing steadily in the Arab League is telecommunications.\nEconomical achievements within members have been low in the league's history, other smaller Arab Organizations have achieved more than the league has, such as the GCC, but lately several major economic projects that are promising are to be completed, the Arab Gas Pipeline is to end by 2010, Connecting Egyptian and Iraqi Gas to Jordan, Syria and Lebanon, and then to Turkey thus Europe, a free trade Agreement (GAFTA) is to be completed by 1 January 2008, making 95% of all Arab products tax free of customs.\nTransport.\nThe Arab League is divided into five parts when it comes to transport, with the Arabian Peninsula and the Near East being entirely connected by air, sea, roads and railways. Another part of the League is the Nile Valley, made up of Egypt and Sudan. These two member states have started to improve the River Nile's navigation system to improve accessibility and thus foster trading. A new railway system is also set to connect the southern Egyptian city of Abu Simbel with the northern Sudanese city of Wadi Halfa and then to Khartoum and Port Sudan. The third division of the League is the Maghreb, where a 3,000\u00a0km stretch of railway runs from the southern cities of Morocco to Tripoli in Western Libya. The fourth division of the League is the Horn of Africa, whose member states include Djibouti and Somalia. These two Arab League states are separated by only ten nautical miles from the Arabian Peninsula by the Bab el Mandeb and this is quickly changing as Tarik bin Laden, the brother of Osama bin Laden, has initiated the construction of the ambitious Bridge of the Horns project, which ultimately aims to connect the Horn of Africa with the Arabian Peninsula via a massive bridge. The project is intended to facilitate and accelerate the already centuries-old trade and commerce between the two regions. The last division of the League is the isolated archipelago of the Comoros located off the coast of East Africa, which is not physically connected to any other Arab state, but still trades with other Arab League members.\nLiteracy.\nIn collecting literacy data, many countries estimate the number of literate people based on self-reported data. Some use educational attainment data as a proxy, but measures of school attendance or grade completion may differ. Because definitions and data collection methods vary across countries, literacy estimates should be used with caution. United Nations Development Programme, Human Development Report 2010. The Persian Gulf region has had an oil boom, enabling more schools and universities to be set up.\nDemographics.\nWhile Egyptians constitute the largest ethnic group in the Arab League, there are several other ethnic groups that also reside in the region, including Arabs, Berbers, Kurds, Somalis, Assyrians, Armenians, Nubians, Mandaeans, and Circassians. Each of these groups have their own distinct cultures, languages, and traditions. As of 1 July 2013, about 359 million people live in the states of the Arab League. Its population grows faster than in most other global regions. The most populous member state is Egypt, with a population of over 100 million. The least populated is the Comoros, with approximately 850,000 inhabitants.\nReligion.\nThe majority of the Arab League's citizens adhere to Islam, with Christianity being the second largest religion. At least 15 million Christians combined live in Egypt, Iraq, Jordan, Lebanon, Palestine, Sudan and Syria. In addition, there are smaller but significant numbers of Druze, Yazidis, Shabaks and Mandaeans. Numbers for nonreligious Arabs are generally not available, but research by the Pew Forum suggests around 1% of people in the MENA region are \"unaffiliated\".\nLanguages.\nThe official language of the Arab League is Literary Arabic, based on Classical Arabic. However, several Arab League member states have other co-official or national languages, such as Somali, Afar, Comorian, French, English, Berber and Kurdish. In most countries, there is a dominant non-codified spoken Arabic dialect.\nCulture.\nSports.\nThe Pan-Arab Games are considered the biggest Arab sporting event, which brings together athletes from all the Arab countries to participate in a variety of different sports.\nThe Union of Arab Football Associations organises the Arab Cup (for national teams) and the Arab Club Champions Cup (for clubs). Arab sport federations also exist for several games, include basketball, volleyball, handball, table tennis, tennis, squash and swimming.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52626", "revid": "20306027", "url": "https://en.wikipedia.org/wiki?curid=52626", "title": "Dutch Republic", "text": "Predecessor state of the Netherlands (1581\u20131795)\nThe Republic of the Seven United Netherlands (), also known as the United Provinces (of the Netherlands), and referred to in historiography as the Dutch Republic, was a confederation and great power that existed from 1588 until the Batavian Revolution in 1795. It was a predecessor state of the present-day Netherlands and the first independent Dutch nation state. The republic was established after seven Dutch provinces in the Spanish Netherlands revolted against Spanish rule, forming a mutual alliance against Spain in 1579 (the Union of Utrecht) and declaring their independence in 1581 (the Act of Abjuration), after which they confederated in 1588 (the Instruction of 12 April 1588) after the States General could not agree on a new monarch. The seven provinces it comprised were Groningen (present-day Groningen), Frisia (present-day Friesland), Overijssel (present-day Overijssel), Guelders (present-day Gelderland), Utrecht (present-day Utrecht), Holland (present-day North Holland and South Holland), and Zeeland (present-day Zeeland).\nAlthough the state was small and had only around 1.5\u00a0million inhabitants, it controlled a worldwide network of seafaring trade routes. Through its trading companies, the Dutch East India Company (VOC) and the Dutch West India Company (GWC), it established a Dutch colonial empire. The income from this trade allowed the Dutch Republic to compete militarily against much larger countries. Major conflicts were fought in the Eighty Years' War against Spain (from the foundation of the Dutch Republic until 1648), the Dutch\u2013Portuguese War (1598\u20131663), four Anglo-Dutch Wars (1652\u20131654, 1665\u20131667, 1672\u20131674, and 1780\u20131784), the Franco-Dutch War (1672\u20131678), War of the Grand Alliance (1688\u20131697), the War of the Spanish Succession (1702\u20131713), the War of Austrian Succession (1744\u20131748), and the War of the First Coalition (1792\u20131795) against the Kingdom of France.\nThe republic was more tolerant of different religions and ideas than contemporary states, allowing freedom of thought to its residents. Artists flourished under this regime, including painters such as Rembrandt, Johannes Vermeer, and many others. So did scientists, such as Hugo Grotius, Christiaan Huygens, and Antonie van Leeuwenhoek. Dutch trade, science, armed forces, and art were among the most acclaimed in the world during much of the 17th century, a period which became known as the Dutch Golden Age.\nThe republic was a confederation of provinces, each with a high degree of independence from the federal assembly: the States General. In the Peace of Westphalia (1648), the republic gained approximately 20% more territory, located outside the member provinces, which was ruled directly by the States General as Generality Lands. Each province was led by a ; this office was nominally open to anyone, but most provinces appointed a member of the House of Orange. The position gradually became hereditary, with the Prince of Orange simultaneously holding most or all of the stadtholderships, making him effectively the head of state. This created tension between political factions: the Orangists favoured a powerful stadtholder, while the Republicans favoured a strong States General. The Republicans forced two Stadtholderless Periods, 1650\u20131672 and 1702\u20131747, with the latter causing national instability and the end of great power status.\nEconomic decline led to the 1780\u20131787 Patriottentijd, a period of political instability. This unrest was temporarily suppressed by a Prussian invasion in support of the stadtholder. The French Revolution and subsequent War of the First Coalition reignited these tensions. Following military defeat by France, the stadtholder was expelled in the Batavian Revolution of 1795, ending the Dutch Republic, which was succeeded by the Batavian Republic.\nHistory.\nUntil the 16th century, the Low Countries\u2014corresponding roughly to the present-day Netherlands, Belgium, and Luxembourg\u2014consisted of a number of duchies, counties, and prince-bishoprics, almost all of which were under the supremacy of the Holy Roman Empire, with the exception of the County of Flanders, most of which was under the Kingdom of France.\nMost of the Low Countries had come under the rule of the House of Burgundy and subsequently the House of Habsburg. In 1549, Holy Roman Emperor Charles V issued the Pragmatic Sanction, which further unified the Seventeen Provinces under his rule. In 1568, the Netherlands, led by William I of Orange, together with Philip de Montmorency, Count of Hoorn, and Lamoral, Count of Egmont revolted against Charles's successor, Philip II of Spain, because of high taxes, persecution of Protestants by the government, and Philip's efforts to modernize and centralize the devolved-medieval government structures of the provinces. This was the start of the Eighty Years' War. During the initial phase of the war, the revolt was largely unsuccessful. Spain regained control over most of the rebelling provinces. This period is known as the \"Spanish Fury\" due to the high number of massacres, instances of mass looting, and total destruction of multiple cities, in particular Antwerp between 1572 and 1579.\nIn 1579, a number of the northern provinces of the Low Countries signed the Union of Utrecht, in which they promised to support each other in their defence against the Army of Flanders. This was followed in 1581 by the Act of Abjuration, the declaration of independence of the provinces from Philip II. Dutch colonialism began at this point, as the Netherlands was able to capture a number of Portuguese and Spanish colonies, particularly in the Asia-Pacific region. After the assassination of William of Orange on 10 July 1584, both Henry III of France and Elizabeth I of England declined offers of sovereignty. However, the latter agreed to turn the United Provinces into a protectorate of England (Treaty of Nonsuch, 1585), and sent the Earl of Leicester as governor-general. This was unsuccessful, and with the instruction of 12 April 1588, the United Provinces became a republic. The Union of Utrecht is regarded as the foundation of the Republic of the Seven United Provinces, which was not recognized by Spain until the Peace of Westphalia in 1648.\nReligious toleration and refugees.\nAn important factor in the growth of the Netherlands as an economic power was the influx of groups seeking religious toleration of the Dutch Republic. In particular, it became the destination of Portuguese and Spanish Jews fleeing the Inquisitions in Iberia in the sixteenth and seventeenth centuries. and later, poorer German Jews. The Portuguese Jewish community had many wealthy merchants who, both lived openly as Jews and participated in the thriving economy on a par with wealthy Dutch merchants. The Netherlands became home to many other notable refugees, including Protestants from Antwerp and Flanders, which remained under Spanish Catholic rule; French Huguenots; and English Dissenters, including the Pilgrim Fathers. Many immigrants came to the cities of Holland in the 17th and 18th century from the Protestant parts of Germany and elsewhere. The number of first-generation immigrants from outside the Netherlands in Amsterdam was nearly 50% in the 17th and 18th centuries. Amsterdam, which was a hub of the Atlantic world, had a population primarily of immigrants and others not considered Dutch, if one includes second and third generation immigrants. There were also migrants from the Dutch countryside. People in most parts of Europe were poor and many were unemployed. But in Amsterdam there was always work. Religious toleration was important, because a continuous influx of immigrants was necessary for the economy. Travellers visiting Amsterdam reported their surprise at the lack of control over the influx.\nEconomic growth.\nThe era of explosive economic growth is roughly coterminous with the period of social and cultural bloom that has been called the Dutch Golden Age, and that actually formed the material basis for that cultural era. Amsterdam became the hub of world trade, the center into which staples and luxuries flowed for sorting, processing, and distribution, and then reexported around Europe and the world.\nDuring 1585 through 1622 there was the rapid accumulation of trade capital, often brought in by refugee merchants from Antwerp and other ports. The money was typically invested in high-risk ventures like pioneering expeditions to the East Indies to engage in the spice trade. These ventures were soon consolidated in the Dutch East India Company (VOC). There were similar ventures in different fields however, like the trade on Russia and the Levant. The profits of these ventures were ploughed back in the financing of new trade, which led to its exponential growth.\nRapid industrialization led to the rapid growth of the nonagricultural labor force and the increase in real wages during the same time. In the half-century between 1570 and 1620 this labor supply increased 3 percent per annum, a truly phenomenal growth. Despite this, nominal wages were repeatedly increased, outstripping price increases. In consequence, real wages for unskilled laborers were 62 percent higher in 1615\u20131619 than in 1575\u20131579.\nAmsterdam.\nBy the mid-1660s Amsterdam had reached the optimum population (about 200,000) for the level of trade, commerce and agriculture then available to support it. The city contributed the largest quota in taxes to the States of Holland which in turn contributed over half the quota to the States General. Amsterdam was also one of the most reliable in settling tax demands and therefore was able to use the threat to withhold such payments to good effect.\nAmsterdam was governed by a body of regents, a large, but closed, oligarchy with control over all aspects of the city's life, and a dominant voice in the foreign affairs of Holland. Only men with sufficient wealth and a long enough residence within the city could join the ruling class. The first step for an ambitious and wealthy merchant family was to arrange a marriage with a long-established regent family. In the 1670s one such union, that of the Trip family (the Amsterdam branch of the Swedish arms makers) with the son of Burgomaster Valckenier, extended the influence and patronage available to the latter and strengthened his dominance of the council. The oligarchy in Amsterdam thus gained strength from its breadth and openness. In the smaller towns family interest could unite members on policy decisions but contraction through intermarriage could lead to the degeneration of the quality of the members.\nIn Amsterdam the network was so large that members of the same family could be related to opposing factions and pursue widely separated interests. The young men who had risen to positions of authority in the 1670s and 1680s consolidated their hold on office well into the 1690s and even the new century.\nAmsterdam's regents provided good services to residents. They spent heavily on the water-ways and other essential infrastructure, as well as municipal almshouses for the elderly, hospitals and churches.\nAmsterdam's wealth was generated by its commerce, which was in turn sustained by the judicious encouragement of entrepreneurs whatever their origin. This open door policy has been interpreted as proof of a tolerant ruling class. But tolerance was practiced for the convenience of the city. Therefore, the wealthy Sephardic Jews from Portugal were welcomed and accorded all privileges except those of citizenship, but the poor Ashkenazi Jews from Eastern Europe were far more carefully vetted and those who became dependent on the city were encouraged to move on. Similarly, provision for the housing of Huguenot immigrants was made in 1681 when Louis XIV's religious policy was beginning to drive these Protestants out of France; no encouragement was given to the dispossessed Dutch from the countryside or other towns of Holland. The regents encouraged immigrants to build churches and provided sites or buildings for churches and temples for all except the most radical sects and the Catholics by the 1670s (although even the Catholics could practice quietly in a chapel within the Beguinhof).\nFirst Stadtholderless Period (1650\u20131675).\nDuring the wars a tension had arisen between the Orange-Nassau leaders and the patrician merchants. The former\u2014the Orangists\u2014were soldiers and centralizers who seldom spoke of compromise with the enemy and looked for military solutions. They included many rural gentry as well as ordinary folk attached to the banner of the House of Orange. The latter group were the Republicans, led by the Grand Pensionary (a sort of prime minister) and the regents stood for localism, municipal rights, commerce, and peace. In 1650, the stadtholder William II, Prince of Orange suddenly died; his son was a baby and the Orangists were leaderless. The regents seized the opportunity: there would be no new stadtholder in Holland for 22 years. Johan de Witt, a brilliant politician and diplomat, emerged as the dominant figure. Princes of Orange became the stadtholder and an almost hereditary ruler in 1672 and 1748. The Dutch Republic of the United Provinces was a true republic from 1650 to 1672 and 1702\u20131748. These periods are called the First Stadtholderless Period and Second Stadtholderless Period.\nFirst and Second Anglo-Dutch wars.\nThe Dutch and English were major rivals in world trade and naval power. Halfway through the 17th century the Dutch States Navy was the rival of the English Royal Navy as the most powerful navy in the world. The Republic fought a series of three naval wars against England from 1652 to 1674.\nIn 1651, the Parliament of England introduced the Navigation Act, which restricted Dutch trade with English colonies. An incident at sea concerning the Act resulted in the First Anglo-Dutch War, which lasted from 1652 to 1654, ending in the Treaty of Westminster (1654), which left the Navigation Act in effect.\nAfter the Stuart Restoration in 1660, Charles II tried to serve his dynastic interests by attempting to make Prince William III of Orange, his nephew, stadtholder of the Republic, using some military pressure. King Charles thought a naval war would weaken the Dutch traders and strengthen the English economy and empire, so the Second Anglo-Dutch War was launched in 1665. At first many Dutch ships were captured and the English scored great victories. However, the Raid on the Medway, in June 1667, ended the war with a Dutch victory. The Dutch recovered their trade, while the English economy was seriously hurt and its treasury nearly bankrupt. The greatly expanded Dutch navy was for years after the world's strongest. The Dutch Republic was at the zenith of its power.\nFranco-Dutch War and Third Anglo-Dutch War (1672\u20131702).\nThe year 1672 is known in the Netherlands as the \"Disaster Year\" (\"Rampjaar\"). England declared war on the Republic, (the Third Anglo-Dutch War), followed by France, M\u00fcnster and Cologne, which had all signed alliances against the Republic. France, Cologne and M\u00fcnster invaded the Republic. Johan de Witt and his brother Cornelis, who had accomplished a diplomatic balancing act for a long time, were now the obvious scapegoats. They were lynched, and a new stadtholder, William III, was appointed.\nAn Anglo-French attempt to land on the Dutch shore was barely repelled in three desperate naval battles under command of Admiral Michiel de Ruyter. The advance of French troops from the south was halted by a costly inundation of its own heartland, by breaching river dikes. With the aid of friendly German princes, the Dutch succeeded in fighting back Cologne and M\u00fcnster, after which the peace was signed with both of them, although some territory in the east was lost forever. Peace was signed with England as well, in 1674 (Second Treaty of Westminster). In 1678, peace was made with France at the Treaty of Nijmegen, although the Spanish and German allies of the Dutch Republic felt betrayed by this.\nIn 1688, at the start of the Nine Years' War with France, the relations with England reached crisis level once again. Convinced that he needed English support against France and that he had to prevent a second Anglo-French alliance, Stadtholder William III decided he had to take a huge gamble and invade England. To this end he secured the support from the Dutch States-General and from Protestant English nobles opposed to William's Catholic father-in-law James II of England. This led to the Glorious Revolution and cemented the principle of parliamentary rule and Protestant ascendency in England. James fled to France, and William ascended to the English throne as co-monarch with his wife Mary, James' eldest daughter. This manoeuvre secured England as a critical ally of the United Provinces in its ongoing war with Louis XIV of France. William was the commander of the Dutch and English armies and fleets until his death in 1702. During William's reign as King of England, his primary focus was leveraging English manpower and finances to aid the Dutch against the French. The combination continued during the War of the Spanish Succession after his death as the combined Dutch, English, and Imperial armies conquered Flanders and Brabant, and invaded French territory before the alliance collapsed in 1713 due to British political infighting.\nSecond Stadtholderless Period (1702\u20131747).\nThe \"Second Stadtholderless Period\" () is the designation in Dutch historiography of the period between the death of stadtholder William III on 19 March 1702 and the appointment of William IV, Prince of Orange as stadtholder and captain general in all provinces of the Dutch Republic on 2 May 1747. During this period the office of stadtholder was left vacant in the provinces of Holland, Zeeland, and Utrecht, though in other provinces that office was filled by members of the House of Nassau-Dietz (later called Orange-Nassau) during various periods.\nDuring the period, the Republic lost its Great-Power status and its primacy in world trade, processes that went hand-in-hand, the latter causing the former. Though the economy declined considerably, causing deindustrialization and deurbanization in the maritime provinces, a \"rentier\"-class kept accumulating a large capital fund that formed the basis for the leading position the Republic achieved in the international capital market. A military crisis at the end of the period caused the Orangist revolution and the restoration of the Stadtholderate in all provinces.\nEconomic decline after 1730.\nThe slow economic decline after 1730 was relative: other countries grew faster, eroding the Dutch lead and surpassing it. Wilson identifies three causes. Holland lost its world dominance in trade as competitors emerged and copied its practices, built their own ships and ports, and traded on their own account directly without going through Dutch intermediaries. Second, there was no growth in manufacturing, due perhaps to a weaker sense of industrial entrepreneurship and to the high wage scale. Third the wealthy turned their investments to foreign loans. This helped jump-start other nations and provided the Dutch with a steady income from collecting interest, but leaving them with few domestic sectors with a potential for rapid growth.\nAfter the Dutch fleet declined, merchant interests became dependent on the goodwill of Britain. The main focus of Dutch leaders was reducing the country's considerable budget deficits. Dutch trade and shipping remained at a fairly steady level through the 18th century, but no longer had a near monopoly and also could not match growing British and French competition. The Netherlands lost its position as the trading centre of Northern Europe to Britain.\nAlthough the Netherlands remained wealthy, investments for the nation's money became more difficult to find. Some investment went into purchases of land for estates, but most went to foreign bonds and Amsterdam remained one of Europe's banking capitals.\nCulture and society.\nDutch culture also declined both in the arts and sciences. Literature for example largely imitated English and French styles with little in the way of innovation or originality. The most influential intellectual was Pierre Bayle (1647\u20131706), a Protestant refugee from France who settled in Rotterdam where he wrote the massive \"Dictionnaire Historique et Critique\" (\"Historical and Critical Dictionary\", 1696). It had a major impact on the thinking of The Enlightenment across Europe, giving an arsenal of weapons to critics who wanted to attack religion. It was an encyclopaedia of ideas that argued that most \"truths\" were merely opinions, and that gullibility and stubbornness were prevalent. \nReligious life became more relaxed as well. Catholics grew from 18% to 23% of the population during the 18th century and enjoyed greater tolerance, even as they continued to be outside the political system. They became divided by the feud between moralistic Jansenists (who denied free will) and orthodox believers. One group of Jansenists formed a splinter sect, the Old Catholic Church in 1723. The upper classes willingly embraced the ideas of the Enlightenment, tempered by the tolerance that meant less hostility to organized religion compared to France.\nDutch universities declined in importance, no longer attracting large numbers of foreign students. The Netherlands remained an important hub of intellectual exchange, creating reviews of foreign publications that made scholars aware of new works in French, German, and English. Dutch painting declined, no longer being innovative, with painters pursuing the styles of the old masters.\nLife for the average Dutchman became slower and more relaxed in the 18th century. The upper and middle classes continued to enjoy prosperity and high living standards. The drive to succeed seemed less urgent. Unskilled laborers remained locked in poverty and hardship. The large underclass of unemployed required government and private charity to survive.\nThe Orangist revolution (1747\u20131751).\nDuring Anthonie van der Heim's tenure as Grand Pensionary (1737\u20131746), the Dutch Republic was reluctantly drawn into the War of Austrian Succession, despite efforts to remain neutral. French attacks on Dutch fortresses in the Spanish Netherlands and occupation of the Dutch Zeelandic Flanders led to the Republic joining the Quadruple Alliance, which suffered a significant defeat at the Battle of Fontenoy. The French invasion exposed the weaknesses of Dutch defenses, leading to memories of \"Disaster Year\" of 1672 and widespread calls for the restoration of the stadtholderate. William IV, Prince of Orange, seized this opportunity to consolidate power and place loyal officials in strategic government positions to wrest control from the regenten. The struggle involved religious, anti-Catholic, and democratic elements, as well as mob violence and political agitation. The war concluded with the Treaty of Aix-la-Chapelle (1748), and the French voluntarily retreated from the Dutch frontier. However, William IV died unexpectedly in 1751 at the age of 40.\nRegency and indolent rule (1752\u20131779).\nHis son, William V, was 3 years old when his father died, and a long regency characterised by corruption and misrule began. His mother delegated most of the powers of the regency to Bentinck and her favorite, Duke Louis Ernest of Brunswick-L\u00fcneburg. All power was concentrated in the hands of an unaccountable few, including the Frisian nobleman Douwe Sirtema van Grovestins. Still a teenager, William V assumed the position of stadtholder in 1766, the last to hold that office. In 1767, he married Princess Wilhelmina of Prussia, the daughter of Augustus William of Prussia, niece of Frederick the Great.\nThe position of the Dutch during the American War of Independence (1775\u20131783) was one of neutrality. William V, leading the pro-British faction within the government, blocked attempts by anti-Orangist, and later pro-French, elements to drag the government to war. However, things came to a head with the Dutch attempt to join the Russian-led League of Armed Neutrality, leading to the outbreak of the disastrous Fourth Anglo-Dutch War in 1780. After the signing of the Treaty of Paris (1783), the impoverished nation grew restless under William's rule.\nAn English historian summed him up uncharitably as \"a Prince of the profoundest lethargy and most abysmal stupidity.\" And yet he would guide his family through the difficult French-Batavian period and his son would be crowned king.\nFourth Anglo-Dutch War (1780\u20131784).\nThe Fourth Anglo\u2013Dutch War (1780\u20131784) was a conflict between the Kingdom of Great Britain and the Dutch Republic. The war, tangentially related to the American Revolutionary War, broke out over British and Dutch disagreements on the legality and conduct of Dutch trade with Britain's enemies in that war.\nAlthough the Dutch Republic did not enter into a formal alliance with the United States and their allies, U.S. ambassador (and future President) John Adams managed to establish diplomatic relations with the Dutch Republic, making it the second European country to diplomatically recognize the Continental Congress in April 1782. In October 1782, a treaty of amity and commerce was concluded as well.\nMost of the war consisted of a series of largely successful British operations against Dutch colonial economic interests, although British and Dutch naval forces also met once off the Dutch coast. The war ended disastrously for the Dutch and exposed the weakness of the political and economic foundations of the country. The Treaty of Paris (1784), according to Fernand Braudel, \"sounded the knell of Dutch greatness.\"\nPatriot rebellion and its suppression (1785\u20131795).\nAfter the war with Great Britain ended disastrously in 1784, there was growing unrest and a rebellion by the anti-Orangist Patriots. Influenced by the American Revolution, the Patriots sought a more democratic form of government. The opening shot of this revolution is often considered to be the 1781 publication of a manifesto called \"Aan het Volk van Nederland\" (\"To the People of the Netherlands\") by Joan van der Capellen tot den Pol, who would become an influential leader of the Patriot movement. Their aim was to reduce corruption and the power held by the stadtholder, William V, Prince of Orange.\nSupport for the Patriots came mostly from the middle class. They formed militias called \"exercitiegenootschappen\". In 1785, there was an open Patriot rebellion, which took the form of an armed insurrection by local militias in certain Dutch towns, \"Freedom\" being the rallying cry. Herman Willem Daendels attempted to organise an overthrow of various municipal governments (vroedschap). The goal was to oust government officials and force new elections. \"Seen as a whole this revolution was a string of violent and confused events, accidents, speeches, rumours, bitter enmities and armed confrontations\", wrote French historian Fernand Braudel, who saw it as a forerunner of the French Revolution. The Patriot movement focused more on local political power, where they had no say in their towns' governance. Although they were able to curtail the power of the stadholder, and hold democratic elections in select towns, they were divided in their political vision, which was more local than national. Supporters were drawn from religious dissenters and Catholics in particular places, while pro-stadholder Orangists had more widespread geographical support of sections of the lower classes, the Dutch Reformed clergy, and the Jewish community.\nIn 1785 the stadholder left The Hague and moved his court to Nijmegen in Guelders, a city remote from the heart of Dutch political life. In June 1787, his energetic wife Wilhelmina (the sister of Frederick William II of Prussia) tried to travel to The Hague. Outside Schoonhoven, she was stopped by Patriot militiamen and taken to a farm near Goejanverwellesluis. She was forced to return to Nijmegen. She appealed to her brother for help, and he sent some 26,000 troops to invade, led by Charles William Ferdinand, Duke of Brunswick, to suppress the rebellion. The Patriot militias could not contend with these forces, melting away. Dutch banks at this time still held much of the world's capital. Government-sponsored banks owned up to 40% of Great Britain's national debt and there were close connections to the House of Stuart. The stadholder had supported British policies after the American Revolution and in foreign policy, the stadholder was \"little more than a pawn of the British and Prussians\", so that Patriot pressure was ignored by William.\nThis severe military response overwhelmed the Patriots and put the stadholder firmly back in control. A small unpaid Prussian army was billeted in the Netherlands and supported themselves by looting and extortion. The \"exercitiegenootschappen\" continued urging citizens to resist the government. They distributed pamphlets, formed \"Patriot Clubs\" and held public demonstrations. The government responded by pillaging those towns where opposition continued. Five leaders were sentenced to death, forcing them to flee. Lynchings also occurred. For a while, no one dared appear in public without an orange cockade to show their support for Orangism. Many Patriots, perhaps around 40,000 in all, fled to Brabant, France (especially Dunkirk and St. Omer) and elsewhere. Before long the French became involved in Dutch politics and the tide turned toward the Patriots.\nThe French Revolution was popular, and numerous underground clubs were promoting it when in January 1795 the French army invaded. The underground rose up, overthrew the municipal and provincial governments, and proclaimed the Batavian Republic in Amsterdam. Stadtholder William V fled to England and the States General dissolved itself.\nEconomy.\nDuring the Dutch Golden Age in the late-16th and 17th centuries, the Dutch Republic dominated world trade, conquering a vast colonial empire and operating the largest fleet of merchantmen of any nation. When Southern Europe was experiencing poor harvests, the Dutch very profitably exported surplus grain from Poland. The County of Holland was the wealthiest and most urbanized region in the world. In 1650 the urban population of the Dutch Republic as a percentage of total population was 31.7\u00a0percent, while that of the Spanish Netherlands was 20.8\u00a0percent, of Portugal 16.6\u00a0percent, and of Italy 14\u00a0percent. In 1675 the urban population density of Holland alone was 61\u00a0percent, compared to the rest of the Dutch Republic, where 27\u00a0percent lived in urban areas.\nThe free trade spirit of the time was augmented by the development of a modern, effective stock market in the Low Countries. The Netherlands has the oldest stock exchange in the world, founded in 1602 by the Dutch East India Company, while Rotterdam has the oldest bourse in the Netherlands. The Dutch East-India Company exchange went public in six different cities. Later, a court ruled that the company had to reside legally in a single city, so Amsterdam is recognized as the oldest such institution based on modern trading principles. While the banking system evolved in the Low Countries, it was quickly incorporated by the well-connected English, stimulating English economic output.\nThe Dutch Republic was a master of banking, often compared to 14th century Florence.\nPolitics.\nThe republic was a confederation of seven provinces, which had their own governments and were very independent, and a number of so-called Generality Lands. The latter were governed directly by the States General, the federal government. The States General were seated in The Hague and consisted of representatives of each of the seven provinces. The provinces of the republic were, in official feudal order:\nThere was an eighth province, the County of Drenthe (corresponding to the modern province of Drenthe), but this area was so poor that it was exempt from paying federal taxes, and as a consequence, it was denied representation in the States General, which is why the official name of the state was the \"Seven United Netherlands\" and not the \"Eight United Netherlands\".\nEach province was governed by the Provincial States, their main executive official (though not the official head of state) being a \"raadpensionaris\" or \"landsadvocaat\". In times of war, the stadtholder, who commanded the army, would have more power than the \"raadpensionaris\". In theory, the stadtholders were freely appointed by and subordinate to the states of each province. However, in practice the princes of Orange of the House of Orange-Nassau, beginning with William the Silent, were always chosen as stadtholders of most of the provinces.\nZeeland and usually Utrecht had the same stadtholder as Holland. There was a constant power struggle between the Orangists, who supported the stadtholders and specifically the princes of Orange, and the Republicans, who supported the States General and hoped to replace the semi-hereditary nature of the stadtholdership with a true republican structure.\nAfter the Peace of Westphalia, several border territories were assigned to the United Provinces. They were federally governed Generality Lands. These were Staats-Brabant, Staats-Vlaanderen, Staats-Overmaas, and (after the Treaty of Utrecht) Staats-Opper-Gelre. The States General of the United Provinces were in control of the Dutch East India Company and the Dutch West India Company, but some shipping expeditions were initiated by some of the provinces, mostly Holland and Zeeland.\nThe framers of the United States Constitution were influenced by the Constitution of the Republic of the United Provinces, as Federalist No. 20, by James Madison, shows. The United States did not intend to emulate the United Provinces; Madison describes the Dutch confederacy as exhibiting \"Imbecility in the government; discord among the provinces; foreign influence and indignities; a precarious existence in peace, and peculiar calamities from war.\" However, the 1776 American Declaration of Independence is similar to the 1581 Act of Abjuration, essentially the declaration of independence of the United Provinces, although there is no evidence of direct influence.\nReligion.\nIn the Union of Utrecht of 20 January 1579, Holland and Zeeland were granted the right to accept only one religion (in practice, Calvinism). Every other province had the freedom to regulate the religious question as it wished, although the Union stated every person should be free in the choice of personal religion and that no person should be prosecuted based on religious choice. William of Orange had been a strong supporter of public and personal freedom of religion and hoped to unite Protestants and Catholics in the new union, and, for him, the Union was a defeat. In practice, Catholic services in all provinces were quickly forbidden, and the Dutch Reformed Church became the \"public\" or \"privileged\" church in the republic.\nDuring the republic, any person who wished to hold public office had to conform to the Reformed Church and take an oath to this effect. The extent to which different religions or denominations were persecuted depended much on the time period and regional or city leaders. In the beginning, this was especially focused on Roman Catholics, being the religion of the enemy. In 17th-century Leiden, for instance, people opening their homes to services could be fined 200 guilders (a year's wage for a skilled tradesman) and banned from the city. Throughout this, however, personal freedom of religion existed and was one factor\u2014along with economic reasons\u2014in causing large immigration of religious refugees from other parts of Europe.\nIn the first years of the republic, controversy arose within the Reformed Church, mainly around the subject of predestination. This has become known as the struggle between Arminianism and Gomarism, or between Remonstrants and Contra-Remonstrants. In 1618, the Synod of Dort tackled this issue, which led to the banning of the Remonstrant faith.\nBeginning in the 18th century, the situation changed from more or less active persecution of religious services to a state of restricted toleration of other religions, as long as their services took place secretly in private churches.\nDecline.\nLong-term rivalry between the two main factions in Dutch society, the \"Staatsgezinden\" (Republicans, Dutch States Party) and the \"Prinsgezinden\" (Royalists or Orangists), sapped the strength and unity of the country. Johan de Witt and the Republicans did reign supreme for a time at the middle of the 17th century (the First Stadtholderless Period) until his overthrow and murder in 1672. Subsequently, William III of Orange became stadtholder. After a 22-year stadtholderless era, the Orangists regained power, and his first problem was to survive the Franco-Dutch War (with the derivative Third Anglo-Dutch War), when France, England, M\u00fcnster, and Cologne united against his country.\nWars to contain the expansionist policies of France in various coalitions after the Glorious Revolution burdened the republic with huge debts, although little of the fighting after 1673 took place on Dutch territory. The necessity to maintain a vast army against France meant that less money could be spent on the navy, weakening the republic's economy. After William III's death in 1702 the Second Stadtholderless Period was inaugurated. Despite having contributed much in the War of the Spanish Succession, the Dutch Republic gained little from the peace talks in Utrecht (1713). However, the Dutch had over a period of forty years successfully defended their positions in the Southern Netherlands and their troops were central in the alliances which had halted French territorial expansion in Europe until 1792. The end of the War of the Austrian Succession in 1748, and Austria becoming allies with France against Prussia, marked the end of the republic as a major military power.\nFierce competition for trade and colonies, especially from France and England, furthered the economic downturn of the country. The three Anglo-Dutch Wars and the rise of mercantilism had a negative effect on Dutch shipping and commerce.\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52627", "revid": "1319201270", "url": "https://en.wikipedia.org/wiki?curid=52627", "title": "Antonio Banderas", "text": "Spanish actor (born 1960)\nJos\u00e9 Antonio Dom\u00ednguez Bandera (born 10 August 1960), known professionally as Antonio Banderas, is a Spanish actor. Known for his work in films of several genres, he has received numerous accolades, including a Cannes Film Festival Award and a Goya Award, as well as nominations for an Academy Award, two Primetime Emmy Awards, five Golden Globe Awards, and a Tony Award. Films in which he has appeared have grossed over $7.7 billion worldwide.\nBanderas made his acting debut at a small theater in M\u00e1laga, where he caught the attention of director Pedro Almod\u00f3var, who gave the actor his film debut in the screwball comedy \"Labyrinth of Passion\" (1982). They have since collaborated on many films, including \"Matador\" (1986), \"Law of Desire\" (1987), \"Women on the Verge of a Nervous Breakdown\" (1988), \"Tie Me Up! Tie Me Down!\" (1989), \"The Skin I Live In\" (2011), and \"Pain and Glory\" (2019), the last of which earned him the Cannes Film Festival Award for Best Actor, the Goya Award for Best Actor as well as a nomination for the Academy Award for Best Actor.\nIn 1992, Banderas made his American film debut with the musical drama \"The Mambo Kings\" (1992), followed by roles in \"Philadelphia\" (1993), \"Interview with the Vampire\" (1994), \"Assassins\" (1995), and \"Evita\" (1996). He took roles in franchises playing El Mariachi in \"Desperado\" (1995) and \"Once Upon a Time in Mexico\" (2003), Zorro in \"The Mask of Zorro\" (1998) and \"The Legend of Zorro\" (2005), the patriarch in the \"Spy Kids\" series (2001\u20132003) and voiced Puss in Boots in the \"Shrek\" films (2004\u2013present). He made his directorial debut with the comedy film \"Crazy in Alabama\" (1999), followed by \"Summer Rain\" (2006).\nOn stage, Banderas made his Broadway theatre debut playing an Italian film director in the musical revival \"Nine\" (2003), for which he was nominated for a Tony Award for Best Actor in a Musical. He received Primetime Emmy Award nominations for his roles as Pancho Villa in the HBO television film \"And Starring Pancho Villa as Himself\" (2004) and Pablo Picasso in the anthology series \"Genius\" (2018).\nEarly life.\nJos\u00e9 Antonio Dom\u00ednguez Bandera was born on 10 August 1960, in M\u00e1laga, Andalusia, to Civil Guard officer Jos\u00e9 Dom\u00ednguez Prieto (1920\u20132008) and schoolteacher Ana Bandera Gallego (1933\u20132017). He has a younger brother named Francisco. As a young boy, Banderas wanted to become a professional football player until a broken foot sidelined his dreams at the age of 15. He showed a strong interest in the performing arts and formed part of the ARA Theatre School run by \u00c1ngeles Rubio-Arg\u00fcelles y Alessandri (wife of diplomat and filmmaker Edgar Neville) and the College of Dramatic Art, both in M\u00e1laga. His work in the theater and his performances on the streets eventually landed him a spot with the Spanish National Theatre.\nCareer.\n1982\u20131989: Early collaborations with Pedro Almod\u00f3var.\nBanderas began his acting studies at the School of Dramatic Art in M\u00e1laga and made his acting debut at a small theater in M\u00e1laga. He began working in small shops during Spain's post-dictatorial cultural movement known as La Movida Madrile\u00f1a.\nWhile performing with the theater, Banderas caught the attention of Spanish director Pedro Almod\u00f3var, who gave the young actor his film debut in the screwball sex comedy \"Labyrinth of Passion\" (1982). Five years later, he went on to appear in the director's comedic thriller \"Law of Desire\" (1987), making headlines with his performance as a gay man, which required him to engage in his first male-to-male onscreen kiss. Banderas appeared in Almod\u00f3var's surrealist sex comedy \"Matador,\" with Vincent Canby of \"The New York Times\" writing, \"The movie looks terrific and is acted with absolute, straight-faced conviction by the excellent cast headed by Miss Serna, Mr. Martinez and Mr. Banderas.\"\nThe director cast him in his internationally acclaimed 1988 film, \"Women on the Verge of a Nervous Breakdown\". Rita Kemply of \"The Washington Post\" described Banderas' performance as \"warm\" and described the film as a \"glossy delight.\" The recognition Banderas gained for his role increased years later, when he starred in Almod\u00f3var's controversial \"Tie Me Up! Tie Me Down!\" (1989) as a mental patient who kidnaps a porn star (Victoria Abril) and keeps her tied up until she returns his love. The breakthrough role helped spur him on to Hollywood. Almod\u00f3var is credited with helping launch Banderas's international career, as he became a regular feature in his films throughout the 1980s.\n1990\u20131999: Hollywood stardom.\nIn 1991, Madonna introduced Banderas to Hollywood. (He was an object of her desires in her pseudodocumentary film of one of her concert tours, \"\".) The following year, still speaking minimal English, he began acting in American films. Despite having to learn all his lines phonetically, Banderas still managed to turn in a critically praised performance as a struggling musician in his first American drama film, \"The Mambo Kings\" (1992). Kenneth Turan of \"The Los Angeles Times\" described Banderas as giving a \"quietly effective job\". David Nansen of \"Newsweek\" declared, \"Banderas had to learn English to play this role, but you wouldn't know it: he plumbs all the nuances of charm and self-pity in Nestor's melancholic soul\". Owen Gleiberman of \"Entertainment Weekly\" also praised Banderas' performance writing, \"he gives a surprisingly confident and subtle performance as the implosive Nestor\".\nBanderas then broke through to mainstream American audiences in the 1993 Jonathan Demme film \"Philadelphia\" as the life partner of lawyer Tom Hanks and Denzel Washington. Also in 1993, he acted in the Bille August-directed \"The House of the Spirits,\" an adaptation of the Isabel Allende novel of the same name. Banderas acted alongside Meryl Streep, Jeremy Irons, Glenn Close, and Winona Ryder.\nThe film's success earned Banderas wide recognition, and the following year, he was given a role in Neil Jordan's high-profile adaptation of Anne Rice's \"Interview with the Vampire\" (1994), sharing the screen with Brad Pitt, Tom Cruise, and Kirsten Dunst. He starred in several major Hollywood films, including the Robert Rodriguez-directed neo-Western action film \"Desperado\" (1995), alongside Salma Hayek, Steve Buscemi, and Quentin Tarantino. The film was a financial success. Owen Gleiberman of \"Entertainment Weekly\" wrote, \"The movie\u2019s greatest visual coup... is Banderas himself. The camera loves this velvet stud as much as it did the young Clint Eastwood.\"\nThat same year, Banderas portrayed the antagonist in the Richard Donner-directed action film \"Assassins\", co-starring opposite Sylvester Stallone and Julianne Moore. In 1996, he starred alongside Madonna in the musical film \"Evita\", an adaptation of the stage musical by Andrew Lloyd Webber and Tim Rice in which he played the narrator, Che, a role played by David Essex in the original 1978 West End production. Janet Maslin of \"The New York Times\" wrote that \"Banderas... does an unexpectedly splendid job as the film's conspiratorial singing narrator.\" For his performance, he was nominated for the Golden Globe Award for Best Actor in a Motion Picture \u2013 Musical or Comedy. He also had success with his role as the masked swordsman Zorro in the 1998 film \"The Mask of Zorro,\" starring Anthony Hopkins and Catherine Zeta-Jones. Roger Ebert praised the onscreen chemistry between the two leads, writing, \"The best scenes in the movie are between Banderas and Zeta-Jones, who share chemistry and, it turns out, a sense of justice.\" His performance earned him another Golden Globe Award nomination. In 1999, he starred in the historical action film \"The 13th Warrior\", a movie about a Muslim caught up in a war between the Northman and human-eating beasts.\n2000\u20132009: Broadway debut and franchise films.\nIn 2001, Banderas collaborated with Robert Rodriguez, who cast him in the first three movies of the \"Spy Kids\" franchise (2001\u20132003). He portrayed Gregorio Cortez, a retired OSS agent, alongside Carla Gugino, who played his wife, Ingrid Cortez. Roger Ebert praised the first film, describing it as \"giddy with the joy of its invention. It's an exuberant, colorful extravaganza, wall-to-wall with wildly original sets and visual gimmicks, and smart enough to escape the kids film category and play in the mainstream.\" He also starred in Michael Cristofer's \"Original Sin\" alongside Angelina Jolie the same year.\nIn 2002, he portrayed social realist painter David Alfaro Siqueiros in Julie Taymor's biographical drama \"Frida,\" with Salma Hayek playing Frida Kahlo. That same year, he starred in Brian De Palma's erotic thriller \"Femme Fatale\" opposite Rebecca Romijn, and in 2003, he starred in the last installment of the trilogy \"Once Upon a Time in Mexico\" (in which he appeared with Johnny Depp and Hayek). Banderas' debut as a director was the poorly received \"Crazy in Alabama\" (1999), starring his then wife Melanie Griffith. He starred in the Christopher Hampton-directed historical drama \"Imagining Argentina\" (2003) alongside Emma Thompson.\nBanderas made his Broadway debut playing Guido Contini in the 2003 revival of Maury Yeston's musical \"Nine\", based on the film \"8\u00bd\", playing the prime role originated by Raul Julia. Ben Brantley, the chief theater critic of \"The New York Times,\" wrote that Banderas was \"a bona fide matinee idol for the 21st century -- a pocket Adonis who suggests a more sensitive, less menacing variation on the Latin lovers of yore,\" adding that \"he has an appealingly easy stage presence and an agreeable singing voice that shifts, a bit abruptly, between pop whisperiness and Broadway belting.\" He won both the Outer Critics Circle Award and the Drama Desk Award for Best Actor in a Musical and was nominated for the Tony Award for Best Actor in a Musical. His performance is preserved on the Broadway cast recording released by PS Classics. Later that year, he received the Rita Moreno HOLA Award for Excellence from the Hispanic Organization of Latin Actors.\nAlso in 2003, he starred as Mexican revolutionary Pancho Villa in the HBO television film \"And Starring Pancho Villa as Himself\". Banderas acted alongside Alan Arkin, Jim Broadbent, and Michael McKean. The film was directed by Bruce Beresford and written by Larry Gelbart. Phil Gallo of \"Variety\" wrote, \"Villa was larger than life, and Banderas vibrantly captures his bravado. Everything in the telepic, though, is designed to make Villa a likable force, which pushes and pulls Banderas in a number of directions, only some of which play well. Eventually, 'Villa' exposes a dark side in the man, and Banderas forsakes crafting the image of a hero to allow the man\u2019s ambiguity to shine.\" Banderas was nominated for the Primetime Emmy Award for Outstanding Lead Actor in a Limited or Anthology Series or Movie and the Golden Globe Award for Best Actor \u2013 Miniseries or Television Film for his performance.\nThe following year, Banderas portrayed Puss in Boots in the DreamWorks animated film \"Shrek 2\" (2004). Todd McCarthy of \"Variety\" praised his performance, writing that he is \"deliciously sending up his Zorro persona.\" The film was an immense box office and critical hit. It went on to receive a nomination for the Academy Award for Best Animated Feature. Banderas reprised his role in \"Shrek the Third\" (2007) and the last film in the \"Shrek\" franchise, \"Shrek Forever After\" (2010), which helped make the character popular on the family film circuit. In all of his mainline appearances as Puss in Boots, he has also voiced him in Spanish; this is also true for the film Assassins. In 2005, he reprised his role as Zorro in \"The Legend of Zorro\". In 2006, he starred in \"Take the Lead\", a high-set movie in which he played a ballroom dancing teacher. That year, he directed his second film, \"El camino de los ingleses\", based on the novel by Antonio Soler, and also received the L.A. Latino International Film Festival's \"Gabi\" Lifetime Achievement Award on 14 October. Banderas received a star on the Hollywood Walk of Fame in 2005, the 2,294th person to do so; his star is located on the north side of the 6800 block of Hollywood Boulevard.\n2010\u2013present: Reunion with Almod\u00f3var.\nBanderas acted in the Woody Allen-directed comedy-drama \"You Will Meet a Tall Dark Stranger\" (2010), starring Anthony Hopkins, Josh Brolin, and Naomi Watts. The film premiered at the Cannes Film Festival and received mixed reviews. The following year, he starred in the horror thriller \"The Skin I Live In\" (2011), which marked the return of Banderas to Pedro Almod\u00f3var, the Spanish director who launched his international career. The two had not worked together since 1990 (\"Tie Me Up! Tie Me Down!\"). In \"The Skin I Live In,\" he breaks out of the \"Latin lover\" mold from his Hollywood work and stars as a calculating revenge-seeking plastic surgeon following the rape of his daughter. According to the Associated Press, Banderas' performance is among his strongest in recent memory. That same year, he reprised his voice role as Puss in Boots, this time as the protagonist of the \"Shrek\" spin-off prequel, \"Puss in Boots\". This film reunited Banderas with Salma Hayek for the sixth time. The film received critical acclaim and was a box-office hit.\nBanderas took a small role in Almod\u00f3var's comedy \"I'm So Excited!\" (2013) and also acted in Steven Soderbergh's action thriller \"Haywire\" (2011), Jonathan Dayton and Valerie Faris' romance fantasy \"Ruby Sparks\" (2012), and Terrence Malick's experimental drama \"Knight of Cups\" (2015). Banderas starred in \"\" as Burger Beard, the film's main antagonist. In 2018, Banderas starred in the National Geographic limited series \"Genius: Picasso\" as the noted sculptor and painter Pablo Picasso. For his performance, he received a Primetime Emmy Award, a Screen Actors Guild Award, and a Golden Globe Award nomination. He also acted in \"Life Itself\" (2018), which premiered at the Toronto International Film Festival.\nIn 2019, Banderas starred in the Spanish film \"Pain and Glory\" (\"Dolor y gloria\"), directed by Pedro Almod\u00f3var. The film centers around an aging film director played by Banderas who has a chronic illness and writer's block as he reflects on his life in flashbacks to his childhood. On 25 May 2019, Banderas won the Cannes Film Festival Award for Best Actor for his role in the film. Manohla Dargis of \"The New York Times\" praised his performance, writing that \"Banderas\u2019s melancholic presence and subtle, intricate performance add depth and intensities of feeling... because he draws so flawlessly from Almod\u00f3var.\" He was later nominated for his first ever Academy Award for Best Actor in a Leading Role for \"Pain and Glory\" and lost to Joaquin Phoenix for his role in \"Joker\" (2019).\nThat same year, Banderas starred in Steven Soderbergh's Netflix film \"The Laundromat\" alongside Meryl Streep and Gary Oldman. During this time, he starred in Spanish-language adaptations of the musicals \"A Chorus Line\" (2019) and \"Company\" (2021) at the Teatro del Soho CaixaBank in Spain. In 2020, he co-starred with Robert Downey Jr. in the fantasy adventure film \"Dolittle\". The following year, he starred in the black comedy \"Official Competition\" alongside Pen\u00e9lope Cruz, which had its world premiere at the 78th Venice International Film Festival. The film is a meta-comedy and satire on the film industry. A.O. Scott of \"The New York Times\" wrote, \"Banderas... can be marvelously subtle and affecting as well as magnetic. It\u2019s almost indecent for someone so beautiful to possess such skill, and you might have to go back to the old days\u2014to Gary Cooper\u2014to find a matinee idol with equivalent gifts.\"\nIn 2022, Banderas appeared as Santiago Moncada, the antagonist of the film \"Uncharted\" with Tom Holland and Mark Wahlberg. He also returned to work for DreamWorks Animation, reprising his voice as Puss in Boots in the sequel \"\" with Hayek again and a new cast with Florence Pugh, Olivia Colman, Ray Winstone, and Wagner Moura. In 2023, he appeared in \"Indiana Jones and the Dial of Destiny\" with Harrison Ford, Mads Mikkelsen, Phoebe Waller-Bridge and Toby Jones . He also portrayed Herod in the Christmas musical film \"Journey to Bethlehem\".\nIn June 2023, it was announced that Banderas was cast in \"Paddington in Peru\" in the role of Hunter Cabot. Other co-stars include Hugh Bonneville, Emily Mortimer, Olivia Colman, and Jim Broadbent. He starred opposite Nicole Kidman in the A24 erotic thriller \"Babygirl,\" directed by Halina Reijn.\nNew stage as theater producer.\nAntonio Banderas has always declared that what makes him happiest is theater. On 15 November 2019, his theater project, the Teatro del Soho CaixaBank, opened its doors in Malaga. It is a creation center dedicated to the production, exhibition and distribution of shows, and training in the different areas of the performing arts.\nBeginning in 2024, Banderas has also sponsored a new performing arts school in Malaga, the Sohrlin Andaluc\u00eda School of Arts. The school is located on an old metallurgical factory and it's objective is to become a centre in which to design, create and export Andalusian talent to the world.\nPersonal life.\nHe is a longtime supporter of M\u00e1laga CF. In May 2010, Banderas received an honorary doctorate from the University of M\u00e1laga. He received an honorary degree from Dickinson College in 2000.\nIn August 2015, Banderas enrolled in a fashion-design course at Central Saint Martins. As of 2016, Banderas resides in the United Kingdom in Cobham, Surrey.\nReligious beliefs.\nBanderas once described himself as an agnostic in an interview with \"People\" magazine in 2006: \"I have to recognize that I am agnostic. I don\u2019t believe in any kind of fundamentalism. I prefer to take life in a different way, with a sense of humor. I try to teach my kids to be open. Whatever they believe is fine with me.\" He does describe himself close to Catholic spirituality, especially to Holy Week, which he considers a \"metaphor for life\". He is an officer (\"mayordomo de trono\") of a religious brotherhood in his hometown of M\u00e1laga and travels during Holy Week to take part in the processions. Banderas developed his relationship with Catholicism back in 1994 after a spiritual search.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"There was a moment in my life in which I separated a bit from the Church. I was searching for a spiritual connection in other places, until in 1994, after my brother had a surgery we were very afraid of, in which we could lose him, I realized I should have not searched for so much, that I had had always that connection with the transcendental in front of my face. It also happened in a way which followed our own traditions, which we shouldn't look for in the Buddha, as these characters were right there. In my own neighborhood was that way to connect myself to the trascendental through the Passion of the Christ, until concluding in Resurrection.\"\nIn 2021, he described his religious beliefs and vision of the Holy Week to \"El Pa\u00eds\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"I live comfortably in the mystery, I'm very doubting, I don't know if agnostic is exactly the word. But I think yes, there is something, although we don't know what is it. The Big Bang, yes, and before the Big Bang, what? Holy Week has many colors, it's a very strange poliedrum. It is related to faith, popular religion and Andalusian idiosyncrasy. It's just the Roman Ides of March: winter dies and spring is born. The Andalusian version is so colourful and merry because everybody knows the guy will resurrect on Sunday. And there is a happy ending.\"\nRelationships.\nBanderas married Ana Leza in 1987 and divorced her in 1996. He met and began a relationship with American actress Melanie Griffith in 1995 while shooting \"Two Much\". They married on 14 May 1996, in London. They have a daughter, Stella del Carmen Banderas (born 24 September 1996), who appeared onscreen with Griffith in Banderas' directorial debut \"Crazy in Alabama\" (1999). In 2002, the couple received the Stella Adler Angel Award for their extensive philanthropy. Griffith had a tattoo of Banderas' name on her right arm that has since been removed.\nIn June 2014, Banderas and Griffith announced they were divorcing \"in a loving and friendly manner,\" despite \"irreconcilable differences.\" The divorce became official in December 2015. Despite their divorce, Banderas and Griffith remain close friends; his former stepdaughter Dakota Johnson considers Banderas part of the family, calling him a \"bonus dad.\" As of November 2015, Banderas is dating Nicole Kimpel, an investment banker.\nHealth.\nIn 2009, Banderas underwent surgery for a benign tumor in his back. Speaking at the M\u00e1laga Film Festival in March 2017, Banderas revealed he had suffered a heart attack on 26 January 2017, but said it \"wasn't serious and hasn't caused any damages.\" Following that incident, he underwent heart surgery to insert three stents into his arteries. In a \"Fresh Air\" interview in September 2019, he recalled it as being life-changing. He said, \"It just gave me a perspective of who I was, and it just made the important things [go to] the surface. When I say this, people may just think that I'm crazy, but it's one of the best things that ever happened in my life.\"\nBusiness ventures.\nHe has invested some of his film earnings in Andalusian products, which he promotes in Spain and the US. He owns 50% of a winery in Villalba de Duero, Burgos, Spain, called Anta Banderas, which produces red and ros\u00e9 wines.\nHe performed a voice-over for an animated bee, which were broadcast in the United States in television commercials for Nasonex, an allergy medication, and was seen in the 2007 Christmas advertising campaign for Marks &amp; Spencer, a British retailer.\nHe is a veteran of the perfume industry. The actor has been working with fragrance and beauty multinational company Puig for over ten years, becoming one of the brand's most successful representatives. Banderas and Puig have successfully promoted a number of fragrances so far: \"Diavolo\", \"Diavolo for Women\", \"Mediterraneo\", \"Spirit\", and \"Spirit for Women\". After the success of \"Antonio for Men\" and \"Blue Seduction for Men\" in 2007, he launched his latest, \"Blue Seduction for Women,\" the following year.\nAwards and honors.\nBanderas has received many award nominations throughout his career, including an Academy Award nomination for \"Pain and Glory\". He also received five Golden Globe Award nominations for his work ranging from films to television. He has also received two Primetime Emmy Award nominations for his work, on the television projects \"And Starring Pancho Villa as Himself\" (2004) and \"\" (2018). He also received a Screen Actors Guild Award nomination for his performance as Pablo Picasso in \"Genius: Picasso\". In 2003, he received a Tony Award nomination for Best Actor in a Musical for his performance in the Broadway musical production of \"Nine\". That year, however, he did win the Drama Desk Award for Outstanding Actor in a Musical for his performance in \"Nine\". In 2019, he won the Cannes Film Festival Award for Best Actor, the European Film Award for Best Actor, the Goya Award for Best Actor, and the New York Film Critics Circle Award for Best Actor for his performance in Almodovar's \"Pain and Glory\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52629", "revid": "164032", "url": "https://en.wikipedia.org/wiki?curid=52629", "title": "Kingdom of Holland", "text": "Puppet state of Napoleonic France (1806\u20131810)\nThe Kingdom of Holland ( (contemporary), (modern); ) was the successor state of the Batavian Republic. It was created by Napoleon Bonaparte in March 1806 in order to strengthen control over the Netherlands by replacing the republican government with a monarchy. Since becoming emperor in 1804, Napoleon sought to extirpate republican tendencies in territories France controlled, and placed his third brother, Louis Bonaparte, on the throne of the puppet kingdom. In 1807, the adjacent German regions of East Frisia and Jever were added to the kingdom.\nIn 1809, after the Walcheren Campaign, Holland had to surrender all territories south of the River Rhine to France. Also in 1809, Dutch forces fighting on the French side participated in defeating the anti-Bonapartist German rebellion led by Ferdinand von Schill, at the Battle of Stralsund.\nKing Louis did not perform to Napoleon's expectations \u2013 he tried to serve Dutch interests instead of his brother's \u2013 and the kingdom was dissolved in 1810, after which the Netherlands were annexed by France until 1813. Holland covered the area of the present-day East Frisia (northwest Germany) and Netherlands with the exception of the province of Limburg, and parts of Zeeland, which became annexed and incorporated into greater France. It was the first formal monarchy in Dutch territory since 1581, when most of it was under the Spanish crown (Spanish Netherlands).\nCoat of arms.\nNapol\u00e9on's brother Louis Bonaparte was installed as 'King of Holland' on 5 June 1806. Originally the arms of the new kingdom were to be like those of the Kingdom of Italy: an eagle bearing a shield, with the arms of the United Netherlands, the lion, now royally crowned. In December\u00a01806, in Paris, A.\u00a0Renodi designed arms quartering the Napol\u00e9onic eagle with the lion of the United Netherlands. Around the shield was the French Order of the Grand Eagle. Behind the shield are crossed sceptres, typical for Napoleonic heraldry, and above the shield, Napoleon's star.\nA few months later, on 20\u00a0May 1807, King Louis \u2013 now called \"Lodewijk\" \u2013 altered these arms, adding a helmet, leaving out his brother's star, and replacing the Grand Eagle with his own Dutch Order of the Union and the old Dutch devise \"Unity makes strength\" around the shield. Exemplary for the innovation in Napoleon's heraldry are the two hands coming out of clouds from behind the shield holding swords, designating King Louis as \"Conn\u00e9table de France\".\nHistory.\nPreface.\nThe Batavian Republic adopted in October 1801 a new constitution which was more moderate than its predecessor and the Republic was renamed to the Batavian Commonwealth, to make it less revolutionary. In the Commonwealth, the old provinces received more autonomy at the expense of the central government in The Hague and a Staatsbewind of twelve persons was installed to govern the country. At that time Napoleon Bonaparte was already criticizing the lack of executive authority in the Dutch state. A new constitution was drafted by Rutger Jan Schimmelpenninck in March 1805 which reinstated the unity state. Schimmelpenninck was installed as Grand Pensionary of the Batavian Republic. With these changes, the republic became more centralised than before and maintained its republican character.\nNapoleon remained troubled by the instability of the Batavian regime. He attributed this to its political organization and the weak position of the Grand Pensionary. In his eyes, only a monarchy could \"prevent either the country succumbing to British pressure, or the Dutch continuing to long for a return to the old regime.\" Besides this, the Dutch did not live up to their military duties and Schimmelpennick was not a very docile ally.\nIn February 1806 it became clear Schimmelpenninck's days were numbered. In the years before 1806, Napoleon had transformed the former Sister Republics of the French Republic into kingdoms for his family. The Italian Republic was transformed into the Kingdom of Italy with Napoleon as its king. Joachim Murat became Grand Duke of Berg and Joseph Bonaparte received the established Kingdom of Naples. In early 1806 the Swiss Confederation and the Batavian Republic were the last remaining Sister Republics.\nSchimmelpenninck objected to the idea of a regime change. According to him a hereditary head of state was incompatible with the Dutch national character. Napoleon presented on 28 April 1806 an ultimatum to the Dutch diplomats: they had eight days to accept Louis Bonaparte as their king. The majority of the members of the government ratified the treaty without popular consultation. With this Napoleon created a facade of legitimacy. The transition of a republic to a monarchy had actually already been prepared by the one-man rule of Schimmelpenninck.\nLouis Bonaparte assumes office.\nIn May 1806 the Treaty of Paris was written and it stipulated that it became time to strengthen the weak Dutch nation. For this, the country gained a hereditary prince who had the primary task of promoting national reconciliation and flourishing national prosperity. In the treaty, Napoleon also confirmed the country's independence. On 23 June 1806 Louis Napoleon made his entrance in The Hague. Louis Napoleon was never crowned as king of Holland and problems with his sovereignty would haunt him during his entire reign. Shortly after his arrival, Louis Napoleon appointed three members of the Council of State to draft a new constitution for the new monarchy.\nWith Louis Napoleon on the Dutch throne the Kingdom of Holland the country participated in the War of the Fourth Coalition. After the victory of the Battle of Jena-Auerstedt Louis hoped he could enlarge his kingdom with parts of Westphalia and the Grand Duchy of Berg. The kingdom only gained the territories of East Frisia and Jever in North Germany.\nLouis the Good.\nNapoleon had intended for Louis to be little more than a French prefect of Holland. However, Louis had his own mind, and tried to be as independent of his older brother as possible. He made a sincere effort to learn the Dutch language, adopted the Dutch spelling of his name, \"Lodewijk,\" and declared himself Dutch rather than French. Louis's court and ministers had mostly been provided by Napoleon, but Louis insisted that they follow his example and declare themselves Dutch.\nAt the same time, Louis introduced the Napoleonic politics of centralisation and standardisation in the Netherlands. In the new centralised state of the Kingdom of Napoleon the king was able to appoint the mayors of the larger Dutch cities. In 1806 a new country-wide tax system was implemented that ended the widespread corruption. Louis also introduced the Civil Registry, Land Registry, and a Guarantee Act. In 1809 the king introduced a revised Penal Code and Civil Code which was based on the French criminal code, but which respected the Dutch customs and law. Louis Napoleon also replaced the provincial mints with a national one. During his reign he also promoted the equality of Jews, Catholics, and dissenters in the Netherlands. The centralism Louis Bonaparte promoted also led to the foundation or reorganisation of several cultural institutions. The Royal Netherlands Academy of Arts and Sciences and the Royal Museum (precursor of Rijksmuseum Amsterdam) were founded during his reign.\nAside from the politics of centralisation Louis Bonaparte showed himself as a king who was a concerned father of his country. In 1807 he was present at the site of the Leiden gunpowder disaster. To help the affected people in Leiden he started a national collection, donated 30.000 guilders and opened Huis ten Bosch as a hospital. He showed the same affection to his people at the floodings in Zeeland (1808) and the Betuwe (1809). Because of these actions, the Dutch started to see Louis as a good and a rightful king.\nDownfall.\nDespite Louis Napoleon's success in the Netherlands he got into conflict with the emperor. The conflicts between Napoleon and the king of Holland centered on three topics. The first was the tiering of the national debt which Louis Napoleon refused to do because the Dutch administration believed it would lead to damage to financial confidence and would be a blow to Dutch investors. Louis Napoleon should also contribute to the French war effort by the introduction of conscription. The king refused to do this but to help his brother at least he ordered that the Dutch orphans enlist for the army. This was also not a popular measure. On 14 July 1809, a riot broke out in Rotterdam when the army came to pick up the orphan boys.\nLouis Napoleon also did not have a strict policy on maintaining the Continental System. Smuggling continued to exist and only after great pressure from Paris did he take measures to combat this. However, he did not want to pursue a harsh coercive policy because this would be disastrous for Dutch maritime trade. Napoleon saw his brother as a slacker and after the Walcheren Campaign (1809) he called Louis back to Paris. Napoleon incorporated the Dutch territories between the Meuse and the Scheldt. Louis Napoleon accepted the decisions of his older brother, but the treaty of March 1810 was only the beginning of the end. On 4 July French troops captured Amsterdam. Louis Napoleon abdicated on 1 July in favour of his son. By Imperial Decree the Kingdom of Holland was abolished and incorporated into the French Empire.\nAdministrative division.\nIn 1807 the Kingdom of Holland was divided into eleven departments. Each of them where divided into quarters, districts and cities. With this division the Dutch government followed the French centralization politics.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52630", "revid": "372290", "url": "https://en.wikipedia.org/wiki?curid=52630", "title": "History of the Russian Federation", "text": "History of Russia after the dissolution of the USSR\nThe modern history of Russia began with the Russian SFSR, a constituent republic of the Soviet Union, gaining more political and economical autonomy amidst the imminent dissolution of the USSR during 1988\u20131991, proclaiming its sovereignty inside the Union in June 1990, and electing its first President Boris Yeltsin a year later. The Russian Soviet Federative Socialist Republic was the largest Soviet Socialist Republic, but it had no significant independence before, being the only Soviet republic to not have its own branch of the Communist Party.\nThe RSFSR was the largest of the fifteen republics that made up the USSR, accounting for over 60% of its GDP and over 50% of its population. Russians also dominated the Soviet military and the Communist Party. As such, the Russian Federation was widely accepted as the USSR's successor state in diplomatic affairs and it assumed the USSR's permanent membership and veto in the UN Security Council (see Russia and the United Nations).\nPrior to the dissolution of the USSR, Yeltsin had been elected President of the RSFSR in June 1991 in the first direct presidential election in Russian history. This ensured that he would be the political leader of the Russian successor state following dissolution. This situation resulted in political turmoil as the Soviet and Russian leadership wrestled for control, which culminated in the 1991 August coup, where the Soviet military attempted to overthrow Mikhail Gorbachev. Although the coup was ultimately averted, this situation contributed to rising instability in the Soviet Union. As the USSR was on the verge of collapse by October 1991, Yeltsin announced that Russia would proceed with radical reforms, including shock therapy policies to introduce capitalism. This caused a sustained economic recession, and GDP per capita levels eventually returned to their 1991 levels by the mid-2000s. Following Yeltsin's resignation in 1999, Russia's politics have since been dominated by Vladimir Putin, serving as either President or Prime Minister. Although the Russian economy has improved significantly under Putin's leadership following relative economic chaos under Yeltsin, Putin has also been widely accused of corruption, authoritarian leadership, and widespread human rights abuses. An authoritarian form of governance in Russia since 2000 has been called Putinism.\nFor the most part, the Russian armed forces were in near complete disarray by 1992, one year after dissolution. This degraded military effectiveness would become all too clear during the 1994 Chechen War, and in the interim posed significant practical challenges for global security and arms control. Under Russian leadership, the Lisbon Protocol ensured that former Soviet republics would disarm themselves of nuclear weapons. This affected Kazakhstan in particular, as it hosted a significant share of the world's nuclear weapons immediately following the dissolution of the Soviet Union. However, the former Soviet republics were able to maintain transnational cooperation in other military areas, like establishing shared responsibility for the rocket and space infrastructure such as the Baikonur Cosmodrome.\nReforms.\n\"Shock therapy\".\nWith the dissolution of the Warsaw Pact and COMECON and other treaties that served to bind its satellite states to the Soviet Union, the conversion of the world's largest state-controlled economy into a market-oriented economy would have been extraordinarily difficult regardless of the policies chosen. The policies chosen for this transition were (1) liberalization, (2) stabilization and (3) privatization. These policies were based on the Washington Consensus of the International Monetary Fund (IMF), World Bank and Treasury Department.\nOn 2 January 1992, Yeltsin\u2014acting as his own prime minister\u2014enacted the most comprehensive components of economic reform by decree, thereby circumventing the Supreme Soviet of Russia and Congress of People's Deputies of Russia, which had been elected in March 1990, before the dissolution of the USSR. While this spared Yeltsin from the prospects of bargaining and wrangling with Soviet deputies, it also eliminated any meaningful discussion of the right course of action for the country.\nThe programs of liberalization and stabilization were designed by Yeltsin's deputy prime minister Yegor Gaidar, a liberal economist inclined toward radical reform, and widely known as an advocate of \"shock therapy\". Shock therapy was originally used in Bolivia by notable economist Jeffery Sachs to combat inflation in the 1980s. Having achieved some major successes in Bolivia, shock therapy was then imported to the Polish context following the dissolution of the Soviet Union, and Russia shortly after.\nThe partial results of liberalization (lifting price controls) included worsening already apparent hyperinflation, initially due to monetary overhang and exacerbated after the central bank, an organ under parliament, which was skeptical of Yeltsin's reforms, was short of revenue and printed money to finance its debt. This resulted in the near bankruptcy of much of Russian industry.\nThe process of liberalization would create winners and losers, depending on how particular industries, classes, age groups, ethnic groups, regions, and other sectors of Russian society were positioned. Some would benefit by the opening of competition; others would suffer. Among the winners were the new class of entrepreneurs and black marketeers that had emerged under Mikhail Gorbachev's \"perestroika\". But liberalizing prices meant that the elderly and others on fixed incomes would suffer a severe drop in living standards, and people would see a lifetime of savings wiped out.\nWith inflation at double-digit rates per month as a result of printing, macroeconomic stabilization was enacted to curb this trend. Stabilization, also called structural adjustment, is a harsh austerity regime (tight monetary policy and fiscal policy) for the economy in which the government seeks to control inflation. Under the stabilization program, the government let most prices float, raised interest rates to record highs, raised heavy new taxes, sharply cut back on government subsidies to industry and construction, and made massive cuts in state welfare spending. These policies caused widespread hardship as many state enterprises found themselves without orders or financing. A deep credit crunch shut down many industries and brought about a protracted depression.\nThe rationale of the program was to squeeze the built-in inflationary pressure out of the economy so that producers would begin making sensible decisions about production, pricing and investment instead of chronically overusing resources\u2014a problem that resulted in shortages of consumer goods in the Soviet Union in the 1980s. By letting the market rather than central planners determine prices, product mixes, output levels, and the like, the reformers intended to create an incentive structure in the economy where efficiency and risk would be rewarded and waste and carelessness were punished. Removing the causes of chronic inflation, the reform architects argued, was a precondition for all other reforms: Hyperinflation would wreck both democracy and economic progress, they argued; they also argued that only by stabilizing the state budget could the government proceed to dismantle the Soviet planned economy and create a new capitalist Russia.\nNonetheless, radical reform continued to face some critical political barriers. The Central Bank was still subordinate to the conservative Supreme Soviet who continued to support socialist policies in opposition to Yeltsin and the presidency. During the height of hyperinflation in 1992\u20131993, the Central Bank actually tried to derail reforms by actively printing even more money during this period of inflation. After all, the Russian government was short of revenue and was forced to print money to finance its debt. As a result, inflation exploded into hyperinflation, and the Russian economy continued into an evermore serious slump.\nPrivatization.\nUpon the Soviet Union's collapse, the new Russian government was forced to manage the huge state enterprise sector inherited from the Soviet economy. Privatization was carried out by the State Committee for State Property Management of the Russian Federation under Anatoly Chubais with the primary goal being to transform the formerly state-owned enterprises into profit-seeking businesses, which would not be dependent on government subsidies for their survival. To distribute property quickly and to win over popular support, the reformers decided to rely mostly on the mechanism of free voucher privatization, which was earlier implemented in Czechoslovakia. The Russian government believed that the open sale of state-owned assets, as opposed to the voucher program, would have likely resulted in the further concentration of ownership among the Russian mafia and the nomenklatura, which they sought to avoid. Nevertheless, contrary to the government's expectations, insiders managed to acquire control over most of the assets, which remained largely dependent on government support for years to come. From 1992 to 1994, ownership of 15,000 firms was transferred from state control via the voucher program.\nPrivatization of the oil sector was regulated by presidential decree No.1403 approved on 17 November 1992. Vertically integrated companies were created by joining some oil-producing enterprises and refineries into open-stock companies. Starting in 1994 many former state oil companies were privatized. This privatization had been partial because the federal government had obtained ownership positions in several companies and had also retained full control over the transport of oil to lucrative world markets.\nIn 1995, facing severe fiscal deficit and in desperate need of funds for the 1996 presidential elections, the government of Boris Yeltsin adopted a \"loans-for-share\" scheme proposed by banker Vladimir Potanin and endorsed by Anatoly Chubais, then a deputy prime minister, whereby some of the largest state industrial assets (including state-owned shares in Norilsk Nickel, Yukos, Lukoil, Sibneft, Surgutneftegas, Novolipetsk Steel, and Mechel) were leased through auctions for money lent by commercial banks to the government. The auctions were rigged and lacked competition, being largely controlled by favored insiders with political connections or used for the benefit of the commercial banks themselves. As neither the loans nor the leased enterprises were returned in time, this effectively became a form of selling, or privatizing, state assets at very low prices.\nThe privatization facilitated the transfer of significant wealth to a relatively small group of business oligarchs and New Russians, particularly natural gas and oil executives.\nObstacles to reform.\nThe former Soviet Union had to deal with a number of unique obstacles during the post-Soviet transition including political reform, economic restructuring and the redrawing of political boundaries. The discomfort associated with these changes was not felt the same in each former Soviet republic. As a general rule, states to Russia's west, such as Poland, Hungary, and the Czech Republic, have fared slightly better than their eastern neighbors since the collapse of the Eastern bloc, while Russia itself and countries to Russia's east experienced greater difficulties and found themselves on worse footing immediately after dissolution. A major reason that Russia's transition has been so wrenching is that it is remaking both its Soviet-era political and economic institutions at once. In addition to institutional reforms designed to create a new political-economic system, Russia was also charged with remaking itself into a new national state following the disintegration of the Soviet Union.\nThe first major problem facing Russia was the legacy of the Soviet Union's enormous commitment to the Cold War. In the late 1980s, the Soviet Union devoted a quarter of its gross economic output to the defense sector (at the time most Western analysts believed that this figure was 15 percent). At the time, the military-industrial complex employed at least one of every five adults in the Soviet Union. In some regions of Russia, at least half of the workforce was employed in defense plants (the comparable U.S. figures were roughly one-sixteenth of gross national product and about one of every sixteen in the workforce). These over-reliance on the military sector made Russian industry and human capital relatively noncompetitive upon entry into a market-oriented system. Furthermore, the end of the Cold War and the cutback in military spending affected industry quite dramatically making it difficult to quickly retool equipment, retrain workers, and find new markets. In the process of economic re-tooling, an enormous body of experience, qualified specialists and know-how was lost or misallocated, as the plants were sometimes switching from, for example, producing hi-tech military equipment to making kitchen utensils.\nA second obstacle, partly related to the sheer vastness and geographical diversity of the Russian landmass, was the sizable number of \"mono-industrial\" regional economies (regions dominated by a single industrial employer) that Russia inherited from the Soviet Union. The concentration of production in a relatively small number of big state enterprises meant that many local governments were entirely dependent on the economic health of a single employer; when the Soviet Union collapsed and the economic ties between Soviet republics and even regions were severed, the production in the whole country dropped by more than fifty percent. Roughly half of Russia's cities had only one large industrial enterprise, and three fourths had no more than four. Consequently, the decrease in production caused tremendous unemployment and underemployment.\nThirdly, post-Soviet Russia did not inherit a system of state social security and welfare from the USSR. Instead the companies, mainly large industrial firms, were traditionally responsible for a broad range of social welfare functions\u2014building and maintaining housing for their work forces, and managing health, recreational, educational, and similar facilities. The towns in contrast possessed neither the apparatus nor the funds for the provision of basic social services. Industrial employees were left heavily dependent on their firms. Thus, economic transformation created severe problems in maintaining social welfare since local governments were unable to assume finance or operational responsibility for these functions.\nFinally, there is a human capital dimension to the failure of post-Soviet reforms in Russia. The former Soviet population was not necessarily uneducated. Literacy was nearly universal, and the educational level of the Soviet population was among the highest in the world with respect to science, engineering, and some technical disciplines, although the Soviets devoted little to what would be described as \"liberal arts\" in the West. With the move to a post-Communist system, the Russian university system collapsed. Rampant credential inflation in the Russian university system made it difficult for employers to determine who was really skilled and the problems of the higher education system more generally made it difficult to remedy other issues of human capital that came from the transition to a market-oriented system, such as upskilling and re-skilling. For example, former state enterprise managers were highly skilled at coping with the demands on them under the Soviet system of planned production targets, but discouraged the risk-and-reward centered behavior of market capitalism. These managers were responsible for a broad array of social welfare functions for their employees, their families, and the population of the towns and regions where they were located. Profitability and efficiency, however, were generally not the most prominent priorities for Soviet enterprise managers. Thus, almost no Soviet employees or managers had firsthand experience with decision-making in the conditions of a market economy.\nEconomic depression and mortality crisis.\nAfter the initial turmoil and euphoria of early marketizations, Russia's economy sank into deep depression by the mid-1990s due to botched reform efforts and low commodity prices globally but not before George H. W. Bush helped Yeltsin with \"an unparalleled opportunity to change the nuclear posture of both the United States and the Soviet Union\" and to end the Cold War peacefully with the Nunn\u2013Lugar cash-for-weapons scheme, in order to avoid the worst of the dissolution of the vast Soviet technological empire. Russia's economy was hit further by the financial crash of 1998 before experiencing a modest recovery in 1999\u20132000 as commodity prices began to rise again. According to Russian government statistics, the economic decline was far more severe than the Great Depression was in the United States in terms of gross domestic product.\nIn 1995, a little over 3% of the work force was officially registered as unemployed, but, in addition to the technically jobless, 4.4% of the labour force were working only part time, while a further 3.9% had been sent on involuntary leave. Also millions of Russians turned up for work each day, but were not paid by the employers. If all these categories of jobless, semi-employed and unpaid workers were taken into account, the 18% Russian unemployment figure cited in June 1995 by labour market expert Tatyana Maleva of the Institute of Economic Analysis seemed real. With unemployment benefits sufficient only to buy a small loaf of bread each day, trying to survive without some other income was not an option for those who lost jobs. They were toiling during the warmer months to grow food in family vegetable plots, selling newspapers or lottery tickets on the streets, busking, begging, turning to prostitution. Often they sank into the criminal underworld.\nIn 1997, at least 98,400 companies were defaulting on payments to employees. It was estimated that one out of four Russian workers, or close on 20 million people, were not paid for months. Some were paid \"in kind\": for example, women workers were paid in brassieres and shoes that they resold in the streets, workers of Moskvich, the auto plant in Moscow, were paid in spare parts, those of the Ivanovo textile plants were paid in bedsheets, and those of the Gus-Khrustalny porcelain factory were paid in crystal and ceramic vases.\nBy way of a domestic comparison, the post-Soviet economic decline was about half as severe as the economic catastrophe borne out of the immediate consequence of World War I, the fall of Tsarism, and the Russian Civil War.\nFollowing the economic collapse of the early 1990s, Russia suffered from a sharp increase in the rates of poverty and economic inequality. Estimates by the World Bank based on both macroeconomic data and surveys of household incomes and expenditures indicate that whereas 1.5% of the population was living in poverty (defined as income below the equivalent of $25 per month) in the late Soviet era, by mid-1993 between 39% and 49% of the population was living in poverty. Per capita incomes fell by another 15% by 1998, according to government figures.\nPublic health indicators show a dramatic corresponding decline. Although all post-Soviet countries experience an immediate decline in birth-rates due to economic turmoil this may have been particularly acute in Russia. In 1999, total population fell by about three-quarters of a million people. Meanwhile, life expectancy dropped for men from 64 years in 1990 to 57 years by 1994, while women's dropped from 74 to about 71. Both health factors and a sharp increase in deaths of the youth demographic from unnatural causes (such as murders, suicides, and accidents) have significantly contributed to this trend. Closely related to the declining life expectancy, alcohol-related deaths skyrocketed 60% in the 1990s and deaths from infectious and parasitic diseases shot up 100%, mainly because medicines were no longer affordable to the poor. The mortality crisis resulted in approximately 1.6 million excess deaths during 1990\u20131995 when compared to earlier levels. During 1998\u20132001, the excessive rate of mortality was predominantly represented by suicide, traffic incidents, homicide, unintentional alcohol poisoning and falls. Mortality was lower in areas where privatisation was more gradual, with this effect continuing into the 2000s.\nWhile the opening of the Russian market to imports in the early 1990s meant the nation no longer suffered from the supply shortages of consumer goods that was often characteristic of the USSR (\"see\" Consumer goods in the Soviet Union), the relative impoverishment of the Russian people during this time meant only a limited number saw any significant benefit. Russians on fixed incomes (the vast majority of the workforce) saw their purchasing power drastically reduced, so while the stores might have been well stocked in the Yeltsin era, average people could now afford to buy little, if anything from these stores. By 2011, the average income has risen to more than $700 per month, emblematic of the mild recovery in recent years largely due to high oil prices. The growing revenue, however, has not been evenly distributed. Social inequality has risen sharply since the 1990s with the Gini coefficient, for example, reaching 42% by the end of 2010. Russia's income disparities are now nearly as large as Brazil (which has long been a world leader in the area) while regional disparities in the level of poverty continue to trend upwards.\nBacklash.\nStructural reform and a severe devaluation of the ruble lowered the standard of living for most segments of the Russian population. As a result, there was powerful political opposition to reform. Democratization opened the political channels for venting these frustrations, which translated into votes for anti-reform candidates, especially those of the Communist Party of the Russian Federation and its allies in the Duma. Russian voters, able to vote for opposition parties in the 1990s, often rejected economic reforms and yearned for the stability and personal security of the Soviet era. These were the groups that had enjoyed the benefits of Soviet-era state-controlled wages and prices, high state spending to subsidize priority sectors of the economy, protection from competition with foreign industries, and welfare entitlement programs. During the Yeltsin years in the 1990s, these anti-reformist groups were well organized, voicing their opposition to reform through strong trade unions, associations of directors of state-owned firms, and political parties in the popularly elected parliament whose primary constituencies were among those vulnerable to reform. A constant theme of Russian history in the 1990s was the conflict between economic reformers and those hostile to the new capitalism.\nIn the 1990s, former Soviet bureaucrats, factory directors, aggressive businessmen and criminal organizations used insider deals, bribery and simple brute force in order to grab lucrative assets, which were previously state-owned. Russia's new \"capitalists\" spent millions of dollars for protection. However, almost every business in Russia, from curbside vendors to huge oil and gas companies, made payments to the organized crime for protection (\"krysha\"). Businessmen said that they needed the \"krysha\" because the laws and the court system were not functioning properly in Russia. The only way for them to enforce a contract was to turn to a criminal \"krysha\". They also used it to intimidate competitors, collect debts or take over new markets. It was also increasingly common for businesses to turn to the \"red krysha\" \u2014 corrupt police who ran protection rackets. Within this system, a sharp rise in contract killings developed.\nCrisis.\nConstitutional crisis.\nThe struggle for the center of power in Soviet Russia following the collapse of the Soviet Union and for the nature of the economic reforms culminated in a political crisis and bloodshed in the autumn of 1993. Yeltsin, who represented a course of radical privatization, was opposed by the Supreme Soviet. Confronted with opposition to the presidential power of decree and threatened with impeachment, he \"dissolved\" the parliament on 21 September, in contravention of the existing constitution, and ordered new elections and a referendum on a new constitution. The parliament then declared Yeltsin deposed and appointed Aleksandr Rutskoy acting president on 22 September. Tensions built quickly, and matters came to a head after street riots on 2 \u2013 3 October. On 4 October, Yeltsin ordered Special Forces and elite army units to storm the parliament building, the \"White House\" as it is called. With tanks thrown against the small-arms fire of the parliamentary defenders, the outcome was not in doubt. Rutskoy, Ruslan Khasbulatov, and the other parliamentary supporters surrendered and were immediately arrested and jailed. The official count was 147 dead, 437 wounded (with several men killed and wounded on the presidential side).\nThus the transitional period in post-Soviet Russian politics came to an end. A new constitution was approved by referendum in December 1993. Russia was given a strongly presidential system. Radical privatization went ahead. Although the old parliamentary leaders were released without trial on 26 February 1994, they would not play an open role in politics thereafter. Though its clashes with the executive would eventually resume, the remodeled Russian parliament had greatly circumscribed powers. (\"For details on the constitution passed in 1993 see Constitution and government structure of Russia.\")\nFirst Chechen War.\nIn 1994, Yeltsin dispatched 40,000 troops to the southern region of Chechnya to prevent its secession from Russia. Living south of Moscow, the predominantly Muslim Chechens for centuries had gloried in defying Russia. Dzhokhar Dudayev, Chechnya's nationalist president, was driven to take his republic out of the Russian Federation, declaring independence in 1991. Gripped by the chaos of the Soviet Union's ongoing dissolution, Chechnya initially operated as a de facto independent nation-though this status was never recognized by Russia. In 1994, the Russian Armed Forces invaded and quickly became submerged in a military quagmire. In January 1995, the Russian army and air force commenced a siege of the Chechen capital of Grozny; about 25,000 Chechen civilians died under week-long air raids and artillery fire in the sealed-off city. Massive use of artillery and air-strikes remained the dominating strategy throughout the Russian campaign. Even so, Chechen forces seized thousands of Russian hostages, while inflicting humiliating losses on the demoralized and ill-equipped Russian troops.\nThe Russians finally managed to gain control of Grozny by February 1995 after heavy fighting. In August 1996, Yeltsin agreed to a ceasefire with Chechen leaders, and a peace treaty was formally signed in May 1997. However, the conflict resumed in 1999; this time the rebellion was crushed by Vladimir Putin.\nRise of the oligarchs.\nThe new capitalist opportunities presented by the opening of the Russian economy in the late 1980s and early 1990s affected many people's interests. As the Soviet system was being dismantled, well-placed bosses and technocrats in the Communist Party, KGB, and Komsomol (Soviet Youth League) were cashing in on their Soviet-era power and privileges. Some quietly liquidated the assets of their organization and secreted the proceeds in overseas accounts and investments. Others created banks and business in Russia, taking advantage of their insider positions to win exclusive government contracts and licenses and to acquire financial credits and supplies at artificially low, state-subsidized prices in order to transact business at high, market-value prices. Great fortunes were made almost overnight.\nBetween 1987 and 1992, trading of natural resources and foreign currencies, as well as imports of highly demanded consumer goods and then domestic production of their rudimentary substitutes, rapidly enabled these pioneering entrepreneurs to accumulate considerable wealth. In turn, the emerging cash-based, highly opaque markets provided a breeding ground for a large number of racket gangs.\nBy the mid-1990s, the best-connected former nomenklatura leaders accumulated considerable financial resources, while on the other hand, the most successful entrepreneurs became acquainted with government officials and public politicians. The privatization of state enterprises was a unique opportunity because it gave many of those who had gained wealth in the early 1990s a chance to convert it into shares of privatized enterprises.\nThe Yeltsin government hoped to use privatization to spread ownership of shares in former state enterprises as widely as possible to create political support for his government and his reforms. The government used a system of free vouchers as a way to give mass privatization a jump-start. But it also allowed people to purchase shares of stock in privatized enterprises with cash. Even though initially each citizen received a voucher of equal face value, within months most of the vouchers converged in the hands of intermediaries who were ready to buy them for cash right away.\nAs the government ended the voucher privatization phase and launched cash privatization, it devised a program that it thought would simultaneously speed up privatization and yield the government a much-needed infusion of cash for its operating needs. Under the scheme, which quickly became known in the West as \"loans for shares,\" the Yeltsin regime auctioned off substantial packages of stock shares in some of its most desirable enterprises, such as energy, telecommunications, and metallurgical firms, as collateral for bank loans.\nIn exchange for the loans, the state handed over assets worth many times as much. Under the terms of the deals, if the Yeltsin government did not repay the loans by September 1996, the lender acquired title to the stock and could then resell it or take an equity position in the enterprise. The first auctions were held in the fall of 1995. The auctions themselves were usually held in such a way so to limit the number of banks bidding for shares and thus to keep the auction prices extremely low. By summer 1996, major packages of shares in some of Russia's largest firms had been transferred to a small number of major banks, thus allowing a handful of powerful banks to acquire substantial ownership shares over major firms at shockingly low prices. These deals were effectively giveaways of valuable state assets to a few powerful, well-connected, and wealthy financial groups.\nThe concentration of immense financial and industrial power, which loans for shares had assisted, extended to the mass media. One of the most prominent of the financial barons Boris Berezovsky, who controlled major stakes in several banks and companies, exerted an extensive influence over state television programming for a while. Berezovsky and other ultra-wealthy, well-connected tycoons who controlled these great empires of finance, industry, energy, telecommunications, and media became known as the \"Russian oligarchs\". Along with Berezovsky, Mikhail Khodorkovsky, Roman Abramovich, Vladimir Potanin, Vladimir Bogdanov, Rem Viakhirev, Vagit Alekperov, Viktor Chernomyrdin, Viktor Vekselberg, and Mikhail Fridman emerged as Russia's most powerful and prominent oligarchs.\nA tiny clique who used their connections built up during the last days of the Soviet years to appropriate Russia's vast resources during the rampant privatizations of the Yeltsin years, the oligarchs emerged as the most hated men in the nation. The Western world generally advocated a quick dismantling of the Soviet planned economy to make way for free-market reforms but later expressed disappointment over the newfound power and corruption of the oligarchs.\nPresidential election of 1996.\nCampaigns.\nEarly in the campaign it had been thought that Yeltsin, who was in uncertain health (after recuperating from a series of heart attacks) and whose behavior was sometimes erratic, had little chance for reelection. When campaigning opened at the beginning of 1996, Yeltsin's popularity was close to zero. Meanwhile, the opposition Communist Party of the Russian Federation had already gained ground in parliamentary voting on 17 December 1995, and its candidate, Gennady Zyuganov, had a strong grassroots organization, especially in the rural areas and small towns, and appealed effectively to memories of the old days of Soviet prestige on the international stage and the socialist domestic order.\nPanic struck the Yeltsin team when opinion polls suggested that the ailing president could not win; members of his entourage urged him to cancel presidential elections and effectively rule as dictator from then on. Instead, Yeltsin changed his campaign team, assigning a key role to his daughter, Tatyana Dyachenko, and appointing Anatoly Chubais campaign manager. Chubais, who was not just Yeltsin's campaign manager but also the architect of Russia's privatization program, set out to use his control of the privatization program as the key instrument of Yeltsin's reelection campaign.\nIn addition, American lobbyists spent millions of dollars to see Yeltsin elected.\nThe president's inner circle assumed that it had only a short time in which to act on privatization; it, therefore, needed to take steps that would have a large and immediate impact, making the reversal of reform prohibitively costly for their opponents. Chubais' solution was to co-opt potentially powerful interests, including enterprise directors and regional officials, in order to ensure Yeltsin's reelection.\nThe position of the enterprise directors to the program was essential to maintaining economic and social stability in the country. The managers represented one of the most powerful collective interests in the country; it was the enterprise managers who could ensure that labor did not erupt in a massive wave of strikes. The government, therefore, did not strenuously resist the tendency for voucher privatization to turn into \"insider privatization,\" as it was termed, in which senior enterprise officials acquired the largest proportion of shares in privatized firms. Thus, Chubais allowed well-connected employees to acquire majority stakes in the enterprises. This proved to be the most widely used form of privatization in Russia. Three-quarters of privatized enterprises opted for this method, most often using vouchers. Real control thus wound up in the hands of the managers.\nSupport from the oligarchs was also crucial to Yeltsin's reelection campaign. The \"loans for shares\" giveaway took place in the run-up to the 1996 presidential election\u2014at a point when it had appeared that Zyuganov might defeat Yeltsin. Yeltsin and his entourage gave the oligarchs an opportunity to scoop up some of Russia's most desirable assets in return for their help in his reelection effort. The oligarchs, in turn, reciprocated the favor.\nIn the spring of 1996, with Yeltsin's popularity at a low ebb, Chubais and Yeltsin recruited a team of six leading Russian financiers and media barons (all oligarchs) who bankrolled the Yeltsin campaign with $3\u00a0million and guaranteed coverage on television and in leading newspapers directly serving the president's campaign strategy. The media painted a picture of a fateful choice for Russia, between Yeltsin and a \"return to totalitarianism.\" The oligarchs even played up the threat of civil war if a Communist were elected president.\nIn the outlying regions of the country, the Yeltsin campaign relied on its ties to other allies\u2014the patron-client ties of the local governors, most of whom had been appointed by the president.\nThe Zyuganov campaign had a strong grass-roots organization, but it was simply no match for the financial resources and access to patronage that the Yeltsin campaign could marshal.\nYeltsin campaigned energetically, dispelling concerns about his health, exploiting all the advantages of incumbency to maintain a high media profile. To assuage voters' discontent, he made the claim that he would abandon some unpopular economic reforms and boost welfare spending, end the war in Chechnya, pay wage and pension arrears, and abolish military conscription (he did not live up to his promises after the election, except for ending the Chechen war, which was halted for 3 years). Yeltsin's campaign also got a boost from the announcement of a $10\u00a0billion loan to the Russian government from the International Monetary Fund.\nGrigory Yavlinsky was the liberal alternative to Yeltsin and Zyuganov. He appealed to a well-educated middle class that saw Yeltsin as an incompetent alcoholic and Zyuganov as a Soviet-era throwback. Seeing Yavlinsky as a threat, Yeltsin's inner circle of supporters worked to bifurcate political discourse, thus excluding a middle ground\u2014and convince voters that only Yeltsin could defeat the Communist \"menace.\" The election became a two-man race, and Zyuganov, who lacked Yeltsin's resources and financial backing, watched helplessly as his strong initial lead was whittled away.\nElections.\nVoter turnout in the first round of the polling on 16 June was 69.8%. According to returns announced on 17 June, Yeltsin won 35% of the vote; Zyuganov won 32%; Aleksandr Lebed, a populist ex-general, a surprisingly high 14.5%; liberal candidate Grigory Yavlinsky 7.4%; far-right nationalist Vladimir Zhirinovsky 5.8%; and former Soviet president Mikhail Gorbachev 0.5%. With no candidate securing an absolute majority, Yeltsin and Zyuganov went into a second round of voting. In the meantime, Yeltsin co-opted a large segment of the electorate by appointing Lebed to the posts of national security adviser and secretary of the Security Council.\nIn the end, Yeltsin's election tactics paid off. In the run-off on 3 July, with a turnout of 68.9%, Yeltsin won 53.8% of the vote and Zyuganov 40.3%, with the rest (5.9%) voting \"against all\". Moscow and Saint Petersburg (formerly Leningrad) together provided over half of the incumbent president's support, but he also did well in large cities in the Urals and in the north and northeast. Yeltsin lost to Zyuganov in Russia's southern industrial heartland. The southern stretch of the country became known as the \"red belt\", underscoring the resilience of the Communist Party in elections since the breakup of the Soviet Union.\nAlthough Yeltsin promised that he would abandon his unpopular neoliberal austerity policies and increase public spending to help those suffering from the pain of capitalist reforms, within a month of his election, Yeltsin issued a decree canceling almost all of these promises.\nRight after the election, Yeltsin's physical health and mental stability were increasingly precarious. Many of his executive functions thus devolved upon a group of advisers (most of whom had close links with the oligarchs).\nFinancial collapse.\nThe global recession of 1998, which started with the Asian financial crisis in July 1997, exacerbated Russia's continuing economic crisis. Given the ensuing decline in world commodity prices, countries heavily dependent on the export of raw materials such as oil were among those most severely hit. Oil, natural gas, metals, and timber account for more than 80% of Russian exports, leaving the country vulnerable to swings in world prices. Oil is also a major source of government tax revenue which brought significant negative implications for Russia's fiscal situation, foreign exchange stores and ultimately, the value of the ruble.\nThe pressures on the ruble, reflecting the weakness of the economy, resulted in a disastrous fall in the value of the currency. Massive tax evasion continued and accelerated due to financial instability and decreasing government capacity. This further decreased government revenues and soon, the central government found itself unable to service the massive loans it had accumulated and ultimately was even unable to pay its employees. The government stopped making timely payment of wages, pensions, and debts to suppliers; and when workers were paid, it was often with bartered goods rather than rubles. Coal miners were especially hard hit, and for several weeks in the summer they blocked sections of the Trans-Siberian railroad with protests, effectively cutting the country in two. As time wore on, they added calls for the resignation of Yeltsin in addition to their demands for wages.\nA political crisis came to a head in March when Yeltsin suddenly dismissed Prime Minister Viktor Chernomyrdin and his entire cabinet on 23 March. Yeltsin named a virtually unknown technocrat, Energy Minister Sergei Kiriyenko, aged 35, as acting prime minister. Russian observers expressed doubts about Kiriyenko's youth and inexperience. The Duma rejected his nomination twice. Only after a month-long standoff, during which Yeltsin threatened to dissolve the legislature, did the Duma confirm Kiriyenko on a third vote on 24 April.\nKiriyenko appointed a new cabinet strongly committed to stemming the fall in the value of Russia's currency. The oligarchs strongly supported Kiriyenko's efforts to maintain the exchange rate. A high exchange rate meant that they needed fewer rubles to buy imported goods, especially luxury items.\nIn an effort to prop up the currency and stem the flight of capital, Kiriyenko hiked interest rates to 150% in order to attract buyers for government bonds. But concerns about the financial crisis in Asia and the slump in world oil prices were already prompting investors to withdraw from Russia. By mid-1998, it was clear Russia would need help from IMF to maintain its exchange rate.\nThe Russian crisis caused alarm in the West. Pouring more money into the Russian economy would not be a long-term solution, but the U.S. in particular feared that Yeltsin's government would not survive a looming financial crisis without IMF help. U.S. President Bill Clinton's treasury secretary, Robert Rubin, also feared that a Russian collapse could create a panic on world money markets (and it indeed did help bring down one major US hedge fund Long-Term Capital Management). The IMF approved a $22.6\u00a0billion emergency loan on 13 July.\nDespite the bailout, Russia's monthly interest payments still well exceeded its monthly tax revenues. Realizing that this situation was unsustainable, investors continued to flee Russia despite the IMF bailout. Weeks later the financial crisis resumed and the value of the ruble resumed its fall, and the government fell into a self-perpetuating trap. To pay off the interest on the loans it had taken, it needed to raise still more cash, which it did through foreign borrowing. As lenders became increasingly certain that the government could not make good on its obligations, they demanded ever-higher interest rates, deepening the trap. Ultimately the bubble burst.\nOn 17 August, Kiriyenko's government and the central bank were forced to suspend payment on Russia's foreign debt for 90 days, restructure the nation's entire debt, and devalue the ruble. The ruble went into free fall as Russians sought frantically to buy dollars. Western creditors lost heavily, and a large part of Russia's fledgling banking sector was destroyed, since many banks had substantial dollar borrowings. Foreign investment rushed out of the country, and financial crisis triggered an unprecedented flight of capital from Russia.\nPolitical fallout.\nThe financial collapse produced a political crisis, as Yeltsin, with his domestic support evaporating, had to contend with an emboldened opposition in the parliament. A week later, on 23 August, Yeltsin fired Kiryenko and declared his intention of returning Chernomyrdin to office as the country slipped deeper into economic turmoil. Powerful business interests, fearing another round of reforms that might cause leading concerns to fail, welcomed Kiriyenko's fall, as did the Communists.\nYeltsin, who began to lose his hold as his health deteriorated, wanted Chernomyrdin back, but the legislature refused to give its approval. After the Duma rejected Chernomyrdin's candidacy twice, Yeltsin, his power clearly on the wane, backed down. Instead, he nominated Foreign Minister Yevgeny Primakov, who on 11 September was overwhelmingly approved by the Duma.\nPrimakov's appointment restored political stability because he was seen as a compromise candidate able to heal the rifts between Russia's quarreling interest groups. There was popular enthusiasm for Primakov as well. Primakov promised to make the payment of wage and pension arrears his government's first priority, and invited members of the leading parliamentary factions into his Cabinet.\nCommunists and trade unionists staged a nationwide strike on 7 October, and called on President Yeltsin to resign. On 9 October, Russia, which was also suffering from a bad harvest, appealed for international humanitarian aid, including food.\nRecovery.\nRussia bounced back from the August 1998 financial crash with surprising speed. Much of the reason for the recovery is that world oil prices rapidly rose during 1999\u20132000 (just as falling energy prices on the world market had deepened Russia's financial troubles) so that Russia ran a large trade surplus in 1999 and 2000. Another reason is that domestic industries such as food processing have benefited from the devaluation, which caused a steep increase in the prices of imported goods. Also, since Russia's economy was operating to such a large extent on barter and other non-monetary instruments of exchange, the financial collapse had far less of an impact on many producers than it would have, had the economy been dependent on a banking system. Finally, the economy has been helped by an infusion of cash; as enterprises were able to pay off arrears in back wages and taxes, it, in turn, allowed consumer demand for the goods and services of Russian industry to rise. For the first time in many years, unemployment in 2000 fell as enterprises added workers.\nNevertheless, the political and social equilibrium of the country remains tenuous to this day, and power remains a highly personalized commodity. The economy remains vulnerable to downturn if, for instance, world oil prices fall at a dramatic pace.\nSuccession crisis.\nYevgeny Primakov did not remain in his post long. Yeltsin grew suspicious that Primakov was gaining in strength and popularity and dismissed him in May 1999, after only eight months in office. Yeltsin then named Sergei Stepashin, who had formerly been head of the FSB (the successor agency to the KGB) and later been Interior Minister, to replace him. The Duma confirmed his appointment on the first ballot by a wide margin.\nStepashin's tenure was even shorter than Primakov's. In August 1999, Yeltsin once again abruptly dismissed the government and named Vladimir Putin as his candidate to head the new government. Like Stepashin, Putin had a background in the secret police, having made his career in the foreign intelligence service and later as head of the FSB. Yeltsin went so far as to declare that he saw Putin as his successor as president. The Duma narrowly voted to confirm Putin.\nWhen appointed, Putin was a relatively unknown politician, but he quickly established himself both in public opinion and in Yeltsin's estimation as a trusted head of government, largely due to the Second Chechen War. Just days after Yeltsin named Putin as a candidate for prime minister, Chechen forces engaged the Russian army in Dagestan, a Russian autonomy near Chechnya. In the next month, several hundred people died in apartment building bombings in Moscow and other cities, bombings Russian authorities attributed to Chechen rebels. In response, the Russian army entered Chechnya in late September 1999, starting the Second Chechen War. The Russian public at the time, angry over the terrorist bombings, widely supported the war. The support translated into growing popularity for Putin, who had taken decisive action in Chechnya.\nAfter the success of political forces close to Putin in the December 1999 parliamentary elections, Yeltsin evidently felt confident enough in Putin that he resigned from the presidency on 31 December, six months before his term was due to expire. This made Putin acting president and gave Putin ample opportunity to position himself as the frontrunner for the Russian presidential election held on 26 March 2000, which he won. The Chechen War figured prominently in the campaign. In February 2000, Russian troops entered Grozny, the Chechen capital, and a week before the election, Putin flew to Chechnya on a fighter jet, claiming victory.\nPutin era.\nIn August 2000, the Russian submarine K-141 Kursk suffered an explosion, causing the submarine to sink in the shallow area of the Barents Sea. Russia organized a vigorous but hectic attempt to save the crew, and the entire futile effort was surrounded by unexplained secrecy. This, as well as the slow initial reaction to the event and especially to the offers of foreign aid in saving the crew, brought much criticism on the government and personally on President Putin.\nOn 23 October 2002, Chechen separatists took over a Moscow theater. Over 700 people inside were taken hostage in what has been called the Moscow theater hostage crisis. The separatists demanded the immediate withdrawal of Russian forces from Chechnya and threatened to blow up the building if authorities attempted to enter. Three days later, Russian commandos stormed the building after the hostages had been subdued with a sleeping gas, shooting the unconscious militants, and killing over 100 civilian hostages with the sleeping gas in the process.\nIn the aftermath of the theater siege, Putin began renewed efforts to eliminate the Chechen insurrection. (\"For additional details on the war in Chechnya under Putin, see Second Chechen War.\") The government canceled scheduled troop withdrawals, surrounded Chechen refugee camps with soldiers, and increased the frequency of assaults on separatist positions.\nChechen militants responded in kind, stepping up guerrilla operations and rocket attacks on federal helicopters. Several high-profile attacks have taken place. In May 2004, Chechen separatists assassinated Akhmad Kadyrov, the pro-Russia Chechen leader who became the president of Chechnya 8 months earlier after an election conducted by Russian authorities. On 24 August 2004, two Russian aircraft were bombed. This was followed by the Beslan school hostage crisis in which Chechen separatists took 1,300 hostages. The initially high public support for the war in Chechnya has declined.\nPutin has confronted several very influential oligarchs (Vladimir Gusinsky, Boris Berezovsky and Mikhail Khodorkovsky, in particular) who attained large stakes of state assets, allegedly through illegal schemes, during the privatization process. Gusinsky and Berezovsky have been forced to leave Russia and give up parts of their assets. Khodorkovsky was jailed in Russia and has lost his YUKOS company, formerly the largest oil producer in Russia. Putin's stand against oligarchs is generally popular with the Russian people, even though the jailing of Khodorkovsky was mainly seen as part of a takeover operation by government officials, according to another Levada-Center poll.\nThese confrontations have also led to Putin establishing control over Russian media outlets previously owned by the oligarchs. In 2001 and 2002, TV channels NTV (previously owned by Gusinsky), TV6 and TVS (owned by Berezovsky) were all taken over by media groups loyal to Putin. Similar takeovers have also occurred with print media.\nPro-Putin United Russia party won the 2003 legislative election, thus giving him unlimited and unchecked power.\nVladimir Putin's regime began to undermine judicial independence and gradually subordinated it to the Kremlin.\nPutin's popularity, which stems from his reputation as a strong leader, stands in contrast to the unpopularity of his predecessor, but it hinges on a continuation of economic recovery. Putin came into office at an ideal time: after the devaluation of the ruble in 1998, which boosted demand for domestic goods, and while world oil prices were rising. Indeed, during the seven years of his presidency, real GDP grew on average 6.7% a year, average income increased 11% annually in real terms, and a consistently positive balance of the federal budget enabled the government to cut 70% of the external debt (according to the Institute for Complex Strategic Studies). Thus, many credited him with the recovery, but his ability to withstand a sudden economic downturn has been untested. Putin won the Russian presidential election in March 2004 without any significant competition.\nSome researchers assert that most Russians (as of 2007) have come to regret the collapse of the Soviet Union in 1991. On repeated occasions, even Vladimir Putin\u2014Boris Yeltsin's handpicked successor\u00a0\u2014 stated that the fall of Soviet rule had led to few gains and many problems for most Russian citizens. In a campaign speech in February 2004, for example, Putin called the dismantlement of the Soviet Union a \"national tragedy on an enormous scale,\" from which \"only the elites and nationalists of the republics gained.\" He added, \"I think that ordinary citizens of the former Soviet Union and the post-Soviet space gained nothing from this. On the contrary, people have faced a huge number of problems.\"\nPutin's international prestige suffered a major blow in the West during the disputed 2004 Ukrainian presidential election. Putin had twice visited Ukraine before the election to show his support for the pro-Russian Viktor Yanukovych against opposition leader Viktor Yushchenko, a pro-Western liberal economist. He congratulated Yanukovych, followed shortly afterwards by Belarusian president Alexander Lukashenko, on his victory before election results were even made official and made statements opposing the rerun of the disputed second round of elections, won by Yanukovych, amid allegations of large-scale voting fraud. The second round was ultimately rerun; Yushchenko won the round and was eventually declared the winner on 10 January 2005. In the West, the reaction to Russia's handling of, or perhaps interference in, the Ukrainian election evoked echoes of the Cold War, but relations with the U.S. remained stable.\nOn 14 March 2004, Putin was elected to the presidency for a second term, receiving 71% of the vote. The Beslan school hostage crisis took place in September 2004, in which hundreds died. Many in the Russian press and in the international media warned that the death of 130 hostages in the special forces' rescue operation during the 2002 Moscow theater hostage crisis would severely damage President Putin's popularity. However, shortly after the siege had ended, the Russian president enjoyed record public approval ratings \u2013 83% of Russians declared themselves satisfied with Putin and his handling of the siege.\nIn 2005, the Russian government replaced the broad in-kind Soviet-era benefits, such as free transportation and subsidies for heating and other utilities for socially vulnerable groups by cash payments. The reform, known as monetization, has been unpopular and caused a wave of demonstrations in various Russian cities, with thousands of retirees protesting against the loss of their benefits. This was the first time such wave of protests took place during the Putin administration. The reform hurt the popularity of the Russian government, but Putin personally remained popular, with a 77% approval rating.\nThe near 10-year period prior to the rise of Putin after the dissolution of Soviet rule was a time of upheaval in Russia. In a 2005 Kremlin speech, Putin characterized the collapse of the Soviet Union as the \"greatest geopolitical catastrophe of the Twentieth Century.\" Putin elaborated: \"Moreover, the epidemic of disintegration infected Russia itself.\" The country's cradle-to-grave social safety net was gone and life expectancy declined in the period preceding Putin's rule. In 2005, the National Priority Projects were launched to improve Russia's health care, education, housing and agriculture.\nThe continued criminal prosecution of Russia's then richest man, President of Yukos oil and gas company Mikhail Khodorkovsky, for fraud and tax evasion was seen by the international press as a retaliation for Khodorkovsky's donations to both liberal and communist opponents of the Kremlin. The government said that Khodorkovsky was \"corrupting\" a large segment of the Duma to prevent changes to the tax code. Khodorkovsky was arrested, Yukos was bankrupted and the company's assets were auctioned at below-market value, with the largest share acquired by the state company Rosneft. The fate of Yukos was seen as a sign of a broader shift of Russia towards a system of state capitalism. This was underscored in July 2014 when shareholders of Yukos were awarded $50\u00a0billion in compensation by the Permanent Arbitration Court in The Hague.\nOn 7 October 2006, Anna Politkovskaya, a journalist who exposed corruption in the Russian army and its conduct in Chechnya, was shot in the lobby of her apartment building, on Putin's birthday. The death of Politkovskaya triggered international criticism, with accusations that Putin has failed to protect the country's new independent media. Putin himself said that her death caused the government more problems than her writings.\nIn 2007, \"Dissenters' Marches\" were organized by the opposition group The Other Russia, led by former chess champion Garry Kasparov and national-Bolshevist leader Eduard Limonov. Following prior warnings, demonstrations in several Russian cities were met by police action, which included interfering with the travel of the protesters and the arrests of as many as 150 people who attempted to break through police lines.\nOn 12 September 2007, Putin dissolved the government upon the request of Prime Minister Mikhail Fradkov. Fradkov commented that it was to give the President a \"free hand\" in the run-up to the parliamentary election. Viktor Zubkov was appointed the new prime minister.\nIn the December 2007 election, United Russia won 64.30% of the popular vote in their run for State Duma. This victory was seen by many as an indication of strong popular support of the then Russian leadership and its policies.\nAt the end of Putin's second term, Jonathan Steele has commented on Putin's legacy: \"What, then, is Putin's legacy? Stability and growth, for starters. After the chaos of the 90s, highlighted by Yeltsin's attack on the Russian parliament with tanks in 1993 and the collapse of almost every bank in 1998, Putin has delivered political calm and a 7% annual rate of growth. Inequalities have increased and many of the new rich are grotesquely crass and cruel, but not all the Kremlin's vast revenues from oil and gas have gone into private pockets or are being hoarded in the government's \"stabilisation fund\". Enough has gone into modernising schools and hospitals so that people notice a difference. Overall living standards are up. The second Chechen war, the major blight on Putin's record, is almost over\".\nPutin was barred from a third term by the Constitution of Russia. First Deputy Prime Minister Dmitry Medvedev was elected his successor. In a power-switching operation on 8 May 2008, only a day after handing the presidency to Medvedev, Putin was appointed Prime Minister of Russia, maintaining his political dominance.\nIn 2008, Kosovo's declaration of independence saw a marked deterioration in Russia's relationship with the West. It also saw South Ossetia war against Georgia, that followed Georgia's attempt to take over the breakaway region of South Ossetia. Russian troops entered South Ossetia and forced Georgian troops back, establishing their control on this territory. In the fall of 2008, Russia unilaterally recognized the independence of South Ossetia and Abkhazia.\nPutin has said that overcoming the consequences of the world economic crisis was one of the two main achievements of his second Premiership. The other was the stabilizing the size of Russia's population between 2008 and 2011 following a long period of demographic collapse that began in the 1990s.\nAt the United Russia Congress in Moscow on 24 September 2011, Medvedev officially proposed that Putin stand for the presidency in March 2012, an offer Putin accepted. Given United Russia's near-total dominance of Russian politics, many observers believed that Putin was assured of a third term. The move was expected to see Medvedev stand on the United Russia ticket in the parliamentary elections in December, with a goal of becoming prime minister at the end of his presidential term.\nAfter the parliamentary elections on 4 December 2011, tens of thousands of Russians engaged in protests against alleged electoral fraud, the largest protests in Putin's time. Protesters criticized Putin and United Russia and demanded annulment of the election results. Those protests sparked the fear of a colour revolution in society. Putin allegedly organized a number of paramilitary groups loyal to himself and to the United Russia party in the period between 2005 and 2012.\nOn 4 March 2012, Putin won the 2012 Russian presidential elections in the first round, with 63.6% of the vote, despite widespread accusations of vote-rigging. Opposition groups accused Putin and the United Russia party of fraud. While efforts to make the elections transparent were publicized, including the usage of webcams in polling stations, the vote was criticized by the Russian opposition and by international observers from the Organization for Security and Co-operation in Europe for procedural irregularities.\nAnti-Putin protests took place during and directly after the presidential campaign. The most notorious protest was the Pussy Riot performance on 21 February, and subsequent trial. An estimated 8,000\u201320,000 protesters gathered in Moscow on 6 May, when eighty people were injured in confrontations with police, and 450 were arrested, with another 120 arrests taking place the following day.\nIn 2012 and 2013, Putin and the United Russia party backed stricter legislation against the LGBT community, in Saint Petersburg, Arkhangelsk and Novosibirsk; a law called the Russian gay propaganda law, that is against \"homosexual propaganda\" (which prohibits such symbols as the rainbow flag as well as published works containing homosexual content) was adopted by the State Duma in June 2013. Responding to international concerns about Russia's legislation, Putin asked critics to note that the law was a \"ban on the propaganda of pedophilia and homosexuality\" and he stated that homosexual visitors to the 2014 Winter Olympics should \"leave the children in peace\" but denied there was any \"professional, career or social discrimination\" against homosexuals in Russia.\nRusso-Ukrainian War.\nOn 22 February 2014, the Yanukovych government of Ukraine collapsed as a result of the Revolution of Dignity, which the Russian government called a foreign backed proxy movement. On the same day, according to Russian president Vladimir Putin, he called an all-night meeting of his military leaders, at the end of which he ordered them to \"begin the work to bring Crimea back into Russia.\" By 27 February, unmarked Russian troops in Ukraine were establishing a blockade of the borders and Ukrainian military bases in the Autonomous Republic of Crimea, and took armed control of its regional parliament.\nA new Ukrainian government was formed and scheduled new elections for May 2014. On 1 March, from exile, Viktor Yanukovych requested that Russia use military forces \"to establish legitimacy, peace, law and order, stability and defending the people of Ukraine\". On the same day, Vladimir Putin requested and received authorization from the Russian Parliament to deploy Russian troops to Ukraine in response to the crisis and gained complete control over Crimean Peninsula within a day.\nOn 6 March 2014, the Crimean Parliament voted to \"enter into the Russian Federation with the rights of a subject of the Russian Federation\" and later held a referendum asking the people of these regions whether they wanted to join Russia as a federal subject, or if they wanted to restore the 1992 Crimean constitution and Crimea's status as a part of Ukraine. Though passed with an overwhelming majority, the results are contested by some and approved by others. \nCrimea and Sevastopol formally declared independence as the Republic of Crimea and requested that they be admitted as constituents of the Russian Federation. On 18 March 2014, Russia and Crimea signed a treaty of accession of the Republic of Crimea and Sevastopol in the Russian Federation, while the United Nations General Assembly voted in favor of a non-binding Resolution 68/262 to oppose Russia's annexation of the peninsula.\nOn 24 February 2022, Russia launched a full-scale invasion of Ukraine, although it was described as a \"special military operation\" by Putin. The invasion led to international condemnation followed by political, economic and cultural sanctions. The invasion also sparked protests around the world as well as within Russia.\nOn 21 September 2022, Vladimir Putin announced a partial mobilization. He also said that his country will use \"all means\" to \"defend itself\". Later that day, the minister of defence Sergei Shoigu stated that 300,000 reservists would be called on a compulsory basis. Following president Putin's announcement of partial mobilization, massive Russian emigration began, with estimates of hundreds of thousands of male citizens fleeing, many going to Kazakhstan, Serbia, Georgia and Finland.\nIn late September 2022, Russian-installed officials in Ukraine organized referendums on annexation of occupied territories of Ukraine, including the Donetsk People's Republic and the Luhansk People's Republic in Russian occupied Donetsk and Luhansk oblasts of Ukraine, as well as the Russian-appointed military administrations of Kherson Oblast and Zaporizhzhia Oblast. Denounced by Ukraine's government and its allies as sham, the official results showed overwhelming majorities in favor of annexation. On 30 September 2022, Russia's president Vladimir Putin announced the annexation of Donetsk, Kherson, Luhansk and Zaporizhzhia oblasts of Ukraine in an address to both houses of the Russian parliament. The United Nations, Ukraine, and many other countries condemned the annexation.\nOn 23 June 2023, the private military company Wagner Group, which had been assisting Russia in its invasion of Ukraine, declared a rebellion against the Russian military. Several cities along the M-4 Highway, including Rostov and Vorenhzh, were seized by Wagner forces, as they began to march towards Moscow. The following day, Wagner forces stepped down and the rebellion ended.\nRelations with the West.\nIn the early period after Russia became independent, Russian foreign policy repudiated Marxism\u2013Leninism as a putative guide to action, emphasizing cooperation with the West in solving regional and global problems, and soliciting economic and humanitarian aid from the West in support of internal economic reforms.\nHowever, although Russia's leaders now described the West as its natural ally, they grappled with defining new relations with the East European states, the new states formed upon the disintegration of Yugoslavia, and Eastern Europe. Russia opposed the expansion of NATO into the former Soviet bloc nations of the Czech Republic, Poland, and Hungary in 1997 and, particularly, the second NATO expansion into Bulgaria, Estonia, Latvia, Lithuania, Romania, Slovakia and Slovenia in 2004. In 1999, Russia opposed the NATO bombing of Yugoslavia for more than two months (\"see\" Kosovo War), but later joined NATO peace-keeping forces in the Balkans in June 1999.\nRelations with the West have also been strained by Russia's relationship with Belarus. Belarusian President Alexander Lukashenko, an authoritarian leader, has shown no interest in implementing Western-backed economic and political reforms and has aligned his country with Russia, and has no interest in deepening ties with NATO. A union agreement between Russia and Belarus was formed on 2 April 1996. The agreement was tightened, becoming the Union of Russia and Belarus on 3 April 1997. Further strengthening of the union occurred on 25 December 1998, and in 1999.\nUnder Putin, Russia has sought to strengthen ties with the People's Republic of China by signing the Treaty of Good-Neighborliness and Friendly Cooperation as well building the Trans-Siberian oil pipeline geared toward growing Chinese energy needs. He also made a number of appearances in the media with President of the United States George W. Bush in which the two described each other as \"friends\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nMark Hollingsworth &amp; Stewart Lansley, Londongrad: From Russia With Cash, 2009, 4th Estate"}
{"id": "52631", "revid": "17862675", "url": "https://en.wikipedia.org/wiki?curid=52631", "title": "Tobacco industry", "text": "Persons and companies that produce tobacco-related products\nThe tobacco industry comprises those persons and companies who are engaged in the growth, preparation for sale, shipment, advertisement, and distribution of tobacco and tobacco-related products. It is a global industry; tobacco can grow in any warm, moist environment, which means it can be farmed on all continents except Antarctica.\nAccording to the WHO Framework Convention on Tobacco Control, the \"tobacco industry\" encompasses tobacco manufacturers, wholesale distributors and importers of tobacco products. This evidence-based treaty expects its 181 ratified member states to implement public health policies with respect to tobacco control \"to protect present and future generations from the devastating health, social, environmental and economic consequences of tobacco consumption and exposure to tobacco smoke.\"\nTobacco, one of the most widely used addictive substances in the world, is a plant native to the Americas and historically one of the most important crops grown by American farmers. More specifically, tobacco refers to any of various plants of the genus \"Nicotiana\" (especially \"N. tabacum\") native to tropical America and widely cultivated for their leaves, which are dried and processed chiefly for smoking in pipes, cigarettes, and cigars; it is also cut to form chewing tobacco or ground to make snuff or dipping tobacco, as well as other less common preparations. From 1617 to 1793, tobacco was the most valuable cash crop export from British North America and the United States. Until the 1960s, the United States grew, manufactured and exported more tobacco than any other country.\nTobacco is an agricultural commodity product, similar in economic terms to agricultural foodstuffs: the price is in part determined by crop yields, which vary depending on local weather conditions. The price also varies by specific species or cultivar grown, the total quantity on the market ready for sale, the area where it is grown, the health of the plants, and other characteristics individual to product quality.\nSince 1964, conclusive medical evidence of the deadly effects of tobacco consumption has led to a sharp decline in official support for producers and manufacturers of tobacco, although it contributes to the agricultural, fiscal, manufacturing, and exporting sectors of the economy. Policy and law restricting tobacco smoking has increased globally, but almost 6 trillion cigarettes are still produced each year, representing an increase of over 12% since the year 2000. Tobacco is often heavily taxed to gain revenues for governments and as an incentive for people not to smoke.\nHistory.\nFor a history of how tobacco has been grown and marketed, see tobacco, smoking and articles on similar topics.\nPosition of industry.\nThe phrase \"tobacco industry\" generally refers to the companies involved in the manufacture of cigarettes, cigars, snuff, chewing tobacco and pipe tobacco. China National Tobacco Co. has become the largest tobacco company in the world by volume. Following extensive merger and acquisition activity in the 1990s and 2000s as well as the spinoff of Altria's international tobacco holdings as Philip Morris International in 2008, five firms dominate international markets \u2013 in alphabetical order:\nAltria still owns the Philip Morris tobacco business in the United States, but Philip Morris International has been fully independent since 2008. In most countries these companies either have long-established dominance, or have purchased the major domestic producer or producers (often a former state monopoly). Until 2014 the United States had one other substantial independent firm, Lorillard, which Reynolds American, Inc. acquired. India has its own major player, ITC Limited (25.4%-owned by British American Tobacco). A small number of state monopolies survive, as well as some small independent firms.\nTobacco advertising is becoming increasingly restricted by the governments of countries around the world citing health issues as a reason to restrict tobaccos appeal.\nIndustry outlook in the United States.\nThe tobacco industry in the United States has suffered greatly since the mid-1990s, when it was successfully sued by several U.S. states. The suits claimed that tobacco causes cancer, that companies in the industry knew this, and that they deliberately understated the significance of their findings, contributing to the illness and death of many citizens in those states.\nThe industry was found to have decades of internal memos confirming in detail that tobacco (which contains nicotine) is both addictive and carcinogenic (cancer-causing). The industry had long denied that nicotine is addictive.\nThe suit resulted in a large cash settlement being paid by a group of tobacco companies to the states that sued. Further, since the suit was settled, other individuals have come forth, in class action lawsuits, claiming individual damages. \nThe tobacco industry has historically been largely successful in this litigation process, with the majority of cases being won by the industry. During the first 42 years of tobacco litigation (between 1954 and 1996) the industry maintained a clean record in litigation thanks to tactics described in a R.J. Reynolds Tobacco Company internal memo as \"the way we won these cases, to paraphrase Gen. Patton, is not by spending all of Reynolds' money, but by making the other son of a bitch spend all of his.\" Between 1995 and 2005 only 59% of cases were won by the tobacco industry either outright or on appeal in the US, but the continued success of the industry's efforts to win these cases is questionable. In Florida, the industry has lost 77 of the 116 \"Engle progeny\" cases that have gone to trial. The U.S. Supreme Court has also denied the industry's major grounds for appeal of Engle cases.\nIn June 2009, U.S. President Barack Obama signed into law the Family Smoking Prevention and Tobacco Control Act which has been called a \"sweeping anti-smoking\" bill. Among other restrictions, this Act banned the use of any constituent, additive, herb or spice that adds a \"characterizing flavor\" to the tobacco product or smoke (Section 907)(a)(1)(A). The aim of this ban is to prevent children and teenagers from becoming addicted to cigarettes at a young age with the US Department of Health and Human Services citing that \"studies have shown that 17 year old smokers are three times as likely to use flavored cigarettes as are smokers over the age of 25\". This ban however does not apply to menthol cigarettes, which are exempt from the bill.\nLawsuits against the tobacco industry are primarily restricted to the United States due to differences in legal systems in other countries. Many businesses class ongoing lawsuits as a cost of doing business in the US and feel their revenue will be only marginally affected by the activities.\nLarge tobacco companies have entered the electronic cigarette market by either buying some of the small e-cigarette companies or by starting their own e-cigarette companies. By 2014 all the major multinational tobacco companies had entered the e-cigarette market. They did so either by buying existing e-cigarette companies (including Ruyan, the original Chinese e-cigarette company, which was bought by Imperial Tobacco) or by developing their own products. A 2017 review states, \"The tobacco industry dominates the e-cigarette market.\" All of the large tobacco companies are selling e-cigarettes. A 2017 review states, \"Small companies initially dominated the electronic nicotine delivery systems (ENDS) market, and these firms had no links to the tobacco industry. Today, however, all transnational tobacco companies sell these products. Increased concentration of the ENDS market in the hands of the transnational tobacco companies is concerning to the public health community, given the industry's legacy of obfuscating many fundamental truths about their products and misleading the public with false claims, including that low-tar and so-called \"light\" cigarettes would reduce the harms associated with smoking. Although industry representatives are claiming interest in ENDS because of their harm-reduction potential, many observers believe that profit remains the dominant motivation.\"\nMajor tobacco companies are dominating the political and policy-making environments just as they have in conventional cigarette policy making. As they have done to influence tobacco control policies for conventional cigarettes, the large companies often try to stay out of sight and work through third parties that can obscure their links to the tobacco industry. The one difference from the historical pattern of industry efforts to shape tobacco policy from behind the scenes is that there are also genuine independent sellers of e-cigarettes and associated users (so-called vape shops) who are not necessarily being directed by the cigarette companies. These smaller operators are, however, losing market share to the big tobacco companies, and the real political power is now being exercised by the cigarette companies. The cigarette companies try to take advantage of the existence of independent players while acting through the industry's traditional allies and front groups.\nTobacco control.\nOn May 11, 2004, the U.S. became the 108th country to sign the World Health Organization's Global Treaty on Tobacco Control. This treaty places broad restrictions on the sale, advertising, shipment, and taxation of tobacco products. The U.S. has not yet ratified this treaty in its Senate and does not yet have a schedule for doing so.\nMost recently, there has been discussion within the tobacco control community of transforming the tobacco industry through the replacement of tobacco corporations by other types of business organizations that can be established to provide tobacco to the market while not attempting to increase market demand.\nOn February 20, 2007, the US Supreme Court ruled that the Altria Group (formerly Philip Morris) did not have to pay $79.5 million in punitive damages awarded to Mayola Williams in a 1999 Oregon court ruling, when she sued Phillip Morris for responsibility in the cancer death of her husband, Jesse Williams. The Supreme Court's decision overturns a ruling made by the Oregon Supreme Court that upheld the award.\nOn April 3, 2008, the U.S. Court of Appeals for the Second Circuit threw out an $800 billion class-action lawsuit filed on behalf of a group or class of people who smoked light cigarettes. The plaintiffs' lawyers were confident that they would be able to win this suit due to the success of \"Schwab v. Philip Morris\" wherein tobacco companies were found guilty of fraud-like charges because they were selling the idea that light cigarettes were safer than regular cigarettes. The ruling by the three-judge panel will not allow the suit to be pursued as a class, but instead need proof for why individual smokers chose light cigarettes over regular cigarettes.\nProduction by country or region.\nThe United Nations Food and Agriculture Organization estimates the following production of unmanufactured tobacco by country/region in 2022. (Figures are in thousands of tonnes.)(FAO)\nCigarette production by factory.\nMuch of global tobacco production is used in the manufacturing of cigarettes. The following is a chart compiled by Dr. Robert Proctor detailing the largest cigarette factories, accompanied by their estimated annual death toll due to the harms of cigarettes to health.\nIn popular culture.\nThe tobacco industry has had a long relationship with the entertainment industry. In silent era movies, back-lit smoke was often used by filmmakers to create sense of mystery and sensuality in a scene. Later, cigarettes were deliberately placed in the hands of Hollywood stars as an early phase of product placement, until health regulating bodies tightened rules on tobacco advertisement and anti-smoking groups pressured actors and studio executives against such tactics. Big Tobacco has since been the subject focus of films such as the docudrama \"The Insider\" (1999) and \"Thank You For Smoking\" (2005).\nThese issues have also constituted a recurring storyline in the AMC series \"Mad Men\", from season 1 beginning with the pilot episode (\"Smoke Gets In Your Eyes\") through season 7's midseason finale, \"Waterloo\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52632", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=52632", "title": "Philip Morris Cos.", "text": ""}
{"id": "52633", "revid": "45789152", "url": "https://en.wikipedia.org/wiki?curid=52633", "title": "Microwaving", "text": ""}
{"id": "52634", "revid": "50477716", "url": "https://en.wikipedia.org/wiki?curid=52634", "title": "Baking", "text": "Food producing method\nBaking is a method of preparing food that uses dry heat, typically in an oven, but it can also be done in hot ashes, or on hot stones. Bread is the most commonly baked item, but many other types of food can also be baked. Heat is gradually transferred from the surface of cakes, cookies, and pieces of bread to their center, typically conducted at elevated temperatures surpassing 300\u00a0\u00b0F (148 \u00b0C). ( Dry heat cooking imparts a distinctive richness to foods through the processes of caramelization and surface browning. As heat travels through, it transforms batters and doughs into baked goods and more with a firm dry crust and a softer center. Baking can be combined with grilling to produce a hybrid barbecue variant by using both methods simultaneously, or one after the other. Baking is related to barbecuing because the concept of the masonry oven is similar to that of a smoke pit.\nBaking has traditionally been performed at home for day-to-day meals and in bakeries and restaurants for local consumption. When production was industrialized, baking was automated by machines in large factories. The art of baking remains a fundamental skill and is important for nutrition, as baked goods, especially bread, are a common and important food, both from an economic and cultural point of view. A person who prepares baked goods as a profession is called a baker.\nFoods and techniques.\nAll types of food can be baked, but some require special care and protection from direct heat. Various techniques have been developed to provide this protection.\nIn addition to bread, baking is used to prepare cakes, pastries, pies, tarts, quiches, cookies, scones, crackers, pretzels, and more. These popular items are known collectively as \"baked goods,\" and are often sold at a bakery, which is a store that carries only baked goods, or at markets, grocery stores, farmers markets or through other venues.\nMeats\u2014including cured meats like ham\u2014However, baking is typically reserved for meatloaf, smaller cuts of whole meat, or whole meats that are stuffed or coated with bread crumbs or buttermilk batter. Some foods are surrounded with moisture during baking by placing a small amount of liquid (such as water or broth) in the bottom of a closed pan, and letting it steam up around the food. Roasting is a term synonymous with baking, but traditionally denotes the cooking of whole animals or major cuts through exposure to dry heat; for instance, one bakes chicken parts but roasts the whole bird. One can bake pork or lamb chops but roasts the whole loin or leg. There are many exceptions to this rule of the two terms. Baking and roasting otherwise involve the same range of cooking times and temperatures. Another form of baking is the method known as \"en cro\u00fbte\" (French for \"in crust\", referring to a pastry crust), which protects the food from direct heat and seals the natural juices inside. Meat, poultry, game, fish or vegetables can be prepared by baking \"en cro\u00fbte\". Well-known examples include Beef Wellington, where the beef is encased in pastry before baking; p\u00e2t\u00e9 en cro\u00fbte, where the terrine is encased in pastry before baking; and the Vietnamese variant, a meat-filled pastry called p\u00e2t\u00e9 chaud. The \"en cro\u00fbte\" method also allows meat to be baked by burying it in the embers of a fire\u2014a favorite method of cooking venison. Salt can also be used to make a protective crust that is not eaten. Another method of protecting food from the heat while it is baking is to cook it \"en papillote\" (French for \"in parchment\"). In this method, the food is covered by baking paper (or aluminum foil) to protect it while it is being baked. The cooked parcel of food is sometimes served unopened, allowing diners to discover the contents for themselves.\nEggs can also be used in baking to produce savory or sweet dishes. In combination with dairy products especially cheese, they are often prepared as a dessert. For example, although a baked custard can be made using starch (in the form of flour, cornflour, arrowroot, or potato flour), the flavor of the dish is much more delicate if eggs are used as the thickening agent. Baked custards, such as cr\u00e8me caramel, are among the items that need protection from an oven's direct heat, and the \"bain-marie\" method serves this purpose. The cooking container is half-submerged in water in another, larger one so that the heat in the oven is more gently applied during the baking process. Baking a successful souffl\u00e9 requires that the baking process be carefully controlled. The oven temperature must be absolutely even and the oven space must not be shared with another dish. These factors, along with the theatrical effect of an air-filled dessert, have given this baked food a reputation for being a culinary achievement. Similarly, a good baking technique (and a good oven) are also needed to create a baked Alaska because of the difficulty of baking hot meringue and cold ice cream at the same time.\nBaking can also be used to prepare other foods such as pizzas, baked potatoes, baked apples, baked beans, some casseroles and pasta dishes such as lasagne.\nBaking can also be used to prepare other foods such as pizzas, baked potatoes, baked apples, baked beans, some casseroles and pasta dishes such as lasagne. Baking goods are not limited to being served warm or right after baking, however, as some recipes, such as cheesecake, are served differently. Specifically, cheesecake requires cooling after being removed from the oven, before then being set to freeze inside of a refrigerator for several hours, and finally served cold.\nBaking in ancient times.\nThe earliest known form of baking occurred when humans took wild grass grains, soaked them in water, and mashed the mixture into a kind of broth-like paste. The paste was cooked by pouring it onto a flat, hot rock, resulting in a bread-like substance. Later, as humans mastered fire, they roasted the paste on hot embers, making bread-making more convenient as it could be done whenever fire was created. According to Britannica, the Ancient Egyptians invented the first ovens. They also baked bread using yeast, which they had previously been using to brew beer. By 2600 BCE, they were making bread in ways similar in principle to those of today. The book \"Bread for the Wilderness\" states that \"Ovens and worktables have been discovered in archaeological digs from Turkey (Hacilar) to Palestine (Jericho (Tell es-Sultan)) and date back to 5600 BC.\"\nBaking flourished during the Roman Empire. Beginning around 300 BC, the pastry cook became an occupation for Romans (known as the pastillarium) and became a respected profession because pastries were considered decadent, and Romans loved festivity and celebration. Thus, pastries were often cooked especially for large banquets, and any pastry cook who could invent new types of tasty treats was highly prized. Around 1 AD, there were more than three hundred pastry chefs in Rome, and Cato wrote about how they created all sorts of diverse foods and flourished professionally and socially because of their creations. Cato speaks of an enormous number of breads including; libum (cakes made with flour and honey, often sacrificed to gods), placenta (groats and cress), spira (modern day flour pretzels), scibilata (tortes), savillum (sweet cake), and globus apherica (fritters). A great selection of these, with many different variations, different ingredients, and varied patterns, were often found at banquets and dining halls. The Romans baked bread in an oven with its own chimney, and had mills to grind grain into flour. A bakers' guild was established in 168 BC in Rome.\nCommercial baking.\nEventually, the Roman art of baking became known throughout Europe and eventually spread to eastern parts of Asia. By the 13th century in London, commercial trading, including baking, had many regulations attached. In the case of food, they were designed to create a system \"so there was little possibility of false measures, adulterated food or shoddy manufactures\". There were by that time twenty regulations applying to bakers alone, including that every baker had to have \"the impression of his seal\" upon bread.\nBeginning in the 19th century, alternative leavening agents became more common, such as baking soda. Bakers often baked goods at home and then sold them in the streets. This scene was so common that Rembrandt, among others, painted a pastry chef selling pancakes in the streets of Germany, with children clamoring for a sample. In London, pastry chefs sold their goods from handcarts. This developed into a delivery system of baked goods to households and greatly increased demand as a result. In Paris, the first open-air caf\u00e9 of baked goods was developed, and baking became an established art throughout the entire world.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Every family used to prepare the bread for its own consumption, the \"trade\" of baking, not having yet taken shape. Mrs Beeton (1861)\nBaking eventually developed into a commercial industry using automated machinery which enabled more goods to be produced for widespread distribution. In the United States, the baking industry \"was built on marketing methods used during feudal times and production techniques developed by the Romans.\" Some makers of snacks such as potato chips or crisps have produced baked versions of their snack products as an alternative to the usual cooking method of deep frying in an attempt to reduce their calorie or fat content. Baking has opened up doors to businesses such as cake shops and factories where the baking process is done with larger amounts in large, open furnaces.\nThe aroma and texture of baked goods as they come out of the oven are strongly appealing but is a quality that is quickly lost. Since the flavour and appeal largely depend on freshness, commercial producers have to compensate by using food additives as well as imaginative labeling. As more and more baked goods are purchased from commercial suppliers, producers try to capture that original appeal by adding the label \"home-baked.\" Such attempts seek to make an emotional link to the remembered freshness of baked goods as well as to attach positive associations the purchaser has with the idea of \"home\" to the bought product. Freshness is such an important quality that restaurants, although they are commercial (and not domestic) preparers of food, bake their own products. For example, scones at The Ritz London Hotel \"are not baked until early afternoon on the day they are to be served, to make sure they are as fresh as possible.\"\nEquipment.\nBaking needs an enclosed space for heating\u00a0\u2013 typically in an oven. Formerly, primitive clay ovens were in use. The fuel can be supplied by wood, coal, gas, or electricity. Adding and removing items from an oven may be done by hand with an oven mitt or by a peel, a long handled tool specifically used for that purpose.\nMany commercial ovens are equipped with two heating elements: one for baking, using convection and thermal conduction to heat the food, and one for broiling or grilling, heating mainly by radiation. Another piece of equipment still used for baking is the Dutch oven. \"Also called a bake kettle, bastable, bread oven, fire pan, bake oven kail pot, tin kitchen, roasting kitchen, \"doufeu\" (French: \"gentle fire\") or \"feu de compagne\" (French: \"country oven\") [it] originally replaced the cooking jack as the latest fireside cooking technology,\" combining \"the convenience of pot-oven and hangover oven.\"\nAsian cultures have adopted steam baskets to produce the effect of baking while reducing the amount of fat needed.\nOther equipment/tools needed for baking precision include a method for measuring ingredients. Ideally, a scale accurate to the gram is used, as exact measurements provide the best results, but some bakers rely on measuring cups and measuring spoons.\nDigital kitchen scales are also popular in baking where precise measurements are a must for dry ingredients. The tare function simplifies the process by allowing multiple ingredients to be measured in the same mixing bowl, resetting the scale to zero between each addition and eliminating the need for extra measuring tools.\nProcess.\nEleven events occur concurrently during baking, some of which (such as starch gelatinization) would not occur at room temperature.\nThe dry heat of baking changes the form of starches in the food and causes its outer surfaces to brown, giving it an attractive appearance and taste. The browning is caused by the caramelization of sugars and the Maillard reaction. Maillard browning occurs when \"sugars break down in the presence of proteins. Because foods contain many different types of sugars and proteins, Maillard browning contributes to the flavour of a wide range of foods, including nuts, roast beef, and baked bread.\" The moisture is never entirely \"sealed in\"; over time, an item being baked will become dry. This is often an advantage, especially in situations where drying is the desired outcome, like drying herbs or roasting certain types of vegetables.\nThe baking process does not require any fat to be used to cook in an oven. When baking, consideration must be given to the amount of fat that is contained in the food item. Higher levels of fat such as margarine, butter, lard, or vegetable shortening will cause an item to spread out during the baking process.\nWith the passage of time, breads harden and become stale. This is not primarily due to moisture being lost from the baked products, but more a reorganization of the way in which the water and starch are associated over time. This process is similar to recrystallization and is promoted by storage at cool temperatures, such as in a domestic refrigerator or freezer.\nCultural and religious significance.\nBaking, especially of bread, holds special significance for many cultures. It is such a fundamental part of everyday food consumption that the children's nursery rhyme \"Pat-a-cake, pat-a-cake, baker's man\" takes baking as its subject. Baked goods are normally served at all kinds of parties and special attention is given to their quality at formal events. They are also one of the main components of a tea party, including at nursery teas and high teas, a tradition which started in Victorian Britain, reportedly when Anna Russell, Duchess of Bedford \"grew tired of the sinking feeling which afflicted her every afternoon round 4 o'clock\u00a0... In 1840, she plucked up courage and asked for a tray of tea, bread and butter, and cake to be brought to her room. Once she had formed the habit she found she could not break it, so spread it among her friends instead. As the century progressed, afternoon tea became increasingly elaborate.\"\nThe Benedictine Sisters of the Benedictine Monastery of Caltanissetta baked a pastry called Crocetta of Caltanissetta (Cross of Caltanissetta). They used to be prepared for the Holy Crucifix festivity. The monastery was situated next to the Church of the Holy Cross, from which these sweet pastries take the name.\nFor Jews, matzo is a baked product of considerable religious and ritual significance. Baked matzah bread can be ground up and used in other dishes, such as gefilte fish, and baked again. For Christians, bread has to be baked to be used as an essential component of the sacrament of the Eucharist. In the Eastern Christian tradition, baked bread in the form of birds is given to children to carry to the fields in a spring ceremony that celebrates the Forty Martyrs of Sebaste.\nJesus defines himself as the \u201cbread of life\u201d (John 6:35). Divine \u201cGrace\u201d is called \u201cbread of the strong\u201d and preaching, religious teaching, the \u201cbread of the word of God\u201d. In Roman Catholicism, the piece of blessed wax encased in a reliquary is the \u201csacred bread\u201d. In Hebrew, Bethlehem means \"the house of bread\", and Christians see in the fact that Jesus was born (before moving to Nazareth) in a city of that name, the significance of his sacrifice via the Eucharist. The Eucharist is often interpreted as a connection to the Holy Spirit, a symbol of God\u2019s love, and an invitation to reflect that love in service to others, providing strength for living out one\u2019s faith.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52635", "revid": "45789152", "url": "https://en.wikipedia.org/wiki?curid=52635", "title": "Barbecuing", "text": ""}
{"id": "52636", "revid": "48944631", "url": "https://en.wikipedia.org/wiki?curid=52636", "title": "Boiling", "text": "Physical process\nBoiling or ebullition is the rapid phase transition from liquid to gas or vapour; the reverse of boiling is condensation. Boiling occurs when a liquid is heated to its boiling point, so that the vapour pressure of the liquid is equal to the pressure exerted on the liquid by the surrounding atmosphere. Boiling and evaporation are the two main forms of liquid vapourization.\nThere are two main types of boiling: nucleate boiling, where small bubbles of vapour form at discrete points; and critical heat flux boiling, where the boiling surface is heated above a certain critical temperature and a film of vapour forms on the surface. Transition boiling is an intermediate, unstable form of boiling with elements of both types. The boiling point of water is 100\u00a0\u00b0C or 212\u00a0\u00b0F but is lower with the decreased atmospheric pressure found at higher altitudes.\nBoiling water is used as a method of making it potable by killing microbes and viruses that may be present. The sensitivity of different micro-organisms to heat varies, but if water is held at for one minute, most micro-organisms and viruses are inactivated. Ten minutes at a temperature of 70\u00a0\u00b0C (158\u00a0\u00b0F) is also sufficient to inactivate most bacteria.\nBoiling water is also used in several cooking methods including boiling, blanching, steaming, and poaching.\nTypes.\nFree convection.\nThe lowest heat flux seen in boiling is only sufficient to cause natural convection, where the warmer fluid rises due to its slightly lower density. This condition occurs only when the superheat is very low, meaning that the hot surface near the fluid is nearly the same temperature as the boiling point.\nNucleate.\nNucleate boiling is characterised by the growth of bubbles or pops on a heated surface (heterogeneous nucleation), which rises from discrete points on a surface, whose temperature is only slightly above the temperature of the liquid. In general, the number of nucleation sites is increased by an increasing surface temperature.\nAn irregular surface of the boiling vessel (i.e., increased surface roughness) or additives to the fluid (i.e., surfactants and/or nanoparticles) facilitate nucleate boiling over a broader temperature range, while an exceptionally smooth surface, such as plastic, lends itself to superheating. Under these conditions, a heated liquid may show boiling delay and the temperature may go somewhat above the boiling point without boiling.\nHomogeneous nucleation, where the bubbles form from the surrounding liquid instead of on a surface, can occur if the liquid is warmer in its center, and cooler at the surfaces of the container. This can be done, for instance, in a microwave oven, which heats the water and not the container.\nCritical heat flux.\nCritical heat flux (CHF) describes the thermal limit of a phenomenon where a phase change occurs during heating (such as bubbles forming on a metal surface used to heat water), which suddenly decreases the efficiency of heat transfer, thus causing localised overheating of the heating surface. As the boiling surface is heated above a critical temperature, a film of vapour forms on the surface. Since this vapour film is much less capable of carrying heat away from the surface, the temperature rises very rapidly beyond this point into the transition boiling regime. The point at which this occurs is dependent on the characteristics of boiling fluid and the heating surface in question.\nTransition.\nTransition boiling may be defined as the unstable boiling, which occurs at surface temperatures between the maximum attainable in nucleate and the minimum attainable in film boiling.\nThe formation of bubbles in a heated liquid is a complex physical process which often involves cavitation and acoustic effects, such as the broad-spectrum hiss one hears in a kettle not yet heated to the point where bubbles boil to the surface.\nFilm.\nIf a surface heating the liquid is significantly hotter than the liquid then film boiling will occur, where a thin layer of vapour, which has low thermal conductivity, insulates the surface. This condition of a vapour film insulating the surface from the liquid characterises \"film boiling\".\nInfluence of geometry.\nPool boiling.\n\"Pool boiling\" refers to boiling where there is no forced convective flow. Instead, the flow occurs due to density gradients. It can experience any of the regimes mentioned above.\nFlow boiling.\n\"Flow boiling\" occurs when the boiling fluid circulates, typically through pipes. Its movement can be powered by pumps, such as in power plants, or by density gradients, such as in a thermosiphon or a heat pipe. Flows in flow boiling are often characterised by a void fraction parameter, which indicates the fraction of the volume in the system that is vapor. One can use this fraction and the densities to calculate the vapor quality, which refers to the mass fraction that is in the gas phase. Flow boiling can be very complex, with heavy influences of density, flow rates, and heat flux, as well as surface tension. The same system may have regions that are liquid, gas, and two-phase flow. Such two phase regimes can lead to some of the best heat transfer coefficients of any system.\nConfined boiling.\nConfined boiling refers to boiling in confined geometries, typically characterized by a Bond number that compares the gap spacing to the capillary length. Confined boiling regimes begin to play a major role when Bo &lt; 0.5. This boiling regime is dominated by \"vapour stem bubbles\" left behind after vapour departs. These bubbles act as seeds for vapor growth. Confined boiling typically has higher heat transfer coefficient but a lower CHF than pool boiling. CHF occurs when the vapor momentum force at the two-phase interface balances the combined surface tension and hydrostatic forces, leading to irreversible growth of the dry spot. Confined boiling is particularly promising for electronics cooling.\nPhysics.\nThe boiling point of an element at a given pressure is a characteristic attribute of the element. This is also true for many simple compounds including water and simple alcohols. Once boiling has started and provided that boiling remains stable and the pressure is constant, the temperature of the boiling liquid remains constant. This attribute led to the adoption of boiling points as the definition of 100\u00a0\u00b0C.\nDistillation.\nMixtures of volatile liquids have a boiling point specific to that mixture producing vapour with a constant mix of components - the constant boiling mixture. This attribute allows mixtures of liquids to be separated or partly separated by boiling and is best known as a means of separating ethanol from water.\nUses.\nRefrigeration and air conditioning.\nMost types of refrigeration and some type of air-conditioning work by compressing a gas so that it becomes liquid and then allowing it to boil. This adsorbs heat from the surroundings cooling the fridge or freezer or cooling the air entering a building. Typical liquids include propane, ammonia, carbon dioxide or nitrogen.\nFor making water potable.\nAs a method of disinfecting water, bringing it to its boiling point at , is the oldest and most effective way since it does not affect the taste, it is effective despite contaminants or particles present in it, and is a single step process which eliminates most microbes responsible for causing intestine related diseases. The boiling point of water is at sea level and at normal barometric pressure. In places having a proper water purification system, it is recommended only as an emergency treatment method or for obtaining potable water in the wilderness or in rural areas, as it cannot remove chemical toxins or impurities.\nThe elimination of micro-organisms by boiling follows first-order kinetics\u2014at high temperatures, it is achieved in less time and at lower temperatures, in more time. The heat sensitivity of micro-organisms varies, at , \"Giardia\" species (which cause giardiasis) can take ten minutes for complete inactivation, most intestine affecting microbes and \"E.\u00a0coli\" (gastroenteritis) take less than a minute; at boiling point, \"Vibrio cholerae\" (cholera) takes ten seconds and hepatitis A virus (causes the symptom of jaundice), one minute. Boiling does not ensure the elimination of all micro-organisms; the bacterial spores \"Clostridium\" can survive at but are not water-borne or intestine affecting. Thus for human health, complete sterilization of water is not required.\nThe traditional advice of boiling water for ten minutes is mainly for additional safety, since microbes start getting eliminated at temperatures greater than and bringing it to its boiling point is also a useful indication that can be seen without the help of a thermometer, and by this time, the water is disinfected. Though the boiling point decreases with increasing altitude, it is not enough to affect the disinfecting process.\nIn cooking.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nBoiling is the method of cooking food in boiling water or other water-based liquids such as stock or milk. Simmering is gentle boiling, while in poaching the cooking liquid moves but scarcely bubbles.\nThe boiling point of water is typically considered to be , especially at sea level. Pressure and a change in the composition of the liquid may alter the boiling point of the liquid. High elevation cooking generally takes longer since boiling point is a function of atmospheric pressure. At an elevation of about , water boils at approximately . Depending on the type of food and the elevation, the boiling water may not be hot enough to cook the food properly. Similarly, increasing the pressure as in a pressure cooker raises the temperature of the contents above the open air boiling point.\nBoil-in-the-bag.\nAlso known as \"boil-in-bag\", this involves heating or cooking ready-made foods sealed in a thick plastic bag. The bag containing the food, often frozen, is submerged in boiling water for a prescribed time. The resulting dishes can be prepared with greater convenience as no pots or pans are dirtied in the process. Such meals are available for camping as well as home dining.\nContrast with evaporation.\nAt any given temperature, the molecules in a liquid have varying kinetic energies. Some high energy particles on the liquid surface may have enough energy to escape the intermolecular forces of attraction of the liquid and become a gas. This is called evaporation.\nEvaporation only happens on the surface while boiling happens throughout the liquid.\nWhen a liquid reaches its boiling point bubbles of gas form in it which rise into the surface and burst into the air. This process is called boiling. If the boiling liquid is heated more strongly the temperature does not rise but the liquid boils more actively.\nThis distinction is exclusive to the liquid-to-gas transition; any transition directly from solid to gas is always referred to as sublimation regardless of whether it is at its boiling point or not.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52638", "revid": "671411", "url": "https://en.wikipedia.org/wiki?curid=52638", "title": "Altria", "text": "American tobacco corporation\nAltria Group, Inc. (previously known as Philip Morris Companies, Inc. until 2003) is an American corporation and one of the world's largest producers and marketers of tobacco, cigarettes, and medical products in the treatment of illnesses caused by tobacco. It operates worldwide and is headquartered in the city of Richmond, Virginia.\nAltria is the parent company of Philip Morris USA, John Middleton, Inc., U.S. Smokeless Tobacco Company, Inc., Philip Morris Capital Corporation, and NJOY Holdings, Inc. Altria also maintains large minority stakes in Belgium-based brewer AB InBev and the Canadian cannabis company Cronos Group. It is a component of the S&amp;P 500 and was a component of the Dow Jones Industrial Average from 1985 to 2008, dropping due to spin-offs of Kraft Foods Inc. in 2007 and Philip Morris International in 2008.\nHistory.\nAltria emerged from Philip Morris USA. The onset of \"rebranding\" of Philip Morris Companies to Altria took place in 2003 (Philip Morris would later split, with Philip Morris USA remaining Altria's primary and only consistently held asset). According to Altria, it was created because Philip Morris wished to emphasize that its business portfolio had come to consist of more than Philip Morris USA and Philip Morris International; at the time, it owned an 84% stake in Kraft Foods, although that business has since been spun off. The name \"Altria\" is claimed to come from the Latin word for \"high\" and was part of a trend of companies rebranding to names that previously did not exist, Accenture (previously Andersen Consulting) and Verizon being notable examples, though linguist Steven Pinker suggests that in fact the name is an \"egregious example\" of phonesthesia\u2014with the company attempting to \"switch its image from bad people who sell addictive carcinogens to a place or state marked by altruism and other lofty values\".\nThe company's branding consultants, the Wirthlin Group, said: \"The name change alternative offers the possibility of masking the negatives associated with the tobacco business\", thus enabling the company to improve its image and raise its profile without sacrificing tobacco profits. Philip Morris executives thought a name change would insulate the larger corporation and its other operating companies from the political pressures on tobacco.\nThe rebranding took place amidst social, legal, and financially troubled circumstances. In 2003 Altria was ranked \"Fortune\" number 11, and has steadily declined since. In 2010 Altria Group (MO) ranked at \"Fortune\" number 137, whereas its former asset, Philip Morris International, was ranked 94th.\nIn 2006, a United States court found that Philip Morris \"publicly ... disputed scientific findings linking smoking and disease knowing their assertions were false.\" In a 2006 ruling, a federal court found that Altria, along with R. J. Reynolds, Lorillard and Philip Morris were found guilty of misleading the public about the dangers of smoking. Within this ruling, it was noted that \"defendants altered the chemical form of nicotine delivered in mainstream cigarette smoke for the purpose of improving nicotine transfer efficiency and increasing the speed with which nicotine is absorbed by smokers.\" This was done by manipulating smoke pH with ammonia. Adding ammonia increases the smoke pH, in a process called \"freebasing\" which causes smokers to be \"exposed to higher internal nicotine doses and become more addicted to the product.\"\nOn March 30, 2007, Altria's 88.1% stake in Kraft Foods was spun off, through a distribution of the remaining stake of shares (88.1%) to Altria shareholders. That same year, Altria began selling all its shares of Philip Morris International to Altria stockholders, a spin-off that was completed on March 28, 2008. Again in 2007 the company began the acquisition of cigar manufacturer John Middleton Co. from Bradford Holdings, which was complete in 2008. After Philip Morris International spun off, the former international subsidiaries halted the purchase of tobacco from America, which was a major factor in the closing of a newly renovated plant in North Carolina, an approximately 50% reduction in manufacturing, large-scale layoffs, and induced early retirements.\nIn 2008, Altria officially moved its headquarters from New York City to Richmond, Virginia, after Philip Morris sold its downtown offices in New York City a decade earlier. With a few exceptions, all manufacturing, commercial, and executive employees had long been based in and around Richmond. The company is now headquartered in an unincorporated area within Henrico County, less than west of the city limits of Richmond and less than from its downtown Richmond campus.\nAside from the Philip Morris/Altria headquarters, some of their other buildings included the Altria Center for Research and Technology in downtown Richmond, their manufacturing center in South Richmond, and the adjacent operations center which began shutting down in 2007\u20132008, as a result of the loss of demand from Philip Morris International member companies. The layoffs beginning in 2007 affected thousands of Altria, Altria Client Services, Philip Morris USA, and contracted employees in Richmond and North Carolina.\nIn 2009, Altria finalized its purchase of UST Inc., whose products included smokeless tobacco (made by U.S. Smokeless Tobacco Company) and wine (made by Chateau Ste. Michelle). This ended a short era of competition between the new Marlboro smokeless tobacco products such as snus, and those produced by UST Inc.\nOn December 8, 2018, Altria announced its intent to acquire a 45% stake in Cronos Group for $1.8 billion.\nOn December 20, 2018, Altria finalized the acquisition of a 35% stake in JUUL Labs, an e-cigarette company based out of San Francisco, California, for $12.8 billion. On November 3, 2019, it was reported that Altria was taking a $4.5 billion writedown on its stake in Juul, 35% of its original value. On July 28, 2022, it was reported that Altria's investment in Juul is now worth only 5% of the original amount of $12.8 billion. Despite the losses, Altria has announced that it will continue to support Juul and avoid investing in competing products.\nAltria is taking a stake in the global business of Swiss tobacco company Burger S\u00f6hne (Helix Innovations with the On! brand) for $372 million in June 2019.\nAltria and Japan Tobacco announced a joint venture called Horizon Innovations LLC on October 27, 2022. Horizon, owned 75 percent by Altria and 25 percent by Japan Tobacco, intends to sell Ploom heated tobacco sticks in the United States. FDA approval was expected to take until 2025, with customers able to buy Ploom by 2027.\nAltria completed the acquisition of NJOY Holdings, Inc. on June 1, 2023.\nFinances.\nAltria and its predecessors is one of the best-performing publicly traded companies of the 20th century.\nFor the fiscal year 2020, Altria reported earnings of US$4.45 billion, with an annual revenue of US$26.15 billion. Altria's shares traded at over $66 per share, and its market capitalization was valued at over US$118.5 billion in October 2018. As of 2018, the company ranked 154th on the Fortune 500 list of the largest United States corporations by revenue.\nCorporate governance.\nBoard of directors.\nMembers of the board of directors of Altria Group as of February 2013 were:\nHeadquarters.\nPrior to being based in Virginia, Philip Morris had its headquarters in Midtown Manhattan, New York City. In 2003, Philip Morris announced that it would move its headquarters to Virginia. The company said that it planned to keep around 750 employees in its former headquarters. Brendan McCormick, a spokesperson for Philip Morris, said that the company estimated that the move would save the company over $60 million each year. The company now has its head offices in an unincorporated area of Henrico County, Virginia, near Richmond. In addition, the company has a 450,000-square-foot, $350 million Center for Research and Technology located in downtown Richmond at the Virginia BioTechnology Research Park that employs approximately 600 scientists, engineers and support staff.\nDiversification.\nAltria, like other tobacco companies, has invested in science and medical companies which develop and produce medical products for conditions caused or aggravated by smoking. As of 2024, Altria's three medical subsidiaries included the following: Cronos group (maker of recreational cannabis), Lexaria Bioscience (Developer of proprietary drug delivery technology, DehydraTECH, to improve active pharmaceutical ingredients entrance into the bloodstream) and Micreos (biotech company focused on discovering and developing recombinant proteins for chronic dermatology and oncology conditions).\nIt has also designed and marketed electronic cigarettes. Altria launched the MarkTen and Green Smoke brands. Both of these were discontinued in December 2018. The company returned to this market through the acquisition of NJOY.\nPolitical influence.\nAccording to the Center for Public Integrity, Altria spent around $101 million on lobbying the United States government between 1998 and 2004, the second-highest such figure for any organization in the nation.\nAltria also funded The Advancement of Sound Science Coalition which lobbied against the scientific consensus on anthropogenic climate change.\nDaniel Smith, representing Altria, sits on the Private Enterprise Board of the American Legislative Exchange Council.\nIn 2025, Altria was one of the donors funding the White House's East Wing demolition, and planned building of a ballroom.\nControversies.\nIn August 2006, the Altria group was found guilty of civil fraud and racketeering. The lawsuit claimed that Altria's marketing of \"light\" and \"low tar\" cigarettes constituted fraudulent misrepresentations under the Maine Unfair Trade Practices Act (MUTPA) because it deceived smokers into thinking the products are safer than regular cigarettes.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52639", "revid": "57465403", "url": "https://en.wikipedia.org/wiki?curid=52639", "title": "Tobacco company", "text": ""}
{"id": "52640", "revid": "42401395", "url": "https://en.wikipedia.org/wiki?curid=52640", "title": "Cigarettes", "text": ""}
{"id": "52641", "revid": "45215721", "url": "https://en.wikipedia.org/wiki?curid=52641", "title": "William McMahon", "text": "Prime Minister of Australia from 1971 to 1972\nSir William McMahon (23 February 1908\u00a0\u2013 31 March 1988) was an Australian politician who served as the 20th prime minister of Australia from 1971 to 1972. He held office as the leader of the Liberal Party of Australia, and previously held various ministerial positions from 1951 to 1971, the longest continuous service in Australian history.\nMcMahon was born and raised in Sydney, and worked as a commercial lawyer before entering politics. He served in the Australian Army during World War II, reaching the rank of major. After the war's end he returned to university to complete an economics degree. McMahon was elected to the House of Representatives at the 1949 federal election. Robert Menzies promoted him to the ministry in 1951 and added him to cabinet in 1956. He held several different portfolios in the Menzies government, most notably as Minister for Labour and National Service from 1958 to 1966. In that capacity, he oversaw the reintroduction of conscription in 1964.\nIn 1966, Menzies retired and was replaced as prime minister by Harold Holt. McMahon then succeeded Holt as deputy leader of the Liberal Party. He was appointed Treasurer in the Holt government, and over the following three years oversaw a large reduction in the national deficit. After Holt's death in 1967, McMahon would have normally been the frontrunner to succeed Holt as Liberal leader and hence Prime Minister. However, he had his candidacy vetoed by John McEwen, the leader of the Liberals' junior partner, the Country Party. The new prime minister was John Gorton. McMahon initially continued on as Treasurer in the Gorton government, but in 1969 was demoted to Minister for External Affairs after an unsuccessful challenge for the leadership. He eventually replaced Gorton in March 1971 following Gorton\u2019s resignation, winning a vote against Billy Snedden.\nMcMahon became prime minister at the age of 63, and remains the oldest non-interim prime minister to take office. His government has been described by the \"Australian Dictionary of Biography\" as \"a blend of cautious innovation and fundamental orthodoxy\". It continued many of the policies of its immediate predecessors, such as the phased withdrawal of Australian troops from Vietnam. In its final year it faced high inflation and unemployment. Gough Whitlam's Labor Party defeated McMahon at the 1972 federal election, ending 23 consecutive years of Coalition rule. No other Australian prime minister has served for longer without winning a general election. He resigned the Liberal leadership, but remained in parliament until 1982 as a backbencher.\nMcMahon has been described as one of Australia's worst prime ministers by Australian political scientists and historians, and after leaving office several of his former colleagues openly criticised his leadership style and personal character. Whitlam, his successor, acknowledged him as \"an extraordinarily skilful, resourceful and tenacious politician\", and credited him with having prevented a larger margin of defeat in 1972.\nEarly life.\nBirth and family background.\nMcMahon was born in Redfern, Sydney, New South Wales, on 23 February 1908. He was the third of five children born to solicitor William Daniel McMahon and Mary (n\u00e9e Walder), daughter of a sailmaker; an older brother predeceased him. His father, a Catholic, had a reputation as a heavy drinker and habitual gambler; his mother, an Anglican, was of Irish and English descent.\nMcMahon's paternal grandfather, James \"Butty\" McMahon, was born in County Clare, Munster, Ireland, and married Mary Coyle of County Fermanagh, Ulster, Ireland. He arrived in Australia as a child, and eventually founded his own freight company, which became one of the largest in Sydney. Upon his death in 1914, his estate was valued at almost \u00a3240,000, an immense sum at the time.\nChildhood and education.\nMcMahon spent his early life in Redfern. His mother died in 1917, when he was nine years old, and he was subsequently raised by her relatives. He moved home frequently as he was shifted between family members, living for periods in Kensington, Beecroft, Gordon, and Centennial Park. McMahon saw little of his father or his siblings, who were raised separately; his older brother James died of Spanish flu in 1919. His uncle Samuel Walder \u2013 a businessman who was Lord Mayor of Sydney in 1932 \u2013 acted as a sort of surrogate father. McMahon began his education at Abbotsholme College, a short-lived private school in Killara. One of his schoolmates there was Harold Holt, another future prime minister. He was later sent to Sydney Grammar School, where he was an above-average student without excelling academically.\nMcMahon's father died in 1926, when his son was 18 years old, leaving him a substantial inheritance. He had failed the leaving certificate at Sydney Grammar, but by his passing a matriculation exam was able to enter the University of Sydney in 1927. At the insistence of Walder, he chose to study law, graduating with a Bachelor of Laws in 1930. McMahon, who lived at St Paul's College, was more interested in the social scene than his degree. He spent his inheritance freely, owning several racehorses, and was known for betting significant amounts on the races. According to Alan Reid, \"his reputation was that he completed his university career on less actual work than anyone in the college\".\nDespite his diminutive physique \u2013 he stood as an adult \u2013 McMahon did achieve some success as an athlete. He won his university's lightweight boxing title, and in his final year at Sydney Grammar rowed in the Head of the River race.\nLegal career and military service.\nAccording to Don Whitington, McMahon's life before entering politics was \"the aimless, indolent existence of a wealthy young man with a position in a big city's smart set, no positive ambition or even interests, except in enjoying himself, and no family ties to give him a feeling of responsibility or even consideration for others\". After graduating from university, he secured a position as a solicitor with Allen, Allen &amp; Hemsley, a major Sydney law firm; he was made a junior partner in 1939. He was assigned to the Commonwealth Bank and the Bank of New South Wales for periods, which helped spark his interest in economics. McMahon had hoped to practise as a barrister, but his partial deafness made this impractical. His hearing remained an issue throughout his life, making parliamentary debates hard to follow, but did improve somewhat through surgery and the use of hearing aids.\nIn April 1940, McMahon was commissioned as a lieutenant in the Citizens Military Force. He transferred to the Australian Imperial Force (the regular army) in October 1940, and was promoted to captain in 1942 and to major in 1943. McMahon was turned down for overseas service due to his hearing loss and a knee injury. In the early part of the war he was attached to coastal defence units in Sydney. He later served on the headquarters staff of the II Corps (1942\u20131943) and the Second Army (1943\u20131945). He was formally discharged in October 1945.\nAfter leaving the military, McMahon travelled overseas for 18 months, visiting Europe and North America. His experience of post-war Europe was said to have been one of the primary influences on his subsequent decision to enter politics. In 1947, McMahon returned to the University of Sydney to study economics and public administration. He graduated with a Bachelor of Economics degree in 1948, completing the course two years early due to his previous studies. He topped his economics class and won two prizes for proficiency in his final year.\nPolitics.\nMenzies government.\nMcMahon was elected to the House of Representatives at the 1949 federal election, winning the newly created Division of Lowe for the Liberal Party. His candidacy was endorsed by Billy Hughes, who had known his grandfather. McMahon soon developed a reputation as \"a deadly earnest, dogged, enormously hardworking and dedicated member\". In 1950, he successfully proposed an amendment to the Menzies government's Communist Party Dissolution Bill, reversing the effect of a clause so that the burden of proof was on the government rather than an accused person. However, the bill was subsequently struck down by the High Court. In July 1951, McMahon replaced Philip McBride as Minister for the Navy and Minister for Air. He subsequently approved and oversaw Donald Hardman's proposal to reorganise the Royal Australian Air Force (RAAF) along functional command lines (rather than the previous area command system).\nAfter the 1954 election, McMahon was appointed Minister for Social Services in place of Athol Townley. In January 1956, he was instead made Minister for Primary Industry, an appointment that was seen as a surprise given his lack of experience in agriculture. He effectively became the junior minister to John McEwen, the deputy leader of the Country Party and Minister for Trade. It was hoped by the Country Party (and tacitly accepted by Menzies) that McMahon would simply be a proxy for McEwen on policy matters. However, he managed to preserve the influence and independence of his department, and in fact made a number of cabinet submissions that were contrary to McEwen's wishes. This impressed his colleagues in the Liberal Party, but laid the foundations for the poor relations with the Country Party that would prove challenging later in his career.\nMcMahon was promoted to Minister for Labour and National Service after the 1958 election, in place of Harold Holt. This brought him firmly into the inner ranks of the Liberal Party, and in terms of cabinet rank placed him among the party's most senior figures in New South Wales. McMahon oversaw the creation and administration of what became the \"National Service Act 1964\", which re-introduced compulsory conscription for 20-year-old males in anticipation of further Australian involvement in South-East Asia. On the labour side of his portfolio, he frequently came into conflict with the leadership of the Australian Council of Trade Unions (ACTU), though there was no major industrial action during his tenure. He attempted to reduce the influence of trade unions known to be controlled by the Communist Party, particularly the Waterside Workers' Federation. In 1964, McMahon was made Vice-President of the Executive Council, further confirming his status within the government.\nHolt government: treasurer and deputy leader.\nIn January 1966, following Menzies' retirement, Harold Holt was elected unopposed as Liberal leader and prime minister. McMahon narrowly defeated external affairs minister Paul Hasluck to replace Holt as deputy leader, following multiple ballots.\nMcMahon was appointed federal treasurer in Holt's new ministry, a position he had long sought. He was the first person with an economics degree to hold the post. McMahon proclaimed a \"very deep liking and respect\" for the Department of the Treasury and upheld its advice in policy battles with McEwen's Department of Trade and Industry. According to Alan Reid, he \"fought relentlessly to maintain Treasury's influence, prestige and power\". Although he consulted widely within his department, he also had a reputation for indecisiveness and deferring difficult decisions. the early retirement of long-serving Treasury secretary Roland Wilson in October 1966 was credited in part to his dislike of McMahon.\nAs treasurer, McMahon oversaw the implementation of Australia's conversion to decimal currency (a decision of the previous government), with the Australian dollar introduced in February 1966 in place of the Australian pound. A year later he announced that the transition had cost half as much as estimated and that the period of dual currencies would be shortened, with the dollar being the only legal tender from August 1967. In November 1967, McMahon secured cabinet approval for Australia to leave the sterling area, by refusing to match the British government's devaluation of the pound sterling. The decision brought him into renewed conflict with McEwen, who had been out of the country when it was taken and sought to secure it reversal. There was further conflict over McEwen's proposal for a government-owned Australian Industry Development Corporation, which McMahon and Treasury sought to counter with a proposal for a privately owned Australian Resources Development Bank.\nGorton government: treasurer and foreign minister.\nWhen Holt disappeared in December 1967, McMahon was assumed to be his probable successor. However, John McEwen, interim Prime Minister and leader of the Country Party, announced that he and his party would not serve in a government led by McMahon. McEwen did not state his reasons publicly, but privately he told McMahon he did not trust him. McEwen, an arch-protectionist, correctly suspected that McMahon favoured policies of free trade and deregulation.\nMcMahon therefore withdrew, and Senator John Gorton won the subsequent party room ballot for party leader and therefore Prime Minister. McMahon remained Treasurer and waited for his chance at a comeback. The Coalition was nearly defeated at the 1969 federal election. After the election, McMahon unsuccessfully challenged for the leadership, but was nonetheless re-elected as deputy leader. He was subsequently demoted from Treasurer to Minister for External Affairs. John McEwen had announced in the lead-up to the spill that he would lift his party's veto on McMahon as prime minister.\nIn March 1971, the Defence Minister, Malcolm Fraser, resigned from Cabinet and denounced Gorton, who then announced a leadership spill. The ensuing party room vote was tied, and under the party rules of the time this meant the motion was lost and Gorton could have theoretically remained as leader and Prime Minister. Nevertheless, Gorton declared that a tie vote meant he no longer had the confidence of the party, and voluntarily resigned the leadership. McMahon was then elected leader (and thus prime minister), and Gorton was elected deputy leader.\nPrime Minister (1971\u20131972).\nMcMahon came into office at a bad time for the Coalition, which was increasingly seen as tired and unfocused after more than 21 years in power. His first problem was Gorton. Since Gorton had been elected as Liberal deputy leader, McMahon was all but forced to name him Defence Minister. This farcical situation came to a head when Gorton published two articles detailing the problems he had with ministers leaking information from cabinet. McMahon forced Gorton's resignation. Billy Snedden was chosen as the new deputy Liberal leader.\nMcMahon found himself dealing with a resurgent Labor Party under Gough Whitlam. Labor had come within four seats of winning government in 1969, and since then had positioned itself as a credible government-in-waiting. Over the next year-and-a-half, McMahon was unable to get the better of Whitlam. McMahon was no match in parliamentary debates for Whitlam, a witty and powerful orator. He frequently found himself on the defensive as Whitlam attacked the increasingly unpopular Vietnam War and advocated radical new policies such as universal health insurance. In a typical instance, McMahon attacked Whitlam for his demands that Australia recognise the People's Republic of China, only to have to back down when U.S President Richard Nixon announced his visit to China. He was not helped by rising inflation, which hurt his reputation as a sound economic manager. Additionally, the Liberal Party was showing severe schisms, which came at an especially bad time since McMahon had, at most, two years before the next election. His voice and appearance also came across badly on television.\nIn June 1971, McMahon cancelled Gorton's planned nuclear power program, which had included a reactor capable of generating weapons-grade plutonium. He considered it inconsistent with the goals of the Nuclear Non-Proliferation Treaty, signed under Gorton in 1970 and ratified under Whitlam in 1973.\nMcMahon went into 1972 facing a statutory general election. By then, Labor had established a clear lead in the polls and McMahon's approval ratings had dwindled to 28 percent. The press had turned on him so violently that the British psephologist David Butler recalled on a visit to Australia that he could not recall a prime minister in any country being \"so comprehensively panned\" as McMahon. By then, it was widely perceived that McMahon simply \"did not look or sound like a Prime Minister\". He waited for as long as he could, but finally called a federal election for 2 December. During the campaign, McMahon was abandoned by some of his own ministers, unheard of in a Westminster system. The Coalition was swept from power on an eight-seat swing. Late on election night, with the result beyond doubt, McMahon conceded defeat, ending the longest unbroken run in government in Australian history.\nMcMahon had been a minister continuously for 21 years and 6 months, a record in the Australian Government that has never been threatened. Only Sir George Pearce and Sir John McEwen had longer overall ministerial service, but their terms were not continuous.\nLater parliamentary career (1972\u20131982).\nMcMahon's term as prime minister ended on 5 December 1972. He did not immediately resign as Liberal leader, but it soon became clear that there was no support for him to continue.\nMcMahon became the first Prime Minister to have lost an election and retained his seat who did not then serve as Leader of the Opposition.\nOn 20 December, the Liberal Party elected Billy Snedden as his successor. As a mark of respect for his past service, McMahon was included in Snedden's new shadow cabinet (as was John Gorton). However, at his own request he was not allocated a specific portfolio. In an interview with HSV7 in June 1973, McMahon stated that \"disloyalty within our own party\" was the main reason the Liberals had lost the election. He also said that he had three regrets from his time as prime minister \u2013 that he failed to abolish national service, that he had mishandled the 1971 budget, and that he had been a poor communicator.\nAfter the 1974 election, McMahon returned to the backbench for the first time since 1951. In the lead-up to the dismissal of the Whitlam government in 1975, he strongly defended the power of the Senate to block supply. However, he believed that Governor-General John Kerr had acted unconstitutionally in dismissing the prime minister, and said that he would have challenged the decision in the High Court if he had been in Whitlam's position. McMahon believed that those responsible for the \"loans affair\" \u2013 including Whitlam and several of his ministers \u2013 had acted illegally and should be prosecuted for their involvement. He assisted Danny Sankey (a private citizen) in bringing a private prosecution against Whitlam, which eventually came before the High Court as \"Sankey v Whitlam\". Malcolm Fraser had promised Kerr that his government would bring no action against its predecessor, and was frustrated by McMahon's actions. In his memoirs, he said: \"I knew McMahon was running around up to his tricks ... I couldn't control what he did, but I could make damn sure that the government, my government, did not get involved\".\nPrior to the 1977 election, McMahon was unsuccessfully challenged for Liberal preselection by John Abel, whose Division of Evans had been abolished in an electoral redistribution. After being re-elected, he became the joint Father of the House of Representatives with Clyde Cameron. He was the sole Father of the House after the 1980 election, winning election for a fourteenth and final time at the age of 72. In his final years in parliament he was often critical of the Fraser government. McMahon left parliament after 32 years in January 1982, citing dissatisfaction with the 1981 budget as a major factor in his decision to retire before a general election. He nominated future prime minister Malcolm Turnbull as his preferred successor in Lowe, but the Liberal Party chose another candidate Philip Taylor. The by-election was won by the Labor Party on a 9.4-point swing.\nHe was the last former Prime Minister to be reelected to Parliament until Kevin Rudd in 2010.\nFinal years and death.\nIn retirement, McMahon devoted much of his time to working on his memoirs, which he planned to title \"A Liberal View\". They were rejected by six publishers, and reviewers (who included Barry Jones and Phillip Adams) considered them to be poorly written and overly detailed. In 1984, McMahon endorsed Bob Hawke and the Labor Party for re-election over the Coalition, which he said would not be ready for government for another four or five years. Later that year, he described Andrew Peacock's hold on the Liberal leadership as \"very, very fragile\", and tacitly endorsed John Howard as a future leader.\nIn his final years, McMahon underwent a series of operations related to skin cancer. He died aged 80 in his sleep at St Luke's Private Hospital, Potts Point, on the morning of 31 March 1988. His remains were cremated at the Northern Suburbs Crematorium. A state memorial service was held at St Andrew's Cathedral, Sydney, on 8 April, with the eulogy given by David Fairbairn.\nPersonal life.\nIn 1965, aged 57, McMahon married Sonia Rachel Hopkins, who was then aged 32. McMahon had proposed six months after the pair first met. The wedding was held three months later at St Mark's Church, Darling Point, followed by a reception for 400 people at the Royal Sydney Golf Club. She survived him by more than twenty years, dying on 2 April 2010, aged 77. The couple had three children, one of whom was the actor Julian McMahon.\nThere were frequent rumours throughout his life that McMahon was homosexual. The suggestion was repeatedly denied by Lady McMahon. On one occasion in the 1970s, that resulted in an infamous headline in the defunct Melbourne tabloid, \"Sunday Observer\": \"My Billy's No Poofter \u2013 Sonia Tells\".\nIn the 1972 election, David Widdup, a pioneer of LGBTQ+ rights in Australia, ran as a candidate against McMahon in the seat of Lowe, making history as Australia\u2019s first openly gay candidate for public office. His campaign slogan, \u201cI\u2019ve got my eyes on Billy\u2019s seat!\u201d, garnered significant media attention, particularly given the rumours about McMahon\u2019s sexuality.\nReligion.\nMcMahon was an Anglican, although he did not have a strong religious upbringing. His father was a lapsed Catholic and self-described \"rationalist\", while his mother's family were Anglican. McMahon developed an interest in theology as a teenager, and read widely on the subject over the rest of his life. He cited the works of William Temple as a major influence. McMahon was one of the few contemporary politicians to speak publicly on the connection between their religious and political beliefs. In 1953, he gave an address to the Australian Institute of Political Science in which he explained how he believed Christian doctrines necessitated parliamentary democracy and a market economy.\nEvaluation.\nMcMahon is often ranked among Australia's worst prime ministers. In 2001, five out of six historians surveyed by \"Australian Financial Review\" ranked him among their worst five prime ministers. Similarly, \"The Age\" surveyed eight historians in 2004 and all but one ranked McMahon as Australia's worst prime minister since World War II. Some of McMahon's most prominent critics have been those who served with him in cabinet. John Gorton called him \"utterly untrustworthy\", while Doug Anthony said he was \"just not big enough for the job\". Malcolm Fraser said he \"had an insatiable ambition [...] he wasn't immoral, he was totally amoral\". Billy Snedden considered McMahon \"conspiratorial, devious, untrustworthy\", and Paul Hasluck viewed him as \"disloyal, devious, dishonest, untrustworthy, petty, cowardly\", in his diaries referring to him as \"that treacherous bastard\".\nMcMahon was nicknamed \"Billy the Leak\" for his willingness to divulge intimate and confidential information to the media. Despite this, he was disliked by many journalists and political commentators. Donald Horne called him \"perhaps the silliest prime minister we ever had\", and Peter Ryan said that \"McMahon's way of politics was one of lying and leaking, conniving and conspiring, deceit and double-crossing\". Malcolm Mackerras thought that he had \"no achievements beyond actually getting the top job\". Political journalist Laurie Oakes described McMahon as \"devious, nasty, dishonest - he lied all the time and stole things\" before describing an incident where McMahon attempted to steal a tape recorder from his radio station by claiming ownership of the device despite it having the radio station's name engraved on it. He concludes by saying that McMahon was a \"totally unworthy individual and the fact that he was Prime Minister of this country was a disgrace\".\nSome writers have defended McMahon's reputation, arguing that he was a skilled politician who has been unfairly scapegoated for an almost inevitable election loss. According to John Hawkins, McMahon was \"grudgingly admired for his energy and diligence\", and generally acknowledged as having a mastery of economic policy. Mungo MacCallum, while noting that he left no lasting achievements, called his prime ministership a \"brief but cheerful interlude\" and praised him for leaving office with good grace. Marian Simms compared McMahon to Richard Nixon, suggesting that his character traits have been overemphasised, while Troy Bramston viewed him as \"a prime minister who clearly understood the challenge of the times and was fighting to get his ship back on course\" when he was forced out of office. Andrew Peacock, who served in McMahon's ministry, said that McMahon was \"much better than he has been painted... He is somewhat ill-treated by history\", and described him as \"difficult, irascible, nervous yet capable\". In his memoirs, Gough Whitlam wrote that McMahon was \"an extraordinarily skilful, resourceful and tenacious politician ... had he been otherwise, the ALP victory in December 1972 would have been more convincing than it was\".\nHonours.\nMcMahon was appointed a Privy Counsellor in 1966, a Member of the Order of the Companions of Honour in the 1972 New Year Honours, and a Knight Grand Cross of the Order of St Michael and St George in the Queen's Birthday Honours of 1977.\nFollowing the 2009 redistribution of New South Wales federal electorates, the Division of Prospect was renamed the Division of McMahon starting at the 2010 federal election.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52642", "revid": "3125232", "url": "https://en.wikipedia.org/wiki?curid=52642", "title": "Van de Graaff generator", "text": "Electrostatic generator operating on the triboelectric effect\nA Van de Graaff generator is an electrostatic generator which uses a moving belt to accumulate electric charge on a hollow metal globe on the top of an insulated column, creating very high electric potentials. It produces very high voltage direct current (DC) electricity at low current levels. It was invented by American physicist Robert J. Van de Graaff in 1929.\nThe potential difference achieved by modern Van de Graaff generators can be as much as 5 megavolts. A tabletop version can produce on the order of 100\u00a0kV and can store enough energy to produce visible electric sparks. Small Van de Graaff machines are produced for entertainment, and for physics education to teach electrostatics; larger ones are displayed in some science museums.\nThe Van de Graaff generator was originally developed as a particle accelerator for physics research, as its high potential can be used to accelerate subatomic particles to great speeds in an evacuated tube. It was the most powerful type of accelerator until the cyclotron was developed in the early 1930s. Van de Graaff generators are still used as accelerators to generate energetic particle and X-ray beams for nuclear research and nuclear medicine.\nThe voltage produced by an open-air Van de Graaff machine is limited by arcing and corona discharge to about 5\u00a0MV. Most modern industrial machines are enclosed in a pressurized tank of insulating gas; these can achieve potentials as large as about 25\u00a0MV.\nHistory.\nBackground.\nThe concept of an electrostatic generator in which charge is mechanically transported in small amounts into the interior of a high-voltage electrode originated with the Kelvin water dropper, invented in 1867 by William Thomson (Lord Kelvin), in which charged drops of water fall into a bucket with the same polarity charge, adding to the charge.\nIn a machine of this type, the gravitational force moves the drops against the opposing electrostatic field of the bucket. Kelvin himself first suggested using a belt to carry the charge instead of water. The first electrostatic machine that used an endless belt to transport charge was constructed in 1872 by Augusto Righi. It used an india rubber belt with wire rings along its length as charge carriers, which passed into a spherical metal electrode. The charge was applied to the belt from the grounded lower roller by electrostatic induction using a charged plate. John Gray also invented a belt machine about 1890. Another more complicated belt machine was invented in 1903 by Juan Burboa. A more immediate inspiration for Van de Graaff was a generator W. F. G. Swann was developing in the 1920s in which charge was transported to an electrode by falling metal balls, thus returning to the principle of the Kelvin water dropper.\nInitial development.\nThe Van de Graaff generator was developed, starting in 1929, by physicist Robert J. Van de Graaff at Princeton University, with help from colleague Nicholas Burke. The first model was demonstrated in October 1929. The first machine used an ordinary tin can, a small motor, and a silk ribbon bought at a five-and-dime store. After that, he went to the chairman of the physics department requesting $100 to make an improved version. He did get the money, with some difficulty. By 1931, he could report achieving 1.5 million volts, saying \"The machine is simple, inexpensive, and portable. An ordinary lamp socket provides the only power needed.\" According to a patent application, it had two 60-cm-diameter charge-accumulation spheres mounted on borosilicate glass columns 180\u00a0cm high; the apparatus cost $90 in 1931.\nVan de Graaff applied for a second patent in December 1931, which was assigned to Massachusetts Institute of Technology in exchange for a share of net income; the patent was later granted.\nIn 1933, Van de Graaff built a 40\u00a0ft (12\u00a0m) model at MIT's Round Hill facility, the use of which was donated by Colonel Edward H. R. Green. One consequence of the location of this generator in an aircraft hangar was the \"pigeon effect\": arcing from accumulated droppings on the outer surface of the spheres.\nHigher energy machines.\nIn 1937, the Westinghouse Electric company built a machine, the Westinghouse Atom Smasher capable of generating 5\u00a0MeV in Forest Hills, Pennsylvania. It marked the beginning of nuclear research for civilian applications. It was decommissioned in 1958 and was partially demolished in 2015. (The enclosure was laid on its side for safety reasons.)\nA more recent development is the tandem Van de Graaff accelerator, containing one or more Van de Graaff generators, in which negatively charged ions are accelerated through one potential difference before being stripped of two or more electrons, inside a high-voltage terminal, and accelerated again. An example of a three-stage operation has been built in Oxford Nuclear Laboratory in 1964 of a 10\u00a0MV single-ended \"injector\" and a 6\u00a0MV EN tandem.\nBy the 1970s, as much as 14 MV could be achieved at the terminal of a tandem that used a tank of high-pressure sulfur hexafluoride (SF6) gas to prevent sparking by trapping electrons. This allowed the generation of heavy ion beams of several tens of MeV, sufficient to study light-ion direct nuclear reactions. The greatest potential sustained by a Van de Graaff accelerator is 25.5\u00a0MV, achieved by the tandem in the Holifield Radioactive Ion Beam Facility in Oak Ridge National Laboratory.\nA further development is the pelletron, where the rubber or fabric belt is replaced by a chain of short conductive rods connected by insulating links, and the air-ionizing electrodes are replaced by a grounded roller and inductive charging electrode. The chain can be operated at a much greater velocity than a belt, and both the voltage and currents attainable are much greater than with a conventional Van de Graaff generator. The 14\u00a0UD Heavy Ion Accelerator at the Australian National University houses a 15\u00a0MV pelletron. Its chains are more than 20\u00a0m long and can travel faster than .\nThe Nuclear Structure Facility (NSF) at Daresbury Laboratory was proposed in the 1970s, commissioned in 1981, and opened for experiments in 1983. It consisted of a tandem Van de Graaff generator operating routinely at 20 MV, housed in a distinctive building 70\u00a0m high. During its lifetime, it accelerated 80 different ion beams for experimental use, ranging from protons to uranium. A particular feature was the ability to accelerate rare isotopic and radioactive beams. Perhaps the most important discovery made using the NSF was that of super-deformed nuclei. These nuclei, when formed from the fusion of lighter elements, rotate very rapidly. The pattern of gamma rays emitted as they slow down provided detailed information about the inner structure of the nucleus. Following financial cutbacks, the NSF closed in 1993.\nDescription.\nA simple Van de Graaff generator consists of a belt of rubber (or a similar flexible dielectric material) moving over two rollers of differing material, one of which is surrounded by a hollow metal sphere. A comb-shaped metal electrode with sharp points (2 and 7 in the diagram), is positioned near each roller. The upper comb (2) is connected to the sphere, and the lower one (7) to ground. When a motor is used to drive the belt, the triboelectric effect causes the transfer of electrons from the dissimilar materials of the belt and the two rollers. In the example shown, the rubber of the belt will become negatively charged while the acrylic glass of the upper roller will become positively charged. The belt carries away negative charge on its inner surface while the upper roller accumulates positive charge.\nNext, the strong electric field surrounding the positive upper roller (3) induces a very high electric field near the points of the nearby comb (2). At the points of the comb, the field becomes strong enough to ionize air molecules. The electrons from the air molecules are attracted to the outside of the belt, while the positive ions go to the comb. At the comb they are neutralized by electrons from the metal, thus leaving the comb and the attached outer shell (1) with fewer net electrons and a net positive charge. By Gauss's law (as illustrated in the Faraday ice pail experiment), the excess positive charge is accumulated on the outer surface of the outer shell, leaving no electric field inside the shell. Continuing to drive the belt causes further electrostatic induction, which can build up large amounts of charge on the shell. Charge will continue to accumulate until the rate of charge leaving the sphere (through leakage and corona discharge) equals the rate at which new charge is being carried into the sphere by the belt. \nOutside the terminal sphere, a high electric field results from the high voltage on the sphere, which would prevent the addition of further charge from the outside. However, since electrically charged conductors do not have any electric field inside, charges can be added continuously from the inside without needing to overcome the full potential of the outer shell. \nThe larger the sphere and the farther it is from ground, the higher its peak potential. The sign of the charge (positive or negative) can be controlled by the selection of materials for the belt and rollers. Higher potentials on the sphere can also be achieved by using a voltage source to charge the belt directly, rather than relying solely on the triboelectric effect.\nA Van de Graaff generator terminal does not need to be sphere-shaped to work, and in fact, the optimum shape is a sphere with an inward curve around the hole where the belt enters. A rounded terminal minimizes the electric field around it, allowing greater potentials to be achieved without ionization of the air, or other dielectric gas, surrounding it. Since a Van de Graaff generator can supply the same small current at almost any level of electrical potential, it is an example of a nearly ideal current source.\nThe maximal achievable potential is roughly equal to the sphere radius \"R\" multiplied by the electric field \"E\"max at which corona discharges begin to form within the surrounding gas. For air at standard temperature and pressure (STP) the breakdown field is about . Therefore, a polished spherical electrode in diameter could be expected to develop a maximal voltage \"V\"max = \"R\"\u00b7\"E\"max of about . This explains why Van de Graaff generators are often made with the largest possible diameter.\nUse as a particle accelerator.\nThe initial motivation for the development of the Van de Graaff generator was as a source of high voltage to accelerate particles for nuclear physics experiments. The high potential difference between the surface of the terminal and ground results in a corresponding electric field. When an ion source is placed near the surface of the sphere (typically within the sphere itself) the field will accelerate charged particles of the appropriate sign away from the sphere. By insulating the generator with pressurized gas, the breakdown voltage can be raised, increasing the maximum energy of accelerated particles.\nTandem accelerators.\nParticle-beam Van de Graaff accelerators are often used in a \"tandem\" configuration with the high potential terminal located at the center of the machine. Negatively charged ions are injected at one end, where they are accelerated by attractive force toward the terminal. When the particles reach the terminal, they are stripped of some electrons to make them positively charged, and are subsequently accelerated by repulsive forces away from the terminal. This configuration results in two accelerations for the cost of one Van de Graaff generator and has the added advantage of leaving the ion source instrumentation accessible near ground potential.\nPelletron.\nThe pelletron is a style of tandem accelerator designed to overcome some of the disadvantages of using a belt to transfer charge to the high voltage terminal. In the pelletron, the belt is replaced with \"pellets\", metal spheres joined by insulating links into a chain. This chain of spheres serves the same function as the belt in a traditional Van de Graff accelerator \u2013 to convey charge to the high voltage terminal. The separate charged spheres and higher durability of the chain mean that higher voltages can be achieved at the high voltage terminal, and charge can be conveyed to the terminal more quickly.\nEntertainment and educational generators.\nThe Round Hill generator, the largest air-insulated Van de Graaff generator in the world, completed by Dr. Van de Graaff in 1933, is now displayed permanently at Boston's Museum of Science. With two conjoined aluminium spheres standing on columns tall, this generator can often obtain 2\u00a0MV (2 million volts). Shows using the Van de Graaff generator and several Tesla coils are conducted two to three times a day. \nMany science museums, such as the American Museum of Science and Energy, have small-scale Van de Graaff generators on display, and exploit their static-producing qualities to create \"lightning\" or make people's hair stand up. Van de Graaff generators are also used in schools and science shows.\nComparison with other electrostatic generators.\nOther electrostatic machines such as the Wimshurst machine or Bonetti machine work similarly to the Van De Graaff generator; charge is transported by moving plates, disks, or cylinders to a high voltage electrode. For these generators, however, corona discharge from exposed metal parts at high potentials and poorer insulation result in smaller voltages. In an electrostatic generator, the rate of charge transported (current) to the high-voltage electrode is very small. After the machine is started, the voltage on the terminal electrode increases until the leakage current from the electrode equals the rate of charge transport. Therefore, leakage from the terminal determines the maximum voltage attainable. In the Van de Graaff generator, the belt allows the transport of charge into the interior of a large hollow spherical electrode. This is the ideal shape to minimize leakage and corona discharge, so the Van de Graaff generator can produce the greatest voltage. This is why the Van de Graaff design has been used for all electrostatic particle accelerators. In general, the larger the diameter and the smoother the sphere is, the higher the voltage that can be achieved.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52643", "revid": "62", "url": "https://en.wikipedia.org/wiki?curid=52643", "title": "Van de Graff generator", "text": ""}
{"id": "52644", "revid": "35498457", "url": "https://en.wikipedia.org/wiki?curid=52644", "title": "Cysteine", "text": "Proteinogenic amino acid\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nCysteine (; symbol Cys or C) is a semiessential proteinogenic amino acid with the formula . The thiol side chain in cysteine enables the formation of disulfide bonds, and often participates in enzymatic reactions as a nucleophile. Cysteine is chiral, but both and -cysteine are found in nature. \u2011Cysteine is a protein monomer in all biota, and -cysteine acts as a signaling molecule in mammalian nervous systems. Cysteine is named after its discovery in urine, which comes from the urinary bladder or cyst, from Greek \u03ba\u03cd\u03c3\u03c4\u03b9\u03c2 \"k\u00fdstis\", \"bladder\". \nThe thiol is susceptible to oxidation to give the disulfide derivative cystine, which serves an important structural role in many proteins. In this case, the symbol Cyx is sometimes used. The deprotonated form can generally be described by the symbol Cym as well.\nWhen used as a food additive, cysteine has the E number E920.\nCysteine is encoded by the codons UGU and UGC.\nStructure.\nLike other amino acids (not as a residue of a protein), cysteine exists as a zwitterion. Cysteine has l chirality in the older d/l notation based on homology to d- and l-glyceraldehyde. In the newer \"R\"/\"S\" system of designating chirality, based on the atomic numbers of atoms near the asymmetric carbon, cysteine (and selenocysteine) have \"R\" chirality, because of the presence of sulfur (or selenium) as a second neighbor to the asymmetric carbon atom. The remaining chiral amino acids, having lighter atoms in that position, have \"S\" chirality. Replacing sulfur with selenium gives selenocysteine.\nDietary sources.\nCysteinyl is a residue in high-protein foods. Some foods considered rich in cysteine include poultry, eggs, beef, and whole grains. In high-protein diets, cysteine may be partially responsible for reduced blood pressure and stroke risk. Although classified as a nonessential amino acid, in rare cases, cysteine may be essential for infants, the elderly, and individuals with certain metabolic diseases or who suffer from malabsorption syndromes. Cysteine can usually be synthesized by the human body under normal physiological conditions if a sufficient quantity of methionine is available.\nIndustrial sources.\nThe majority of l-cysteine is obtained industrially by hydrolysis of animal materials, such as poultry feathers or hog hair. Despite widespread rumor, human hair is rarely a source material. Indeed, food additive or cosmetic product manufactures may not legally source from human hair in the European Union. \nSome animal-originating sources of l-cysteine as a food additive contravene kosher, halal, vegan, or vegetarian diets. To avoid this problem, synthetic l-cysteine, compliant with Jewish kosher and Muslim halal laws, is also available, albeit at a higher price. The typical synthetic route involves fermentation with an artificial \"E.\u00a0coli\" strain. \nAlternatively, Evonik (formerly Degussa) introduced a route from substituted thiazolines. \"Pseudomonas thiazolinophilum\" hydrolyzes racemic 2\u2011amino-\u03942\u2011thiazoline-4\u2011carboxylic acid to l\u2011cysteine.\nBiosynthesis.\nIn animals, biosynthesis begins with the amino acid serine. The sulfur is derived from methionine, which is converted to homocysteine through the intermediate \"S\"-adenosylmethionine. Cystathionine beta-synthase then combines homocysteine and serine to form the asymmetrical thioether cystathionine. The enzyme cystathionine gamma-lyase converts the cystathionine into cysteine and alpha-ketobutyrate. In plants and bacteria, cysteine biosynthesis also starts from serine, which is converted to \"O\"-acetylserine by the enzyme serine transacetylase. The enzyme cysteine synthase, using sulfide sources, converts this ester into cysteine, releasing acetate.\nBiological functions.\nThe cysteine sulfhydryl group is nucleophilic and easily oxidized. The reactivity is enhanced when the thiol is ionized, and cysteine residues in proteins have pKa values close to neutrality, so are often in their reactive thiolate form in the cell. Because of its high reactivity, the sulfhydryl group of cysteine has numerous biological functions.\nPrecursor to the antioxidant glutathione.\nDue to the ability of thiols to undergo redox reactions, cysteine and cysteinyl residues have antioxidant properties. Its antioxidant properties are typically expressed in the tripeptide glutathione, which occurs in humans and other organisms. The systemic availability of oral glutathione (GSH) is negligible; so it must be biosynthesized from its constituent amino acids, cysteine, glycine, and glutamic acid. While glutamic acid is usually sufficient because amino acid nitrogen is recycled through glutamate as an intermediary, dietary cysteine and glycine supplementation can improve synthesis of glutathione.\nPrecursor to iron-sulfur clusters.\nCysteine is an important source of sulfide in human metabolism. The sulfide in iron-sulfur clusters and in nitrogenase is extracted from cysteine, which is converted to alanine in the process.\nMetal ion binding.\nBeyond the iron-sulfur proteins, many other metal cofactors in enzymes are bound to the thiolate substituent of cysteinyl residues. Examples include zinc in zinc fingers and alcohol dehydrogenase, copper in the blue copper proteins, iron in cytochrome P450, and nickel in the [NiFe]-hydrogenases. The sulfhydryl group also has a high affinity for heavy metals, so that proteins containing cysteine, such as metallothionein, will bind metals such as mercury, lead, and cadmium tightly.\nRoles in protein structure.\nIn the translation of messenger RNA molecules to produce polypeptides, cysteine is coded for by the UGU and UGC codons.\nCysteine has traditionally been considered to be a hydrophilic amino acid, based largely on the chemical parallel between its sulfhydryl group and the hydroxyl groups in the side chains of other polar amino acids. However, the cysteine side chain has been shown to stabilize hydrophobic interactions in micelles to a greater degree than the side chain in the nonpolar amino acid glycine and the polar amino acid serine. In a statistical analysis of the frequency with which amino acids appear in various proteins, cysteine residues were found to associate with hydrophobic regions of proteins. Their hydrophobic tendency was equivalent to that of known nonpolar amino acids such as methionine and tyrosine (tyrosine is polar aromatic but also hydrophobic), those of which were much greater than that of known polar amino acids such as serine and threonine. Hydrophobicity scales, which rank amino acids from most hydrophobic to most hydrophilic, consistently place cysteine towards the hydrophobic end of the spectrum, even when they are based on methods that are not influenced by the tendency of cysteines to form disulfide bonds in proteins. Therefore, cysteine is now often grouped among the hydrophobic amino acids, though it is sometimes also classified as slightly polar, or polar.\nMost cysteine residues are covalently bonded to other cysteine residues to form disulfide bonds, which play an important role in the folding and stability of some proteins, usually proteins secreted to the extracellular medium. Since most cellular compartments are reducing environments, disulfide bonds are generally unstable in the cytosol with some exceptions as noted below.\nDisulfide bonds in proteins are formed by oxidation of the sulfhydryl group of cysteine residues. The other sulfur-containing amino acid, methionine, cannot form disulfide bonds. More aggressive oxidants convert cysteine to the corresponding sulfinic acid and sulfonic acid. Cysteine residues play a valuable role by crosslinking proteins, which increases the rigidity of proteins and also functions to confer proteolytic resistance (since protein export is a costly process, minimizing its necessity is advantageous). Inside the cell, disulfide bridges between cysteine residues within a polypeptide support the protein's tertiary structure. Insulin is an example of a protein with cystine crosslinking, wherein two separate peptide chains are connected by a pair of disulfide bonds.\nProtein disulfide isomerases catalyze the proper formation of disulfide bonds; the cell transfers dehydroascorbic acid to the endoplasmic reticulum, which oxidizes the environment. In this environment, cysteines are, in general, oxidized to cystine and are no longer functional as a nucleophiles.\nAside from its oxidation to cystine, cysteine participates in numerous post-translational modifications. The nucleophilic sulfhydryl group allows cysteine to conjugate to other groups, e.g., in prenylation. Ubiquitin ligases transfer ubiquitin to its pendant, proteins, and caspases, which engage in proteolysis in the apoptotic cycle. Inteins often function with the help of a catalytic cysteine. These roles are typically limited to the intracellular milieu, where the environment is reducing, and cysteine is not oxidized to cystine.\nEvolutionary role of cysteine.\nCysteine is considered a \"newcomer\" amino acid, being the 17th amino acid incorporated into the genetic code. Similar to other later-added amino acids such as methionine, tyrosine, and tryptophan, cysteine exhibits strong nucleophilic and redox-active properties. These properties contribute to the depletion of cysteine from respiratory chain complexes, such as Complexes I and IV, since reactive oxygen species (ROS) produced by the respiratory chain can react with the cysteine residues in these complexes, leading to dysfunctional proteins and potentially contributing to aging. The primary response of a protein to ROS is the oxidation of cysteine and the loss of free thiol groups, resulting in increased thiyl radicals and associated protein cross-linking. In contrast, another sulfur-containing, redox-active amino acid, methionine, does not exhibit these biochemical properties and its content is relatively upregulated in mitochondrially encoded proteins.\nApplications.\nCysteine, mainly the l-enantiomer, is a precursor in the food, pharmaceutical, and personal-care industries. One of the largest applications is the production of flavors. For example, the reaction of cysteine with sugars in a Maillard reaction yields meat flavors. l-Cysteine is also used as a processing aid for baking.\nIn the field of personal care, cysteine is used for permanent-wave applications, predominantly in Asia. Again, the cysteine is used for breaking up the disulfide bonds in the hair's keratin.\nCysteine is a very popular target for site-directed labeling experiments to investigate biomolecular structure and dynamics. Maleimides selectively attach to cysteine using a covalent Michael addition. Site-directed spin labeling for EPR or paramagnetic relaxation-enhanced NMR also uses cysteine extensively.\nReducing toxic effects of alcohol.\nCysteine has been proposed as a preventive or antidote for some of the negative effects of alcohol, including liver damage and hangover. It counteracts the poisonous effects of acetaldehyde. It binds to acetaldehyde to form the low-toxicity heterocycle methylthioproline.\nIn a rat study, test animals received an LD90 dose of acetaldehyde. Those that received cysteine had an 80% survival rate; when both cysteine and thiamine were administered, all animals survived. The control group had a 10% survival rate.\nIn 2020 an article was published that suggests L-cysteine might also work in humans.\n\"N\"-Acetylcysteine.\n\"N\"-Acetyl-l-cysteine is a derivative of cysteine wherein an acetyl group is attached to the nitrogen atom. This compound is sold as a dietary supplement, and used as an antidote in cases of acetaminophen overdose.\nSheep.\nCysteine is required by sheep to produce wool. It is an essential amino acid that is taken in from their feed. As a consequence, during drought conditions, sheep produce less wool; however, transgenic sheep that can make their own cysteine have been developed.\nChemical reactions.\nBeing multifunctional, cysteine undergoes a variety of reactions. Much attention has focused on protecting the sulfhydryl group. Methylation of cysteine gives S-methylcysteine. Treatment with formaldehyde gives the thiazolidine thioproline. With phosgene and related carbonylating agents, cysteine gives procysteine.\nCysteine forms a variety of coordination complexes upon treatment with metal ions. This coordination behavior is seen in many metal-cysteine metalloenzymes.\nSafety.\nRelative to most other amino acids, cysteine is much more toxic.\nHistory.\nIn 1884 German chemist Eugen Baumann found that reduction of cystine with zinc gave monomer, which he named \"cyste\u00efne\". The easy redox interconversion of cysteine and cystine has \"provided more puzzles to protein chemists than any of the other amino acids.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52646", "revid": "62", "url": "https://en.wikipedia.org/wiki?curid=52646", "title": "Van de Graf generator", "text": ""}
{"id": "52647", "revid": "45620479", "url": "https://en.wikipedia.org/wiki?curid=52647", "title": "Liberty (disambiguation)", "text": "Liberty is the ability to do as one pleases, or have the power and resources to fulfill one's purposes.\nLiberty may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "52648", "revid": "32990417", "url": "https://en.wikipedia.org/wiki?curid=52648", "title": "Camera", "text": "Optical device for recording images\nA camera is an instrument used to capture and store images and videos, either digitally via an electronic image sensor, or chemically via a light-sensitive material such as photographic film. As a pivotal technology in the fields of photography and videography, cameras have played a significant role in the progression of visual arts, media, entertainment, surveillance, and scientific research. The invention of the camera dates back to the 19th century and has since evolved with advancements in technology, leading to a vast array of types and models in the 21st century.\nCameras function through a combination of multiple mechanical components and principles. These include exposure control, which regulates the amount of light reaching the sensor or film; the lens, which focuses the light; the viewfinder, which allows the user to preview the scene; and the film or sensor, which captures the image.\nSeveral types of camera exist, each suited to specific uses and offering unique capabilities. Single-lens reflex (SLR) cameras provide real-time, exact imaging through the lens. Large-format and medium-format cameras offer higher image resolution and are often used in professional and artistic photography. Compact cameras, known for their portability and simplicity, are popular in consumer photography. Rangefinder cameras, with separate viewing and imaging systems, were historically widely used in photojournalism. Motion picture cameras are specialized for filming cinematic content, while digital cameras, which became prevalent in the late 20th and early 21st century, use electronic sensors to capture and store images.\nThe rapid development of smartphone camera technology in the 21st century has blurred the lines between dedicated cameras and multifunctional devices, as the smartphone camera is easier to use, profoundly influencing how society creates, shares, and consumes visual content.&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\n19th century.\nBeginning with the use of the camera obscura and transitioning to complex photographic cameras, the evolution of the technology in the 19th century was driven by pioneers like Thomas Wedgwood, Nic\u00e9phore Ni\u00e9pce, and Henry Fox Talbot. First using the camera obscura for chemical experiments, they ultimately created cameras specifically for chemical photography, and later reduced the camera's size and optimized lens configurations.\nThe introduction of the daguerreotype process in 1839 facilitated commercial camera manufacturing, with various producers contributing diverse designs. As camera manufacturing became a specialized trade in the 1850s, designs and sizes were standardized.\nThe latter half of the century witnessed the advent of dry plates and roll-film, prompting a shift towards smaller and more cost-effective cameras, epitomized by the original Kodak camera, first produced in 1888. This period also saw significant advancements in lens technology and the emergence of color photography, leading to a surge in camera ownership.\n20th century.\nThe first half of the 20th century saw continued miniaturization and the integration of new manufacturing materials. After World War I, Germany took the lead in camera development, spearheading industry consolidation and producing precision-made cameras. The industry saw significant product launches such as the Leica camera and the Contax, which were enabled by advancements in film and lens designs. Additionally, there was a marked increase in accessibility to cinematography for amateurs with Eastman Kodak's production of the first 16-mm and 8-mm reversal safety films. The World War II era saw a focus on the development of specialized aerial reconnaissance and instrument-recording equipment, even as the overall pace of non-military camera innovation slowed.\nIn the second half of the century, Japanese manufacturers in particular advanced camera technology. From the introduction of the affordable Ricohflex III TLR in 1952 to the first 35mm SLR with automatic exposure, the Olympus AutoEye in 1960, new designs and features continuously emerged. Electronics became integral to camera design in the 1970s, evident in models like Polaroid's SX-70 and Canon's AE-1.\nTransition to digital photography marked the late 20th century, culminating in digital camera sales surpassing film cameras in the United States by 2003. In contrast, the film camera industry in the UK, Western Europe, and the USA declined during this period, while manufacturing continued in the USSR, German Democratic Republic, and China, often mimicking Western designs.\n21st century.\nThe 21st century witnessed the mass adoption of digital cameras and significant improvements in sensor technology. A major revolution came with the incorporation of cameras into smartphones, making photography a commonplace activity. The century also marked the rise of computational photography, using algorithms and AI to enhance image quality. Features like low-light and HDR photography, optical image stabilization, and depth-sensing became common in smartphone cameras.\nMechanics.\nMost cameras capture light from the visible light spectrum, while specialized cameras capture other portions of the electromagnetic spectrum, such as infrared.\nAll cameras use the same basic design: light enters an enclosed box through a converging or convex lens and an image is recorded on a light-sensitive medium. A shutter mechanism controls the length of time that light enters the camera.\nMost cameras also have a viewfinder, which shows the scene to be recorded, along with means to adjust various combinations of focus, aperture and shutter speed.\nExposure control.\nAperture.\nLight enters the camera through an aperture, an opening adjusted by overlapping plates called the aperture ring. Typically located in the lens, this opening can be widened or narrowed to alter the amount of light that strikes the film or sensor. The size of the aperture can be set manually, by rotating the lens or adjusting a dial or automatically based on readings from an internal light meter.\nAs the aperture is adjusted, the opening expands and contracts in increments called \"f-stops\". The smaller the f-stop, the more light is allowed to enter the lens, increasing the exposure. Typically, f-stops range from &lt;templatestyles src=\"F//styles.css\" /&gt;f/1.4 to &lt;templatestyles src=\"F//styles.css\" /&gt;f/32 in standard increments: 1.4, 2, 2.8, 4, 5.6, 8, 11, 16, 22, and 32. The light entering the camera is halved with each increasing increment.\nThe wider opening at lower f-stops narrows the range of focus so the background is blurry while the foreground is in focus. This depth of field increases as the aperture closes. A narrow aperture results in a high depth of field, meaning that objects at many different distances from the camera will appear to be in focus. What is acceptably in focus is determined by the circle of confusion, the photographic technique, the equipment in use and the degree of magnification expected of the final image.\nShutter.\nThe shutter, along with the aperture, is one of two ways to control the amount of light entering the camera. The shutter determines the duration that the light-sensitive surface is exposed to light. The shutter opens, light enters the camera and exposes the film or sensor to light, and then the shutter closes.\nThere are two types of mechanical shutters: the leaf-type shutter and the focal-plane shutter. The leaf-type uses a circular iris diaphragm maintained under spring tension inside or just behind the lens that rapidly opens and closes when the shutter is released. \nMore commonly, a focal-plane shutter is used. This shutter operates close to the film plane and employs metal plates or cloth curtains with an opening that passes across the light-sensitive surface. The curtains or plates have an opening that is pulled across the film plane during exposure. The focal-plane shutter is typically used in single-lens reflex (SLR) cameras, since covering the film (rather than blocking the light passing through the lens) allows the photographer to view the image through the lens at all times, except during the exposure itself. Covering the film also facilitates removing the lens from a loaded camera, as many SLRs have interchangeable lenses.\nA digital camera may use a mechanical or electronic shutter, the latter of which is common in smartphone cameras. Electronic shutters either record data from the entire sensor simultaneously (a global shutter) or record the data line by line across the sensor (a rolling shutter). In movie cameras, a rotary shutter opens and closes in sync with the advancement of each frame of film.\nThe duration for which the shutter is open is called the \"shutter speed\" or \"exposure time\". Typical exposure times can range from one second to 1/1,000 of a second, though longer and shorter durations are not uncommon. In the early stages of photography, exposures were often several minutes long. These long exposure times often resulted in blurry images, as a single object is recorded in multiple places across a single image for the duration of the exposure. To prevent this, shorter exposure times can be used. Very short exposure times can capture fast-moving action and eliminate motion blur. However, shorter exposure times require more light to produce a properly exposed image, so shortening the exposure time is not always possible.\nLike aperture settings, exposure times increment in powers of two. The two settings determine the exposure value (EV), a measure of how much light is recorded during the exposure. There is a direct relationship between the exposure times and aperture settings so that if the exposure time is lengthened one step, but the aperture opening is also narrowed one step, then the amount of light that contacts the film or sensor is the same.\nLight meter.\nIn most modern cameras, the amount of light entering the camera is measured using a built-in light meter or exposure meter. Taken through the lens (called \"TTL metering\"), these readings are taken using a panel of light-sensitive semiconductors. They are used to calculate optimal exposure settings. These settings are typically determined automatically as the reading is used by the camera's microprocessor. The reading from the light meter is incorporated with aperture settings, exposure times, and film or sensor sensitivity to calculate the optimal exposure.\nLight meters typically average the light in a scene to 18% middle gray. More advanced cameras are more nuanced in their metering\u2014weighing the center of the frame more heavily (center-weighted metering), considering the differences in light across the image (matrix metering), or allowing the photographer to take a light reading at a specific point within the image (spot metering).\nLens.\nA camera lens is an assembly of multiple optical elements, typically made from high-quality glass. Its primary function is to focus light onto a camera's film or digital sensor, thereby producing an image. This process significantly influences image quality, the overall appearance of the photo, and which parts of the scene are brought into focus.\nA camera lens is constructed from a series of lens elements, small pieces of glass arranged to form an image accurately on the light-sensitive surface. Each element is designed to reduce optical aberrations, or distortions, such as chromatic aberration (a failure of the lens to focus all colors at the same point), vignetting (darkening of image corners), and distortion (bending or warping of the image). The degree of these distortions can vary depending on the subject of the photo.\nThe focal length of the lens, measured in millimeters, plays a critical role as it determines how much of the scene the camera can capture and how large the objects appear. Wide-angle lenses provide a broad view of the scene, while telephoto lenses capture a narrower view but magnify the objects. The focal length also influences the ease of taking clear pictures handheld, with longer lengths making it more challenging to avoid blur from small camera movements.\nTwo primary types of lenses include zoom and prime lenses. A zoom lens allows for changing its focal length within a certain range, providing the convenience of adjusting the scene capture without moving the camera or changing the lens. A prime lens, in contrast, has a fixed focal length. While less flexible, prime lenses often provide superior image quality, are typically lighter, and perform better in low light.\nFocus involves adjusting the lens elements to sharpen the image of the subject at various distances. The focus is adjusted through the focus ring on the lens, which moves the lens elements closer or further from the sensor. Autofocus is a feature included in many lenses, which uses a motor within the lens to adjust the focus quickly and precisely based on the lens's detection of contrast or phase differences. This feature can be enabled or disabled using switches on the lens body.\nAdvanced lenses may include mechanical image stabilization systems that move lens elements or the image sensor itself to counteract camera shake, especially beneficial in low-light conditions or at slow shutter speeds. Lens hoods, filters, and caps are accessories used alongside a lens to enhance image quality, protect the lens, or achieve specific effects.\nViewfinder.\nThe camera's viewfinder provides a real-time approximation of what will be captured by the sensor or film. It assists photographers in aligning, focusing, and adjusting the composition, lighting, and exposure of their shots, enhancing the accuracy of the final image.\nViewfinders fall into two primary categories: optical and electronic. Optical viewfinders, commonly found in Single-Lens Reflex (SLR) cameras, use a system of mirrors or prisms to reflect light from the lens to the viewfinder, providing a clear, real-time view of the scene. Electronic viewfinders, typical in mirrorless cameras, project an electronic image onto a small display, offering a wider range of information such as live exposure previews and histograms, albeit at the cost of potential lag and higher battery consumption. Specialized viewfinder systems exist for specific applications, like subminiature cameras for spying or underwater photography.\nParallax error, resulting from misalignment between the viewfinder and lens axes, can cause inaccurate representations of the subject's position. While negligible with distant subjects, this error becomes prominent with closer ones. Some viewfinders incorporate parallax-compensating devices to mitigate that issue.\nFilm and sensor.\nImage capture in a camera occurs when light strikes a light-sensitive surface: photographic film or a digital sensor. Housed within the camera body, the film or sensor records the light's pattern when the shutter is briefly opened to allow light to pass during the exposure.\nLoading film into a film camera is a manual process. The film, typically housed in a cartridge, is loaded into a designated slot in the camera. One end of the film strip, the film leader, is manually threaded onto a take-up spool. Once the back of the camera is closed, the film advance lever or knob is used to ensure the film is correctly placed. The photographer then winds the film, either manually or automatically depending on the camera, to position a blank portion of the film in the path of the light. Each time a photo is taken, the film advance mechanism moves the exposed film out of the way, bringing a new, unexposed section of film into position for the next shot.\nThe film must be advanced after each shot to prevent double exposure \u2014 where the same section of film is exposed to light twice, resulting in overlapped images. Once all frames on the film roll have been exposed, the film is rewound back into the cartridge, ready to be removed from the camera for developing.\nIn digital cameras, sensors typically comprise Charge-Coupled Devices (CCDs) or Complementary Metal-Oxide-Semiconductor (CMOS) chips, both of which convert incoming light into electrical charges to form digital images. CCD sensors, though power-intensive, are recognized for their excellent light sensitivity and image quality. Conversely, CMOS sensors offer individual pixel readouts, leading to less power consumption and faster frame rates, with their image quality having improved significantly over time.\nDigital cameras convert light into electronic data that can be directly processed and stored. The volume of data generated is dictated by the sensor's size and properties, necessitating storage media such as Compact Flash, Memory Sticks, and SD (Secure Digital) cards. Modern digital cameras typically feature a built-in monitor for immediate image review and adjustments. Digital images are also more readily handled and manipulated by computers, offering a significant advantage in terms of flexibility and post-processing potential over traditional film.\nCamera accessories.\nFlash.\nA flash provides a short burst of bright light during exposure and is a commonly used artificial light source in photography. Most modern flash systems use a battery-powered high-voltage discharge through a gas-filled tube to generate bright light for a very short time (1/1,000 of a second or less).\nMany flash units measure the light reflected from the flash to help determine the appropriate duration of the flash. When the flash is attached directly to the camera\u2014typically in a slot at the top of the camera (the flash shoe or hot shoe) or through a cable\u2014activating the shutter on the camera triggers the flash, and the camera's internal light meter can help determine the duration of the flash.\nAdditional flash equipment can include a light diffuser, mount and stand, reflector, soft box, trigger and cord.\nOther accessories.\nAccessories for cameras are mainly used for care, protection, special effects, and functions.\nLarge format cameras use special equipment that includes a magnifier loupe, view finder, angle finder, and focusing rail/truck. Some professional SLRs can be provided with interchangeable finders for eye-level or waist-level focusing, focusing screens, eyecup, data backs, motor-drives for film transportation or external battery packs.\nPrimary types.\nSingle-lens reflex (SLR) camera.\nIn photography, the single-lens reflex camera (SLR) is provided with a mirror to redirect light from the lens to the viewfinder prior to releasing the shutter for composing and focusing an image. When the shutter is released, the mirror swings up and away, allowing the exposure of the photographic medium, and instantly returns after the exposure is finished. No SLR camera before 1954 had this feature, although the mirror on some early SLR cameras was entirely operated by the force exerted on the shutter release and only returned when the finger pressure was released. The Asahiflex II, released by Japanese company Asahi (Pentax) in 1954, was the world's first SLR camera with an instant return mirror.\nIn the single-lens reflex camera, the photographer sees the scene through the camera lens. This avoids the problem of parallax which occurs when the viewfinder or viewing lens is separated from the taking lens. Single-lens reflex cameras have been made in several formats including sheet film 5x7\" and 4x5\", roll film 220/120 taking 8,10, 12, or 16 photographs on a 120 roll, and twice that number of a 220 film. These correspond to 6x9, 6x7, 6x6, and 6x4.5 respectively (all dimensions in cm). Notable manufacturers of large format and roll film SLR cameras include Bronica, Graflex, Hasselblad, Seagull, Mamiya and Pentax. However, the most common format of SLR cameras has been 35\u00a0mm and subsequently the migration to digital SLR cameras, using almost identical sized bodies and sometimes using the same lens systems.\nAlmost all SLR cameras use a front-surfaced mirror in the optical path to direct the light from the lens via a viewing screen and pentaprism to the eyepiece. At the time of exposure, the mirror is flipped up out of the light path before the shutter opens. Some early cameras experimented with other methods of providing through-the-lens viewing, including the use of a semi-transparent pellicle as in the Canon Pellix and others with a small periscope such as in the Corfield Periflex series.\nLarge-format camera.\nThe large-format camera, taking sheet film, is a direct successor of the early plate cameras and remained in use for high-quality photography and technical, architectural, and industrial photography. There are three common types: the view camera, with its monorail and field camera variants, and the press camera. They have extensible bellows with the lens and shutter mounted on a lens plate at the front. Backs taking roll film and later digital backs are available in addition to the standard dark slide back. These cameras have a wide range of movements allowing very close control of focus and perspective. Composition and focusing are done on view cameras by viewing a ground-glass screen which is replaced by the film to make the exposure; they are suitable for static subjects only and are slow to use.\nPlate camera.\nThe earliest cameras produced in significant numbers were \"plate cameras\", using sensitized glass plates. Light entered a lens mounted on a lens board which was separated from the plate by extendible bellows. There were simple box cameras for glass plates but also single-lens reflex cameras with interchangeable lenses and even for color photography (Autochrome Lumi\u00e8re). Many of these cameras had controls to raise, lower, and tilt the lens forwards or backward to control perspective.\nFocusing of these plate cameras was by the use of a ground glass screen at the point of focus. Because lens design only allowed rather small aperture lenses, the image on the ground glass screen was faint and most photographers had a dark cloth to cover their heads to allow focusing and composition to be carried out more quickly. When focus and composition were satisfactory, the ground glass screen was removed, and a sensitized plate was put in its place protected by a dark slide. To make the exposure, the dark decline was carefully slid out and the shutter opened, and then closed and the dark fall replaced.\nGlass plates were later replaced by sheet film in a dark slide for sheet film; adapter sleeves were made to allow sheet film to be used in plate holders. In addition to the ground glass, a simple optical viewfinder was often fitted.\nMedium-format camera.\nMedium-format cameras have a film size between the large-format cameras and smaller 35\u00a0mm cameras. Typically these systems use 120 or 220 roll film. The most common image sizes are 6\u00d74.5\u00a0cm, 6\u00d76\u00a0cm and 6\u00d77\u00a0cm; the older 6\u00d79\u00a0cm is rarely used. The designs of this kind of camera show greater variation than their larger brethren, ranging from monorail systems through the classic Hasselblad model with separate backs, to smaller rangefinder cameras. There are even compact amateur cameras available in this format.\nTwin-lens reflex camera.\nTwin-lens reflex cameras used a pair of nearly identical lenses: one to form the image and one as a viewfinder. The lenses were arranged with the viewing lens immediately above the taking lens. The viewing lens projects an image onto a viewing screen which can be seen from above. Some manufacturers such as Mamiya also provided a reflex head to attach to the viewing screen to allow the camera to be held to the eye when in use. The advantage of a TLR was that it could be easily focused using the viewing screen and that under most circumstances the view seen on the viewing screen was identical to that recorded on film. At close distances, however, parallax errors were encountered, and some cameras also included an indicator to show what part of the composition would be excluded.\nSome TLRs had interchangeable lenses, but as these had to be paired lenses, they were relatively heavy and did not provide the range of focal lengths that the SLR could support. Most TLRs used 120 or 220 films; some used the smaller 127 films.\nCompact cameras.\nInstant camera.\nAfter exposure, every photograph is taken through pinch rollers inside the instant camera. Thereby the developer paste contained in the paper 'sandwich' is distributed on the image. After a minute, the cover sheet just needs to be removed and one gets a single original positive image with a fixed format. With some systems, it was also possible to create an instant image negative, from which then could be made copies in the photo lab. The ultimate development was the SX-70 system of Polaroid, in which a row of ten shots \u2013 engine driven \u2013 could be made without having to remove any cover sheets from the picture. There were instant cameras for a variety of formats, as well as adapters for instant film use in medium- and large-format cameras.\nSubminiature camera.\nSubminiature cameras were first produced in the twentieth century and use film significantly smaller than 35mm. The expensive 8\u00d711mm Minox, the only type of camera produced by the company from 1937 to 1976, became very widely known and was often used for espionage (the Minox company later also produced larger cameras). Later inexpensive subminiatures were made for general use, some using rewound 16\u00a0mm cine film. Image quality with these small film sizes was limited.\nFolding camera.\nThe introduction of films enabled the existing designs for plate cameras to be made much smaller and for the baseplate to be hinged so that it could be folded up, compressing the bellows. These designs were very compact and small models were dubbed \"vest pocket\" cameras. One of the smallest and best-selling cameras was the Vest Pocket Kodak, sold in two generations between 1912 and 1934. Folding roll film cameras were preceded by folding plate cameras, more compact than other designs.\nBox camera.\nBox cameras were introduced as budget-level cameras and had few if any controls. The original box Brownie models had a small reflex viewfinder mounted on the top of the camera and had no aperture or focusing controls and just a simple shutter. Later models such as the Brownie 127 had larger direct view optical viewfinders together with a curved film path to reduce the impact of deficiencies in the lens.\nRangefinder camera.\nAs camera lens technology developed and wide aperture lenses became more common, rangefinder cameras were introduced to make focusing more precise. Early rangefinders had two separate viewfinder windows, one of which is linked to the focusing mechanisms and moved right or left as the focusing ring is turned. The two separate images are brought together on a ground glass viewing screen. When vertical lines in the object being photographed meet exactly in the combined image, the object is in focus. A normal composition viewfinder is also provided. Later the viewfinder and rangefinder were combined. Many rangefinder cameras had interchangeable lenses, each lens requiring its range- and viewfinder linkages.\nRangefinder cameras were produced in half- and full-frame 35\u00a0mm and roll film (medium format).\nMotion picture cameras.\nA movie camera or a video camera operates similarly to a still camera, except it records a series of static images in rapid succession, commonly at a rate of 24 frames per second. When the images are combined and displayed in order, the illusion of motion is achieved.\nCameras that capture many images in sequence are known as movie cameras or as cine cameras in Europe; those designed for single images are still cameras. However, these categories overlap as still cameras are often used to capture moving images in special effects work and many modern cameras can quickly switch between still and motion recording modes.\nA cin\u00e9 camera or movie camera takes a rapid sequence of photographs on an image sensor or strips of film. In contrast to a still camera, which captures a single snapshot at a time, the cin\u00e9 camera takes a series of images, each called a \"frame\", through the use of an intermittent mechanism.\nThe frames are later played back in a cin\u00e9 projector at a specific speed, called the \"frame rate\" (number of frames per second). While viewing, a person's visual system merges the separate pictures to create the illusion of motion. The first cin\u00e9 camera was built around 1888 and by 1890 several types were being manufactured. The standard film size for cin\u00e9 cameras was quickly established as 35mm film and this remained in use until the transition to digital cinematography. Other professional standard formats include 70\u00a0mm film and 16\u00a0mm film whilst amateur filmmakers used 9.5\u00a0mm film, 8\u00a0mm film, or Standard 8 and Super 8 before the move into digital format.\nThe size and complexity of cin\u00e9 cameras vary greatly depending on the uses required of the camera. Some professional equipment is very large and too heavy to be handheld whilst some amateur cameras were designed to be very small and light for single-handed operation.\nProfessional video camera.\nA professional video camera (often called a \"television camera\" even though the use has spread beyond television) is a high-end device for creating electronic moving images (as opposed to a movie camera, that earlier recorded the images on film). Originally developed for use in television studios, they are now also used for music videos, direct-to-video movies, corporate and educational videos, marriage videos, etc.\nThese cameras earlier used vacuum tubes and later electronic image sensors.\nCamcorders.\nA camcorder is an electronic device combining a video camera and a video recorder. Although marketing materials may use the colloquial term \"camcorder\", the name on the package and manual is often \"video camera recorder\". Most devices capable of recording video are camera phones and digital cameras primarily intended for still pictures; the term \"camcorder\" is used to describe a portable, self-contained device, with video capture and recording its primary function.\nDigital camera.\nA digital camera (or digicam) is a camera that encodes digital images and videos and stores them for later reproduction. They typically use semiconductor image sensors. Most cameras sold today are digital, and they are incorporated into many devices ranging from mobile phones (called camera phones) to vehicles.\nDigital and film cameras share an optical system, typically using a lens of variable aperture to focus light onto an image pickup device. The aperture and shutter admit the correct amount of light to the imager, just as with film but the image pickup device is electronic rather than chemical. However, unlike film cameras, digital cameras can display images on a screen immediately after being captured or recorded, and store and delete images from memory. Most digital cameras can also record moving videos with sound. Some digital cameras can crop and stitch pictures &amp; perform other elementary image editing.\nConsumers adopted digital cameras in the 1990s. Professional video cameras transitioned to digital around the 2000s\u20132010s. Finally, movie cameras transitioned to digital in the 2010s.\nThe first camera using digital electronics to capture and store images was developed by Kodak engineer Steven Sasson in 1975. He used a charge-coupled device (CCD) provided by Fairchild Semiconductor, which provided only 0.01 megapixels to capture images. Sasson combined the CCD device with movie camera parts to create a digital camera that saved black and white images onto a cassette tape.The images were then read from the cassette and viewed on a TV monitor. Later, cassette tapes were replaced by flash memory.\nIn 1986, Japanese company Nikon introduced an analog-recording electronic single-lens reflex camera, the Nikon SVC.\nThe first full-frame digital SLR cameras were developed in Japan from around 2000 to 2002: the MZ-D by Pentax, the N Digital by Contax's Japanese R6D team, and the EOS-1Ds by Canon. Gradually in the 2000s, the full-frame DSLR became the dominant camera type for professional photography.\nOn most digital cameras a display, often a liquid crystal display (LCD), permits the user to view the scene to be recorded and settings such as ISO speed, exposure, and shutter speed.\nCamera phone.\nIn 2000, Sharp introduced the world's first digital camera phone, the J-SH04 J-Phone, in Japan. By the mid-2000s, higher-end cell phones had an integrated digital camera, and by the beginning of the 2010s, almost all smartphones had an integrated digital camera.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52649", "revid": "150564", "url": "https://en.wikipedia.org/wiki?curid=52649", "title": "Acetylcholine", "text": "Organic chemical and neurotransmitter\n&lt;templatestyles src=\"Infobox drug/styles.css\"/&gt;\nAcetylcholine (ACh) is an organic compound that functions in the brain and body of many types of animals (including humans) as a neurotransmitter. Its name is derived from its chemical structure: it is an ester of acetic acid and choline. Parts in the body that use or are affected by acetylcholine are referred to as cholinergic.\nAcetylcholine is the neurotransmitter used at the neuromuscular junction. In other words, it is the chemical that motor neurons of the nervous system release in order to activate muscles. This property means that drugs that affect cholinergic systems can have very dangerous effects ranging from paralysis to convulsions. Acetylcholine is also a neurotransmitter in the autonomic nervous system, both as an internal transmitter for both the sympathetic and the parasympathetic nervous system, and as the final product released by the parasympathetic nervous system. Acetylcholine is the primary neurotransmitter of the parasympathetic nervous system.\nIn the brain, acetylcholine functions as a neurotransmitter and as a neuromodulator. The brain contains a number of cholinergic areas, each with distinct functions; such as playing an important role in arousal, attention, memory and motivation. Acetylcholine has also been found in cells of non-neural origins as well as microbes. Recently, enzymes related to its synthesis, degradation and cellular uptake have been traced back to early origins of unicellular eukaryotes. The protist pathogens \"Acanthamoeba\" spp. have shown evidence of the presence of ACh, which provides growth and proliferative signals via a membrane-located M1-muscarinic receptor homolog.\nPartly because of acetylcholine's muscle-activating function, but also because of its functions in the autonomic nervous system and brain, many important drugs exert their effects by altering cholinergic transmission. Numerous venoms and toxins produced by plants, animals, and bacteria, as well as chemical nerve agents such as sarin, cause harm by inactivating or hyperactivating muscles through their influences on the neuromuscular junction. Drugs that act on muscarinic acetylcholine receptors, such as atropine, can be poisonous in large quantities, but in smaller doses they are commonly used to treat certain heart conditions and eye problems. Scopolamine, or diphenhydramine, which also act mainly on muscarinic receptors in an inhibitory fashion in the brain (especially the M1 receptor) can cause delirium, hallucinations, and amnesia through receptor antagonism at these sites. So far as of 2016, only the M1 receptor subtype has been implicated in anticholinergic delirium. The addictive qualities of nicotine are derived from its effects on nicotinic acetylcholine receptors in the brain.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nChemistry.\nAcetylcholine is a choline molecule that has been acetylated at the oxygen atom. Because of the charged ammonium group, acetylcholine does not penetrate lipid membranes. Because of this, when the molecule is introduced externally, it remains in the extracellular space and at present it is considered that the molecule does not pass through the blood\u2013brain barrier.\nBiochemistry.\nAcetylcholine is synthesized in certain neurons by the enzyme choline acetyltransferase from the compounds choline and acetyl-CoA. Cholinergic neurons are capable of producing ACh. An example of a central cholinergic area is the nucleus basalis of Meynert in the basal forebrain.\nThe enzyme acetylcholinesterase converts acetylcholine into the inactive metabolites choline and acetate. This enzyme is abundant in the synaptic cleft, and its role in rapidly clearing free acetylcholine from the synapse is essential for proper muscle function. Certain neurotoxins work by inhibiting acetylcholinesterase, thus leading to excess acetylcholine at the neuromuscular junction, causing paralysis of the muscles needed for breathing and stopping the beating of the heart.\nFunctions.\nAcetylcholine functions in both the central nervous system (CNS) and the peripheral nervous system (PNS). In the CNS, cholinergic projections from the basal forebrain to the cerebral cortex and hippocampus support the cognitive functions of those target areas. In the PNS, acetylcholine activates muscles and is a major neurotransmitter in the autonomic nervous system.\nCellular effects.\nLike many other biologically active substances, acetylcholine exerts its effects by binding to and activating receptors located on the surface of cells. There are two main classes of acetylcholine receptor, nicotinic and muscarinic. They are named for chemicals that can selectively activate each type of receptor without activating the other: muscarine is a compound found in the mushroom \"Amanita muscaria\"; nicotine is found in tobacco.\nNicotinic acetylcholine receptors are ligand-gated ion channels permeable to sodium, potassium, and calcium ions. In other words, they are ion channels embedded in cell membranes, capable of switching from a closed to an open state when acetylcholine binds to them; in the open state they allow ions to pass through. Nicotinic receptors come in two main types, known as muscle-type and neuronal-type. The muscle-type can be selectively blocked by curare, the neuronal-type by hexamethonium. The main location of muscle-type receptors is on muscle cells, as described in more detail below. Neuronal-type receptors are located in autonomic ganglia (both sympathetic and parasympathetic), and in the central nervous system.\nMuscarinic acetylcholine receptors have a more complex mechanism, and affect target cells over a longer time frame. In mammals, five subtypes of muscarinic receptors have been identified, labeled M1 through M5. All of them function as G protein-coupled receptors, meaning that they exert their effects via a second messenger system. The M1, M3, and M5 subtypes are Gq-coupled; they increase intracellular levels of IP3 and calcium by activating phospholipase C. Their effect on target cells is usually excitatory. The M2 and M4 subtypes are Gi/Go-coupled; they decrease intracellular levels of cAMP by inhibiting adenylate cyclase. Their effect on target cells is usually inhibitory. Muscarinic acetylcholine receptors are found in both the central nervous system and the peripheral nervous system of the heart, lungs, upper gastrointestinal tract, and sweat glands.\nNeuromuscular junction.\nAcetylcholine is the substance the nervous system uses to activate skeletal muscles, a kind of striated muscle. These are the muscles used for all types of voluntary movement, in contrast to smooth muscle tissue, which is involved in a range of involuntary activities such as movement of food through the gastrointestinal tract and constriction of blood vessels. Skeletal muscles are directly controlled by motor neurons located in the spinal cord or, in a few cases, the brainstem. These motor neurons send their axons through motor nerves, from which they emerge to connect to muscle fibers at a special type of synapse called the neuromuscular junction.\nWhen a motor neuron generates an action potential, it travels rapidly along the nerve until it reaches the neuromuscular junction, where it initiates an electrochemical process that causes acetylcholine to be released into the space between the presynaptic terminal and the muscle fiber. The acetylcholine molecules then bind to nicotinic ion-channel receptors on the muscle cell membrane, causing the ion channels to open. Sodium ions then flow into the muscle cell, initiating a sequence of steps that finally produce muscle contraction.\nFactors that decrease release of acetylcholine (and thereby affecting P-type calcium channels):\nCalcium channel blockers (nifedipine, diltiazem) do not affect P-channels. These drugs affect L-type calcium channels.\nAutonomic nervous system.\nThe autonomic nervous system controls a wide range of involuntary and unconscious body functions. Its main branches are the sympathetic nervous system and parasympathetic nervous system. Broadly speaking, the function of the sympathetic nervous system is to mobilize the body for action; the phrase often invoked to describe it is fight-or-flight. The function of the parasympathetic nervous system is to put the body in a state conducive to rest, regeneration, digestion, and reproduction; the phrase often invoked to describe it is \"rest and digest\" or \"feed and breed\". Both of these aforementioned systems use acetylcholine, but in different ways.\nAt a schematic level, the sympathetic and parasympathetic nervous systems are both organized in essentially the same way: preganglionic neurons in the central nervous system send projections to neurons located in autonomic ganglia, which send output projections to virtually every tissue of the body. In both branches the internal connections, the projections from the central nervous system to the autonomic ganglia, use acetylcholine as a neurotransmitter to innervate (or excite) ganglia neurons. In the parasympathetic nervous system the output connections, the projections from ganglion neurons to tissues that do not belong to the nervous system, also release acetylcholine but act on muscarinic receptors. In the sympathetic nervous system the output connections mainly release noradrenaline, although acetylcholine is released at a few points, such as the sudomotor innervation of the sweat glands.\nDirect vascular effects.\nAcetylcholine in the serum exerts a direct effect on vascular tone by binding to muscarinic receptors present on vascular endothelium. These cells respond by increasing production of nitric oxide, which signals the surrounding smooth muscle to relax, leading to vasodilation.\nCentral nervous system.\nIn the central nervous system, ACh has a variety of effects on plasticity, arousal and reward. ACh has an important role in the enhancement of alertness when we wake up, in sustaining attention and in learning and memory.\nDamage to the cholinergic (acetylcholine-producing) system in the brain has been shown to be associated with the memory deficits associated with Alzheimer's disease. ACh has also been shown to promote REM sleep.\nIn the brainstem acetylcholine originates from the Pedunculopontine nucleus and laterodorsal tegmental nucleus collectively known as the mesopontine tegmentum area or pontomesencephalotegmental complex. In the basal forebrain, it originates from the basal nucleus of Meynert and medial septal nucleus:\nIn addition, ACh acts as an important internal transmitter in the striatum, which is part of the basal ganglia. It is released by cholinergic interneurons. In humans, non-human primates and rodents, these interneurons respond to salient environmental stimuli with responses that are temporally aligned with the responses of dopaminergic neurons of the substantia nigra.\nMemory.\nAcetylcholine has been implicated in learning and memory in several ways. The anticholinergic drug scopolamine impairs acquisition of new information in humans and animals. In animals, disruption of the supply of acetylcholine to the neocortex impairs the learning of simple discrimination tasks, comparable to the acquisition of factual information and disruption of the supply of acetylcholine to the hippocampus and adjacent cortical areas produces forgetfulness, comparable to anterograde amnesia in humans.\nDiseases and disorders.\nMyasthenia gravis.\nThe disease myasthenia gravis, characterized by muscle weakness and fatigue, occurs when the body inappropriately produces antibodies against acetylcholine nicotinic receptors, and thus inhibits proper acetylcholine signal transmission. Over time, the motor end plate is destroyed. Drugs that competitively inhibit acetylcholinesterase (e.g., neostigmine, physostigmine, or primarily pyridostigmine) are effective in treating the symptoms of this disorder. They allow endogenously released acetylcholine more time to interact with its respective receptor before being inactivated by acetylcholinesterase in the synaptic cleft (the space between nerve and muscle).\nPharmacology.\nBlocking, hindering or mimicking the action of acetylcholine has many uses in medicine. Drugs acting on the acetylcholine system are either agonists to the receptors, stimulating the system, or antagonists, inhibiting it. Acetylcholine receptor agonists and antagonists can either have an effect directly on the receptors or exert their effects indirectly, e.g., by affecting the enzyme acetylcholinesterase, which degrades the receptor ligand. Agonists increase the level of receptor activation; antagonists reduce it.\nAcetylcholine itself does not have therapeutic value as a drug for intravenous administration because of its multi-faceted action (non-selective) and rapid inactivation by cholinesterase. However, it is used in the form of eye drops to cause constriction of the pupil during cataract surgery, which facilitates quick post-operational recovery.\nNicotinic receptors.\nNicotine binds to and activates nicotinic acetylcholine receptors, mimicking the effect of acetylcholine at these receptors. ACh opens a Na+ channel upon binding so that Na+ flows into the cell. This causes a depolarization, and results in an excitatory post-synaptic potential. Thus, ACh is excitatory on skeletal muscle; the electrical response is fast and short-lived. Curares are arrow poisons, which act at nicotinic receptors and have been used to develop clinically useful therapies.\nMuscarinic receptors.\nMuscarinic receptors form G protein-coupled receptor complexes in the cell membranes of neurons and other cells. Atropine is a non-selective competitive antagonist with Acetylcholine at muscarinic receptors.\nCholinesterase inhibitors.\nMany ACh receptor agonists work indirectly by inhibiting the enzyme acetylcholinesterase. The resulting accumulation of acetylcholine causes continuous stimulation of the muscles, glands, and central nervous system, which can result in fatal convulsions if the dose is high.\nThey are examples of enzyme inhibitors, and increase the action of acetylcholine by delaying its degradation; some have been used as nerve agents (Sarin and VX nerve gas) or pesticides (organophosphates and the carbamates). Many toxins and venoms produced by plants and animals also contain cholinesterase inhibitors. In clinical use, they are administered in low doses to reverse the action of muscle relaxants, to treat myasthenia gravis, and to treat symptoms of Alzheimer's disease (rivastigmine, which increases cholinergic activity in the brain).\nSynthesis inhibitors.\nOrganic mercurial compounds, such as methylmercury, have a high affinity for sulfhydryl groups, which causes dysfunction of the enzyme choline acetyltransferase. This inhibition may lead to acetylcholine deficiency, and can have consequences on motor function.\nRelease inhibitors.\nBotulinum toxin (Botox) acts by suppressing the release of acetylcholine, whereas the venom from a black widow spider (alpha-latrotoxin) has the reverse effect. ACh inhibition causes paralysis. When bitten by a black widow spider, one experiences the wastage of ACh supplies and the muscles begin to contract. If and when the supply is depleted, paralysis occurs.\nPhotopharmacological agents.\nPhotopharmacology is an emerging field that uses light to control the activity of biologically active compounds with high spatial and temporal precision. Recent advances have applied this approach to the cholinergic system, including photoactivatable agonists and antagonists of muscarinic and nicotinic acetylcholine receptors, as well as light-sensitive acetylcholinesterase inhibitors, that enable reversible and targeted modulation of cholinergic signaling upon irradiation. These light-regulated compounds, based on either photolabile protecting groups (\"caged\" ligands) or photoisomerizable scaffolds, offer unprecedented control over acetylcholine-mediated processes and represent promising tools for both basic research and potential therapeutic applications.\nComparative biology and evolution.\nAcetylcholine is used by organisms in all domains of life for a variety of purposes. It is believed that choline, a precursor to acetylcholine, was used by single celled organisms billions of years ago for synthesizing cell membrane phospholipids. Following the evolution of choline transporters, the abundance of intracellular choline paved the way for choline to become incorporated into other synthetic pathways, including acetylcholine production. Acetylcholine is used by bacteria, fungi, and a variety of other animals. Many of the uses of acetylcholine rely on its action on ion channels via GPCRs like membrane proteins.\nThe two major types of acetylcholine receptors, muscarinic and nicotinic receptors, have convergently evolved to be responsive to acetylcholine. This means that rather than having evolved from a common homolog, these receptors evolved from separate receptor families. It is estimated that the nicotinic receptor family dates back longer than 2.5 billion years. Likewise, muscarinic receptors are thought to have diverged from other GPCRs at least 0.5 billion years ago. Both of these receptor groups have evolved numerous subtypes with unique ligand affinities and signaling mechanisms. The diversity of the receptor types enables acetylcholine to create varying responses depending on which receptor types are activated, and allow for acetylcholine to dynamically regulate physiological processes. ACh receptors are related to 5-HT3 (serotonin), GABA, and Glycine receptors, both in sequence and structure, strongly suggesting that they have a common evolutionary origin.\nHistory.\nIn 1867, Adolf von Baeyer resolved the structures of choline and acetylcholine and synthesized them both, referring to the latter as \"acetylneurin\" in the study. Choline is a precursor for acetylcholine. Acetylcholine was first noted to be biologically active in 1906, when Reid Hunt (1870\u20131948) and Ren\u00e9 de M. Taveau found that it decreased blood pressure in exceptionally tiny doses. This was after Frederick Walker Mott and William Dobinson Halliburton noted in 1899 that choline injections decreased the blood pressure of animals.\nIn 1914, Arthur J. Ewins was the first to extract acetylcholine from nature. He identified it as the blood pressure-decreasing contaminant from some \"Claviceps purpurea\" ergot extracts, by the request of Henry Hallett Dale. Later in 1914, Dale outlined the effects of acetylcholine at various types of peripheral synapses and also noted that it lowered the blood pressure of cats via subcutaneous injections even at doses of one nanogram.\nThe concept of neurotransmitters was unknown until 1921, when Otto Loewi noted that the vagus nerve secreted a substance that inhibited the heart muscle whilst working as a professor in the University of Graz. He named it \"vagusstoff\" (\"vagus substance\"), noted it to be a structural analog of choline and suspected it to be acetylcholine. In 1926, Loewi and E. Navratil deduced that the compound is probably acetylcholine, as vagusstoff and synthetic acetylcholine lost their activity in a similar manner when in contact with tissue lysates that contained acetylcholine-degrading enzymes (now known to be cholinesterases). This conclusion was accepted widely. Later studies confirmed the function of acetylcholine as a neurotransmitter.\nIn 1936, H. H. Dale and O. Loewi shared the Nobel Prize in Physiology or Medicine for their studies of acetylcholine and nerve impulses.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52652", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=52652", "title": "NIH (disambiguation)", "text": "NIH is the National Institutes of Health in the United States.\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nNIH may also refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "52653", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=52653", "title": "Squash (sport)", "text": "Racket sport\nSquash, sometimes called squash rackets, is a racket sport played by two (singles) or four players (doubles) in a four-walled court with a small, hollow, rubber ball. The players alternate striking the ball with their rackets, directing it onto the playable surfaces of the four walls of the court. The object of the game is to hit the ball in such a way that the opponent is not able to play a valid return. There are about 20 million people who play squash regularly worldwide in over 185 countries. The governing body of squash, World Squash, is recognized by the International Olympic Committee, and the sport will be included in the Olympic Games, starting in the 2028 Summer Olympics in Los Angeles. The Professional Squash Association (PSA) organizes the pro tour.\nHistory.\nSquash has its origins in the older game of rackets, which was played in London's prisons in the 19th century. Later, around 1830, boys at Harrow School noticed that a punctured ball, which \"squashed\" on impact with the wall, offered more variety to the game. The game spread to other schools. The first courts built at Harrow were dangerous because they were near water pipes, buttresses, chimneys, and ledges. Natural rubber was the preferred material for the ball. Students modified their rackets to have a smaller reach and improve their ability to play in these cramped conditions. In 1864, the school built four outside courts.\nIn the 20th century, the game increased in popularity with various schools, clubs and private individuals building squash courts, but with no set dimensions. The first squash court in North America was built at St. Paul's School in Concord, New Hampshire, in 1884. In 1904 in Philadelphia, Pennsylvania, the earliest national association of squash in the world, the United States Squash Racquets Association, now known as U.S. Squash, was formed. In April 1907, the Tennis, Rackets &amp; Fives Association of Queens, New York, which regulated those three sports (fives being a similar sport using hands instead of a racket), established a subcommittee to set standards for squash. In 1912, the association published rules for \"squash\", combining aspects of these three sports.\nIn 1912, the RMS \"Titanic\" featured a squash court in first class, available for 8 pence (\u00a37.75 as of 2025 terms). The 1st-Class Squash Court was situated on G-Deck. The Spectators Viewing Gallery was one level higher, on F-Deck. Passengers could use the court for one hour unless others were waiting.\nIn 1923, the Royal Automobile Club hosted a meeting to further discuss the rules and regulations. Five years later, the Squash Rackets Association, now known as England Squash, was formed to set standards for the game in Great Britain and internationally.\nThe rackets were made from one piece of English ash, with a suede leather grip and natural gut stringing.\nThe 1980s witnessed a period of restructuring and consolidation. The Cambridge rackets factory was forced to close in face of the move to graphite rackets, and production was moved to East Asia. Customization of squash rackets has grown over the years as well. There are custom variations on racket head shape, racket balance, and racket weight. The most common racket variation for international singles squash is a teardrop (closed throat) head shape, even balance, and racket weight of 130g. For hardball doubles, the most common variation is an open throat head shape, even balance, and racket weight of 140g.\nThere are several variations of squash played across the world, although the international version of the sport has become the dominant form. In the United States, a variant of squash known as hardball was traditionally played with a harder ball and differently sized courts. Hardball squash has lost much of its popularity in North America (in favor of the international version). Doubles squash is a variant played by four players. There is a tennis-like variation of squash known as squash tennis. Finally, \"racketball\", similar to racquetball but played on a squash court, has been rebranded as Squash 57 by the World Squash Federation.\nEquipment.\nRacket.\nSquash rackets have maximum dimensions of 686\u00a0mm (27.0\u00a0in) long and 215\u00a0mm (8.5\u00a0in) wide, with a maximum strung area of 500 square centimeters (77.5\u00a0sq\u00a0in). The permitted maximum weight is , but most have a weight between 90 and 150\u00a0grams (3\u20135.3\u00a0oz.). The strings of the racket usually have a tension of 25\u201330 pounds.\nBall.\nSquash balls are between 39.5 and 40.5\u00a0mm in diameter and weigh 23 to 25\u00a0grams. They are made with two pieces of rubber plastic compound, glued together to form a hollow sphere and buffed to a matte finish. Different balls are provided for varying temperature and atmospheric conditions and standards of play: more experienced players use slow balls that have less bounce than those used by less experienced players (slower balls tend to \"die\" in court corners, rather than \"standing up\" to allow easier shots). Squash balls must be hit dozens of times to warm them up at the beginning of a session; cold squash balls have very little bounce. Small colored dots on the ball indicate its dynamic level (bounciness). \nThe \"double-yellow dot\" ball, introduced in 2000, is the competition standard, replacing the earlier \"yellow-dot\" ball. There is also an \"orange dot\" ball for use at high altitudes. The recognized colors are:\nSome ball manufacturers such as Dunlop use a different method of grading balls based on experience. They still have the equivalent dot rating but are named to help choose a ball that is appropriate for one's skill level. The four different ball types are Intro (Blue dot, 140% of Pro bounce), Progress (Red dot, 120% of Pro bounce), Competition (single yellow dot, 110% of Pro bounce) and Pro (double yellow dot).\nMany squash venues mandate the use of shoes with non-marking tread and eye protection. Some associations require that all juniors and doubles players must wear eye protection. The National Institutes of Health recommends wearing goggles with polycarbonate lenses.\nCourt.\nThe squash court is a playing surface surrounded by four walls. The court surface contains a front line separating the front and back of the court and a half court line, separating the left and right sides of the back portion of the court, creating three 'boxes': the front half, the back left quarter and the back right quarter. The back two boxes contain smaller service boxes.\nThe court's four walls are divided into a front wall, two side walls, and a back wall. An 'out line' runs along the top of the front wall, descending along the side walls to the back wall. The bottom line of the front wall marks the top of the 'tin', a half meter-high metal area. The middle line of the front wall is the service line. The dimensions of the court are:\nNorth American hardball doubles courts are larger than international singles courts because of a hard ball that has a much faster pace. With double the number of players, the doubles court needs to be significantly larger than a singles court. Doubles courts measure wide by long and have a ceiling height of at least .\nManner of play.\nService.\nThe players spin a racket to decide who serves first. This player starts the first rally by electing to serve from either the left or right service box. For a legal serve, one of the server's feet must be in the service box, not touching any part of the service box lines, as the player strikes the ball. After being struck by the racket, the ball must strike the front wall above the service line and below the out line and land in the opposite back quarter court. The receiving player can choose to volley a serve after it has hit the front wall or may let it bounce. If the server wins the point, the two players switch sides for the following point. If the server loses the point, the opponent then serves, and can serve from either box.\nPlay.\nAfter the serve, the players take turns hitting the ball against the front wall, above the tin and below the out line. The ball may strike the side or back walls at any time, as long as it hits below the out line. It must not hit the floor after hitting the racket and before hitting the front wall. A ball landing on either the out line or the line along the top of the tin is considered to be out. After the ball hits the front wall, it is allowed to bounce once on the floor (and any number of times against the side or back walls) before a player must return it. Players may move anywhere around the court, but accidental or deliberate obstruction of the other player's movements is forbidden and could result in the point being redone or given to the player being obstructed. Players typically return to the centre of the court after making a shot, as it is the optimal position in the court to receive the opponent's shot. The centre of the court is typically referred to as \"the T\", named after the shape of the floor lines.\nGeneral strategy and tactics.\nA key idea in squash is known as \"dominating the T\" (the intersection of the red lines near the centre of the court, shaped like the letter \"T\", where the player is in the best position to retrieve the opponent's next shot). Skilled players will return a shot, and then move back toward the \"T\" before playing the next shot. From this position, the player can quickly access any part of the court to retrieve the opponent's next shot with a minimum of movement and possibly maximizing the movement required by the opponent to answer the returned shot. Very skilled players will, oftentimes, shift slightly away from the \"T,\" based on the position of the other player, if they believe that their shot selection is limited.\nA common tactic is to hit the ball straight up the side walls to the back corners; this is the basic squash shot, referred to as a \"rail\", straight drive, wall, or \"length\". After hitting this shot, the player will then move to the centre of the court near the \"T\" to be well placed to retrieve the opponent's return. Attacking with soft or \"short\" shots to the front corners (referred to as \"drop shots\") causes the opponent to cover more of the court and may result in a winner. Boasts or angle shots are deliberately struck off one of the side walls before the ball reaches the front. They are used for deception and again to cause the opponent to cover more of the court. Rear wall shots float to the front either straight or diagonally drawing the opponent to the front. One goal of a player is to try to move the opponent into each of the four corners so that they have to cover a lot of distance and will get tired. Advantageous tactical shots are available in response to a weak return by the opponent if stretched, the majority of the court being free to the striker. Nicks are when the ball comes into contact with the intersection of the floor and any sidewall.\nRallies between experienced players may involve 30 or more shots and therefore a very high premium is placed on fitness, both aerobic and anaerobic. As players become more skilled and, in particular, better able to retrieve shots, points often become a war of attrition. At higher levels of the game, the fitter player has a major advantage.\nThe ability to change the direction of the ball at the last instant is also a tactic used to unbalance the opponent often called \"holding.\" Expert players can anticipate the opponent's shot a few tenths of a second before the average player, giving them a chance to react sooner.\nDepending on the style of play, it is common to refer to squash players as\nInterference and obstruction.\nInterference and obstruction are an inevitable aspect of squash, since two players are confined within a shared space. Generally, the rules entitle players to a direct straight-line access to the ball, room for a reasonable swing and an unobstructed shot to any part of the front wall. When interference occurs, a player may appeal for a \"let\" and the referee (or the players themselves if there is no official) then interprets the extent of the interference. The referee may allow a let and the players then replay the point or award a \"stroke\" to the appealing player (meaning that he is declared the winner of that point) depending on the degree of interference, whether the interfering player made an adequate effort to avoid interfering, and whether the player interfered with was likely to have hit a winning shot had the interference not occurred. An exception occurs when the interfering player is directly in the path of the other player's swing, effectively preventing the swing, in which case a stroke is always awarded.\nWhen it is deemed that there has been little or no interference, the rules provide that no let is to be allowed in the interests of continuity of play and the discouraging of spurious appeals for lets. Because of the subjectivity in interpreting the nature and magnitude of interference, awarding (or withholding) of lets and strokes is often controversial and professional players will get \"reviews\" where a different referee will review the footage and make a decision. If the review is successful than the player will get their review back but if the review is unsuccessful they lose their review.\nInterference also occurs when a player's shot hits their opponent prior to hitting the front wall. If the ball was travelling towards the side wall when it hit the opponent, or if it had already hit the side wall and was travelling directly to the front wall, it is usually a let. However, it is a stroke to the player who hit the ball if the ball was travelling straight to the front wall when the ball hit the opponent, without having first hit the side wall. Generally, after a player has been hit by the ball, both players stand still; if the struck player is standing directly in front of the player who hit the ball, he loses the stroke; if he is not straight in front, a let is played. If it is deemed that the player who is striking the ball is deliberately trying to hit his opponent, they will lose the stroke. An exception occurs when the player hitting the ball has \"turned\", i.e., letting the ball pass them on one side, but then hitting it on the other side as it came off the back wall. In these cases, the stroke goes to the player who was hit by the ball.\nReferee.\nThe referee is usually a certified position issued by the club or assigned squash league. Any conflict or interference is dealt with by the referee. The referee may also take away points or games due to improper etiquette regarding conduct or rules. Improper etiquette may include swearing, purposeful physical contact, and throwing equipment. The referee is also usually responsible for the scoring of games. Three referees are usually used in professional tournaments. The Central referee has responsibility to call the score and make decisions with the two side referees.\nScoring system.\nPoint-a-Rally to 11.\nGames are played according to point-a-rally scoring (PARS) to 11 points. PARS is almost universally preferred by the game's top professionals and is the current official scoring system for all levels of professional squash tournaments. In PARS, the winner of a rally receives a point, regardless of whether they were the server or returner. Games are played to 11 and must be won by two points. That is, if the score reaches 10\u201310, play continues until one player wins by two points. Competition matches are usually played to \"best-of-five\" games (i.e., the first player to win three games).\nSquash can also be played with different scoring systems, such as PARS to 15, traditional English or Hand-in-Hand-Out (HiHo) scoring to 9, or RAM scoring (see below). Players often experience PARS and Hi-Ho as requiring different tactics and player attributes.\nOther scoring systems.\nPoint-a-Rally to 15.\nPoint-a-rally scoring to 15 was used for the World Championships between 1989 and 2003. PARS to 15, with the tiebreak being two clear points (as per standard PARS) from 14\u201314, was used in many amateur leagues because PARS to 11 was considered too short. This system fell out of favor in 2004 when the Professional Squash Association (PSA) decided to switch to PARS to 11. Games were considered to last too long and the winner would usually be the fitter player, not necessarily the better player.\nEnglish/Hand-In-Hand-Out to 9.\nKnown as English or hand-in-hand-out scoring, under this system, if the server wins a rally, they receive a point, while if the returner wins rally, only the service changes (i.e., the ball goes \"hand-out\") and no point is given. The first player to reach nine points wins the game. However, if the score reaches 8\u20138, the player who was first to reach eight decides whether the game will be played to nine, as before (called \"set one\"), or to 10 (called \"set two\"). This scoring system was formerly preferred in Britain, and also among countries with traditional British ties, such as Australia, Canada, Pakistan, South Africa, India and Sri Lanka.\nRAM.\nThe RAM scoring system is a proposed new scoring system created by former World Champion, Ramy Ashour and co-founded by Osama Khalifa. This consists of playing a best of five games. Each game is three minutes long; however, this only refers to the three minutes in play. The 'downtime' in between the end of a rally and a serve is not counted. Once the time is up, the clock stops, and the leading player needs to win a final point. If the player who is behind wins the point the game continues until the trailing player catches up and wins one more point than the initially leading player.\nFor example, Player one is leading 5\u20133 and the clock stops. Player two wins the next two points and the score is 5\u20135. Whoever wins the next point wins the game. This is called sudden death. If the score is 0\u20130 when the clock stops the clock is reset and the game restarts. For Let Calls the clock reverts to the start time of that point. Further rules include that there must be a referee and a time keeper to make this match official. Players have two minutes of rest between games, and all other standard PSA and WSF rules apply.\nTransition from English/HiHo to PARS 11.\nIn 2004, the Professional Squash Association (PSA) decided to switch to PARS 11. This decision was ratified in 2009 when the World Squash Federation confirmed the switch to the PARS 11 scoring system. Since that time, almost all professional and league games have been played according to PARS to 11. One of the reasons for switching to PARS was that long, taxing matches became less frequent and promoters could more easily predict match and session length. Gawain Briars, who served as the Executive Director of the Professional Squash Association when the body decided to switch to PARS in 2004 hoped that PARS would make the \"professional game more exciting to watch, [and] then more people will become involved in the game and our chances of Olympic entry may be enhanced.\"\nOne of the problems with English or Hi-Ho scoring is that games often last longer as players continually win service before losing service to the other player without the score being affected. Consequently, the winner is more often than not the fitter athlete. Moreover, English or Hi-Ho scoring can encourage players to play defensively with the aim of wearing down one's opponent before winning by virtue of one's fitness. Such exhausting, defensive play can affect player's prospects in knock-out tournaments and does not make for riveting TV. In English or Hi-Ho, one player might win by 9\u20130 despite the opponent having repeatedly won service, but without converting that service into actual points.\nFor the World Championships: HiHo to 9 was used until 1988; PARS to 15 from 1989 to 2003; and PARS to 11 from 2004. For the British Open: HiHo to 9 was used until 1994; PARS to 15 from 1995 to 2003; and PARS to 11 from 2004.\nThe WSF's decision to switch to PARS 11 proved controversial in the United Kingdom and Commonwealth where games were usually played according to English or Hi-Ho. When the Veterans Squash Rackets Club of Great Britain surveyed their members in 2012, they found that 80% of their members were against switching from HiHo to PARS. President Philip Ayton argued that PARS would \"kill the essence of the game.\" Ayton was particularly concerned that the \"great comebacks\" that characterised English or Hi-Ho when \"the player who is down in a game can still attack when in hand serving\" would disappear as PARS fostered an \"ultra-defensive attitude, because every rally counts the same.\"\nJahangir Khan has countered that PARS actually made the game far more attacking, but diminished the psychological aspect of the game: \"With the nine points scoring system, matches were more mental and physical and could go longer, but now with the 11-point system, every rally counts, and even if you go behind you can still recover. That makes it a lot more attacking.\" Maj Madan, one of the game's top referees, similarly stated that PARS had \"destroyed the fitness element and, more importantly, the cerebral magic of the\u2026game.\" His comments were unearthed when an email chain of referees discussing the problem of shorter and shorter squash matches was leaked in 2011.\nContribution to health.\nSquash provides an excellent cardiovascular workout. Players can expend approximately 600\u20131,000 food calories (3,000\u20134,000 kJ) every hour playing squash, according to English or Hi-Ho scoring. The sport also provides a good upper- and lower-body workout by exercising both the legs in running around the court and the arms (especially the racket arm) and torso in swinging the racket. In 2003, \"Forbes\" rated squash as the number-one healthiest sport to play. However, one study has implicated squash as a cause of possible fatal cardiac arrhythmia and argued that squash is an inappropriate form of exercise for older men with heart disease.\nAround the world.\nAs of November 2019, there were players from eighteen countries in the top fifty of the men's world rankings, with Egypt dominating with fifteen players, six of whom were in the top ten, including ranks one through four. Similarly, the women's world rankings featured players from sixteen countries, again led by Egypt taking thirteen spots of the top fifty, whilst holding spots one through four in the world.\nThe men's and women's Professional Squash Association tour, men's rankings and women's rankings are run by the Professional Squash Association (PSA).\nThe Professional Squash Tour is a tour based in the United States.\nInclusion in multi-sport events.\nSquash has been featured regularly at the multi-sport events of the World Games, Commonwealth Games and Asian Games since 1998. Squash is also a regular sport at the Pan American Games since 1995. Squash players and associations have lobbied for many years for the sport to be accepted into the Olympic Games. Squash narrowly missed being instated for the 2012 London Games and the 2016 Rio de Janeiro Games (missed out again as the IOC assembly decided to add golf and rugby sevens to the Olympic programme). Squash also was not selected as an event in the 2020 Olympic Games. At the 125th IOC Session in Buenos Aires, the IOC voted for Wrestling instead of Squash or Baseball/Softball. The usual reason cited for the failure of the sport to be adopted for Olympic competition is that it is difficult for spectators to follow the action, especially via television. Previous world number one Peter Nicol stated that he believed squash had a \"very realistic chance\" of being added to the list of Olympic sports for the 2016 Olympic Games, but it ultimately lost out to golf and rugby sevens. Squash has been part of the World Games since 1997.\nSquash was accepted as a demonstration sport for the 2018 Summer Youth Olympics. The World Squash Federation had hoped that this inclusion would create a strong bid for a potential inclusion at the 2024 Summer Olympics.\nAlthough not included in the 2024 Summer Olympics, squash received approval from the International Olympic Committee for inclusion in the 2028 Summer Olympics in Los Angeles, on 16 October 2023.\nPlayers, records and rankings.\nThe (British) Squash Rackets Association (now known as England Squash) conducted its first British Open championship for men in December 1930, using a \"challenge\" system. Charles Read was designated champion in 1930, but he was beaten in home and away matches by Don Butcher, who was then recorded as the champion for 1931. The championship continues to this day, but it has been conducted with a \"knockout\" format since 1947.\nThe women's championship started in 1921, and it has been dominated by relatively few players: Joyce Cave, Nancy Cave, Cecily Fenwick (England) in the 1920s; Margot Lumb and Susan Noel (England) in the 1930s; Janet Morgan (England) in the 1950s; Heather McKay (Australia) in the 1960s and 1970s; Vicki Cardwell (Australia) and Susan Devoy (New Zealand) in the 1980s; Michelle Martin and Sarah Fitz-Gerald (Australia) in the 1990s; and Nicol David (Malaysia) in the 2000s.\nThe Men's British Open has similarly been dominated by relatively few players: F. D. Amr Bey (Egypt) in the 1930s; Mahmoud Karim (Egypt) in the 1940s; brothers Hashim Khan and Azam Khan (Pakistan) in the 1950s and 1960s; Jonah Barrington (Great Britain and Ireland) and Geoff Hunt (Australia) in the 1960s and 1970s; Jahangir Khan (Pakistan) 1980s; Jansher Khan (Pakistan) in the 1990s; and more recently, David Palmer and Nick Matthew.\nThe World Open professional championship was inaugurated in 1976 and serves as the main competition today. Jansher Khan holds the record of winning eight World titles followed by Jahangir Khan with six, Geoff Hunt &amp; Amr Shabana four, Nick Matthew &amp; Ramy Ashour three. The women's record is held by Nicol David with eight wins followed by Sarah Fitzgerald five, Susan Devoy four, and Michelle Martin three.\nHeather McKay remained undefeated in competitive matches for 19 years (between 1962 and 1981) and won sixteen consecutive British Open titles between 1962 and 1977.\nCurrent rankings.\nThe Professional Squash Association (PSA) publishes monthly rankings of professional players:\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52655", "revid": "14423536", "url": "https://en.wikipedia.org/wiki?curid=52655", "title": "Squash (plant)", "text": ""}
{"id": "52656", "revid": "1026738133", "url": "https://en.wikipedia.org/wiki?curid=52656", "title": "Radiogenic", "text": ""}
{"id": "52657", "revid": "3145267", "url": "https://en.wikipedia.org/wiki?curid=52657", "title": "Madam Curie", "text": ""}
{"id": "52659", "revid": "9021902", "url": "https://en.wikipedia.org/wiki?curid=52659", "title": "Albert Brudzewski", "text": "Polish academic and diplomat (c. 1445 - c. 1497)\nAlbert Brudzewski, also known as Albert Blar (of Brudzewo), Adalbertus,Albert of Brudzewo or Albert of Brudzew (: ; c.1445\u2013c.1497) was a Polish astronomer, philosopher and diplomat. A major accomplishment of Albert's was his modernization of the teaching of astronomy by introducing the most up-to-date texts. He was an influential teacher to Nicolaus Copernicus, who initiated the Copernican Revolution.\nLater in his life he was secretary and diplomat of Alexander Jagiellon, Grand Duke of Lithuania.\nLife.\nAlbert (), who would sign himself \"de Brudzewo\" (\"of Brudzewo\"), was born about 1445 in the city of Brudzew or Brudzewo, in the Kingdom of Poland.\nHe matriculated at the Krak\u00f3w Academy (now Jagiellonian University), where he earned his bachelor degree in 1470 and a master in 1474. Brudzewski was a student of Micha\u0142 Falkener in physical sciences and of John of G\u0142og\u00f3w in mathematics. Brudzewski may have also been a disciple of German astronomer Regiomontanus at the University of Vienna. Brudzewski was well versed in Georg von Peuerbach's \"Theoricae novae planetarum\" and Regiomontanus' \"Tabulae directionum\" and \"Ephemerides\".\nHe drew up tables for calculating the positions of heavenly bodies. In 1482 he wrote a \"Commentariolum super Theoricas novas\" \u2014 a commentary on Peuerbach's text, which was published in Milan in 1495. Peuerbach noted that Mercury does not describes a perfect circle but an oval-shaped orbit. Brudzewski in his 1482 commentary remarks that the Moon follows a similar orbit, as it always shows its same side to the Earth. As previously done by Sandivogius of Czechel, Brudzewski added a secondary epicycle to explain the motion of the Moon.\nBrudzewski also considered that the motion of the planets was influenced by the Sun as their source of power.\nOther works include \"Introductorium Astronomorum Cracoviensium;Tabula resoluta Astronomic pro supputandis motibus corporum c\u0153lestium\" and \"De Constructone Astrolabii.\"\nTeaching.\nBrudzewski is also remembered as a remarkable teacher. Filippo Buonaccorsi (Callimachus) wrote in a letter:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Everything created by the keen perceptions of Euclides and Ptolemaeus, [Brudzewski] made a part of his intellectual property. All that remained deeply hidden to lay eyes, he knew how to set before the eyes of his pupils\nAt the Krak\u00f3w Academy he impressed students by his extraordinary knowledge of literature, and taught mathematics and astronomy. From 1489 to 1491, German poet and Renaissance humanist, Conrad Celtes traveled to Poland to meet and learn astrology from Brudzewski. They became friends and exchanged letters even after Celtes departure.\nBrudzewski lectured on arithmetic, optics, Peuerbach astronomy and Mashallah ibn Athari works. In 1490, he earned a bachelor in theology, and from then onwards he lectured only on Aristotle's philosophy and his work \"On the Heavens\". These lectures were attended by Nicolaus Copernicus, who enrolled at the academy from 1491 to 1495. It is possible that Brudzewski also discussed other topics with Copernicus privately. Cartographer and friend of Copernicus Bernard Wapowski also studied under Brudzewski.\nDepart to Vilnius.\nIn 1494, Brudzewski left Krakow. In Vilnius, he engaged as secretary at the service of the Grand Duke of Lithuania Aleksander Jagiellon, who would later become King of Poland after the death of Brudzewki. It was in Vilnius that Albert wrote his treatise, \"Conciliator\", the original of which has not yet been found.\nAlbert of Brudzewo died in Vilnius circa 1497.\nViews and contributions.\nOn Averroes.\nBrudzewski was seen as influential and persuasive astronomer, a fictionalist, and an opponent of Middle Ages Andalusian scholar Averroes (Ibn Rushd). Averroes disagreed with the majority of the astronomer Ptolemy's work. He believed that Ptolemy's devices and principles disobeyed the fundamental principles and basic consequences of Aristotelian physics. Averroes worked to replace the Ptolemaic astronomical system with a novel system that was similar to a system created by Eudoxus. Albert Brudzewski disagreed and criticized Averroes immediately. The major dispute was the figuring out the number of celestial orbs or spheres that lay in the heavens. Averroes refused to believe that there was a ninth sphere in the heavens. He believed that the creation of all celestial beings had to arise from the stars, but the ninth sphere did not possess any stars, so this could not be true. Albert Brudzewski argued with this and said that the heavens possessed more than ten spheres. He believed that the Sun itself had three spheres and the planets had their own as well.\nTo make sense and clarify to his followers, Brudzewski said that the terms 'orb' or 'sphere' had three meanings of interpretation. The first meaning could be the whole entire heavens was designated into a single object which was the orb or sphere. This object was not separate from the whole heavens yet it could exist by itself. The second meaning he paralleled it to the sphere or orb from Peurbach's \"Theoricae novae planetarum\" although it was unconventional, it still existed in the heavens. The third meaning or clarification of orb was an orb that was aligned with the Earth. The third meaning was actually a collection of orbs that was crucial to the motion of a planet.\nBrudzewski further disputes Averroes by depending on the assumptions of Aristotle. He said that Aristotle demonstrated and verified five claims about the heavens that could disprove Averroes. The first claim was that the heavens was a simple being. The second claim was that because the heavens was a simple being, the motion of the being also had to be simple and uncomplicated. There could only be one motion and it had to follow the laws of nature. The third claim was that any motion that did not follow the laws of nature had to have an addition motion that did follow the laws of nature. The fourth claim was that a single sphere or orb could not be moved by several motions because it was a simple body. The fifth claim was that any superior or greater orb could have an impact on lesser orbs and spheres but the lesser orbs and spheres could not have any leverage on the superior's ones.\nTo finally disprove Averroes, Brudzewski mentions the three recognizable motions of the sphere of fixed stars. The first motion was that the sphere possessed a daily rotation that occurred from the East to the West. The second motion was movement of the sphere in the opposition direction from West to East. The third motion was a cyclical motion that Brudzewski named trepidation. Brudzewski gave these three motions to the last three spheres respectively. With the assumptions of Aristotle as well as the motions of the sphere of the fixed stars, Brudzewski is able to prove that Averroes is wrong about the number of celestial spheres in the heavens.\nOn the heavens and planetary motion.\nAlbert Brudzewski was known as a fictionalist. He did not think that the motions of the heavens were understood by any human. Richard of Wallingford, an astronomer in the 1300s, had an opposing view for the spheres of the planets. He claimed that no mortal knows whether eccentrics truly exist in the spheres of the planets, but spirits could give humans revelations about the true planetary motion of the heavens through mathematicians. This claim limits the astronomical knowledge of mortals and suggests that spirits do not have the same limitations. Brudzewski acknowledges the existence of these viewpoints but criticized their validity. To astronomers, spirits had an accurate knowledge of the number of celestial orbs. Although, he did not want to discredit the ability of mortals to make claims based on astronomical observations. Brudzewski made the claim for the fundamental principle of astrology that the heavens exert causal influences on the Earth.\nThe paths of planets were thought to be moved by orbs instead of circles. This was a claim by Brudzeski about causal relationships between the planets and their motion. With this view, he disagreed with Averroes about the number of orbs, the concept of epicycles and eccentric circles, and on theoretical orbs. Brudzewski was seen as a source for some of Copernicus's work on orbs, specifically with the Tusi couple.\nTusi couple.\nThe Tusi couple was known as an epicycle arrangement that creates straight line motion of the planets, created by Copernicus. Some think that Brudzewski is the source for Copernicus's model of the Tusi couple. Albert does account for the moon and its double epicycles where he mentions a spot on the moon. The spot on the Moon is the problem of explaining the appearance of the face of the Moon when always viewing the Earth. These views were not aligned with the Tusi couple. Although, it is speculated that Copernicus could have encountered such a model, where the primary epicycle carries the center of a second epicycle. This is not the Tusi couple, but it could be slightly changed to match its model. The spot on the moon that is always viewed from the Earth would not appear if there was no epicyclical motion of the moon. The motion of the moon was termed as prosneusis motion which was part of the lunar theory. This motion means motion of inclination and turning, which corresponds to the single epicycle in Ptolemy's theory of the moon, and the two epicycles in Brudzewski's model.\nBrudzewski was aware of the possibility of linear motions from circular motions based on his model of Mercury's motion. This could be an alternative way that Copernicus generated his idea of linear motion for the Tusi couple. Although it seems that Copernicus used Albert's ideas, he highly relied on Islamic sources for the Tusi couple. Copernicus's parameters for the moon are exactly the same as those of Ibn al-Shatir. It is unclear where Copernicus truly got his ideas.\nOn philosophy.\nBrudzewski was nominalist, but defended humanism. Along with Cracow Academy, Brudzewski sided with the advocates of philosophical realism in the defense of scholasticism.\nIn popular culture.\nA fictionalized version of Albert Brudzewski is the protagonist of the final part of the 2020 manga series \"\", which was adapted into an anime in 2024.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52662", "revid": "36188177", "url": "https://en.wikipedia.org/wiki?curid=52662", "title": "65 BC", "text": "Calendar year\n \nThe year 65 BC was a year of the pre-Julian Roman calendar. At the time, it was known as the Year of the Consulship of Cotta and Torquatus (or, less frequently, the year 689 \"Ab urbe condita\"). The denomination 65 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nWestern Han Empire.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52663", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=52663", "title": "64 BC", "text": "Calendar year\n \nYear 64 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Caesar and Figulus (or, less frequently, year 690 \"Ab urbe condita\"). The denomination 64 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nSyria.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52664", "revid": "47610170", "url": "https://en.wikipedia.org/wiki?curid=52664", "title": "Racket (sports equipment)", "text": "Sports equipment used to strike ball or shuttlecock\nA racket or racquet is an item of sporting equipment used to strike a ball or shuttlecock in a variety of sports. A racket consists of three major components: a widened distal end known as the \"head\", an elongated handle known as the \"grip\", and a reinforced connection between the head and handle known as the \"throat\" or \"heart\". The head of the racket forms a flattened firm surface, known as the \"face\", which is used to strike the ball or shuttlecock.\nIn the strictest sense, the word \"racket\" specifically refers to a striking implement with a mesh face made of interlaced, tightly stretched strings fixed on an ovoid frame known as the \"rim\". This type of racket is used in sports such as tennis, badminton, and racquetball. Some rackets have a rigid one-piece head with a solid or fenestrated face instead of a meshwork of strings. Such rackets are called a paddle or bat, and are used in sports such as table tennis, pickleball and padel. Collectively, sporting games using rackets and paddles are all known as racket sports.\nRacket design, materials and manufacturing has changed considerably over the centuries. The frame of rackets for all sports was traditionally made of solid wood (later laminated wood) and the strings of animal intestine known as catgut. The traditional racket size was limited by the strength and weight of the wooden frame which had to be strong enough to hold the strings and stiff enough to hit the ball or shuttle. Manufacturers started adding non-wood laminates to wood rackets to improve stiffness. Non-wood rackets were made first of steel, then of aluminium, and then carbon fiber composites. Wood is still used for real tennis, rackets, and xare. Most rackets are now made of composite materials including carbon fiber or fiberglass, metals such as titanium alloys, or ceramics.\nCatgut has been partially replaced by synthetic materials including nylon, polyamide, and other polymers. Rackets are restrung when necessary, which may be after every match for a professional. Despite the name, \"catgut\" has never been made from any part of a cat.\nSpelling.\n\"Racket\" is the standard American spelling of the word. \"Racquet\" is an alternative spelling more common in Britain, as evidenced by the BBC style guide. \"Racquet\" is used more commonly in certain sports, such as tennis, squash, racquetball, and badminton, and less commonly in others. However, the International Tennis Federation uses \"racket\", which is the original spelling; dating from the 16th century. \"Racquet\" appeared in the 19th century as a French-influenced variant of \"racket\".\nEtymology.\nThe origin of the term \"racket\" is unclear. It may be derived from the Flemish word \"raketsen\" which is itself derived from Middle French \"rachasser\", meaning \"to strike (the ball) back\".\nBadminton.\nBadminton rackets are light, with top quality rackets weighing between about 70 and 95\u00a0 grams. Modern rackets are composed of carbon fiber composite (graphite reinforced plastic), which may be augmented by a variety of materials. Carbon fiber has an excellent strength to weight ratio, is stiff, and gives excellent kinetic energy transfer. Before the adoption of carbon fiber composite, rackets were made of wood to their excessive weight and cost.\nThere is a wide variety of racket designs, although the badminton racket size and shape are limited by the laws of the game. Different rackets have playing characteristics that appeal to different players. The traditional oval head shape is still available, but an isometric head shape is increasingly common in new rackets.\nVarious companies have emerged but Yonex of Japan, Victor of Taiwan, China and Li-Ning of China are the dominant players in the market. The majority of top tournaments are sponsored by these companies. Every year new technology is introduced by these companies but predominantly, all rackets are made of carbon graphite composite.\nRackets or Racquets.\nThis sport, which is the predecessor to the modern game of squash, rackets, is played with wooden rackets. While squash equipment has evolved in the intervening century, rackets equipment has changed little.\nRacquetball.\nAccording to the current racquetball rules there are no limitations on the weight of a racquetball racket.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;#The racket, including bumper guard and all solid parts of the handle, may not exceed 22 inches in length.\nRacquetball rackets, unlike many other types, generally have little or no neck, the grip connecting directly to the head. They also tend to have head shapes that are notably wider at the top, with some older rackets looking almost triangular or teardrop shaped.\nReal tennis.\nIn real tennis, also called court tennis, 27-inch (686-mm) long rackets are made of wood and very tight strings to cope with the game's heavy balls. The racket heads are bent slightly to make striking balls close to the floor or in corners easier.\nSquash.\nStandard squash rackets are governed by the rules of the game. Traditionally they were made of laminated timber (typically Ash), with a small strung area using natural gut strings. After a rule change in the mid-1980s, they are now almost always made of composite materials such as carbon fiber or metals (graphite, Kevlar, titanium, and/or boron) with synthetic strings. Modern rackets are 70\u00a0cm long, with a maximum strung area of 500 square centimetres (approximately 75 square inches) and a mass between 90 and 200\u00a0grams (4\u20137 ounces).\nTable tennis.\nTable tennis uses a table tennis racket made from laminated wood covered with rubber on one or two sides depending on the grip of the player. Unlike a conventional racket, it does not contain strings strung across an open frame. This is called either a paddle, racket, or a bat, with usage differing by region. In the USA the term \"paddle\" is common, in Europe the term is \"bat\", and the official ITTF term is \"racket.\"\nTable Tennis racket specs are defined at the ITTF handbook section 2.04 and currently include the following.\nTennis.\nPopular lawn tennis rackets vary primarily in length, weight, balance point, stiffness, beam thickness, string pattern, string density, and head size. They generally conform to unofficial standards that differ from past rackets. Currently, almost all adult rackets are made from a graphite composite. Those made from wood (the original racket frame row material), steel, fiberglass, or aluminium are considered obsolete, although those materials are technically legal for play. Inexpensive rackets often have poor performance characteristics such as excessive flexibility and inadequate weight. No recent manufacturers use single-throated beams, although Prince tried to reintroduce the single throat design in the 1990s: the only professional who used one was Mirjana Lu\u010di\u0107. Braided graphite rackets were considered high-end until recently and molded rackets have been the norm for some time. Molding is less expensive to manufacture and offer high stiffness. Graphite-composite rackets are today's industry standard in professional tennis.\nFor length, is normally the junior racket range, while is for stronger more physically mature players. Some are also available at lengths of . The Gamma Big Bubba was produced with an length but it is no longer legal in that length. Gamma responded by changing the length of the grip portion of the racket, to continue sales. The length restriction was based on the concern that such long rackets would make the serve too dominant, but that concern has never been objectively supported with testing. Moreover, some players, such as John Isner, are much taller and have longer arms than average professionals (and especially low stature ones), giving them a much larger advantage in terms of height for the service than is possible with several inches of racket length. This makes the length restriction more questionable. Finally, the professionals who nearly always choose to use the longest rackets typically choose them because they use two-handed groundstrokes for both forehand and backhand, using the extra length to improve their reach. An example is Marion Bartoli. As this type of player is not dominant in the sport, or even close to being average in terms of per capita representation, the length restriction seems even more unnecessary. Despite Prince's attempt to market longer length \"longbody\" rackets in the 1990s, standard length remains the overwhelming choice of players, further negating the argument in favor of the length restriction. When most players who choose to use a longer racket than choose one, they typically only use a model, rather than one approaching . Longer rackets were introduced by Dunlop.\nThe weights of a racket ranges between unstrung and strung. Until the 1980s, rackets weighted at \"medium\" were produced. \"Heavy\" rackets were produced during the height of the wood era (e.g. the 1960s), very sparingly. The \"medium\" weight is heavier than any of the rackets produced since it was discontinued by companies. Many professionals added weight to their rackets to improve stability. Many continue to do so. Pete Sampras added lead tape to make his racket have a weight and Venus Williams is known for using a frame modified to be quite heavy, in terms of the recent times average. By contrast, Andy Roddick surprised many when he said he used a stock Pro Drive series model, series of racket which was light when compared with the rackets used by most top professionals. In both recreational and professional tennis, the trend has been away from heavy rackets and toward lighter rackets, despite the drawbacks from light rackets, such as increased twisting. Lawn tennis rackets originally flared outward at the bottom of the handle to prevent slippage. The rounded bottom was called a bark bottom after its inventor Matthew Barker. But by 1947, this style became superfluous. More mass gives rackets \"plow through\", momentum that continues once the player has managed to get the racket into motion and which is more resistant to stoppage from the ball's momentum. This can give the perception that the racket produces shots with more power, although this is complicated by the typically slower stroke production. Higher mass typically involves a slower swing but more energy to execute the swing. More mass also provides more cushioning against ball impact shock, a source of injuries such as tennis elbow. However, high racket mass can cause fatigue in the shoulder area. Typically, it is safer for the body to have higher mass. More mass, additionally, provides more stability. It makes the racket more resistant to twisting forces and pushback. The drawbacks are that heavier rackets have lower maneuverability (reducing reaction time) and require more energy to move. As a racket gets heavier, the player finds it increasingly difficult to do fast reaction shots such as quick volleys and returns of serve. However, the additional mass can help with return of serve, in particular, by making the racket much more resistant to twist from a high-powered service. Light rackets have the additional drawback of making it easier for beginning players to use inappropriate wrist-dominant strokes, which often leads to injury. This is because poor stroke mechanics can be much easier to produce with a lightweight racket, such as in using one's wrist to mostly swing the racket. An extremely typical mistake beginning players make is to choke up heavily on the racket (to try to compensate for twist from a light racket, as well as too high racket angle upon impact) and use the wrist too much. The only professional well-known player to have had success with a strongly choked-up grip is Zina Garrison.\nHead size plays a very key role in a racket's performance characteristics. A larger head size very generally means more power and a larger \"sweet spot\". This is an area in the string bed that is partially more forgiving on off-center hits and which produces more ball-reflective power from string deformation, known as the trampoline effect. However, large head sizes can increase twisting, which makes off-center hits more difficult to control and can reduce a player's overall power production due to the playing compensating for the extra inherent power, typically with stiffer strings to reduce the increased string deformation of large heads. A smaller head size generally offers more control for many shots, particularly the service and groundstrokes aimed near the lines, but can lead to more shanks (wild misses, from hitting the frame or missing the sweet spot). This drawback is most common for professional players using single-handed topspin backhands, as well as for recreational and aged players at net. Shanking due to small racket head size is typically exacerbated by racket weight, which slows the reaction time, as well as, to a lesser degree, the racket's balance point. In professional tennis, currently-used racket head sizes vary between , with most players adopting one from . Rackets with smaller and larger head sizes, , are still produced but are not used by professionals currently. A very small number of professionals, such as Monica Seles, used rackets during some point in their careers. Rackets with smaller heads than have not been in production since the 1980s and rackets with larger head sizes than are not currently legal for the sport, even though only elderly players typically choose to use rackets beyond and it is nearly unheard-of for a serious player who is not elderly to choose a racket over . The WEED company, founded by Tad Weed, specializes in producing very large rackets, primarily for the elderly market. Rackets that are moderately higher in power production, moderately lower in weight, moderately larger in size, and which typically possess a slightly head-heavy balance are often called \"tweener rackets.\" Rackets that have the smallest heads in current use, the highest weights in current use, and headlight or even balance are referred to as \"players' rackets\". Oversize rackets, typically in size, were once pejoratively referred to as \"granny sticks\" but resistance to them being seen as illegitimate rackets for younger players decreased dramatically with the successful use of these rackets by a small number professionals such as Andre Agassi and Pam Shriver. Originally, even midsize frames () were considered jumbo, and some top players, such as Martina Navratilova and Rod Laver said they should be banned for making the sport too easy. Later, these same professionals, including John McEnroe, signed a letter supporting a switch back to wood frames, or a limitation to the original standard size of approximately . Perhaps the last professional to use a standard-size racket in professional tennis was Aaron Krickstein, known for the strongly-contested match against Connors at the 1991 US Open. He used a Wilson Ultra-II standard-size graphite racket also used in the 1980s by the hard-hitting teen Andrea Jaeger. The first oversize, the fiberglass Bentley Fortissimo from Germany, was praised by racket designers but was considered too large to be taken seriously by the small number of players who were exposed to it.\nThe head-light balance point is rarer in professional tennis than it once was, as the sport has converted to larger-headed rackets, stiffer rackets, stiffer strings, more western grips and accompanying stroke production, and more topspin. The head-light balance point is most optimal for the serve and volley style with a continental grip. Serve and volley is no longer a viable option for nearly all professionals as the mode of playing for most points in a match. Head-heavy rackets became popular, mainly with recreational players, primarily with the introduction of the Wilson ProFile widebody racket. The head-light balance makes volleys and serves easier to produce, while groundstrokes are less stable. The head-heavy balance makes groundstrokes more stable, which typically increases the player's comfort for swinging harder to add power, but makes serves and volleys more cumbersome. A head-heavy balance also puts more stress on the elbow and shoulder.\nVibration dampeners (also sometimes known as \"gummies\") may be interlaced in the proximal part of the string array, to reduce the percussive sound of the ball hitting the strings and/or to reduce perceived vibration. They do not, however, reduce impact shock significantly, so they are of no safety value. Some professionals, such as Andre Agassi, used rubber bands instead of specialized dampeners. Dampeners come in two main types. The first uses the two central main strings to hold it in place. The second is sometimes called a \"worm\" and it is woven between many of the main strings. Dampeners are nearly always placed very near the bottom of the racket string bed.\nAs rackets have become lighter, stiffer, and larger-headed, the professional game has moved, basically completely, from softer and more flexible string materials to stiff materials. This is, in large part, to tone down the additional power potential of the \"modern\" rackets. However, it also is related to the tendency for different string materials to move out of place when subjected to heavy topspin strokes. Polyester is the string of choice today because of that resistance, despite its increased stiffness (harsher feel and more aggravating for the joints) and reduced tension-holding ability (versus a string like natural gut, which excels at that). The top professionals of the 1970s and earlier, despite having access to stiffer materials such as nylon, nearly always chose to use the very flexible natural gut instead. String bed stiffness can be increased by using stiffer materials, such as kevlar and polyester, by increasing the density of the string pattern, and by stringing with a higher tension. Racket makers and players have experimented with very dense string patterns and very \"open\" patterns, beginning with the Snauwaert Hi Ten, which had a pattern with as few as 12 mains and 13 crosses. Doubles great Mark Woodforde used one of them. More recently, Grigor Dimitrov is known for having played with a very open-patterned racket during part of his career. String choice, both in thickness and material, string tension, string pattern, and string pattern density can have a very large effect on how a racket performs.\nThroughout most of lawn tennis' history, most rackets were made of laminated wood, with heads of around . A small number of them were made of metal, such as a 1920s racket by Dayton. Some, rarely, also had metal strings. In the late 1960s, Wilson popularized the T-2000 steel racket with wire wound around the frame to make string loops, after having purchased the design from Ren\u00e9 Lacoste, who produced the racket first in a more limited run. It was popularized by the top American player Jimmy Connors and was also, prior to Connors using it, by Billie Jean King in her early career. Many players said it lacked control but had more power, when compared with wood frames of the period. Connors used the rarer \"firm\" model that had additional throat welds to increase its stiffness. In 1968 Spalding launched an aluminium racket, called The Smasher. Aluminium, though lighter and more flexible than steel, was sometimes less accurate than wood. The biggest complaint, however, was that metal rackets caused strong cases of tennis elbow, especially the kind that had holes for the strings directly in the frame, rather than using an external wire wrapper, as in the T-2000. Because of that drawback in particular, most of the top players still preferred to use wooden frames.\nBy 1975, aluminium construction improvements allowed for the introduction of the first American \"oversized\" racket, which was manufactured by http://. Prince popularized the oversize racket, which had a head size of approximately . Howard Head was able to obtain a broad patent for Prince, despite the prior art of the Bentley Fortissimo (the first oversize, made in Germany of fiberglass) and the Weed. The patent was rejected by Germany but approved in the USA. The popularity of the Prince aluminium oversize had the side effect of popularizing rackets having other non-standard head sizes such as mid-size and mid-plus sizes . Fairly quickly, midsize frames began to become the most-used frames in the pro tours. Martina Navratilova popularized the midsize graphite racket, with her wins using the Yonex R-7, the first midsize graphite racket made by Yonex. Nearly at the same time, however, she said the \"jumbo\" rackets (midsize included) should be removed from the sport for making it easier. She said she would use them only because other players could, as they were tournament-legal. Fewer players chose to use oversize rackets, and some switched to midplus frames after their earliest career for more control. Fiberglass frames also had a brief period of limited popularity, making fewer inroads among top players than aluminium. Also, the earliest composites, such as the Head Competition series, used by Arthur Ashe, were made without graphite. These were more flexible than a typical early graphite composite but stiffer than wood, fiberglass, and aluminium.\nIn the early 1980s, \"graphite\" (carbon fibre) composites were introduced, and other materials were added to the composite, including ceramics, glass fibre, boron, and titanium. Some of the earliest models typically had 20% or more fiberglass, to make them more flexible. Stiff rackets were typically not preferred by most players because of their familiarity with the comfortable softness of wood. These early models tended to be very flexible and not very powerful, although they were a power upgrade over wood and metal rackets. Wilson created the Jack Kramer Pro Staff, the graphite version of the wood racket of the same name extremely popular in the late 70s and early 80s. This was the origin of the extremely influential Wilson Pro Staff 85. Chris Evert's first graphite racket was this Jack Kramer version, which had 20% fiberglass. It was not a market success and she, along with everyone else, quickly replaced it with the stiffer Pro Staff 85, which had 20% kevlar. It used the same mold and had the same braided graphite, but offered a very noticeable improvement in power. The very popular Prince original graphite, an oversize in its most popular form, was also quite influential and used by many pros, especially as juniors. Jennifer Capriati and Monica Seles, for instance, used the Prince graphite to contest their influential Wimbledon match in 1991 that has often been hailed as the beginning of the power baselining game in the WTA, although that claim is somewhat hyperbolic and is, in large part, due to the mistaken impression that the players were hitting much harder when, in fact, the rackets were more powerful. However, the very large head size, when compared with the midsize and, especially, the old \"standard\" size, made it easier to produce power. The racket also had an open string pattern. The Prince \"original\" graphite name is rather a misnomer, as it went through some significant design adjustments over its lifetime. For instance, the truly original model had a reverse teardrop head shape, something no subsequent versions had. Stiffer composite rackets, when compared with the first and second generations of graphite composites, are the contemporary standard. The last wooden racket used at Wimbledon appeared in 1987, long after they were abandoned by practically all professionals. Borg tried to stage a comeback with his standard wood racket, after his premature retirement, but it quickly ended in failure, as the standard wood was no match when placed against a stiff midplus graphite. It is also commonly argued that Chris Evert would have been able to beat Martina Navratilova during the latter's most dominant period if she had switched from her wood racket years sooner. Additionally, the last influential wooden racket, the Prince Woodie, had layers of graphite to increase its stiffness and was an oversize. It was used by Tommy Haas, Gabriela Sabatini, and quite a few others. It offered very little power but did offer much more surface area than a standard-size wooden frame. Sabatini found it helpful, as compared with smaller rackets, due to her production of heavy topspin. The only woman to beat Martina Navratilova in 1984, Kathleen Horvath, used the Prince Woodie, one of only six losses Navratilova suffered in a three-year stretch involving 260 matches.\nA denser pattern is often considered to deliver more control, at the expense of spin potential. A more open pattern is often believed to offer greater potential for power and spin. However, how much power is produced by a player can be strongly influenced by how a player adapts to the characteristics of the racket. Some players may hit harder with a dense string pattern, producing faster shots because of the added control from the dense pattern. Rackets, including those of much of the wood era, are marked with a recommended string tension range. The basic rule is that a lower tension creates more power (from the trampoline effect) and a higher string tension creates more control (less string deformation which results in a more predictable the power and angle of the departure from the string bed.) Some professionals used small-headed rackets with flexible-material strings (natural gut) strung at very high tension. Examples include Pete Sampras and Bj\u00f6rn Borg. Some used large-headed rackets with very inflexible-material strings (kevlar). Andre Agassi is an example. Many professionals during the standard wood era strung at relatively low tension and used natural gut string; both decisions were to increase the trampoline effect for more power. By contrast, almost every professional player today uses the much stiffer polyester string in their much stiffer rackets which also have larger heads and which tend to be lighter. Madeline Hauptman sold a line of rackets, called the MAD RAQ, which featured a Star of David pattern (a six-pointed figure consisting of two interlaced equilateral triangles), as it used three strings instead of two for stringing the racket. This pattern is used in snowshoes. This stringing pattern was said to feature less string notching, improving string lifespan. It was even claimed that many pro shops refused to carry the racket because less string breakage would reduce string and stringing service sales. It has also been claimed that the racket is more difficult to string than a two string racket. However, the Wilson T-2000-type requires a great deal more time for stringing than a typical racket and rackets of that series were very popular. Whatever the cause of the failure of the MAD RAQ in the marketplace, it was the only time a snowshoe pattern was used in tennis. Hauptman switched her racket line to a two string diamond pattern (PowerAngle). This pattern had already been used in much earlier rackets but had not had much popularity. It is said to be easier to string than the MAD RAQ but does not have the benefit of reduced string notching, at least not to the same degree. The claim is that this diagonal pattern offers more comfort than a traditional square pattern.\nThe stiffest graphite racket that has been sold is the Prince More Game MP, which is rated at 80 RA on the industry-standard Babolat measuring equipment. The Prince More series used two pieces (a top side and bottom side of the racket, or a left side and a right side) and no grommet strip. Prince had briefly used a design without a grommet strip in an early version of its \"original\" graphite oversize. The most famous user of a More series racket was Martina Navratilova, who returned to play doubles in her 40s, using a Prince More Control DB (a midplus) for her initial wins in the mixed doubles at Wimbledon and the Australian Open with Leander Paes. She had used the stiffer More Game MP prior. Navratilova later switched to a design by Warren Bosworth (the founder of Bosworth Tennis) which had a customized asymmetric grip and an unusual geometric head shape. Stiffer rackets typically offer more power and control at the expense of increased ball shock, which can lead to injury or tennis elbow aggravation. Typically, power and control are at odds. However, in the case of stiff rackets, less energy is dissipated by the racket deforming, transmitting it back to the ball. Control is improved because there is less deformation. However, a player's overall power level may decrease due to the need to moderate ball striking effort to reduce discomfort and even injury. Although known as a hard hitter in her younger years, in her 40s she was known more as a precision player who used finesse (and especially tactics) more than power. In fact, the last doubles partner she won a major with in mixed, Bob Bryan, remarked on how slow her serve was, despite how effective she was on the court. Navratilova also used string that was much softer than what anyone else on tour used (thick uncoated natural gut), to help compensate for the stiffness of her racket. The vastly higher injury rate in tennis (when compared with the wood era) is, in part, due to the increase in stiffness, both of the racket and of the strings.\nReal tennis uses wooden rackets and cork-filled balls. It is a very different sport from today's lawn tennis.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52665", "revid": "40428319", "url": "https://en.wikipedia.org/wiki?curid=52665", "title": "Newcastle, New South Wales", "text": "&lt;templatestyles src=\"Infobox_Australian_place/styles.css\"/&gt;\nNewcastle, also known as Greater Newcastle ( ; ), is a large metropolitan area and the second-most-populous such area of New South Wales, Australia. It includes the cities of Newcastle and Lake Macquarie and it is the hub of the Lower Hunter region, which includes most parts of the cities of Newcastle, Lake Macquarie, Maitland, Cessnock, and Port Stephens Council. Newcastle is also known by its colloquial nickname, Newy. A Newcastle resident can also be known as a Novocastrian.\nLocated at the mouth of the Hunter River, it is the predominant city within the Hunter Region. Famous for its coal, Newcastle is the largest coal exporting harbour in the world, exporting 143 million tonnes of coal in 2022. Beyond the city, the Hunter Region possesses large coal deposits. Geologically, the area is located in the central-eastern part of the Sydney Basin.\nHistory.\nAboriginal history.\nNewcastle and the lower Hunter Region were traditionally occupied by the Awabakal and Worimi Aboriginal people, who called the area Malubimba.\nBased on Aboriginal-language references documented in maps, sketches and geological descriptions, eight landmarks have been officially dual-named by the NSW Geographic Names Board with their traditional Aboriginal names. They include Nobbys Head also known as Whibayganba; Flagstaff Hill also known as Tahlbihn; Pirate Point also known as Burrabihngarn; Port Hunter also known as Yohaaba; Hunter River (South Channel) also known as Coquun;\nShepherds Hill also known as Khanterin; Ironbark Creek also known as Toohrnbing and Hexham Swamp also known as Burraghihnbihng.\nBritish exploration.\nIn June 1796, a group of fishermen from the British convict outpost at Sydney, were driven by bad weather into a harbour at what is now Newcastle. They found considerable amounts of coal lying on the ground near the beach, some of which they brought back to Sydney. The fishermen had \"conducted themselves improperly\" while ashore and gotten into conflict with the local Aboriginal people. Two of the fishermen were wounded, one of them fatally.\nOver a year later, in September 1797, Lieutenant John Shortland explored the area and named the Hunter River. This was largely accidental, as he had been sent to the region in search of a number of convicts who had seized a vessel called \"Cumberland\" while it was sailing from Sydney Cove. Leiutenant Shortland entered what he later described as \"a very fine river\", which he named after New South Wales' Governor John Hunter. He returned with reports of the deep-water port and the area's abundant resources of coal and cedar.\nEarly coal and cedar operations.\nOver the next two years, influential colonists like Simeon Lord and James Underwood sent vessels and workers to the region to extract the valuable coal and cedarwood. Some of these workers skirmished with local Awabakal men, and an armed party under Henry Hacking was dispatched to investigate, which resulted in the shooting of several Aboriginal people. Coal mined from the area was the New South Wales colony's first export.\nFirst attempt at British settlement.\nIn 1800, fifteen convicts seized a small supply ship from the Hawkesbury River and sailed it to the mouth of the Hunter River where it was wrecked. Three of the surviving convicts became the area's first British residents when they were adopted into a local Aboriginal clan. A year later, Philip Gidley King, the Governor of New South Wales, decided to send a surveying expedition under Colonel William Paterson and Francis Barrallier to assess the feasibility of establishing an official settlement. Paterson returned with a positive account outlining the cedar and coal resources, and also the massive loads of oyster shell middens which could be utilised for much needed lime mortar. \nSubsequently, later in 1801, a convict camp called King's Town (named after the governor) was established to mine coal and cut timber. The convicts, numbering under twenty, were treated harshly and mutinied twice in six months before Governor King decided to abandon the settlement in February 1802.\nNewcastle convict colony.\nEstablishment.\nA convict settlement was again attempted in 1804, as a place of secondary punishment for unruly convicts. The settlement was named Coal River, also Kingstown and then renamed Newcastle, after the English city. The name first appeared by the commission issued by Governor King on 15 March 1804 to Lieutenant Charles Menzies of the marine detachment on , then at Port Jackson, appointing him superintendent of the new settlement. \nThe first consignment, consisting of 34 convicts and a military guard, arrived at the Hunter River on 27 March 1804 in three ships: , the \"Resource\" and the \"James\". The convicts were Irish rebels from the 1804 Castle Hill convict rebellion. Newcastle gained a reputation as a \"hellhole\" as it was a place where the most dangerous convicts were sent to dig in the coal mines as harsh punishment for their crimes. The link with Newcastle upon Tyne, England (its namesake) and also whence many of the 19th-century coal miners came, is still obvious in some of the place-names\u2014such as Jesmond, Hexham, Wickham, Wallsend and Gateshead. Morpeth, New South Wales is a similar distance north of Newcastle as Morpeth, Northumberland is north of Newcastle upon Tyne.\nIn 1805, Menzies resigned as commandant, with Cadwallader Draffin being promoted to the role. He was soon found to be mentally unstable and in turn was quickly replaced by the medical officer of the settlement, Charles Throsby. Throsby brought order and discipline to the convict colony, where the prisoners were set to work securing coal, cedar and salt from sunrise to sunset.\nDevelopment.\nIn 1808, Lieutenant William Lawson was appointed as commandant. Lawson was a member of the Rum Corps who overthrew Governor William Bligh. Associates of Bligh, such as Henry Browne Hayes were sent as convicts to Newcastle where Lawson treated them harshly. Under Lawson, the severe work of manual limeburning was commenced, where the convicts were forced to burn and carry caustic unslaked lime through seawater to load onto barges.\nLawson was replaced in 1810 and a period of relatively merciful administration followed under the command of several military officers. In early 1816, Newcastle's first school opened with seventeen pupils in attendance.\nUnder Captain James Wallis, commandant from 1816 to 1818, the convicts' conditions improved, and a building boom began. Captain Wallis laid out the streets of the town, built the first church of the site of the present Christ Church Cathedral, erected the old gaol on the seashore, and began work on the breakwater which now joins Nobbys Head to the mainland. The quality of these first buildings was poor, and only the (much reinforced) breakwater survives. Wallis also established a female factory on Nobbys Head for insubordinate women convicts. This scheme was short-lived due to the terrible conditions endured by the women.\nIncreased severity under Major Morisset.\nA major enquiry beginning in 1819, led by John Bigge, investigated the management of the British convict colonies in Australia. Bigge recommended that the treatment of convicts be more severe to act as an increased deterrent to crime. Major James Morisset was appointed commandant at Newcastle in 1819 and a subsequent increase in harsh punishments of the convicts occurred. Floggings and solitary confinement became more common, and unruly female convicts were placed in neck irons and worked in chain gangs. Morisset had a flogging apparatus built into his boat to act as a mobile place of punishment when he toured the farms along the Hunter River worked with convict labourers. Convicts who laboured in the cramped underground coal mines were each expected to produce up to two and a half tons of coal per day. The shafts were consistently knee-deep with water and the convicts had to remain in their wet clothing. Despite being overworked and having insufficient rations and poor housing, Morisset had the convicts carve him an ocean bath (termed the Bogey Hole) into the rock shelf near Newcastle.\nMorisset also increased surveillance around Newcastle to locate and capture runaway convicts. He established a military outpost in Port Stephens at a place which is still called Soldier's Point. He also expanded the use of local Aboriginal men to act as trackers to locate, disable and sometimes kill fugitive convicts. Men such as Biraban, Burigon and Bob Barrett became well-known in this role and were reviled by the convicts. When Burigon was murdered by prisoner John Kirby, Morisset had the convict arrested and charged. Kirby was later executed.\nClosure of the convict settlement.\nNewcastle became open to free settlement from 1822. The large agricultural corporation, the Australian Agricultural Company, took up its immense land grant north of Port Stephens in 1824, while wealthy colonists around the same time starting carving out estates along the upper Hunter River. Prisoner numbers were gradually reduced from around 1,000 to 100 (most of these were employed on the building of the breakwater), and the remaining 900 were sent to the newly-formed penal colony at Port Macquarie. The convict colony at Newcastle was closed in 1826.\nCivilian government and onwards.\nAfter the closure of the convict settlement in 1826, the town was freed from the infamous influence of penal law. It began to acquire the aspect of a typical British colonial settlement, and a steady flow of colonists and their convict labourers poured into the hinterland. However, Newcastle itself initially faced a decrease in population with an observer stating in 1827, that the number of Aboriginal people in the township at least equalled that of the white population.\nDuring the nineteenth century the formation of the Newcastle &amp; Hunter River Steamship Company saw the establishment of regular steamship services from Morpeth and Newcastle with Sydney. The company had a fleet of freighters as well as several fast passenger vessels, including the PS \"Newcastle\" and the PS \"Namoi\". The \"Namoi\" had first-class cabins with the latest facilities.\nBecause of the coal supply, small ships plied between Newcastle and Sydney, Brisbane, Melbourne and Adelaide, carrying coal to gas works and bunkers for shipping, and railways. These were commonly known as sixty-milers, referring to the nautical journey between Newcastle and Sydney. These ships continued in service until recent times.\n1920s to present.\nDuring World War II, Newcastle was an important industrial centre for the Australian war effort. In 1942, the Japanese planned to attack Sydney Harbour. On the early hours of 8 June, the Japanese submarine briefly shelled Newcastle. Among the areas hit within the city were dockyards, the Newcastle Steelworks, Parnell Place in the city's East End, the breakwall and Art Deco Ocean baths. There were no casualties in the attack and damage was minimal.The Port of Newcastle remains the economic and trade centre for the resource-rich Hunter Valley and for much of the north and north-west of New South Wales. Newcastle is the world's largest coal export port and Australia's oldest and second-largest tonnage throughput port, with over 3,000 shipping movements handling cargo of 95.8 Mt per annum, of which coal exports represented 90.8 Mt in 2008\u201309. The volume of coal exported, and attempts to increase coal exports, are opposed by environmental groups including Newcastle-based Rising Tide Australia. These have undertaken various protests targeting the export of coal from the city, such as in 2023 when 3000 people took part in a water based blockade and 109 were arrested.\nNewcastle had a shipbuilding industry with the Walsh Island Dockyard &amp; Engineering Works, State Dockyard and Forgacs Shipyard. In recent years the only major ship-construction contract awarded to the area was the construction of the \"Huon\"-class minehunters. The era of extensive heavy industry passed when the steel works closed in 1999. Many of the remaining manufacturing industries have located themselves well away from the city itself.\nNewcastle has one of the oldest theatre districts in Australia. Victoria Theatre on Perkins Street is the oldest purpose-built theatre in the country. The theatre district that occupied the area around what is now the Hunter Street Mall vanished during the 1940s. The old city centre has seen some new apartments and hotels built in recent years, but the rate of commercial and retail occupation remains low while alternate suburban centres have become more important. The CBD itself is shifting to the west, towards the major urban renewal area known as \"Honeysuckle\". This renewal, to run for another 10 years, is a major part of arresting the shift of business and residents to the suburbs. Commercial renewal has been accompanied by cultural renaissance. There is a vibrant arts scene in the city including a highly regarded art gallery, and an active Hunter Writers' Centre. Recent fictional representations (for example Antoinette Eklund's 'Steel River') present a new vision of the city, using the city's historic past as a backdrop for contemporary fiction.\nThe old central business district, located at Newcastle's eastern end, still has a considerable number of historic buildings, dominated by Christ Church Cathedral, seat of the Anglican Bishop of Newcastle. Other noteworthy buildings include Fort Scratchley, the Ocean Baths, the old Customs House, the 1920s City Hall, the 1890s https:// (once regarded as the finest building in the colony) and the 1930s art deco University House (formerly NESCA House, seen in the film \"Superman Returns\").\nGeography.\nNewcastle is on the southern bank of the Hunter River mouth. The northern side is dominated by sand dunes, swamps and multiple river channels. A \"green belt\" protecting plant and wildlife flanks the city from the west (Watagan mountains) around to the north where it meets the coast just north of Stockton. Urban development is mainly restricted to the hilly southern bank. The small town of Stockton sits opposite central Newcastle at the river mouth and is linked by ferry. Road access between Stockton and central Newcastle is via the Stockton Bridge, a distance of . Much of the city is undercut by the coal measures of the Sydney sedimentary basin, and what were once numerous coal-mining villages located in the hills and valleys around the port have merged into a single urban area extending southwards to Lake Macquarie. The Greater Newcastle area is situated right between the Central Coast and Mid North Coast regions, with the Central Coast bordering in the south and the Mid North Coast bordering in the north as well as other Hunter local government areas (outside of Newcastle) bordering in the west and north-west.\nParks.\nNewcastle has several public parks including King Edward Park, which was designated in 1863. Features of the park include coastal views, a sunken garden and a Victorian rotunda.\nClimate.\nNewcastle has a humid subtropical climate (\"Cfa\") that is typical of the Australian east coast. Precipitation is heaviest in late autumn and early winter, while the second half of the year is slightly drier on average. The climate is generally moderated by the Pacific Ocean to the east. Summers are mostly warm and humid with periods of very dry and hot weather occasionally due to hot west to north-westerly winds, which can bring temperatures in excess of . The highest recorded temperature was on 18 January 2013 at the Nobbys Head weather station.\nWinters are generally mild with drier conditions than summer on average. Cold fronts affect the area and sometimes bring strong westerly winds behind them, but due to the foehn effect they generally provide clear conditions as the region lies leeward of the Great Dividing Range. The lowest recorded temperature was on 27 July 1986. East coast lows also impact Newcastle, sometimes delivering winds well above and torrential rainfall, usually lasting a couple of days. The east coast low in May 1974, the 2007 New South Wales storms and April 2015 are extreme examples of this type of weather.\nDemographics.\nThe metropolitan area of Newcastle is the second-most-populous area in New South Wales to Sydney.\nWhat is generally labelled as the 'Greater Newcastle Area' includes the LGAs of Newcastle, Lake Macquarie, Maitland, Cessnock and Port Stephens. In 2021 this region had a total population of 682,465.\nOf people in the Newcastle metropolitan area, 83.6 per cent were born in Australia. The next most common countries of birth were England 2.3%, New Zealand 1.0%, China 0.7%, India 0.5% and Philippines 0.4%. Aboriginal and Torres Strait Islander people made up 3.8% of the population. 88.2% of people spoke only English at home. Other languages spoken at home included Mandarin 0.7%, Macedonian 0.5%, Italian 0.4%, Greek 0.3% and Cantonese 0.3%. The most common responses for religion in Newcastle were No Religion 31.1%, Catholic 21.7% and Anglican 19.2%.\nNewcastle is often quoted as being the seventh-largest city in Australia. This is misleading as the area represented extends well beyond both the City of Newcastle and the Newcastle metropolitan area. The area, officially the Newcastle Statistical District, is referred to as Greater Newcastle or the Lower Hunter Region, which includes most parts of the Newcastle, Lake Macquarie, Cessnock, Maitland and Port Stephens local government areas and, as of 30 June 2009, has an estimated population of 540,796. Despite their proximity, all of the LGAs in the region maintain their own individual identities, separate from Newcastle.\nThe population of the suburb of Newcastle is 3,852 as of the 2021 census.\nThe demonym for the people of Newcastle is \"Novocastrian\", derived from Latin \"novus\" (new) and \"castra\" (castle or fort).\nEconomy.\nNewcastle as a traditional area of heavy industry was not immune from the effects of economic downturns that plagued New South Wales and wider Australia since the 1970s. These downturns were particularly hard hitting for heavy industry which was particularly prevalent in Newcastle. The early 1990s recession caused significant job losses across Australia and the Newcastle region experienced a peak unemployment rate of 17% in February 1993, compared to 12.1% in New South Wales and 11.9% across Australia.\nIn 1999, the steelworks closed after 84 years' operation and had employed about 50,000 during its existence, many for decades. The closure of the BHP steelworks occurred at a time of strong economic expansion in Australia. At the time of the closure and since the closure Newcastle experienced a significant amount of economic diversification which has strengthened the local economy.\nSince 2003, Australia experienced the effects of the 2000s commodities boom as commodities prices for major export good such as coal and iron ore rose significantly. This provided a large incentive for investment in the Newcastle and Hunter region due to its status as a major coal mining and export hub to Asian markets. Large projects related to the coal industry helped to propel the Newcastle unemployment rate to 20 year lows and allow the Newcastle region to weather the effects of the late 2000s recession better than NSW as a whole. As of 2009, the two largest single employers are the Hunter New England Area Health Service and the University of Newcastle. The National Stock Exchange of Australia (formerly Newcastle Stock Exchange) was formerly based in the city.\n19th and early 20th centuries.\nCoal.\nCoal mining began in earnest on 3 May 1833 when the Australian Agricultural Company received land grants at Newcastle plus a 31-year monopoly on that town's coal traffic. Other collieries were within a radius of the town. Principal coal mines were located at Stockton, Tighes Hill, Carrington and the Newcastle Coal and Copper Company's collieries at Merewether (includes the Glebe), Wallsend and the Waratah collieries. All operations had closed by the early 1960s.\nOn 10 December 1831, the Australian Agricultural Company officially opened Australia's first railway, at the intersection of Brown &amp; Church Streets, Newcastle. Privately owned and operated to service the \"A Pit\" coal mine, it was a cast-iron fishbelly rail on an inclined plane as a gravitational railway.\nCopper.\nIn the 1850s, a major copper smelting works was established at Burwood, near Merewether. An engraving of this appeared in \"The Illustrated London News\" on 11 February 1854. The English and Australian Copper Company built another substantial works at Broadmeadow circa 1890, and in that decade the Cockle Creek Smelter was built.\nSoap.\nThe largest factory of its kind in the Southern Hemisphere was constructed in 1885, on an site between the suburbs of Tighes Hill and Port Waratah, by Charles Upfold, from London, for his Sydney Soap and Candle Company, to replace a smaller factory in Wickham. Their soap products won 17 medals at International Exhibitions. At the Sydney International Exhibition, they won a bronze medal \"against all-comers from every part of the world\", the only first prize awarded for soap and candles. Following World War I, the company was sold to Messrs Lever &amp; Kitchen (today Unilever), and the factory closed in the mid-1930s.\nSteel.\nIn 1911, BHP chose the city as the site for its steelworks due to the abundance of coal. The land put aside was prime real estate, on the southern edge of the harbour. In 1915, the Newcastle Steelworks opened, beginning a period of some 80 years dominating the steel works and heavy industry. As Mayfield and the suburbs surrounding the steelworks declined in popularity because of pollution, the steelworks thrived, becoming the region's largest employer.\nGovernment and politics.\nWith its history as a traditionally working-class area, Newcastle has been a stronghold for the centre-left Labor Party at all levels of politics since Federation. Labor currently holds every federal and state seat that overlaps at least partially with Newcastle.\nThe only area of Greater Newcastle where the centre-right Liberal Party has ever been consistently competitive is the Port Stephens region in the north of the Newcastle metropolitan area, as well as in some beachside, middle-class suburbs near the Newcastle CBD such as Bar Beach and Merewether. The Port Stephens area is traditionally marginal and while historically was dominated by Labor, has been won by the Liberals.\nOne time the Liberals did win seats in Newcastle was at the 2011 state election. At this election, the incumbent Labor government, led by then-Premier Kristina Keneally, was defeated by the Liberal-National Coalition, led by then-Opposition Leader Barry O'Farrell, in a landslide, suffering the worst ever defeat of a sitting government in New South Wales history and (at the time) the worst defeat of a sitting government anywhere in Australia since World War II. Labor won just 20 seats in the New South Wales Legislative Assembly; of these, only two (Cessnock and Wallsend) were in the Hunter Region. Before the election, the Liberal Party only held one seat in the entire Hunter Region (the seat of Port Stephens, which the party narrowly gained from Labor in 2007). However, at the subsequent state election in 2015, although the Coalition retained majority government (and subsequently retained government again in 2019 before Labor formed a minority government in 2023), the party lost all of its Hunter-based seats.There are three federal electoral divisions that are mostly or entirely within Greater Newcastle: Newcastle (covering the inner-city suburbs; this seat has only ever elected Labor MPs since it was created in 1901), Paterson (covering the Port Stephens area as well as the nearby city of Maitland and the town of Kurri Kurri; this seat is currently a marginal Labor seat that the Liberals have won previously, though it historically included more rural areas and did not include Maitland or Kurri Kurri) and Shortland (a fairly safe Labor seat that includes the eastern suburbs of the Lake Macquarie region in southern Newcastle, and extends to the far northeastern suburbs of the Central Coast). The traditionally Labor-held seat of Hunter (now a marginal Labor seat) is based around the western portion of the Hunter, but includes some western and Southern suburbs of Newcastle.\nOn the state level, there are five electoral districts that are located entirely within Greater Newcastle; of these, four (Charlestown, Newcastle, Port Stephens and Swansea) are Labor seats while the remaining seat (Lake Macquarie) is held by an independent.\nGreater Newcastle also includes five local government areas (LGAs): the City of Newcastle, the City of Lake Macquarie, the City of Cessnock, the City of Maitland and the Port Stephens Council.\nEducation.\nPrimary and secondary schools.\nNewcastle High School, which was formed by the merger of three schools, traces its lineage to a secondary school section initially founded on the grounds of Newcastle East Public School.\nThere are three selective state schools in the area:\nThe two main independent schools in Newcastle are Newcastle Grammar School and St Philip's Christian College, both coeducational K\u201312 schools.\nThe local area is also home to two Steiner schools: the Newcastle Waldorf School at Glendale in Lake Macquarie, and the Linuwel Steiner School in East Maitland.\nTertiary and further education.\nThe city's main provider of tertiary education is the University of Newcastle. It was established in 1951 as a satellite campus of the University of New South Wales and obtained autonomy in 1965. The university now offers over 150 undergraduate and graduate courses to a student population of more than 38,000, including 7,000 international students from more than 113 countries. The main campus is in the suburb of Callaghan about from the CBD.\nThere are three campuses of the Hunter Institute of TAFE, one located in the Newcastle CBD, one in the suburb of Hamilton East and the other located in the suburb of Tighes Hill. The Tighes Hill campus is the network's largest campus and offers courses in business, hospitality and various trades.\nCulture.\nFestivals.\nNewcastle holds a variety of cultural events and festivals.\nThe Newcastle Regional Show is held in the Newcastle Showground annually. There are a mixture of typical regional show elements such as woodchopping displays, showbags, rides and stalls and usually fireworks to complement the events in the main arena.\nThe Mattara festival, founded in 1961, is the official festival of Newcastle with a more traditional \"country fair\" type program that combines a parade, rides, sporting events, band competitions and portrait and landscape painting exhibitions. Mattara means \"hand of friendship\" in the local Awabakal language. Originally held at Civic Park and then moved to Newcastle foreshore in 2006 In 2017 the festival was moved to Wallsend Park.\nThe Newcastle Jazz Festival is held across three days in August, and attracts performers and audiences from all over Australia. The first festival was held in September 1988 as part the NSW Bicentenital Festival of Music which was organised by the Newcastle Jazz Action Society.\nThe Shoot Out 24 Hour Filmmaking Festival, first started in Newcastle in 1999. This is the film festival where film-makers come together in one place to make a short film in 24 hours. It is run annually in July.\nThis Is Not Art is a national festival of new media and arts held in Newcastle each year over the October long weekend. Since its humble beginnings in 1998, it has become one of the leading arts festivals in Australia dedicated to the work and ideas of communities not included in other major Australian arts festivals. The umbrella program includes the independent festivals Electrofringe, the National Young Writers' Festival, Critical Animals, Sound Summit, Crack Theatre Festival and other projects that vary from year to year.\nThe Newcastle Entertainment Centre, located inside the Newcastle Showground is a popular venue for regular events including wrestling, concerts and monster truck shows.\nMusic.\nNewcastle has an active youth music culture, as well as a Conservatorium of Music which is part of the University of Newcastle. It continues to support local bands and has a large underground music scene. The members of Silverchair, the highly successful Australian band, hail from Newcastle, as do the Australian bands The Screaming Jets and Vacations. It has a fertile punk rock and hardcore scene, which has spawned successful local acts and national acts. Newcastle was also home to the short-lived band Velvet Underground (no relation to the famous American band The Velvet Underground) which featured future AC/DC guitarist Malcolm Young. The region also has its own youth marching band, the Marching Koalas, in which Silverchair drummer Ben Gillies began his drumming career. Danielle Marsh, a member of the world-famous South Korean K-pop girl group NewJeans, as well has her older sister and singer Olivia Marsh, also hails from Newcastle.\nInfluential gabber group Nasenbluten were formed and based in Newcastle, until their disbandment in 2001.\nVisual arts and galleries.\nNotable modernist artists associated with Newcastle are seascape sketcher Shay Docking (1928\u20131998), the cubist-influenced abstract painter William Rose (1929\u20131999), landscape painter John Olsen, who was born in Newcastle in 1928, still-life painter Margaret Olley, portraitist William Dobell and figurative painter John Montefiore lived at Lake Macquarie to the south of the city. Art collector William Bowmore resided in Newcastle and collected Brett Whiteley paintings as well as owning a large collection of international art and artefacts. The Von Bertouch Galleries was a commercial gallery founded by Anne Von Bertouch and for more than forty years from 1963 exhibited nationally and locally known artists.\nThe Newcastle Art Gallery is home to one of Australia's most substantial public art collections outside a major capital city, and its extensive collection of works by contemporary and historical Australian visual artists presents an overview of Australian art. Due to an ongoing space issue, the gallery is planning a major redevelopment. The Lock Up is a multidisciplinary contemporary art space located in the inner city and hosts local, national and international artists to exhibit in the historic former Newcastle Police station.\nTheatre.\nNewcastle has a variety of smaller theatres, but the main theatre in the CBD is now the \"Civic\", at Wheeler Place, (seating capacity about 1,500), one of Australia's great historic theatres built during 1929 in Art Deco style. It hosts a wide range of musicals, plays, concerts, dance and other events each year. Newcastle previously boasted several large theatres, among them the oldest purpose-built theatre in Australia, the Victoria Theatre on Perkins Street (built 1876, capacity 1,750), saw touring international opera companies such as the D'Oyly Carte Opera Company, and other troupes, and played host to some of the greatest stars of the age, such as Dame Nellie Melba, Gladys Moncrieff and Richard Tauber (it is now closed and derelict); the \"Century\", Nineways, Broadmeadow (built 1941, capacity 1,800)\u2014although largely used as a cinema\u2014was a popular Symphony orchestra venue (demolished 1990 after being severely damaged by the 1989 earthquake); the \"Hunter\" (capacity 1,000) at The Junction, had advanced modern stage facilities, but was eventually sold and demolished to make way for a motel that was destroyed by the 1989 earthquake. The decline in theatres and cinemas from the 1960s onwards was blamed on television.\nNewcastle has also been home to noted Australian actors, comedians and entertainers, including Sarah Wynter, John Doyle (part of comic act Roy &amp; HG), Susie Porter, Celia Ireland, Yahoo Serious and Jonathan Biggins. The cast of the Tap Dogs show also come from Newcastle.\nMedia arts.\nNewcastle is home to the Octapod Association, a New Media Arts collective established in 1996. Octapod presents the annual This Is Not Art Festival and is also home to the Podspace Gallery.\nMuseums.\nThe Newcastle Museum was founded in 1988 in the former headquarters of the Great Northern Railway and stewards local history, culture, industry and science. It features permanent exhibitions relating to coal mining and steel production, Aboriginal history and the area's history, as well as a hands-on science centre.\nLibraries.\nNewcastle has a public library system, Newcastle Libraries. The main branch is in the Newcastle War Memorial and Cultural Centre, and opened in 1957. There are eleven branches: Adamstown, Beresfield, The Digital Library (Newcastle West), Hamilton, Lambton, The Local History Library, Mayfield, New Lambton (with the Newcastle Toy Library), Stockton, and Wallsend. The library has a collaborative collection with the libraries at Dungog and Port Stephens. Though Newcastle Libraries are lending libraries, The stack (City Library basement) has over 100,000 non-lending items which include old Newcastle Morning Heralds, NBN film reels, land title documents, maps, and limited edition books.\nThe Auchmuty Library at the University of Newcastle is also open to the public, though only students may borrow items.\nTransport.\nLike most major cities, the Newcastle metropolitan area has an extensive system of both road links and road based public transport services (bus, taxi etc.) which cover most areas of both Newcastle and Lake Macquarie and which extend beyond the metropolitan area itself. Rail transport, however, is accessible to only a relatively small percentage of the population along the major rail transport routes and ferry services are restricted to those commuting between Newcastle and Stockton. Within the metropolitan area the car remains the dominant form of transportation. Newcastle, like all major Australian urban centres, had a tram system, but it was closed in 1950. In February 2019, trams returned to the city with the opening of the Newcastle Light Rail.\nRoad.\nNewcastle is connected to surrounding cities by the Pacific Motorway (south), Hunter Expressway (west), New England Highway (west) and the Pacific Highway (north and south). Hunter Street is the main shopping street in the Newcastle CBD and, along with King Street, is one of the major links to the Pacific Highway from the CBD. King Street provides direct access to the Newcastle Link Road and then the Pacific Motorway and Hunter Expressway.\nBus.\nBus services within Newcastle are operated by Newcastle Transport. Prior to July 2017, these were operated by Newcastle Buses &amp; Ferries. Hunter Valley Buses, Port Stephens Coaches and Rover Coaches also operate services into the CBD from other parts of the Hunter Region.\nThe network radiates from a bus terminal at Newcastle Interchange. Major interchanges are located at the University of Newcastle, Wallsend, Glendale, Warners Bay, Belmont, Charlestown Square and Westfield Kotara.\nGreyhound Australia, Premier Motor Service and Sid Fogg's long-distance services serve Newcastle.\nRail.\nThe Newcastle area is serviced by two NSW TrainLink intercity lines providing local and regional commuter services terminating at Newcastle Interchange along the Newcastle line. The Central Coast &amp; Newcastle Line has twice-hourly train services to Sydney and the Central Coast. The Hunter Line has twice-hourly services to Maitland and less frequently to Scone and Dungog. Two long-distance lines operate through the Newcastle area using Broadmeadow station. These provide services to Moree, Armidale, Brisbane and Sydney.\nNewcastle once had rail passenger services to Belmont and Toronto, on Lake Macquarie, Wallsend, Kurri Kurri and several towns and villages between Maitland and Cessnock on the South Maitland Railway, but these lines have been closed. In the late-1990s there was intense debate about the future of the rail line into central Newcastle.\nIn December 2014, the Newcastle line was curtailed to Hamilton. A new Newcastle Interchange opened on 15 October 2017. The Newcastle Light Rail line also operates from here.\nFrom 1924 until 1994, Broadmeadow Locomotive Depot was the main railway centre for the Hunter region. Cardiff Locomotive Workshops opened in 1928, primarily as a major repair centre for New South Wales Government Railways locomotives, although it did build twelve 38 class and two 58 class locomotives. Today it is operated by Downer Rail and along with UGL Rail's Broadmeadow plant, remains active as a locomotive and rolling stock manufacturer and repairer.\nWater.\nThe Port of Newcastle is crucial to the economic life of Newcastle and the Hunter Valley region beyond. Over 90 million tonnes of coal is shipped through the facility each year\u2014making it the largest coal exporting port in the world. The Port of Newcastle claims to be Australia's first port. Coal was first exported from the harbour in 1799.\nNewcastle Transport operates a ferry service across the Hunter River between Newcastle's CBD and Stockton.\nAirport.\nNewcastle Airport is located north of the Newcastle CBD ( by road). The airport, which is a joint venture between Newcastle City Council and Port Stephens Council, has experienced rapid growth since 2000 as a result of an increase in low-cost airline operations. The airport is located at RAAF Base Williamtown, a Royal Australian Air Force base on land leased from the Department of Defence.\nNewcastle Heliport operates alongside the lower section of Newcastle Harbour.\nThe suburb of Broadmeadow is home to the base of the Westpac Life Saver Rescue Helicopter Service. The Helicopter service is one of the longest running services of this type in the world. Two helicopters operate out of this base and operate 24 hours a day.\nThe closure of Belmont Airport, commonly referred to as Aeropelican, in the Lake Macquarie suburb of Marks Point has caused Williamtown to become Newcastle's only major airport and residents in the south of the Newcastle metropolitan area must commute up to by car to reach Williamtown.\nSport.\nRugby league.\nRugby league is the most popular sport in Newcastle, with the Newcastle Knights representing the city in the National Rugby League. The Knights play at the 33,000-capacity McDonald Jones Stadium, situated in the suburb of New Lambton.\nThe Newcastle Rugby League holds local club competition and has done so since the early 1900s. Touring domestic and international teams would play against Newcastle's representative team which was made up of players from this league. The Newcastle &amp; Hunter Rugby League is a community competition also based in the region which was created from a merger in 2007 of leagues which ran under various names since the mid-20th century, and is the largest community rugby league competition anywhere in the world. It generally features smaller teams compared to the Newcastle Rugby League.\nMcDonald Jones Stadium hosted the 2016 Anzac Test between Australia and New Zealand.\nFootball (Soccer).\nThe Newcastle Jets Football Club, which plays in Australia's highest-level soccer competition, the A-League, also play at McDonald Jones Stadium. The Newcastle Jets won the A-League competition in their third season, defeating local rivals the Central Coast Mariners in the grand final.\nThe city also played host to four games of the 2015 AFC Asian Cup, including the semi-final between Australia and the United Arab Emirates, as well as the third-place playoff between the United Arab Emirates and Iraq.\nBasketball.\nNewcastle has had two teams in the top tier of Australian Men's basketball, the National Basketball League. They were the Newcastle Falcons (NBL) and later the Hunter Pirates. Both teams folded due to financial difficulties. Newcastle is still represented in the 2nd tier, the NBL1. The Newcastle Basketball club field Men's and Women's teams, using the Newcastle Falcons (NBL1) name again.\nThe city co-hosted the 1985 FIBA Oceania Championship where Australia's national basketball team won its seventh straight title.\nCricket.\nA bid for Newcastle to establish a 2012 team in the national Twenty20 competition the Big Bash League, with games played at either Hunter Stadium or No.1 Sports Ground was unsuccessful.\nAustralian rules.\nThe sport of Australian rules is played in Newcastle and administered by AFL Hunter Central Coast. Australian Football League (AFL) pre-season matches have been held at the No.1 Sports Ground.\nRugby union.\nRugby union is a football code that has been played in Newcastle since at least 1869, with the Newcastle Football Club formed in 1877. Newcastle and Hunter Rugby Union is the main body overseeing the sport in the region. In 2019, the New South Wales Waratahs of the professional Super Rugby competition played a competition match in Newcastle at Hunter Stadium for the first time.\nHorse racing.\nBroadmeadow Racecourse is in the suburb of Broadmeadow. It is home to the Newcastle Jockey Club, established in 1907, which (as of 2016[ [update]]) races 35 times annually at the spacious turf track with a home straight. It is the venue for three Group 3 races: in March is the Newcastle Newmarket Handicap; and in September the 1,400-metre Cameron Handicap, and the Newcastle Gold Cup. In 2015 work an inner track, known as the Beaumont Track, was added.\nAboriginal jockey Merv Maynard commenced his career at Newcastle Racecourse, under Keith Tinson. Maynard enjoyed his first success in the 1948\u201349 season there, and went on to have a career spanning 50 years, winning the Newcastle Premiership twice, along with 1,500 winning rides in four countries.\nIce hockey and skating.\nThe Newcastle North Stars are Newcastle's representatives in the Australian Ice Hockey League championships. Originally based in Newcastle West in the 1970 and '80s, the North Stars now play out of the Hunter Ice Skating Stadium in Warners Bay.\nMotorsport.\nNewcastle hosted the final round of the Supercars Championship in 2017. The Newcastle 500 is held on the Newcastle Street Circuit in the East End of the city. The city previously hosted the Mattara Hillclimb which was held in King Edward Park, and has hosted the F1 Offshore Powerboats in the harbour.\nNetball.\nThe Hunter Jaegers (Commonwealth Bank Trophy \u2013 Netball) were based at the Newcastle Entertainment Centre. They became defunct in 2007 after merging with the Sydney Swifts to become the New South Wales Swifts. Officially opened in June 1992, the Entertainment Centre offers 5,000 square metres of clear-span floor space and is capable of catering for capacities from 2,000 to 6,500 for entertainment-style events. The Centre was built to house the now-defunct Newcastle Falcons National Basketball League team and was also home to the Hunter Pirates before a lack of sponsorship forced them to close after the 2005\u201306 season, with the licence sold to the Singapore Slingers. The Slingers played one home game at the Centre during the 2006\u201307 season.\nWater sports.\nNewcastle has an abundance of beaches and surf breaks for which the city is internationally well known. Newcastle hosts the annual surfing contest Surfest on the world professional surfing tour. Four-time world champion surfer Mark Richards grew up surfing at Newcastle's Merewether Beach, and is a local icon, appearing at many local functions, and supporting local charities. Nobbys Beach is a very popular kitesurfing spot, especially during the warm summer months when there are north-easterly sea breezes.\nMedia.\nNewcastle is served by a daily tabloid, \"The Herald\" (formerly \"The Newcastle Morning Herald and Miners' Advocate\" and then \"The Newcastle Herald\"), several weeklies including the \"Newcastle Star\", \"The Post\" and the bi-monthly \"The Hunter Advocate\".\nOther alternative media in the city include the university's student publications \"Opus\" and \"Yak\" magazine, \"Newcastle Mirage\" (a local arts and culture zine) and \"Urchin\" (a zine published by the media and arts organisation Octapod).\nThe city is also served by several local radio stations, including those owned by the Australian Broadcasting Corporation and SBS.\nNewcastle is also served by five television networks, three commercial and two national services:\nNine airs NBN News live from their Honeysuckle studios each night at six. The bulletin is a mix of its own locally produced stories mixed in with national and international stories sourced from the Nine Network. Local news updates are aired by the Seven, Nine (as NBN News) and 10 throughout the day to fulfil local content quotas.\nDisasters.\n1989 earthquake.\nOn 28 December 1989, Newcastle experienced an earthquake measuring 5.6 on the Richter scale, which killed 13 people, injured 162 and destroyed or severely damaged a number of prominent buildings. Some had to be demolished, including the large George Hotel in Scott Street (city), the Century Theatre at Broadmeadow, the Hunter Theatre (formerly 'The Star') and the majority of The Junction school at Merewether. Part of the Newcastle Workers' Club, a popular venue, was destroyed and later replaced by a new structure. The following economic recession of the early 1990s meant that the city took several years to recover. However, Beaumont Street, Hamilton, where many buildings sustained major damage, became a thriving cosmopolitan restaurant strip after the earthquake and is still going strong today. The earthquake helped to rekindle business in this suburban strip.\nJune 2007 Hunter Region and Central Coast storms.\nOn 8 June 2007 the Hunter and Central Coast regions were battered by the worst series of storms to hit New South Wales in 30 years. This resulted in extensive flooding and nine deaths. Thousands of homes were flooded, and many were destroyed. The Hunter and Central Coast regions were declared natural disaster areas by the State Premier, Morris Iemma, on 8 June 2007. Further flooding was predicted by the Bureau of Meteorology but was less severe than predicted.\nDuring the early stages of the storms, the bulk carrier ship \"Pasha Bulker\" ran aground at Nobbys Beach after failing to heed warnings to move offshore. After the first few attempts failed, the \"Pasha Bulker\" was refloated on the third salvage attempt on 2 July 2007 despite earlier fears that the ship would break up. After initially entering the port for minor repairs, it departed under tow on 26 July 2007 for major repairs in Asia.\nMaritime.\nOn 12 July 1866, a paddle steamer the , on its way to Brisbane from Newcastle carrying 60 passengers, was caught in a storm as it made its way out of the harbour. Sixty people died; coincidentally, one survivor, Frederick Hedges, was plucked from the water by the sole survivor of the \"Dunbar\" that had sunk in Sydney Harbour nine years earlier.\nThe most tragic maritime accident of the 20th century in Newcastle occurred on 9 August 1934 when the Stockton-bound ferry \"Bluebell\" collided with the coastal freighter, \"Waraneen\", and sank in the middle of the Hunter River. The Bluebell Collision claimed three lives and fifteen passengers were admitted to the Newcastle Hospital, with two suffering severely from the effects of immersion. It was later found that the ferry captain was at fault.\nThese are only two events in Newcastle's very long history of shipwrecks including the 1974 beaching of the , and the 2007 beaching of the \"Pasha Bulker\".\nAviation.\nOn 16 August 1966, an RAAF CAC Sabre crashed into the inner-city suburb of The Junction. The pilot, Flying Officer Warren William Goddard, experienced engine troubles and unsuccessfully tried to get the plane over the Pacific Ocean. The Junction is a highly populated suburb of Newcastle and most of the plane wreckage landed in the shopping area of the suburb. In 2007 a memorial plaque was unveiled for the killed pilot.\nHeritage listings.\nNewcastle has a number of heritage-listed sites, including:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "52666", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=52666", "title": "Joseph Lyons", "text": "Prime Minister of Australia from 1932 to 1939\nJoseph Aloysius Lyons (15 September 1879 \u2013 7 April 1939) was an Australian politician who served as the tenth prime minister of Australia, from 1932 until his death in 1939. He held office as the inaugural leader of the United Australia Party (UAP), having previously led the Tasmanian branch of the Australian Labor Party (ALP) before the Australian Labor Party split of 1931. He served as the 26th premier of Tasmania from 1923 to 1928.\nLyons was born in Stanley, Tasmania, and before entering politics worked as a schoolteacher. He was active in the Labor Party from a young age and won election to the Tasmanian House of Assembly in 1909. He was Treasurer of Tasmania (1914\u20131916) under John Earle, before replacing Earle as party leader in 1916. After two elections that ended in hung parliaments, Lyons was appointed premier in 1923 at the head of a minority government. He pursued moderate reforms and successfully negotiated a constitutional crisis over the powers of the Legislative Council. At the 1925 election he led Labor to its first majority government in Tasmania, but the party lost office three years later.\nIn 1929, Lyons resigned from state parliament to enter federal politics, winning the seat of Wilmot in Labor's landslide victory at the 1929 election. He was immediately appointed to cabinet by the new prime minister James Scullin, becoming Postmaster-General of Australia and Minister for Works and Railways. In 1930, he was acting treasurer while Scullin was overseas, and came into conflict with the Labor caucus over the government's response to the Great Depression; he preferred orthodox financial policies. In early 1931, Lyons and his followers left Labor to sit as independents. His exact motivations for leaving the party have been subject to debate. A few months later his group merged with other opposition parties to form the United Australia Party; he was elected Leader of the Opposition.\nLyons led the UAP to a landslide victory at the 1931 election. Nicknamed \"Honest Joe\", he was known as a masterful political campaigner and became popular with the general public. His personal popularity was a major factor in the government's re-election in 1934 and 1937; he was the first prime minister to win three federal elections. The UAP initially governed alone but after 1934 formed a coalition with the Country Party. Lyons was his own treasurer until 1935 and oversaw Australia's recovery from the Great Depression. He faced a number of foreign-policy challenges, but accelerated Australia's transition towards an independent foreign policy. In the lead-up to World War II his government pursued a policy of appeasement and rearmament.\nLyons died of a heart attack in April 1939, becoming the first Australian prime minister to die in office. He is the only prime minister from Tasmania and one of two state premiers who have become prime minister, along with George Reid. Several years after his death, his widow Enid Lyons became the first woman elected to the House of Representatives.\nEarly life.\nBirth and family background.\nLyons was born in Stanley, Tasmania, on 15 September 1879. He was the fifth of eight children born to Ellen (n\u00e9e Carroll) and Michael Henry Lyons, both of Irish descent. His mother was born in County Kildare and arrived in Australia in 1857, aged eleven, while his father was born in Tasmania to immigrants from County Galway. Lyons was the first prime minister to have an Australian-born parent. His paternal grandfather, Michael Lyons Sr., had arrived in Tasmania in 1843 with his wife and an infant daughter. Initially an indentured labourer, he became a tenant farmer after completing his term of service, and eventually saved enough to purchase land at Stanley, on the north-west coast. He had a reputation as a shrewd businessman, frequently buying and selling tracts of land and also dabbling in the hotel trade for a period. His sons followed him into farming, and the Lyons family was prominent in the small local community.\nChildhood.\nWhen Lyons was four years old, his father moved the family from Stanley to Ulverstone, where he opened a combined bakery and butcher's shop. In 1887, he lost the family's savings betting on the Melbourne Cup, driving them into poverty. He had to sell the shop and resort to working as an unskilled labourer; his oldest children took part-time jobs to support the family. Lyons began working at the age of nine, as a printer's messenger boy. By the age of twelve, he was \"cutting scrub\" (clearing land) for local farmers. Lyons had begun his education at the Ulverstone State School in 1885, before switching to the local Catholic school in 1887. His early years of schooling were interrupted by his family's financial difficulties, and his attendance was sometimes irregular, though this was not uncommon in small rural schools at the time. In 1891, he moved back to Stanley to live with his aunts, Etty and Mary Carroll, and was enrolled at the Stanley State School.\nTeaching career.\nIn 1895, aged fifteen, Lyons began working as a pupil-teacher under the monitorial system. This allowed him to continue his own education while being paid to teach younger students, and eventually qualify as a full-time teacher himself. Apart from a three-month stint as a relief teacher at Irishtown, he remained at Stanley until early 1901, when he was given charge of two small \"half-time\" schools on the east coast, Apslawn and Apsley Meadows. During that period, he lived at \"Apsley House\", the family estate of Sir William Lyne, Premier of New South Wales. In March 1902, Lyons transferred to the Midlands, taking charge of the schools at Conara and Llewellyn. He was transferred again in July 1905 to Tullah, then a few months later to Smithton, and then in April 1906 to Pioneer. In 1907, Lyons moved to Hobart to attend the newly opened Hobart Teachers' College for a year. He was then posted to Launceston, teaching at the Glen Dhu and Wellington Square State Schools, as well as briefly acting as headmaster at Perth. He came into conflict with the Department of Education on a number of occasions, often complaining about poor working conditions. His superiors also disapproved of his political activities, which together with his complaints probably contributed to his frequent transfers and failure to win desirable postings.\nState politics.\nLyons came from a family that was broadly sympathetic to the Australian labour movement, but without any formal political involvement. Though widely read, he did not actively participate in politics until after leaving Stanley. Lyons helped found a branch of the Workers' Political League during his time in Smithton, but was forced to resign his membership due to restrictions on the involvement of public servants in political activities. Those rules were later relaxed, and by 1908 he was spending most of his free time campaigning for the Labor Party; he had a reputation as a first-rate orator. Lyons was elected to the Tasmanian House of Assembly at the 1909 state election, standing in the six-member Division of Wilmot. This required him to resign from the Education Department and give up his teaching career, which reduced his annual salary from \u00a3125 to \u00a3100. He was comfortably re-elected in 1912, although he was attacked with a horsewhip during one of his campaign speeches. The son of one of his political opponents was convicted of assault, and the incident received widespread media attention.\nLabor came to power in Tasmania in 1914, after the existing Liberal government of Albert Solomon was defeated on a confidence motion. The new premier was John Earle, who had previously held office for one week in October 1909. In the new government, Lyons was made Treasurer, Minister for Education, and Minister for Railways; it was common for ministers to hold more than one portfolio. He was somewhat inexperienced with economic matters, and often turned to his friend and colleague Lyndhurst Giblin for advice; they eventually renewed their relationship at federal level during the 1930s. Less than a month after taking office, Lyons announced that the government was moving its accounts from the Commercial Bank of Tasmania to the Commonwealth Bank, which had only been established a few years earlier. In return he was able to secure a substantial loan and an overdraft of \u00a3100,000. The government faced a number of challenges during its two years in office, including a statewide drought, a series of bushfires in early 1915, and labour shortages due to the ongoing war. As Labor was in minority, many of its legislative initiatives were thwarted by the opposition. The party lost the 1916 state election by two seats, despite increasing its share of the vote.\nWhen the ALP split over conscription during the First World War in 1916, Earle, a pro-conscriptionist, followed Prime Minister Billy Hughes out of the Labor party. Like most Australians of Irish Catholic background, Lyons was an anti-conscriptionist and stayed in the Labor Party, becoming its new leader in Tasmania.\nPremier of Tasmania.\nLyons led the Labor opposition in the Tasmanian Parliament until 1923 when he became Premier of Tasmania, leading a minority ALP government. He held office until 1928, also serving as Treasurer during the whole period of his premiership. Lyons's government was cautious and pragmatic, establishing good relations with business and the conservative government in Canberra, but attracting some criticism from unionists within his own party. Labor narrowly lost the 1928 state election to the Nationalist Party.\nAs premier, Lyons faced a constitutional crisis relating to the powers of the Tasmanian Legislative Council (the parliament's upper house). The Legislative Council had a limited franchise and was occupied mostly by conservative landowners, and was consequently opposed to much of the government's platform. Historically, it had claimed for itself the power to amend money bills, despite having no express constitutional authority to do so. In November 1924, the council returned the government's budget to the Legislative Assembly with a series of proposed reductions in spending. Lyons chose to ignore the amendments, instead sending the bill directly to the Administrator, Herbert Nicholls, who approved it. In 1926, the government amended the state constitution to codify the Legislative Council's powers over money bills, bringing them into line with the other states.\nOn 15 July 1926, Lyons suffered severe leg injuries when his car\u2014driven by a chauffeur\u2014collided with a goods train near Perth. He came close to death, and stood down from public duties for four months to recover; Allan Guy was acting premier in his absence. Michael O'Keefe, the Speaker of the Tasmanian House of Assembly, was also a passenger in the car, and lingered for several months before dying of his injuries.\nFederal politics.\nAt the 1929 Australian federal election Lyons ran for the federal seat of Wilmot, covering the same territory as his state seat. He was swept into office in Labor's landslide victory under James Scullin. He was appointed Postmaster-General and Minister for Works and Railways.\nWhen the Great Depression struck in 1930, the Scullin government split over its response. Lyons became the leading advocate within the government of orthodox finance and deflationary economic policies, and an opponent of the inflationary, proto-Keynesian policies of Treasurer Ted Theodore. Theodore was forced to resign over accusations of corruption in June 1930, and Scullin took over the Treasury portfolio in addition to the Prime Ministership. Lyons was acting Treasurer from August 1930 to January 1931, whilst Scullin was in Britain for the Imperial Conference. Lyons announced his plan for recovery in October 1930, insisting on the need to maintain a balanced budget and cut public spending and salaries, although also advising lower interest rates and the provision of greater credit for industry.\nHis conservative economic approach won him support among business, but angered many in the Labor caucus, who wanted to expand the deficit to stimulate the economy, and were horrified at the prospect of cuts in salaries and government spending. Alienated by their attacks, Lyons began to consider suggestions from a group of his new business supporters, including influential members of the Melbourne Establishment, that he leave the government to take over the leadership of the conservative opposition.\nResignation from the Labor Party.\nWhen Scullin returned in January 1931, he reappointed Theodore (as it had become clear Theodore would not be charged with corruption) to the Cabinet as Treasurer, which Lyons took as a rejection of his own policies. Lyons immediately resigned from the Cabinet, and then in mid\u2013March from the Labor Party. Accompanied by another senior minister in the Scullin government, James Fenton, and four other right-wing Labor MPs, he crossed the floor to sit on the opposition benches. Soon afterward, Lyons and his supporters joined with the opposition Nationalist Party and the Australian Party, a small party led by Billy Hughes, to form a new party, the United Australia Party (UAP).\nAlthough the UAP was essentially an enlarged Nationalist Party, Lyons was chosen as leader of the party. He thus became Leader of the Opposition, with former Nationalist leader John Latham as his deputy. The UAP realised that Lyons, an affable family man with the common touch, was a far more electorally appealing figure than the aloof Latham. Additionally, his Labor background and his Catholicism would allow him to win traditional Labor constituencies (working-class voters and Irish Catholics) over to what was essentially an upper- and middle-class conservative party.\nIn March, at about the same time as Lyons led his group of defectors from the right of the Labor Party across the floor, five left-wing NSW Labor MPs, supporters of New South Wales Premier Jack Lang, also split from the official Labor Party over the government's economic policies (for Lyons official Labor had been too radical, for the Langites they were not radical enough), forming a \"Lang Labor\" group on the cross-benches and costing the government its majority in the House of Representatives. Late in the year, the Langite MPs supported a UAP motion of no confidence and brought the government down, forcing an early election.\nPrime minister.\nElections and government formation.\nAt the 1931 election Lyons and the UAP offered stable, orthodox financial policies in response to what they branded as Scullin's poor stewardship of the economy. While Labor remained split between the official party and the Langites, the UAP projected an image of putting national unity above class conflict. The result was a huge victory for the UAP, which took 34 seats against 18 seats for the two wings of the Labor Party combined.\nAt the outset, the UAP did not renew the traditional non-Labor Coalition with the Country Party, then led by Sir Earle Page. While the two parties ran separate House campaigns, they presented a joint ticket for the Senate. The massive swing to the UAP left it only four seats short of a majority in its own right. The five MPs elected for the Emergency Committee of South Australia, which stood for the UAP and Country Party in South Australia, joined the UAP party room, giving the UAP a bare majority of two seats. While Lyons was still willing to take the Country Party into his government (which would have commanded over 70 percent of the seats), negotiations stalled, and Lyons decided to govern alone. The new government was sworn in January 1932. Lyons became the third former federal or state Labor leader (after Hughes and Joseph Cook) to become a non-Labor Prime Minister.\nAfter the UAP suffered an eight-seat swing in the 1934 election, Lyons was forced to invite the Country Party into his government in a full coalition, with Earle Page as Deputy Prime Minister. The government won a third term at the 1937 election, with 44 of 74 seats and 50.6 percent of the two-party-preferred vote against a reunited Labor Party led by John Curtin.\nWhile campaigning, Lyons made extensive use of the new technologies of radio, film, and air travel. He held frequent press conferences and personally briefed journalists, editors, and newspaper proprietors to gain favourable publicity.\nDomestic policy.\nLyons adhered to the principles of \"sound finance\", opposing inflation and government debt and stressing the importance of balanced budgets and orderly loan repayments. Although he had been state treasurer for seven years, he portrayed himself as a relative outsider to economic policy who would take the advice of experts. Lyons appointed himself Treasurer of Australia, the first non-Labor prime minister to do so and the first incoming prime minister to do so since Andrew Fisher in 1914. He had earlier offered the treasurership to Ben Chifley as an inducement to leave the Labor Party, but Chifley declined. He appointed experienced assistant treasurers, initially Stanley Bruce and later Walter Massy-Greene and Richard Casey, who eventually succeeded as Treasurer in 1935.\nThe Lyons government's plan for recovery was a reprise of the Premiers' Plan which had split the Labor Party. It called for devaluation of the Australian pound, cuts to public servants' wages, reductions in tariffs, reductions in budget deficits, and greater spending on work-relief programmes. Lyons's first budget in 1932 restricted maternity allowances, cut pensions, and cut public servants' wages. His second budget reversed wage cuts and offered tax cuts, which were followed by further tax cuts in the 1934 budget. By some measures Australia recovered from the Great Depression more rapidly than other similar countries, but the effect of the government's policies have been subject to debate, with some arguing they either slowed or had little effect on Australia's recovery.\nIn April 1933, Western Australia voted overwhelmingly to secede from the rest of the country. Lyons spent two weeks campaigning for the \"No\" vote with George Pearce and Tom Brennan. The state's isolation at the time was such that he had to appoint John Latham as acting prime minister for the duration of the trip. Despite the result of vote, the federal government viewed secession as unconstitutional and refused to allow Western Australia to leave the federation. The state's appeal to the British government to intervene was also unsuccessful. In July 1933, Lyons established the Commonwealth Grants Commission to provide impartial advice about the distribution of federal government grants to the states; it remains in existence.\nOther legislative accomplishments of the Lyons government include the creation of the Australian Broadcasting Commission (ABC) in 1932 and the \"Income Tax Assessment Act 1936\". The government's landmark national insurance scheme proved politically controversial and was never enacted. Political controversies included the Egon Kisch affair of 1934 and the Dalfram dispute of 1938. In 1937, two simultaneous referendums were held, relating to aviation and the marketing of agricultural products; both failed.\nForeign policy.\nLyons had no previous experience in international relations or diplomacy, but as prime minister took a keen interest in foreign relations and exerted significant influence over the government's foreign policy. His government pursued what has been called a policy of \"appeasement and rearmament\". Increases in Australia's defence budget in the years before World War II made him \"the greatest peace-time rearmer in Australian history\", and saw the military rebuilt after severe funding cuts during the Great Depression. Lyons had pacifist leanings and was keen to avoid a repeat of the First World War. These were rooted in his religious convictions, but also influenced by visits to the battlefields of Europe in which he viewed the graves of Australian soldiers. The appeasement aspect of his foreign policy was primarily directed at Italy and Japan, as it was likely that war between those countries and other major powers would affect the important trade routes in the Mediterranean and the Pacific upon which Australia relied. He was particularly concerned with Anglo-Italian and Anglo-Japanese relations, where his goal was to \"influence British policy in a manner conducive to Australian interests\".\nAccording to David Bird, whose book \"The Tame Tasmanian\" examined the Lyons government's foreign policy, there was a growing realisation in the 1930s that Australian interests would not be aligned with British interests in all cases. In order to differentiate the two, Lyons authorised three \"Pacific initiatives\". The first was the Australian Eastern Mission of 1934 led by Deputy Prime Minister John Latham, which visited seven Asian countries. The second was the 1935 appointment of Australian government representatives in China, the Dutch East Indies, Japan, and United States \u2013 albeit below the rank of ambassador \u2013 where previously Australia's interests had been represented solely by British officials. The third was Lyons's \"Pacific Pact\" proposal, which envisioned a non-aggression pact between the major powers in the Pacific. Although he championed the pact at the 1937 Imperial Conference, discussions failed to progress. In Bird's opinion, \"the Lyons years should thus be seen as a part of the evolution of Australian external policy from dependency towards autonomy [\u2026] it is perhaps the continuation and acceleration of the process of transition for which Lyons as Prime Minister ought to be best remembered\".\nLyons was prime minister during the Edward VIII abdication crisis of 1936. He and the other Dominion leaders were only officially informed of the king's intention to abdicate a few weeks before it occurred, although he had found out about the situation earlier through unofficial channels. Lyons strongly opposed the proposed marriage to Wallis Simpson, a view shared by his cabinet; it is unclear if he was initially aware how deep the king's feelings were. He later telegraphed the king asking him not to abdicate, and after the event gave a speech in parliament announcing his regret at the king's decision. Lyons is the only Australian prime minister to have held office during the reigns of three monarchs, and the only prime minister to serve throughout a monarch's entire reign.\nRetirement plans.\nIt was initially assumed Lyons would be succeeded by his deputy John Latham, but Latham left parliament at the 1934 election and the following year was appointed Chief Justice of Australia. His replacement in the Division of Kooyong was Robert Menzies, a prominent figure in Victorian politics and an ally of Lyons. In April 1936, Lyons hand-wrote a letter to Menzies endorsing him as his successor. For various reasons, Menzies did not enjoy universal support within the UAP, and several other were seen as potential successors to Lyons. Within the parliamentary UAP, Richard Casey, Charles Hawker, Billy Hughes, and Archdale Parkhill all had supporters. There was also support for figures outside parliament, including former prime minister Stanley Bruce and Bertram Stevens, premier of New South Wales.\nBy 1938, Lyons was making concrete plans to retire, renovating his house in Devonport and moving his youngest children away from Canberra to attend local schools. According to his wife, they discussed his future two weeks before his death and agreed that he would retire as soon as possible. However, UAP officials repeatedly pressured him to stay on until the most suitable successor could be found.\nDeath.\nOn 5 April 1939, Lyons suffered a heart attack while being driven from Melbourne to Sydney. It occurred shortly after he had stopped in at Goulburn to collect his son Kevin from St Patrick's College for the Easter holidays. Lyons was rushed to St Vincent's Hospital, Darlinghurst, in a critical condition. By the following day, he was unable to speak and was drifting in and out of consciousness. He soon fell into a coma, and died on the morning of 7 April, which was Good Friday. Lyons's body lay in state at St Mary's Cathedral until 10 April (Easter Monday). A requiem service was held the following day, and then a procession bearing his coffin proceeded from the cathedral to Circular Quay. Lyons's body was transported to his home town of Devonport aboard HMAS \"Vendetta\". His funeral was held at the Church of Our Lady of Lourdes on 13 April, and he was buried in the church grounds. He was re-interred in the new Mersey Vale Memorial Park in 1969, where he was joined by his wife in 1981.\nLyons was the first Australian prime minister to die in office. There was no constitutional precedent as to who should be appointed as his successor, and the situation was further complicated by the UAP's lack of a deputy leader. When the seriousness of Lyons's condition became apparent, Earle Page\u2014the leader of the Country Party and \"de facto\" deputy prime minister\u2014called a cabinet meeting, where it was agreed that he should serve as prime minister on an interim basis while the UAP elected a new leader. He was sworn in by Governor-General Lord Gowrie only 3 hours after Lyons's death. The 1939 United Australia Party leadership election was held on 18 April and won by Robert Menzies, who replaced Page as prime minister on 26 April. According to Laurie Fitzhardinge, Lyons's death \"removed the only force that had held in check the smouldering animosities and barely suppressed rivalries which divided [the UAP's] members\".\nPersonal life.\nOn 28 April 1915, Lyons married Enid Burnell, the daughter of a family friend; she was almost 18 years his junior. He had begun courting her in 1912, when she was 15. The couple had twelve children together:\nSeveral years after Lyons's death, his widow Enid also embarked on a political career, becoming the first woman elected to the House of Representatives and serving in cabinet in the post-war Menzies Government. Their sons Kevin and Brendan entered Tasmanian politics, becoming state government ministers several decades after their father's death. Their grandchildren include Libby Lyons, sigma (and director) of the Workplace Gender Equality Agency, and Kevin Lyons Jr., who was appointed to the Supreme Court of Victoria in 2018.\nBefore his marriage, Lyons had briefly been engaged to Pearl \"Pib\" Bailey, whom he met while teaching at Conara in about 1902. He broke off their relationship for reasons unknown, but they remained firm friends; Bailey never married and kept the love letters they exchanged for the rest of her life.\nIn 2018, a Jim Starkey who is married to Wendy Starkey, a great-granddaughter of another former prime minister Billy Hughes, claimed to be the great-grandson of Lyons. However, Starkey's claim of familial relations with Lyons has been disputed by the Lyons family and Lyons biographer Anne Henderson.\nLegacy.\nLyons was one of the most genuinely popular men to hold the office of prime minister, and his death caused widespread grief. His genial, laid-back appearance often led to his portrayal in cartoons as a sleepy koala. A devout Catholic, he was the second Catholic to become prime minister, after his immediate predecessor Scullin, and the only non-Labor Catholic prime minister until Tony Abbott.\nLyons is the only person in Australian history to have been prime minister, premier of a state, treasurer and leader of the opposition in both the Federal Parliament and a state parliament (although George Reid had been premier of a colony before Federation). Lyons is also the only prime minister to have come from Tasmania. At the time of his death, he was the second-longest serving prime minister in Australia's history, behind only Hughes.\nHonours.\nLyons was appointed to the Privy Council of the United Kingdom in June 1932, a traditional honour for Australian prime ministers. He was formally sworn of the council when he visited London in March 1935. In the 1936 Birthday Honours, he was appointed as a Member of the Order of the Companions of Honour (CH), one of only four such appointments made by Edward VIII before his abdication.\nAfter Lyons's death, the Canberra suburb of Lyons was named in his honour, located in the Woden Valley adjacent to Curtin and Chifley. In 1975 he was honoured on a postage stamp bearing his portrait issued by Australia Post. His old seat of Wilmot was renamed the Division of Lyons in 1984, in joint honour of him and his wife Enid. The state seat of Wilmot was also renamed Lyons for the same reason. Lyons's birthplace in Stanley (\"Joe Lyons Cottage\") and family home in Devonport (\"Home Hill\") are operated as heritage sites, the latter by the National Trust of Australia.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52667", "revid": "11968233", "url": "https://en.wikipedia.org/wiki?curid=52667", "title": "Ben Chifley", "text": "Prime Minister of Australia from 1945 to 1949\nJoseph Benedict Chifley (; 22 September 1885 \u2013 13 June 1951) was an Australian politician who served as the 16th prime minister of Australia from 1945 to 1949. He held office as the leader of the Australian Labor Party (ALP), and was notable for defining Australia's post-war reconstruction efforts, enacting social and immigration reform and advancing the nationalisation of essential industries.\nChifley was born in Bathurst, New South Wales, and joined the New South Wales Government Railways after leaving school, eventually qualifying as an engine driver. Before entering politics, he was an organiser for the Federated Union of Locomotive Employees, and was also a director of \"The National Advocate\". After several previous unsuccessful candidacies, Chifley was elected to parliament in the 1928 federal election. In 1931, he was appointed Minister for Defence in the government of James Scullin. He served in cabinet for less than a year before losing his seat at the 1931 federal election, which saw the government suffer an electoral wipeout.\nAfter his electoral defeat, Chifley remained involved in politics as a party official, siding with the federal Labor leadership against the Lang Labor faction. He served on a royal commission into the banking system in 1935, and in 1940 became a senior public servant in the Department of Munitions. Chifley was re-elected to parliament later that year, on his third attempt since 1931. He was appointed Treasurer in the new Curtin government in 1941, as one of the few Labor MPs with previous ministerial experience. The following year Chifley was additionally made Minister for Postwar Reconstruction, making him one of the most powerful members of the government. He became prime minister following Curtin's death in office in 1945, defeating caretaker prime minister Frank Forde in a leadership ballot.\nAt the 1946 Australian federal election, Chifley was re-elected with a slightly reduced majority \u2013 the first time that an incumbent Labor government had won re-election. The war had ended a month after he took office, and over the following three years his government embarked on an ambitious program of social reforms and nation-building schemes. These included the expansion of the welfare state, increased the post-war immigration to Australia, and the establishment of the Australian National University, the Australian Security Intelligence Organisation (ASIO), and the Snowy Mountains Scheme. Some of the new legislation was successfully challenged in the High Court, and as a result the constitution was amended to give the federal government extended powers over social services.\nSome of Chifley's more interventionist economic policies were poorly received by Australian business, particularly an attempt to nationalise banks. His government was defeated at the 1949 Australian federal election, which brought Robert Menzies' Liberal Party to power for the first time. He stayed on as Leader of the Opposition until his death, which came a few months after the 1951 Australian federal election; Labor did not return to government until 1972. For his contributions to post-war prosperity, Chifley is often regarded as one of Australia's greatest prime ministers. He is held in particularly high regard by the Labor Party, with his \"light on the hill\" speech seen as seminal in both the history of the party and the broader Australian labour movement.\nEarly life.\nChifley was born at 29 Havannah Street, Bathurst, New South Wales, on 22 September 1885. He was the first of three sons born to Roman Catholic parents: Mary Anne (n\u00e9e Corrigan) and Patrick Chifley II. His father, a blacksmith, was born in Bathurst to Irish immigrants from County Tipperary, while his mother was born in County Fermanagh, in present-day Northern Ireland.\nAt the age of five, Chifley was sent to live with his widowed grandfather, Patrick Chifley I, who had a small farm at Limekilns, New South Wales, while his aunt, Mary Bridget Chifley, kept house for them. Chifley began his education at the local state school, which was known as a \"half-time school\" due to it being too small to offer daily classes; it shared a single teacher with a neighbouring community. He moved back to his parents' home at the age of 13, following his grandfather's death in January 1899, and attended a Patrician Brothers school for about two years. He was a voracious reader from a young age, and would later supplement his limited formal education by attending classes at night schools or mechanics' institutes.\nAfter leaving school, Chifley's first job was as a cashier's assistant at a local department store. He later worked at a tannery for a period, and then in September 1903 joined the New South Wales Government Railways as a \"shop boy\" at the Bathurst locomotive shed. Over the following decade, he was promoted through the ranks to engine-cleaner and fireman, and then finally in March 1914 to engine-driver. The position of driver was considered relatively prestigious, and Chifley had to sit various examinations before being certified. He developed an intimate technical understanding of his locomotives, and became a lecturer and instructor at the Bathurst Railway Institute. Chifley drove both goods trains and passenger trains. He was based in Bathurst and worked on the Main Western railway, except for a few months in 1914 when he drove on the Main Southern railway and worked out of Harden, New South Wales.\nChifley became involved with the labour movement as a member of the Locomotive Enginemen's Association. He never held executive office, preferring to work as an organiser, but did serve as a divisional delegate to state and federal conferences. He developed a reputation for compromise, maintaining good relations with both the railway management and the more militant sections of the union. However, Chifley was one of the local leaders of the 1917 Australian general strike, and as a result was dismissed by NSWGR. He and most of the other strikers were eventually reinstated, but lost seniority and related privileges; Chifley was demoted from engine-driver to fireman. Despite repeated lobbying, their pre-1917 benefits were not restored until 1925. After the strike, the state government of William Holman also de-registered their union, placing it at a severe disadvantage against other railway unions. Chifley worked to secure its re-registration, which occurred in 1921, and was also involved in the formation of a national union \u2013 the Australian Federated Union of Locomotive Enginemen \u2013 in 1920. He appeared as an expert witness before the Commonwealth Court of Conciliation and Arbitration in 1924, which subsequently implemented a new federal industrial award for the enginemen.\nEarly political involvement.\nChifley joined the Australian Labor Party at a young age, and was involved in state and federal election campaigns as an organizer. In 1921, he replaced his father on the board of \"The National Advocate\", a local newspaper that functioned as the mouthpiece of the labour movement. In 1922 and 1924, Chifley unsuccessfully contested Labor preselection for the NSW Electoral district of Bathurst. He was eventually chosen as the Labor candidate for the Division of Macquarie at the 1925 Australian federal election. Macquarie was a large and diverse electorate, covering an area from Bathurst east across the Blue Mountains to Penrith, on the outskirts of Sydney; it included industrial, agricultural, and mining districts in virtually equal measure. It was one of the most marginal seats in the country, and had last been won by Labor in 1919. Lacking name recognition, Chifley lost the election to the incumbent Nationalist MP, Arthur Manning. However, he reprised his candidacy in 1928, mounting a campaign that focused on the Bruce government's unpopular labour policies. He accused the government of endangering the White Australia policy by allowing Southern European migrant workers into the country, claiming it had \"allowed so many dagoes and aliens in Australia that today they are all over the country taking work which rightly belongs to all Australians\". The Labor Party recorded a 6.2-point swing in Macquarie, with Chifley becoming one of three candidates in New South Wales to win seats from the government.\nEarly political career.\nAt the 1929 election, Chifley was re-elected on a 10.7-point swing as Labor won a landslide victory. James Scullin became the new prime minister, the fourth member of his party to hold the office. As a backbencher with little parliamentary experience, Chifley did not stand for election to the Scullin Ministry, but did join the Public Accounts Committee. As the Great Depression worsened, he defended the government's economic response against criticism from two factions within his own party \u2013 economic conservatives led by Joseph Lyons and left-wing populists led by Jack Lang. His loyalty paid off in March 1931, when the Labor caucus chose him to fill one of the vacancies in cabinet caused by the resignations of Lyons and James Fenton. Scullin appointed him Minister for Defence, a portfolio that had been disregarded somewhat in the face of more pressing concerns. There was little appetite for policy development, and Chifley instead concentrated on finding savings in his department that could be redirected to unemployment relief. He opened up unused military camps to the homeless, and also distributed surplus military clothing.\nChifley was somewhat reluctant in his support of the Premiers' Plan, but believed there was no better alternative and felt bound by the principle of cabinet solidarity. His endorsement of the plan, which required cuts to wages and pensions, was received poorly in his own constituency. Many in the local labour movement defected to Lang Labor, which opposed the plan, and his own union expelled him in August 1931. Joseph Lyons reportedly offered Chifley the treasurership as an inducement to join the new United Australia Party (UAP); Chifley declined and remained a member of the Labor Party. At the 1931 election, Chifley suffered a negative swing of 16.2 points in Macquarie, losing his seat to John Lawson, the UAP candidate, by just 456 votes on the final count. The Labor Party was reduced to 14 seats out of 75 in the House of Representatives, with five other ministers (including Treasurer Ted Theodore) and future prime minister John Curtin also losing their seats.\nWilderness years.\nDuring the Great Depression, with no parliamentary salary and no chance of returning to the railway, Chifley survived on his wife's family's money and his part-ownership of the Bathurst newspaper \"The National Advocate\".\nIn 1938, Chifley and most other Labor supporters in Bathurst joined the Industrial Labor Party (ILP), a breakaway organisation formed by Bob Heffron and dedicated to thwarting the Lang Labor faction that controlled the ALP in New South Wales. He was a delegate to the party's annual conference in Sydney in April 1939. After a unity conference in August 1939, the ILP members rejoined the ALP and ended Jack Lang's dominance. Chifley was subsequently elected to the ALP state executive.\nIn 1935 the Lyons government appointed Chifley as a member of the Royal Commission on Banking, a subject on which he had become an expert. He submitted a minority report advocating that the private banks be nationalised. After an unsuccessful effort to win back Macquarie at the 1934 Australian federal election, Chifley finally won his seat back at the 1940 Australian federal election on a swing of ten percent.\nCurtin government.\nChifley was appointed Treasurer of Australia when the Labor leader, John Curtin, formed a mid-term Labor government in 1941 following the collapse of the first Menzies government. Although deputy Labor leader Frank Forde was nominally the deputy in the government, Chifley became the minister Curtin most relied on, controlling most domestic policy while Curtin was preoccupied with the Second World War. Of highest importance was war funding, followed by the strong desire to control inflation. In February 1942, he announced the pegging of wages and profits, the introduction of controls on production, trade and consumption to reduce private spending, and the transfer of surplus personal income to savings and war loans. On 15 April 1942, more price controls were introduced. On 23 July, a uniform income tax was attained when the States were defeated in the High Court of Australia.\nThe Australian Dictionary of Biography claims Chifley proved himself to be his country's greatest treasurer \u2013 fiscally responsible, able to transmit the necessity for a reasonable equality of sacrifice, and capable of managing a wartime economy of complexity and difficulty. Financing the war by increased taxation, loans from the Australian public, and central bank credit, he ensured that the nation did not become burdened with overseas debt, as it had been after First World War. Every budget was accompanied by his strictures on 'vigorous self-denial', labour discipline and restriction of consumer demand with the aim of controlling a huge accumulation of purchasing power.\nPrime minister.\nFollowing the death of Curtin in July 1945, Forde became prime minister since he was the ALP deputy leader. In the ensuing leadership ballot, Chifley defeated Forde to replace him as prime minister and Curtin as leader of the ALP. Once the war ended in September, normal political life resumed, and Chifley faced Robert Menzies and his new Liberal Party in the 1946 election, which Chifley won with 54 percent of the two-party-preferred vote. It marked the first time that an incumbent full-term federal Labor government was re-elected. In the post-war years, Chifley maintained wartime economic controls, including the highly unpopular petrol rationing. He did this partly to help Britain in its postwar economic difficulties.\nUpon becoming prime minister, Chifley continued as Treasurer and remained so for the entirety of his prime ministership. To date, Chifley is the last prime minister to have been his own Treasurer for a period that was not transitionary, as happened in 1972 and 1991 with Gough Whitlam and Bob Hawke respectively.\nChifley was also the longest-serving Labor Treasurer until this record was broken by Paul Keating in 1991 and Keating, like Chifley, would become prime minister.\nLegislative achievements.\nFeeling secure in an unprecedented position, Chifley looked toward the Labor platform objective of democratic socialism. According to a biographer of Chifley, his government embarked upon greater intervention in \"economic and social affairs\", with policies directed towards better workplace conditions, full employment, and the \"equalisation of wealth, income and opportunity\". Chifley was successful in steering the economy into peacetime, and undertook a number of social welfare initiatives, as characterised by fairer pensions and unemployment and sickness benefits, the construction of new universities, technical colleges, and 200,000 houses.\nThe amount of reforms undertaken was such that, between 1946 and 1949, the Parliament of Australia passed an at-the-time record 299 Acts of Parliament, which was well beyond the previous record of 113 Acts by the Second Fisher government. Among other measures, the Chifley government passed legislation to establish universal health care modelled on the British National Health Service, including a free formulary of essential medicines. This was successfully opposed as unconstitutional in the High Court of Australia by the Australian branches of the British Medical Association, who were the precursors of the Australian Medical Association, in the \"First Pharmaceutical Benefits case\". One of the few successful referendums to modify the Australian Constitution, the 1946 Social Services referendum, made possible many of the Chifley government's other legislative initiatives in social welfare and social provision and permitted federal legislation over pharmaceutical benefits and medical and dental services. It also authorised federal legislation with respect to pensions, benefits, and allowances.\nSuch as, in the same year as the referendum, when concessional rate radio licences were introduced for pensioners, and were later extended to widow pensioners and also to television licences. The following year, in 1947, specific racial disqualifications other than those referring to Aboriginal Australians were removed, while the Wife's Allowance became payable to de facto wives who had lived with the pensioner for at least three years. The subsequent federal legislation in relation to pharmaceutical benefits was deemed constitutional by the High Court. This paved the way for the introduction of the Pharmaceutical Benefits Scheme (PBS), an important component of Australia's modern public health system.\nFrom July 1947, a prepayment of Maternity Allowance could be made up to four weeks before the expected date of the birth of the child. Moreover, eligibility for maternity benefits was extended to mothers who were classified as an alien but had lived in Australia for 12 months residence. Then again that same year, eligibility for Child's Allowance was extended to those wives whose husbands were in asylums and to single invalid pensioners who had the custody, care and control of a child. An additional benefit of five shillings per week for the first child became available to a beneficiary who had custody and spent an equivalent or more of the benefit on the child. Amendments were also made to legislation on Child Endowment to allow Australians temporarily absent from Australia and newly arrived migrants to receive the benefit. Furthermore, from July 1947, funeral benefits could be paid in respect of claimants for Age Pension or Invalid Pension who would have qualified had they lived. Under the \"Social Services Consolidation Act 1947\", an additional benefit became payable in cases where a man with one or more dependent children had a female partner, where he was not receiving benefit for his wife; a partial additional benefit became payable for a partially dependent spouse; and wives legally separated or likely to be permanently living apart from their husbands became eligible for benefit.\nChifley's government oversaw the creation of the Commonwealth Employment Service, the introduction of federal funds to the States for public housing construction and the \"Acoustic Laboratories Act 1948\", which established the Commonwealth Acoustic Laboratories to undertake scientific investigations into hearing loss. Although it failed in its attempts to establish a national health service, the Chifley government was successful in making arrangements with the states to upgrade the quality and availability of hospital treatment. The \"Mental Institutions Benefits Act 1948\" marked the entry of the Commonwealth into mental health funding, where, in return for free treatment, the states were paid a benefit equal to the charges upon the relatives of mental hospital patients. The achievements of the Labor governments of Chifley and Curtin in expanding Australia's social welfare services were brought together under the \"Social Services Consolidation Act 1947\", which consolidated the various social services benefits, liberalised some existing social security provisions, and increased the rates of various benefits.\nAmong the government's other legislative achievements included the establishment of a separate Australian citizenship in 1948 and the founding of ASIO. Science and education was also expanded, with a reorganisation and enlargement of the CSIRO, alongside passing the \"Australian National University Act\" which provided post-graduate facilities in Australia and augmented the supply of staff for universities. Tertiary education extensively benefitted through the establishment of the Australian National University and the Commonwealth Education Office. The establishment of the Commonwealth Reconstruction Training Scheme to provide ex-servicemen with the opportunity to undertake a university education, with an interim five-year scholarships established to encourage other able students to attend universities. This was alongside annual grants to universities to provide the necessary staff and accommodation for the influx of assisted students and ex-servicemen. In addition, returned soldiers were also provided with a war gratuity and entitlement to special unemployment allowances, loans, vocational training, and preference in employment for seven years.\nIn July 1948, the Dairy Industry Fund was created with the purpose of stabilising returns from exports, and further financial grants to the States were introduced to assist them in expanding their agricultural activities. The establishment of a Coal Industry Tribunal and a Joint Coal Board in 1946 also brought significant gains for miners; and life insurance came to be comprehensively regulated.\nAmong the Chifley government's other legislative measures included the post-war immigration scheme, the establishment of Australian citizenship, the beginning of construction of the Snowy Mountains Scheme, the establishment and nationalisation of Trans Australia Airlines and Qantas respectively, improvements in social services, the creation of the Commonwealth Employment Service, the introduction of federal funds to the States for public housing construction, the establishment of a Universities Commission for the expansion of university education, free hospital treatment, the reorganisation and enlargement of the CSIRO, and the establishment of the Commonwealth Rehabilitation Service. As noted by one historian, Chifley's government \"balanced economic development and welfare support with restraint and regulation and provided the framework for Australia's post-war economic prosperity.\"\nLater controversial actions.\nIn 1947, Chifley announced the government would initiate a nationalisation of the banks. This provoked massive opposition from the press, and middle-class opinion turned against Labor. The High Court found Chifley's legislation to be unconstitutional. The government appealed the decision in the Privy Council, but it upheld the High Court's decision.\nHowever, Chifley's government did succeed in passing the \"Banking Act 1945\" and the \"Commonwealth Bank Act 1945\" which gave the government control over monetary policy and established the Commonwealth Bank as Australia's national bank.\nDuring the 1948 Queensland railway strike, Chifley barred striking workers from being eligible for unemployment benefits. A prolonged and bitter strike in the coal industry began in June 1949 and caused unemployment and hardship. Chifley saw the strike as a move by the Communist Party to challenge Labor's place as the party of the working class, and he sent in 13,000 army troops to break the strike. Early on in the strike, Chifley and H. V. Evatt froze Miner's Federation funds and \"introduced legislation aimed at starving the workers back to work\".\nIn 1949 in the House of Representatives, Chifley stated that the Labor Party was a \"bulwark against communism\", and that the most effective way of weakening the strength of the Communist Party was \"improving the conditions of the people\". Despite this, Menzies exploited the rising Cold War hysteria to portray Labor as soft on Communism. These events, together with a perception that Chifley and Labor had grown increasingly arrogant in office, led to the Liberal election victory at the 1949 election. While Labor won an additional four seats in a House of Representatives that had been expanded from 74 seats to 121 seats, Menzies and the Coalition won an additional 48. Labor retained a Senate majority however.\nOpposition.\nChifley was now aged 64 and in poor health (like Curtin, he was a lifelong smoker), but he refused to retire from politics. Though out of government, having retained a Senate majority, Chifley continued as Labor leader and became Leader of the Opposition. The opposition Senate majority would frequently ensure the passing of Labor amendments, or outright blocking, of Menzies Government legislation.\nMenzies responded by introducing a bill to ban the Communist Party of Australia in 1950. He expected Chifley to reject it and give him an excuse to call a double dissolution election. Menzies apparently hoped to repeat his \"soft-on-Communism\" theme to win a majority in both chambers.\nHowever, Chifley let the bill pass after a redraft (it was ultimately thrown out by the High Court). However, when Chifley rejected Menzies' Commonwealth Banking Bill a few months later, Menzies called a double dissolution election for April 1951. Although Chifley managed to lead Labor to a five-seat swing in the House, Labor lost six seats in the Senate, giving the Coalition control of both chambers.\nDeath.\nA few weeks later on 13 June 1951, Chifley suffered a heart attack in his room at the Hotel Kurrajong in Canberra.\nChifley at first made light of the sudden chest pains and attempted to dissuade his secretary and confidante, Phyllis Donnelly, who was making him a cup of tea, from calling a doctor. As his condition deteriorated, however, Donnelly called Dr. John Holt, who ordered Chifley's immediate removal to hospital. Chifley died in an ambulance on the way to the Canberra Community Hospital. He was pronounced dead at 10:45\u00a0pm.\nMenzies heard of Chifley's demise while attending a parliamentary ball at King's Hall in Parliament House to celebrate the 50th Jubilee of Federation (Chifley was invited but had declined to attend). Menzies was deeply distressed and abandoned his normally impassive demeanour to announce in a halting subdued voice:It is my very sorrowful duty during this celebration tonight to tell you that Mr Chifley has died. I don't want to try to talk about him now because, although we were political opponents, he was a friend of mine and yours, and a fine Australian. You will all agree that in the circumstances the festivities should end. It doesn't matter about party politics on an occasion such as this. Oddly enough, in Parliament we get on very well. We sometimes find we have the warmest friendships among people whose politics are not ours. Mr Chifley served this country magnificently for years.\nChifley was buried at the Bathurst cemetery on 18 June 1951.\nPersonal life.\nChifley married Elizabeth McKenzie (known as \"Lizzie\") on 6 June 1914. She was the daughter of a more senior railways employee, George McKenzie. The couple began courting in 1912, but had known each other since childhood. The McKenzies were Presbyterian, and Elizabeth did not want to convert to Chifley's Catholic faith. Due to the Catholic Church's opposition to mixed marriages, the couple chose to marry in a Presbyterian church in Glebe, Sydney. Their parents opposed the union and did not attend the ceremony, but they and their families were eventually reconciled. The McKenzies were relatively wealthy, and Chifley was seen as \"marrying into money, or as much money as he could hope to marry into in the context of the relatively class-bound society of Bathurst\".\nAfter their marriage, Chifley's father-in-law gave the couple a house on Busby Street, Bathurst, which they would occupy for the rest of their respective lives. It is now listed on the New South Wales State Heritage Register as \"Ben Chifley's House\", and has operated as a house museum since 1973. Chifley and his wife had no children. She suffered a \"serious health problem\", probably a miscarriage, in about 1915, and later developed chronic back pain that restricted her mobility. The couple lived mostly separate lives, initially because of her husband's work on the railways and later because of his political career. She rarely travelled outside Bathurst and never lived in Canberra, even while her husband was prime minister. She usually visited the city for only special occasions. Her health prevented her from campaigning for her husband, and she was known to have little interest in politics. Nonetheless, the couple \"seemingly enjoyed a close and caring relationship throughout his life\". She survived her husband by 11 years, dying in 1962.\nAccording to his biographer David Day, Chifley engaged in a long-running extramarital affair with his private secretary Phyllis Donnelly. Day believed that their relationship began shortly after Chifley was elected in parliament in 1928, and continued more or less uninterrupted until his death in 1951; she was present in his room at the Hotel Kurrajong when he suffered his final heart attack. She stayed at the same hotel, and they were known to spend their free time with each other while in Canberra. She also accompanied him on many of his travels. According to Frank Slavin, Chifley's campaign manager at the 1940 election, his wife was aware of the relationship and tolerated it. Day also speculated that Chifley may have had a similar relationship with Phyllis's older sister Nell. He assisted her financially in the 1930s, including buying her a house in Bathurst. Day based his conclusions on interviews conducted with the Donnelly family and other Bathurst residents who had known Chifley. His claims have been disputed by members of the Chifley family, and some reviewers of his book felt there was insufficient evidence to conclude that Chifley's relationship with either of the Donnelly sisters was sexual in nature.\nLegacy.\nIn 1987 the New South Wales Labor government decided to name the planned new university in Sydney's western suburbs Chifley University. Controversy broke out when, in 1989, a new Liberal government renamed it the University of Western Sydney. According to a debate on the topic, held after the Labor Party had regained government, the decision to rename Chifley University reflected a desire to attach the name of Western Sydney to institutions of lasting significance, and that idea ultimately received the support of Bob Carr, later the Premier of New South Wales.\nHonours.\nPlaces and institutions that have been named after Chifley include:\nIn 1975 he was honoured on a postage stamp bearing his portrait issued by Australia Post.\nOne of the locomotives driven by Chifley, 5112, is preserved on a plinth at the eastern end of Bathurst railway station. In 1971 Commonwealth Railways named diesel locomotive NJ1 that was assembled at the Clyde Engineering factory in Kelso, \"Ben Chifley\".\nIn popular culture.\nChifley was portrayed by Bill Hunter in the 1984 TV miniseries \"The Last Bastion\", by Ed Devereaux in the 1988 miniseries \"True Believers\", and Geoff Morrell in the 2007 film \"Curtin\".\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52669", "revid": "1100608", "url": "https://en.wikipedia.org/wiki?curid=52669", "title": "John McEwen", "text": "Prime Minister of Australia from 1967 to 1968\nSir John McEwen (29 March 1900 \u2013 20 November 1980) was an Australian politician and farmer who served as the 18th prime minister of Australia from 1967 to 1968, in a caretaker capacity following the disappearance of prime minister Harold Holt. He was the leader of the Country Party from 1958 to 1971, serving as the inaugural deputy prime minister of Australia from 1968 to 1971.\nMcEwen was born in Chiltern, Victoria. He was orphaned at the age of seven and raised by his grandmother, initially in Wangaratta and then in Dandenong. McEwen left school when he was 13 and joined the Australian Army at the age of 18, but the war ended before his unit was shipped out. He was nonetheless eligible for a soldier settlement scheme, and selected a property at Stanhope. He established a dairy farm, but later bought a larger property and farmed beef cattle.\nAfter several previous unsuccessful candidacies, McEwen was elected to the House of Representatives at the 1934 federal election. He was first elevated to cabinet by Joseph Lyons in 1937. McEwen became deputy leader of the Country Party in 1943, under Arthur Fadden. He replaced Fadden as leader in 1958, and remained in the position until his retirement from politics in 1971. He served in parliament for 36 years in total, spending a record 25 years as a government minister.\nThe Liberal-Country Coalition returned to power in 1949, initially under Robert Menzies and then under Harold Holt. McEwen came to have a major influence on economic policy, particularly in the areas of agriculture, manufacturing, and trade. As soon as McEwen became the leader of the Country Party, he became the de facto deputy prime minister. \nIn December 1967, Harold Holt disappeared and was presumed dead while in office. As the de facto deputy prime minister, McEwen was commissioned as caretaker prime minister while the Liberal Party elected a new leader. He was 67 at the time, the oldest person to become prime minister and only the third from the Country Party, as well as the last to be born before Australia's federation. McEwen ceded power to John Gorton after 23 days in office in January 1968, and in recognition of his service was appointed deputy prime minister, the first time that position had been formally created. He was Australia's third shortest serving prime minister, after Earle Page and Frank Forde. He remained as deputy prime minister until his retirement from politics in 1971.\nEarly life.\nBirth and family background.\nMcEwen was born on 29 March 1900, at his parents' home in Chiltern, Victoria. He was the son of Amy Ellen (n\u00e9e Porter) and David James McEwen. His mother was born in Victoria, and had English and Irish ancestry. His father was of Ulster Scots origin, born in Mountnorris, County Armagh (in present-day Northern Ireland). He worked as a chemist, and also served a term on the Chiltern Shire Council. The family surname was originally spelled \"MacEwen\", but was altered upon David McEwen's arrival in Australia in 1889.\nChildhood.\nIn his memoirs, McEwen recounted that he had almost no memories of his parents. His mother died of lung disease in March 1902, just before his second birthday; she had given birth to a daughter, Amy, a few months earlier. She was the second of his father's three wives, and McEwen had three half-siblings \u2013 Gladys, Evelyn, and George. After their mother's death, McEwen and his sister were raised by their father, living in the rooms behind his chemist's shop. He died from meningitis in September 1907, when his son was seven. John and Amy were sent to live with their widowed grandmother, Nellie Porter (n\u00e9e Cook), while their younger half-brother went to live with his mother in Melbourne. They had never lived with their older half-sisters, who had been sent to live in a children's home upon their mother's death in 1893.\nMcEwen's grandmother ran a boardinghouse in Wangaratta. He grew up in what he described as \"pretty frugal circumstances\", and in 1912 his grandmother moved the family to Dandenong, on the outskirts of Melbourne. McEwen attended state schools in Wangaratta and Dandenong until the age of thirteen, when he began working for Rocke, Tompsitt &amp; Co., a drug manufacturer in central Melbourne. He initially worked as a switchboard operator, for which he was paid 15 shillings per week. McEwen began attending night school in Prahran, and in 1915 passed an examination for the Commonwealth Public Service and began working as a junior clerk at the office of the Commonwealth Crown Solicitor. His immediate superior there was Fred Whitlam, the father of another future prime minister, Gough Whitlam.\nSoldier-settler.\nWith World War I ongoing, McEwen resolved to enter the military when he turned 18. He joined the Australian Army Cadets and completed a Royal Australian Navy course in radiotelegraphy, hoping to qualify for the newly opened Royal Military College, Duntroon. He passed the entrance exam, but instead chose to enlist as a private in the Australian Imperial Force, in order to be posted overseas sooner. The war ended before his unit shipped out. Despite the briefness of his service, McEwen was eligible for the Victorian government's soldier settlement scheme. He selected an lot at Stanhope, on land that previously been a sheep station. As with many other soldier-settlers, McEwen initially did not have the money or the expertise needed to run a farm. He spent several months working as a farm labourer and later did the same as a stevedore at the Port of Melbourne, eventually saving enough money to return to Stanhope and establish his dairy farm.\nMcEwen's new property was virtually undeveloped, with only a single existing building (a small shack) and no fences, irrigation, or paddocks. He and the other soldier-settlers in the Stanhope district suffered a number of hardships in the early 1920s, including droughts, rabbit plagues, and low milk prices. Many of them were forced off their properties, allowing those who survived to expand their holdings relatively cheaply. In 1926, McEwen sold his property and bought a larger farm nearby, which he named \"Chilgala\" (a portmanteau of Chiltern and Tongala, the birthplaces of himself and his wife). He switched from dairy to beef cattle, and was able to expand his property by buying abandoned farms from the government. At its peak, \"Chilgala\" covered and carried 1,800 head of cattle. McEwen had a reputation as one of the best farmers in the district, and came to be seen by the other soldier-settlers as a spokesman and leader. He represented them in meetings with government officials, and was secretary of the local Water Users' League, which protected the interests of irrigators. In 1923, he co-founded the Stanhope Dairy Co-operative, and was elected as the company's inaugural chairman.\nEarly years in politics.\nMcEwen joined the Victorian Farmers' Union in 1919 at the age of 19 and was soon active in the Country Party, its political wing. He first stood for parliament at the 1932 Victorian state election, contesting the Legislative Assembly seat of Waranga. While unsuccessful, he more than doubled the Country Party's vote from the previous election. His campaigning efforts brought him to the attention of party leaders and he soon joined the state executive.\nIn 1934, the Victorian Country Party's central council mandated that its federal MPs and senators sign a pledge requiring strict party discipline and giving the central council a veto over the terms of any coalition government. The party's three MPs and two senators in Victoria refused to sign the pledge, receiving support from their parliamentary colleagues and the party's federal executive. Country MP William Hill decided to quit politics altogether in protest, with McEwen endorsed by the Victorian party as its replacement for Hill in the seat of Echuca. At the 1934 election he faced two \"Independent Country\" opponents supported by the federal party, with the party's federal leader Earle Page actively campaigning in their favour. McEwen nonetheless retained Echuca with the aid of favourable preference flows from Australian Labor Party (ALP) voters.\nDespite McEwen's acceptance of the Victorian Country Party's pledge, after his election to parliament he \"immediately associated himself with the federal party and incurred the hostility of his Victorian colleagues for urging that the breach be healed\". In his first term he successfully lobbied the Lyons government to introduce a variable excise duty on flour, linking the duty paid by farmers to the international spot rate. He regarded this as \"the first step towards a wheat industry stabilisation plan\". In April 1935 he announced his support for a royal commission into the Australian banking system, which the government convened later in the year. In 1936, following the Privy Council's ruling in \"James v Commonwealth\", McEwen moved in parliament that the constitution be amended to allow for the federal government to legislate on the marketing of agricultural products. The government ultimately put forward a referendum proposal in 1937 which was defeated by voters.\nInterior minister, 1937\u20131939.\nMcEwen's seat was abolished in a redistribution during his first term and he transferred to the seat of Indi at the 1937 election. He rose rapidly within the parliamentary Country Party and narrowly failed to win the deputy leadership after the 1937 election, losing to Harold Thorby by a single vote on the second ballot. He was subsequently appointed Minister for the Interior in the third Lyons ministry, a coalition government between the Country Party and the United Australia Party (UAP) led by Prime Minister Joseph Lyons. His new portfolio was \"spacious in its command of broad policy issues and diversity of administrative functions\" and included \"Commonwealth public works, railways, immigration, the Northern and Australian Capital territories, Aborigines, electoral administration, mining, and oil exploration\".\nAs interior minister, McEwen instituted the New Deal for Aborigines, a landmark policy statement on Indigenous Australians which described its aim as \"the raising of their status so as to entitle them by right and by qualification to the ordinary rights of citizenship and enable them and help them to share with us the opportunities that are available in their own native land\". The policy specified cultural assimilation as the basis on which civil rights would be extended to the Indigenous population. The policy was drafted by McEwen in conjunction with his adviser A. P. Elkin.\nFollowing Lyons' death in April 1939, Country Party leader Earle Page withdrew his party from the coalition with the UAP and McEwen's first stint as a minister came to an end. Page's decision \u2013 largely due to his personal disdain for the new UAP prime minister Robert Menzies \u2013 proved controversial within his own party and four Country MPs left the parliamentary party.\nCountry Party conflict.\nMcEwen's decision to accept a ministerial post after the 1937 election placed him into conflict with the central council of the Victorian Country Party, which had previously called on its federal MPs to withdraw from the federal coalition with the UAP. At the time, the central council was under the control of a left-wing faction and the party's state leader Albert Dunstan was governing in Victoria with the support of the Labor Party. In December 1937, McEwen was formally expelled from the Victorian Country Party, while remaining a member of the federal parliamentary Country Party. In response, he issued a statement denying the legitimacy of his expulsion and stating it was instead because he had been \"too powerful in opposing the ambitions of the radical element in control of the Victorian central council\". McEwen's supporters subsequently formed an alternative organisation, the Liberal Country Party (LCP), to support his election campaigns. His parliamentary colleague Thomas Paterson resigned from the Victorian Country Party in solidarity, with he and McEwen re-elected with the support of the LCP at the 1940 election. The LCP eventually merged back into the Victorian Country Party in 1943.\nWorld War II and aftermath.\nLeadership candidate.\nPage resigned as Country Party leader following the outbreak of World War II, in order to facilitate the resumption of a coalition government with the UAP. McEwen contested the resulting leadership ballot on 13 September 1939, losing by seven votes to five to South Australian MP Archie Cameron. Prior to the ballot, the party room had voted against allowing the four dissident MPs to rejoin the parliamentary party, although this decision was reversed a few months later. According to McEwen, the four MPs were his supporters and their presence would have meant he won the leadership ballot over Cameron.\nCameron's leadership of the Country Party proved troubled due to his leadership style. Only a few weeks after his election, McEwen joined three other Country Party MPs in crossed the floor to support an ALP amendment to a bill on conscientious objectors. The 1940 federal election resulted in a hung parliament, with the Country Party losing three seats. A further leadership ballot was held on 16 October 1940, McEwen and Page again nominating for the leadership. Cameron regarded this as a betrayal and \"stormed out of the meeting in a fury\", defecting to the UAP a few weeks later. Two ballots were held, with McEwen and Page tied on eight votes each. Arthur Fadden was then elected acting leader as a compromise candidate. He was subsequently confirmed in the position in March 1941, a role he would hold until 1958.\nExternal affairs minister, 1939\u20131940.\nFollowing the resumption of the coalition with the UAP, McEwen was appointed Minister for External Affairs in the second Menzies ministry on 14 March 1940.\nAir minister, 1940\u20131941.\nOn 16 October 1940, McEwen was appointed Minister for Air and Minister for Civil Aviation in a post-election cabinet reshuffle. Fadden had been acting in the portfolios for several months following the death of James Fairbairn, who had been one of three government ministers killed in the Canberra air disaster in August 1940. McEwen remained as air and civil aviation minister until the defeat of the Fadden government in October 1941, with Fadden having succeeded as prime minister upon Menzies' resignation in August 1941.\nAs air minister, McEwen oversaw the continued expansion of the Royal Australian Air Force (RAAF). He secured war cabinet approval for volunteers to be recruited from the Citizen Military Forces and also authorised steps to expand RAAF auxiliaries, announcing the creation of the Australian Air Force Cadets and the Women's Auxiliary Australian Air Force in early 1941. According to an official RAAF history, he \"made it clear that he did not favour the enlistment of women in the air force unless it was unavoidable, but unavoidable it became\". He had a strained relationship with RAAF chief Charles Burnett, frequently clashing over expenditure matters.\nMcEwen oversaw the acceleration of Australia's involvement in the Empire Air Training Scheme, which saw RAAF personnel receive training in Canada before being seconded to the Royal Air Force (RAF) for combat in the European theatre. In May 1941, McEwen announced that 1,000 RAAF ground staff would be seconded to the RAF. He faced criticisms that RAAF personnel in the UK were being assigned to RAF units rather than the Article XV squadrons required by the scheme, and that Australian officers were being denied senior leadership opportunities in RAF commands. In August 1941 he despatched Richard Williams to London to establish RAAF Overseas Headquarters, with the aim of securing greater Australian input in decision-making.\nOpposition, 1941\u20131949.\nMcEwen continued to serve on the Advisory War Council following the Fadden government's defeat, remaining as a member for the duration of the war. On the council he advocated for \"independent and first-hand reports of the New Guinea situation, and was critical of the northern air defence strategy\". McEwen was elected deputy leader of the Country Party in September 1943, with the position having been vacant since Fadden's elevation to the leadership. He opposed suggestions that the Country Party should merge into the new Liberal Party of Australia, created by Menzies as a replacement for the UAP, and remained defensive of the Country Party's independence throughout his political career.\nRemaining in opposition after the ALP won majority government at the 1943 and 1946 elections, McEwen was \"closely involved with Fadden in rebuilding the Country Party, developing its policies, and preparing it for office in partnership with Menzies' rejuvenated Liberal Party\". He was a prominent campaigner for the \"No\" vote in the Curtin government's 1944 post-war reconstruction referendum. He was also a leading opponent of the Chifley government's attempts to nationalise the private banking sector in 1947 and 1948.\nMenzies and Holt governments.\nThe conservatives returned to office in 1949 under Robert Menzies after eight years in opposition. At this election, McEwen stood in the new seat of Murray, which had been carved out of Indi's northwest section. He became Minister for Commerce and Agriculture, switching to Minister for Trade in 1956. Menzies nicknamed him \"Black Jack\", due to his dark eyebrows, grim nature, and occasional temper. In the Menzies government, McEwen pursued what became known as \"McEwenism\" \u2013 a policy of high tariff protection for the manufacturing industry, so that industry would not challenge the continuing high tariffs on imported raw materials, which benefitted farmers but pushed up industry's costs. This policy was a part (some argue the foundation) of what became known as the \"Australian settlement\" which promoted high wages, industrial development, government intervention in industry (Australian governments traditionally owned banks and insurance companies and the railways and through policies designed to assist particular industries) and decentralisation.\nTrade negotiations.\nBeginning in the early 1950s, McEwen and his departmental secretary John Crawford played a key role in the normalisation and acceleration of the Australia\u2013Japan trade relationship. Prior to World War II, Japan had been one of the largest destinations for Australian exports. The resumption of trade after the war was politically sensitive, due both to lingering anti-Japanese sentiment \u2013 including from several of McEwen's parliamentary colleagues who had been prisoners-of-war \u2013 and concerns from Australian manufacturers over the cheaper cost of labour in Japan. McEwen came to see the resumption of trade with Japan as important for Australian producers, as Australia sought new markets outside the existing framework of Imperial Preference.\nMcEwen first put forward a cabinet proposal to enter into trade negotiations with Japan in July 1953, which was rejected although an accompanying recommendation to liberalise restrictions on Japanese imports was accepted. He eventually secured cabinet approval for trade talks with Japan in November 1954, on his third attempt. In February 1955, he also persuaded cabinet to agree to Japan's accession to the General Agreement on Tariffs and Trade (GATT), although Australia and many other former Allied powers invoked an exception under Article 35 of the GATT treaty allowing them to continue to discriminate against Japan. After years of negotiations, McEwen and his Japanese counterpart Kishi Nobusuke signed the Japan\u2013Australia Commerce Agreement in July 1957, with each country conferring most favoured nation status on the other and Australia providing a commitment to revoke its Article 35 exception. This eventually occurred in 1960 after McEwen secured Japanese concessions on imports of Australian beef. The final discriminatory trade provisions were removed in a new agreement signed in 1963.\nThe trade agreement with Japan \"ushered in a new era of Australian trade which would make Japan immeasurably Australia's biggest trading partner\". Its signing was regarded as a personal triumph for McEwen, who was its main advocate in the government and bore much of the political risk. According to Malcolm Fraser, Menzies only authorised McEwen to negotiate in his own name, not on behalf of the government, and \"if it had gone wrong Menzies could have disowned him up to the moment the government accepted the agreement\". In 1973, the Japanese government awarded McEwen the Grand Cordon of the Order of the Rising Sun, making him only the second Australian politician after Edmund Barton to receive the honour.\nRelationship with the Liberal Party.\nIn 1958, following Fadden's retirement, McEwen was elected unopposed as leader of the Country Party. Under the Coalition agreement, he thus became the \"de facto\" deputy prime minister, and was afforded a free choice of portfolio. Fadden had been Treasurer, but McEwen somewhat unexpectedly chose to continue on as trade minister. This allowed Harold Holt to become the first Liberal MP to serve as Treasurer; since then every Treasurer in a Coalition government has been a Liberal. McEwen nonetheless had considerable influence in cabinet. He and his party favoured interventionist economic policies and were opposed to foreign ownership of industrial assets, which placed him frequently at odds with his Liberal colleagues. In 1962, a dispute between McEwen and Assistant Treasurer Les Bury ended with Bury being sacked from cabinet. His stature eventually grew to the point where he was considered a potential successor to Menzies as prime minister. An opinion poll in December 1963 showed that 19 percent of Coalition voters favoured McEwen as Menzies' successor, only two points behind the poll leader Holt. By December 1965, this number had risen to 27 percent, compared with Holt's 22 percent. McEwen's cause was championed by a number of media outlets, including \"The Sun\" and \"The Australian\". Nonetheless, he had few supporters within the Liberal Party, and it was generally held that he would have to become a Liberal if he were to lead the Coalition, which he was unwilling to do.\nHolt replaced Menzies as prime minister in January 1966, with McEwen continuing on his previous position. His portfolio had been expanded after the 1963 election, with his department now called the Department of Trade and Industry. McEwen enjoyed a \"sound working relationship\" with Holt, but without the same rapport he had had with Menzies. However, he had a poor relationship with William McMahon, Holt's replacement as Treasurer. They had philosophical differences over free trade and foreign investment, both of which McEwen opposed. McMahon was also suspected to be undermining McEwen through his connections in the media.\nMcEwen's most serious disagreement with Holt came in November 1967, when it was announced that Australia \u2013 which had converted to decimal currency the previous year \u2013 would not follow the recent devaluation of the pound sterling. This effectively marked Australia's withdrawal from the sterling area. McEwen issued a public statement criticising the decision, which he feared would damage primary industry. Holt considered this a breach of cabinet solidarity, and made preparations for the Liberal Party to govern in its own right in case the Country Party withdrew from the government. The situation was eventually resolved In Holt's favour.\nPrime minister.\nHarold Holt disappeared while swimming at Portsea, Victoria, on 17 December 1967, and was officially presumed dead two days later. The Governor-General, Lord Casey, sent for McEwen and commissioned him as interim prime minister, on the understanding that his commission would continue only so long as it took for the Liberals to elect a new leader. McEwen contended that if Casey commissioned a Liberal as interim prime minister, it would give that person an undue advantage in the upcoming ballot for a full-time leader.\nMcEwen retained all of Holt's ministers, and had them sworn in as the McEwen Ministry. Approaching 68, McEwen was the oldest person ever to be appointed Prime Minister of Australia, although not the oldest to serve; Menzies left office one month and six days after his 71st birthday. McEwen had been encouraged to remain prime minister on a more permanent basis but to do so would have required him to defect to the Liberals, an option he had never contemplated.\nIt had long been presumed that McMahon, who was both Treasurer and deputy Liberal leader, would succeed Holt as Liberal leader and hence prime minister. However, McEwen sparked a leadership crisis when he announced that he and his Country Party colleagues would not serve under McMahon. McEwen is reported to have despised McMahon personally. More importantly, McEwen was bitterly opposed to McMahon on political grounds, because McMahon was allied with free trade advocates in the conservative parties and favoured sweeping tariff reforms, a position that was vehemently opposed by McEwen, his Country Party colleagues and their rural constituents.\nAnother key factor in McEwen's antipathy towards McMahon was hinted at soon after the crisis by the veteran political journalist Alan Reid. According to Reid, McEwen was aware that McMahon was habitually breaching Cabinet confidentiality and regularly leaking information to favoured journalists and lobbyists, including Maxwell Newton, who had been hired as a \"consultant\" by Japanese trade interests.\nEven in the wake of their landslide victory in 1966, the Liberals were still four seats short of an outright majority. With only the Country Party as a realistic coalition partner, McEwen's opposition forced McMahon to withdraw from the leadership ballot. This opened the door for the successful campaign to promote the Minister for Education and Science, Senator John Gorton, to the Prime Ministership with the support of a group led by Defence Minister Malcolm Fraser. Gorton was elected as leader of the Liberal Party on 9 January 1968, and succeeded McEwen as prime minister the following day. It was the second time the Country Party had effectively vetoed its senior partner's choice for the leadership; in 1923 Earle Page had demanded that the Nationalist Party, one of the forerunners of the Liberals, remove Billy Hughes as leader before he would even consider coalition talks.\nGorton government and final years.\nGorton created the formal title deputy prime minister for McEwen, confirming his status as the second-ranking member of the government. Prior to then, the title had been used informally for whoever was recognised as the second-ranking member of the government \u2013 the leader of the Country Party when the Coalition was in government, and Labor's deputy leader when Labor was in government. Even before being formally named Deputy Prime Minister, McEwen had exercised an effective veto over government policy since 1966 by virtue of being the most senior member of the government, having been a member of the Coalition frontbench without interruption since 1937.\nMcEwen retired from politics in 1971. In his memoir, he recalls his career as being \"long and very, very hard\", and turned back to managing 1,800 head of cattle on his property in Goulburn Valley. In the same year, Clifton Pugh won the Archibald Prize for a portrait of McEwen. While he had softened in his \"unequivocal support for protection\" by the time of his retirement he had given way to free-traders with regards to agriculture. However, he felt differently about manufacturing, as it was essential to National power:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;At the time of his resignation, he had served in parliament for 36 years and 5 months, serving the last 34 years as either a minister (1937\u20131941 and 1949\u20131971) or opposition frontbencher (1941\u20131949). He was the last serving parliamentarian from the Great Depression era, and hence the last parliamentary survivor of the Lyons government. By the time of his death, Malcolm Fraser's government was abandoning McEwenite trade policies.\nHonours.\nMcEwen was appointed a Member of the Order of the Companions of Honour (CH) in 1969. He was knighted in 1971 after his retirement from politics, becoming a Knight Grand Cross of the Order of St Michael and St George (GCMG). The Japanese government conferred on him the Grand Cordon, Order of the Rising Sun in 1973.\nPersonal life and death.\nOn 21 September 1921, he married Anne Mills McLeod, known as Annie; they had no children. In 1966, she was made a Dame Commander of the Order of the British Empire (DBE). After a long illness Dame Anne McEwen died on 10 February 1967.\nAt the time of becoming prime minister in December of that year, McEwen was a widower, being the first Australian prime minister unmarried during his term of office. (The next such case was Julia Gillard, prime minister 2010\u201313, who had a domestic partner although unwed.)\nOn 26 July 1968, McEwen married Mary Eileen Byrne, his personal secretary for 15 years, at Wesley Church, Melbourne; he was aged 68, she was 46. In retirement he distanced himself from politics, undertook some consulting work, and travelled to Japan and South Africa. He had no children by any of his marriages.\nMcEwen had severe dermatitis for most of his adult life. He recounted that \"for literally months at a time, I would be walking about Parliament House with my feet bleeding and damaged.\" The pain became unbearable in later years, and he began refusing food in order to hasten his death; he died of self-imposed starvation on 20 November 1980, aged 80. McEwen was cremated, and his estate was sworn for probate at $2,180,479.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52670", "revid": "41248025", "url": "https://en.wikipedia.org/wiki?curid=52670", "title": "Hippy", "text": ""}
{"id": "52671", "revid": "50036965", "url": "https://en.wikipedia.org/wiki?curid=52671", "title": "Psychosomatic medicine", "text": "Interdisciplinary medical field exploring various influences on bodily processes\nPsychosomatic medicine is an interdisciplinary medical field exploring the relationships among social, psychological, behavioral factors on bodily processes and quality of life in humans and animals.\nThe academic forebearer of the modern field of behavioral medicine and a part of the practice of consultation-liaison psychiatry, psychosomatic medicine integrates interdisciplinary evaluation and management involving diverse specialties including psychiatry, psychology, neurology, psychoanalysis, internal medicine, pediatrics, surgery, allergy, dermatology, and psychoneuroimmunology. Clinical situations where mental processes act as a major factor affecting medical outcomes are areas where psychosomatic medicine has competence.\nPsychosomatic disorders.\nSome physical diseases are believed to have a mental component derived from stresses and strains of everyday living. Some researchers have suggested, for example, that lower back pain and high blood pressure may be related to stresses in everyday life. The psychosomatic framework additionally sees mental and emotional states as capable of significantly influencing the course of any physical illness. Psychiatry traditionally distinguishes between psychosomatic disorders, disorders in which mental factors play a significant role in the development, expression, or resolution of a physical illness, and somatoform disorders, disorders in which mental factors are the sole cause of a physical illness.\nIt is difficult to establish for certain whether an illness has a psychosomatic component. A psychosomatic component is often inferred when there are some aspects of the patient's presentation that are unaccounted for by biological factors, or some cases where there is no biological explanation at all. For instance, \"Helicobacter pylori\" causes 80% of peptic ulcers. However, most people living with \"Helicobacter pylori\" do not develop ulcers, and 20% of patients with ulcers have no \"H. pylori\" infection. Therefore, in these cases, psychological factors could still play some role. Similarly, in irritable bowel syndrome (IBS), there are abnormalities in the behavior of the gut. However, there are no actual structural changes in the gut, so stress and emotions might still play a role.\nThe strongest perspective on psychosomatic disorders is that attempting to distinguish between purely physical and mixed psychosomatic disorders is obsolete as almost all physical illness have mental factors that determine their onset, presentation, maintenance, susceptibility to treatment, and resolution. According to this view, even the course of serious illnesses, such as cancer, can potentially be influenced by a person's thoughts, feelings and general state of mental health.\nAddressing such factors is the remit of the applied field of behavioral medicine. In modern society, psychosomatic aspects of illness are often attributed to stress making the remediation of stress one important factor in the development, treatment, and prevention of psychosomatic illness.\nResearch and Clinical Relevance.\nPsychosomatic medicine has clarified bidirectional links between hepatitis C virus (HCV) infection and psychiatric disorders. Large cohort and review studies have demonstrated elevated rates of mood, anxiety, substance use, and psychotic disorders among individuals with hepatitis C. In turn, higher hepatitis C seroprevalence has been observed among individuals with serious mental illness, highlighting the importance of routine screening and integrated care models in these populations. These findings underscore the need for coordinated care that addresses both the physical and mental health aspects of patients with hepatitis C.\nEarly contributions by Muhamad Aly Rifai and colleagues synthesized psychiatric considerations in hepatitis C care and reported treatment outcomes in psychiatric populations, paving the way for later guidance on screening and management in mental health settings. Their work significantly informed later clinical guidelines and highlighted the importance of considering psychiatric comorbidities when managing hepatitis C patients.\nConnotations of the term \"psychosomatic illness\".\nThe term \"psychosomatic disease\" was most likely first used by Paul D. MacLean in his 1949 seminal paper \u2018Psychosomatic disease and the \u201cvisceral brain\u201d; recent developments bearing on the Papez theory of emotions.\u2019 In the field of psychosomatic medicine, the phrase \"psychosomatic illness\" is used more narrowly than it is within the general population. For example, in lay language, the term often encompasses illnesses with no physical basis at all, and even illnesses that are faked (malingering). In contrast, in contemporary psychosomatic medicine, the term is normally restricted to those illnesses that do have a clear physical basis, but where it is believed that psychological and mental factors also play a role. Some researchers within the field believe that this overly broad interpretation of the term may have caused the discipline to fall into disrepute clinically. For this reason, among others, the field of behavioral medicine has taken over much of the remit of psychosomatic medicine in practice and there exist large areas of overlap in the scientific research.\nCriticism.\nStudies have yielded mixed evidence regarding the impact of psychosomatic factors in illnesses. Early evidence suggested that patients with advanced-stage cancer may be able to survive longer if provided with psychotherapy to improve their social support and outlook. However, a major review published in 2007, which evaluated the evidence for these benefits, concluded that no studies meeting the minimum quality standards required in this field have demonstrated such a benefit. The review further argues that unsubstantiated claims that \"positive outlook\" or \"fighting spirit\" can help slow cancer may be harmful to the patients themselves if they come to believe that their poor progress results from \"not having the right attitude\".\nTreatment.\nWhile in the U.S., psychosomatic medicine is considered a subspecialty of the fields of psychiatry and neurology, in Germany and other European countries it is considered a subspecialty of internal medicine. Thure von Uexk\u00fcll and contemporary physicians following his thoughts regard the psychosomatic approach as a core attitude of medical doctors, thereby declaring it not as a subspecialty, but rather an integrated part of every specialty. Medical treatments and psychotherapy are used to treat illnesses believed to have a psychosomatic component.\nHistory.\nIn the medieval Islamic world the Persian psychologist-physicians Ahmed ibn Sahl al-Balkhi (d. 934) and Haly Abbas (d. 994) developed an early model of illness that emphasized the interaction of the mind and the body. He proposed that a patient's physiology and psychology can influence one another.\nContrary to Hippocrates and Galen, Ahmed ibn Sahl al-Balkhi did not believe that mere regulation and modulation of the body tempers and medication would remedy mental disorders because words play a vital and necessary role in emotional regulation. To change such behaviors, he used techniques, such as belief altering, regular musing, rehearsals of experiences, and imagination.\nIn the beginnings of the 20th century, there was a renewed interest in psychosomatic concepts. Psychoanalyst Franz Alexander had a deep interest in understanding the dynamic interrelation between mind and body. Sigmund Freud pursued a deep interest in psychosomatic illnesses following his correspondence with Georg Groddeck who was, at the time, researching the possibility of treating physical disorders through psychological processes. H\u00e9l\u00e8ne Michel-Wolfromm applied psychosomatic medicine to the field of gynecology and sexual problems experienced by women.\nIn the 1970s, Thure von Uexk\u00fcll and his colleagues in Germany and elsewhere proposed a biosemiotic theory (the umwelt concept) that was widely influential as a theoretical framework for conceptualizing mind-body relations. This model shows that life is a meaning or functional system. Farzad Goli further explains in \"Biosemiotic Medicine\" (2016), how signs in the form of matter (e.g., atoms, molecules, cells), energy (e.g., electrical signals in nervous system), symbols (e.g., words, images, machine codes), and reflections (e.g., mindful moments, metacognition) can be interpreted and translated into each other.\nHenri Laborit, one of the founders of modern neuropsychopharmacology, carried out experiments in the 1970s that showed that illness quickly occurred when there was inhibition of action in rats. Rats in exactly the same stressful situations but whom were not inhibited in their behavior (those who could flee or fight\u2014even if fighting is completely ineffective) had no negative health consequences. He proposed that psychosomatic illnesses in humans largely have their source in the constraints that society puts on individuals in order to maintain hierarchical structures of dominance. The film \"My American Uncle\", directed by Alain Resnais and influenced by Laborit, explores the relationship between self and society and the effects of the inhibition of action.\nIn February 2005, the Boston Syndromic Surveillance System detected an increase in young men seeking medical treatment for stroke. Most of them did not actually experience a stroke, but the largest number presented a day after Tedy Bruschi, a local sports figure, was hospitalized for a stroke. Presumably they began misinterpreting their own harmless symptoms, a group phenomenon now known as Tedy Bruschi syndrome.\nRobert Adler is credited with coining the term Psychoneuroimmunology (PNI) to categorize a new field of study also known as mind-body medicine. The principles of mind-body medicine suggest that our mind and the emotional thoughts we produce have an incredible impact on our physiology, either positive or negative.\nPNI integrates the mental/psychological, nervous, and immune system, and these systems are further linked together by ligands, which are hormones, neurotransmitters and peptides. PNI studies how every single cell in our body is in constant communication\u2014how they are literally having a conversation and are responsible for 98% of all data transferred between the body and the brain.\nDr. Candace Pert, a professor and neuroscientist who discovered the opiate receptor, called this communication between our cells the \u2018Molecules of Emotion' because they produce the feelings of bliss, hunger, anger, relaxation, or satiety. Dr. Pert maintains that our body is our subconscious mind, so what is going on in the subconscious mind is being played out by our body.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52672", "revid": "1311073219", "url": "https://en.wikipedia.org/wiki?curid=52672", "title": "Toasting (Jamaican music)", "text": "Talking or chanting to an instrumental rhythm\nToasting (rap in other parts of the Anglo Caribbean) or deejaying is the act of talking, usually in a monotone melody, over a rhythm or beat by a deejay. It can either be improvised or pre-written. Toasting developed in Jamaica, before taking up that name and being part of the sound system era. A similar sound is found in mento and now can be heard over musical styles including ska, reggae, dancehall, dub, grime, hip-hop, soca and bouyon music. The combination of singing and toasting is known as singjaying.\nIn the late 1950s in Jamaica, one of the first Selector, also being a promoter optimized of using a mic and to entertain an audience while playing records was Count Matchuki. He conceived the idea for being comically entertaining from listening to commercial ads and disc jockeys on American radio stations etc. He would create and come up with comical phrases also doing African American jive over the music while selecting and playing R&amp;B music. Deejays like Count Machuki working for producers would play the latest hits on traveling sound systems at parties and add his vocals to the music. These talks consisted of comedy, boastful commentaries, half-sung rhymes, rhythmic chants, squeals, screams and rhymed storytelling.\nOsbourne Ruddock ( King Tubby) was a Jamaican sound recording engineer who created vocal-less rhythm backing tracks that were used by DJs doing toasting by creating one-off vinyl discs (also known as dub plates) of songs without the vocals and adding echo and sound effects.\nLate 1960s toasting deejays included U-Roy and Dennis Alcapone, the latter known for mixing gangster talk with humor in his toasting. In the early 1970s, toasting deejays included I-Roy (his nickname is in homage to U-Roy) and Dillinger, the latter known for his humorous toasting style. In the early 1970s with the rise of dub Big Youth became popular, also Prince Jazzbo in his early appearance toasting with more cadence on dubs. In the late 1970s, Trinity followed.\nThe 1980s saw the first deejay toasting duo, Michigan &amp; Smiley, and the development of toasting outside of Jamaica. In England, Pato Banton explored his Caribbean roots, humorous and political toasting while Ranking Roger of the Second Wave or Two-Tone ska revival band The Beat from the 1980s did Jamaican toasting over music that blended ska, pop, and some punk influences.\nJamaican deejay toasting also influenced various types of dance music, such as jungle music and UK garage. Dancehall artists that have achieved pop hits with toasting-influenced vocals include Shabba Ranks, Shaggy, Lady Saw, Sean Paul, Terror Fabulous and Damian Marley.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52673", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=52673", "title": "Gulf War Syndrome", "text": ""}
{"id": "52675", "revid": "7059334", "url": "https://en.wikipedia.org/wiki?curid=52675", "title": "Strouhal number", "text": "Dimensionless number describing oscillating flow mechanisms\nIn dimensional analysis, the Strouhal number (St, or sometimes Sr to avoid the conflict with the Stanton number) is a dimensionless number describing oscillating flow mechanisms. The parameter is named after Vincenc Strouhal, a Czech physicist who experimented in 1878 with wires experiencing vortex shedding and singing in the wind. The Strouhal number is an integral part of the fundamentals of fluid mechanics.\nThe Strouhal number is often given as\nformula_1\nwhere \"f\" is the frequency of vortex shedding in Hertz, \"L\" is the characteristic length (for example, hydraulic diameter or the airfoil thickness) and \"U\" is the flow velocity. In certain cases, like heaving (plunging) flight, this characteristic length is the amplitude of oscillation. This selection of characteristic length can be used to present a distinction between Strouhal number and reduced frequency:\nformula_2\nwhere \"k\" is the reduced frequency, and \"A\" is amplitude of the heaving oscillation.\nFor large Strouhal numbers (order of 1), viscosity dominates fluid flow, resulting in a collective oscillating movement of the fluid \"plug\". For low Strouhal numbers (order of 10\u22124 and below), the high-speed, quasi-steady-state portion of the movement dominates the oscillation. Oscillation at intermediate Strouhal numbers is characterized by the buildup and rapidly subsequent shedding of vortices.\nFor spheres in uniform flow in the Reynolds number range of 8\u00d7102 &lt; Re &lt; 2\u00d7105 there co-exist two values of the Strouhal number. The lower frequency is attributed to the large-scale instability of the wake, is independent of the Reynolds number Re and is approximately equal to 0.2. The higher-frequency Strouhal number is caused by small-scale instabilities from the separation of the shear layer.\nDerivation.\nKnowing Newton's second law stating force is equivalent to mass times acceleration, or formula_3, and that acceleration is the derivative of velocity, or formula_4 (characteristic speed/time) in the case of fluid mechanics, we see\nformula_5,\nSince characteristic speed can be represented as length per unit time, formula_6, we get\nformula_7,\nwhere,\n \"m\" = mass,\n \"U\" = characteristic speed,\n \"L\" = characteristic length.\nDividing both sides by formula_8, we get\nformula_9 \u21d2 formula_10,\nwhere,\n \"m\" = mass,\n \"U\" = characteristic speed,\n \"F\" = net external forces,\n \"L\" = characteristic length.\nThis provides a dimensionless basis for a relationship between mass, characteristic speed, net external forces, and length (size) which can be used to analyze the effects of fluid mechanics on a body with mass.\nIf the net external forces are predominantly elastic, we can use Hooke's law to see\nformula_11,\nwhere,\n \"k\" = spring constant (stiffness of elastic element),\n \"\u0394L\" = deformation (change in length).\nAssuming formula_12, then formula_13. With the natural resonant frequency of the elastic system, formula_14, being equal to formula_15, we get\nformula_16,\nwhere,\n \"m\" = mass,\n \"U\" = characteristic speed,\n \"formula_17\" = natural resonant frequency,\n \"\u0394L\" = deformation (change in length).\nGiven that cyclic motion frequency can be represented by formula_18 we get,\nformula_19,\nwhere,\n \"f\" = frequency,\n \"L\" = characteristic length,\n \"U\" = characteristic speed.\nApplications.\nMicro/Nanorobotics.\nIn the field of micro and nanorobotics, the Strouhal number is used alongside the Reynolds number in analyzing the impact of an external oscillatory fluidic flow on the body of a microrobot. When considering a microrobot with cyclic motion, the Strouhal number can be evaluated as\nformula_20,\nwhere,\n \"f\" = cyclic motion frequency,\n \"L\" = characteristic length of robot,\n \"U\" = characteristic speed.\nThe analysis of a microrobot using the Strouhal number allows one to assess the impact that the motion of the fluid it is in has on its motion in relation to the inertial forces acting on the robot\u2013regardless of the dominant forces being elastic or not.\nMedical.\nIn the medical field, microrobots that use swimming motions to move may make micromanipulations in unreachable environments.\nThe equation used for a blood vessel:\nformula_21,\nwhere,\n \"f\" = oscillation frequency of the microbot swimming motion\n \"D\" = blood vessel diameter\n \"V\" = unsteady viscoelastic flow\nThe Strouhal number is used as a ratio of the Deborah number (De) and Weissenberg number (Wi):\nformula_22.\nThe Strouhal number may also be used to obtain the Womersley number (Wo). The case for blood flow can be categorized as an unsteady viscoelastic flow, therefore the Womersley number is\nformula_23,\nOr considering both equations,\nformula_24.\nMetrology.\nIn metrology, specifically axial-flow turbine meters, the Strouhal number is used in combination with the Roshko number to give a correlation between flow rate and frequency. The advantage of this method over the frequency/viscosity versus K-factor method is that it takes into account temperature effects on the meter.\nformula_25\nwhere,\n \"f\" = meter frequency,\n \"U\" = flow rate,\n \"C\" = linear coefficient of expansion for the meter housing material.\nThis relationship leaves Strouhal dimensionless, although a dimensionless approximation is often used for \"C\"3, resulting in units of pulses/volume (same as K-factor).\nThis relationship between flow and frequency can also be found in the aeronautical field. Considering pulsating methane-air coflow jet diffusion flames, we get\nformula_26,\nwhere,\n \"a\" = fuel jet radius\n \"w\" = the modulation frequency\n \"U\" = exit velocity of the fuel jet\nFor a small Strouhal number (St=0.1) the modulation forms a deviation in the flow that travels very far downstream. As the Strouhal number grows, the non-dimensional frequency approaches the natural frequency of a flickering flame, and eventually will have greater pulsation than the flame.\nAnimal locomotion.\nIn swimming or flying animals, Strouhal number is defined as\nformula_27\nwhere,\n \"f\" = oscillation frequency (tail-beat, wing-flapping, etc.),\n \"U\" = flow rate,\n \"A\" = peak-to-peak oscillation amplitude.\nIn animal flight or swimming, propulsive efficiency is high over a narrow range of Strouhal constants, generally peaking in the 0.2 &lt; St &lt; 0.4 range. This range is used in the swimming of dolphins, sharks, and bony fish, and in the cruising flight of birds, bats and insects. However, in other forms of flight other values are found. Intuitively the ratio measures the steepness of the strokes, viewed from the side (e.g., assuming movement through a stationary fluid) \u2013 \"f\" is the stroke frequency, \"A\" is the amplitude, so the numerator \"fA\" is half the vertical speed of the wing tip, while the denominator \"V\" is the horizontal speed. Thus the graph of the wing tip forms an approximate sinusoid with aspect (maximal slope) twice the Strouhal constant.\nEfficient motion.\nThe Strouhal number is most commonly used for assessing oscillating flow as a result of an object's motion through a fluid. The Strouhal number reflects the difficulty for animals to travel efficiently through a fluid with their cyclic propelling motions. The number relates to propulsive efficiency, which peaks between when within the optimal Strouhal number range of . Through the use of factors such as the stroke frequency, the amplitude of each stroke, and velocity, the Strouhal number is able to analyze the efficiency and impact of an animal's propulsive forces through a fluid, such as those from swimming or flying. For instance, the value represents the constraints to achieve greater propulsive efficiency, which affects motion when cruising and aerodynamic forces when hovering.\nGreater reactive forces and properties that act against the object, such as viscosity and density, reduce the ability of an animal's motion to fall within the ideal Strouhal number range when swimming. Through the assessment of different species that fly or swim, it was found that the motion of many species of birds and fish falls within the optimal Strouhal range. However, the Strouhal number varies more within the same species than other species based on the method of how they move in a constrained manner in response to aerodynamic forces.\nExample: Alcid.\nThe Strouhal number has significant importance in analyzing the flight of animals since it is based on the streamlines and the animal's velocity as it travels through the fluid. Its significance is demonstrated through the motion of alcids as it passes through different mediums (air to water). The assessment of alcids determined the peculiarity of being able to fly under the efficient Strouhal number range in air and water despite a high mass relative to their wing area. The alcid's efficient dual-medium motion developed through natural selection where the environment played a role in the evolution of animals over time to fall under a certain efficient range. The dual-medium motion demonstrates how alcids had two different flight patterns based on the stroke velocities as it moved through each fluid. However, as the bird travels through a different medium, it has to face the influence of the fluid's density and viscosity. Furthermore, the alcid also has to resist the upward-acting buoyancy as it moves horizontally.\nScaling of the Strouhal number.\nScale Analysis.\nIn order to determine significance of the Strouhal number at varying scales, one may perform scale analysis\u2013a simplification method to analyze the impact of factors as they change with respect to some scale. When considered in the context of microrobotics and nanorobotics, size is the factor of interest when performing scale analysis.\nScale analysis of the Strouhal number allows for analysis of the relationship between mass and inertial forces as both change with respect to size. Taking its original underived form, formula_28, we can then relate each term to size and see how the ratio changes as size changes.\nGiven formula_29 where \"m\" is mass, \"V\" is volume, and formula_30 is density, we can see mass is directly related to size as volume scales with length (L). Taking the volume to be formula_31, we can directly relate mass and size as\nformula_32.\nCharacteristic speed (\"U\") is in terms of formula_33, and relative distance scales with size, therefore\nformula_34.\nThe net external forces (\"F\") scales in relation to mass and acceleration, given by formula_35. Acceleration is in terms of formula_36, therefore formula_37. The mass-size relationship was established to be formula_32, so considering all three relationships, we get\nformula_39.\nLength (\"L\") already denotes size and remains \"L\".\nTaking all of this together, we get\nformula_40.\nWith the Strouhal number relating the mass to inertial forces, this can be expected as these two factors will scale proportionately with size and neither will increase nor decrease in significance with respect to their contribution to the body's behavior in the cyclic motion of the fluid.\nRelationship with the Richardson number.\nThe scaling relationship between the Richardson number and the Strouhal number is represented by the equation:\nformula_41,\nwhere \"a\" and \"b\" are constants depending on the condition.\nFor round helium buoyant jets and plumes:\nformula_42.\nWhen formula_43,\nformula_44.\nWhen formula_45,\nformula_46.\nFor planar buoyant jets and plumes:\nformula_47.\nFor shape-independent scaling:\nformula_48\nRelationship with Reynolds number.\nThe Strouhal number and Reynolds number must be considered when addressing the ideal method to develop a body made to move through a fluid. Furthermore, the relationship for these values is expressed through Lighthill's elongated-body theory, which relates the reactive forces experienced by a body moving through a fluid with its inertial forces. The Strouhal number was determined to depend upon the dimensionless Lighthill number, which in turn relates to the Reynolds number. The value of the Strouhal number can then be seen to decrease with an increasing Reynolds number, and to increase with an increasing Lighthill number.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52676", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=52676", "title": "Function (programming)", "text": ""}
{"id": "52678", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=52678", "title": "Application-programming interface", "text": ""}
{"id": "52679", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=52679", "title": "Function (Programming)", "text": ""}
{"id": "52680", "revid": "988731400", "url": "https://en.wikipedia.org/wiki?curid=52680", "title": "Three Theban plays", "text": ""}
{"id": "52681", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=52681", "title": "The three Theban plays", "text": ""}
{"id": "52682", "revid": "1292588195", "url": "https://en.wikipedia.org/wiki?curid=52682", "title": "Greek literature", "text": " \nGreek literature () dates back from the ancient Greek literature, beginning in 800 BC, to the modern Greek literature of today. \nAncient Greek literature was written in an Ancient Greek dialect, literature ranges from the oldest surviving written works until works from approximately the fifth century AD. This time period is divided into the Preclassical, Classical, Hellenistic, and Roman periods. Preclassical Greek literature primarily revolved around myths and include the works of Homer; the \"Iliad\" and the \"Odyssey\". The Classical period saw the dawn of drama and history. Three philosophers are especially notable: Socrates, Plato, and Aristotle. During the Roman era, significant contributions were made in a variety of subjects, including history, philosophy, and the sciences.\nByzantine literature, the literature of the Byzantine Empire, was written in Atticizing, Medieval and early Modern Greek. Chronicles, distinct from historics, arose in this period. Encyclopedias also flourished in this period.\nModern Greek literature is written in common Modern Greek. The Cretan Renaissance poem \"Erotokritos\" is one of the most significant works from this time period. Adamantios Korais and Rigas Feraios are two of the most notable figures.\nAncient Greek literature (800 BC \u2013 350 AD).\nAncient Greek literature refers to literature written in Ancient Greek dialects. These works range from the oldest surviving written works in the Greek language until works from the fifth century AD. The Greek language arose from the proto-Indo-European language; roughly two-thirds of its words can be derived from various reconstructions of the tongue. A number of alphabets and syllabaries had been used to render Greek, but surviving Greek literature was written in a Phoenician-derived alphabet that arose primarily in Greek Ionia and was fully adopted by Athens by the fifth century BC.\nPreclassical / Heroic Period (800\u2013500 BC).\nAll ancient Greek literature was to some degree oral in nature, and the earliest literature was completely so. The Greeks created poetry before making use of writing for literary purposes. Poems created in the Preclassical period were meant to be sung or recited (writing was little known before the 7th century BC). Most poems focused on myths, legends that were part folktale and part religion. Tragedies and comedies emerged around 600 BC.\nAt the beginning of Greek literature stand the works of Homer; the \"Iliad\" and the \"Odyssey\". Though dates of composition vary, these works were fixed around 800 BC or after. Another significant figure was the poet Hesiod. His two surviving works are \"Works and Days\" and \"Theogony\".\nClassical (500\u2013323 BC).\nDuring the classical period, many of the genres of western literature became more prominent. Lyrical poetry, odes, pastorals, elegies, epigrams; dramatic presentations of comedy and tragedy; histories, rhetorical treatises, philosophical dialectics, and philosophical treatises all arose in this period.\nThe two major lyrical poets were Sappho and Pindar. Of the hundreds of tragedies written and performed during this time period, only a limited number of plays survived. These plays are authored by Aeschylus, Sophocles, and Euripides.\nThe comedy arose from a ritual in honor of Dionysus. These plays were full of obscenity, abuse, and insult. The surviving plays by Aristophanes are a treasure trove of comic presentation.\nTwo influential historians of this age are Herodotus and Thucydides. A third historian, Xenophon, wrote \"Hellenica,\" which is considered an extension of Thucydides's work.\nThe greatest prose achievement of the 4th century BC was in philosophy. Greek philosophy flourished during the classical period. Of the philosophers, Socrates, Plato, and Aristotle are the most famous.\nHellenistic (323\u201331 BC).\nBy 338 BC many of the key Greek cities had been conquered by Philip II of Macedon. Philip II's son Alexander extended his father's conquests greatly.\nThe Hellenistic age is defined as the time between the death of Alexander the Great and the rise of Roman domination. After the 3rd century BC, the Greek colony of Alexandria in northern Egypt became the center of Greek culture.\nGreek poetry flourished with significant contributions from Theocritus, Callimachus, and Apollonius of Rhodes. Theocritus, who lived from about 310 to 250 BC, was the creator of pastoral poetry, a type that the Roman Virgil mastered in his Eclogues.\nDrama was represented by the New Comedy, of which Menander was the principal exponent.\nOne of the most valuable contributions of the Hellenistic period was the Septuagint translation of the Old Testament into Greek. This work was done at Alexandria and completed by the end of the 2nd century BC.\nRoman Age (31 BC \u2013 284 AD).\nLiterature in Greek in the Roman period contributed significant works to the subjects of poetry, comedy, history, and tragedy. A large proportion of literature from this time period were histories.\nSignificant historians of the period were Timaeus, Polybius, Diodorus Siculus, Dionysius of Halicarnassus, Appian of Alexandria, Arrian, and Plutarch. The period of time they cover extends from late in the 4th century BC to the 2nd century AD.\nEratosthenes of Alexandria wrote on astronomy and geography, but his work is known mainly from later summaries. The physician Galen pioneered developments in various scientific disciplines including anatomy, physiology, pathology, pharmacology, and neurology. This is also the period in which most of the Ancient Greek novels were written.\nThe New Testament, written by various authors in varying qualities of Koine Greek, hails from this period. The Gospels and the Epistles of Saint Paul were written in this time period as well.\nByzantine literature (350\u20131453).\nByzantine literature refers to literature of the Byzantine Empire written in Atticizing, Medieval and early Modern Greek.\nByzantine literature combined Greek and Christian civilization on the common foundation of the Roman political system. This type of literature was set in the intellectual and ethnographic atmosphere of the Near East. Byzantine literature possesses four primary cultural elements: Greek, Christian, Roman, and Oriental.\nAside from personal correspondence, the literature of this period was primarily written in the Atticizing style. Some early literature of this period was written in Latin; some of the works from the Latin Empire were written in French.\nChronicles, distinct from historic, arose in this period. Encyclopedias also flourished in this period.\n\"Digenes Akritas\" (\u0394\u03b9\u03b3\u03b5\u03bd\u1fc6\u03c2 \u1f08\u03ba\u03c1\u03af\u03c4\u03b1\u03c2) is the most famous of the Acritic songs and is often regarded as the only surviving epic poem from the Byzantine Empire. It is considered by some to signal the beginnings of modern Greek literature.\nModern Greek literature (1453\u2013present).\nModern Greek literature is written in common Modern Greek. During this period, the modern vernacular form of the Greek language became more commonplace in writing.\nThis period saw the revival of Greek and Roman studies and the development of Renaissance humanism and science.\nThe Cretan Renaissance poem \"Erotokritos\" is a prominent work of this time period. It is a verse romance written around 1600 by Vitsentzos Kornaros (1553\u20131613).\nModern Greek literature is significantly influenced by the Diafotismos, a movement that translated the ideas of the European Enlightenment into the Greek world. Adamantios Korais and Rigas Feraios are two prominent figures of this movement.\nToday, Modern Greek Literature participates in the global literary community. The Greek authors Giorgos Seferis and Odysseas Elytis have been awarded the Nobel Prize in Literature.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52684", "revid": "2563820", "url": "https://en.wikipedia.org/wiki?curid=52684", "title": "Ancient Greek architecture", "text": " \nAncient Greek architecture came from the Greeks, or Hellenes, whose culture flourished on the Greek mainland, the Peloponnese, the Aegean Islands, and in colonies in Anatolia and Italy for a period from about 900 BC until the 1st century AD, with the earliest remaining architectural works dating from around 600 BC.\nAncient Greek architecture is best known for its temples, many of which are found throughout the region, with the Parthenon regarded, now as in ancient times, as the prime example. Most remains are very incomplete ruins, but a number survive substantially intact, mostly outside modern Greece. The second important type of building that survives all over the Hellenic world is the open-air theatre, with the earliest dating from around 525\u2013480 BC. Other architectural forms that are still in evidence are the processional gateway (\"propylon\"), the public square (\"agora\") surrounded by storied colonnade (\"stoa\"), the town council building (\"bouleuterion\"), the public monument, the monumental tomb (\"mausoleum\") and the \"stadium\".\nAncient Greek architecture is distinguished by its highly formalised characteristics, both of structure and decoration. This is particularly so in the case of temples where each building appears to have been conceived as a sculptural entity within the landscape, very often raised on high ground so that the elegance of its proportions and the effects of light on its surfaces might be viewed from all angles. Nikolaus Pevsner refers to \"the plastic shape of the [Greek] temple [...] placed before us with a physical presence more intense, more alive than that of any later building\".\nThe formal vocabulary of ancient Greek architecture, in particular the division of architectural style into three defined orders: the Doric Order, the Ionic Order and the Corinthian Order, was to have a profound effect on Western architecture of later periods. The architecture of ancient Rome grew out of that of Greece and maintained its influence in Italy unbroken until the present day. From the Renaissance, revivals of Classicism have kept alive not only the precise forms and ordered details of Greek architecture, but also its concept of architectural beauty based on balance and proportion. The successive styles of Neoclassical architecture and Greek Revival architecture followed and adapted ancient Greek styles closely.\nInfluences.\nGeography.\nThe mainland and islands of Greece are very rocky, with deeply indented coastline, and rugged mountain ranges with few substantial forests. The most freely available building material is stone. Limestone was readily available and easily worked. There is an abundance of high quality white marble both on the mainland and islands, particularly Paros and Naxos. This finely grained material was a major contributing factor to precision of detail, both architectural and sculptural, that adorned ancient Greek architecture. Deposits of high-quality potter's clay were found throughout Greece and the Islands, with major deposits near Athens. It was used not only for pottery vessels but also roof tiles and architectural decoration.\nThe climate of Greece is maritime, with both the coldness of winter and the heat of summer tempered by sea breezes. This led to a lifestyle where many activities took place outdoors. Hence temples were placed on hilltops, their exteriors designed as a visual focus of gatherings and processions, while theatres were often an enhancement of a naturally occurring sloping site where people could sit, rather than a containing structure. Colonnades encircling buildings, or surrounding courtyards provided shelter from the sun and from sudden winter storms.\nThe light of Greece may be another important factor in the development of the particular character of ancient Greek architecture. The light is often extremely bright, with both the sky and the sea vividly blue. The clear light and sharp shadows give a precision to the details of the landscape, pale rocky outcrops and seashore. This clarity is alternated with periods of haze that varies in colour to the light on it. In this characteristic environment, the ancient Greek architects constructed buildings that were marked by the precision of detail. The gleaming marble surfaces were smooth, curved, fluted, or ornately sculpted to reflect the sun, cast graded shadows and change in colour with the ever-changing light of day.\nHistory.\nHistorians divide ancient Greek civilization into two eras, the Hellenic period (from around 900 BC to the death of Alexander the Great in 323 BC), and the Hellenistic period (323 BC \u2013 30 AD). During the earlier Hellenic period, substantial works of architecture began to appear around 600 BC. During the later (Hellenistic) period, Greek culture spread as a result of Alexander's conquest of other lands, and later as a result of the rise of the Roman Empire, which adopted much of Greek culture.\nBefore the Hellenic era, two major cultures had dominated the region: the Minoan (c.\u20092800\u00a0\u2013 c.\u20091100 BC), and the Mycenaean (c. 1500\u20131100 BC). Minoan is the name given by modern historians to the culture of the people of ancient Crete, known for its elaborate and richly decorated Minoan palaces, and for its pottery, the most famous of which painted with floral and motifs of sea life. The Mycenaean culture, which flourished on the Peloponnesus, was different in character. Its people built citadels, fortifications and tombs, and decorated their pottery with bands of marching soldiers rather than octopus and seaweed. Both these civilizations came to an end around 1100 BC, that of Crete possibly because of volcanic devastation, and that of Mycenae because of an invasion by the Dorian people who lived on the Greek mainland. Following these events, there was a period from which only a village level of culture seems to have existed. This period is thus often referred to as the Greek Dark Age.\nArt.\nThe art of the Hellenic era is generally subdivided into four periods: the Protogeometric (1100\u2013900 BC), the Geometric (900\u2013700 BC), the Archaic (700\u2013500 BC) and the Classical (500\u2013323 BC) with sculpture being further divided into Severe Classical, High Classical and Late Classical. The first signs of the particular artistic character that defines ancient Greek architecture are to be seen in the pottery of the Dorian Greeks from the 10th century BC. Already at this period it is created with a sense of proportion, symmetry and balance not apparent in similar pottery from Crete and Mycenae. The decoration is precisely geometric, and ordered neatly into zones on defined areas of each vessel. These qualities were to manifest themselves not only through a millennium of Greek pottery making, but also in the architecture that was to emerge in the 6th century. The major development that occurred was in the growing use of the human figure as the major decorative motif, and the increasing surety with which humanity, its mythology, activities and passions were depicted.\nThe development in the depiction of the human form in pottery was accompanied by a similar development in sculpture. The tiny stylised bronzes of the Geometric period gave way to life-sized highly formalised monolithic representation in the Archaic period. The Classical period was marked by a rapid development towards idealised but increasingly lifelike depictions of gods in human form. This development had a direct effect on the sculptural decoration of temples, as many of the greatest extant works of ancient Greek sculpture once adorned temples, and many of the largest recorded statues of the age, such as the lost chryselephantine statues of Zeus at the Temple of Zeus at Olympia and Athena at the Parthenon, Athens, both over 40 feet high, were once housed in them.\nReligion and philosophy.\nThe religion of ancient Greece was a form of nature worship that grew out of the beliefs of earlier cultures. However, unlike earlier cultures, man was no longer perceived as being threatened by nature, but as its sublime product. The natural elements were personified as gods of the complete human form, and very human behaviour.\nThe home of the gods was thought to be Olympus, the highest mountain in Greece. The most important deities were: Zeus, the supreme god and ruler of the sky; Hera, his wife and goddess of marriage; Athena, goddess of wisdom; Poseidon, the god of the sea; Demeter, goddess of the harvest; Apollo, the god of the sun, law, healing, plague, reason, music and poetry; Artemis, goddess of chastity, the hunt and the wilderness; Aphrodite, goddess of love; Ares, God of war; Hermes, the god of commerce and travellers, Hephaestus, the god of fire and metalwork; and Dionysus, the god of wine and fruit-bearing plants. Worship, like many other activities, was done in the community, in the open. However, by 600 BC, the gods were often represented by large statues and it was necessary to provide a building in which each of these could be housed. This led to the development of temples.\nThe ancient Greeks perceived order in the universe, and in turn, applied order and reason to their creations. Their humanist philosophy put mankind at the centre of things and promoted well-ordered societies and the development of democracy. At the same time, the respect for human intellect demanded a reason, and promoted a passion for enquiry, logic, challenge, and problem-solving. The architecture of the ancient Greeks, and in particular, temple architecture, responds to these challenges with a passion for beauty, and for order and symmetry which is the product of a continual search for perfection, rather than a simple application of a set of working rules.\nArchitectural character.\nEarly development.\nThere is a clear division between the architecture of the preceding Mycenaean and Minoan cultures and that of the ancient Greeks, with much of the techniques and an understanding of their style being lost when these civilisations fell.\nMycenaean architecture is marked by massive fortifications, typically surrounding a citadel with a royal palace, much smaller than the rambling Minoan \"palaces\", and relatively few other buildings. The megaron, a rectangular hall with a hearth in the centre, was the largest room in the palaces, and also larger houses. Sun-dried brick above rubble bases were the usual materials, with wooden columns and roof-beams. Rows of ashlar stone orthostats lined the base of walls in some prominent locations.\nThe Minoan architecture of Crete was of the trabeated form like that of ancient Greece. It employed wooden columns with capitals, but the wooden columns were of a very different form to Doric columns, being narrow at the base and splaying upward. The earliest forms of columns in Greece seem to have developed independently. As with Minoan architecture, ancient Greek domestic architecture centred on open spaces or courtyards surrounded by colonnades. This form was adapted to the construction of hypostyle halls within the larger temples. The evolution that occurred in architecture was towards the public building, first and foremost the temple, rather than towards grand domestic architecture such as had evolved in Crete, if the Cretan \"palaces\" were indeed domestic, which remains uncertain.\nSome Mycenaean tombs are marked by circular structures and tapered domes with flat-bedded, cantilevered courses. This architectural form did not carry over into the architecture of ancient Greece, but reappeared about 400 BC in the interior of large monumental tombs such as the Lion Tomb at Knidos (c. 350 BC).\nTypes of buildings.\nDomestic buildings.\nThe Greek word for the family or household, \"oikos\", is also the name for the house. Houses followed several different types. It is probable that many of the earliest houses were simple structures of two rooms, with an open porch or pronaos, above which rose a low pitched gable or pediment. This form is thought to have contributed to temple architecture.\nThe construction of many houses employed walls of sun-dried clay bricks or wooden framework filled with fibrous material such as straw or seaweed covered with clay or plaster, on a base of stone which protected the more vulnerable elements from damp. The roofs were probably of thatch with eaves which overhung the permeable walls. Many larger houses, such as those at Delos, were built of stone and plastered. The roofing material for the substantial house was tile. Houses of the wealthy had mosaic floors and demonstrated the Classical style.\nMany houses centred on a wide passage or \"pasta\" which ran the length of the house and opened at one side onto a small courtyard which admitted light and air. Larger houses had a fully developed peristyle (courtyard) at the centre, with the rooms arranged around it. Some houses had an upper floor which appears to have been reserved for the use of the women of the family.\nCity houses were built with adjoining walls and were divided into small blocks by narrow streets. Shops were sometimes located in the rooms towards the street. City houses were inward-facing, with major openings looking onto the central courtyard, rather than the street.\nPublic buildings.\nThe rectangular temple is the most common and best-known form of Greek public architecture. This rectilinear structure borrows from the Late Helladic, Mycenaean megaron, which contained a central throne room, vestibule, and porch. The temple did not serve the same function as a modern church, since the altar stood under the open sky in the \"temenos\" or sacred precinct, often directly before the temple. Temples served as the location of a cult image and as a storage place or strong room for the treasury associated with the cult of the god in question, and as a place for devotees of the god to leave their votive offerings, such as statues, helmets and weapons. Some Greek temples appear to have been oriented astronomically. The temple was generally part of a religious precinct known as the \"acropolis\". According to Aristotle, \"the site should be a spot seen far and wide, which gives good elevation to virtue and towers over the neighbourhood\". Small circular temples, \"tholoi\" were also constructed, as well as small temple-like buildings that served as treasuries for specific groups of donors.\nDuring the late 5th and 4th centuries BC, town planning became an important consideration of Greek builders, with towns such as Paestum and Priene being laid out with a regular grid of paved streets and an agora or central market place surrounded by a colonnade or stoa. The completely restored Stoa of Attalos can be seen in Athens. Towns were also equipped with a public fountain where water could be collected for household use. The development of regular town plans is associated with Hippodamus of Miletus, a pupil of Pythagoras.\nPublic buildings became \"dignified and gracious structures\", and were sited so that they related to each other architecturally. The propylon or porch, formed the entrance to temple sanctuaries and other significant sites with the best-surviving example being the Propylaea on the Acropolis of Athens. The bouleuterion was a large public building with a hypostyle hall that served as a court house and as a meeting place for the town council (boule). Remnants of bouleuterion survive at Athens, Olympia and Miletus, the latter having held up to 1,200 people.\nEvery Greek town had an open-air theatre. These were used for both public meetings as well as dramatic performances. The theatre was usually set in a hillside outside the town, and had rows of tiered seating set in a semicircle around the central performance area, the \"orchestra\". Behind the orchestra was a low building called the \"sk\u00ean\u00ea\", which served as a store-room, a dressing room, and also as a backdrop to the action taking place in the orchestra. A number of Greek theatres survive almost intact, the best known being at Epidaurus by the architect Polykleitos the Younger.\nGreek towns of substantial size also had a palaestra or a gymnasium, the social centre for male citizens which included spectator areas, baths, toilets and club rooms. Other buildings associated with sports include the hippodrome for horse racing, of which only remnants have survived, and the stadium for foot racing, 600 feet in length, of which examples exist at Olympia, Delphi, Epidaurus and Ephesus, while the Panathinaiko Stadium in Athens, which seats 45,000 people, was restored in the 19th century and was used in the 1896, 1906 and 2004 Olympic Games.\nStructure.\nPost and lintel.\nThe architecture of ancient Greece is of a trabeated or \"post and lintel\" form, i.e. it is composed of upright beams (posts) supporting horizontal beams (lintels). Although the existent buildings of the era are constructed in stone, it is clear that the origin of the style lies in simple wooden structures, with vertical posts supporting beams which carried a ridged roof. The posts and beams divided the walls into regular compartments which could be left as openings, or filled with sun dried bricks, lathes or straw and covered with clay daub or plaster. Alternately, the spaces might be filled with rubble. It is likely that many early houses and temples were constructed with an open porch or \"pronaos\" above which rose a low pitched gable or pediment.\nThe earliest temples, built to enshrine statues of deities, were probably of wooden construction, later replaced by the more durable stone temples many of which are still in evidence today. The signs of the original timber nature of the architecture were maintained in the stone buildings.\nA few of these temples are very large, with several, such as the Temple of Zeus Olympus and the Olympians at Athens being well over 300 feet in length, but most were less than half this size. It appears that some of the large temples began as wooden constructions in which the columns were replaced piecemeal as stone became available. This, at least was the interpretation of the historian Pausanias looking at the Temple of Hera at Olympia in the 2nd century AD.\nThe stone columns are made of a series of solid stone cylinders or \"drums\" that rest on each other without mortar, but were sometimes centred with a bronze pin. The columns are wider at the base than at the top, tapering with an outward curve known as entasis. Each column has a capital of two parts, the upper, on which rests the lintels, being square and called the abacus. The part of the capital that rises from the column itself is called the echinus. It differs according to the order, being plain in the Doric order, fluted in the Ionic and foliate in the Corinthian. Doric and usually Ionic capitals are cut with vertical grooves known as fluting. This fluting or grooving of the columns is a retention of an element of the original wooden architecture.\nEntablature and pediment.\nThe columns of a temple support a structure that rises in two main stages, the entablature and the pediment.\nThe entablature is the major horizontal structural element supporting the roof and encircling the entire building. It is composed of three parts. Resting on the columns is the architrave made of a series of stone \"lintels\" that spanned the space between the columns, and meet each other at a joint directly above the centre of each column.\nAbove the architrave is a second horizontal stage called the frieze. The frieze is one of the major decorative elements of the building and carries a sculptured relief. In the case of Ionic and Corinthian architecture, the relief decoration runs in a continuous band, but in the Doric order, it is divided into sections called metopes, which fill the spaces between vertical rectangular blocks called triglyphs. The triglyphs are vertically grooved like the Doric columns, and retain the form of the wooden beams that would once have supported the roof.\nThe upper band of the entablature is called the cornice, which is generally ornately decorated on its lower edge. The cornice retains the shape of the beams that would once have supported the wooden roof at each end of the building. At the front and rear of each temple, the entablature supports a triangular structure called the pediment. The tympanum is the triangular space framed by the cornices and the location of the most significant sculptural decoration on the exterior of the building.\nMasonry.\nEvery temple rested on a masonry base called the crepidoma, generally of three steps, of which the upper one which carried the columns was the stylobate. Masonry walls were employed for temples from about 600 BC onwards. Masonry of all types was used for ancient Greek buildings, including rubble, but the finest ashlar masonry was usually employed for temple walls, in regular courses and large sizes to minimise the joints. The blocks were rough hewn and hauled from quarries to be cut and bedded very precisely, with mortar hardly ever being used. Blocks, particularly those of columns and parts of the building bearing loads were sometimes fixed in place or reinforced with iron clamps, dowels and rods of wood, bronze or iron fixed in lead to minimise corrosion.\nOpenings.\nDoor and window openings were spanned with a lintel, which in a stone building limited the possible width of the opening. The distance between columns was similarly affected by the nature of the lintel, columns on the exterior of buildings and carrying stone lintels being closer together than those on the interior, which carried wooden lintels. Door and window openings narrowed towards the top. Temples were constructed without windows, the light to the naos entering through the door. It has been suggested that some temples were lit from openings in the roof. A door of the Ionic Order at the Erechtheion (17 feet high and 7.5 feet wide at the top) retains many of its features intact, including mouldings, and an entablature supported on console brackets. \nRoof.\nThe widest span of a temple roof was across the cella, or inner chamber. In a large building, this space contains columns to support the roof, the architectural form being known as hypostyle. It appears that, although the architecture of ancient Greece was initially of wooden construction, the early builders did not have the concept of the diagonal truss as a stabilising member. This is evidenced by the nature of temple construction in the 6th century BC, where the rows of columns supporting the roof of the cella rise higher than the outer walls, unnecessary if roof trusses are employed as an integral part of the wooden roof. The indication is that initially all the rafters were supported directly by the entablature, walls and hypostyle, rather than on a trussed wooden frame, which came into use in Greek architecture only in the 3rd century BC.\nAncient Greek buildings of timber, clay and plaster construction were probably roofed with thatch. With the rise of stone architecture came the appearance of fired ceramic roof tiles. These early roof tiles showed an S-shape, with the pan and cover tile forming one piece. They were much larger than modern roof tiles, being up to long, wide, thick and weighing around apiece. Only stone walls, which were replacing the earlier mudbrick and wood walls, were strong enough to support the weight of a tiled roof.\nThe earliest finds of roof tiles of the Archaic period in Greece are documented from a very restricted area around Corinth, where fired tiles began to replace thatched roofs at the temples of Apollo and Poseidon between 700 and 650 BC. Spreading rapidly, roof tiles were within fifty years in evidence for a large number of sites around the Eastern Mediterranean, including Mainland Greece, Western Asia Minor, Southern and Central Italy. Being more expensive and labour-intensive to produce than thatch, their introduction has been explained by the fact that their fireproof quality would have given desired protection to the costly temples. As a side-effect, it has been assumed that the new stone and tile construction also ushered in the end of overhanging eaves in Greek architecture, as they made the need for an extended roof as rain protection for the mudbrick walls obsolete.\nVaults and arches were not generally used, but begin to appear in tombs (in a \"beehive\" or cantilevered form such as used in Mycenaea) and occasionally, as an external feature, exedrae of voussoired construction from the 5th century BC. The dome and vault never became significant structural features, as they were to become in ancient Roman architecture.\nTemple plans.\nMost ancient Greek temples were rectangular, and were approximately twice as long as they were wide, with some notable exceptions such as the enormous Temple of Olympian Zeus, Athens, with a length of nearly 2&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 times its width. A number of surviving temple-like structures are circular, and are referred to as \"tholos\". The smallest temples are less than 25 metres (approx. 75 feet) in length, or in the case of the circular \"tholos\", in diameter. The great majority of temples are between 30 and 60 metres (approx. 100\u2013200 feet) in length. A small group of Doric temples, including the Parthenon, are between 60 and 80 metres (approx. 200\u2013260 feet) in length. The largest temples, mainly Ionic and Corinthian, but including the Doric Temple of the Olympian Zeus, Agrigento, were between 90 and 120 metres (approx. 300\u2013390 feet) in length.\nThe temple rises from a stepped base or stylobate, which elevates the structure above the ground on which it stands. Early examples, such as the Temple of Zeus at Olympus, have two steps, but the majority, like the Parthenon, have three, with the exceptional example of the Temple of Apollo at Didyma having six. The core of the building is a masonry-built \"naos\" within which is a cella, a windowless room originally housing the statue of the god. The cella generally has a porch or \"pronaos\" before it, and perhaps a second chamber or \"antenaos\" serving as a treasury or repository for trophies and gifts. The chambers were lit by a single large doorway, fitted with a wrought iron grill. Some rooms appear to have been illuminated by skylights.\nOn the stylobate, often completely surrounding the naos, stand rows of columns. Each temple is defined as being of a particular type, with two terms: one describing the number of columns across the entrance front, and the other defining their distribution.\nExamples:\nProportion and optical illusion.\nThe ideal of proportion that was used by ancient Greek architects in designing temples was not a simple mathematical progression using a square module. The math involved a more complex geometrical progression, the so-called golden mean. The ratio is similar to that of the growth patterns of many spiral forms that occur in nature such as rams' horns, nautilus shells, fern fronds, and vine tendrils and which were a source of decorative motifs employed by ancient Greek architects as particularly in evidence in the volutes of capitals of the Ionic and Corinthian Orders.\nformula_1\nThe ancient Greek architects took a philosophic approach to the rules and proportions. The determining factor in the mathematics of any notable work of architecture was its ultimate appearance. The architects calculated for perspective, for the optical illusions that make edges of objects appear concave and for the fact that columns that are viewed against the sky look different from those adjacent that are viewed against a shadowed wall. Because of these factors, the architects adjusted the plans so that the major lines of any significant building are rarely straight. The most obvious adjustment is to the profile of columns, which narrow from base to top. However, the narrowing is not regular, but gently curved so that each column appears to have a slight swelling, called \"entasis\" below the middle. The \"entasis\" is never sufficiently pronounced as to make the swelling wider than the base; it is controlled by a slight reduction in the rate of decrease of diameter.\nThe Parthenon, the Temple to the Goddess Athena on the Acropolis in Athens, is referred to by many as the pinnacle of ancient Greek architecture. Helen Gardner refers to its \"unsurpassable excellence\", to be surveyed, studied and emulated by architects of later ages. Yet, as Gardner points out, there is hardly a straight line in the building. Banister Fletcher calculated that the \"stylobate\" curves upward so that its centres at either end rise about above the outer corners, and on the longer sides. A slightly greater adjustment has been made to the entablature. The columns at the ends of the building are not vertical but are inclined towards the centre, with those at the corners being out of plumb by about . These outer columns are both slightly wider than their neighbours and are slightly closer than any of the others.\nStyle.\nOrders.\nAncient Greek architecture of the most formal type, for temples and other public buildings, is divided stylistically into three Classical orders, first described by the Roman architectural writer Vitruvius. These are: the Doric order, the Ionic order, and the Corinthian order, the names reflecting their regional origins within the Greek world. While the three orders are most easily recognizable by their capitals, they also governed the form, proportions, details and relationships of the columns, entablature, pediment, and the stylobate. The different orders were applied to the whole range of buildings and monuments.\nThe Doric order developed on mainland Greece and spread to Magna Graecia (Italy). It was firmly established and well-defined in its characteristics by the time of the building of the Temple of Hera at Olympia, c. 600 BC. The Ionic order co-existed with the Doric, being favoured by the Greek cities of Ionia, in Asia Minor and the Aegean Islands. It did not reach a clearly defined form until the mid 5th\u00a0century BC. The early Ionic temples of Asia Minor were particularly ambitious in scale, such as the Temple of Artemis at Ephesus. The Corinthian order was a highly decorative variant not developed until the Hellenistic period and retaining many characteristics of the Ionic. It was popularised by the Romans.\nDoric order.\nThe Doric order is recognised by its capital, of which the \"echinus\" is like a circular cushion rising from the top of the column to the square \"abacus\" on which rest the lintels. The echinus appears flat and splayed in early examples, deeper and with greater curve in later, more refined examples, and smaller and straight-sided in Hellenistic examples. A refinement of the Doric column is the entasis, a gentle convex swelling to the profile of the column, which prevents an optical illusion of concavity. This is more pronounced in earlier examples.\nDoric columns are almost always cut with grooves, known as \"fluting\", which run the length of the column and are usually 20 in number, although sometimes fewer. The flutes meet at sharp edges called \"arrises\". At the top of the columns, slightly below the narrowest point, and crossing the terminating arrises, are three horizontal grooves known as the \"hypotrachelion\". Doric columns have no bases, until a few examples in the Hellenistic period.\nThe columns of an early Doric temple such as the Temple of Apollo at Syracuse, Sicily, may have a height to base diameter ratio of only 4:1 and a column height to entablature ratio of 2:1, with relatively crude details. A column height to diameter of 6:1 became more usual, while the column height to entablature ratio at the Parthenon is about 3:1. During the Hellenistic period, Doric conventions of solidity and masculinity dropped away, with the slender and unfluted columns reaching a height to diameter ratio of 7.5:1.\nThe Doric entablature is in three parts, the architrave, the frieze and the cornice. The architrave is composed of the stone lintels which span the space between the columns, with a joint occurring above the centre of each abacus. On this rests the frieze, one of the major areas of sculptural decoration. The frieze is divided into \"triglyphs\" and \"metopes\", the triglyphs, as stated elsewhere in this article, are a reminder of the timber history of the architectural style. Each triglyph has three vertical grooves, similar to the columnar fluting, and below them, seemingly connected, are guttae, small strips that appear to connect the triglyphs to the architrave below. A triglyph is located above the centre of each capital, and above the centre of each lintel. However, at the corners of the building, the triglyphs do not fall over the centre the column. The ancient architects took a pragmatic approach to the apparent \"rules\", simply extending the width of the last two metopes at each end of the building.\nThe cornice is a narrow jutting band of complex molding, which overhangs and protects the ornamented frieze, like the edge of an overhanging wooden-framed roof. It is decorated on the underside with projecting blocks, \"mutules\", further suggesting the wooden nature of the prototype. At either end of the building the pediment rises from the cornice, framed by moulding of similar form.\nThe pediment is decorated with figures that are in relief in the earlier examples, though almost free-standing by the time of the sculpture on the Parthenon. Early architectural sculptors found difficulty in creating satisfactory sculptural compositions in the tapering triangular space. By the Early Classical period, with the decoration of the Temple of Zeus at Olympia (486\u2013460 BC), the sculptors had solved the problem by having a standing central figure framed by rearing centaurs and fighting men who are falling, kneeling and lying in attitudes that fit the size and angle of each part of the space. The famous sculptor Phidias fills the space at the Parthenon (448\u2013432 BC) with a complex array of draped and undraped figures of deities, who appear in attitudes of sublime relaxation and elegance.\nIonic order.\nThe Ionic order is recognized by its voluted capital, in which a curved \"echinus\" of similar shape to that of the Doric order, but decorated with stylised ornament, is surmounted by a horizontal band that scrolls under to either side, forming spirals or \"volutes\" similar to those of the nautilus shell or ram's horn. In plan, the capital is rectangular. It is designed to be viewed frontally but the capitals at the corners of buildings are modified with an additional scroll so as to appear regular on two adjoining faces. In the Hellenistic period, four-fronted Ionic capitals became common.\nLike the Doric order, the Ionic order retains signs of having its origins in wooden architecture. The horizontal spread of a flat timber plate across the top of a column is a common device in wooden construction, giving a thin upright a wider area on which to bear the lintel, while at the same time reinforcing the load-bearing strength of the lintel itself. Likewise, the columns always have bases, a necessity in wooden architecture to spread the load and protect the base of a comparatively thin upright. The columns are fluted with narrow, shallow flutes that do not meet at a sharp edge but have a flat band or \"fillet\" between them. The usual number of flutes is twenty-four but there may be as many as forty-four. The base has two convex mouldings called \"torus\", and from the late Hellenic period stood on a square plinth similar to the \"abacus\".\nThe architrave of the Ionic order is sometimes undecorated, but more often rises in three outwardly-stepped bands like overlapping timber planks. The frieze, which runs in a continuous band, is separated from the other members by rows of small projecting blocks. They are referred to as dentils, meaning \"teeth\", but their origin is clearly in narrow wooden slats which supported the roof of a timber structure. The Ionic order is altogether lighter in appearance than the Doric, with the columns, including base and capital, having a 9:1 ratio with the diameter, while the whole entablature was also much narrower and less heavy than the Doric entablature. There was some variation in the distribution of decoration. Formalised bands of motifs such as alternating forms known as egg-and-dart were a feature of the Ionic entablatures, along with the bands of dentils. The external frieze often contained a continuous band of figurative sculpture or ornament, but this was not always the case. Sometimes a decorative frieze occurred around the upper part of the \"naos\" rather than on the exterior of the building. These Ionic-style friezes around the \"naos\" are sometimes found on Doric buildings, notably the Parthenon. Some temples, like the Temple of Artemis at Ephesus, had friezes of figures around the lower drum of each column, separated from the fluted section by a bold moulding.\nCaryatids, draped female figures used as supporting members to carry the entablature, were a feature of the Ionic order, occurring at several buildings including the Siphnian Treasury at Delphi in 525 BC and at the Erechtheion, about 410 BC.\nCorinthian order.\nThe Corinthian order does not have its origin in wooden architecture. It grew directly out of the Ionic in the mid 5th century BC, and was initially of much the same style and proportion, but distinguished by its more ornate capitals. The capital was very much deeper than either the Doric or the Ionic capital, being shaped like a large \"krater\", a bell-shaped mixing bowl, and being ornamented with a double row of acanthus leaves above which rose voluted tendrils, supporting the corners of the abacus, which, no longer perfectly square, splayed above them. According to Vitruvius, the capital was invented by a bronze founder, Callimachus of Corinth, who took his inspiration from a basket of offerings that had been placed on a grave, with a flat tile on top to protect the goods. The basket had been placed on the root of an acanthus plant which had grown up around it. The ratio of the column height to diameter is generally 10:1, with the capital taking up more than 1/10 of the height. The ratio of capital height to diameter is generally about 1.16:1.\nThe Corinthian order was initially used internally, as at the Temple of Apollo Epicurius at Bassae (c. 450\u2013425 BC). In 334 BC, it appeared as an external feature on the Choragic Monument of Lysicrates in Athens, and then on a huge scale at the Temple of Zeus Olympia in Athens (174 BC\u2013132 AD). It was popularised by the Romans, who added a number of refinements and decorative details. During the Hellenistic period, Corinthian columns were sometimes built without fluting.\nDecoration.\nArchitectural ornament.\nEarly wooden structures, particularly temples, were ornamented and in part protected by fired and painted terracotta revetments in the form of rectangular panels, and ornamental discs. Many fragments of these have outlived the buildings that they decorated and demonstrate a wealth of formal border designs of geometric scrolls, overlapping patterns and foliate motifs. With the introduction of stone-built temples, the revetments no longer served a protective purpose and sculptured decoration became more common.\nThe clay ornaments were limited to the roof of buildings, decorating the cornice, the corners and surmounting the pediment. At the corners of pediments they were called acroteria and along the sides of the building, antefixes. Early decorative elements were generally semi-circular, but later of roughly triangular shape with moulded ornament, often palmate. Ionic cornices were often set with a row of lion's masks, with open mouths that ejected rainwater. From the Late Classical period, acroteria were sometimes sculptured figures (see Architectural sculpture).\nIn the three orders of ancient Greek architecture, the sculptural decoration, be it a simple half round astragal, a frieze of stylised foliage or the ornate sculpture of the pediment, is all essential to the architecture of which it is a part. In the Doric order, there is no variation in its placement. Reliefs never decorate walls in an arbitrary way. The sculpture is always located in several predetermined areas, the metopes and the pediment. In later Ionic architecture, there is greater diversity in the types and numbers of mouldings and decorations, particularly around doorways, where voluted brackets sometimes occur supporting an ornamental cornice over a door, such as that at the Erechtheion. A much applied narrow moulding is called \"bead and reel\" and is symmetrical, stemming from turned wooden prototypes. Wider mouldings include one with tongue-like or pointed leaf shapes, which are grooved and sometimes turned upward at the tip, and \"egg and dart\" moulding which alternates ovoid shapes with narrow pointed ones.\nArchitectural sculpture.\nArchitectural sculpture showed a development from early Archaic examples through Severe Classical, High Classical, Late Classical and Hellenistic. Remnants of Archaic architectural sculpture (700\u2013500 BC) exist from the early 6th century BC with the earliest surviving pedimental sculptures being fragments of a Gorgon flanked by heraldic panthers from the centre of the pediment of the Artemis Temple of Corfu. A metope from a temple known as \"Temple C\" at Selinus, Sicily, shows, in a better preserved state, Perseus slaying the Gorgon Medusa. Both images parallel the stylised depiction of the Gorgons on the black figure name vase decorated by the Nessos painter (c. 600 BC), with the face and shoulders turned frontally, and the legs in a running or kneeling position. At this date, images of terrifying monsters have predominance over the emphasis on the human figure that developed with Humanist philosophy.\nEarly pedimental sculptures, and those on smaller temples, were usually in relief, and the late free-standing ones were often in terracotta, which has survived only in fragments. The sculptures were covered with a layer of stucco and painted or, if terracotta, painted with the more restrained fired colours of Greek pottery.\nThe \"Severe Classical Style\" (500\u2013450 BC) is represented by the pedimental sculptures of the Temple of Zeus at Olympia (470\u2013456 BC). The eastern pediment shows a moment of stillness and \"impending drama\" before the beginning of a chariot race, the figures of Zeus and the competitors being severe and idealised representations of the human form. The western pediment has Apollo as the central figure, \"majestic\" and \"remote\", presiding over a battle of Lapiths and Centaurs, in strong contrast to that of the eastern pediment for its depiction of violent action, and described by Donald E. Strong as the \"most powerful piece of illustration\" for a hundred years.\nThe reliefs and three-dimensional sculpture which adorned the frieze and pediments, respectively, of the Parthenon, are the lifelike products of the High Classical style (450\u2013400 BC) and were created under the direction of the sculptor Phidias. The pedimental sculpture represents the Gods of Olympus, while the frieze shows the Panathenaic procession and ceremonial events that took place every four years to honour the titular Goddess of Athens. The frieze and remaining figures of the eastern pediment show a profound understanding of the human body, and how it varies depending upon its position and the stresses that action and emotion place upon it. Benjamin Robert Haydon described the reclining figure of Dionysus as \"the most heroic style of art, combined with all the essential detail of actual life\".\nThe names of many famous sculptors are known from the Late Classical period (400\u2013323 BC), including Timotheos, Praxiteles, Leochares and Skopas, but their works are known mainly from Roman copies. Little architectural sculpture of the period remains intact. The Temple of Asclepius at Epidauros had sculpture by Timotheos working with the architect Theodotos. Fragments of the eastern pediment survive, showing the Sack of Troy. The scene appears to have filled the space with figures carefully arranged to fit the slope and shape available, as with the earlier east pediment of the Temple of Zeus at Olympus. But the figures are more violent in action, the central space taken up, not with a commanding God, but with the dynamic figure of Neoptolemos as he seizes the aged king Priam and stabs him. The remaining fragments give the impression of a range of human emotions, fear, horror, cruelty and lust for conquest. The \"acroteria\" were sculptured by Timotheus, except for that at the centre of the east pediment which is the work of the architect. The palmate acroteria have been replaced here with small figures, the eastern pediment being surmounted by a winged Nike, poised against the wind.\nHellenistic architectural sculpture (323\u201331 BC) was to become more flamboyant, both in the rendering of expression and motion, which is often emphasised by flowing draperies, the Nike Samothrace which decorated a monument in the shape of a ship being a well-known example. The Pergamon Altar (c. 180\u2013160 BC) has a frieze (120 metres long by 2.3 metres high) of figures in very high relief. The frieze represents the battle for supremacy of Gods and Titans, and employs many dramatic devices: frenzy, pathos and triumph, to convey the sense of conflict.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52685", "revid": "50303599", "url": "https://en.wikipedia.org/wiki?curid=52685", "title": "Ancient Roman architecture", "text": " \n \nAncient Roman architecture adopted the external language of classical ancient Greek architecture for the purposes of the ancient Romans, but was different from Greek buildings, becoming a new architectural style. The two styles are often considered one body of classical architecture. Roman architecture flourished in the Roman Republic and to an even greater extent under the Empire, when the great majority of surviving buildings were constructed. It used new materials, particularly Roman concrete, and newer technologies such as the arch and the dome to make buildings that were typically strong and well engineered. Large numbers remain in some form across the former empire, sometimes complete and still in use today.\nRoman architecture covers the period from the establishment of the Roman Republic in 509 BC to about the 4th century AD, after which it becomes reclassified as Late Antique or Byzantine architecture. Few substantial examples survive from before about 100 BC, and most of the major survivals are from the later empire, after about 100 AD. Roman architectural style continued to influence building in the former empire for many centuries, and the style used in Western Europe beginning about 1000 is called Romanesque architecture to reflect this dependence on basic Roman forms.\nThe Romans only began to achieve significant originality in architecture around the beginning of the Imperial period, after they had combined aspects of their originally Etruscan architecture with others taken from Greece, including most elements of the style we now call classical architecture. They moved from trabeated construction mostly based on columns and lintels to one based on massive walls, punctuated by arches, and later domes, both of which greatly developed under the Romans. The classical orders now became largely decorative rather than structural, except in colonnades. Stylistic developments included the Tuscan and Composite orders; the first being a shortened, simplified variant on the Doric order and the Composite being a tall order with the floral decoration of the Corinthian and the scrolls of the Ionic. The period from roughly 40 BC to about 230 AD saw most of the greatest achievements, before the Crisis of the Third Century and later troubles reduced the wealth and organizing power of the central governments.\nThe Romans produced massive public buildings and works of civil engineering, and were responsible for significant developments in housing and public hygiene, for example their public and private baths and latrines, under-floor heating in the form of the hypocaust, mica glazing (examples in Ostia Antica), and piped hot and cold water (examples in Pompeii and Ostia).\nOverview.\nDespite the technical developments of the Romans, which took their buildings far away from the basic Greek conception where columns were needed to support heavy beams and roofs, they were reluctant to abandon the classical orders in formal public buildings, even though these had become essentially decorative. However, they did not feel entirely restricted by Greek aesthetic concerns and treated the orders with considerable freedom.\nInnovation started in the 3rd or 2nd century BC with the development of Roman concrete as a readily available adjunct to, or substitute for, stone and brick. More daring buildings soon followed, with great pillars supporting broad arches and domes. The freedom of concrete also inspired the colonnade screen, a row of purely decorative columns in front of a load-bearing wall. In smaller-scale architecture, concrete's strength freed the floor plan from rectangular cells to a more free-flowing environment.\nFactors such as wealth and high population densities in cities forced the ancient Romans to discover new architectural solutions of their own. The use of vaults and arches, together with a sound knowledge of building materials, enabled them to achieve unprecedented successes in the construction of imposing infrastructure for public use. Examples include the aqueducts of Rome, the Baths of Diocletian and the Baths of Caracalla, the basilicas and Colosseum. These were reproduced at a smaller scale in the most important towns and cities in the Empire. Some surviving structures are almost complete, such as the town walls of Lugo in Hispania Tarraconensis, now northern Spain. The administrative structure and wealth of the Empire made possible very large projects even in locations remote from the main centers, as did the use of slave labor, both skilled and unskilled.\nEspecially under the empire, architecture often served a political function, demonstrating the power of the Roman state in general, and of specific individuals responsible for building. Roman architecture perhaps reached its peak in the reign of Hadrian, whose many achievements include rebuilding the Pantheon in its current form and leaving his mark on the landscape of northern Britain with Hadrian's Wall.\nOrigins.\nWhile borrowing much from the preceding Etruscan architecture, such as the use of hydraulics and the construction of arches, Roman prestige architecture remained firmly under the spell of ancient Greek architecture and the classical orders. This came initially from Magna Graecia, the Greek colonies in southern Italy, and indirectly from Greek influence on the Etruscans. This influence intensified following the Roman conquest of Greece, a process culminating in the sack of Corinth in 146 BCE, after which Greek artworks were transferred to Rome. These works provided direct models for Roman architects and artists, a phenomenon evident in practices such as the introduction and use of the triclinium in Roman villas. Roman builders employed Greeks in many capacities, especially in the great boom in construction in the early Empire.\nRoman architectural revolution.\nThe Roman architectural revolution, also known as the \"concrete revolution\", was the widespread use in Roman architecture of the previously little-used architectural forms of the arch, vault, and dome. For the first time in history, their potential was fully exploited in the construction of a wide range of civil engineering structures, public buildings, and military facilities. These included amphitheatres, aqueducts, baths, bridges, circuses, dams, domes, harbours, temples, and theatres. According to Gottfried Semper, Roman architecture was \"the idea of world domination expressed in stone\".\nA crucial factor in this development, which saw a trend toward monumental architecture, was the invention of Roman concrete (\"opus caementicium\"), which led to the liberation of shapes from the dictates of the traditional materials of stone and brick.\nThese enabled the building of the many aqueducts throughout the Roman Empire, such as the Aqueduct of Segovia, the Pont du Gard, and the eleven aqueducts of Rome. The same concepts produced numerous bridges, some of which are still in daily use, for example, the Puente Romano at M\u00e9rida in Spain, and the Pont Julien and the bridge at Vaison-la-Romaine, both in Provence, France. \nThe dome permitted the construction of vaulted ceilings without crossbeams and made possible large covered public spaces such as public baths and basilicas, such as Hadrian's Pantheon, the Baths of Diocletian and the Baths of Caracalla, all in Rome.\nThe Romans first adopted the arch from the Etruscans and implemented it in their own building. The use of arches that spring directly from the tops of columns was a Roman development, seen from the 1st century AD, that was very widely adopted in medieval Western, Byzantine and Islamic architecture.\nDomes.\nThe Romans were the first builders in the history of architecture to realize the potential of domes for the creation of large and well-defined interior spaces. Domes were introduced in a number of Roman building types such as temples, thermae, palaces, mausolea and later also churches. Half-domes also became a favored architectural element and were adopted as apses in Christian sacred architecture.\nMonumental domes began to appear in the 1st century BC in Rome and the provinces around the Mediterranean Sea. Along with vaults, they gradually replaced the traditional post and lintel construction which makes use of the column and architrave. The construction of domes was greatly facilitated by the invention of concrete, a process which has been termed the Roman architectural revolution. Their enormous dimensions remained unsurpassed until the introduction of structural steel frames in the late 19th century (see List of the world's largest domes).\nInfluence on later architecture.\nRoman architecture supplied the basic vocabulary of Pre-Romanesque and Romanesque architecture, and spread across Christian Europe well beyond the old frontiers of the empire, to Ireland and Scandinavia for example. In the East, Byzantine architecture developed new styles of churches, but most other buildings remained very close to Late Roman forms. The same can be said in turn of Islamic architecture, where Roman forms long continued, especially in private buildings such as houses and the bathhouse, and civil engineering such as fortifications and bridges.\nIn Europe the Italian Renaissance saw a conscious revival of correct classical styles, initially purely based on Roman examples. Vitruvius was respectfully reinterpreted by a series of architectural writers, and the Tuscan and Composite orders formalized for the first time, to give five rather than three orders. After the flamboyance of Baroque architecture, the Neoclassical architecture of the 18th century revived purer versions of classical style, and for the first time added direct influence from the Greek world.\nNumerous local classical styles developed, such as Palladian architecture, Georgian architecture and Regency architecture in the English-speaking world, Federal architecture in the United States, and later Stripped Classicism and PWA Moderne.\nRoman influences may be found around us today, in banks, government buildings, great houses, and even small houses, perhaps in the form of a porch with Doric columns and a pediment or in a fireplace or a mosaic shower floor derived from a Roman original, often from Pompeii or Herculaneum. The mighty pillars, domes and arches of Rome echo in the New World too, where in Washington, D.C. stand the Capitol building, the White House, the Lincoln Memorial, and other government buildings. All across the US the seats of regional government were normally built in the grand traditions of Rome, with vast flights of stone steps sweeping up to towering pillared porticoes, with huge domes gilded or decorated inside with the same or similar themes that were popular in Rome.\nIn Britain, a similar enthusiasm has seen the construction of thousands of neoclassical buildings over the last five centuries, both civic and domestic, and many of the grandest country houses and mansions are purely Classical in style, an obvious example being Buckingham Palace.\nMaterials.\nStone.\nMarble is not found especially close to Rome, and was only rarely used there before Augustus, who famously boasted that he had found Rome made of brick and left it made of marble, though this was mainly as a facing for brick or concrete. The Temple of Hercules Victor of the late 2nd century BC is the earliest surviving exception in Rome. From Augustus' reign the quarries at Carrara were extensively developed for the capital, and other sources around the empire exploited, especially the prestigious Greek marbles like Parian. Travertine limestone was found much closer, around Tivoli, and was used from the end of the Republic; the Colosseum is mainly built of this stone, which has good load-bearing capacity, with a brick core. Other more or less local stones were used around the Empire.\nThe Romans were fond of luxury imported coloured marbles with fancy veining, and the interiors of the most important buildings were often faced with slabs of these, which have usually now been removed even where the building survives. Imports from Greece for this purpose began in the 2nd century BC.\nRoman brick.\nThe Romans made fired clay bricks from about the beginning of the Empire, replacing earlier sun-dried mudbrick. Roman brick was almost invariably of a lesser height than modern brick, but was made in a variety of different shapes and sizes. Shapes included square, rectangular, triangular and round, and the largest bricks found have measured over three feet in length. Ancient Roman bricks had a general size of 1\u00bd Roman feet by 1 Roman foot, but common variations up to 15 inches existed. Other brick sizes in ancient Rome included 24\" x 12\" x 4\", and 15\" x 8\" x 10\". Ancient Roman bricks found in France measured 8\" x 8\" x 3\". The Constantine Basilica in Trier is constructed from Roman bricks 15\" square by 1\u00bd\" thick. There is often little obvious difference (particularly when only fragments survive) between Roman bricks used for walls on the one hand, and tiles used for roofing or flooring on the other, so archaeologists sometimes prefer to employ the generic term ceramic building material (CBM).\nThe Romans perfected brick-making during the first century of their empire and used it ubiquitously, in public and private construction alike. They took their brickmaking skills everywhere they went, introducing the craft to the local populations. The Roman legions, which operated their own kilns, introduced bricks to many parts of the Empire; bricks are often stamped with the mark of the legion that supervised their production. The use of bricks in southern and western Germany, for example, can be traced to traditions already described by the Roman architect Vitruvius. In the British Isles, the introduction of Roman brick by the ancient Romans was followed by a 600\u2013700 year gap in major brick production.\nRoman concrete.\nConcrete quickly supplanted brick as the primary building material, and more daring buildings soon followed, with great pillars supporting broad arches and domes rather than dense lines of columns suspending flat architraves. The freedom of concrete also inspired the colonnade screen, a row of purely decorative columns in front of a load-bearing wall. In smaller-scale architecture, concrete's strength freed the floor plan from rectangular cells to a more free-flowing environment. Most of these developments are described by Vitruvius, writing in the first century BC in his work \"De architectura\".\nAlthough concrete had been used on a minor scale in Mesopotamia, Roman architects perfected Roman concrete and used it in buildings where it could stand on its own and support a great deal of weight. The first use of concrete by the Romans was in the town of Cosa sometime after 273 BC. Ancient Roman concrete was a mixture of lime mortar, aggregate, pozzolana, water, and stones, and was stronger than previously used concretes. The ancient builders placed these ingredients in wooden frames where they hardened and bonded to a facing of stones or (more frequently) bricks. The aggregates used were often much larger than in modern concrete, amounting to rubble.\nWhen the framework was removed, the new wall was very strong, with a rough surface of bricks or stones. This surface could be smoothed and faced with an attractive stucco or thin panels of marble or other coloured stones called a \"revetment\". Concrete construction proved to be more flexible and less costly than building solid stone buildings. The materials were readily available and not difficult to transport. The wooden frames could be used more than once, allowing builders to work quickly and efficiently. Concrete is arguably the Roman contribution most relevant to modern architecture.\nBuilding types.\nAmphitheatre.\nThe amphitheatre was, with the triumphal arch and basilica, the only major new type of building developed by the Romans. Some of the most impressive secular buildings are the amphitheatres, over 200 being known and many of which are well preserved, such as that at Arles, as well as its progenitor, the Colosseum in Rome. They were used for gladiatorial contests, public displays, public meetings and bullfights, the tradition of which still survives in Spain and Portugal. Their typical shape, functions and name distinguish them from Roman theatres, which are more or less semicircular in shape; from the circuses (akin to hippodromes) whose much longer circuits were designed mainly for horse or chariot racing events; and from the smaller stadia, which were primarily designed for athletics and footraces.\nThe earliest Roman amphitheatres date from the middle of the first century BC, but most were built under Imperial rule, from the Augustan period (27 BC\u201314 AD) onwards. Imperial amphitheatres were built throughout the Roman Empire; the largest could accommodate 40,000\u201360,000 spectators, and the most elaborate featured multi-storeyed, arcaded fa\u00e7ades and were elaborately decorated with marble, stucco and statuary. After the end of gladiatorial games in the 5th century and of animal killings in the 6th, most amphitheatres fell into disrepair, and their materials were mined or recycled. Some were razed, and others converted into fortifications. A few continued as convenient open meeting places; in some of these, churches were sited.\nArchitecturally, they are typically an example of the Roman use of the classical orders to decorate large concrete walls pierced at intervals, where the columns have nothing to support. Aesthetically, however, the formula is successful.\nBasilica.\nThe Roman basilica was a large public building where business or legal matters could be transacted. They were normally where the magistrates held court, and used for other official ceremonies, having many of the functions of the modern town hall. The first basilicas had no religious function. As early as the time of Augustus, a public basilica for transacting business had been part of any settlement that considered itself a city, used in the same way as the late medieval covered market houses of northern Europe, where the meeting room, for lack of urban space, was set above the arcades. Although their form was variable, basilicas often contained interior colonnades that divided the space, giving aisles or arcaded spaces on one or both sides, with an apse at one end (or less often at each end), where the magistrates sat, often on a slightly raised dais. The central aisle tended to be wide and was higher than the flanking aisles, so that light could penetrate through the clerestory windows.\nThe oldest known basilica, the Basilica Porcia, was built in Rome in 184\u00a0BC by Cato the Elder during the time he was censor. Other early examples include the basilica at Pompeii (late 2nd century\u00a0BC). After Christianity became the official religion, the basilica shape was found appropriate for the first large public churches, with the attraction of avoiding reminiscences of the Greco-Roman temple form.\nCircus.\nThe Roman circus was a large open-air venue used for public events in the ancient Roman Empire. The circuses were similar to the ancient Greek hippodromes, although circuses served varying purposes and differed in design and construction. Along with theatres and amphitheatres, circuses were one of the main entertainment sites of the time. Circuses were venues for chariot racing, horse races, and performances that commemorated important events of the Empire were performed there. For events that involved re-enactments of naval battles, the circus was flooded with water.\nThe performance space of the Roman circus was normally, despite its name, an oblong rectangle of two linear sections of race track, separated by a median strip running along the length of about two thirds the track, joined at one end with a semicircular section and at the other end with an undivided section of track closed (in most cases) by a distinctive starting gate known as the \"carceres\", thereby creating a circuit for the races.\nForum.\nDuring the years of the Republic, Augustus claimed he \"found the city in brick and left it in marble\". While chances are high that this was an exaggeration, there is something to be said for the influx of marble use in Roman Forum from 63 BC onwards. During Augustus' reign, the Forum was described to have been \"a larger, freer space than was the Forum of Imperial times.\" The Forum began to take on even more changes upon the arrival of Julius Caesar, who drew out extensive plans for the market hub. While Caesar's death came prematurely, his ideas, as well as Augustus' in regards to the Forum proved to be the most influential for years to come. According to Walter Dennison's \"The Roman Forum As Cicero Saw It\", the author writes that \"the diverting of public business to the larger and splendid Imperial fora erected in the vicinity resulted in leaving the general design of the Forum Romanum\".\nEvery city had at least one forum of varying size. In addition to its standard function as a marketplace, a forum was a gathering place of great social significance, and often the scene of diverse activities, including political discussions and debates, rendezvous, meetings, etc. The best known example is the Roman Forum, the earliest of several in Rome. In new Roman towns the forum was usually located at, or just off, the intersection of the main north\u2013south and east\u2013west streets (the cardo and decumanus). All forums would have a Temple of Jupiter at the north end, and would also contain other temples, as well as the basilica; a public weights and measures table, so customers at the market could ensure they were not being sold short measures; and would often have the baths nearby.\nHorreum.\nA horreum was a type of public warehouse used during the ancient Roman period. Although the Latin term is often used to refer to granaries, Roman horrea were used to store many other types of consumables; the giant Horrea Galbae in Rome were used not only to store grain but also olive oil, wine, foodstuffs, clothing and even marble. By the end of the Imperial period, the city of Rome had nearly 300 horrea to supply its demands. The biggest were enormous, even by modern standards; the Horrea Galbae contained 140 rooms on the ground floor alone, covering an area of some .\nThe first horrea were built in Rome towards the end of the 2nd century BC, with the first known public horreum being constructed by the ill-fated tribune Gaius Gracchus in 123 BC. The word came to be applied to any place designated for the preservation of goods; thus, it was often used to refer to cellars (\"horrea subterranea\"), but it could also be applied to a place where artworks were stored, or even to a library. Some public horrea functioned somewhat like banks, where valuables could be stored, but the most important class of horrea were those where foodstuffs such as grain and olive oil were stored and distributed by the state.\nThe word itself is thought to have linguist roots tied to the word \"hordeum\", which in Latin means barley. In the Johns Hopkins University Press, The Classical Weekly states that \"Pliny the Elder does indeed make a distinction between the two words. He describes the horreum as a structure made of brick, the walls of which were not less than three feet thick; it had no windows or openings for ventilation\". Furthermore, the storehouses would also host oil and wine and also use large jars that could serve as cache's for large amounts of products. These storehouses were also used to keep large sums of money and were used much like personal storage units today are. \"These horrea were divided and subdivided, so that one could hire only so much space as one wanted, a whole room (cella), a closet (armarium), or only a chest or strong box (arca, arcula, locus, loculus).\"\nInsula.\nMulti-story apartment blocks called \"insulae\" catered to a range of residential needs. The cheapest rooms were at the top owing to the inability to escape in the event of a fire and the lack of piped water. Windows were mostly small, facing the street, with iron security bars. \"Insulae\" were often dangerous, unhealthy, and prone to fires because of overcrowding and haphazard cooking arrangements. There are examples in the Roman port town of Ostia, that date to the reign of Trajan, but they seem to have been found mainly in Rome and a few other places. Elsewhere writers report them as something remarkable, but Livy and Vitruvius refer to them in Rome. External walls were in \"opus reticulatum\" and interiors in \"opus incertum\", which would then be plastered and sometimes painted.\nTo lighten up the small dark rooms, some tenants able to afford a degree of painted colourful murals on the walls. Examples have been found of jungle scenes with wild animals and exotic plants. Imitation windows (\"trompe-l'\u0153il\") were sometimes painted to make the rooms seem less confined.\nAncient Rome had elaborate and luxurious houses owned by the elite. The average house, or in cities apartment, of a commoner or plebeius did not contain many luxuries. The \"domus\", or single-family residence, was only for the well-off in Rome, with most having a layout of the closed unit, consisting of one or two rooms. Between 312 and 315 AD Rome had 1781 \"domus\" and 44,850 of \"insulae\".\n\"Insulae\" have been the subject of debate for historians of Roman culture, defining the various meanings of the word. \"Insula\" was a word used to describe apartment buildings, or the apartments themselves, meaning apartment, or inhabitable room, demonstrating just how small apartments for plebeians were. Urban divisions were originally street blocks, and later began to divide into smaller divisions, the word \"insula\" referring to both blocks and smaller divisions. The \"insula\" contained \"cenacula\", \"tabernae\", storage rooms under the stairs, and lower floor shops. Another type of housing unit for plebs was a \"cenaculum\", an apartment, divided into three individual rooms: \"cubiculum\", \"exedra\", and \"medianum\". Common Roman apartments were mainly masses of smaller and larger structures, many with narrow balconies that present mysteries as to their use, having no doors to access them, and they lacked the excessive decoration and display of wealth that aristocrats' houses contained. Luxury in houses was not common, as the life of the average person did not consist of being in their houses, as they instead would go to public baths, and engage in other communal activities.\nLighthouses.\nMany lighthouses were built around the Mediterranean and the coasts of the empire, including the Tower of Hercules at A Coru\u00f1a in northern Spain, a structure which survives to this day. A smaller lighthouse at Dover, England also exists as a ruin about half the height of the original. The light would have been provided by a fire at the top of the structure.\nThermae.\nAll Roman cities had at least one \"thermae\", a popular facility for public bathing, exercising and socializing. Exercise might include wrestling and weightlifting, as well as swimming. Bathing was an important part of the Roman day, where some hours might be spent, at a very low cost subsidized by the government. Wealthier Romans were often accompanied by one or more slaves, who performed any required tasks such as fetching refreshment, guarding valuables, providing towels, and at the end of the session, applying olive oil to their masters' bodies, which was then scraped off with a strigil, a scraper made of wood or bone.\nRoman bath-houses were also provided for private villas, town houses and forts. They were normally supplied with water from an adjacent river or stream, or by aqueduct. The design of \"thermae\" is discussed by Vitruvius in \"De architectura\".\nTemples.\nRoman temples were among the most important and richest buildings in Roman culture, though only a few survive in any sort of complete state. Their construction and maintenance was a major part of ancient Roman religion, and all towns of any importance had at least one main temple, as well as smaller shrines. The main room \"(cella)\" housed the cult image of the deity to whom the temple was dedicated, and often a small altar for incense or libations. Behind the \"cella\" was a room or rooms used by temple attendants for storage of equipment and offerings.\nRemains of many Roman temples survive, above all in Rome itself, but the relatively few near-complete examples were nearly all converted to Christian churches, usually a considerable time after the initial triumph of Christianity under Constantine. The decline of Roman religion was relatively slow, and the temples themselves were not appropriated by the government until a decree of the Emperor Honorius in 415. Some of the oldest surviving temples include the Temple of Hercules Victor (mid 2nd century BC) and Temple of Portunus (120\u201380 BC), both standing within the Forum Boarium. Original marble columns of the Temple of Janus in Rome's Forum Holitorium, dedicated by Gaius Duilius after his naval victory at the Battle of Mylae in 260 BC, still stand as a component of the exterior wall of the Renaissance era church of San Nicola in Carcere.\nThe form of the Roman temple was mainly derived from the Etruscan model, but using Greek styles. Roman temples emphasised the front of the building, which followed Greek temple models and typically consisted of wide steps leading to a portico with columns, a pronaos, and usually a triangular pediment above, which was filled with statuary in the most grand examples; this was as often in terracotta as stone, and no examples have survived except as fragments. However, unlike the Greek models, which generally gave equal treatment to all sides of the temple, which could be viewed and approached from all directions, the sides and rear of Roman temples might be largely undecorated (as in the Pantheon, Rome and temple of Vic), inaccessible by steps (as in the \"Maison carr\u00e9e\" and Vic), and even back on to other buildings. As in the \"Maison carr\u00e9e\", columns at the side might be engaged columns, emerging from (\"engaged with\" in architectural terminology) the wall. The platform on which the temple sat was typically raised higher in Roman examples than Greek, with up ten or twelve or more steps rather than the three typical in Greek temples; the Temple of Claudius was raised twenty steps. These steps were normally only at the front, and typically not the whole width of that.\nThe Greek classical orders in all their details were closely followed in the fa\u00e7ades of temples, as in other prestigious buildings. However, the idealized proportions between the different elements set out by the only significant Roman writer on architecture to survive, Vitruvius, and subsequent Italian Renaissance writers, do not reflect actual Roman practice, which could be very variable, though always aiming at balance and harmony. Following a Hellenistic trend, the Corinthian order and its variant the Composite order were most common in surviving Roman temples, but for small temples like that at Alc\u00e1ntara, a simple Tuscan order could be used.\nThere was considerable local variation in style, as Roman architects often tried to incorporate elements the population expected in its sacred architecture. This was especially the case in Egypt and the Near East, where different traditions of large stone temples were already millennia old. The Romano-Celtic temple was a simple style for small temples found in the Western Empire, and by far the most common type in Roman Britain. It often lacked any of the distinctive classical features, and may have had considerable continuity with pre-Roman temples of the Celtic religion.\nTheatres.\nRoman theatres were built in all areas of the Empire, from Spain to the Middle East. Because of the Romans' ability to influence local architecture, numerous theatres were built around the world with uniquely Roman attributes.\nThese buildings were semi-circular and possessed certain inherent architectural structures, with minor differences depending on the region in which they were constructed. The \"scaenae frons\" was a high back wall of the stage floor, supported by columns. The \"proscaenium\" was a wall that supported the front edge of the stage with ornately decorated niches to the sides. The Hellenistic influence is seen through the use of the \"proscaenium\". The Roman theatre also had a \"podium\", which sometimes supported the columns of the \"scaenae frons\". The \"scaenae\" was originally not part of the building itself, constructed only to provide sufficient background for the actors. Eventually, it became a part of the edifice itself, made out of concrete. The theatre itself was divided into the stage (orchestra) and the seating section (auditorium). \"Vomitoria\" or entrances and exits were made available to the audience.\nVilla.\nA Roman villa was a country house built for the upper class, while a \"domus\" was a wealthy family's house in a town. The Empire contained many kinds of villas, not all of them lavishly appointed with mosaic floors and frescoes. In the provinces, any country house with some decorative features in the Roman style may be called a \"villa\" by modern scholars. Some, like Hadrian's Villa at Tivoli, were pleasure palaces such as those that were situated in the cool hills within easy reach of Rome or, like the Villa of the Papyri at Herculaneum, on picturesque sites overlooking the Bay of Naples. Some villas were more like the country houses of England, the visible seat of power of a local magnate, such as the famous palace rediscovered at Fishbourne in Sussex.\nSuburban villas on the edge of cities were also known, such as the Middle and Late Republican villas that encroached on the Campus Martius, at that time on the edge of Rome, and which can be also seen outside the city walls of Pompeii, including the Villa of the Mysteries, known for its frescos. These early suburban villas, such as the one at Rome's Auditorium site or at Grottarossa in Rome, demonstrate the antiquity and heritage of the \"villa suburbana\" in Central Italy. It is possible that these early, suburban villas were also in fact the seats of power (maybe even palaces) of regional strongmen or heads of important families (\"gentes\").\nA third type of villa provided the organizational center of the large farming estates called \"latifundia\"; such villas might be lacking in luxuries. By the 4th century, \"villa\" could simply mean an agricultural estate or holding: Jerome translated the Gospel of Mark (xiv, 32) \"chorion\", describing the olive grove of Gethsemane, with \"villa\", without an inference that there were any dwellings there (\"Catholic Encyclopedia\" \"Gethsemane\").\nWith the colossal Diocletian's Palace, built in the countryside but later turned into a fortified city, a form of residential castle emerges, that anticipates the Middle Ages.\nWatermills.\nThe initial invention of the watermill appears to have occurred in the Hellenized eastern Mediterranean in the wake of the conquests of Alexander the Great and the rise of Hellenistic science and technology. In the subsequent Roman era, the use of water-power was diversified and different types of watermills were introduced. These include all three variants of the vertical water wheel as well as the horizontal water wheel. Apart from its main use in grinding flour, water-power was also applied to pounding grain, crushing ore, sawing stones and possibly fulling and bellows for iron furnaces.\nDecorative structures.\nMonoliths.\nIn architecture, a monolith is a structure which has been excavated as a unit from a surrounding matrix or outcropping of rock. Monoliths are found in all types of Roman buildings. They were either: quarried without being moved; or quarried and moved; or quarried, moved and lifted clear off the ground into their position (e.g., architraves); or quarried, moved and erected in an upright position (e.g., columns).\nTransporting was done by land or water (or a combination of both), in the later case often by special-built ships such as obelisk carriers. For lifting operations, ancient cranes were employed since c. 515 BC, such as in the construction of Trajan's Column.\nObelisks.\nAn obelisk is a tall, four-sided, narrow tapering monument which ends in a pyramid-like shape at the top. These were originally called \"tekhenu\" by the builders, the ancient Egyptians. The Greeks who saw them used the Greek 'obeliskos' to describe them, and this word passed into Latin and then English. The Romans commissioned obelisks in an ancient Egyptian style. Examples include:\nRoman gardens.\nRoman gardens were influenced by Egyptian, Persian, and Greek gardening techniques. In Ancient Latium, a garden was part of every farm. According to Cato the Elder, every garden should be close to the house and should have flower beds and ornamental trees. Horace wrote that during his time flower gardens became a national indulgence.\nGardens were not reserved for the extremely wealthy. Excavations in Pompeii show that gardens attaching to residences were scaled down to meet the space constraints of the home of the average Roman. Modified versions of Roman garden designs were adopted in Roman settlements in Africa, Gaul, and Britannia. As town houses were replaced by tall \"insulae\" (apartment buildings), these urban gardens were replaced by window boxes or roof gardens.\nTriumphal arches.\nA triumphal arch is a monumental structure in the shape of an archway with one or more arched passageways, often designed to span a road. The origins of the Roman triumphal arch are unclear, other than in the temporary structures, whose appearance is unknown, erected for Roman triumphs under the Roman Republic, and later. There were precursors to the permanent triumphal arch within the Roman world; in Italy, the Etruscans used elaborately decorated single bay arches as gates or portals to their cities. Surviving examples of Etruscan arches can still be seen at Perugia and Volterra. The two key elements of the triumphal arch \u2013 a round-topped arch and a square entablature \u2013 had long been in use as separate architectural elements in ancient Greece.\nThe innovation of the Romans was to use these elements in a single free-standing structure. The columns became purely decorative elements on the outer face of the arch, while the entablature, liberated from its role as a building support, became the frame for the civic and religious messages that the arch builders wished to convey. Little is known about how the Romans viewed triumphal arches. Pliny the Elder, writing in the first century AD, was the only ancient author to discuss them. He wrote that they were intended to \"elevate above the ordinary world\" an image of an honoured person usually depicted in the form of a statue with a quadriga.\nThe first recorded Roman triumphal arches were set up in the time of the Roman Republic. Generals who were granted a triumph were termed \"triumphators\" and would erect \"fornices\" or honorific arches bearing statues to commemorate their victories.\nRoman triumphal practices changed significantly at the start of the Imperial period, when the first Roman Emperor Augustus decreed that only emperors would be granted triumphs. The triumphal arch changed from being a personal monument to being an essentially propagandistic one, serving to announce and promote the presence of the ruler and the laws of the state. Arches were not necessarily built as entrances, but \u2013 unlike many modern triumphal arches \u2013 they were often erected across roads and were intended to be passed through, not round.\nMost Roman triumphal arches were built during the Imperial period. By the fourth century AD there were 36 such arches in Rome, of which three have survived \u2013 the Arch of Titus (AD 81), the Arch of Septimius Severus (203\u2013205) and the Arch of Constantine (312). Numerous arches were built elsewhere in the Roman Empire. The single arch was the most common, but many triple arches were also built, of which the Triumphal Arch of Orange (c. AD 21) is the earliest surviving example. From the 2nd century AD, many examples of the \"arcus quadrifrons\" \u2013 a square triumphal arch erected over a crossroads, with arched openings on all four sides \u2013 were built, especially in North Africa. Arch-building in Rome and Italy diminished after the time of Trajan (AD 98\u2013117) but remained widespread in the provinces during the 2nd and 3rd centuries AD; they were often erected to commemorate imperial visits.\nThe ornamentation of an arch was intended to serve as a constant visual reminder of the triumph and \"triumphator\". The fa\u00e7ade was ornamented with marble columns, and the piers and attics with decorative cornices. Sculpted panels depicted victories and achievements, the deeds of the \"triumphator\", the captured weapons of the enemy or the triumphal procession itself. The spandrels usually depicted flying Victories, while the attic was often inscribed with a dedicatory inscription naming and praising the \"triumphator\". The piers and internal passageways were also decorated with reliefs and free-standing sculptures. The vault was ornamented with coffers. Some triumphal arches were surmounted by a statue or a \"currus triumphalis\", a group of statues depicting the emperor or general in a quadriga.\nInscriptions on Roman triumphal arches were works of art in themselves, with very finely cut, sometimes gilded letters. The form of each letter and the spacing between them was carefully designed for maximum clarity and simplicity, without any decorative flourishes, emphasizing the Roman taste for restraint and order. This conception of what later became the art of typography remains of fundamental importance to the present day.\nInfrastructure.\nRoads.\nRoman roads were vital to the maintenance and development of the Roman state, and were built from about 500 BC through the expansion and consolidation of the Roman Republic and the Roman Empire. They provided efficient means for the overland movement of armies, officials and civilians, and the inland carriage of official communications and trade goods. At the peak of Rome's development, no fewer than 29 great military highways radiated from the capital, and the Late Empire's 113 provinces were interconnected by 372 great road links.\nRoman road builders aimed at a regulation width (see Laws and standards above), but actual widths have been measured at between and more than . Today, the concrete has worn from the spaces around the stones, giving the impression of a very bumpy road, but the original practice was to produce a surface that was much closer to being flat.\nAqueduct.\nThe Romans constructed numerous aqueducts in order to bring water from distant sources into their cities and towns, supplying public baths, latrines, fountains and private households. Waste water was removed by complex sewage systems and released into nearby bodies of water, keeping the towns clean and free from effluent. Aqueducts also provided water for mining operations, milling, farms and gardens.\nAqueducts moved water through gravity alone, being constructed along a slight downward gradient within conduits of stone, brick or concrete. Most were buried beneath the ground, and followed its contours; obstructing peaks were circumvented or, less often, tunnelled through. Where valleys or lowlands intervened, the conduit was carried on bridgework, or its contents fed into high-pressure lead, ceramic or stone pipes and siphoned across. Most aqueduct systems included sedimentation tanks, sluices and distribution tanks to regulate the supply as needed.\nAncient Rome's first aqueduct \u2013 the Aqua Appia \u2013 supplied a water-fountain sited at the city's cattle market in the fourth century BC. By the third century AD, the city had eleven aqueducts, sustaining a population of over a million people in a water-extravagant economy; most of the water supplied the city's many public baths. Cities and municipalities throughout the Roman Empire emulated this model and funded aqueducts as objects of public interest and civic pride, \"an expensive yet necessary luxury to which all could, and did, aspire.\"\nMost Roman aqueducts proved reliable, and durable; some were maintained into the early modern era, and a few are still partly in use. Methods of aqueduct surveying and construction are noted by Vitruvius in his work \"De architectura\" (1st century BC). The general Frontinus gives more detail in his official report on the problems, uses and abuses of Imperial Rome's public water supply. Notable examples of aqueduct architecture include the supporting piers of the Aqueduct of Segovia, and the aqueduct-fed cisterns of Constantinople.\nBridges.\nRoman bridges, built by ancient Romans, were the first large and lasting bridges built. Roman bridges were built with stone and had the arch as the basic structure. Most used concrete as well, which the Romans were the first to use for bridges.\nRoman arch bridges were usually semicircular, although a few were segmental (such as Alcon\u00e9tar Bridge). A segmental arch is an arch that is less than a semicircle. The advantages of the segmental arch bridge were that it allowed great amounts of flood water to pass under it, which would prevent the bridge from being swept away during floods and the bridge itself could be more lightweight. Generally, Roman bridges featured wedge-shaped primary arch stones (voussoirs) of the same in size and shape. The Romans built both single spans and lengthy multiple arch aqueducts, such as the Pont du Gard and Segovia Aqueduct. Their bridges featured from an early time onwards flood openings in the piers, e.g. in the Pons Fabricius in Rome (62 BC), one of the world's oldest major bridges still standing. Roman engineers were the first and until the Industrial Revolution the only ones to construct bridges with concrete, which they called \"opus caementicium\". The outside was usually covered with brick or ashlar, as in the Alc\u00e1ntara bridge.\nThe Romans also introduced segmental arch bridges into bridge construction. The 330\u00a0m long Limyra Bridge in southwestern Turkey features 26 segmental arches with an average span-to-rise ratio of 5.3:1, giving the bridge an unusually flat profile unsurpassed for more than a millennium. Trajan's bridge over the Danube featured open-spandrel segmental arches made of wood (standing on 40\u00a0m high concrete piers). This was to be the longest arch bridge for a thousand years both in terms of overall and individual span length, while the longest extant Roman bridge is the 790\u00a0m long Puente Romano at M\u00e9rida.\nCanals.\nRoman canals were typically multi-purpose structures, intended for irrigation, drainage, land reclamation, flood control and navigation where feasible. Some navigational canals were recorded by ancient geographers and are still traceable by modern archaeology. Channels which served the needs of urban water supply are covered at the List of aqueducts in the Roman Empire.\nCisterns.\nFreshwater reservoirs were commonly set up at the termini of aqueducts and their branch lines, supplying urban households, agricultural estates, imperial palaces, \"thermae\" or naval bases of the Roman navy.\nDams.\nRoman dam construction began in earnest in the early imperial period. For the most part, it concentrated on the semi-arid fringe of the empire, namely the provinces of North Africa, the Near East, and Hispania. The relative abundance of Spanish dams below is due partly to more intensive field work there; for Italy only the Subiaco Dams, created by emperor Nero (54\u201368 AD) for recreational purposes, are attested. These dams are noteworthy, though, for their extraordinary height, which remained unsurpassed anywhere in the world until the Late Middle Ages.\nThe most frequent dam types were earth- or rock-filled embankment dams and masonry gravity dams. These served a wide array of purposes, such as irrigation, flood control, river diversion, soil-retention, or a combination of these functions. The impermeability of Roman dams was increased by the introduction of waterproof hydraulic mortar and especially \"opus caementicium\" in the Concrete Revolution. These materials also allowed for bigger structures to be built, like the Lake Homs Dam, possibly the largest water barrier today, and the sturdy Harbaqa Dam, both of which consist of a concrete core.\nRoman builders were the first to realize the stabilizing effect of arches and buttresses, which they integrated into their dam designs. Previously unknown dam types introduced by the Romans include arch-gravity dams, arch dams, buttress dams, and multiple-arch buttress dams.\nDefensive walls.\nThe Romans generally fortified cities rather than fortresses, but there are some fortified camps such as the Saxon Shore forts like Porchester Castle in England. City walls were already significant in Etruscan architecture, and in the struggle for control of Italy under the early Republic many more were built, using different techniques. These included tightly fitting massive irregular polygonal blocks, shaped to fit exactly in a way reminiscent of later Inca work. The Romans called a simple rampart wall an agger; at this date great height was not necessary. The Servian Wall around Rome was an ambitious project of the early 4th century BC. The wall was up to in height in places, wide at its base, long, and is believed to have had 16 main gates, though many of these are mentioned only from writings, with no other known remains. Some of it had a \"fossa\" or ditch in front, and an agger behind, and it was enough to deter Hannibal. Later the Aurelian Wall replaced it, enclosing an expanded city, and using more sophisticated designs, with small forts at intervals.\nThe Romans walled major cities and towns in areas they saw as vulnerable, and parts of many walls remain incorporated in later defensive fortifications, as at C\u00f3rdoba (2nd century BC), Chester (earth and wood in the 70s AD, stone from c.\u2009100), and York (from 70s AD). Strategic walls across open country were far rarer, and Hadrian's Wall (from 122) and the Antonine Wall (from 142, abandoned only 8 years after completion) are the most significant examples, both on the Pictish frontier of Roman Britain.\nArchitectural features.\nMosaics.\nOn his return from campaigns in Greece, the general Sulla brought back what is probably the best-known element of the early imperial period: the mosaic, a decoration made of colourful chips of stone inserted into cement. This tiling method took the empire by storm in the late first century and the second century and in the Roman home joined the well-known mural in decorating floors, walls, and grottoes with geometric and pictorial designs.\nThere were two main techniques in Greco-Roman mosaic. \"Opus vermiculatum\" used tiny \"tesserae\", typically cubes of 4 millimeters or less, and was produced in workshops in relatively small panels, which were transported to the site glued to some temporary support. The tiny \"tesserae\" allowed very fine detail and an approach to the illusionism of painting. Often small panels called \"emblemata\" were inserted into walls or as the highlights of larger floor-mosaics in coarser work. The normal technique, however, was \"opus tessellatum\", using larger tesserae, which were laid on site. There was a distinct native Italian style using black on a white background, which was no doubt cheaper than fully coloured work.\nA specific genre of Roman mosaic obtained the name \"asaroton\" (Greek \"unswept floor\"). It represented an optical illusion of the leftovers from a feast on the floor of rich houses.\nHypocaust.\nA hypocaust was an ancient Roman system of underfloor heating, used to heat buildings with hot air. The Roman architect Vitruvius, writing about the end of the 1st century BC, attributes their invention to Sergius Orata. Many remains of Roman hypocausts have survived throughout Europe, western Asia, and northern Africa. The hypocaust was an invention which improved the hygiene and living conditions of citizens, and was a forerunner of modern central heating.\nHypocausts were used for heating hot baths (\"thermae\"), houses and other buildings, whether public or private. The floor was raised above the ground by pillars, called pilae stacks, with a layer of tiles, then a layer of concrete, then another of tiles on top; and spaces were left inside the walls so that hot air and smoke from the furnace would pass through these enclosed areas and out of flues in the roof, thereby heating but not polluting the interior of the room.\nRoman roofs.\nIn Magna Graecia truss roofs presumably appeared as early as 550 BC. Their potential was fully realized in the Roman period, which saw trussed roofs over 30 meters wide spanning the rectangular spaces of monumental public buildings such as temples, basilicas, and later churches. Such spans were three times as wide as the widest prop-and-lintel roofs and only surpassed by the largest Roman domes.\nThe largest truss roof by span of ancient Rome covered the Aula Regia (throne room) built for emperor Domitian (81\u201396\u00a0AD) on the Palatine Hill, Rome. The timber truss roof had a width of 31.67\u00a0m, slightly surpassing the postulated limit of 30\u00a0m for Roman roof constructions. Tie-beam trusses allowed for much larger spans than the older prop-and-lintel system and even concrete vaulting. Nine out of the ten largest rectangular spaces in Roman architecture were bridged this way, the only exception being the groin vaulted Basilica of Maxentius.\nSpiral stairs.\nThe spiral stair is a type of stairway which, due to its complex helical structure, was introduced relatively late into architecture. Although the oldest example dates to the 5th century BC, it was only in the wake of the influential design of Trajan's Column that this space-saving new type permanently caught hold in Roman architecture.\nApart from the triumphal columns in the imperial cities of Rome and Constantinople, other types of buildings such as temples, thermae, basilicas and tombs were also fitted with spiral stairways. Their notable absence in the towers of the Aurelian Wall indicates that although used in medieval castles, they did not yet figure prominently in Roman military engineering. By late antiquity, separate stair towers were constructed adjacent to the main buildings, as in the Basilica of San Vitale.\nThe construction of spiral stairs passed on both to Christian and Islamic architecture.\nCity design.\nThe ancient Romans employed regular orthogonal structures on which they molded their colonies. They probably were inspired by Greek and Hellenic examples, as well as by regularly planned cities that were built by the Etruscans in Italy. (see Marzabotto)\nThe Romans used a consolidated scheme for city planning, developed for military defense and civil convenience. The basic plan consisted of a central forum with city services, surrounded by a compact, rectilinear grid of streets, and wrapped in a wall for defense. To reduce travel times, two diagonal streets crossed the square grid, passing through the central square. A river usually flowed through the city, providing water, transport, and sewage disposal. Hundreds of towns and cities were built by the Romans throughout their Empire.\nMany European towns, such as Turin, preserve the remains of these schemes, which show the very logical way the Romans designed their cities. They would lay out the streets at right angles, in the form of a square grid. All roads were equal in width and length, except for two, which were slightly wider than the others. One of these ran east\u2013west, the other, north\u2013south, and they intersected in the middle to form the center of the grid. All roads were made of carefully fitted flagstones and filled in with smaller, hard-packed rocks and pebbles. Bridges were constructed where needed. Each square marked off by four roads was called an \"insula,\" the Roman equivalent of a modern city block. \nEach \"insula\" was square, with the land within it divided. As the city developed, each \"insula\" would eventually be filled with buildings of various shapes and sizes and crisscrossed with back roads and alleys. Most \"insulae\" were given to the first settlers of a Roman city, but each person had to pay to construct his own house.\nThe city was surrounded by a wall to protect it from invaders and to mark the city limits. Areas outside city limits were left open as farmland. At the end of each main road was a large gateway with watchtowers. A portcullis covered the opening when the city was under siege, and additional watchtowers were constructed along the city walls. An aqueduct was built outside the city walls.\nThe development of Greek and Roman urbanization is well-known, as there are relatively many written sources, and there has been much attention to the subject, since the Romans and Greeks are generally regarded as the main ancestors of modern Western culture. It should not be forgotten, though, that the Etruscans had many considerable towns and there were also other cultures with more or less urban settlements in Europe, primarily of Celtic origin.\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52686", "revid": "19158033", "url": "https://en.wikipedia.org/wiki?curid=52686", "title": "Romanesque architecture", "text": "Architectural style of Medieval Europe\nRomanesque architecture is an architectural style of medieval Europe that was predominant in the 11th and 12th centuries. The style eventually developed into the Gothic style with the shape of the arches providing a simple distinction: the Romanesque is characterized by semicircular arches, while the Gothic is marked by the pointed arches. The Romanesque emerged nearly simultaneously in multiple countries of Western Europe; its examples can be found across the continent, making it the first pan-European architectural style since Imperial Roman architecture. Similarly to Gothic, the name of the style was transferred onto the contemporary Romanesque art.\nCombining features of ancient Roman and Byzantine buildings and other local traditions, Romanesque architecture is known by its massive quality, thick walls, round arches, sturdy pillars, barrel vaults, large towers and decorative arcading. Each building has clearly defined forms, frequently of very regular, symmetrical plan. The overall appearance is one of simplicity when compared with the Gothic buildings that were to follow. The style can be identified right across Europe, despite regional characteristics and different materials.\nMany castles were built during this period, but they are greatly outnumbered by churches. The most significant are the great abbey churches, many of which are still standing, more or less complete and frequently in use. The enormous quantity of churches built in the Romanesque period was succeeded by the still busier period of Gothic architecture, which partly or entirely rebuilt most Romanesque churches in prosperous areas like England and Portugal. The largest groups of Romanesque survivors are in areas that were less prosperous in subsequent periods, including parts of southern France, rural Spain, rural Portugal and rural Italy. Survivals of unfortified Romanesque secular houses and palaces, and the domestic quarters of monasteries are far rarer, but these used and adapted the features found in church buildings, on a domestic scale.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nDefinition.\nThe French term \"\" or the English \"Romanesque\", meaning \"in the manner of Romans\", has been used to describe the architectural style of the Mediaeval era, preceding the more easily recognizable Gothic architecture, since early in the 19th century. It describes the architectural style which flourished across Europe from the 11th to the 13th century, and is distinguished from the Gothic style that followed by semi-circular arches and more massive forms. The development of vaults from barrel and groin vaults to ribbed vaults was the main structural innovation of this period. \nUse of the term \"Romanesque\".\nThe distinction between the style of architecture now known as Romanesque and the succeeding style of Gothic architecture was recognised as early as the 15th century, as demonstrated by some artworks of that period. Robert Campin clearly presented the division in his \"Marriage of the Virgin\"; on the left side, representing the Old Testament, the building is in the Romanesque style, while that on the right, representing the New Testament, is Gothic. Until the 19th century, however, the style preceding Gothic was not recognized as a whole, and was instead, just like Gothic at the time, treated as a multitude of styles: Giorgio Vasari and Christopher Wren were writing about \"Tuscan\", \"Saxon\", or \"Norman\" architectures.\nThe word \"Romanesque\" (\"in the manner of Romans\") appeared in English by 1666, and was used to designate what are now called Romance languages. Definition of \"Romanesque architecture\" changed over time; the development of the modern English meaning of the word involved primarily two steps: \nThe French term \"\" was first used in the architectural sense by archaeologist Charles de Gerville in a letter of 18 December 1818 to Auguste Le Pr\u00e9vost to describe what Gerville sees as a \"debased Roman architecture\". In an 1823 public lecture (published in 1824) Gerville's friend Arcisse de Caumont adopted the label \"\" to describe the \"degraded\" European architecture from the 5th to the 13th centuries, in his \"Essai sur l'architecture religieuse du moyen-\u00e2ge, particuli\u00e8rement en Normandie\", at a time when the actual dates of many of the buildings so described had not been ascertained:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"The name Roman (esque) we give to this architecture, which should be universal as it is the same everywhere with slight local differences, also has the merit of indicating its origin and is not new since it is used already to describe the language of the same period. Romance language is degenerated Latin language. Romanesque architecture is debased Roman architecture.\"\nThe term \"Pre-romanesque\" is sometimes applied to architecture in Germany of the Carolingian and Ottonian periods and Visigothic, Mozarab and Asturian constructions between the 8th and the 10th centuries in the Iberian Peninsula while \"First Romanesque\" is applied to buildings in north of Italy and Spain and parts of France that have Romanesque features but pre-date the influence of the Abbey of Cluny. The Romanesque style in England and Sicily is still referred to as Norman architecture. A \"dazzling\" style developed in Pisa in the mid-11th century is called \"Pisan Romanesque\".\nEric Fernie writes that by the beginning of the 21st century there is \"something like agreement\" on the characteristics of the Romanesque style. Some researchers argue that due to an \"astonishing diversity\" of the Romanesque buildings, a unanimous definition is impossible: \"[n]o single model, no single rule, ever seems adequate to prevail\", and the Romanesque should be treated as a \"collection of trends\". Despite disagreement, the term became a \"common currency\", and is universally accepted at least for convenience.\nScope.\nBuildings of every type were constructed in the Romanesque style, with evidence remaining of simple domestic buildings, elegant town houses, grand palaces, commercial premises, civic buildings, castles, city walls, bridges, village churches, abbey churches, abbey complexes and large cathedrals. Of these types of buildings, domestic and commercial buildings are the most rare, with only a handful of survivors in the United Kingdom, several clusters in France, isolated buildings across Europe and by far the largest number, often unidentified and altered over the centuries, in Italy. Many castles exist, the foundations of which date from the Romanesque period. Most have been substantially altered, and many are in ruins.\nBy far the greatest number of surviving Romanesque buildings are churches. These range from tiny chapels to large cathedrals. Although many have been extended and altered in different styles, a large number remain either substantially intact or sympathetically restored, demonstrating the form, character and decoration of Romanesque church architecture.\nHistory.\nOrigins.\nRomanesque architecture was the first distinctive style to spread across Europe since the Roman Empire. With the decline of Rome, Roman building methods survived to an extent in Western Europe, where successive Merovingian, Carolingian and Ottonian architects continued to build large stone buildings such as monastery churches and palaces. In the more northern countries, Roman building styles and techniques had never been adopted except for official buildings, while in Scandinavia they were unknown. Although the round arch continued in use, the engineering skills required to vault large spaces and build large domes were lost. There was a loss of stylistic continuity, particularly apparent in the decline of the formal vocabulary of the Classical Orders. \nIn Rome several great Constantinian basilicas continued in use as an inspiration to later builders. Some traditions of Roman architecture also survived in Byzantine architecture with the 6th-century octagonal Byzantine Basilica of San Vitale in Ravenna being the inspiration for the greatest building of the Early Middle Ages in Europe, the Emperor Charlemagne's Palatine Chapel, Aachen, Germany, built around the year AD 800.\nDating shortly after the Palatine Chapel is a remarkable 9th-century Swiss manuscript known as the Plan of Saint Gall and showing a very detailed plan of a monastic complex, with all its various monastic buildings and their functions labelled. The largest building is the church, the plan of which is distinctly Germanic, having an apse at both ends, an arrangement not generally seen elsewhere. Another feature of the church is its regular proportion, the square plan of the crossing tower providing a module for the rest of the plan. These features can both be seen at the Proto-Romanesque St. Michael's Church, Hildesheim, 1001\u20131030.\nArchitecture of a Romanesque style also developed simultaneously in the north of Italy, parts of France and in the Iberian Peninsula in the 10th century and prior to the later influence of the Abbey of Cluny. The style, sometimes called First Romanesque or Lombard Romanesque, is characterised by thick walls, lack of sculpture and the presence of rhythmic ornamental arches known as a Lombard band.\nPolitics.\nCharlemagne was crowned by Pope Leo III in Old St. Peter's Basilica on Christmas Day of 800, with an aim to re-establishing the old Roman Empire. Charlemagne's political successors continued to rule much of Europe, with a gradual emergence of the separate political states that were eventually to become welded into nations, either by allegiance or defeat, into the Kingdom of Germany giving rise to the Holy Roman Empire. The invasion of England by William, Duke of Normandy, in 1066, saw the building of both castles and churches that reinforced the Norman presence. Several significant churches that were built at this time were founded by rulers as seats of temporal and religious power, or places of coronation and burial. These include the Abbaye-Saint-Denis, Speyer Cathedral and Westminster Abbey (where little of the Pre-Conquest church now remains).\nAt a time when the remaining architectural structures of the Roman Empire were falling into decay and much of its learning and technology lost, the building of masonry domes and the carving of decorative architectural details continued unabated, though greatly evolved in style since the fall of Rome, in the enduring Byzantine Empire. The domed churches of Constantinople and Eastern Europe were to greatly affect the architecture of certain towns, particularly through trade and through the Crusades. The most notable single building that demonstrates this is St Mark's Basilica, Venice, but there are many lesser-known examples, particularly in France, such as the church of Saint-Front, P\u00e9rigueux and Angoul\u00eame Cathedral.\nMuch of Europe was affected by feudalism in which peasants held tenure from local rulers over the land that they farmed in exchange for military service. The result of this was that they could be called upon, not only for local and regional spats, but to follow their lord to travel across Europe to the Crusades, if they were required to do so. The Crusades, 1095\u20131270, brought about a very large movement of people and, with them, ideas and trade skills, particularly those involved in the building of fortifications and the metal working needed for the provision of arms, which was also applied to the fitting and decoration of buildings. The continual movement of people, rulers, nobles, bishops, abbots, craftsmen and peasants, was an important factor in creating a homogeneity in building methods and a recognizable \"Romanesque style\", despite regional differences.\nLife became generally less secure after the Carolingian period. This resulted in the building of castles at strategic points, many of them being constructed as strongholds of the Normans, descendants of the Vikings who invaded northern France under Rollo in 911. Political struggles also resulted in the fortification of many towns, or the rebuilding and strengthening of walls that remained from the Roman period. One of the most notable surviving fortifications is that of the city of Carcassonne. The enclosure of towns brought about a lack of living space within the walls, and resulted in a style of town house that was tall and narrow, often surrounding communal courtyards, as at San Gimignano in Tuscany and Bologna and Pavia in Lombardy.\nIn Germany, the Holy Roman Emperors built a number of residences, fortified, but essentially palaces rather than castles, at strategic points and on trade routes. The Imperial Palace of Goslar (heavily restored in the 19th century) was built in the early 11th century by Otto III and Henry III, while the ruined Palace at Gelnhausen was received by Frederick Barbarossa prior to 1170. The movement of people and armies also brought about the building of bridges, some of which have survived, including the 12th-century bridge at Besal\u00fa, Catalonia, the 11th-century Puente de la Reina, Navarre and the Pont-Saint-B\u00e9n\u00e9zet, Avignon.\nReligion.\nAcross Europe, the late 11th and 12th centuries saw an unprecedented growth in the number of churches. A great number of these buildings, both large and small, remain, some almost intact and in others altered almost beyond recognition in later centuries. They include many very well known churches such as Santa Maria in Cosmedin in Rome, the Baptistery in Florence and San Zeno Maggiore in Verona. In France, the famous abbeys of Aux Dames and Les Hommes at Caen and Mont Saint-Michel date from this period, as well as the abbeys of the pilgrimage route to Santiago de Compostela. Many cathedrals owe their foundation to this date, with others beginning as abbey churches, and later becoming cathedrals. \nIn England, of the cathedrals of ancient foundation, all were begun in this period with the exception of Salisbury, where the monks relocated from the Norman church at Old Sarum, and several, such as Canterbury, which were rebuilt on the site of Saxon churches. In Spain, the most famous church of the period is Santiago de Compostela. In Germany, the Rhine and its tributaries were the location of many Romanesque abbeys, notably Mainz, Worms, Speyer and Bamberg. In Cologne, then the largest city north of the Alps, a very important group of large city churches survived largely intact. As monasticism spread across Europe, Romanesque churches sprang up in Scotland, Scandinavia, Poland, Hungary, Sicily, Serbia and Tunisia. Several important Romanesque churches were built in the Crusader kingdoms.\nMonasticism.\nThe system of monasticism in which the religious become members of an order, with common ties and a common rule, living in a mutually dependent community, rather than as a group of hermits living in proximity but essentially separate, was established by the monk Benedict in the 6th century. The Benedictine monasteries spread from Italy throughout Europe, being always by far the most numerous in England. They were followed by the Cluniac order, the Cistercians, Carthusians and Augustinian Canons. During the Crusades, the military orders of the Knights Hospitaller and the Knights Templar were founded.\nThe monasteries, which sometimes also functioned as cathedrals, and the cathedrals that had bodies of secular clergy often living in community, were a major source of power in Europe. Bishops and the abbots of important monasteries lived and functioned like princes. The monasteries were the major seats of learning of all sorts. Benedict had ordered that all the arts were to be taught and practiced in the monasteries. Within the monasteries books were transcribed by hand, and few people outside the monasteries could read or write.\nIn France, Burgundy was the centre of monasticism. The enormous and powerful monastery at Cluny was to have lasting effect on the layout of other monasteries and the design of their churches. Very little of the abbey church at Cluny remains; the \"Cluny II\" rebuilding of 963 onwards has completely vanished, but we have a good idea of the design of \"Cluny III\" from 1088 to 1130, which until the Renaissance remained the largest building in Europe. However, the church of St. Sernin at Toulouse, 1080\u20131120, has remained intact and demonstrates the regularity of Romanesque design with its modular form, its massive appearance and the repetition of the simple arched window motif.\nPilgrimage and Crusade.\nOne of the effects of the Crusades, which were intended to wrest the Holy Places of the Levant from Islamic control, was to excite a great deal of religious fervour, which in turn inspired great building programs. The Nobility of Europe, upon safe return, thanked God by the building of a new church or the enhancement of an old one. Likewise, those who did not return from the Crusades could be suitably commemorated by their family in a work of stone and mortar.\nThe Crusades resulted in the transfer of, among other things, a great number of Holy Relics of saints and apostles. Many churches, like Saint-Front, P\u00e9rigueux, had their own home grown saint while others, most notably Santiago de Compostela, claimed the remains and the patronage of a powerful saint, in this case one of the Twelve Apostles. Santiago de Compostela, located in the Kingdom of Galicia (present day Galicia, Spain) became one of the most important pilgrimage destinations in Europe. Most of the pilgrims travelled the Way of St. James on foot, many of them barefooted as a sign of penance. They moved along one of the four main routes that passed through France, congregating for the journey at Jumi\u00e8ges, Paris, V\u00e9zelay, Cluny, Arles and St. Gall in Switzerland. They crossed two passes in the Pyrenees and converged into a single stream to traverse north-western Spain. Along the route they were urged on by those pilgrims returning from the journey. On each of the routes abbeys such as those at Moissac, Toulouse, Roncesvalles, Conques, Limoges and Burgos catered for the flow of people and grew wealthy from the passing trade. Saint-Beno\u00eet-du-Sault, in the Berry province, is typical of the churches that were founded on the pilgrim route.\nCharacteristics.\nThe general impression given by Romanesque architecture, in both ecclesiastical and secular buildings, is one of massive solidity and strength. In contrast with both the preceding Roman and later Gothic architecture, in which the load-bearing structural members are, or appear to be, columns, pilasters and arches, Romanesque architecture, in common with Byzantine architecture, relies upon its walls, or sections of walls called piers.\nRomanesque architecture is often divided into two periods known as the \"First Romanesque\" style and the \"Romanesque\" style. The difference is chiefly a matter of the expertise with which the buildings were constructed. The First Romanesque employed rubble walls, smaller windows and unvaulted roofs. A greater refinement marks the Second Romanesque, along with increased use of the vault and dressed stone.\nWalls.\nThe walls of Romanesque buildings are often of massive thickness with few and comparatively small openings. They are often double shells, filled with rubble.\nThe building material differs greatly across Europe, depending upon the local stone and building traditions. In Italy, Poland, much of Germany and parts of the Netherlands, brick is generally used. Other areas saw extensive use of limestone, granite and flint. The building stone was often used in comparatively small and irregular pieces, bedded in thick mortar. Smooth ashlar masonry was not a distinguishing feature of the style (especially not in the earlier part of the period), but it did occur, chiefly where easily worked limestone was available.\nButtresses.\nBecause of the massive nature of Romanesque walls, buttresses are not a highly significant feature, as they are in Gothic architecture. Romanesque buttresses are generally of flat square profile and do not project a great deal beyond the wall. In the case of aisled churches, barrel vaults, or half-barrel vaults over the aisles helped to buttress the nave, if it was vaulted.\nIn the cases where half-barrel vaults were used, they effectively became like flying buttresses. Often aisles extended through two storeys, rather than the one usual in Gothic architecture, so as to better support the weight of a vaulted nave. In the case of Durham Cathedral, flying buttresses have been employed, but are hidden inside the triforium gallery.\nArches and openings.\nThe arches used in Romanesque architecture are nearly always semicircular, for openings such as doors and windows, for vaults and for arcades. Wide doorways are usually surmounted by a semi-circular arch, except where a door with a lintel is set into a large arched recess and surmounted by a semi-circular \"lunette\" with decorative carving. These doors sometimes have a carved central jamb.\nNarrow doors and small windows might be surmounted by a solid stone lintel. Larger openings are nearly always arched. A characteristic feature of Romanesque architecture, both ecclesiastic and domestic, is the pairing of two arched windows or arcade openings, separated by a pillar or colonette and often set within a larger arch. Ocular windows are common in Italy, particularly in the fa\u00e7ade gable and are also seen in Germany. Later Romanesque churches may have wheel windows or rose windows with plate tracery.\nThere are a very small number of buildings in the Romanesque style, such as Autun Cathedral in France and Monreale Cathedral in Sicily in which pointed arches have been used extensively, apparently for stylistic reasons. It is believed that in these cases there is a direct imitation of Islamic architecture. At other late Romanesque churches such as Durham Cathedral, and Cefal\u00f9 Cathedral, the pointed arch was introduced as a structural device in ribbed vaulting. Its increasing application was fundamental to the development of Gothic architecture.\nArcades.\nAn arcade is a row of arches, supported on piers or columns. They occur in the interior of large churches, separating the nave from the aisles, and in large secular interiors spaces, such as the great hall of a castle, supporting the timbers of a roof or upper floor. Arcades also occur in cloisters and atriums, enclosing an open space.\nArcades can occur in storeys or stages. While the arcade of a cloister is typically of a single stage, the arcade that divides the nave and aisles in a church is typically of two stages, with a third stage of window openings known as the clerestory rising above them. Arcading on a large scale generally fulfils a structural purpose, but it is also used, generally on a smaller scale, as a decorative feature, both internally and externally where it is frequently \"blind arcading\" with only a wall or a narrow passage behind it.\nPiers.\nIn Romanesque architecture, piers were often employed to support arches. They were built of masonry and square or rectangular in section, generally having a horizontal moulding representing a capital at the springing of the arch. Sometimes piers have vertical shafts attached to them, and may also have horizontal mouldings at the level of the base.\nAlthough basically rectangular, piers can often be of highly complex form, with half-segments of large hollow-core columns on the inner surface supporting the arch, or a clustered group of smaller shafts leading into the mouldings of the arch.\nPiers that occur at the intersection of two large arches, such as those under the crossing of the nave and transept, are commonly cruciform in shape, each arch having its own supporting rectangular pier at right angles to the other.\nColumns.\nColumns are an important structural feature of Romanesque architecture. Colonnettes and attached shafts are also used structurally and for decoration. Monolithic columns cut from a single piece of stone were frequently used in Italy, as they had been in Roman and Early Christian architecture. They were also used, particularly in Germany, when they alternated between more massive piers. Arcades of columns cut from single pieces are also common in structures that do not bear massive weights of masonry, such as cloisters, where they are sometimes paired.\nSalvaged columns.\nIn Italy, during this period, a great number of antique Roman columns were salvaged and reused in the interiors and on the porticos of churches. The most durable of these columns are of marble and have the stone horizontally bedded. The majority are vertically bedded and are sometimes of a variety of colours. They may have retained their original Roman capitals, generally of the Corinthian or Roman Composite style.\nSome buildings, like Santa Maria in Cosmedin and the atrium at San Clemente in Rome, may have an odd assortment of columns in which large capitals are placed on short columns and small capitals are placed on taller columns to even the height. Architectural compromises of this type are seen where materials have been salvaged from a number of buildings. Salvaged columns were also used to a lesser extent in France.\nDrum columns.\nIn most parts of Europe, Romanesque columns were massive, as they supported thick upper walls with small windows, and sometimes heavy vaults. The most common method of construction was to build them out of stone cylinders called drums, as in the crypt at Speyer Cathedral.\nHollow core columns.\nWhere really massive columns were called for, such as those at Durham Cathedral, they were constructed of ashlar masonry and the hollow core was filled with rubble. These huge untapered columns are sometimes ornamented with incised decorations.\nAlternating supports.\nA common characteristic of Romanesque buildings, occurring both in churches and in the arcades that separate large interior spaces of castles, is the alternation of piers and columns.\nThe most simple form that this takes is to have a column between each adjoining pier. Sometimes the columns are in multiples of two or three. At St. Michael's, Hildesheim, an A B B A alternation occurs in the nave while an A B A alternation can be seen in the transepts.\nAt Jumi\u00e8ges there are tall drum columns between piers each of which has a half-column supporting the arch. There are many variations on this theme, most notably at Durham Cathedral where the mouldings and shafts of the piers are of exceptional richness and the huge masonry columns are deeply incised with geometric patterns.\nOften the arrangement was made more complex by the complexity of the piers themselves, so that it was not piers and columns that alternated, but rather, piers of entirely different form from each other, such as those of Sant' Ambrogio, Milan, where the nature of the vault dictated that the alternate piers bore a great deal more weight than the intermediate ones and are thus very much larger.\nCapitals.\nThe foliate Corinthian style provided the inspiration for many Romanesque capitals, and the accuracy with which they were carved depended very much on the availability of original models, those in Italian churches such as Pisa Cathedral or church of Sant'Alessandro in Lucca and southern France being much closer to the Classical than those in England.\nThe Corinthian capital is essentially round at the bottom where it sits on a circular column and square at the top, where it supports the wall or arch. This form of capital was maintained in the general proportions and outline of the Romanesque capital. This was achieved most simply by cutting a rectangular block and taking the four lower corners off at an angle so that the block was square at the top, but octagonal at the bottom, as can be seen at St. Michael's Hildesheim.\nThis shape lent itself to a wide variety of superficial treatments, sometimes foliate in imitation of the source, but often figurative. In Northern Europe the foliate capitals generally bear far more resemblance to the intricacies of manuscript illumination than to Classical sources. In parts of France and Italy, there are strong links to the pierced capitals of Byzantine architecture. It is in the figurative capitals that the greatest originality is shown. While some are dependent on manuscripts illustrations of Biblical scenes and depictions of beasts and monsters, others are lively scenes of the legends of local saints.\nThe capitals, while retaining the form of a square top and a round bottom, were often compressed into little more than a bulging cushion-shape. This is particularly the case on large masonry columns, or on large columns that alternate with piers as at Durham.\nVaults and roofs.\nThe majority of buildings have wooden roofs, generally of a simple \"truss\", \"tie beam\" or \"king post\" form. In the case of trussed rafter roofs, they are sometimes lined with wooden ceilings in three sections like those that survive at Ely and Peterborough cathedrals in England. In churches, typically the aisles are vaulted, but the nave is roofed with timber, as is the case at both Peterborough and Ely. In Italy where open wooden roofs are common, and tie beams frequently occur in conjunction with vaults, the timbers have often been decorated as at San Miniato al Monte, Florence.\nVaults of stone or brick took on several different forms and showed marked development during the period, evolving into the pointed ribbed arch characteristic of Gothic architecture.\nBarrel vault.\nThe simplest type of vaulted roof is the barrel vault in which a single arched surface extends from wall to wall, the length of the space to be vaulted, for example, the nave of a church. An important example, which retains medieval paintings, is the vault of Saint-Savin-sur-Gartempe, France, of the early 12th century. However, the barrel vault generally required the support of solid walls, or walls in which the windows were very small.\nGroin vault.\nGroin vaults occur in early Romanesque buildings, notably at Speyer Cathedral where the high vault of about 1060 is the first employment in Romanesque architecture of this type of vault for a wide nave. In later buildings employing ribbed vaultings, groin vaults are most frequently used for the less visible and smaller vaults, particularly in crypts and aisles. A groin vault is almost always square in plan and is constructed of two barrel vaults intersecting at right angles. Unlike a ribbed vault, the entire arch is a structural member. Groin vaults are frequently separated by transverse arched ribs of low profile as at Speyer and Santiago de Compostela. At Sainte Marie Madeleine, V\u00e9zelay, the ribs are square in section, strongly projecting and polychrome.\nRibbed vault.\nRibbed vaults came into general use in the 12th century. In ribbed vaults, not only are there ribs spanning the vaulted area transversely, but each vaulted bay has diagonal ribs, following the same course as the groins in a groin vault. However, whereas in a groin vault, the vault itself is the structural member, in a ribbed vault, it is the ribs that are the structural members, and the spaces between them can be filled with lighter, non-structural material.\nBecause Romanesque arches are nearly always semi-circular, the structural and design problem inherent in the ribbed vault is that the diagonal span is larger and therefore higher than the transverse span. The Romanesque builders used a number of solutions to this problem. One was to have the centre point where the diagonal ribs met as the highest point, with the infill of all the surfaces sloping upwards towards it, in a domical manner. This solution was employed in Italy at San Michele, Pavia, and Sant' Ambrogio, Milan.\nThe solution employed in England was to stilt the transverse ribs, maintaining a horizontal central line to the roof like that of a barrel vault. The diagonal ribs could also be depressed, a solution used on the sexpartite vaults at both the Saint-\u00c9tienne, (Abbaye-aux-Hommes) and Sainte-Trinit\u00e9, (Abbaye-aux-Dames) at Caen, France, in the late 11th and early 12th centuries.\nPointed arched vault.\nThe problems encountered in the structure and appearance of vaults was solved late in the Romanesque period with the introduction of pointed arched ribs which allowed the height of both diagonal and transverse ribs to be varied in proportion to each other. Pointed ribs made their first appearance in the transverse ribs of the vaults at Durham Cathedral in northern England, dating from 1128. Durham is a cathedral of massive Romanesque proportions and appearance, yet its builders introduced several structural features that were new to architectural design and were later to be hallmark features of the Gothic style. Another Gothic structural feature employed at Durham is the flying buttress. However, these are hidden beneath the roofs of the aisles.\nThe earliest pointed vault in France is that of the narthex of La Madeleine, V\u00e9zelay, dating from 1130. They were subsequently employed with the development of the Gothic style at the east end of the Basilica of St Denis in Paris in 1140. An early ribbed vault in the Romanesque architecture of Sicily is that of the chancel at the Cathedral of Cefal\u00f9.\nDomes.\nDomes in Romanesque architecture are generally found within crossing towers at the intersection of a church's nave and transept, which conceal the domes externally. Called a \"tiburio\", this tower-like structure often has a blind arcade near the roof. Romanesque domes are typically octagonal in plan and use corner squinches to translate a square bay into a suitable octagonal base. Octagonal cloister vaults appear \"in connection with basilicas almost throughout Europe\" between 1050 and 1100. The precise form differs from region to region.\nEcclesiastical architecture.\nPlan.\nMany parish churches, abbey churches and cathedrals are in the Romanesque style, or were originally built in the Romanesque style and have subsequently undergone changes.\nThe simplest Romanesque churches are aisleless halls with a projecting apse at the chancel end, or sometimes, particularly in England, a projecting rectangular chancel with a chancel arch that might be decorated with mouldings. More ambitious churches have aisles separated from the nave by arcades.\nAbbey and cathedral churches generally follow the Latin Cross plan. In England, the extension eastward may be long, while in Italy it is often short or non-existent, the church being of T plan, sometimes with apses on the transept ends as well as to the east. In France the church of St Front, P\u00e9rigueux, appears to have been modelled on St. Mark's Basilica, Venice, or the Byzantine Church of the Holy Apostles and is of a Greek cross plan with five domes. In the same region, Angoul\u00eame Cathedral is an aisleless church of the Latin cross plan, more usual in France, but is also roofed with domes.\nIn Germany, Romanesque churches are often of distinctive form, having apses at both east and west ends, the main entrance being central to one side. It is probable that this form came about to accommodate a baptistery at the west end.\nNOTE: The plans below do not show the buildings in their current states.\nThe Abbey Church of St. Gall, Switzerland, shows the plan that was to become common throughout Germanic Europe. It is a Latin Cross with a comparatively long nave and short transepts and eastern end, which is apsidal. The nave is aisled, but the chancel and transepts are not. It has an apsidal west end, which was to become a feature of Churches of Germany, such as Worms Cathedral. Speyer Cathedral, Germany, also has aisleless transept and chancel. It has a markedly modular look. A typical Germanic characteristic is the presence of towers framing the chancel and the west end. There is marked emphasis on the western entrance, called \"Westwerk\", which is seen in several other churches. Each vault compartment covers two narrow bays of the nave.\nAt Autun Cathedral, France, the pattern of the nave bays and aisles extends beyond the crossing and into the chancel, each aisle terminating in an apse. Each nave bay is separated at the vault by a transverse rib. Each transept projects to the width of two nave bays. The entrance has a narthex which screens the main portal. This type of entrance was to be elaborated in the Gothic period on the transepts at Chartres. Angoul\u00eame Cathedral, France, is one of several instances in which the Byzantine churches of Constantinople seem to have been influential in the design in which the main spaces are roofed by domes. This structure has necessitated the use of very thick walls, and massive piers from which the domes spring. There are radiating chapels around the apse, which is a typically French feature and was to evolve into the chevet.\nAs was typically the case in England, Ely Cathedral was a Benedictine monastery, serving both monastic and secular function. To facilitate this, the chancel or \"presbytery\" is longer than usually found in Europe, as are the aisled transepts which contained chapels. In England, emphasis was placed on the orientation of the chapels to the east. The very large piers at the crossing signify that there was once a tower. The western end having two round towers flanking a tall central tower was unique in Britain. Ely Cathedral was never vaulted and retains a wooden ceiling over the nave.\nThe cathedral of Santiago de Compostela shares many features with Ely, but is typically Spanish in its expansive appearance. Santiago held the body of St. James and was the most significant pilgrimage site in Europe. The narthex, the aisles, the large aisled transepts and numerous projecting chapels reflect this. The chancel is short, compared to that of Ely, and the altar set so as to provide clear view to a vast congregation simultaneously.\nThe basilica Saint-Sernin of Toulouse is a typical example of a pilgrimage church. It is very large and its interior plan made it possible to direct traffic. With double side aisles and with an aisled transept and an ambulatory surrounding the apse, pilgrims could make the circuit around the church and were able to stop for meditation and prayer at the apsidal chapels of the transept and the radiating chapels of the choir.\nModena Cathedral shows a typically Italian Romanesque plan, often architecturally termed a \"basilica\", because of its similarity in plan to a Roman basilicas.\nSection.\nIn section, the typical aisled church or cathedral has a nave with a single aisle on either side. The nave and aisles are separated by an arcade carried on piers or on columns. The roof of the aisle and the outer walls help to buttress the upper walls and vault of the nave, if present. Above the aisle roof are a row of windows known as the clerestory, which give light to the nave. During the Romanesque period there was a development from this two-stage elevation to a three-stage elevation in which there is a gallery, known as a \"triforium\", between the arcade and the clerestory. This varies from a simple blind arcade decorating the walls, to a narrow arcaded passage, to a fully developed second story with a row of windows lighting the gallery.\nChurch and cathedral east ends.\nThe eastern end of a Romanesque church is almost always semi-circular, with either a high chancel surrounded by an ambulatory as in France, or a square end from which an apse projects as in Germany and Italy. Where square ends exist in English churches, they are probably influenced by Anglo-Saxon churches. Peterborough and Norwich Cathedrals have retained round east ends in the French style. However, in France, simple churches without apses and with no decorative features were built by the Cistercians who also founded many houses in England, frequently in remote areas.\nChurch and cathedral fa\u00e7ades and external decoration.\nRomanesque church fa\u00e7ades, generally to the west end of the building, are usually symmetrical, have a large central portal made significant by its mouldings or porch, and an arrangement of arched-topped windows. In Italy there is often a single central ocular or wheel window. The common decorative feature is arcading.\nSmaller churches often have a single tower that is usually placed to the western end in France or England, either centrally or to one side, while larger churches and cathedrals often have two.\nIn France, Saint-\u00c9tienne, Caen, presents the model of a large French Romanesque fa\u00e7ade. It is a symmetrical arrangement of nave flanked by two tall towers each with two buttresses of low flat profile that divide the fa\u00e7ade into three vertical units. The lowest stage is marked by large doors, each set within an arch in each of the three vertical sections. The wider central section has two tiers of three identical windows, while in the outer sections there are two tiers of single windows, giving emphasis to the mass of the towers. The towers rise above the fa\u00e7ade through three further tiers, the lowest of tall blind arcading, the next of arcading pierced by two narrow windows and the third of two large windows, divided into two lights by a colonnette.\nThis fa\u00e7ade can be seen as the foundation for many other buildings, including both French and English Gothic churches. While the form is typical of northern France, its various components were common to many Romanesque churches of the period across Europe. Similar fa\u00e7ades are found in Portugal. In England, Southwell Cathedral has maintained this form, despite the insertion of a huge Gothic window between the towers. Lincoln and Durham must once have looked like this. In Germany, Limburg Cathedral has a rich variety of openings and arcades in horizontal storeys of varying heights.\nThe churches of San Zeno Maggiore, Verona, and San Michele, Pavia, present two types of fa\u00e7ade that are typical of Italian Romanesque, that which reveals the architectural form of the building, and that which screens it. At San Zeno, the components of nave and aisles are made clear by the vertical shafts that rise to the level of the central gable and by the varying roof levels. At San Miniato al Monte the definition of the architectural parts is made even clearer by the polychrome marble, a feature of many Italian medieval fa\u00e7ades, particularly in Tuscany.\nAt San Michele the vertical definition is present as at San Zeno, but the rooflines are screened behind a single large gable decorated with stepped arcading. At Santa Maria della Pieve, Arezzo, this screening is carried even further, as the roofline is horizontal and the arcading rises in many different levels while the colonettes that support them have a great diversity of decoration.\nIn the Rhineland and Netherlands the Carolingian form of west end known as the westwerk prevailed. Towers and apse of the western end are often incorporated into a multi-storey structure that bears little structural or visual relationship to the building behind it. These westwerks take a great variety of forms as may be seen at Maria Laach Abbey, St Gertrude, Nivelles, and St Serviatius, Maastricht.\nChurch towers.\nTowers were an important feature of Romanesque churches and a great number of them are still standing. They take a variety of forms: square, circular and octagonal, and are positioned differently in relation to the church building in different countries. In northern France, two large towers, such as those at Caen, were to become an integral part of the fa\u00e7ade of any large abbey or cathedral. In central and southern France this is more variable and large churches may have one tower or a central tower. Large churches of Spain and Portugal usually have two towers.\nMany abbeys of France, such as that at Cluny, had many towers of varied forms. This is also common in Germany, where the apses were sometimes framed with circular towers and the crossing surmounted by an octagonal tower as at Worms Cathedral. Large paired towers of square plan could also occur on the transept ends, such as those at Tournai Cathedral in Belgium. In Germany, where four towers frequently occur, they often have spires that may be four or eight sided, or the distinctive \"Rhenish helm\" shape seen on the cathedrals of Limburg or Speyer.\nIn England, for large abbeys and cathedral buildings, three towers were favoured, with the central tower being the tallest. This was often not achieved, through the slow process of the building stages, and in many cases the upper parts of the tower were not completed until centuries later as at Durham and Lincoln. Large Norman towers exist at the cathedrals of Durham, Exeter, Southwell, Norwich and Tewkesbury Abbey. Such towers were often topped during the late medieval period with a Gothic spire of wooden construction covered with lead, copper or shingles. In the case of Norwich Cathedral, the huge, ornate, 12th-century crossing-tower received a 15th-century masonry spire rising to a height of 320 feet and remaining to this day.\nIn Italy towers are almost always free standing and the position is often dictated by the landform of the site, rather than aesthetics. This is the case in nearly all Italian churches both large and small, except in Sicily where a number of churches were founded by the Norman rulers and are more French in appearance.\nAs a general rule, large Romanesque towers are square with corner buttresses of low profile, rising without diminishing through the various stages. Towers are usually marked into clearly defined stages by horizontal courses. As the towers rise, the number and size of openings increases as can be seen on the right tower of the transept of Tournai Cathedral where two narrow slits in the fourth level from the top becomes a single window, then two windows, then three windows at the uppermost level. This sort of arrangement is particularly noticeable on the towers of Italian churches, which are usually built of brick and may have no other ornament. Two fine examples occur at Lucca, at the church of San Frediano and at the \"Duomo\". It is also seen in Spain.\nIn Italy there are a number of large free-standing towers that are circular, the most famous of these being the Leaning Tower of Pisa. In other countries where circular towers occur, such as Germany, they are usually paired and often flank an apse. Circular towers are uncommon in England, but occur throughout the early medieval period in Ireland.\nPolygonal towers were often used on crossings and occur in France, Germany, Italy and Spain such as that of the Old Cathedral, Salamanca, which is covered by a dome supported on a ribbed vault.\nSmaller churches sometimes had bell-gables instead of towers, a feature which, according to some authors, is characteristic of the simplicity of much architecture in the Romanesque style.\nPortals.\nRomanesque churches generally have a single portal centrally placed on the west front, the focus of decoration for the fa\u00e7ade of the building. Some churches such as Saint-\u00c9tienne, Caen, (11th century) and Pisa Cathedral (late 12th century) had three western portals, in the manner of Early Christian basilicas. Many churches, both large and small, had lateral entrances that were commonly used by worshippers.\nRomanesque doorways have a character form, with the jambs having a series of receding planes, into each of which is set a circular shaft, all surmounted by a continuous abacus. The semi-circular arch which rises from the abacus has the same series planes and circular mouldings as the jambs. There are typically four planes containing three shafts, but there may be as many as twelve shafts, symbolic of the apostles.\nThe opening of the portal may be arched, or may be set with a lintel supporting a tympanum, generally carved, but in Italy sometimes decorated with mosaic or fresco. A carved tympanum generally constitutes the major sculptural work of a Romanesque church. The subject of the carving on a major portal may be Christ in Majesty or the Last Judgement. Lateral doors may include other subjects such as the Birth of Christ. The portal may be protected by a porch, with simple open porches being typical of Italy, and more elaborate structures typical of France and Spain.\nInteriors.\nThe structure of large churches differed regionally and developed across the centuries. The use of piers of rectangular plan to support arcades was common, as at Mainz Cathedral and St Gertrude Nivelle, and remained usual in smaller churches across Europe, with the arcades often taking the form of openings through the surface of a wall. In Italy, where there was a strong tradition of using marble columns, complete with capital, base and abacus, this remained prevalent, often reusing existent ancient columns, as at San Miniato al Monte. \nA number of 11th-century churches have naves distinguished by huge circular columns with no clerestory, or a very small one as at St Philibert, Tournus. In England stout columns of large diameter supported decorated arches, gallery and clerestory, as at the nave of Malmesbury Abbey (see \"Piers and columns\", above). By the early 12th century composite piers had evolved, in which the attached shafts swept upward to a ribbed vault or were continued into the mouldings of the arcade, as at V\u00e9zelay Abbey, Saint-\u00c9tienne, Caen, and Peterborough Cathedral.\nThe nature of the internal roofing varied greatly, from open timber roofs, and wooden ceilings of different types, which remained common in smaller churches, to simple barrel vaults and groin vaults and increasingly to the use of ribbed vaults in the late 11th and 12th centuries, which were to become a common feature of larger abbey churches and cathedrals. A number of Romanesque churches are roofed with a series of Domes. At Fontevrault Abbey the nave is covered by four domes, while at the Church of Saint Front, P\u00e9rigueux, the church is of Greek cross plan, with a central dome surrounded by four smaller domes over the nave, chancel and transepts.\nInternal decoration varied across Europe. Where wide expanses of wall existed, they were often plastered and painted. Wooden ceilings and timber beams were decorated. In Italy walls were sometimes faced with polychrome marble. Where buildings were constructed of stone that was suitable for carving, many decorative details occur, including ornate capitals and mouldings.\nThe apsidal east end was often a focus of decoration, with both architectonic forms such as arcading and pictorial features such as carved figures, murals and occasionally mosaics. Stained glass came into increasing use from the 11th century. In many churches the eastern end has been rebuilt in a later style. Of England's Norman cathedrals, no eastern end remains unchanged. In France the eastern terminals of the important abbeys of Caen, V\u00e9zelay and, most significantly, the Basilica of St Denis were completely rebuilt in the Gothic style. In Germany, major reconstructions of the 19th century sought to return many Romanesque buildings to their original form. Examples of simple Romanesque apses can be seen in the images of St Gertrude, Nivelles; St Philibert, Tournus, and San Miniato al Monte.\nOther structures.\nAmong the structures associated with church buildings are crypts, porches, chapter houses, cloisters and baptisteries.\nCrypts are often present as an underlying structure to a substantial church, and are generally a completely discrete space, but occasionally, as in some Italian churches, may be a sunken space under a raised chancel and open, via steps, to the body of the nave. Romanesque crypts have survived in many instances, such as Canterbury Cathedral, when the church itself has been rebuilt.\nThe usual construction of a Romanesque crypt is with many short stout columns carrying groin vaults, as at Worcester Cathedral.\nPorches sometimes occur as part of the original design of a fa\u00e7ade. This is very much the case in Italy, where they are usually only one bay deep and are supported on two columns, often resting on couchant lions, as at St Zeno, Verona. Elsewhere, porches of various dates have been added to the fa\u00e7ade or side entrance of existent churches and may be quite a substantial structure, with several bays of vaulting supported on an open or partially open arcade, and forming a sort of narthex as at the Church of St Maria, Laach. In Spain, Romanesque churches often have large lateral porches, like loggias.\nChapter houses often occur adjacent to monastic or cathedral churches. Few have survived intact from the Romanesque period. Early chapter houses were rectangular in shape, with the larger ones sometimes having groin or ribbed vaults supported on columns. Later Romanesque chapter houses sometimes had an apsidal eastern end. The chapter house at Durham Cathedral is a wide space with a ribbed vault, restored as originally constructed in 1130. The circular chapter house at Worcester Cathedral, built by Bishop Wulfstan (1062\u201395), was the first circular chapter house in Europe and was much imitated in England.\nCloisters are generally part of any monastic complex and also occur at cathedral and collegiate churches. They were essential to the communal way of life, a place for both working during daylight hours and relaxing during inclement weather. They usually abut the church building and are enclosed with windowless walls on the outside and an open arcade on the inside, looking over a courtyard or \"cloister garth\". They may be vaulted or have timber roofs. The arcades are often richly decorated and are home to some of the most fanciful carved capitals of the Romanesque period with those of Santo Domingo de Silos in Spain and the Abbey of St Pierre Moissac, being examples. Many Romanesque cloisters have survived in Spain, France, Italy and Germany, along with some of their associated buildings.\nBaptisteries often occur in Italy as a free standing structure, associated with a cathedral. They are generally octagonal or circular and domed. The interior may be arcaded on several levels as at Pisa Cathedral. Other notable Romanesque baptisteries are that at Parma Cathedral remarkable for its galleried exterior, and the polychrome Baptistery of San Giovanni of Florence Cathedral, with vault mosaics of the 13th century including Christ in Majesty, possibly the work of the almost legendary Coppo di Marcovaldo.\nDecoration.\nArchitectural embellishment.\nArcading is the single most significant decorative feature of Romanesque architecture. It occurs in a variety of forms, from the Lombard band, which is a row of small arches that appear to support a roofline or course, to shallow blind arcading that is often a feature of English architecture and is seen in great variety at Ely Cathedral, to the open dwarf gallery, first used at Speyer Cathedral and widely adopted in Italy as seen on both Pisa Cathedral and its famous Leaning Tower. Arcades could be used to great effect, both externally and internally, as exemplified by the church of Santa Maria della Pieve, in Arezzo.\nArchitectural sculpture.\nThe Romanesque period produced a profusion of sculptural ornamentation. This most frequently took a purely geometric form and was particularly applied to mouldings, both straight courses and the curved moldings of arches. In La Madeleine, Vezelay, for example, the polychrome ribs of the vault are all edged with narrow filets of pierced stone. Similar decoration occurs around the arches of the nave and along the horizontal course separating arcade and clerestory. Combined with the pierced carving of the capitals, this gives a delicacy and refinement to the interior.\nIn England, such decoration could be discrete, as at Hereford and Peterborough cathedrals, or have a sense of massive energy as at Durham where the diagonal ribs of the vaults are all outlined with chevrons, the mouldings of the nave arcade are carved with several layers of the same and the huge columns are deeply incised with a variety of geometric patterns creating an impression of directional movement. These features combine to create one of the richest and most dynamic interiors of the Romanesque period.\nAlthough much sculptural ornament was sometimes applied to the interiors of churches, the focus of such decoration was generally the west front, and in particular, the portals. Chevrons and other geometric ornaments, referred to by 19th-century writers as \"barbaric ornament\", are most frequently found on the mouldings of the central door. Stylized foliage often appears, sometimes deeply carved and curling outward after the manner of the acanthus leaves on Corinthian capitals, but also carved in shallow relief and spiral patterns, imitating the intricacies of manuscript illuminations. In general, the style of ornament was more classical in Italy, such as that seen around the door of San Giusto in Lucca, and more \"barbaric\" in England, Germany and Scandinavia, such as that seen at Lincoln and Speyer Cathedrals. France produced a great range of ornament, with particularly fine interwoven and spiralling vines in the \"manuscript\" style occurring at Saint-Sernin, Toulouse.\nFigurative sculpture.\nThe name of the architectural style was transferred onto the art of the period. Romanesque art provided fine examples of painting and sculpture, but, while the Romanesque churches were flush with colours, most large paintings were lost. The period brought a major revival of sculpture.\nWith the fall of the Roman Empire, the tradition of carving large works in stone and sculpting figures in bronze died out. The best-known surviving large sculptural work of Proto-Romanesque Europe is the life-size wooden Crucifix commissioned by Archbishop Gero of Cologne in about 960\u201365. During the 11th and 12th centuries, figurative sculpture flourished in a distinctly Romanesque style that can be recognised across Europe, although the most spectacular sculptural projects are concentrated in South-Western France, Northern Spain and Italy.\nMajor figurative decoration occurs particularly around the portals of cathedrals and churches, ornamenting the tympanum, lintels, jambs and central posts. The tympanum is typically decorated with the imagery of Christ in Majesty with the symbols of the Four Evangelists, drawn directly from the gilt covers of medieval Gospel Books. This style of doorway occurs in many places and continued into the Gothic period. A rare survival in England is that of the \"Prior's Door\" at Ely Cathedral. In France, many have survived, with impressive examples at the Abbey of Saint-Pierre, Moissac, the Abbey of Sainte-Marie, Souillac, and Abbey of la Madaleine, V\u00e9zelay\u00a0\u2013 all daughter houses of Cluny, with extensive other sculpture remaining in cloisters and other buildings. Nearby, Autun Cathedral has a Last Judgement of great rarity in that it has uniquely been signed by its creator Giselbertus (who was perhaps the patron rather than the sculptor). The same artist is thought to have worked at la Madeleine Vezelay which uniquely has two elaborately carved tympanum, the early inner one representing the Last Judgement and that on the outer portal of the narthex representing Jesus sending forth the Apostles to preach to the nations.\nIt is a feature of Romanesque art, both in manuscript illumination and sculptural decoration, that figures are contorted to fit the space that they occupy. Among the many examples that exist, one of the finest is the figure of the Prophet Jeremiah from the pillar of the portal of the Abbey of Saint-Pierre, Moissac, France, from about 1130. A significant motif of Romanesque design is the spiral, a form applied to both plant motifs and drapery in Romanesque sculpture. An outstanding example of its use in drapery is that of the central figure of Christ on the outer portal at La Madaleine, Vezelay.\nMany of the smaller sculptural works, particularly capitals, are Biblical in subject and include scenes of Creation and the Fall of Man, episodes from the life of Christ and those Old Testament scenes that prefigure his Death and Resurrection, such as Jonah and the Whale and Daniel in the lions' den. Many Nativity scenes occur, the theme of the Three Kings being particularly popular. The cloisters of Santo Domingo de Silos Abbey in Northern Spain, and Moissac are fine examples surviving complete.\nMurals.\nThe large wall surfaces and plain curving vaults of the Romanesque period lent themselves to mural decoration. Many of these early wall paintings have been destroyed by damp or the walls have been replastered and painted over. In most of Northern Europe such pictures were systematically destroyed in bouts of Reformation iconoclasm. In other countries they have suffered from war, neglect and changing fashion.\nA classic scheme for the full painted decoration of a church, derived from earlier examples often in mosaic, had, as its focal point in the semi-dome of the apse, Christ in Majesty or Christ the Redeemer enthroned within a mandorla and framed by the four winged beasts, symbols of the Four Evangelists, comparing directly with examples from the gilt covers or the illuminations of Gospel Books of the period. If the Virgin Mary was the dedicatee of the church, she might replace Christ here. On the apse walls below would be saints and apostles, perhaps including narrative scenes, for example of the saint to whom the church was dedicated. On the sanctuary arch were figures of apostles, prophets or the twenty-four \"Elders of the Apocalypse\", looking in towards a bust of Christ, or his symbol the Lamb, at the top of the arch. The north wall of the nave would contain narrative scenes from the Old Testament, and the south wall from the New Testament. On the rear west wall would be a Doom painting or Last Judgement, with an enthroned and judging Christ at the top.\nOne of the most intact schemes to exist is that at Saint-Savin-sur-Gartempe in France. The long barrel vault of the nave provides an excellent surface for fresco, and is decorated with scenes of the Old Testament, showing the Creation, the Fall of Man and other stories including a lively depiction of Noah's Ark complete with a fearsome figurehead and numerous windows through with can be seen the Noah and his family on the upper deck, birds on the middle deck, while on the lower are the pairs of animals. Another scene shows with great vigour the swamping of Pharaoh's army by the Red Sea. The scheme extends to other parts of the church, with the martyrdom of the local saints shown in the crypt, and Apocalypse in the narthex and Christ in Majesty. The range of colours employed is limited to light blue-green, yellow ochre, reddish brown and black. Similar paintings exist in Serbia, Spain, Germany, Italy and elsewhere in France.\nStained glass.\nThe oldest-known fragments of medieval pictorial stained glass appear to date from the 10th century. The earliest intact figures are five prophet windows at Augsburg, dating from the late 11th century. The figures, though stiff and formalised, demonstrate considerable proficiency in design, both pictorially and in the functional use of the glass, indicating that their maker was well accustomed to the medium. At Canterbury and Chartres Cathedrals, a number of panels of the 12th century have survived, including, at Canterbury, a figure of Adam digging, and another of his son Seth from a series of Ancestors of Christ. Adam represents a highly naturalistic and lively portrayal, while in the figure of Seth, the robes have been used to great decorative effect, similar to the best stone carving of the period.\nMany of the magnificent stained glass windows of France, including the famous windows of Chartres, date from the 13th century. Far fewer large windows remain intact from the 12th century. One such is the Crucifixion of Poitiers, a remarkable composition that rises through three stages, the lowest with a quatrefoil depicting the Martyrdom of St Peter, the largest central stage dominated by the crucifixion and the upper stage showing the Ascension of Christ in a mandorla. The figure of the crucified Christ is already showing the Gothic curve. The window is described by George Seddon as being of \"unforgettable beauty\".\nTransitional style and the continued use of Romanesque forms.\nDuring the 12th century, features that were to become typical of Gothic architecture began to appear. It is not uncommon, for example, for a part of building that has been constructed over a lengthy period extending into the 12th century, to have very similar arcading of both semi-circular and pointed shape, or windows that are identical in height and width, but in which the later ones are pointed. This can be seen on the towers of Tournai Cathedral and on the western towers and fa\u00e7ade at Ely Cathedral. Other variations that appear to hover between Romanesque and Gothic occur, such as the fa\u00e7ade designed by Abbot Suger at the Abbey of Saint-Denis, which retains much that is Romanesque in its appearance, and the fa\u00e7ade of Laon Cathedral, which, despite its Gothic form, has round arches.\nAbbot Suger's innovative choir of the Abbey of Saint-Denis, 1140\u201344, led to the adoption of the Gothic style by Paris and its surrounding area, but other parts of France were slower to take it up, and provincial churches continued to be built in the heavy manner and rubble stone of the Romanesque, even when the openings were treated with the fashionable pointed arch.\nIn England, the Romanesque groundplan, which in that country commonly had a very long nave, continued to affect the style of building of cathedrals and those large abbey churches which were also to become cathedrals at the dissolution of the monasteries in the 16th century. Despite the fact that English cathedrals were built or rebuilt in many stages, substantial areas of Norman building can be seen in many of them, particularly in the nave arcades. In the case of Winchester Cathedral, the Gothic arches were literally carved out of the existent Norman piers. Other cathedrals have sections of their building which are clearly an intermediate stage between Norman and Gothic, such as the western towers of Ely Cathedral and part of the nave at Worcester Cathedral. The first truly Gothic building in England is the long eastern end of Canterbury Cathedral commenced in 1175.\nIn Italy, although many churches such as Florence Cathedral and Santa Maria Novella were built in the Gothic style, or utilising the pointed arch and window tracery, Romanesque features derived from the Roman architectural heritage, such as sturdy columns with capitals of a modified Corinthian form, continued to be used. The pointed vault was utilised where convenient, but it is commonly interspersed with semicircular arches and vaults wherever they conveniently fit. The fa\u00e7ades of Gothic churches in Italy are not always easily distinguishable from the Romanesque.\nGermany was not quick to adopt the Gothic style, and when it did so in the 1230s, the buildings were often modelled very directly upon French cathedrals, as Cologne Cathedral was modelled on Amiens. The smaller churches and abbeys continued to be constructed in a more provincial Romanesque manner, the date only being registered by the pointed window openings.\nRomanesque castles, houses and other buildings.\nThe Romanesque period was a time of great development in the design and construction of defensive architecture. After churches and the monastic buildings with which they are often associated, castles are the most numerous type of building of the period. While most are in ruins through the action of war and politics, others, like William the Conqueror's White Tower within the Tower of London have remained almost intact.\nIn some regions, particularly Germany, large palaces were built for rulers and bishops. Local lords built great halls in the countryside, while rich merchants built grand town houses. In Italy, city councils constructed town halls (called Broletto or Arengario), while wealthy cities of Northern Europe protected their trading interests with warehouses and commercial premises. All over Europe, dwellers of the town and country built houses to live in, some of which, sturdily constructed in stone, have remained to this day with sufficient of their form and details intact to give a picture of the style of domestic architecture that was in fashion at the time.\nExamples of all these types of buildings can be found scattered across Europe, sometimes as isolated survivals like the two merchants' houses on opposite sides of Steep Hill in Lincoln, England, and sometimes giving form to a whole medieval city like San Gimignano in Tuscany, Italy. These buildings are the subject of a separate article.\nRomanesque Revival.\n \"See also\" Romanesque Revival architecture in the United Kingdom\nDuring the 19th century, when Gothic Revival architecture was fashionable, buildings were occasionally designed in the Romanesque style. There are a number of Romanesque Revival churches, dating from as early as the 1830s and continuing into the 20th century where the massive and \"brutal\" quality of the Romanesque style was appreciated and designed in brick.\nThe Natural History Museum, London, designed by Alfred Waterhouse, 1879, on the other hand, is a Romanesque revival building that makes full use of the decorative potential of Romanesque arcading and architectural sculpture. The Romanesque appearance has been achieved while freely adapting an overall style to suit the function of the building. The columns of the foyer, for example, give an impression of incised geometric design similar to those of Durham Cathedral. However, the sources of the incised patterns are the trunks of palms, cycads and tropical tree ferns. The animal motifs, of which there are many, include rare and exotic species.\nThe type of modern buildings for which the Romanesque style was most frequently adapted was the warehouse, where a lack of large windows and an appearance of great strength and stability were desirable features. These buildings, generally of brick, frequently have flattened buttresses rising to wide arches at the upper levels after the manner of some Italian Romanesque fa\u00e7ades. This style was adapted to suit commercial buildings by opening the spaces between the arches into large windows, the brick walls becoming a shell to a building that was essentially of modern steel-frame construction, the architect Henry Hobson Richardson giving his name to the style, Richardsonian Romanesque. \nGood examples of the style are Marshall Field's Wholesale Store, Chicago, by H.H. Richardson, 1885, and the Chadwick Lead Works in Boston, United States, by William Preston, 1887. The style also lent itself to the building of cloth mills, steelworks and powerstations.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52687", "revid": "50330333", "url": "https://en.wikipedia.org/wiki?curid=52687", "title": "Classical architecture", "text": "Architectural style, inspired by classical Greco-Roman architectural principles\nClassical architecture typically refers to architecture consciously derived from the principles of Greek and Roman architecture of classical antiquity, or more specifically, from \"De architectura\" (c. 10 AD) by the Roman architect Vitruvius. Variations of classical architecture have arguably existed since the Carolingian Renaissance, and became especially prominent during the Italian Renaissance and the later period known as neoclassical architecture or Classical revival. While classical styles of architecture can vary, they generally share a common \"vocabulary\" of decorative and structural elements. Across much of the Western world, classical architectural styles have dominated the history of architecture from the Renaissance until World War II. Classical architecture continues to influence contemporary architects.\nThe term \"classical architecture\" can also refer to any architectural tradition that has evolved to a highly refined form, such as classical Chinese or Mayan architecture. It may also describe architecture that adheres to classical aesthetic philosophy. The term might be used differently from \"traditional\" or \"vernacular architecture\", it can share underlying axioms with it.\nFor contemporary buildings following authentic classical principles, the term New Classical architecture is often used.\nHistory.\nOrigins.\nClassical architecture is derived from the architecture of ancient Greece and ancient Rome. After the collapse of the western part of the Roman empire, the architectural traditions of the Roman Empire ceased to be practised in large parts of western Europe. In the Byzantine Empire, however, ancient ways of building methods survived, though they gradually developed into a distinct Byzantine style. The first conscious attempts to bring back the architectural language of classical antiquity into Western Europe emerged during the Carolingian Renaissance of the late 8th and 9th centuries. The gatehouse of Lorsch Abbey (c.\u2009800) in present-day Germany features alternating attached columns and archesl an almost direct paraphrase of e.g., that of the Colosseum in Rome. \nWhile Byzantine, Romanesque, and even to some aspects of Gothic architecture (with which classical architecture is often posed) incorporate classical elements and details, they generally do not reflect a systematic effort to revive or emulate the architectural principles of antiquity. For instance, they typically do not adhere the idea of a systematic order of proportions for columns. As such, these styles are not considered classical architecture in the strict sense.\nDevelopment.\nDuring the Italian Renaissance and with the demise of Gothic style, major efforts were made by architects such as Leon Battista Alberti, Sebastiano Serlio and Giacomo Barozzi da Vignola to revive the language of architecture of first and foremost ancient Rome. This was done in part through the study of the ancient Roman architectural treatise by Vitruvius, and to some extent by studying the actual remains of ancient Roman buildings in Italy. Nonetheless, the classical architecture of the Renaissance from the outset represents a highly specific interpretation of the classical ideas. In a building like the Ospedale degli Innocenti in Florence by Filippo Brunelleschi, one of the earliest Renaissance buildings (built 1419\u20131445), the treatment of the columns for example has no direct antecedent in ancient Roman architecture. During this time period, the study of ancient architecture developed into the architectural theory of classical architecture; somewhat over-simplified, that classical architecture in its variety of forms ever since have been interpretations and elaborations of the architectural rules set down during antiquity.\nMost of the styles originating in post-Renaissance Europe can be described as classical architecture. This broad use of the term is employed by Sir John Summerson in \"The Classical Language of Architecture\". The elements of classical architecture have been applied in radically different architectural contexts than those for which they were developed, however. For example, Baroque or Rococo architecture are styles which, although classical at root, display an architectural language much in their own right. During these periods, architectural theory still referred to classical ideas but rather less sincerely than during the Renaissance.\nThe Palladian architecture developed from the style of the Venetian architect Andrea Palladio (1508\u20131580) had a great influence long after his death, above all in Britain, where it was adopted for many of the grander buildings of the Georgian architecture of the 18th and early 19th century.\nAs a reaction to late Baroque and Rococo forms, architectural theorists from c.\u20091750 through what became known as Neoclassicism again consciously and earnestly attempted to emulate antiquity, supported by recent developments in Classical archaeology and a desire for an architecture based on clear rules and rationality. Claude Perrault, Marc-Antoine Laugier and Carlo Lodoli were among the first theorists of Neoclassicism, while \u00c9tienne-Louis Boull\u00e9e, Claude Nicolas Ledoux, Friedrich Gilly and John Soane were among the more radical and influential. Neoclassical architecture held a particularly strong position on the architectural scene c.\u20091750\u20131850. The competing neo-Gothic style however rose to popularity during the early 1800s, and the later part the 19th century was characterised by a variety of styles, some of them only slightly or not at all related to classicism (such as Art Nouveau), and Eclecticism. Although classical architecture continued to play an important role and for periods of time at least locally dominated the architectural scene, as exemplified by the Nordic Classicism during the 1920s, classical architecture in its stricter form never regained its former dominance. With the advent of Modernism during the early 20th century, classical architecture arguably almost ceased to be practised.\nScope.\nAs noted above, classical styles of architecture dominated Western architecture for a long time, roughly from the Renaissance until the advent of Modernism. That is to say, that classical antiquity at least in theory was considered the prime source of inspiration for architectural endeavours in the West for much of Modern history. Even so, because of liberal, personal or theoretically diverse interpretations of the antique heritage, classicism covers a broad range of styles, some even so to speak cross-referencing, like Neo-Palladian architecture, which draws its inspiration from the works of Italian Renaissance architect Andrea Palladio, who himself drew inspiration from ancient Roman architecture. Furthermore, it can be argued that styles of architecture not typically considered classical, like Gothic, can contain classical elements. Therefore, a simple delineation of the scope of classical architecture is difficult to make. The more or less defining characteristic can still be said to be a reference to ancient Greek or Roman architecture, and the architectural rules or theories that derived from that architecture.\nPetrification.\nIn the grammar of architecture, the word \"petrification\" is often used when discussing the development of sacred structures such as temples, mainly with reference to developments in the Greek world. During the Archaic and early Classical periods (about the 6th and early 5th centuries BC), the architectural forms of the earliest temples had solidified and the Doric emerged as the predominant element. The most widely accepted theory in classical studies is that the earliest temple structures were of wood and the great forms, or elements of architectural style, were codified and rather permanent by the time the Archaic became emergent and established. It was during this period, at different times and places in the Greek world, that the use of dressed and polished stone replaced the wood in these early temples, but the forms and shapes of the old wooden styles were retained in a skeuomorphic fashion, just as if the wooden structures had turned to stone, thus the designation \"petrification\" or sometimes \"petrified carpentry\" for this process.\nThis careful preservation of the traditional wooden appearance in the stone fabric of the newer buildings was scrupulously observed and this suggests that it may have been dictated by religion rather than aesthetics, although the exact reasons are now lost in antiquity. Not everyone within the reach of Hellenic civilization made this transition. The Etruscans in Italy were, from their earliest period, greatly influenced by their contact with Greek culture and religion, but they retained their wooden temples (with some exceptions) until their culture was completely absorbed into the Roman world, with the great wooden Temple of Jupiter on the Capitol in Rome itself being a good example. Nor was it the lack of knowledge of stone working on their part that prevented them from making the transition from timber to dressed stone.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52688", "revid": "211905", "url": "https://en.wikipedia.org/wiki?curid=52688", "title": "Baroque painting", "text": "European art movement from about 1590 to 1750\nBaroque painting is the painting associated with the Baroque cultural movement. The movement is often identified with Absolutism, the Counter Reformation and Catholic Revival, but the existence of important Baroque art and architecture in non-absolutist and Protestant states throughout Western Europe underscores its widespread popularity.\nBaroque painting encompasses a great range of styles, as most important and major painting during the period beginning around 1600 and continuing throughout the 17th century, and into the early 18th century is identified today as Baroque painting. In its most typical manifestations, Baroque art is characterized by great drama, rich, deep colour, and intense light and dark shadows, but the classicism of French Baroque painters like Poussin and Dutch genre painters such as Vermeer are also covered by the term, at least in English. As opposed to Renaissance art, which usually showed the moment before an event took place, Baroque artists chose the most dramatic point, the moment when the action was occurring: Michelangelo, working in the High Renaissance, shows his David composed and still before he battles Goliath; Bernini's Baroque David is caught in the act of hurling the stone at the giant. Baroque art was meant to evoke emotion and passion instead of the calm rationality that had been prized during the Renaissance.\nAmong the greatest painters of the Baroque period are Vel\u00e1zquez, Caravaggio, Rembrandt, Rubens, Poussin, and Vermeer. Caravaggio is an heir of the humanist painting of the High Renaissance. His realistic approach to the human figure, painted directly from life and dramatically spotlit against a dark background, shocked his contemporaries and opened a new chapter in the history of painting. Baroque painting often dramatizes scenes using chiaroscuro light effects; this can be seen in works by Rembrandt, Vermeer, Le Nain and La Tour.\nThe Flemish painter Anthony van Dyck developed a graceful but imposing portrait style that was very influential, especially in England.\nThe prosperity of 17th century Holland led to an enormous production of art by large numbers of painters who were mostly highly specialized and painted only genre scenes, landscapes, still lifes, portraits or history paintings. Technical standards were very high, and Dutch Golden Age painting established a new repertoire of subjects that was very influential until the arrival of Modernism.\nHistory.\nThe Council of Trent (1545\u20131563), in which the Roman Catholic Church answered many questions of internal reform raised by both Protestants and by those who had remained inside the Catholic Church, addressed the representational arts in a short and somewhat oblique passage in its decrees. This was subsequently interpreted and expounded by a number of clerical authors like Molanus, who demanded that paintings and sculptures in church contexts should depict their subjects clearly and powerfully, and with decorum, without the stylistic airs of Mannerism.\nThis return toward a populist conception of the function of ecclesiastical art is seen by many art historians as driving the innovations of Caravaggio and the Carracci brothers, all of whom were working (and competing for commissions) in Rome around 1600, although unlike the Carracci, Caravaggio persistently was criticised for lack of decorum in his work.\nHowever, although religious painting, history painting, allegories, and portraits were still considered the most noble subjects, landscape, still life, and genre scenes were also becoming more common in Catholic countries, and were the main genres in Protestant ones.\nThe term.\nThe term \"Baroque\" was initially used with a derogatory meaning, to underline the excesses of its emphasis. Others derive it from the mnemonic term \"Baroco\" denoting, in logical \"Scholastica\", a supposedly laboured form of syllogism.\nIn particular, the term was used to describe its eccentric redundancy and noisy abundance of details, which sharply contrasted the clear and sober rationality of the Renaissance. It was first rehabilitated by the Swiss-born art historian, Heinrich W\u00f6lfflin (1864\u20131945) in his \"Renaissance und Barock\" (1888); W\u00f6lfflin identified the Baroque as \"movement imported into mass\", an art antithetic to Renaissance art. He did not make the distinctions between Mannerism and Baroque that modern writers do, and he ignored the later phase, the academic Baroque that lasted into the 18th century. Writers in French and English did not begin to treat Baroque as a respectable study until W\u00f6lfflin's influence had made German scholarship pre-eminent.\nNational variations.\nLed by Italian Baroque painting, Mediterranean countries, slowly followed by most of the Holy Roman Empire in Germany and Central Europe, generally adopted a full-blooded Baroque approach.\nA rather different art developed out of northern realist traditions in 17th century Dutch Golden Age painting, which had very little religious art, and little history painting, instead playing a crucial part in developing secular genres such as still life, genre paintings of everyday scenes, and landscape painting. While the Baroque nature of Rembrandt's art is clear, the label is less used for Vermeer and many other Dutch artists. Most Dutch art lacks the idealization and love of splendour typical of much Baroque work, including the neighbouring Flemish Baroque painting which shared a part in Dutch trends, while also continuing to produce the traditional categories in a more clearly Baroque style.\nIn France a dignified and graceful classicism gave a distinctive flavour to Baroque painting, where the later 17th century is also regarded as a golden age for painting. Two of the most important artists, Nicolas Poussin and Claude Lorrain, remained based in Rome, where their work, almost all in easel paintings, was much appreciated by Italian as well as French patrons.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52691", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=52691", "title": "Morris dance", "text": "English performance folk dance\nMorris dancing is a form of English folk dance. It is based on rhythmic stepping and the execution of choreographed figures by a group of dancers in costume, usually wearing bell pads on their shins, their shoes or both. A band or single musician, also costumed, will accompany them. Sticks, swords, handkerchiefs, and a variety of other implements may be wielded by the dancers.\nMorris dancing first appeared in England in the 15th century. Its earliest surviving mention dates to 1448 and records the payment of seven shillings to Morris dancers by the Goldsmiths' Company in London. The term \"Morris\" derives from the Spanish term , although Morris dancing has no known historical connection to the Moors.\nThree prominent groups organise and support Morris in England: Morris Ring, Morris Federation and Open Morris; all three organisations have members from other countries as well.\nThere are around 150 Morris sides (or teams) in the United States. English immigrants form a large part of the Morris tradition in Australia, Canada, New Zealand and Hong Kong. There are relatively isolated groups in other countries, for example those in Utrecht and Helmond, Netherlands; the Arctic Morris Group of Helsinki, Finland and Stockholm, Sweden; as well as in Cyprus and St Petersburg, Russia.\nName and origins.\nThroughout its history, the Morris seems to have been common. It was imported from village festivities into popular entertainment after the invention of the court masque by Henry VIII. The word Morris apparently derived from \"morisco\", meaning 'Moorish'. Cecil Sharp, whose collecting of Morris dances preserved many from extinction, suggested that it might have arisen from the dancers' blacking their faces as part of the necessary ritual disguise.\nThe name is first recorded in English in the mid-15th century as , , , i.e. 'Moorish dance'. The term entered English via Flemish . Comparable terms in other languages include German (also from the 15th century), French , Croatian , and , or in Italy and Spain. The modern spelling \"Morris-dance\" first appeared in the 17th century. In Edward Phillips's \"The New World of English Words\", first published in 1658, the term \"morisco\" was referenced as both \"a Moor\" and \"the Morris dance, as it were the Moorish dance\", while John Bullokar defined it in 1695 as \"a certain dance used among the Moors; whence our Morris dance\".\nIt is unclear how the dance came to be referred to as Moorish, \"unless in reference to fantastic dancing or costumes\", i.e. the deliberately \"exotic\" flavour of the performance. The English dance thus apparently arose as part of a wider 15th-century European fashion for supposedly \"Moorish\" spectacle, which also left traces in Spanish and Italian folk dance. The means and chronology of the transmission of this fashion is now difficult to trace; the \"London Chronicle\" recorded \"spangled Spanish dancers\" performed an energetic dance before King Henry VII at Christmas in 1494, but Heron's accounts also mention \"\" four days earlier, and the attestation of the English term from the mid-15th century establishes that there was a \"Moorish dance\" performed in England decades prior to 1494.\nAn alternative derivation from the Latin , (custom and usage) has also been suggested.\nIt has been suggested that the tradition of rural English dancers blackening their faces may be a form of disguise, or a reference either to the Moors or to miners; the origins of the practice remain unclear and are the subject of ongoing debate. In June 2020 the Joint Morris Organisation called for the use of black makeup to be discontinued, in response to the Black Lives Matter movement. Groups that used face paint changed to blue, green, or yellow and black stripes.\nHistory in England.\nThe earliest (15th-century) references place the Morris dance in a courtly setting. The dance became part of performances for the lower classes by the later 16th century. Henry VIII owned a gold salt cellar which depicted a Morris dance with five dancers and a \"tabrett\". A \"tabret\" is a small tabor drum. On 4 January 1552, George Ferrers, the Lord of Misrule of Edward VI, put on a show in London which included \"mores danse, dansyng with a tabret\". In 1600, the Shakespearean actor William Kempe Morris danced from London to Norwich, an event chronicled in his \"Nine Daies Wonder\" (1600).\nAlmost nothing is known about the folk dances of England before the mid-17th century. While it is possible to speculate on the transition of \"Morris dancing\" from the courtly to a rural setting, it may have acquired elements of pre-Elizabethan (medieval) folk dance, such proposals will always be based on an argument from silence as there is no direct record of what such elements would have looked like. In the Elizabethan period, there was significant cultural contact between Italy and England, and it has been suggested that much of what is now considered traditional English folk dance, and especially English country dance, is descended from Italian dances imported in the 16th century.\nBy the mid 17th century, the working peasantry took part in Morris dances, especially at Whitsun. The Puritan government of Oliver Cromwell, however, suppressed Whitsun ales and other such festivities. When the crown was restored by Charles II, the springtime festivals were restored. In particular, Whitsun Ales came to be celebrated on Whitsunday (Pentecost), as the date was close to the birthday of Charles II.\nA regional reference occurs in Horsham, Sussex in 1750.\nMorris dancing continued in popularity until the Industrial Revolution and its accompanying social changes. Four teams claim a continuous lineage of tradition within their village or town: Abingdon (their Morris team was kept going by the Hemmings family), Bampton, Headington Quarry, and Chipping Campden. Other villages have revived their own traditions, and hundreds of other teams across the globe have adopted (and adapted) these traditions, or have created their own styles from the basic building blocks of Morris stepping and figures.\nBy the late 19th century, and in the West Country at least, Morris dancing was fast becoming more a local memory than an activity. D'Arcy Ferris (or de Ferrars), a Cheltenham-based singer, music teacher and organiser of pageants, became intrigued by the tradition and sought to revive it. He first encountered Morris in Bidford and organised its revival. Over the following years he took the side to several places in the West Country, from Malvern to Bicester and from Redditch to Moreton in Marsh. By 1910, he and Cecil Sharp were in correspondence on the subject.\nSeveral English folklorists were responsible for recording and reviving the tradition in the early 20th century, often from a bare handful of surviving members of mid-19th-century village sides. Among these, the most notable are Cecil Sharp and Mary Neal.\nRevival.\nBoxing Day 1899 is widely regarded as the starting point for the Morris revival. Cecil Sharp was visiting at a friend's house in Headington, near Oxford, when the Headington Quarry Morris side arrived to perform. Sharp was intrigued by the music and collected several tunes from the side's musician, William Kimber, including Country Gardens. A decade later he began collecting the dances, spurred and at first assisted by Mary Neal, a founder of the Esp\u00e9rance Club (a dressmaking co-operative and club for young working women in London), and Herbert MacIlwaine, musical director of the Esp\u00e9rance Club. Neal was looking for dances for her girls to perform, and so the first revival performance was by young women in London.\nOrganisations.\nIn the first few decades of the 20th century, several men's sides were formed, and in 1934 the Morris Ring was founded by six revival sides:\nIn the 1950s and especially the 1960s, there was an explosion of new dance teams, some of them women's or mixed sides. At the time, there was often heated debate over the propriety and even legitimacy of women dancing the Morris, even though there is evidence as far back as the 16th century that there were female Morris dancers. There are now male, female and mixed sides to be found.\nPartly because women's and mixed sides were not eligible for full membership of the Morris Ring (this has now changed), two other national (and international) bodies were formed, the Morris Federation and Open Morris. All three bodies provide communication, advice, insurance, instructionals (teaching sessions) and social and dancing opportunities to their members. The three bodies co-operate on some issues, while maintaining their distinct identities. An umbrella body that includes all three, the Joint Morris Organisation, organises joint events and discusses issues that affect all members, such as access to both public liability and personal insurance cover.\nMorris dancing in Wales.\nTraditional Welsh dance experienced a revival in the early twentieth century, and while these dances were commonly performed as progressive longways display dances, Lois Blake noted that the Llanover Dances displayed \"the influence of the Morris, both in form and movements\". \nWhile these traditions that had been recorded by Ceinwen Thomas and Catherine Margretta Thomas were not specifically Morris dances as recognised today, they were interpreted in new ways by Morris men. While one dance, \"Y Gaseg Eira\" would become a central part of the Welsh morris. \nThe revival saw the reinvention of a living tradition in Wales, with new dances such as \"Y Derwydd\", \"Hela'r Sgwarnog\", \"Ty Coch Caerdydd\" and \"Y Goron\" becoming recognised to be just as much a part of the Nantgarw tradition as the original dance.\nMorris dancing in the United States.\nMorris dancing has been practiced in the United States since at least 1908, although an article published by the Country Dance and Song Society points to 1910 as the year Morris dancing truly took off in America. The primary organization supporting Morris Dance in the US is the North American Morris Dance Organization, which is affiliated with the Country Dance and Song Society as well as the Morris Ring, Morris Federation, and Open Morris. British-American musician and folklorist Tony Barrand was key in developing and documenting Morris history in the US, including founding the Marlboro Morris Men as well as the Marlboro Morris Ale.\nMost Morris sides in the United States are concentrated on the East Coast, particularly in the Boston-Washington development corridor. Large regular events in this part of the country include the Marlboro Morris Ale and Dancing America Rapper Tournament (the American offshoot of Dancing England Rapper Tournament). Minneapolis is the hub for Morris dancing in the Midwest, with 6 teams in the Minneapolis-St. Paul metro area and 9 teams in the whole of Minnesota. Dancing the sun up on May Day is an important activity for many American Morris dance teams.\nStyles.\nToday, there are six predominant styles of Morris dancing, and different dances or traditions within each style named after their region of origin.\nCotswold.\nLionel Bacon records Cotswold Morris traditions from these towns and villages:\nAbingdon, Adderbury, Ascot-under-Wychwood, Badby, Bampton, Bidford, Bledington, Brackley, Bucknell, Chipping Campden, Ducklington, Eynsham, Headington Quarry, Hinton-in-the-Hedges, Ilmington, Kirtlington, Leafield (Field Town), Longborough, Oddington, Sherbourne, Stanton Harcourt, Upton-upon-Severn and Wheatley.\nBacon also lists the tradition from Lichfield, which is Cotswold-like despite that city's distance from the Cotswold Morris area; the authenticity of this tradition has been questioned. In 2006, a small number of dances from a previously unknown tradition was discovered by Barry Care, MBE, keeper of The Morris Ring Photographic Archive, and a founding member of Moulton Morris Men (Ravensthorpe, Northamptonshire)\u2014two of them danceable.\nOther dances listed by Bacon include Border Morris dances from Brimfield, Bromsberrow Heath, Evesham, Leominster, Much Wenlock, Pershore, Upton-upon-Severn, Upton Snodsbury, White Ladies Aston, and miscellaneous non-Cotswold, non-Border dances from Steeple Claydon and Winster. There are a number of traditions which have been collected since the mid-twentieth century, though few have been widely adopted. Examples are Broadwood, Duns Tew, and Ousington-under-Wash in the Cotswold style, and Upper and Lower Penn in the Border style. In fact, for many of the \"collected\" traditions in Bacon, only sketchy information is available about the way they were danced in the nineteenth century, and they have been reconstructed to a degree that makes them largely twentieth-century inventions as well. Some traditions have been reconstructed in several strikingly disparate ways; an example would be Adderbury, danced very differently by the Adderbury Morris Men and the Adderbury Village Morris.\nNorth West.\nThe North West tradition is named after the North West region of England and has always featured mixed and female sides, at least as far back as the 18th century. There is a picture of Eccles Wakes painted in 1822 that shows both male and female dancers.\nHistorically, most sides danced in various styles of shoes or boots, although dancing in clogs was also very common. Modern revivalist sides have tended more towards the wearing of clogs. The dances were often associated with rushcarts at the local wakes or holidays, and many teams rehearsed only for these occasions. While some teams continue to rehearse and dance for a single local festival or event (such as the Abram Morris Dancers), the majority of teams now rehearse throughout the year, with the majority of performances occurring in the spring and summer. The dances themselves were often called 'maze' or 'garland dances' as they involved a very intricate set of movements in which the dancers wove in and out of each other. Some dances were performed with a wicker hoop (decorated with garlands of flowers) held above the dancer's head. Some dancers were also associated with a tradition of mumming and hold a pace egging play in their area.\nThe Britannia Coconut Dancers, named after a mill not far from Bacup, are unique in the tradition, in that they used sawn bobbins to make a noise, and perform to the accompaniment of a brass ensemble. They are one of the few North West Morris groups that still black up their faces. It is said that the dance found its way to the area through Cornishmen who migrated to work in the Rossendale quarries.\nCarnival morris dancing shares a parallel history with North West morris dancing but began to evolve independently from around the 1940s onwards. It remains extremely popular with upwards of 8,000 current dancers.\nGirls' carnival morris dancing is highly competitive and characterised by precise, synchronous routines with pom-poms (or 'shakers') executed to pop music. It is performed almost exclusively by girls and women in Lancashire, Cheshire and parts of North Wales. Performances typically take place in sports halls and community centres and participants more closely align with British carnival performances such as jazz kazoo marching bands, entertainer troupes and majorettes, than with the morris performances of the folk revival.\nIn 2005, playwright Helen Blakeman staged 'The Morris' at the Liverpool Everyman, inspired by her childhood experience as a carnival morris dancer. In 2017, an exhibition of photographs taken at a carnival morris dancing competition in Southport by artist, Lucy Wright was presented at Cecil Sharp House.\nBorder.\nThe term \"Border Morris\" was first used by E. C. Cawte in a 1963 article on the Morris dance traditions of Herefordshire, Shropshire and Worcestershire: counties along the border with Wales. Characteristics of the tradition as practised in the 19th and early 20th centuries include: blackface or coloured facepaint (in some areas), use of either a small strip of bells (in some areas) or no bells at all (in others), costume often consisting of ordinary clothes decorated with ribbons, strips of cloth, or pieces of coloured paper (known as 'raggies'); or sometimes \"fancy dress\", small numbers of traditional dances in the team repertoire, often only one and rarely more than two, highly variable number of dancers in the set and configurations of the set (some sides had different versions of a dance for different numbers of dancers), and an emphasis on stick dances almost to the exclusion of hankie dances.\nSword dancing.\nUsually regarded as a type of Morris, although many of the performers themselves consider it as a traditional dance form in its own right, is the sword dance tradition, which includes both rapper sword and longsword traditions. In both styles the \"swords\" are not actual swords, but implements specifically made for the dance. The dancers are usually linked one to another via the swords, with one end of each held by one dancer and the other end by another. Rapper sides consist of five dancers, who are permanently linked-up during the dance. The rapper sword is a very flexible strip of spring-steel with a wooden handle at each end. The longsword is about long, with a wooden handle at one end, a blunt tip, and no edge. Sometimes ribbons are threaded through a hole in the tip of the sword, and the dancers grab on to them during the course of the dance. Longsword sides consist usually of five to eight dancers. In both rapper and longsword there is often a supernumerary \"character\", who dances around, outside, and inside the set.\nOther traditions.\nThe English mummers play occasionally involves Morris or sword dances either incorporated as part of the play or performed at the same event. Mummers plays are often performed in the streets near Christmas to celebrate the New Year and the coming springtime. In these plays are central themes of death and rebirth.\nOther forms include Molly dance from Cambridgeshire. Molly dance, which is associated with Plough Monday, is a parodic form danced in work boots and with at least one Molly man dressed as a woman. The largest Molly Dance event is the Whittlesea Straw Bear Festival, established in 1980, held at Whittlesey in Cambridgeshire in January.\nThere is also Stave dancing from the south-west and the Abbots Bromley Horn Dance.\nAdditionally, there is a specifically Welsh version of the art that is distinct from the Borders Morris style. This style is called Nantgarw tradition after a small village in the Taff Valley. One Nantgarw dance, Y Caseg Eira, is derived directly from notes made on traditional Welsh dances from the 1890s. These notes were made by Ceinwen Thomas in the 1950s from the childhood recollections of her mother, Catherine Margretta Thomas. Others are more modern inventions made in the style of older dances. Dances in the Nantgarw style include; Caseg Eira (The Snow Mare), Hela'r Sgwarnog (Hunting The Hare) and Ty Coch Caerdydd (The Red House of Cardiff).\nMusic.\nMusic was traditionally provided by either a pipe and tabor or a fiddle. These are still used today, but the most common instrument is the melodeon. Accordions and concertinas are also common, and other instruments are sometimes used. Often drums are employed.\nCotswold and sword dancers are most often accompanied by a single player, but Northwest and Border sides often have a band, usually including a drum.\nFor Cotswold and (to a degree) Border dances, the tunes are traditional and specific: the name of the dance is often actually the name of the tune, and dances of the same name from different traditions will have slightly different tunes. For Northwest and sword dancing there is less often a specific tune for a dance: the players may use several tunes, and will often change tunes during a dance.\nFor dances which have set tunes, there is often a short song set to the tune. This is sung by the musician(s) or by the whole side as an introduction to the tune before the dance. The songs are usually rural in focus (i.e. related to agricultural practices or village life) and often bawdy or vulgar. Songs for some dances vary from side to side, and some sides omit songs altogether.\nSeveral notable albums have been released, in particular the \"Morris On\" series, which consists of \"Morris On\", \"Son of Morris On\", \"Grandson of Morris On\", \"Great Grandson of Morris On\", \"Morris on the Road\", and \"Mother of all Morris\".\nTerminology.\nLike many activities, Morris dancing has a range of words and phrases that it uses in special ways.\nMany participants refer to the world of Morris dancing as a whole as \"the Morris\".\nA Morris troupe is usually referred to as a \"side\" or a \"team\". The two terms are interchangeable. Despite the terminology, Morris dancing is hardly ever competitive.\nA \"set\" (which can also be referred to as a \"side\") is a number of dancers in a particular arrangement for a dance. Most Cotswold Morris dances are danced in a rectangular set of six dancers, and most Northwest dances in a rectangular set of eight; but there are many exceptions.\nA \"jig\" is a dance performed by one (or sometimes two) dancers, rather than by a set. Its music does not usually have the rhythm implied by the word \"jig\" in other contexts.\nThe titles of officers vary from side to side, but most sides have at least the following:\nMany sides have one or more \"fools\". A fool is usually extravagantly dressed, and communicates directly with the audience in speech or mime. The fool often dances around and even through a dance without appearing really to be a part of it, but it takes a talented dancer to pull off such fooling while actually adding to and not distracting from the main dance set.\nMany sides also have a \"beast\": a dancer in a costume made to look like a real or mythical animal. Beasts mainly interact with the audience, particularly children. In some groups this dancer is called the \"hobby\".\nA \"tradition\" in Cotswold Morris is a collection of dances that come from a particular area, and have something in common: usually the steps, arm movements, and dance figures. Many newer traditions are invented by revival teams.\nMost Cotswold dances alternate \"common figures\" (or just \"figures\") with a \"distinctive figure\" (or \"chorus\"). The common figures are common to all (or some) dances in the \"tradition\"; the distinctive figure distinguishes that dance from others in the same tradition. Sometimes (particularly in \"corner\" dances) the choruses are not identical, but have their own sequence specific to the tradition. Nevertheless, something about the way the chorus is danced distinguishes that dance from others. Several traditions often have essentially the same dance, where the name, tune, and distinctive figure are the same or similar, but each tradition employs its common figures and style.\nIn England, an \"ale\" is a private party where a number of Morris sides get together and perform dances for their own enjoyment rather than for an audience. Food is usually supplied, and sometimes this is a formal meal known as a feast or ale-feast. Occasionally, an evening ale is combined with a day or weekend of dance, where all the invited sides tour the area and perform in public. In North America the term is widely used to describe a full weekend of dancing involving public performances and sometimes workshops. In the sixteenth to nineteenth centuries, the term \"ale\" referred to a church- or dale-sponsored event where ale or beer was sold to raise funds. Morris dancers were often employed at such events.\nEvolution.\nContinuance of Morris tradition.\nThe continuance of Morris is as much in the hands of independent groups of enthusiasts as it is in the nationwide groupings such as The Morris Ring or The Morris Federation. So while for some sides there is a feeling that the music and dance recorded in the 19th century should be maintained, there are others who freely reinterpret the music and dance to suit their abilities and including modern influences. In 2008 a front-page article in the \"Independent Magazine\" noted the rising influence of neopaganism within the modern Morris tradition. The article featured the views of Neopagan sides Wolf's Head and Vixen Morris and Hunter's Moon Morris and contrasted them with those of the more traditional Long Man Morris Men. The Morris may have become popular in neopaganism thanks to the scholarship of James Frazer, who hypothesised that rural folk traditions were survivals of ancient pagan rituals. Though this view was fiercely criticised even by Frazer's contemporaries, it was fully embraced by Sir Edmund Chambers, one of the first to produce serious writing on English folk plays and dances, and who became a major influence on popular understanding of Morris dancing in the 20th century.\nAge and gender issues.\nIn January 2009 \"The Telegraph\" published a report predicting the demise of Morris dancing within 20 years, due to the lack of young people willing to take part. This widespread story originated from a senior member of the more traditionally minded Morris Ring, and may only reflect the situation in relation to member groups of that one organisation.\nA survey published in December 2020 identified how the profile of morris dancers had evolved since the first survey published in 2014. The number of morris dancers in the UK had increased from 12,800 in 2014 to 13,600 in 2020. The average age of a morris dancer in the UK was 55, up from 52 in 2014. The survey also reported an even balance between male and female performers by 2020.\nUse of the Internet.\nThe advent of the Internet in the 1990s has also given Morris sides a new platform upon which to perform. Many Morris sides now have entertaining websites which seek to reflect the public persona of the individual sides as much as record their exploits and list forthcoming performances.\nMorris sides have traditionally raised funds by collecting cash from spectators, but in the post-Covid moves to a more cashless society, many sides now use portable card payment terminals.\nThere are also a multitude of thriving Morris-related blogs and forums, and individual sides are to be found maintaining an interactive presence on major social networking sites. Surveys in 2021 of use of social media services by morris sides found that the Westminster Morris Men YouTube channel had received over 100,00 views and the Shrewsbury Morris's Twitter account had over 100,000 followers.\nIn popular culture.\nThe success of Terry Pratchett's \"Discworld\" novels has seen the entirely invented Dark Morris tradition being brought to life in some form by genuine Morris sides such as the Witchmen Morris and Jack Frost Morris. Dark Morris has been described as having been \"evolved from the border revival of the 1970s which was part of a wider neo-traditionalist surge of interest in regional morris styles\".\nKit and clothing.\nThere is great variety shown in how Morris sides dress, from the predominantly white clothing of Cotswold sides to the tattered jackets worn by Border teams. Common items of clothing include\nbell pads, baldrics, braces, rosettes, sashes, waistcoats, tatter-coats (or raggies), knee-length breeches, wooden clogs, hats (straw hats, top hats, or bowlers), neckerchiefs, and armbands.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52693", "revid": "28979433", "url": "https://en.wikipedia.org/wiki?curid=52693", "title": "Square dance", "text": "Dance for four couples arranged in a square\nA square dance is a dance for four couples, or eight dancers in total, arranged in a square, with one couple on each side, facing the middle of the square. Square dances are part of a broad spectrum of dances known by various names: country dances, traditional dances, folk dances, barn dances, ceilidh dances, contra dances, Playford dances, etc. These dances appear in over 100 different formations, of which the Square and the Longways Set are by far the most popular formations.\nSquare dances contain elements from numerous traditional dances including English country dances, which were first documented in 17th-century England, and 18th-century French quadrilles and cotillions; square dancing travelled to North America with the European settlers and developed significantly there.\nSquare dancing is done in many different styles all around the world. In some countries and regions, through preservation and repetition, square dances have attained the status of a folk dance. Square dancing is strongly associated with the United States, in part due to its association with the romanticized image of the American cowboy in the 20th century, and 31 states have designated it as their official state dance. The main North American types of square dances include traditional square dance and modern western square dance, which is widely known and danced worldwide. Other main types popular in England, Ireland, and Scotland include Playford dances, regional folk dances, ceili, Irish set dances, and Scottish country dances.\nThe couples in a square are numbered, although numbering varies among different types. In many of the types, two of the couples are known as \"heads\" and the other two are called \"sides\". In most American forms of square dance, the dancers are prompted or cued through a sequence of steps by a caller to the beat (and, in some traditions, the phrasing) of music. In other variations, dancers have no caller and instead memorize and perform a specific routine and sequence of steps. Square dance music varies widely, with some forms using traditional tunes and others employing more modern types.\nDances can be organized by square dance clubs, bands, individuals, or similar organizations. Attire varies by type, with some forms possessing a specific dress code and others having no requirements. The standard square formation can also vary at times to include more or fewer dancers or arrange dancers in a different shape.\nHistory.\nThe origins of Square dances can be traced back to steps and figures used in traditional folk dances and social dances from many countries. One of the earliest influences may have been the Morris dance, an English dance for six men involving a line formation and energetic steps. This dance is closely related to another ancestor of square dancing, English country dance, which included a variety of dances for groups of couples arranged in circles, lines, or squares. In 1651, John Playford published 105 of these dances in \"The English Dancing Master\", eight of which are square dances exhibiting concepts still in use, such as the head couples performing an action and the side couples repeating it. Three of the dances, such as \"Dull Sir John\", specifically use the term \"square dance\" in the phrase, \"A Square Dance for eight thus\". In the early 1800s, English country dances merged with French dances to form the quadrille, a dance for four couples in a square.\nThese dances further evolved in America, where they arrived with European settlers. After the American Revolution, the quadrille became especially popular. Quadrilles were originally danced from memorized steps and sequences, but as African American slaves played music for the dances, they began calling out the steps. This practice became common by the early 1900s and gave rise to the modern caller. Between 1940 and 1960, modern western square dance evolved from the western style of traditional square dance that had formed in the United States. Traditional western square dancing was promoted beginning in the 1930s by Lloyd Shaw, who solicited definitions from callers across the country in order to preserve that dance form and make it available to other teachers. The American folk music revival in New York City in the 1950s was rooted in the resurgent interest in square dancing and folk dancing there in the 1940s, which gave musicians such as Pete Seeger popular exposure.\nStarting in the 1970s, many U.S. states adopted square dance as their state dance, the result of a campaign by square dancers to make it the national dance.\nMain types.\nSquare dances are considered folk dances in many countries and regions, although the term \"square dance\" varies. In the United States the term is used for dances in square formations and also refers to the dance events where square dances are performed. In England, Ireland, and Scotland, the term is used less frequently, and many dance events involve dances in square, circle, and line formations. The term has also become associated with barn dances, where many different formations of dance are used.\nUnited States and Canada.\nTraditional square dance.\nAlso called \"old-time square dance\" or \"quadrilles\" by some older New England callers in recognition of the dance it descended from, traditional square dance is not standardized and can be subdivided into three main regional styles: Northeast/New England, Southeast/Appalachian, and Western. The New England and Appalachian styles have been particularly well documented in the early U.S. and have survived to the 21st century. There are several other styles, some of which have survived or been revived while others have not. Where traditional square dance has been revived, it encompasses a wide range of new choreography.\nTraditional square dance structure varies by region, but it usually consists of a limited number of calls occurring in a set order. Traditional square dance is frequently presented in alternation with contra dances, particularly in revival groups, or with some form of freestyle couple dancing at surviving local events.\nModern western square dance.\nModern western square dance, which is also called \"western square dance\", \"contemporary western square dance\", or \"modern American square dance\", evolved from the western style of traditional square dance.\nIndustrialist Henry Ford popularized the form, believing that Jews invented jazz as a plot to corrupt society and that this plot could be counteracted by returning America to dances and musical styles that he saw as traditional and white. As a result, beginning in the early 1920s, he used his wealth to promote square dancing, through books and square dancing events. Ford also promoted square dance classes in public school, which were present in half of all American schools by 1928 as part of the standard physical education curriculum. Modern western square dance evolved in square dance events funded by Ford, using direction and guidance prepared by Colorado school superintendent Lloyd \"Pappy\" Shaw.\n Since the 1970s, modern western square dance has been promoted and standardized by Callerlab, the International Association of Square Dance Callers.The initial stage reached by all dancers is called Mainstream. This program consists of a core list of about 70 moves which is revised periodically. Modern western square dance is sometimes presented in alternation with round dances. This modern form of square dancing is taught in around 30 countries, including the United States, Canada, the United Kingdom, Australia, Belgium, France, Germany, Denmark, Sweden, Norway, Finland, Switzerland, the Netherlands, Australia, China, Japan, and Russia. Within Europe, the majority of square dance clubs are in Germany and the United Kingdom. All teach the Callerlab syllabus, but there are slight style and call title variations throughout the world. Because of this standardization, anyone with the proper training can dance modern western square dancing in many countries around the world. Instruction is typically given in the local language, but the calls are always in English, allowing people to dance internationally once they learn the calls.\nUnited Kingdom and Ireland.\nPlayford dances.\nAlso called \"English country dances\", Playford-style dances originated from the dances published in John Playford's book \"The English Dancing Master\". Some of the square dances listed in the book, such as \"Newcastle\", have survived to the 21st century, and countless new dances have been written in the Playford style. These dances include a range of moves, from smooth, gentle steps to more energetic leaps. They are supported by the English Folk Dance and Song Society.\nRegional folk dances.\nMany traditional English regional folk dances are square dances that have survived into the 21st century. For instance, in both the Goathland square eight and the Cumberland square eight, which originated from different English villages, dancers perform a series of memorized moves in a square formation. Many of these dances are danced at folk or barn dances, along with other types of square dances including Playford dances; dances derived from the quadrille, such as \"La Russe\" published by H.D. Willock in the \"Manual of Dancing\" (c.\u20091847); American traditional square dances; and countless new square dances written in the 20th and 21st centuries.\nCeili.\nIrish ceili dances cover a wide range of formations, including many square dances. They are often performed at traditional Irish and Scottish social gatherings called \"c\u00e8ilidhs\". C\u00e8ilidhs are also held in England, where the same squares may be done as at folk dances or barn dances but with more stepping, including skip steps, hop steps, polka steps, and rants.\nIrish set dance.\nIrish set dance is a square dance with strong regional associations. The dance involves stepping, often with a flat-foot polka step. Unlike in traditional and modern western square dancing, where couples are designated as \"heads\" or \"sides\", couples in Irish set dances are either \"tops\" or \"sides\". It is traditional to have 4 couples dance together on the sides of a square.\nScottish country dance.\nScottish country dances cover a wide range of formations, including many square dances. These dances, which are standardized by the Royal Scottish Country Dance Society, involve specific steps and formations that are performed in different sequences for different dances.\nContinental Europe.\nMany traditions have square dances. They are usually not called; rather, the sequence of figures is fixed and known by the dancers. Examples include the German \"Bekedorfer\", French \"Carr\u00e9 de Campagne\", \"Mie Katoen\" from the Low Countries, and Eastern European Jewish Sher or Sherele. Variations include double squares, with two couples on each side, like the Danish \"Sonderborger Doppelkadril\" or the Dutch \"Vleegerd\". Some are composed of multiple figures, indicating descent from the high-society quadrille.\nNumbering of couples.\nThe four couples arranged in a square are called a set, and each couple is numbered. Couple numbering in a square dance set usually begins with the couple nearest the head of the hall (the side of the room containing the musicians and caller, or, in the pre-caller era, the royal presence or other hosts or important guests). This couple is the \"first\" or \"number one\" couple.\nIf most figures are danced around the set, with one or more couples visiting the others in turn, the couples are likewise numbered around the set. In most surviving American square dance traditions, the couples are numbered counterclockwise: the second couple is to the first couple's right, the third couple is across from the first, and the fourth couple is to the left of the first. The first and third are \"head couples\" or \"heads\" (or, in older parlance, the \"first four\"); the second and fourth are \"side couples\" or \"sides\" (formerly \"side four\" or \"second four\").\nIf most of the figures are danced between facing couples across the set, as in the 19th century quadrille and dances derived from it, the couple opposite the first is the \"second couple\". The first and second couples constitute the \"head\" or \"top\" couples (or the \"head and foot\" couples); the third and fourth couples are the \"side\" couples. In Irish set dances, the third couple (sometimes termed the \"first side couple\") is to the left of the \"first top couple\". The couples facing the first top and first side are the \"second top couple\" and the \"second side couple\" respectively.\nCallers and calls.\nSquare dance movements are known as \"calls\", and some forms of the dance, such as traditional and modern western square dancing, use a caller to direct the dancers through different calls. In some forms of traditional square dancing, the caller may be one of the dancers or musicians, but in modern western square dancing, the caller is on stage giving full attention to directing the dancers.\nA square dance call may take a very short time or a very long time to execute. Most calls require between 4 and 32 counts, where a count is roughly one step. In traditional square dancing, the timing of a call is dictated by tradition; in some regional styles, particularly that of New England, the dance movements are closely fitted to the phrases of the music. In modern western square dancing, many calls have been given formally specified durations, based partly on direct observation of how long it takes an average dancer to execute them.\nTraditional and modern western square dance differ in the number of calls and their levels of standardization. Traditional square dance uses between ten and thirty calls, depending on the region and the individual caller. Many traditional square dance calls are similar or identical to contra dance calls, and new dance moves are explained by the caller. In modern western square dance, the participants learn and become proficient in a particular defined set of calls known as a \"program\". The Mainstream program, which is the default level of achievement, consists of close to 70 basic and mainstream calls. Rather than learning a complete routine, modern western square dancers learn basic movements and calls but do not know in what order they will be called. Unlike traditional square dance, two modern western dances are rarely alike. Most modern western square dancers participate only in the programs they have fully learned. Callerlab, the callers' international association, sets all programs and governs the training of callers.\nTraditional and modern western square dancing have a number of calls in common, but there are usually small differences in the way they are performed. For example, the Allemande Left is traditionally performed by grasping left hands with the other dancer, pulling away from each other slightly, and walking halfway around a central axis then stepping through. In modern western square dance, the grip is modified so that each dancer grips the forearm of the other, and there is no pulling (that is, each dancer supports his or her own weight). These modifications make it easier to enter and exit the movement and thus easier to incorporate it into a long sequence of calls.\nIn many communities, including Scotland and Ireland, and also continental Europe, the dancers know the complete dance and there is no caller.\nMusic.\nSquare dance music varies widely by type of dance.\nTraditional square dance is primarily danced to live music. Since the 19th century, much of the square dance repertoire has been derived from jigs and reels from Scotland and Ireland, sometimes in relatively unaltered form, sometimes as played in the old-time music tradition or as adapted by other cultures, such as that of Quebec. This sort of music is played on acoustic instruments, such as the fiddle, banjo, guitar, and double bass; certain instruments, including the piano, accordion, concertina, and hammered dulcimer, are popular in specific regions. In some communities where square dancing has survived, the prevailing form of music has become popular songs from the 1930s, 1940s, and 1950s, played on instruments such as saxophones, drums, and electric guitars. Tempos can vary from around 108 to more than 150 beats per minute, depending on the regional style.\nModern western square dance is danced to a variety of music types, including pop, traditional and contemporary country music, songs from Broadway musicals, rock, Motown, techno, and hip-hop. The music is usually played from recordings, and the tempo is more uniform than in traditional square dancing, ranging from 120\u2013128 beats per minute. At this speed, dancers take one step per beat of the music.\nIrish and Scottish dances are normally done to traditional tunes. English dances may be done to traditional tunes, though there is experimentation with many different musical styles, especially at c\u00e8ilidhs.\nClubs and attire.\nSquare dance events can be run in different ways. In North America, traditional square dances are organized by bands, callers, or small groups of dancers. Modern western square dances are arranged by square dance clubs. The clubs offer classes, socials, and dance evenings and arrange larger dances that are usually open to non-club members. In Britain, square dance clubs are affiliated with the British Association of American Square Dance Clubs, which also organizes the teaching of modern western square dance to Callerlab definitions. Most square dance events in Britain are run according to the Callerlab syllabus by a caller who is either a member of Callerlab or of the Square Dance Callers Club of Great Britain, and the level of dancing is indicated on the publicity material, as in \"Mainstream\" or \"Mainstream with Pre-Announced Plus\". C\u00e9ilidh and barn dance events are also often advertised as being square dance events.\nSquare dance attire varies by the type of dance and by region. Traditional square dance groups often have no particular dress code. In the United States, larger modern western square dance events sometimes request a strict western-style dress code, which originated in the late 1950s and early 1960s and is known as \"traditional square dance attire\", although it was not traditional before that time. Some clubs require a less strict dress code, known as \"proper\", or no dress code, called \"casual\". Although many modern western square dancers in Britain wear traditional square dance attire, events often have a relaxed dress code. Where traditional square dancing exists as a community social dance, sometimes in the form of a barn dance or a c\u00e8ilidh, people often dress up, though their clothing is not square-dance-specific.\nIn the United States, lines between the forms of square dancing have become blurred. Traditional-revival groups typically adopt very casual dress, and traditional-revival choreographers have begun to use basic movements that were invented for modern western square dance forms. A few modern western callers incorporate older dances from various traditions, such as New England or Appalachian, into their programs.\nVariations.\nWhile the standard formation for a square dance is four couples in a square, there are many variations on the theme. These include:\nModern choreography also includes dances which morph from one form to another. There are contra dances and four-couple longways sets which turn into a square dance part of the way through the dance and then back to the original formation.\nGrid squares are dances where the squares are arranged in a grid, with sets carefully aligned across the room and up and down the room. The calls move dancers from one square to another in intricate patterns.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52694", "revid": "78380", "url": "https://en.wikipedia.org/wiki?curid=52694", "title": "Irish dance", "text": "Traditional dances from Ireland\nIrish dance refers to the traditional dance forms that originate in Ireland, including both solo and group dance forms, for social, competitive, and performance purposes. Irish dance has evolved over centuries and is believed to have its roots in ancient Celtic dance. In the 17th and 18th centuries, dance was taught by \"travelling dance masters\" across Ireland, and separate dance forms developed according to regional practice and differing purposes. Irish dance became a significant part of Irish culture, particularly for Irish nationalist movements. From the early 20th century, a number of organisations promoted and codified the various forms of dance, creating competitive structures and standardised styles. Irish dancers who compete for competitive reasons dance in a dance style that is more modern than traditional Irish dance. It is mainly done solo, but there is some team dancing in groups of 2, 3, 4, 6, 8, 10, 16 or more.\nSolo Irish dance includes the most well-known form of Irish dance, Irish stepdance, which was popularized from 1994 onwards by shows such as \"Riverdance\", and which is practised competitively across not only the Irish diaspora but by many people of disparate cultural backgrounds. Stepdance is characterised by the rigid upper body and intricate footwork of its performers. Other forms of solo Irish dance include sean-n\u00f3s dance, a relaxed and social dance style involving improvised steps, and festival Irish dance, a style which separated from step dance in the mid-20th century.\nIrish group dancing has some French influences, and was particularly influenced by the French quadrille in the late 18th century. Ceili dance, practised both competitively and socially, is performed by groups of two to sixteen people, and often uses traditional or codified dances and formations. Its footwork is simple, and emphasis is placed on the figures and formations of the dances. Set dance is primarily a social tradition, for groups of four dancers, and includes elements of the intricate footwork found in step dance.\nHistory.\nThere is very little documentary evidence of dance being practised in Ireland prior to the 7th century; this could be due to the destruction of written records in Ireland during Viking raids. Scholars have hypothesised this is from non-literate nature of the Irish cultural tradition. Indeed, the modern Irish words for \"dance\", \"rince\" and \"damhsa\" did not develop until the 16th century. The scant evidence available is primarily that of visitors to Ireland, such as a fourteenth-century song written in the South of England, where the poet invites his listeners to \"come ant daunce wyt me in Irlaunde\". The first native Irish documentary evidence of dancing is an account of a Mayor of Waterford's visit to Baltimore, County Cork in 1413, where the attendees \"took to the floor\" to celebrate Christmas Eve. However, the Norman invasion of Ireland in the twelfth century may have brought with it the round dance tradition, as it was contemporaneously performed in British camps while every now and then being seen in a Norman stronghold.\nAccounts of dancing in the 17th century means that dancing was by that time extremely widespread throughout Ireland. In 1674 Richard Head wrote in reference to Ireland, 'In every field a fiddle, and the lasses footing till they all of a foam,' suggesting some type of Irish dancing or dance with heavy foot movement. There is ample evidence of Irish jigs or Irish dancing in the 16th century, in 1569 Sir Henry Sydney sent a letter to Queen Elizabeth in which he expresses his enthusiasm for the Irish jigs, or fiddle of Galway. A report from 1600 mentions that some forms of Irish dances were similar in form to English country dances, and later references mention the \"rinnce fada\", also known as the \"long dance\" or \"fading\". This dance, performed to a jig tune though not to any particular piece of music, became the customary conclusion to balls held in Ireland towards the end of the seventeenth century. At this time, dancing was commonly accompanied by musicians playing bagpipes or the Jew's harp.\nBy the 1760s, the distinctive hornpipe rhythm of the Irish dance tradition had developed, and with the introduction of the fiddle to Ireland from the European continent, a new class of \"dancing master\" began to emerge. Reference to the Irish fiddle can also be found in John Dunton's \"Teague Land: or A Merry Ramble to the Wild Irish\" (1698) he says \u201con Sundays and Holydays, all the people resorted with the piper and fiddler to the village green, suggesting the fiddle was introduced to Ireland much earlier then 1760.\nThe dancing traditions of Ireland probably grew in association with traditional Irish music. Although its origins are unclear, it was possibly later influenced by dance forms from the Continent, such as the \"Quadrille\". Travelling dancing masters taught across Ireland as late as the 18th and early 19th centuries. Because local venues were usually small, dances were often demonstrated on tabletops, or even the tops of barrels. As a result, these early styles are characterised by the arms held rigidly at the sides, and a lack of lateral movement. As larger dance venues became available, styles grew to include more movement of the body and around the dance area.\nIrish dance.\nAccounts of dancing in the 17th century suggest that dancing was by that time extremely widespread throughout Ireland. In 1674 Richard Head wrote in reference to Ireland, 'In every field a fiddle, and the lasses footing till they all of a foam,' suggesting some type of Irish dancing or dance with heavy foot movement. There is ample evidence of Irish jigs or Irish dancing in the 16th century, in 1569 Sir Henry Sydney sent a letter to Queen Elizabeth in which he expresses his enthusiasm for the Irish jigs, or fiddle of Galway. A variety of forms of solo Irish Dance have developed which are described as dance. These include the well-known \"modern\" stepdance performed competitively; old-style stepdance, which is closer in style to the dance practised by 19th-century travelling dance masters; and festival dance, which separated from modern stepdance over stylistic and administrative disputes in the mid-20th century.\nModern dance.\nThe most predominant form of Irish dance is that popularised by the Broadway show Riverdance, and other Irish dancing stage shows since the late 20th century. Characterised by a rigid torso and dances performed high on the balls of the feet, this style became distinct from the late 19th century when the Gaelic League began efforts to preserve and promote Irish dance as part of a broader nationalist movement concerned with Irish culture. Although a rigid torso may be the initial characterisation of Irish dance, modern soft shoe Irish dancers commonly gracefully use their arms in flowing movements, abandoning the traditional form. It is not uncommon for hard shoe dancers to use their arms in strict hand formations other than arms at sides, though competition dance continues to require the arms be kept by the dancer's sides.\nIn 1929, the League formed \"An Coimisi\u00fan Le Rinc\u00ed Gaelacha\" (CLRG, The Irish Dancing Commission) in order to codify and standardise stepdancing competition and education. Over the following decades, CLRG expanded globally, and promoted this particular form of stepdance by developing examinations and qualifications for teachers and competition adjudicators. Today, stepdance in the style codified by the Gaelic League is performed competitively in a number of countries, and under the auspices of a number of organisations which have at various times broken away from CLRG.\nDances.\nIrish solo dances fall into two broad categories based on the shoes worn: 'hard shoe' (also known as jig shoe or heavy shoe) and 'soft shoe' (or light shoe) dances.\nThere are four soft shoe dance styles: the reel, slip jig, light jig and 'single jig' (also referred to as 'hop jig'). Reels have a (or sometimes or ) time signature. Slip jigs are in time. Light and single jigs are in time, with different emphasis within the measure distinguishing the music.\nHard shoe dances include the hornpipe in syncopated or time, the treble jig (also called the 'heavy jig' or 'double jig') in a slow , the treble reel (a short sixteen bar hard shoe dance done to reel music) and 'traditional sets', which are a group of dances with set music and steps. Many traditional sets have irregular musical phrasing. There are multiple traditional sets, including St. Patrick's Day, Blackbird, Job of Journeywork, Three Sea Captains, Garden of Daisies, and King of the Fairies. While theoretically standardised, different organisations recognise different traditional sets and slight variations exist between teachers. There are also \"non-traditional sets\" done by advanced dancers. These have set music, but not steps; the steps are choreographed by individual dance schools.\nCompetitive dancers generally dance two or three steps at a time, depending on their dancing level. Each step lasts for sixteen bars of music for the treble jig and the reel. Dances such as the hornpipe and slip jig instead have eight bars of music for their third steps. The dances are each danced starting with the right foot for eight bars, then repeated with the left foot for the last eight bars, doing the same movements with the opposite feet. Set dances, however, have a different format. The dancer usually dances one step, which is limited to the length of the first part of the music that is repeated (often eight bars, though this varies depending on the specific set dance), and is then repeated, resembling the steps of other dances. Then the dancer usually dances a \"set\" which is not repeated. It is a highly sought after and competitive feat to recall to dance this \"third round\" \u2014 at regional, national, and world competitions, only a small percentage (typically the top half of dancers graded after the first two rounds) of dancers are invited back to perform.\nThe \"C\u00e9il\u00ed\" dances used in competitions are more precise versions of those danced in less formal settings. There is a list of 30 \"C\u00e9il\u00ed\" dances which have been standardised and published in \"An Coimisi\u00fan's\" \"Ar Rinncidhe Foirne\" as examples of typical Irish folk dances; these are called the \"book\" dances by competitive stepdancers. Most Irish dancing competitions only ask for a short piece of any given dance, in the interests of time and the endurance of the dancers.\nShoes and costume.\nThere are two types of shoes; soft shoes (also known as ghillies or pumps) and hard shoes. Hard shoes are similar to tap shoes, except that the tips and heels are made of fiberglass, instead of metal, and are significantly bulkier. Another aspect of the hard shoe that sets it apart from a tap shoe is its ability to go \"on block\" or en pointe. The first hard shoes had wooden or leather taps with metal nails. Later the taps and heels were made of resin or fiberglass to reduce the weight and to make the sounds louder. The soft shoes, which are called \"ghillies\", are black leather lace-up shoes similar to ballet slippers. \"Ghillies\" are only worn by girls, while boys wear black leather shoes called \"reel shoes\", which resemble black jazz shoes with a hard heel. Boy's soft-shoe dancing features audible heel clicks and stomps. A new trend includes adding white laces to the soft shoes, and white tape to the straps of the hard shoes to blend in with the sock and give the illusion of elongating the legs.\nSeveral generations ago, the appropriate dress for a competition was simply \"Sunday best\" (clothes one would wear to church). Irish Dance schools generally have school dresses, worn by lower-level competitors, in public performances, and in team competitions. As dancers advance in competition or are given starring roles in public performances, they may get a solo dress of their own design and colours or wear the team dress. In the 1970s and 1980s, ornately embroidered dresses became popular. Today even more ornamentation is used on girls' dresses, including rhinestones, sequins, and other bling. Solo dresses are unique to each dancer. Today most women and girls wear a wig, a bun or hairpiece for a competition, but some still curl their own hair. Costumes are heavily integrated into the Irish dance culture and feature traditional elements of classic peasant wear adorned with Celtic designs. Most men wear a shirt, vest or jacket, and tie paired with black trousers. The vest or jacket of the men's costume is also commonly adorned with crystals, traditional knotwork, and embroidery. Each Irish dance school has its own distinctive full skirted dress, often featuring lace or an embroidered pattern copied from the medieval Irish Book of Kells.\nCompetition structure.\nAn organised dance competition is referred to as a \"feis\" (plural \"feiseanna\"). The word \"feis\" means \"festival\" in Irish, and strictly speaking would also have competitions in music and crafts. \"F\u00e9ile\" () is a more correct term for the dance competition, but the terms may be used interchangeably. Dance competitions are divided by age and level of expertise. The names of the levels and other organising rules vary between countries and regions. Dancers are scored based on technique (placement of the feet, turn out, off of their heels, etc.), style (grace, power, etc.) and other items such as timing, rhythm, carriage, choreography and sounds in their hard shoe dances. \nIn most organizations, the lower and entry levels of Irish dance include beginner 1 and beginner 2, in which dancers mostly compete soft shoe dances. Then, after around 2 years of experience at these levels, dancers can advance to the intermediate levels, which include novice and prizewinner. At these levels, most dancers are competing five to six dances including both hard shoe and soft shoe. To advance through each of the levels, the dancer must receive specific placements in each of their dances. After obtaining a first place in each of their prizewinner dances (or by teacher discretion), a dancer can move up into the preliminary champion level (PC). At the PC level, dancers usually compete a longer soft shoe, hard shoe, and set dance, and then get an overall score for each of their dances combined. After obtaining two to three overall first places at the PC level, dancers can move into the highest level open champion (OC), where they compete a longer hard shoe and soft shoe, and set dance. The set dance at the champion level is a long hard shoe danced where the dancer is alone on stage and it focuses largely on advanced rhythm and timing. Within the PC and OC levels, dancers can qualify for the regional championships, Oireachtas. From Oireachtas placements, dancers can qualify for various National and World Championships.\n\"An Coimisi\u00fan\" dancers take part in their annual regional Championship competition, which is known as an oireachtas (). An Coimisi\u00fan also holds various \"national\" championship competitions. These are qualifying events for Oireachtas Rince na Cruinne, or \"The World Championships\". An Coimisi\u00fan's World Championships are the largest of all Irish step dance organisations, with over 6,000 dancers competing from over 30 countries worldwide. The \"Aisling\" Award (pronounced 'Ashling', Gaelic for dream) is awarded to the highest placing dancer in each solo dancing category from outside of Ireland, the United Kingdom, the US and Canada to encourage them to continue their dream of dancing. Other smaller Irish step dance organisations host their own premier championship.\n\"Oireachtas Rince na Cruinne\", or \"The World Championships\" (for An Coimisi\u00fan dancers), first took place in Dublin in 1970 at \"Col\u00e1iste Mhuire\", a school in Parnell Square. The \"Worlds\" outgrew its original location and moved around the Republic of Ireland and Northern Ireland. In 2002, for the first time, the \"Worlds\" left Ireland for Glasgow. In 2009, for the first time, the World Championships were held in the United States, in Philadelphia. The 2010-2019 championships were held in Glasgow, Dublin, Belfast, Boston, London, Montr\u00e9al, Glasgow, Dublin, Glasgow, and Greensboro, respectively, always taking place during the week leading up to Easter Sunday, when the championships end. The BBC documentary film \"Jig\" provided an insight into championship level dancers competing in the 2010 World Championships held in Glasgow. Oireachtas Rince Na Cruinne planned return to Dublin in 2020 for the 50 year anniversary of the championships was cancelled due to the COVID-19 pandemic. In 2022, the competition was held in Belfast.\nAn Coimsi\u00fan also holds Oireachtas Rince na h\u00c9ireann, or \"The All Irelands\" which take place in Killarney in February of each year. It is the oldest Irish dancing competition in the world.\nAn Comhdhail's World championships also take place each Easter week, with the competition being held in Dublin in 2018 and Killarney in 2019. WIDA (World Irish Dance Association), which mainly consists of dancers from European countries, also hold their own World and International Championships over the Easter week, with the competition being held in Maastricht in 2018, Eindhoven in 2019, digitally in 2021 due to the COVID-19 pandemic, and in Moers in 2022.\nOld-style step dancing.\nOld-style step dancing is a tradition related to, yet distinct from, sean-n\u00f3s dancing, though it is sometimes called \"Munster-style sean-n\u00f3s\". Old-style step dancing evolved in the 17th-18th century from the dancing of travelling Irish dance masters. The dance masters slowly formalised and transformed both solo and social dances. Modern masters of old-style step dancing style can trace the lineage of their steps directly back to 18th century dancers.\nThe Irish Dance masters refined and codified indigenous Irish dance traditions. Rules emerged about proper upper body, arm, and foot placement. Also, dancers were instructed to dance a step twice\u2014first with the right foot then with the left. Old-style step dancers dance with arms loosely (but not rigidly) at their sides. They dance in a limited space. There is an emphasis on making percussive sound with the toes. The Irish dance masters of this period also choreographed particular steps to particular tunes in traditional music creating the solo traditional set dances such as the Blackbird, St. Patrick's Day, and the Job of Journey Work, which also persist in modern Irish stepdancing. In this context, \"set dance\" signifies a separate tradition from the social dance tradition also called set dance.\nFestival dance.\nFollowing criticism of CLRG for its emphasis on certain regional forms of stepdance to the detriment of others, dance teacher Patricia Mulholland developed a new style of stepdance, beginning in the 1950s. It was described as a form of \"folk ballet\" which appealed to dancers of both Catholic and Protestant religious persuasions. Like other forms which share the heritage of modern stepdance but have departed from its codification, festival dance emphasises individuality and practises more relaxed style and posture.\nSean-n\u00f3s dance.\n\"Sean-n\u00f3s\", or \"old style\" dance is a form of Irish dancing which originated from western regions of Ireland. It has been described variously as a regional style of stepdancing, and as an entirely separate style that was virtually unknown outside small areas until the late 20th century. It is distinguished by footwork which is percussive but low to the ground in comparison to step dancing, and by its more freeform nature. Performers use a more relaxed posture, and improvise steps to fit with music. Typically, sean-n\u00f3s dances are performed in small spaces, traditionally doors laid flat and table tops.\nIrish c\u00e9il\u00ed dances.\nIrish social, or c\u00e9il\u00ed (, ) dances vary widely throughout Ireland and the rest of the world. A c\u00e9il\u00ed dance may be performed with as few as two people and as many as sixteen.\nC\u00e9il\u00ed dances may also be danced with an unlimited number of couples in a long line or proceeding around in a circle (such as in \"The Walls of Limerick\", \"The Waves of Tory\", \"Haymakers Jig\", \"An Rince Mor\" or \"Bonfire Dance\"). C\u00e9il\u00ed dances are often fast and some are quite complex (\"Antrim Reel\", \"Morris Reel\").\nIn a social setting, a c\u00e9il\u00ed dance may be \"called\"\u00a0\u2013 that is, the upcoming steps are announced during the dance for the benefit of newcomers. The c\u00e9il\u00ed dances are typically danced to Irish instruments such as the Irish \"bodhr\u00e1n\" or fiddle in addition to the concertina (and similar instruments), guitar, whistle or flute.\nThe term \"c\u00e9il\u00ed dance\" was invented in the late 19th century by the Gaelic League. as a noun differs from the adjective . A c\u00e9il\u00ed is a social gathering featuring Irish music and dance. C\u00e9il\u00ed dancing is a specific type of Irish dance. Some (plural of c\u00e9il\u00ed) will only have c\u00e9il\u00ed dancing, some only have set dancing, and some will have a mixture.\nIrish set dancing.\nIrish set dancing (also referred to as \"country set dancing\") are dances similar to English country dancing and later French quadrilles; later adapting and integrating forms of the dance with the Irish sean-n\u00f3s steps and Irish music. Distinguishing characteristics of Irish set dancing include that it is danced in square sets of four couples (eight people), and consist of several \"figures,\" each of which has a number of parts, frequently repeated throughout the set. Each part of the set dance (figure) is danced to a music tempo, mostly reels, jigs, polkas and hornpipes. The sets come from various parts of Ireland and are often named for their place of origin; examples are the North Kerry Set, the Clare Set, the Corofin Plain Set, the South Galway Set and the Clare Lancers Set.\nThere are many solo set dances which can be performed in competition. These include both traditional sets and non-traditional sets. Some traditional sets include Blackbird (hornpipe), Job of the Journeywork (hornpipe), Garden of Daises (hornpipe), St. Patrick's Day (treble jig), King of the Fairies (hornpipe). These dances are set in their choreography, which means that no teacher can vastly change the steps.\nThe organisation \"Comhaltas Ceolt\u00f3ir\u00ed \u00c9ireann\" promotes and hosts many set and ceili dance events."}
{"id": "52696", "revid": "4626", "url": "https://en.wikipedia.org/wiki?curid=52696", "title": "Cro Hook", "text": ""}
{"id": "52697", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=52697", "title": "Cro-Hook", "text": ""}
{"id": "52698", "revid": "4626", "url": "https://en.wikipedia.org/wiki?curid=52698", "title": "Cro hook", "text": ""}
{"id": "52699", "revid": "49332102", "url": "https://en.wikipedia.org/wiki?curid=52699", "title": "Filet crochet", "text": "Type of crocheted fabric\nFilet crochet is a type of crocheted fabric that imitates filet lace. This type of crocheted lace is gridlike because it uses only two crochet stitches: the chain stitch and the double crochet stitch (U.S. terminology; known in some other countries as \"chain stitch\" and \"treble\"). Old filet patterns used a treble or triple stitch vertically but chained two between the vertical stitches. This was to prevent distortion of some patterns. Chain stitches use less yarn than double crochet stitches, which results in a visual difference in appearance between the two kinds of stitch. Filet crochet forms patterns by filling in parts of a mostly chain stitch mesh with double crochet stitches. Filet crochet is usually constructed from monotone crochet thread made of Mercerised cotton in white or ecru, and worked in rows. Filet crochet is often used for decorative applications, such as window curtains, tablecloths, and place settings, such as coasters and placemats, but can also be used to create clothing, including yokes, as well as accessories and small bags.\nFilet crochet is most often worked from a graph or a symbol diagram. Patterns are created by combining solid and open meshes, usually working the design in solid meshes and the background in open meshes. The size of the space is determined by the number of chain stitches between each double stitch. Filet crochet may also be worked by alternating chain stitches with another type of crochet stitch such as (U.S. terminology) half double or triple crochet, and may be worked from yarn instead of thread.\nReading Charts.\nAs stated above, filet crochet patterns most often consist of a two-color grid. Each square represents either 2 chain stitches, or 2 double crochet stitches depending on the color. The space between two squares is always worked as a single double crochet stitch. \nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52701", "revid": "14984434", "url": "https://en.wikipedia.org/wiki?curid=52701", "title": "Tunisian crochet", "text": "Type of crochet\nTunisian crochet or Afghan crochet is a type of crochet that uses an elongated hook, often with a stopper on the handle end, called an Afghan hook. It is sometimes considered to be a mixture of crocheting and knitting. As such, some techniques used in knitting are also applicable in Tunisian crochet. One example is the intarsia method.\nDescription.\nThe work is begun with the traditional crochet starting chain, a series of chain stitches. Once the chain is completed, the first row is worked by inserting the hook back into the previous link of the chain, and a loop from the free end of the yarn is grabbed with the hook and pulled back through the link. Unlike traditional crochet, however, this new loop is not then pulled through the initial loop. Both remain on the hook and then the process is repeated, working from right to left if the artisan is right-handed, until each link in the chain has been worked. At the end, there will be as many loops on the hook as there are stitches required. This step is called forward pass, it is similar to casting on in knitting. This is the first of two parts for creating a row.\nFor the \"Tunisian simple stitch\" and most basic ones, the work is never turned. Once the correct number of loops is obtained, the process is reversed with each loop being worked off from the hook by pulling a fresh loop of yarn through each stitch, working from left to right, called the reverse or backward pass. It is both parts of the process which form a completed row. The tension of the yarn is much looser than in standard crochet or knitting.\nTunisian crochet can also be worked in the round as when making a seamless cap. To work in the round, a double-ended crochet hook and two balls of yarn are used. The first hook and ball of yarn are used to add loops (casting on). When the process is reversed (as described above), the loops are worked off using the second hook and second ball of yarn. When using a flexible cable to connect the two ends of the double-ended crochet hook, a single ball of yarn is sufficient.\nThere are a variety of stitches that can be created depending on how and where the hook is inserted and how the working yarn is held. Tunisian stitches include variations on knit, purl, post stitch, and entrelac.\nThe fabric created by Tunisian crochet is slightly less elastic than normal crochet and substantially thicker, particularly the knit stitch. This makes it most suitable for blankets and winter knits, but unsuitable for finer items like babywear and socks. The fabric also has a tendency to curl, and usually needs to be shaped by wetting or steaming the fabric (known as blocking) upon completion. It is slightly faster to create fabric by Tunisian than normal crochet, and approximately twice the speed of knitting. \nNaming history.\nTunisian crochet has gone by many names including Afghan crochet, Victorian crochet, tricot stitch, Scotch knitting, Princess Frederick William stitch, Princess Royal Crochet stitch, idiot's crochet, fool's crochet, and shepherd's knitting. The first mention of knitting with Tunisian-style hooked needles appeared in what is now Germany around 1787\u22121800, then in France in 1817. The first use of Tunisian in relation to this form of crochet was found in 1857 in Sweden (, \"Tunisian simple stitch\"). The term \"Tunisian Crochet\" is first found in English in an American publication from 1862.\nThere is no definite link between Tunisia and the Tunisian crochet; it might have been made because similar crafts are practised in Tunisia, or because Tunisia was situated on the trading route from Egypt to Europe where hooked needles were sold. Another possibility is that the name was given to indicate that this is an \"exotic\" fiber craft.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52702", "revid": "62", "url": "https://en.wikipedia.org/wiki?curid=52702", "title": "Afghan crocket", "text": ""}
{"id": "52703", "revid": "51", "url": "https://en.wikipedia.org/wiki?curid=52703", "title": "Carbon Nanotubes", "text": ""}
{"id": "52704", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=52704", "title": "Half Life", "text": ""}
{"id": "52705", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=52705", "title": "Leonardo DeCaprio", "text": ""}
{"id": "52707", "revid": "26578167", "url": "https://en.wikipedia.org/wiki?curid=52707", "title": "Kate Winslet", "text": "English actress (born 1975)\nKate Elizabeth Winslet (; born 5 October 1975) is an English actress. Primarily known for her roles as headstrong and complicated women in independent films, particularly period dramas, she has received numerous accolades, including an Academy Award, two Primetime Emmy Awards, five BAFTA Awards and five Golden Globe Awards. \"Time\" magazine named Winslet one of the 100 most influential people in the world in 2009 and 2021. She was appointed Commander of the Order of the British Empire (CBE) in 2012.\nWinslet studied drama at the Redroofs Theatre School. Her first screen appearance, at age fifteen, was in the British television series \"Dark Season\" (1991). She made her film debut playing a teenage murderess in \"Heavenly Creatures\" (1994), and went on to win a BAFTA Award for playing Marianne Dashwood in \"Sense and Sensibility\" (1995). Global stardom followed with her leading role in James Cameron's epic romance \"Titanic\" (1997), which was the highest-grossing film at the time. Winslet then eschewed parts in blockbusters in favour of critically acclaimed period pieces, including \"Quills\" (2000) and \"Iris\" (2001).\nThe science fiction romance \"Eternal Sunshine of the Spotless Mind\" (2004), in which Winslet was cast against type in a contemporary setting, proved to be a turning point in her career, and she gained further recognition for her performances in \"Finding Neverland\" (2004), \"Little Children\" (2006), \"The Holiday\" (2006), \"Revolutionary Road\" (2008), and \"The Reader\" (2008). For playing a former Nazi camp guard in the last, she won the BAFTA Award and the Academy Award for Best Actress. Winslet's portrayal of Joanna Hoffman in the biopic \"Steve Jobs\" (2015) won her another BAFTA Award. That same year Winslet won the AACTA Award for her performance in \"The Dressmaker\" (2015). For television, she received two Primetime Emmy Awards for her performances in the HBO miniseries \"Mildred Pierce\" (2011) and \"Mare of Easttown\" (2021). In 2022, she produced and starred in the single drama \"I Am Ruth\", winning two BAFTA TV Awards, and played a supporting role through motion capture in Cameron's top-grossing science fiction film \"\".\nFor her narration of a short story in the audiobook \"Listen to the Storyteller\" (1999), Winslet won a Grammy Award. She performed the song \"What If\" for the soundtrack of her film, \"\" (2001). A co-founder of the charity Golden Hat Foundation, which aims to create autism awareness, Winslet has also written a book on the topic. Divorced from film directors Jim Threapleton and Sam Mendes, Winslet has been married to businessman Edward Abel Smith since 2012. She has a child from each marriage, two of whom are the actors Mia Threapleton and Joe Anders.\nEarly life.\nKate Elizabeth Winslet was born on 5 October 1975 in Reading, Berkshire, to Sally Ann (n\u00e9e Bridges) and Roger John Winslet. Her mother worked as a nanny and waitress, while her father, a struggling actor, took labouring jobs to support the family. Her maternal grandparents were both actors and ran the Reading Repertory Theatre Company. Winslet has two sisters, Anna and Beth, both of whom are actresses, and a younger brother, Joss. The siblings are of British, Irish, and Swedish descent. The family had limited financial means; they lived on free meal benefits and were supported by a charity, the Actors' Charitable Trust. When Winslet was ten, her father severely injured his foot in a boating accident and found it harder to work, leading to more financial hardships for the family. Winslet has said her parents always made them feel cared for and that they were a supportive family.\nWinslet attended St Mary and All Saints' Church of England primary school. Living in a family of actors inspired her to pursue acting from a young age. She and her sisters participated in amateur stage shows at school and at a local youth theatre, named Foundations. When she was five, Winslet made her first stage appearance as Mary in her school's production of the Nativity play. She describes herself as an overweight child who was called \"blubber\" by her schoolmates and bullied for her appearance. She said she did not let this stop her.\nAt eleven, Winslet was accepted into the Redroofs Theatre School, an independent school in Maidenhead. The school also functioned as an agency and took students to London to audition for acting jobs. She appeared in a Sugar Puffs commercial and dubbed for foreign films. At school, she was made head girl, took part in productions of \"Alice's Adventures in Wonderland\" and \"The Lion, the Witch and the Wardrobe\", and played the lead role of Wendy Darling in \"Peter Pan\". She worked simultaneously with the Starmaker Theatre Company in Reading. She participated in over twenty of their stage productions, but was rarely selected as the lead due to her weight. Nonetheless, she played key roles as Miss Agatha Hannigan in \"Annie\", the Mother Wolf in \"The Jungle Book\", and Lena Marelli in \"Bugsy Malone\".\nIn 1991, within two weeks of finishing her GCSE examinations, Winslet made her screen debut as one of the main cast members of the BBC science fiction television series \"Dark Season\", written by Russell T Davies. Her part was that of Reet, a schoolgirl who helps her classmates fight against a sinister man distributing free computers to her school. She did not earn much from the job and, at age sixteen, lack of funds forced Winslet to leave Redroofs. To support herself, she worked at a delicatessen.\nCareer.\nEarly work and breakthrough (1992\u20131996).\nIn 1992, she had a small part in the television film \"Anglo-Saxon Attitudes\", an adaptation of Angus Wilson's satirical novel. Winslet, who weighed at the time, played the daughter of an obese woman. During filming, after hearing an off-hand comment from the director Diarmuid Lawrence about the likeness between her and the actress who played her mother, Winslet became motivated to lose weight. She next took on the role of the young daughter of a bankrupt self-made man (played by Ray Winstone) in the television sitcom \"Get Back\" (1992\u20131993). She also had a guest role in a 1993 episode of the medical drama series \"Casualty\".\nWinslet was among 175 women to audition for Peter Jackson's psychological drama \"Heavenly Creatures\" (1994), and was cast after impressing Jackson with the intensity she brought to her part. The New Zealand-based production is based on the Parker\u2013Hulme murder case of 1954, in which Winslet played Juliet Hulme, a teenager who assists her friend, Pauline Parker (played by Melanie Lynskey), in the murder of Pauline's mother. She prepared for the part by reading the transcripts of the girls' murder trial, their letters and diaries, and interacted with their acquaintances. She has said she learnt tremendously from the job. Jackson filmed in the real murder locations, and the experience left Winslet traumatised. She found it difficult to detach herself from her character, and said that after returning home, she often cried. The film was a critical breakthrough for Winslet; Desson Thomson, a reviewer for \"The Washington Post\", called her \"a bright-eyed ball of fire, lighting up every scene she's in\". Winslet recorded \"Juliet's Aria\" for the film's soundtrack. Also that year, she appeared as Geraldine Barclay, a prospective secretary, in the Royal Exchange Theatre production of Joe Orton's farce \"What the Butler Saw\".\nWhile promoting \"Heavenly Creatures\" in Los Angeles, Winslet auditioned for the minor part of Lucy Steele for a 1995 film adaptation of Jane Austen's novel \"Sense and Sensibility\", written by and starring Emma Thompson. Impressed by her reading, Thompson cast her in the much larger part of the recklessly romantic teenager Marianne Dashwood. The director Ang Lee wanted Winslet to play the part with grace and restraint\u2014aspects that he felt were missing from her performance in \"Heavenly Creatures\"\u2014and thus asked her to practise tai chi, read gothic literature, and learn to play the piano. David Parkinson of \"Radio Times\" considered Winslet to be a standout among the cast, and Mick LaSalle of the \"San Francisco Chronicle\" took note of how well she portrayed her character's growth and maturity. The film grossed over $134\u00a0million worldwide. She won the Screen Actors Guild and British Academy Film Award for Best Supporting Actress, and received an Academy Award nomination in the same category. Also in 1995, Winslet featured in the poorly received Disney film \"A Kid in King Arthur's Court\".\nWinslet had roles in two period dramas of 1996\u2014\"Jude\" and \"Hamlet\". As with \"Heavenly Creatures\", her roles in these films were those of women with a \"mad edge\". In Michael Winterbottom's \"Jude\", based on the novel \"Jude the Obscure\" by Thomas Hardy, she played Sue Bridehead, a young woman with suffragette leanings who falls in love with her cousin, Jude (played by Christopher Eccleston). The critic Roger Ebert believed the part allowed Winslet to display her acting range, and praised her for the defiance she brought to the role. After unsuccessfully auditioning for Kenneth Branagh's 1994 film \"Mary Shelley's Frankenstein\", she was cast in the part of Ophelia, the doomed lover of the title character, in Branagh's adaptation of the William Shakespeare tragedy \"Hamlet\". Twenty-year-old Winslet was intimidated by the experience of performing Shakespeare with established actors such as Branagh and Julie Christie, saying the job required a level of intellect that she thought she did not possess. Mike Jeffries of \"Empire\" believed that she had played the part \"well beyond her years\". Despite the acclaim, \"Jude\" and \"Hamlet\" earned little at the box office.\nWorldwide recognition and independent films (1997\u20132003).\nWinslet was keen on playing Rose DeWitt Bukater, a socialite aboard the ill-fated RMS \"Titanic\", in James Cameron's epic romance \"Titanic\" (1997). Cameron was initially reluctant to cast her, preferring the likes of Claire Danes and Gwyneth Paltrow, but she pleaded with him, \"You don't understand! I am Rose! I don't know why you're even seeing anyone else!\" Her persistence led him to give her the part. Leonardo DiCaprio featured as her love interest, Jack. \"Titanic\" had a production budget of $200\u00a0million, and its arduous principal photography was held at Baja Studios where a replica of the ship was created. Filming proved taxing for Winslet; she almost drowned, caught influenza, experienced hypothermia, and had bruises on her arms and knees. The workload allowed her only four hours of sleep per day and she felt drained by the experience. Writing for \"Newsweek\", David Ansen commended Winslet for capturing her character's zeal with delicacy, and Mike Clark of \"USA Today\" considered her to be the film's prime asset. Against expectations, \"Titanic\" went on to become the highest-grossing film to that point, earning over $2\u00a0billion in box office receipts worldwide, and established Winslet as a global star. The film won eleven Academy Awards\u2014tied for most for a single film\u2014including Best Picture, and earned the 22-year-old Winslet a nomination for Best Actress. She also received Golden Globe and SAG nominations for Best Actress.\nWinslet did not view \"Titanic\" as a platform for larger salaries. She avoided parts in blockbuster films in favour of independent productions that were not widely seen, believing that she \"still had a lot to learn\" and was unprepared to be a star. She later said her decision ensured career longevity. \"Hideous Kinky\", a low-budget drama shot before the release of \"Titanic\", was Winslet's sole film release of 1998. She turned down offers to star in \"Shakespeare in Love\" (1998) and \"Anna and the King\" (1999) to do the film. Based on the semi-autobiographical novel by Esther Freud, \"Hideous Kinky\" tells the story of a single British mother yearning for a new life in 1970s Morocco. Janet Maslin of \"The New York Times\" credited Winslet for her decision to follow-up \"Titanic\" with such an offbeat project and highlighted how well she captured her character's \"obliviousness and optimism\".\nJane Campion's psychological drama \"Holy Smoke!\" (1999) featured Winslet as an Australian woman who joins an Indian religious cult. She found the script brave and was challenged by the idea of playing an unlikeable, manipulative woman. She learnt to speak with an Australian accent and worked closely with Campion to justify her character's vileness. The film required her to perform explicit sex scenes with co-star Harvey Keitel, and featured a scene in which her character appears naked and urinates on herself. David Rooney of \"Variety\" wrote, \"Showing the kind of courage few young thesps would be capable of and an extraordinary range\u00a0... from animal cunning to unhinged desperation, [Winslet] holds nothing back.\" That same year, she voiced a fairy for the animated film \"Faeries\", and won the Grammy Award for Best Spoken Word Album for Children for narrating the short story \"The Face in the Lake\" for the children's audiobook \"Listen to the Storyteller\".\nIn \"Quills\" (2000), a biopic of the erratic Marquis de Sade, starring Geoffrey Rush and Joaquin Phoenix, Winslet played the supporting role of a sexually repressed laundress working in a mental asylum. Hailing her as the \"most daring actress working today\", James Greenberg of \"Los Angeles\" magazine praised Winslet for \"continuing to explore the bounds of sexual liberation\". She received a SAG Award nomination for Best Supporting Actress. The following year, she played a fictitious mathematician involved in the cracking of the Enigma ciphers in Michael Apted's espionage thriller \"Enigma\". Winslet's character was vastly expanded from a subsidiary love-interest in the novel it was based on to a prominent code-breaker in the film. She was pregnant while filming, and to prevent this from showing, she wore corsets under her costume.\nThe biopic \"Iris\" (2001) featured Winslet and Judi Dench as the novelist Iris Murdoch at different ages. The director Richard Eyre cast the two actresses after finding a \"correspondence of spirit between them\". Winslet was drawn to the idea of playing an intellectual and zesty female lead, and in research, she read Murdoch's novels, studied her husband's memoir \"Elegy for Iris\", and watched televised interviews of Murdoch. The project was filmed over four weeks and allowed Winslet to bring her daughter, who was six months old at the time, on set. Writing for \"The Guardian\", Martin Amis remarked that \"the seriousness and steadiness of [Winslet's] gaze effectively suggest the dawning amplitude of the Murdoch imagination\". She received her third Oscar nomination for \"Iris\", in addition to BAFTA and Golden Globe nominations for Best Supporting Actress.\nWinslet's third film release of 2001 was the animated film \"\", based on Charles Dickens' novel. For the film's soundtrack she recorded \"What If\", which proved to be a commercial hit. After a year-long absence from the screen, Winslet starred as a headstrong journalist interviewing a professor on death row in the thriller \"The Life of David Gale\" (2003). She agreed to the project to work with the director Alan Parker, whom she admired, and believed the film raised pertinent questions about capital punishment. Mick LaSalle thought the film had muddled the subject and disliked both the film and Winslet's performance.\nCareer progression (2004\u20132007).\nTo avoid typecasting in historical dramas, Winslet actively looked for roles in contemporary-set films. She found it in the science fiction romance \"Eternal Sunshine of the Spotless Mind\" (2004), in which she played a neurotic and impetuous woman who decides to erase memories of her ex-boyfriend (played by Jim Carrey). Unlike her previous assignments, the role allowed her to display the quirky side to her personality. Gondry encouraged Winslet and Carrey to improvise on set, and to keep herself agile she practised kickboxing. \"Eternal Sunshine of the Spotless Mind\" proved to be a modest financial success and several critics have regarded it as one of the best films of the 21st century. Peter Travers of \"Rolling Stone\" described it as a \"uniquely funny, unpredictably tender and unapologetically twisted romance\" and found Winslet to be \"electrifying and bruisingly vulnerable\" in it. A journalist for \"Premiere\" magazine commended her for abandoning her \"corseted English rose persona\", and ranked it as the 81st greatest film performance of all time. Winslet considers it to be a favourite among her roles, and she received Best Actress nominations at the Oscar and BAFTA award ceremonies. She has said the film marked a turning point in her career and prompted directors to offer her a wide variety of parts.\nHer next release of the year was the drama \"Finding Neverland\", about the relationship between J. M. Barrie (played by Johnny Depp) and the Llewelyn Davies boys, which inspired Barrie to write Peter Pan. Winslet was paid \u00a36\u00a0million to play the boys' mother, Sylvia, and despite her reluctance to star in another period piece, she agreed to the project after empathising with Sylvia's love for her children. Ella Taylor of \"LA Weekly\" found her to be \"radiant and earthy as ever\", and CNN's Paul Clinton thought she was \"exceptional in a delicate and finely tuned performance\". She received a second Best Actress nomination at that year's BAFTA Award ceremony. With a box office gross of $116\u00a0million, \"Finding Neverland\" became her most widely seen film since \"Titanic\".\nIn 2005, Winslet took on a guest role in an episode of the British comedy sitcom \"Extras\", starring Ricky Gervais and Stephen Merchant. She played a satirical version of herself in it\u2014an actress, who in an effort to win an Oscar, takes the role of a nun in a Holocaust film. She received a Primetime Emmy Award for Outstanding Guest Actress in a Comedy Series nomination. Within three months of giving birth to her second child, Winslet returned to work on \"Romance &amp; Cigarettes\", a musical romantic comedy directed by John Turturro, in which she played Tula, a promiscuous and foul-mouthed woman. The part required her to sing and dance, and it helped her lose weight gained during the pregnancy. She twisted her ankle while filming one of the dance sequences. Derek Elley of \"Variety\" wrote that despite her limited screen time, Winslet had \"the showiest role and filthiest one-liners\". She turned down an offer from Woody Allen to star in \"Match Point\" (2005) to spend more time with her children.\nWinslet had four film releases in 2006. She first appeared in \"All the King's Men\", a political thriller set in 1940s Louisiana, featuring Sean Penn and Jude Law. She played the supporting part of the love interest to Law's character. The film received negative reviews for its lack of political insight and narrative cohesiveness, and failed to recoup its $55\u00a0million investment. Her next release, the Todd Field drama \"Little Children\", was better received. Based on the novel of the same name, the film tells the story of Sarah Pierce, an unhappy housewife who has an affair with a married neighbour (played by Patrick Wilson). Winslet was challenged by the role of an uncaring mother, as she did neither understand nor respect her character's actions. Scenes requiring her to be hostile towards the child actress playing her daughter proved upsetting for her. Having borne two children, she was nervous about the sex scenes in which she had to be nude; she took on the challenge to present a positive image for women with, in her words, \"imperfect bodies\". A. O. Scott of \"The New York Times\" wrote that Winslet successfully \"registers every flicker of Sarah's pride, self-doubt and desire, inspiring a mixture of recognition, pity and concern\". Once again, she received BAFTA and Academy Award nominations for Best Actress; the latter making her, at 31, the youngest performer to accrue five Oscar nominations.\nAfter \"Little Children\", Winslet took on a part she found more sympathetic in Nancy Meyers's romantic comedy \"The Holiday\". She played a Briton who temporarily exchanges homes with an American (played by Cameron Diaz) during the Christmas holiday season. It became her biggest commercial success in nine years, grossing over $205\u00a0million worldwide. The critic Justin Chang found the film formulaic yet pleasing, and took note of Winslet's radiance and charm. In her final release of the year, she voiced Rita, a scavenging sewer rat, in the animated film \"Flushed Away\". Her sole project of 2007 was as the narrator for the English version of the French children's film \"The Fox and the Child\".\nAwards success (2008\u20132011).\nWinslet had two critically acclaimed roles in 2008. After reading Justin Haythe's script for \"Revolutionary Road\", an adaptation of Richard Yates's debut novel, Winslet recommended the project to her then-husband, director Sam Mendes, and her \"Titanic\" co-star Leonardo DiCaprio. The film traces the tribulations of a young married couple in 1950s suburban America. Winslet was drawn to the idea of playing a woman whose aspirations had not been met, and she read \"The Feminine Mystique\" to understand the psychology of unhappy housewives from the era. Mendes encouraged Winslet and DiCaprio to spend time together, and she believed the small set they used helped them to develop their characters' strained relationship. Hailing her as \"the best English-speaking film actress of her generation\", David Edelstein of \"New York\" magazine wrote that \"[t]here isn't a banal moment in Winslet's performance\u2014not a gesture, not a word.\"\nTo avoid a scheduling conflict with \"Revolutionary Road\", Winslet turned down an offer to star in \"The Reader\". After her replacement Nicole Kidman left the project due to her pregnancy, Winslet was signed to it. Directed by Stephen Daldry, \"The Reader\" is based on Bernhard Schlink's novel \"Der Vorleser\" and is about Hanna Schmitz, an illiterate Nazi concentration camp guard (Winslet), who has an affair with a teenage boy. Winslet researched the Holocaust and the SS guards. To educate herself on the stigma of illiteracy, she spent time with students at the Literacy Partners, an organisation that teaches adults to read and write. She was unable to sympathise with Schmitz and struggled to play the part honestly without humanising the character's actions. Despite this, some historians criticised the film for making Schmitz an object of the audience's sympathy and accused the filmmakers of Holocaust revisionism. Writing for \"Variety\", Todd McCarthy commended Winslet for \"suppl[ying] a haunting shell to this internally decimated woman,\" and Sukhdev Sandhu of \"The Daily Telegraph\" considered her to be \"absolutely fearless here, not just in her willingness to expose herself physically, but her refusal to expose her character psychologically.\"\nWinslet received significant awards attention for her performances in \"Revolutionary Road\" and \"The Reader\". She won a Golden Globe Award for each of these films, and for the latter, she was awarded the Academy Award and BAFTA Award for Best Actress. At age 33, she surpassed her own record as the youngest performer to accrue six Oscar nominations. She also became the third actress in history to win two Golden Globe Awards at the same ceremony. Exhausted by the media attention during this period, Winslet took two years off work until she was ready to creatively engage again.\nWinslet returned to acting with the five-part HBO series \"Mildred Pierce\" (2011), an adaptation of James M. Cain's novel from the director Todd Haynes. It is about the titular heroine (Winslet), a divorc\u00e9e during the Great Depression struggling to establish a restaurant business while yearning for the respect of her narcissistic daughter (played by Evan Rachel Wood). Winslet, who had recently divorced Mendes, believed certain aspects of her character's life mirrored her own. She was intimidated by the scope of the production, as she featured in every scene of the 280-page script. She was disturbed and upset by the story, and was particularly fascinated by the complex relationship between the mother-daughter pair. She collaborated closely with the production and costume designers, and learnt to bake pies and prepare chickens. The broadcast received a limited audience but gained positive reviews. Matt Zoller Seitz of \"Salon\" called the series a \"quiet, heartbreaking masterpiece\" and described Winslet's performance as \"terrific\u2014intelligent, focused and seemingly devoid of ego\". She won the Primetime Emmy Award, Golden Globe and SAG Award for Best Actress in a miniseries.\nThe ensemble thriller \"Contagion\" from Steven Soderbergh was Winslet's first film release of 2011. She was cast as a disease detective for the CDC, and she modelled her role on Anne Schuchat, the director of the NCIRD. \"Contagion\" was a commercial success, and David Denby of \"The New Yorker\" credited Winslet for capturing the essence of an exasperated woman. Her next project was the Roman Polanski-directed \"Carnage\", adapted from the play \"God of Carnage\" by Yasmina Reza. Set entirely inside an apartment, the black comedy follows two sets of parents feuding over their respective children. Jodie Foster, John C. Reilly, and Christoph Waltz co-starred. The cast rehearsed the script like a play for two weeks, and Winslet brought her children with her to Paris for the eight weeks of filming. Critics found the adaptation to be less compelling than the play, but praised the performances of Winslet and Foster. They both received Golden Globe nominations for it.\nCareer fluctuations (2012\u20132019).\nWinslet said her workload in 2011 helped her overcome heartbreak from her divorce, and after completing work on \"Carnage\" she took a break from acting to focus on her children. A short part that she had filmed four years prior for the anthology film \"Movie 43\" was her sole screen appearance of 2012, and it received the worst reviews of her career. Winslet also performed an audiobook recording of \u00c9mile Zola's novel \"Th\u00e9r\u00e8se Raquin\". She was reluctant to accept Jason Reitman's offer to star in his 2013 film adaptation of Joyce Maynard's novel \"Labor Day\", but agreed after Reitman postponed the production for a year to accommodate Winslet's commitment to her children. Set over a Labor Day weekend, it tells the story of Adele (Winslet), an agoraphobic single mother who falls in love with an escaped convict. Describing Adele's characterisation as having \"more vulnerability than strength\", Winslet found her a departure from the strong-willed women she typically played. A scene in the film required her to make a pie, for which she drew on her baking experience from \"Mildred Pierce\". Reviews of the film were negative; Chris Nashawaty of \"Entertainment Weekly\" dismissed it as \"mawkish and melodramatic\" but credited Winslet for adding layers to her passive role. She received her tenth Golden Globe nomination.\nThe novelty of playing a villain drew Winslet to the part of Jeanine Matthews in the science fiction film \"Divergent\" (2014). Set in a dystopian future, the adaptation of Veronica Roth's young adult novel stars Shailene Woodley as a heroine fighting an oppressive regime headed by Winslet's character. She was pregnant with her third child during production, and her tight-fitting costumes had to be altered to accommodate the pregnancy. To maintain her character's intimidating persona, she remained aloof from her co-stars for much of the filming. Richard Lawson of \"Vanity Fair\" compared the film unfavourably to the \"Hunger Games\" series, and found Winslet to be underutilised in it. The film grossed $288\u00a0million worldwide. \"A Little Chaos\" marked her return to the period film genre. Directed by Alan Rickman, it is about a rivalry among gardeners commissioned to create a fountain at the Palace of Versailles. Winslet's role was that of fictional architect Sabine de Barra, a character she believed had overcome extreme grief and hardship like herself. Catherine Shoard of \"The Guardian\" took note of the \"emotional honesty\" Winslet brought to her part, but criticised the implausibility of her role. Also that year, she read audiobooks of Roald Dahl's children's novels \"Matilda\" and \"The Magic Finger\".\nIn 2015, Winslet reprised the role of Jeanine Matthews in the second instalment of the \"Divergent\" series, subtitled \"\", which despite negative reviews grossed $297\u00a0million worldwide. Her next film, an adaptation of the Australian gothic novel \"The Dressmaker\", was described by the director Jocelyn Moorhouse as being reminiscent of the western \"Unforgiven\" (1992). Winslet starred as the femme fatale Tilly Dunnage, a seamstress who returns to her hometown years after she was accused of murder. She learnt to sew for the part and designed some of her own costumes. The project was filmed in the Australian desert and she found it difficult to wear couture dresses in the harsh weather. Despite disliking the film, Robert Abele of the \"Los Angeles Times\" credited Winslet for underplaying her over-the-top part. The film emerged as one of the highest-grossing Australian films of all time, but earned little elsewhere. Winslet won the AACTA Award for Best Actress.\nWhile filming \"The Dressmaker\", Winslet became aware of a forthcoming Steve Jobs biopic written by Aaron Sorkin and directed by Danny Boyle. Keen to play Jobs's marketing chief and confidante Joanna Hoffman, she sent a picture of herself dressed as Hoffman to the film's producer. \"Steve Jobs\", starring Michael Fassbender in the title role, is told in three acts, each depicting a key milestone in Jobs's career. In preparation, Winslet spent time with Hoffman, and worked with a dialect coach to speak in Hoffman's accent, a mixture of Armenian and Polish, which she considered to be the most difficult of her career. The cast rehearsed each act like a play and filmed it in sequence. Winslet collaborated closely with Fassbender, and their off-screen relationship mirrored the collegial dynamic between Jobs and Hoffman. The film earned her some of the best reviews of her career, though it was a box-office flop. Peter Howell of the \"Toronto Star\" commended Winslet for finding \"strength and grace\" in her part, and Gregory Ellwood of HitFix thought she improved on Hoffman's characterisation. She won the Golden Globe and BAFTA Awards for Best Supporting Actress, and received her seventh Oscar nomination.\nJohn Hillcoat's ensemble crime-thriller \"Triple 9\" (2016) featured Winslet as Irina Vlaslov, a ruthless Russian-Israeli gangster. The critic Ann Hornaday of \"The Washington Post\" felt Winslet had failed to effectively portray her. Her next release of the year, \"Collateral Beauty\", about a man (played by Will Smith) struggling with the death of his daughter, was panned by critics. Writing for \"Vulture\", Emily Yoshida dismissed the film as a vacuous remake of \"A Christmas Carol\" and added that Winslet had \"never looked more painted and tired\". It was a modest earner at the box office. Winslet agreed to the romantic disaster film \"The Mountain Between Us\" (2017) to take on the challenge of a role requiring physical exertion. It featured her and Idris Elba as two strangers who crash land on an icy and isolated mountain range. They filmed in the mountains of Western Canada at above sea level where the temperature was well below freezing. Winslet performed her own stunts and described it as the most physically gruelling experience of her career. Moira Macdonald of \"The Seattle Times\" opined that the duo's charisma and chemistry enhanced a mediocre film.\nWoody Allen's \"Wonder Wheel\", a drama set in 1950s Coney Island, was Winslet's final release of 2017. She played Ginny, a temperamental housewife having an affair with a lifeguard (played by Justin Timberlake). She described Ginny as permanently dissatisfied and uneasy, and playing her proved difficult for Winslet, who experienced anxiety. Manohla Dargis of \"The New York Times\" disliked Allen's writing but credited Winslet for filling her \"shabby character with feverish life\". When asked during the film's promotion about her decision to work with Allen despite an allegation of child sexual abuse against him, Winslet chose not to comment on the filmmaker's personal life but said she was pleased with the collaboration. She would later go on to express regret over working with both Allen and Roman Polanski. In 2019, Winslet provided her voice to \"Moominvalley\", an animated television series about the Moomins, and took on a leading role alongside Susan Sarandon and Mia Wasikowska in \"Blackbird\", a remake of the Danish film \"Silent Heart\" (2014). Benjamin Lee of \"The Guardian\" dismissed it as \"less of a film and more of an actors' workshop\" and found Winslet miscast.\nResurgence and expansion (2020\u2013present).\nWinslet portrayed paleontologist Mary Anning in \"Ammonite\" (2020), a period drama about a romance between Anning and Charlotte Murchison (played by Saoirse Ronan) set in 1840s England. She dropped out of Wes Anderson's \"The French Dispatch\" to have more preparation time for the project. She collaborated closely with Ronan, and they choreographed their own sex scenes. For much of the filming, she lived in isolation in a rented cottage in Dorset, where the film was shot, to get into her character's headspace. Caryn James of the BBC credited Winslet for portraying Anning as \"stern and brittle but immensely sympathetic\" and considered her \"contained, potent performance\" to be one of the best of her career, and Manuel Betancourt of \"New York\" magazine welcomed it as a \"return to form\". She next voiced the titular horse in a film adaptation of the novel \"Black Beauty\", which was released on Disney+.\nIn 2021, Winslet executive produced and starred in \"Mare of Easttown\", an HBO miniseries about a troubled police detective solving a murder case. Set in Delaware County, Winslet insisted on using the \"Delco accent\", a version of Philadelphia English used in the county; she considered it to be one of the hardest accents she has had to learn. To play Mare, a woman who has lost a child to suicide, she created a backstory for her character and collaborated closely with a grief counsellor. The series and Winslet's performance received critical acclaim; Richard Roeper wrote that she \"adds to a long list of magnificent, disappear-into-the-character performances\" and Lucy Mangan of \"The Guardian\" opined, \"If you can have a defining performance this late in a career, this is surely Winslet's.\" \"Mare of Easttown\" proved to be a ratings hit for HBO, and Winslet once again won the Primetime Emmy, Golden Globe, and SAG Awards for Best Actress in a miniseries.\nFollowing \"Mare of Easttown\", Winslet took a year off work to spend time with her family. She narrated the documentary \"Eleven Days in May\" (2022), about the 2021 bombing of Gaza by Israel. She starred with her daughter Mia Threapleton in an improvised feature-length episode of the Channel 4 anthology series \"I Am...\", titled \"I Am Ruth\", about the negative effects of social media, which she developed and co-authored with director Dominic Savage. She won two BAFTA TV Awards for Best Actress and Best Single Drama (as producer). In her acceptance speech, she urged lawmakers to criminalise harmful digital content. In 2017 and 2018, Winslet concurrently filmed two sequels to James Cameron's science fiction film \"Avatar\" (2009) using motion capture technology. She learnt freediving for her role and was able to hold her breath underwater for seven minutes, setting a new record for any film scene shot underwater. Released in 2022, \"\" earned over $2\u00a0billion to rank as the third highest-grossing film of all time and Winslet's second film after \"Titanic\" to cross the $2\u00a0billion mark.\nAfter being attached to a biopic of model and war photographer Lee Miller for eight years, Winslet produced and starred in \"Lee\" (2023). She hired cinematographer Ellen Kuras (who had filmed her in \"Eternal Sunshine of the Spotless Mind\") to make her feature directorial debut with the project. Winslet slipped and fell while filming, leading to three haematomas on her spine; she continued working despite the pain. Reviewers for \"The Hollywood Reporter\" and \"The Daily Beast\" noted how much Winslet's performance helped elevate a conventional biopic. Winslet next executive produced and starred in the HBO miniseries \"The Regime\" (2024), a satire about a fictional authoritarian country. To play a megalomaniac dictator, she consulted a neuroscientist and a psychotherapist to create a backstory for her character. Critics deemed her performance superior to the series. She earned Golden Globe nominations for her performances in both \"Lee\" and \"The Regime\", in addition to a BAFTA nomination for Outstanding British Film as a producer on \"Lee\".\nWinslet will next reprise her role in the sequel \"\". She is set to make her directorial debut with the Netflix drama film \"Goodbye June\", written by her son Joe Anders, in which she will also star and produce. \nReception and acting style.\nJournalists consider Winslet to be among the finest actresses of her generation. Despite achieving stardom early in her career with the blockbuster \"Titanic\", she has rarely acted in commerce-driven films. A journalist for \"Elle\" believes that her choices reflect the \"soul and attitude of a jobbing actress, trapped in the body of a movie star\". Winslet was voted one of the 50 greatest actors of all time in a 2022 readers' poll by \"Empire\"; the magazine termed her \"a dramatic force, turning her hand to all kinds of periods and genres with an inimitable sense of dignity and strength\". In 2025, \"The Independent\" named her the 45th-greatest actor of the 21st century.\nWinslet belongs to a group of esteemed British actresses who are typically showing \"restraint, rendering emotions through intellect rather than feelings, and a sense of irony, which demonstrates the heroine's superior understanding\". Tom Perrotta, the author of \"Little Children\", has said that Winslet \"gravitates toward troubling roles in smaller films\", typically those of \"thorny, potentially unsympathetic\" women. The journalist Mark Harris writes that she specialises in \"unsentimentalized, restless, troubled, discontented, disconcerted, difficult women\" and John Hiscock of \"The Daily Telegraph\" has identified a theme of characters who are free-spirited with a sexual edge to them. Anthony Lane of \"The New Yorker\" associates Winslet with stubbornness, writing that \"the set of her jaw and the blaze of her glance suggest a self-freeing spirit who knows the path ahead and is determined to take it\". Stephen Whitty of NJ.com associates Winslet with \"serious, almost despairing material\", although he finds it hard to pigeonhole her as an actress. Josephine Livingstone of \"The New Republic\", however, finds Winslet unconvincing in roles where she has \"no real emotional vulnerability\", believing she is most compelling when she has \"the opportunity to get hysterical\".\u00a0\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"I can't just learn my lines and do [my job], but perhaps that's because I don't want to act, I want to be. And I do think there's a difference.\"\n\u2014Winslet on acting\nLeonardo DiCaprio, her co-star in \"Titanic\" and \"Revolutionary Road\", considers Winslet to be \"the most prepared and well-researched actor on set\", and Jude Law, her co-star in \"The Holiday\", believes that despite her seriousness she remains \"very calm and good-natured\". Her \"Steve Jobs\" director Danny Boyle has identified a willingness in Winslet to avoid typecasting and said that she takes an effort \"to reposition directors' and producers' perspective on her\" to allow herself to be challenged as an artist.\nWinslet has said she is interested in playing \"angst-ridden women\" with strong dispositions masking flaws and insecurities, and that she connects with \"women who are either finding their way out of a situation, looking for love, having some struggle within love, or questioning the big things in life\". Drawn to parts that are in tandem with her personal struggles at certain points in her life, she finds it difficult to detach herself from her roles, saying that \"you have to confront your true feelings every single day. And that's pretty exhausting. Then you have to go home and make dinner\". Even so, she finds it therapeutic to perform. Winslet is known for her willingness to perform nude scenes, having done so in over a dozen of her films, although she considers its contribution to the narrative before agreeing to it. She believes that such scenes promote a positive body image amongst women.\nPersonal life.\nWhile filming \"Dark Season\", a fifteen-year-old Winslet began a romantic relationship with actor-writer Stephen Tredre, who was twelve years her senior. She considered him a major influence in her life and they lived together in London from 1991. They broke up in 1995, but remained close until Tredre died of bone cancer two years later. Winslet decided not to attend the premiere of \"Titanic\" to attend his funeral. In 2008, she said that she had not overcome his death.\nA year after Tredre's death, Winslet met Jim Threapleton on the set of \"Hideous Kinky\", on which he served as an assistant director. They married in November 1998 at her family's local church, and their daughter, Mia, was born in 2000. Describing her marriage to Threapleton as a \"mess\", Winslet later said that she lost control of her instincts during this period. They divorced in 2001.\nSoon after separating from Threapleton, she met director Sam Mendes when he offered her a part in a play; she turned down the offer but began dating him. Dismayed at how the British tabloids portrayed her personal life, Winslet relocated to New York City. She married Mendes in May 2003 on the island of Anguilla, and their son, Joe, was born later that year. The family divided their time in New York with frequent visits to their estate in the Cotswolds, England. Amid intense media speculation of an affair between Mendes and actress Rebecca Hall, he and Winslet announced their separation in 2010 and were divorced a year later. She reported being heartbroken by the split, but affirmed her determination to look after her children in spite of her marital break-up. In 2010, Winslet moved with her children from New York City to England in order to avoid paparazzi.\nWhile holidaying at Richard Branson's estate on Necker Island in 2011, Winslet met his nephew Edward Abel Smith (legally known as Ned Rocknroll from 2008 to 2019), the then-head of marketing promotion and astronaut experience at Virgin Galactic, during a house fire. They married in December 2012 in New York, and their son, Bear, was born the following year. Following their wedding, Abel Smith became a stay-at-home dad helping Winslet raise her children, and also helping her practice her lines despite being severely dyslexic. He later added \"Winslet\" as one of his middle names. After moving back to England, Winslet purchased a property worth \u00a33.25\u00a0million by the sea in West Wittering, Sussex, where she lives with Abel Smith and her children as of 2015[ [update]]. In a 2015 interview, she commented on how much she enjoyed living in the countryside.\nWinslet has stated that despite three marriages and a family structure that might be perceived by some as \"unconventional\", she does not consider it to be any \"less of a family\". She turns down offers of work that otherwise would take her away from her children for too long, and likes to schedule her filming commitments around their school holidays. Discussing her parenting style, she said she enjoys packing lunches and doing the school run.\nActivism and charity.\nWinslet has lent her support to several charities and causes, along with financial donations and items for auctions. In 2006, she became a patron of a Gloucester-based charity, the Family Haven, which provides counselling services to vulnerable families. The same year, hand-made envelopes designed by Winslet were auctioned for the \"Pushing the Envelope\" campaign created by the National Literacy Trust. Winslet was one of the celebrities to participate in a 2007 auction to raise funds for the Afghanistan Relief Organization. In 2009, she contributed to the Butterfly Book, a compilation of doodles made by several celebrities, to raise money for leukaemia research. Also that year, Winslet, along with Leonardo DiCaprio, James Cameron, and Celine Dion, contributed $30,000 to support Millvina Dean, the last living \"Titanic\" survivor at the time. The funds covered nursing home fees in the UK where Dean resided.\nIn 2009, Winslet narrated the English version of an Icelandic documentary named \"A Mother's Courage: Talking Back to Autism\", about Margret Ericsdottir, whose child Keli Thorsteinsson has non-verbal autism. Inspired by the story, she teamed with Ericsdottir in 2010 to form an NGO named the Golden Hat Foundation. The organisation aims to create autism awareness and was named after a poem written by Thorsteinsson. As the ambassador for the luxury brands Lanc\u00f4me and Longines, Winslet partnered with these companies to raise awareness and funds for the foundation. She created a make-up collection for Lanc\u00f4me in 2011 and, in 2017, she designed a new watch for Longines.\nIn 2012, Winslet wrote a book about autism, entitled \"The Golden Hat: Talking Back to Autism\", which was published by Simon &amp; Schuster. It contains correspondence between Winslet and Ericsdottir, personal statements from various celebrities, and contributions from Thorsteinsson. A reviewer for \"Publishers Weekly\" praised the book for its \"warmth and sincerity\". The United Nations featured the book during a ceremony on the World Autism Awareness Day of 2012. For her work with the Golden Hat Foundation, Winslet received Spain's Yo Dona award for Best Humanitarian Work.\nWinslet narrated a video for PETA in 2010 that showed animal cruelty in the production of foie gras. She encouraged chefs to remove the item from their menu and urged consumers to boycott it. In 2015, she lent her support to the UNICEF campaign World's Largest Lesson, which creates awareness among children about sustainable development and global citizenship. Teased as a child for her weight, Winslet takes a stand against body-shaming and bullying. She narrated an Australian animated short film named \"Daisy Chain\" (2015), about a victim of cyberbullying. In 2017, Winslet teamed with Leonardo DiCaprio's environmental foundation for a fundraiser on global warming. Also that year, she and DiCaprio auctioned a private dinner with themselves to raise money for a British woman's cancer treatment. Winslet teamed with Lanc\u00f4me and the National Literacy Trust in 2018 to launch a programme that aims to educate underprivileged women in the UK. In 2020, Winslet read a bedtime story as part of \"Save with Stories\" to raise funds for Save the Children's Emergency Coronavirus Appeal. In 2021, Winslet commented on homophobia in Hollywood, saying that she knew actors \"who are terrified their sexuality will be revealed and that it will stand in the way of their being cast in straight roles\". In 2025, Winslet was appointed as an ambassador for The King's Foundation.\nPublic image.\nIn a 2015 article for \"Elle\", Sally Holmes described Winslet's ability to establish rapport with her manner. Jo Ellison of \"Vogue\" writes that she has an \"authoritative, almost ambassadorial aura\", and Kira Cochrane of \"The Guardian\" considers her to be \"articulate, sophisticated, [with] a definite hint of grandeur\". Describing Winslet as plain-spoken, Krista Smith of \"Vanity Fair\" believes that despite her stardom she is unpretentious.\nWinslet's weight fluctuations over the years have been well-documented by the media. She has been outspoken in her refusal to allow Hollywood to dictate her weight. In 2003, the British edition of \"GQ\" magazine published photographs of Winslet which had been digitally altered to make her look thinner and taller. She said the alterations were made without her consent, and \"GQ\" subsequently issued an apology. In 2007, Winslet won a libel case against \"Grazia\" magazine after it claimed she had visited a dietitian. She claimed \u00a310,000 in damages, and donated the amount to an eating disorder charity. She won another case in 2009 against the British tabloid \"Daily Mail\" after it claimed she had lied about her exercise regimen. She received an apology and a payout of \u00a325,000.\nWinslet was included on \"People\" magazine's \"Most Beautiful People\" listing in 2005. Her beauty and sex appeal have been picked up by several other publications, including \"Harper's Bazaar\", \"Who\", and \"Empire\" magazines. She has said she does not subscribe to the beauty ideal of Hollywood, and uses her celebrity to empower women to accept their appearance with pride. She has spoken against Botox and plastic surgery. In an effort to encourage natural ageing, she formed the British Anti-Cosmetic Surgery League, alongside fellow actresses Emma Thompson and Rachel Weisz. She instructs magazines and brands not to digitally smooth her wrinkles in photographs. Winslet is reluctant to discuss the gender pay gap in the film industry, as she dislikes speaking publicly about her salary. She has expressed an aversion to elaborate press junkets and red carpet events, terming them a waste of money.\nIn 2009, \"Forbes\" reported her annual salary to be $2\u00a0million, a majority of that stemming from her endorsement deals. Also that year, the UK Film Council calculated that she had earned \u00a320\u00a0million from her acting roles since 1995. She was named one of the 100 most influential people in the world by \"Time\" magazine in 2009 and 2021. Madame Tussauds in London unveiled a wax statue of Winslet in 2011. The following year, she received the Honorary C\u00e9sar award, and in 2014, she received a star on the Hollywood Walk of Fame. Winslet was appointed Commander of the Order of the British Empire (CBE) in the 2012 Birthday Honours for her services to drama.\nActing credits and awards.\nProlific in film since 1994, Winslet's most acclaimed and highest-grossing films, according to the online portal Box Office Mojo and the review aggregate site Rotten Tomatoes, include \"Heavenly Creatures\" (1994), \"Sense and Sensibility\" (1995), \"Hamlet\" (1996), \"Titanic\" (1997), \"Eternal Sunshine of the Spotless Mind\" (2004), \"Finding Neverland\" (2004), \"The Holiday\" (2006), \"Contagion\" (2011), \"Divergent\" (2014), ' (2015), \"Steve Jobs\" (2015), and ' (2022). Her television projects include the miniseries \"Mildred Pierce\" (2011) and \"Mare of Easttown\" (2021).\nWinslet has been recognised by the Academy of Motion Picture Arts and Sciences for the following performances:\nWinslet has won five BAFTA Awards: Best Actress in a Leading Role for \"The Reader\" (2008); Best Actress in a Supporting Role for \"Sense and Sensibility\" (1995) and \"Steve Jobs\" (2016); Best Leading Actress and Best Single Drama for \"I Am Ruth.\" She has also won two Primetime Emmy Awards for Outstanding Actress in a Leading Role in a Limited or Anthology Series or Movie for \"Mildred Pierce\" (2011), and \"Mare of Easttown\" (2021) as well as the Grammy Award for Best Spoken Word Album for Children for narrating the children's audiobook \"Listen to the Storyteller\" (1999). Winslet is the recipient of five Golden Globe Awards from the Hollywood Foreign Press Association, winning Best Supporting Actress \u2013 Motion Picture for \"The Reader\" and \"Steve Jobs\", Best Actress in a Motion Picture \u2013 Drama for \"Revolutionary Road\", and Best Actress in a Miniseries or Motion Picture \u2013 Television for \"Mildred Pierce\" and \"Mare of Easttown\". She is among the few actresses to have won three of the four major American entertainment awards.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52708", "revid": "14965160", "url": "https://en.wikipedia.org/wiki?curid=52708", "title": "Republic of the Seven United Provinces", "text": ""}
{"id": "52709", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=52709", "title": "Republic of the Seven United Netherlands", "text": ""}
{"id": "52710", "revid": "32580781", "url": "https://en.wikipedia.org/wiki?curid=52710", "title": "Brazzaville", "text": "Capital and the largest city of the Republic of the Congo\nBrazzaville () is the capital and largest city of the Republic of the Congo. Administratively, it is a department and a commune. Constituting the financial and administrative centre of the country, it is located on the north side of the Congo River, opposite Kinshasa, the capital city of the Democratic Republic of the Congo (DR Congo).\nThe population of the capital is estimated to exceed 2.1 million residents, comprising more than a third of the national populace. Some 40% are employed in non-agricultural professions. During World War II, Brazzaville served as the de facto capital of Free France between 1940 and 1942.\nIn 2013, Brazzaville was designated a City of Music by UNESCO; since then it has also been a member of the Creative Cities Network.\nToponymy.\nThe prefix \"Brazza\" comes from the surname of the Italian count Pierre Savorgnan de Brazza, who worked on exploration expeditions for France and is credited with founding the town.\nThe place name Brazzaville unintentionally has the literal meaning of \"City of the Armed Wing\". The surname Brazza refers to the village of Brazzacco, in the commune of Moruzzo, Italy, whose name derives from the latin \"bracchium\", meaning \"armed wing\".\nIn the Kongo language it has the names or variants of \"Ntamo\", \"Ntambo\", \"Kintamo\", \"Kintambo\", \"Tandala\", \"Mavula\" and in the Teke languages \"M'fa\", \"Mfaa\", \"Mfa\", \"Mfoa\".\nGeography.\nBrazzaville covers a large area to the north of the Congo River, just below the Pool Malebo. Mbamu, a large island within the Pool, is part of the Republic of Congo's territory.\nBrazzaville is inland from the Atlantic Ocean and approximately south of the equator. Around the city are large plains. The town is relatively flat, and situated at an altitude of . Downriver the Congo has numerous rapids, known as Livingston Falls, preventing navigation upriver to this point from its mouth at the Atlantic.\nKinshasa, the capital of the Democratic Republic of the Congo, is located on the southern bank of the Congo, directly across from Brazzaville. To distinguish between the two African countries that have \"Congo\" in their names, the Republic of the Congo is sometimes called Congo-Brazzaville, as opposed to Congo-Kinshasa. Kinshasa is more than five times larger than Brazzaville in population. This is the only place in the world where two national capital cities developed on opposite banks of a river, within sight of each other.\nIn March 2018, the \"Brazzaville Declaration\" was signed to promote better management and conservation of the Cuvette Centrale, a region in Congo Basin and primarily in DRC. It is the world's largest tropical peatland, made up of swamp forests. Conservation of this area is important for the survival of megafauna, and also critical to the world's climate. Burning the peat would release too much carbon and raise the Earth's temperature. The declaration to save peatlands as the world's largest terrestrial organic carbon stock was signed by Democratic Republic of the Congo, the Republic of the Congo, and Indonesia, which also has peatlands.\nHistory.\nIn precolonial times, the location of the modern-day city of Brazzaville was inhabited by two trading centres, Mfwa and Mpila, which were part of the Tio Kingdom (the Eastern Teke).\nBrazzaville was founded by the French colonial empire upon an existing indigenous Bateke settlement called Ncuna, during the Scramble for Africa when European nations established spheres of influence on the continent. The Italian-born explorer Pierre Savorgnan de Brazza, who was granted French citizenship in 1874, officially founded the settlement on 10 September 1880; it commemorates his name.\nThe Tio king, Iloo I, signed a treaty of protection with Brazza, which subjugated his lands to the French Empire. From October 1880 until May 1882, a small squad of troops led by Senegalese Sergeant Malamine Camara occupied the site, in order to prevent the land from falling into Belgian hands. Their forces were active on the south side of the river, where King Leopold II ruled the Belgian Congo for a period as a private holding. The first large-scale building work of the city began four years later, as the French competed with L\u00e9opoldville (now Kinshasa) which Belgian colonists were developing on the south side of the river.\nThe Berlin Conference of 1884 placed French control over this area on an official footing. The city became the capital of the French Congo in 1904. It continued as capital when French Equatorial Africa was founded in 1910, as a federation of French colonial states: it included Gabon, the Central African Republic, and Chad until 1960. From 1910 to 1915 the major municipal buildings were constructed, including a courthouse and headquarters for the Banque de l'AEF and Institut Pasteur.\nIn 1934, the Congo\u2013Ocean Railway opened, linking Brazzaville with the Atlantic port of Pointe-Noire and bypassing the rapids on the Congo River. Construction of the railway resulted in the deaths of more than 17,000 Africans, and the people revolted against the French in 1928.\nDuring World War II, Brazzaville and the rest of French Equatorial Africa remained beyond the control of Vichy France, which served the Nazi occupation. The city served as the capital of Free France from 1940 to 1943. In 1944, Brazzaville hosted a meeting of the French resistance forces and representatives of France's African colonies. The resulting Brazzaville Declaration represented an attempt to redefine the relationship between France and its African colonies.\nUntil the 1960s, the city was divided into European (the centre of the city) and African sections (Poto-Poto, Bacongo, and Mak\u00e9l\u00e9k\u00e9l\u00e9). In 1980, it became a \"commune\" separated from the surrounding Pool Department and divided into nine \"arrondissements\" along the French model of administration.\nSince the late 20th century, the city has frequently been a staging ground for wars, including internal conflicts between rebel and government forces. It has been a base of conflicts between forces of the Republic of the Congo, the Democratic Republic of the Congo (DRC), and Angola. During the 1990s, civil wars resulted in thousands of civilian deaths here and forced hundreds of thousands of refugees to flee the city.\nMore recently thousands of people leaving the DRC have made their way to Brazzaville; the local United Nations force and the DRC government have accused the city of deporting thousands of these refugees.\nIn April 2016 fighting occurred between police and local militia units, with at least 18 people killed.\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nAs of the 2023 census, the city had a population of 2.15 million.\nThe National Institute of Statistics for 2014 is 1.73 million. Kinshasa, DRC, had more than 10 million inhabitants in 2014.\nTogether with Kinshasa, the combined conurbation of Kinshasa-Brazzaville has about 12 million inhabitants. Significant political and infrastructure challenges prevent the two cities from functioning with any meaningful connection. \nSince the mid-19th century, the two cities have been rivals in trade, sports and power. There have been proposals to connect the two capitals by a Brazzaville\u2013Kinshasa Bridge. In 2018, with relative peace re-established in the region, the African Development Bank and Africa50 signed a deal with both governments to develop the project.\nGovernment.\nBrazzaville, like Pointe-Noire, is a commune (municipality) contained within a department of the same name. It is governed by a municipal council and a departmental council. The mayor is the president of the municipal council.\nThe commune of Brazzaville is divided into nine \"arrondissements\" (boroughs), each with an official number:\nThe department of Brazzaville includes the area of the commune and, since 2011, the new district of Ile Mbamou. In October 2024, the department absorbed the commune of Kint\u00e9l\u00e9, which was previously part of the department of Pool.\nEconomy.\nThe location of Brazzaville near the pool of the Congo River enabled it to grow as an industrial, trading and port settlement. It was connected through trade by ships and boats traveling upriver to inland areas, which produced raw materials from the beginning of the colonial period. Construction of the railway connecting to Pointe-Noire increased the ability of city businessmen to get their products to the port for export. Industries present in Brazzaville include machine shops, textiles, tanning, and manufacturing. As a key port on the Congo River, Brazzaville still takes deliveries of raw materials, such as rubber, wood, and agricultural products. From here they are generally sent onward to Pointe-Noire for export.\nMany companies, government organizations and NGOs have regional offices in the capital city, where they can work with government officials. The World Health Organization has its regional office for Africa located in Brazzaville. Companies headquartered in Brazzaville include Equatorial Congo Airlines and the mobile operator Warid Congo.\nCulture.\nRoger Erell, a highly regarded architect, designed a house in the city for Charles de Gaulle when he was the leader of Free France here. Other buildings include the Pierre Savorgnan de Brazza Mausoleum, the Nabemba Tower, and the Congressional Palace (Brazzaville).\nThe Marien Ngouabi Mausoleum, Brazzaville Zoo, and the Poto-Poto School of Painting are also destinations for visitors and city residents.\nPlaces of worship.\nMany Congolese converted to Catholicism during the French colonial period. Christian churches are most prevalent in the city, where the Roman Catholic Church has an archdiocese. Since then, churches have been established by new immigrants and by local adoption of evangelical Protestantism. Examples include the Basilica of Sainte-Anne-du-Congo in Brazzaville, Greek Orthodox Archdiocese of Brazzaville and Gabon (Patriarchate of Alexandria and All Africa), Evangelical Church of Congo (World Communion of Reformed Churches), and Assemblies of God.\nEducation.\nThe Marien Ngouabi University is a public university in Brazzaville, named after a former leader. The university was founded in December 1971 after independence. Today it has approximately 26,000 students.\nInternational schools:\nClimate.\nBrazzaville features a tropical wet and dry climate. Its wet season, which runs from October\u2013May, is longer than its dry season, which covers the remaining months. Brazzaville's driest months, July and August, on average have no significant precipitation. Since Brazzaville is south of the equator, its dry season begins at around its \"winter\" solstice, which is the month of June. The city has relatively consistent temperatures throughout the course of the year.\nTransport.\nThe city is home to Maya-Maya Airport, which lies in the centre of the city and which has regular flights to Pointe-Noire as well as international destinations in Africa, Europe and the Middle East. A flight operates twice weekly between Brazzaville and Kinshasa, but the flight time is only five minutes.\nThe Congo-Ocean Railway has a station in the city and in 2014 was operating the \"La Gazelle\" train service every other day to Pointe-Noire and intermediate destinations.\nThe city is an important river port, with ferries sailing to Kinshasa and to Bangui via Impfondo. Ferries and fast private boats serve as the primary means of connection between Kinshasa and Brazzaville. The Livingstone Falls lie on the outskirts of the city, where the Djou\u00e9 River meets the Congo, rendering river transport to the coast impossible, qualifying the railway as a portage railway.\nAlthough there is no organised public transport system, privately owned buses are available in the capital.\nTaxis are available on every street and are easily recognized, being painted with a green body and white top, and the fare for a short trip is CF700. About twenty percent of the vehicles in Brazzaville are taxis. There are also collective taxis that drive certain routes and charge CF150.\nA road-rail bridge is proposed to connect Brazzaville with Kinshasa. The rail gauge on both sides is the same at 1067mm.\n\"See \"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52711", "revid": "42151856", "url": "https://en.wikipedia.org/wiki?curid=52711", "title": "Leonardo DiCaprio", "text": "American actor and producer (born 1974)\nLeonardo Wilhelm DiCaprio (; ; born November 11, 1974) is an American actor and film producer. Known for his work in biographical and period films, he is the recipient of numerous accolades, including an Academy Award, a British Academy Film Award, and three Golden Globe Awards. As of 2019,[ [update]] his films have grossed over $7.2\u00a0billion worldwide, and he has been placed eight times in annual rankings of the world's highest-paid actors.\nBorn in Los Angeles, DiCaprio began his career in the late 1980s by appearing in television commercials. He had a recurring role in the sitcom \"Parenthood\" (1990\u20131991), and had his first major film part as author Tobias Wolff in \"This Boy's Life\" (1993). He received critical acclaim and his first Academy Award nomination for playing a developmentally disabled boy in \"What's Eating Gilbert Grape\" (1993). DiCaprio achieved international stardom with the star-crossed romances \"Romeo + Juliet\" (1996) and \"Titanic\" (1997). After the latter became the highest-grossing film in the world at the time, he reduced his workload for a few years. In an attempt to shed his image of a romantic hero, DiCaprio sought roles in other genres, including the 2002 crime dramas \"Catch Me If You Can\" and \"Gangs of New York\"; the latter marked the first of his many successful collaborations with director Martin Scorsese.\nDiCaprio continued to gain acclaim for his performances in the biopic \"The Aviator\" (2004), the political thriller \"Blood Diamond\" (2006), the crime drama \"The Departed\" (2006), and the romantic drama \"Revolutionary Road\" (2008). He later made environmental documentaries and starred in several high-profile directors' successful projects, including the thrillers \"Inception\" and \"Shutter Island\" (both 2010); the western \"Django Unchained\" (2012); the romantic drama \"The Great Gatsby\" (2013) for which he won the AACTA Award for Best Actor in a Leading Role; the biopic \"The Wolf of Wall Street\" (2013); the survival drama \"The Revenant\" (2015), for which he won the Academy Award for Best Actor; the comedy-drama \"Once Upon a Time in Hollywood\" (2019); and the crime dramas \"Killers of the Flower Moon\" (2023) and \"One Battle After Another\" (2025).\nDiCaprio is the founder of Appian Way Productions\u2014a production company that has made some of his films and the documentary series \"Greensburg\" (2008\u20132010)\u2014and Leonardo DiCaprio Foundation, a nonprofit organization devoted to promoting environmental awareness. A United Nations Messenger of Peace, he regularly supports charitable causes. In 2005, he was named a Commander of the Order of Arts and Letters for his contributions to the arts, and in 2016, he appeared in \"Time\" magazine's 100 most influential people in the world. DiCaprio was voted one of the 50 greatest actors of all time in a 2022 readers' poll by \"Empire\" magazine.\nEarly life and acting background.\nLeonardo Wilhelm DiCaprio was born on November 11, 1974, in Los Angeles, California. He is the only child of Irmelin Indenbirken, a German legal secretary, and George DiCaprio, an American underground comix artist and distributor. The couple met while attending college and moved to Los Angeles after graduating. George's paternal grandparents, Salvatore Di Caprio and Rosina Cassella, were Italian, while his mother, Olga Anne Jacobs, was of German descent. Irmelin's father, Wilhelm Indenbirken, was German, while her mother, Helene Indenbirken, was a Russian immigrant living in Germany. Some sources have falsely claimed that Helene was born in Odesa, Ukraine; there is no evidence that DiCaprio has any relatives of Ukrainian birth or heritage.\nDiCaprio got his name because a pregnant Irmelin first felt him kick while she was looking at a Leonardo da Vinci painting in the Uffizi museum in Florence, Italy. When he was one year old, Irmelin and George divorced after the latter fell in love with another woman and moved out. To raise DiCaprio together, Irmelin and George moved into twin cottages with a shared garden in Echo Park, Los Angeles. George lived with his girlfriend and her son, Adam Farrar, with whom DiCaprio developed a close bond. DiCaprio and Irmelin later moved to other neighborhoods, such as Los Feliz. He has described Irmelin and George as \"bohemian in every sense of the word\" and as \"the people I trust the most in the world\". DiCaprio has mentioned growing up poor in a neighborhood plagued with prostitution, crime and violence. He was raised Catholic. Attending the Los Angeles Center for Enriched Studies for four years and later Seeds Elementary School, DiCaprio later enrolled at John Marshall High School. He disliked public school and wanted to audition for acting jobs instead. He dropped out of high school later, eventually earning a general equivalency diploma.\nAs a child, DiCaprio wanted to become either a marine biologist or an actor. He eventually favored the latter; he liked impersonating characters and imitating people, and enjoyed seeing their reactions to his acting. According to DiCaprio, his interest in performing began at the age of two when he went onto the stage at a performance festival and danced spontaneously to a positive response from the crowd. He was also motivated to learn acting when Farrar's appearance in a television commercial earned him $50,000. DiCaprio has said in interviews that his first television appearance was in the children's series \"Romper Room\", and that he was dismissed from the show for being disruptive. The show's host has denied that any children were removed from the show in this way. At the age of 11, DiCaprio almost quit acting in order to pursue breakdancing, having gotten second place in a competition in Irmelin's native Germany. At the age of 14, he began appearing in several commercials for Matchbox cars, which he calls his first role. DiCaprio later appeared in commercials for Kraft Singles, Bubble Yum, and Apple Jacks. In 1989, he played the role of Glen in two episodes of the television show \"The New Lassie\".\nAt the beginning of his career, DiCaprio had difficulty finding an agent. When he found one, the agent suggested DiCaprio change his name to Lenny Williams to appeal to American audiences, which he declined to do. DiCaprio remained jobless for a year and a half, although he had 100auditions. Following this lack of success, DiCaprio was going to give up acting but George persuaded him to persevere. Motivated by George and by the prospect of financial security, DiCaprio continued to audition. After a talent agent, who knew Irmelin's friend, recommended him to casting directors, DiCaprio secured roles in about 20commercials.\nBy the early1990s, DiCaprio began acting regularly on television, starting with a role in the pilot of \"The Outsiders\" (1990) and one episode of the soap opera \"Santa Barbara\" (1990), in which he played a teenage alcoholic. DiCaprio's career prospects improved when he was cast in \"Parenthood\", a series based on the 1989 comedy film of the same name. To prepare for the role of Garry Buckman, a troubled teenager, he analyzed Joaquin Phoenix's performance in the original film. His work that year earned him two nominations at the 12th Youth in Film Awards\u2014Best Young Actor in a Daytime Series for \"Santa Barbara\" and Best Young Actor Starring in a New Television Series for \"Parenthood\". Around this time, he was a contestant on the children's game show \"Fun House\", on which he performed several stunts, including catching the fish inside a small pool using only his teeth.\nCareer.\n1991\u20131996: Early work and breakthrough.\nDiCaprio made his film debut in 1991 as the stepson of an unscrupulous landlord in the low-budget horror sequel \"Critters 3\"\u2014a part he later described as \"your average, no-depth, standard kid with blond hair\". DiCaprio has stated that he prefers not to remember \"Critters 3\", viewing it as \"possibly one of the worst films of all time\" and the kind of role he wanted to avoid in the future. Later in 1991, he became a recurring cast member on the sitcom \"Growing Pains\", playing Luke Brower, a homeless boy who is taken in by the show's central family. Co-star Joanna Kerns recalls DiCaprio being \"especially intelligent and disarming for his age\" but she noted that he was also mischievous and jocular on set, and often made fun of his co-stars. DiCaprio was cast by the producers to appeal to young female audience, but his arrival did not improve the show's ratings and he left before the end of its run. He was nominated for a Young Artist Award for Best Young Actor Co-starring in a Television Series. DiCaprio also had an uncredited role in 1991 in one episode of \"Roseanne\".\nIn 1992, DiCaprio had a brief role in the first installment of the \"Poison Ivy\" film series, and was handpicked by Robert De Niro from a shortlist of 400 young actors to co-star with him in \"This Boy's Life.\" Adapted from the memoir by Tobias Wolff, the film focuses on the relationship between a rebellious teenager, Toby (DiCaprio), and his mother (Ellen Barkin) and abusive stepfather (De Niro). Director Michael Caton-Jones said that DiCaprio did not know how to behave on set; accordingly, Caton-Jones used a strict mentoring style, after which DiCaprio's behavior began to improve. Bilge Ebiri of \"Rolling Stone\" found that the powerful bond between Barkin and DiCaprio elevated the film, praising DiCaprio's portrayal of his character's complex growth from a rebellious teen to an independent young man. \"This Boy's Life\" was the first film that gained him recognition.\nDiCaprio played the developmentally disabled brother of Johnny Depp's character in \"What's Eating Gilbert Grape\" (1993), a comedy-drama about a dysfunctional Iowa family. Caton-Jones recommended DiCaprio to director Lasse Hallstr\u00f6m who was initially skeptical, as he considered DiCaprio too good-looking for the part. Hallstr\u00f6m cast DiCaprio after he emerged as \"the most observant\" auditionee. To ensure authenticity in his portrayal, DiCaprio studied similarly impaired children and their mannerisms, and Hallstr\u00f6m allowed him to create the character using his own researched attributes. The film became a critical success. At 19, DiCaprio earned a National Board of Review Award, as well as nominations for a Golden Globe Award and an Academy Award for Best Supporting Actor, making him the seventh-youngest Oscar nominee in the category. \"The film's real show-stopping turn comes from Mr. DiCaprio,\" wrote \"The New York Times\" critic Janet Maslin, \"who makes Arnie's many tics so startling and vivid that at first he is difficult to watch. The performance has a sharp, desperate intensity from beginning to end.\" Caryn James, also writing for \"The New York Times\", said of his performances in \"This Boy's Life\" and \"What's Eating Gilbert Grape\": \"He made the raw, emotional neediness of those boys completely natural and powerful.\"\nDiCaprio's first role of 1995 was in Sam Raimi's Western \"The Quick and the Dead\". When Sony Pictures became dubious over DiCaprio's casting, co-star Sharon Stone paid his salary herself. The film was released to dismal box office performance and mixed reviews from critics. DiCaprio next starred as a teenage Jim Carroll, a drug-addicted high school basketball player and budding writer, in the biopic \"The Basketball Diaries\". He starred in the erotic drama \"Total Eclipse\" (1995), driven by the desire to showcase an exceptional performance, which would focus on his acting talent rather than his much-discussed physical appeal. Directed by Agnieszka Holland, it is a fictionalized account of the same-sex relationship between Arthur Rimbaud (DiCaprio) and Paul Verlaine (David Thewlis). DiCaprio was cast when River Phoenix died before filming began. Although the film failed commercially, it has been included in the catalog of the Warner Archive Collection, which releases classic and cult films from Warner Bros.' library on home video. A review in the \"San Francisco Chronicle\" called DiCaprio \"his generation's great acting promise\" but criticized the mismatch between Thewlis's \"cultivated\" British accent and DiCaprio's \"Southern California twang\".\nDiCaprio next starred opposite Claire Danes in Baz Luhrmann's \"Romeo + Juliet\" (1996), an abridged modernization of William Shakespeare's romantic tragedy, which retained the original Shakespearean dialogue. DiCaprio was initially unsure about another Romeo and Juliet adaptation, but at his father's suggestion, he agreed to examine Luhrmann's work more closely. DiCaprio and Luhrmann then spent a two-week workshop exchanging ideas, which led to the collaboration. \"Romeo + Juliet\" established DiCaprio as a leading Hollywood actor; according to film scholar Murray Pomerance, DiCaprio's newfound popularity helped the film become profitable only days after its release. Reviewing DiCaprio's early works, David Thomson of \"The Guardian\" called DiCaprio \"a revelation\" in \"What's Eating Gilbert Grape\", \"very moving\" in \"This Boy's Life\", \"suitably desperate\" in \"The Basketball Diaries\" and \"a vital spark\" in \"Romeo + Juliet\". The latter earned DiCaprio a Silver Bear for Best Actor at the 1997 Berlin International Film Festival. He then portrayed a young man who has been committed to a mental asylum in \"Marvin's Room\" (1996), a family drama about two estranged sisters, played by Meryl Streep and Diane Keaton, who are reunited through tragedy. He played Hank, the troubled son of Streep's character. Lisa Schwarzbaum of \"Entertainment Weekly\" praised \"the deeply gifted DiCaprio\" for holding his own against veteran actresses Keaton and Streep, describing the three as \"full-bodied and so powerfully affecting that you're carried along on the pleasure of being in the presence of their extraordinary talent\".\n1997\u20132001: \"Titanic\" and worldwide recognition.\nDiCaprio rejected a role in \"Boogie Nights\" (1997) to star opposite Kate Winslet in James Cameron's \"Titanic\" as members of different social classes who fall in love aboard RMS \"Titanic\". DiCaprio had doubts, but was encouraged by Cameron to pursue the part. With a production budget of more than $200\u00a0million, \"Titanic\" was the most expensive in history at the time. It became the highest-grossing film at the time, earning more than $2.1\u00a0billion in box-office receipts worldwide. It won 11\u00a0Academy Awards\u2014the most wins for any film\u2014including Best Picture; DiCaprio's failure to gain a nomination led to a protest against the Academy of Motion Picture Arts and Sciences by more than 200fans. He was nominated for other high-profile awards, including a Golden Globe Award for Best Actor. \n\"Titanic\" transformed DiCaprio into a superstar, drawing adoration among teenage girls and young women that became known as \"Leo-mania\". The success bolstered DiCaprio's standing as a teen idol and romantic lead, an image from which he sought to dissociate himself. He reduced his workload \"to learn to hear [his] own voice in choosing the roles\" that he wanted to pursue. He said in 2000: \"I have no connection with me during that whole \"Titanic\" phenomenon and what my face became around the world[...] I'll never reach that state of popularity again, and I don't expect to[...] It's not something I'm going to try to achieve either.\" In 2025, DiCaprio said he regretted the decision to turn down \"Boogie Nights\", saying it was \"a profound movie of my generation\".\nIn his 2015 \"Rolling Stone\" article, Ebiri called the \"Titanic\" role DiCaprio's best, writing that he and Winslet \"infuse their earnest back-and-forth with so much genuine emotion that it's hard not to get swept up in their doomed love affair\". A writer for \"Vanity Fair\" in 2008 labeled them \"Hollywood's most iconic screen couple\" since Humphrey Bogart and Ingrid Bergman. Writing about her first viewing of \"Titanic\" in 2017, \"Vox\" contributor Alissa Wilkinson described DiCaprio's \"boyish charm\" and found his performance \"natural and unaffected\". \nDiCaprio had a brief featured role in Woody Allen's 1998 satire of fame, \"Celebrity\". Ebiri labeled DiCaprio \"the best thing in the film\". That year, he also took on the dual roles of villainous King Louis XIV and his secret, sympathetic twin brother Philippe in Randall Wallace's \"The Man in the Iron Mask\", with common elements from the 1939 film and a 1929 film with Douglas Fairbanks. It received mixed reviews, but grossed $180\u00a0million against a budget of $35\u00a0million. \"Entertainment Weekly\" critic Owen Gleiberman wrote that DiCaprio did not look old enough to play the part, but praised him as \"a fluid and instinctive actor, with the face of a mischievous angel\". \"The Guardian\"'s Alex von Tunzelmann was similarly impressed with the actor's performance but found his talent wasted in the film. DiCaprio won a Golden Raspberry Award for Worst Screen Couple for the dual roles in 1999.\nAlso in 1998, DiCaprio was cast to star in \"American Psycho\" (2000) for a reported salary of $20\u00a0million; after disagreements with Oliver Stone on the film's direction, DiCaprio left the project, taking the lead role in \"The Beach\" instead. Adapted from Alex Garland's 1996 novel, the film saw him play a backpacking American tourist who ends up in a secret island commune in the Gulf of Thailand. Budgeted at $50\u00a0million, the film earned almost three times that at the box office, but was negatively reviewed by critics, and earned him a nomination for the Golden Raspberry Award for Worst Actor. Todd McCarthy of \"Variety\" thought DiCaprio gave a compelling performance but his character lacked defining qualities. The film received criticism for damaging the filming location in Thailand, after which DiCaprio worked to restore the area.\nIn the mid-1990s, DiCaprio agreed to be in the mostly improvised black-and-white short film \"Don's Plum\" as a favor to aspiring director R. D. Robb. When Robb expanded it to a full-length film, DiCaprio and co-star Tobey Maguire had its release blocked in the US and Canada by court order, arguing they never intended to make a feature film. The film premiered at the 2001 Berlin International Film Festival but remains obscure.\n2002\u20132009: Work with Martin Scorsese and film production.\nDiCaprio turned down the role of Anakin Skywalker in \"\" (2002), feeling unprepared to \"take that dive\" at the time. His first film that year was the biopic \"Catch Me If You Can\", based on the life of Frank Abagnale Jr., who before his 19th birthday committed check fraud to make\u00a0millions in the 1960s. Directed by Steven Spielberg, the film was shot across 147\u00a0different locations in 52\u00a0days, making it \"the most adventurous, super-charged movie-making\" DiCaprio had experienced yet. The film received critical acclaim and grossed $355\u00a0million against a budget of $52\u00a0million, becoming his second highest-grossing release after \"Titanic\". Roger Ebert praised his departure from dark and troubled characters, and two \"Entertainment Weekly\" critics in 2018 called it DiCaprio's best role, labeling him \"delightfully persuasive, deceptive, flirtatious, and sometimes tragic\u2014and we dare you to find a better role, if you can\". DiCaprio received his third Golden Globe nomination for his performance in the film.\nAlso in 2002, DiCaprio starred in Martin Scorsese's \"Gangs of New York\", a historical drama set in the mid-19th century in the Five Points district of New York City. Scorsese initially struggled selling his idea of realizing the film until DiCaprio became interested in starring in the film, and thus Miramax Films got involved with financing the project. Nonetheless, production on the film was plagued by overshooting of budgets and producer-director disagreements, resulting in an eight-month shoot. With a budget of $103\u00a0million, the film was the most expensive Scorsese had ever made. DiCaprio was drawn to playing Amsterdam Vallon, the young leader of an Irish-American street gang, as it marked a shift from \"boyish\" roles to a mature leading man. \"Gangs of New York\" earned $193\u00a0million worldwide and received positive critical response. Anne Thompson of \"The Observer\" took note of DiCaprio's \"low-key, sturdy performance\", but felt that co-star Daniel Day-Lewis overshadowed him.\nIn 2004, DiCaprio founded the production company Appian Way Productions, a namesake of the Italian road. He was interested in finding unique source material and preserving its essence during development, citing previous experiences where the involvement of too many people influenced the final product in a negative way. DiCaprio first executive-produced \"The Assassination of Richard Nixon\", which starred Sean Penn as Samuel Byck, and was screened at the 2004 Cannes Film Festival. DiCaprio and Scorsese reunited for a biopic of Howard Hughes, an American film director and aviation pioneer suffering from obsessive\u2013compulsive disorder, in \"The Aviator\" (2004), which DiCaprio also co-produced under Appian Way. He initially developed the project with Michael Mann who was eventually replaced by Scorsese. \"The Aviator\" became a critical and financial success, grossing $213million against its budget of $110million. Simond Braund of \"Empire\" thought DiCaprio convincingly played a complex role and highlighted the scenes depicting Hughes's paranoia and obsession. He received his first Golden Globe Award for Best Actor \u2014 Motion Picture Drama and nominations for an Academy Award, a BAFTA Award and a Screen Actors Guild Award.\nIn 2006, DiCaprio starred in the crime film \"The Departed\" and the political war thriller \"Blood Diamond\". In Scorsese's \"The Departed\", DiCaprio played the role of Billy Costigan, a state trooper working undercover in the Irish Mob in Boston, someone he characterizes as being in a \"constant 24-hour panic attack\". DiCaprio especially liked the experience of working with co-star Jack Nicholson, describing a scene with him as \"one of the most memorable moments\" of his life as an actor. In preparation, he visited Boston to interact with people associated with the Irish Mob and gained of muscle. Critically acclaimed, the film grossed $291\u00a0million against a budget of $90\u00a0million, becoming DiCaprio and Scorsese's highest-grossing collaboration to that point. Peter Travers of \"Rolling Stone\" praised DiCaprio's and co-star Matt Damon's performances as \"explosive, emotionally complex\", but felt that Nicholson overshadowed the two. Despite DiCaprio's leading role in \"The Departed\", the film's distributor Warner Bros. Pictures submitted his performance for a Best Supporting Actor nomination at the AMPAS to avoid internal conflict with his part in \"Blood Diamond\". Instead, his co-star Mark Wahlberg was nominated, though DiCaprio earned other accolades for \"The Departed\", including a Satellite Award for Best Supporting Actor and Best Actor nominations at the Golden Globes and BAFTA Awards.\nIn \"Blood Diamond\", DiCaprio starred as a diamond smuggler from Rhodesia who is involved in the Sierra Leone Civil War. While filming, he worked with 24\u00a0orphaned children from the SOS Children's Village in Maputo, Mozambique, and said he was touched by his interactions with them. To prepare, he spent six months in Africa, learned about camouflage from people in South African military and interviewed and recorded people in the country to improve his accent. The film received generally favorable reviews, and DiCaprio was noted for his South African accent, which is generally known as difficult to imitate. Claudia Puig of the \"USA Today\" approvingly highlighted DiCaprio's transition from a boy to a man on screen, and Ann Hornaday of \"The Washington Post\" similarly noted his growth as an actor since \"The Departed\". DiCaprio received nominations for an Academy Award and a Golden Globe for \"Blood Diamond\".\nIn 2007, DiCaprio produced the comedy drama \"Gardener of Eden\", which according to \"The Hollywood Reporter\"'s Frank Scheck \"lack[ed] the necessary dramatic urgency or black humor to connect with audiences\". Later that year, he produced, co-wrote and narrated \"The 11th Hour\", a documentary on the state of the natural environment that won the Earthwatch Environmental Film Award in 2008. DiCaprio's Appian Way produced Planet Green's \"Greensburg\" (2008\u20132010), which ran for three seasons. Set in Greensburg, Kansas, it is about rebuilding the town in a sustainable way after being hit by the 2007 Greensburg tornado. Also in 2008, DiCaprio starred in \"Body of Lies\", a spy film based on the novel of the same name. He played one of three agents battling a terrorist organization in the Middle East. Considering the film to be a throwback to political features of the 1970s like \"The Parallax View\" (1974) and \"Three Days of the Condor\" (1975), DiCaprio dyed his hair brown and wore brown contacts for the role. The film received mixed reviews from critics, and grossed $118\u00a0million against a budget of $67.5\u00a0million.\nLater in 2008, DiCaprio collaborated with Kate Winslet for the drama \"Revolutionary Road\", directed by her then-husband Sam Mendes. As both actors had been reluctant to make romantic films similar to \"Titanic\", it was Winslet who suggested that they both work with her on a film adaptation of the 1961 eponymous novel by Richard Yates. She found that the script, by Justin Haythe, had little in common with the 1997 blockbuster. Playing a couple in a failing marriage in the 1950s, DiCaprio and Winslet spent some time together in preparation, and DiCaprio felt claustrophobic on the small set they used. He saw his character as \"unheroic\", \"slightly cowardly\" and someone \"willing to be just a product of his environment\". Peter Travers liked DiCaprio's pairing with Winslet and his multi-layered portrayal of an overwhelmed character, and Marshall Sella of \"GQ\" called it the \"most mature and memorable performance of his lifetime\". DiCaprio earned his seventh Golden Globes nomination for the film. \"Revolutionary Road\" grossed $75.9million against its budget of $35million. He ended the 2000s by producing director Jaume Collet-Serra's psychological horror thriller film \"Orphan\" (2009), starring Vera Farmiga, Peter Sarsgaard and Isabelle Fuhrman. Although the film received mixed reviews, it was a commercial success.\n2010\u20132013: Films with high-profile directors.\nDiCaprio continued to collaborate with Scorsese in the 2010 psychological thriller film \"Shutter Island\", based on the 2003 novel of the same name by Dennis Lehane. He played Edward \"Teddy\" Daniels, a U.S. Marshal investigating a psychiatric facility located on an island, who comes to question his own sanity. DiCaprio and Scorsese became interested in the project in 2007, and the former co-produced the film under Appian Way with Phoenix Pictures. Because of the film's disturbing scenes, DiCaprio had nightmares of mass murder during production and considered relaxing with his friends a form of therapy. The film was released to mixed reviews; Peter Bradshaw of \"The Guardian\" praised Scorsese's direction and the acting but criticized its twist ending. Peter Travers called it DiCaprio's \"most haunting and emotionally complex performance yet\", and particularly liked his cave scene with co-star Patricia Clarkson. The film was a commercial success, grossing $294\u00a0million worldwide against a budget of $80\u00a0million.\nDiCaprio's second role in 2010 was in Christopher Nolan's critically acclaimed ensemble science-fiction film \"Inception\". Inspired by the experience of lucid dreaming and dream incubation, the film features Dom Cobb (DiCaprio), an \"extractor\" who enters the dreams of others to obtain information that is otherwise inaccessible. Cobb is promised a chance to regain his old life in exchange for planting an idea in a corporate target's mind. DiCaprio was fascinated with the idea of a \"dream-heist\" and the potential for his character to manipulate his dreamworld and impact his real life. Made on a budget of $160\u00a0million, the film grossed $836\u00a0million worldwide to become DiCaprio's second highest-grossing film. To star in this film, DiCaprio agreed to a pay cut from his $20\u00a0million fee and opted for a share in first-dollar gross points, which entitled him to a percentage of the cinema ticket sales. The risk proved fruitful, as DiCaprio earned $50\u00a0million from the film, becoming his highest payday yet.\nDiCaprio starred as J. Edgar Hoover in Clint Eastwood's \"J. Edgar\" (2011). A biopic about Hoover, the film focuses on his career as an FBI director, including an examination of his private life as an alleged closeted homosexual. Critics felt that the film lacked coherence overall but commended DiCaprio's performance. Roger Ebert praised DiCaprio's ability to bring depth and nuance to the character, suggesting that his performance conveyed aspects of Hoover's personality that were possibly even unknown to the man himself. Also in 2011, he produced Catherine Hardwicke's romantic horror film \"Red Riding Hood\". Though it was named one of the ten worst films of 2011 by \"Time\" magazine, it had moderate box-office returns. Also that year, DiCaprio's Appian Way produced George Clooney's political drama \"The Ides of March\", an adaptation of Beau Willimon's 2008 play \"Farragut North\".\nIn 2012, DiCaprio starred as plantation owner Calvin Candie in Quentin Tarantino's Spaghetti Western, \"Django Unchained\". After reading the script, DiCaprio felt uncomfortable with the extent of racism portrayed in the film, but his co-stars and Tarantino convinced him not to sugarcoat it. While filming, DiCaprio accidentally cut his hand on glass, but continued filming, and Tarantino elected to use the take in the final product. The film received critical acclaim; a writer for \"Wired\" magazine commended him for playing a villainous role and found his performance \"blood-chilling\". The film earned DiCaprio a Golden Globe Award nomination for Best Supporting Actor. \"Django Unchained\" grossed $425\u00a0million worldwide on a production budget of $100\u00a0million.\nIn January\u00a02013, DiCaprio said he would take a long break from acting to \"fly around the world doing good for the environment\". That year, he had four releases as an actor and a producer. His first was in the role of millionaire Jay Gatsby in Baz Luhrmann's \"The Great Gatsby\", an adaptation of F. Scott Fitzgerald's 1925 novel of the same name, co-starring Carey Mulligan and Tobey Maguire. The film received mixed reviews from critics, but DiCaprio's performance was praised and earned him the AACTA Award for Best Actor in a Leading Role. Critic Rafer Guzman of \"Newsday\" wrote that DiCaprio was not only \"tough[...] but also vulnerable, touching, funny, a faker, a human. It's a tremendous, hard-won performance.\" Matt Zoller Seitz of Roger Ebert's website described his performance as \"the movie's greatest and simplest special effect\", and \"iconic\u2014maybe his career best\". The film grossed $353\u00a0million worldwide, more than three times its budget. Three films were produced by DiCaprio under Appian Way in 2013\u2014the ensemble crime thriller \"Runner Runner\", which \"The Guardian\"'s Xan Brooks described as \"a lazy, trashy film that barely goes through the motions\"; the commercially failed thriller \"Out of the Furnace\"; and the black comedy-drama \"The Wolf of Wall Street\".\nDiCaprio reunited with Scorsese for the fifth time in \"The Wolf of the Wall Street\", a film based on the life of stockbroker Jordan Belfort (played by DiCaprio), who was arrested in the late\u00a01990s for securities fraud and money laundering. DiCaprio wanted to play Belfort ever since he had read his autobiography and won a bidding war with Warner Bros. against Brad Pitt and Paramount Pictures for the rights to Belfort's memoir in 2007. He was fond of Belfort's honest and unapologetic portrayal of his actual experiences in the book, and was inspired by the 2008 financial crisis to make the film. \"The Wolf of Wall Street\" received positive reviews for Scorsese's and DiCaprio's work together. \"The Hollywood Reporter\"'s Todd McCarthy lauded DiCaprio for fully realizing his character's potential with a carefree performance. Jonathan Romney of \"Film Comment\" wrote that DiCaprio displays a great deal of comedic talent, excelling in \"rubber-limbed slapstick\" humor. The film earned him the Golden Globe Award for Best Actor \u2013 Motion Picture Musical or Comedy and nominations for a BAFTA Award for Best Actor in a Leading Role, as well as Academy Awards for Best Actor and Best Picture.\n2014\u2013present: Environmental documentaries and awards success.\nDiCaprio was an executive producer on \"Virunga\", a 2014 British documentary film about four people fighting to protect the world's last mountain gorillas from war and poaching. The film premiered at the Tribeca Film Festival in April2014, and DiCaprio was nominated for the 2015 Primetime Emmy Award for Outstanding Documentary or Nonfiction Special. \"\" was another documentary film that year for which he was an executive producer\u2014he took part in the new cut released exclusively on Netflix that September. It explores the impact of animal agriculture on the environment.\nIn 2015, DiCaprio produced and played fur trapper Hugh Glass in Alejandro G. I\u00f1\u00e1rritu's survival drama \"The Revenant\". DiCaprio found his role in the film difficult; he had to eat a raw slab of bison's liver and sleep in animal carcasses. He also learned to shoot a musket, build a fire, speak two Native American languages (Pawnee and Arikara) and apply ancient healing techniques. Built on a budget of $135\u00a0million, the film earned $533\u00a0million worldwide. The film received positive reviews with particular praise for DiCaprio's acting. Mark Kermode of \"The Guardian\" wrote that DiCaprio shone with a performance that prioritizes physicality over speech, and Nick De Semlyen of \"Empire\" noted that he uplifted the film. The film earned him numerous awards, including the Academy Award, BAFTA, Critics' Choice, Golden Globe and SAG Award for Best Actor. For the next three years, DiCaprio narrated documentaries and served as a producer for films. In 2016, he was an executive producer for \"The Ivory Game\" and \"Catching the Sun\"; he also produced, hosted and narrated the documentary \"Before the Flood\" about climate change. He produced the crime drama \"Live by Night\" (2016), which received unenthusiastic reviews and failed to recoup its $65\u00a0million production budget. His next production ventures were in 2018\u2014the psychological horror \"Delirium\" and the commercially failed action\u2013adventure \"Robin Hood\".\nAfter producing and narrating the 2019 global warming documentary \"Ice on Fire\", DiCaprio returned to acting following a four-year break in Quentin Tarantino's comedy-drama \"Once Upon a Time in Hollywood\", which traces the relationship between Rick Dalton (DiCaprio), an aging television actor and his stuntman, Cliff Booth (Brad Pitt). To help the film's financing, DiCaprio and Pitt agreed to take a pay cut, and they each received $10\u00a0million. DiCaprio liked working with Pitt, and Tarantino described the pair as the most exciting since Robert Redford and Paul Newman. DiCaprio was fascinated with the film's homage to Hollywood and focus on the friendship between his and Pitt's characters. He drew from real-life experience of witnessing the struggles and rejections of his actor friends in the industry. The film premiered at the 2019 Cannes Film Festival, where critics praised his and Pitt's performances. A writer for \"Business Insider\" called it one of the best performances of DiCaprio's career, and Ian Sandwell of Digital Spy particularly liked the duo's chemistry, believing their scenes together to be some of the film's strongest parts. DiCaprio received nominations for an Oscar, a Golden Globe, a BAFTA Award and a Screen Actors Guild Award for Best Actor. The film earned $374\u00a0million against a budget of $90\u00a0million.\nIn 2020, DiCaprio served as an executive producer for \"The Right Stuff\", a television series adaption of the 1973 namesake book. After being in development at National Geographic, it was released on Disney+. That May, DiCaprio briefly featured in the finale of the miniseries \"The Last Dance\". In 2021, DiCaprio appeared in Adam McKay's satirical comedy \"Don't Look Up\". He spent five months changing the film's script with McKay before agreeing to the part. Starring alongside Jennifer Lawrence as two astronomers attempting to warn humanity about an extinction-level comet, DiCaprio saw this film as an analogy of the world's indifference to the climate crisis. As a frequent supporter of environmentalism, DiCaprio said he has often looked to star in and make films tackling issues related to it, something he found hard due to people's inability to listen. He praised McKay for envisioning a project on how humans would react to a serious issue from a political, social and scientific standpoint. While reviews for the film were mixed, most critics praised DiCaprio's and Lawrence's performances; journalists from Digital Spy and NDTV lauded their pairing. DiCaprio earned nominations for a Golden Globe and a BAFTA Award for the film. It broke the record for the most views (152\u00a0million hours) in a single week in Netflix history.\nDiCaprio next starred in Scorsese's crime drama \"Killers of the Flower Moon\" (2023) based on the book of the same name by David Grann, for which he was paid $30 million. Initially signed for the heroic part of FBI agent Thomas Bruce White Sr., DiCaprio insisted on playing the morally complex role of murderer Ernest Burkhart, leading to extensive script rewrites. Declaring it the best performance of DiCaprio's career, IndieWire's David Ehrlich wrote that \"his nuanced and uncompromising turn as the cretinous Ernest Burkhart mines new wonders from the actor's long-standing lack of vanity\". He received another Golden Globe nomination for his performance. DiCaprio next starred in Paul Thomas Anderson's film \"One Battle After Another\" (2025), alongside Sean Penn and Regina Hall.\nReception and acting style.\nEarly in his career, DiCaprio gained a reputation for his reckless behavior and intense partying with a group of male celebrities dubbed \"the Pussy Posse\" in the 1990s. In an infamous article published by \"New York Magazine\" in 1998, journalist Nancy Jo Sales criticized the group as men whose pursuit was to \"chase girls, pick fights and not tip the waitress\". During an unknown activity, DiCaprio got himself and friend Justin Herwick almost killed when his parachute failed to open, after which his instructor released an emergency core. In response, DiCaprio said he is fond of doing things that scare him. John McCain, who was a United States Senator for Arizona, called him \"an androgynous wimp\". DiCaprio found people's perception of him exaggerated, adding, \"They want you miserable, just like them. They don't want heroes; what they want is to see you fall.\" Steven Spielberg, who directed him in \"Catch Me If You Can\", defended DiCaprio's reputation as a \"party boy\", believing it is a common behavior for young people and describing him as a family-oriented person during the film's production. Considering DiCaprio to be conscious of his public reputation, \"The New York Times\"' Caryn James credited him as one of the few actors to use his stardom to further social causes. Carole Cadwalladr of \"The Guardian\" said DiCaprio is \"polite, charming, makes jokes, engages eye contact. And manages[...] to give almost no hint whatsoever of his actual personality.\"\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nLife can get pretty monotonous. Acting is like living multiple lives. When you make a movie, you go off to different places, live different cultures, investigate somebody else's reality, and you try to manifest that to the best of your ability. It is incredibly eye-opening. That's why I love acting. There's nothing as transformative as what a film, a documentary, can do to get people to care about something else besides their own lives.\n\u2014DiCaprio on his love of acting\nDiCaprio is regarded as one of the finest actors of his generation. In a 2022 readers' poll by \"Empire\", he was voted one of the 50 greatest actors of all time. The magazine praised his willingness to \"go to the ends of the earth (often literally) to get under his characters' skin\". Colin Covert of \"The Seattle Times\" similarly believed DiCaprio \"redefines film stardom\" through his willingness to take on challenging roles that few of his contemporaries are capable of performing.\nSince his international stardom with \"Titanic\" (1997), he has admitted feeling nervous about starring in big-budget studio films because of their hype and marketing campaigns. As an actor, he views film as a \"relevant art form, like a painting or sculpture. A hundred years from now, people will still be watching that movie.\" He often plays roles based on real-life people and stories told in specific periods. According to Caryn James, DiCaprio is unafraid of working with established directors on unconventional projects; taking such risks has led him to star in failed films like \"The Beach\" (2000), but also his successful collaborations with Martin Scorsese. DiCaprio has described his relationship with Scorsese as dreamlike and admires his knowledge of film, crediting the director with having taught him its history and importance. Scorsese has commented on DiCaprio's ability to repeatedly demonstrate emotion on screen. Jesse Hassenger of \"The A.V. Club\" considers the duo's collaborations\u2014which earned them the 2013 National Board of Review (Spotlight Award)\u2014to be career-defining moments for both of them and as vital as Scorsese's acclaimed collaborations with Robert De Niro.\nAuthor Michael K. Hammond wrote that DiCaprio built his star reputation by demonstrating his acting ability, and praised him for \"revealing a character while concealing the actor\" and \"disappearing into [his] roles\". According to Agnieszka Holland, who directed DiCaprio in \"Total Eclipse\" (1995), DiCaprio is \"one of the most mature actors\" she has worked with and is \"courageous\" in his choice of roles. Holland remarked that he does not rely on method acting but rather on a trick that allows him to truly \"become the character\". Meryl Streep, who co-starred with DiCaprio in \"Marvin's Room\", said he possesses the kind of unpredictability that makes his career difficult to classify, his life precarious and his work thrilling. Writing for \"The Observer\", film critic Philip French has asserted that many characters portrayed by DiCaprio are in the process of becoming men. He wrote that DiCaprio's inclination toward films about dysfunctional families and characters seeking father figures may allude to his own troubled childhood. DiCaprio often plays characters who themselves are playing roles, which Caryn James says looks simple on screen but requires sophisticated acting. He tends to play antiheroes and characters who lose their mental stability as the narrative progresses. Derek Thompson of \"The Atlantic\" argued that DiCaprio gives his best performances when playing \"frauds and cheats and double-crossing liars and mercenaries\".\nSeveral media publications, such as \"People\", \"Empire\" and \"Harper's Bazaar\", have included DiCaprio in their listings of the most attractive actors. In 1998, he sued \"Playgirl\" magazine over plans to publish a fully nude picture of him. He has said he does not believe in focusing on appearance\u2014as this is only temporary and can negatively affect one's profession in the industry\u2014and looks for career longevity instead. In 2005, DiCaprio was made a commander of the Ordre des Arts et des Lettres by the French Minister of Culture for his contributions to the arts. In 2016, he was named one of the 100most influential people in the world by \"Time\" magazine. He was included on \"Forbes\"' annual list of the world's highest-paid actors in 2008 and from 2010 to 2016 with respective earnings of $45\u00a0million, $28\u00a0million, $77\u00a0million, $37\u00a0million, $39\u00a0million, $39\u00a0million, $29\u00a0million and $27\u00a0million, topping the list in 2011. The magazine has commended DiCaprio's ability to star in risky, R-rated films that become box office successes. \"The Hollywood Reporter\" listed him as one of the 100 most powerful people in entertainment from 2016 to 2019. A writer for the same magazine credits DiCaprio as the rare actor to have a successful career \"without ever having made a comic book movie, family film or pre-branded franchise. Leo is the franchise.\" Stacey Wilson Hunt, analyzing his career in \"New York Magazine\" in 2016, opined DiCaprio, unlike most of his contemporaries, had not starred in a bad film in the previous ten years. Of his success, DiCaprio says, \"My attitude is the same as when I started. I feel very connected to that fifteen-year-old kid who got his first movie.\"\nDiCaprio has named Robert De Niro and James Dean as two of his favorite and most influential actors, stating \"There were a lot of great actors I really fell in love with, but if I were to pick two, from different generations, it would be De Niro and James Dean\". When asked about a performance that stayed with him the most, DiCaprio responded, \"I remember being incredibly moved by Jimmy Dean, in \"East of Eden\". There was something so raw and powerful about that performance. His vulnerability [...] his confusion about his entire history, his identity, his desperation to be loved. That performance just broke my heart.\"\nOther ventures.\nActivism.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nClimate change is real, it is happening right now. It is the most urgent threat facing our entire species, and we need to work collectively together and stop procrastinating. We need to support leaders around the world who do not speak for the big polluters, but who speak for all of humanity, for the indigenous people of the world, for the billions and billions of underprivileged people out there who would be most affected by this. For our children's children, and for those people out there whose voices have been drowned out by the politics of greed.\n \u2014DiCaprio during his acceptance speech at the 88th Academy Awards, 2016\nAn active celebrity in the climate change movement, DiCaprio believes global warming is the world's \"number-one environmental challenge\". Eager to learn about ecology from an early age, he would watch documentaries on rainforest depletion and the loss of species and habitats. In 1998, he established the Leonardo DiCaprio Foundation, a non-profit organization devoted to promoting environmental awareness. It supports organizations and campaigns committed to ensuring a viable future for planet Earth, and produced the short web documentaries \"Water Planet\" and \"Global Warning.\" The foundation has also funded debt-for-nature swaps. By 2018, the foundation had funded more than 200 projects, providing $100 million in support. He has been an active supporter of numerous environmental organizations and sat on the board of the World Wildlife Fund and International Fund for Animal Welfare.\nDiCaprio has owned environment-friendly electric-hybrid vehicles. His use of private jets and large yachts have been criticized as hypocritical due to their large carbon footprints. DiCaprio chaired the national Earth Day celebration in 2000 where he interviewed Bill Clinton and they discussed plans to deal with global warming and the environment. He presented at the 2007 American leg of Live Earth. DiCaprio donated $1\u00a0million to the Wildlife Conservation Society at Russia's Tiger Summit. DiCaprio's persistence in reaching the event after encountering two plane delays caused then Prime Minister Vladimir Putin to describe him as a \"muzhik\" or \"real man\". In 2013, he organized a benefit fine art auction, \"11th\u00a0Hour\", which raised nearly $38.8\u00a0million for his foundation. In September 2014, United Nations Secretary-General Ban Ki-moon designated DiCaprio as a United Nations Messenger of Peace with a focus on climate change. Later that month, he made an opening statement to members of the UN Climate Summit; his speech reached an estimated one billion people worldwide. In 2015, he announced his intention to divest from fossil fuels. He again spoke at the UN in April\u00a02016 prior to the signing of the Paris Climate Change Agreement.\nAt a 2016 meeting with Pope Francis, DiCaprio donated to charity and discussed environmental issues with him. A few days later, possibly influenced by this meeting, the Pope said he would act in a charity film. DiCaprio traveled to Indonesia in early 2016 where he criticized the government's palm oil industry's slash-and-burn forest clearing methods. In July 2016, his foundation donated $15.6\u00a0million to help protect wildlife and the rights of Native Americans, along with mitigating climate change. That October, DiCaprio joined Mark Ruffalo in support of the Standing Rock tribe's opposition to the Dakota Access Pipeline.\nIn April\u00a02017, DiCaprio protested against President Donald Trump's inaction on climate change by attending the People's Climate March. In July, a charity auction and celebrity concert arranged by DiCaprio's foundation had raised over $30\u00a0million in one night. The DiCaprio foundation donated $100\u00a0million in December\u00a02018 to fight climate change. In May\u00a02021, DiCaprio pledged $43million to enact conservation operations across the Gal\u00e1pagos Islands.\nPolitical views.\nDiCaprio endorsed Hillary Clinton for the 2016\u00a0presidential election. In March 2020, DiCaprio attended a fundraiser for Joe Biden at the home of Paramount Pictures executive Sherry Lansing. Prior to the 2020\u00a0election, DiCaprio narrated a Netflix documentary series about voting rights, stating, \"All of us may have been created equal. But we'll never actually be equal until we all vote. So don't wait.\" On social media, DiCaprio urged voters to make a plan to cast their ballots and to draw attention to voter suppression and restrictive voter ID laws, citing VoteRiders as a source of information and assistance. In 2023, DiCaprio testified during the trial against Prakazrel Michel, who is being accused of participating in a foreign influence campaign that was aimed at the Obama and Trump administrations. During October 2024, DiCaprio formally endorsed Democratic nominee Kamala Harris for president due to her policies on climate change mitigation, and criticized her Republican opponent Donald Trump.\nPhilanthropy.\nIn 1998, DiCaprio and his mother donated $35,000 for a \"Leonardo DiCaprio Computer Center\" at a library in Los Feliz. In May\u00a02009, DiCaprio joined Kate Winslet, director James Cameron and Canadian singer Celine Dion, in a campaign to raise money to financially support the fees of the nursing home where Millvina Dean, a survivor of the RMS \"Titanic\", was residing. DiCaprio and Winslet donated $20,000 to support Dean. In 2010, he donated $1\u00a0million to relief efforts in Haiti after the earthquake. In 2011, DiCaprio joined the Animal Legal Defense Fund's campaign to release Tony, a tiger that had spent the last decade at a truck stop in Grosse T\u00eate, Louisiana. DiCaprio donated $61,000 to the gay rights group GLAAD in 2013.\nIn 2016, DiCaprio donated $65,000 to the annual fundraising gala for the Children of Armenia Fund, where he was a special guest of his friend and honorary chair, Tony Shafrazi. Supporting Hurricane Harvey (2017) relief efforts, DiCaprio provided $1\u00a0million through his foundation. In 2020, DiCaprio's foundation donated $3\u00a0million to Australia bushfire relief efforts. Amidst the 2022 Russian invasion of Ukraine, the media announced DiCaprio donated $10million to support Ukraine, although the news agency Associated Press suggested this amount was inaccurate.\nPersonal life.\nDiCaprio is agnostic. His personal life is the subject of widespread media attention, though he rarely grants interviews and is reluctant to discuss his private life. Since his 40s, DiCaprio has been the focus of various reports detailing his involvement with women aged 25 or younger, and has faced criticism for the age disparity of those relationships. In 1999, DiCaprio met Brazilian model Gisele B\u00fcndchen, whom he dated until 2005. He was romantically involved with Israeli model Bar Refaeli from 2005 to 2011. He later dated German fashion model Toni Garrn from 2013 to 2014 and later in 2017. DiCaprio was briefly romantically linked with Barbadian singer Rihanna, with the pair attending Coachella together in 2016. DiCaprio successfully sued French tabloid \"Oops\u200a\" after it made claims that DiCaprio had got Rihanna pregnant. DiCaprio was in a relationship with American model and actress Camila Morrone from 2017 until 2022. He has been dating Italian model Vittoria Ceretti since August 2023.\nDiCaprio owns houses in Los Angeles and apartments in New York City. In 2009, he bought an island, Blackadore Caye, off mainland Belize\u2014on which he is set to open an environmentally friendly resort\u2014and in 2014, he purchased the original Dinah Shore residence designed by architect Donald Wexler in Palm Springs, California.\nIn 2005, DiCaprio's face was severely injured when model Aretha Wilson hit him over the head with a broken bottle at a Hollywood party. As a result, he required seventeen stitches to his face and neck. Wilson pleaded guilty to the assault and was sentenced in 2010 to two years in prison.\nIn 2017, when \"The Wolf of Wall Street\" producer Red Granite Pictures was involved in the 1Malaysia Development Berhad scandal, DiCaprio turned over the gifts he received from business associates at the production company, including from fugitive businessman Jho Low, to the US government. These included a Best Actor Oscar trophy won by Marlon Brando, a $3.2\u00a0million Pablo Picasso painting, and a $9\u00a0million Jean-Michel Basquiat collage. \nOn December 30, 2019, while vacationing near St. Barts, DiCaprio agreed to divert the boat he was on to search for a man who had fallen overboard. As the only vessel to respond to the mayday call, his crew rescued the man, who had been treading water for 11 hours, shortly before a storm hit.\nIn June2025, DiCaprio drew criticism by attending the wedding of Jeff Bezos and Lauren S\u00e1nchez. Amazon has faced criticism for its impact on the environment. People questioned DiCaprio's decision, considering his activism regarding environmental and humanitarian causes. A photo of DiCaprio at the event showed him hiding his face with his baseball cap. In July2025, DiCaprio received backlash from activists for co-financing a luxury hotel project near Tel Aviv in Israel despite the ongoing Gaza\u2013Israel conflict, on which he has not commented.\nFilmography and accolades.\nAccording to the online portal Box Office Mojo and the review aggregate site Rotten Tomatoes, DiCaprio's most critically and commercially successful films include \"What's Eating Gilbert Grape\" (1993), \"Romeo + Juliet\" (1996), \"Titanic\" (1997), \"Catch Me If You Can\" (2002), \"Gangs of New York\" (2002), \"The Aviator\" (2004), \"The Departed\" (2006), \"Blood Diamond\" (2006), \"Revolutionary Road\" (2008), \"Shutter Island\" (2010), \"Inception\" (2010), \"Django Unchained\" (2012), \"The Great Gatsby\" (2013), \"The Wolf of Wall Street\" (2013), \"The Revenant\" (2015), \"Once Upon a Time in Hollywood\" (2019), \"Don't Look Up\" (2021), \"Killers of the Flower Moon\" (2023), and \"One Battle After Another\" (2025). His films have grossed $7.2\u00a0billion worldwide.\nDiCaprio has been recognized by the Academy of Motion Picture Arts and Sciences for the following:\nDiCaprio has won three Golden Globe Awards: Best Actor \u2013 Motion Picture Drama for \"The Aviator\" and \"The Revenant\" and Best Actor \u2013 Motion Picture Musical or Comedy for \"The Wolf of Wall Street\", as well as a BAFTA Award and a Screen Actors Guild Award for Best Actor for \"The Revenant\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCited sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52712", "revid": "62", "url": "https://en.wikipedia.org/wiki?curid=52712", "title": "Leonardo di Caprio", "text": ""}
{"id": "52713", "revid": "48661546", "url": "https://en.wikipedia.org/wiki?curid=52713", "title": "Binary star", "text": "System of two stars orbiting each other\nA binary star or binary star system is a system of two stars that are gravitationally bound to and in orbit around each other. Binary stars in the night sky that are seen as a single object to the naked eye are often resolved as separate stars using a telescope, in which case they are called \"visual binaries\". Many visual binaries have long orbital periods of several centuries or millennia and therefore have orbits which are uncertain or poorly known. They may also be detected by indirect techniques, such as spectroscopy (\"spectroscopic binaries\") or astrometry (\"astrometric binaries\"). If a binary star happens to orbit in a plane along our line of sight, its components will eclipse and transit each other; these pairs are called \"eclipsing binaries\", or, together with other binaries that change brightness as they orbit, \"photometric binaries\".\nIf components in binary star systems are close enough, they can gravitationally distort each other's outer stellar atmospheres. In some cases, these \"close binary systems\" can exchange mass, which may bring their evolution to stages that single stars cannot attain. Examples of binaries are Sirius and Cygnus X-1 (Cygnus X-1 being a well-known black hole). Binary stars are also common as the nuclei of many planetary nebulae, and are the progenitors of both novae and type Ia supernovae.\nDiscovery.\nDouble stars, a pair of stars that appear close to each other, have been observed since the invention of the telescope. Early examples include Mizar and Acrux. Mizar, in the Big Dipper (Ursa Major), was observed to be double by Giovanni Battista Riccioli in 1650 (and probably earlier by Benedetto Castelli and Galileo). The bright southern star Acrux, in the Southern Cross, was discovered to be double by Father Fontenay in 1685.\nEvidence that stars in pairs were more than just optical alignments came in 1767 when English natural philosopher and clergyman John Michell became the first person to apply the mathematics of statistics to the study of the stars, demonstrating in a paper that many more stars occur in pairs or groups than a perfectly random distribution and chance alignment could account for. He focused his investigation on the Pleiades cluster, and calculated that the likelihood of finding such a close grouping of stars was about one in half a million. He concluded that the stars in these double or multiple star systems might be drawn to one another by gravitational pull, thus providing the first evidence for the existence of binary stars and star clusters.\nWilliam Herschel began observing double stars in 1779, hoping to find a near star paired with a distant star so he could measure the near star's changing position as the Earth orbited the Sun (measure its parallax), allowing him to calculate the distance to the near star. He would soon publish catalogs of about 700 double stars. By 1803, he had observed changes in the relative positions in a number of double stars over the course of 25 years, and concluded that, instead of showing parallax changes, they seemed to be orbiting each other in binary systems. The first orbit of a binary star was computed in 1827, when F\u00e9lix Savary computed the orbit of Xi Ursae Majoris.\nOver the years, many more double stars have been catalogued and measured. As of June 2017, the Washington Double Star Catalog, a database of visual double stars compiled by the United States Naval Observatory, contains over 100,000 pairs of double stars, including optical doubles as well as binary stars. Orbits are known for only a few thousand of these double stars.\nEtymology.\nThe term \"binary\" was first used in this context by Sir William Herschel in 1802, when he wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If, on the contrary, two stars should really be situated very near each other, and at the same time so far insulated as not to be materially affected by the attractions of neighbouring stars, they will then compose a separate system, and remain united by the bond of their own mutual gravitation towards each other. This should be called a real double star; and any two stars that are thus mutually connected, form the binary sidereal system which we are now to consider.\nBy the modern definition, the term \"binary star\" is generally restricted to pairs of stars which revolve around a common center of mass. Binary stars which can be resolved with a telescope or interferometric methods are known as \"visual binaries\". For most of the known visual binary stars one whole revolution has not been observed yet; rather, they are observed to have travelled along a curved path or a partial arc.\nThe more general term \"double star\" is used for pairs of stars which are seen to be close together in the sky. This distinction is rarely made in languages other than English. Double stars may be binary systems or may be merely two stars that appear to be close together in the sky but have vastly different true distances from the Sun. The latter are termed \"optical doubles\" or \"optical pairs\".\nClassifications.\nMethods of observation.\nBinary stars are classified into four types according to the way in which they are observed: visually, by observation; spectroscopically, by periodic changes in spectral lines; photometrically, by changes in brightness caused by an eclipse; or astrometrically, by measuring a deviation in a star's position caused by an unseen companion. Any binary star can belong to several of these classes; for example, several spectroscopic binaries are also eclipsing binaries.\nVisual binaries.\nA \"visual binary\" star is a binary star for which the angular separation between the two components is great enough to permit them to be observed as a double star in a telescope, or even high-powered binoculars. The angular resolution of the telescope is an important factor in the detection of visual binaries, and as better angular resolutions are applied to binary star observations, an increasing number of visual binaries will be detected. The relative brightness of the two stars is also an important factor, as glare from a bright star may make it difficult to detect the presence of a fainter component.\nThe brighter star of a visual binary is the \"primary\" star, and the dimmer is considered the \"secondary.\" In some publications (especially older ones), a faint secondary is called the \"comes\" (plural \"comites\"; companion). If the stars are the same brightness, the discoverer designation for the primary is customarily accepted.\nThe position angle of the secondary with respect to the primary is measured, together with the angular distance between the two stars. The time of observation is also recorded. After a sufficient number of observations are recorded over a period of time, they are plotted in polar coordinates with the primary star at the origin, and the most probable ellipse is drawn through these points such that the Keplerian law of areas is satisfied. This ellipse is known as the \"apparent ellipse\", and is the projection of the actual elliptical orbit of the secondary with respect to the primary on the plane of the sky. From this projected ellipse the complete elements of the orbit may be computed, where the semi-major axis can only be expressed in angular units unless the stellar parallax, and hence the distance, of the system is known.\nSpectroscopic binaries.\nSometimes, the only evidence of a binary star comes from the Doppler effect on its emitted light. In these cases, the binary consists of a pair of stars where the spectral lines in the light emitted from each star first shifts towards the blue, when the star is moving towards us, and towards the red, when it is moving away from us, during its motion about their common center of mass, with the period of their common orbit.\nIn these systems, the separation between the stars is usually very small, and the orbital velocity very high. Unless the plane of the orbit happens to be perpendicular to the line of sight, the orbital velocities have components in the line of sight, and the observed radial velocity of the system varies periodically. Since radial velocity can be measured with a spectrometer by observing the Doppler shift of the stars' spectral lines, the binaries detected in this manner are known as \"spectroscopic binaries\". Most of these cannot be resolved as a visual binary, even with telescopes of the highest existing resolving power.\nIn some spectroscopic binaries, spectral lines from both stars are visible, and the lines are alternately double and single. Such a system is known as a double-lined spectroscopic binary (often denoted \"SB2\"). In other systems, the spectrum of only one of the stars is seen, and the lines in the spectrum shift periodically towards the blue, then towards red and back again. Such stars are known as single-lined spectroscopic binaries (\"SB1\").\nThe orbit of a spectroscopic binary is determined by making a long series of observations of the radial velocity of one or both components of the system. The observations are plotted against time, and from the resulting curve a period is determined. If the orbit is circular, then the curve is a sine curve. If the orbit is elliptical, the shape of the curve depends on the eccentricity of the ellipse and the orientation of the major axis with reference to the line of sight.\nIt is impossible to determine individually the semi-major axis \"a\" and the inclination of the orbit plane \"i\". However, the product of the semi-major axis and the sine of the inclination (i.e. \"a\"\u2009sin\u2009\"i\") may be determined directly in linear units (e.g. kilometres). If either \"a\" or \"i\" can be determined by other means, as in the case of eclipsing binaries, a complete solution for the orbit can be found.\nBinary stars that are both visual and spectroscopic binaries are rare and are a valuable source of information when found. About 40 are known. Visual binary stars often have large true separations, with periods measured in decades to centuries; consequently, they usually have orbital speeds too small to be measured spectroscopically. Conversely, spectroscopic binary stars move fast in their orbits because they are close together, usually too close to be detected as visual binaries. Binaries that are found to be both visual and spectroscopic thus must be relatively close to Earth.\nEclipsing binaries.\nAn \"eclipsing binary star\" is a binary star system in which the orbital plane of the two stars lies so nearly in the line of sight of the observer that the components undergo mutual eclipses. In the case where the binary is also a spectroscopic binary and the parallax of the system is known, the binary is quite valuable for stellar analysis. Algol, a triple star system in the constellation Perseus, contains the best-known example of an eclipsing binary.\nEclipsing binaries are variable stars, not because the light of the individual components vary but because of the eclipses. The light curve of an eclipsing binary is characterized by periods of practically constant light, with periodic drops in intensity when one star passes in front of the other. The brightness may drop twice during the orbit, once when the secondary passes in front of the primary and once when the primary passes in front of the secondary. The deeper of the two eclipses is called the primary regardless of which star is being occulted, and if a shallow second eclipse also occurs it is called the secondary eclipse. The size of the brightness drops depends on the relative brightness of the two stars, the proportion of the occulted star that is hidden, and the surface brightness (i.e. effective temperature) of the stars. Typically the occultation of the hotter star causes the primary eclipse.\nAn eclipsing binary's period of orbit may be determined from a study of its light curve, and the relative sizes of the individual stars can be determined in terms of the radius of the orbit, by observing how quickly the brightness changes as the disc of the nearest star slides over the disc of the other star. If it is also a spectroscopic binary, the orbital elements can also be determined, and the mass of the stars can be determined relatively easily, which means that the relative densities of the stars can be determined in this case.\nSince about 1995, measurement of extragalactic eclipsing binaries' fundamental parameters has become possible with 8-meter class telescopes. This makes it feasible to use them to directly measure the distances to external galaxies, a process that is more accurate than using standard candles. By 2006, they had been used to give direct distance estimates to the LMC, SMC, Andromeda Galaxy, and Triangulum Galaxy. Eclipsing binaries offer a direct method to gauge the distance to galaxies to an improved 5% level of accuracy.\nNon-eclipsing binaries that can be detected through photometry.\nNearby non-eclipsing binaries can also be photometrically detected by observing how the stars affect each other in three ways. The first is by observing extra light which the stars reflect from their companion. Second is by observing ellipsoidal light variations which are caused by deformation of the star's shape by their companions. The third method is by looking at how relativistic beaming affects the apparent magnitude of the stars. Detecting binaries with these methods requires accurate photometry.\nAstrometric binaries.\nAstronomers have discovered some stars that seemingly orbit around an empty space. \"Astrometric binaries\" are relatively nearby stars which can be seen to wobble around a point in space, with no visible companion. The same mathematics used for ordinary binaries can be applied to infer the mass of the missing companion. The companion could be very dim, so that it is currently undetectable or masked by the glare of its primary, or it could be an object that emits little or no electromagnetic radiation, for example a neutron star.\nThe visible star's position is carefully measured and detected to vary, due to the gravitational influence from its counterpart. The position of the star is repeatedly measured relative to more distant stars, and then checked for periodic shifts in position. Typically this type of measurement can only be performed on nearby stars, such as those within 10\u00a0parsecs. Nearby stars often have a relatively high proper motion, so astrometric binaries will appear to follow a \"wobbly\" path across the sky.\nIf the companion is sufficiently massive to cause an observable shift in position of the star, then its presence can be deduced. From precise astrometric measurements of the movement of the visible star over a sufficiently long period of time, information about the mass of the companion and its orbital period can be determined. Even though the companion is not visible, the characteristics of the system can be determined from the observations using Kepler's laws.\nThis method of detecting binaries is also used to locate extrasolar planets orbiting a star. However, the requirements to perform this measurement are very exacting, due to the great difference in the mass ratio, and the typically long period of the planet's orbit. Detection of position shifts of a star is a very exacting science, and it is difficult to achieve the necessary precision. Space telescopes can avoid the blurring effect of Earth's atmosphere, resulting in more precise resolution.\nConfiguration of the system.\nAnother classification is based on the distance between the stars, relative to their sizes:\n\"Detached binaries\" are binary stars where each component is within its Roche lobe, i.e. the area where the gravitational pull of the star itself is larger than that of the other component. While on the main sequence the stars have no major effect on each other, and essentially evolve separately. Most binaries belong to this class.\n\"Semidetached binary stars\" are binary stars where one of the components fills the binary star's Roche lobe and the other does not. In this interacting binary star, gas from the surface of the Roche-lobe-filling component (donor) is transferred to the other, accreting star. The mass transfer dominates the evolution of the system. In many cases, the inflowing gas forms an accretion disc around the accretor.\nA \"contact binary\" is a type of binary star in which both components of the binary fill their Roche lobes. The uppermost part of the stellar atmospheres forms a \"common envelope\" that surrounds both stars. As the friction of the envelope brakes the orbital motion, the stars may eventually merge. W Ursae Majoris is an example.\nCataclysmic variables and X-ray binaries.\nWhen a binary system contains a compact object such as a white dwarf, neutron star or black hole, gas from the other (donor) star can accrete onto the compact object. This releases gravitational potential energy, causing the gas to become hotter and emit radiation. Cataclysmic variable stars, where the compact object is a white dwarf, are examples of such systems. In X-ray binaries, the compact object can be either a neutron star or a black hole. These binaries are classified as low-mass or high-mass according to the mass of the donor star. High-mass X-ray binaries contain a young, early-type, high-mass donor star which transfers mass by its stellar wind, while low-mass X-ray binaries are semidetached binaries in which gas from a late-type donor star or a white dwarf overflows the Roche lobe and falls towards the neutron star or black hole. Probably the best known example of an X-ray binary is the high-mass X-ray binary Cygnus X-1. In Cygnus\u00a0X-1, the mass of the unseen companion is estimated to be about nine times that of the Sun, far exceeding the Tolman\u2013Oppenheimer\u2013Volkoff limit for the maximum theoretical mass of a neutron star. It is therefore believed to be a black hole; it was the first object for which this was widely believed.\nOrbital period.\nOrbital periods can be less than an hour (for AM CVn stars), or a few days (components of Beta Lyrae), but also hundreds of thousands of years (Proxima Centauri around Alpha Centauri AB).\nVariations in period.\nThe Applegate mechanism explains long term orbital period variations seen in certain eclipsing binaries. As a main-sequence star goes through an activity cycle, the outer layers of the star are subject to a magnetic torque changing the distribution of angular momentum, resulting in a change in the star's oblateness. The orbit of the stars in the binary pair is gravitationally coupled to their shape changes, so that the period shows modulations (typically on the order of \u2206P/P ~ 10\u22125) on the same time scale as the activity cycles (typically on the order of decades).\nAnother phenomenon observed in some Algol binaries has been monotonic period increases. This is quite distinct from the far more common observations of alternating period increases and decreases explained by the Applegate mechanism. Monotonic period increases have been attributed to mass transfer, usually (but not always) from the less massive to the more massive star\nDesignations.\nA and B.\nThe components of binary stars are denoted by the suffixes \"A\" and \"B\" appended to the system's designation, \"A\" denoting the primary and \"B\" the secondary. The suffix \"AB\" may be used to denote the pair (for example, the binary star \u03b1 Centauri AB consists of the stars \u03b1 Centauri A and \u03b1 Centauri B.) Additional letters, such as \"C\", \"D\", etc., may be used for systems with more than two stars. In cases where the binary star has a Bayer designation and is widely separated, it is possible that the members of the pair will be designated with superscripts; an example is Zeta Reticuli, whose components are \u03b61 Reticuli and \u03b62 Reticuli.\nDiscoverer designations.\nDouble stars are also designated by an abbreviation giving the discoverer together with an index number. \u03b1 Centauri, for example, was found to be double by Father Richaud in 1689, and so is designated \"RHD 1\". These discoverer codes can be found in the Washington Double Star Catalog.\nHot and cold.\nThe secondary star in a binary star system may be designated as the \"hot companion\" or \"cool companion\", depending on its temperature relative to the primary star.\nExamples:\nEvolution.\nFormation.\nWhile it is not impossible that some binaries might be created through gravitational capture between two single stars, given the very low likelihood of such an event (three objects being actually required, as conservation of energy rules out a single gravitating body capturing another) and the high number of binaries currently in existence, this cannot be the primary formation process. The observation of binaries consisting of stars not yet on the main sequence supports the theory that binaries develop during star formation. Fragmentation of the molecular cloud during the formation of protostars is an acceptable explanation for the formation of a binary or multiple star system.\nThe outcome of the three-body problem, in which the three stars are of comparable mass, is that eventually one of the three stars will be ejected from the system and, assuming no significant further perturbations, the remaining two will form a stable binary system.\nMass transfer and accretion.\nAs a main-sequence star increases in size during its evolution, it may at some point exceed its Roche lobe, meaning that some of its matter ventures into a region where the gravitational pull of its companion star is larger than its own. The result is that matter will transfer from one star to another through a process known as Roche lobe overflow (RLOF), either being absorbed by direct impact or through an accretion disc. The mathematical point through which this transfer happens is called the first Lagrangian point. It is not uncommon that the accretion disc is the brightest (and thus sometimes the only visible) element of a binary star.\nIf a star grows outside of its Roche lobe too fast for all abundant matter to be transferred to the other component, it is also possible that matter will leave the system through other Lagrange points or as stellar wind, thus being effectively lost to both components.\nSince the evolution of a star is determined by its mass, the process influences the evolution of both companions, and creates stages that cannot be attained by single stars.\nStudies of the eclipsing ternary Algol led to the \"Algol paradox\" in the theory of stellar evolution: although components of a binary star form at the same time, and massive stars evolve much faster than the less massive ones, it was observed that the more massive component Algol A is still in the main sequence, while the less massive Algol B is a subgiant at a later evolutionary stage. The paradox can be solved by mass transfer: when the more massive star became a subgiant, it filled its Roche lobe, and most of the mass was transferred to the other star, which is still in the main sequence. In some binaries similar to Algol, a gas flow can actually be seen.\nRunaways and novae.\nIt is also possible for widely separated binaries to lose gravitational contact with each other during their lifetime, as a result of external perturbations. The components will then move on to evolve as single stars. A close encounter between two binary systems can also result in the gravitational disruption of both systems, with some of the stars being ejected at high velocities, leading to runaway stars.\nIf a white dwarf has a close companion star that overflows its Roche lobe, the white dwarf will steadily accrete gases from the star's outer atmosphere. These are compacted on the white dwarf's surface by its intense gravity, compressed and heated to very high temperatures as additional material is drawn in. The white dwarf consists of degenerate matter and so is largely unresponsive to heat, while the accreted hydrogen is not. Hydrogen fusion can occur in a stable manner on the surface through the CNO cycle, causing the enormous amount of energy liberated by this process to blow the remaining gases away from the white dwarf's surface. The result is an extremely bright outburst of light, known as a nova.\nIn extreme cases this event can cause the white dwarf to exceed the Chandrasekhar limit and trigger a supernova that destroys the entire star, another possible cause for runaways. An example of such an event is the supernova SN 1572, which was observed by Tycho Brahe. The Hubble Space Telescope recently took a picture of the remnants of this event.\nAstrophysics.\nBinaries provide the best method for astronomers to determine the mass of a distant star. The gravitational pull between them causes them to orbit around their common center of mass. From the orbital pattern of a visual binary, or the time variation of the spectrum of a spectroscopic binary, the mass of its stars can be determined, for example with the binary mass function. In this way, the relation between a star's appearance (temperature and radius) and its mass can be found, which allows for the determination of the mass of non-binaries.\nBecause a large proportion of stars exist in binary systems, binaries are particularly important to our understanding of the processes by which stars form. In particular, the period and masses of the binary tell us about the amount of angular momentum in the system. Because this is a conserved quantity in physics, binaries give us important clues about the conditions under which the stars were formed.\nCalculating the center of mass in binary stars.\nIn a simple binary case, the distance \"r\"1 from the center of the first star to the center of mass or barycenter is given by\nformula_1\nwhere\nIf \"a\" is taken to be the semimajor axis of the orbit of one body around the other, then \"r\"1 is the semimajor axis of the first body's orbit around the center of mass or \"barycenter\", and \"r\"2 = \"a\" \u2212 \"r\"1 is the semimajor axis of the second body's orbit. When the center of mass is located within the more massive body, that body appears to wobble rather than following a discernible orbit.\nCenter-of-mass animations.\nThe red cross marks the center of mass of the system. These images do not represent any specific real system.\nResearch findings.\nIt is estimated that approximately one third of the star systems in the Milky Way are binary or multiple, with the remaining two thirds being single stars. The overall multiplicity frequency of ordinary stars is a monotonically increasing function of stellar mass. That is, the likelihood of being in a binary or a multi-star system steadily increases as the masses of the components increase.\nThere is a direct correlation between the period of revolution of a binary star and the eccentricity of its orbit, with systems of short period having smaller eccentricity. Binary stars may be found with any conceivable separation, from pairs orbiting so closely that they are practically in contact with each other, to pairs so distantly separated that their connection is indicated only by their common proper motion through space. Among gravitationally bound binary star systems, there exists a so-called log normal distribution of periods, with the majority of these systems orbiting with a period of about 100 years. This is supporting evidence for the theory that binary systems are formed during star formation.\nIn pairs where the two stars are of equal brightness, they are also of the same spectral type.\nIn systems where the brightnesses are different, the fainter star is bluer if the brighter star is a giant star, and redder if the brighter star belongs to the main sequence.\nThe mass of a star can be directly determined only from its gravitational attraction. Apart from the Sun and stars which act as gravitational lenses, this can be done only in binary and multiple star systems, making the binary stars an important class of stars. In the case of a visual binary star, after the orbit and the stellar parallax of the system has been determined, the combined mass of the two stars may be obtained by a direct application of the Keplerian harmonic law.\nUnfortunately, it is impossible to obtain the complete orbit of a spectroscopic binary unless it is also a visual or an eclipsing binary, so from these objects only a determination of the joint product of mass and the sine of the angle of inclination relative to the line of sight is possible. In the case of eclipsing binaries which are also spectroscopic binaries, it is possible to find a complete solution for the specifications (mass, density, size, luminosity, and approximate shape) of both members of the system.\nPlanets.\nWhile a number of binary star systems have been found to harbor extrasolar planets, such systems are comparatively rare compared to single star systems. Observations by the Kepler space telescope have shown that most single stars of the same type as the Sun have plenty of planets, but only one-third of binary stars do. According to theoretical simulations, even widely separated binary stars often disrupt the discs of rocky grains from which protoplanets form. On the other hand, other simulations suggest that the presence of a binary companion can actually improve the rate of planet formation within stable orbital zones by \"stirring up\" the protoplanetary disk, increasing the accretion rate of the protoplanets within.\nDetecting planets in multiple star systems introduces additional technical difficulties, which may be why they are only rarely found. Examples include the white dwarf-pulsar binary PSR B1620-26, the subgiant-red dwarf binary Gamma Cephei, and the white dwarf-red dwarf binary NN Serpentis, among others.\nA study of fourteen previously known planetary systems found three of these systems to be binary systems. All planets were found to be in S-type orbits around the primary star. In these three cases the secondary star was much dimmer than the primary and so was not previously detected. This discovery resulted in a recalculation of parameters for both the planet and the primary star.\nScience fiction has often featured planets of binary or ternary stars as a setting, for example, George Lucas' Tatooine from \"Star Wars\", and one notable story, \"Nightfall\", even takes this to a six-star system. In reality, some orbital ranges are impossible for dynamical reasons (the planet would be expelled from its orbit relatively quickly, being either ejected from the system altogether or transferred to a more inner or outer orbital range), whilst other orbits present serious challenges for eventual biospheres because of likely extreme variations in surface temperature during different parts of the orbit. Planets that orbit just one star in a binary system are said to have \"S-type\" orbits, whereas those that orbit around both stars have \"P-type\" or \"circumbinary\" orbits. It is estimated that 50\u201360% of binary systems are capable of supporting habitable terrestrial planets within stable orbital ranges.\nExamples.\nThe large distance between the components, as well as their difference in color, make Albireo one of the easiest observable visual binaries. The brightest member, which is the third-brightest star in the constellation Cygnus, is actually a close binary itself. Also in the Cygnus constellation is Cygnus X-1, an X-ray source considered to be a black hole. It is a high-mass X-ray binary, with the optical counterpart being a variable star. Sirius is another binary and the brightest star in the night time sky, with a visual apparent magnitude of \u22121.46. It is located in the constellation Canis Major. In 1844 Friedrich Bessel deduced that Sirius was a binary. In 1862 Alvan Graham Clark discovered the companion (Sirius B; the visible star is Sirius A). In 1915 astronomers at the Mount Wilson Observatory determined that Sirius B was a white dwarf, the first to be discovered. In 2005, using the Hubble Space Telescope, astronomers determined Sirius B to be in diameter, with a mass that is 98% of the Sun.\nAn example of an eclipsing binary is Epsilon Aurigae in the constellation Auriga. The visible component belongs to the spectral class F0, the other (eclipsing) component is not visible. The last such eclipse occurred from 2009 to 2011, and it is hoped that the extensive observations that will likely be carried out may yield further insights into the nature of this system. Another eclipsing binary is Beta Lyrae, which is a semidetached binary star system in the constellation of Lyra.\nOther interesting binaries include 61 Cygni (a binary in the constellation Cygnus, composed of two K class (orange) main-sequence stars, 61 Cygni A and 61 Cygni B, which is known for its large proper motion), Procyon (the brightest star in the constellation Canis Minor and the eighth-brightest star in the night time sky, which is a binary consisting of the main star with a faint white dwarf companion), SS Lacertae (an eclipsing binary which stopped eclipsing), V907 Sco (an eclipsing binary which stopped, restarted, then stopped again), BG Geminorum (an eclipsing binary which is thought to contain a black hole with a K0 star in orbit around it), and 2MASS J18082002\u22125104378 (a binary in the \"thin disk\" of the Milky Way, and containing one of the oldest known stars).\nMultiple-star examples.\nSystems with more than two stars are termed multiple stars. Algol is the most noted ternary (long thought to be a binary), located in the constellation Perseus. Two components of the system eclipse each other, the variation in the intensity of Algol first being recorded in 1670 by Geminiano Montanari. The name Algol means \"demon star\" (from \"al-gh\u016bl\"), which was probably given due to its peculiar behavior. Another visible ternary is Alpha Centauri, in the southern constellation of Centaurus, which contains the third-brightest star in the night sky, with an apparent visual magnitude of \u22120.01. This system also underscores the fact that no search for habitable planets is complete if binaries are discounted. Alpha Centauri A and B have an 11\u00a0AU distance at closest approach, and both should have stable habitable zones.\nThere are also examples of systems beyond ternaries: Castor is a sextuple star system, which is the second-brightest star in the constellation Gemini and one of the brightest stars in the nighttime sky. Astronomically, Castor was discovered to be a visual binary in 1719. Each of the components of Castor is itself a spectroscopic binary. Castor also has a faint and widely separated companion, which is also a spectroscopic binary. The Alcor\u2013Mizar visual binary in Ursa Majoris also consists of six stars: four comprising Mizar and two comprising Alcor. QZ Carinae is a complex multiple star system made up of at least nine individual stars.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes and references.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52714", "revid": "47668471", "url": "https://en.wikipedia.org/wiki?curid=52714", "title": "Super Famicom", "text": ""}
{"id": "52716", "revid": "1214952979", "url": "https://en.wikipedia.org/wiki?curid=52716", "title": "Microsoft SharePoint Workspace", "text": "Microsoft SharePoint Workspace (formerly Microsoft Office Groove) is a discontinued desktop application designed for document collaboration in teams with members who are regularly off-line or who do not share the same network security clearance. It is no longer included with Microsoft Office 2013. It has been replaced by a web-based service called OneDrive for Business.\nGroove's uses have included coordination between emergency relief agencies, where different organizations do not share a common security infrastructure and where offline access is important, and amongst teams of knowledge workers, such as consultants who need to work securely on client sites.\nIt is also used as a staging system for documents in development, where content can be developed then transferred to a portal when complete.\nGroove was initially developed by Lotus Notes creator Ray Ozzie, and developed by Groove Networks of Beverly, Massachusetts, until Microsoft's acquisition of Groove Networks in March 2005.\nCollaboration tools.\nGroove's basic set of services (including always-on security, persistent chat, store-and-forward messaging delivery, firewall/NAT transparency, \"ad-hoc\" group formation, and change notification) may be customized with tools.\n\"Tools\" are mini-applications that rely on Groove's underlying functionality to disseminate and synchronize their contents with other members' copies of the workspace. Groove provides various tools that can be added to (and removed from) a workspace to customize the functionality of each space (for example a calendar, discussion, file sharing, an outliner, pictures, notepad, sketchpad, web browser, etc.).\nTools that members use in a workspace often drive the nature of the person-to-person collaboration that ensues. In Groove 2007, the SharePoint Files tools can be used to take SharePoint 2007 document libraries offline.\nGroove 2007 includes a presence subsystem, which keeps track of which users in the contact store are online, and presents the information in the launchbar. If Groove server is used, a user is considered online when they log on to the server. In absence of a server, the \"Device Presence Protocol\" (which comes in different variants for LANs and WANs) is used. Groove also allows sending instant messages to peers. All session and user information is stored by the Groove client at client side.\nVersions.\nGroove Virtual Office 3.1 was the last version before Microsoft's acquisition of Groove Networks. The following versions have been released since:\nMicrosoft claims the name change is a natural progression, since Groove is to SharePoint what Outlook is to Exchange. Microsoft asserts that features have been added to make it easier to deploy and manage, and claims that SharePoint Workspace will make it easier to access SharePoint content (or content from any server that implements the publicly documented protocols).\nServer application.\nMicrosoft Groove Server is a tool for centrally managing all deployments of Microsoft SharePoint Workspace in an enterprise. It enables using Active Directory for Groove user accounts, and create Groove Domains, with individual policy settings.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52717", "revid": "40781349", "url": "https://en.wikipedia.org/wiki?curid=52717", "title": "Louis Sullivan", "text": "American architect (1856\u20131924)\nLouis Henry Sullivan (September 3, 1856\u00a0\u2013 April 14, 1924) was an American architect, and has been called a \"father of skyscrapers\" and \"father of modernism\". He was an influential architect of the Chicago School, a mentor to Frank Lloyd Wright, and an inspiration to the Chicago group of architects who have come to be known as the Prairie School. Along with Wright and Henry Hobson Richardson, Sullivan is one of \"the recognized trinity of American architecture.\" The phrase \"form follows function\" is attributed to him; it encapsulated earlier theories of architecture and he applied them to the modern age of the skyscraper. In 1944, Sullivan was the second architect to posthumously receive the AIA Gold Medal.\nEarly life and career.\nSullivan was born to a Swiss-born mother, Andrienne n\u00e9e List (who had emigrated to Boston from Geneva with her parents and two siblings, Jenny, b. 1836, and Jules, b. 1841) and an Irish-born father, Patrick Sullivan. Both had immigrated to the United States in the late 1840s. He learned that he could both graduate from high school a year early and bypass the first two years at the Massachusetts Institute of Technology by passing a series of examinations. Entering MIT at the age of sixteen, Sullivan studied architecture there briefly. After one year of study, he moved to Philadelphia and took a job with architect Frank Furness.\nThe Depression of 1873 dried up much of Furness's work, and he was forced to let Sullivan go. Sullivan moved to Chicago in 1873 to take part in the building boom following the Great Chicago Fire of 1871. He worked for William LeBaron Jenney, the architect often credited with erecting the first steel frame building. After less than a year with Jenney, Sullivan moved to Paris and studied at the \u00c9cole des Beaux-Arts for a year. He returned to Chicago and began work for the firm of Joseph S. Johnston &amp; John Edelman as a draftsman. Johnston &amp; Edleman were commissioned for the design of the Moody Tabernacle, and tasked Sullivan with the design of the interior decorative \"fresco secco\" stencils (stencil technique applied on dry plaster). In 1879 Dankmar Adler hired Sullivan. A year later, Sullivan became a partner in Adler's firm. The time at Adler &amp; Sullivan marked the beginning of Sullivan's most productive years.\nAdler and Sullivan initially achieved fame as theater architects. While most of their theaters were in Chicago, their fame won commissions as far west as Pueblo, Colorado, and Seattle, Washington (unbuilt). The culminating project of this phase of the firm's history was the 1889 Auditorium Building (1886\u201390, opened in stages) in Chicago, an extraordinary mixed-use building that included not only a 4,200-seat theater, but also a hotel and an office building with a 17-story tower and commercial storefronts at the ground level of the building, fronting Congress and Wabash Avenues. After 1889 the firm became known for their office buildings, particularly the 1891 Wainwright Building in St. Louis and the Schiller (later Garrick) Building and theater (1890) in Chicago. Other buildings often noted include the Chicago Stock Exchange Building (1894), the Guaranty Building (also known as the Prudential Building) of 1895\u201396 in Buffalo, New York, and the 1899\u20131904 Carson Pirie Scott Department Store by Sullivan on State Street in Chicago.\nSullivan and the steel high-rise.\nPrior to the late nineteenth century, the weight of a multi-story building had to be supported principally by the strength of its walls. The taller the building, the more strain this placed on the lower sections of the building; since there were clear engineering limits to the weight such \"load-bearing\" walls could sustain, tall designs meant massively thick walls on the ground floors, and definite limits on the building's height.\nThe development of cheap, versatile steel in the second half of the nineteenth century changed those rules. America was in the midst of rapid social and economic growth that made for great opportunities in architectural design. A much more urbanized society was forming and the society called out for new, larger buildings. The mass production of steel was the main driving force behind the ability to build skyscrapers during the mid-1880s. By assembling a framework of steel girders, architects and builders could create tall, slender buildings with a strong and relatively lightweight steel skeleton. The rest of the building elements\u2014walls, floors, ceilings, and windows\u2014were suspended from the skeleton, which carried the weight. This new way of constructing buildings, so-called \"column-frame\" construction, pushed them up rather than out. The steel weight-bearing frame allowed not just taller buildings, but permitted much larger windows, which meant more daylight reaching interior spaces. Interior walls became thinner, which created more usable (and rentable) floor space.\nChicago's Monadnock Building (not designed by Sullivan) straddles this remarkable moment of transition: the northern half of the building, finished in 1891, is of load-bearing construction, while the southern half, finished only two years later, is of column-frame construction. While experiments in this new technology were taking place in many cities, Chicago was the crucial laboratory. Industrial capital and civic pride drove a surge of new construction throughout the city's downtown in the wake of the 1871 fire.\nThe technical limits of weight-bearing masonry had imposed formal as well as structural constraints; suddenly, those constraints were gone. None of the historical precedents needed to be applied and this new freedom resulted in a technical and stylistic crisis of sorts. Sullivan addressed it by embracing the changes that came with the steel frame, creating a grammar of form for the high rise (base, shaft, and cornice), simplifying the appearance of the building by breaking away from historical styles, using his own intricate floral designs, in vertical bands, to draw the eye upward and to emphasize the vertical form of the building, and relating the shape of the building to its specific purpose. All this was revolutionary, appealingly honest, and commercially successful.\nIn 1896, Louis Sullivan wrote:\nIt is the pervading law of all things organic and inorganic, of all things physical and metaphysical, of all things human, and all things super-human, of all true manifestations of the head, of the heart, of the soul, that the life is recognizable in its expression, that form ever follows function. \"This is the law.\" (italics in original)\n\"Form follows function\" would become one of the prevailing tenets of modern architects.\nSullivan attributed the concept to Marcus Vitruvius Pollio, the Roman architect, engineer, and author, who first asserted in his book, \"De architectura (On architecture)\", that a structure must exhibit the three qualities of \"firmitas, utilitas, venustas\" \u2013 that is, it must be \"solid, useful, beautiful.\" This credo, which placed the demands of practical use equal to aesthetics, later would be taken by influential designers to imply that decorative elements, which architects call \"ornament\", were superfluous in modern buildings, but Sullivan neither thought nor designed along such dogmatic lines during the peak of his career and this credo never put one concept above another. While his buildings could be spare and crisp in their principal masses, he often punctuated their plain surfaces with eruptions of lush Art Nouveau or Celtic Revival decorations, usually cast in iron or terra cotta, and ranging from organic forms, such as vines and ivy, to more geometric designs and interlace, inspired by his Irish design heritage. Terra cotta is lighter and easier to work with than stone masonry. Sullivan used it in his architecture because it had a malleability that was appropriate for his ornament. Probably the most famous example of ornament used by Sullivan is the writhing green ironwork that covers the entrance canopies of the Carson Pirie Scott store on south State Street.\nSuch ornaments, often executed by the talented younger draftsmen in Sullivan's employ, eventually would become Sullivan's trademark; to students of architecture, they are instantly recognizable as his signature.\nAnother signature element of Sullivan's work is the massive, semi-circular arch. Sullivan employed such arches throughout his career\u2014in shaping entrances, in framing windows, or as interior design.\nAll of these elements are found in Sullivan's widely admired Guaranty Building, which he designed while partnered with Adler. Completed in 1895, this office building in Buffalo, New York is in the Palazzo style, visibly divided into three \"zones\" of design: a plain, wide-windowed base for the ground-level shops; the main office block, with vertical ribbons of masonry rising unimpeded across nine upper floors to emphasize the building's height; and an ornamented cornice perforated by round windows at the roof level, where the building's mechanical units (such as the elevator motors) were housed. The cornice is covered by Sullivan's trademark Art Nouveau vines and each ground-floor entrance is topped by a semi-circular arch.\nBecause Sullivan's remarkable accomplishments in design and construction occurred at such a critical time in architectural history, he often has been described as the \"father\" of the American skyscraper. But many architects had been building skyscrapers before or as contemporaries of Sullivan; they were designed as an expression of new technology. Chicago was replete with extraordinary designers and builders in the late years of the nineteenth century, including Sullivan's partner, Dankmar Adler, as well as Daniel Burnham and John Wellborn Root. Root was one of the builders of the Monadnock Building (see above). That and another Root design, the Masonic Temple Tower (both in Chicago), are cited by many as the originators of skyscraper aesthetics of bearing wall and column-frame construction, respectively.\nLater career and decline.\nIn 1890, Sullivan was one of the ten U.S. architects, five from the east and five from the west, chosen to build a major structure for the \"White City\", the World's Columbian Exposition, held in Chicago in 1893. Sullivan's massive Transportation Building and huge arched \"Golden Door\" stood out as the only building not of the current Beaux-Arts style, and with the only multicolored facade in the entire White City. Sullivan and fair director Daniel Burnham were vocal about their displeasure with each other. Sullivan later claimed (1922) that the fair set the course of American architecture back \"for half a century from its date, if not longer.\" His was the only building to receive extensive recognition outside America, receiving three medals from the French-based \"Union Centrale des Arts Decoratifs\" the following year.\nLike all American architects, Adler and Sullivan suffered a precipitous decline in their practice with the onset of the Panic of 1893. According to Charles Bebb, who was working in the office at that time, Adler borrowed money to try to keep employees on the payroll. By 1894, however, in the face of continuing financial distress with no relief in sight, Adler and Sullivan dissolved their partnership. The Guaranty Building was considered the last major project of the firm.\nBy both temperament and connections, Adler had been the one who brought in new business to the partnership, and following the rupture Sullivan received few large commissions after the Carson Pirie Scott Department Store. He went into a twenty-year-long financial and emotional decline, beset by a shortage of commissions, chronic financial problems, and alcoholism. He obtained a few commissions for small-town Midwestern banks (see below), wrote books, and in 1922 appeared as a critic of Raymond Hood's winning entry for the Tribune Tower competition.\nIn 1922, Sullivan was paid $100 a month to write an autobiography in installments to be published in the journal for the American Institute of Architects. Sullivan worked on the series with Journal editor Charles Harris Whitaker, who advised he \"plot out the material by periods.\" \"The Autobiography of an Idea\" began its publication in the June 1922 Journal for the American Institute of Architects and upon its conclusion was published as a book.\nHe died in a Chicago hotel room on April 14, 1924. He left a wife, Mary Azona Hattabaugh, from whom he was separated. A modest headstone marks his final resting spot in Graceland Cemetery in Chicago's Uptown and Lake View neighborhood. Later, a monument was erected in Sullivan's honor, a few feet from his headstone.\nLegacy.\nSullivan's legacy is contradictory. Some consider him the first modernist. His forward-looking designs clearly anticipate some issues and solutions of Modernism; however, his embrace of ornament makes his contribution distinct from the Modern Movement that coalesced in the 1920s and became known as the \"International Style\". Sullivan's built work expresses the appeal of his incredible designs: the vertical bands on the Wainwright Building, the burst of welcoming Art Nouveau ironwork on the corner entrance of the Carson Pirie Scott store, the (lost) terra cotta griffins and porthole windows on the Union Trust building, and the white angels of the Bayard Building, Sullivan's only work in New York City. Except for some designs by his longtime draftsman George Grant Elmslie, and the occasional tribute to Sullivan such as Schmidt, Garden &amp; Martin's First National Bank in Pueblo, Colorado (built across the street from Adler and Sullivan's Pueblo Opera House), his style is unique. A visit to the preserved Chicago Stock Exchange trading floor, now at The Art Institute of Chicago, is proof of the immediate and visceral power of the ornament that he used so selectively.\nAfter his death Sullivan was referred to as a bold architect: \"Boldly he challenged the whole theory of copying and imitating, and the catchword of \"precedent\", declaring that architecture was naturally a living and creative art.\"\nOriginal drawings and other archival materials from Sullivan are held by the Ryerson &amp; Burnham Libraries in the Art Institute of Chicago and by the drawings and archives department in the Avery Architectural and Fine Arts Library at Columbia University. Fragments of Sullivan buildings also are held in many fine art and design museums around the world.\nPreservation.\nDuring the postwar era of urban renewal, Sullivan's works fell into disfavor, and many were demolished. In the 1970s, growing public concern for these buildings finally resulted in many being saved. The most vocal voice was Richard Nickel, who organized protests against the demolition of architecturally significant buildings. Nickel and others sometimes rescued decorative elements from condemned buildings, sneaking in during demolition. Nickel died inside Sullivan's Stock Exchange building while trying to retrieve some elements, when a floor above him collapsed. Nickel had compiled extensive research on Adler and Sullivan and their many architectural commissions, which he intended to publish in book form.\nAfter Nickel's death, in 1972, the Richard Nickel Committee was formed, to arrange for completion of his book, which was published in 2010. The book features all 256 commissions of Adler and Sullivan. The extensive archive of photographs and research that underpinned the book was donated to the Ryerson and Burnham Libraries at The Art Institute of Chicago. More than 1,300 photographs may be viewed on their website and more than 15,000 photographs are part of the collection at The Art Institute of Chicago. As finally published, the book, \"The Complete Architecture of Adler &amp; Sullivan\", was authored by Richard Nickel, Aaron Siskind, John Vinci, and Ward Miller.\nAnother champion of Sullivan's legacy was the architect Crombie Taylor (1907\u20131991), of Crombie Taylor Associates. After working in Chicago, where he headed the famous \"Institute of Design\" (later known as the Illinois Institute of Technology (IIT)) in the 1950s and early 1960s, he moved to Southern California. He led the effort to save the Van Allen Building in Clinton, Iowa from demolition. Taylor, acting as an aesthetic consultant, worked on the renovation of the Auditorium Building (now Roosevelt University) in Chicago.\nWhen he read an article about the planned demolition in Clinton, he uprooted his family from their home in southern California and moved them to Iowa. With the vision of a destination neighborhood comparable to Oak Park, Illinois, he set about creating a nonprofit to save the building, and was successful in doing so. Another advocate for the buildings of both Sullivan and Wright was Jack Randall, who led an effort to save the Wainwright Building in St. Louis, Missouri at a very critical time. He relocated his family to Buffalo, New York to save Sullivan's Guaranty Building and Frank Lloyd Wright's Darwin Martin House from possible demolition. His efforts were successful in both St. Louis and Buffalo.\nA collection of architectural ornaments designed by Sullivan is on permanent display at Lovejoy Library at Southern Illinois University Edwardsville. The St. Louis Art Museum also has Sullivan architectural elements displayed. The City Museum in St. Louis has a large collection of Sullivan ornamentation on display, including a cornice from the demolished Chicago Stock Exchange, 29 feet long on one side, 13 feet on another, and nine feet high.\nThe Guaranty Building Interpretive Center in Buffalo, on the first floor of the building now owned and occupied by the law firm Hodgson Russ, LLP, opened in 2017. The exhibit space was financed by Hodgson Russ and co-designed by Flynn Battaglia Architects and Hadley Exhibits. It features a scale model of the building by David J. Carli, professor of engineering at the State University of New York at Alfred. The center's exhibits were donated to Preservation Buffalo Niagara. The center, the only museum dedicated to Sullivan, is open to the public.\nSullivan in Ayn Rand's \"The Fountainhead\".\nThat the fictional character of Henry Cameron in Ayn Rand's 1943 novel \"The Fountainhead\" was similar to the real-life Sullivan was noted, if only in passing, by at least one journalist contemporary to the book.\nAlthough Rand's journal notes contain \"in toto\" only some 50 lines directly referring to Sullivan, it is clear from her mention of Sullivan's \"Autobiography of an Idea\" (1924) in her 25th-anniversary introduction to her earlier novel \"We the Living\" (first published in 1936, and unrelated to architecture) that she was intimately familiar with his life and career. The term \"the Fountainhead\", which appears nowhere in Rand's novel proper, is found twice (as \"the fountainhead\" and later as \"the fountain head\") in Sullivan's autobiography, both times used metaphorically.\nThe fictional Cameron is, like Sullivan \u2013 whose physical description he matches \u2013 a great innovative skyscraper pioneer late in the nineteenth century who dies impoverished and embittered in the mid-1920s. Cameron's rapid decline is explicitly attributed to the wave of classical Greco-Roman revivalism in architecture in the wake of the 1893 World's Columbian Exposition, just as Sullivan in his autobiography attributed his own downfall to the same event.\nThe major difference between novel and real life was in the chronology of Cameron's relation with his prot\u00e9g\u00e9 Howard Roark, the novel's hero, who eventually goes on to redeem his vision. That Roark's uncompromising individualism and his innovative organic style in architecture were drawn from the life and work of Frank Lloyd Wright is clear from Rand's journal notes, her correspondence, and various contemporary accounts. In the novel, however, the 23-year-old Roark, a generation younger than the real-life Wright, becomes Cameron's prot\u00e9g\u00e9 in the early 1920s, when Sullivan was long in decline.\nThe young Wright, by contrast, was Sullivan's prot\u00e9g\u00e9 for seven years, beginning in 1887, when Sullivan was at the height of his fame and power. The two architects would sever their ties in 1894 due to Sullivan's angry reaction to Wright's moonlighting in breach of his contract with Sullivan, but Wright continued to call Sullivan \"lieber Meister\" (\"beloved Master\") for the rest of his life. After decades of estrangement, Wright would again become close to the now-destitute Sullivan in the early 1920s, the time when Roark first comes under the likewise impoverished Cameron's tutelage in the novel. Wright, however, was now in his fifties. Nevertheless, both the young Roark and middle-aged Wright had in common at that time that they both faced a decade of struggle ahead. After the triumphs earlier in his career, Wright came increasingly to be viewed as a has-been, until he experienced a renaissance in the latter half of the 1930s with such projects as Fallingwater and the Johnson Wax Headquarters.\nSelected projects.\nBuildings 1887\u20131895 by Adler &amp; Sullivan:\nBuildings 1887\u20131922 by Louis Sullivan:\nBanks.\nBy the end of the first decade of the twentieth century, Sullivan's star was well on the descent and, for the remainder of his life, his output consisted primarily of a series of small bank and commercial buildings in the Midwest. Yet a look at these buildings clearly reveals that Sullivan's muse had not abandoned him. When the director of a bank that was considering hiring him asked Sullivan why they should engage him at a cost higher than the bids received for a conventional Neo-Classic styled building from other architects, Sullivan is reported to have replied, \"A thousand architects could design those buildings. Only I can design this one.\" He got the job. Today these commissions are collectively referred to as Sullivan's \"Jewel Boxes\". All still stand.\nThe entrance and other portions of the building were removed prior to the demolition and subsequently were restored in the Art Institute of Chicago in 1977; the entryway arch (seen at right) stands outside on the northeast corner of the AIC site\nReferences.\nNotes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography"}
