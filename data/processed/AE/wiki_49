{"id": "50534", "revid": "2387872", "url": "https://en.wikipedia.org/wiki?curid=50534", "title": "Caroline of Ansbach", "text": "Queen of Great Britain and Ireland from 1727 to 1737\nCaroline of Brandenburg-Ansbach (Wilhelmina Charlotte Caroline; 1 March 1683\u00a0\u2013 20 November 1737) was Queen of Great Britain and Ireland and Electress of Hanover from 11 June 1727 (O.S.) until her death in 1737 as the wife of King George II.\nCaroline's father, Margrave John Frederick of Brandenburg-Ansbach, belonged to a branch of the House of Hohenzollern and was the ruler of a small German state, the Principality of Ansbach. After Caroline was orphaned at a young age, she moved to the enlightened court of her guardians, King Frederick I and Queen Sophia Charlotte of Prussia. At the Prussian court, her previously limited education was widened and she adopted the liberal outlook possessed by Sophia Charlotte, who became her good friend and whose views influenced Caroline all her life.\nWhen she was a young woman, Caroline was much sought after as a bride. After rejecting the suit of Archduke Charles of Austria, a claimant to the Spanish throne, she married George Augustus, who was third in line to the English throne (and subsequently the British throne) and heir apparent to the Electorate of Hanover. They had eight children, seven of whom reached adulthood. Caroline moved to Britain permanently in 1714 when her husband became Prince of Wales. As Princess of Wales she joined George Augustus in rallying political opposition to his father, King George I. In 1717, after a family row, George Augustus was expelled from court. Caroline came to be associated with Robert Walpole, an opposition politician who was a former government minister. Walpole rejoined the government in 1720, and George Augustus reconciled publicly with his father on Walpole's advice. Over the next few years Walpole rose to become the leading minister.\nUpon her husband's accession in 1727, Caroline became queen and electress, and her eldest son, Frederick, became Prince of Wales. He was a focus for the opposition, like his father before him, and Caroline's relationship with him was strained. As princess and as queen, Caroline was known for her political influence, which she exercised both through and for Walpole. Her tenure included four regencies, which occurred during George II's stays in Hanover; she is credited with strengthening the House of Hanover's place in Britain during a period of political instability. After her death in 1737, Caroline was widely mourned by her political allies as well as by the King, who refused to remarry.\nEarly life.\nCaroline was born on 1 March 1683 at Ansbach, the daughter of John Frederick, Margrave of Brandenburg-Ansbach, and his second wife, Princess Eleonore Erdmuthe of Saxe-Eisenach. Her father was the ruler of one of the smallest German states; he died of smallpox at the age of 32, when Caroline was three years old. Caroline and her only full sibling, her younger brother Margrave William Frederick, left Ansbach with their mother, who returned to her native Eisenach.\nIn 1692, Caroline's widowed mother was pushed into an unhappy marriage with the Elector of Saxony, and she and her two children moved to the Saxon court at Dresden. Eleonore Erdmuthe was widowed again two years later, after her unfaithful husband contracted smallpox from his mistress. Eleonore remained in Saxony for another two years, until her death in 1696. The orphaned Caroline and William Frederick returned to Ansbach to stay with their elder half-brother, Margrave George Frederick II. George Frederick was a youth with little interest in parenting a girl, and so Caroline soon moved to L\u00fctzenburg outside Berlin, where she entered into the care of her new guardians, Frederick, Elector of Brandenburg, and his wife, Sophia Charlotte, who had been a friend of Eleonore Erdmuthe.\nEducation.\nFrederick and Sophia Charlotte became king and queen of Prussia in 1701. The Queen was the daughter of Sophia, Dowager Electress of Hanover, and the sister of George, Elector of Hanover. She was renowned for her intelligence and strong character, and her uncensored and liberal court attracted a great many scholars, including philosopher Gottfried Leibniz. Caroline was exposed to a lively intellectual environment quite different from anything she had experienced previously. Before she began her education under Sophia Charlotte's care, Caroline had received little formal education; her handwriting remained poor throughout her life. With her lively mind, Caroline developed into a scholar of considerable ability. She and Sophia Charlotte developed a strong relationship in which Caroline was treated as a surrogate daughter; the Queen once declared Berlin was \"a desert\" without Caroline whenever she left temporarily for Ansbach.\nMarriage.\nAn intelligent and attractive woman, Caroline was much sought after as a bride. Dowager Electress Sophia and British diplomat Edmund Poley both called her \"the most agreeable Princess in Germany\". She was considered for the hand of Archduke Charles of Austria, who was a candidate for the throne of Spain and later became Holy Roman Emperor. Charles made official overtures to her in 1703, and the match was encouraged by King Frederick of Prussia. After some consideration, Caroline refused in 1704, as she would not convert from Lutheranism to Catholicism. Early in the following year, Queen Sophia Charlotte died on a visit to her native Hanover. Caroline was devastated, writing to Leibniz, \"The calamity has overwhelmed me with grief and sickness, and it is only the hope that I may soon follow her that consoles me.\"\nIn June 1705, Sophia Charlotte's nephew Prince George Augustus of Hanover visited the Ansbach court, supposedly incognito, to inspect Caroline, as his father the Elector did not want his son to enter into a loveless arranged marriage as he himself had. The nephew of three childless uncles, George Augustus was under pressure to marry and father an heir to prevent endangering the Hanoverian succession. He had heard reports of Caroline's \"incomparable beauty and mental attributes\". He immediately took a liking to her \"good character\" and the British envoy reported that George Augustus \"would not think of anybody else after her\". For her part, Caroline was not fooled by the prince's disguise, and found her suitor attractive. He was the heir apparent of his father's Electorate of Hanover and third-in-line to the English throne, then held by his distant cousin Queen Anne, after his grandmother Dowager Electress Sophia and his father the Elector.\nOn 22 August 1705, Caroline arrived in Hanover for her wedding to George Augustus; they were married that evening in the palace chapel at Herrenhausen. By May of the following year, Caroline was pregnant, and her first child Prince Frederick was born on 20 January 1707. A few months after the birth, in July, Caroline fell seriously ill with smallpox followed by pneumonia. Her baby was kept away from her, but George Augustus remained devotedly at her side, catching the infection himself. They both survived. Over the next seven years, Caroline had three more children, Anne, Amelia, and Caroline, all of whom were born in Hanover.\nGeorge Augustus and Caroline had a successful and loving marriage, though he continued to keep mistresses, as was customary for the time. Caroline was aware of his infidelities; they were well known and he told her about them himself. His two best-known mistresses were Henrietta Howard, later Countess of Suffolk, and, beginning in 1735, Amalie von Wallmoden, Countess of Yarmouth. Howard was one of Caroline's Women of the Bedchamber and became Mistress of the Robes when her husband inherited a peerage in 1731; she retired in 1734. In contrast with George Augustus and his mother, Sophia Dorothea, Caroline was known for her marital fidelity; she never made any embarrassing scenes nor did she take lovers. She preferred her husband's mistresses to be her ladies-in-waiting so that she could keep a closer eye on them.\nAfter the union of England and Scotland in 1707, the succession of George Augustus's family to the united British throne was confirmed but insecure, since Queen Anne's half-brother James Stuart contested the Hanoverian claim, and Anne had fallen out with Dowager Electress Sophia. The Queen refused permission for any of the Hanoverians to visit Britain in her lifetime. Caroline wrote to Leibniz, \"I accept the comparison which you draw, though all too flattering, between me and Queen Elizabeth as a good omen. Like Elizabeth, the Electress's rights are denied her by a jealous sister [Queen Anne], and she will never be sure of the English crown until her accession to the throne.\" In June 1714, Sophia died in Caroline's arms at the age of 83, and Caroline's father-in-law became Queen Anne's heir presumptive. Just weeks later, Anne died, and the Elector of Hanover was proclaimed her successor, becoming George I of Great Britain.\nPrincess of Wales.\nGeorge Augustus sailed to England in September 1714, and Caroline and two of her daughters followed in October. Her journey across the North Sea from The Hague to Margate was the only sea voyage she took in her life. Their young son, Prince Frederick, remained in Hanover for the rest of George I's reign, and was brought up by private tutors.\nOn the accession of George I in 1714, George Augustus automatically became Duke of Cornwall and Duke of Rothesay. Shortly afterwards, he was invested as Prince of Wales, whereupon Caroline became Princess of Wales. She was the first woman to receive the title at the same time as her husband received his. She was also the first Princess of Wales in over two hundred years, the previous one being Catherine of Aragon in the 16th century. Since George I had repudiated his wife, Sophia Dorothea of Celle, in 1694 before he became King of Great Britain, there was no queen consort, and Caroline was therefore the highest-ranking woman in the kingdom. George Augustus and Caroline made a concerted effort to \"anglicise\" by getting to know England's language, people, politics and customs. Two separate and very different courts developed: the old king's court had German courtiers and government ministers, while the Wales's court attracted English nobles who were out of favour with the King, and was considerably more popular with the British people. George Augustus and Caroline gradually became centres of the political opposition to the King.\nTwo years after their arrival in England, Caroline suffered a stillbirth, which her friend the Countess of B\u00fcckeburg blamed on the incompetence of English doctors, but the following year she had another son, Prince George William, in November. At the baptism, George Augustus fell out with his father over the choice of godparents, leading to the couple's placement under house arrest at St James's Palace prior to their banishment from court. Caroline was originally allowed to stay with their children, but refused as she believed her place was with George Augustus. The couple moved into Leicester House, while their children remained in the care of the King. Caroline fell sick with worry, and fainted during a secret visit to her children made without the King's approval. By January, the King had relented and allowed Caroline unrestricted access. In February, Prince George William fell ill, and the King allowed both George Augustus and Caroline to see him at Kensington Palace without any conditions. When the baby died, a post-mortem was conducted to prove that the cause of death was disease (a polyp on the heart) rather than the separation from his mother. Further tragedy occurred in 1718, when she miscarried at Richmond Lodge, her country residence, after being startled by a violent storm. Over the next few years, Caroline had three more children: William, Mary and Louise. In July 1725, her 11th and final pregnancy ended in a second miscarriage.\nLeicester House became a frequent meeting place for the ministry's political opponents. Caroline struck up a friendship with politician Sir Robert Walpole, a former minister in the Whig government who led a disgruntled faction of the party. In April 1720, Walpole's wing of the Whig party reconciled with the governing wing, and Walpole and Caroline helped to effect a reconciliation between the King and George Augustus for the sake of public unity. Caroline wanted to regain her three eldest daughters, who remained in the care of the King, and thought the reconciliation would lead to their return, but negotiations came to nothing. George Augustus came to believe that Walpole had tricked him into the reconciliation as part of a scheme to gain power. The prince was isolated politically when Walpole's Whigs joined the government, and Leicester House played host to literary figures and wits, such as John Arbuthnot and Jonathan Swift, rather than politicians. Arbuthnot told Swift that Caroline had enjoyed his \"Gulliver's Travels\", particularly the tale of the crown prince who wore one high-heel and one low-heel in a country where the King and his party wore low heels, and the opposition wore high ones: a barely veiled reference to the political leanings of the Prince of Wales.\nCaroline's intellect far outstripped her husband's, and she read avidly. She established an extensive library at St James's Palace. As a young woman, she corresponded with Gottfried Leibniz, the intellectual colossus who was courtier and factotum to the House of Hanover. She later facilitated the Leibniz-Clarke correspondence, arguably the most important philosophy of physics discussion of the 18th century. She helped to popularise the practice of variolation (an early type of immunisation), which had been witnessed by Lady Mary Wortley Montagu and Charles Maitland in Constantinople. With Caroline's support, six condemned prisoners from Newgate Prison were offered the chance to undergo variolation instead of execution: they all survived the procedure, as did six orphan children given the same treatment as a further test. Convinced of its medical value, Caroline had her children Amelia, Caroline and Frederick inoculated against smallpox in the same manner. In praising her support for smallpox inoculation, Voltaire wrote of her, \"I must say that despite all her titles and crowns, this princess was born to encourage the arts and the well-being of mankind; even on the throne she is a benevolent philosopher; and she has never lost an opportunity to learn or to manifest her generosity.\"\nQueen consort and regent.\nOn George I's death in 1727, George Augustus ascended as George II and Caroline became queen consort. George II and Caroline's coronation was held at Westminster Abbey on 11 October that year. Though George II denounced Walpole as a \"rogue and rascal\" over the terms of the reconciliation with his father, Caroline advised her husband to retain Walpole as the leading minister. Walpole commanded a substantial majority in Parliament and George II had little choice but to accept him or risk ministerial instability. Walpole secured a civil list payment of \u00a3100,000 a year for Caroline, and she was given both Somerset House and Richmond Lodge. Courtier Lord Hervey called Walpole \"the Queen's minister\" in recognition of their close relationship. For the next ten years, Caroline had immense influence. She persuaded the King to adopt policies at the behest of Walpole, and persuaded Walpole against taking inflammatory actions. Caroline had absorbed the liberal opinions of her mentor, Queen Sophia Charlotte of Prussia, and supported clemency for the Jacobites (supporters of the rival Stuart claim to the throne), freedom of the press, and freedom of speech in Parliament.\nOver the next few years, the King and Queen fought a constant battle against their eldest son, Frederick, Prince of Wales, who had been left behind in Germany when they came to England. He joined the family in 1728, by which time he was an adult, had mistresses and debts, and was fond of gambling and practical jokes. He opposed his father's political beliefs, and complained of his lack of influence in government. The Regency Act 1728 made Caroline rather than Frederick regent when her husband was in Hanover for five months from May 1729. During her regency, a diplomatic incident with Portugal (where a British ship had been seized on the Tagus) was defused, and the negotiation of the Treaty of Seville between Britain and Spain was concluded. From May 1732, she was regent for four months while George II was again away in Hanover. An investigation into the penal system uncovered widespread abuses, including cruel treatment and conspiracy in the escape of wealthy convicts. Caroline pressed Walpole for reform, largely unsuccessfully. In March 1733, Walpole introduced an unpopular Excise Bill to parliament, which the Queen supported, but it gathered such strong opposition that it was eventually dropped.\nCaroline's entire life in Britain was spent in southeast England in or around London. As queen, she continued to surround herself with artists, writers and intellectuals. She collected jewellery, especially cameos and intaglios, acquired important portraits and miniatures, and enjoyed the visual arts. She commissioned works such as terracotta busts of the kings and queens of England from Michael Rysbrack, and supervised a more naturalistic design of the royal gardens by William Kent and Charles Bridgeman. In 1728, she rediscovered sets of sketches by Leonardo da Vinci and Hans Holbein that had been hidden in a drawer since the reign of William III.\nCaroline's eldest daughter, Anne, married William IV of Orange in 1734 and moved with her husband to the Netherlands. Caroline wrote to her daughter of her \"indescribable\" sadness at the parting. Anne soon felt homesick and travelled back to England when her husband went on campaign. Eventually her husband and father commanded her to return to Holland.\nFinal years.\nIn mid-1735, Prince Frederick was further dismayed when Caroline, rather than himself, again acted as regent while the King was absent in Hanover. The King and Queen arranged Frederick's marriage, in 1736, to Princess Augusta of Saxe-Gotha. Shortly after the wedding, George went to Hanover, and Caroline resumed her role as \"Protector of the Realm\". As regent, Caroline considered the reprieve of Captain John Porteous, who had been convicted of murder in Edinburgh. Before she could act, a mob stormed the jail where he was held and killed him. Caroline was appalled. George's absences abroad were leading to unpopularity, and in late 1736 he made plans to return, but his ship was caught in poor weather, and it was rumoured that he had been lost at sea. Caroline was devastated, and disgusted by the insensitivity of her son, who hosted a grand dinner while the gale was blowing. During her regency, Frederick attempted to start a number of quarrels with his mother, whom he saw as a useful proxy to irritate the King. George eventually returned in January 1737.\nFrederick applied to Parliament unsuccessfully for an increased financial allowance that had hitherto been denied him by the King, and public disagreement over the money drove a further wedge between parents and son. On the advice of Walpole, Frederick's allowance was raised in an attempt to mitigate further conflict, but by less than he had asked. In June 1737, Frederick informed his parents that Augusta was pregnant, and due to give birth in October. In fact, Augusta's due date was earlier and a peculiar episode followed in July in which the prince, on discovering that his wife had gone into labour, sneaked her out of Hampton Court Palace in the middle of the night, to ensure that the King and Queen could not be present at the birth. George and Caroline were horrified. Traditionally, royal births were witnessed by members of the family and senior courtiers to guard against supposititious children, and Augusta had been forced by her husband to ride in a rattling carriage for an hour and a half while heavily pregnant and in pain. With a party including her daughters Amelia and Caroline and Lord Hervey, the Queen raced over to St James's Palace, where Frederick had taken Augusta. Caroline was relieved to discover that Augusta had given birth to a \"poor, ugly little she-mouse\", also called Augusta, rather than a \"large, fat, healthy boy\" as the pitiful nature of the baby made a supposititious child unlikely. The circumstances of the birth deepened the estrangement between mother and son. According to Lord Hervey, she once remarked after seeing Frederick, \"Look, there he goes\u2014that wretch!\u2014that villain!\u2014I wish the ground would open this moment and sink the monster to the lowest hole in hell!\"\nIn the final years of her life, Caroline was troubled by gout in her feet, but more seriously she had suffered an umbilical hernia at the birth of her final child in 1724. On 9 November 1737, she felt an intense pain and, after struggling through a formal reception, took to her bed. Part of her small intestine had poked through the hernia opening. Over the next few days she was bled, purged, and operated on, without anaesthetic, but there was no improvement in her condition. George refused Frederick permission to see his mother, a decision with which she complied; she sent her son a message of forgiveness through Walpole. She asked her husband to remarry after her death, which he rejected saying he would take only mistresses; she replied \"Ah, mon Dieu, cela n'emp\u00eache pas\" (\"My God, that doesn't prevent it\"). On 17 November, her strangulated bowel burst. She died on 20 November 1737 at St James's Palace.\nCaroline was buried in Westminster Abbey on 17 December. Frederick was not invited to the funeral. George Frideric Handel composed an anthem for the occasion, \"The Ways of Zion Do Mourn / Funeral Anthem for Queen Caroline\". George arranged for a pair of matching coffins with removable sides, so that when he followed her to the grave (23 years later), they could lie together again.\nLegacy.\nCaroline was widely mourned. The Protestants lauded her moral example, and even the Jacobites acknowledged her compassion, and her intervention on the side of mercy for their compatriots. During her lifetime her refusal to convert when offered the hand of Archduke Charles was used to portray her as a strong adherent to Protestantism. For example, John Gay wrote of Caroline in \"A Letter to A Lady\" (1714):\nThe pomp of titles easy faith might shake,\nShe scorn'd an empire for religion's sake:\nFor this, on earth, the British crown is giv'n,\nAnd an immortal crown decreed in heav'n.\nCaroline was widely seen by both the public and the court as having great influence over her husband. A satirical verse of the period went:\nYou may strut, dapper George, but 'twill all be in vain,\nWe all know 'tis Queen Caroline, not you, that reign\u00a0\u2013\nYou govern no more than Don Philip of Spain.\nThen if you would have us fall down and adore you,\nLock up your fat spouse, as your dad did before you.\nThe memoirs of the 18th century, particularly those of John, Lord Hervey, fed perceptions that Caroline and Walpole governed her husband. Peter Quennell wrote that Hervey was the \"chronicler of this remarkable coalition\" and that she was Hervey's \"heroine\". Using such sources, biographers of the 19th and 20th centuries credit her with aiding the establishment of the House of Hanover in Britain, in the face of Jacobite opposition. R. L. Arkell wrote \"by her acumen and geniality, [Caroline] ensured the dynasty's rooting itself in England\", and William Henry Wilkins said her \"gracious and dignified personality, her lofty ideals and pure life did much to counteract the unpopularity of her husband and father-in-law, and redeem the early Georgian era from utter grossness.\" Although modern historians tend to believe that Hervey, Wilkins and Arkell have overestimated her importance, it is nevertheless probable that Caroline of Ansbach was one of the most influential consorts in British history.\nTitles, styles, honours and arms.\nHonours.\nCaroline County in the British Colony of Virginia was named in the Queen's honour when it was formed in 1727.\nArms.\nThe royal coat of arms of the United Kingdom are impaled with those of Caroline's father. The arms of her father were quarterly of fifteen, 1st, per fess gules and argent, within a bordure counter-changed of the same (for Magdeburg); 2nd, argent, an eagle displayed sable, crowned or; 3rd, or, a griffin segreant gules, crowned; 4th and 5th, argent, a griffin segreant gules; 6th, or, a griffin segreant sable; 7th, argent, an eagle displayed sable (for Crossen); 8th, per pale argent and gules within a bordure counter-changed of the same (for Halberstadt); 9th, argent, an eagle displayed sable; 10th, or, a lion rampant sable, crowned, within a bordure gobon\u00e9 argent and gules (for Nuremberg); 11th, gules, two keys in saltire or (for Minden); 12th, quarterly argent and sable (for Hohenzollern); 13th, the field gules, the figure argent; 14th, per fess gules and argent; 15th, plain field of gules (for right of regalia); overall an inescutcheon, argent, an eagle displayed gules (for Brandenburg).\nIssue.\nCaroline's ten or eleven pregnancies resulted in eight live births, of whom one died in infancy, and seven lived to adulthood.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50535", "revid": "1171045195", "url": "https://en.wikipedia.org/wiki?curid=50535", "title": "Warren County", "text": "Warren County is the name of fourteen counties in the USA. Some are named after General Joseph Warren, who was killed in the Battle of Bunker Hill in the American Revolutionary War:\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about distinct geographical locations with the same name. "}
{"id": "50538", "revid": "39494265", "url": "https://en.wikipedia.org/wiki?curid=50538", "title": "Eugene V. Debs", "text": "American labor and political leader (1855\u20131926)\nEugene Victor Debs (November 5, 1855 \u2013 October 20, 1926) was an American socialist activist and trade unionist. He was one of the founding members of the Industrial Workers of the World (IWW) and a five-time candidate of the Socialist Party of America for President of the United States; through his presidential candidacies as well as his work with labor movements, Debs eventually became one of the best-known socialists living in the United States.\nEarly in his political career, Debs was a member of the Democratic Party. He was elected as a Democrat to the Indiana General Assembly in 1884. After working with several smaller unions, including the Brotherhood of Locomotive Firemen, Debs led his union in a major ten-month strike against the CB&amp;Q Railroad in 1888. Debs was instrumental in the founding of the American Railway Union (ARU), one of the nation's first industrial unions. After workers at the Pullman Palace Car Company organized a wildcat strike over pay cuts in the summer of 1894, Debs signed many into the ARU. He led a boycott by the ARU against handling trains with Pullman cars in what became the nationwide Pullman Strike, affecting most lines west of Detroit and more than 250,000 workers in 27 states. Purportedly to keep the mail running, President Grover Cleveland used the United States Army to break the strike. As a leader of the ARU, Debs was convicted of federal charges for defying a court injunction against the strike and served six months in prison.\nIn prison, Debs read various works of socialist theory and emerged six months later as a committed adherent of the international socialist movement. Debs was a founding member of the Social Democracy of America (1897), the Social Democratic Party of America (1898) and the Socialist Party of America (1901). Debs ran as a Socialist candidate for President of the United States five times: 1900 (earning 0.6 percent of the popular vote), 1904 (3.0 percent), 1908 (2.8 percent), 1912 (6.0 percent), and 1920 (3.4 percent), the last time from a prison cell. He was also a candidate for United States Congress from his native state Indiana in 1916.\nDebs was noted for his oratorical skills, and his speech denouncing American participation in World War\u00a0I led to his second arrest in 1918. He was convicted under the Sedition Act of 1918 and sentenced to a 10-year term. President Warren G. Harding commuted his sentence in December 1921. Debs died in 1926, not long after being admitted to a sanatorium due to cardiovascular problems that had developed during his time in prison.\nEarly life.\nEugene Victor \"Gene\" Debs was born on November 5, 1855, in Terre Haute, Indiana, to Jean Daniel and Marguerite Mari Bettrich Debs, who emigrated to the United States from Colmar, Alsace, France. His father, who came from a prosperous Protestant family, owned a textile mill and meat market. Debs was named after the French authors Eug\u00e8ne Sue and Victor Hugo.\nDebs attended public school, dropping out of high school at age 14. He took a job with the Vandalia Railroad cleaning grease from the trucks of freight engines for fifty cents a day. He later became a painter and car cleaner in the railroad shops. In December 1871, when a drunken locomotive fireman failed to report for work, Debs was pressed into service as a night fireman. He decided to remain a fireman on the run between Terre Haute and Indianapolis, earning more than a dollar a night for the next three and half years. In July 1875, Debs left to work at a wholesale grocery house, where he remained for four years while attending a local business school at night.\nDebs joined the Brotherhood of Locomotive Firemen (BLF) in February 1875 and became active in the organization. In 1877 he served as a delegate of the Terre Haute lodge to the organization's national convention. Debs was elected associate editor of the BLF's monthly organ, \"Firemen's Magazine\", in 1878. Two years later, he was appointed Grand Secretary and Treasurer of the BLF and editor of the magazine in July 1880. He worked as a BLF functionary until February 1893 and as the magazine's editor until September 1894.\nAt the same time, he became a prominent figure in the community. He served two terms as Terre Haute's city clerk from September 1879 to September 1883. In the autumn of 1884, he was elected as a Democrat to represent Terre Haute and Vigo County in the Indiana General Assembly. He served for one term in 1885.\nMarriage and family.\nDebs married Katherine \"Kate\" Metzel on June 9, 1885, at St. Stephen's Episcopal church. Their home still stands in Terre Haute, preserved on the campus of Indiana State University.\nLabor activism.\nThe railroad brotherhoods were comparatively conservative organizations, focused on providing fellowship and services rather than on collective bargaining. Their motto was \"Benevolence, Sobriety, and Industry\". As editor of the official journal of the Brotherhood of Locomotive Firemen, Debs initially concentrated on improving the brotherhood's death and disability insurance programs. During the early 1880s, Debs's writing stressed themes of self-uplift: temperance, hard work, and honesty. Debs also held the view that \"labor and capital are friends\" and opposed strikes as a means of settling differences. The brotherhood had never authorized a strike from its founding in 1873 to 1887, a record which Debs was proud of. Railroad companies cultivated the brotherhood and granted them perks like free transportation to their conventions for the delegates. Debs also invited railroad president Henry C. Lord to write for the magazine. Summarizing Debs's thought in this period, the historian David A. Shannon wrote: \"Debs's desideratum was one of peace and co-operation between labor and capital, but he expected management to treat labor with respect, honor and social equality\".\nDebs gradually became convinced of the need for a more unified and confrontational approach as railroads were powerful forces in the economy. One influence was his involvement in the Burlington Railroad Strike of 1888, a defeat for labor that convinced Debs of \"the need to reorganize across craft lines\", according to Joanne Reitano. After stepping down as Brotherhood Grand Secretary in 1893, Debs organized one of the first industrial unions in the United States, the American Railway Union (ARU), for unskilled workers. He was elected president of the ARU upon its founding, with fellow railway labor organizer George W. Howard as first vice president. The union successfully struck the Great Northern Railway in April 1894, winning most of its demands.\nPullman Strike.\nIn 1894, Debs became involved in the Pullman Strike, which grew out of a compensation dispute started by the workers who constructed the rail cars made by the Pullman Palace Car Company. The Pullman Company, citing falling revenue after the economic Panic of 1893, had cut the wages of its factory employees by twenty-eight percent. The workers, many of whom were already members of the ARU, appealed for support to the union at its convention in Chicago, Illinois. Debs tried to persuade union members, who worked on the railways, that the boycott was too risky given the hostility of the railways and the federal government, the weakness of the union, and the possibility that other unions would break the strike.\nThe membership ignored his warnings and refused to handle Pullman cars or any other railroad cars attached to them, including cars containing the U.S. mail. After ARU Board Director Martin J. Elliott extended the strike to St. Louis, doubling its size to eighty thousand workers, Debs relented and decided to take part in the strike, which was now endorsed by almost all members of the ARU in the immediate area of Chicago. On July 9, 1894, a \"New York Times\" editorial called Debs \"a lawbreaker at large, an enemy of the human race\". Strikers fought by establishing boycotts of Pullman train cars and with Debs's eventual leadership the strike came to be known as \"Debs' Rebellion\".\nThe federal government intervened, obtaining an injunction against the strike on the grounds that the strikers had obstructed the U.S. mail, carried on Pullman cars, by refusing to show up for work. President Grover Cleveland, whom Debs had supported in all three of his presidential campaigns, sent the United States Army to enforce the injunction. The presence of the army was enough to break the strike. Overall, thirty strikers were killed in the strike, thirteen of them in Chicago, and thousands were blacklisted. An estimated $80 million worth of property was damaged and Debs was found guilty of contempt of court for violating the injunction and sent to federal prison.\nDebs was represented by Clarence Darrow, later a leading American lawyer and civil libertarian, who had previously been a corporate lawyer for the railroad company. Although it is commonly thought that Darrow \"switched sides\" to represent Debs, a myth repeated by Irving Stone's biography, \"Clarence Darrow for the Defense\", he had in fact resigned from the railroad earlier, after the death of his mentor William Goudy. A Supreme Court case decision, \"In re Debs\", later upheld the right of the federal government to issue the injunction.\nSocialist leader.\nAt the time of his arrest for mail obstruction, Debs was not yet a socialist. While serving his six-month term in the jail at Woodstock, Illinois, Debs and his ARU comrades received a steady stream of letters, books and pamphlets in the mail from socialists around the country. Debs recalled several years later:\nI began to read and think and dissect the anatomy of the system in which workingmen, however organized, could be shattered and battered and splintered at a single stroke. The writings of [Edward] Bellamy and [Robert] Blatchford early appealed to me. \"The Cooperative Commonwealth\" of [Laurence] Gronlund also impressed me, but the writings of [Karl] Kautsky were so clear and conclusive that I readily grasped, not merely his argument, but also caught the spirit of his socialist utterance\u00a0\u2013 and I thank him and all who helped me out of darkness into light.\nAdditionally, Debs was visited in jail by the Milwaukee socialist newspaper editor Victor L. Berger, who in Debs's words \"came to Woodstock, as if a providential instrument, and delivered the first impassioned message of Socialism I had ever heard\". In his 1926 obituary in \"Time\", it was said that Berger left him a copy of \"Capital\" and \"prisoner Debs read it slowly, eagerly, ravenously\". Debs emerged from jail at the end of his sentence a changed man. He spent the final three decades of his life proselytizing for the socialist cause.\nAfter Debs and Martin Elliott were released from prison in 1895, Debs started his socialist political career. Debs started agitating for the ARU membership to form a Social Democratic organization. In 1896, Debs supported Democratic candidate William Jennings Bryan in the presidential election following Bryan's Cross of Gold speech. After Bryan's loss in the election, a disappointed Debs decided for certain that the future for socialist policies lay outside the Democratic Party. In June 1897, the ARU membership finally joined with the Brotherhood of the Cooperative Commonwealth to form the Social Democracy of America.\nSplit to found the Social Democratic Party.\nThe Social Democracy of America (SDA), founded in June 1897 by Eugene V. Debs from the remnants of his American Railway Union, was deeply divided between those who favored a tactic of launching a series of colonies to build socialism by practical example and others who favored establishment of a European-style socialist political party with a view to capture of the government apparatus through the ballot box.\nThe June 1898 convention would be the group's last, with the minority political action wing quitting the organization to establish a new organization, the Social Democratic Party of America (SDP), also called the Social Democratic Party of the United States. Debs was elected to the National Executive Board, the five-member committee which governed the party, and his brother, Theodore Debs, was selected as its paid executive secretary, handling day-to-day affairs of the organization. Although by no means the sole decision-maker in the organization, Debs's status as prominent public figure in the aftermath of the Pullman strike provided cachet and made him the recognized spokesman for the party in the newspapers.\nPresidential elections.\nAlong with Elliott, who ran for Congress in 1900, Debs was the first federal office candidate for the fledgling socialist party, running unsuccessfully for president the same year. Debs and his running mate Job Harriman received 87,945 votes (0.6 percent of the popular vote) and no electoral votes.\nFollowing the 1900 Election, the Social Democratic Party and dissidents who had split from the Socialist Labor Party in 1899 unified forces at a Socialist Unity Convention held in Indianapolis in mid-1901\u00a0\u2013 a meeting which established the Socialist Party of America (SPA).\nDebs was the Socialist Party of America candidate for president in 1904, 1908, 1912, and 1920 (the final time from prison). Though he received increasing numbers of popular votes in each subsequent election, he never won any votes in the Electoral College. In both 1904 and 1908, Debs ran with running-mate Ben Hanford. They received 402,810 votes in 1904, for 3.0 percent of the popular vote and an overall third-place finish. In the 1908 election, they received a slightly higher number of votes (420,852) than in their previous run, but at 2.8 percent, a smaller percentage of the total votes cast. In 1912, Debs ran with Milwaukee mayor Emil Seidel as a running mate and received 901,551 votes, which was 6.0 percent of the popular vote, which remains the all-time highest percentage of the vote for a Socialist Party candidate in a U.S. presidential election. Though Debs won no state's electoral votes, in Florida, he came in second behind Wilson and ahead of President William Howard Taft and former President Theodore Roosevelt. Finally, in 1920, running with Seymour Stedman, Debs won 914,191 votes (3.4%), which remains the all-time high number of votes for a Socialist Party candidate in a U.S. presidential election. Notably, the Nineteenth Amendment passed in 1920, granting women the federal right to vote across the country, and with the expanded voting pool, his vote total accounted for only 3.4 percent of the total number of votes cast. The size of the vote is nevertheless remarkable since Debs was at the time a federal prisoner in jail for sedition, though he promised to pardon himself if elected.\nAlthough he received some success as a third-party candidate, Debs was largely dismissive of the electoral process as he distrusted the political bargains that Victor Berger and other \"sewer socialists\" had made in winning local offices. He put much more value on organizing workers into unions, favoring unions that brought together all workers in a given industry over those organized by the craft skills workers practiced.\nFounding the Industrial Workers of the World.\nAfter his work with the Brotherhood of Locomotive Firemen and the American Railway Union, Debs's next major work in organizing a labor union came during the founding of the Industrial Workers of the World (IWW). On June 27, 1905, in Chicago, Illinois, Debs and other influential union leaders including Bill Haywood, leader of the Western Federation of Miners; and Daniel De Leon, leader of the Socialist Labor Party, held what Haywood called the \"Continental Congress of the working class\". Haywood stated: \"We are here to confederate the workers of this country into a working-class movement that shall have for its purpose the emancipation of the working class\". Debs stated: \"We are here to perform a task so great that it appeals to our best thought, our united energies, and will enlist our most loyal support; a task in the presence of which weak men might falter and despair, but from which it is impossible to shrink without betraying the working class\".\nSocialists split with the Industrial Workers of the World.\nAlthough the IWW was built on the basis of uniting workers of industry, a rift began between the union and the Socialist Party. It started when the electoral wing of the Socialist Party, led by Victor Berger and Morris Hillquit, became irritated with speeches by Haywood. In December 1911, Haywood told a Lower East Side audience at New York City's Cooper Union that parliamentary Socialists were \"step-at-a-time people whose every step is just a little shorter than the preceding step\". It was better, Haywood said, to \"elect the superintendent of some branch of industry, than to elect some congressman to the United States Congress\". In response, Hillquit attacked the IWW as \"purely anarchistic\".\nThe Cooper Union speech was the beginning of a split between Haywood and the Socialist Party, leading to the split between the factions of the IWW, one faction loyal to the Socialist Party and the other to Haywood. The rift presented a problem for Debs, who was influential in both the IWW and the Socialist Party. The final straw between Haywood and the Socialist Party came during the Lawrence Textile Strike. The decision of the elected officials in Lawrence, Massachusetts, to send police, who subsequently used their clubs on children, disgusted Haywood, who publicly declared that \"I will not vote again\" until such a circumstance was rectified. Haywood was purged from the National Executive Committee by passage of an amendment that focused on the direct action and sabotage tactics advocated by the IWW. Debs was probably the only person who could have saved Haywood's seat.\nIn 1906, when Haywood had been on trial for his life in Idaho, Debs had described him as \"the Lincoln of Labor\" and called for Haywood to run against Theodore Roosevelt for president, but times had changed and Debs, facing a split in the party, chose to echo Hillquit's words, accusing the IWW of representing anarchy. Debs thereafter stated that he had opposed the amendment, but that once it was adopted it should be obeyed. Debs remained friendly to Haywood and the IWW after the expulsion despite their perceived differences over IWW tactics.\nPrior to Haywood's dismissal, the Socialist Party membership had reached an all-time high of 135,000. One year later, four months after Haywood was recalled, the membership dropped to 80,000. The reformists in the Socialist Party attributed the decline to the departure of the \"Haywood element\" and predicted that the party would recover, but it did not. In the election of 1912, many of the Socialists who had been elected to public office lost their seats.\nLeadership style.\nDebs was noted by many to be a charismatic speaker who sometimes called on the vocabulary of Christianity and much of the oratorical style of evangelism, even though he was generally disdainful of organized religion. Howard Zinn opined that \"Debs was what every socialist or anarchist or radical should be: fierce in his convictions, kind and compassionate in his personal relations.\" Heywood Broun noted in his eulogy for Debs, quoting a fellow Socialist: \"That old man with the burning eyes actually believes that there can be such a thing as the brotherhood of man. And that's not the funniest part of it. As long as he's around I believe it myself\".\nAlthough sometimes called \"King Debs\", Debs himself was not wholly comfortable with his standing as a leader. As he told an audience in Detroit in 1906:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I am not a Labor Leader; I do not want you to follow me or anyone else; if you are looking for a Moses to lead you out of this capitalist wilderness, you will stay right where you are. I would not lead you into the promised land if I could, because if I led you in, someone else would lead you out. You must use your heads as well as your hands, and get yourself out of your present condition.\nSedition conviction and appeal to U.S. Supreme Court.\nDebs's speeches against the Wilson administration and the war earned the enmity of President Woodrow Wilson, who later called Debs a \"traitor to his country.\" On June 16, 1918, Debs made a speech in Canton, Ohio, urging resistance to the military draft. He was arrested on June 30 and charged with ten counts of sedition.\nSeymour Stedman headed Debs' legal defense team. Seymour Stedman, in his opening statement, stated, \"We ask you to judge Eugene V. Debs by his life, his deeds and his works. If you will do that we shall abide by your verdict.\" His trial defense called no witnesses, asking that Debs be allowed to address the court in his defense. That unusual request was granted, and Debs spoke for two hours. He was found guilty on September 12. At his sentencing hearing on September 14, he again addressed the court and his speech has become a classic. Heywood Broun, a liberal journalist and not a Debs partisan, said it was \"one of the most beautiful and moving passages in the English language. He was for that one afternoon touched with inspiration. If anyone told me that tongues of fire danced upon his shoulders as he spoke, I would believe it.\" Debs said in part:\nYour honor, I have stated in this court that I am opposed to the form of our present government; that I am opposed to the social system in which we live; that I believe in the change of both but by perfectly peaceable and orderly means.\u00a0...\nI am thinking this morning of the men in the mills and factories; I am thinking of the women who, for a paltry wage, are compelled to work out their lives; of the little children who, in this system, are robbed of their childhood, and in their early, tender years, are seized in the remorseless grasp of Mammon, and forced into the industrial dungeons, there to feed the machines while they themselves are being starved body and soul.\u00a0...\nYour honor, I ask no mercy, I plead for no immunity. I realize that finally the right must prevail. I never more fully comprehended than now the great struggle between the powers of greed on the one hand and upon the other the rising hosts of freedom. I can see the dawn of a better day of humanity. The people are awakening. In due course of time they will come into their own.\nWhen the mariner, sailing over tropic seas, looks for relief from his weary watch, he turns his eyes toward the Southern Cross, burning luridly above the tempest-vexed ocean. As the midnight approaches the Southern Cross begins to bend, and the whirling worlds change their places, and with starry finger-points the Almighty marks the passage of Time upon the dial of the universe; and though no bell may beat the glad tidings, the look-out knows that the midnight is passing\u00a0\u2013 that relief and rest are close at hand.\nLet the people take heart and hope everywhere, for the cross is bending, midnight is passing, and joy cometh with the morning.\nDebs was sentenced on September 18, 1918, to ten years in prison and was also disenfranchised for life. Debs presented what has been called his best-remembered statement at his sentencing hearing:\nYour Honor, years ago I recognized my kinship with all living beings, and I made up my mind that I was not one bit better than the meanest on earth. I said then, and I say now, that while there is a lower class, I am in it, and while there is a criminal element, I am of it, and while there is a soul in prison, I am not free.\nDebs appealed his conviction to the Supreme Court. In its ruling on \"Debs v. United States\", the court examined several statements Debs had made regarding World War I and socialism. While Debs had carefully worded his speeches in an attempt to comply with the Espionage Act of 1917, the Court found he had the intention and effect of obstructing the draft and military recruitment. Among other things, the Court cited Debs's praise for those imprisoned for obstructing the draft. Justice Oliver Wendell Holmes Jr. stated in his opinion that little attention was needed since Debs's case was essentially the same as that of \"Schenck v. United States\", in which the court had upheld a similar conviction.\nDebs went to prison on April 13, 1919. In protest of his jailing, Charles Ruthenberg led a parade of unionists, socialists, and communists on May 1 (May Day) in Cleveland, Ohio. The event quickly broke into the violent May Day riots of 1919.\n1920 presidential run.\nDebs ran for president in the 1920 election while imprisoned in the Atlanta Federal Penitentiary. Campaign pins reading \"For President: Convict No. 9653\" accompanied his campaign. He received 914,191 votes (3.4 percent), a smaller percentage than he had won in 1912, when he received 6 percent, the highest number of votes for a Socialist Party presidential candidate in the United States. During his time in prison, Debs wrote a series of columns deeply critical of the prison system. They appeared in sanitized form in the Bell Syndicate and were published in his only book, \"Walls and Bars\", with several added chapters. It was published posthumously.\nIn March 1919, President Wilson asked Attorney General A. Mitchell Palmer for his opinion on clemency, offering his own: \"I doubt the wisdom and public effect of such an action.\" Palmer generally favored releasing people convicted under the wartime security acts, but when he consulted with Debs's prosecutors\u00a0\u2013 even those with records as defenders of civil liberties\u00a0\u2013 they assured him that Debs's conviction was correct and his sentence appropriate. The President and his Attorney General both believed that public opinion opposed clemency and that releasing Debs could strengthen Wilson's opponents in the debate over the ratification of the peace treaty. Palmer proposed clemency in August and October 1920 without success. At one point, Wilson wrote: \"While the flower of American youth was pouring out its blood to vindicate the cause of civilization, this man, Debs, stood behind the lines sniping, attacking, and denouncing them.\u00a0... This man was a traitor to his country and he will never be pardoned during my administration.\" In January 1921, Palmer, citing Debs's deteriorating health, proposed to Wilson that Debs receive a presidential pardon freeing him on February 12, Lincoln's birthday. Wilson returned the paperwork after writing \"Denied\" across it.\nIn March 1921, soon after the inauguration of President Warren G. Harding, Debs met Harding's Attorney General Harry Daugherty, but was returned to jail afterwards.\nOn December 23, 1921, President Harding commuted Debs's sentence to time served, effective Christmas Day. He did not issue a pardon. A White House statement summarized the administration's view of Debs's case:\nThere is no question of his guilt.\u00a0... He was by no means, however, as rabid and outspoken in his expressions as many others, and but for his prominence and the resulting far-reaching effect of his words, very probably might not have received the sentence he did. He is an old man, not strong physically. He is a man of much personal charm and impressive personality, which qualifications make him a dangerous man calculated to mislead the unthinking and affording excuse for those with criminal intent.\nLast years.\nWhen Debs was released from the Atlanta Penitentiary, the other prisoners sent him off with \"a roar of cheers\" and a crowd of fifty thousand greeted his return to Terre Haute to the accompaniment of band music. En route home, Debs was warmly received at the White House by Harding, who greeted him by saying: \"Well, I've heard so damned much about you, Mr. Debs, that I am now glad to meet you personally.\"\nIn 1924, Debs was nominated for the Nobel Peace Prize by the Finnish Socialist Karl H. Wiik on the grounds that \"Debs started to work actively for peace during World War I, mainly because he considered the war to be in the interest of capitalism.\" The same year, he was named \"national chairman\" of the Socialist Party, a newly created office that allowed him to step away from the taxing work of the National Executive Committee.\nHe spent his remaining years trying to recover his health, which was severely undermined by prison confinement. In late 1926, he was admitted to Lindlahr Sanitarium in Elmhurst, Illinois. He died there of heart failure on October 20, 1926, at the age of 70. His body was cremated and buried in Highland Lawn Cemetery in Terre Haute, Indiana.\nLegacy.\nDebs helped motivate the American left to organize political opposition to corporations and World War I. American socialists, communists, and anarchists honor his work for the labor movement and motivation to have the average working man build socialism without large state involvement. Several books have been written about his life as an inspirational American socialist.\nThe Vermont senator and presidential candidate Bernie Sanders has long been an admirer of Debs and produced in 1979 a documentary about Debs which was released as a film and an audio LP record as an audio-visual teaching aid. In the documentary, he described Debs as \"probably the most effective and popular leader that the American working class has ever had\". Sanders hung a portrait of Debs in city hall in Burlington, Vermont, when he served as mayor of the city in the 1980s and has a plaque dedicated to Debs in his congressional office. On October 25, 2025, the Eugene V. Debs Foundation gave Senator Sanders the namesake award that was first recognized on John L. Lewis in 1965. \nOn May 22, 1962, Debs's home was purchased for $9,500 by the Eugene V. Debs Foundation, which worked to preserve it as a Debs memorial. In 1965 it was designated as an official historic site of the state of Indiana, and in 1966 it was designated as a National Historic Landmark of the United States. The preservation of the museum is monitored by the National Park Service. In 1990, the Department of Labor named Debs a member of its Labor Hall of Fame.\nWhile Debs did not leave a collection of papers to a university library, the pamphlet collection which he and his brother amassed is held by Indiana State University in Terre Haute. The scholar Bernard Brommel, author of a 1978 biography of Debs, has donated his biographical research materials to the Newberry Library in Chicago, where they are open to researchers. The original manuscript of Debs's book \"Walls and Bars\", with handwritten amendments, presumably by Debs, is held in the Thomas J. Morgan Papers in the special collections department of the University of Chicago Library.\nDebs was so synonymous with the American socialist movement that other socialist politicians like Frank Crosswaith and Abraham Shiplacoff became known as the \"Negro Debs\" and the \"Jewish Debs,\" respectively.\nEugene Township in Lake of the Woods County, Minnesota, was likely named after Debs. The community of Debs in Minnesota's Beltrami County may have also been named after him.\nEugene V. Debs Hall in Buffalo, NY is a 501(c)7 nonprofit social club; and home to the Eugene V. Debs Local Initiative, a project to document and commemorate Buffalo's labor movement history.\nFormer New York radio station WEVD (now ESPN radio), then owned by the socialist Yiddish newspaper \"The Jewish Daily Forward\", took its call letters from his initials and was known as the \"Debs Memorial Station.\"\nDebs Place, a housing block in Co-op City in the Bronx, New York, was named in his honor. The Eugene V. Debs Cooperative House in Ann Arbor, Michigan, was named after Debs.\nDebs School, a one-room schoolhouse built in 1926 in Hinsdale County, Colorado, was named in honor of Debs; the building also served as a community gathering spot for the rural area. Noteworthy for its unique ornamental concrete block construction, it was added to the National Register of Historic Places in 2005.\nThere are at least two beers named after Debs, namely Debs's Red Ale and Eugene.\nThe Oregon State Senator Eugene \"Debbs\" Potts was named in Debs's honor.\nIn 2025, democratic socialist New York City mayor-elect Zohran Mamdani in his victory speech quoted Debs's appeal to the Supreme Court, saying \"I can see the dawn of a better day for humanity.\"\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50542", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=50542", "title": "James Rouse", "text": "American real estate developer (1914\u20131996)\nJames Wilson Rouse (April 26, 1914 \u2013 April 9, 1996) was an American businessman and founder of The Rouse Company. Rouse was a pioneering American real estate developer, urban planner, civic activist, and later, free enterprise-based philanthropist. He received the Presidential Medal of Freedom, the highest civilian award, for his lifetime achievements.\nEarly life and education.\nJames \"Jim\" Rouse was born in Easton, Maryland, to Lydia Agnes (n\u00e9e Robinson) and Willard Goldsmith Rouse, a canned-foods broker. His father, a lawyer trained at Johns Hopkins University, once ran for state's attorney for Harford County. When he lost, the Rouse family moved from Bel Air, Maryland, to Easton. Rouse grew up in Easton (then population: 5,000) on a well-to-do street on the edge of town. He was taught at home by his mother until second grade when he transferred to a public school. In 1930, Rouse lost his father to bladder cancer, his mother to heart failure, and his childhood home to bank foreclosure. His brother Bill paid for him to attend the private preparatory Tome School in Port Deposit, Maryland, for a year.\nFacing money problems and unable to continue at the Tome School, the Rouse family sought a way for him to attend college by appealing to his oldest sister, who had married a United States Navy officer stationed in Hawaii. Rouse declared himself his sister's dependent and, with Navy connections now secured, was thereby able to attend the University of Hawai\u02bbi at M\u0101noa at a greatly reduced cost. Rouse later attended the University of Virginia. He declared his major as political science and waited tables at a local boarding house. Because he was unable to cover the gap between his scholarship and his remaining expenses, he left Charlottesville and moved to Baltimore to try to make it on his own.\nCareer.\nHe found a job parking cars at the St. Paul Garage for one year. He later remarked that he got the job even though he could not drive, and had convinced his foreman to teach him rather than fire him. In May 1935, Rouse wrote Millard Tydings, who found him a position with the Federal Housing Administration as a clerk specializing in completing FHA loans to eastern Maryland banks. Although he had only two years of undergraduate college on his transcript, in the 1930s that was enough to qualify for law school. He borrowed money in March 1936 from Guy Hollyday who was a loan officer with the Title Guarantee and Trust Company seeking FHA loan guarantees and attended classes three nights a week at the University of Maryland School of Law. He was hired at age 22 by his mentor Hollyday.\nWhile working at the FHA during the New Deal, Rouse was tasked with enforcing racially discriminatory guidelines. Rouse used antisemitic quotas when building in the Roland Park neighborhood of Baltimore. In 1951, Rouse enforced a quota of no more than 12% Jewish residents for the Maryland Apartment in north Baltimore until 75% of the apartments were rented.\nRouse graduated in 1937 and in 1939 left the FHA and became partner with Hunter Moss at a mortgage banking firm called the Moss-Rouse Company funded by a $20,000 loan from Moss's sister, which would eventually become the Rouse Company. The company would specialize in FHA backed loans, and hired Churchill G. Carey from Connecticut General, with his former company providing loan capital to Moss-Rouse. Both Moss and Rouse served during WWII, with Moss joining the Marines and Rouse the Navy. Rouse was able to defer duty while his wife was pregnant, shipping out to Hawaii to work on John Henry Towers staff on July 4, 1942. Rouse returned from the war and went back to work with Moss, using his gambling assets. By 1951, the Moss-Rouse Company had become the largest mortgage banking company in the state of Maryland. In 1954, the two partners split, with Moss summarizing the split this way: \"[Rouse] was a person who liked to do things in a big way. I liked the smaller company. So we split up.\"\nAs he was growing his business, Rouse pursued various civic activities. He co-founded the Citizens Planning and Housing Association (CPHA) and became involved in Baltimore, Maryland's efforts to rehabilitate its decayed housing stock through The Baltimore Plan. The national publicity of this program led to his participation in Dwight D. Eisenhower's National Housing Task Force starting in 1953. He introduced (or at least helped popularize) the term \"urban renewal\" to describe the series of recommendations made by that task force.\nShopping malls.\nIn 1958, Rouse built Harundale Mall in Glen Burnie, Maryland, the first enclosed shopping center east of the Mississippi River and the first built by a real estate developer. His company used the term \"mall\" to describe the development, which was an alternative to the more typical strip malls usually built in the suburbs (the \"mall\" in \"strip mall\" came into usage later, after the enclosed mall had been popularized by Rouse's company). Although many now attribute the rise of the shopping mall to the decline of the American downtown core, Rouse's focus at the time was on the introduction of malls as a form of town center for the suburbs.\nHis company became an active developer and manager of shopping center and mall properties, even as he shifted focus to new projects which eventually included planned communities and festival marketplaces.\nIn late 1973, the Columbia project took a downturn as Maryland land developers such as Joel Kline, and politicians such as Governor Marvin Mandel, and Vice President Spiro Agnew were indicted on various charges of corruption related to land speculation. Rouse was indicted for donations to Mandel's 1974 campaign which violated campaign contribution limits, but the charges were dropped because they had been brought outside the one-year limit.\nHarundale Mall has since been replaced by Harundale Plaza. In 1999, the mall reopened and redeveloped as Harundale Plaza, a strip shopping center. Stores include A.J. Wright, a Super Fresh supermarket, Outback Steakhouse, Hollywood Video, Burlington Coat Factory, and a U.S. Post Office, along with several other typical strip-mall stores. The signature \"rock\" from Harundale Mall is now at Harundale Plaza.\nPlanned communities.\nIn the 1960s Rouse turned his focus to planned communities. After engaging in a planning exercise for the Pocantico Hills estate of the Rockefellers, Rouse constructed his first planned residential development: the Village of Cross Keys in Baltimore. On June 16, 1961, Rouse bought inside the city from the Baltimore Country Club for $25,000 an acre. Rouse excitedly proclaimed that this undertaking \"will be the largest, and potentially most important development in the history of Baltimore.\" Rouse hoped that he could bring to the residential field \"some of the fresh thinking, good taste and high standards which we believe have marked our shopping center developments.\"\nFamiliar with bad housing in Baltimore and Washington, D.C., Rouse now had an opportunity to demonstrate what housing within a city's borders could be like. \"There is a real need for residential development,\" he said, \"in which there is a strong sense of community; a need to feed into the city some of the atmosphere and pace of the small town and village; a need to create a community which can meet as many as possible of the needs of the people who live there; which can bring these people into natural contact with one another; which can produce out of these relationships a spirit and feeling of neighborliness and a rich sense of belonging to a community.\" In a city that practiced strict racial segregation, Rouse intended Cross Keys to be open to all who could afford to live there. The development was a mixture of townhouses, garden apartments, a high-rise apartment house designed by Frank Gehry, stores grouped around a village square, and an office complex. By 1970, the Village of Cross Keys had become among the most desirable places to live in the Baltimore area.\nWhile Cross Keys was still under construction, Rouse decided to build a whole new \"city.\" The creation of Columbia, Maryland, between Baltimore and Washington, D.C., was the greatest adventure of Rouse's life. Columbia was the ultimate opportunity: the chance to embody his ideals in a whole new city. For the undertaking that would become Columbia, Rouse turned to his partner in previous projects, the Connecticut General Life Insurance Company (\"CG\"). At a meeting at company headquarters in Hartford, Rouse made his pitch to CG's top real estate and mortgage people and the company's chairman of the board, Frazar B. Wilde. The questioning was mostly negative, until Wilde joined in. He expressed the view that CG couldn't lose. If Rouse's project did not succeed, the land could always be sold, and probably for a higher price than what it cost.\nThe land for the new city would be owned by a subsidiary called Howard Research and Development Corporation. CG would own half of that corporation and Rouse's corporation the other half. Rouse would be responsible for the management of the acquired land and for preparing a master plan for development. CG also put up some of the money for Columbia's infrastructure. The rest was supplied by Teachers Insurance and Annuity Association and the Chase Manhattan Bank.\nBy the end of the summer of 1963 close to of Howard County farmland had been acquired, and the time was at hand to begin planning what to do with it. Rouse wanted to hear from a wide assortment of experts and scholars. He brought together an assemblage which became known as \"The Work Group.\" It consisted of top people in health, family life, education, recreation, government, transportation, and employment. Ultimately emerging was the idea that the new city should be a real multi-faceted city, not a bedroom suburb. It should be possible for its residents to find everything they needed right there\u2014jobs, education, recreation, health care, and any other necessity.\nRouse was not reluctant to bring up his home town of Easton as a model for Columbia. Consensus formed around the idea that the basic subdivision within the new city should be the village, a unit of 10,000 to 15,000 people. This number was thought to be the most likely to foster a local feeling of identification: for merchants to get to know their customers, ministers their memberships, and teachers their pupils and parents.\nWithin the city, there would be 12 villages. Each village would have a central gathering place where people of different income levels and types of housing would cross paths and mix. Each village would have a middle school and a high school, a teen center, a supermarket, a library, a hospital, an auditorium, offices, restaurants, some specialty shops, and a few larger recreational facilities. It also would have a multi-denominational house of worship known as an \"interfaith center\" based on the Gordon Cosby's Ecumenical Church of the Savior called the Kittamaqundi Community. The hope was that one building would be used by several religions.\nIn addition to the villages there would be a core area that would function as the new city's \"downtown.\" Here would be the main cluster of retail stores (arranged as a mall), a hotel and conference center, a hospital, movie theaters and a concert hall, a community college, and branches of the Maryland Institute College of Art and the Peabody Conservatory of Music.\nThe main entertainment area was to be known as Tivoli, after the entertainment area in Copenhagen. Early on, Rouse said that he hoped Tivoli would be a place \"where, under the benign influence of having fun and relaxing in familiar ways, people would have opportunities, especially attractive and conveniently presented, for discovering new ways to enjoy their free time\u2014new foods, new visual and tactile aesthetic experiences, even new social relations.\" Rouse wanted the town center in Columbia to provide the most comprehensive range of recreational activities and services that had ever been contemplated in a new town.\nThe recession of the 1970s hit Columbia hard, and CG had to refinance the project, reducing The Rouse Company's stake. CG later pulled out of the project completely in 1985, but by that time it had returned to profitability.\nFestival marketplaces.\nRouse shifted focus from suburban retail to urban malls, which he called \"festival marketplaces,\" of which the Faneuil Hall Marketplace was the first and most successful example. Completed in 1976, and partly funded with assistance from the United States Department of Housing and Urban Development, the Faneuil Hall Marketplace (comprising Quincy Market and other spaces adjacent to Boston's Faneuil Hall) was designed by architect Benjamin C. Thompson and was a financial success, an act of historic preservation, and an anchor for urban revitalization. Later the Boston Museum of Fine Arts established an annex at the Quincy Market, and the mall generated more foot traffic than the museum. Initially, there were critics who predicted the project would fail, while other dismissed its early success as a fad. Calvin Trillin and Peter Hall each invoked Disneyland in their claims that Faneuil Hall Marketplace was an example of fake urbanism. Robert Campbell, an architecture critic, rejected this kind of criticism as snobbery, and claimed that the festival marketplace was effective at getting people out of their cars and getting them to experience the city. In his planning for the project, Rouse imagined that people would not just shop, that they would also be entertained. However, he later claimed that he had not anticipated its popularity as a tour bus destination.\nOther examples of Rouse Company \"festival marketplace\" developments include South Street Seaport in New York City, The Gallery at Market East, in Philadelphia, Harborplace in Baltimore, St. Louis Union Station in St. Louis, Downtown Portland's Pioneer Place, and the Riverwalk Marketplace of New Orleans. The early festival marketplaces like Faneuil Hall and Harborplace led \"TIME\" magazine to dub Rouse \"the man who made cities fun again.\"\nRetirement.\nAfter 40 years at the Rouse Company, Rouse retired from day-to-day management in 1979. Soon afterwards, he and his wife founded the Enterprise Community Partners, a not-for-profit foundation funded in part by a for-profit subsidiary, The Enterprise Development Company, and focused on seeding partnerships with community groups that would address the need for affordable housing and associated social services for poor neighborhoods. In 1984, Jim Rouse was soliciting business representing both Rouse Company as CEO and Enterprise Development as president. The Rouse Company board of directors asked Jim Rouse to leave as CEO of the Rouse Company and his position in Enterprise Development which ended his involvement with the company he founded.\nRouse was inducted into the Junior Achievement U.S. Business Hall of Fame in 1981. In 1988, Rouse was awarded the second Honor Award from the National Building Museum.\nThe Rouse Theatre in Wilde Lake High School is named after James. In May 2006, an approximately four-mile stretch of Maryland Route 175 between Interstate 95 and U.S. Route 29 in Columbia, Maryland, was named after Rouse and his wife, Patty. The Jim Rouse Visionary Center opened in 2006 in a formerly contaminated Whiskey Warehouse in Baltimore.\nAwards.\nIn 1978, Rouse received the S. Roger Horchow Award for Greatest Public Service by a Private Citizen, an award given out annually by Jefferson Awards.\nIn 1981, Rouse received the Golden Plate Award of the American Academy of Achievement.\nIn 1995, Rouse was awarded the Presidential Medal of Freedom by President Bill Clinton.\nPersonal life.\nJames Rouse's first wife was Elizabeth Jamieson \"Libby\" (n\u00e9e Winstead) whom he married on May 3, 1941. His daughter Robin is the mother of actor Edward Norton. His son Jim applied for conscientious objector status during the Vietnam War with his father's support. In May 1970, Rouse posted full page anti-war ads in \"The Washington Post\" and later \"The New York Times\" that upset the new Nixon administration. Rouse separated from Libby in 1973, and married Myrtle Patricia \"Patty\" Traugott, from Norfolk, Virginia, in November 1974. He died of amyotrophic lateral sclerosis on April 9, 1996. Patty Rouse died on March 5, 2012.\nRouse's nephew, Willard Rouse III, was also a real estate developer.\nHomage.\nHis grandson Edward Norton, upon graduating from Yale University in 1991, moved to Japan to work for the Rouses' foundation. Later, Norton directed the film \"Motherless Brooklyn\", released in 2019, \"as an homage to the things [James Rouse] cared about\". In particular, the movie denounces the controversial urbanist Robert Moses, accused of lust for power, questionable ethics, vindictiveness, and racism.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50544", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=50544", "title": "Chester (disambiguation)", "text": "Chester is a city in Cheshire, England.\nChester may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "50545", "revid": "706848", "url": "https://en.wikipedia.org/wiki?curid=50545", "title": "Cardcaptors", "text": ""}
{"id": "50546", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=50546", "title": "Card Captor Sakura", "text": ""}
{"id": "50548", "revid": "13892963", "url": "https://en.wikipedia.org/wiki?curid=50548", "title": "Oakland, California", "text": "City in California, United States\nOakland is a city in the East Bay region of the San Francisco Bay Area in the U.S. state of California. It is the county seat of and the most populous city in Alameda County, with a population of 440,646 in 2020. A major West Coast port, Oakland is the most populous city in the East Bay, the third most populous city in the Bay Area, and the eighth most populous city in California. It serves as the Bay Area's trade center: the Port of Oakland is the busiest port in Northern California, and the fifth- or sixth-busiest in the United States. A charter city, Oakland was incorporated on May 4, 1852, in the wake of the state's increasing population due to the California gold rush.\nOakland's territory covers what was once a mosaic of California coastal terrace prairie, oak woodland, and north coastal scrub. In the late 18th century, it became part of a large \"rancho\" grant in the colony of New Spain, and was known for its plentiful oak tree stands. Its land served as a resource when its hillside oak and redwood timber were logged to build San Francisco. The fertile flatland soils helped it become a prolific agricultural region. In the 1850s, what became the first campus of the University of California was founded in Oakland, and Oakland was selected as the western terminal of the Transcontinental Railroad in 1869. The following year, Oakland's Lake Merritt became the United States' first officially designated wildlife refuge, now a National Historic Landmark. Following the catastrophic 1906 San Francisco earthquake, many San Francisco citizens moved to Oakland, enlarging the population, increasing its housing stock, and improving its infrastructure. It continued to grow in the 20th century with its port, shipyards, and manufacturing industry. In the 21st century, between 2019 and 2023, after the city and county refused requests for hundreds of millions of dollars in benefits to the privately owned teams, Oakland lost three teams of the major North American sports leagues within a span of five years.\nHistory.\nOhlone era.\nThe earliest known inhabitants of the area were the Huchiun natives, who lived there for thousands of years. The Huchiun belonged to a linguistic grouping later called the Ohlone (a Miwok word meaning \"western people\"). In Oakland, they were concentrated around Lake Merritt and Temescal Creek, a stream that enters the San Francisco Bay at Emeryville.\nSpanish and Mexican eras.\nIn 1772, the area that later became Oakland was colonized, along with the rest of California, by Spanish settlers for the king of Spain. In the early 19th century, the Spanish crown granted the East Bay area to Luis Mar\u00eda Peralta for his Rancho San Antonio. The grant was confirmed by the successor Mexican republic upon its independence from Spain. Upon his death in 1842, Peralta divided his land among his four sons. Most of Oakland was within the shares given to Antonio Maria and Vicente. The portion of the parcel that is now Oakland was called \"Encinar\" (misrendered at an early date and carried forward as \"encinal\") \u2013 Spanish for \"oak grove\" \u2013 due to the large oak forest that covered the area, which eventually led to the city's name.\nAccording to Stanford University historian Albert Camarillo, the Peralta family struggled to keep their land after the incorporation of California into the United States after the Mexican\u2013American War. Camarillo claims the family was the victim of targeted racial violence. He writes in \"Chicanos in California\", \"They lost everything when squatters cut down their fruit trees, killed their cattle, destroyed their buildings, and even fenced off the roads leading to the rancho. Especially insidious were the actions of attorney Horace Carpentier, who tricked Vicente Peralta into signing a 'lease' which turned out to be a mortgage against the 19,000-acre rancho. The lands became Carpentier's when Peralta refused to repay the loan he believed was fraudulently incurred. The Peraltas had no choice but to abandon the homesite they had occupied for two generations.\"\nCity beginnings.\nIn 1851, three men\u2014Horace Carpentier, Edson Adams, and Andrew Moon\u2014began developing what is now downtown Oakland. In 1852, the Town of Oakland was incorporated by the state legislature. During this time, Oakland had 75\u2013100 inhabitants, two hotels, a wharf, two warehouses, and only cattle trails. Two years later, on March 25, 1854, Oakland re-incorporated as the City of Oakland. Horace Carpentier was elected the first mayor, though a scandal ended his mayorship in less than a year. In 1853, a preparatory academy was founded in Oakland that soon became the College of California, and in 1869, the first campus of the University of California. The university moved just north to Berkeley in the 1870s.\nDuring the 1850s, just as gold was discovered in California, Oakland started growing and further developing because land was becoming too expensive in San Francisco. People in China were struggling financially as a result of the First Opium War, the Second Opium War, and the Taiping Rebellion, so they began migrating to Oakland, many of whom were recruited to work on railroads. However, the Chinese struggled to settle because they were discriminated against by the white community and their living quarters were burned down on several occasions.\nThe city and its environs quickly grew with the railroads, becoming a major rail terminal in the late 1860s and 1870s. In 1868, the Central Pacific constructed the Oakland Long Wharf at Oakland Point, the site of today's Port of Oakland.\nA number of horsecar and cable car lines were constructed in Oakland during the latter half of the 19th century. The first electric streetcar set out from Oakland to Berkeley in 1891, and other lines were converted and added over the course of the 1890s. The various streetcar companies operating in Oakland were acquired by Francis \"Borax\" Smith and consolidated into what eventually became known as the Key System, the predecessor of today's publicly owned AC Transit.\n1900\u20131950s.\nOakland was one of the worst affected cities in California that was impacted by the San Francisco plague of 1900\u20131904. Quarantine measures were set in place at the Oakland ports requiring the authorities at the port to inspect the arriving vessels for the presence of infected rats. Quarantine authorities at these ports inspected over a thousand vessels per year for plague and yellow fever. By 1908, over 5,000 people were detained in quarantine. Hunters were sent to poison the affected areas in Oakland and shoot the squirrels, but the eradication work was limited in its range because the State Board of Health and the United States Public Health Service were only allotted about $60,000 a year to eradicate the disease. During this period Oakland did not have sufficient health facilities, so some of the infected patients were treated at home.\nThe State Board of Health along with Oakland also advised physicians to promptly report any cases of infected patients. Yet, in 1919 it still resulted in a small epidemic of Pneumonic plague which killed a dozen people in Oakland. This started when a man went hunting in Contra Costa Valley and killed a squirrel. After eating the squirrel, he fell ill four days later and another household member contracted the plague. This in turn was passed on either directly or indirectly to about a dozen others. The officials in Oakland acted quickly by issuing death certificates to monitor the spread of plague.\nIncorporation.\nAt the time of incorporation in 1852, Oakland had consisted of the territory that lay south of today's major intersection of San Pablo Avenue, Broadway, and Fourteenth Street. The city gradually annexed farmlands and settlements to the east and the north. Oakland's rise to industrial prominence, and its subsequent need for a seaport, led to the digging of a shipping and tidal channel in 1902. This resulted in the nearby town of Alameda being made an island. In 1906, the city's population doubled with refugees made homeless after the 1906 San Francisco earthquake and fire.\nIn 1908, the lawyer, former miner, and newspaper owner Homer Wood (1880\u20131976) suggested to his friend Frank Bilger of Blake and Bilger Rock Quarry and Paving Company that he organize a gathering to establish a Rotary Club east of the bay. On November 27, 1908, Homer took a ferry across the bay in a driving rainstorm and met for lunch with Frank and twenty three other businessmen at the Hotel Metropole at 13th and Jefferson. This gathering became the first meeting of the Tri-City Rotary Club, renamed in 1911 The Rotary Club of Oakland, the third Rotary Club in the world. This group established the tradition of weekly meetings, something most clubs worldwide follow today.\nIn 1917, General Motors opened an automobile factory in East Oakland called Oakland Assembly. It produced Chevrolet cars and then GMC trucks until 1963, when it was moved to Fremont in southern Alameda County. Also in 1916, the Fageol Motor Company chose East Oakland for their first factory, manufacturing farming tractors from 1918 to 1923. By 1920, Oakland was the home of numerous manufacturing industries, including metals, canneries, bakeries, internal combustion engines, automobiles, and shipbuilding. By 1929, when Chrysler expanded with a new plant there, Oakland had become known as the \"Detroit of the West,\" referring to the major auto manufacturing center in Michigan.\nOakland expanded during the 1920s, as its population expanded with factory workers. Approximately 13,000 homes were built in the 3 years between 1921 and 1924, more than during the 13 years between 1907 and 1920. Many of the large downtown office buildings, apartment buildings, and single-family houses still standing in Oakland were built during the 1920s; they reflect the architectural styles of the time.\nRussell Clifford Durant established Durant Field at 82nd Avenue and East 14th Street in 1916. The first transcontinental airmail flight finished its journey at Durant Field on August 9, 1920, flown by Army Capt. Eddie Rickenbacker and Navy Lt. Bert Acosta. Durant Field was often called Oakland Airport, though the current Oakland San Francisco Bay Airport was soon established to the southwest.\nDuring World War II, the East Bay Area was home to many war-related industries. Oakland's Moore Dry Dock Company expanded its shipbuilding capabilities and built over 100 ships. Valued at $100\u00a0million in 1943, Oakland's canning industry was its second-most-valuable war contribution after shipbuilding. The largest canneries were in the Fruitvale District, and included the Josiah Lusk Canning Company, the Oakland Preserving Company (which started the Del Monte brand), and the California Packing Company.\nPresident Franklin D. Roosevelt called on defense industries with government contracts to integrate their workforces and provide opportunities for all Americans. Tens of thousands of laborers came from around the country, especially poor whites and blacks from the Deep South: Alabama, Arkansas, Georgia, Louisiana, Mississippi, South Carolina, and Texas, as well as Missouri and Tennessee. Henry J. Kaiser's representatives recruited sharecroppers and tenant farmers from rural areas to work in his shipyards. African Americans were part of the Great Migration by which five million persons left the South, mostly for the West, from 1940 to 1970. White migrants from the Jim Crow South carried their racial attitudes, causing tensions to rise among black and white workers competing for better-paying jobs in the Bay Area. The racial harmony Oakland African-Americans had been accustomed to prior to the war evaporated. Also migrating to the area during this time were many Mexican Americans from southwestern states such as New Mexico, Texas, and Colorado. Many worked for the Southern Pacific Railroad, at its major rail yard in West Oakland. Their young men encountered hostility and discrimination by Armed Forces personnel, and tensions broke out in \"zoot suit riots\" in downtown Oakland in 1943 in the wake of a major disturbance in Los Angeles that year.\nIn 1946, National City Lines (NCL), a General Motors holding company, acquired 64% of Key System stock; during the next several years NCL engaged in the conspiratorial dissolution of Oakland's electric streetcar system. The city's expensive electric streetcar fleet was converted to cheaper diesel buses. The state Legislature created the Alameda and Contra Costa Transit District in 1955, which operates today as AC Transit, the third-largest bus-only transit system in the nation.\nAfter the war, as Oakland's shipbuilding industry declined and the automobile industry went through restructuring, many jobs were lost. In addition, labor unrest increased as workers struggled to protect their livelihoods. Oakland was the center of a general strike during the first week of December 1946, one of six cities across the country that had such a strike after World War II.\nThe Mary's First and Last Chance in Oakland was a lesbian bar, once the focus of the 1950s California Supreme Court lawsuit Vallerga v. Dept. Alcoholic Bev. Control, when the bar challenged a state law for the right to serve gay patrons and won in 1959.\n1960\u20131999.\nIn 1960, Kaiser Corporation opened its new headquarters; it was the largest skyscraper in Oakland, as well as \"the largest office tower west of Chicago\" up to that time. In the postwar period, suburban development increased around Oakland, and wealthier residents moved to new housing. Despite the major increases in the number and proportion of African Americans in the city, in 1966 only 16 of the city's 661 police officers were black. Tensions between the black community and the largely white police force were high, as expectations during the civil rights era increased to gain social justice and equality before the law. Police abuse of black people was common.\nStudents Huey Newton and Bobby Seale founded the Black Panther Party at Merritt College (then located at a former high school on Grove Street, now occupied by Children's Hospital Oakland Research Institute), which emphasized Black nationalism, advocated armed self-defense against police, and was involved in several incidents that ended in the deaths of police officers and other Black Panther members. Among their social programs were feeding children and providing other services to the needy.\nAs in many other American cities during the 1980s, crack cocaine became a serious problem in Oakland. Drug dealing in general, and the dealing of crack cocaine in particular, resulted in elevated rates of violent crime, causing Oakland to consistently be listed as one of America's most crime-ridden cities.\nIn 1980, Oakland's Black population reached its 20th-century peak at approximately 47% of the overall city population.\nThe 6.9 Loma Prieta earthquake occurred on October 17, 1989. The rupture was related to the San Andreas fault system and affected the entire San Francisco Bay Area with a maximum Mercalli intensity of IX (\"Violent\"). Many structures in Oakland were badly damaged including the double-decker portion of Interstate 880 that collapsed. The eastern span of the San Francisco\u2013Oakland Bay Bridge also sustained damage and was closed to traffic for one month.\nOn October 20, 1991, a massive firestorm swept down from the Berkeley/Oakland hills above the Caldecott Tunnel. Twenty-five people were killed, 150 people were injured, and nearly 4,000 homes destroyed. With the loss of life and an estimated economic loss of US$1.5\u00a0billion, this was the worst urban firestorm in American history, until 2017.\nDuring the mid-1990s, Oakland's economy began to recover as it transitioned to new types of jobs. In addition, the city participated in large development and urban renewal projects, concentrated especially in the downtown area, at the Port of Oakland, and at the Oakland San Francisco Bay Airport.\n21st century.\nAfter his 1999 inauguration, Oakland Mayor Jerry Brown continued his predecessor Elihu Harris' public policy of supporting downtown housing development in the area defined as the Central Business District in Oakland's 1998 General Plan. Brown's plan and other redevelopment projects were controversial due to potential rent increases and gentrification, which would displace lower-income residents from downtown Oakland into outlying neighborhoods and cities.\nDue to allegations of misconduct by the Oakland Police Department, the City of Oakland has paid claims for a total of US$57\u00a0million during the 2001\u20132011 timeframe to plaintiffs claiming police abuse; this is the largest sum paid by any city in California. On October 10, 2011, protesters and civic activists began \"Occupy Oakland\" demonstrations at Frank Ogawa Plaza in Downtown Oakland.\nAfrican-Americans dropped to 28% of Oakland's population in 2010, from nearly half in 1980, due to fast-rising rents and an extreme housing crisis in the region.\nThe city inspected warehouses and live/work spaces after a fire broke out in the Ghost Ship warehouse, killing 36 people in 2016.\nOakland is the second U.S. city, after Denver, to decriminalize psilocybin mushrooms. In June 2019, the City Council passed the resolution in a unanimous vote ending the investigation and imposition of criminal penalties for use and possession of natural entheogens.\nIn November 2019, two homeless mothers and their children illegally occupied a vacant three-bedroom house in West Oakland. The group, calling themselves Moms 4 Housing, said their goal was to protest what they said was a large number of vacant houses in Oakland owned by redevelopment companies while the city experienced a housing crisis. Two months later they were evicted from the house by three dozen sheriff's deputies, as hundreds of supporters demonstrated in favor of the women. The incident received nationwide coverage. The company that owns the house later said they would sell it to a nonprofit affordable housing group. As of 2019, Oakland's per-capita homeless rate was higher than San Francisco and Berkeley. Between 2014 and 2020, Oakland strengthened its protections for tenants in order to reduce the displacement of its long-time residents. However, since 2019, the city of Oakland has reduced the number of approved housing permits by more than 80%, further worsening the housing shortage in Oakland.\nBetween January 2020 and March 2022, Oakland suffered a disproportionate death toll from the COVID-19 pandemic and Delta cron hybrid variant within the San Francisco Bay Area.\nIn 2023, prior to and during the COVID pandemic, Oakland became the first city in American history to lose three professional major league sports teams to other cities within a span of five years.\nGeography.\nOakland is in the eastern region of the San Francisco Bay.\nThe United States Census Bureau says the city's total area is , including of land and (28.48 percent) of water.\nOakland's highest point is near Grizzly Peak Blvd, east of Berkeley, just over above sea level at about . Oakland has of shoreline, but Radio Beach is the only beach in Oakland.\nOaklanders refer to their city's terrain as \"the flatlands\" and \"the hills\". Until recent waves of gentrification, these terms also symbolized Oakland's deep economic divide, with \"the hills\" being more affluent communities. About two-thirds of Oakland lies in the flat plain of the East Bay, with one-third rising into the foothills and hills of the East Bay range.\nRuptures along the nearby San Andreas Fault caused severe earth movement in the San Francisco Bay Area in 1906 and 1989. San Andreas quakes induces creep (movement occurring on earthquake faults) in the Hayward fault, which runs directly through Oakland, Berkeley, San Jose and other Bay Area cities.\nNeighborhoods.\nOakland has more than 50 distinct neighborhoods. The city's greater divisions include downtown Oakland and its greater Central Business District, Lake Merritt, East Oakland, North Oakland, West Oakland, and the Oakland Hills. East Oakland, which includes the East Oakland Hills, encompasses more than half of Oakland's land area, stretching from Lakeshore Avenue on the east shore of Lake Merritt southeast to the San Leandro border. North Oakland encompasses the neighborhoods between downtown and Berkeley and Emeryville. West Oakland is the area between downtown and the Bay, partially surrounded by the Oakland Point, and encompassing the Port of Oakland. In 2011, Oakland was ranked the tenth most walkable city in the United States by Walk Score.\nLake Merritt, an urban estuary near downtown, is a mix of fresh and salt water draining in and out from the Oakland Harbor at the San Francisco Bay and one of Oakland's most notable features. It was designated the United States' first official wildlife refuge in 1870. Originally a marsh-lined wildlife haven, Lake Merritt was dredged and bordered with parks from the 1890s to the 1910s. Despite this reduction in habitat, Oakland is home to a number of rare and endangered species, many of which are localized to serpentine soils and bedrock. Lake Merritt is surrounded by residential and business districts, including downtown and Grand Lake.\nThe city of Piedmont, incorporated in Oakland's central foothills after the 1906 earthquake, is a small independent city surrounded by the city of Oakland.\nClimate.\nOakland has a warm-summer Mediterranean climate (K\u00f6ppen: \"Csb\", Trewartha: \"Csbl\") with an average of 260 sunny days per year. In general, the city features warm, dry summers, and cool, wet winters.\nBased on data gathered by the National Oceanic and Atmospheric Administration, Oakland is ranked No. 1 in climate among U.S. cities. Oakland's climate is typified by the temperate and seasonal Mediterranean climate. Summers are usually dry and warm and winters are cool and damp. It has features found in both nearby coastal cities such as San Francisco and inland cities such as San Jose, making it warmer than San Francisco and cooler than San Jose. Its position on San Francisco Bay across from the Bay Bridge means the northern part of the city can have cooling maritime fog. It is far enough inland that the fog often burns off by midday, allowing it to have typically sunny California days. The hills tend to have more fog than the flatlands, as the fog drifts down from Berkeley.\nThe U.S. Weather Bureau kept weather records in downtown Oakland from October 4, 1894, to July 31, 1958. During that time, the record high temperature was on June 24, 1957, and the record low temperature was on January 23, 1949. Dry, warm offshore \"Diablo\" winds (similar to the Santa Ana winds of Southern California) sometimes occur, especially in fall, and raise the fire danger. In 1991, such an episode allowed the catastrophic Oakland Hills fire to spread and consume many homes.\nOakland, like much of Northern California, is susceptible to winter rainstorms and Atmospheric rivers. The wettest \"rain year\" was from July 1997 to June 1998 with and the driest from July 2020 to June 2021 with . The most rainfall in one month was in January 1911. The most rainfall in 24 hours was on December 31, 2022. Rainfall near the bayfront is only , but is higher in the Oakland Hills to the east (up to ), with nearly all precipitation falling between November and April. While measurable amounts of snowfall in Oakland at sea level is very rare, light snow accumulates on the ground the higher elevations of the Oakland hills with more regularity.\nOvernight lows are mild. Oakland seldom experiences warm nights with the warmest recorded night of in September 1971 and an average of for the annual warmest low. The coldest day of the year averages a mild and has never been recorded below .\nThe National Weather Service today has two official weather stations in Oakland: Oakland San Francisco Bay Airport and the Oakland Museum (established 1970).\nVegetation.\nThe higher rainfall in the hills supports woods of oak, madrona, pine, fir and a few redwood groves in the wetter areas. Before being logged in the 19th century, some of the tallest redwood trees in California (used for navigation by ships entering the Golden Gate) may have stood in the Oakland Hills. One old stump in diameter can be seen near Redwood Regional Park. Sunny, drier slopes are grassy or covered in scattered oaks and chaparral brush. Australian eucalyptus trees have been extensively planted in many areas, as they come from a similar climate.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nThe 2020 United States census reported Oakland had a population of 440,646. The population density was .\nReligion.\n34.95% of people in Oakland are affiliated with a religion, in a total of 417 congregations.\nMajor places of worship in Oakland include \u2013 \nRace and ethnicity.\nThe 2020 United States census reported that the racial makeup of Oakland was 156,429 (35.5%) White, 104,873 (23.8%) Black or African American, 68,300 (15.5%) Asian, 2,643 (0.6%) Pacific Islander, 3,965 (0.9%) Native American, and 30,404 (6.9%) multiracial (two or more races). There were 118,974 (27.0%) of Hispanic or Latino ancestry, of any race.\nFrom the 2010 United States census the racial makeup of Oakland was 134,925 (34.5%) White (non-Hispanic White 25.9%), 129,471 (28.0%) African American, 3,040 (0.8%) Native American, 65,811 (16.8%) Asian (8.7% Chinese, 2.2% Vietnamese, 1.6% Filipino, 0.7% Cambodian, 0.7% Laotian, 0.6% Korean, 0.5% Japanese, 0.5% Indian, 0.1% Mongolian), 2,222 (0.6%) Pacific Islander (0.3% Tongan), 53,378 (13.7%) from other races, and 21,877 (5.6%) from two or more races. There were 99,068 people of Hispanic or Latino ancestry, of any race (25.4%). 18.1% of the population were of Mexican descent, 1.9% Salvadoran, 1.3% Guatemalan, and 0.7% Puerto Rican.\n2022 United States Census Bureau American Community Survey estimates.\nAccording to 2022 US Census Bureau estimates, Oakland's population declined to 430,531, and was 31.1% White (29.7% Non-Hispanic White and 1.5% Hispanic White), 20.6% Black or African American, 1.3% Native American and Alaskan Native, 15.9% Asian, 0.3% Pacific Islander, 19.6% Other Race, and 11.3% from two or more races.\nWhite Americans are the largest racial/ethnic group at either 31.1% (including White Hispanics) or 29.7% (excluding White Hispanics).\nHispanics have been the second largest ethnic group since 2012 when they displaced the Black population. However, Black Americans still form the second largest racial group. By ethnicity, 26.8% of the total population is Hispanic-Latino (of any race) and 73.2% is Non-Hispanic (of any race). The majority of Hispanics self-identify as Some Other Race (69.3%) with the remainder choosing White (5.4%), Multiracial (19.2%), Black (1.6%), American Indian and Alaskan Native (3.8%), Asian (0.7%), and Hawaiian and Pacific Islander (0.1%).\nThe Black population is the third largest ethnic group and second largest racial group at either 20.6% (including Black Hispanics) or 20.1% excluding Black Hispanics.\nThe Asian population continues to remain the fourth largest group at 15.9% of the population.\n5.1% are of English ancestry, French (except Basque), 1.4% German, 6.1% Irish - 6.2% Italian, 3.1% Norwegian, 1.1% Polish - 1.7% Scottish and 1.0%Subsaharan African 2.5%.\nThe most common ancestries in Oakland are German, Irish, English, Italian and European. Spanish and Chinese are the most common non-English spoken languages.\nEducational attainment and income.\nThe greater Oakland area has the fifth largest cluster of \"elite zip codes\" ranked by the number of households with the highest combination of income and education. 37.9% of residents over 25 years of age have bachelor's degree or higher. Oakland ranked among the top cities with residents with bachelor's degrees and graduate degrees per square mile.\nOakland ranks in the top 20 of American cities in median household income, with a 2012 value of US$51,863. In 2012, the median income for a household in the city was US$51,863 and the median income for a family was US$59,459. The mean income for a household was US$77,888 and the mean income for a family was US$90,948. Males had a median income of US$50,140 versus US$50,304 for females. The unemployment rate as of December 2013 was 9.7%.\nIn 2007 approximately 15.3 percent of families and 17.0 percent of the general population were below the poverty line, including 27.9 percent of those under age 18 and 13.1 percent of those age 65 or over. 0.7% of the population is homeless. Home ownership is 41% and 14% of rental units are subsidized.\nAs of the census of 2000, 19.4% of the population and 16.2% of families were below the poverty line. Out of the total population, 27.9% of those under the age of 18 and 13.1% of those 65 and older were living below the poverty line.\nHouseholds.\nThe census reported 382,586 people (97.9% of the population) lived in households, 5,675 (1.5%) lived in non-institutionalized group quarters, and 2,463 (0.6%) were institutionalized.\nThere were 153,791 households, out of which 44,762 (29.1%) had children under the age of 18 living in them, 50,797 (33.0%) were opposite-sex married couples living together, 24,122 (15.7%) had a female householder with no husband present, 8,799 (5.7%) had a male householder with no wife present. There were 11,289 (7.3%) unmarried opposite-sex partnerships, and 3,442 (2.2%) same-sex married couples or partnerships. 52,103 households (33.9%) were made up of individuals, and 13,778 (9.0%) had someone living alone who was 65 years of age or older. The average household size was 2.49. There were 83,718 families (54.4% of all households); the average family size was 3.27.\nThe population was spread out, with 83,120 people (21.3%) under the age of 18, 36,272 people (9.3%) aged 18 to 24, 129,139 people (33.1%) aged 25 to 44, 98,634 people (25.2%) aged 45 to 64, and 43,559 people (11.1%) who were 65 years of age or older. The median age was 36.2 years. For every 100 females, there were 94.2 males. For every 100 females age 18 and over, there were 91.8 males.\nThere were 169,710 housing units at an average density of , of which 153,791 were occupied, of which 63,142 (41.1%) were owner-occupied, and 90,649 (58.9%) were occupied by renters. The homeowner vacancy rate was 3.0%; the rental vacancy rate was 8.5%. 166,662 people (42.7% of the population) lived in owner-occupied housing units and 215,924 people (55.3%) lived in rental housing units.\nShifting of cultures.\nOakland has consistently ranked as one of the most ethnically diverse major cities in the country. A 2019 analysis by WalletHub showed that Oakland was the most ethnoracially diverse city in the United States. The city's formerly most populous ethnic group, whites, declined from 95.3% in 1940 to 32.5% by 1990, due to a combination of factors, including suburbanization. Oakland became a destination for African Americans in the Great Migration during and after World War II as they gained high-paying jobs in the defense industry. Blacks have formed a plurality in Oakland for many years, peaking in 1980 at about 47% of the population.\nOakland's Black population decreased by nearly 25 percent between 2000 and 2010. The city's demographics have changed due to a combination of rising housing prices associated with gentrification and with blacks relocating to better (and in many cases more affordable) housing in Bay Area suburbs or moving to the Southern United States in a reverse migration, where conditions (including race relations) are considered to have improved in comparison to previous generations. These trends and cultural shifts have led to a decline among some of Oakland's long standing black institutions, such as churches, businesses and nightclubs, which had developed during the growing years of the 1950s through 1970.\nIn the 2010 census African Americans maintained their status as Oakland's single largest ethnic group, with 27% of the population, followed by non-Hispanic whites at 25.9%, and Hispanics of any race at 25.4%. Ethnic Asians constitute 17%, followed by smaller minority groups.\nMany immigrants have settled in the city. Immigrants and others have marched by the thousands down Oakland's International Boulevard in support of legal reforms benefiting undocumented immigrants.\nAn analysis by the Urban Institute of U.S. Census 2000 numbers showed Oakland had the third-highest concentration of gays and lesbians among the 50 largest U.S. cities, behind San Francisco and Seattle. Census data showed that among incorporated places that have at least 500 female couples, Oakland had the nation's largest proportion. In the 2000 census, 2,650 lesbian couples identified as such in Oakland; one in every 41 Oakland couples identified as a same-sex female partnership.\nGentrification.\nAccording to the lobbying non-profit National Community Reinvestment Coalition, from 2013-2017 the San Francisco-Oakland Metro shows indications of having the greatest intensity of gentrification nationally, with over 31% of eligible neighborhoods gentrifying. Gentrifying neighborhoods showed significant increases in median home value, median household income, percentage of college educated residents, but also in economic inequality.\nIn West Oakland, median household income rose from $80,700 to $86,300 between 2010 and 2017, while the percent of population with four-year degrees rose from one-third to nearly one-half, according to the National Community Reinvestment Coalition.\nLocal technology companies have created jobs in Oakland, and some new apartments have appeared, rents increased, and some working-class residents have moved to suburbs further inland. The city of Oakland has failed to approve new housing permits to keep up with demand for new housing, which caused housing prices to rise.\nAccording to 2015 data compiled by the Bay Area Equity Atlas, 18% of low-income households of color were in neighborhoods that were gentrifying compared to 33.7% of low-income white households.\nCrime.\nA 2014 study by the Chief Justice Earl Warren Institute on Law &amp; Social Policy at the University of California, Berkeley School of Law examined crime in the city from 1987 to 2012 and concluded that \"The story of crime in Oakland over the last 25 years is a nuanced one, as there are both positive and negative aspects of the crime trends.\" Crime dramatically decreased since the early 1990s but the city has continued to suffer from serious violent crime problems. Crime trends generally tracked comparison cities of Fresno, Richmond, Sacramento, and Stockton \"in terms of direction if not magnitude\"; this suggested that crime trends are regional rather than city-specific.\nA 2007 journal article identified crime in Oakland as being fueled by the dramatic increase of street narcotics sales and use since the 1970s, with Oakland becoming a major west-coast hub for heroin and cocaine distribution. Subsequent battle for control over the lucrative narcotics trade incited gang conflicts and violence, with shootings becoming a regular occurrence. A concurrent rise in rape, robbery, burglary, auto-theft and other crimes occurred as well. Prior to 1960, there had been successful government-funded social programs whereby rebellious teens were enrolled in youth centers that would teach them proper values and improve their behavior. Similar programs since then have been inconsistent.\nBy the 1970s, the police and Federal Bureau of Investigation (FBI) used military tactics such as SWAT teams, infiltration and counter intelligence in an attempt to counter groups such as the Black Panthers (responsible for several police ambushes), the S.L.A. and organized drug gangs such as the \"69 Mob\", with increases in arrests, prosecutions, and imprisonment. During the first decade of the 21st century, Oakland has consistently been listed as one of the most dangerous large cities in the United States.\nThe number of Oakland Police Department officers has varied from a low of 626 (in 1996 and in 2012) to a high of 814 (in 2002). There were 723 officers at the end of 2015. The city's strategic plan recommended 925 officers, and an independent study commissioned by the city in the mid-1990s recommended 1,200 officers. As of 2025, the city employed only 675 police officers, budgeted for only 600, and of these, 100 were on leave.\nAmong Oakland's 35 police patrol beats, violent crime remains a serious problem in specific East and West Oakland neighborhoods. In 2008, homicides were concentrated: 72% occurred in three City Council districts, District 3 in West Oakland and Districts 6 and 7 in East Oakland, although these districts have 44% of Oakland's residents.\nIn 2012, Oakland implemented Operation Ceasefire, a gang violence reduction plan used in other cities, based in part on the research and strategies of author David M. Kennedy.\nEconomy.\nOakland is a major West Coast port, and the fifth-busiest in the United States by cargo volume. The Port of Oakland handles 99% of all containerized goods moving through Northern California, representing $41 billion worth of international trade. There are nearly 200,000 jobs related to marine cargo transport in the Oakland area. These jobs range from minimum wage hourly positions to Transportation Storage and Distribution Managers who earn an annual average salary of US$91,520.\nThe Port of Oakland was an early innovator/pioneer in the technologies of Intermodal Containerized Shipping. The city is also home to several major corporations including Kaiser Permanente, Clorox, and Dreyer's ice cream. Tech companies such as Ask.com and Pandora Radio are in Oakland, and in recent years many start-up high tech and green energy companies have found a home in the downtown neighborhoods of Uptown, City Center, Jack London Square and Lake Merritt Financial District.\nAs of 2013[ [update]], the San Francisco-Oakland-Hayward metropolitan area has a gross domestic product (GDP) of US$360.4\u00a0billion, ranking eighth among metropolitan areas in the United States. In 2014, Oakland was amongst the best cities to start a career, the highest ranked city in California after San Francisco. Additionally, Oakland ranked fourth in cities with professional opportunities. Numerous companies in San Francisco continue to expand in or migrate over to Oakland.\nOakland experienced an increase of both its population and of land values in the early-to-mid first decade of the 21st century. The 10k Plan, which began during former mayor Elihu Harris' administration, and intensified during former mayor Jerry Brown's administration resulted in several thousand units of new multi-family housing and development. In 2023, Oakland became the first American city ever to lose three professional major league sports teams to other cities within a five-year span.\nTop employers.\nAs of 2024[ [update]], the top employers in the city were:\nTourism.\nIn 2013, over 2.5 million people visited Oakland, contributed US$1.3\u00a0billion into the economy. Oakland has been experiencing an increase in hotel demand. Occupancy is 74%, while RevPAR (Revenue Per Available Room) increased by 14%, the highest increase of any big city in the western region of the United States. Both Oakland and San Francisco were forecasted to experience the highest increases in ADR (Average daily rate).\nIn recent years, Oakland has gained national recognition as a travel destination. In 2012, The New York Times named Oakland the top North American city to visit, highlighting its growing number of sophisticated restaurants and bars, top music venues, and increasing nightlife appeal. Oakland also took the No. 16 spot in \"America's Coolest Cities\", ranked by metrics like entertainment options and recreational opportunities per capita, etc. In 2013, Oakland topped the No. 1 spot in \"America's Most Exciting Cities\", notably having the most movie theaters, theater companies, and museums per square mile. In \"America's Most Hipster Cities\", Oakland took the number-5 spot, cited for luring San Francisco \"hippies\" into the city. Oakland has also increased its travel destination allure internationally.\nArts and culture.\nOakland has a vibrant art scene and claims the highest concentration of artists per capita in the United States. In 2013, Oakland was designated as one of America's top twelve art communities, recognizing Downtown (including Uptown), Chinatown, Old Oakland, and Jack London Square as communities \"that have most successfully combined art, artists and venues for creativity and expression with independent businesses, retail shops and restaurants, and a walkable lifestyle to make vibrant neighborhoods.\"\nGalleries exist in various parts of Oakland, with the newest additions centered mostly in the Uptown area. Oakland ranked 11th in cities for designers and artists. The city is a renowned culinary hotbed, offering both a wide variety and innovative approaches to diverse cuisines in restaurants and markets, often featuring locally grown produce and international styles such as French, Italian, Portuguese/Spanish, Ethiopian, Asian, Latin American, as well as Caribbean, Southern United States/Louisiana Creole, etc., all of which reflects the culinary traditions of the city's ethnically diverse population.\nHistorically a focal point of the West Coast blues and jazz scenes, Oakland is also home to musicians representing such genres as rhythm and blues, gospel, funk, punk, heavy metal, Rap/Gangsta rap, and hip hop. Artists who come out of Oakland include Green Day, Tower of Power, Mistah F.A.B., E-40, Too Short, Tupac Shakur, Raphael Saadiq, MC Hammer, Keyshia Cole, Kehlani, G-Eazy, Del the Funky Homosapien, Edwin Hawkins, Tony! Toni! Ton\u00e9! and many more.\nNightlife.\nDowntown Oakland has an assortment of bars and nightclubs. They include dive bars, dance clubs, modern lounges and jazz bars. The Paramount Theater features headlining musical tours and productions, while Fox Oakland Theatre draws various musical genres including jam bands, rock, punk, blues, jazz, and reggae. The Paramount and Fox theaters often book simultaneous events, creating busy nights uptown. In 2012, Oakland was dubbed a \"New Sin City\", following its 2010 decision to relax its cabaret laws, which gave a boost to its nightclub and bar scene.\nRecent years have seen the growth of the Oakland Art Murmur event, occurring in the Uptown neighborhood the first Friday evening of every month. The event attracts around 20,000 people along twenty city blocks, featuring live performances, food trucks, and over 30 galleries and venues.\n\"There is no there there\".\nIn her 1937 book \"Everybody's Autobiography\", Gertrude Stein said of Oakland: \"There is no there there\", upon learning that the neighborhood where she lived as a child had been torn down to make way for an industrial park. The quote is usually misconstrued to refer to Oakland as a whole.\nModern-day Oakland has made steps to rebuke Stein's claim with a statue downtown titled \"There\". In 2005 a sculpture called \"HERETHERE\" was installed by the City of Berkeley on the Berkeley-Oakland border at Martin Luther King Jr. Way. The sculpture consists of eight-foot-tall letters spelling \"HERE\" and \"THERE\" in front of the BART tracks as they descend from their elevated section in Oakland to the subway through Berkeley.\nSports.\nOakland's former baseball team, the Oakland Athletics of Major League Baseball won three consecutive World Series championships in 1972, 1973, and 1974, and appeared in another three consecutive World Series from 1988 to 1990, winning their fourth championship in 1989. Formerly based at the Oakland Coliseum, the Oakland Athletics announced plans to move to Las Vegas to play at a new 33,000-seat partially retractable ballpark on the Las Vegas Strip with the team itself spending three seasons at Sutter Health Park in West Sacramento as a temporary home. The move leaves Oakland without a major professional sports team for the first time since 1959.\nOakland's former football team, the Oakland Raiders of the National Football League (NFL), won Super Bowl XI in 1976 and Super Bowl XV in 1980, during their tenure in Oakland. The Raiders relocated to Las Vegas in 2020 and are now known as the Las Vegas Raiders.\nOakland's former basketball team, the Golden State Warriors won the 1974\u201375, 2014\u201315, 2016\u201317, and the 2017\u201318 NBA championships, while losing in 2016 and 2019. The Warriors, whose primary owners reside in Southern California, announced in April 2014 that they would leave Oakland once their new arena was built across the Bay in San Francisco. In 2019, the Warriors built and moved to Chase Center across the Bay. Since the team remained in the Bay Area, they decided not to revert to the San Francisco Warriors name it had in its first stint with the city.\nThe Oakland Roots SC are a professional soccer team that was formed in 2018. The Roots began play in 2019 in a new third division professional league known as the National Independent Soccer Association, however, the team announced that it would move into the second division of US professional soccer, and play in the USL Championship beginning in the 2021 season. The Roots play their home matches at Oakland Coliseum.\nThe Oakland Soul SC, a woman's professional soccer club began play in May 2023 as an expansion team in the USL W League, a pre-professional league; they also play at the Oakland Coliseum.\nOakland's former hockey team, the California Golden Seals were a professional ice hockey club that competed in the National Hockey League (NHL) from 1967 to 1976. Based in Oakland, they played their home games at the Oakland\u2013Alameda County Coliseum Arena. The Seals were one of six teams added to the league as part of the 1967 NHL expansion. Initially named the California Seals, the team was renamed the Oakland Seals during the 1967\u201368 season and then the Bay Area Seals in 1970 before becoming the California Golden Seals the same year.\nThe Seals were the least successful of the teams added in the 1967 expansion, never earning a winning record and only making the playoffs twice in nine seasons of play. Off the ice, they were plagued by low attendance. The franchise was relocated prior to the beginning of the 1976\u201377 season to become the Cleveland Barons, who would cease operation two years later.\nOakland's ultimate team, Oakland Spiders, relocated to Oakland in 2022 after playing eight years as the San Jose Spiders.\nOakland's former sports teams include:\nParks and recreation.\nParks.\nOakland has many parks and recreation centers which total . In its 2013 ParkScore ranking, The Trust for Public Land, a national land conservation organization, reported that Oakland had the 18th best park system among the 50 most populous U.S. cities. In 2013, Oakland ranked fourth among American cities as an urban destination for nature lovers.\nSome of the city's most notable parks include:\nAdditionally, the following nine East Bay Regional Parks are entirely or partially in the city of Oakland:\nMcLaughlin Eastshore State Park is partially in the city of Oakland and although it is a California State Park, it is managed by the East Bay Regional Park District.\nGovernment.\nOakland has a mayor-council government. The mayor is elected at-large for a four-year term. The Oakland City Council has eight council members representing seven districts in Oakland with one member elected at-large and others from single-member districts; council members serve staggered four-year terms. The mayor appoints a city administrator, subject to the confirmation by the City Council, who is the city's chief administrative officer. Other city officers include: city attorney (elected), city auditor (elected), and city clerk (appointed by city administrator). Oakland's mayor is limited to two terms. There are no term limits for the city council.\nOakland City Hall was evacuated after the 1989 Loma Prieta earthquake until US$80M seismic retrofit and hazard abatement work was complete in 1995. City offices had to be housed in leased space and other locations.\nJean Quan was elected mayor in November 2010, beating Don Perata and Rebecca Kaplan in the city's first ranked choice balloting. This new system is intended to increase voters' ability to choose preferred candidates, as they can combine ranked votes when several candidates are competing. Sheng Thao, the first Hmong American mayor of a major city in the United States, served from 2023 until her recall in 2024. Barbara Lee has served as mayor of Oakland since 2025.\nOakland is also part of Alameda County, for which the Government of Alameda County is defined and authorized under the California Constitution, California law, and the Charter of the County of Alameda. The County government provides countywide services such as elections and voter registration, law enforcement, jails, vital records, property records, tax collection, public health, and social services. The County government is primarily composed of the elected five-member Board of Supervisors, other elected offices including the Sheriff/Coroner, the District Attorney, Assessor, Auditor-Controller/County Clerk/Recorder, and Treasurer/Tax Collector, and numerous county departments and entities under the supervision of the County Administrator.\nIn the California State Legislature, Oakland is in the senatorial district, represented by Democrat Tim Grayson, and is split between the 14th, 15th, and 18th Assembly districts, represented by Buffy Wicks, Anamarie Avila Farias, and Mia Bonta, respectively. In the United States House of Representatives, Oakland is in California's 12th congressional district, represented by Democrat Lateefah Simon.\nPolitics.\nOakland was a Republican Party bastion from the 1860s to the 1950s, with positions expressed by the Republican-oriented \"Oakland Tribune\" newspaper. In the 1960s, the majority of voters began to favor liberal policies and the Democratic Party. Oakland has the second highest percentage of registered Democrats of any of the incorporated cities in Alameda County, with Berkeley coming in first.\nThe last Republican presidential candidate to receive at least one-third of vote in Oakland was Richard Nixon in 1972. Since then, the Republican percentage of the vote has generally declined in each successive election.[citation needed]\nAccording to the California Secretary of State, as of February 10, 2019, Oakland has 245,111 registered voters. Of those, 159,771 (65.2%) are registered Democrats, 9,544 (3.9%) are registered Republicans, and 65,416 (26.7%) have declined to state a political party. Oakland is widely regarded as being one of the most liberal major cities in the nation. The Cook Partisan Voting Index of Congressional District 12, which includes Oakland and Berkeley, is D+40, making it the most Democratic congressional district in California and the fourth most Democratic district in the US.\nOn November 27, 2023, the City Council unanimously passed a resolution calling for a ceasefire in Israel's war on Hamas, after hearing more than 500 residents speak on the topic. \nIn 2024, Oakland voters recalled then-mayor Sheng Thao, becoming the first Oakland mayor to be recalled in the city's history. Thao was also indicted by the Department of Justice for bribery and other crimes.\nTaxes.\nOakland has the second highest sales tax rate in California, at 10.75%. The residential property tax rates in Oakland are also among the highest in California, at a median of 1.71%.\nEducation.\nPrimary and secondary education.\nThe Oakland Unified School District (OUSD), which covers the city except for Sheffield Village, operates most of Oakland's public schools. Due to financial troubles and administrative failures, it was in receivership by the state of California from 2002 to 2008. As of 2015[ [update]], the Oakland Unified School District includes 86 division-run schools and 32 charter schools; the district also manages several adult education programs. As of 2015[ [update]] there are 48,181 K\u201312 students; among division-run schools, there are 4,600 plus employees.\nOUSD test scores historically lag behind the rest of California, in particular due to a high proportion of English-language learners. Some individual schools have much better performance than the citywide average. As of 2013[ [update]], for example, over half the students at Hillcrest Elementary School in the Montclair upper hills neighborhood performed at the \"advanced\" level in the English portion of the test, and students at Lincoln Elementary School in the Chinatown neighborhood performed at the \"advanced\" level in the math portion.\nOakland's three largest public high schools are Oakland High School, Oakland Technical High School, and Skyline High School. Other Oakland public high schools include Castlemont High School, Fremont High School, and McClymonds High School, briefly known as Castlemont Community of Small Schools, Fremont Federation of High Schools, and McClymonds Educational Complex, respectively.\nAmong charter schools in the district, North Oakland Community Charter School (NOCCS), an elementary and middle school, is one of the few public progressive schools in the country. Other charter schools include the Oakland Military Institute, Oakland School for the Arts, Bay Area Technology School, East Bay Innovation Academy, and Oakland Charter Academy.\nThere are several religious and secular private high schools, including The College Preparatory School, Head-Royce School, Bishop O'Dowd High School, Holy Names High School, St. Elizabeth High School and Oakland Hebrew Day School. Catholic schools in Oakland are operated by the Roman Catholic Diocese of Oakland also include eight K\u20138 schools (plus one in Piedmont on the Oakland city border). Northern Light School is a private nonprofit elementary and middle school. Bentley School is an Independent Co-educational K\u201312, college preparatory school on two campuses in Oakland and Lafayette, California.\nFunding.\nIn 2017, the Oakland Unified School District has received funding from the technology company Pandora in partnership with Little Kids Rock, towards expanding music education programs within the schools. The result from these donations has given teachers from 20 additional Oakland-area schools the ability to participate in an eight-hour professional development workshop, and receive music education instruction from Little Kids Rock. The donation includes providing new instruments, that will benefit over 2,000 Oakland students.\nColleges and universities.\nAccredited colleges and universities include:\nOakland is also the home of the headquarters of the University of California system, the University of California Office of the President.\nIn 2001, the SFSU Oakland Multimedia Center was opened, allowing San Francisco State University to conduct classes near downtown Oakland. The Oakland Higher Education Consortium and the City of Oakland's Community and Economic Development Agency (CEDA) opened the Oakland Higher Education Center downtown in 2002 to provide \"access to multiple higher education service providers within a shared urban facility.\" Member schools include primary user California State University, East Bay as well as Lincoln University, New College of California, Saint Mary's College of California, SFSU Multimedia Studies Program, UC Berkeley Extension, University of Phoenix and Peralta Community College District.\nMedia.\nOakland is served by major television stations broadcasting primarily out of San Francisco and San Jose. The region's Fox O&amp;O, KTVU 2, is based in (and licensed to) Oakland at Jack London Square along with co-owned MyNetworkTV outlet KICU-TV 36 (licensed to San Jose). In addition, the city is served by various radio stations as well; AM stations KKSF 910, KMKY 1310 and KNEW 960 are licensed to Oakland.\nOakland was served by the \"Oakland Tribune\", which published its first newspaper on February 21, 1874. The Tribune Tower, which features a large clock, is an Oakland landmark. At key times throughout the day (8:00\u00a0am, noon and 5:00\u00a0pm), the clock tower carillon plays a variety of classic melodies, which change daily. In 2007, the Oakland Tribune moved its offices from the tower to an East Oakland location, before folding in 2011.\nThe \"East Bay Express\", a locally owned free weekly paper, is based in Jack London Square and distributed throughout the East Bay.\nOaklandwiki is a thriving (mostly) English-language LocalWiki.\nInfrastructure.\nTransportation.\nAir and rail.\nOakland residents have access to the three major airports of the San Francisco Bay Area: Oakland San Francisco Bay Airport, San Francisco International Airport, and San Jose International Airport. Oakland International Airport, within Oakland's city limits, is south of downtown Oakland and serves domestic and international destinations. AC Transit provides 24-hour service to the airport, and BART's Oakland Airport Connector automated guideway transit line provides frequent service between the airport and Oakland Coliseum station.\nThe city has regional and long-distance passenger train service provided by Amtrak, with stations near Jack London Square and the RingCentral Coliseum. Amtrak's \"California Zephyr\" has its western terminus at the nearby Emeryville station.\nHistorically, the city was served by several train companies, which terminated in different terminals. Santa Fe trains terminated at its Oakland depot, actually located within the city limits of Emeryville at 40th and San Pablo. Southern Pacific trains ended at the 16th Street Station. Western Pacific trains ended at the 3rd and Washington station. However, a common feature was that the different railroads continued one more stop to a station at Oakland Pier. From this latter point passengers would ride ferries to San Francisco.\nMass transit and bicycling.\nData compiled in 2007 by the United States Census Bureau before gasoline price spikes in 2008, showed that 24.3% of Oaklanders used public transportation, walked or used \"other means\" to commute to work, not including remote work, with 17% of Oakland households being \"car free\" and/or statistically categorized as having \"no vehicles available.\"\nBus transit service in Oakland and the inner East Bay is provided by the Alameda and Contra Costa Transit District, AC Transit. The district originated in 1958 after the conspiratorial dissolution of the Key System of streetcars. Many AC Transit lines follow old routes of the Key System. During COVID-19, AC Transit canceled many bus lines in Oakland, and never restored their service.\nIntercity bus companies that serve Oakland include Greyhound, BoltBus, USAsia, and Hoang Transportation. Megabus no longer serves Oakland.\nThe metropolitan area is served by Bay Area Rapid Transit (BART) from eight stations in Oakland, served by all BART lines.The system has headquarters in Oakland, with major transfer hubs at MacArthur and 19th Street stations. BART's headquarters was in a building above the Lake Merritt BART station until 2006, when it relocated to the Kaiser Center due to seismic safety concerns.\nThe Alameda / Oakland Ferry operates ferry service from Jack London Square to Alameda, Oracle Park, Pier 41, the San Francisco Ferry Building, and the South San Francisco Ferry Terminal.\nOakland licenses taxi cabs, and has zoned cab stands in its downtown, including a bicycle pedi-cab service.\nThe Oakland City Council adopted a Bicycle Master Plan in 1999 as a part of the Land Use and Transportation (LUTE) element of Oakland's 1998 General Plan. The creation of the plan was to promote alternatives to the private automobile. The Oakland City Council reaffirmed the bike plan in 2005, revised it in 2007, and reaffirmed it in 2012. From 1999 to 2007, the city installed 900 bike racks throughout Oakland, accommodating over 2,000 bicycles. By the end of 2017, over 160 bikeway miles and 9,900 bike parking spaces were constructed. Facilities for parking thousands of bicycles have been installed downtown and in other commercial districts throughout Oakland. According to the U.S. Census Bureau's 2011 American Community Survey, Oakland came in seventh place out of the 100 largest cities in the nation by percentage of people that chose to commute by bike in 2011.\nMotorized scooters.\nIn July 2019, the City of Oakland Department of Transportation announced that it had issued official permits for the deployment of shared e-scooters to four companies: Bird, Clevr, Lime, and Lyft. Oakland requires these operators to educate users on the correct and safe use of scooters, to distribute the scooters equitably throughout the city, to ensure accessibility, and to provide insurance and indemnification.\nBridges, freeways, and tunnels.\nOakland is served by several major highways: Eastbound Bay Bridge traffic entering Oakland then splits into three freeways at the MacArthur Maze freeway interchange: Interstate 580 (MacArthur Freeway) heads southeast toward Hayward and eventually to the California Central Valley; Interstate 880 (Nimitz Freeway) runs south to San Jose; and the Eastshore Freeway (Interstate 80/I-580) runs north, providing connections to Sacramento and San Rafael, respectively.\nInterstate 980 (Williams Freeway) begins its eastbound journey at I-880 in Downtown Oakland before turning into State Route 24 (Grove Shafter Freeway) at I-580. State Route 13 begins as the Warren Freeway at I-580, and runs through a scenic valley in the Montclair District before entering Berkeley. A stub of a planned freeway was constructed at the High Street exit from the Nimitz Freeway, but that freeway extension plan was abandoned.\nAt the time of the 1989 Loma Prieta earthquake, the Cypress Street Viaduct double-deck segment of the Nimitz Freeway collapsed, killing 42 people. The old freeway segment had passed through the middle of West Oakland, forming a barrier between West Oakland neighborhoods. Following the earthquake, this section was rerouted around the perimeter of West Oakland and rebuilt in 1997\u20132001. The east span of the San Francisco\u2013Oakland Bay Bridge also suffered damage from the quake when a 50-foot (15-m) section of the upper deck collapsed onto the lower deck; the damaged section was repaired within a month of the earthquake. As a result of Loma Prieta, a significant seismic retrofit was performed on the western span of the Bay Bridge. The eastern span has now been replaced with a dramatic single-tower self-anchoring suspension span.\nTwo underwater tunnels, the Webster and Posey Tubes, connect the main island of Alameda to downtown Oakland, coming above ground in Chinatown. In addition, the Park Street, Fruitvale, and High Street bridges connect Alameda to East Oakland over the Oakland Estuary.\nIn the hills, the Leimert Bridge crosses Dimond Canyon, connecting the Oakmore neighborhood to Park Boulevard. The Caldecott Tunnel carries Highway 24 through the Berkeley Hills, connecting central Contra Costa County to Oakland. The Caldecott has four bores.\nOakland Slow Streets Program.\nOn April 11, 2020, the City of Oakland launched its Slow Streets Program. This was facilitated in part by the sudden decrease of vehicle traffic that resulted from the state-wide stay-at-home order and school closures in response to the spread of the COVID-19 in California. The goal of the program was to \"support safe physical activity and alleviate overcrowding in parks and on trails by discouraging through traffic.\" This was accomplished by closing 74 miles of streets to through traffic.\nOver the course of three months the city installed \"soft closure\" barriers consisting of signage, traffic cones, and barricades in over 21 miles of city streets. While the primary goal at the time was to encourage socially distanced outdoor physical activities like biking, walking, and jogging, the long term implementation of the Slow Streets Program contributed to the city's traffic calming measures and promoted alternatives to car use as well.\nAlthough the Slow Streets Program was initially praised for its rapid implementation and prioritization of pedestrian safety, the Oakland Department of Transportation quickly came under fire for its failure to collect feedback that represented the opinions of the diverse range of residents whom the program affected. The high engagement with online surveys by wealthy white residents initially suggested an almost universally positive reaction to the program.\nAfter the flaws of the feedback forms were brought to light, city planners made concentrated efforts to meet with representatives from different community groups who in turn stressed that simply closing streets to through traffic was not enough to protect pedestrians from dangerous driving. In response the city expressed its commitment to its local residents calling for road traffic safety by rolling out Slow Streets: Essential Places, a phase of the program which installed cones and signage at dangerous traffic areas in order to make grocery stores, COVID-19 test sites, and food distribution sites easily and safely accessible. By January 2022, all of the Slow Streets were removed, and road fatalities continued to be elevated above 2019 levels. No updates have been shared publicly by the city on any future Slow Streets improvements. In contrast, other cities, including San Francisco, kept and improved many of their Slow Streets.\nFreight rail.\nFreight service, which consists primarily of moving shipping containers to and from the Port of Oakland, is provided today by Union Pacific Railroad (UP), and to a lesser extent by BNSF Railway (which now shares the tracks of the UP between Richmond and Oakland).\nHistorically, Oakland was served by several railroads. Besides the transcontinental line of the Southern Pacific, there was also the Santa Fe (whose Oakland terminal was actually in Emeryville), the Western Pacific Railroad (who built a pier adjacent to the SP's), and the Sacramento Northern Railroad (eventually absorbed by the Western Pacific, which in turn was absorbed by UP in 1983).\nShipping.\nAs one of the three major ports on the West Coast of the United States, the Port of Oakland is the largest seaport on San Francisco Bay and the fifth busiest container port in the United States. It was one of the earliest seaports to switch to containerization and to intermodal container transfer, thereby displacing the Port of San Francisco, which never modernized its waterfront. One of the earlier limitations to growth was the inability to transfer containers to rail lines, all cranes historically operating between ocean vessels and trucks. In the 1980s, the Port of Oakland began the evaluation of development of an intermodal container transfer capability, i.e., facilities that now allow trans-loading of containers from vessels to either trucks or rail modes.\nUtilities.\nPublic water supply and sewage treatment are provided by East Bay Municipal Utility District (EBMUD). Pacific Gas and Electric Company (PG &amp; E) provides natural gas and electricity service. Municipal garbage collection is franchised to Waste Management, Inc. Telecommunications and subscriber television services are provided by multiple private corporations and other service providers in accordance with the competitive objectives of the Telecommunications Act of 1996.\nOakland tops the list of the 50 largest US cities using electricity from renewable sources.\nHealthcare.\nOriginating in Oakland, Kaiser Permanente is an HMO started in 1942, during World War II, by industrialist Henry J. Kaiser to provide medical care for Kaiser Shipyards workers. It is the largest managed care organization in the United States and the largest non-governmental health care provider in the world. It is headquartered at One Kaiser Plaza in Downtown Oakland and maintains a large medical center in the Piedmont Avenue neighborhood.\nAlta Bates Summit Medical Center, an East Bay hospital system, maintains its Summit Campus in the neighborhood known as \"Pill Hill\" north of downtown. Until 2000, it was the Summit Medical Center before merging with Berkeley-based Alta Bates. All campuses now operate under the Sutter Health network.\nAlameda Health System is an integrated public health care system organized as a public hospital authority. It operates five Alameda County hospitals including Oakland's Highland Hospital and four primary care medical clinics including Oakland's Highland Wellness Center and Eastmont Wellness Center.\nChildren's Hospital Oakland is the primary medical center specializing in pediatrics in the East Bay. It is a designated Level I pediatric trauma center and the only independent children's hospital in Northern California.\nThere are also several community health centers in Oakland. Some examples include Lifelong Medical Care, Asian Health Services, and Roots Community Health Center.\nInternational relations.\nSister cities.\nOakland has 13 sister cities:\nFriendship cities.\nOakland has 18 friendship cities:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50549", "revid": "18779361", "url": "https://en.wikipedia.org/wiki?curid=50549", "title": "Diocese", "text": "Christian district governed by a bishop\nIn church governance, a diocese or bishopric is the ecclesiastical district under the jurisdiction of a bishop.\nHistory.\nIn the later organization of the Roman Empire, the increasingly subdivided provinces were administratively associated in a larger unit, the diocese (Latin \"dioecesis\", from the Greek term \u03b4\u03b9\u03bf\u03af\u03ba\u03b7\u03c3\u03b9\u03c2, meaning \"administration\").\nChristianity was given legal status in 313 with the Edict of Milan. Churches began to organize themselves into dioceses based on the civil dioceses, not on the larger regional imperial districts. These dioceses were often smaller than the provinces. Christianity was declared the Empire's official religion by Theodosius I in 380. Constantine I in 318 gave litigants the right to have court cases transferred from the civil courts to the bishops. This situation must have hardly survived Julian, 361\u2013363. Episcopal courts are not heard of again in the East until 398 and in the West in 408. The quality of these courts was low, and not above suspicion as the Bishop of Alexandria Troas found that clergy were making a corrupt profit. Nonetheless, these courts were popular as people could get quick justice without being charged fees. Bishops had no part in the civil administration until the town councils, in decline, lost much authority to a group of 'notables' made up of the richest councilors, powerful and rich persons legally exempted from serving on the councils, retired military, and bishops post-AD 450. As the Western Empire collapsed in the 5th century, bishops in Western Europe assumed a larger part of the role of the former Roman governors. A similar, though less pronounced, development occurred in the East, where the Roman administrative apparatus was largely retained by the Byzantine Empire. In modern times, many dioceses, though later subdivided, have preserved the boundaries of a long-vanished Roman administrative division. For Gaul, Bruce Eagles has observed that \"it has long been an academic commonplace in France that the medieval dioceses, and their constituent \"pagi\", were the direct territorial successors of the Roman \"civitates\".\"\nModern usage of 'diocese' tends to refer to the sphere of a bishop's jurisdiction. This became commonplace during the self-conscious \"classicizing\" structural evolution of the Carolingian Empire in the 9th century, but this usage had itself been evolving from the much earlier \"parochia\" (\"parish\"; Late Latin derived from the Greek \u03c0\u03b1\u03c1\u03bf\u03b9\u03ba\u03af\u03b1 \"paroikia\"), dating from the increasingly formalized Christian authority structure in the 4th century.\nArchdiocese.\nDioceses ruled by an archbishop are commonly referred to as archdioceses; most are metropolitan sees, being placed at the head of an ecclesiastical province. In the Catholic Church, some are suffragans of a metropolitan see or are directly subject to the Holy See.\nThe term \"archdiocese\" is not found in Catholic canon law, with the terms \"diocese\" and \"episcopal see\" being applicable to the area under the ecclesiastical jurisdiction of any bishop. If the title of archbishop is granted on \"personal\" grounds to a diocesan bishop, his diocese does not thereby become an archdiocese.\nCatholic Church.\nThe Canon Law of the Catholic Church defines a diocese as \"a portion of the people of God which is entrusted to a bishop for him to shepherd with the cooperation of the presbyterium, so that, adhering to its pastor and gathered by him in the Holy Spirit through the gospel and the Eucharist, it constitutes a particular church in which the one, holy, catholic, and apostolic Church of Christ is truly present and operative.\"\nAlso known as \"particular churches\" or \"local churches\", dioceses are under the authority of a bishop. They are described as ecclesiastical districts defined by geographical territory. Dioceses are often grouped by the Holy See into ecclesiastical provinces for greater cooperation and common action among regional dioceses. Within an ecclesiastical province, one diocese can be designated an \"archdiocese\" or \"metropolitan archdiocese\", establishing centrality within an ecclesiastical province and denoting a higher rank. Archdioceses are often chosen based on their population and historical significance. All dioceses and archdioceses, and their respective bishops or archbishops, are distinct and autonomous. An archdiocese has limited responsibilities within the same ecclesiastical province assigned to it by the Holy See.\nAs of \u00a02024[ [update]], in the Catholic Church there are 2,898 regular dioceses (or eventually eparchies) consisting of: 1 papal see, 9 patriarchates, 4 major archeparchies, 564 metropolitan archdioceses, 77 single archdioceses and 2,261 dioceses in the world.\nIn the Eastern Catholic Churches that are in communion with the Pope, the equivalent entity is called an \"eparchy\" or \"archeparchy\", with an \"eparch\" or \"archeparch\" serving as the ordinary.\nThe \"Constitution on the Sacred Liturgy\" issued by the Second Vatican Council in 1963 directed that every diocese, or where appropriate a combination of dioceses, should establish a diocesan commission on the sacred liturgy, and, if possible, a commission for sacred music and a commission for sacred art, directing that they either work together in close collaboration or form a single body.\nEastern Orthodox Church.\nThe Eastern Orthodox Church calls dioceses \"episkopes\" (from the Greek \u1f10\u03c0\u03b9\u03c3\u03ba\u03bf\u03c0\u03ae) in the Greek tradition and \"eparchies\" (from \u1f10\u03c0\u03b1\u03c1\u03c7\u03af\u03b1) in the Slavic tradition.\nLutheran churches.\nCertain Lutheran denominations such as the Church of Sweden do have individual dioceses similar to Roman Catholics. These dioceses and archdioceses are under the government of a bishop (see Archbishop of Uppsala). Other Lutheran bodies and synods that have dioceses and bishops include the Church of Denmark, the Evangelical Lutheran Church of Finland, the Evangelical Church in Germany (partially), and the Church of Norway.\nFrom about the 13th century until the German mediatization of 1803, the majority of the bishops of the Holy Roman Empire were prince-bishops, and as such exercised political authority over a principality, their so-called Hochstift, which was distinct, and usually considerably smaller than their diocese, over which they only exercised the usual authority of a bishop.\nSome American Lutheran church bodies such as the Evangelical Lutheran Church in America have a bishop acting as the head of the synod, but the synod does not have dioceses and archdioceses as the churches listed above. Rather, it is divided into a middle judicatory.\nThe Lutheran Church - International, based in Springfield, Illinois, presently uses a traditional diocesan structure, with four dioceses in North America. Its current president is Archbishop Robert W. Hotes.\nAnglican Communion.\nAfter the English Reformation, the Church of England retained the existing diocesan structure which remains throughout the Anglican Communion. The one change is that the areas administered under the Archbishop of Canterbury and Archbishop of York are properly referred to as dioceses, not archdioceses: they are the metropolitan bishops of their respective provinces and bishops of their own diocese and have the position of archbishop.\nThe Anglican Church in Aotearoa, New Zealand and Polynesia in its constitution uses the specific term \"Episcopal Unit\" for both dioceses and because of its unique three-\"tikanga\" (culture) system. are the tribal-based jurisdictions of M\u0101ori (bishops) which overlap with the \"New Zealand dioceses\" (i.e. the geographical jurisdictions of the (European) bishops); these function like dioceses, but are never called so.\nPentecostalism.\nChurch of God in Christ.\nThe Church of God in Christ (COGIC) has dioceses throughout the United States. In the COGIC, most states are divided into at least three or more dioceses that are each led by a bishop (sometimes called a \"state bishop\"); some states have as many as ten dioceses. These dioceses are called \"jurisdictions\" within COGIC.\nChurch of Jesus Christ of Latter-day Saints.\nIn the Church of Jesus Christ of Latter-day Saints, the term \"bishopric\" is used to describe the bishop together with his two counselors, not the ward or congregation of which a bishop has charge.\nA diocese would be more similarly compared to a stake in the Church of Jesus Christ of Latter-day Saints, led by a stake president who, similarly to a bishopric, forms the head of a stake presidency along with two counselors that assist him.\nCatharism.\nAn organization created by the Gnostic group known as the Cathars in 1167 called the Council of Saint-F\u00e9lix organized Cathar communities into bishoprics, which each had a bishop presiding over a specific division, even though there was no central authority.\nChurches that have bishops, but not dioceses.\nIn the Free Methodist Church, Global Methodist Church, Evangelical Wesleyan Church, African Methodist Episcopal Church and United Methodist Church, a bishop is given oversight over a geographical area called an episcopal area. Each episcopal area contains one or more annual conferences, which is how the churches and clergy under the bishop's supervision are organized. Thus, the use of the term \"diocese\" referring to geography is the most equivalent in the United Methodist Church, whereas each annual conference is part of one episcopal area (though that area may contain more than one conference). \nIn the British Methodist Church and Irish Methodist Church, the closest equivalent to a diocese is the 'circuit'. Each local church belongs to a circuit, and the circuit is overseen by a superintendent minister who has pastoral charge of all the circuit churches (though in practice they delegate such charge to other presbyters who each care for a section of the circuit and chair the local church meetings as deputies of the superintendent). This echoes the practice of the early church where the bishop was supported by a bench of presbyters. Circuits are grouped together to form districts. All of these, combined with the local membership of the church, are referred to as the \"connexion\". This 18th-century term, endorsed by John Wesley, describes how people serving in different geographical centres are 'connected' to each other. Personal oversight of the Methodist Church is exercised by the president of the conference, a presbyter elected to serve for a year by the Methodist Conference; such oversight is shared with the vice-president, who is always a deacon or layperson. Each district is headed by a 'chair', a presbyter who oversees the district. Although the district is similar in size to a diocese, and chairs meet regularly with their partner bishops, the Methodist superintendent is closer to the bishop in function than is the chair. The purpose of the district is to resource the circuits; it has no function otherwise.\nChurches that have neither bishops nor dioceses.\nMany churches worldwide have neither bishops nor dioceses. Most of these churches are descended from the Protestant Reformation and more specifically the Swiss Reformation led by John Calvin; these are known as the Reformed Churches (which include the Continental Reformed, Presbyterian, and Congregationalist traditions).\nContinental Reformed churches are ruled by assemblies of \"elders\" or ordained officers. This is usually called Synodal government by the continental Reformed, but is essentially the same as presbyterian polity.\nPresbyterian churches derive their name from the presbyterian form of church government, which is governed by representative assemblies of elders. The Church of Scotland is governed solely through presbyteries, at parish and regional level, and therefore has no dioceses or bishops.\nCongregational churches practice congregationalist church governance, in which each congregation independently and autonomously runs its own affairs.\nSome Methodist denominations have a congregational polity, such as the Congregational Methodist Church, while others such as the Fellowship of Independent Methodist Churches or Association of Independent Methodists are composed of independent Methodist congregations.\nMost Baptists hold that no church or ecclesiastical organization has inherent authority over a Baptist church. Churches can properly relate to each other under this polity only through voluntary cooperation, never by any sort of coercion. Furthermore, this Baptist polity calls for freedom from governmental control. Most Baptists believe in \"Two offices of the church\"\u2014pastor-elder and deacon\u2014based on certain scriptures (; ). Exceptions to this local form of local governance include a few churches that submit to the leadership of a body of elders, as well as the Episcopal Baptists that have an episcopal system.\nChurches of Christ, being strictly non-denominational, are governed solely at the congregational level.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50550", "revid": "49089944", "url": "https://en.wikipedia.org/wiki?curid=50550", "title": "Oakland, Maryland", "text": "Town in Maryland, United States\nOakland is a town in Garrett County, Maryland, United States, and its county seat. The population was 1,851 at the 2020 census. It is near Deep Creek Lake and the Wisp Ski Resort.\nHistory.\nOakland was formally incorporated as a town in 1862.\nThe town is home to the historic Baltimore and Ohio Railroad Oakland Station, which was listed on the National Register of Historic Places in 1973 and restored in the 2000s. Today, the station is mainly used for special organizations or gatherings, although trains still run on tracks behind the station. A gift shop is located within the station. Seasonal decorations and events, such as a Christmas tree, are located at the station.\nMain Street comprises historic two- to four-story edifices with retail businesses, such as a theater, museum, bookstore, pharmacy, antique shops, clothing stores, and banks. Many of the buildings in the downtown area are Victorian architecture. Much of the central section of Oakland is part of the Oakland Historic District, listed on the National Register of Historic Places in 1984. Also listed on the National Register are the Garrett County Courthouse and Hoye Site.\nIn the late 19th century and early 20th century, a large hotel named the Oakland Hotel was located near Oakland Station. It was constructed in 1878 by the B&amp;O Railroad. The hotel was a major tourist attraction until it was torn down in the early 20th century.\nOne of the most prominent and historic churches in Oakland is St. Matthew's Episcopal Church, where U.S. Presidents Ulysses S. Grant, James Garfield, Grover Cleveland, and Benjamin Harrison have all attended services. As a result, it is now known as the \"Church of Presidents\". Another prominent and historic church is St. Peter the Apostle Church, a Catholic church located on Fourth Street. A large neoclassical courthouse prominently stands in the town center.\nGeography.\nOakland is in the south-central to western portion of Garrett County. It is set in a small valley near Deep Creek Lake. According to the United States Census Bureau, the town has a total area of , of which is land and is water.\nOakland is part of the Pittsburgh media market.\nClimate.\nOakland, owing to its high elevation and valley location, is among the coldest and snowiest locales in the state of Maryland, and has a warm-summer humid continental climate (K\u00f6ppen \"Dfb\"). The state record low of was recorded here on January 13, 1912. The monthly mean temperature ranges from in January to in July, with temperatures not reaching above freezing on an average of 34 afternoons and falling to or below on an average of 5.8 mornings. The average first and last dates for freezing temperatures are September 28 and May 15, respectively.\nThe record high is on August 7, 1918, which, together with the preceding day, are the only two instances of + readings on record in Oakland; from 1981 to 2010, only thirteen years ever reached .\nAccording to weather data tallied between July 1, 1985, and June 30, 2015, for every location in the National Oceanic and Atmospheric Administration's official climate database, Oakland is the snowiest place in the state of Maryland with an average of of snow per year. The most snow in 24 hours was on February 16, 1908, and the average first and last dates for measurable (\u2265) snowfall are November 13 and April 7.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2010 census.\nAs of the census of 2010, there were 1,925 persons, 875 households, and 470 families living in the town. The population density was . There were 1,009 housing units at an average density of . The racial makeup of the town was 98.0% White, 0.2% African American, 0.3% Native American, 0.6% Asian, 0.1% from other races, and 0.9% from two or more races. Hispanic or Latino of any race were 0.7% of the population.\nThere were 875 households, of which 23.1% had children under the age of 18 living with them, 40.1% were married couples living together, 10.5% had a female householder with no husband present, 3.1% had a male householder with no wife present, and 46.3% were non-families. 40.5% of all households were made up of individuals, and 16.6% had someone living alone who was 65 years of age or older. The average household size was 2.03, and the average family size was 2.73.\nand 24; 22.6% were from 25 to 44; 30.2% were from 45 to 64; and 22.5% were 65 years of age or older. The gender makeup of the town was 47.7% male and 52.3% female.\n2000 census.\nAs of the census of 2000, there were 1,930 persons, 787 households, and 447 families living in the town. The population density was . There were 918 housing units at an average density of . The racial makeup of the town was 98.13% White, 0.73% African American, 0.16% Native American, 0.57% Asian, 0.16% from other races, and 0.26% from two or more races. Hispanic or Latino of any race were 0.78% of the population. 33% of Oakland's residents were of German descent, 11% English, 11% Irish, 6% Italian, 2% Dutch, 2% French, 2% Polish, 2% Scottish, 2% Scotch-Irish and 2% Swedish. People of Swiss, British, Welsh and Hungarian descent each comprised 1% of the population.\nThere were 787 households, out of which 25.3% had children under the age of 18 living with them, 43.6% were married couples living together, 9.8% had a female householder with no husband present, and 43.1% were non-families. 38.8% of all households were made up of individuals, and 18.7% had someone living alone who was 65 years of age or older. The average household size was 2.09, and the average family size was 2.75.\nIn the town, the population was spread out, with 18.5% under the age of 18, 9.4% from 18 to 24, 24.0% from 25 to 44, 23.2% from 45 to 64, and 24.9% who were 65 years of age or older. The median age was 43 years. For every 100 females, there were 85.8 males. For every 100 females age 18 and over, there were 84.2 males.\nThe median income for a household in the town was $26,728, and the median income for a family was $38,750. Males had a median income of $29,625 versus $21,542 for females. The per capita income for the town was $16,872. About 13.3% of families and 19.0% of the population were below the poverty line, including 21.9% of those under age 18 and 21.0% of those age 65 or over.\nAmish community.\nThe Oakland area is home to an Amish community that consists of a church district of about 70 homes. The Amish community dates back to 1850 and became associated with the New Order Amish, with electricity permitted inside homes. The Amish community in Oakland has a small number of converts to the Amish faith, a rarity in the Amish world. There are only between 150 and 200 Amish converts in the United States out of a population of around 200,000. The Lancaster County, Pennsylvania, Amish have had only one successful convert in over 100 years.\nAttractions and events.\nThe Oakland post office is home to a Depression-era mural, \"Buckwheat Harvest\", painted by American artist Robert Franklin Gates. Gates was funded by the Treasury Section of Fine Arts to complete the mural as part of President Franklin Roosevelt's New Deal. Gates was probably inspired by Garrett County's strong tradition of growing buckwheat.\nOakland is home to the Oakland B&amp;O Museum and the Garrett County Museum of Transportation.\nTransportation.\nSeveral state-maintained highways serve Oakland. The most prominent of these is U.S. Route 219, which follows Garrett Highway, Oak Street, and Third Street through the town. To the north, US 219 connects to Maryland Route 42, Interstate 68, and U.S. Route 40, along with the towns of Accident and Grantsville, before passing into Pennsylvania. Heading south, US 219 briefly passes through Mountain Lake Park and connects with U.S. Route 50 before entering West Virginia. Two other state highways, Maryland Route 39 and Maryland Route 135 also serve Oakland. MD 39 heads northwest to West Virginia, while MD 135 heads east, connecting to Maryland Route 560, Maryland Route 38 and Maryland Route 495, as well as the towns of Mountain Lake Park and Deer Park, before entering Allegany County near the town of Luke.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50552", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=50552", "title": "James V", "text": "King of Scotland from 1513 to 1542\nJames V (10 April 1512 \u2013 14 December 1542) was King of Scotland from 9 September 1513 until his death in 1542. He was crowned on 21 September 1513 at the age of seventeen months. James was the son of King James IV and Margaret Tudor, daughter of Henry VII of England. During his childhood Scotland was governed by regents, firstly by his mother until she remarried, and then by his first cousin once removed, John Stewart, Duke of Albany. James's personal rule began in 1528 when he finally escaped the custody of his stepfather, Archibald Douglas, 6th Earl of Angus. His first action was to exile Angus and confiscate the lands of the Douglases.\nJames greatly increased his income by tightening control over royal estates and from the profits of justice, customs and feudal rights. He founded the College of Justice in 1532 and also acted to end lawlessness and rebellion in the Borders and the Hebrides. The rivalry among France, England and the Holy Roman Empire lent James unwonted diplomatic weight, and saw him secure two politically and financially advantageous French marriages, first to Madeleine of Valois and then to Mary of Guise. James also fathered at least nine illegitimate children by a series of mistresses.\nJames's reign witnessed the beginnings of Protestantism in Scotland, and his uncle Henry VIII of England's break with Rome in the 1530s placed James in a powerful bargaining position with the papacy, allowing James to exploit the situation to increase his control over ecclesiastical appointments and the financial dividends from church revenues. Pope Paul III also granted him the title of \"Defender of the Faith\" in 1537. James maintained diplomatic correspondence with various Irish nobles and chiefs throughout their resistance to Henry VIII in the 1530s, and in 1540 they offered him the kingship of Ireland. A patron of the arts, James spent lavishly on the construction of several royal residences in the High Gothic and Renaissance styles.\nJames has been described as a vindictive king, whose policies were largely motivated by the pursuit of wealth, and a paranoid fear of his nobility which led to the ruthless appropriation of their lands. He has also been characterised as the \"poor man's king\", due to his accessibility to the poor and his acting against their oppressors. James died in December 1542 following the Scottish defeat by the English at the Battle of Solway Moss. His only surviving legitimate child, Mary, succeeded him at the age of just six days old.\nEarly life.\nJames was the third son of King James IV and his wife Margaret Tudor, the eldest daughter of Henry VII of England, and was the only legitimate child of James IV to survive infancy. He was born on 10 April 1512 at Linlithgow Palace and baptised the following day, receiving the title Duke of Rothesay. James became king at just seventeen months old when his father was killed at the Battle of Flodden on 9 September 1513.\nStruggle for the regency.\nJames was crowned in the Chapel Royal at Stirling Castle on 21 September 1513. The nobility accepted Margaret Tudor as regent for her young son, in accordance with the terms of James IV's will, which also stated that Margaret was to retain this position so long as she remained a widow. The long minority of James V would last for nearly fifteen years, with Margaret's position as regent soon challenged by the French-born John, Duke of Albany, who was James V's second cousin and the nearest male heir to the throne after the king and his younger brother, Alexander, Duke of Ross, who was born in April 1514.\nIn August 1514, Margaret Tudor married Archibald Douglas, 6th Earl of Angus. This marriage was opposed by many among the nobility, who feared the advancement of the Douglases. They sought to deprive Margaret of the regency because she had remarried. The Privy Council removed Margaret from the office of regent and appointed the Duke of Albany to replace her.\nMinority rule.\nAlbany's regency.\nAlbany arrived at Dumbarton Castle with eight ships and a troop of French soldiers in May 1514. He entered Edinburgh on 26 May, and in July Parliament confirmed his restoration as Duke of Albany and his position as regent. Albany's noble supporters intended his arrival to bring stable and good government, while Francis I of France sought to use Albany to maintain support for the Auld Alliance with France. The first year of his regency was a period when a vigorous defence of his authority was essential to prevent the crumbling of Scottish government either into anarchy or into English control.\nControl of the person of the King was an essential prelude to Albany's attempt to govern, as he was aware from the beginning that his claims to act for the King and with full royal authority depended on the continued goodwill of the King himself, or rather of whoever had control of his person and could therefore claim to speak with his voice. Margaret and Angus were potentially hostile to Albany's intentions, and James V had to be removed from their influence. Albany besieged Stirling Castle and Margaret was forced to relinquish possession of the King and the Duke of Ross. James would not see his mother again for two years. Having lost the regency, her income and control of her sons, Margaret departed from the court in September 1515, fleeing from Linlithgow Palace, where she had gone for her lying in, to Tantallon Castle, where she gave birth to her daughter, Lady Margaret Douglas, in Northumberland.\nThe birth and long journey left her extremely ill and she was not told of the death of her second son Alexander in December 1515 until she had recovered her strength. The Earl of Angus made his peace with Albany later in 1516.\nA contemporary tribute was paid to the Duke of Albany's success in bringing order and good government to Scotland, by Sebastian Giustinian, the Venetian ambassador at Henry VIII's court, who wrote that Scotland, \"... was as much under Albany's control as if he were King\". In February 1517, James was brought from Stirling to the Palace of Holyroodhouse in Edinburgh, but during an outbreak of plague in the city, he was moved to the care of Antoine d'Arces at nearby rural Craigmillar Castle.\nAt Stirling, the ten-year-old James had a guard of 20 footmen dressed in his colours, red and yellow. When he went to the park below the Castle, \"by secret and in right fair and soft wedder (weather)\", six horsemen would scour the countryside two miles roundabout for intruders. Poets wrote nursery rhymes for James and advised him on royal behavior. Although his academic development was effectively cut short under Angus's captivity from 1525 onward, James V had been given a strong grounding by his tutors, including David Lyndsay and Gavin Dunbar. James was taught French and Latin, but as an adult, he spoke halting French, and his need for an interpreter to converse with an Italian bishop suggests that his spoken Latin and Italian were poor. His musical skills were good, although it was said his singing voice was harsh.\nBetween 1517 and 1520, Albany sojourned in France, and did not exercise the regency in person, but through his lieutenants including Antoine d'Arces, sieur de la Bastie. On 26 August 1517 Albany and Charles, Duke of Alen\u00e7on agreed the Treaty of Rouen, which renewed the Auld Alliance between Scotland and France and promised a French royal bride for James V. At England's request, Albany was detained in France for four years, and with him absent, Queen Margaret returned to Scotland and sought in vain to regain the regency. Young James V was kept a virtual prisoner by Albany and his lieutenants, and Margaret was allowed to see her son only once between 1516 and the end of Albany's regency in 1524. Following the signing of the Treaty of Bruges (1521) between Henry VIII of England and Holy Roman Emperor Charles V, Francis I allowed the Duke of Albany to return to Scotland to strengthen the Franco-Scottish alliance.\nThe Treaty of Rouen was ratified, and Madeleine of Valois was suggested as a suitable bride for James V. When the Duke of Albany returned in November 1521 Margaret sided with him against her husband, the Earl of Angus. Albany came to Edinburgh Castle, where James V was kept, and in a public ceremony, the keeper gave him the keys, which he passed to Margaret, who gave them back to Albany, symbolising that the government of Scotland was in his hands. Thus, Albany was able to keep an upper hand in regard to the ambitious Angus. The regent put Angus under charges of high treason in December 1521 and later sent him practically a prisoner to France. In November 1522, Albany took an army to besiege Wark Castle defended by William Lisle, but gave up after three days when the weather deteriorated.\nMargaret's coup.\nIn 1524, Albany was finally removed from power in a \"coup d'\u00e9tat\" while he was in France. Margaret, with the help of James Hamilton, 1st Earl of Arran and his followers, brought James V from Stirling to Edinburgh. In August, Parliament declared the regency at an end, and the 12-year-old King James was prematurely \"erected\" to full kingly powers. In November, Parliament formally recognised Margaret as the chief councillor to the King. Margaret's alliance with the Hamiltons inevitably alienated other noble houses. Henry VIII allowed the Earl of Angus (who Albany had banished) to return to Scotland in 1524, and he entered into an alliance with John Stewart, 3rd Earl of Lennox, an enemy of Margaret and Arran. When Angus arrived in Edinburgh with a large group of armed men, claiming his right to attend Parliament, Margaret ordered cannons to be fired on them from Edinburgh Castle. Parliament subsequently made Angus a \"Lord of the Articles\" and a member of the \"council of regency\".\nAngus captivity.\nA plan was agreed to end the feuding among these opposing groups by allowing each of them in turn to act as host to the young king. However, the plan fell apart in November 1525 when, at the end of his period of custody, Angus refused to surrender the King who, in effect, became a prisoner of the Red Douglases for the next two-and-a-half years. Angus again \"erected\" James V to full kingly powers, took him on justice ayres and kept him under close supervision. He spoiled the King with various lavish gifts in an attempt to buy his favour and make the detention more tolerable, and when James showed signs of tiring of these gifts, Angus also introduced the adolescent king to the pleasures of the flesh with a succession of prostitutes.\nAngus overreached himself, assuming the office of Lord Chancellor, and granting his followers almost every lucrative post available in the royal household. While James V clearly enjoyed some aspects of his captivity, he grew to hate his captor. Several attempts were made to free the young king\u2014one by Walter Scott of Branxholme and Buccleuch, who ambushed the King's forces on 25 July 1526 at the Battle of Melrose and was routed off the field. Another attempt later that year, on 4 September at the Battle of Linlithgow Bridge, failed again to relieve the King from the clutches of Angus. In May 1528 James finally escaped from Angus's captivity when he fled from Edinburgh to Stirling in disguise. After meeting with his mother at Stirling, James V re-entered Edinburgh in July with a large army. Summoned for treason, Angus holed himself up in Tantallon Castle until an agreement was reached whereby he was allowed to go into exile in England after surrendering his castles.\nPersonal rule.\nPierre de Ronsard saw James in 1537 when the King was twenty-four and summed up his paradoxical appearance: \"La douceur et la force illustroient son visage Si que Venus et Mars en avoient fait partage\" \u2013 His royal bearing, and vigorous pursuit of virtue, of honour, and love's war, this sweetness and strength illuminate his face, as if he were the child of Venus and Mars.\nReligion.\nThe first action James took as king was to remove Angus from the scene. The Douglas family \u2014 excluding James's half-sister Margaret, who was already safely in England, innocent of any crime against him (and thus safe from any revenge James took) \u2014 were forced into exile and James besieged their castle at Tantallon. He then subdued the Border rebels and the chiefs of the Western Isles. As well as taking advice from his nobility and using the services of the Duke of Albany in France and at Rome, James had a team of professional lawyers and diplomats, including Adam Otterburn and Thomas Erskine of Haltoun. Even his pursemaster and yeoman of the wardrobe, John Tennent of Listonschiels, was sent on an errand to England, though he got a frosty reception.\nJames increased his income by tightening control over royal estates and from the profits of justice, customs and feudal rights. He also gave his illegitimate sons lucrative benefices, diverting substantial church wealth into his coffers. James spent a large amount of his wealth on building up a collection of tapestries from those inherited from his father. James sailed to France for his first marriage and strengthened the royal fleet. In 1540, he sailed to Kirkwall in Orkney, then Lewis, in his ship the \"Salamander\", first making a will in Leith, knowing this to be \"uncertane aventuris.\" The purpose of this voyage was to show the royal presence and hold regional courts, called \"justice ayres.\"\nDomestic and international policy was affected by the Reformation, especially after Henry VIII broke from the Catholic Church. James V did not tolerate heresy and during his reign a number of outspoken Protestants were persecuted. The most famous of these was Patrick Hamilton, who was burned at the stake as a heretic at St Andrews in 1528. Later in the reign, the English ambassador Ralph Sadler tried to encourage James to close the monasteries and take their revenue so that he would not have to keep sheep like a mean subject. James replied that he had no sheep, he could depend on his god-father the king of France, and it was against reason to close the abbeys that \"stand these many years, and God's service maintained and kept in the same, and I might have anything I require of them.\" Sadler knew that James did farm sheep on his estates.\nJames recovered money from the church by getting Pope Clement VII to allow him to tax monastic incomes. He sent \u00a350 to Johann Cochlaeus, a German opponent of Martin Luther, after receiving one of his books in 1534. On 19 January 1537, Pope Paul III sent James a blessed sword and hat symbolising his prayers that James would be strengthened against heresies from across the border. These gifts were delivered by the Pope's messenger while James was at Compi\u00e8gne in France on 25 February 1537.\nAccording to 16th-century writers, his treasurer James Kirkcaldy of Grange tried to persuade James against the persecution of Protestants and to meet Henry VIII at York. James and Henry corresponded about meeting in 1536. Pope Paul III advised James against travelling to England, and sent an envoy or nuncio to Scotland to discuss the initiative. Although Henry VIII sent his tapestries to York in September 1541 ahead of a meeting, James did not come. The lack of commitment to this meeting was regarded by English observers as a sign that Scotland was firmly allied to France and Catholicism, particularly by the influence of Cardinal Beaton, Keeper of the Privy Seal, and as a cause for war.\nIn 1540, Irish nobles and chiefs offered James the kingship of Ireland, as a further challenge to Henry VIII.\nBuilding.\nJames V spent a large amount of money (at least \u00a341,000) during his adult reign on extensively remodelling all the major residences and several minor ones, including the construction of new structures, with the most significant work focused on Falkland Palace and Stirling Castle. Early in his personal rule, James began the construction of the present Late Gothic tower at the north-west corner of the Palace of Holyroodhouse, which provided new royal lodgings on the first and second floors, and a high degree of security. A new west front was also built.\nAt Linlithgow Palace, James closed off the original east entranceway and formed a new access from the south, including an inner gatehouse and an outer entrance gate decorated with the carved arms of chivalric orders, the Garter, Golden Fleece, Saint Michael, with the Thistle badge. The three-tiered octagonal fountain topped by an imperial crown was built in 1538 as the centrepiece of the courtyard.\nAt Falkland Palace, James V extended his father's buildings in French Renaissance style between 1537 and 1541 and built a real tennis court in the garden in 1541. The tennis court survives and is the oldest in the United Kingdom. James built a new entrance tower in the south range, and the inner courtyard facades of the east and south ranges built in 1537 and 1539 are the earliest examples of Renaissance architecture in the British Isles. The largest of James V's building projects was the construction of the Royal Palace at Stirling Castle, built between 1538 and 1540, with its Renaissance facades and the north, east and south quarters housing the king's and queen's apartments. Work was also carried out at Tantallon Castle, Blackness Castle and Hermitage Castle.\nMarriages.\nAs early as August 1517, a clause of the Treaty of Rouen provided that if the Auld Alliance between France and Scotland was maintained, James should have a daughter of Francis I of France as a bride. Yet by the 1520s Francis's two surviving daughters were too frail or too young. In 1528 the Holy Roman Emperor Charles V and the English diplomat Thomas Magnus both raised the possibility of a marriage between the King and his cousin, Princess Mary, while that same year, Margaret of Austria, Charles V's aunt, suggested that James should marry Charles's sister, Mary of Austria. Charles V also proposed James marry his niece, Maria of Portugal. Perhaps to remind Francis I of his obligations, in 1529 James V began negotiations for his marriage elsewhere, sending the Duke of Albany to Rome to negotiate a marriage to Catherine de' Medici, the niece of Pope Clement VII. By 1533 there was discussion of James marrying one of his second cousins, Christina or Dorothea, the daughters of Christian II of Denmark, while in 1534 Margaret of Valois-Angoul\u00eame, sister of Francis I, suggested her sister-in-law Isabella.\nIn December 1534, Francis I insisted that his eldest daughter Madeleine's health was too poor for marriage, suggesting that James V should marry Mary of Bourbon, daughter of the Duke of Vend\u00f4me, instead to fulfil the Treaty of Rouen. Again, the Duke of Albany briefly entertained the idea that James might marry Christina of Denmark, and the King halted progress on the marriage negotiations. There was also an investigation into the possibility of James marrying his former mistress, Margaret Erskine before the negotiations resumed again, and in March 1536 a final contract made for Mary of Bourbon to marry James V. She would have a dowry as if she were a French princess, and Francis I consolidated the agreement by sending James the collar of the Order of Saint Michael as a token of his affection.\nMarriage to Madeleine of Valois.\nJames decided to travel to France to meet his prospective bride in person. He sailed from Kirkcaldy on 1 September 1536, with the earls of Arran, Argyll and Rothes, Lord Fleming, David Beaton and a force of 500 men in a fleet of six ships, using the \"Mary Willoughby\" as his flagship. Before his departure, James appointed six vice-regents to govern Scotland in his absence, Gavin Dunbar, Archbishop of Glasgow (the Lord Chancellor), James Beaton, Archbishop of St Andrews, the earls of Huntly, Montrose, and Eglinton, and Lord Maxwell. In the event, James V would be away from Scotland for eight months, becoming the first Scottish king to voluntarily remain away from his realm since David II almost two hundred years earlier.\nArriving at Dieppe on 8 September, the Scots travelled to the Duke of Vend\u00f4me's court at Saint-Quentin. James V met Mary of Bourbon, according to several accounts in disguise with his servant John Tennent, but was not impressed. He then travelled south to the French court at the Ch\u00e2teau d'Amboise, where he met Madeleine, and again pressed Francis for her hand in marriage. Fearing the harsh climate of Scotland would prove fatal to his daughter's already failing health, Francis initially refused to permit the marriage, but the couple persuaded Francis to reluctantly grant permission to their marriage. The marriage contract was signed in November, with Francis I granting Madeleine a dowry of 100,000 \u00e9cu, and a further 30,000 francs a year for James.\nJames V renewed the Auld Alliance and fulfilled the terms of the Treaty of Rouen on 1 January 1537 by marrying Madeleine at Notre-Dame de Paris. James received papal approval in the form of the Blessed sword and hat, and was granted the title of \"Defender of the Faith\" by Pope Paul III on 19 January 1537, symbolising the hopes of the papacy that he would resist the path that his uncle Henry VIII had followed. After months of festivities and celebrations, and visits to Chantilly, Compi\u00e8gne and Rouen (where Madeleine fell ill), the royal couple embarked for Scotland in May 1537, arriving at Leith on 19 May. Madeleine wrote to her father from Edinburgh on 8 June 1537 saying that she was better and her symptoms had diminished. However, a month later, on 7 July 1537, Queen Madeleine died in her husband's arms at Holyrood Palace of tuberculosis. James V wrote to Francis I to inform him of what had happened, saying that if it were not for the fact that he was relying on the French king to remain his \"good father\", he would be in even greater pain. The Queen was interred in Holyrood Abbey in Edinburgh.\nMarriage to Mary of Guise.\nFollowing Madeleine's death, James V's thoughts turned to a second French bride to further the interests of the Franco-Scottish alliance. David Beaton was sent to France to persuade Francis I to agree to James marrying his only surviving daughter, Margaret. Francis offered Mary of Guise as a bride instead. The daughter of Claude, Duke of Guise, Mary had recently been widowed by the death of her husband, Louis II d'Orl\u00e9ans, Duke of Longueville. David Beaton wrote to James V from Lyon in October 1537 that Mary was \"stark (strong), well complexioned, and fit to travel\", and that her father was \"marvellous desirous of the expedition and hasty end of the matter,\" and had already consulted with his brother, Antoine, Duke of Lorraine, and Mary herself. The marriage contract was finalised in January 1538, with James V receiving a dowry of 150,000 livres. As was customary, if the King died first, Mary would retain for her lifetime her jointure houses of Falkland Palace, Stirling Castle, Dingwall Castle and Threave Castle, along with the rentals of the earldoms of Fife, Strathearn, Ross and Orkney, and the lordships of Galloway, Ardmannoch and the Isles.\nThe proxy wedding of James V and Mary of Guise was held on 9 May 1538 at the Ch\u00e2teau de Ch\u00e2teaudun. Some 2,000 Scottish lords and barons came from Scotland aboard a fleet of ships under Lord Maxwell to attend, with Lord Maxwell standing as proxy for James V. Mary departed from Le Havre on 10 June 1538, and landed in Scotland 6 days later at Crail in Fife. She was formally received by the king at St Andrews a few days later amid pageants and plays performed in her honour, and James and Mary were married in person at St Andrews Cathedral on 18 June 1538. James's mother Margaret Tudor wrote to Henry VIII in July, \"I trust she will prove a wise Princess. I have been much in her company, and she bears herself very honourably to me, with very good entertaining.\" James and Mary had two sons: James, Duke of Rothesay (born 22 May 1540 at St Andrews), and Robert (or Arthur), Duke of Albany (born and baptised on 12 April 1541); however, both died on 21 April 1541, when James was nearly one year old and Robert (or Arthur) was nine days old. Mary's mother, Antoinette de Bourbon, wrote that the couple were still young and should hope for more children. The third and last child of the union was a daughter, Mary, who was born on 8 December 1542.\nOutside interests.\nAccording to legend, James was nicknamed \"King of the Commons\" as he would sometimes travel around Scotland disguised as a common man, describing himself as the \"Gudeman of Ballengeich\". (\"Gudeman\" means \"landlord\" or \"farmer\", and \"Ballengeich\" was the nickname of a road next to Stirling Castle \u2014 meaning \"windy pass\" in Gaelic). One traditional ballad, \"The Jolly Beggar\", is considered by some to refer to his activities.\nJames was a keen lute player. In 1562, Sir Thomas Wood reported that James had \"a singular good ear and could sing that he had never seen before\" (sight-read), but his voice was \"rawky\" and \"harske.\" At court, James maintained a band of Italian musicians who adopted the name Drummond. These were joined for the winter of 1529/30 by a musician and diplomat sent by the Duke of Milan, Thomas de Averencia de Brescia, probably a lutenist. The historian Andrea Thomas makes a useful distinction between the loud music provided at ceremonies and processionals and instruments employed for more private occasions or worship, the \"music fyne\" described by Helena Mennie Shire. This quieter music included a consort of viols played by four Frenchmen led by Jacques Columbell. It seems certain that David Peebles wrote music for James V and probable that the Scottish composer Robert Carver was in royal employ, though evidence is lacking.\nAs a patron of poets and authors, James supported William Stewart and John Bellenden, the son of his nurse, who translated the Latin \"History of Scotland\" compiled in 1527 by Hector Boece into verse and prose. Sir David Lindsay of the Mount, the Lord Lyon, head of the Lyon Court and diplomat, was a prolific poet. He produced an interlude at Linlithgow Palace thought to be a version of his play \"The Thrie Estaitis\" in 1540. James also attracted the attention of international authors. The French poet Pierre de Ronsard, who had been a page of Madeleine of Valois, offered unqualified praise:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Son port estoit royal, son regard vigoureuxDe vertus, et de l'honneur, et guerre amoureuxLa douceur et la force illustroient son visageSi que Venus et Mars en avoient fait partage.His royal bearing, and vigorous pursuitof virtue, of honour, and love's war,this sweetness and strength illuminate his face,as if he were the child of Venus and Mars.\nWhen James married Mary of Guise, Giovanni Ferrerio, an Italian scholar who had been at Kinloss Abbey in Scotland, dedicated to the couple a new edition of his work \"On the True Significance of Comets against the Vanity of Astrologers.\" Like Henry VIII, James employed many foreign artisans and craftsmen in order to enhance the prestige of his renaissance court. Robert Lindsay of Pitscottie listed their professions:\nhe plenished the country with all kind of craftsmen out of other countries, as French-men, Spaniards, Dutch men, and Englishmen, which were all cunning craftsmen, every man for his own hand. Some were gunners, cunning wrights and carvers, painters, masons, smiths, harness-makers (armourers), tapesters, broudinstars (embroiderers), tailors, cunning chirugeons (surgeons), pottingaris (apothecaries), with all other kind of craftsmen to apparel his palaces.\nOne technological initiative was a special mill for polishing armour at Holyroodhouse next to his mint. The mill had a pole drive 32 feet long powered by horses. Mary of Guise's mother Antoinette of Bourbon sent him an armourer who made steel plates for his jousting saddles in October 1538, and delivered a skirt of plate armour in February 1540. In the same year, for his wife's coronation, the treasurer's accounts record that James personally devised fireworks made by his master gunners. His goldsmith John Mosman renovated the crown jewels for the occasion. When James took steps to suppress the circulation of slanderous ballads and rhymes against Henry VIII, Henry sent Fulke ap Powell, Lancaster Herald, to give thanks and to make arrangements for the present of a lion for James's menagerie of exotic pets.\nWar with England and death.\nThe death of James's mother in 1541 removed any incentive for peace with England, and war broke out. Initially, the Scots won a victory at the Battle of Haddon Rig in August 1542. The Imperial ambassador in London, Eustace Chapuys, wrote on 2 October that the Scottish ambassadors ruled out a conciliatory meeting between James and Henry VIII in England until the pregnant Mary of Guise delivered her child. Henry would not accept this condition and mobilised his army against Scotland. James was with his army at Lauder on 31 October 1542. Although he hoped to invade England, his nobles were reluctant. He returned to Edinburgh, on the way writing a letter in French to his wife from Falahill mentioning he had three days of illness. On 24 November his army suffered a serious defeat at the Battle of Solway Moss. Following a few days spent at Linlithgow Palace with Queen Mary, who was in the final stages of her pregnancy, on 6 December James travelled to Falkland Palace, where he soon took ill.\nAlthough James V's army had been beaten at Solway Moss, it was neither a personal humiliation for the King (who was not there) nor the result of noble disaffection. In fact, James had substantial support for his war policy and early in December, he had made plans to renew the conflict with England. James was on his deathbed at Falkland when news arrived from Linlithgow that the Queen had given birth to a daughter. According to John Knox, on hearing of the birth of his daughter, the King said \"It cam wi' a lass, and it will gang wi' a lass\" (meaning \"It began with a girl and it will end with a girl\"). This could refer to the Stewart dynasty's accession to the throne through Marjorie Bruce, daughter of Robert the Bruce. The prophecy could have been intended to express his belief that his new-born daughter Mary would be the last of the Stewart monarchs. In fact, the last Stewart monarch was female: Anne, Queen of Great Britain. James V died at Falkland Palace on 14 December 1542, aged thirty. The King had been ill on a number of occasions during the previous decade: in 1533 \"of a sore fois (face)\"; in 1534 of the \"pox, and fevir contenew\"; in Paris in 1536; and in 1540, when he wrote to his wife to say that he had been as ill as he had ever been in his life, but was now recovered. Evidently, his immune system had not recovered, as he had been ill again in November 1542. It is likely that James V died from cholera or dysentery, rather than shame or despair brought on by the news of Solway Moss.\nJames was succeeded by his infant daughter, Mary, Queen of Scots. On 7 January 1543, the King's body was conveyed from Falkland to the Forth ferry at Kinghorn, before being transported to Edinburgh, escorted by a funeral cortege, and accompanied by Cardinal Beaton, the Earls of Arran, Argyll, Rothes, Marischal and other nobles. James V was buried on 8 January at Holyrood Abbey, next to his first wife, Madeleine, and his two sons. A stone tomb was erected, on which Andrew Mansioun carved a lion, a crown and an eighteen-foot-long inscription in Roman letters. Alms were distributed to the poor of Edinburgh who had been present at the soul-Mass and dirge performed for the King.\nDuring the Rough Wooing, the invading English armies inflicted structural damage on Holyrood Abbey in 1544 and 1547, destroying James V's tomb. In subsequent decades, the rule of James V enjoyed a reputation for financial stability and security, cited by the Gowrie Regime in 1582, and by the advisers of James VI in 1591. This reflects an expansion of the legal system which allowed an increase in crown revenue.\nJames was the last monarch to die in Scotland until 8 September 2022 when Queen Elizabeth II died at Balmoral Castle in Aberdeenshire, 480 years later. Days later her body was carried through the streets of Edinburgh, the first time that a royal cortege had passed through the city since James V's burial.\nFictional portrayals.\nJames V has been depicted in historical novels, poems, short stories and one notable opera. They include the following:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n\u00a0 incorporates text from a publication now in the public domain:\u00a0"}
{"id": "50553", "revid": "90173", "url": "https://en.wikipedia.org/wiki?curid=50553", "title": "Pseudotsuga", "text": "Genus of conifers in the family Pinaceae\nPseudotsuga () is a genus of evergreen coniferous trees in the family Pinaceae (subfamily Laricoideae). Common names for species in the genus include Douglas fir, Douglas-fir, Douglas tree, Oregon pine and Bigcone spruce. \"Pseudotsuga menziesii\" (Douglas fir proper) is widespread in western North America and is an important source of timber. The number of species has long been debated, but two in western North America and two to four in eastern Asia are commonly acknowledged.\nNineteenth-century botanists had problems in classifying Douglas firs, due to the species' similarity to various other conifers better known at the time; they have at times been classified in \"Pinus\", \"Picea\", \"Abies\", \"Tsuga\", and even \"Sequoia\". Because of their distinctive cones, Douglas firs were finally placed in the new genus \"Pseudotsuga\" (meaning \"false hemlock\") by the French botanist Carri\u00e8re in 1867. The genus name has also been hyphenated as \"Pseudo-tsuga\".\nName.\nThe tree takes its English name from David Douglas, the Scottish botanist who first introduced \"Pseudotsuga menziesii\" into cultivation at Scone Palace in 1827. Douglas is known for introducing many native American tree species to Europe. The hyphenated form \"Douglas-fir\" is used by some to indicate that \"Pseudotsuga\" species are not true firs, which belong to the genus \"Abies\".\nDescription.\nDouglas-firs are medium-size to extremely large evergreen trees, tall (although only coast Douglas-firs reach such great height). The leaves are flat, soft, linear, long, generally resembling those of the firs, occurring singly rather than in fascicles; they completely encircle the branches, which can be useful in recognizing the species. The female cones are pendulous, with persistent scales (unlike true firs), and are distinctive in having a long tridentine (three-pointed) bract that protrudes prominently above each scale (it resembles the back half of a mouse, with two feet and a tail).\n\"Pseudotsuga menziesii\" var. \"menziesii\" has attained heights of 393 feet (120* m). That was the estimated height of the tallest conifer ever well-documented, the Mineral Tree (Mineral, Washington), measured in 1924 by Dr. Richard E. McArdle, former chief of the U.S. Forest Service. The volume of that tree was . The tallest living individual is the Brummitt (Doerner) Fir in Coos County, Oregon, tall. Only coast redwood and \"Eucalyptus regnans\" reach greater heights based on current knowledge of living trees: 379 and 331 feet (116 and 101* m), respectively.\nAt Quinault, Washington, is found a collection of the largest Douglas-firs in one area. Quinault Rain Forest hosts most of the top ten known largest Douglas-firs.\nAs of 2009[ [update]], the largest known Douglas-firs in the world are, by volume:\nTaxonomy.\nPhylogeny of \"Pseudotsuga\" according to Stull 2021:\nBy far the best-known is the widespread and abundant North American species \"Pseudotsuga menziesii\", a taxonomically complex species divided into two major varieties (treated as distinct species or subspecies by some botanists): coast Douglas-fir or \"green Douglas-fir\", on the Pacific coast; and Rocky Mountain Douglas-fir or \"interior Douglas-fir\", in the interior west of the continent. According to some botanists, Rocky Mountain Douglas-fir extends south into Mexico to include all Mexican Douglas-fir populations, whereas others have proposed multiple separate species in Mexico and multiple varieties in the United States. Morphological and genetic evidence suggest that Mexican Douglas-fir should probably be considered a distinct variety within \"P. menziesii\".\nAll of the other species are of restricted range and little-known outside of their respective native environments, where they are often rare and of scattered occurrence in mixed forests; all those have unfavorable conservation status. The taxonomy of the Asian Douglas-firs continues to be disputed, but the most recent taxonomic treatment accepts four species: three Chinese and one Japanese. The three Chinese species have been variously considered varieties of \"P. sinensis\" or broken down into additional species and varieties. In the current treatment, the Chinese species \"P. sinensis\" is further subdivided into two varieties: var. \"sinensis\" and var. \"wilsoniana\".\nUses.\nDouglas-fir wood is used for structural applications that are required to withstand high loads. It is used extensively in the construction industry. Other examples include its use for homebuilt aircraft such as the RJ.03 IBIS canard. Very often, these aircraft were designed to utilize Sitka spruce, which is becoming increasingly difficult to source in aviation quality grades. Oregon pine is also used in boat building when it is available in long, fairly knot-free lengths. Most timber now comes from plantation forests in North America which are managed to produce faster growing timber with fewer knots. This timber is generally lighter but weaker. Traditionally, Oregon pine was used in mast building due to its ability to resist bending loads without fracturing. This was based on using older native forest wood with a high number of growth rings per inch. This sort of wood is seldom available new but can be sourced from merchants dealing in recycled timber. Native Oregon pine is considerably heavier than Sitka spruce, which is about the same weight as western red cedar, but with far better bending characteristics than cedar. Large-sized Oregon pine, as used in beams, is inclined to split as it dries, like oak, but this does not reduce its strength.\nDouglas-fir is one of the most commonly marketed Christmas tree species in the United States, where they are sold alongside firs like noble fir and grand fir. Douglas-fir Christmas trees are usually trimmed to a near perfect cone instead of left to grow naturally like noble and grand firs.\nPests and diseases.\nDouglas-firs are used as food plants by the larvae of some Lepidoptera species, including autumnal moth, bordered white, engrailed moth, pine beauty and turnip moth. The gelechiids \"Chionodes abella\" and \"Chionodes periculella\" and the tortrix moth \"Cydia illutana\" have been specifically recorded on \"P. menziesii\".\nCulture.\nA California Native American myth explains that each three-ended bract is the tail and two tiny legs of a mouse that hid inside the scales of the tree's cones during forest fires, and the tree was kind enough to be its enduring sanctuary.\nA Douglas-fir species, \"Pseudotsuga menziesii\", is the state tree of Oregon.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50555", "revid": "39191556", "url": "https://en.wikipedia.org/wiki?curid=50555", "title": "Domoic acid", "text": "&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nDomoic acid (DA) is a kainic acid\u2013type neurotoxin that causes amnesic shellfish poisoning (ASP). It is produced by algae and accumulates in shellfish, sardines, and anchovies. When sea lions, otters, cetaceans, humans, and other predators eat contaminated animals, poisoning may result. Exposure to this compound affects the brain, causing seizures, delirium and possibly death.\nHistory.\nThere has been little use of domoic acid throughout history except for in Japan, where it has been used as an anthelmintic for centuries.\nDomoic acid was first isolated in 1959 from a species of red algae, \"Chondria armata\", in Japan, which is commonly referred to as in the Tokunoshima dialect, or . Poisonings in history have been rare, or undocumented; however, it is thought that the increase in human activities is resulting in an increasing frequency of harmful algal blooms along coastlines in recent years. In 2015, the North American Pacific coast was heavily impacted by an algal bloom, consisting predominantly of the domoic acid-producing pennate diatom, \"Pseudo-nitzschia.\" Consequently, elevated levels of domoic acid were measured in stranded marine mammals, prompting the closure of beaches and damaging razor clam, rock crab and Dungeness crab fisheries.\nIn 1961, seabirds attacked the Capitola area in California, and though it was never confirmed, it was later hypothesized that they were under the influence of domoic acid.\nIn 1987, in Prince Edward Island, Canada, there was a shellfish poisoning resulting in 3 deaths. Blue mussels (\"Mytilus edulis\") contaminated with domoic acid were blamed.\nDomoic acid has been suggested to have been involved in an incident which took place on June 22, 2006, when a California brown pelican flew through the windshield of a car on the Pacific Coast Highway.\nOn Friday, June 14, 2019, a teenager was attacked and injured by a sea lion that was alleged to be under the influence of domoic acid in Pismo Beach on the Central California coast.\nChemistry.\nGeneral.\nDomoic acid is a structural analog of kainic acid, proline, and endogenous excitatory neurotransmitter glutamate. Ohfune and Tomita, who wanted to investigate its absolute stereochemistry, were the first and only to synthesize domoic acid in 1982.\nBiosynthesis.\nIn 1999, using 13C- and 14C-labelled precursors, the biosynthesis of domoic acid in the diatom genus \"Pseudo-nitzschia\" was examined. After addition of [1,2-13C2]-acetate, NMR spectroscopy showed enrichment of every carbon in domoic acid, indicating incorporation of the carbon isotopes. This enrichment was consistent with two biosynthetic pathways. The labeling pattern determined that domoic acid can be biosynthesized by an isoprenoid intermediate in combination with a tricarboxylic acid (TCA) cycle intermediate.\nIn 2018, using growth conditions known to induce domoic acid production in \"Pseudo-nitzschia multiseries\", transcriptome sequencing successfully identified candidate domoic acid biosynthesis genes responsible for the pyrrolidine core. These domoic acid biosynthesis genes, or 'Dab' enzymes were heterologously expressed, characterized, and annotated as \"dabA\" (terpene cyclase), \"dabB\" (hypothetical protein), \"dabC\" (\u03b1-ketoglutarate\u2013dependent dioxygenase), and \"dabD\" (CYP450).Domoic acid biosynthesis begins with the DabA-catalyzed geranylation of L-glutamic acid (L-Glu) with geranyl pyrophosphate (GPP) to form \"N-geranyl\"-L-glutamic acid (L-NGG). DabD then performs three successive oxidation reactions at the 7\u2032-methyl of L-NGG to produce 7\u2032-carboxy-L-NGG, which is then cyclized by DabC to generate the naturally occurring isodomoic acid A. Finally, an uncharacterized isomerase could convert isodomoic acid A to domoic acid. Further investigation is needed to resolve the final isomerization reaction to complete the pathway to Domoic acid.\nSynthesis.\nUsing intermediates 5 and 6, a Diels-Alder reaction produced a bicyclic compound (7). 7 then underwent ozonolysis to open the six-membered ring leading to selenide (8). 8 was then deselenated to form 9 (E-9 and Z-9), lastly leading to the formation of (-) domoic acid.\nMechanism of action.\nThe effects of domoic acid have been attributed to several mechanisms, but the one of concern is through glutamate receptors. Domoic acid is an excitatory amino acid analogue of glutamate; a neurotransmitter in the brain that activates glutamate receptors. Domoic acid has a very strong affinity for these receptors, which results in excitotoxicity initiated by an integrative action on ionotropic glutamate receptors at both sides of the synapse, coupled with the effect of blocking the channel from rapid desensitization. In addition there is a synergistic effect with endogenous glutamate and N-Methyl-D-aspartate receptor agonists that contribute to the excitotoxicity.\nIn the brain, domoic acid especially damages the hippocampus and amygdaloid nucleus. It damages the neurons by activating AMPA and kainate receptors, causing an influx of calcium. Although calcium flowing into cells is normal, the uncontrolled increase of calcium causes the cells to degenerate. Because the hippocampus may be severely damaged, short-term memory loss occurs. It may also cause kidney damage \u2013 even at levels considered safe for human consumption, a new study in mice has revealed. The kidney is affected at a hundred times lower than the concentration allowed under FDA regulations.\nToxicology.\nDomoic acid producing algal blooms are associated with the phenomenon of amnesic shellfish poisoning (ASP). Domoic acid can bioaccumulate in marine organisms such as shellfish, anchovies, and sardines that feed on the phytoplankton known to produce this toxin. It can accumulate in high concentrations in the tissues of these plankton feeders when the toxic phytoplankton are high in concentration in the surrounding waters.\nDomoic acid is a neurotoxin that inhibits neurochemical processes, causing short-term memory loss, brain damage, and, in severe cases, death in humans. In marine mammals, domoic acid typically causes seizures and tremors.\nStudies have shown that there are no symptomatic effects in humans at levels of 0.5\u00a0mg/kg of body weight. In the 1987 domoic acid poisoning on Prince Edward Island concentrations ranging from 0.31 to 1.28\u00a0mg/kg of muscle tissue were noted in people that became ill (three of whom died). Dangerous levels of domoic acid have been calculated based on cases such as the one on Prince Edward island. The exact LD50 for humans is unknown; for mice the LD50 is 3.6\u00a0mg/kg.\nNew research has found that domoic acid is a heat-resistant and very stable toxin, which can damage kidneys at concentrations that are 100 times lower than what causes neurological effects.\nDiagnosis and prevention.\nIn order to be diagnosed and treated if poisoned, domoic acid must first be detected. Methods such as ELISA or probe development with polymerase chain reaction (PCR) may be used to detect the toxin or the organism producing this toxin.\nThere is no known antidote available for domoic acid. Therefore, if poisoning occurs, it is advised to go quickly to a hospital. Cooking or freezing affected fish or shellfish tissue that are contaminated with domoic acid does not lessen the toxicity.\nAs a public health concern, the concentration of domoic acid in shellfish and shellfish parts at point of sale should not exceed the current permissible limit of 20\u00a0mg/kg tissue. In addition, during processing shellfish, it is important to pay attention to environmental condition factors.\nIn popular culture.\nOn August 18, 1961, in Capitola and Santa Cruz, California, there was an invasion of what people described as chaotic seabirds. These birds were believed to be under the influence of domoic acid, and it inspired a scene in Alfred Hitchcock's feature film \"The Birds\".\nIn the \"Elementary\" Season 1 Episode 13 \"The Red Team\", domoic acid was used as a poison to mimic Alzheimer's.\nIn the TV show \"Bunk'd\", domoic acid somehow combines with fog to create a chemical that causes people to lose memory or gain alter-egos when inhaled.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50556", "revid": "164032", "url": "https://en.wikipedia.org/wiki?curid=50556", "title": "James IV of Scotland", "text": "King of Scotland from 1488 to 1513\nJames IV (17 March 1473 \u2013 9 September 1513) was King of Scotland from 11 June 1488 until his death at the Battle of Flodden in 1513. He inherited the throne at the age of fifteen on the death of his father, James III, at the Battle of Sauchieburn, following a rebellion in which the younger James was the figurehead of the rebels. James IV is generally regarded as the most successful of the Stewart monarchs of Scotland. He was responsible for a major expansion of the Scottish royal navy, which included the founding of two royal dockyards and the acquisition or construction of 38 ships, including the \"Great Michael\", the largest warship of its time.\nJames was a patron of the arts and took an active interest in the law, literature and science. With his patronage the printing press came to Scotland, the University of Aberdeen and the Royal College of Surgeons of Edinburgh were founded, and he commissioned the building of the Palace of Holyroodhouse and Falkland Palace. The Education Act 1496 passed by the Parliament of Scotland introduced compulsory schooling. During James's twenty-five-year reign, royal income doubled, the Crown exercised firm control over the Scottish church, and by 1493 had overcome the last independent Lord of the Isles. Relations with England improved with the Treaty of Perpetual Peace in 1502 and James's marriage to Margaret Tudor in 1503, which led to the Union of the Crowns in 1603.\nThe long period of domestic peace after 1497 allowed James to focus more on foreign policy, which included the sending of several of his warships to aid his uncle, John of Denmark, in his conflict with Sweden; amicable relations with the Pope, Holy Roman Emperor Maximilian I and Louis XII of France; and James's aspiration to lead a European naval crusade against the Ottoman Empire. James was granted the title of \"Protector and Defender of the Christian Faith\" in 1507 by Pope Julius II.\nWhen Henry VIII of England invaded France in 1513 as part of the Holy League, James chose the Auld Alliance with the French over the \"Perpetual Peace\" with the English, and led a large army across the border into England. James and many of his nobles were killed at the Battle of Flodden on 9 September 1513, fighting against the English forces of Catherine of Aragon, Henry VIII's wife and regent. James was the last monarch in Great Britain to be killed in battle and was succeeded by his son James V.\nEarly life.\nBorn on 17 March 1473 at Stirling Castle, James was the eldest son of King James III and Margaret of Denmark. As heir apparent to the Scottish crown, he became Duke of Rothesay at birth. James probably spent most of his infancy and youth at Stirling Castle in the care of his mother, along with his two younger brothers, James and John. In 1478, Queen Margaret was officially entrusted with the custody and education of the Duke of Rothesay. Not much is known about James's early life, but it is known that he received a good education from Archibald Whitelaw, the humanist scholar and secretary of state, and the theologian John Ireland, under the direction of his mother. In addition to Scots, James became fluent in Latin and Spanish, also learned French, German, Flemish and Italian, and was the last Scottish monarch known to have spoken Gaelic. The surviving exchequer records show that Prince James was taken from Stirling to visit Edinburgh in the summers of 1474 and 1479, and that his nurse in the 1470s was Agnes Turing, the wife of an Edinburgh burgess.\nIn October 1474, James III agreed a peace treaty with Edward IV of England, the foundation of which was to be a marriage between Prince James and Edward's daughter, Cecily of York, when they both reached marriageable age. The treaty marked the beginning of James III's pursuit of friendship with England, a policy which was unpopular in Scotland. This policy would see further prospective English brides proposed for his son: Anne de la Pole (niece of Richard III of England) in 1484 and an unspecified daughter of Edward IV in 1487. James III was an unpopular king: he faced two major rebellions during his reign, and alienated members of his close family, especially his younger brother, Alexander, Duke of Albany. James III's unpopular pro-English policy rebounded badly upon him when the peace with England broke down in 1480. This led to the invasion of Scotland and capture of Berwick in 1482 by Richard, Duke of Gloucester, in the company of the Duke of Albany. When James III attempted to lead his army against the invasion, his army rebelled against him and he was briefly imprisoned by his own councillors. During James III's imprisonment, Albany visited Queen Margaret and Rothesay at Stirling Castle to discuss the crisis with them.\nFor the nine-year-old heir to the throne, the crisis of 1482 had shattered the calm of his youthful existence at Stirling. Following the death of Margaret of Denmark in July 1486, Rothesay may have viewed the king's deliberate promotion of his second son \u2014 the 1486 and 1487 proposals to marry him to one of the younger daughters of Edward IV of England, and the conferring on him of the dukedom of Ross in January 1488 \u2014 with apprehension. There is no explanation of why James III seemed to be favouring his second son over his heir, although it has been suggested that James III's suspicion and distrust of his heir arose from Rothesay's meeting with the Duke of Albany during the 1482 crisis.\nOn 2 February 1488, Rothesay departed from Stirling Castle, without the king's knowledge. This defection saw the start of another major rebellion against James III, led by the earls of Angus and Argyll, and the Home and Hepburn families. Pitscottie claimed that the prince defected as he had heard that his father was approaching Stirling with a large army to imprison him. The prince became the figurehead of the rebels, who claimed that they had removed him from Stirling to protect him from his vindictive father, who had surrounded himself with wicked Anglophile counsellors. Like Rothesay, many of the rebels also feared for their safety if James III continued to rule. Matters came to a head on 11 June 1488, when the royal and rebel armies fought outside Stirling at the Battle of Sauchieburn. The royal army was defeated and James III was killed during the battle, though several later sources claimed that Rothesay had forbidden any man to harm his father. James IV bore intense guilt for the indirect role which he had played in the death of his father. He decided to do penance for his sin, constantly wearing an iron belt around his waist, next to the skin, to which he added weight every year throughout his life.\nEarly reign.\nThe victorious rebels moved swiftly to consolidate their power, and on 12 June, only a day after Sauchieburn, the new king issued his first charter. Edinburgh and Stirling castles were secured, as were the late king's money and jewels, and the rebel leaders were rewarded with offices of state and posts in the royal household. James IV's coronation took place on 24 June 1488 at Scone Abbey. The Archbishop of St Andrews, William Scheves, a favourite of James III, did not officiate during the coronation ceremony, with the new king being instead crowned by Robert Blackadder, Bishop of Glasgow. A few days later, James IV attended the burial of his father at Cambuskenneth Abbey, a scene later portrayed in James IV's book of hours. The new king also hosted his maternal great-uncle, Gerhard VI, Count of Oldenburg, who arrived at Leith with a Danish fleet in August, and remained in Scotland until the following year.\nJames IV quickly proved to be a wise and effective ruler, and entrusted the running of his government to Patrick Hepburn, 1st Earl of Bothwell, Archibald Douglas, 5th Earl of Angus, and William Elphinstone, Bishop of Aberdeen. He defeated a major rebellion led by the Master of Huntly, the Earl of Lennox and Lord Lyle in 1489, laying siege to Crookston, Duchal and Dumbarton castles, and defeating a rebel army at Gartloaning in Stirlingshire. James also took a direct interest in the administration of justice, brought the feud between the Murrays and the Drummonds in Strathearn to an end, and went out on justice ayres across the kingdom throughout his reign. A tax of \u00a35,000 was granted by the Parliament of Scotland to fund an embassy to France and Spain to search for a foreign bride for the king. Pope Innocent VIII conferred the Golden Rose on James in 1491, and the alliance with France was renewed in 1492. Treaties were also made with Denmark and Spain, and truces were negotiated with Henry VII of England in 1493 and 1494. In 1494 James received the Sceptre of Scotland as a papal gift from Pope Alexander VI. James IV met with Hugh Roe O'Donnell, King of Tyrconnell in June 1495 in Glasgow. O'Donnell was the most powerful northern Irish magnate and a committed enemy of Henry VII's government in Ireland, and the Scottish and Irish kings made a defensive alliance. They also discussed Perkin Warbeck, the pretender to the English throne, who O'Donnell had been a supporter of for years.\nJames IV received Warbeck in Scotland in November 1495. The attraction of Warbeck to James lay in the recognition of Warbeck's claim to the English throne by Maximilian, King of the Romans, Ferdinand II and Isabella I of Spain (the Catholic monarchs), Philip, Duke of Burgundy, and Margaret of York. Embracing Warbeck's cause would give James IV international leverage to seek European alliances, and threatening Henry VII with Warbeck would surely produce a much more attractive offer of alliance from the English king. As Ferdinand and Isabella were negotiating an alliance with Henry VII, James knew that Spain would help him in his struggles with England in order to prevent the situation escalating into war with France. Spanish ambassadors arrived in Edinburgh, and later Pedro de Ayala was established as a resident ambassador during the crisis.\nIn September 1496, James IV invaded England alongside Warbeck, destroying Tillmouth, Duddo, Branxton and Howtel towers, and Twizell Castle and Heaton Castle. However, the army quickly retreated when resources were expended, and hoped-for support for Perkin Warbeck in Northumberland failed to materialise. The Scottish army left on 25 September 1496 when an English army commanded by Lord Neville approached from Newcastle. When news of this invasion reached Ludovico Sforza, Duke of Milan, on 21 October 1496, he wrote to his ambassador in Spain, to request the Spanish monarchs make peace between England and Scotland. The peace mission was entrusted to the Spanish ambassador in Scotland, Pedro de Ayala. Later, wishing to be rid of Warbeck, James IV provided a ship called the \"Cuckoo\" and a hired crew under a Breton captain, Guy Foulcart. Horses were hired for 30 of Perkin's companions to ride to the ship at Ayr on 5 July 1497, where Perkin sailed to Ireland. In August 1497, James invaded England once more and laid siege to Norham Castle with a huge artillery train, including Mons Meg, a huge medieval bombard or cannon.\nPeace efforts with England.\nJames IV's use of war as a forceful extension of his diplomacy with England, and Henry VII's realisation of how vulnerable the Anglo-Scottish border was, saw Henry treat for peace with James. The Treaty of Ayton was signed on 30 September 1497, agreeing to a seven-year truce between Scotland and England. Shipping and trade were to be conducted according to the 1464 Treaty of York, and Border wardens on either side were given new powers to execute cross-border murderers after 20 days detention and punish thieves caught red-handed, and neither king should harbour the other's rebels. The Spanish monarchs Ferdinand and Isabella were appointed to arbitrate future disputes and unresolved issues such as redress for damages caused by the recent invasions. The possibility was also raised of strengthening the peace between both kingdoms with the marriage of James IV to Henry VII's eldest daughter, Margaret.\nFollowing several years in which the Treaty of Ayton held, Scottish and English commissioners met at Richmond Palace on 24 January 1502. They agreed the marriage between James IV and Margaret, with a dowry of \u00a335,000 Scots, and a peace treaty between the two kingdoms. Under the terms of the Treaty of Perpetual Peace, there was to be \"good, real and sincere, true, sound, and firm peace, friendship, league and confederation, to last all time coming\" between England and Scotland, neither king or their successors were to make war against the other, and if either king broke the treaty, the Pope would excommunicate him. In a ceremony at the altar of Glasgow Cathedral on 10 December 1502, James confirmed the Treaty of Perpetual Peace with Henry VII, the first peace treaty between Scotland and England since 1328. The marriage was completed by proxy on 25 January 1503 at Richmond Palace in the presence of the king and queen of England, the Earl of Bothwell standing as proxy for the Scottish king. Margaret left Richmond for Scotland on 27 June and, after crossing the border at Berwick upon Tweed on 1 August 1503, was received at Lamberton by the Archbishop of Glasgow and the Bishop of Moray. On 8 August 1503, the marriage of the 30-year-old Scottish king and his 13-year-old English bride was celebrated in person in Holyrood Abbey. The rites were performed by Robert Blackadder, Archbishop of Glasgow and Thomas Savage, Archbishop of York. Their wedding was commemorated by the gift of the Hours of James IV of Scotland, and was portrayed as the marriage of The Thrissil and the Rois (the thistle and rose \u2014 the flowers of Scotland and England, respectively) by the poet William Dunbar, who was then resident at James's court.\nMargaret did not bear her first child until 1507 when she was seventeen. James IV's marriage to Margaret meant that only the future Henry VIII stood between the Scottish king and the English succession, as Henry's lack of an heir made it possible that either James or one of his successors might succeed if the Tudors failed to produce heirs. Margaret's first pregnancy resulted in the birth of James, Duke of Rothesay at the Palace of Holyroodhouse in February 1507. However, this heir to the throne died a year later in February 1508. At this point Margaret was already pregnant with a second child, a daughter whose name is unknown, and who was born and died in July 1508. In October 1509, a second son was born and named Arthur, a name recalling Margaret's late brother, Arthur, Prince of Wales, and reminding the still heirless Henry VIII that, if he were unable to produce a legitimate son to succeed him, it might be a son of Margaret Tudor who would succeed.\nGovernment.\nPolicy in the Highlands and Isles.\nFrom the perspective of the new administration in the early 1490s, the Western Highlands and the Hebrides were regarded as a problem area and a threat to the rest of the kingdom. By that period the Lordship of the Isles was fracturing as rivalries in Clan Donald disrupted the authority of John of Islay, Lord of the Isles. John was a weak leader whose authority had been damaged in 1476 when he had forfeited the earldom of Ross and his lands in Knapdale and Kintyre to James III due to the treasonous Treaty of Westminster he had agreed with Edward IV of England. After this, Ross-shire was continually invaded by the MacDonald islanders. In 1491, Alexander MacDonald of Lochalsh, heir to the lordship of the Isles, attempted to recover the earldom of Ross by raiding Ross-shire in alliance with Clan Cameron and Clan Chattan. They marched to Inverness, where they stormed Inverness Castle, and clashed with Clan Mackenzie before being routed. In consequence of this insurrection, at a meeting of parliament in Edinburgh in May 1493, the title and possessions of John MacDonald, Lord of the Isles were declared to be forfeited to the Crown. In August 1493, King James made his first expedition to the western Highlands. Accompanied by Chancellor Angus, Bishop Elhinstone, the Earl of Bothwell, Lord Home, and Secretary of State Archibald Whitelaw, James IV sailed to Dunstaffnage Castle, where the local chiefs, including John MacLean of Lochbuie and John MacIain of Ardnamurchan, made their submissions of loyalty to him. John of Islay surrendered and was brought back to the royal court and given an annual pension of \u00a3133 6s 8d.\nThe following year, Sir John MacDonald of Dunnyveg rebelled, and in July the king sailed with an army from Dumbarton to Tarbert Castle, before sailing south to Dunaverty Castle in Kintyre. The royal forces repaired both castles and soon afterwards Sir John was summoned for treason committed in Kintyre. Sir John ignored the summons and continued to reside at Islay, but was later captured by John MacIain of Ardnamurchan and brought to Edinburgh to be hanged for treason. In 1495 King James sailed on his third and final expedition to the Isles to find and reward supporters of the Crown within the forfeited lordship, sailing to Mingary Castle, where Lachlan Maclean of Duart, Alan Cameron, and MacNeil of Barra came in to Mingary to submit and offer their allegiance to the king in person, who confirmed them in their lands and offices.\nIn October 1496, the Privy Council ordered that the clan chiefs in the region would be held responsible by the king for crimes of the islanders. This act for the governance of the region was unworkable, and after the Act of Revocation of 1498 undermined the chiefs' titles to their lands, resistance to Edinburgh rule was strengthened. James waited at Kilkerran Castle at Campbeltown Loch to regrant the chiefs' charters in the summer of 1498. Few of the chiefs turned up. At first, Archibald Campbell, 2nd Earl of Argyll, was set to fill the power vacuum and enforce royal authority, but he met with limited success in a struggle with his brother-in-law, Torquil MacLeod of Lewis.\nAfter this defiance, Alexander Gordon, 3rd Earl of Huntly, was granted Torquil's lands. He raised an army in Lochaber and also cleared the tenants of that area, replacing them with his supporters. After the parliament of 1504, a royal fleet sailed north from Ayr to attack the Castle of Cairn-na-Burgh, west of Mull, where it is thought that Maclean of Duart had Domhnall Dubh in his keeping. As progress at the siege was slow, James sent Hans the royal gunner in Robert Barton's ship and then the Earl of Arran with provisions and more artillery. Cairn-na-Burgh was captured by June 1504 but Domhnall Dubh remained at liberty. In September 1507, Torquil MacLeod was besieged at Stornoway Castle on Lewis. Domhnall Dubh was captured and imprisoned for 37 years until he was released in 1543 and died in 1545 in Ireland; Torquil MacLeod died in exile in 1511. The Earl of Huntly was richly rewarded for his troubles, a price that James was prepared to pay.\nParliament.\nJames IV's reign saw a decline in the holding of parliaments, which was a departure from the practice of previous reigns. While ten meetings of the three estates were held between 1488 and 1496, there were only three during the remaining seventeen years of the reign, with no parliaments held in the eight years between 1496 and 1504. There was also a substantial reduction in the numbers of those attending parliaments as the reign progressed. This development matched that of the English and European monarchies in the playing down of the role of their representative assemblies, and placing more reliance on conciliar government: Edward IV of England only held six parliaments during his twenty-three-year reign, and Henry VII held seven in his twenty-four years on the throne. In France, the Estates General were not summoned again for seventy-six years after 1484.\nWith the ending of the conflicts with England in 1497, the Crown no longer needed Parliament to grant extraordinary revenue in the form of taxation, with Parliament no longer being summoned with the same regularity as a result. In the decade before 1496, successive parliaments had presided over, or sanctioned, regicide or rebellion, and failed foreign embassies to find the king a bride. With this experience of parliaments, perhaps James IV considered the frequent calling of parliaments inimical to good royal government.\nThe absence of parliaments between 1496 and 1504 may also have been due to James's discovery of other methods of raising revenue, and his reluctance to summon meetings of the three estates due to their propensity for dissent. The last three parliaments of James IV's reign in 1504, 1506 and 1509 were all called to address the administration of justice and the forfeiture of rebels following further risings in the western Highlands. James IV managed to govern effectively without regular parliaments from 1496 onwards due to his use of general councils (a sister institution to Parliament) in 1497, 1498, 1502, 1511 and 1512, and the use of greatly enlarged sessions of the Privy Council in 1508, 1511 and 1513.\nFinances.\nFrom the beginning of his reign, one of James's objectives was to increase the relatively limited Crown income by extracting larger returns from all available sources of revenue. The king had to fund all government expenses out of his own income, which came from the revenue from Crown lands, and from burgh customs, mails, tolls and duties. The annual revenues of the Crown from these sources remained constant throughout James's reign (around \u00a35\u20136,000 Scots). However, the king only received a small amount of the income from burgh revenues, as the majority of that income was alienated to provide annuities to reward numerous nobles and Crown servants.\nTaxation imposed by Parliament offered the king greater opportunities to raise income. Between 1488 and 1497, Parliament voted taxation almost annually to support diplomacy and war, including embassies to the continent, the king's naval expeditions to the western Highlands, and the 1496\u201397 conflicts with England. However, James soon learned that using taxation extensively as a means of generating revenue was likely to provoke resistance without bringing in the sums required. Following the failure to raise the huge sum of \u00a312,000 Scots from the three estates (clergy, nobility and burghs) in 1502\u20131504 to fund the sending of a naval expedition and a small army to Denmark, no further taxation was imposed until 1512, and even then the tax which brought in almost \u00a37,000 was only imposed on the clergy.\nJames's annual income increased remarkably between 1497 and 1513, due to several sources of revenue. In 1497 he received a substantial windfall from the death of Archbishop William Scheves of St Andrews. James appointed his younger brother, the Duke of Ross, to fill the vacant see of St Andrews, bringing the highest office of the Scottish church within the royal family, with the appointment generating an annual income of around \u00a32,500 for the Crown from the revenues of the archbishopric. Although Bishop Elphinstone protested against this scandalous appointment, it was a shrewd move by the king as it removed any potential dynastic threat which his legitimate younger brother might pose in the future. James also appointed Ross as abbot of Holyrood (1498), Dunfermline (1500) and Arbroath (1503). These offices, in combination with his appointment to the chancellorship in 1501, gave the Duke of Ross the highest status after the king. Following the death of the Duke of Ross in 1504, James IV appointed his eleven-year-old illegitimate son, Alexander, as archbishop, thereby ensuring that the Crown would continue to receive the revenues of St Andrews.\nIn 1498, James IV reached the age of twenty-five and was entitled to make a formal act of revocation of all grants made by him during his minority. Although James could \u2014 in theory \u2014 cancel all grants of lands and offices which had been made since his accession, the purpose of the revocation was only to assert royal authority by re-granting lands and offices surrendered to the Crown, and raise thousands of pounds in revenue, as their holders paid compensation to the Treasurer to receive confirmation of their holdings. The payment of Margaret Tudor's dowry between 1503 and 1505 also brought in a relatively meagre \u00a310,000 sterling. By the end of the reign the Treasurer's annual receipts had increased \u2014 due to feudal payments made to the Crown by the holders of land, and judicial fines for criminal offences \u2014 from around \u00a34,500 in 1496\u20131497 to a huge \u00a328,000 by 1512. When these receipts are added to income from ecclesiastical properties and the rental income from Crown lands, James IV may have received a total income of around \u00a344,500 by 1513, although by that time there was an annual deficit of around \u00a37,000.\nMilitary.\nJames IV took a close interest in the development of the Royal Scots Navy, viewing a strong fleet as a means of protecting Scottish shipping, gaining international prestige, and providing him with an outlet to pursue foreign policies in alliance with either England or France. In the course of his reign, James commissioned or acquired a total of at least thirty-eight ships. His naval building programme was large, especially so for the ruler of a small kingdom. Naval spending was by far the greatest single item of royal expenditure in the later years of his reign. In the early years, the annual average spent on ships was about \u00a3140 Scots. By the early 1510s it was \u00a38,710.\nIn 1491, James determined to address the many attacks on Scottish shipping in the vicinity of the Firth of Forth from the English and other pirates. He erected fortresses at Largo and Inchgarvie, and made extensive repairs to Dunbar Castle, to defend the firth from hostile attacks. In 1493 James ordered every burgh to provide the Crown with a boat of 20 tons, and to conscript able men to crew them. The forfeiture of the Lordship of the Isles was followed by James's naval expeditions to Argyll and the Hebrides in 1492\u20131495 and 1498, and in May 1502 James sent a fleet of five ships and 2,000 troops under the command of James Hamilton, 1st Earl of Arran to Denmark to aid his uncle, John, King of Denmark, who had appealed to James for aid during the Dano-Swedish War. The expedition was a failure, arriving too late to help Queen Christina hold Stockholm. The Danish expedition seems to have concentrated James IV's mind on naval expansion: shipwrights and craftsmen were recruited from across Scotland, and from France, Flanders, Denmark and Spain; timber for shipbuilding was felled in Lanarkshire and the Highlands and imported from Norway and France. James was also responsible for the founding of new dockyards on the Forth at Newhaven in 1504, and Pool of Airth in 1506. The king also wore the insignia of an Admiral \u2014 a whistle and a chain of gold.\nThe \"Margaret\", built at Leith and launched in 1506, weighed around 600\u2013700 tons, was armed with four falconets, a cannon and twenty-one other guns, and cost the king an estimated \u00a38,000 \u2014 more than a quarter of his annual income. The carrack \"Great Michael\" was the largest warship of its time. Built at Newhaven and launched in 1511, it measured between and in length, weighed around 1,000 tons, and was supposed to have cost around \u00a330,000. Armed with twenty-four bronze cannons and three basilisks, it marked a shift in design as it was designed specifically to carry a main armament of heavy artillery. The navy's core of four large ships (the \"Treasurer\", the \"Margaret\", the \"James\" and the \"Michael\") were supported by a number of smaller craft and privately owned merchant ships.\nLike his grandfather and father, James IV also took an enthusiastic interest in artillery, and from early in his reign he added to James III's French train of artillery. In 1507 he shot some \"great guns\" at Holyrood Abbey with three of his gunners, and the following year it is recorded that he held shooting matches with hand culverins in the great halls of Holyrood Palace and Stirling Castle. James also took a culverin to stalk deer in the park of Falkland Palace and shot at sea birds with one from a row boat off the Isle of May. James IV imported guns, shot and powder from France, and in 1511 the royal gun foundry was moved from Stirling Castle to Edinburgh Castle, where Scots, Dutch, German, and French gunmakers worked under the master gunner, Robert Borthwick, in what was the earliest significant foundry for producing large bronze guns in the British Isles. Their output included guns for the \"Michael\", and the \"Seven Sisters\", a set of cannons captured by the English at Flodden. James's artillery also included arquebus \u00e0 croc (mounted heavy arquebuses), hand culverins and falconets.\nCulture and patronage.\nJames IV was a true Renaissance prince and a patron of the arts, including many literary figures, most notably the Scots makars. Poets associated with his court include William Dunbar, Walter Kennedy and Gavin Douglas. James patronised music at Restalrig using rental money from the King's Wark, and gave his backing to the foundation of King's College, Aberdeen, by his chancellor, William Elphinstone, and St Leonard's College, St Andrews, by his illegitimate son, Alexander, Archbishop of St Andrews, and John Hepburn, Prior of St Andrews. In 1496, partly at Elphinstone's instance, he also passed what has been described as Scotland's first education act, which introduced compulsory education at grammar school for the eldest sons and heirs of all barons and freeholders of substance.\nJames was both highly intelligent and well educated. In July 1498, Spanish ambassador, Pedro de Ayala, reported to Ferdinand II of Aragon and Isabella I of Castile:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The King is 25 years and some months old. He is of noble stature, neither tall nor short, and as handsome in complexion and shape as a man can be. His address is very agreeable. He speaks the following foreign languages: Latin, very well; French, German, Flemish, Italian, and Spanish; Spanish as well as the Marquis, but he pronounces it more distinctly. He likes, very much, to receive Spanish letters. His own Scots language is as different from English as Aragonese from Castilian. The King speaks, besides, the language of the savages who live in some parts of Scotland and on the islands. It is as different from Scots as Biscayan is from Castilian. His knowledge of languages is wonderful. He is well read in the Bible and in some other devout books. He is a good historian. He has read many Latin and French histories, and profited by them, as he has a very good memory. He never cuts his hair or his beard. It becomes him very well.\nJames also ensured that the very best education was given to his illegitimate son, Alexander, who was tutored by Erasmus in Padua, Siena and Rome. James IV allegedly conducted a language deprivation experiment in which two children were sent to be raised by a mute woman alone on the island of Inchkeith, to determine if language was learned or innate.\nJames IV had a wide range of intellectual interests and took an interest in practical and scientific matters. He patronised the establishment of Scotland's first printing press, Chepman and Myllar Press, in 1507, and granted the Incorporation of Surgeons and Barbers of Edinburgh a royal charter in 1506. James was also interested in dentistry, an interest which began in 1503 when the king summoned a \"barbour\" to extract one of his teeth for the sum of 14 shillings. In 1504, he sought more practical experience of dentistry and purchased two gold toothpicks suspended from a chain, and \"ane turcase [pincer] to tak out teith\". It is recorded that James pulled two teeth from one of his own barber-surgeons, for which the king paid him 14 shillings, and also tried bloodletting on patients, and treating and dressing ulcer wounds. He also took an interest in other sciences which are now less creditable, establishing an alchemy workshop at Stirling Castle, where alchemist John Damian looked for ways to turn base metals into gold. The project consumed quantities of mercury, golden litharge, and tin. A goldsmith, Matthew Auchinleck, provided the alchemists with a still made of silver. Damian also researched aviation and undertook a failed experiment to fly from the battlements of Stirling Castle, an event which William Dunbar satirised in two separate poems.\nJames poured large amounts of money into the construction or remodelling of several royal residences. He commissioned the construction between 1501 and 1505 of the Palace of Holyroodhouse. The impetus for the work probably came from his marriage to Margaret Tudor, which took place in Holyrood Abbey in August 1503. James also commissioned the construction of Falkland Palace in Fife between 1501 and 1513, on a site to the south of Falkland Castle. At Stirling Castle, James commissioned the construction of the great hall and a new royal lodging (the present-day King's Old Building), the remodelling of the chapel royal, and the reconstruction of the principal defences on the southern and eastern sides of the castle. He also commissioned the construction of the great hall at Edinburgh Castle, rebuilding at Linlithgow Palace, Rothesay Castle, and Dunbar Castle, and furnished his palaces with tapestries.\nThe first evidence of whisky production in Scotland comes from an entry in the \"Exchequer Rolls\" for 1494 where malt is sent \"To Friar John Cor, by order of the king, to make aquavitae\", enough to make about 500 bottles. James IV reportedly had a great liking for whisky, and in 1506 the town of Dundee purchased a large amount of whisky from the Guild of Barber-Surgeons, which held the monopoly on production at the time.\nPresence at the Scottish court.\nJames IV's court and royal household were cosmopolitan, containing assorted foreign peoples including French, Italian and German minstrels, Flemish metalworkers, and Spanish dancers. The court also hosted a number of Africans, some working as servants or (possibly) slaves, but others appearing to have been courtiers, invited guests or musicians. In 1504, two African women, who were later christened as Margaret and Helen or Elen More, are mentioned in the \"Accounts of the Lord High Treasurer of Scotland\". The women were visible in court life and Helen More became the presumed subject of the poem \"Of Ane Blak-Moir\" by William Dunbar describing an African woman offered as a prize in jousting tournaments. The poem is critical of her appearance and status as a black woman in a predominantly white court and country.\nAn African drummer referred to as the \"More taubronar\" travelled with James around Scotland. \"Peter the Moor\" was an African man whose travel and expenses were paid for by royal funds. He first appears in records in 1500 and some historians believe he and other Africans arrived in Scotland initially as \"human booty\" captured by Scottish privateers from Portuguese cargo ships. Records show that Peter the Moor was a companion to King James in his various trips across the country, appearing in the records until August 1504, when he received a large and final payment. Historian Imtiaz Habib argues that Peter was \"clearly a favourite companion to the monarch\" and was \"well accepted\" into the court culture. The status of the Africans in James IV's court is contested, with some historians taking the view that the two women Elen and Margaret More were \"enjoying in the royal service a benevolent form of ... black slavery\". Other historians emphasise that these individuals were treated as \"court curiosities\" rather than being in control of their own lives, and were most likely enslaved to some extent.\nDiplomacy and war.\nJames was granted the title \"Protector and Defender of the Christian Faith\" in 1507 by Pope Julius II, and in April 1507 at Holyrood Abbey he received the Blessed sword and hat. In 1508 James IV made plans to go on pilgrimage to Jerusalem, after a journey to Venice, before sailing from there to Jaffa in a Venetian ship. James's uncle, King John of Denmark, protested against his projected pilgrimage to Jerusalem in a letter written to the Archbishop of Glasgow in July 1507, remarking that the Scottish king should think first of his young wife and his country. Archbishop Blackadder left Scotland in February 1508 to set out on pilgrimage to the Holy Land, probably as a reconnaissance for the king's pilgrimage. Blackadder's death on 28 July 1508, presumably from an infectious illness, on board a ship from Venice to Jaffa appears to have convinced James IV of the inadvisability of sailing to Jerusalem. In 1507\u20131508, Louis XII of France was endeavouring to have James renew the Franco-Scottish alliance, and James wrote to Louis raising the idea of a joint Franco-Scottish crusade to the Holy Land. James's maintenance of Scotland's traditional good relations with France occasionally created diplomatic problems with England. In April 1508, Thomas Wolsey was sent to Scotland to discuss Henry VII's concerns over rumours that James would renew the Auld Alliance with France. Wolsey found \"there was never a man worse welcome into Scotland than I. ... They keep their matters so secret here that the wives in the market know every cause of my coming.\" Wolsey was unable to persuade James to abandon the Auld Alliance, but Anglo-Scottish relations nonetheless remained stable until the death of Henry VII in 1509.\nRelations between Scotland and England deteriorated with the accession of Henry VIII of England in April 1509. Unlike his father, Henry had no interest in appeasing James because his focus was on France. Henry VIII also believed that whatever the implications of the Treaty of Perpetual Peace, the King of Scotland owed him obedience. At the core of the increasing hostility between James and Henry was James IV's position in relation to the English throne. From his accession in 1509 until the birth of his daughter Mary in 1516 \u2014 apart from the short life of his son Henry, Duke of Cornwall in 1511 \u2014 Henry was childless and had no recognised heir. Through his wife Margaret, James IV was an heir to the English throne. When Margaret gave birth to a son in October 1509, the baby was christened Arthur, not after Margaret and Henry's elder brother, but to advertise the Scottish claim to the Arthurian legend and as a British name for a potential British king. Then on 10 April 1512, Margaret gave birth to another boy, to be called James. This boy, the future James V, was still alive and well a year later, while his uncle continued to remain childless.\nAs a result of the Italian Wars, in October 1511 Pope Julius II created a Holy League against France. The new alliance included the Papacy, Venice, Spain and the Holy Roman Empire. In November 1511, England also joined the League, with Henry VIII deciding to use the occasion as an excuse to conclude the Treaty of Westminster \u2014 a pledge of mutual aid against the French \u2014 with Ferdinand II. Relations between the Scottish and English kings continued to deteriorate with the passing of the Subsidy Act by the English parliament in 1512, with the act preamble declaring that the King of Scotland was \"the very homage and obedience of right to your Highness [Henry VIII]\". This assault on Scotland's independence was a reassertion of claims to English overlordship which had been implicitly revoked on a permanent basis by the 1502 Treaty of Perpetual Peace. The English justification of the claim was that James IV had broken the peace, and was preparing for war. This was completely specious as James had by then not even acceded to Louis XII's urgent requests to renew the Franco-Scottish alliance. In theory, there was a \"court of appeal\" which had the power to adjudicate such differences between the parties to the treaty: the Papacy. But Pope Julius II was now an ally of England, and far from being an honest broker. James IV had so far refused the French king's requests to renew the Franco-Scottish alliance as Louis XII was not offering a sufficient benefit in return. However, Henry VIII's increasingly belligerent stance effectively ensured that the Auld Alliance would be renewed. James gave formal agreement to the renewal of the alliance in July 1512, but this was a gesture rather than a commitment of active support against England, and it was still possible that Scotland would remain neutral in any Anglo-French war.\nBefore his death in February 1513, Pope Julius II had been persuaded by the Archbishop of York, Christopher Bainbridge, to impose an interdict as a general censure against the Scottish people. He also threatened to excommunicate the Scottish king if he was judged to have broken the treaty with England, and granted Bainbridge the power to excommunicate James in such circumstances. James IV sent Andrew Forman, the Bishop of Moray, to Rome to try and persuade the new Pope, Leo X, to countermand the interdict, but without success. Leo sent a letter to James, threatening him with ecclesiastical censure for breaking peace treaties, and in the summer of 1513 the king was excommunicated by Bainbridge. On 30 June, Henry VIII invaded France, his troops defeating a French army at the Battle of the Spurs, before capturing Th\u00e9rouanne and Tournai. James IV summoned the Scottish army, and sent a naval fleet of twenty-two vessels, including the \"Great Michael\", to join the ships of Louis XII of France. The fleet, commanded by James Hamilton, 1st Earl of Arran, departed from the Firth of Forth on 25 July and sailed around the north of Scotland. It first created a diversion in Ireland, where it attacked the English royal garrison at Carrickfergus and burnt the town, with support from Hugh Duff O'Donnell. The Scottish fleet then joined the French at Brest, from where it might cut the English army in France's line of communication across the English Channel. However, the fleet was so badly delayed that it played no part in the war; James had sent most of his experienced artillerymen with the expedition, a decision which was to have unforeseen consequences for his land campaign.\nFlodden.\nLed by James IV, the Scottish army, numbering some 42,000 men, and including a large artillery train, crossed the River Tweed into England near Coldstream around 22 August. The Scottish troops were unpaid and were only required by feudal obligation to serve for forty days. Once across the border, a detachment turned south to attack Wark on Tweed Castle, while the bulk of the army followed the course of the Tweed downstream to the northeast to invest the remaining border castles. Norham Castle was taken and partly demolished, and the army then moved south, capturing the castles of Etal and Ford. On 8 September the Scottish army took up position against an English army commanded by Thomas Howard, Earl of Surrey, on Branxton Hill in Northumberland. James's army, somewhat reduced from the original 42,000 by sickness and desertion, still amounted to about 34,000, outnumbering the English force by 8,000. The Scottish infantry had been equipped with pikes by their French allies; a new weapon which had proved devastating in continental Europe, but required training, discipline and suitable terrain to use effectively. The Scottish artillery, consisting mainly of heavy siege guns, included five great curtals and two great culverins, together with four sakers and six great serpentines. The English infantry were equipped with traditional polearms, mostly bills which were the favoured pole arm of the English infantry. There was also a large contingent of well-trained archers armed with the English longbow. The English artillery consisted of light field guns of rather old-fashioned design, typically firing a ball of only about , but easy to handle and capable of rapid fire.\nJames IV began the battle with an artillery duel, but his heavy guns did not perform well, contemporary accounts putting this down to the difficulty for the Scots of shooting downhill, another factor being that their guns had been hastily sited instead of the careful emplacement which was usually required for such heavy weapons, slowing their rate of fire. This allowed the light English guns to turn a rapid fire on the massed ranks of Scottish infantry. The Scottish left, under Lord Home and the Earl of Huntly, then advanced downhill towards the English army. The Scots had placed their most heavily armoured men in the front rank so that the English archers had little impact. The outnumbered English formation was forced back and elements of it began to run off before Surrey ordered the intervention of Dacre's light horsemen. The eventual result was a stalemate in which both sides stood off from each other and played no further part in the battle.\nIn the meantime, James had observed Home and Huntly's initial success and ordered the advance of the next formation in line, commanded by the earls of Errol, Crawford and Montrose. At the foot of Branxton Hill, they encountered an unforeseen obstacle, an area of marshy ground, made worse by days of heavy rain. As they struggled to cross the waterlogged ground, the Scots lost the cohesion and momentum on which pike formations depended for success. Once the line was disrupted, the long pikes became an unwieldy encumbrance, and the Scots began to drop them. Reaching for their side-arms of swords and axes, they found themselves outreached by the English bills in the close-quarter fighting that developed. It is unclear whether James had seen the difficulty encountered by the earls formation, but he followed down the slope regardless, making for Surrey's formation. James has been criticised for placing himself in the front line, thereby putting himself in personal danger and losing his overview of the field. He was, however, well known for taking risks in battle, and it would have been out of character for him to stay back. Encountering the same difficulties as the previous attack, James's men nevertheless fought their way to Surrey's bodyguard. The fierce fighting continued, centred on the contest between Surrey and James. As other English formations overcame the Scottish forces they had initially engaged, they moved to reinforce the Earl of Surrey. An instruction to English troops that no prisoners were to be taken explains the exceptional mortality amongst the Scottish nobility. James IV himself was killed in the final stage of the battle, having fought to within a spear length of the Earl of Surrey.\nThe Battle of Flodden was one of Scotland's worst military defeats: the loss of not only a popular and capable king but also a large portion of the political community, was a major blow to the realm. James IV's son, James V, was crowned three weeks after the disaster at Flodden but was only one year old, and his minority was to be fraught with political upheaval.\nDeath.\nThe body of James IV was found the following day amongst the thousands of Scottish dead on the battlefield, having been identified by two Scottish soldiers captured by the English, and by Thomas Dacre, 2nd Baron Dacre. James's lower jaw had been pierced by an arrow, an injury which would have disabled him sufficiently for the attacking English soldiers to move in and slash him with their bills, almost severing his left hand and slicing his throat open. James's body was taken to Berwick-upon-Tweed, where it was embalmed, sealed in a lead-lined coffin, and transported to Sheen Priory in Surrey, where it remained unburied. James's slashed and bloodstained surcoat was sent to Henry VIII (then on campaign in France) by his queen, Catherine of Aragon.\nAs James had been excommunicated prior to his death, he could not be buried in consecrated ground until the Pope remitted the sentence. Although Henry VIII obtained a dispensation from Pope Leo X on 29 November 1513 to have the Scottish king buried in St Paul's Cathedral in London, James IV remained unburied. His coffin remained above ground at Sheen Priory, as the decades passed and the priory was dissolved in 1539 during the English Reformation, becoming the secularised estate of Henry Grey, 1st Duke of Suffolk. During the reign of Edward VI of England the antiquarian John Stow was shown the coffin, lying in a store room: \"since the dissolution of the House I have been shewed the same body (as was affirmed) so lapped in lead throwne into an old wast roome, amongst old timber, stone, lead, and other rubble\". James IV's coffin was rediscovered during the reign of Elizabeth I of England when it was opened and his body became a plaything, John Stow writing that \"Workmen there for their foolish pleasure hewed off his head.\" The body disappeared, its last-known resting place at Sheen now lying under the fairway of the 14th hole of the Royal Mid-Surrey Golf Course. Elizabeth I's master glazier, Lancelot Young, is said to have kept James's \"sweetly scented\" head (still identifiable as James by its red hair and beard) as a curio at his home in Wood Street in the City of London, before giving it to the sexton of the local church, St Michael's. The head was then buried in a charnel pit in St Michael's churchyard. The church was later demolished, and the site redeveloped many times.\nRumours persisted that James IV had survived and was seen riding back across the Tweed; that he had gone on pilgrimage to Jerusalem; or that his body was buried in Scotland. Two castles in the Borders are claimed as his resting place. The legend ran that, before the Scottish charge at Flodden, James had ripped off his surcoat to show his nobles that he was prepared to fight as an ordinary man-at-arms. Border legend claimed that during the battle, four Home horsemen or supernatural riders swept across the field snatching up the king's body, or that the king left the field alive and was killed soon afterwards. In the 19th century, when the medieval well of Hume Castle was being cleared, the skeleton of a man with a chain round his waist was discovered in a side cave; but this skeleton has since disappeared. Another version of this tale has the skeleton discovered at Hume a few years after the battle and re-interred at Holyrood Abbey. The same story was told for Roxburgh Castle, with the skeleton there discovered in the 17th century. Yet another tradition is the discovery of the royal body at Berry Moss, near Kelso. Fuelling these legends, Robert Lindsay of Pitscottie, writing in the 1570s, claimed that a convicted criminal offered to show John Stewart, 2nd Duke of Albany the king's grave ten years after the battle, but Albany refused.\nFictional portrayals.\nJames IV has been depicted in historical novels, short stories and media portrayals. They include the following:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50557", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=50557", "title": "Phytoplankton", "text": "Autotrophic members of the plankton ecosystem\nPhytoplankton () are the autotrophic (self-feeding) components of the plankton community and a key part of ocean and freshwater ecosystems. The name comes from Ancient Greek \u03c6\u03c5\u03c4\u03cc\u03bd (\"phut\u00f3n\"), meaning \"plant\", and \u03c0\u03bb\u03b1\u03b3\u03ba\u03c4\u03cc\u03c2 (\"plankt\u00f3s\"), meaning \"drifter, wanderer, roamer\", and thus, \"plant drifter\".\nPhytoplankton obtain their energy through photosynthesis, as trees and other plants do on land. This means phytoplankton must have light from the sun, so they live in the well-lit surface layers (euphotic zone) of oceans and lakes. In comparison with terrestrial plants, phytoplankton are distributed over a larger surface area, are exposed to less seasonal variation and have markedly faster turnover rates than trees (days versus decades). As a result, phytoplankton respond rapidly on a global scale to climate variations.\nPhytoplankton form the base of marine and freshwater food webs and are key players in the global carbon cycle. They account for about half of global photosynthetic activity and at least half of the oxygen production, despite amounting to only about 1% of the global plant biomass.\nPhytoplankton are very diverse, comprising photosynthesizing bacteria (cyanobacteria) and various unicellular protist groups (notably the diatoms). \nMost phytoplankton are too small to be individually seen with the unaided eye. However, when present in high enough numbers, some varieties may be noticeable as colored patches on the water surface due to the presence of chlorophyll within their cells and accessory pigments (such as phycobiliproteins or xanthophylls) in some species.\nTypes.\nPhytoplankton are photosynthesizing microscopic protists and bacteria that inhabit the upper sunlit layer of marine and fresh water bodies of water on Earth. Paralleling plants on land, phytoplankton undertake primary production in water, creating organic compounds from carbon dioxide dissolved in the water. Phytoplankton form the base of \u2014 and sustain \u2014 the aquatic food web, and are crucial players in the Earth's carbon cycle.\nPhytoplankton are very diverse, comprising photosynthesizing bacteria (cyanobacteria) and various unicellular protist groups (notably the diatoms). Many other organism groups formally named as phytoplankton, including coccolithophores and dinoflagellates, are now no longer included as they are not only phototrophic but can also eat other organisms. These organisms are now more correctly termed\u00a0mixoplankton. This recognition has important consequences for how the functioning of the planktonic food web is viewed.\nEcology.\nPhytoplankton obtain energy through the process of photosynthesis and must therefore live in the well-lit surface layer (termed the euphotic zone) of an ocean, sea, lake, or other body of water. Phytoplankton account for about half of all photosynthetic activity on Earth. Their cumulative energy fixation in carbon compounds (primary production) is the basis for the vast majority of oceanic and also many freshwater food webs (chemosynthesis is a notable exception).\nWhile almost all phytoplankton species are obligate photoautotrophs, there are some that are mixotrophic and other, non-pigmented species that are actually heterotrophic (the latter are often viewed as zooplankton). Of these, the best known are dinoflagellate genera such as \"Noctiluca\" and \"Dinophysis\", that obtain organic carbon by ingesting other organisms or detrital material.\nPhytoplankton live in the photic zone of the ocean, where photosynthesis is possible. During photosynthesis, they assimilate carbon dioxide and release oxygen. If solar radiation is too high, phytoplankton may fall victim to photodegradation. Phytoplankton species feature a large variety of photosynthetic pigments which species-specifically enables them to absorb different wavelengths of the variable underwater light. This implies different species can use the wavelength of light different efficiently and the light is not a single ecological resource but a multitude of resources depending on its spectral composition. By that it was found that changes in the spectrum of light alone can alter natural phytoplankton communities even if the same intensity is available. For growth, phytoplankton cells additionally depend on nutrients, which enter the ocean by rivers, continental weathering, and glacial ice meltwater on the poles. Phytoplankton release dissolved organic carbon (DOC) into the ocean. Since phytoplankton are the basis of marine food webs, they serve as prey for zooplankton, fish larvae and other heterotrophic organisms. They can also be degraded by bacteria or by viral lysis. Although some phytoplankton cells, such as dinoflagellates, are able to migrate vertically, they are still incapable of actively moving against currents, so they slowly sink and ultimately fertilize the seafloor with dead cells and detritus.\nPhytoplankton are crucially dependent on a number of nutrients. These are primarily macronutrients such as nitrate, phosphate or silicic acid, which are required in relatively large quantities for growth. Their availability in the surface ocean is governed by the balance between the so-called biological pump and upwelling of deep, nutrient-rich waters. The stoichiometric nutrient composition of phytoplankton drives \u2014 and is driven by \u2014 the Redfield ratio of macronutrients generally available throughout the surface oceans. Phytoplankton also rely on trace metals such as iron (Fe), manganese (Mn), zinc (Zn), cobalt (Co), cadmium (Cd) and copper (Cu) as essential micronutrients, influencing their growth and community composition. Limitations in these metals can lead to co-limitations and shifts in phytoplankton community structure. Across large areas of the oceans such as the Southern Ocean, phytoplankton are often limited by the lack of the micronutrient iron. This has led to some scientists advocating iron fertilization as a means to counteract the accumulation of human-produced carbon dioxide (CO2) in the atmosphere. Large-scale experiments have added iron (usually as salts such as ferrous sulfate) to the oceans to promote phytoplankton growth and draw atmospheric CO2 into the ocean. Controversy about manipulating the ecosystem and the efficiency of iron fertilization has slowed such experiments. The ocean science community still has a divided attitude toward the study of iron fertilization as a potential marine Carbon Dioxide Removal (mCDR) approach.\nPhytoplankton depend on B vitamins for survival. Areas in the ocean have been identified as having a major lack of some B Vitamins, and correspondingly, phytoplankton.\nThe effects of anthropogenic warming on the global population of phytoplankton is an area of active research. Changes in the vertical stratification of the water column, the rate of temperature-dependent biological reactions, and the atmospheric supply of nutrients are expected to have important effects on future phytoplankton productivity.\nThe effects of anthropogenic ocean acidification on phytoplankton growth and community structure has also received considerable attention. The cells of coccolithophore phytoplankton are typically covered in a calcium carbonate shell called a coccosphere that is sensitive to ocean acidification. Because of their short generation times, evidence suggests some phytoplankton can adapt to changes in pH induced by increased carbon dioxide on rapid time-scales (months to years).\nPhytoplankton serve as the base of the aquatic food web, providing an essential ecological function for all aquatic life. Under future conditions of anthropogenic warming and ocean acidification, changes in phytoplankton mortality due to changes in rates of zooplankton grazing may be significant. One of the many food chains in the ocean \u2013 remarkable due to the small number of links \u2013 is that of phytoplankton sustaining krill (a crustacean similar to a tiny shrimp), which in turn sustain baleen whales.\nThe El Ni\u00f1o-Southern Oscillation (ENSO) cycles in the Equatorial Pacific area can affect phytoplankton. Biochemical and physical changes during ENSO cycles modify the phytoplankton community structure. Also, changes in the structure of the phytoplankton, such as a significant reduction in biomass and phytoplankton density, particularly during El Nino phases can occur. The sensitivity of phytoplankton to environmental changes is why they are often used as indicators of estuarine and coastal ecological condition and health. To study these events satellite ocean color observations are used to observe these changes. Satellite images help to have a better view of their global distribution.\nDiversity.\nThe term phytoplankton encompasses all photoautotrophic microorganisms in aquatic food webs. However, unlike terrestrial communities, where most autotrophs are plants, phytoplankton are a diverse group, incorporating protistan eukaryotes and both eubacterial and archaebacterial prokaryotes. There are about 5,000 known species of marine phytoplankton. How such diversity evolved despite scarce resources (restricting niche differentiation) is unclear.\nIn terms of numbers, the most important groups of phytoplankton include the diatoms, cyanobacteria and dinoflagellates, although many other groups of algae are represented. One group, the coccolithophorids, is responsible (in part) for the release of significant amounts of dimethyl sulfide (DMS) into the atmosphere. DMS is oxidized to form sulfate which, in areas where ambient aerosol particle concentrations are low, can contribute to the population of cloud condensation nuclei, mostly leading to increased cloud cover and cloud albedo according to the so-called CLAW hypothesis. Different types of phytoplankton support different trophic levels within varying ecosystems. In oligotrophic oceanic regions such as the Sargasso Sea or the South Pacific Gyre, phytoplankton is dominated by the small sized cells, called picoplankton and nanoplankton (also referred to as picoflagellates and nanoflagellates), mostly composed of cyanobacteria (\"Prochlorococcus\", \"Synechococcus\") and picoeucaryotes such as \"Micromonas\". Within more productive ecosystems, dominated by upwelling or high terrestrial inputs, larger dinoflagellates are the more dominant phytoplankton and reflect a larger portion of the biomass.\nGrowth strategies.\nIn the early twentieth century, Alfred C. Redfield found the similarity of the phytoplankton's elemental composition to the major dissolved nutrients in the deep ocean. Redfield proposed that the ratio of carbon to nitrogen to phosphorus (106:16:1) in the ocean was controlled by the phytoplankton's requirements, as phytoplankton subsequently release nitrogen and phosphorus as they are remineralized. This so-called \"Redfield ratio\" in describing stoichiometry of phytoplankton and seawater has become a fundamental principle to understand marine ecology, biogeochemistry and phytoplankton evolution. However, the Redfield ratio is not a universal value and it may diverge due to the changes in exogenous nutrient delivery and microbial metabolisms in the ocean, such as nitrogen fixation, denitrification and anammox.\nThe dynamic stoichiometry shown in unicellular algae reflects their capability to store nutrients in an internal pool, shift between enzymes with various nutrient requirements and alter osmolyte composition. Different cellular components have their own unique stoichiometry characteristics, for instance, resource (light or nutrients) acquisition machinery such as proteins and chlorophyll contain a high concentration of nitrogen but low in phosphorus. Meanwhile, growth machinery such as ribosomal RNA contains high nitrogen and phosphorus concentrations.\nBased on allocation of resources, phytoplankton is classified into three different growth strategies, namely survivalist, bloomer and generalist. Survivalist phytoplankton has a high ratio of N:P (&gt;30) and contains an abundance of resource-acquisition machinery to sustain growth under scarce resources. Bloomer phytoplankton has a low N:P ratio (&lt;10), contains a high proportion of growth machinery, and is adapted to exponential growth. Generalist phytoplankton has similar N:P to the Redfield ratio and contain relatively equal resource-acquisition and growth machinery.\nFactors affecting abundance.\nThe NAAMES study was a five-year scientific research program conducted between 2015 and 2019 by scientists from Oregon State University and NASA to investigated aspects of phytoplankton dynamics in ocean ecosystems, and how such dynamics influence atmospheric aerosols, clouds, and climate (NAAMES stands for the North Atlantic Aerosols and Marine Ecosystems Study). The study focused on the sub-arctic region of the North Atlantic Ocean, which is the site of one of Earth's largest recurring phytoplankton blooms. The long history of research in this location, as well as relative ease of accessibility, made the North Atlantic an ideal location to test prevailing scientific hypotheses in an effort to better understand the role of phytoplankton aerosol emissions on Earth's energy budget.\nNAAMES was designed to target specific phases of the annual phytoplankton cycle: minimum, climax and the intermediary decreasing and increasing biomass, in order to resolve debates on the timing of bloom formations and the patterns driving annual bloom re-creation. The NAAMES project also investigated the quantity, size, and composition of aerosols generated by primary production in order to understand how phytoplankton bloom cycles affect cloud formations and climate.\nFactors affecting productivity.\nPhytoplankton are the key mediators of the biological pump. Understanding the response of phytoplankton to changing environmental conditions is a prerequisite to predict future atmospheric concentrations of CO2. Temperature, irradiance and nutrient concentrations, along with CO2 are the chief environmental factors that influence the physiology and stoichiometry of phytoplankton. The stoichiometry or elemental composition of phytoplankton is of utmost importance to secondary producers such as copepods, fish and shrimp, because it determines the nutritional quality and influences energy flow through the marine food chains. Climate change may greatly restructure phytoplankton communities leading to cascading consequences for marine food webs, thereby altering the amount of carbon transported to the ocean interior.\nThe figure gives an overview of the various environmental factors that together affect phytoplankton productivity. All of these factors are expected to undergo significant changes in the future ocean due to global change. Global warming simulations predict oceanic temperature increase; dramatic changes in oceanic stratification, circulation and changes in cloud cover and sea ice, resulting in an increased light supply to the ocean surface. Also, reduced nutrient supply is predicted to co-occur with ocean acidification and warming, due to increased stratification of the water column and reduced mixing of nutrients from the deep water to the surface.\nRole of phytoplankton.\nThe compartments influenced by phytoplankton include the atmospheric gas composition, inorganic nutrients, and trace element fluxes as well as the transfer and cycling of organic matter via biological processes (see figure). The photosynthetically fixed carbon is rapidly recycled and reused in the surface ocean, while a certain fraction of this biomass is exported as sinking particles to the deep ocean, where it is subject to ongoing transformation processes, e.g., remineralization.\nPhytoplankton contribute to not only a basic pelagic marine food web but also to the microbial loop. Phytoplankton are the base of the marine food web and because they do not rely on other organisms for food, they make up the first trophic level. Organisms such as zooplankton feed on these phytoplankton which are in turn fed on by other organisms and so forth until the fourth trophic level is reached with apex predators. Approximately 90% of total carbon is lost between trophic levels due to respiration, detritus, and dissolved organic matter. This makes the remineralization process and nutrient cycling performed by phytoplankton and bacteria important in maintaining efficiency.\nPhytoplankton blooms in which a species increases rapidly under conditions favorable to growth can produce harmful algal blooms (HABs).\nAquaculture.\nPhytoplankton are a key food item in both aquaculture and mariculture. Both utilize phytoplankton as food for the animals being farmed. In mariculture, the phytoplankton is naturally occurring and is introduced into enclosures with the normal circulation of seawater. In aquaculture, phytoplankton must be obtained and introduced directly. The plankton can either be collected from a body of water or cultured, though the former method is seldom used. Phytoplankton is used as a foodstock for the production of rotifers, which are in turn used to feed other organisms. Phytoplankton is also used to feed many varieties of aquacultured molluscs, including pearl oysters and giant clams. A 2018 study estimated the nutritional value of natural phytoplankton in terms of carbohydrate, protein and lipid across the world ocean using ocean-colour data from satellites, and found the calorific value of phytoplankton to vary considerably across different oceanic regions and between different time of the year.\nThe production of phytoplankton under artificial conditions is itself a form of aquaculture. Phytoplankton is cultured for a variety of purposes, including foodstock for other aquacultured organisms, a nutritional supplement for captive invertebrates in aquaria. Culture sizes range from small-scale laboratory cultures of less than 1L to several tens of thousands of litres for commercial aquaculture. Regardless of the size of the culture, certain conditions must be provided for efficient growth of plankton. The majority of cultured plankton is marine, and seawater of a specific gravity of 1.010 to 1.026 may be used as a culture medium. This water must be sterilized, usually by either high temperatures in an autoclave or by exposure to ultraviolet radiation, to prevent biological contamination of the culture. Various fertilizers are added to the culture medium to facilitate the growth of plankton. A culture must be aerated or agitated in some way to keep plankton suspended, as well as to provide dissolved carbon dioxide for photosynthesis. In addition to constant aeration, most cultures are manually mixed or stirred on a regular basis. Light must be provided for the growth of phytoplankton. The colour temperature of illumination should be approximately 6,500 K, but values from 4,000 K to upwards of 20,000 K have been used successfully. The duration of light exposure should be approximately 16 hours daily; this is the most efficient artificial day length.\nAnthropogenic changes.\nMarine phytoplankton perform half of the global photosynthetic CO2 fixation (net global primary production of ~50\u2009Pg\u2009C per year) and half of the oxygen production despite amounting to only ~1% of global plant biomass. In comparison with terrestrial plants, marine phytoplankton are distributed over a larger surface area, are exposed to less seasonal variation and have markedly faster turnover rates than trees (days versus decades). Therefore, phytoplankton respond rapidly on a global scale to climate variations. These characteristics are important when one is evaluating the contributions of phytoplankton to carbon fixation and forecasting how this production may change in response to perturbations. Predicting the effects of climate change on primary productivity is complicated by phytoplankton bloom cycles that are affected by both bottom-up control (for example, availability of essential nutrients and vertical mixing) and top-down control (for example, grazing and viruses). Increases in solar radiation, temperature and freshwater inputs to surface waters strengthen ocean stratification and consequently reduce transport of nutrients from deep water to surface waters, which reduces primary productivity. Conversely, rising CO2 levels can increase phytoplankton primary production, but only when nutrients are not limiting.\nSome studies indicate that overall global oceanic phytoplankton density has decreased in the past century, but these conclusions have been questioned because of the limited availability of long-term phytoplankton data, methodological differences in data generation and the large annual and decadal variability in phytoplankton production. Moreover, other studies suggest a global increase in oceanic phytoplankton production and changes in specific regions or specific phytoplankton groups. The global Sea Ice Index is declining, leading to higher light penetration and potentially more primary production; however, there are conflicting predictions for the effects of variable mixing patterns and changes in nutrient supply and for productivity trends in polar zones.\nThe effect of human-caused climate change on phytoplankton biodiversity is not well understood. Should greenhouse gas emissions continue rising to high levels by 2100, some phytoplankton models predict an increase in species richness, or the number of different species within a given area. This increase in plankton diversity is traced to warming ocean temperatures. In addition to species richness changes, the locations where phytoplankton are distributed are expected to shift towards the Earth's poles. Such movement may disrupt ecosystems, because phytoplankton are consumed by zooplankton, which in turn sustain fisheries. This shift in phytoplankton location may also diminish the ability of phytoplankton to store carbon that was emitted by human activities. Human (anthropogenic) changes to phytoplankton impact both natural and economic processes.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50558", "revid": "49573244", "url": "https://en.wikipedia.org/wiki?curid=50558", "title": "Zooplankton", "text": "Heterotrophic protistan or metazoan members of the plankton ecosystem\nZooplankton are the heterotrophic component of the planktonic community, having to consume other organisms to thrive. The name comes from Ancient Greek \u03b6\u1ff7\u03bf\u03bd (\"z\u014d\u00eeon\"), meaning \"animal\", and \u03c0\u03bb\u03b1\u03b3\u03ba\u03c4\u03cc\u03c2 (\"plankt\u00f3s\"), meaning \"drifter, wanderer, roamer\", and thus, \"animal drifter\". Plankton are aquatic organisms that are unable to swim effectively against currents. Consequently, they drift or are carried along by currents in the ocean, or by currents in seas, lakes or rivers.\nZooplankton can be contrasted with phytoplankton (cyanobacteria and microalgae), which are the plant-like component of the plankton community (the \"phyto-\" prefix comes from , although taxonomically \"not\" plants). Zooplankton are heterotrophic (other-feeding), whereas phytoplankton are autotrophic (self-feeding), often generating biological energy and macromolecules through chlorophyllic carbon fixation using sunlight\u00a0\u2013 in other words, zooplankton cannot manufacture their own food, while phytoplankton can. As a result, zooplankton must acquire nutrients by feeding on other organisms such as phytoplankton, which are generally smaller than zooplankton. Most zooplankton are microscopic but some (such as jellyfish) are macroscopic, meaning they can be seen with the naked eye.\nMany protozoans (single-celled protists that prey on other microscopic life) are zooplankton, including zooflagellates, foraminiferans, radiolarians, some dinoflagellates and marine microanimals. Macroscopic zooplankton include pelagic cnidarians, ctenophores, molluscs, arthropods and tunicates, as well as planktonic arrow worms and bristle worms.\nThe distinction between autotrophy and heterotrophy often breaks down in very small organisms. Recent studies of marine microplankton have indicated over half of microscopic plankton are mixotrophs, which can obtain energy and carbon from a mix of internal plastids and external sources. Many marine microzooplankton are mixotrophic, which means they could also be classified as phytoplankton.\nOverview.\nZooplankton (; ) are heterotrophic (sometimes detritivorous) plankton. The word \"zooplankton\" is derived from ; and .\nZooplankton is a categorization spanning a range of organism sizes including small protozoans and large metazoans. It includes holoplanktonic organisms whose complete life cycle lies within the plankton, as well as meroplanktonic organisms that spend part of their lives in the plankton before graduating to either the nekton or a sessile, benthic existence. Although zooplankton are primarily transported by ambient water currents, many have locomotion, used to avoid predators (as in diel vertical migration) or to increase prey encounter rate.\nJust as any species can be limited within a geographical region, so are zooplankton. However, species of zooplankton are not dispersed uniformly or randomly within a region of the ocean. As with phytoplankton, 'patches' of zooplankton species exist throughout the ocean. Though few physical barriers exist above the mesopelagic, specific species of zooplankton are strictly restricted by salinity and temperature gradients, while other species can withstand wide temperature and salinity gradients. Zooplankton patchiness can also be influenced by biological factors, as well as other physical factors. Biological factors include breeding, predation, concentration of phytoplankton, and vertical migration. The physical factor that influences zooplankton distribution the most is mixing of the water column (upwelling and downwelling along the coast and in the open ocean) that affects nutrient availability and, in turn, phytoplankton production.\nThrough their consumption and processing of phytoplankton and other food sources, zooplankton play a role in aquatic food webs, as a resource for consumers on higher trophic levels (including fish), and as a conduit for packaging the organic material in the biological pump. Since they are typically small, zooplankton can respond rapidly to increases in phytoplankton abundance, for instance, during the spring bloom. Zooplankton are also a key link in the biomagnification of pollutants such as mercury.\nEcologically important protozoan zooplankton groups include the foraminiferans, radiolarians and dinoflagellates (the last of these are often mixotrophic). Important metazoan zooplankton include cnidarians such as jellyfish and the Portuguese Man o' War; crustaceans such as cladocerans, copepods, ostracods, isopods, amphipods, mysids and krill; chaetognaths (arrow worms); molluscs such as pteropods; and chordates such as salps and juvenile fish. This wide phylogenetic range includes a similarly wide range in feeding behavior: filter feeding, predation and symbiosis with autotrophic phytoplankton as seen in corals. Zooplankton feed on bacterioplankton, phytoplankton, other zooplankton (sometimes cannibalistically), detritus (or marine snow) and even nektonic organisms. As a result, zooplankton are primarily found in surface waters where food resources (phytoplankton or other zooplankton) are abundant.\nZooplankton can also act as a disease reservoir. Crustacean zooplankton have been found to house the bacterium \"Vibrio cholerae\", which causes cholera, by allowing the cholera vibrios to attach to their chitinous exoskeletons. This symbiotic relationship enhances the bacterium's ability to survive in an aquatic environment, as the exoskeleton provides the bacterium with carbon and nitrogen.\nSize classification.\nBody size has been defined as a \"master trait\" for plankton as it is a morphological characteristic shared by organisms across taxonomy that characterises the functions performed by organisms in ecosystems. It has a paramount effect on growth, reproduction, feeding strategies and mortality. One of the oldest manifestations of the biogeography of traits was proposed over 170 years ago, namely Bergmann's rule, in which field observations showed that larger species tend to be found at higher, colder latitudes.\nIn the oceans, size is critical in determining trophic links in planktonic ecosystems and is thus a critical factor in regulating the efficiency of the biological carbon pump. Body size is sensitive to changes in temperature due to the thermal dependence of physiological processes. The plankton is mainly composed of ectotherms which are organisms that do not generate sufficient metabolic heat to elevate their body temperature, so their metabolic processes depends on external temperature. Consequently, ectotherms grow more slowly and reach maturity at a larger body size in colder environments, which has long puzzled biologists because classic theories of life-history evolution predict smaller adult sizes in environments delaying growth. This pattern of body size variation, known as the temperature-size rule (TSR), has been observed for a wide range of ectotherms, including single-celled and multicellular species, invertebrates and vertebrates.\nThe processes underlying the inverse relationship between body size and temperature remain to be identified. Despite temperature playing a major role in shaping latitudinal variations in organism size, these patterns may also rely on complex interactions between physical, chemical and biological factors. For instance, oxygen supply plays a central role in determining the magnitude of ectothermic temperature-size responses, but it is hard to disentangle the relative effects of oxygen and temperature from field data because these two variables are often strongly inter-related in the surface ocean.\nZooplankton can be broken down into size classes which are diverse in their morphology, diet, feeding strategies, etc. both within classes and between classes:\nMicrozooplankton.\nMicrozooplankton are defined as heterotrophic and mixotrophic plankton. They primarily consist of phagotrophic protists, including ciliates, dinoflagellates, and mesozooplankton nauplii. Microzooplankton are major grazers of the plankton community. As the primary consumers of marine phytoplankton, microzooplankton consume ~\u200959\u201375% daily of the marine primary production, much larger than mesozooplankton. That said, macrozooplankton can sometimes have greater consumption rates in eutrophic ecosystems because the larger phytoplankton can be dominant there. Microzooplankton are also pivotal regenerators of nutrients which fuel primary production and food sources for metazoans.\nDespite their ecological importance, microzooplankton remain understudied. Routine oceanographic observations seldom monitor microzooplankton biomass or herbivory rate, although the dilution technique, an elegant method of measuring microzooplankton herbivory rate, has been developed for over four decades (Landry and Hassett 1982). The number of observations of microzooplankton herbivory rate is around 1600 globally, far less than that of primary productivity (&gt;\u200950,000). This makes validating and optimizing the grazing function of microzooplankton difficult in ocean ecosystem models.\nMesozooplankton.\nMesozooplankton are one of the larger size classes of zooplankton. In most regions, mesozooplankton are dominated by copepods, such as Calanus finmarchicus and Calanus helgolandicus. Mesozooplankton are an important prey for fish.\nAs plankton are rarely fished, it has been argued that mesoplankton abundance and species composition can be used to study marine ecosystems' response to climate change. This is because they have life cycles that generally last less than a year, meaning they respond to climate changes between years. Sparse, monthly sampling will still indicate vacillations.\nTaxonomic groups.\nProtozooplankton.\nProtozooplankton refers to protist zooplankton (planktonic protozoans). All protozooplankton are protozoans, but not all protozoans are protozooplankton, since some live in environments like soil or as parasites. Marine planktonic protozoans include zooflagellates, foraminiferans, radiolarians and some dinoflagellates.\nProtozoans are protists that feed on organic matter such as other microorganisms or organic tissues and debris. Historically, the protozoa were regarded as \"one-celled animals\", because they often possess animal-like behaviours, such as motility and predation, and lack a cell wall, as found in plants and many algae. Although the traditional practice of grouping protozoa with animals is no longer considered valid, the term continues to be used in a loose way to identify single-celled organisms that can move independently and feed by heterotrophy.\nRadiolarians.\nRadiolarians are unicellular predatory protists encased in elaborate globular shells usually made of silica and pierced with holes. Their name comes from the Latin for \"radius\". They catch prey by extending parts of their body through the holes. As with the silica frustules of diatoms, radiolarian shells can sink to the ocean floor when radiolarians die and become preserved as part of the ocean sediment. These remains, as microfossils, provide valuable information about past oceanic conditions.\nForaminiferans.\nLike radiolarians, foraminiferans (\"forams\" for short) are single-celled predatory protists, also protected with shells that have holes in them. Their name comes from the Latin for \"hole bearers\". Their shells, often called tests, are chambered (forams add more chambers as they grow). The shells are usually made of calcite, but are sometimes made of agglutinated sediment particles or chiton, and (rarely) silica. Most forams are benthic, but about 40 species are planktic. They are widely researched with well-established fossil records which allow scientists to infer a lot about past environments and climates.\nDinoflagellates.\nDinoflagellates are a phylum of unicellular flagellates with about 2,000 marine species. Some dinoflagellates are predatory, and thus belong to the zooplankton community. Their name comes from the Greek \"dinos\" meaning \"whirling\" and the Latin \"flagellum\" meaning a \"whip\" or \"lash\". This refers to the two whip-like attachments (flagella) used for forward movement. Most dinoflagellates are protected with red-brown, cellulose armour. Excavates may be the most basal flagellate lineage.\nDinoflagellates often live in symbiosis with other organisms. Many nassellarian radiolarians house dinoflagellate symbionts within their tests. The nassellarian provides ammonium and carbon dioxide for the dinoflagellate, while the dinoflagellate provides the nassellarian with a mucous membrane useful for hunting and protection against harmful invaders. There is evidence from DNA analysis that dinoflagellate symbiosis with radiolarians evolved independently from other dinoflagellate symbioses, such as with foraminifera.\nMixoplankton.\nMixoplankton are mixotrophic plankton, capable of both photosynthesis and predation. A mixotroph is an organism that can use a mix of different sources of energy and carbon, instead of having a single trophic mode on the continuum from complete autotrophy at one end to heterotrophy at the other. It is estimated that mixotrophs comprise more than half of all microscopic plankton. There are two types of eukaryotic mixotrophs: those with their own chloroplasts, and those with endosymbionts\u2014and others that acquire them through kleptoplasty or by enslaving the entire phototrophic cell.\nThe distinction between plants and animals often breaks down in very small organisms. Possible combinations are photo- and chemotrophy, litho- and organotrophy, auto- and heterotrophy or other combinations of these. Mixotrophs can be either eukaryotic or prokaryotic. They can take advantage of different environmental conditions.\nMany marine microzooplankton are mixotrophic, which means they could also be classified as phytoplankton. Recent studies of marine microzooplankton found 30\u201345% of the ciliate abundance was mixotrophic, and up to 65% of the amoeboid, foram and radiolarian biomass was mixotrophic.\n\"Phaeocystis\" species are endosymbionts to acantharian radiolarians. \"Phaeocystis\" is an important algal genus found as part of the marine phytoplankton around the world. It has a polymorphic life cycle, ranging from free-living cells to large colonies. It has the ability to form floating colonies, where hundreds of cells are embedded in a gel matrix, which can increase massively in size during blooms. As a result, \"Phaeocystis\" is an important contributor to the marine carbon and sulfur cycles.\nA number of forams are mixotrophic. These have unicellular algae as endosymbionts, from diverse lineages such as the green algae, red algae, golden algae, diatoms, and dinoflagellates. Mixotrophic foraminifers are particularly common in nutrient-poor oceanic waters. Some forams are kleptoplastic, retaining chloroplasts from ingested algae to conduct photosynthesis.\nBy trophic orientation, dinoflagellates are all over the place. Some dinoflagellates are known to be photosynthetic, but a large fraction of these are in fact mixotrophic, combining photosynthesis with ingestion of prey (phagotrophy). Some species are endosymbionts of marine animals and other protists, and play an important part in the biology of coral reefs. Others predate other protozoa, and a few forms are parasitic. Many dinoflagellates are mixotrophic and could also be classified as phytoplankton. The toxic dinoflagellate \"Dinophysis acuta\" acquire chloroplasts from its prey. \"It cannot catch the cryptophytes by itself, and instead relies on ingesting ciliates such as the red \"Myrionecta rubra\", which sequester their chloroplasts from a specific cryptophyte clade (Geminigera/Plagioselmis/Teleaulax)\".\nPlanktonic metazoa (animals).\nFree-living species in the crustacean class Copepoda are typically 1 to 2\u00a0mm long with teardrop-shaped bodies. Like all crustaceans, their bodies are divided into three sections: head, thorax, and abdomen, with two pairs of antennae; the first pair is often long and prominent. They have a tough exoskeleton made of calcium carbonate and usually have a single red eye in the centre of their transparent head. About 13,000 species of copepods are known, of which about 10,200 are marine. They are usually among the more dominant members of the zooplankton.\nIn addition to copepods the crustacean classes ostracods, branchiopods and malacostracans also have planktonic members. Barnacles are planktonic only during the larval stage.\nIchthyoplankton.\nIchthyoplankton are the eggs and larvae of fish (\"ichthyo\" comes from the Greek word for \"fish\"). They are planktonic because they cannot swim effectively under their own power, but must drift with the ocean currents. Fish eggs cannot swim at all, and are unambiguously planktonic. Early stage larvae swim poorly, but later stage larvae swim better and cease to be planktonic as they grow into juvenile fish. Fish larvae are part of the zooplankton that eat smaller plankton, while fish eggs carry their own food supply. Both eggs and larvae are themselves eaten by larger animals.\nGelatinous zooplankton.\nGelatinous zooplankton include ctenophores, medusae, salps, and Chaetognatha in coastal waters. Jellyfish are slow swimmers, and most species form part of the plankton. Traditionally jellyfish have been viewed as trophic dead ends, minor players in the marine food web, gelatinous organisms with a body plan largely based on water that offers little nutritional value or interest for other organisms apart from a few specialised predators such as the ocean sunfish and the leatherback sea turtle.\nThat view has recently been challenged. Jellyfish, and more gelatinous zooplankton in general, which include salps and ctenophores, are very diverse, fragile with no hard parts, difficult to see and monitor, subject to rapid population swings and often live inconveniently far from shore or deep in the ocean. It is difficult for scientists to detect and analyse jellyfish in the guts of predators, since they turn to mush when eaten and are rapidly digested. But jellyfish bloom in vast numbers, and it has been shown they form major components in the diets of tuna, spearfish and swordfish as well as various birds and invertebrates such as octopus, sea cucumbers, crabs and amphipods. \"Despite their low energy density, the contribution of jellyfish to the energy budgets of predators may be much greater than assumed because of rapid digestion, low capture costs, availability, and selective feeding on the more energy-rich components. Feeding on jellyfish may make marine predators susceptible to ingestion of plastics.\" According to a 2017 study, narcomedusae consume the greatest diversity of mesopelagic prey, followed by physonect siphonophores, ctenophores and cephalopods.\nThe importance of the so-called \"jelly web\" is only beginning to be understood, but it seems medusae, ctenophores and siphonophores can be key predators in deep pelagic food webs with ecological impacts similar to predator fish and squid. Traditionally gelatinous predators were thought ineffectual providers of marine trophic pathways, but they appear to have substantial and integral roles in deep pelagic food webs.\nRole in food webs.\nGrazing by single-celled zooplankton accounts for the majority of organic carbon loss from marine primary production. However, zooplankton grazing remains one of the key unknowns in global predictive models of carbon flux, the marine food web structure and ecosystem characteristics, because empirical grazing measurements are sparse, resulting in poor parameterisation of grazing functions. To overcome this critical knowledge gap, it has been suggested that a focused effort be placed on the development of instrumentation that can link changes in phytoplankton biomass or optical properties with grazing.\nGrazing is a central, rate-setting process in ocean ecosystems and a driver of marine biogeochemical cycling. In all ocean ecosystems, grazing by heterotrophic protists constitutes the single largest loss factor of marine primary production and alters particle size distributions. Grazing affects all pathways of export production, rendering grazing important both for surface and deep carbon processes. Predicting central paradigms of ocean ecosystem function, including responses to environmental change requires accurate representation of grazing in global biogeochemical, ecosystem and cross-biome-comparison models. Several large-scale analyses have concluded that phytoplankton losses, which are dominated by grazing are the putative explanation for annual cycles in phytoplankton biomass, accumulation rates and export production.\nRole in biogeochemistry.\nIn addition to linking primary producers to higher trophic levels in marine food webs, zooplankton also play an important role as \"recyclers\" of carbon and other nutrients that significantly impact marine biogeochemical cycles, including the biological pump. This is particularly important in the oligotrophic waters of the open ocean. Through sloppy feeding, excretion, egestion, and leaching of fecal pellets, zooplankton release dissolved organic matter (DOM) which controls DOM cycling and supports the microbial loop. Absorption efficiency, respiration, and prey size all further complicate how zooplankton are able to transform and deliver carbon to the deep ocean.\nSloppy feeding and release of DOM.\nExcretion and sloppy feeding (the physical breakdown of food source) make up 80% and 20% of crustacean zooplankton-mediated DOM release respectively. In the same study, fecal pellet leaching was found to be an insignificant contributor. For protozoan grazers, DOM is released primarily through excretion and egestion and gelatinous zooplankton can also release DOM through the production of mucus. Leaching of fecal pellets can extend from hours to days after initial egestion and its effects can vary depending on food concentration and quality. Various factors can affect how much DOM is released from zooplankton individuals or populations. Absorption efficiency (AE) is the proportion of food absorbed by plankton that determines how available the consumed organic materials are in meeting the required physiological demands. Depending on the feeding rate and prey composition, variations in AE may lead to variations in fecal pellet production, and thus regulates how much organic material is recycled back to the marine environment. Low feeding rates typically lead to high AE and small, dense pellets, while high feeding rates typically lead to low AE and larger pellets with more organic content. Another contributing factor to DOM release is respiration rate. Physical factors such as oxygen availability, pH, and light conditions may affect overall oxygen consumption and how much carbon is loss from zooplankton in the form of respired CO2. The relative sizes of zooplankton and prey also mediate how much carbon is released via sloppy feeding. Smaller prey are ingested whole, whereas larger prey may be fed on more \"sloppily\", that is more biomatter is released through inefficient consumption. There is also evidence that diet composition can impact nutrient release, with carnivorous diets releasing more dissolved organic carbon (DOC) and ammonium than omnivorous diets.\nCarbon export.\nZooplankton play a critical role in supporting the ocean's biological pump through various forms of carbon export, including the production of fecal pellets, mucous feeding webs, molts, and carcasses. Fecal pellets are estimated to be a large contributor to this export, with copepod size rather than abundance expected to determine how much carbon actually reaches the ocean floor. The importance of fecal pellets can vary both by time and location. For example, zooplankton bloom events can produce larger quantities of fecal pellets, resulting in greater measures of carbon export. Additionally, as fecal pellets sink, they are reworked by microbes in the water column, which can thus alter the carbon composition of the pellet. This affects how much carbon is recycled in the euphotic zone and how much reaches depth. Fecal pellet contribution to carbon export is likely underestimated; however, new advances in quantifying this production are currently being developed, including the use of isotopic signatures of amino acids to characterize how much carbon is being exported via zooplankton fecal pellet production. Carcasses are also gaining recognition as being important contributors to carbon export. Jelly falls \u2013 the mass sinking of gelatinous zooplankton carcasses \u2013 occur across the world as a result of large blooms. Because of their large size, these gelatinous zooplankton are expected to hold a larger carbon content, making their sinking carcasses a potentially important source of food for benthic organisms.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50559", "revid": "48736052", "url": "https://en.wikipedia.org/wiki?curid=50559", "title": "Albany County, New York", "text": "County in New York, United States\nAlbany County ( ) is a county in the state of New York, United States. Its northern border is formed by the Mohawk River, at its confluence with the Hudson River, which is to the east. As of the 2020 United States Census, the population was 314,848. The county seat and largest city is Albany, which is also the state capital of New York. As originally established by the English government in the colonial era, Albany County had an indefinite amount of land, but has had an area of since March 3, 1888. The county is named for the Duke of York and of Albany, who became James II of England (James VII of Scotland). The county is part of the Capital District region of the state.\nHistory.\nColonial.\nAfter England took control of the colony of New Netherland from the Dutch, Albany County was created on November 1, 1683, by New York Governor Thomas Dongan, and confirmed on October 1, 1691. The act creating the county vaguely defined its territory \"to containe the Towns of Albany, the \"Collony\" Rensselaerwyck, Schonecteda, and all the villages, neighborhoods, and Christian \"Planta\u00e7ons\" on the east side of Hudson River from Roelef's Creek, and on the west side from Sawyer's Creek (Saugerties) to the Sarraghtoga.\" The confirmation declared in 1691 was similar but omitted the Town of Albany, substituted \"\"Mannor\" of Ranselaerswyck\" for \"\"Collony\" Rensselaerwyck\", and stated \"to the uttermost end of Sarraghtoga\" instead of just \"to Sarraghtoga\". Livingston Manor was annexed to Albany County from Dutchess County in 1717.\nAlbany's boundaries were defined more closely as state statutes would add land to the county, or more commonly subtract land for the formation of new counties. In 1772 with the creation of Tryon and Charlotte counties, Albany gained definitive boundaries and included what are now Albany, Columbia, Rensselaer, Saratoga, and Schenectady counties; large parts of Greene and Washington counties; and the disputed southwest corner of Vermont.\nThe city of Albany was the first municipality within this large county, founded as the village (dorp in Dutch) of Beverwyck by the Director-General of New Amsterdam, Pieter Stuyvesant, who also established the first court in Albany. Albany was established as a city in 1686 by Governor Dongan through the Dongan Charter after the English took over the colony. Schenectady to the west was given a patent with some municipal rights in 1684 and became a borough in 1765.\nThe Manor of Rensselaerswyck was created as a district within the county in 1772, and later divided into two districts, one on each side of the Hudson River in 1779. The west district included all of what is now Albany County other than lands were in the city of Albany at the time. Though the Manor of Rensselaerswyck was the only district (along with the city of Albany) in what is today Albany County, it was not the only district in what was Albany County at the time. Pittstown in 1761, and Duanesburgh in 1764, were created as townships. But when districts were created in 1772, those townships were incorporated into new districts, Pittstown in Schaghticoke and Duanesburgh into the United Districts of Duanesburgh and Schoharie. Schenectady was also made from a borough to a district in 1772. Other districts established in 1772 were Hoosick, Coxsackie, Cambridge, Saratoga, Halfmoon, Kinderhook, Kings, Claverack, Great Imboght, and the Manor of Livingston.\nIn a census of 1697, there were 1,452 individuals living in Albany County; two years later it would be counted as 2,016 at the beginning of King William's War. By the end of the war in 1698, the population had dropped to 1,482, but rebounded quickly and was at 2,273 by 1703. By 1723, it had increased to 6,501 and in 1731 to 8,573, which was slightly less than the population of the city of New York in the same year. In 1737, the inhabitants of Albany County would outnumber those of New York County by 17 people. In 1774, Albany County, with 42,706 people, was the largest county in colonial New York. According to the first Federal Census in 1790, Albany County reached 75,921 inhabitants and was still the state's largest county.\nFormation of towns.\nOn March 7, 1788, the state of New York divided the entire state into towns eliminating districts as administrative units by passing New York Laws of 1788, Chapters 63 and 64.\nTimeline of boundary changes.\nAlbany County was one of the original twelve counties created by the Province of New York on November 1, 1683. At the time, it included all of New York state north of Dutchess and Ulster counties, all of what is now Bennington County in Vermont.\nOn May 27, 1717, Albany County was adjusted to gain an indefinite amount of land from Dutchess County and other non-county lands.\nOn October 7, 1763, King George III, as part of his Proclamation of 1763, created the new province of Quebec, implicitly setting the northern limit of New York at the parallel of 45 degrees north latitude from the Atlantic-St. Lawrence watershed westward to the St. Lawrence River, implicitly setting the northern limit of Albany County, but it was never mapped.\nOn July 20, 1764, King George III established the boundary between New Hampshire and New York along the west bank of the Connecticut River, north of Massachusetts and south of the parallel of 45 degrees north latitude. Albany County implicitly gained present-day Vermont. Although disputes occasionally broke out later, this line became the boundary between New Hampshire and Vermont, and has remained unchanged to the present. When New York refused to recognize land titles through the New Hampshire Grants (towns created earlier by New Hampshire in present Vermont), dissatisfied colonists organized in opposition, which led to the creation of independent Vermont in 1777.\nOn July 3, 1766, Cumberland County was partitioned from Albany County to cover all territory to the northern and eastern limits of the colony, including Windsor County, most of Windham County, and parts of Bennington and Rutland counties in present-day Vermont.\nOn June 26, 1767, Albany County regained all of Cumberland County.\nOn March 19, 1768, Albany County was re-partitioned, and Cumberland County restored.\nOn March 16, 1770, Albany County was again partitioned. Gloucester County was created to include all of Orange, Caledonia and Essex counties, most of Washington County, and parts of Orleans, Lamoille, Addison and Chittenden counties in present-day Vermont.\nOn March 12, 1772, Albany County was partitioned again, this time into the counties of Albany, Tryon (now Montgomery), and Charlotte (now Washington). This established a definite area for Albany County of .\nOn March 24, 1772, Albany County was partitioned again, with an additional handed over to Cumberland County.\nOn March 9, 1774, Albany County was partitioned again, this time passing to Ulster County.\nOn April 1, 1775, Albany was again partitioned, this time giving up to Charlotte County, who then exchanged this land with a like parcel in Cumberland County.\nOn January 15, 1777, Albany County was again partitioned, this time on account of the independence of Vermont from New York, reducing Albany County by an additional .\nOn June 26, 1781, Bennington County, Vermont, attempted to annex a portion of Albany County that today includes portions of Washington and Rensselaer counties to form what they called \"The West Union\". The fledgling United States \u2013 under the Articles of Confederation \u2013 arbitrated this annexation, and condemned it, resulting in Vermont ceasing the annexation on 1782-02-23.\nOn April 4, 1786, Columbia County was created from of Albany County land.\nOn March 7, 1788, New York, refusing to recognize the independence of Vermont, and the attendant elimination of Cumberland County, attempted to adjust the line that separated Cumberland from Albany County in present-day Vermont, but to no effect.\nOn February 7, 1791, Albany County was partitioned again, this time to form Rensselaer and Saratoga counties. Rensselaer received , while Saratoga received . Also the town of Cambridge was transferred to Washington County. A total of changed hands.\nOn June 1, 1795, Albany County was once again partitioned, this time losing to Schoharie County.\nOn April 5, 1798, another partition took place, with passing to Ulster County.\nOn March 25, 1800, once again Albany County was partitioned, with being used to create Greene County.\nOn April 3, 1801, all New York counties were redefined, with Albany County gaining .\nOn March 7, 1809, Schenectady County was created from of Albany County land, reducing Albany County to its current size.\nOn March 3, 1888, Albany County ceded Havre Island to Saratoga County.\nGeography.\nAccording to the U.S. Census Bureau, the county has an area of , of which is land and (2.0%) is water.\nAlbany County is in east central New York, extending southward and westward from where the Mohawk River joins the Hudson River. Its eastern boundary is the Hudson; a portion of its northern boundary is the Mohawk.\nThe terrain of the county ranges from flat near the Hudson and Mohawk Rivers to high and hilly to the southwest, of the Helderberg Escarpment and the Helderberg Mountains. The highest point is one of several summits near Henry Hill at approximately above sea level; The lowest point is above sea level at the Hudson River's southernmost extent in the county.\nClimate.\nThe Capital District has a humid continental climate, with cold, snowy winters, and hot, wet summers. Albany receives around of rain per year, with 135 days of at least of precipitation. Snowfall is significant, totaling about annually, but with less accumulation than the lake-effect areas to the north and west, being far enough from Lake Ontario. Albany County is however, close enough to the coast to receive heavy snow from Nor'easters, and the region gets the bulk of its yearly snowfall from these types of storms. The county also occasionally receives Alberta clippers. Winters are often very cold with fluctuating conditions, temperatures often drop to below at night. Summers in the Albany can contain stretches of excessive heat and humidity, with temperatures above\u00a0 and dew points near 70. Severe thunderstorms are common but tornadoes are rare. Albany receives on average per year 69 sunny days, 111 partly cloudy days, and 185 cloudy days; and an average, over the course of a year, of less than four hours of sunshine per day, with just over an average of 2.5 hours per day over the course of the winter. The chance during daylight hours of sunshine is 53%, with the highest percentage of sunny daylight hours being in July with 64%, and the lowest month is November with 37%.\nAdjacent counties.\nAlbany County is bordered by six counties. Listed clockwise, they are:\nCityscape.\nArchitecture.\nAlbany County has myriad different architectural styles spanning centuries of development. Within the city of Albany alone there is Dutch Colonial (the Quackenbush House), French Renaissance (the New York State Capitol), Federal style (the original Albany Academy in Academy Park), Romanesque Revival (Albany City Hall), Art deco (the Alfred E. Smith Building), and Modern (Empire State Plaza). The cities of Albany, Cohoes, and Watervliet and the village of Green Island are more urban in architecture; while the towns of Colonie, Guilderland, New Scotland, and Bethlehem more suburban and the remaining Hilltowns (Berne, Knox, Westerlo, and Rensselaerville) very rural.\nParks.\nAlbany County is home to the Emma Treadwell Thacher Nature Center, which opened in July 2001 and is near the shore of Thompson's Lake between the two state parks that are in Albany County- Thompson's Lake State Park and John Boyd Thacher State Park. There are also state-owned nature preserves with interactive educational programs such as the Five Rivers Environmental Education Center and the Albany Pine Bush. The cities, towns, and villages of Albany County have many municipal parks, playgrounds, and protected green areas. Washington Park in the city of Albany and The Crossing in the town of Colonie are two of the largest. There are many small hiking and biking trails and longer distance bike-hike trails such the Mohawk-Hudson Bike-Hike Trail which goes from the city of Albany north to Cohoes and then west along the Mohawk River to Schenectady County.\nFestivals.\nOne of the largest events in Albany County is the Tulip Fest held in the city of Albany every spring at Washington Park. The tradition stems from when Mayor Erastus Corning 2nd had a city ordinance passed declaring the tulip as Albany's official flower on July 1, 1948. The African-American tradition of Pinksterfest, whose origins are traced back even further to Dutch festivities, was later incorporated into the Tulip Fest. The Albany LatinFest has been held since 1996 and drew 10,000 to Washington Park in 2008. PolishFest is a three-day celebration of Polish culture in the Capital District, held in the town of Colonie for the past eight years.\nAmusement.\nAlbany County has two shopping malls classified as super-regional malls (malls with over 800,000 sq ft), Crossgates Mall in Guilderland and Colonie Center in Colonie with over one million square feet of rentable space in each. Huck Finn's Playland is a children's amusement park open during the summer, which started operations in the Summer of 2015\u2014after purchasing the rides from the former Hoffman's Playland in Newtonville, which was in operation from 1951 to the Fall of 2014. During the winter there are over of official trails for snowshoeing at the Albany Pine Bush Preserve, in the city of Albany and towns of Colonie and Guilderland.\nMuseums.\nAlbany County has many historical sites and museums covering a wide range of topics and time periods. The Albany Institute of History and Art, founded in 1791, is one of the oldest museums in the United States, and the New York State Museum is the country's oldest and largest state museum. Many of the museums are historical sites themselves, such as Cherry Hill, the Ten Broeck Mansion, and the Schuyler Mansion in the city of Albany and the Pruyn House in Colonie. The Quackenbush House is the second oldest house in Albany and part of the Albany Heritage Area Visitors Center, which includes a planetarium. The Albany Pine Bush Discovery Center in Albany includes hands-on activities to learn about the unique Pine Bush Barrens of the Albany, Guilderland, and Colonie. Covering the history of pharmacy is the Throop Drug Store Museum at the Albany College of Pharmacy. The USS Slater, DE-766 is a World War II Destroyer Escort, the last floating Destroyer Escort, owned by the Destroyer Escort Historical Museum is moored from Spring to Fall at the foot of Quay Street in the Hudson River. The ship is open for tours each week and has a well-maintained collection of World War II US Naval artifacts.\nThere are several art museums in Albany County: the Albany Center Gallery, in downtown Albany, which exhibits works by local artists within a radius of that city; the University Art Museum, at the University at Albany, SUNY; and the Opalka Gallery, at the Sage College of Albany. The Empire State Plaza in Albany has one of the most important state collections of modern art in the U.S.\nPerforming arts.\nAlbany County itself owns the largest venue for performing arts in the county, the Times Union Center, which was originally built as the Knickerbocker Arena; it opened on January 30, 1990, with a performance by Frank Sinatra. In 1996, The Grateful Dead released a concert album from their March 1990 performances titled \"Dozin' at the Knick\".\nSports.\nMany athletes and coaches in major sports have begun their careers in Albany County. Phil Jackson, former NBA head coach of the Chicago Bulls and Los Angeles Lakers won his first championship ring as a coach when he guided the Albany Patroons to the 1984 CBA championship. Three years later, the Patroons completed a 50\u20136 regular season, including winning all 28 of their home games; at that time, Sacramento Kings head coach George Karl was the Patroons' head coach. Future NBA stars Mario Elie and Vincent Askew were part of that season's squad. Mike Tyson received his early training in the Capital District and his first professional fight was in Albany in 1985 and Tyson's first televised fight was in Troy in 1986. He fought professionally four times in Albany and twice each in Troy and Glens Falls between 1985 and 1986.\nSince 1988, the Siena College men's basketball team (the Siena Saints) have appeared in six NCAA Tournaments (1989, 1999, 2002, 2008, 2009, and 2010).\nReligious life.\nAlbany County was originally settled primarily by Protestants from northern Europe: the Netherlands, British Isles, and Germany. In the 19th century it was a destination for many Catholic immigrants, first from Ireland\u2014fleeing the Great Famine\u2014and later from southern Germany and central and southern Europe. Late 19th- and early 20th-century immigrants included Jews from eastern Europe. In addition to other Jewish congregations, the county has one of the few Karaite Jewish communities outside Israel. This community is active and has its own synagogue. The Albany Metro Area has consistently been found to be among the highest ranking postchristian cities in the US.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2020 census.\nAs of the 2020 US Census, there were 314,848 people in 126,540 households residing in the county. The population density was . There were 134,072 housing units at an average density of . The racial makeup of the county was 78.2% White, 12.7% Black or African American, 0.2% Native American, 4.8% Asian, 0.0% Pacific Islander, 1.6% from other races, and 2.5% from two or more races. 4.9% of the population were Hispanic or Latino of any race. 19.2% were of Irish, 16.0% Italian, 11.0% German, 6.1% English and 5.1% Polish ancestry according to Census 2000. 90.4% spoke English, 2.7% Spanish and 1.0% Italian as their first language.\nThere were 124,682 households, out of which 28.9% had children under the age of 18 living with them, 43.2% were married couples living together, 12.2% had a female householder with no husband present, and 41.1% were non-families. 33.0% of all households were made up of individuals, and 11.3% had someone living alone who was 65 years of age or older. The average household size was 2.32 and the average family size was 2.99.\nIn the county, the age distribution of the population shows 22.6% under the age of 18, 11.3% from 18 to 24, 28.8% from 25 to 44, 22.8% from 45 to 64, and 14.5% who were 65 years of age or older. The median age was 37 years. For every 100 females there were 91.7 males. For every 100 females age 18 and over, there were 87.8 males.\nThe median income for a household in the county was $42,935, and the median income for a family was $56,724. Males had a median income of $39,838 versus $30,127 for females. The per capita income for the county was $23,345. About 7.2% of families and 13.1% of the population were below the poverty line, including 14.9% of those under age 18 and 6.3% of those age 65 or over.\nEconomy.\nTech Valley.\nSince the 2000s, the economy of Albany County and the surrounding Capital District has been redirected toward high technology. Tech Valley is a marketing name for the eastern part of New York State, encompassing Albany County, the Capital District, and the Hudson Valley. Originated in 1998 to promote the greater Albany area as a high-tech competitor to regions such as Silicon Valley and Boston, it has since grown to represent the counties in the Capital District and extending to IBM's Westchester County plants in the south and the Canada\u2013US border to the north. The area's high technology ecosystem is supported by technologically focused academic institutions including Rensselaer Polytechnic Institute and the State University of New York Polytechnic Institute. Tech Valley encompasses 19 counties straddling both sides of the Adirondack Northway and the New York Thruway, and with heavy state taxpayer subsidy, has experienced significant growth in the computer hardware side of the high-technology industry, with great strides in the nanotechnology sector, digital electronics design, and water- and electricity-dependent integrated microchip circuit manufacturing.\nGovernment and politics.\nFor most of its history, Albany County has predominantly backed Democratic Party presidential candidates. In only three elections since 1924 has a Republican Party candidate carried the county in a presidential election, the most recent being Richard Nixon in 1972. The Democratic Party dominance has become more pronounced in recent years, with George H. W. Bush in 1988 the most recent Republican candidate to win even forty percent of the county's vote.\nAlbany County was governed by a board of supervisors until 1968. The board consisted of the town supervisors of each town in the county, as well as county supervisors elected from the wards of each city in the county. In the later years of its existence, the board used a system of weighted voting to comply with recently enacted federal and state proportional representation requirements. On January 1, 1976, Albany County government was changed by a new charter establishing a county executive elected at-large, in addition to the 39-seat county legislature. In the first election for county executive, Democratic nominee James J. Coyne Jr., who was then serving as county clerk, defeated Liberal nominee Theresa Cooke, county treasurer and a critic of the county and city Democratic machine run by Daniel P. O'Connell, and Republican nominee Almerin C. O'Hara, former state Commissioner of the Office of General Services. Each of the 39 legislators are elected from single-member districts. As of 2023, the county legislature has 29 Democrats, 10 Republicans.\nThe County Executive is Daniel P. McCoy. Other officials elected countywide include District Attorney Lee Kindlon, Clerk Bruce A. Hidley, Comptroller Susan A. Rizzo, and Sheriff Craig D. Apple. All county officials are Democrats. Other elected officials with districts in the county include:&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nLaw enforcement.\nThe Albany County Sheriff's Office is one of the oldest law enforcement agencies in the United States, having been established in the 1660s. Sheriff Craig Apple was first elected in 2011.\nThe sheriff is also responsible for the county jail, which was built in 1931, and renamed from the Albany County Correctional Facility to the Albany County Corrections and Rehabilitative Services Center in 2019. It has a contract with New York City to accept prisoners from its facilities. \"The New York Times\" has reported that juveniles sent to Albany were beaten and placed in isolation, which is forbidden in New York City.\nThe department investigated a criminal complaint against Governor Andrew Cuomo during the Andrew Cuomo sexual harassment allegations, and filed a misdemeanor criminal complaint on its own authority to bring charges.\nEducation.\nTertiary.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nK-12 education.\nPublic school districts include:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nTransportation.\nAlbany County has long been at the forefront of transportation technology from the days of turnpikes and plank roads to the Erie Canal, from the first passenger railroad in the state to the oldest municipal airport in the United States. Today, Interstates, Amtrak, and the Albany International Airport continue to make the Albany County a major crossroads of the Northeastern United States.\nThe Capital District Transportation Committee (CDTC) is the Metropolitan Planning Organization (MPO) for the Albany-Schenectady-Troy Metropolitan Statistical Area (MSA). Every metropolitan area in the United States with a population of over 50,000 must have a MPO in order to get any federal transportation funding. The US Department of Transportation (USDOT) uses an MPO to make decisions on what projects are most important to a metro area for immediate versus long term funding. The USDOT will not approve federal funds for transportation projects unless they are on an MPO's list.\nInterstate and other major highways.\nAlbany County is at a major crossroads of the Northeastern United States, first formed by the Mohawk and Hudson rivers. Even before the Interstate Highway System and the U.S. Highway system, Albany County was the hub of many turnpikes and plank roads that connected the region, as well as the Erie Canal reaching the Great Lakes.\nToday, Interstate 87 and Interstate 90 meet in Albany County. The Thomas E. Dewey New York State Thruway is a toll-road that from Exit 24 in the city of Albany is I-87 and travels south to connect the county with downstate New York. West from Exit 24, the Thruway is I-90 and connects the county with Schenectady, Utica, Syracuse, Rochester, and Buffalo.\nNorth of Exit 24, I-87 is the Adirondack Northway and connects the city and county of Albany with their suburbs in Saratoga County and provides long-distance travel to Montreal. East of Exit 24, I-90 travels along the northern boundary of the city of Albany and exits the county on the Patroon Island Bridge into Rensselaer County to access Albany's eastern suburbs. Interstate 787 connects the Thruway (I-87) to Downtown Albany, Menands, Watervliet, and Cohoes. U.S. Route 9 enters the county on the Dunn Memorial Bridge and travels through the city of Albany north, connecting it with the suburbs in the Colonie and Saratoga County. U.S. Route 20 also enters the county on the Dunn Memorial Bridge and travels west through Albany (city) and the Town of Guilderland. New York State Route 5 and New York State Route 7 are two important highways that bisect the county and are developed as important shopping strips.\nMass transit.\nAlbany County is served by the Capital District Transportation Authority, a five-county bus service that also serves Rensselaer, Schenectady, Montgomery and Saratoga counties. Greyhound Lines, Trailways, and Peter Pan Bus Lines buses all serve a downtown terminal. Chinatown bus lines leaves from Central Avenue and provide service to Chinatown, Manhattan.\nAirports.\nAlbany International Airport is the only commercial airport in the county. Destinations for flights out of Albany include Atlanta; Las Vegas; Chicago; Charlotte, North Carolina; and Orlando, Florida, among many others.\nRail.\nSince 1968 when Union Station in the city of Albany was abandoned for a new station across the Hudson in the city of Rensselaer, Albany County has been without a train station. Amtrak has several routes serving the Albany-Rensselaer Station. The Adirondack (north to Montreal, Quebec and south to the city of New York), Empire Service (west to Buffalo and Niagara Falls, south to New York), Ethan Allen Express (northeast to Rutland, Vermont and south to New York), Maple Leaf (west to Toronto and south to New York), and the Lake Shore Limited (at Albany-Rensselaer separate routes from Boston and New York merge to one train west to Chicago, on way east one train splits to two, one east to Boston and another south to New York).\nCommunities.\nAlbany County is composed of three cities and 10 towns.\nTowns.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nHamlets.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50560", "revid": "49636717", "url": "https://en.wikipedia.org/wiki?curid=50560", "title": "Lemures", "text": "Shades or spirits in Roman mythology\nThe were shades or spirits of the restless or malignant dead in Roman religion, sometimes used interchangeably with the term (from Latin , 'mask').\nThe term was first used by the Augustan poet Horace (in Epistles 2.2.209), and was the more common literary term during the Augustan era, with being used only once by Horace. However, is also uncommon: Ovid being the other main figure to employ it, in his \"Fasti\", the six-book calendar poem on Roman holidays and religious customs.\nLater the two terms were used nearly or completely interchangeably, e.g. by St. Augustine in \"De Civitate Dei\".\nThe word can be traced to the Proto-Indo-European stem , which also appears in the name of the Greek monster Lamia.\nDescription.\n\"\" may represent the wandering and vengeful spirits of those not afforded proper burial, funeral rites or affectionate cult by the living: they are thus not attested by tomb or votive inscriptions. Ovid interprets them as vagrant, unsatiated and potentially vengeful \"di manes\" or \"di parentes\", ancestral gods or spirits of the underworld. To him, the rites of their cult suggest an incomprehensibly archaic, quasi-magical and probably very ancient rural tradition.\n' were formless and liminal, associated with darkness and its dread. In Republican and Imperial Rome, May 9, 11, and 13 were dedicated to their placation in the household practices of or \"Lemuria\". The head of household (\"paterfamilias\") would rise at midnight and cast black beans behind him with averted gaze; the ' were presumed to feast on them. Black was the appropriate colour for offerings to chthonic deities. William Warde Fowler interprets the gift of beans as an offer of life, and points out that they were a ritual pollution for priests of Jupiter. The themselves were both fearsome and fearful: any malevolent shades dissatisfied with the offering of the \"paterfamilias\" could be startled into flight by the loud banging of bronze pots.\nIn scientific Latin.\nThe inspired Linnaeus's Modern Latin backformation \"lemur\" (denoting a type of primates). According to Linnaeus' own explanation, the name was selected because of the nocturnal activity and slow movements of the slender loris. Being familiar with the works of Virgil and Ovid and seeing an analogy that fit with his naming scheme, Linnaeus adapted the term \"lemur\" for these nocturnal primates. However, it has been commonly and falsely assumed that Linnaeus was referring to the ghost-like appearance, reflective eyes, and ghostly cries of lemurs. In Goethe's \"Faust\", a chorus of Lemurs who serve Mephistopheles dig Faustus' grave.\nIn the English \"Daemonologie\".\nIn the book by King James I of England, \"Daemonologie, In Forme of a Dialogie, Divided into three Bookes\", it is written:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Nowe I returne to my purpose: As to the first kinde of these spirites, that were called by the auncients by diuers names, according as their actions were. For if they were spirites that haunted some houses, by appearing in diuers and horrible formes, and making greate dinne: they were called or . If they appeared in likenesse of anie defunct to some friends of his, they wer called : And so innumerable stiles they got, according to their actiones, as I haue said alreadie. As we see by experience, how manie stiles they haue given them in our language in the like maner: Of the appearing of these spirites, wee are certified by the Scriptures, [marginal note - \"Esay\". 13. \"Iere\". 50] where the Prophet ESAY 13. and 34. cap. threatening the destruction of \"Babell\" and \"Edom\": declares, that it shal not onlie be wracked, but shall become so greate a solitude, as it shall be the habitackle of Howlettes, and of ZIIM and IIM, which are the proper Hebrewe names for these Spirites. The cause whie they haunte solitarie places, it is by reason, that they may affraie and brangle the more the faith of suche as them alone hauntes such places. For our nature is such, as in companies wee are not so soone mooued to anie such kinde of feare, as being solitare, which the Deuill knowing well inough, hee will not therefore assaile vs but when we are weake: And besides that, GOD will not permit him so to dishonour the societies and companies of Christians, as in publicke times and places to walke visiblie amongst them. On the other parte, when he troubles certaine houses that are dwelt in, it is a sure token either of grosse ignorance, or of some grosse and slanderous sinnes amongst the inhabitantes thereof: which God by that extraordinarie rod punishes.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50561", "revid": "5183450", "url": "https://en.wikipedia.org/wiki?curid=50561", "title": "Dominance", "text": "Dominance may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "50562", "revid": "51038717", "url": "https://en.wikipedia.org/wiki?curid=50562", "title": "Smyrna", "text": "Ancient Greek city, currently \u0130zmir, Turkey\nSmyrna ( ; , or ) was an Ancient Greek city located at a strategic point on the Aegean coast of Anatolia. Due to its advantageous port conditions, its ease of defence, and its good inland connections, Smyrna rose to prominence. Since about 1930, the city's name has been \u0130zmir.\nTwo sites of the ancient city are today within \u0130zmir's boundaries. The first, probably founded by indigenous peoples, rose to prominence during the Archaic Period as one of the principal ancient Greek settlements in western Anatolia. The second, whose foundation is associated with Alexander the Great, reached metropolitan proportions during the period of the Roman Empire. Most of the ancient city's present-day remains date to the Roman era, the majority from after a 2nd-century AD earthquake. In practical terms, a distinction is often made between these. \"Old Smyrna\" was the initial settlement founded around the 11th century BC, first as an Aeolian settlement, and later taken over and developed during the Archaic Period by the Ionians. \"Smyrna\" proper was the new city to which residents moved as of the 4th century BC and whose foundation was inspired by Alexander the Great.\nLocalization.\nOld Smyrna was on a small peninsula connected to the mainland by a narrow isthmus at the northeastern corner of the inner Gulf of \u0130zmir, at the edge of a fertile plain and at the foot of Mount Yamanlar. This Anatolian settlement commanded the gulf. Today, the archaeological site, named \"Bayrakl\u0131 H\u00f6y\u00fc\u011f\u00fc,\" is approximately inland, in the Tepekule neighbourhood of Bayrakl\u0131. \"New\" Smyrna developed simultaneously on the slopes of the Mount Pagos (Kadifekale today) and alongside the coastal strait, immediately below where a small bay existed until the 18th century.\nThe core of the late Hellenistic and early Roman Smyrna is preserved in the large area of \u0130zmir Agora Open Air Museum at this site. Research is being pursued at the sites of both the old and the new cities. This has been conducted since 1997 for Old Smyrna and since 2002 for the Classical Period city, in collaboration between the \u0130zmir Archaeology Museum and the Metropolitan Municipality of \u0130zmir.\nSmyrna was at the mouth of the small river Hermus and at the head of a deep arm of the sea (\"Smyrnaeus Sinus\") that reached far inland. This enabled Greek trading ships to sail into the heart of Lydia, making the city part of an essential trade route between Anatolia and the Aegean. During the 7th century BC, Smyrna rose to power and splendor. One of the great trade routes that cross Anatolia descends the Hermus valley past Sardis, and then, diverging from the valley, passes south of Mount Sipylus and crosses a low pass into the little valley where Smyrna lies between the mountains and the sea. Miletus and later Ephesus were at the sea end of the other great trade route across Anatolia; for a time they successfully competed with Smyrna, but after both cities' harbors silted up, Smyrna was without a rival.\nThe Meles River, which flowed by Smyrna, is famous in literature and was worshipped in the valley. A common and consistent tradition connects Homer with the valley of Smyrna and the banks of the Meles; his figure was one of the stock types on coins of Smyrna, one class of which numismatists call \"Homerian.\" The epithet \"Melesigenes\" was applied to him; the cave where he was wont to compose his poems was shown near the source of the river; his temple, the \"Homereum\", stood on its banks. The steady, equable flow of the Meles, alike in summer and winter, and its short course, beginning and ending near the city, are celebrated by Aristides and Himerius. The stream rises from abundant springs east of the city and flows into the southeast extremity of the gulf.\nHistory.\nHellenistic period.\nAlexander the Great conceived the idea of restoring the Greek city in a scheme that was, according to Strabo, actually carried out under Antigonus (316\u2013301\u00a0BC) and Lysimachus (301\u00a0BC\u2014281\u00a0BC), who enlarged and fortified the city. The ruined acropolis of the ancient city, the \"crown of Smyrna\", had been on a steep peak about high, which overhangs the northeast extremity of the gulf. Modern \u0130zmir was constructed atop the later Hellenistic city, partly on the slopes of a rounded hill the Greeks called \"Pagos\" near the southeast end of the gulf, and partly on the low ground between the hill and the sea. The beauty of the Hellenistic city, clustering on the low ground and rising tier over tier on the hillside, was frequently praised by the ancients and is celebrated on its coins.\nSmyrna is shut in on the west by a hill now called Deirmen Tepe, with the ruins of a temple on the summit. The walls of Lysimachus crossed the summit of this hill, and the acropolis occupied the top of Pagus. Between the two the road from Ephesus entered the city by the Ephesian gate, near which was a gymnasium. Closer to the acropolis the outline of the stadium is still visible, and the theatre was on Pagus's north slopes. Smyrna possessed two harbours. The outer harbour was simply the open roadstead of the gulf, and the inner was a small basin with a narrow entrance partially filled up by Tamerlane in 1402.\nThe streets were broad, well paved and laid out at right angles; many were named after temples: the main street, called the Golden, ran across the city from west to east, beginning probably from the temple of Zeus Akraios on the west slope of Pagus, and running round the lower slopes of Pagus (like a necklace on the statue, to use the favorite terms of Aristides the orator) towards Tepecik outside the city on the east, where probably stood the temple of Cybele, worshipped under the name of Meter Sipylene, the city's patroness. The name is from nearby Mount Sipylus, which bounds the valley of the city's backlands. The plain towards the sea was too low to be properly drained, and in rainy weather, the lower town's streets were deep with mud and water.\nAt the end of the Hellenistic period, in 197\u00a0BC, the city suddenly cut its ties with King Eumenes of Pergamum and appealed to Rome for help. Because Rome and Smyrna had no ties until then, Smyrna created a cult of Rome to establish a bond, and the cult eventually became widespread throughout the Roman Empire. As of 195\u00a0BC, the city of Rome started to be deified, in the cult to the goddess Roma. In this sense, the Smyrneans can be considered as the creators of the goddess Roma.\nIn 133\u00a0BC, when the last Attalid king, Attalus III, died without an heir, his will conferred his entire kingdom, including Smyrna, to the Romans. They organized it into the Roman province of Asia, making Pergamum the capital. As a major seaport, Smyrna became a leading city in the newly constituted province.\nRoman and Byzantine period.\nAs one of the principal cities of Roman Asia, Smyrna vied with Ephesus and Pergamum for the title \"First City of Asia.\"\nA Christian church and a bishopric existed there from earliest times, probably originating in the considerable Jewish colony. It was one of the seven churches addressed in the Book of Revelation. Saint Ignatius of Antioch visited Smyrna and later wrote letters to its bishop, Polycarp. A mob of Jews and pagans abetted the martyrdom of Polycarp in AD 153. Saint Irenaeus, who heard Polycarp as a boy, was probably a native of Smyrna. Another famous resident of the same period was Aelius Aristides.\nAfter a destructive earthquake in 178\u00a0AD, Smyrna was rebuilt in the Roman period (2nd century AD) under the emperor Marcus Aurelius. Aelius Aristides wrote a letter to Marcus Aurelius and his son Commodus, inviting them to become the new founders of the city. The bust of the emperor's wife Faustina on the second arch of the western stoa confirms this fact.\nPolycrates reports a succession of bishops including Polycarp of Smyrna, as well as others in nearby cities such as Melito of Sardis. Of that time, the German historian W. Bauer wrote:\nAsian Jewish Christianity received in turn the knowledge that henceforth the \"church\" would be open without hesitation to the Jewish influence mediated by Christians, coming not only from the apocalyptic traditions, but also from the synagogue with its practices concerning worship, which led to the appropriation of the Jewish passover observance. Even the observance of the sabbath by Christians appears to have found some favor in Asia...we find that in post-apostolic times, in the period of the formation of ecclesiastical structure, the Jewish Christians in these regions come into prominence.\nIn the late second century, Irenaeus also noted:\nPolycarp also was not only instructed by apostles, and conversed with many who had seen Christ, but was also, by apostles in Asia, appointed bishop of the Church in Smyrna...always taught the things which he had learned from the apostles, and which the Church has handed down, and which alone are true. To these things all the Asiatic Churches testify, as do also those men who have succeeded Polycarp. \nTertullian wrote c. 208\u00a0AD:\nAnyhow the heresies are at best novelties, and have no continuity with the teaching of Christ. Perhaps some heretics may claim Apostolic antiquity: we reply: Let them publish the origins of their churches and unroll the catalogue of their bishops till now from the Apostles or from some bishop appointed by the Apostles, as the Smyrnaeans count from Polycarp and John, and the Romans from Clement and Peter; let heretics invent something to match this.\nHence, the church in Smyrna was apparently one of the churches that Tertullian felt had real apostolic succession.\nDuring the mid-3rd century, most became affiliated with the Greco-Roman churches.\nWhen Constantinople became the seat of government, the trade between Anatolia and the West diminished in importance, and Smyrna declined.\nThe Seljuq commander Tzachas seized Smyrna in 1084 and used it as a base for naval raids, but the city was recovered by the general John Doukas.\nThe city was several times ravaged by the Turks, and had become quite ruinous when the Nicaean emperor John III Doukas Vatatzes rebuilt it about 1222.\nOttoman period.\nIbn Batuta found Smyrna still in great part a ruin when the homonymous chieftain of the Beylik of Ayd\u0131n had conquered it about 1330 and made his son, Umur, governor. It became the port of the emirate.\nDuring the Smyrniote Crusade in 1344, on October 28, the combined forces of the Knights Hospitallers of Rhodes, the Republic of Venice, the Papal States, and the Kingdom of Cyprus captured both the harbor and city from the Turks, which they held for nearly 60 years; the citadel fell in 1348, with the death of the governor Umur Baha ad-Din Ghazi.\nIn 1402, Tamerlane stormed the town and massacred almost all the inhabitants. His conquest was only temporary, but Smyrna was recovered by the Turks under the Ayd\u0131n dynasty, after which it became Ottoman, when the Ottomans took over the lands of Ayd\u0131n after 1425.\nGreek influence was so strong in the area that the Turks called it \"Smyrna of the infidels\" (Gavur \u0130zmir). Turkish sources track the term's emergence to the 14th century, when two separate parts of the city were controlled by two different powers, the upper \u0130zmir being Muslim and the lower part of the city Christian.\nThe Armenians, alongside the Greeks, played a significant role in the city's development, most notably during the age of exploration, where Armenians became a crucial player in the trade sector.\nThe Armenians had trade routes stretching from the far east to Europe. One most notable good the Armenians traded was Iranian silk, which the Shah Abbas of Iran gave them a monopoly over in the 17th century.\nThe Armenians traded Iranian silk with European and Greek merchants in Smyrna; this trade made the Armenians very rich. Besides trade, the Armenians were involved in manufacturing, banking, and other highly productive professions.\nDuring the late 19th and early 20th centuries, Smyrna was an important financial and cultural center of the Greek world. Of its 391 factories, 322 belonged to local Greeks, while 3 of its 9 banks were backed by Greek capital. Education was also dominated by the local Greek communities, with 67 male and 4 female schools. The Ottomans continued to control the area, with the exception of the 1919\u20131922 period, when the city was assigned to Greece by the Treaty of S\u00e8vres.\nThe region's most important Greek educational institution was the Evangelical School, which operated from 1733 to 1922.\nPost-World War I.\nAfter the end of the First World War, Greece occupied Smyrna from 15 May 1919 and put in place a military administration. The Greek premier Venizelos had plans to annex Smyrna and he seemed to be realizing his objective in the Treaty of S\u00e8vres, signed 10 August 1920. (However, this treaty was not ratified by the parties; the Treaty of Peace of Lausanne replaced it.)\nThe occupation of Smyrna came to an end when the Turkish army of Kemal Atat\u00fcrk entered the city on September 9, 1922, at the end of the Greco-Turkish War (1919\u20131922). In the immediate aftermath, a fire broke out in the Greek and Armenian quarters of the city on September 13, 1922, known as the Great Fire of Smyrna. The death toll is estimated to range from 10,000 to 100,000.\nAgora.\nThe remains of the ancient agora of Smyrna constitute today the space of \"\u0130zmir Agora Museum\" in \u0130zmir's Namazgah quarter, although its area is commonly referred to as \"Agora\" by the city's inhabitants.\nSituated on the northern slopes of the Pagos hills, it was the commercial, judicial and political nucleus of the ancient city, its center for artistic activities and for teaching.\n\u0130zmir Agora Open Air Museum consists of five parts, including the agora area, the base of the northern basilica gate, the stoa and the ancient shopping centre.\nThe agora of Smyrna was built during the Hellenistic era.\nExcavations.\nAlthough Smyrna was explored by Charles Texier in the 19th century and the German consul in \u0130zmir had purchased the land around the ancient theater in 1917 to start excavations, the first scientific digs can be said to have started in 1927. Most of the discoveries were made by archaeological exploration carried as an extension during the period between 1931 and 1942 by the German archaeologist Rudolf Naumann and Sel\u00e2hattin Kantar, the director of \u0130zmir and Ephesus museums. They uncovered a three-floor, rectangular compound with stairs in the front, built on columns and arches around a large courtyard in the middle of the building.\nNew excavations in the agora began in 1996 by the Directorate of Archaeology Museum in Izmir. They have continued since 2002 under the sponsorship of the Metropolitan Municipality of \u0130zmir. A primary school adjacent to the agora that had burned in 1980 was not reconstructed. Instead, its space was incorporated into the historical site. The area of the agora was increased to . This permitted the evacuation of a previously unexplored zone. The archaeologists and the local authorities, means permitting, are also keenly eyeing a neighbouring multi-storey car park, which is known to cover an important part of the ancient settlement. During the present renovations the old restorations in concrete are gradually being replaced by marble.\nThe new excavation has uncovered the agora's northern gate. It has been concluded that embossed figures of the goddess Hestia found in these digs were a continuation of the Zeus altar uncovered during the first digs. Statues of the gods Hermes, Dionysos, Eros and Heracles have also been found, as well as many statues, heads, embossments, figurines and monuments of people and animals, made of marble, stone, bone, glass, metal and terracotta. Inscriptions found here list the people who provided aid to Smyrna after the earthquake of 178\u00a0AD.\nEconomy.\nIn the early 20th-century, Smyrna had a number of mills spinning thread. As of 1920, there were two factories in Smyrna dyeing yarn, which were owned by British companies. These companies employed over 60,000 people. During this time, there was also a French owned cotton spinning mill. The city also produced soap made of refuse olive oil. An ironworks, also owned by the British, produced tools and equipment. Those tools were used to extract tannin from valonia oak. As of 1920, the ironwork was exporting 5,000 tons of product a year. The city also produced wooden boxes, which were used for fig and raisin storage. The wood for the boxes was imported from Austria and Romania.\nToponyms.\nSeveral American cities have been named after Smyrna, including Smyrna, Georgia; Smyrna, Tennessee; Smyrna, North Carolina; Smyrna, South Carolina; Smyrna, Delaware; Smyrna, Michigan; Smyrna, Maine and New Smyrna Beach, Florida.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50563", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=50563", "title": "Sucrose", "text": "Disaccharide made of glucose and fructose\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nSucrose, a disaccharide, is a sugar composed of glucose and fructose subunits. It is produced naturally in plants and is the main constituent of white sugar. It has the molecular formula C12H22O11.\nFor human consumption, sucrose is extracted and refined from either sugarcane or sugar beet. Sugar mills \u2013 typically located in tropical regions near where sugarcane is grown \u2013 crush the cane and produce raw sugar which is shipped to other factories for refining into pure sucrose. Sugar beet factories are located in temperate climates where the beet is grown, and process the beets directly into refined sugar. The sugar-refining process involves washing the raw sugar crystals before dissolving them into a sugar syrup which is filtered and then passed over carbon to remove any residual colour. The sugar syrup is then concentrated by boiling under a vacuum and crystallized as the final purification process to produce crystals of pure sucrose that are clear, odorless, and sweet.\nSugar is often an added ingredient in food production and recipes. About 185 million tonnes of sugar were produced worldwide in 2017.\nEtymology.\nThe word \"sucrose\" was coined in 1857, by the English chemist William Miller from the French (\"sugar\") and the generic chemical suffix for sugars \"-ose\". The abbreviated term \"Suc\" is often used for \"sucrose\" in scientific literature.\nThe name \"saccharose\" was coined in 1860 by the French chemist Marcellin Berthelot. Saccharose is an obsolete name for sugars in general, especially sucrose.\nPhysical and chemical properties.\nStructure.\nSucrose's IUPAC name is \"\u03b2--fructofuranosyl-(2\u21921)-\u03b1--glucopyranoside\". In this disaccharide, glucose and fructose are linked via a glycosidic linkage, i.e. an ether bond between C1 on the glucosyl subunit and C2 on the fructosyl unit. Glucose exists predominantly as a mixture of \u03b1 and \u03b2 \"pyranose\" anomers, but sucrose has only the \u03b1 form. Fructose exists as a mixture of five tautomers but sucrose has only the \u03b2--fructofuranose form. Unlike most disaccharides, the glycosidic bond in sucrose is formed between the reducing ends of both glucose and fructose, and not between the reducing end of one and the non-reducing end of the other. This linkage inhibits further bonding to other saccharide units, and prevents sucrose from spontaneously reacting with cellular and circulatory macromolecules in the manner that glucose and other reducing sugars do. Since sucrose contains no anomeric hydroxyl groups, it is classified as a non-reducing sugar.\nSucrose crystallizes in the monoclinic space group P21 with room-temperature lattice parameters \"a\" = 1.08631\u00a0nm, \"b\" = 0.87044\u00a0nm, \"c\" = 0.77624\u00a0nm, \u03b2 = 102.938\u00b0.\nThermal and oxidative degradation.\nSucrose does not melt at high temperatures. Instead, it decomposes at to form caramel. Like other carbohydrates, it combusts to carbon dioxide and water by the simplified equation:\nMixing sucrose with the oxidizer potassium nitrate produces the fuel known as rocket candy that is used to propel amateur rocket motors.\nThis reaction is somewhat simplified though. Some of the carbon does get fully oxidized to carbon dioxide, and other reactions, such as the water-gas shift reaction also take place. A more accurate theoretical equation is:\nSucrose burns with chloric acid, formed by the reaction of hydrochloric acid and potassium chlorate:\nSucrose can be dehydrated with concentrated sulfuric acid to form a black, carbon-rich solid, as indicated in the following idealized equation:\nThe formula for sucrose's decomposition can be represented as a two-step reaction: the first simplified reaction is dehydration of sucrose to pure carbon and water, and then carbon is oxidised to by from air.\nHydrolysis.\nHydrolysis breaks the glycosidic bond converting sucrose into glucose and fructose. Hydrolysis is, however, so slow that solutions of sucrose can sit for years with negligible change. If the enzyme sucrase is added, however, the reaction will proceed rapidly. Hydrolysis can also be accelerated with acids, such as cream of tartar or lemon juice, both weak acids. Likewise, gastric acidity converts sucrose to glucose and fructose during digestion, the bond between them being an acetal bond which can be broken by an acid.\nGiven (higher) heats of combustion of 1349.6\u00a0kcal/mol for sucrose, 673.0 for glucose, and 675.6 for fructose, hydrolysis releases about per mole of sucrose, or about 3 small calories per gram of product.\nSynthesis and biosynthesis of sucrose.\nThe biosynthesis of sucrose proceeds via the precursors UDP-glucose and fructose 6-phosphate, catalyzed by the enzyme sucrose-6-phosphate synthase. The energy for the reaction is gained by the cleavage of uridine diphosphate (UDP).\nSucrose is formed by plants, algae and cyanobacteria but not by other organisms. Sucrose is the end product of photosynthesis and is found naturally in many food plants along with the monosaccharide fructose. In many fruits, such as pineapple and apricot, sucrose is the main sugar. In others, such as grapes and pears, fructose is the main sugar.\nChemical synthesis.\nAfter numerous unsuccessful attempts by others, Raymond Lemieux and George Huber succeeded in synthesizing sucrose from acetylated glucose and fructose in 1953.\nMeasurement.\nThe purity of sucrose is measured by polarimetry, i.e., the rotation of plane-polarized light by a sugar solution. The specific rotation at using yellow \"sodium-D\" light (589\u00a0nm) is +66.47\u00b0. Commercial samples of sugar are assayed using this parameter. Sucrose does not deteriorate at ambient conditions.\nThe sugar industry uses degrees Brix (symbol \u00b0Bx), introduced by Adolf Brix, as units of measurement of the mass ratio of dissolved substance to water in a liquid. A 25 \u00b0Bx sucrose solution has 25\u00a0grams of sucrose per 100\u00a0grams of liquid; or, to put it another way, 25\u00a0grams of sucrose sugar and 75\u00a0grams of water exist in the 100\u00a0grams of solution. A 25 \u00b0Bx solution therefore has a concentration of 25 mass % sucrose.\nThe Brix degrees are measured using an infrared sensor. This measurement does not equate to Brix degrees from a density or refractive index measurement, because it will specifically measure dissolved sugar concentration instead of all dissolved solids. When using a refractometer, one should report the result as \"refractometric dried substance\" (RDS). One might speak of a liquid as having 20 \u00b0Bx RDS. This refers to a measure of percent by weight of \"total\" dried solids and, although not technically the same as Brix degrees determined through an infrared method, renders an accurate measurement of sucrose content, since sucrose in fact forms the majority of dried solids. The advent of in-line infrared Brix measurement sensors has made measuring the amount of dissolved sugar in products economical using a direct measurement.\nSources.\nIn nature, sucrose is present in many plants, and in particular their roots, fruits and nectars, because it serves as a way to store energy, primarily from photosynthesis. Many mammals, birds, insects and bacteria accumulate and feed on the sucrose in plants and for some it is their main food source. Although honeybees consume sucrose, the honey they produce consists primarily of fructose and glucose, with only trace amounts of sucrose.\nAs fruits ripen, their sucrose content usually rises sharply, but some fruits contain almost no sucrose at all. This includes grapes, cherries, blueberries, blackberries, figs, pomegranates, tomatoes, avocados, lemons and limes. In grapes, for instance, during ripening the sucrose molecules are hydrolyzed (separated) into glucose and fructose.\nSucrose is a naturally occurring sugar, but with the advent of industrialization, it has been increasingly refined and consumed in all kinds of processed foods.\nProduction.\nTable sugar (sucrose) comes from plant sources. Two important sugar crops predominate: sugarcane (\"Saccharum spp.\") and sugar beets (\"Beta vulgaris\"), in which sugar can account for 12% to 20% of the plant's dry weight. The plant material is separated to isolate the sucrose-rich portions. Purification of the sucrose exploits the good solubility of sucrose in water. After this aqueous extraction, a variety of tools and techniques allow further purification and production of solid forms suited for the markets.\nCulinary sugars.\nMill white.\nMill white, also called plantation white, crystal sugar or superior sugar is produced from raw sugar. It is exposed to sulfur dioxide during the production to reduce the concentration of color compounds and helps prevent further color development during the crystallization process. Although common to sugarcane-growing areas, this product does not store or ship well. After a few weeks, its impurities tend to promote discoloration and clumping; therefore this type of sugar is generally limited to local consumption.\nBlanco directo.\nBlanco directo, a white sugar common in India and other south Asian countries, is produced by precipitating many impurities out of cane juice using phosphoric acid and calcium hydroxide, similar to the carbonatation technique used in beet sugar refining. Blanco directo is purer than mill white sugar, but less pure than white refined sugar.\nWhite refined.\nWhite refined is the most common form of sugar in North America and Europe. Refined sugar is made by dissolving and purifying raw sugar using phosphoric acid similar to the method used for blanco directo, a carbonatation process involving calcium hydroxide and carbon dioxide, or by various filtration strategies. It is then further purified by filtration through a bed of activated carbon or bone char. Beet sugar refineries produce refined white sugar directly without an intermediate raw stage.\nWhite refined sugar is typically sold as granulated sugar, which has been dried to prevent clumping and comes in various crystal sizes for home and industrial use:\nBrown sugar comes either from the late stages of cane sugar refining, when sugar forms fine crystals with significant molasses content, or from coating white refined sugar with a cane molasses syrup (blackstrap molasses). Brown sugar's color and taste become stronger with increasing molasses content, as do its moisture-retaining properties. Brown sugars also tend to harden if exposed to the atmosphere, although proper handling can reverse this.\nConsumption.\nRefined sugar was a luxury before the 18th century. It became widely popular in the 18th century, then graduated to becoming a necessary food in the 19th century. This evolution of taste and demand for sugar as an essential food ingredient unleashed major economic and social changes. Eventually, table sugar became sufficiently cheap and common enough to influence standard cuisine and flavored drinks.\nSucrose forms a major element in confectionery and desserts. Cooks use it for sweetening. It can also act as a food preservative when used in sufficient concentrations, and thus is an important ingredient in the production of fruit preserves. Sucrose is important to the structure of many foods, including biscuits and cookies, cakes and pies, candy, and ice cream and sorbets. It is a common ingredient in many processed and so-called \"junk foods\".\nNutritional information.\nFully refined sugar is 99.9% sucrose, thus providing only carbohydrate as dietary nutrient and 390 kilocalories per 100 g serving (table). There are no micronutrients of significance in fully refined sugar (table).\nMetabolism of sucrose.\nIn humans and other mammals, sucrose is broken down into its constituent monosaccharides, glucose and fructose, by sucrase or isomaltase glycoside hydrolases, which are located in the membrane of the microvilli lining the duodenum. The resulting glucose and fructose molecules are then rapidly absorbed into the bloodstream. In bacteria and some animals, sucrose is digested by the enzyme invertase. Sucrose is an easily assimilated macronutrient that provides a quick source of energy, provoking a rapid rise in blood glucose upon ingestion. Sucrose, as a pure carbohydrate, has an energy content of 3.94\u00a0calories per gram (or 17\u00a0kilojoules per gram).\nIf consumed excessively, sucrose may contribute to the development of metabolic syndrome, including increased risk for type 2 diabetes, insulin resistance, weight gain and obesity in adults and children.\nTooth decay.\nTooth decay (dental caries) has become a pronounced health hazard associated with the consumption of sugars, especially sucrose. Oral bacteria such as \"Streptococcus mutans\" live in dental plaque and metabolize \"any\" free sugars (not just sucrose, but also glucose, lactose, fructose, and cooked starches) into lactic acid. The resultant lactic acid lowers the pH of the tooth's surface, stripping it of minerals in the process known as tooth decay.\nAll 6-carbon sugars and disaccharides based on 6-carbon sugars can be converted by dental plaque bacteria into acid that demineralizes teeth, but sucrose may be uniquely useful to \"Streptococcus sanguinis\" (formerly \"Streptococcus sanguis\") and \"Streptococcus mutans\". Sucrose is the only dietary sugar that can be converted to sticky glucans (dextran-like polysaccharides) by extracellular enzymes. These glucans allow the bacteria to adhere to the tooth surface and to build up thick layers of plaque. The anaerobic conditions deep in the plaque encourage the formation of acids, which leads to carious lesions. Thus, sucrose could enable \"S. mutans\", \"S. sanguinis\" and many other species of bacteria to adhere strongly and resist natural removal, e.g. by flow of saliva, although they are easily removed by brushing. The glucans and levans (fructose polysaccharides) produced by the plaque bacteria also act as a reserve food supply for the bacteria.\nSuch a special role of sucrose in the formation of tooth decay is much more significant in light of the almost universal use of sucrose as the most desirable sweetening agent. Widespread replacement of sucrose by high-fructose corn syrup (HFCS) has not diminished the danger from sucrose. If smaller amounts of sucrose are present in the diet, they will still be sufficient for the development of thick, anaerobic plaque and plaque bacteria will metabolise other sugars in the diet, such as the glucose and fructose in HFCS.\nGlycemic index.\nSucrose is a disaccharide made up of 50% glucose and 50% fructose and has a glycemic index of 65. Sucrose is digested rapidly, but has a relatively low glycemic index due to its content of fructose, which has a minimal effect on blood glucose.\nAs with other sugars, sucrose is digested into its components via the enzyme sucrase to glucose (blood sugar). The glucose component is transported into the blood where it serves immediate metabolic demands, or is converted and reserved in the liver as glycogen.\nGout.\nThe occurrence of gout is connected with an excess production of uric acid. A diet rich in sucrose may lead to gout as it raises the level of insulin, which prevents excretion of uric acid from the body. As the concentration of uric acid in the body increases, so does the concentration of uric acid in the joint liquid and beyond a critical concentration, the uric acid begins to precipitate into crystals. Researchers have implicated sugary drinks high in fructose in a surge in cases of gout.\nUN dietary recommendation.\nIn 2015, the World Health Organization published a new guideline on sugars intake for adults and children, as a result of an extensive review of the available scientific evidence by a multidisciplinary group of experts. The guideline recommends that both adults and children ensure their intake of free sugars (monosaccharides and disaccharides added to foods and beverages by the manufacturer, cook or consumer, and sugars naturally present in honey, syrups, fruit juices and fruit juice concentrates) is less than 10% of total energy intake. A level below 5% of total energy intake brings additional health benefits, especially with regards to dental caries.\nReligious concerns.\nThe sugar refining industry often uses bone char (calcinated animal bones) for decolorizing. About 25% of sugar produced in the U.S. is processed using bone char as a filter, the remainder being processed with activated carbon. As bone char does not seem to remain in finished sugar, Jewish religious leaders consider sugar filtered through it to be pareve, meaning that it is neither meat nor dairy and may be used with either type of food. However, the bone char must source to a kosher animal (e.g. cow, sheep) for the sugar to be kosher.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50564", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=50564", "title": "Gray code", "text": "Ordering of binary values, used for positioning and error correction\nThe reflected binary code (RBC), also known as reflected binary (RB) or Gray code after Frank Gray, is an ordering of the binary numeral system such that two successive values differ in only one bit (binary digit).\nFor example, the representation of the decimal value \"1\" in binary would normally be \"001\", and \"2\" would be \"010\". In Gray code, these values are represented as \"001\" and \"011\". That way, incrementing a value from 1 to 2 requires only one bit to change, instead of two.\nGray codes are widely used to prevent spurious output from electromechanical switches and to facilitate error correction in digital communications such as digital terrestrial television and some cable TV systems. The use of Gray code in these devices helps simplify logic operations and reduce errors in practice.\nFunction.\nMany devices indicate position by closing and opening switches. If that device uses natural binary codes, positions 3 and 4 are next to each other but all three bits of the binary representation differ:\nThe problem with natural binary codes is that physical switches are not ideal: it is very unlikely that physical switches will change states exactly in synchrony. In the transition between the two states shown above, all three switches change state. In the brief period while all are changing, the switches will read some spurious position. Even without keybounce, the transition might look like 011 \u2014 001 \u2014 101 \u2014 100. When the switches appear to be in position 001, the observer cannot tell if that is the \"real\" position 1, or a transitional state between two other positions. If the output feeds into a sequential system, possibly via combinational logic, then the sequential system may store a false value.\nThis problem can be solved by changing only one switch at a time, so there is never any ambiguity of position, resulting in codes assigning to each of a contiguous set of integers, or to each member of a circular list, a word of symbols such that no two code words are identical and each two adjacent code words differ by exactly one symbol. These codes are also known as \"unit-distance\", \"single-distance\", \"single-step\", \"monostrophic\" or \"syncopic codes\", in reference to the Hamming distance of 1 between adjacent codes.\nInvention.\nIn principle, there can be more than one such code for a given word length, but the term Gray code was first applied to a particular binary code for non-negative integers, the \"binary-reflected Gray code\", or BRGC. Bell Labs researcher \nGeorge R.\u00a0Stibitz described such a code in a 1941 patent application, granted in 1943. Frank Gray introduced the term \"reflected binary code\" in his 1947 patent application, remarking that the code had \"as yet no recognized name\". He derived the name from the fact that it \"may be built up from the conventional binary code by a sort of reflection process\".\nIn the standard encoding of the Gray code the least significant bit follows a repetitive pattern of 2\u00a0on, 2\u00a0off the next digit a pattern of 4\u00a0on, 4\u00a0off; the \"i\"-th least significant bit a pattern of 2\"i\"\u00a0on 2\"i\"\u00a0off. The most significant digit is an exception to this: for an \"n\"-bit Gray code, the most significant digit follows the pattern 2\"n\"\u22121\u00a0on, 2\"n\"\u22121\u00a0off, which is the same (cyclic) sequence of values as for the second-most significant digit, but shifted forwards 2\"n\"\u22122 places. The four-bit version of this is shown below:\nFor decimal 15 the code rolls over to decimal 0 with only one switch change. This is called the \"cyclic\" or \"adjacency property\" of the code.\nIn modern digital communications, Gray codes play an important role in error correction. For example, in a digital modulation scheme such as QAM where data is typically transmitted in symbols of 4 bits or more, the signal's constellation diagram is arranged so that the bit patterns conveyed by adjacent constellation points differ by only one bit. By combining this with forward error correction capable of correcting single-bit errors, it is possible for a receiver to correct any transmission errors that cause a constellation point to deviate into the area of an adjacent point. This makes the transmission system less susceptible to noise.\nDespite the fact that Stibitz described this code before Gray, the reflected binary code was later named after Gray by others who used it. Two different 1953 patent applications use \"Gray code\" as an alternative name for the \"reflected binary code\"; one of those also lists \"minimum error code\" and \"cyclic permutation code\" among the names. A 1954 patent application refers to \"the Bell Telephone Gray code\". Other names include \"cyclic binary code\", \"cyclic progression code\", \"cyclic permuting binary\" or \"cyclic permuted binary\" (CPB).\nThe Gray code is sometimes misattributed to 19th century electrical device inventor Elisha Gray.\nHistory and practical application.\nMathematical puzzles.\nReflected binary codes were applied to mathematical puzzles before they became known to engineers.\nThe binary-reflected Gray code represents the underlying scheme of the classical Chinese rings puzzle, a sequential mechanical puzzle mechanism described by the French Louis Gros in 1872.\nIt can serve as a solution guide for the Towers of Hanoi problem, based on a game by the French \u00c9douard Lucas in 1883. Similarly, the so-called Towers of Bucharest and Towers of Klagenfurt game configurations yield ternary and pentary Gray codes.\nMartin Gardner wrote a popular account of the Gray code in his August 1972 \"Mathematical Games\" column in \"Scientific American\".\nThe code also forms a Hamiltonian cycle on a hypercube, where each bit is seen as one dimension.\nTelegraphy codes.\nWhen the French engineer \u00c9mile Baudot changed from using a 6-unit (6-bit) code to 5-unit code for his printing telegraph system, in 1875 or 1876, he ordered the alphabetic characters on his print wheel using a reflected binary code, and assigned the codes using only three of the bits to vowels. With vowels and consonants sorted in their alphabetical order, and other symbols appropriately placed, the 5-bit character code has been recognized as a reflected binary code. This code became known as Baudot code and, with minor changes, was eventually adopted as International Telegraph Alphabet No.\u00a01 (ITA1, CCITT-1) in 1932. \nAbout the same time, the German-Austrian Otto Sch\u00e4ffler demonstrated another printing telegraph in Vienna using a 5-bit reflected binary code for the same purpose, in 1874.\nAnalog-to-digital signal conversion.\nFrank Gray, who became famous for inventing the signaling method that came to be used for compatible color television, invented a method to convert analog signals to reflected binary code groups using vacuum tube-based apparatus. Filed in 1947, the method and apparatus were granted a patent in 1953, and the name of Gray stuck to the codes. The \"PCM tube\" apparatus that Gray patented was made by Raymond W. Sears of Bell Labs, working with Gray and William M. Goodall, who credited Gray for the idea of the reflected binary code.\nGray was most interested in using the codes to minimize errors in converting analog signals to digital; his codes are still used today for this purpose.\nPosition encoders.\nGray codes are used in linear and rotary position encoders (absolute encoders and quadrature encoders) in preference to weighted binary encoding. This avoids the possibility that, when multiple bits change in the binary representation of a position, a misread will result from some of the bits changing before others.\nFor example, some rotary encoders provide a disk which has an electrically conductive Gray code pattern on concentric rings (tracks). Each track has a stationary metal spring contact that provides electrical contact to the conductive code pattern. Together, these contacts produce output signals in the form of a Gray code. Other encoders employ non-contact mechanisms based on optical or magnetic sensors to produce the Gray code output signals.\nRegardless of the mechanism or precision of a moving encoder, position measurement error can occur at specific positions (at code boundaries) because the code may be changing at the exact moment it is read (sampled). A binary output code could cause significant position measurement errors because it is impossible to make all bits change at exactly the same time. If, at the moment the position is sampled, some bits have changed and others have not, the sampled position will be incorrect. In the case of absolute encoders, the indicated position may be far away from the actual position and, in the case of incremental encoders, this can corrupt position tracking.\nIn contrast, the Gray code used by position encoders ensures that the codes for any two consecutive positions will differ by only one bit and, consequently, only one bit can change at a time. In this case, the maximum position error will be small, indicating a position adjacent to the actual position.\nGenetic algorithms.\nDue to the Hamming distance properties of Gray codes, they are sometimes used in genetic algorithms. They are very useful in this field, since mutations in the code allow for mostly incremental changes, but occasionally a single bit-change can cause a big leap and lead to new properties.\nBoolean circuit minimization.\nGray codes are also used in labelling the axes of Karnaugh maps since 1953 as well as in H\u00e4ndler circle graphs since 1958, both graphical methods for logic circuit minimization.\nError correction.\nIn modern digital communications, 1D- and 2D-Gray codes play an important role in error prevention before applying an error correction. For example, in a digital modulation scheme such as QAM where data is typically transmitted in symbols of 4 bits or more, the signal's constellation diagram is arranged so that the bit patterns conveyed by adjacent constellation points differ by only one bit. By combining this with forward error correction capable of correcting single-bit errors, it is possible for a receiver to correct any transmission errors that cause a constellation point to deviate into the area of an adjacent point. This makes the transmission system less susceptible to noise.\nCommunication between clock domains.\nDigital logic designers use Gray codes extensively for passing multi-bit count information between synchronous logic that operates at different clock frequencies. The logic is considered operating in different \"clock domains\". It is fundamental to the design of large chips that operate with many different clocking frequencies.\nCycling through states with minimal effort.\nIf a system has to cycle sequentially through all possible combinations of on-off states of some set of controls, and the changes of the controls require non-trivial expense (e.g. time, wear, human work), a Gray code minimizes the number of setting changes to just one change for each combination of states. An example would be testing a piping system for all combinations of settings of its manually operated valves.\nA balanced Gray code can be constructed, that flips every bit equally often. Since bit-flips are evenly distributed, this is optimal in the following way: balanced Gray codes minimize the maximal count of bit-flips for each digit.\nGray code counters and arithmetic.\nGeorge R. Stibitz utilized a reflected binary code in a binary pulse counting device in 1941 already.\nA typical use of Gray code counters is building a FIFO (first-in, first-out) data buffer that has read and write ports that exist in different clock domains. The input and output counters inside such a dual-port FIFO are often stored using Gray code to prevent invalid transient states from being captured when the count crosses clock domains. The updated read and write pointers need to be passed between clock domains when they change, to be able to track FIFO empty and full status in each domain. Each bit of the pointers is sampled non-deterministically for this clock domain transfer. So for each bit, either the old value or the new value is propagated. Therefore, if more than one bit in the multi-bit pointer is changing at the sampling point, a \"wrong\" binary value (neither new nor old) can be propagated. By guaranteeing only one bit can be changing, Gray codes guarantee that the only possible sampled values are the new or old multi-bit value. Typically Gray codes of power-of-two length are used.\nSometimes digital buses in electronic systems are used to convey quantities that can only increase or decrease by one at a time, for example the output of an event counter which is being passed between clock domains or to a digital-to-analog converter. The advantage of Gray codes in these applications is that differences in the propagation delays of the many wires that represent the bits of the code cannot cause the received value to go through states that are out of the Gray code sequence. This is similar to the advantage of Gray codes in the construction of mechanical encoders, however the source of the Gray code is an electronic counter in this case. The counter itself must count in Gray code, or if the counter runs in binary then the output value from the counter must be reclocked after it has been converted to Gray code, because when a value is converted from binary to Gray code, it is possible that differences in the arrival times of the binary data bits into the binary-to-Gray conversion circuit will mean that the code could go briefly through states that are wildly out of sequence. Adding a clocked register after the circuit that converts the count value to Gray code may introduce a clock cycle of latency, so counting directly in Gray code may be advantageous.\nTo produce the next count value in a Gray-code counter, it is necessary to have some combinational logic that will increment the current count value that is stored. One way to increment a Gray code number is to convert it into ordinary binary code, add one to it with a standard binary adder, and then convert the result back to Gray code. Other methods of counting in Gray code are discussed in a report by Robert W. Doran, including taking the output from the first latches of the master-slave flip flops in a binary ripple counter.\nGray code addressing.\nAs the execution of executable code typically causes an instruction memory access pattern of locally consecutive addresses, bus encodings using Gray code addressing instead of binary addressing can reduce the number of state changes of the address bits significantly, thereby reducing the CPU power consumption in some low-power designs.\nConstructing an \"n\"-bit Gray code.\nThe binary-reflected Gray code list for \"n\" bits can be generated recursively from the list for \"n\"\u00a0\u2212\u00a01 bits by reflecting the list (i.e. listing the entries in reverse order), prefixing the entries in the original list with a binary 0, prefixing the entries in the reflected list with a binary\u00a01, and then concatenating the original list with the reversed list. For example, generating the \"n\"\u00a0=\u00a03 list from the \"n\"\u00a0=\u00a02 list:\nThe one-bit Gray code is \"G\"1\u00a0=\u00a0(0,1). This can be thought of as built recursively as above from a zero-bit Gray code \"G\"0\u00a0=\u00a0(\u00a0\u039b\u00a0) consisting of a single entry of zero length. This iterative process of generating \"G\"\"n\"+1 from \"G\"\"n\" makes the following properties of the standard reflecting code clear:\nThese characteristics suggest a simple and fast method of translating a binary value into the corresponding Gray code. Each bit is inverted if the next higher bit of the input value is set to one. This can be performed in parallel by a bit-shift and exclusive-or operation if they are available: the \"n\"th Gray code is obtained by computing formula_1. Prepending a 0 bit leaves the order of the code words unchanged, prepending a 1 bit reverses the order of the code words. If the bits at position formula_2 of codewords are inverted, the order of neighbouring blocks of formula_3 codewords is reversed. For example, if bit 0 is inverted in a 3 bit codeword sequence, the order of two neighbouring codewords is reversed\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nIf bit 1 is inverted, blocks of 2 codewords change order:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nIf bit 2 is inverted, blocks of 4 codewords reverse order:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThus, performing an exclusive or on a bit formula_4 at position formula_2 with the bit formula_6 at position formula_7 leaves the order of codewords intact if formula_8, and reverses the order of blocks of formula_9 codewords if formula_10. Now, this is exactly the same operation as the reflect-and-prefix method to generate the Gray code.\nA similar method can be used to perform the reverse translation, but the computation of each bit depends on the computed value of the next higher bit so it cannot be performed in parallel. Assuming formula_11 is the formula_2th Gray-coded bit (formula_13 being the most significant bit), and formula_4 is the formula_2th binary-coded bit (formula_16 being the most-significant bit), the reverse translation can be given recursively: formula_17, and formula_18. Alternatively, decoding a Gray code into a binary number can be described as a prefix sum of the bits in the Gray code, where each individual summation operation in the prefix sum is performed modulo two.\nTo construct the binary-reflected Gray code iteratively, at step 0 start with the formula_19, and at step formula_20 find the bit position of the least significant 1 in the binary representation of formula_2 and flip the bit at that position in the previous code formula_22 to get the next code formula_23. The bit positions start 0, 1, 0, 2, 0, 1, 0, 3, ... See find first set for efficient algorithms to compute these values.\nConverting to and from Gray code.\nThe following functions in C convert between binary numbers and their associated Gray codes. While it may seem that Gray-to-binary conversion requires each bit to be handled one at a time, faster algorithms exist.\ntypedef unsigned int uint;\n// This function converts an unsigned binary number to reflected binary Gray code.\nuint BinaryToGray(uint num)\n return num ^ (num \u00bb 1); // The operator \u00bb is shift right. The operator ^ is exclusive or.\n// This function converts a reflected binary Gray code number to a binary number.\nuint GrayToBinary(uint num)\n uint mask = num;\n while (mask) { // Each Gray code bit is exclusive-ored with all more significant bits.\n mask \u00bb= 1;\n num ^= mask;\n return num;\n// A more efficient version for Gray codes 32 bits or fewer through the use of SWAR (SIMD within a register) techniques. \n// It implements a parallel prefix XOR function. The assignment statements can be in any order.\n// This function can be adapted for longer Gray codes by adding steps.\nuint GrayToBinary32(uint num)\n num ^= num \u00bb 16;\n num ^= num \u00bb 8;\n num ^= num \u00bb 4;\n num ^= num \u00bb 2;\n num ^= num \u00bb 1;\n return num;\n// A Four-bit-at-once variant changes a binary number (abcd)2 to (abcd)2 ^ (00ab)2, then to (abcd)2 ^ (00ab)2 ^ (0abc)2 ^ (000a)2.\nOn newer processors, the number of ALU instructions in the decoding step can be reduced by taking advantage of the CLMUL instruction set. If MASK is the constant binary string of ones ended with a single zero digit, then carryless multiplication of MASK with the grey encoding of x will always give either x or its bitwise negation.\nSpecial types of Gray codes.\nIn practice, \"Gray code\" almost always refers to a binary-reflected Gray code (BRGC). However, mathematicians have discovered other kinds of Gray codes. Like BRGCs, each consists of a list of words, where each word differs from the next in only one digit (each word has a Hamming distance of 1 from the next word).\nGray codes with \"n\" bits and of length less than 2\"n\".\nIt is possible to construct binary Gray codes with \"n\" bits with a length of less than 2\"n\", if the length is even. One possibility is to start with a balanced Gray code and remove pairs of values at either the beginning and the end, or in the middle. OEIS sequence A290772 gives the number of possible Gray sequences of length 2\"n\" that include zero and use the minimum number of bits.\n\"n\"-ary Gray code.\nThere are many specialized types of Gray codes other than the binary-reflected Gray code. One such type of Gray code is the \"n\"-ary Gray code, also known as a non-Boolean Gray code. As the name implies, this type of Gray code uses non-Boolean values in its encodings.\nFor example, a 3-ary (ternary) Gray code would use the values . The (\"n\",\u00a0\"k\")-\"Gray code\" is the \"n\"-ary Gray code with \"k\" digits.\nThe sequence of elements in the (3,\u00a02)-Gray code is: . The (\"n\",\u00a0\"k\")-Gray code may be constructed recursively, as the BRGC, or may be constructed iteratively. An algorithm to iteratively generate the (\"N\",\u00a0\"k\")-Gray code is presented (in C):\n// inputs: base, digits, value\n// output: Gray\n// Convert a value to a Gray code with the given base and digits.\n// Iterating through a sequence of values would result in a sequence\n// of Gray codes in which only one digit changes at a time.\nvoid toGray(unsigned base, unsigned digits, unsigned value, unsigned gray[digits])\n unsigned baseN[digits]; // Stores the ordinary base-N number, one digit per entry\n unsigned i; // The loop variable\n // Put the normal baseN number into the baseN array. For base 10, 109 \n // would be stored as [9,0,1]\n for (i = 0; i &lt; digits; i++) {\n baseN[i] = value % base;\n value = value / base;\n \n // Convert the normal baseN number into the Gray code equivalent. Note that\n // the loop starts at the most significant digit and goes down.\n unsigned shift = 0;\n while (i--) {\n // The Gray digit gets shifted down by the sum of the higher\n // digits.\n gray[i] = (baseN[i] + shift) % base;\n shift = shift + base - gray[i]; // Subtract from base so shift is positive\n// EXAMPLES\n// input: value = 1899, base = 10, digits = 4\n// output: baseN[] = [9,9,8,1], gray[] = [0,1,7,1]\n// input: value = 1900, base = 10, digits = 4\n// output: baseN[] = [0,0,9,1], gray[] = [0,1,8,1]\nThere are other Gray code algorithms for (\"n\",\"k\")-Gray codes. The (\"n\",\"k\")-Gray code produced by the above algorithm is always cyclical; some algorithms, such as that by Guan, lack this property when \"k\" is odd. On the other hand, while only one digit at a time changes with this method, it can change by wrapping (looping from \"n\"\u00a0\u2212\u00a01 to 0). In Guan's algorithm, the count alternately rises and falls, so that the numeric difference between two Gray code digits is always one.\nGray codes are not uniquely defined, because a permutation of the columns of such a code is a Gray code too. The above procedure produces a code in which the lower the significance of a digit, the more often it changes, making it similar to normal counting methods.\nSee also Skew binary number system, a variant ternary number system where at most two digits change on each increment, as each increment can be done with at most one digit carry operation.\nBalanced Gray code.\nAlthough the binary reflected Gray code is useful in many scenarios, it is not optimal in certain cases because of a lack of \"uniformity\". In balanced Gray codes, the number of changes in different coordinate positions are as close as possible. To make this more precise, let \"G\" be an \"R\"-ary complete Gray cycle having transition sequence formula_24; the \"transition counts\" (\"spectrum\") of \"G\" are the collection of integers defined by\nformula_25\nA Gray code is \"uniform\" or \"uniformly balanced\" if its transition counts are all equal, in which case we have formula_26 for all \"k\". Clearly, when formula_27, such codes exist only if \"n\" is a power of 2. If \"n\" is not a power of 2, it is possible to construct \"well-balanced\" binary codes where the difference between two transition counts is at most 2; so that (combining both cases) every transition count is either formula_28 or formula_29. Gray codes can also be \"exponentially balanced\" if all of their transition counts are adjacent powers of two, and such codes exist for every power of two.\nFor example, a balanced 4-bit Gray code has 16 transitions, which can be evenly distributed among all four positions (four transitions per position), making it uniformly balanced:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nwhereas a balanced 5-bit Gray code has a total of 32 transitions, which cannot be evenly distributed among the positions. In this example, four positions have six transitions each, and one has eight:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nWe will now show a construction and implementation for well-balanced binary Gray codes which allows us to generate an \"n\"-digit balanced Gray code for every \"n\". The main principle is to inductively construct an (\"n\"\u00a0+\u00a02)-digit Gray code formula_30 given an \"n\"-digit Gray code \"G\" in such a way that the balanced property is preserved. To do this, we consider partitions of formula_31 into an even number \"L\" of non-empty blocks of the form\nformula_32\nwhere formula_33, formula_34, and formula_35). This partition induces an formula_36-digit Gray code given by\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;formula_37\nIf we define the \"transition multiplicities\"\nformula_38\nto be the number of times the digit in position \"i\" changes between consecutive blocks in a partition, then for the (\"n\"\u00a0+\u00a02)-digit Gray code induced by this partition the transition spectrum formula_39 is\nformula_40\nThe delicate part of this construction is to find an adequate partitioning of a balanced \"n\"-digit Gray code such that the code induced by it remains balanced, but for this only the transition multiplicities matter; joining two consecutive blocks over a digit formula_2 transition and splitting another block at another digit formula_2 transition produces a different Gray code with exactly the same transition spectrum formula_39, so one may for example designate the first formula_44 transitions at digit formula_2 as those that fall between two blocks. Uniform codes can be found when formula_46 and formula_47, and this construction can be extended to the \"R\"-ary case as well.\nLong run Gray codes.\nLong run (or \"maximum gap\") Gray codes maximize the distance between consecutive changes of digits in the same position. That is, the minimum run-length of any bit remains unchanged for as long as possible.\nMonotonic Gray codes.\nMonotonic codes are useful in the theory of interconnection networks, especially for minimizing dilation for linear arrays of processors.\nIf we define the \"weight\" of a binary string to be the number of 1s in the string, then although we clearly cannot have a Gray code with strictly increasing weight, we may want to approximate this by having the code run through two adjacent weights before reaching the next one.\nWe can formalize the concept of monotone Gray codes as follows: consider the partition of the hypercube formula_48 into \"levels\" of vertices that have equal weight, i.e.\nformula_49\nfor formula_50. These levels satisfy formula_51. Let formula_52 be the subgraph of formula_53 induced by formula_54, and let formula_55 be the edges in formula_52. A monotonic Gray code is then a Hamiltonian path in formula_53 such that whenever formula_58 comes before formula_59 in the path, then formula_60.\nAn elegant construction of monotonic \"n\"-digit Gray codes for any \"n\" is based on the idea of recursively building subpaths formula_61 of length formula_62 having edges in formula_63. We define formula_64, formula_65 whenever formula_66 or formula_67, and\nformula_68\notherwise. Here, formula_69 is a suitably defined permutation and formula_70 refers to the path \"P\" with its coordinates permuted by formula_71. These paths give rise to two monotonic \"n\"-digit Gray codes formula_72 and formula_73 given by\nformula_74\nThe choice of formula_69 which ensures that these codes are indeed Gray codes turns out to be formula_76. The first few values of formula_61 are shown in the table below.\nThese monotonic Gray codes can be efficiently implemented in such a way that each subsequent element can be generated in \"O\"(\"n\") time. The algorithm is most easily described using coroutines.\nMonotonic codes have an interesting connection to the Lov\u00e1sz conjecture, which states that every connected vertex-transitive graph contains a Hamiltonian path. The \"middle-level\" subgraph formula_78 is vertex-transitive (that is, its automorphism group is transitive, so that each vertex has the same \"local environment\" and cannot be differentiated from the others, since we can relabel the coordinates as well as the binary digits to obtain an automorphism) and the problem of finding a Hamiltonian path in this subgraph is called the \"middle-levels problem\", which can provide insights into the more general conjecture. The question has been answered affirmatively for formula_79, and the preceding construction for monotonic codes ensures a Hamiltonian path of length at least 0.839\u200d\"N\", where \"N\" is the number of vertices in the middle-level subgraph.\nBeckett\u2013Gray code.\nAnother type of Gray code, the Beckett\u2013Gray code, is named for Irish playwright Samuel Beckett, who was interested in symmetry. His play \"Quad\" features four actors and is divided into sixteen time periods. Each period ends with one of the four actors entering or leaving the stage. The play begins and ends with an empty stage, and Beckett wanted each subset of actors to appear on stage exactly once. Clearly the set of actors currently on stage can be represented by a 4-bit binary Gray code. Beckett, however, placed an additional restriction on the script: he wished the actors to enter and exit so that the actor who had been on stage the longest would always be the one to exit. The actors could then be represented by a first in, first out queue, so that (of the actors onstage) the actor being dequeued is always the one who was enqueued first. Beckett was unable to find a Beckett\u2013Gray code for his play, and indeed, an exhaustive listing of all possible sequences reveals that no such code exists for \"n\" = 4. It is known today that such codes do exist for \"n\" = 2, 5, 6, 7, and 8, and do not exist for \"n\" = 3 or 4. An example of an 8-bit Beckett\u2013Gray code can be found in Donald Knuth's \"Art of Computer Programming\". According to Sawada and Wong, the search space for \"n\" = 6 can be explored in 15 hours, and more than solutions for the case \"n\" = 7 have been found.\nSnake-in-the-box codes.\nSnake-in-the-box codes, or \"snakes\", are the sequences of nodes of induced paths in an \"n\"-dimensional hypercube graph, and coil-in-the-box codes, or \"coils\", are the sequences of nodes of induced cycles in a hypercube. Viewed as Gray codes, these sequences have the property of being able to detect any single-bit coding error. Codes of this type were first described by William H. Kautz in the late 1950s; since then, there has been much research on finding the code with the largest possible number of codewords for a given hypercube dimension.\nSingle-track Gray code.\nYet another kind of Gray code is the single-track Gray code (STGC) developed by Norman B. Spedding and refined by Hiltgen, Paterson and Brandestini in \"Single-track Gray Codes\" (1996). The STGC is a cyclical list of \"P\" unique binary encodings of length n such that two consecutive words differ in exactly one position, and when the list is examined as a \"P\"\u00a0\u00d7\u00a0\"n\" matrix, each column is a cyclic shift of the first column.\nThe name comes from their use with rotary encoders, where a number of tracks are being sensed by contacts, resulting for each in an output of 0 or 1. To reduce noise due to different contacts not switching at exactly the same moment in time, one preferably sets up the tracks so that the data output by the contacts are in Gray code. To get high angular accuracy, one needs lots of contacts; in order to achieve at least 1\u00b0 accuracy, one needs at least 360 distinct positions per revolution, which requires a minimum of 9 bits of data, and thus the same number of contacts.\nIf all contacts are placed at the same angular position, then 9 tracks are needed to get a standard BRGC with at least 1\u00b0 accuracy. However, if the manufacturer moves a contact to a different angular position (but at the same distance from the center shaft), then the corresponding \"ring pattern\" needs to be rotated the same angle to give the same output. If the most significant bit (the inner ring in Figure 1) is rotated enough, it exactly matches the next ring out. Since both rings are then identical, the inner ring can be cut out, and the sensor for that ring moved to the remaining, identical ring (but offset at that angle from the other sensor on that ring). Those two sensors on a single ring make a quadrature encoder. That reduces the number of tracks for a \"1\u00b0 resolution\" angular encoder to 8 tracks. Reducing the number of tracks still further cannot be done with BRGC.\nFor many years, Torsten Sillke and other mathematicians believed that it was impossible to encode position on a single track such that consecutive positions differed at only a single sensor, except for the 2-sensor, 1-track quadrature encoder. So for applications where 8 tracks were too bulky, people used single-track incremental encoders (quadrature encoders) or 2-track \"quadrature encoder + reference notch\" encoders.\nNorman B. Spedding, however, registered a patent in 1994 with several examples showing that it was possible. Although it is not possible to distinguish 2\"n\" positions with \"n\" sensors on a single track, it \"is\" possible to distinguish close to that many. Etzion and Paterson conjecture that when \"n\" is itself a power of 2, \"n\" sensors can distinguish at most 2\"n\"\u00a0\u2212\u00a02\"n\" positions and that for prime \"n\" the limit is 2\"n\"\u00a0\u2212\u00a02 positions. The authors went on to generate a 504-position single track code of length 9 which they believe is optimal. Since this number is larger than 28 = 256, more than 8 sensors are required by any code, although a BRGC could distinguish 512 positions with 9 sensors.\nAn STGC for \"P\"\u00a0=\u00a030 and \"n\"\u00a0=\u00a05 is reproduced here:\nEach column is a cyclic shift of the first column, and from any row to the next row only one bit changes.\nThe single-track nature (like a code chain) is useful in the fabrication of these wheels (compared to BRGC), as only one track is needed, thus reducing their cost and size.\nThe Gray code nature is useful (compared to chain codes, also called De Bruijn sequences), as only one sensor will change at any one time, so the uncertainty during a transition between two discrete states will only be plus or minus one unit of angular measurement the device is capable of resolving.\nSince this 30 degree example was added, there has been a lot of interest in examples with higher angular resolution. In 2008, Gary Williams, based on previous work, discovered a 9-bit single track Gray code that gives a 1 degree resolution. This Gray code was used to design an actual device which was published on the site Thingiverse. This device was designed by etzenseep (Florian Bauer) in September 2022.\nAn STGC for \"P\"\u00a0=\u00a0360 and \"n\"\u00a0=\u00a09 is reproduced here:\nTwo-dimensional Gray code.\nTwo-dimensional Gray codes are used in communication to minimize the number of bit errors in quadrature amplitude modulation (QAM) adjacent points in the constellation. In a typical encoding the horizontal and vertical adjacent constellation points differ by a single bit, and diagonal adjacent points differ by 2 bits.\nTwo-dimensional Gray codes also have uses in location identifications schemes, where the code would be applied to area maps such as a Mercator projection of the earth's surface and an appropriate cyclic two-dimensional distance function such as the Mannheim metric be used to calculate the distance between two encoded locations, thereby combining the characteristics of the Hamming distance with the cyclic continuation of a Mercator projection.\nExcess Gray code.\nIf a subsection of a specific codevalue is extracted from that value, for example the last 3 bits of a 4-bit Gray code, the resulting code will be an \"excess Gray code\". This code shows the property of counting backwards in those extracted bits if the original value is further increased. Reason for this is that Gray-encoded values do not show the behaviour of overflow, known from classic binary encoding, when increasing past the \"highest\" value.\nExample: The highest 3-bit Gray code, 7, is encoded as (0)100. Adding 1 results in number 8, encoded in Gray as 1100. The last 3 bits do not overflow and count backwards if you further increase the original 4 bit code.\nWhen working with sensors that output multiple, Gray-encoded values in a serial fashion, one should therefore pay attention whether the sensor produces those multiple values encoded in 1 single Gray code or as separate ones, as otherwise the values might appear to be counting backwards when an \"overflow\" is expected.\nGray isometry.\nThe bijective mapping { 0 \u2194 00, 1 \u2194 01, 2 \u2194 11, 3 \u2194 10 } establishes an isometry between the metric space over the finite field formula_80 with the metric given by the Hamming distance and the metric space over the finite ring formula_81 (the usual modular arithmetic) with the metric given by the Lee distance. The mapping is suitably extended to an isometry of the Hamming spaces formula_82 and formula_83. Its importance lies in establishing a correspondence between various \"good\" but not necessarily linear codes as Gray-map images in formula_80 of ring-linear codes from formula_81.\nRelated codes.\nThere are a number of binary codes similar to Gray codes, including:\nThe following binary-coded decimal (BCD) codes are Gray code variants as well:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50565", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=50565", "title": "Executive", "text": "Executive (exe., exec., execu.) may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "50567", "revid": "88116", "url": "https://en.wikipedia.org/wiki?curid=50567", "title": "Gold code", "text": "Binary codes in telecommunications and GPS\nA Gold code, also known as Gold sequence, is a type of binary sequence, used in telecommunications (CDMA) and satellite navigation (GPS). Gold codes are named after Robert Gold. Gold codes have bounded small cross-correlations within a set, which is useful when multiple devices are broadcasting in the same frequency range. A set of Gold code sequences consists of 2\"n\" + 1 sequences each one with a period of 2\"n\" \u2212 1.\nA set of Gold codes can be generated with the following steps. Pick two maximum length sequences of the same length 2\"n\" \u2212 1 such that their absolute cross-correlation is less than or equal to 2(\"n\"+2)/2, where \"n\" is the size of the linear-feedback shift register used to generate the maximum length sequence. The set of the 2\"n\" \u2212 1 exclusive-ors of the two sequences in their various phases (i.e. translated into all relative positions) together with the two maximum length sequences form a set of 2\"n\" + 1 Gold code sequences. The highest absolute cross-correlation in this set of codes is 2(\"n\"+2)/2 + 1 for even \"n\" and 2(\"n\"+1)/2 + 1 for odd \"n\".\nThe exclusive or of two different Gold codes from the same set is another Gold code in some phase.\nWithin a set of Gold codes about half of the codes are balanced\u00a0\u2013 the number of ones and zeros differs by only one.\nGold codes are used in GPS. The GPS C/A ranging codes are Gold codes of period 1,023.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50568", "revid": "1461430", "url": "https://en.wikipedia.org/wiki?curid=50568", "title": "Personal rapid transit", "text": "Public transport mode\nPersonal rapid transit (PRT), also referred to as podcars or guided/railed taxis, is a public transport mode featuring a network of specially built guideways on which ride small automated vehicles that carry few (generally less than 6) passengers per vehicle. PRT is a type of automated guideway transit (AGT), a class of system which also includes larger vehicles all the way to small subway systems. In terms of routing, it tends towards personal public transport systems.\nPRT vehicles are sized for individual or small group travel, typically carrying no more than three to six passengers per vehicle. Guideways are arranged in a network topology, with all stations located on sidings, and with frequent merge/diverge points. This allows for nonstop, point-to-point travel, bypassing all intermediate stations. The point-to-point service has been compared to a taxi or a horizontal lift (elevator).\nNumerous PRT systems have been proposed but most have not been implemented. , only a handful of PRT systems are operational: Morgantown Personal Rapid Transit (the oldest and most extensive), in Morgantown, West Virginia, has been in continuous operation since 1975. Since 2010 a 10-vehicle 2getthere system has operated at Masdar City, UAE, and since 2011 a 21-vehicle Ultra PRT system has run at London Heathrow Airport. A 40-vehicle Vectus system with in-line stations officially opened in Suncheon, South Korea, in April 2014. A PRT system connecting the terminals and parking has been built at the new Chengdu Tianfu International Airport, which opened in 2021.\nOverview.\nMost mass transit systems move people in groups over scheduled routes. This has inherent inefficiencies. For passengers, time is wasted by waiting for the next vehicle to arrive, indirect routes to their destination, stopping for passengers with other destinations, and often confusing or inconsistent schedules. Slowing and accelerating large weights can undermine public transport's benefit to the environment while slowing other traffic.\nPersonal rapid transit systems attempt to eliminate these wastes by moving small groups nonstop in automated vehicles on fixed tracks. Passengers can ideally board a pod immediately upon arriving at a station, and can \u2013 with a sufficiently extensive network of tracks \u2013 take relatively direct routes to their destination without stops.\nThe low weight of PRT's small vehicles allows smaller guideways and support structures than mass transit systems like light rail. The smaller structures translate into lower construction costs, smaller easements, and less visually obtrusive infrastructure.\nAs it stands, a citywide deployment with many lines and closely spaced stations, as envisioned by proponents, has yet to be constructed. Past projects have failed because of financing, cost overruns, regulatory conflicts, political issues, misapplied technology, and flaws in design, engineering or review.\nHowever, the theory remains active. For example, from 2002 to 2005, the EDICT project, sponsored by the European Union, conducted a study on the feasibility of PRT in four European cities. The study involved 12 research organizations, and concluded that PRT:\nThe report also concluded that, despite these advantages, public authorities will not commit to building PRT because of the risks associated with being the first public implementation.\nThe PRT acronym was introduced formally in 1978 by J. Edward Anderson. The Advanced Transit Association (ATRA), a group which advocates the use of technological solutions to transit problems, compiled a definition in 1988 that can be seen here.\nList of operational automated transit networks (ATN) systems.\nCurrently, five advanced transit networks (ATN) systems are operational, and several more are in the planning stage.\nIn addition, one PRT has completed construction but has not been commissioned.\nList of ATN suppliers.\nThe following list summarizes several well-known automated transit networks (ATN) suppliers as of 2014, with subsequent amendments.\nHistory.\nOrigins.\nModern PRT concepts began around 1953 when Donn Fichter, a city transportation planner, began research on PRT and alternative transportation methods. In 1964, Fichter published a book which proposed an automated public transit system for areas of medium to low population density. One of the key points made in the book was Fichter's belief that people would not leave their cars in favor of public transit unless the system offered flexibility and end-to-end transit times that were much better than existing systems \u2013 flexibility and performance he felt only a PRT system could provide. Several other urban and transit planners also wrote on the topic and some early experimentation followed, but PRT remained relatively unknown.\nAround the same time, Edward Haltom was studying monorail systems. Haltom noticed that the time to start and stop a conventional large monorail train, like those of the Wuppertal Schwebebahn, meant that a single line could only support between 20 and 40 vehicles an hour. In order to get reasonable passenger movements on such a system, the trains had to be large enough to carry hundreds of passengers (see headway for a general discussion). This, in turn, demanded large guideways that could support the weight of these large vehicles, driving up capital costs to the point where he considered them unattractive.\nHaltom turned his attention to developing a system that could operate with shorter timings, thereby allowing the individual cars to be smaller while preserving the same overall route capacity. Smaller cars would mean less weight at any given point, which meant smaller and less expensive guideways. To eliminate the backup at stations, the system used \"offline\" stations that allowed the mainline traffic to bypass the stopped vehicles. He designed the Monocab system using six-passenger cars suspended on wheels from an overhead guideway. Like most suspended systems, it suffered from the problem of difficult switching arrangements. Since the car rode on a rail, switching from one path to another required the rail to be moved, a slow process that limited the possible headways.\nUMTA is formed.\nBy the late 1950s the problems with urban sprawl were becoming evident in the United States. When cities improved roads and the transit times were lowered, suburbs developed at ever increasing distances from the city cores, and people moved out of the downtown areas. Lacking pollution control systems, the rapid rise in car ownership and the longer trips to and from work were causing significant air quality problems. Additionally, movement to the suburbs led to a flight of capital from the downtown areas, one cause of the rapid urban decay seen in the US.\nMass transit systems were one way to combat these problems. Yet during this period, the federal government was feeding the problems by funding the development of the Interstate Highway System, while at the same time funding for mass transit was being rapidly scaled back. Public transit ridership in most cities plummeted.\nIn 1962, President John F. Kennedy charged Congress with the task of addressing these problems. These plans came to fruition in 1964, when President Lyndon B. Johnson signed the Urban Mass Transportation Act of 1964 into law, thereby forming the Urban Mass Transportation Administration. UMTA was set up to fund mass transit developments in the same fashion that the earlier Federal Aid Highway Act of 1956 had helped create the Interstate Highways. That is, UMTA would help cover the capital costs of building out new infrastructure.\nPRT research starts.\nHowever, planners who were aware of the PRT concept were worried that building more systems based on existing technologies would not help the problem, as Fitcher had earlier noted. Proponents suggested that systems would have to offer the flexibility of a car:\nThe reason for the sad state of public transit is a very basic one \u2013 the transit systems just do not offer a service which will attract people away from their automobiles. Consequently, their patronage comes very largely from those who cannot drive, either because they are too young, too old, or because they are too poor to own and operate an automobile. Look at it from the standpoint of a commuter who lives in a suburb and is trying to get to work in the central business district (CBD). If he is going to go by transit, a typical scenario might be the following: he must first walk to the closest bus stop, let us say a five or ten minute walk, and then he may have to wait up to another ten minutes, possibly in inclement weather, for the bus to arrive. When it arrives, he may have to stand unless he is lucky enough to find a seat. The bus will be caught up in street congestion and move slowly, and it will make many stops completely unrelated to his trip objective. The bus may then let him off at a terminal to a suburban train. Again he must wait, and, after boarding the train, again experience a number of stops on the way to the CBD, and possibly again he may have to stand in the aisle. He will get off at the station most convenient to his destination and possibly have to transfer again onto a distribution system. It is no wonder that in those cities where ample inexpensive parking is available, most of those who can drive do drive.\nIn 1966, the United States Department of Housing and Urban Development was asked to \"undertake a project to study ... new systems of urban transportation that will carry people and goods ... speedily, safely, without polluting the air, and in a manner that will contribute to sound city planning.\" The resulting report was published in 1968 and proposed the development of PRT, as well as other systems such as dial-a-bus and high-speed interurban links.\nIn the late 1960s, the Aerospace Corporation, an independent non-profit corporation set up by the US Congress, spent substantial time and money on PRT, and performed much of the early theoretical and systems analysis. However, this corporation is not allowed to sell to non-federal government customers. In 1969, members of the study team published the first widely publicized description of PRT in \"Scientific American\".\nIn 1978 the team also published a book. These publications sparked off a sort of \"transit race\" in the same sort of fashion as the space race, with countries around the world rushing to join what appeared to be a future market of immense size.\nThe oil crisis of 1973 made vehicle fuels more expensive, which naturally interested people in alternative transportation.\nSystem developments.\nIn 1967, aerospace giant Matra started the Aramis project in Paris. After spending about 500 million francs, the project was canceled when it failed its qualification trials in November 1987. The designers tried to make Aramis work like a \"virtual train\", but control software issues caused cars to bump unacceptably. The project ultimately failed.\nBetween 1970 and 1978, Japan operated a project called \"Computer-controlled Vehicle System\" (CVS). In a full-scale test facility, 84 vehicles operated at speeds up to on a guideway; one-second headways were achieved during tests. Another version of CVS was in public operation for six months from 1975 to 1976. This system had 12 single-mode vehicles and four dual-mode vehicles on a track with five stations. This version carried over 800,000 passengers. CVS was cancelled when Japan's Ministry of Land, Infrastructure and Transport declared it unsafe under existing rail safety regulations, specifically in respect of braking and headway distances.\nOn March 23, 1973, U.S. Urban Mass Transportation Administration (UMTA) administrator Frank Herringer testified before Congress: \"A DOT program leading to the development of a short, one-half to one-second headway, high-capacity PRT (HCPRT) system will be initiated in fiscal year 1974.\" According to PRT supporter J. Edward Anderson, this was \"because of heavy lobbying from interests fearful of becoming irrelevant if a genuine PRT program became visible.\" From that time forward people interested in HCPRT were unable to obtain UMTA research funding.\nIn 1975, the Morgantown Personal Rapid Transit project was completed. It has five off-line stations that enable non-stop, individually programmed trips along an track serviced by a fleet of 71 cars. This is a crucial characteristic of PRT. However, it is not considered a PRT system because its vehicles are too heavy and carry too many people. When it carries many people, it operates in a point-to-point fashion, instead of running like an automated people mover from one end of the line to the other. During periods of low usage all cars make a full circuit stopping at every station in both directions. Morgantown PRT is still in continuous operation at West Virginia University in Morgantown, West Virginia, with about 15,000 riders per day (as of 2003[ [update]]). The steam-heated track has proven expensive and the system requires an operation and maintenance budget of $5 million annually. Although it successfully demonstrated automated control and it is still operating it was not sold to other sites. A 2010 report concluded replacing the system with buses on roads would provide unsatisfactory service and create congestion. Subsequently, the forty year old computer and vehicle control systems were replaced in the 2010s and there are plans to replace the vehicles.\nFrom 1969 to 1980, Mannesmann Demag and MBB cooperated to build the \"Cabinentaxi\" urban transportation system in Germany. Together the firms formed the Cabintaxi Joint Venture. They created an extensive PRT technology, including a test track, that was considered fully developed by the German government and its safety authorities. The system was to have been installed in Hamburg, but budget cuts stopped the proposed project before the start of construction. With no other potential projects on the horizon, the joint venture disbanded, and the fully developed PRT technology was never installed. Cabintaxi Corporation, a US-based company, obtained the technology in 1985, and remains active in the private-sector market trying to sell the system but so far there have been no installations.\nIn 1979 the three station Duke University Medical Center Patient Rapid Transit system was commissioned. Uniquely, the cars could move sideways, as well as backwards and forwards and it was described as a \"horizontal elevator\". The system was closed in 2009 to allow for expansion of the hospital.\nIn the 1990s, Raytheon invested heavily in a system called PRT 2000, based on technology developed by J. Edward Anderson at the University of Minnesota. Raytheon failed to install a contracted system in Rosemont, Illinois, near Chicago, when estimated costs escalated to US$50 million per mile, allegedly due to design changes that increased the weight and cost of the system relative to Anderson's original design. In 2000, rights to the technology reverted to the University of Minnesota, and were subsequently purchased by Taxi2000.\nLater developments.\nIn 1999 the 2getthere designed ParkShuttle system was opened in the Kralingen neighbourhood of eastern Rotterdam using 12-seater driverless buses. The system was extended in 2005 and new second-generation vehicles introduced to serve five stations over with five grade crossings over ordinary roads. Operation is scheduled in peak periods and on demand at other times. In 2002, 2getthere operated twenty five 4-passenger \"CyberCabs\" at Holland's 2002 Floriade horticultural exhibition. These transported passengers along a track spiraling up to the summit of Big Spotters Hill. The track was approximately long (one-way) and featured only two stations. The six-month operation was intended to research the public acceptance of PRT-like systems.\nIn 2010 a 10-vehicle (four seats each), two station 2getthere system was opened to connect a parking lot to the main area at Masdar City, UAE. The systems runs in an undercroft beneath the city and was supposed to be a pilot project for a much larger network, which would also have included transport of freight. Expansion of the system was cancelled just after the pilot scheme opened due to the cost of constructing the undercroft and since then other electric vehicles have been proposed.\nIn January 2003, the prototype ULTra (\"Urban Light Transport\") system in Cardiff, Wales, was certified to carry passengers by the UK Railway Inspectorate on a test track. ULTra was selected in October 2005 by BAA plc for London's Heathrow Airport. Since May 2011 a three-station system has been open to the public, transporting passengers from a remote parking lot to terminal 5. During the deployment of the system the owners of Heathrow became owners of the UltrPRT design. In May 2013 Heathrow Airport Limited included in its draft five-year (2014\u20132019) master plan a scheme to use the PRT system to connect terminal 2 and terminal 3 to their respective business car parks. The proposal was not included in the final plan due to spending priority given to other capital projects and has been deferred. If a third runway is constructed at Heathrow will destroy the existing system, which will be built over, will be replaced by another PRT.\nIn June 2006, a Korean/Swedish consortium, Vectus Ltd, started constructing a test track in Uppsala, Sweden. This test system was presented at the 2007 PodCar City conference in Uppsala. A 40-vehicle, 2-station, system called \"SkyCube\" was opened in Suncheon, South Korea, in April 2014.\nIn the 2010s the Mexican Western Institute of Technology and Higher Education began research into project LINT (\"Lean Intelligent Network Transportation\") and built a 1/12 operational scale model. This was further developed and became the Modutram system and a full-scale test track was built in Guadalajara, which was operational by 2014.\nIn 2018 it was announced that a PRT system would be installed at the new Chengdu Tianfu International Airport. The system will include 6 miles of guideway, 4 stations, 22 pods and will connect airport parking to two terminal buildings. It is supplied by Ultra MTS. The airport is due to open in 2021.\nSystem design.\nAmong the handful of prototype systems (and the larger number that exist on paper) there is a substantial diversity of design approaches, some of which are controversial.\nVehicle design.\nVehicle weight influences the size and cost of a system's guideways, which are in turn a major part of the capital cost of the system. Larger vehicles are more expensive to produce, require larger and more expensive guideways, and use more energy to start and stop. If vehicles are too large, point-to-point routing also becomes more expensive. Against this, smaller vehicles have more surface area per passenger (thus have higher total air resistance which dominates the energy cost of keeping vehicles moving at speed), and larger motors are generally more efficient than smaller ones.\nThe number of riders who will share a vehicle is a key unknown. In the U.S., the average car carries 1.16 persons, and most industrialized countries commonly average below two people; not having to share a vehicle with strangers is a key advantage of private transport. Based on these figures, some have suggested that two passengers per vehicle (such as with skyTran, EcoPRT and Glydways), or even a single passenger per vehicle is optimum. Other designs use a car for a model, and choose larger vehicles, making it possible to accommodate families with small children, riders with bicycles, disabled passengers with wheelchairs, or a pallet or two of freight.\nPropulsion.\nAll current designs (except for the human-powered Shweeb) are powered by electricity. In order to reduce vehicle weight, power is generally transmitted via lineside conductors although two of the operating systems use on-board batteries. According to the designer of Skyweb/Taxi2000, J. Edward Anderson, the lightest system uses linear induction motor (LIM) on the vehicle for both propulsion and braking, which also makes manoeuvres consistent regardless of the weather, especially rain or snow. LIMs are used in a small number of rapid transit applications, but most designs use rotary motors. Most such systems retain a small on-board battery to reach the next stop after a power failure. CabinTaxi uses a LIM and was able to demonstrate 0.5 second headways on its test track. The Vectus prototype system used continuous track mounted LIMs with the reaction plate on the vehicle, eliminating the active propulsion system (and power required) on the vehicle.\nULTra and 2getthere use on-board batteries, recharged at stations. This increases the safety, and reduces the complexity, cost and maintenance of the guideway. As a result, the ULTRa guideway resembles a sidewalk with curbs and is inexpensive to construct. ULTRa and 2getthere vehicles resembles small automated electric cars, and use similar components. (The ULTRa POD chassis and cabin have been used as the basis of a shared autonomous vehicle for running in mixed traffic.)\nSwitching.\nAlmost all designs avoid track switching, instead advocating vehicle-mounted switches (which engage with special guiderails at the junctions) or conventional steering. Advocates say that vehicle-switching permits faster routing so vehicles can run closer together which increases capacity. It also simplifies the guideway, makes junctions less visually obtrusive and reduces the impact of malfunctions, because a failed switch on one vehicle is less likely to affect other vehicles.\nTrack switching greatly increases headway distance. A vehicle must wait for the previous vehicle to clear the junction, for the track to switch and for the switch to be verified. Communication between the vehicle and wayside controllers adds both delays and more points of failure. If the track switching is faulty, vehicles must be able to stop before reaching the switch, and all vehicles approaching the failed junction would be affected.\nMechanical vehicle switching minimizes inter-vehicle spacing or headway distance, but it also increases the minimum distances between consecutive junctions. A mechanically switching vehicle, maneuvering between two adjacent junctions with different switch settings, cannot proceed from one junction to the next. The vehicle must adopt a new switch position, and then wait for the in-vehicle switch's locking mechanism to be verified. If the vehicle switching is faulty, that vehicle must be able to stop before reaching the next switch, and all vehicles approaching the failed vehicle would be affected.\nConventional steering allows a simpler 'track' consisting only of a road surface with some form of reference for the vehicle's steering sensors. Switching would be accomplished by the vehicle following the appropriate reference line \u2013 maintaining a set distance from the left roadway edge would cause the vehicle to diverge left at a junction, for example.\nInfrastructure design.\nGuideways.\nSeveral types of guideways have been proposed or implemented, including beams similar to monorails, bridge-like trusses supporting internal tracks, and cables embedded in a roadway. Most designs put the vehicle on top of the track, which reduces visual intrusion and cost, as well as easing ground-level installation. An overhead track is necessarily higher, but may also be narrower. Most designs use the guideway to distribute power and data communications, including to the vehicles. The Morgantown PRT failed its cost targets because of the steam-heated track required to keep the large channel guideway free of frequent snow and ice. Heating uses up to four times as much as energy as that used to propel the vehicles. Most proposals plan to resist snow and ice in ways that should be less expensive. The Heathrow system has a special de-icing vehicle. Masdar's system has been limited because the exclusive right-of-way for the PRT was gained by running the vehicles in an undercroft at ground-level while building an elevated \"street level\" between all the buildings. This led to unrealistically expensive buildings and roads.\nStations.\nProposals usually have stations close together, and located on side tracks so that through traffic can bypass vehicles picking up or dropping off passengers. Each station might have multiple berths, with perhaps one-third of the vehicles in a system being stored at stations waiting for passengers. Stations are envisioned to be minimalistic, without facilities such as rest rooms. For elevated stations, an elevator may be required for accessibility.\nAt least one system, Metrino, provides wheelchair and freight access by using a cogway in the track, so that the vehicle itself can go from a street-level stop to an overhead track.\nSome designs have included substantial extra expense for the track needed to decelerate to and accelerate from stations. In at least one system, Aramis, this nearly doubled the width and cost of the required right-of-way and caused the nonstop passenger delivery concept to be abandoned. Other designs have schemes to reduce this cost, for example merging vertically to reduce the footprint.\nOperational characteristics.\nHeadway distance.\nSpacing of vehicles on the guideway influences the maximum passenger capacity of a track, so designers prefer smaller headway distances. Computerized control and active electronic braking (of motors) theoretically permit much closer spacing than the two-second headways recommended for cars at speed. In these arrangements, multiple vehicles operate in \"platoons\" and can be braked simultaneously. There are prototypes for automatic guidance of private cars based on similar principles.\nVery short headways are controversial. The UK Railway Inspectorate has evaluated the ULTra design and is willing to accept one-second headways, pending successful completion of initial operational tests at more than 2 seconds. In other jurisdictions, preexisting rail regulations apply to PRT systems (see CVS, above); these typically calculate headways for absolute stopping distances with standing passengers. These severely restrict capacity and make PRT systems infeasible. Another standard said trailing vehicles must stop if the vehicle in front stopped instantaneously (or like a \"brick wall\"). In 2018 a committee of the American Society of Mechanical Engineers considered replacing the \"brick wall\" standard with a requirement for vehicles to maintain a safe \"separation zone\" based on the minimum stopping distance of the lead vehicle and the maximum stopping of the trailing vehicle. These changes were introduced into the standard in 2021.\nCapacity.\nPRT is usually proposed as an alternative to rail systems, so comparisons tend to be with rail. PRT vehicles seat fewer passengers than trains and buses, and must offset this by combining higher average speeds, diverse routes, and shorter headways. Proponents assert that equivalent or higher overall capacity can be achieved by these means.\nSingle line capacity.\nWith two-second headways and four-person vehicles, a single PRT line can achieve theoretical maximum capacity of 7,200 passengers per hour. However, most estimates assume that vehicles will not generally be filled to capacity, due to the point-to-point nature of PRT. At a more typical average vehicle occupancy of 1.5 persons per vehicle, the maximum capacity is 2,700 passengers per hour. Some researchers have suggested that rush hour capacity can be improved if operating policies support ridesharing.\nCapacity is inversely proportional to headway. Therefore, moving from two-second headways to one-second headways would double PRT capacity. Half-second headways would quadruple capacity. Theoretical minimum PRT headways would be based on the mechanical time to engage brakes, and these are much less than a half second. Researchers suggest that high capacity PRT (HCPRT) designs could operate safely at half-second headways, which has already been achieved in practice on the Cabintaxi test track in the late 1970s. Using the above figures, capacities above 10,000 passengers per hour seem in reach.\nIn simulations of rush hour or high-traffic events, about one-third of vehicles on the guideway need to travel empty to resupply stations with vehicles in order to minimize response time. This is analogous to trains and buses travelling nearly empty on the return trip to pick up more rush hour passengers.\nGrade separated light rail systems can move 15,000 passengers per hour on a fixed route, but these are usually fully grade separated systems. Street level systems typically move up to 7,500 passengers per hour. Heavy rail subways can move 50,000 passengers per hour per direction. As with PRT, these estimates depend on having enough trains.\nNeither light nor heavy rail scales operated efficiently in off-peak when capacity utilization is low but a schedule must be maintained. In a PRT system when demand is low, surplus vehicles will be configured to stop at empty stations at strategically placed points around the network. This enables an empty vehicle to quickly be despatched to wherever it is required, with minimal waiting time for the passenger. PRT systems will have to re-circulate empty vehicles if there is an imbalance in demand along a route, as is common in peak periods.\nNetworked PRT capacity.\nThe above discussion compares line or corridor capacity and may therefore not be relevant for a networked PRT system, where several parallel lines (or parallel components of a grid) carry traffic. In addition, Muller estimated that while PRT may need more than one guideway to match the capacity of a conventional system, the capital cost of the multiple guideways may still be less than that of the single guideway conventional system. Thus comparisons of line capacity should also consider the cost per line.\nPRT systems should require much less horizontal space than existing metro systems, with individual cars being typically around 50% as wide for side-by-side seating configurations, and less than 33% as wide for single-file configurations. This is an important factor in densely populated, high-traffic areas.\nTravel speed.\nFor a given peak speed, nonstop journeys are about three times as fast as those with intermediate stops. This is not just because of the time for starting and stopping. Scheduled vehicles are also slowed by boardings and exits for multiple destinations.\nTherefore, a given PRT seat transports about three times as many passenger miles per day as a seat performing scheduled stops. So PRT should also reduce the number of needed seats threefold for a given number of passenger miles.\nWhile a few PRT designs have operating speeds of , and one as high as , most are in the region of . Rail systems generally have higher maximum speeds, typically and sometimes well in excess of , but average travel speed is reduced about threefold by scheduled stops and passenger transfers.\nRidership attraction.\nIf PRT designs deliver the claimed benefit of being substantially faster than cars in areas with heavy traffic, simulations suggest that PRT could attract many more car drivers than other public transit systems. Standard mass transit simulations accurately predict that 2% of trips (including cars) will switch to trains. Similar methods predict that 11% to 57% of trips would switch to PRT, depending on its costs and delays.\nControl algorithms.\nThe typical control algorithm places vehicles in imaginary moving \"slots\" that go around the loops of track. Real vehicles are allocated a slot by track-side controllers. Traffic jams are prevented by placing north\u2013south vehicles in even slots, and east/west vehicles in odd slots. At intersections, the traffic in these systems can interpenetrate without slowing.\nOn-board computers maintain their position by using a negative feedback loop to stay near the center of the commanded slot. Early PRT vehicles measured their position by adding up the distance using odometers, with periodic check points to compensate for cumulative errors. Next-generation GPS and radio location could measure positions as well.\nAnother system, \"pointer-following control\", assigns a path and speed to a vehicle, after verifying that the path does not violate the safety margins of other vehicles. This permits system speeds and safety margins to be adjusted to design or operating conditions, and may use slightly less energy. The maker of the ULTra PRT system reports that testing of its control system shows lateral (side-to-side) accuracy of 1\u00a0cm, and docking accuracy better than 2\u00a0cm.\nSafety.\nComputer control eliminates errors from human drivers, so PRT designs in a controlled environment should be much safer than private motoring on roads. Most designs enclose the running gear in the guideway to prevent derailments. Grade-separated guideways would prevent conflict with pedestrians or manually controlled vehicles. Other public transit safety engineering approaches, such as redundancy and self-diagnosis of critical systems, are also included in designs.\nThe Morgantown system, more correctly described as a Group Rapid Transit (GRT) type of Automated Guideway Transit system (AGT), has completed 110 million passenger-miles without serious injury. According to the U.S. Department of Transportation, AGT systems as a group have higher injury rates than any other form of rail-based transit (subway, metro, light rail, or commuter rail) though still much better than ordinary buses or cars. More recent research by the British company ULTra PRT reported that AGT systems have a better safety than more conventional, non-automated modes.\nAs with many current transit systems, personal passenger safety concerns are likely to be addressed through CCTV monitoring, and communication with a central command center from which engineering or other assistance may be dispatched.\nEnergy efficiency.\nThe energy efficiency advantages claimed by PRT proponents include two basic operational characteristics of PRT: an increased average load factor; and the elimination of intermediate starting and stopping.\nAverage load factor, in transit systems, is the ratio of the total number of riders to the total theoretical capacity. A transit vehicle running at full capacity has a 100% load factor, while an empty vehicle has 0% load factor. If a transit vehicle spends half the time running at 100% and half the time running at 0%, the \"average\" load factor is 50%. Higher average load factor corresponds to lower energy consumption per passenger, so designers attempt to maximize this metric.\nScheduled mass transit (i.e. buses or trains) trades off service frequency and load factor. Buses and trains must run on a predefined schedule, even during off-peak times when demand is low and vehicles are nearly empty. So to increase load factor, transportation planners try to predict times of low demand, and run reduced schedules or smaller vehicles at these times. This increases passengers' wait times. In many cities, trains and buses do not run at all at night or on weekends.\nPRT vehicles, in contrast, would only move in response to demand, which places a theoretical lower bound on their average load factor. This allows 24-hour service without many of the costs of scheduled mass transit. \nULTra PRT estimates its system will consume 839 BTU per passenger mile (0.55 MJ per passenger km). By comparison, cars consume 3,496 BTU, and personal trucks consume 4,329 BTU per passenger mile.\nDue to PRT's efficiency, some proponents say solar becomes a viable power source. PRT elevated structures provide a ready platform for solar collectors, therefore some proposed designs include solar power as a characteristic of their networks.\nFor bus and rail transit, the energy per passenger-mile depends on the ridership and the frequency of service. Therefore, the energy per passenger-mile can vary significantly from peak to non-peak times. In the US, buses consume an average of 4,318 BTU/passenger-mile, transit rail 2,750 BTU/passenger-mile, and commuter rail 2,569 BTU/passenger-mile.\nOpposition and controversy.\nOpponents to PRT schemes have expressed a number of concerns:\nTechnical feasibility debate.\nVukan R. Vuchic, professor of Transportation Engineering at the University of Pennsylvania and a proponent of traditional forms of transit, has stated his belief that the combination of small vehicles and expensive guideway makes it highly impractical in both cities (not enough capacity) and suburbs (guideway too expensive). According to Vuchic: \"...the PRT concept combines two mutually incompatible elements of these two systems: very small vehicles with complicated guideways and stations. Thus, in central cities, where heavy travel volumes could justify investment in guideways, vehicles would be far too small to meet the demand. In suburbs, where small vehicles would be ideal, the extensive infrastructure would be economically unfeasible and environmentally unacceptable.\"\nPRT supporters claim that Vuchic's conclusions are based on flawed assumptions. PRT proponent J.E. Anderson wrote, in a rebuttal to Vuchic: \"I have studied and debated with colleagues and antagonists every objection to PRT, including those presented in papers by Professor Vuchic, and find none of substance. Among those willing to be briefed in detail and to have all of their questions and concerns answered, I find great enthusiasm to see the system built.\"\nThe manufacturers of ULTra acknowledge that current forms of their system would provide insufficient capacity in high-density areas such as central London, and that the investment costs for the tracks and stations are comparable to building new roads, making the current version of ULTra more suitable for suburbs and other moderate capacity applications, or as a supplementary system in larger cities.\nRegulatory concerns.\nPossible regulatory concerns include emergency safety, headways, and accessibility for the disabled. Many jurisdictions regulate PRT systems as if they were trains. At least one successful prototype, CVS, failed deployment because it could not obtain permits from regulators.\nSeveral PRT systems have been proposed for California, but the California Public Utilities Commission (CPUC) states that its rail regulations apply to PRT, and these require railway-sized headways. The degree to which CPUC would hold PRT to \"light rail\" and \"rail fixed guideway\" safety standards is not clear because it can grant particular exemptions and revise regulations.\nOther forms of automated transit have been approved for use in California, notably the Airtrain system at SFO. CPUC decided not to require compliance with General Order 143-B (for light rail) since Airtrain has no on-board operators. They did require compliance with General Order 164-D which mandates a safety and security plan, as well as periodic on-site visits by an oversight committee.\nIf safety or access considerations require the addition of walkways, ladders, platforms or other emergency/disabled access to or egress from PRT guideways, the size of the guideway may be increased. This may impact the feasibility of a PRT system, though the degree of impact would depend on both the PRT design and the municipality.\nConcerns about PRT research.\nWayne D. Cottrell of the University of Utah conducted a critical review of PRT academic literature since the 1960s. He concluded that there are several issues that would benefit from more research, including urban integration, risks of PRT investment, bad publicity, technical problems, and competing interests from other transport modes. He suggests that these issues, \"while not unsolvable, are formidable,\" and that the literature might be improved by better introspection and criticism of PRT. He also suggests that more government funding is essential for such research to proceed, especially in the United States.\nNew urbanist opinion.\nSeveral proponents of new urbanism, an urban design movement that advocates for walkable cities, have expressed opinions on PRT.\nPeter Calthorpe and Sir Peter Hall have supported the concept, but James Howard Kunstler disagrees.\nPRT vs. autonomous vehicles.\nAs the development of self-steering technology for autonomous cars and shuttles advances, the guideway technology of PRT seems obsolete at first glance. Automated operation might become feasible on existing roads too. On the other hand, PRT systems can also make use of self-steering technology and significant benefits remain from operating on a segregated route network.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50571", "revid": "6979398", "url": "https://en.wikipedia.org/wiki?curid=50571", "title": "Transportation engineering", "text": "Academic discipline and occupational field\nTransportation engineering or transport engineering is the application of technology and scientific principles to the planning, functional design, operation and management of facilities for any mode of transportation to provide for the safe, efficient, rapid, comfortable, convenient, economical, and environmentally compatible movement of people and goods transport.Transportation engineering is considered a sub discipline of civil engineering, focusing on infrastructure systems that enable mobility of people and goods.It addresses both passenger and freight systems, balancing safety, cost effectiveness, and environmental impact.\nTheory.\nThe planning aspects of transportation engineering relate to elements of urban planning, and involve technical forecasting decisions and political factors. Technical forecasting of passenger travel usually involves an urban transportation planning model, requiring the estimation of trip generation, trip distribution, mode choice, and route assignment. More sophisticated forecasting can include other aspects of traveler decisions, including auto ownership, trip chaining (the decision to link individual trips together in a tour) and the choice of residential or business location (known as land use forecasting). Four step travel demand models remain the standard tool for forecasting urban transport needs worldwide.Passenger trips are the focus of transportation engineering because they often represent the peak of demand on any transportation system.\nA review of descriptions of the scope of various committees indicates that while facility planning and design continue to be the core of the transportation engineering field, such areas as operations planning, logistics, network analysis, financing, and policy analysis are also important, particularly to those working in highway and urban transportation. The National Council of Examiners for Engineering and Surveying (NCEES) list online the safety protocols, geometric design requirements, and signal timing.\nTransportation engineering, primarily involves planning, design, construction, maintenance, and operation of transportation facilities. The facilities support air, highway, railroad, pipeline, water, and even space transportation. The design aspects of transportation engineering include the sizing of transportation facilities (how many lanes or how much capacity the facility has), determining the materials and thickness used in pavement designing the geometry (vertical and horizontal alignment) of the roadway (or track).\nBefore any planning occurs an engineer must take what is known as an inventory of the area or, if it is appropriate, the previous system in place. This inventory or database must include information on population, land use, economic activity, transportation facilities and services, travel patterns and volumes, laws and ordinances, regional financial resources, and community values and expectations. These inventories help the engineer create business models to complete accurate forecasts of the future conditions of the system. Advances in data collection, such as GPS and mobile phone tracking, have improved the accuracy of transport demand modeling.\nOperations and management involve traffic engineering, so that vehicles move smoothly on the road or track. Intelligent transportation systems (ITS) use communication technologies to manage traffic congestion and incidents in real time. Older techniques include signs, signals, markings, and tolling. Newer technologies involve intelligent transportation systems, including advanced traveler information systems (such as variable message signs), advanced traffic control systems (such as ramp meters), and vehicle infrastructure integration. Adaptive traffic signal control has been shown to reduce delays and fuel consumption at intersections.Human factors are an aspect of transportation engineering, particularly concerning driver-vehicle interface and user interface of road signs, signals, and markings.\nSpecialization.\nHighway engineering.\nEngineers in this specialization:\nRailroad engineering.\nRailway engineers handle the design, construction, and operation of railroads and mass transit systems that use a fixed guideway (such as light rail or monorails).\nTypical tasks include:\nRailway engineers work to build a cleaner and safer transportation network by reinvesting and revitalizing the rail system to meet future demands. In the United States, railway engineers work with elected officials in Washington, D.C., on rail transportation issues to make sure that the rail system meets the country's transportation needs.Railway systems engineering incorporates safety systems such as Positive Train Control (PTC) in the U.S to reduce collisions.\nRailroad engineers can also move into the specialized field of train dispatching which focuses on train movement control.\nPort and harbor engineering.\nPort and harbor engineers handle the design, construction, and operation of ports, harbors, canals, and other maritime facilities. Port and harbor engineers also address dredging, breakwater design, and environmental protection.\nAirport engineering.\nAirport engineers design and construct airports. Airport engineers must account for the impacts and demands of aircraft in their design of airport facilities. These engineers must use the analysis of predominant wind direction to determine runway orientation, determine the size of runway border and safety areas, different wing tip to wing tip clearances for all gates and must designate the clear zones in the entire port. The Civil Engineering Department, consisting of Civil and Structural Engineers, undertakes the structural design of passenger, terminal design and cargo terminals, aircraft hangars (for parking commercial, private and government aircraft), runways and other pavements, technical buildings for installation of airport ground aids etc. for the airports in-house requirements and consultancy projects. They are even responsible for the master plan for airports they are authorized to work with.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50572", "revid": "1", "url": "https://en.wikipedia.org/wiki?curid=50572", "title": "Well-ordered", "text": ""}
{"id": "50573", "revid": "1", "url": "https://en.wikipedia.org/wiki?curid=50573", "title": "Well-ordering", "text": ""}
{"id": "50574", "revid": "205121", "url": "https://en.wikipedia.org/wiki?curid=50574", "title": "Rolling Stones", "text": ""}
{"id": "50576", "revid": "1", "url": "https://en.wikipedia.org/wiki?curid=50576", "title": "Well ordered", "text": ""}
{"id": "50577", "revid": "1", "url": "https://en.wikipedia.org/wiki?curid=50577", "title": "Well ordering", "text": ""}
{"id": "50578", "revid": "31737083", "url": "https://en.wikipedia.org/wiki?curid=50578", "title": "Queueing theory", "text": "Mathematical study of waiting lines, or queues\nQueueing theory is the mathematical study of waiting lines, or queues. A queueing model is constructed so that queue lengths and waiting time can be predicted. Queueing theory is generally considered a branch of operations research because the results are often used when making business decisions about the resources needed to provide a service.\nQueueing theory has its origins in research by Agner Krarup Erlang, who created models to describe the system of incoming calls at the Copenhagen Telephone Exchange Company. These ideas were seminal to the field of teletraffic engineering and have since seen applications in telecommunications, traffic engineering, computing, project management, and particularly industrial engineering, where they are applied in the design of factories, shops, offices, and hospitals.\nSpelling.\nThe spelling \"queueing\" over \"queuing\" is typically encountered in the academic research field. In fact, one of the flagship journals of the field is \"Queueing Systems\".\nDescription.\nQueueing theory is one of the major areas of study in the discipline of management science. Through management science, businesses are able to solve a variety of problems using different scientific and mathematical approaches. Queueing analysis is the probabilistic analysis of waiting lines, and thus the results, also referred to as the operating characteristics, are probabilistic rather than deterministic. The probability that n customers are in the queueing system, the average number of customers in the queueing system, the average number of customers in the waiting line, the average time spent by a customer in the total queuing system, the average time spent by a customer in the waiting line, and finally the probability that the server is busy or idle are all of the different operating characteristics that these queueing models compute. The overall goal of queueing analysis is to compute these characteristics for the current system and then test several alternatives that could lead to improvement. Computing the operating characteristics for the current system and comparing the values to the characteristics of the alternative systems allows managers to see the pros and cons of each potential option. These systems help in the final decision making process by showing ways to increase savings, reduce waiting time, improve efficiency, etc. The main queueing models that can be used are the single-server waiting line system and the multiple-server waiting line system, which are discussed further below. These models can be further differentiated depending on whether service times are constant or undefined, the queue length is finite, the calling population is finite, etc.\nSingle queueing nodes.\nA \"queue\" or \"queueing node\" can be thought of as nearly a black box. \"Jobs\" (also called \"customers\" or \"requests\", depending on the field) arrive to the queue, possibly wait some time, take some time being processed, and then depart from the queue.\nHowever, the queueing node is not quite a pure black box since some information is needed about the inside of the queueing node. The queue has one or more \"servers\" which can each be paired with an arriving job. When the job is completed and departs, that server will again be free to be paired with another arriving job.\nAn analogy often used is that of the cashier at a supermarket. Customers arrive, are processed by the cashier, and depart. Each cashier processes one customer at a time, and hence this is a queueing node with only one server. A setting where a customer will leave immediately if the cashier is busy when the customer arrives, is referred to as a queue with no \"buffer\" (or no \"waiting area\"). A setting with a waiting zone for up to \"n\" customers is called a queue with a buffer of size \"n\".\nBirth-death process.\nThe behaviour of a single queue (also called a \"queueing node\") can be described by a birth\u2013death process, which describes the arrivals and departures from the queue, along with the number of jobs currently in the system. If \"k\" denotes the number of jobs in the system (either being serviced or waiting if the queue has a buffer of waiting jobs), then an arrival increases \"k\" by 1 and a departure decreases \"k\" by 1.\nThe system transitions between values of \"k\" by \"births\" and \"deaths\", which occur at the arrival rates formula_1 and the departure rates formula_2 for each job formula_3. For a queue, these rates are generally considered not to vary with the number of jobs in the queue, so a single average rate of arrivals/departures per unit time is assumed. Under this assumption, this process has an arrival rate of formula_4 and a departure rate of formula_5.\nBalance equations.\nThe steady state equations for the birth-and-death process, known as the balance equations, are as follows. Here formula_6 denotes the steady state probability to be in state \"n\".\n formula_7\n formula_8\n formula_9\nThe first two equations imply\n formula_10\nand\n formula_11.\nBy mathematical induction,\n formula_12.\nThe condition formula_13 leads to\n formula_14\nwhich, together with the equation for formula_6 formula_16, fully describes the required steady state probabilities.\nKendall's notation.\nSingle queueing nodes are usually described using Kendall's notation in the form A/S/\"c\" where \"A\" describes the distribution of durations between each arrival to the queue, \"S\" the distribution of service times for jobs, and \"c\" the number of servers at the node. For an example of the notation, the M/M/1 queue is a simple model where a single server serves jobs that arrive according to a Poisson process (where inter-arrival durations are exponentially distributed) and have exponentially distributed service times (the M denotes a Markov process). In an M/G/1 queue, the G stands for \"general\" and indicates an arbitrary probability distribution for service times.\nExample analysis of an M/M/1 queue.\nConsider a queue with one server and the following characteristics:\nFurther, let formula_20 represent the number of times the system enters state \"n\", and formula_21 represent the number of times the system leaves state \"n\". Then formula_22 for all \"n\". That is, the number of times the system leaves a state differs by at most 1 from the number of times it enters that state, since it will either return into that state at some time in the future (formula_23) or not (formula_24).\nWhen the system arrives at a steady state, the arrival rate should be equal to the departure rate.\nThus the balance equations\n formula_25\n formula_26\n formula_27\nimply\n formula_28\nThe fact that formula_29 leads to the geometric distribution formula\n formula_30\nwhere formula_31.\nSimple two-equation queue.\nA common basic queueing system is attributed to Erlang and is a modification of Little's Law. Given an arrival rate \"\u03bb\", a dropout rate \"\u03c3\", and a departure rate \"\u03bc\", length of the queue \"L\" is defined as:\n formula_32.\nAssuming an exponential distribution for the rates, the waiting time \"W\" can be defined as the proportion of arrivals that are served. This is equal to the exponential survival rate of those who do not drop out over the waiting period, giving:\n formula_33\nThe second equation is commonly rewritten as:\n formula_34\nThe two-stage one-box model is common in epidemiology.\nHistory.\nIn 1909, Agner Krarup Erlang, a Danish engineer who worked for the Copenhagen Telephone Exchange, published the first paper on what would now be called queueing theory. He modeled the number of telephone calls arriving at an exchange by a Poisson process and solved the M/D/1 queue in 1917 and M/D/\"k\" queueing model in 1920. In Kendall's notation:\nIf the node has more jobs than servers, then jobs will queue and wait for service.\nThe M/G/1 queue was solved by Felix Pollaczek in 1930, a solution later recast in probabilistic terms by Aleksandr Khinchin and now known as the Pollaczek\u2013Khinchine formula.\nAfter the 1940s, queueing theory became an area of research interest to mathematicians. In 1953, David George Kendall solved the GI/M/\"k\" queue and introduced the modern notation for queues, now known as Kendall's notation. In 1957, Pollaczek studied the GI/G/1 using an integral equation. John Kingman gave a formula for the mean waiting time in a G/G/1 queue, now known as Kingman's formula.\nLeonard Kleinrock worked on the application of queueing theory to message switching in the early 1960s and packet switching in the early 1970s. His initial contribution to this field was his doctoral thesis at the Massachusetts Institute of Technology in 1962, published in book form in 1964. His theoretical work published in the early 1970s underpinned the use of packet switching in the ARPANET, a forerunner to the Internet.\nThe matrix geometric method and matrix analytic methods have allowed queues with phase-type distributed inter-arrival and service time distributions to be considered.\nSystems with coupled orbits are an important part in queueing theory in the application to wireless networks and signal processing.\nModern day application of queueing theory concerns among other things product development where (material) products have a spatiotemporal existence, in the sense that products have a certain volume and a certain duration.\nProblems such as performance metrics for the M/G/\"k\" queue remain an open problem.\nService disciplines.\nVarious scheduling policies can be used at queueing nodes:\nServer failures occur according to a stochastic (random) process (usually Poisson) and are followed by setup periods during which the server is unavailable. The interrupted customer remains in the service area until server is fixed.\nArriving customers not served (either due to the queue having no buffer, or due to balking or reneging by the customer) are also known as \"dropouts\". The average rate of dropouts is a significant parameter describing a queue.\nQueueing networks.\nQueue networks are systems in which multiple queues are connected by \"customer routing\". When a customer is serviced at one node, it can join another node and queue for service, or leave the network.\nFor networks of \"m\" nodes, the state of the system can be described by an \"m\"\u2013dimensional vector (\"x\"1, \"x\"2, ..., \"x\"\"m\") where \"x\"\"i\" represents the number of customers at each node.\nThe simplest non-trivial networks of queues are called tandem queues. The first significant results in this area were Jackson networks, for which an efficient product-form stationary distribution exists and the mean value analysis (which allows average metrics such as throughput and sojourn times) can be computed. If the total number of customers in the network remains constant, the network is called a \"closed network\" and has been shown to also have a product\u2013form stationary distribution by the Gordon\u2013Newell theorem. This result was extended to the BCMP network, where a network with very general service time, regimes, and customer routing is shown to also exhibit a product\u2013form stationary distribution. The normalizing constant can be calculated with the Buzen's algorithm, proposed in 1973.\nNetworks of customers have also been investigated, such as Kelly networks, where customers of different classes experience different priority levels at different service nodes. Another type of network are G-networks, first proposed by Erol Gelenbe in 1993: these networks do not assume exponential time distributions like the classic Jackson network.\nRouting algorithms.\nIn discrete-time networks where there is a constraint on which service nodes can be active at any time, the max-weight scheduling algorithm chooses a service policy to give optimal throughput in the case that each job visits only a single-person service node. In the more general case where jobs can visit more than one node, backpressure routing gives optimal throughput. A network scheduler must choose a queueing algorithm, which affects the characteristics of the larger network.\nMean-field limits.\nMean-field models consider the limiting behaviour of the empirical measure (proportion of queues in different states) as the number of queues \"m\" approaches infinity. The impact of other queues on any given queue in the network is approximated by a differential equation. The deterministic model converges to the same stationary distribution as the original model.\nHeavy traffic/diffusion approximations.\nIn a system with high occupancy rates (utilisation near 1), a heavy traffic approximation can be used to approximate the queueing length process by a reflected Brownian motion, Ornstein\u2013Uhlenbeck process, or more general diffusion process. The number of dimensions of the Brownian process is equal to the number of queueing nodes, with the diffusion restricted to the non-negative orthant.\nFluid limits.\nFluid models are continuous deterministic analogs of queueing networks obtained by taking the limit when the process is scaled in time and space, allowing heterogeneous objects. This scaled trajectory converges to a deterministic equation which allows the stability of the system to be proven. It is known that a queueing network can be stable but have an unstable fluid limit.\nQueueing Applications.\nQueueing theory finds widespread application in computer science and information technology. In networking, for instance, queues are integral to routers and switches, where packets queue up for transmission. By applying queueing theory principles, designers can optimize these systems, ensuring responsive performance and efficient resource utilization.\nBeyond the technological realm, queueing theory is relevant to everyday experiences. Whether waiting in line at a supermarket or for public transportation, understanding the principles of queueing theory provides valuable insights into optimizing these systems for enhanced user satisfaction. At some point, everyone will be involved in an aspect of queuing. What some may view to be an inconvenience could possibly be the most effective method.\nQueueing theory, a discipline rooted in applied mathematics and computer science, is a field dedicated to the study and analysis of queues, or waiting lines, and their implications across a diverse range of applications. This theoretical framework has proven instrumental in understanding and optimizing the efficiency of systems characterized by the presence of queues. The study of queues is essential in contexts such as traffic systems, computer networks, telecommunications, and service operations.\nQueueing theory delves into various foundational concepts, with the arrival process and service process being central. The arrival process describes the manner in which entities join the queue over time, often modeled using stochastic processes like Poisson processes. The efficiency of queueing systems is gauged through key performance metrics. These include the average queue length, average wait time, and system throughput. These metrics provide insights into the system's functionality, guiding decisions aimed at enhancing performance and reducing wait times.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50579", "revid": "44103609", "url": "https://en.wikipedia.org/wiki?curid=50579", "title": "Gaussian quadrature", "text": "Approximation of the definite integral of a function\nIn numerical analysis, an n-point Gaussian quadrature rule, named after Carl Friedrich Gauss, is a quadrature rule constructed to yield an exact result for polynomials of degree 2\"n\" \u2212 1 or less by a suitable choice of the nodes xi and weights wi for \"i\" = 1, ..., \"n\". \nThe modern formulation using orthogonal polynomials was developed by Carl Gustav Jacobi in 1826. The most common domain of integration for such a rule is taken as [\u22121, 1], so the rule is stated as\nformula_1\nwhich is exact for polynomials of degree 2\"n\" \u2212 1 or less. This exact rule is known as the Gauss\u2013Legendre quadrature rule. The quadrature rule will only be an accurate approximation to the integral above if \"f\" (\"x\") is well-approximated by a polynomial of degree 2\"n\" \u2212 1 or less on [\u22121, 1].\nThe Gauss\u2013Legendre quadrature rule is not typically used for integrable functions with endpoint singularities. Instead, if the integrand can be written as\nformula_2\nwhere \"g\"(\"x\") is well-approximated by a low-degree polynomial, then alternative nodes xi' and weights wi' will usually give more accurate quadrature rules. These are known as Gauss\u2013Jacobi quadrature rules, i.e.,\nformula_3\nCommon weights include formula_4 (Chebyshev\u2013Gauss) and formula_5. One may also want to integrate over semi-infinite (Gauss\u2013Laguerre quadrature) and infinite intervals (Gauss\u2013Hermite quadrature).\nIt can be shown (see Press et al., or Stoer and Bulirsch) that the quadrature nodes xi are the roots of a polynomial belonging to a class of orthogonal polynomials (the class orthogonal with respect to a weighted inner-product). This is a key observation for computing Gauss quadrature nodes and weights.\nGauss\u2013Legendre quadrature.\nFor the simplest integration problem stated above, i.e., \"f\"(\"x\") is well-approximated by polynomials on formula_6, the associated orthogonal polynomials are Legendre polynomials, denoted by \"P\"\"n\"(\"x\"). With the n-th polynomial normalized to give \"P\"\"n\"(1) = 1, the i-th Gauss node, xi, is the i-th root of Pn and the weights are given by the formula\nformula_7\nSome low-order quadrature rules are tabulated below (over interval [\u22121, 1], see the section below for other intervals).\nChange of interval.\nAn integral over [\"a\", \"b\"] must be changed into an integral over [\u22121, 1] before applying the Gaussian quadrature rule. This change of interval can be done in the following way:\nformula_8\nwith formula_9\nApplying the formula_10 point Gaussian quadrature formula_11 rule then results in the following approximation:\nformula_12\nExample of two-point Gauss quadrature rule.\nUse the two-point Gauss quadrature rule to approximate the distance in meters covered by a rocket from formula_13 to formula_14 as given by\nformula_15\nChange the limits so that one can use the weights and abscissae given in Table 1. Also, find the absolute relative true error. The true value is given as 11061.34 m.\nSolution\nFirst, changing the limits of integration from formula_16 to formula_17 gives\nformula_18\nNext, get the weighting factors and function argument values from Table 1 for the two-point rule,\nNow we can use the Gauss quadrature formula\nformula_23\nsince\nformula_24\nformula_25\nGiven that the true value is 11061.34 m, the absolute relative true error, formula_26 is\nformula_27\nOther forms.\nThe integration problem can be expressed in a slightly more general way by introducing a positive weight function \u03c9 into the integrand, and allowing an interval other than [\u22121, 1]. That is, the problem is to calculate\nformula_28\nfor some choices of a, b, and \u03c9. For \"a\" = \u22121, \"b\" = 1, and \"\u03c9\"(\"x\") = 1, the problem is the same as that considered above. Other choices lead to other integration rules. Some of these are tabulated below. Equation numbers are given for Abramowitz and Stegun (A &amp; S).\nFundamental theorem.\nLet pn be a nontrivial polynomial of degree n such that\nformula_29\nNote that this will be true for all the orthogonal polynomials above, because each pn is constructed to be orthogonal to the other polynomials pj for \"j\"&lt;\"n\", and \"x\"\"k\" is in the span of that set.\nIf we pick the n nodes xi to be the zeros of pn, then there exist n weights wi which make the Gaussian quadrature computed integral exact for all polynomials \"h\"(\"x\") of degree 2\"n\" \u2212 1 or less. Furthermore, all these nodes xi will lie in the open interval (\"a\", \"b\").\nTo prove the first part of this claim, let \"h\"(\"x\") be any polynomial of degree 2\"n\" \u2212 1 or less. Divide it by the orthogonal polynomial pn to get\nformula_30\nwhere \"q\"(\"x\") is the quotient, of degree \"n\" \u2212 1 or less (because the sum of its degree and that of the divisor pn must equal that of the dividend), and \"r\"(\"x\") is the remainder, also of degree \"n\" \u2212 1 or less (because the degree of the remainder is always less than that of the divisor). Since pn is by assumption orthogonal to all monomials of degree less than n, it must be orthogonal to the quotient \"q\"(\"x\"). Therefore\nformula_31\nSince the remainder \"r\"(\"x\") is of degree \"n\" \u2212 1 or less, we can interpolate it exactly using n interpolation points with Lagrange polynomials \"l\"\"i\"(\"x\"), where\nformula_32\nWe have\nformula_33\nThen its integral will equal\nformula_34\nwhere \"w\"\"i\", the weight associated with the node \"x\"\"i\", is defined to equal the weighted integral of \"l\"\"i\"(\"x\") (see below for other formulas for the weights). But all the xi are roots of pn, so the division formula above tells us that\nformula_35\nfor all i. Thus we finally have\nformula_36\nThis proves that for any polynomial \"h\"(\"x\") of degree 2\"n\" \u2212 1 or less, its integral is given exactly by the Gaussian quadrature sum.\nTo prove the second part of the claim, consider the factored form of the polynomial \"p\"\"n\". Any complex conjugate roots will yield a quadratic factor that is either strictly positive or strictly negative over the entire real line. Any factors for roots outside the interval from a to b will not change sign over that interval. Finally, for factors corresponding to roots xi inside the interval from a to b that are of odd multiplicity, multiply \"p\"\"n\" by one more factor to make a new polynomial\nformula_37\nThis polynomial cannot change sign over the interval from a to b because all its roots there are now of even multiplicity. So the integral\nformula_38\nsince the weight function \"\u03c9\"(\"x\") is always non-negative. But \"p\"\"n\" is orthogonal to all polynomials of degree \"n\" \u2212 1 or less, so the degree of the product\nformula_39\nmust be at least n. Therefore \"p\"\"n\" has n distinct roots, all real, in the interval from a to b.\nGeneral formula for the weights.\nThe weights can be expressed as\nwhere formula_40 is the coefficient of formula_41 in formula_42. To prove this, note that using Lagrange interpolation one can express \"r\"(\"x\") in terms of formula_43 as\nformula_44\nbecause \"r\"(\"x\") has degree less than n and is thus fixed by the values it attains at n different points. Multiplying both sides by \"\u03c9\"(\"x\") and integrating from a to b yields\nformula_45\nThe weights wi are thus given by\nformula_46\nThis integral expression for formula_47 can be expressed in terms of the orthogonal polynomials formula_48 and formula_49 as follows.\nWe can write\nformula_50\nwhere formula_51 is the coefficient of formula_52 in formula_48. Taking the limit of x to formula_54 yields using L'H\u00f4pital's rule\nformula_55\nWe can thus write the integral expression for the weights as\nIn the integrand, writing\nformula_56\nyields\nformula_57\nprovided formula_58, because\nformula_59\nis a polynomial of degree \"k\" \u2212 1 which is then orthogonal to formula_48. So, if \"q\"(\"x\") is a polynomial of at most nth degree we have\nformula_61\nWe can evaluate the integral on the right hand side for formula_62 as follows. Because formula_63 is a polynomial of degree \"n\" \u2212 1, we have\nformula_64\nwhere \"s\"(\"x\") is a polynomial of degree formula_65. Since \"s\"(\"x\") is orthogonal to formula_49 we have\nformula_67\nWe can then write\nformula_68\nThe term in the brackets is a polynomial of degree formula_65, which is therefore orthogonal to formula_49. The integral can thus be written as\nformula_71\nAccording to equation (2), the weights are obtained by dividing this by formula_72 and that yields the expression in equation (1).\nformula_47 can also be expressed in terms of the orthogonal polynomials formula_48 and now formula_75. In the 3-term recurrence relation formula_76 the term with formula_77 vanishes, so formula_78 in Eq. (1) can be replaced by formula_79.\nProof that the weights are positive.\nConsider the following polynomial of degree formula_80\nformula_81\nwhere, as above, the xj are the roots of the polynomial formula_48. \nClearly formula_83. Since the degree of formula_84 is less than formula_85, the Gaussian quadrature formula involving the weights and nodes obtained from formula_48 applies. Since formula_87 for j not equal to i, we have\nformula_88\nSince both formula_89 and formula_84 are non-negative functions, it follows that formula_91.\nComputation of Gaussian quadrature rules.\nThere are many algorithms for computing the nodes xi and weights wi of Gaussian quadrature rules. The most popular are the Golub-Welsch algorithm requiring \"O\"(\"n\"2) operations, Newton's method for solving formula_92 using the three-term recurrence for evaluation requiring \"O\"(\"n\"2) operations, and asymptotic formulas for large \"n\" requiring \"O\"(\"n\") operations.\nRecurrence relation.\nOrthogonal polynomials formula_93 with formula_94 for formula_95 for a scalar product formula_96, degree formula_97 and leading coefficient one (i.e. monic orthogonal polynomials) satisfy the recurrence relation\nformula_98\nand scalar product defined\nformula_99\nfor formula_100 where n is the maximal degree which can be taken to be infinity, and where formula_101. First of all, the polynomials defined by the recurrence relation starting with formula_102 have leading coefficient one and correct degree. Given the starting point by formula_103, the orthogonality of formula_93 can be shown by induction. For formula_105 one has\nformula_106\nNow if formula_107 are orthogonal, then also formula_108, because in\nformula_109\nall scalar products vanish except for the first one and the one where formula_110 meets the same orthogonal polynomial. Therefore,\nformula_111\nHowever, if the scalar product satisfies formula_112 (which is the case for Gaussian quadrature), the recurrence relation reduces to a three-term recurrence relation: For formula_113 is a polynomial of degree less than or equal to \"r\" \u2212 1. On the other hand, formula_93 is orthogonal to every polynomial of degree less than or equal to \"r\" \u2212 1. Therefore, one has formula_115 and formula_116 for \"s\" &lt; \"r\" \u2212 1. The recurrence relation then simplifies to\nformula_117\nor\nformula_118\n(with the convention formula_119) where\nformula_120\n(the last because of formula_121, since formula_122 differs from formula_93 by a degree less than r).\nThe Golub-Welsch algorithm.\nThe three-term recurrence relation can be written in matrix form formula_124 where formula_125, formula_126 is the formula_10th standard basis vector, i.e., formula_128, and J is the following tridiagonal matrix, called the Jacobi matrix:\nformula_129\nThe zeros formula_130 of the polynomials up to degree n, which are used as nodes for the Gaussian quadrature can be found by computing the eigenvalues of this matrix. This procedure is known as \"Golub\u2013Welsch algorithm\".\nFor computing the weights and nodes, it is preferable to consider the symmetric tridiagonal matrix formula_131 with elements\nformula_132\nThat is,\nformula_133\nJ and formula_131 are similar matrices and therefore have the same eigenvalues (the nodes). The weights can be computed from the corresponding eigenvectors: If formula_135 is a normalized eigenvector (i.e., an eigenvector with euclidean norm equal to one) associated with the eigenvalue xj, the corresponding weight can be computed from the first component of this eigenvector, namely:\nformula_136\nwhere formula_137 is the integral of the weight function\nformula_138\nSee, for instance, for further details.\nError estimates.\nThe error of a Gaussian quadrature rule can be stated as follows. For an integrand which has 2\"n\" continuous derivatives,\nformula_139\nfor some \u03be in (\"a\", \"b\"), where pn is the monic (i.e. the leading coefficient is 1) orthogonal polynomial of degree n and where\nformula_140\nIn the important special case of \"\u03c9\"(\"x\") = 1, we have the error estimate\nformula_141\nStoer and Bulirsch remark that this error estimate is inconvenient in practice, since it may be difficult to estimate the order 2\"n\" derivative, and furthermore the actual error may be much less than a bound established by the derivative. Another approach is to use two Gaussian quadrature rules of different orders, and to estimate the error as the difference between the two results. For this purpose, Gauss\u2013Kronrod quadrature rules can be useful.\nGauss\u2013Kronrod rules.\nIf the interval [\"a\", \"b\"] is subdivided, the Gauss evaluation points of the new subintervals never coincide with the previous evaluation points (except at zero for odd numbers), and thus the integrand must be evaluated at every point. \"Gauss\u2013Kronrod rules\" are extensions of Gauss quadrature rules generated by adding \"n\" + 1 points to an n-point rule in such a way that the resulting rule is of order 2\"n\" + 1. This allows for computing higher-order estimates while re-using the function values of a lower-order estimate. The difference between a Gauss quadrature rule and its Kronrod extension is often used as an estimate of the approximation error.\nGauss\u2013Lobatto rules.\nIn some applications, it is desirable to have quadrature rules that have the high accuracy of Gauss formulas, but that also include the end points of the interval among the evaluation points. Such rules are known as Gauss-Lobatto, or simply Lobatto quadrature, named after Dutch mathematician Rehuel Lobatto. Because for an \"n\" point rule, one can no longer freely choose the locations of all quadrature points (2 of the points are fixed at the end points), one needs to expect that the rule is less accurate than regular Gaussian quadrature. Indeed, an \"n\" point Gauss-Lobatto rule is only accurate for polynomials up to degree 2\"n\" \u2212 3.\nLobatto quadrature of function \"f\"(\"x\") on interval [\u22121, 1]:\nformula_142\nAbscissas: xi is the formula_143st zero of formula_144, here formula_145 denotes the standard Legendre polynomial of m-th degree and the dash denotes the derivative.\nWeights:\nformula_146\nRemainder:\nformula_147\nSome of the weights are:\nAn adaptive variant of this algorithm with 2 interior nodes is found in GNU Octave and MATLAB as codice_1 and codice_2.\nReferences.\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50580", "revid": "46166101", "url": "https://en.wikipedia.org/wiki?curid=50580", "title": "Orange County, Texas", "text": "County in Texas, United States\nOrange County is a county located in the very southeastern corner of the U.S. state of Texas, sharing a boundary with Louisiana, within the Golden Triangle of Texas. As of the 2020 census, its population was 84,808. The county seat is the city of Orange, and it falls within the Beaumont\u2013Port Arthur metropolitan area.\nHistory.\nOrange County was formed in 1852 from portions of Jefferson County. It was named after the orange fruit, the common citrus fruit grown by the early settlers of this county near the mouth of the Sabine River.\nDue to periodic spells of quite cold winter weather (frosts) in Orange County, it is no longer the home of orange trees and citrus orchards. The production of those fruits in Texas long ago was moved a long way southwest into the Rio Grande Valley, where the weather is almost always warm all winter long. Citrus trees produce their fruit in the wintertime, which makes them especially vulnerable to frost and icy weather.\nA similar thing has happened in Florida, where orchards of citrus trees no longer exist in either Citrus County or Orange County because of bad winter freezes in some years. In both Florida and Texas, the citrus agriculture has been moved farther south in search of milder winters, and away from the periodic frosts.\nDuring World War II, Orange County was the home of a large amount of shipbuilding for the navies of the United States and allied countries. The major shipbuilder, Consolidated Steel Corporation, was located in the town of Orange, and among the warships that it built were the (1942), the first warship built there, the (1943), and the (1945\u201346), the last warship built there. During the war, the Consolidate Steel Corporation employed as many as 20,000 people at its shipyard in Orange.\nGeography.\nAccording to the U.S. Census Bureau, the county has a total area of , of which are land and (12%) are covered by water.\nOrange County is bordered on its east by the Sabine River, on its southeast by Sabine Lake, and on the northwest by the Neches River.\nThe geography of Orange County varies relatively little, with an elevation that reaches above sea level at very few points within the county. Orange County is very flat, and its soil is quite sandy, as could be expected in a county along the Gulf of Mexico. (Sandy soil is also common in southern Louisiana, Mississippi, and Alabama, and in western and southern Florida.) Saltwater marshes occur in much of the southeastern part of Orange County that borders the Sabine River. The Piney Woods are in the northern part of the county.\nCommunities.\nCities.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nAs of the census of 2000, 84,966 people, 31,642 households, and 23,794 families resided in the county. The population density was . The 34,781 housing units averaged . The racial makeup of the county was 87.98% White, 8.38% African American, 0.56% Native American, 0.78% Asian, 1.15% from other races, and 1.15% from two or more races. About 3.62% of the population was Hispanic or Latino of any race.\nOf the 31,642 households, 35.30% had children under the age of 18 living with them, 58.80% were married couples living together, 12.10% had a female householder with no husband present, and 24.80% were not families. About 21.7% of all households were made up of individuals, and 9.30% had someone living alone who was 65 years of age or older. The average household size was 2.65 and the average family size was 3.08.\nIn the county, the population was distributed as 27.30% under the age of 18, 8.70% from 18 to 24, 28.10% from 25 to 44, 23.20% from 45 to 64, and 12.70% who were 65 years of age or older. The median age was 36 years. For every 100 females, there were 96.40 males. For every 100 females age 18 and over, there were 92.60 males.\nThe median income for a household in the county was $37,586, and for a family was $44,152. Males had a median income of $40,185 versus $21,859 for females. The per capita income for the county was $17,554. About 11.40% of families and 13.80% of the population were below the poverty line, including 18.50% of those under age 18 and 12.40% of those age 65 or over.\nGovernment.\nThe Orange County Courthouse serves as the court for the region. Republican County Judge John Gothia presides over the five-member Orange County Commissioners' Court.\nOrange County lies in Texas House District 21, represented beginning in 2015 by Republican Dade Phelan of Beaumont.\nPolitics.\n!scope=\"col\" rowspan=\"2\"|Year\n!scope=\"col\" colspan=\"2\"|Republican\n!scope=\"col\" colspan=\"2\"|Democratic\n!scope=\"col\" colspan=\"2\"|Third party(ies)\n!!scope=\"col\"|No.\u202f !!scope=\"col\"|% !!scope=\"col\"|No.\u202f !!scope=\"col\"|% !!scope=\"col\"|No.\u202f !!scope=\"col\"|%\nEconomy.\nPrimary economic activities in Orange County are the petroleum refining industry, paper milling, rice farming, and shrimping.\nOrange County was formerly a center for the building of warships, and a large U.S. Navy ghost fleet (reserve fleet) still exists in Jefferson County - from which currently, many old warships are being cleaned of water pollution sources and then scrapped for their metals, thus employment for residents of Orange County in shipbreaking.\nNewspapers published in the county include the twice-weekly \"Orange Leader\" and weeklies including the Bridge City-based \"Penny Record\", \"County Record\", and \"Vidor Vidorian\".\nTransportation.\nAirports.\nOrange County Airport operates general-aviation flights.\nNearby Southeast Texas Regional Airport (Port Arthur) operates commercial flights.\nEducation.\nThe county is served by five school districts: Bridge City ISD, Little Cypress-Mauriceville Consolidated ISD, Orangefield ISD, Vidor ISD, and West Orange-Cove Consolidated ISD.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50582", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=50582", "title": "Zircon", "text": "Zirconium silicate mineral\nZircon () is a mineral belonging to the group of nesosilicates and is a source of the metal zirconium. Its chemical name is zirconium(IV) silicate, and its corresponding chemical formula is ZrSiO4. An empirical formula showing some of the range of substitution in zircon is (Zr1\u2013y, REEy)(SiO4)1\u2013x(OH)4x\u2013y. Zircon precipitates from silicate melts and has relatively high concentrations of high field strength incompatible elements. For example, hafnium is almost always present in quantities ranging from 1 to 4%. The crystal structure of zircon is tetragonal crystal system. The natural color of zircon varies between colorless, yellow-golden, red, brown, blue, and green.\nThe name derives from the Persian \"zargun\", meaning \"gold-hued\". This word is changed into \"jargoon\", a term applied to light-colored zircons. The English word \"zircon\" is derived from \"Zirkon\", which is the German adaptation of this word. Yellow, orange, and red zircon is also known as \"hyacinth\", from the flower \"hyacinthus\", whose name is of Ancient Greek origin.\nProperties.\nZircon is common in the crust of Earth. It occurs as a common accessory mineral in igneous rocks (as primary crystallization products), in metamorphic rocks and as detrital grains in sedimentary rocks. Large zircon crystals are rare. Their average size in granite rocks is about , but they can also grow to sizes of several cm, especially in mafic pegmatites and carbonatites. Zircon is fairly hard (with a Mohs hardness of 7.5) and chemically stable, and so is highly resistant to weathering. It also is resistant to heat, so that detrital zircon grains are sometimes preserved in igneous rocks formed from melted sediments. Its resistance to weathering, together with its relatively high specific gravity (4.68), make it an important component of the heavy mineral fraction of sandstones.\nBecause of their uranium and thorium content, some zircons undergo metamictization. Connected to internal radiation damage, these processes partially disrupt the crystal structure and partly explain the highly variable properties of zircon. As zircon becomes more and more modified by internal radiation damage, the density decreases, the crystal structure is compromised, and the color changes.\nZircon occurs in many colors, including reddish brown, yellow, green, blue, gray, and colorless. The color of zircons can sometimes be changed by heat treatment. Common brown zircons can be transformed into colorless and blue zircons by heating to . In geological settings, the development of pink, red, and purple zircon occurs after hundreds of millions of years, if the crystal has sufficient trace elements to produce color centers. Color in this red or pink series is annealed in geological conditions above temperatures of around .\nStructurally, zircon consists of parallel chains of alternating silica tetrahedra (silicon ions in fourfold coordination with oxygen ions) and zirconium ions, with the large zirconium ions in eightfold coordination with oxygen ions.\nApplications.\nZircon is mainly consumed as an opacifier, and has been known to be used in the decorative ceramics industry. It is also the principal precursor not only to metallic zirconium, although this application is small, but also to all compounds of zirconium including zirconium dioxide (), an important refractory oxide with a melting point of .\nOther applications include use in refractories and foundry casting and a growing array of specialty applications as zirconia and zirconium chemicals, including in nuclear fuel rods, catalytic fuel converters and in water and air purification systems.\nFord Motor Company used a sand casting method known as the \"Cosworth Casting Method\" for the cylinder heads of its Duratec V6 engine. The process, developed by noted scientist John Campbell used zircon as its casting aggregate to improve material uniformity and create dimensional accuracy, high strength, and a dense, low- or no-porosity structure.\nZircon is one of the key minerals used by geologists for geochronology.\nZircon is a part of the ZTR index to classify highly-weathered sediments.\nGemstone.\nTransparent zircon is a well-known form of semi-precious gemstone, favored for its high specific gravity (between 4.2 and 4.86) and adamantine luster. Because of its high refractive index (1.92) it has sometimes been used as a substitute for diamond, though it does not display quite the same play of color as a diamond. Zircon is one of the heaviest types of gemstone. Its Mohs hardness is between that of quartz and topaz, at 7.5 on the 10 point scale, though below that of the similar manmade stone cubic zirconia (8-8.5). Zircons may sometimes lose their inherent color after long exposure to bright sunlight, which is unusual in a gemstone. It is immune to acid attack except by sulfuric acid and then only when ground into a fine powder.\nMost gem-grade zircons show a high degree of birefringence which, on stones cut with a table and pavilion cuts (i.e., nearly all cut stones), can be seen as the apparent doubling-up of the latter when viewed through the former, and this characteristic can be used to distinguish them from diamonds and cubic zirconias (CZ) as well as soda-lime glass, none of which show this characteristic. However, some zircons from Sri Lanka display only weak or no birefringence at all, and some other Sri Lanka stones may show clear birefringence in one place and little or none in another part of the same cut stone. Other gemstones also display birefringence, so while the presence of this characteristic may help distinguish a given zircon from a diamond or a CZ, it will not help distinguish it from, for example, a topaz gemstone. The high specific gravity of zircon, however, can usually separate it from any other gem and is simple to test.\nAlso, birefringence depends on the cut of the stone in relation to its optical axis. If a zircon is cut with this axis perpendicular to its table, birefringence may be reduced to undetectable levels unless viewed with a jeweler's loupe or other magnifying optics. The highest grade zircons are cut to minimize birefringence.\nThe value of a zircon gem depends largely on its color, clarity, and size. Prior to World War II, blue zircons (the most valuable color) were available from many gemstone suppliers in sizes between 15 and 25 carats; since then, stones even as large as 10 carats have become very scarce, especially in the most desirable color varieties.\nSynthetic zircons have been created in laboratories. They are occasionally used in jewellery such as earrings. Zircons are sometimes imitated by spinel and synthetic sapphire, but are not difficult to distinguish from them with simple tools.\nZircon from Ratanakiri province in Cambodia is heat treated to produce blue zircon gemstones, sometimes referred to by the trade name \"cambolite\".\nOccurrence.\nZircon is a common accessory to trace mineral constituent of all kinds of igneous rocks, but particularly granite and felsic igneous rocks. Due to its hardness, durability and chemical inertness, zircon persists in sedimentary deposits and is a common constituent of most sands. Zircon can occasionally be found as a trace mineral in ultrapotassic igneous rocks such as kimberlites, carbonatites, and lamprophyre, owing to the unusual magma genesis of these rocks.\nZircon forms economic concentrations within heavy mineral sands ore deposits, within certain pegmatites, and within some rare alkaline volcanic rocks (for example the Toongi Trachyte in Dubbo, Australia) in association with the zirconium-hafnium minerals eudialyte and armstrongite.\nAustralia leads the world in zircon mining, producing 37% of the world total and accounting for 40% of world EDR (economic demonstrated resources) for the mineral. South Africa is Africa's main producer, with 30% of world production, second after Australia.\nRadiometric dating.\nZircon has played an important role during the evolution of radiometric dating. Zircons contain trace amounts of uranium and thorium (from 10 ppm up to 1 wt%) and can be dated using several modern analytical techniques. Because zircons can survive geologic processes like erosion, transport, and even high-grade metamorphism, they contain a rich and varied record of geological processes. Currently, zircons are typically dated by uranium\u2013lead (U\u2013Pb), fission-track, and U+Th/He techniques. Imaging the cathodoluminescence emission from fast electrons can be used as a prescreening tool for high-resolution secondary-ion mass spectrometry (SIMS) to image the zonation pattern and identify regions of interest for isotope analysis. This is done using an integrated cathodoluminescence and scanning electron microscope. Zircons in sedimentary rock can identify the sediment source.\nZircons from Jack Hills in the Narryer Gneiss terrane, Yilgarn craton, Western Australia, have yielded U\u2013Pb ages up to 4.404 billion years, interpreted to be the age of crystallization, making them the oldest minerals so far dated on Earth. In addition, the oxygen isotopic compositions of some of these zircons have been interpreted to indicate that more than 4.3 billion years ago there was already liquid water on the surface of the Earth. This interpretation is supported by additional trace element data, but is also the subject of debate. In 2015, \"remains of biotic life\" were found in 4.1-billion-year-old rocks in the Jack Hills of Western Australia. According to one of the researchers, \"If life arose relatively quickly on Earth ... then it could be common in the universe.\"\nSimilar minerals.\nHafnon (), xenotime (), b\u00e9hierite, schiavinatoite (), thorite (), and coffinite () all share the same crystal structure (IVX IVY O4, IIIX VY O4 in the case of xenotime) as zircon.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "50585", "revid": "33299132", "url": "https://en.wikipedia.org/wiki?curid=50585", "title": "Philadelphia", "text": "Largest city in Pennsylvania, US\nPhiladelphia ( ), colloquially referred to as Philly, is the most populous city in the U.S. state of Pennsylvania. It is the sixth-most populous city in the United States with a population of 1.6 million at the 2020 census, while the Philadelphia metropolitan area (sometimes called the Delaware Valley) with 6.33 million residents is the nation's ninth-largest metropolitan area. Philadelphia is known for its culture, cuisine, and history, maintaining contemporary influence in business and industry, culture, sports, and music.\nPhiladelphia was founded in 1682 by William Penn, an English Quaker and advocate of religious freedom, and served as the capital of the colonial era Province of Pennsylvania. It then played a vital role during the American Revolution and Revolutionary War. It served as the central meeting place for the nation's Founding Fathers in hosting the First Continental Congress (1774) and the Second Continental Congress, during which the Founders formed the Continental Army, elected George Washington as its commander, and adopted the Declaration of Independence on July 4, 1776. During the Revolutionary War's Philadelphia campaign, the city fell to the British Army, which occupied Philadelphia for nine months from September 1777 to June 1778. Following the end of the Revolutionary War, the U.S. Constitution was ratified at the Philadelphia Convention. Philadelphia remained the nation's largest city until 1790, and it served as the nation's first capital from May 10, 1775, until December 12, 1776, and on four subsequent occasions until 1800, when construction of the new national capital in Washington, D.C. was completed.\nWith 17 four-year universities and colleges in the city, Philadelphia is one of the nation's leading centers for higher education and academic research. The city hosts more outdoor sculptures and murals than any other city in the nation. Fairmount Park, when combined with adjacent Wissahickon Valley Park in the same watershed, has an area of , representing one of the nation's largest urban parks and the world's 55th largest. With five professional sports teams and one of the nation's most loyal and passionate fan bases, Philadelphia is often ranked as the nation's best city for professional sports fans. The city has a culturally and philanthropically active LGBTQ+ community. Philadelphia also has played an influential historic and ongoing role in the development and evolution of American music, especially R&amp;B, soul, and rock.\nAs of 2023[ [update]], the Philadelphia metropolitan area had a gross metropolitan product of US$557.6 billion and is home to 13 \"Fortune\" 500 corporate headquarters. Metropolitan Philadelphia ranks as one of the nation's Big Five venture capital hubs, facilitated by its proximity to both the financial ecosystems of New York City and the regulatory environment of Washington, D.C. Metropolitan Philadelphia is also a biotechnology hub. The Philadelphia Stock Exchange, owned by Nasdaq since 2008, is the nation's oldest stock exchange and a global leader in options trading. 30th Street Station, the city's primary rail station, is the third-busiest Amtrak hub in the nation with over 4.1 million passengers in 2023. The city's multimodal transportation and logistics infrastructure includes Philadelphia International Airport, the PhilaPort seaport, and Interstate 95, a primary component of the north\u2013south highway system along the U.S. East Coast.\nPhiladelphia is a city of many firsts, including the nation's first library (1731), hospital (1751), medical school (1765), national capital (1774), university (by some accounts) (1779), central bank (1781), stock exchange (1790), zoo (1874), and business school (1881). Philadelphia contains 67 National Historic Landmarks, including Independence Hall. From the city's 17th century founding through the present, Philadelphia has been the birthplace of or home to many prominent and influential Americans.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nNative peoples.\nPrior to the arrival of Europeans in the early 17th century, the Lenape, an Indian tribe also known as the Delaware Indians, lived in the village of Shackamaxon in present-day Philadelphia and the surrounding area. The Lenape historically lived along the Delaware River watershed, western Long Island, and the Lower Hudson Valley. Most Lenape were pushed out of the region during the 18th century as the original Thirteen Colonies expanded, which was further exacerbated by losses from intertribal conflicts. Lenape communities were also weakened by newly introduced diseases, mainly smallpox, and conflicts with Europeans. The Iroquois occasionally fought the Lenape. Surviving Lenape moved west into the upper Ohio River basin. Following the American Revolutionary War and the subsequent establishment of the United States, the Lenape began moving further west. In the 1860s, the U.S. federal government sent most remaining Lenape in the eastern United States to the Indian Territory in present-day Oklahoma and surrounding territories as part of the Indian removal policy.\nColonial era.\nEuropeans first entered Philadelphia and the surrounding Delaware Valley in the early 17th century. The first settlements were founded by Dutch colonists, who built Fort Nassau on the Delaware River in 1623 in what is now Brooklawn, New Jersey. The Dutch considered the entire Delaware River valley to be part of their New Netherland colony. In 1638, Swedish settlers led by renegade Dutch established the colony of New Sweden at Fort Christina, located in present-day Wilmington, Delaware, and quickly spread out in the valley. In 1644, New Sweden supported the Susquehannocks in their war against Maryland colonists. In 1648, the Dutch built Fort Beversreede on the west bank of the Delaware, south of the Schuylkill River near the present-day Eastwick section of Philadelphia, to reassert their dominion over the area. The Swedes responded by building Fort Nya Korsholm, or New Korsholm, named after a town in Finland with a Swedish majority.\nIn 1655, a Dutch military campaign led by New Netherland Director-General Peter Stuyvesant took control of the Swedish colony, ending its claim to independence. The Swedish and Finnish settlers continued to have their own militia, religion, and court, and to enjoy substantial autonomy under the Dutch. An English fleet captured the New Netherland colony in 1664, though the situation did not change substantially until 1682, when the area was included in William Penn's charter for Pennsylvania.\nIn 1681, in partial repayment of a debt, Charles II of England granted Penn a charter for what would become the Pennsylvania colony. Despite the royal charter, Penn bought the land from the local Lenape in an effort to establish good terms with the Native Americans and ensure peace for the colony. Penn made a treaty of friendship with Lenape chief Tammany under an elm tree at Shackamaxon, in what is now the city's Fishtown neighborhood. Penn named the city Philadelphia, which is Greek for 'brotherly love', derived from the Ancient Greek terms ('beloved, dear') and ('brother, brotherly'). There were a number of cities named \"Philadelphia\" () in the Eastern Mediterranean during the Greek and Roman periods, including modern Ala\u015fehir, mentioned as the site of an early Christian congregation in the Book of Revelation. As a Quaker, Penn had experienced religious persecution and wanted his colony to be a place where anyone could worship freely. This tolerance, which exceeded that of other colonies, led to better relations with the local native tribes and fostered Philadelphia's rapid growth into America's most important city.\nPenn planned a city on the Delaware River to serve as a port and place for government. Hoping that Philadelphia would become more like an English rural town instead of a city, Penn laid out roads on a grid plan to keep houses and businesses spread far apart with areas for gardens and orchards.\nThe city's inhabitants did not follow Penn's plans, however, and instead crowded the present-day Port of Philadelphia on the Delaware River and subdivided and resold their lots. Before Penn left Philadelphia for the final time, he issued the Charter of 1701 establishing it as a city. Though poor at first, Philadelphia became an important trading center with tolerable living conditions by the 1750s. Benjamin Franklin, a leading citizen, helped improve city services and founded new ones that were among the first in the nation, including a fire company, library, and hospital.\nA number of philosophical societies were formed, which were centers of the city's intellectual life, including the Philadelphia Society for Promoting Agriculture (1785), the Pennsylvania Society for the Encouragement of Manufactures and the Useful Arts (1787), the Academy of Natural Sciences (1812), and the Franklin Institute (1824). These societies developed and financed new industries that attracted skilled and knowledgeable immigrants from Europe.\nAmerican Revolution.\nPhiladelphia's importance and central location in the colonies made it a natural center for America's revolutionaries. By the 1750s, Philadelphia surpassed Boston as the largest city and busiest port in British America, and the second-largest city in the entire British Empire after London. In 1774, as resentment of the British government's policies towards the colonies and support for independence began burgeoning in the colonies, Philadelphia hosted the First Continental Congress at Carpenters' Hall, and 12 of the original 13 colonies sent delegates to the Congress.\nFrom 1775 to 1781, Philadelphia hosted the Second Continental Congress, whose 56 delegated unanimously adopted the Declaration of Independence inside what was then called Pennsylvania State House and was later renamed Independence Hall. Written predominantly by Thomas Jefferson from his second-floor apartment on Market Street within walking distance of Independence Hall, the Declaration has been described by Pulitzer Prize-winning historian Joseph Ellis as \"the most potent and consequential words in American history,\" and its adoption represented a declaration of war against Great Britain. Since the Declaration's July 4, 1776, adoption, its signing has been cited globally and repeatedly by various peoples of the world seeking independence and liberty. It also has been, since its adoption, the basis for annual celebration by Americans; in 1938, this celebration of the Declaration was formalized as Independence Day, one of only eleven designated U.S. federal holidays.\nAfter George Washington's defeat at the Battle of Brandywine in Chadds Ford Township, on September 11, 1777, during the Philadelphia campaign, the revolutionary capital of Philadelphia was defenseless, and the city prepared for what was perceived to be an inevitable British attack. Because bells could easily be recast into munitions, the Liberty Bell, then known as the Pennsylvania State Bell, and bells from two Philadelphia churches, Christ Church and St. Peter's Church, were hastily taken down and transported by heavily guarded wagon train out of the city. The Liberty Bell was taken to Zion German Reformed Church in Northampton Town, which is present-day Allentown, where it was hidden under the church's floor boards for nine months from September 1777 until departure of British forces from Philadelphia in June 1778. Two Revolutionary War battles, the Siege of Fort Mifflin, fought between September 26 and November 16, 1777, and the Battle of Germantown, fought on October 4, 1777, took place within Philadelphia's city limits.\nIn Philadelphia, the Second Continental Congress adopted the Articles of Confederation on November 15, 1777. Independence Hall in Philadelphia was the meeting place for the Constitutional Convention, which ratified the Constitution on September 17, 1787, which is now the longest-standing codified national constitution.\nPhiladelphia served as capital of the United States for most of the colonial and early post-colonial period, including for a decade, from 1790 to 1800, while Washington, D.C. was being constructed and prepared to serve as the new national capital, and on five prior occasions between 1776 and 1790. In 1793, the largest yellow fever epidemic in U.S. history killed approximately 4,000 to 5,000 people in Philadelphia, or about ten percent of the city's population at the time. The capital of the United States was moved to Washington, D.C. in 1800 upon completion of the White House and U.S. Capitol buildings.\nThe state capital was moved from Philadelphia to Lancaster in 1799, then ultimately to Harrisburg in 1812. Philadelphia remained the nation's largest city until the late 18th century. It also was the nation's financial and cultural center until ultimately being eclipsed in total population by New York City in 1790. In 1816, the city's free Black community founded the African Methodist Episcopal Church, the first independent Black denomination in the country, and the first Black Episcopal Church. The free Black community also established many schools for its children with the help of Quakers. Large-scale construction projects for new roads, canals, and railroads made Philadelphia the first major industrial city in the United States.\n19th century.\nThroughout the 19th century, Philadelphia hosted a variety of industries and businesses; the largest was the textile industry. Major corporations in the 19th and early 20th centuries included the Baldwin Locomotive Works, William Cramp &amp; Sons Shipbuilding Company, and the Pennsylvania Railroad. Established in 1870, the Philadelphia Conveyancers' Association was chartered by the state in 1871. Along with the U.S. Centennial in 1876, the city's industry was celebrated in the Centennial Exposition, the first official World's fair in the U.S.\nImmigrants, mostly from Ireland and Germany, settled in Philadelphia and the surrounding districts. These immigrants were largely responsible for the first general strike in North America in 1835, in which workers in the city won the ten-hour workday. The city was a destination for thousands of Irish immigrants fleeing the Great Famine in the 1840s; housing for them was developed south of South Street and later occupied by succeeding immigrants. They established a network of Catholic churches and schools and dominated the Catholic clergy for decades. Anti-Irish, anti-Catholic nativist riots erupted in Philadelphia in 1844. The rise in population of the surrounding districts helped lead to the Act of Consolidation of 1854, which extended the city limits from the of Center City to the roughly of Philadelphia County.\nIn the latter half of the 19th century and leading into the 20th century, immigrants from Russia, Eastern Europe, and Italy, and African Americans from the southern U.S. settled in the city.\nPhiladelphia was represented by the Washington Grays in the American Civil War. The African-American population of Philadelphia increased from 31,699 to 219,559 between 1880 and 1930, largely stemming from the Great Migration from the South.\n20th century.\nBy the 20th century, Philadelphia had an entrenched Republican political machine and a complacent population. In 1910, a general strike shut down the entire city.\nIn 1917, following outrage over the election-year murder of a Philadelphia police officer, the City Council shrank from two houses to just one. In July 1919, Philadelphia was one of more than 36 industrial cities nationally to suffer a race riot during Red Summer in post-World War I unrest as recent immigrants competed with Black residents for jobs. In the 1920s, the public flouting of Prohibition laws, organized crime, mob violence, and corrupt police involvement in illegal activities led to the appointment of Brig. Gen. Smedley Butler of the U.S. Marine Corps as the city's director of public safety, but political pressure still prevented long-term success in fighting crime and corruption.\nIn 1940, non-Hispanic whites constituted 86.8% of the city's population. In 1950, the population peaked at more than two million residents, then began to decline with the restructuring of industry that led to the loss of many middle-class union jobs. In addition, suburbanization enticed many affluent residents to depart the city for its outlying railroad commuting towns and newer housing. The resulting reduction in Philadelphia's tax base and the resources of local government caused the city to struggle through a long period of adjustment, and it approached bankruptcy by the late 1980s.\nIn 1985, the Philadelphia Police Department, utilizing a Pennsylvania State Police helicopter, bombed the Cobbs Creek neighborhood to execute arrest warrants on MOVE members, a Black liberation movement. The incident killed 11 people, destroyed 61 homes, and displaced 250 residents, marking one of the only times a US city intentionally bombed its own civilians.\nRevitalization and gentrification of neighborhoods began in the late 1970s and continues into the 21st century with much of the development occurring in the Center City and University City neighborhoods. But this expanded a shortage of affordable housing in the city. After many manufacturers and businesses left Philadelphia or shut down, the city started attracting service businesses and began to market itself more aggressively as a tourist destination. Contemporary glass-and-granite skyscrapers were built in Center City beginning in the 1980s. Historic areas such as Old City and Society Hill were renovated during the reformist mayoral era of the 1950s through the 1980s, making both areas among the most desirable Center City neighborhoods. Immigrants from around the world began to enter the U.S. through Philadelphia as their gateway, leading to a reversal of the city's population decline between 1950 and 2000, during which it lost about 25 percent of its residents.\n21st century.\nPhiladelphia eventually began experiencing a growth in its population in 2007, which continued with incremental annual increases through the present. A migration pattern has been established from New York City to Philadelphia by residents opting for a large city with relative proximity and a lower cost of living.\nGeography.\nTopography.\nPhiladelphia's geographic center is about 40\u00b0 0\u2032 34\u2033 north latitude and 75\u00b0 8\u2032 0\u2033 west longitude. The 40th parallel north passes through neighborhoods in Northeast Philadelphia, North Philadelphia, and West Philadelphia including Fairmount Park. The city encompasses , of which is land and , or 6%, is water. Natural bodies of water include the Delaware and Schuylkill rivers, lakes in Franklin Delano Roosevelt Park, and Cobbs, Wissahickon, and Pennypack creeks. The largest artificial body of water is East Park Reservoir in Fairmount Park.\nThe lowest point is sea level and the highest point is in Chestnut Hill, about above sea level on Summit Street near the intersection of Germantown Avenue and Bethlehem Pike at: 40.07815 N, 75.20747 W. Philadelphia is located on the Atlantic Seaboard Fall Line that separates the Atlantic Plain from the Piedmont. The Schuylkill River's rapids at East Falls were inundated by completion of the dam at Fairmount Water Works.\nThe city is the seat of its own county. The city is bordered by six adjacent counties: Montgomery to the northwest; Bucks to the north and northeast; Burlington County, New Jersey to the east; Camden County, New Jersey to the southeast; Gloucester County, New Jersey to the south; and Delaware County to the southwest.\nCityscape.\nCity planning.\nPhiladelphia was created in the 17th century, following the plan by William Penn's surveyor Thomas Holme. Center City is structured with long, straight streets running nearly due east\u2013west and north\u2013south, forming a grid pattern between the Delaware and Schuylkill rivers that is aligned with their courses. The original city plan was designed to allow for easy travel and to keep residences separated by open space that would help prevent the spread of fire. In keeping with the idea of a \"Greene Countrie Towne\", and inspired by the many types of trees that grew in the region, Penn named many of the east\u2013west streets for local trees. Penn planned the creation of five public parks in the city which were renamed in 1824. Centre Square was renamed Penn Square; Northeast Square was renamed Franklin Square; Southeast Square was renamed Washington Square; Southwest Square was renamed Rittenhouse Square; and Northwest Square was renamed Logan Circle/Square. Center City had an estimated 183,240 residents as of 2015[ [update]], making it the second-most populated downtown area in the United States after Midtown Manhattan in New York City.\nPhiladelphia's neighborhoods are divided into six large sections that surround Center City: North Philadelphia, Northeast Philadelphia, South Philadelphia, Southwest Philadelphia, West Philadelphia, and Northwest Philadelphia. The city's geographic boundaries have been largely unchanged since these neighborhoods were consolidated in 1854. However, each of these large areas contains numerous neighborhoods, some of whose boundaries derive from the boroughs, townships, and other communities that constituted Pennsylvania County before their inclusion within the city.\nThe City Planning Commission, tasked with guiding growth and development of the city, has divided the city into 18 planning districts as part of the Philadelphia2035 physical development plan. Much of the city's 1980 zoning code was overhauled from 2007 to 2012 as part of a joint effort between former mayors John F. Street and Michael Nutter. The zoning changes were intended to rectify incorrect zoning maps to facilitate future community development, as the city forecasts an additional 100,000 residents and 40,000 jobs will be added by 2035.\nThe Philadelphia Housing Authority (PHA) is the largest landlord in Pennsylvania. Established in 1937, the PHA is the nation's fourth-largest housing authority, serving about 81,000 people with affordable housing, while employing 1,400 on a budget of $371\u00a0million. The Philadelphia Parking Authority is responsible for ensuring adequate parking for city residents, businesses, and visitors.\nArchitecture.\nPhiladelphia's architectural history dates back to colonial times and includes a wide range of styles. The earliest structures were constructed with logs, but brick structures were common by 1700. During the 18th century, the cityscape was dominated by Georgian architecture, including Independence Hall and Christ Church.\nIn the first decades of the 19th century, Federal and Greek Revival architecture were the dominant styles produced by Philadelphia architects such as Benjamin Latrobe, William Strickland, John Haviland, John Notman, Thomas Walter, and Samuel Sloan. Frank Furness is considered Philadelphia's greatest architect of the second half of the 19th century. His contemporaries included John McArthur Jr., Addison Hutton, Wilson Eyre, the Wilson Brothers, and Horace Trumbauer. In 1871, construction began on the Second Empire-style Philadelphia City Hall. The Philadelphia Historical Commission was created in 1955 to preserve the cultural and architectural history of the city. The commission maintains the Philadelphia Register of Historic Places, adding historic buildings, structures, sites, objects and districts as it sees fit.\nIn 1932, Philadelphia became home to the first modern International Style skyscraper in the United States, the PSFS Building, designed by George Howe and William Lescaze. The City Hall remained the tallest building in the city until 1987 when One Liberty Place was completed. Numerous glass and granite skyscrapers were built in Center City beginning in the late 1980s. In 2007, the Comcast Center surpassed One Liberty Place to become the city's tallest building. The Comcast Technology Center was completed in 2018, reaching a height of , as the tallest building in the United States outside of Manhattan and Chicago.\nFor much of Philadelphia's history, the typical home has been the row house. The row house was introduced to the United States via Philadelphia in the early 19th century and, for a time, row houses built elsewhere in the United States were known as \"Philadelphia rows\". A variety of row houses are found throughout the city, from Federal-style continuous blocks in Old City and Society Hill to Victorian-style homes in North Philadelphia to twin row houses in West Philadelphia. While newer homes have been built recently, much of the housing dates to the 18th, 19th, and early 20th centuries, which has created problems such as urban decay and vacant lots. Some neighborhoods, including Northern Liberties and Society Hill, have been rehabilitated through gentrification.\nParks.\nAs of 2014[ [update]], the city's total park space, including municipal, state, and federal parks in the city, amounts to . Philadelphia's largest park is Fairmount Park, which includes the Philadelphia Zoo and encompasses of the total parkland. Fairmount Park's adjacent Wissahickon Valley Park contains . Fairmount Park, when combined with Wissahickon Valley Park, is one of the largest contiguous urban park areas in the U.S. The two parks, along with the Colonial Revival, Georgian and Federal-style mansions in them, have been listed as one entity on the National Register of Historic Places since 1972.\nClimate.\nWithin the K\u00f6ppen climate classification, Philadelphia falls under the northern periphery of the humid subtropical climate zone (K\u00f6ppen \"Cfa\"). Within the Trewartha climate classification, Philadelphia has a temperate maritime climate (\"Do\") limited to the north by the continental climate (\"Dc\"). Summers are typically hot and muggy. Fall and spring are generally mild, and winter is moderately cold. The plant life hardiness zones are 7a and 7b, reflecting an average annual extreme minimum temperature between .\nSnowfall is highly variable. Some winters have only light snow while others include major snowstorms. The normal seasonal snowfall averages , with rare snowfalls in November or April, and rarely any sustained snow cover. Seasonal snowfall accumulation has ranged from trace amounts in 1972\u201373, to in the winter of 2009\u201310. The city's heaviest single-storm snowfall was , which occurred in January 1996.\nPrecipitation is generally spread throughout the year, with eight to eleven wet days per month, at an average annual rate of , but historically ranging from in 1922 to in 2011. The most rain recorded in one day occurred on July 28, 2013, when fell at Philadelphia International Airport. Philadelphia has a moderately sunny climate with an average of 2,498 hours of sunshine annually. The percentage of sunshine ranges from 47% in December to 61% in June, July, and August.\nThe January daily average temperature is . The temperature frequently rises to during thaws. July averages . Heat waves accompanied by high humidity and heat indices are frequent, with highs reaching or exceeding on 30 days of the year. The average window for freezing temperatures is November 6 to April 2, allowing a growing season of 217 days. Early fall and late winter are generally dry, with February having the lowest average precipitation at . The dewpoint in the summer averages between .\nThe highest recorded temperature was on August 7, 1918. Temperatures at or above are not common, with the last occurrence of such a temperature being July 21, 2019. The lowest officially recorded temperature was on February 9, 1934. Temperatures at or below are rare, with the last such occurrence being January 19, 1994. The record low maximum is on February 10, 1899, and December 30, 1880. The record high minimum is on July 23, 2011, and July 24, 2010. The record high dew point is which occurred on July 15, 1995.\nTime Series.\nAir quality.\nPhiladelphia County received an ozone grade of F and a 24-hour particle pollution rating of D in the American Lung Association's 2017 State of the Air report, which analyzed data from 2013 to 2015. The city was ranked 22nd for ozone, 20th for short-term particle pollution, and 11th for year-round particle pollution. According to the same report, the city experienced a significant reduction in high ozone days since 2001\u2014from nearly 50 days per year to fewer than 10\u2014along with fewer days of high particle pollution since 2000\u2014from about 19 days per year to about 3\u2014and an approximate 30% reduction in annual levels of particle pollution since 2000.\nFive of the ten largest combined statistical areas (CSAs) were ranked higher for ozone: Los Angeles (1st), New York City (9th), Houston (12th), Dallas (13th), and San Jose, California (18th). Many smaller CSAs were also ranked higher for ozone, including Sacramento (8th), Las Vegas (10th), Denver (11th), El Paso (16th), and Salt Lake City (20th). Only two of those same ten CSAs, San Jose and Los Angeles, were ranked higher than Philadelphia for both year-round and short-term particle pollution.\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nAs of the 2020 U.S. census, there were 1,603,797 people residing in Philadelphia, representing a 1.2% increase from the 2019 census estimate. The racial composition of the city was 39.3% Black alone (42.0% Black alone or in combination), 36.3% White alone (41.9% White alone or in combination), 8.7% Asian alone, 0.4% American Indian and Alaska Native alone, 8.7% some other race, and 6.9% multiracial. 14.9% of residents were Hispanic or Latino.\n34.8% had a bachelor's degree or higher. 23.9% spoke a language other than English at home, the most common of which was Spanish (10.8%). 15.0% of the population is foreign born, roughly half of whom are naturalized U.S. citizens. 3.7% of the population are veterans. The median household income was $52,889 and 22.8% of the population lived in poverty. 49.5% of the population drove alone to work, while 23.2% used public transit, 8.2% carpooled, 7.9% walked, and 7.0% worked from home. The average commute is 31 minutes.\nAfter the 1950 census, when a record high of 2,071,605 was recorded, the city's population began a long decline. The population dropped to a low of 1,488,710 residents in 2006 before beginning to rise again. Between 2006 and 2017, Philadelphia added 92,153 residents. In 2017, the U.S. Census Bureau estimated that the racial composition of the city was 41.3% Black (non-Hispanic), 34.9% White (non-Hispanic), 14.1% Hispanic or Latino, 7.1% Asian, 0.4% Native American, 0.05% Pacific Islander, and 2.8% multiracial.\nImmigration and cultural diversity.\nIn addition to the city's economic growth, the city's population has been fueled by foreign immigration. According to The Pew Charitable Trusts, the city's foreign-born population increased by 69% between 2000 and 2016 to constitute nearly 20% of Philadelphia's workforce, and it doubled between 1990 and 2017 to constitute 13.8% of the city's total population, with the top five countries of origin being China by a significant margin followed by the Dominican Republic, Jamaica, India, and Vietnam.\nIrish, Italian, German, Polish, English, Russian, Ukrainian, and French ancestries constitute the largest European ethnic groups in the city. Philadelphia has the second-largest Irish and Italian populations in the United States after New York City. South Philadelphia remains one of the largest Italian neighborhoods in the country and is home to the Italian Market.\nThe Pennsport neighborhood and Gray's Ferry section of South Philadelphia, home to many Mummer clubs, are well known as Irish neighborhoods. The Kensington, Port Richmond, and Fishtown neighborhoods have historically been heavily Irish and Polish. Port Richmond is a center for the Polish-American community in Philadelphia, and it remains a common destination for Polish immigrants. Northeast Philadelphia, although known for its Irish and Irish-American population, is home to a Jewish and Russian population. Mount Airy in Northwest Philadelphia also contains a Jewish community. Nearby Chestnut Hill is historically known as an Anglo-Saxon Protestant community.\nPhiladelphia's Black American population is the fourth-largest in the country after New York City, Chicago, and Houston. West Philadelphia and North Philadelphia are largely African-American neighborhoods, but many are leaving those areas in favor of the Northeast and Southwest sections of Philadelphia. A higher proportion of African-American Muslims reside in Philadelphia than most other major U.S. cities. West Philadelphia and Southwest Philadelphia are home to various Afro-Caribbean and African immigrant communities.\nThe Puerto Rican population in Philadelphia is the second-largest on the U.S. mainland after New York City, and the second-fastest growing after Orlando. Eastern North Philadelphia, particularly Fairhill and surrounding areas to the north and east, has one of the highest concentrations of Puerto Ricans outside Puerto Rico, with many large swaths of blocks being close to 100% Puerto Rican. Puerto Rican and Dominican populations reside in North Philadelphia and the Northeast, and Mexican and Central American populations exist in South Philadelphia. South American migrants were being transported by bus from Texas to Philadelphia beginning in 2022.\nPhiladelphia's Asian American population includes those of Chinese, Indians, Vietnamese, South Koreans, Filipinos, Cambodians, and Indonesians. Over 35,000 Chinese Americans lived in the city in 2015, including a Fuzhounese population. Center City hosts a Chinatown that is served by Chinatown bus lines with service to/from Chinatown, Manhattan. Indians make up the second-largest Asian group in the city of Philadelphia, while making up the largest foreign-born population in the Delaware Valley. A Korean community initially settled in the North Philadelphia neighborhood of Olney; however, the primary Koreatown has subsequently shifted further north, straddling the city's border with adjacent Cheltenham in Montgomery County and Cherry Hill in South Jersey. South Philadelphia is home to Vietnamese-Americans in Little Saigon and Cambodian-Americans in Cambodia Town, as well as Thai-American, Indonesian-American, and Chinese-American communities.\nPhiladelphia's Gay village near Washington Square is home to a concentration of gay and lesbian-friendly businesses, restaurants, and bars.\nReligion.\nIn a 2014 study by the Pew Research Center, 68% of the population of the city identified themselves as Christian. Approximately 41% of Christians in the city and area professed attendance at a variety of churches that could be considered Protestant, while 26% professed Catholic beliefs.\nThe Protestant Christian community in Philadelphia is dominated by mainline Protestant denominations including the Evangelical Lutheran Church in America, United Church of Christ, the Episcopal Church in the United States, Presbyterian Church (USA) and American Baptist Churches USA. One of the most prominent mainline Protestant jurisdictions is the Episcopal Diocese of Pennsylvania. The African Methodist Episcopal Church was established in Philadelphia. Historically, the city has strong connections to the Quakers, Unitarian Universalism, and the Ethical Culture movement, all of which continue to be represented in the city. The Quaker Friends General Conference is based in Philadelphia. Evangelical Protestants making up less than 15% of the population were also prevalent.\nEvangelical Protestant bodies included the Anglican Church in North America, Lutheran Church\u2014Missouri Synod, Presbyterian Church in America, and National Baptist Convention of America. The Catholic community is primarily served by the Latin Catholic Archdiocese of Philadelphia, the Ukrainian Catholic Archeparchy of Philadelphia, and the Syro-Malankara Catholic Eparchy of the United States of America and Canada, though some independent Catholic churches exist throughout Philadelphia and its suburbs. The Latin Church-based jurisdiction is headquartered in the city, and its see is the Cathedral Basilica of Saints Peter and Paul. The Ukrainian Catholic jurisdiction is headquartered in Philadelphia, and is seated at the Cathedral of the Immaculate Conception.\nLess than 1% of Philadelphia's Christians were Mormons. The remainder of the Christian demographic is spread among smaller Protestant denominations and the Eastern and Oriental Orthodox among others. The Diocese of Eastern Pennsylvania (Orthodox Church in America) and Greek Orthodox Archdiocese of America (Ecumenical Patriarchate) divide the Eastern Orthodox in Philadelphia. The Russian Orthodox St. Andrew's Cathedral is in the city.\nThe same study says that other religions collectively compose about 8% of the population, including Judaism, Hinduism, Islam, Buddhism, and Sikhism. Philadelphia has the fifth-largest Muslim population among U.S. cities. The remaining 24% claimed no religious affiliation.\nThe Philadelphia metropolitan area's Jewish population was estimated at 206,000 in 2001, which was the sixth-largest in the U.S. at that time. Jewish traders were operating in southeastern Pennsylvania long before William Penn. Jews in Philadelphia took a prominent part in the War of Independence. Although the majority of the early Jewish residents were of Portuguese or Spanish descent, some among them had emigrated from Germany and Poland. About the beginning of the 19th century, a number of Jews from the latter countries, finding the services of the Congregation Mickv\u00e9 Israel unfamiliar to them, resolved to form a new congregation which would use the ritual to which they had been accustomed.\nAfrican diasporic religions are practiced in some Latino and Hispanic and Caribbean communities in North and West Philadelphia.\nLanguages.\nAs of 2010[ [update]], 79.12% (1,112,441) of Philadelphia residents age 5 and older spoke English at home as a primary language, while 9.72% (136,688) spoke Spanish, 1.64% (23,075) Chinese, 0.89% (12,499) Vietnamese, 0.77% (10,885) Russian, 0.66% (9,240) French, 0.61% (8,639) other Asian languages, 0.58% (8,217) African languages, 0.56% (7,933) Cambodian (Mon-Khmer), and Italian was spoken as a main language by 0.55% (7,773) of the population over the age of five. In total, 20.88% (293,544) of Philadelphia's population age 5 and older spoke a mother language other than English.\nPoverty.\nPhiladelphia is home to many food poverty programs, of which two of the largest are Philabundance which claims to feed 90000 people per week. and Share Food Program which claims to feed 1 million people per month.\nEconomy.\nPhiladelphia's close geographical and transportation connections to other large metropolitan economies along the Eastern Seaboard of the United States have been cited as offering a significant competitive advantage for business creation and entrepreneurship. The city is the center of economic activity in both Pennsylvania and the four-state Delaware Valley metropolitan region. Five Fortune 500 companies are based in the city. As of 2021[ [update]], the Philadelphia metropolitan area is estimated to produce a gross metropolitan product (GMP) of US$479\u00a0billion, an increase from the $445\u00a0billion calculated by the Bureau of Economic Analysis for 2017, representing the ninth-largest U.S. metropolitan economy.\nPhiladelphia's economic sectors include financial services, health care, biotechnology, information technology, trade and transportation, manufacturing, oil refining, food processing, and tourism. Metropolitan Philadelphia is one of the top five American venture capital hubs, credited to its proximity to New York City's financial and tech and biotechnology ecosystems. Financial activities account for the largest economic sector of the metropolitan area, which is one of the largest health education and research centers in the United States. The city's two largest employers are the federal and city governments. Philadelphia's largest private employer is the University of Pennsylvania followed by Children's Hospital of Philadelphia.\nFinance and corporations.\nThe Philadelphia Stock Exchange, acquired by Nasdaq in 2007, is a global leader in options trading. The city is home to the headquarters of Comcast, the nation's largest multinational telecommunications corporation; insurance conglomerates Cigna, Colonial Penn, and Independence Blue Cross; as well as food services company Aramark, chemical makers FMC Corporation and Rohm and Haas, pharmaceutical companies GlaxoSmithKline, Amicus Therapeutics, Spark Therapeutics, apparel retailers Five Below and Urban Outfitters and its subsidiary Anthropologie, automotive parts retailer Pep Boys, and stainless steel producer Carpenter Technology Corporation.\nOther corporation headquarters in the city include RiteAid, Crown Holdings, and Brandywine Realty Trust. The headquarters of Boeing Rotorcraft Systems and its main rotorcraft factory are in the Philadelphia suburb of Ridley Park; The Vanguard Group, and the U.S. headquarters of Siemens Healthineers are headquartered in Malvern, Pennsylvania, a Philadelphia suburb. Healthcare conglomerate AmerisourceBergen is located in suburban Conshohocken, Pennsylvania. Across the Delaware River in adjacent Camden County, New Jersey, Campbell Soup Company and Subaru USA are both headquartered in Camden, New Jersey, and TD Bank (USA) is headquartered in nearby suburban Cherry Hill, New Jersey.\nTech and biotech.\nPhiladelphia is a hub for information technology and biotechnology. Philadelphia and Pennsylvania are attracting new life sciences ventures. As of 2024, the Delaware Valley ranks as one of the Big Five U.S. venture capital hubs, enabled by its proximity to both the entrepreneurial and financial ecosystems of New York City and to the federal regulatory environment of Washington, D.C.\nTourism.\nPhiladelphia's history attracts many tourists, with the Independence National Historical Park, which includes the Liberty Bell, Independence Hall, and other historic sites, received over 5\u00a0million visitors in 2016. The city welcomed 42\u00a0million domestic tourists in 2016 who spent $6.8\u00a0billion, generating an estimated $11\u00a0billion in total economic impact in the city and surrounding four counties of Pennsylvania. The annual Naked Bike Ride attracts participants from around the United States and internationally to Philadelphia.\nTrade and transportation.\nPhiladelphia International Airport, a major Transatlantic gateway and transcontinental hub, has undergone a $900\u00a0million infrastructural expansion to increase passenger capacity and augment passenger experience, and the airport continues an ongoing capital expenditure program to upgrade facilities and add further amenities. The Port of Philadelphia, having experienced the highest percentage growth by tonnage loaded in 2017 among major U.S. seaports, has doubled its shipping capacity to accommodate super-sized post-Panamax shipping vessels since 2018. Philadelphia's 30th Street Station is the third-busiest Amtrak rail hub, following Penn Station in Manhattan and Union Station in Washington, D.C., transporting over 4\u00a0million inter-city rail passengers annually.\nCulture.\nPhiladelphia is home to many national historical sites that relate to the founding of the United States. Independence National Historical Park is the center of these historical landmarks and one of the country's 22 UNESCO World Heritage Sites. Independence Hall, where the Declaration of Independence was signed, and the Liberty Bell is housed, are among the city's most popular attractions. Other national historic sites include the homes of Edgar Allan Poe and Thaddeus Kosciuszko, and early government buildings, including the First and the Second Bank of the United States, Fort Mifflin, and the Gloria Dei (Old Swedes') Church. Philadelphia alone has 67 National Historic Landmarks, the third most of any city in the country.\nPhiladelphia's major science museums include the Franklin Institute, which contains the Benjamin Franklin National Memorial, the Academy of Natural Sciences, the M\u00fctter Museum, and the University of Pennsylvania Museum of Archaeology and Anthropology. History museums include the National Constitution Center, the Museum of the American Revolution, the Philadelphia History Museum, the National Museum of American Jewish History, the African American Museum in Philadelphia, the Historical Society of Pennsylvania, the Masonic Library and Museum of Pennsylvania in the Masonic Temple, and the Eastern State Penitentiary. Philadelphia is home to the United States's first zoo and hospital, as well as Fairmount Park, one of America's oldest and largest urban parks, founded in 1855.\nThe city is home to important archival repositories, including the Library Company of Philadelphia, established in 1731 by Benjamin Franklin at 1314 Locust Street, and the Athenaeum of Philadelphia, founded in 1814. The Presbyterian Historical Society is the country's oldest denominational historical society, organized in 1852.\nArts.\nThe city is home to multiple art museums, including the Pennsylvania Academy of the Fine Arts and the Rodin Museum, which holds the largest collection of work by Auguste Rodin outside France. The city's largest art museum, the Philadelphia Art Museum, is one of the largest art museums in the world. The long flight of steps to the Art Museum's main entrance became famous after the film \"Rocky\" (1976).\nAnnual events include the Philadelphia Film Festival, held annually each October, the 6abc Dunkin' Donuts Thanksgiving Day Parade, the nation's longest-running continuously held Thanksgiving Day parade, and the Mummers Parade, the nation's longest continuously held folk parade, which is held every New Year's Day predominantly on Broad Street.\nAreas such as South Street and the Old City section of the city have a vibrant night life. The Avenue of the Arts in Center City contains many restaurants and theaters, such as the Kimmel Center for the Performing Arts, home of the Philadelphia Orchestra, and the Academy of Music, home of Opera Philadelphia and the Pennsylvania Ballet. The Wilma Theatre and the Philadelphia Theatre Company at the Suzanne Roberts Theatre produce a variety of new plays. Several blocks to the east are the Lantern Theater Company at St. Stephens Episcopal Church; and the Walnut Street Theatre, a National Historic Landmark stated to be the oldest and most subscribed-to theatre in the English-speaking world, founded in 1809. In May 2019, the Walnut Street Theatre announced a major expansion to begin in 2020. New Freedom Theatre, Pennsylvania's oldest African-American theatre, is located on North Broad Street.\nPhiladelphia has more public art than any other American city. In 1872, the Association for Public Art, formerly the Fairmount Park Art Association, was created as the first private association in the United States dedicated to integrating public art and urban planning. In 1959, lobbying by the Artists Equity Association helped create the Percent for Art ordinance, the first for a U.S. city. The program, which has funded more than 200 pieces of public art, is administered by Creative Philadelphia, the city's office of arts and culture. The city has more murals than any other American city, due to the 1984 creation of the Department of Recreation's Mural Arts Program, which seeks to beautify neighborhoods and provide an outlet for graffiti artists. The program has funded more than 2,800 murals by professional, staff and volunteer artists and educated more than 20,000 youth in underserved neighborhoods throughout Philadelphia.\nThe city is home to a number of art organizations, including the regional art advocacy nonprofit Philadelphia Tri-State Artists Equity, the Philadelphia Sketch Club, one of the country's oldest artists' clubs, and The Plastic Club, started by women excluded from the Sketch Club. Many Old City art galleries stay open late on the First Friday event of each month.\nCuisine.\nThe city is known for its hoagies, stromboli, roast pork sandwich, scrapple, soft pretzels, water ice, Irish potato candy, tastykakes, and the cheesesteak sandwich, which was developed by Italian immigrants. The Philadelphia area has many establishments that serve cheesesteaks, including restaurants, taverns, delicatessens and pizza parlors. The originator of the thinly sliced steak sandwich in the 1930s, initially without cheese, is Pat's King of Steaks, which faces its rival Geno's Steaks, founded in 1966, across the intersection of 9th Street and Passyunk Avenue in the Italian Market of South Philadelphia.\nMcGillin's Olde Ale House, opened in 1860 on Drury Street in Center City, is the oldest continuously operated tavern in the city. The City Tavern is a replica of a historic 18th-century building first opened in 1773, demolished in 1854 after a fire, and rebuilt in 1975 on the same site as part of Independence National Historical Park. The tavern offers authentic 18th-century recipes, served in seven period dining rooms, three wine cellar rooms and an outdoor garden.\nThe Reading Terminal Market is a historic food market founded in 1893 in the Reading Terminal building, a designated National Historic Landmark. The enclosed market is one of the oldest and largest markets in the country, hosting over a hundred merchants offering Pennsylvania Dutch specialties, artisan cheese and meat, locally grown groceries, and specialty and ethnic foods.\nDialect.\nThe traditional Philadelphia accent is considered by some linguists to be the most distinctive accent in North America. The Philadelphia dialect, which is spread throughout the Delaware Valley and South Jersey, is part of a larger Mid-Atlantic American English family, a designation that also includes the Baltimore accent. Additionally, it shares many similarities with the New York accent. Owing to over a century of linguistic data collected by researchers at the University of Pennsylvania under sociolinguist William Labov, the Philadelphia dialect has been one of the best-studied forms of American English. The accent is especially found within the Irish American and Italian American working-class neighborhoods. Philadelphia also has its own unique collection of neologisms and slang terms.\nMusic.\nThe Philadelphia Orchestra is generally considered one of the top five orchestras in the United States. The orchestra performs at the Kimmel Center and has a summer concert series at the Mann Center for the Performing Arts. Opera Philadelphia performs at the nation's oldest continually operating opera house\u2014the Academy of Music. The Philadelphia Boys Choir &amp; Chorale has performed its music all over the world. The Philly Pops plays orchestral versions of popular jazz, swing, Broadway, and blues songs at the Kimmel Center and other venues within the mid-Atlantic region. The Curtis Institute of Music is one of the world's premier conservatories and among the most selective institutes of higher education in the nation.\nPhiladelphia has played a prominent role in the music of the United States. The culture of American popular music has been influenced by significant contributions of Philadelphia area musicians and producers, in both the recording and broadcasting industries. In 1952, the teen dance party program called \"Bandstand\" premiered on local television, hosted by Bob Horn. The show was renamed \"American Bandstand\" in 1957, when it began national syndication on ABC, hosted by Dick Clark and produced in Philadelphia until 1964 when it moved to Los Angeles. Promoters marketed youthful musical artists known as teen idols to appeal to the young audience. Philadelphia-born singers, including Frankie Avalon, James Darren, Eddie Fisher, Fabian Forte, Bobby Rydell, and South Philly-raised Chubby Checker, topped the music charts, establishing a clean-cut rock and roll image.\nPhilly soul music of the late 1960s\u20131970s is a highly produced version of soul music which led to later forms of popular music such as disco and urban contemporary rhythm and blues. On July 13, 1985, John F. Kennedy Stadium was the American venue for the Live Aid concert. The city also hosted the Live 8 concert, which attracted about 700,000 people to the Benjamin Franklin Parkway on July 2, 2005.\nNotable rock and pop musicians from Philadelphia and its suburbs include Bill Haley &amp; His Comets, Nazz, Todd Rundgren, Hall &amp; Oates, the Hooters, Cinderella, DJ Jazzy Jeff &amp; the Fresh Prince, Ween, Schoolly D, Pink, the Roots, Beanie Sigel, State Property, Lisa \"Left Eye\" Lopes, Meek Mill, Lil Uzi Vert, and others.\nSports.\nPhiladelphia has one of the nation's richest histories in professional sports, dating back to the mid-19th century. Its first professional sports team, the Philadelphia Athletics, a professional baseball team, was founded in 1860. The Athletics were initially an amateur league team that turned professional in 1871. In 1876, the Athletics joined with seven other teams in founding the National League, now the longest continuously operating league in world sports.\nPhiladelphia is one of 12 U.S. cities to have teams in all four major league sports: the Philadelphia Phillies of Major League Baseball (MLB), the Philadelphia Eagles of the National Football League (NFL), the Philadelphia Flyers of the National Hockey League (NHL), and the Philadelphia 76ers of the National Basketball Association (NBA). The Phillies, formed in 1883 as the Quakers and renamed in 1884, are the oldest team continuously playing under the same name in the same city in the history of American professional sports.\nThe Philadelphia metro area is also home to the Philadelphia Union of Major League Soccer (MLS), plays their home games at Subaru Park, a soccer-specific stadium in Chester, Pennsylvania.\nPhiladelphia was the second of eight U.S. cities to win titles in all four major leagues, the MLB, NFL, NHL, and NBA. It won a title in soccer in the now-defunct North American Soccer League in 1973. Following the 76ers' victory over the Los Angeles Lakers in the 1983 NBA Finals, however, the city's professional teams and their fans endured 25 years without a championship in any professional sport until the Phillies won the 2008 World Series, defeating the Tampa Bay Rays. This quarter century without a championship for any Philadelphia sports team is sometimes described as the Curse of Billy Penn, a reference to a 1987 decision that permitted One Liberty Place to become the first building in city history to surpass the height of \"William Penn\", a statue installed in 1894 atop City Hall. In 2004, during the city's championship drought, ESPN placed Philadelphia second on its list of \"The Fifteen Most Tortured Sports Cities\". The city's sports fans are often both praised and sometimes derided. In 2011, for instance, \"GQ\" magazine named Eagles and Phillies fans the nation's worst professional sports fans, describing them as the \"Meanest Fans in America\" in summarizing repeated incidents of their drunken behavior and long history of booing.\nAfter the Phillies won the 2008 World Series, nine years passed without a championship until the Eagles won their first Super Bowl following the 2017 season, defeating the New England Patriots in Super Bowl LII. Seven seasons later, following the 2024 season, the Eagles won their second Super Bowl, defeating the Kansas City Chiefs in Super Bowl LIX.\nMajor professional sports teams that originated in Philadelphia, which later moved to other cities, include the Golden State Warriors basketball team, which played in Philadelphia from 1946 to 1962 and the Oakland Athletics baseball team, which was originally the Philadelphia Athletics and played in Philadelphia from 1901 to 1954.\nPhiladelphia is home to professional, semi-professional, and elite amateur teams in multiple other sports, including cricket, rugby league, and rugby union. Major running events in the city include the Penn Relays, the Philadelphia Marathon, and the Broad Street Run. The Collegiate Rugby Championship is played annually each June at Talen Energy Stadium in Chester.\nThe city also has a rich history in rowing, which has been popular in Philadelphia since the 18th century. On Boathouse Row, a symbol of Philadelphia's rich rowing history, each Big Five member has its own boathouse. Philadelphia hosts numerous local and collegiate rowing clubs and competitions, including the annual Dad Vail Regatta, the largest intercollegiate rowing event in North America with more than 100 participating U.S. and Canadian colleges and universities; the annual Stotesbury Cup Regatta, which is billed as the world's oldest and largest rowing event for high school students; and the Head of the Schuylkill Regatta. The regattas are held on the Schuylkill River and organized by Schuylkill Navy, an association of area rowing clubs that has produced numerous Olympic rowers.\nThe Philadelphia Spinners were a professional ultimate team in Major League Ultimate (MLU) until 2016. The Spinners were one of the original eight teams of the American Ultimate Disc League (AUDL), which was founded in 2012. They played at Franklin Field and won the inaugural AUDL championship and the final MLU championship in 2016. The MLU was suspended indefinitely by its investors in December 2016. As of 2018[ [update]], the Philadelphia Phoenix continue to play in the AUDL.\nPhiladelphia is home to the Philadelphia Big 5, a group of five NCAA Division I college basketball programs, including La Salle, Penn, Saint Joseph's, Temple, and Villanova universities. The sixth NCAA Division I school in Philadelphia is Drexel University. La Salle won the 1954 championship of the NCAA Division I men's basketball tournament. Villanova won the 1985, 2016, and 2018 NCAA Division I men's basketball tournaments. Philadelphia will be one of the eleven US host cities for the 2026 FIFA World Cup.\nLaw and government.\nPhiladelphia County is a legal nullity. All county functions were assumed by the city in 1952. The city has been coterminous with the county since 1854.\nPhiladelphia's 1952 Home Rule Charter was written by the City Charter Commission, which was created by the Pennsylvania General Assembly in an act of April 1949, and a city ordinance of June 1949. The existing city council received a proposed draft in February 1951, and the electors approved it in an election held in April 1951. The first elections under the new Home Rule Charter were held in November 1951, and the newly elected officials took office in January 1952.\nThe city uses the strong-mayor version of the mayor\u2013council form of government, which is led by one mayor in whom executive authority is vested. The mayor has the authority to appoint and dismiss members of all boards and commissions without the approval of the city council. Elected at-large, the mayor is limited to two consecutive four-year terms, but can run for the position again after an intervening term.\nCourts.\nPhiladelphia County is coterminous with the First Judicial District of Pennsylvania. The Philadelphia County Court of Common Pleas is the trial court of general jurisdiction for the city, hearing felony-level criminal cases and civil suits above the minimum jurisdictional limit of $10,000. The court has appellate jurisdiction over rulings from the Municipal and Traffic Courts, and some administrative agencies and boards. The trial division has 70 commissioned judges elected by the voters, along with about one thousand other employees. The court has a family division with 25 judges and an orphans' court with three judges.\nAs of 2018[ [update]], the city's District Attorney is Larry Krasner, a Democrat. The last Republican to hold the office is Ronald D. Castille, who left in 1991 and later served as the Chief Justice of the Pennsylvania Supreme Court from 2008 to 2014.\nThe Philadelphia Municipal Court handles traffic cases, misdemeanor and felony criminal cases with maximum incarceration of five years, and civil cases involving $12,000 or less ($15,000 in real estate and school tax cases), and all landlord-tenant disputes. The municipal court has 27 judges elected by the voters.\nPennsylvania's three appellate courts also have sittings in Philadelphia. The Supreme Court of Pennsylvania, the court of last resort in the state, regularly hears arguments in Philadelphia City Hall. The Superior Court of Pennsylvania and the Commonwealth Court of Pennsylvania also sit in Philadelphia several times a year. Judges for these courts are elected at large. The state Supreme Court and Superior Court have deputy prothonotary offices in Philadelphia.\nPhiladelphia is home to the federal United States District Court for the Eastern District of Pennsylvania and the Court of Appeals for the Third Circuit, both of which are housed in the James A. Byrne United States Courthouse.\nPolitics.\nThe current mayor is Cherelle Parker who won the election in November 2023. Parker's predecessor, Jim Kenney, served two terms from 2016 to January 2024. Parker is a member of the Democratic Party. For over seven decades, since 1952, every Philadelphia mayor has been a Democrat.\nPhiladelphia City Council is the legislative branch which consists of ten council members representing individual districts and seven members elected at-large, all of whom are elected to four-year terms. Democrats are currently the majority and hold 14 seats including nine of the ten districts and five at-large seats. Republicans hold one seat: the Northeast-based Tenth District. The Working Families Party holds two at-large seats making them the council's minority party. The current council president is Kenyatta Johnson.\nPhiladelphia's political structure consists of a system of wards and divisions. There are 66 wards with 11 to 51 divisions each for a total of 1703 divisions. Each division elects two committee people who are supposed to live within the division boundaries, and committee people select a leader for their ward. Democrats and Republicans elect their own committee people every four years. The committee person's role is to serve as a point of contact between voters and party officials and help get out the vote. Most wards are closed which means the ward leader makes sole endorsement decisions; open wards allow committee people to weigh in on these decisions. There are groups such as https:// and individuals who are working to elect ward leaders who promote an open ward system.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nPhiladelphia had historically been a bastion of the Republican Party from the American Civil War until the mid-1930s. In 1856, the first Republican National Convention was held at Musical Fund Hall at 808 Locust Street in Philadelphia.\nDemocratic registrations increased after the Great Depression; however, the city was not carried by Democrat Franklin D. Roosevelt in his landslide victory of 1932, as Pennsylvania was one of only six states won by Republican Herbert Hoover. Voter turnout surged from 600,000 in 1932 to nearly 900,000 in 1936 and Roosevelt carried Philadelphia with over 60% of the vote. Philadelphia has voted Democratic in every presidential election since 1936. In 2008, Democrat Barack Obama drew 83% of the city's vote. Obama's win was even larger in 2012, capturing 85% of the vote. In 2016, Democrat Hillary Clinton won 82% of the vote.\nAs a result of the previously declining population in the city and state, Philadelphia has only three congressional districts of the 18 districts in Pennsylvania, based on the 2010 census apportionment: the 2nd district, represented by Brendan Boyle; the 3rd, represented by Dwight Evans; and the 5th, represented by Mary Gay Scanlon. All three representatives are Democrats, though Republicans still have some support in the city, primarily in the Northeast. Sam Katz ran competitive mayoral races as the Republican nominee in 1999 and 2003, losing to Democrat John Street both times.\nPennsylvania's longest-serving Senator, Arlen Specter, was an alumnus of the University of Pennsylvania who opened his first law practice in Philadelphia. Specter served as a Republican from 1981 and as a Democrat from 2009, losing that party's primary in 2010 and leaving office in January 2011. He was assistant counsel on the Warren Commission in 1964 and the city's district attorney from 1966 to 1974.\nPhiladelphia has hosted various national conventions, including in 1848 (Whig), 1856 (Republican), 1872 (Republican), 1900 (Republican), 1936 (Democratic), 1940 (Republican), 1948 (Republican), 1948 (Progressive), 2000 (Republican), and 2016 (Democratic). Philadelphia has been home to one vice president, George M. Dallas, and one general of the American Civil War, George B. McClellan, who won his party's nomination for president but lost in the general election to Abraham Lincoln in 1864. In May 2019, former U.S. Vice President Joe Biden chose Philadelphia to be his 2020 U.S. presidential campaign headquarters.\nEnvironmental policy.\n\"Green Cities, Clean Water\" is an environmental policy initiative based in Philadelphia that has shown promising results in mitigating the effects of climate change. The researchers on the policy have stated that despite such promising plans of green infrastructure building, \"the city is forecasted to grow warmer, wetter, and more urbanized over the century, runoff and local temperatures will increase on average throughout the city\". Even though landcover predictive models on the effects of the policy initiative have indicated that green infrastructure could be useful at decreasing the amount of runoff in the city over time, the city government would have to expand its current plans and \"consider the cobenefit of climate change adaptation when planning new projects\" in limiting the scope of city-wide temperature increase.\nPublic safety.\nPolice and law enforcement.\nIn a 2015 report by Pew Charitable Trusts, the police districts with the highest rates of violent crime were Frankford (15th district) and Kensington (24th district) in the Near Northeast, and districts to the North (22nd, 25th, and 35th districts), West (19th district) and Southwest (12th district) of Center City. Each of those seven districts recorded more than a thousand violent crimes in 2014. The lowest rates of violent crime occurred in Center City, South Philadelphia, the Far Northeast, and Roxborough districts, the latter of which includes Manayunk.\nPhiladelphia had 500, 503 according to some sources, murders in 1990, a rate of 31.5 per 100,000. An average of about 400 murders occurred each year for most of the 1990s. The murder count dropped in 2002 to 288, then rose to 406 by 2006, before dropping slightly to 392 in 2007. A few years later, Philadelphia began to see a rapid decline in homicides and violent crime. In 2013, the city had 246 murders, which is a decrease of nearly 40% since 2006.\nIn 2014, 248 homicides were committed. The homicide rate rose to 280 in 2015, then fell slightly to 277 in 2016, before rising again to 317 in 2017. Homicides increased dramatically in the late 2010s/early 2020s, reaching 499 homicides in 2020 and surpassing the 1990 \"record\" in 2021, with 501st murder on November 27 and 510 by the end of the month. Phillie ended the year with 562 murders, an all-time record. It dropped in 2022 to 514, and significantly further again in 2023, to 410.\nIn 2006, Philadelphia's homicide rate of 27.7 per 100,000 people was the highest of the country's 10 most populous cities. In 2012, Philadelphia had the fourth-highest homicide rate among the country's most populous cities. The rate dropped to 16 homicides per 100,000 residents by 2014 placing Philadelphia as the sixth-highest city in the country.\nThe number of shootings in the city has declined significantly since the early years of the 21st century. Shooting incidents peaked at 1,857 in 2006 before declining nearly 44 percent to 1,047 shootings in 2014. Major crimes have decreased gradually since a peak in 2006 when 85,498 major crimes were reported. The number of reported major crimes fell 11 percent in three years to 68,815 occurrences in 2014. Violent crimes, which include homicide, rape, aggravated assault, and robbery, decreased 14 percent in three years to 15,771 occurrences in 2014.\nIn 2014, Philadelphia enacted an ordinance decriminalizing the possession of less than 30 grams of marijuana or eight grams of hashish; the ordinance gave police officers the discretion to treat possession of these amounts as a civil infraction punishable by a $25 ticket, rather than a crime. At the time, Philadelphia was at the largest city in the nation to decriminalize the possession of marijuana. From 2013 to 2018, marijuana arrests in the city dropped by more than 85%. The purchase or sale of marijuana remains a criminal offense in Philadelphia.\nFirefighting.\nThe Philadelphia Fire Department provides fire protection and emergency medical services (EMS). The department's official mission is to protect public safety by quick and professional response to emergencies and the promotion of sound emergency prevention measures. This mandate encompasses all traditional firefighting functions, including fire suppression, with 60 engine companies and 30 ladder companies as well as specialty and support units deployed throughout the city; specialized firefighting units for Philadelphia International Airport and the Port of Philadelphia; investigations conducted by the fire marshal's office to determine the origins of fires and develop preventive strategies; prevention programs to educate the public; and support services including research and planning, management of the fire communications center within the city's 911 system, and operation of the Philadelphia Fire Academy.\nEducation.\nPrimary and secondary education.\nEducation in Philadelphia is provided by many private and public institutions. The School District of Philadelphia is the local school district, operating public schools, in all of the city. The Philadelphia School District is the eighth-largest school district in the nation with 142,266 students in 218 traditional public schools and 86 charter schools as of 2014[ [update]].\nThe city's K-12 enrollment in district\u2013run schools dropped from 156,211 students in 2010 to 130,104 students in 2015. During the same time period, the enrollment in charter schools increased from 33,995 students in 2010 to 62,358 students in 2015. This consistent drop in enrollment led the city to close 24 of its public schools in 2013. During the 2014 school year, the city spent an average of $12,570 per pupil, below the average among comparable urban school districts.\nGraduation rates among district-run schools, meanwhile, steadily increased in the ten years from 2005. In 2005, Philadelphia had a district graduation rate of 52%. This number increased to 65% in 2014, still below the national and state averages. Scores on the state's standardized test, the Pennsylvania System of School Assessment (PSSA) trended upward from 2005 to 2011 but subsequently decreased. In 2005, the district-run schools scored an average of 37.4% on math and 35.5% on reading. The city's schools reached their peak scores in 2011 with 59.0% on math and 52.3% on reading. In 2014, the scores dropped significantly to 45.2% on math and 42.0% on reading.\nOf the city's public high schools, including charter schools, only four performed above the national average on the SAT (1497 out of 2400) in 2014: Masterman, Central, Girard Academic Music Program, and MaST Community Charter School. All other district-run schools were below average.\nHigher education.\nMedical and research facilities of the University of Pennsylvania School of Medicine and the Children's Hospital of Philadelphia. Philadelphia has the third-largest student concentration on the East Coast, with more than 120,000 college and university students enrolled within the city and nearly 300,000 in the metropolitan area. More than 80 colleges, universities, trade, and specialty schools are in the Philadelphia region. One of the founding members of the Association of American Universities is in the city, the University of Pennsylvania, an Ivy League institution with claims to be the first university in the United States.\nThe city's largest university by student enrollment is Temple University, followed by Drexel University. The city's nationally ranked research universities comprise the University of Pennsylvania, Temple University, Drexel University, and Thomas Jefferson University. Philadelphia is also home to five schools of medicine: Drexel University College of Medicine, Perelman School of Medicine at the University of Pennsylvania, Philadelphia College of Osteopathic Medicine, Temple University School of Medicine, and Thomas Jefferson University's Sidney Kimmel Medical College. Hospitals, universities, and higher education research institutions in Philadelphia's four congressional districts received more than $252\u00a0million in National Institutes of Health grants in 2015.\nOther institutions of higher learning within the city's borders include:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nMedia.\nNewspapers.\nPhiladelphia's two major daily newspapers are \"The Philadelphia Inquirer\", first published in 1829\u2014the third-oldest surviving daily newspaper in the country\u2014and the \"Philadelphia Daily News\", first published in 1925. The \"Daily News\" has been published as an edition of the \"Inquirer\" since 2009. Recent owners of the \"Inquirer\" and \"Daily News\" have included Knight Ridder, The McClatchy Company, and Philadelphia Media Holdings, with the latter organization declaring bankruptcy in 2010. After two years of financial struggle, the newspapers were sold to Interstate General Media in 2012. The two newspapers had a combined daily circulation of 306,831 and a Sunday circulation of 477,313 in 2013[ [update]], the 18th-largest circulation in the country, and their collective website, Philly.com, was ranked 13th in popularity among online U.S. newspapers by Alexa Internet the same year.\nSmaller publications include the \"Philadelphia Tribune\" published five days each week for the African-American community; \"Philadelphia\" magazine, a monthly regional magazine; \"Philadelphia Weekly\", a weekly alternative newspaper; \"Philadelphia Gay News\", a weekly newspaper for the LGBT community; \"The Jewish Exponent\", a weekly newspaper for the Jewish community; \"Al D\u00eda\", a weekly newspaper for the Latino community; and \"Philadelphia Metro\", a free daily newspaper.\nStudent-run newspapers include the University of Pennsylvania's \"The Daily Pennsylvanian\", Temple University's \"The Temple News\", and Drexel University's \"The Triangle\".\nRadio.\nThe first experimental radio license was issued in Philadelphia in August 1912 to St. Joseph's College. The first commercial AM radio stations began broadcasting in 1922: first WIP, then owned by Gimbels department store, followed by WFIL, then owned by Strawbridge &amp; Clothier department store, and WOO, a defunct station owned by Wanamaker's department store, as well as WCAU and WDAS.\nAs of 2018[ [update]], the FCC lists 28 FM and 11 AM stations for Philadelphia. As of December 2017, the ten highest-rated stations in Philadelphia were adult contemporary WBEB-FM (101.1), sports talk WIP-FM (94.1), classic rock WMGK-FM (102.9), urban adult contemporary WDAS-FM (105.3), classic hits WOGL-FM (98.1), album-oriented rock WMMR-FM (93.3), country music WXTU-FM (92.5), all-news KYW-AM (1060), talk radio WHYY-FM (90.9), and urban adult contemporary WRNB-FM (100.3). Philadelphia is served by three non-commercial public radio stations: WHYY-FM (NPR), WRTI-FM (classical and jazz), and WXPN-FM (adult alternative music).\nTelevision.\nIn the 1930s, W3XE, an experimental station owned by Philco, was the Delaware Valley's first television station. In 1939, the station became the nation's first NBC affiliate, and later became KYW-TV. In 1952, WFIL, later renamed WPVI, premiered the television show \"Bandstand\", which later became the nationally broadcast \"American Bandstand\" hosted by Dick Clark. In the 1960s, WCAU, WFIL-TV, and WHYY-TV were founded.\nEach of the nation's commercial networks has an owned-and operated station in Philadelphia: WDPN-TV 2 (MeTV and its sister networks), KYW-TV 3 (CBS), WPVI-TV 6 (ABC), WCAU 10 (NBC), WPHL-TV 17 (The CW with MyNetworkTV on a second subchannel), WFPA-CD 28 (UniM\u00e1s), WTXF-TV 29 (Fox), WPSG 57 (a CBS-owned independent station), WPPX-TV 61 (Ion), WWSI 62 (Telemundo), and WUVP-DT 65 (Univision). The region is served also by public broadcasting stations WPPT-TV in Philadelphia, WHYY-TV (licensed to Wilmington, Delaware with facilities in Philadelphia and a repeater station in Seaford, Delaware), WLVT-TV in the Lehigh Valley, and NJ PBS station WNJS, licensed across the Delaware to Camden, New Jersey .\nPhiladelphia is also the headquarters city for Comcast, the owner of NBC and Telemundo, along with WCAU and WWSI and the area's regional sports network NBC Sports Philadelphia, with those stations and NBCSP based out of the city's tallest building, the Comcast Technology Center, and more Comcast operations in the Comcast Center. Additionally, sister company Comcast Spectacor owns the Xfinity Mobile Arena, Stateside Live! and the Philadelphia Flyers, and will own the replacement arena currently scheduled for a 2031 completion.\nAs of 2023, the Philadelphia media market is the fifth-largest in North America with over 7.8 million viewers\nInfrastructure.\nTransportation.\nPhiladelphia is served by SEPTA, which operates buses, trains, rapid transit (as both subways and elevated trains), trolleys, and trackless trolleys (electric buses) throughout Philadelphia, the four Pennsylvania suburban counties of Bucks, Chester, Delaware, and Montgomery, in addition to service to Mercer County, New Jersey (Trenton) and New Castle County, Delaware (Wilmington and Newark, Delaware). The city's subway system consists of two routes: the subway section of the Market\u2013Frankford Line running east\u2013west under Market Street which opened in 1905 to the west and 1908 to the east of City Hall, and the Broad Street Line running north\u2013south beneath Broad Street which opened in stages from 1928 to 1938.\nBeginning in the 1980s, large sections of the SEPTA Regional Rail service to the far suburbs of Philadelphia were discontinued due to a lack of funding for equipment and infrastructure maintenance.\nPhiladelphia's 30th Street Station is a major railroad station on Amtrak's Northeast Corridor with 4.4\u00a0million passengers in 2017 making it the third-busiest station in the country after New York City's Pennsylvania Station and Washington's Union Station. 30th Street Station offers access to Amtrak, SEPTA, and NJ Transit lines. Over 12\u00a0million SEPTA and NJ Transit rail commuters use the station each year, and more than 100,000 people on an average weekday.\nThe PATCO Speedline provides rapid transit service to Camden, Collingswood, Westmont, Haddonfield, Woodcrest (Cherry Hill), Ashland (Voorhees), and Lindenwold, New Jersey, from stations on Locust Street between 16th and 15th, 13th and 12th, and 10th and 9th streets, on Market Street at 8th Street, and at 7th and Race at Franklin Square.\nAirports.\nPhiladelphia is served by two airports. Philadelphia International Airport (PHL), the larger of the two, is south-southwest of Center City on the boundary with Delaware County, and provides scheduled domestic and international air service. As of 2023, Philadelphia International Airport is the 21st-busiest airport in the nation with over 13.6 million passengers. It is also among the world's busiest airports measured by traffic movements, including takeoffs and landings. Over 30\u00a0million passengers pass through the airport annually on 25 airlines, including all major domestic carriers. The airport has nearly 500 daily departures to over 120 destinations worldwide. SEPTA's Airport Line provides direct service between Center City railroad stations and Philadelphia International Airport.\nPhiladelphia's second major airport, Northeast Philadelphia Airport (PNE), is a general aviation relief airport in Northeast Philadelphia, which provides general and corporate aviation.\nRoads.\nWilliam Penn planned Philadelphia with numbered streets traversing north and south, and streets named for trees, including Chestnut, Walnut, and Mulberry (since renamed Arch) Streets, traversing east and west. The two main streets were named Broad Street, the north\u2013south artery, later designated Pennsylvania Route 611, and High Street, the east\u2013west artery, which was later renamed Market Street, converging at Centre Square which later became the site of City Hall.\nInterstate 95, also known as the Delaware Expressway, traverses the southern and eastern edges of the city along the Delaware River as the main north\u2013south controlled-access highway, and connects Philadelphia with Newark, New Jersey and New York City to the north and Baltimore and Washington, D.C. to the south. The city is served by Interstate 76, also known as the Schuylkill Expressway, which runs along the Schuylkill River, intersecting the Pennsylvania Turnpike at King of Prussia and providing access to Harrisburg and points west. Interstate 676, also known as Vine Street Expressway, links I-95 and I-76 through Center City, running below street level between the eastbound and westbound lanes of Vine Street. Entrance and exit ramps for the Benjamin Franklin Bridge are near the eastern end of the expressway just west of the I-95 interchange.\nRoosevelt Boulevard and Expressway, also known as U.S. 1, connects Northeast Philadelphia with Center City via I-76 through Fairmount Park. Woodhaven Road, also known as Route 63, and Cottman Avenue, also known as Route 73, serve the neighborhoods of Northeast Philadelphia, running between I-95 and the Roosevelt Boulevard. Fort Washington Expressway, also known as Route 309, extends north from the city's northern border, serving Montgomery and Bucks Counties. U.S. Route 30, also known as Lancaster Avenue, extends west from West Philadelphia to Lancaster.\nInterstate 476, locally called the Blue Route, traverses Delaware County, bypassing the city to the west and serving the city's western suburbs, providing a direct route to Allentown, the Poconos, and points north. Interstate 276, the Pennsylvania Turnpike's Delaware River Extension, is a bypass and commuter route north of the city, which links to the New Jersey Turnpike and New York City.\nDelaware River Port Authority operates four bridges in the Philadelphia area, each of which cross the Delaware River to South Jersey: Walt Whitman Bridge (I-76), the Benjamin Franklin Bridge (I-676 and U.S. 30), Betsy Ross Bridge (New Jersey Route 90), and Commodore Barry Bridge (U.S. 322 in Delaware County, south of the city. The Burlington County Bridge Commission maintains two additional bridges that cross the Delaware River. Tacony\u2013Palmyra Bridge connects PA Route 73 in the Tacony section of Northeast Philadelphia with New Jersey Route 73 in Palmyra in Burlington County. Burlington\u2013Bristol Bridge connects NJ Route 413/U.S. Route 130 in Burlington, New Jersey with PA Route 413/U.S. 13 in Bristol Township, north of Philadelphia.\nBus service.\nThe Greyhound terminal is at 1001 Filbert Street (at 10th Street) in Center City, southeast of the Pennsylvania Convention Center and south of Chinatown. Several other bus operators provide service at the Greyhound terminal including Fullington Trailways, Martz Trailways, Peter Pan Bus Lines, and NJ Transit buses.\nOther intercity bus services include Megabus with stops at 30th Street Station and the visitor center for Independence Hall, BoltBus (operated by Greyhound) at 30th Street Station, OurBus at various stops in the city.\nRail.\nSince the early days of rail transportation in the United States, Philadelphia has served as a hub for several major rail companies, particularly the Pennsylvania Railroad and the Reading Railroad. The Pennsylvania Railroad first operated Broad Street Station, then 30th Street Station and Suburban Station, and the Reading Railroad operated Reading Terminal, now part of the Pennsylvania Convention Center. The two companies also operated competing commuter rail systems in the area. The two systems now operate as a single system under the control of SEPTA, the regional transit authority. Additionally, the PATCO Speedline subway system and NJ Transit's Atlantic City Line operate successor services to South Jersey.\nIn 1911, Philadelphia had nearly 4,000 electric trolleys running on 86 lines. In 2005, SEPTA reintroduced trolley service to the Girard Avenue Line, Route 15. SEPTA operates six subway-surface trolleys that run on street-level tracks in West Philadelphia and subway tunnels in Center City, along with two surface trolleys in adjacent suburbs.\nPhiladelphia is a regional hub of the federally-owned Amtrak system, with 30th Street Station being a primary stop on the Washington-Boston Northeast Corridor and the Keystone Corridor to Harrisburg and Pittsburgh. 30th Street also serves as a major station for services via the Pennsylvania Railroad's former Pennsylvania Main Line to Chicago. As of 2018[ [update]], 30th Street is Amtrak's third-busiest station in the country, after New York City and Washington.\nUtilities.\nWater purity and availability.\nIn 1815, Philadelphia began sourcing its water via the Fairmount Water Works on the Schuylkill River, the nation's first major urban water supply system. In 1909, the Water Works was decommissioned as the city transitioned to modern sand filtration methods. Philadelphia Water Department (PWD) provides drinking water, wastewater collection, and stormwater services for Philadelphia, as well as surrounding counties. PWD draws about 57 percent of its drinking water from the Delaware River and the balance from the Schuylkill River. The city has two filtration plants on the Schuylkill River and one on the Delaware River. The three plants can treat up to 546\u00a0million gallons of water per day, while the total storage capacity of the combined plant and distribution system exceeds one billion gallons. The wastewater system consists of three water pollution control plants, 21 pumping stations, and about of sewers.\nElectricity.\nExelon subsidiary PECO Energy Company, founded as the Brush Electric Light Company of Philadelphia in 1881 and renamed Philadelphia Electric Company (PECO) in 1902, provides electricity to about 1.6\u00a0million customers and more than 500,000 natural gas customers in the southeastern Pennsylvania area including the city of Philadelphia and most of its suburbs. PECO is the largest electric and natural gas utility in the state with 472 power substations and nearly of electric transmission and distribution lines and of natural gas transmission, distribution, and service lines.\nNatural gas.\nPhiladelphia Gas Works (PGW), overseen by the Pennsylvania Public Utility Commission, is the nation's largest municipally owned natural gas utility. PGW serves over 500,000 homes and businesses in the Philadelphia area. Founded in 1836, the company came under city ownership in 1987 and has been providing the majority of gas distributed within city limits. In 2014, the City Council refused to conduct hearings on a $1.86\u00a0billion sale of PGW, part of a two-year effort that was proposed by the mayor. The refusal led to the prospective buyer terminating its offer.\nTelecommunications.\nSoutheastern Pennsylvania was assigned the 215 area code in 1947 when the North American Numbering Plan of the Bell System went into effect. The geographic area covered by the code was split nearly in half in 1994 when area code 610 was created, with the city and its northern suburbs retaining 215. Overlay area code 267 was added to the 215 service area in 1997, and 484 was added to the 610 area in 1999. A plan in 2001 to introduce a third overlay code to both service areas, area code 445 to 215 and area code 835 to 610, was delayed and later rescinded. Area code 445 was implemented as an overlay for area codes 215 and 267 starting on February 3, 2018.\nSister cities.\nPhiladelphia also has three partnership cities or regions:\nPhiladelphia has eight official sister cities as designated by the Citizen Diplomacy International (CDI) of Philadelphia: Philadelphia has dedicated landmarks to its sister cities. The Sister Cities Park, a site of at 18th and Benjamin Franklin Parkway in Logan Square, was dedicated in June 1976. The park was built to commemorate Philadelphia's first two sister city relationships, with Tel Aviv and Florence. Toru\u0144 Triangle, honoring the sister city relationship with Toru\u0144, Poland, was constructed in 1976, west of the United Way building at 18th Street and Benjamin Franklin Parkway. Sister Cities Park was redesigned and reopened in 2012, featuring an interactive fountain honoring Philadelphia's sister and partnership cities, a caf\u00e9 and visitor center, children's play area, outdoor garden, boat pond, and a pavilion built to environmentally friendly standards.\nThe Chinatown Gate, erected in 1984 and crafted by artisans from Tianjin, stands astride 10th Street, on the north side of its intersection with Arch Street, as a symbol of the sister city relationship. The CDI of Philadelphia has participated in the U.S. Department of State's \"Partners for Peace\" project with Mosul, Iraq, and in accepting visiting delegations from dozens of other countries. In September 2025, John Moolenaar, chair of the United States House Select Committee on Strategic Competition between the United States and the Chinese Communist Party, requested that Philadelphia review its sister city agreement with Tianjin.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nrole=\"presentation\" class=\"wikitable succession-box noprint\" style=\"margin:0.5em auto; font-size:small;clear:both;\""}
{"id": "50587", "revid": "63066", "url": "https://en.wikipedia.org/wiki?curid=50587", "title": "Montreal, Canada", "text": ""}
{"id": "50588", "revid": "13052057", "url": "https://en.wikipedia.org/wiki?curid=50588", "title": "Expo 67", "text": "World's fair held in Montreal, Quebec\nThe 1967 International and Universal Exposition, commonly known as Expo 67, was a general exhibition from April 28 to October 29, 1967. It was a category one world's fair held in Montreal, Quebec, Canada. It is considered to be one of the most successful world's fairs of the 20th century with the most attendees to that date and 62 nations participating. It also set the single-day attendance record for a world's fair, with 569,500 visitors on its third day.\nExpo 67 was Canada's main celebration during its centennial year. The fair had been intended to be held in Moscow, to help the Soviet Union celebrate the Russian Revolution's 50th anniversary; however, for various reasons, the Soviets decided to cancel, and Canada was awarded it in late 1962.\nThe project was not well supported in Canada at first. It took the determination of Montreal's mayor, Jean Drapeau, and a new team of managers to guide it past political, physical and temporal hurdles. Defying a computer analysis that said it could not be done, the fair opened on time.\nAfter Expo 67 ended in October 1967, the site and most of the pavilions continued on as an exhibition called Man and His World, open during the summer months from 1968 until 1984. By that time, most of the buildings\u2014which had not been designed to last beyond the original exhibition\u2014had deteriorated and were dismantled. Today, the islands that hosted the world exhibition are mainly used as parkland and for recreational use, with only a few remaining structures from Expo 67 to show that the event was held there. Major League Baseball's 1969 expansion team, the Montreal Expos (now the Washington Nationals), was named in tribute to this event.\nHistory.\nBackground.\nThe idea of hosting the 1967 World Exhibition dates back to 1957. \"I believe it was Colonel Sevigny who first asked me to do what I could to bring Canada's selection as the site for the international exposition in 1967,\" wrote Prime Minister John Diefenbaker in his memoir. Montreal's mayor, Sarto Fournier, backed the proposal, allowing Canada to make a bid to the Bureau International des Expositions (BIE). At the BIE's May 5, 1960 meeting in Paris, Moscow was awarded the fair after five rounds of voting that eliminated Austria's and then Canada's bids. In April 1962, however, the Soviets scrapped plans to host the fair because of financial constraints and security concerns. Montreal's new mayor, Jean Drapeau, lobbied the Canadian government to try again for the fair, which they did. On November 13, 1962, the BIE changed the location of the World Exhibition to Canada, and Expo 67 went on to become the second-best attended BIE-sanctioned world exposition, after the 1900 Exposition Universelle in Paris. (It is now fourth, having been surpassed by Osaka (1970) and Shanghai (2010).)\nSeveral sites were proposed as the main Expo grounds. One location that was considered was Mount Royal Park, to the north of the downtown core. But it was Drapeau's idea to create new islands in the St. Lawrence river, and to enlarge the existing Saint Helen's Island. The choice overcame opposition from Montreal's surrounding municipalities, and also prevented land speculation. On March 29, 1963, the location for the World's Fair was officially announced as being Saint Helen's Island.\nKey people.\nExpo 67 did not get off to a smooth start; in 1963, many top organizing committee officials resigned. The main reason for the resignations was Mayor Drapeau's choice of the site on new islands to be created around the existing St. Helen's Island and also that a computer program predicted that the event could not possibly be constructed in time. Another more likely reason for the mass resignations was that on April 22, 1963, the federal Liberal government of Prime Minister Lester Pearson took power. This meant that former Prime Minister John Diefenbaker's Progressive Conservative government appointees to the board of directors of the Canadian Corporation for the 1967 World Exhibition were likely forced to resign.\nCanadian diplomat Pierre Dupuy was named Commissioner General, after Diefenbaker appointee Paul Bienvenu resigned from the post in 1963. One of the main responsibilities of the Commissioner General was to attract other nations to build pavilions at Expo. Dupuy would spend most of 1964 and 1965 soliciting 125 countries, spending more time abroad than in Canada. Dupuy's 'right-hand' man was Robert Fletcher Shaw, the deputy commissioner general and vice-president of the corporation. He also replaced a Diefenbaker appointee, C.F. Carsley, Deputy Commissioner General. Shaw was a professional engineer and builder, and is widely credited for the total building of the Exhibition. Dupuy hired Andrew Kniewasser as the general manager. The management group became known as \"Les Durs\"\u2014the tough guys\u2014and they were in charge of creating, building and managing Expo. \"Les Durs\" consisted of: Jean-Claude Delorme, Legal Counsel and Secretary of the Corporation; Dale Rediker, Director of Finances; Colonel Edward Churchill, Director of Installations; Philippe de Gasp\u00e9 Beaubien, Director of Operations, dubbed \"The Mayor of Expo\"; Pierre de Bellefeuille, Director of Exhibitors; and Yves Jasmin, Director of Information, Advertising and Public Relations. To this group the chief architect \u00c9douard Fiset was added. All ten were honoured by the Canadian government as recipients of the Order of Canada, Companions for Dupuy and Shaw, Officers for the others.\nJasmin wrote a book, in French, \"La petite histoire d'Expo 67\", about his 45-month experience at Expo and created the Expo 67 Foundation (available on the web site under that name) to commemorate the event for future generations.\nAs historian Pierre Berton put it, the cooperation between Canada's French- and English-speaking communities \"was the secret of Expo's success\u2014'the Qu\u00e9b\u00e9cois flair, the English-Canadian pragmatism.'\" However, Berton also points out that this is an over-simplification of national stereotypes. Arguably Expo did, for a short period anyway, bridge the \"Two Solitudes.\"\nMontebello conference produces theme.\nIn May 1963, a group of prominent Canadian thinkers\u2014including Alan Jarvis, director of the National Gallery of Canada; novelists Hugh MacLennan and Gabrielle Roy; John Tuzo Wilson, geophysicist; and Claude Robillard, town planner\u2014met for three days at the Seigneury Club in Montebello, Quebec. The theme, \"Man and His World\", was based on the 1939 book entitled \"Terre des Hommes\" (translated as \"Wind, Sand and Stars\") by Antoine de Saint-Exup\u00e9ry. In Roy's introduction to the Expo 67 corporation's book, entitled \"Terre des Hommes/Man and His World\", she elucidates the theme:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In \"Terre des Hommes\", his haunting book, so filled with dreams and hopes for the future, Antoine de Saint-Exup\u00e9ry writes of how deeply moved he was when, flying for the first time by night alone over Argentina, he happened to notice a few flickering lights scattered below him across an almost empty plain. They \"twinkled here and there, alone like stars...\" In truth, being made aware of our own solitude can give us insight into the solitude of others. It can even cause us to gravitate towards one another as if to lessen our distress. Without this inevitable solitude, would there be any fusion at all, any tenderness between human beings.\nMoved as he was by a heightened awareness of the solitude of all creation and by the human need for solidarity, Saint-Exup\u00e9ry found a phrase to express his anguish and his hope that was as simple as it was rich in meaning; and because that phrase was chosen many years later to be the governing idea of Expo 67, a group of people from all walks of life was invited by the Corporation to reflect upon it and to see how it could be given tangible form.\u2014\u200a\nThe organizers also created seventeen theme elements for Man and his World:\nConstruction begins.\nConstruction started on August 13, 1963, with an elaborate ceremony hosted by Mayor Drapeau on barges anchored in the St. Lawrence River. Ceremonially, construction began when Prime Minister Lester B. Pearson pulled a lever that signalled a front-end loader to dump the first batch of fill to enlarge \"\u00cele Sainte-H\u00e9l\u00e8ne\", and Quebec premier Jean Lesage spread the fill with a bulldozer. Of the 25 million tons of fill needed to construct the islands, 10\u201312% was coming from the Montreal Metro's excavations, a public works project that was already under construction before Expo was awarded to Montreal. The remainder of the fill came from quarries on Montreal and the South Shore, however even with that it was insufficient and so bodies of water on both islands were added (lakes and canals) to reduce the amount of fill required. Expo's initial construction period mainly centered on enlarging Saint Helen's Island, creating the artificial island of \u00cele Notre-Dame and lengthening and enlarging the Mackay Pier which became the Cit\u00e9 du Havre. While construction continued, the land rising out of Montreal harbour was not owned by the Expo Corporation yet. After the final mounds of earth completed the islands, the grounds that would hold the fair were officially transferred from the City of Montreal to the corporation on June 20, 1964. This gave Colonel Churchill only 1042 days to have everything built and functioning for opening day. To get Expo built in time, Churchill used the then new project management tool known as the critical path method (CPM). On April 28, 1967, opening day, everything was ready, with one exception: Habitat 67, which was then displayed as a work in progress.\nBuilding and enlarging the islands, along with the new Concorde Bridge built to connect them with the site-specific mass transit system known as the Montreal Expo Express, plus a boat pier, cost more than the Saint Lawrence Seaway project did only five years earlier: this was even before any buildings or infrastructure were constructed. With the initial phase of construction completed, it is easy to see why the budget for the exhibition was going to be larger than anyone expected. In the fall of 1963, Expo's general manager, Andrew Kniewasser, presented the master plan and the preliminary budget of $167 million for construction: it would balloon to over $439 million by 1967. The plan and budget narrowly passed a vote in Pearson's federal cabinet, passing by one vote, and then it was officially submitted on December 23, 1963.\nLogo.\nThe was designed by Montreal artist Julien H\u00e9bert. The basic unit of the logo is an ancient symbol of man. Two of the symbols (pictograms of \"man\") are linked as to represent friendship. The icon was repeated in a circular arrangement to represent \"friendship around the world\". The logotype uses the lower-case Optima typeface. It did not enjoy unanimous support from federal politicians, as some of them tried to kill it with a motion in the House of Commons of Canada.\nTheme songs.\nThe official Expo 67 theme song was composed by St\u00e9phane Venne and was titled: \"Hey Friend, Say Friend/Un Jour, Un Jour\".&lt;ref name=\"Un Jour/ Hey Friend\"&gt;\n&lt;/ref&gt; Complaints were made about the suitability of the song, as its lyrics mentioned neither Montreal nor Expo 67. The song was selected from an international competition with over 2,200 entries from 35 countries.\nHowever, the song that most Canadians associate with Expo was written by Bobby Gimby, a veteran commercial jingle writer who composed the popular Centennial tune \"Ca-na-da\". Gimby earned the name the \"Pied Piper of Canada\".\nThe theme song \"Something to Sing About\", used for the Canadian pavilion, had been written for a 1963 television special. The Ontario pavilion also had its own theme song: \"A Place to Stand, A Place to Grow\", which has evolved to become an unofficial theme song for the province.\nExpo opens.\nOfficial opening ceremonies were held on Thursday afternoon, April 27, 1967. The ceremonies were an invitation-only event, held at Place des Nations. Canada's Governor General, Roland Michener, proclaimed the exhibition open after the Expo flame was ignited by Prime Minister Pearson. On hand were over 7,000 media and invited guests including 53 heads of state. Over 1,000 reporters covered the event, broadcast in NTSC Colour, live via satellite, to a worldwide audience of over 700 million viewers and listeners.\nExpo 67 opened to the public on the morning of Friday, April 28, 1967, with a space age-style countdown. A capacity crowd at Place d'Accueil participated in the atomic clock-controlled countdown that ended when the exhibition opened precisely at 9:30\u00a0a.m. EST. An estimated crowd of between 310,000 and 335,000 visitors showed up for opening day, as opposed to the expected crowd of 200,000. The first person through the Expo gates at \"Place d'Accueil\" was Al Carter, a 41-year-old jazz drummer from Chicago, who was recognized for his accomplishment by Expo 67's director of operations Philippe de Gasp\u00e9 Beaubien. Beaubien presented Carter with a gold watch for his feat.\nOn opening day, there was considerable comment on the uniform of the hostesses from the UK Pavilion. The dresses had been designed to the then-new miniskirt style, popularized a year earlier by Mary Quant.\nIn conjunction with the opening of Expo 67, the Canadian Post Office Department issued a 5\u00a2 stamp commemorating the fair, designed by Harvey Thomas Prosser.\nEntertainment, Ed Sullivan Show, and VIPs.\nThe World Festival of Art and Entertainment at Expo 67 featured art galleries, opera, ballet and theatre companies, orchestras, jazz groups, famous Canadian pop musicians and other cultural attractions. Many pavilions had music and performance stages, where visitors could find free concerts and shows, including the Ukrainian Shumka Dancers. Micheline Legendre organized Canada's first puppetry festival in conjunction with the Expo. Most of the featured entertainment took place in the following venues: Place des Arts, Expo Theatre, Place des Nations, La Ronde, and Automotive Stadium.\nThe La Ronde amusement park was always intended to be a lasting legacy of the fair. Most of its rides and booths were permanent. When the Expo fairgrounds closed nightly, at around 10:00\u00a0p.m., visitors could still visit La Ronde, which closed at 2:30\u00a0a.m.\nIn addition, \"The Ed Sullivan Show\" was broadcast live on May 7 and 21 from Expo 67. Stars on the shows included America's the Supremes, Britain's Petula Clark, Australia's the Seekers and classical performers with conductor Wilfred Pelletier and the Montreal Symphony Orchestra with Swedish soprano Birgit Nilsson and Canadian pianist Ronald Turini.\nAnother attraction was the Canadian Armed Forces Tattoo 1967 at the Autostade in Montreal.\nThe fair was visited by many of the most notable people at the time, including Canada's monarch, Queen Elizabeth II, Lyndon B. Johnson, Princess Grace of Monaco, Jacqueline Kennedy, Robert F. Kennedy, Ethiopia's emperor Haile Selassie, Charles de Gaulle, Bing Crosby, Harry Belafonte, Maurice Chevalier, Maharishi Mahesh Yogi and Marlene Dietrich. Musicians like Thelonious Monk, Grateful Dead, Tiny Tim, the Tokens and Jefferson Airplane entertained the crowds.\nProblems.\nDespite its successes, there were problems: Front de lib\u00e9ration du Qu\u00e9bec militants had threatened to disrupt the exhibition, but were inactive during this period. Vietnam war protesters picketed during the opening day, April 28. American President Lyndon B. Johnson's visit became a focus of war protesters. Threats that the Cuba pavilion would be destroyed by anti-Castro forces were not carried out. In June, the Arab\u2013Israeli conflict in the Middle East flared up again in the Six-Day War, which resulted in Kuwait pulling out of the fair in protest to the way Western nations dealt with the war. The president of France, Charles De Gaulle, caused an international incident on July 24 when he addressed thousands at Montreal City Hall by yelling out the words \"Vive Montr\u00e9al... Vive le Qu\u00e9bec... Vive le Qu\u00e9bec Libre!\" \nIn September, the most serious problem turned out to be a 30-day transit strike. By the end of July, estimates predicted that Expo would exceed 60 million visitors, but the strike cut deeply into attendance and revenue figures, just as the fair was cruising to its conclusion. Another major problem, beyond the control of Expo's management, was guest accommodation and lodging. Logexpo was created to direct visitors to accommodations in the Montreal area, which usually meant that visitors would stay at the homes of people they were unfamiliar with, rather than traditional hotels or motels. The Montreal populace opened their homes to thousands of guests. Unfortunately for some visitors, they were sometimes sent to less than respectable establishments where operators took full advantage of the tourist trade. Management of Logexpo was refused to Expo and was managed by a Quebec provincial authority. Still, Expo would get most of the blame for directing visitors to these establishments. But overall, a visit to Expo from outside Montreal was still seen as a bargain.\nExpo ends.\nExpo 67 closed on Sunday afternoon, October 29, 1967. The fair had been scheduled to close two days earlier; however, a two-day extension granted by the Bureau International des Expositions (BIE) allowed it to continue over the weekend. On the final day 221,554 visitors added to the more than 50 million (54,991,806) that attended Expo 67 at a time when Canada's population was only 20 million, setting a per-capita record for World Exhibition attendance that still stands.\nStarting at 2:00\u00a0p.m., Expo Commissioner General Pierre Dupuy officiated over the medal ceremony, in which participating nations and organizations received gold and silver medallions, and over the ceremony in which national flags were lowered in the reverse order to which they had been raised, with Canada's flag lowered first and Nigeria's lowered last. After Prime Minister Pearson doused the Expo flame, Governor General Roland Michener closed Expo at Place des Nations with the mournful spontaneous farewell: \"It is with great regret that I declare that the Universal and International Exhibition of 1967 has come to an official end.\" All rides and the minirail were shut down by 3:50\u00a0p.m., and the Expo grounds closed at 4:00\u00a0p.m., with the last Expo Express train leaving for \"Place d'Accueil\" at that time. A fireworks display, that went on for an hour, was Expo's concluding event.\nExpo performed better financially than expected. Expo was intended to have a deficit, shared between the federal, provincial and municipal levels of government. Significantly better-than-expected attendance revenue reduced the debt to well below the original estimates. The final financial statistics, in 1967 Canadian dollars, were: revenues of $221,239,872, costs of $431,904,683, and a deficit of $210,664,811.\nPavilions.\nExpo 67 featured 90 pavilions representing Man and His World themes, nations, corporations, and industries including the U.S. pavilion, a geodesic dome designed by Buckminster Fuller. Many pavilions had innovative presentations, almost all using film in one way or another; as a commentator said, \"film was everywhere, unreeling at a furious rate. Expo was a fair of film.\"\nExpo 67 also featured the Habitat 67 modular housing complex designed by architect Moshe Safdie, which was later purchased by private individuals and is still occupied.\nThe most popular pavilion was the Soviet Union's exhibit. It attracted about 13 million visitors. Rounding out the top five pavilions, in terms of attendance were: the Canadian Pavilion (11 million visitors), the United States (9 million), France (8.5 million), and Czechoslovakia (8 million).\nThe participating countries were\nSeveral countries were absent due to different motives and financial reasons, including Spain, South Africa, the People's Republic of China, and many South American countries.\nLegacy.\nMan and His World (1968\u20131984).\nAfter 1967, the exposition struggled for several summer seasons as a standing collection of international pavilions known as \"Man and His World\". However, as attendance declined, the physical condition of the site deteriorated, and less and less of it was open to the public. Before the start of the 1972 season, the entire Notre Dame Island site closed and two years later completely rebuilt around the new rowing and canoe sprint (then flatwater canoeing) basin for Montreal's 1976 Summer Olympics. Space for the basin, the boathouses, the changing rooms and other buildings was obtained by demolishing many of the former pavilions and cutting in half the area taken by the artificial lake and the canals. By late 1973, both major transportation systems for the site, the Blue Minirail and Expo Express, had permanently ceased operation.\nIn 1976, a fire destroyed the acrylic outer skin of Buckminster Fuller's dome, and the previous year the Ontario pavilion was lost due to a major fire. With the site falling into disrepair, and several pavilions left abandoned and vandalized, it began to resemble ruins of a futuristic city.\nIn 1980, the Notre Dame Island site was reopened (primarily for the Floralies) making both islands simultaneously accessible again, albeit only for a brief time. Minor thematic exhibitions were held at the Quebec pavilion at this period. Before the start of the 1982 season, the Saint Helen's Island site permanently closed, shutting out the majority of attractions. Man and His World was able to continue in a limited fashion with the small number of pavilions left standing on Notre Dame Island. However, the few remaining original exhibits closed permanently in 1984.\nPark and surviving relics.\nAfter the Man and His World summer exhibitions were discontinued, with most pavilions and remnants demolished between 1985 and 1987, the former site for Expo 67 on Saint Helen's Island and Notre Dame Island was incorporated into a municipal park run by the city of Montreal. The park, named Parc des \u00celes, opened in 1992 during Montreal's 350th anniversary In 2000, the park was renamed from Parc des \u00celes to Parc Jean-Drapeau, after Mayor Jean Drapeau, who had brought the exhibition to Montreal. In 2006, the corporation that runs the park also changed its name from the \"Soci\u00e9t\u00e9 du parc des \u00celes\" to the \"Soci\u00e9t\u00e9 du parc Jean-Drapeau\". Today very little remains of Expo but two prominent buildings remain in use on the former Expo grounds: the American pavilion's metal-lattice skeleton form its Buckminster Fuller dome, now enclosing an environmental sciences museum called the Montreal Biosphere; and Habitat 67, now a condominium residence. The France and Quebec pavilions, now interconnected, now form the Montreal Casino.\nPart of the structural remains of the Canadian pavilion survive as La Toundra Hall. It is now a special events and banquet hall, while another part of the pavilion serves as Parc Jean-Drapeau's administration building. (Katimavik's distinctive inverted pyramid and much of the rest of the Canadian pavilion were dismantled during the 1970s).\nPlace des Nations, where the opening and closing ceremonies were held, remains, however in an abandoned and deteriorating state (its sizable walkways that bridged all the site's structures was demolished in 2024). The Jamaican, Tunisian and partial remains of the Korean pavilion (roof only) also survive, as well as the CIBC banking centre. In Cite du Havre the Expo Theatre, Administration and Fine Arts buildings remain. Other remaining structures include sculptures and landscaping. The Montreal Metro subway station Berri-UQAM still has an original \"Man and His World\" welcome sign with logo above the pedestrian tunnel entrance to the Yellow Line. La Ronde continued to be operated by the City of Montreal following the Expo. In 2001 it was leased to the Texas-based amusement park company Six Flags, which has operated the park since. The Alcan Aquarium built for the Expo remained in operation for a number of decades until its closure in 1991. The Expo 67 parking lot was converted into Victoria STOLport, an experimental short-take off airport for a brief time in the 1970s.\nThe Olympic basin is used by many local rowing clubs. A beach was built on the shores of the remaining artificial lake. There are many acres of parkland and cycle paths on both Saint Helen's Island and the western tip of Notre Dame Island. The site has been used for a number of events such as a BIE-sponsored international botanical festival, \"Les floralies\". The young trees and shrubs planted for Expo 67 are now mature. The plants introduced during the botanical events have flourished also.\nAnother attraction on today's Notre Dame Island site is the Circuit Gilles Villeneuve race track that is used for the Canadian Grand Prix.\nThe Czechoslovak pavilion was designed to be disassembled and sold, attracting the interest of the province of Newfoundland, though its bid was not preferred by the Czechoslovak government at first. On September 5, 1967, Ceskoslovenske Aerolinie Flight 523 crashed during takeoff from Gander International Airport, and many people were saved by the residents of Gander, which may have led to Newfoundland's purchase offer being accepted. It was assembled as the Grand Falls Arts and Culture Centre, now the Gordon Pinsent Centre for the Arts.\nThe government of Newfoundland also purchased the Yugoslavian pavilion, a triangular building that was converted into the Provincial Seamen's Museum in Grand Bank.\nOne of the few Vaporettos that shuttled visitors around the park on \"Expo Service No. 5\" survived. After it was decommissioned it ended up in Charlottetown, Prince Edward Island in 1971 where it gave harbour tours. It was later moved to Nova Scotia and then New Brunswick. It has subsequently been renovated and returned to Charlottetown.\nExpo's lasting effects.\nIn a political and cultural context, Expo 67 was seen as a landmark moment in Canadian history. In 1968, as a salute to the cultural impact the exhibition had on the city, Montreal's Major League baseball team, the Expos (now the Washington Nationals), was named after the event. 1967 was also the year that invited Expo guest Charles De Gaulle, on July 24, addressed thousands at Montreal City Hall by yelling out the now famous words: \"Vive Montr\u00e9al... Vive le Qu\u00e9bec... Vive le Qu\u00e9bec Libre!\" De Gaulle was rebutted in Ottawa by Prime Minister Lester B. Pearson: \"Canadians do not need to be liberated, Canada will remain united and will reject any effort to destroy her unity.\" In the years that followed, the tensions between the English- and French-speaking communities would continue. As an early 21st-century homage to the fair, satirists Bowser and Blue wrote a full-length musical set at Expo 67 called \"The Paris of America\", which ran for six sold-out weeks at Centaur Theatre in Montreal in April and May 2003.\nExpo 67 was one of the most successful World Exhibitions, and is still regarded fondly by Canadians. In Montreal, 1967 is often referred to as \"the last good year\" before economic decline, Quebec sovereignism (seen as negative from a federalist viewpoint), deteriorating infrastructure and political apathy became common. In this way, it has much in common with the 1964\u201365 New York World's Fair. In 2007, a new group, Expo 17, was looking to bring a smaller-scale \u2014 BIE sanctioned \u2014 exposition to Montreal for Expo 67's 50th anniversary and Canada's sesquicentennial in 2017. Expo 17 hoped a new world's fair would regenerate the spirit of Canada's landmark centennial project.\n50th anniversary.\nStarting in the spring of 2017, as part of the 50th anniversary celebrations for Expo 67, the city of Montreal and the committee in charge of the celebrations of 375th anniversary of the founding of the city put forward a commemoration program including fourteen events.\nWhen visiting these locations and taking part in these events, visitors had access to an electronic or paper passport in which they could collect stamps, just as it had been the case during Expo 67.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50589", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=50589", "title": "Spanking", "text": "Corporal punishment of striking the buttocks\nSpanking is a form of corporal punishment involving the act of striking, with either the palm of the hand or an implement, the buttocks of a person to cause physical pain. The term spanking broadly encompasses the use of either the hand or implement, though the use of certain implements can also be characterized as other, more specific types of corporal punishment such as belting, caning, paddling, and slippering.\nSome parents spank children in response to undesired behavior. Adults more commonly spank boys than girls both at home and in school. Many countries have outlawed the spanking of children in every setting, including homes, schools, and penal institutions, while others permit it when done by a parent or guardian.\nMedical organizations discourage its use in favor of healthier discipline strategies. Some research has found correlations between spanking and increased aggression, mental health issues, and decreased obedience in children, however findings have been inconsistent, and correlation does not prove causation. A 2024 analysis of previous studies found that spanking accounted for less than 1% of changes in child outcomes; concluding that harm caused by spanking had been overstated, but still recommended some caution.\nTerminology.\nIn American English, dictionaries define spanking as being administered with either the open hand or an implement such as a paddle. Thus, the standard form of corporal punishment in US schools (use of a paddle) is often referred to as a \"spanking\". In North America, the word \"spanking\" has often been used as a synonym for an official paddling in school, and sometimes even as a euphemism for the formal corporal punishment of adults in an institution.\nIn British English, most dictionaries define \"spanking\" as being given only with the open hand. In the United Kingdom, Ireland, Australia, and New Zealand, the word \"smacking\" is generally used in preference to \"spanking\" when describing striking with an open hand, rather than with an implement. Whereas a spanking is invariably administered to the bottom, a \"smacking\" is less specific and may refer to slapping the child's hands, arms, or legs as well as its bottom.\nEffect on children.\nThe main reasons parents give for spanking their children are to make children more compliant and to promote better behavior, especially to put a stop to their children's apparent aggressive behaviors. However, research has shown that spanking (or any other form of corporal punishment) is associated with the opposite effect. When adults physically punish children, the children tend to obey parents less with time and develop more aggressive behaviors, including toward other children. This increase in aggressive behavior appears to reflect the child's perception that hitting is the way to deal with anger and frustration. \nThere are also many adverse physical, mental, and emotional effects correlated with spanking and other forms of corporal punishment, including various physical injuries, increased anxiety, depression, and antisocial behavior. Adults who were spanked during their childhood are more likely to abuse their children and spouse.\nThe American Academy of Pediatrics (AAP), Royal College of Paediatrics and Child Health (RCPCH), and the Royal Australasian College of Physicians (RACP) all recommend that no child should be spanked and instead favor the use of effective, healthy forms of discipline. Additionally, the AAP recommends that primary care providers (e.g., pediatricians and family medicine physicians) begin to discuss parents' discipline methods no later than nine months of age and consider initiating such discussions by age 3\u20134 months. By eight months of age, 5% of parents report spanking and 5% report starting to spank by age three months. The AAP also recommends that pediatricians discuss effective discipline strategies and counsel parents about the ineffectiveness of spanking and the risks of harmful effects associated with the practice to minimize harm to children and guide parents.\nAlthough parents and other advocates of spanking often claim that spanking is necessary to promote child discipline, studies have shown that parents tend to apply physical punishment inconsistently and tend to spank more often when they are angry or under stress. The use of corporal punishment by parents increases the likelihood that children will suffer physical abuse, and most documented cases of physical abuse in Canada and the United States begin as disciplinary spankings. If a child is frequently spanked, this form of corporal punishment tends to become less effective at modifying behavior over time (also known as extinction). In response to the decreased effectiveness of spanking, some parents increase the frequency or severity of spanking or use an object.\nA 2024 scientific analysis of previous studies found that spanking accounted for less than 1% of changes in child outcomes, concluding that \"blanket anti-spanking injunctions\" were unsupported.\nAlternatives to spanking.\nParents may spank less \u2013 or not at all \u2013 if they have learned effective discipline techniques, as many view spanking as a last resort for disciplining their children. There are many alternatives to spanking and other forms of corporal punishment:\nIn the home.\nParents commonly spank their children as a form of corporal punishment in the United States; however, support for this practice appears to be declining amongst U.S. parents. Spanking is typically done with one or more slaps on the child's buttocks with a bare hand, although, not uncommonly, various objects are used to spank children, such as a hairbrush or wooden spoon. Historically, adults have spanked boys more than girls. In the United States, adults commonly spank toddlers the most. \nIn schools.\n Corporal punishment, usually delivered with an implement (such as a paddle or cane) rather than with the open hand, used to be a common form of school discipline in many countries, but it is now banned in most of the Western World.\nCorporal punishment, such as caning, remains a common form of discipline in schools in several Asian and African countries, even in countries in which this practice has been deemed illegal such as India and South Africa. In these cultures it is referred to as \"caning\" and not \"spanking.\"\nThe Supreme Court of the United States in 1977 held that the paddling of school students was not \"per se\" unlawful. However, 33 states have now banned paddling in public schools. It is still common in some schools in the South, and more than 167,000 students were paddled in the 2011\u20132012 school year in American public schools. Students can be physically punished from kindergarten to the end of high school, meaning that even adults who have reached the age of majority are sometimes spanked by school officials.\nSeveral medical, pediatric, or psychological societies have issued statements opposing all forms of corporal punishment in schools, citing such outcomes as poorer academic achievements, increases in antisocial behaviors, injuries to students, and an unwelcoming learning environment. They include the American Medical Association, the American Academy of Child and Adolescent Psychiatry, the American Psychoanalytic Association, the American Academy of Pediatrics (AAP), the Society for Adolescent Medicine, the American Psychological Association, the Royal College of Paediatrics and Child Health, the Royal College of Psychiatrists, the Canadian Paediatric Society and the Australian Psychological Society, as well as the United States' National Association of School Psychologists and National Association of Secondary School Principals.\nAdult spanking.\nMost spanking performed between adults in the 21st century within the Western world is erotic spanking.\nWithin the early 20th century, American men spanking their wives and girlfriends was often seen as an acceptable form of discipline. It was a common trope in American films, from the earliest days up through the 1960s, and was often used to allude to romance between the man and woman.\nIn the early 21st century, adherents of a subculture known as \"Christian domestic discipline\" have, on a literalist interpretation of the Bible, justified spanking as a form of acceptable punishment of women by their husbands, even though there are no direct teachings or examples in the Bible of husbands spanking their wives. Critics describe such practices as a form of domestic abuse.\nA few countries have a judicial corporal punishment for adults.\nRitual spanking traditions.\nAsia.\nOn the first day of the lunar Chinese New Year holidays, a week-long 'Spring Festival', the most important festival for Chinese people all over the world, thousands of Chinese visit the Taoist \"Dong Lung Gong\" temple in Tungkang to go through the century-old ritual to get rid of bad luck. Men traditionally receive spankings and women get whipped, with the number of strokes to be administered (always lightly) by the temple staff being decided in either case by the god Wang Ye and by burning incense and tossing two pieces of wood, after which all go home happily, believing their luck will improve.\nEurope.\nOn Easter Monday, there is a Slavic tradition of spanking girls and young ladies with woven willow switches (Czech: \"poml\u00e1zka\"; Slovak: \"korb\u00e1\u010d\") and dousing them with water.\nIn Slovenia, there is a jocular tradition that anyone who succeeds in climbing to the top of Mount Triglav receives a spanking or birching.\nIn Poland, there is a tradition named \"Pasowanie\", which is celebrated on the 18th birthday. The birthday person receives eighteen smacks with the belt from the guests at the birthday party.\nNorth America.\n\"Birthday spanking\" is a tradition within some parts of the United States. Within the tradition, an individual (commonly, though not exclusively, a child) upon their birthday receives, typically corresponding to their age, several spanks. Characteristically, these spankings are playful and are administered in such a fashion that the recipient receives no or only minor discomfort.\nReferences.\nNotes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50591", "revid": "49433774", "url": "https://en.wikipedia.org/wiki?curid=50591", "title": "United States Postal Service", "text": "Independent agency of the U.S. federal government\nThe United States Postal Service (USPS), also known as the Post Office, U.S. Mail, or simply the Postal Service, is an independent agency of the executive branch of the United States federal government responsible for providing postal service in the United States, its insular areas and associated states. It is one of a few government agencies explicitly authorized by the Constitution of the United States. As of March 29, 2024, the USPS has 525,377 career employees and nearly 114,623 pre-career employees.\nThe USPS has a monopoly on traditional letter delivery within the U.S. and operates under a universal service obligation (USO), both of which are defined across a broad set of legal mandates, which obligate it to provide uniform price and quality across the entirety of its service area. The Post Office has exclusive access to letter boxes marked \"U.S. Mail\" and personal letterboxes in the U.S., but has to compete against private package delivery services, such as United Parcel Service, FedEx, and DHL.\nHistory.\nThe first national postal agency in the US, known as the \"United States Post Office\" was founded by the Second Continental Congress in Philadelphia on July 26, 1775, at the beginning of the American Revolution. Benjamin Franklin was appointed the first postmaster general; he also served a similar position for the American colonies. The Post Office Department was created in 1792 with the passage of the Postal Service Act. It was elevated to a cabinet-level department in 1872, and was transformed by the Postal Reorganization Act of 1970 into the U.S. Postal Service as an independent agency.\nThe Post Office Department owned and operated the first public telegraph lines in the United States, starting in 1844 from Washington to Baltimore, and eventually extending to New York, Boston, Buffalo, and Philadelphia. In 1847, the telegraph system was privatized, except for a period during World War I, when it was used to accelerate the delivery of letters arriving at night.\nBetween 1942 and 1945, \"V-Mail\" (for \"Victory Mail\") service was available for military mail. Letters were converted into microfilm and reprinted near the destination, to save room on transport vehicles for military cargo.\nThe United States Information Agency (USIA) helped the Post Office Department, during the Cold War, to redesign stamps to include more patriotic slogans. On March 18, 1970, postal workers in New York City\u2014upset over low wages and poor working conditions, and emboldened by the Civil Rights Movement\u2014organized a strike. The strike initially involved postal workers in only New York City, but it eventually gained support of over 210,000 postal workers across the nation. While the strike ended without any concessions from the federal government, it did ultimately allow for postal worker unions and the government to negotiate a contract which gave the unions most of what they wanted, as well as the signing of the Postal Reorganization Act by President Richard Nixon on August 12, 1970. The act replaced the cabinet-level Post Office Department with a new federal agency, the U.S. Postal Service, and took effect on July 1, 1971.\nAmong the changes from the Postal Reorganization Act, a key aspect was the requirement for the USPS to be self-financing, which introduced a conflict with its other requirement to provide a nationwide service. The next major legislation affecting the service, the Postal Accountability and Enhancement Act, was passed in 2006. This act limited the services that the Postal Service could offer to only those it already provided and also established a requirement for the USPS to save money for the medical benefits of future retirees. The Act set a goal to save $5 billion per year for the first 10 years of a 50-year schedule, however within 6 years the Postal Service began to default on its payments. The Postal Service experienced lower revenues as mail use declined in the 2010s. In 2012, in order to be able to meet obligations for payroll and continuing its operations, the Postal Service defaulted on payments due for retirements benefits in August and again in September that year. In September 2014, it defaulted on the payments for the fourth time, and continued to default into 2017. The Postal Service sought financial reforms from Congress for relief from the funding obligation and debt from the defaults. Legislation was introduced in Congress in 2016 as well as in 2019, aiming to remove the benefits funding obligations, however no new legislation was passed until the 2022 Postal Service Reform Act (PSRA). The PSRA was signed into law in April 2022. It forgave $57 billion in Postal Service debt and released it from the obligation to set aside funds for future retirees' healthcare, as well as adding requirements for delivery timing and reporting on performance metrics, and allowing the Postal Service to offer some non-mail services.\nCurrent operations.\nDeliveries.\nAs of 2023, the Postal Service operates 33,641 Post Office and contract locations in the U.S., and delivered a total of 127.3 billion packages and pieces of mail to 164.9 million delivery points in fiscal year 2022.\nUSPS delivers mail and packages Monday through Saturday as required by the Postal Service Reform Act of 2022; on Sundays only Priority Express and packages for Amazon.com are delivered. The USPS delivers packages on Sundays in most major cities. During the four weeks preceding Christmas since 2013, packages from all mail classes and senders were delivered on Sunday in some areas. Parcels are also delivered on holidays, with the exception of Thanksgiving and Christmas. The USPS started delivering Priority Mail Express packages on Christmas Day in select locations for an additional fee.\nThe holiday season between Thanksgiving and Christmas is the peak period for the Postal Service, representing a total volume of 11.7 billion packages and pieces of mail during this time in 2022.\nFleet.\nThe USPS operates one of the largest civilian vehicle fleets in the world, with over 235,000 vehicles as of 2024, the majority of which are the distinctive and unique Chevrolet/Grumman LLV (long-life vehicle), and the similar, newer Ford-Utilimaster FFV (flexible-fuel vehicle), originally also referred to as the CRV (carrier route vehicle). The LLVs were built from 1987 to 1994 and lack air conditioning, airbags, anti-lock brakes, and space for the large modern volume of e-commerce packages, the Grumman fleet ended its expected 24-year lifespan in fiscal year 2017. The LLV replacement process began in 2015, and after numerous delays, a $6\u00a0billion contract was awarded in February 2021 to Oshkosh Defense to finalize design and produce 165,000 vehicles over 10 years. The Next Generation Delivery Vehicle (NGDV), will have both gasoline and battery electric versions. Half of the initial 50,000 vehicles will be electric, as will all vehicles purchased after 2026.\nThe number of gallons of fuel used in 2009 was 444\u00a0million, at a cost of US$. For every penny increase in the national average price of gasoline, the USPS spends an extra US$ million per year to fuel its fleet.\nThe fleet is notable in that many of its vehicles are right-hand drive, an arrangement intended to give drivers the easiest access to roadside mailboxes. Some rural letter carriers use personal vehicles. All contractors use personal vehicles. Standard postal-owned vehicles do not have license plates. These vehicles are identified by a seven-digit number displayed on the front and rear.\nElectrifying the USPS fleet.\nStarting in 2026, all delivery truck purchases are scheduled to be electric vehicles, partly in response to criticism from the Environmental Protection Agency and an environmental lawsuit, and also due to availability of new funding provided by the Inflation Reduction Act of 2022. The Act included $3 billion for electric USPS vehicles, supporting the initiative by Postmaster General DeJoy and the Biden Administration to add 66,000 electric vehicles to the fleet by 2028. The electric fleet will be composed of 9,250 EVs manufactured by Ford; 11,750 commercial off-the-shelf EVs; and 45,000 Oshkosh Next Generation Delivery Vehicles. In February 2023, the Postal Service announced its purchase of the Ford EVs as well as 14,000 electric vehicle charging stations. The fleet electrification plan is part of the Postal Service's initiative to reduce carbon emissions from fuel and electricity 40 percent and emissions from contracted services 20 percent by 2030. The bulk of the savings comes from less expensive 'fuel' and less required maintenance. Other benefits include less pollution where children live and play.\nIn August 2024, the USPS deployed the first new vehicles from its fleet modernization project at its Topeka Sorting and Delivery Center in Kansas, including: an electric vehicle with higher clearance for routes delivering a high number of packages, and an electric delivery vehicle produced in partnership with Canoo that is a \"pod-like\" smaller van.\nOperation and budget.\nIn fiscal year 2022, the Postal Service had $78.81 billion in revenue and expenses of $79.74 billion. Due to one-time appropriations authorized by the Postal Service Reform Act of 2022, the agency reported a net income of $56.04 billion. In the 2023 fiscal year, revenue had increased to $79.32\u00a0billion, but reported a net loss of $6.48\u00a0billion. In the 2024 fiscal year, revenue increased to $79.53 billion but reported a net loss of $9.5 billion.\nRevenue decline and planned cuts.\nIn 2016, the USPS had its fifth straight annual operating loss, in the amount of $5.6\u00a0billion, of which $5.8\u00a0billion was the accrual of unpaid mandatory retiree health payments.\nDeclining mail volume.\nFirst-class mail volume peaked in 2001 to 103.65 billion declining to 52.62 billion by 2020 due to the increasing use of email and the World Wide Web for correspondence and business transactions. \nPrivate courier services, such as FedEx and United Parcel Service (UPS), directly compete with USPS for the delivery of packages.\nLower volume means lower revenues to support the fixed commitment to deliver to every address once a day, six days a week. According to an official report on November 15, 2012, the U.S. Postal Service lost $15.9\u00a0billion its 2012 fiscal year.\nInternal streamlining and delivery slowdown.\nIn response, the USPS has increased productivity each year from 2000 to 2007, through increased automation, route re-optimization, and facility consolidation. Despite these efforts, the organization saw an $8.5\u00a0billion budget shortfall in 2010, and was losing money at a rate of about $3\u00a0billion per quarter in 2011.\nOn December 5, 2011, the USPS announced it would close more than half of its mail processing centers, eliminate 28,000 jobs and reduce overnight delivery of First-Class Mail. This will close down 252 of its 461 processing centers. (At peak mail volume in 2006, the USPS operated 673 facilities.) As of May 2012, the plan was to start the first round of consolidation in summer 2012, pause from September to December, and begin a second round in February 2014; 80% of first-class mail would still be delivered overnight through the end of 2013. New delivery standards were issued in January 2015, and the majority of single-piece (not presorted) first-class mail is now being delivered in two days instead of one. Large commercial mailers can still have first-class mail delivered overnight if delivered directly to a processing center in the early morning, though as of 2014 this represented only 11% of first-class mail. Unsorted first-class mail will continue to be delivered anywhere in the contiguous United States within three days.\nPost office closures.\nIn July 2011, the USPS announced a plan to close about 3,700 small post offices. Various representatives in Congress protested, and the Senate passed a bill that would have kept open all post offices farther than from the next office. In May 2012, the service announced it had modified its plan. Instead, rural post offices would remain open with reduced retail hours (some as little as two hours per day) unless there was a community preference for a different option. In a survey of rural customers, 54% preferred the new plan of retaining rural post offices with reduced hours, 20% preferred the \"Village Post Office\" replacement (where a nearby private retail store would provide basic mail services with expanded hours), 15% preferred merger with another Post Office, and 11% preferred expanded rural delivery services. In 2012, USPS reported that approximately 40% of postal revenue comes from online purchases or private retail partners including Walmart, Staples, Office Depot, Walgreens, Sam's Club, Costco, and grocery stores. The National Labor Relations Board agreed to hear the American Postal Workers Union's arguments that these counters should be staffed by postal employees who earn far more and have \"a generous package of health and retirement benefits\".\nElimination of Saturday delivery averted.\nOn January 28, 2009, Postmaster General John E. Potter testified before the Senate that, if the Postal Service could not readjust its payment toward the contractually funding earned employee retiree health benefits, as mandated by the Postal Accountability &amp; Enhancement Act of 2006, the USPS would be forced to consider cutting delivery to five days per week during June, July, and August.\nH.R. 22, addressing this issue, passed the House of Representatives and Senate and was signed into law on September 30, 2009. However, Postmaster General Potter continued to advance plans to eliminate Saturday mail delivery.\nOn June 10, 2009, the National Rural Letter Carriers' Association (NRLCA) was contacted for its input on the USPS's current study of the effect of five-day delivery along with developing an implementation plan for a five-day service plan. A team of Postal Service headquarters executives and staff was given a time frame of 60 days to complete the study. The current concept examines the effect of five-day delivery with no business or collections on Saturday, with Post Offices with current Saturday hours remaining open.\nOn Thursday, April 15, 2010, the House Committee on Oversight and Government Reform held a hearing to examine the status of the Postal Service and recent reports on short and long-term strategies for the financial viability and stability of the USPS entitled \"Continuing to Deliver: An Examination of the Postal Service's Current Financial Crisis and its Future Viability\". At which, PMG Potter testified that by 2020, the USPS cumulative losses could exceed $238\u00a0billion, and that mail volume could drop 15 percent from 2009.\nIn February 2013, the USPS announced that in order to save about $2\u00a0billion per year, Saturday delivery service would be discontinued except for packages, mail-order medicines, Priority Mail, Express Mail, and mail delivered to Post Office boxes, beginning August 10, 2013. However, the Consolidated and Further Continuing Appropriations Act, 2013, passed in March, reversed the cuts to Saturday delivery.\nRetirement funding and payment defaults.\nThe Postal Accountability and Enhancement Act of 2006 (PAEA) obligated the USPS to fund the present value of earned retirement obligations (essentially past promises which have not yet come due) within a ten-year time span.\nThe U.S. Office of Personnel Management (OPM) is the main bureaucratic organization responsible for the human resources aspect of many federal agencies and their employees. The PAEA created the Postal Service Retiree Health Benefit Fund (PSRHB) after Congress removed the Postal Service contribution to the Civil Service Retirement System (CSRS). Most other employees that contribute to the CSRS have 7% deducted from their wages. Currently, all new employees contribute into Federal Employee Retirement System (FERS) once they become a full-time regular employees.\nRunning low on cash, in order to continue operations unaffected and continue to meet payroll, the USPS defaulted for the first time on a $5.5 billion retirement benefits payment due August 1, 2012, and a $5.6 billion payment due September 30, 2012.\nOn September 30, 2014, the USPS failed to make a $5.7\u00a0billion payment on this debt, the fourth such default. In 2017, the USPS defaulted on some of the last lump-sum payments required by the 2006 law, though other payments were also still required.\nProposals to cancel the funding obligation and plan a new schedule for the debt were introduced in Congress as early as 2016. A 2019 bill entitled the \"USPS Fairness Act\", which would have eliminated the pension funding obligation, passed the House but did not proceed further. As of March 8, 2022, the Postal Service Reform Act of 2022, which includes a section entitled \"USPS Fairness Act\" cancelling the obligation, has passed both the House and the Senate; President Joe Biden signed the bill into law on April 6, 2022.\nRate increases.\nCongress has limited rate increases for First-Class Mail to the cost of inflation, unless approved by the Postal Regulatory Commission. A three-cent surcharge above inflation increased the rate to 49\u00a2 in January 2014, but this was approved by the commission for two years only. As of July 13, 2025 the cost of postage increased to 78 cents for first class mail.\nReform proposals and delivery changes.\nDuring the Obama administration.\nComprehensive reform packages considered in the 113th Congress include S.1486 and H.R.2748. These include the efficiency measure, supported by Postmaster General Patrick Donahoe of ending door-to-door delivery of mail for some or most of the 35\u00a0million addresses that currently receive it, replacing that with either curbside boxes or nearby \"cluster boxes\". This would save $4.5\u00a0billion per year out of the $30\u00a0billion delivery budget; door-to-door city delivery costs annually on average $353 per stop, curbside $224, and cluster box $160 (and for rural delivery, $278, $176, and $126, respectively).\nS.1486, also with the support of Postmaster General Donahoe, would also allow the USPS to ship alcohol in compliance with state law, from manufacturers to recipients with ID to show they are over 21. This is projected to raise approximately $50\u00a0million per year. (Shipping alcoholic beverages is currently illegal under \u00a0https://(f).)\nIn 2014, the Postal Service was requesting reforms to workers' compensation, moving from a pension to defined contribution retirement savings plan, and paying senior retiree health care costs out of Medicare funds, as is done for private-sector workers.\nDuring the first Trump administration.\nAs part of a June 2018 governmental reorganization plan, the Donald Trump administration proposed turning USPS into \"a private postal operator\" which could save costs through measures like delivering mail fewer days per week, or delivering to central locations instead of door to door. There was strong bipartisan opposition to the idea in Congress.\nIn April 2020, Congress approved a $10 billion loan from the Treasury to the post office. According to \"The Washington Post\", officials under Treasury Secretary Steven Mnuchin suggested using the loan as leverage to give the Treasury Department more influence on USPS operations, including making them raise their charges for package deliveries, a change long sought by President Trump.\nIn May 2020, the Board of Governors of the United States Postal Service appointed Louis DeJoy as Postmaster General. DeJoy was the first appointee in two decades to come from outside the postal service. Prior to the appointment, he was the founder and CEO of the logistics and freight company New Breed Logistics and was a major Republican Party donor and fundraiser for Donald Trump.\nDeJoy immediately began taking measures to reduce costs, such as banning overtime and extra trips to deliver mail. While DeJoy admitted that these measures were causing delays in mail delivery, he said they would eventually improve service.\nMore than 600 high-speed mail sorting machines were scheduled to be dismantled and removed from postal facilities, raising concerns that mailed ballots for the November 3 election might not reach election offices on time.\nMail collection boxes were removed from the streets in many cities; after photos of boxes being removed were spread on social media, a postal service spokesman said they were being moved to higher traffic areas but that the removals would stop until after the election.\nThe inspector general for the postal service opened an investigation into the recent changes. On August 16 the House of Representatives was called back from its summer recess to consider a bill rolling back all of the changes.\nOn August 18, 2020, after days of heavy criticism and the day after lawsuits against the Postal Service and DeJoy personally were filed in federal court by several individuals, DeJoy announced that he would roll back all the changes until after the November election. He said he would reinstate overtime hours, roll back service reductions, and halt the removal of mail-sorting machines and collection boxes. However, 95 percent of the mail sorting machines that were planned for removal had already been removed, and according to House Speaker Nancy Pelosi, DeJoy said he has no intention of replacing them or the mail collection boxes.\nOn December 27, 2020, the Consolidated Appropriations Act of 2021 forgave the previous $10 billion loan.\nCoronavirus pandemic and voting by mail.\nVoting by mail has become an increasingly common practice in the United States, with 25% of voters nationwide mailing their ballots in 2016 and 2018. The coronavirus pandemic of 2020 was predicted to cause a large increase in mail voting because of the possible danger of congregating at polling places. For the 2020 election, a state-by-state analysis concluded that 76% of Americans were eligible to vote by mail in 2020, a record number. The analysis predicted that 80 million ballots could be cast by mail in 2020 \u2013 more than double the number in 2016. The Postal Service sent letters to 46 states in July 2020, warning that the service might not be able to meet each state's deadlines for requesting and casting last-minute absentee ballots. The House of Representatives voted to include an emergency grant of $25 billion to the post office to facilitate the predicted flood of mail ballots, but the bill never reached the Senate floor for a vote.\nA March 2021 report from the Postal Service's inspector general found that the vast majority of mail-in ballots and registration materials in the 2020 election were delivered to the relevant authorities on time. The Postal Service handled approximately 135 million pieces of election-related mail between September 1 and November 3, delivering 97.9% of ballots from voters to election officials within three days, and 99.89% of ballots within seven days.\nCOVID-19 test kits to Americans.\nPostmaster General DeJoy helped the USPS deliver approximately 380 million home test kits from January 2022 through May 2022. As of March 2024, when the program concluded, the USPS had delivered over 1.8 billion free COVID-19 test kits.\nIn September 2024, the distribution of free at-home COVID-19 tests was re-started.\nDelivering for America reform plan.\nIn March 2021, the Postal Service launched a 10-year reform plan called Delivering for America, intended to improve the agency's financial stability, service reliability, and operational efficiency. The plan includes $40 billion in investments meant to improve USPS technology and facilities. In April 2022, the Postal Service Reform Act of 2022 was signed into law. It lifted financial burdens placed on the USPS by the 2006 Postal Accountability and Enhancement Act.\nAs part of Delivering for America, the Postal Service has introduced three new parcel shipping offerings: USPS Connect in June 2022, USPS Ground Advantage in July 2023, and Priority Next Day in March 2025. It has also installed 348 new package sorting machines within its facilities. As of September 2023, the Postal Service is able to process approximately 70 million packages per day, up from 53 million in 2021, and 60 million in 2022.\nThe USPS announced in July 2022 that it would be building 60 new regional processing and distribution centers in order to replace smaller, redundant facilities. One of the first of these facilities, a 700,000-square-foot building in Gastonia, North Carolina, opened in November 2023.\nIn an effort to stabilize its workforce, the Postal Service converted 150,000 of its pre-career workers into full-time employees between October 2020 and September 2023.\nDelivering for America has attempted to stabilize the Postal Service's finances by adjusting service times for mail and package delivery. In 2020, the Postal Regulatory Commission gave the Postal Service increased authority to raise postage rates in order to cover its operating costs. Between 2021 and 2023, USPS has raised the postage rate four times. In May 2023, USPS reported a $2.5 billion loss over the year's first quarter, with approximately $500 million of that figure related to costs within the agency's control. It also reported that its projected ten-year losses had been reduced from $160 billion to $70 billion.\nIn February 2025, the Postal Service announced new service standards for first-class mail, periodicals, marketing mail, and package services. These new standards, which include allowing postal workers to travel a greater distance for deliveries and replacing three-digit regional zip code add-ons with five-digit ones, are intended to improve delivery network reliability and save the agency approximately $36 billion between 2025 and 2035.\nGovernance and organization.\nThe Board of Governors of the United States Postal Service sets policy, procedure, and postal rates for services rendered. It has a similar role to a corporate board of directors. Of the eleven members of the Board, nine are appointed by the president and confirmed by the U.S. Senate (see \u00a0https://). The nine appointed members then select the United States postmaster general, who serves as the board's tenth member, and who oversees the day-to-day activities of the service as chief executive officer (see \u00a0https://\u2013https://). The ten-member board then nominates a deputy postmaster general, who acts as chief operating officer, to the eleventh and last remaining open seat.\nThe independent Postal Regulatory Commission (formerly the Postal Rate Commission) is also controlled by appointees of the president confirmed by the Senate. It oversees postal rates and related concerns, having the authority to approve or reject USPS proposals.\nThe USPS is often mistaken for a state-owned enterprise or government-owned corporation (e.g., Amtrak) because it operates much like a business. It is, however, an \"establishment of the executive branch of the Government of the United States\", (\u00a0https://) as it is controlled by presidential appointees and the postmaster general. As a government agency, it has many special privileges, including sovereign immunity, eminent domain powers, powers to negotiate postal treaties with foreign nations, and an exclusive legal right to deliver first-class and third-class mail. Indeed, in 2004, the U.S. Supreme Court ruled in a unanimous decision \"The Postal Service is not subject to antitrust liability. In both form and function, it is not a separate antitrust person from the United States but is part of the Government, and so is not controlled by the antitrust laws\" such as the Sherman Antitrust Act of 1890. Unlike a state-owned enterprise, the USPS lacks a transparent ownership structure and is not subject to standard rules and norms that apply to commercial entities. The USPS also lacks commercial discretion and control.\n\u00a0https:// creates a statutory monopoly on access to letter boxes by authorizing the federal government to impose fines against anyone who \"knowingly and willfully deposits any mailable matter\" in such letter boxes \"on which no postage has been paid\". The U.S. Supreme Court has upheld this monopoly against a First Amendment freedom of speech challenge; it thus remains illegal in the U.S. for anyone, other than the employees and agents of the USPS, to deliver mail pieces to letter boxes marked \"U.S. Mail\".\nThe Postal Service also has a Mailers' Technical Advisory Committee and local Postal Customer Councils, which are advisory and primarily involve business customers.\nThe USPS assigns city names to various postal addresses; these assignments do not always correspond with municipal boundaries. Mailing address names may stay the same even if city boundaries change.\nFunding and privatization proposals.\nSince the Postal Reorganization Act came into effect in 1971, the USPS has been mandated to be self-financing and rely solely on revenue from stamps and package deliveries to support itself. In 1982, postal stamps were changed to be categorized as products rather than a form of taxation, and since then, the Postal Service has no longer received taxpayer funding.\nSince the 1990s, Republicans have been discussing the idea of privatizing the U.S. Postal Service. In 2017, President Trump criticized the postal service's relationship with Amazon. Amazon maintains that the Postal Service makes a profit from their contract. Trump's administration proposed turning USPS into \"a private postal operator\" as part of a June 2018 governmental reorganization plan, although there was strong bipartisan opposition to the idea in Congress.\nUniversal service obligation and monopoly status.\nLegal basis and rationale.\nArticle I, section 8, Clause 7 of the U.S. Constitution grants Congress the power to establish post offices and post roads, which has been interpreted as a de facto Congressional monopoly over the delivery of first-class residential mail\u2014which has been defined as non-urgent residential letters (not packages). Accordingly, no other system for delivering first-class residential mail\u2014public or private\u2014has been tolerated, absent Congress's consent. The mission of the Postal Service is to provide the American public with trusted universal postal service. While not explicitly defined, the Postal Service's universal service obligation (USO) is broadly outlined in statute and includes multiple dimensions: geographic scope, range of products, access to services and facilities, delivery frequency, affordable and uniform pricing, service quality, and security of the mail. While other carriers may claim to voluntarily provide delivery on a broad basis, the Postal Service is the only carrier with a \"legal obligation\" to provide all the various aspects of universal service.\nProponents of universal service principles claim that since any obligation must be matched by the financial capability to meet that obligation, the postal monopoly was put in place as a funding mechanism for the USO, and it has been in place for over a hundred years. It consists of two parts: the Private Express Statutes (PES) and the mailbox access rule. The PES refer to the Postal Service's monopoly on the delivery of letters, and the mailbox rule refers to the Postal Service's exclusive access to customer mailboxes.\nProponents of universal service principles further claim that eliminating or reducing the PES or mailbox rule would affect the ability of the Postal Service to provide affordable universal service. If, for example, the PES and the mailbox rule were to be eliminated, and the USO maintained, then either billions of dollars in tax revenues or some other source of funding would have to be found.\nSome proponents of universal service principles suggest that private communications that are protected by the veil of government promote the exchange of free ideas and communications. This separates private communications from the ability of a private for-profit or non-profit organization to corrupt. Security for the individual is in this way protected by the United States Post Office, maintaining confidentiality and anonymity, as well as government employees being much less likely to be instructed by superiors to engage in nefarious spying. It is seen by some as a dangerous step to extract the universal service principle from the post office, as the untainted nature of private communications is preserved as assurance of the protection of individual freedom of privacy.\nHowever, as the recent notice of a termination of mail service to residents of the Frank Church\u2013River of No Return Wilderness indicates, mail service has been contracted to private firms such as Arnold Aviation for many decades. KTVB-TV reported:\n2008 report on universal postal service and the postal monopoly.\nThe Postal Act of 2006 required the Postal Regulatory Commission (PRC) to submit a report to the president and Congress on universal postal service and the postal monopoly in December 2008. The report must include any recommended changes. The Postal Service report supports the requirement that the PRC is to consult with and solicit written comments from the Postal Service. In addition, the Government Accountability Office was required to evaluate broader business model issues by 2011.\nOn October 15, 2008, the Postal Service submitted a report to the PRC on its position related to the Universal Service Obligation (USO). It said no changes to the USO and restriction on mailbox access were necessary at that time, but increased regulatory flexibility was required to ensure affordable universal service in the future.\nIn February 2013, the Postal Service announced that starting August 2013, Saturday delivery would be discontinued. Congress traditionally includes a provision in an annual continuing resolution that requires six-day delivery; it did so again in March 2013, and the Postal Service was forced to continue Saturday delivery.\nMonopoly and competition.\nDue to the postal monopoly, neither FedEx nor United Parcel Service (UPS) are allowed to deliver non-urgent letters, and may not directly ship to U.S. Mail boxes at residential and commercial destinations. However, both companies have transit agreements with the USPS in which an item can be dropped off with either FedEx or UPS who will then provide shipment up to the destination post office serving the intended recipient where it will be transferred for delivery to the U.S. Mail destination, including Post Office Box destinations. These services also deliver packages which are larger and heavier than USPS will accept. \nAlthough USPS and UPS are direct competitors, USPS contracts with UPS for air transport of 2\u20133 Day Priority Mail and Priority Mail Express (typically delivered overnight).\nLaw enforcement agencies.\nUnder the Mail Cover Program USPS photographs the front and back of every piece of U.S. mail as part of the sorting process, enabling law enforcement to obtain address information and images of the outsides of mail as part of an investigation without the need for a warrant.\nPostal Inspection Service.\nThe United States Postal Inspection Service (USPIS) is one of the oldest law enforcement agencies in the U.S. Founded by Benjamin Franklin on August 7, 1775, its mission is to protect the Postal Service, its employees, and its customers from crime and protect the nation's mail system from criminal misuse.\nPostal Inspectors enforce over 200 federal laws providing for the protection of mail in investigations of crimes that may adversely affect or fraudulently use the U.S. Mail, the postal system or postal employees.\nThe USPIS has the power to enforce the USPS monopoly by conducting search and seizure raids on entities they suspect of sending non-urgent mail through overnight delivery competitors. According to the American Enterprise Institute, a private conservative think tank, the USPIS raided Equifax offices in 1993 to ascertain if the mail they were sending through FedEx was truly \"extremely urgent\". It was found that the mail was not, and Equifax was fined $30,000.\nThe PIS oversees the activities of the Postal Police Force who patrol and secure major postal facilities in the United States.\nOffice of Inspector General.\nThe United States Postal Service Office of Inspector General (OIG) was authorized by law in 1996. Prior to the 1996 legislation, the Postal Inspection Service performed the duties of the OIG. The inspector general, who is independent of postal management, is appointed by and reports directly to the nine presidentially appointed, Senate\u2013confirmed members of the Board of Governors of the United States Postal Service. The OIG's primary purpose is to prevent, detect and report fraud, waste and program abuse, and promote efficiency. The OIG has \"oversight\" responsibility for all activities of the Postal Inspection Service.\nHow delivery services work.\nElements of addressing and preparing domestic mail.\nAll mailable articles (e.g., letters, flats, machinable parcels, irregular parcels, etc.) shipped within the United States must comply with an array of standards published in the USPS Domestic Mail Manual (DMM). Before addressing the mailpiece, one must first comply with the various mailability standards relating to attributes of the actual mailpiece such as: minimum/maximum dimensions and weight, acceptable mailing containers, proper mailpiece sealing/closure, utilization of various markings, and restrictions relating to various hazardous (e.g., explosives, flammables, etc.) and restricted (e.g., cigarettes, smokeless tobacco, etc.) materials, as well as others articulated in \u00a7\u00a0601 of the DMM.\nUndeliverable mail that cannot be readily returned, including mail without a return address, is treated as dead mail at the Mail Recovery Center in Atlanta, Georgia.\nThe USPS maintains a list of proper abbreviations.\nThe format of a return address is similar. Though some style manuals recommend using a comma between the city and state name when typesetting addresses in other contexts, for optimal automatic character recognition, the Post Office does not recommend this when addressing mail. The official recommendation is to use all upper case block letters with proper formats and abbreviations, and leave out all punctuation except for the hyphen in the ZIP+4 code. If the address is unusually formatted or illegible enough, it will require hand-processing, delaying that particular item. The USPS publishes the entirety of their postal addressing standards.\nPostal address verification tools and services are offered by the USPS and third-party companies to help ensure mail is deliverable by fixing formatting, appending information such as ZIP Code and validating the address is a valid delivery point. Customers can look up ZIP Codes and verify addresses using USPS Web Tools available on the official USPS website and Facebook page, as well as on third-party sites.\nDelivery Point Validation.\nDelivery Point Validation (DPV) provides the highest level of address accuracy checking. In a DPV process, the address is checked against the AMS data file to ensure that it exists as an active delivery point. The USPS provides DPV on their website as part of the ZIP Code Lookup tool; there are also companies that offer services to perform DPV in bulk.\nPaying postage.\nPostage can be paid via:\nAll unused U.S. postage stamps issued since 1861 are still valid as postage at their indicated value. Non-denominated stamps and those with values denominated by a letter are \"valid at the original prices of issue\". Additionally, \"Forever Stamps\" have been sold since 2007, which will always be valid for First-Class Mail up to , regardless of rate changes. In 2011, all first-class one ounce stamps, except for those sold in select coil sizes, \"became forever stamps\".\nThe cost of mailing a First-Class letter increased to 73 cents on July 14, 2024.\nPostage meters.\nA postage meter is a mechanical device used to create and apply physical evidence of postage (or franking) to mailed matter. Postage meters are regulated by a country's postal authority; for example, in the United States, the United States Postal Service specifies the rules for the creation, support, and use of postage meters. A postage meter imprints an amount of postage, functioning as a postage stamp, a cancellation and a dated postmark all in one. The meter stamp serves as proof of payment and eliminates the need for adhesive stamps.\nPC Postage.\nIn addition to using standard stamps, postage can now be printed in the form of an electronic stamp, or e-stamp, from a personal computer using a system called Information Based Indicia. This online PC Postage method relies upon application software on the customer's computer contacting a postal security device at the office of the postal service.\nInternational services.\nIn May 2007, the USPS restructured international service names to correspond with domestic shipping options. Formerly, USPS International services were categorized as Airmail (Letter Post), Economy (Surface) Parcel Post, Airmail Parcel Post, Global Priority, Global Express, and Global Express Guaranteed Mail. The former Airmail (Letter Post) is now First-Class Mail International, and includes small packages weighing up to . Economy Parcel Post was discontinued for international service, while Airmail Parcel Post was replaced by Priority Mail International. Priority Mail International Flat-Rate packaging in various sizes was introduced, with the same conditions of service previously used for Global Priority. Global Express is now Express Mail International, while Global Express Guaranteed was unchanged. All international package services come with USPS tracking up until the point it leaves the US, with further tracking availability dependent on the destination country. First-Class Mail letters and flats are not trackable. On September 29th, 2024, Global Express Guaranteed service was suspended to all destinations.\nOne of the major changes in the updated naming and services definitions is that USPS-supplied mailing boxes for Priority and Express mail are allowed for international use. These services are offered to ship letters and packages to almost every country and territory on the globe. The USPS contracts with various commercial and freight airlines to transport mail and packages to their destination. The Fly America act of 1974 mandates that the postal service must use a US Flag Carrier whenever one is available, regardless of cost. Exceptions apply for destinations not served by US carriers.\nThe USPS provides an &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;M-bag service for international shipment of printed matter; previously surface M-bags existed, but with the 2007 elimination of surface mail, only airmail M-bags remain. The term \"M-bag\" is not expanded in USPS publications; M-bags are simply defined as \"direct sacks of printed matter ... sent to a single foreign addressee at a single address\"; however, the term is sometimes referred to informally as \"media bag\", as the bag can also contain \"discs, tapes, and cassettes\", in addition to books, for which the usual umbrella term is \"media\"; some also refer to them as \"mail bags\".\nThe Department of Defense and the USPS jointly operate a postal system to deliver mail for the military; this is known as the Army Post Office (for Army and Air Force postal facilities) and the Fleet Post Office (for Navy, Marine Corps, and Coast Guard postal facilities). Military mail is billed at domestic rates when being sent from the United States to a military outpost, and is free when sent by deployed military personnel. The overseas logistics are handled by the Military Postal Service Agency in the Department of Defense. Outside of forward areas and active operations, military mail service speeds vary greatly based on location. First-Class takes 7\u201318 days, Priority 7-18 days, Parcel Select and Media Mail 18-45 days, and Priority Mail Express military takes 3 days, though it is only available to select European, North American, and Pacific posts.\nThree independent countries with a Compact of Free Association with the U.S. (Palau, the Marshall Islands, and the Federated States of Micronesia) have a special relationship with the United States Postal Service:\nSorting and delivery process.\nProcessing of standard sized envelopes and cards is highly automated, including reading of handwritten addresses. Mail from individual customers and public USPS mailboxes is collected by letter carriers into plastic tubs, which are taken to one of approximately 251 Processing and Distribution Centers (P&amp;DCs) across the United States. Each P&amp;DC sorts mail for a given region (typically with a radius of around ) and connects with the national network for interregional mail.\nSince the late 20th century, the USPS has been reducing point-to-point links in favor of a spoke-hub distribution paradigm, with sorting work tightly concentrated at the hubs. During the 2010s, the USPS consolidated mail sorting for large regions into the P&amp;DCs on the basis that most mail is addressed to faraway destinations, but for cities at the edge of a P&amp;DC's region, this means all locally addressed mail must travel long distances (that is, to and from the P&amp;DC for sorting) to reach nearby addresses.\nAt the P&amp;DC, mail is emptied into hampers which are automatically dumped into a Dual Pass Rough Cull System (DPRCS). As mail travels through the DPRCS, large items, such as packages and mail bundles, are removed from the stream. As the remaining mail enters the first machine for processing standard mail, the Advanced Facer-Canceler System (AFCS), pieces that passed through the DPRCS but do not conform to physical dimensions for processing in the AFCS (e.g., large envelopes or overstuffed standard envelopes) are automatically diverted from the stream. Mail removed from the DPRCS and AFCS is manually processed or sent to parcel sorting machines.\nIn contrast to the previous system, which canceled and postmarked the upper right corner of the envelope, thereby missing any stamps which were inappropriately placed, the AFCS locates indicia (stamp or metered postage mark) regardless of the orientation of the mailpiece as it enters the machine, and cancels it by applying a postmark. Detection of indicia enables the AFCS to determine the orientation of each mailpiece and sort it accordingly. The AFCS rotates and flips over mailpieces as needed, so all mail is sorted right-side up and faced in the same direction in each output bin.\nMail is sorted by the AFCS into three categories: mail already affixed with a bar code and addressed (such as business reply envelopes and cards); mail with machine printed (typed) addresses; and mail with handwritten addresses.\nMail with typed addresses goes to a Multiline Optical Character Reader (MLOCR) which reads the ZIP Code and address information and prints the appropriate bar code onto the envelope (formerly POSTNET, later Intelligent Mail). Mail with handwritten addresses and illegible typed addresses is diverted from the mailstream to the Remote Bar Coding System (RBCS). Images of such mailpieces are transmitted through RBCS to the Remote Encoding Center, where humans (data entry clerks) read each image and type in the most likely address. Each mailpiece held for RBCS processing is sprayed with an ID Tag, a fluorescent bar code. When address data comes back from the Remote Encoding Center, RBCS uses the ID Tag bar code to identify the corresponding mailpiece and prints the appropriate bar code, then returns the mailpiece to the mailstream.\nProcessed mail is imaged by the Mail Isolation Control and Tracking (MICT) system to allow easier tracking of hazardous substances. Images are taken at more than 200 mail processing centers, and are destroyed after being retained for 30 days.\nIf a customer has filed a change of address card and his or her mail is detected in the mailstream with the old address, the mailpiece is sent to a machine that automatically connects to a Computerized Forwarding System database to determine the new address. If this address is found, the machine will paste a label over the former address with the current address and the appropriate bar code. The mail is returned to the mailstream to be forwarded to the addressee's new location.\nMail with addresses that cannot be read and bar coded by any of the foregoing automated systems is separated for human intervention. Local postal workers can read the address and manually code and sort mail according to the ZIP Code on the article. If the address still cannot be read, mail is either returned to the sender (First-Class Mail with a valid return address) or is sent to the Mail Recovery Center in Atlanta, Georgia (formerly known as the dead letter office). At this office, the mail is opened to try to find an address to forward to. If an address is found, the contents are resealed and delivered. Otherwise, the items are held for 90 days in case of inquiry by the customer; if they are not claimed, they are either destroyed or auctioned off at the monthly Postal Service Unclaimed Parcel auction to raise money for the service.\nOnce the mail is bar coded, it is automatically sorted by a Delivery Bar Code Sorter (DBCS) that reads the bar code, identifies the destination of the mailpiece, and sends it to an appropriate tray that corresponds to the next segment of its journey.\nThere are necessarily two P&amp;DCs for every domestic mailpiece which correspond to the regions in which the sender and recipient are located. The USPS calls these, respectively, the origin and destination P&amp;DCs. Mail for which they are the same (because the senders are located in the same region as the recipients) is either trucked to the appropriate local post office, or kept in the building for carrier routes served directly from the P&amp;DC itself. Out-of-region mail is trucked to the closest airport and then flown, usually as baggage on commercial airlines, to the airport nearest the destination station. At the destination P&amp;DC, mail is again read by a DBCS which sorts items to local post offices; this includes grouping mailpieces by individual letter-carrier route.\nAt the carrier route level, 95% of letters arrive pre-sorted; the remaining mail must be sorted by hand. In 2009, the Post Office was working to increase the percentage of automatically sorted mail, including a pilot program to sort \"flats\".\nUPS is the primary air transport supplier to USPS for Priority and Express Mail. Priority Mail and Express Mail are transported from origin processing centers to the closest UPS-served airport, where they are handed off to UPS. UPS then flies them to the destination airport and hands them back to USPS for transport to the local post office and delivery.\nAfter consolidating sorting work into the P&amp;DCs, the USPS in August 2022 initiated a pilot program to consolidate delivery work into Sorting and Delivery Centers (S&amp;DCs). As of 2022, the USPS was still running \"delivery units\" out of most of its post offices, meaning that most carrier routes were based at post offices and there were dozens of delivery units in each metropolitan area. The USPS planned to merge many delivery units in each metropolitan area into S&amp;DCs, which implied that many letter carriers would have to endure longer commutes to S&amp;DCs and drive longer delivery routes, while many post offices would be reduced to retail stores with no back-end mail processing capability on site. However, the USPS hoped to save money on the trucking fleet moving mail between its facilities. A 2023 audit by the USPS inspector general found that the facilities selected to serve as the initial S&amp;DCs were operating smoothly and functioning as expected, but criticized the USPS for immediately consolidating workers into the S&amp;DCs before they had been upgraded with adequate amenities like restrooms, break rooms, and locker rooms appropriately sized for such large numbers of employees.\nTypes of postal facilities.\nAlthough its retail postal facilities are called post offices in regular speech, the USPS recognizes several types of postal facilities, including the following:\nWhile common usage refers to all types of postal facilities as \"substations\", the USPS Glossary of Postal Terms does not define or even list that word. Post Offices often share facilities with other governmental organizations located within a city's central business district. In those locations, often courthouses and federal buildings, the building is owned by the General Services Administration while the U.S. Postal Services operates as a tenant. The USPS retail system has approximately 36,000 post offices, stations, and branches.\nSelf-Service Kiosks.\nIn 2004, the USPS began deploying Automated Postal Centers (APCs) at USPS locations. In the early 2010s, the USPS renamed APCs to Self-Service Kiosks (SSKs). Self-Service Kiosks are automated and are able to weigh and mail parcels, letters and flats, renew postal office boxes, and print postage.\nEvolutionary Network Development (END) program.\nIn February 2006, the USPS announced that they plan to replace the nine existing facility-types with five processing facility-types:\nOver a period of years, these facilities are expected to replace Processing &amp; Distribution Centers, Customer Service Facilities, Bulk Mail Centers, Logistic and Distribution Centers, annexes, the Hub and Spoke Program, Air Mail Centers, and International Service Centers.\nThe changes are a result of the declining volumes of single-piece First-Class Mail, population shifts, the increase in drop shipments by advertising mailers at destinating postal facilities, advancements in equipment and technology, redundancies in the existing network, and the need for operational flexibility.\nThe program was ended in early 2007 after an analysis revealed that the significant amount of capital investment required to implement the END network concept would not generate the benefits originally anticipated.\nAirline and rail division.\nThe United States Postal Service does not directly own or operate any aircraft or trains, although both were formerly operated. The mail and packages are flown on airlines with which the Postal Service has a contractual agreement. The contracts change periodically. Contract airlines have included: UPS, FedEx Express, American Airlines, United Airlines, Delta Air Lines, Kalitta Air, AmeriJet, Amazon, Northern Air Cargo, and others.\nThe last air delivery route in the continental U.S., to residents in the Frank Church\u2013River of No Return Wilderness, was scheduled to be ended in June 2009. The weekly bush plane route, contracted out to an air taxi company, had in its final year an annual cost of $46,000, or $2400/year per residence, over ten times the average cost of delivering mail to a residence in the United States. This decision has been reversed by the U.S. postmaster general.\nParcel forwarding and private interchange.\nPrivate US parcel forwarding or US mail forwarding companies focusing on personal shopper, relocation, Ex-pat and mail box services often interface with the United States Postal Service for transporting of mail and packages for their customers.\nDelivery timing.\nDelivery days.\nFrom 1810, mail was delivered seven days a week. In 1828, local religious leaders noticed a decline in Sunday-morning church attendance because of local post offices' doubling as gathering places. These leaders appealed to the government to intervene and close post offices on Sundays. The government, however, declined, and mail was delivered seven days a week until 1912. Since then, U.S. Mail (with the exception of Express Mail) has not been delivered on Sunday.\nSaturday delivery was temporarily suspended in April 1957, because of lack of funds, but quickly restored.\nBudget problems prompted consideration of dropping Saturday delivery starting around 2009. This culminated in a 2013 announcement that regular mail services would be cut to five days a week, which was reversed by Congress before it could take effect. (See the section Revenue decline and planned cuts.)\nDirect delivery vs. customer pickup.\nOriginally, mail was not delivered to homes and businesses, but to post offices. In 1863, \"city delivery\" began in urban areas with enough customers to make this economical. This required streets to be named, houses to be numbered, with sidewalks and lighting provided, and these street addresses to be added to envelopes. The number of routes served expanded over time. In 1891, the first experiments with Rural Free Delivery began in less densely populated areas.\nTo compensate for high mail volume and slow long-distance transportation which saw mail arrive at post offices throughout the day, deliveries were made multiple times a day. This ranged from twice for residential areas to up to seven times for the central business district of Brooklyn, New York. In the late 19th century, mail boxes were encouraged, saving carriers the time it took to deliver directly to the addressee in person. During the 1910s and 1920s, they were phased in as a requirement for service. In the 1940s, multiple daily deliveries began to be reduced, especially on Saturdays. By 1990, the last twice-daily deliveries in New York City were eliminated.\nSince then, mail is delivered once a day to most private homes and businesses. The USPS still distinguishes between city delivery (where carriers generally walk and deliver to mailboxes hung on exterior walls or porches, or to commercial reception areas) and rural delivery (where carriers generally drive). With \"curbside delivery\", mailboxes are at the ends of driveways, on the nearest convenient road. \"Central point delivery\" is used in some locations, where several nearby residences share a \"cluster\" of individual mailboxes in a single housing.\nSome customers choose to use post office boxes for an additional fee, for privacy or convenience. This provides a locked box at the post office to which mail is addressed and delivered (usually earlier in the day than home delivery). Customers in less densely populated areas where there is no city delivery and who do not qualify for rural delivery may receive mail only through post office boxes. High-volume business customers can also arrange for special pick-up.\nAnother option is the old-style general delivery, for people who have neither post office boxes nor street addresses. Mail is held at the post office until they present identification and pick it up.\nSome customers receive free post office boxes if the USPS declines to provide door-to-door delivery to their location or a nearby box. People with medical problems can request door-to-door delivery. Homeless people are also eligible for post office boxes at the discretion of the local postmaster, or can use general delivery.\nSpecial delivery.\nFrom 1885 to 1997, a service called special delivery was available, which caused a separate delivery to the final location earlier in the day than the usual daily rounds.\nSame-day trials.\nIn December 2012, the USPS began a limited one-year trial of same-day deliveries directly from retailers or distribution hubs to residential addresses in the same local area, a service it dubbed \"Metro Post\". The trial was initially limited to San Francisco and the only retailer to participate in the first few weeks was 1-800-FLOWERS.\nIn November 2013, the Postal Service began regular package delivery on Sundays for Amazon customers in New York and Los Angeles, which it expanded to 15 cities in May 2014. Amazon Sunday delivery has been expanded to most major markets as of September 2015.\nForwarding and holds.\nResidential customers can fill out a form in-person or online to forward mail to a new address, and can also send pre-printed forms to any of their frequent correspondents. They must have a valid address to forward their mail from \"and\" to, and verify their identity. They can also put their mail on \"hold\", for example, while on vacation. The Post Office will store mail during the hold, instead of letting it overflow in the mailbox. These services are not available to large buildings and customers of a commercial mail receiving agency, where mail is subsorted by non-Post Office employees into individual mailboxes.\nFirst-class packages.\nIn April 2022, the USPS announced it would slow deliveries of almost one third of first-class packages as it sought to rely less on air transportation and find cost savings. In July 2023, USPS eliminated First-Class package service and replaced it with USPS Ground Advantage. USPS also greatly reduced the use of air transportation for First Class Mail letters and flats. \nFinancial services.\nPostal money orders provide a safe alternative to sending cash through the mail, and are available in any amount up to $1,000. Like a bank check, money orders are cashable only by the recipient. Unlike a personal bank check, they are prepaid and therefore cannot be returned because of insufficient funds. Money orders are a declining business for the USPS, as companies like PayPal, Venmo and others are offering electronic replacements.\nFrom 1911 to 1967, the Postal Service also operated the United States Postal Savings System, not unlike a savings and loan association with the amount of the deposit limited.\nA January 2014 report by the inspector general of the USPS suggested that the agency could earn $8.9\u00a0billion per year in revenue by providing financial services, especially in areas where there are no local banks but there is a local post office, and to customers who currently do not have bank accounts.\nEmployment.\nThe Postal Service is the nation's second-largest civilian employer. As of 2023, it employed 525,469 career employees and 115,000 non-career personnel, divided among offices, processing centers, and actual post offices. The United States Postal Service would rank 43rd on the 2021 \"Fortune\" 500 list, if it was a private company and ranks 136 on Global Fortune 500 list.\nA major round of job cuts, early retirements, and a construction freeze were announced on March 20, 2009.\nWorkplace violence.\nIn the early 1990s, widely publicized workplace shootings by disgruntled employees at USPS facilities led to a Human Resource effort to provide care for stressed workers and resources for coworker conflicts. Due to media coverage, postal employees gained a reputation among the general public as more likely to be mentally ill. The USPS Commission on a Safe and Secure Workplace found that \"Postal workers are only a third as likely as those in the national workforce to be victims of homicide at work.\" In the documentary \"Murder by Proxy: How America Went Postal\", it was argued that this number failed to factor out workers killed by external subjects rather than by fellow employees.\nThis series of events in turn has influenced American culture, as seen in the slang term \"going postal\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50592", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=50592", "title": "Hyperlexia", "text": "Significantly advanced reading ability in children\nHyperlexia is a syndrome characterized by a child's precocious ability to read. It was initially identified by Norman E. Silberberg and Margaret C. Silberberg (1967), who defined it as the precocious ability to read words without prior training in learning to read, typically before the age of five. They indicated that children with hyperlexia have a significantly higher word-decoding ability than their reading comprehension levels. Children with hyperlexia also present with an intense fascination for written material at a very early age.\nHyperlexic children are characterized by word-reading ability well above what would be expected given their age. First named and scientifically described in 1967, it can be viewed as an ability in which word recognition ability goes far above expected levels of skill. Some hyperlexics, however, have trouble understanding speech. Some experts believe that most children with hyperlexia, or perhaps even all of them, are autistic. However, one expert, Darold Treffert, proposes that hyperlexia has subtypes, only some of which overlap with autism. Between five and twenty percent of autistic children have been estimated to be hyperlexic.\nHyperlexic children are often fascinated by letters or numbers. They are extremely good at decoding language and thus often become very early readers. Some English-speaking hyperlexic children learn to spell long words (such as \"elephant\") before they are two years old and learn to read whole sentences before they turn three.\nEtymology.\nThe word \"hyperlexia\" is derived from the Greek terms 'over, beyond, overmuch, above measure' and 'word'.\nDevelopment.\nAlthough hyperlexic children usually learn to read in a non-communicative way, several studies have shown that they can acquire reading comprehension and communicative language after the onset of hyperlexia. They follow a different developmental trajectory relative to neurotypical individuals, with milestones being acquired in a different order. Despite hyperlexic children's precocious reading ability, they may struggle to communicate. Often, hyperlexic children will have a precocious ability to read but will learn to speak only by rote and heavy repetition, and may also have difficulty learning the rules of language from examples or from trial and error, which may result in social problems. Their language may develop using echolalia, often repeating words and sentences. Often, the child has a large vocabulary and can identify many objects and pictures, but cannot put their language skills to good use. Spontaneous language is lacking and their pragmatic speech is delayed. Hyperlexic children often struggle with Who? What? Where? Why? and How? questions. Between the ages of four and five years old, many children make great strides in communicating.\nA 2018 review stated that \"despite good decoding and verbal short-term memory skills, individuals with hyperlexia exhibit poor listening, verbal working memory, and reading comprehension skills.\"\nThe social skills of a child with hyperlexia often lag tremendously. Hyperlexic children often have far less interest in playing with other children than do their peers.\nTypes of hyperlexia.\nIn one paper, Darold Treffert proposes three types of hyperlexia. Specifically:\nA different paper by Rebecca Williamson Brown, OD proposes only two types of hyperlexia. These are:\nNon-English studies.\nIn studies in Cantonese and Korean, subjects were able to read non-words in their native orthography without a delay relative to the speed with which they read real words in their native orthography. There is a delay noted with exception words in English, including the examples \"chaos\", \"unique\", and \"enough\". These studies also illustrate difficulties in understanding what it is that they are reading. The findings suggest that non-hyperlexic readers rely more heavily on word semantics in order to make inferences about word meaning.\nThe Cantonese study distinguish homographs and determine the readings for rarely used characters. In this study, the subject also made errors of phonetic analogy and regularization of sound. The authors of the study suggest that the two-routes model for reading Chinese characters may be in effect for hyperlexics. The two-routes model describes understanding of Chinese characters in a purely phonetic sense and the understanding of Chinese characters in a semantic sense.\nThe semantics deficit is also illustrated in the study of Korean hyperlexics through a priming experiment. Non-hyperlexic children read words primed with a related image faster than non-primed words while hyperlexics read them at the same pace. Lee Sunghee and Hwang Mina, the authors of the Korean study, also found that hyperlexics have fewer errors in non-word reading than non-hyperlexics. They suggest that this may be because of an imbalance in the phonological, orthographical, and semantic understandings of the subjects' native language and writing system, in this case, Hangul. This combination of the parts of linguistics is known as connectionism, in which non-words are distinguished from words by differences in interaction between phonology, orthography, and semantics.\nIn the Lee and Hwang study, the subjects scored lower on general language test and vocabulary tests than the average for their age groups. Literacy education in South Korea involves teaching students entire words, rather than starting with the relationship between phonemes and letters in Hangul, despite evidence that letter name knowledge is useful for learning to read words that have not been taught. The results suggest that hyperlexics are able to obtain the relations between letters (or the smallest unit of the writing system) and their phonemes without knowing the names.\nComprehension difficulties can also be a result of hyperlexia. Semantics and comprehension both have ties to meaning. Semantics relates to the meaning of a certain word while comprehension is the understanding of a longer text. In both studies, interpretation-based and meaning-based tests proved difficult for the hyperlexic subjects. In the Weeks study, the subject was unable to identify characters based on the logographic aspect of the writing system, and in the Lee and Hwang study, priming was ineffective in decreasing reading times for hyperlexics.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50593", "revid": "44106950", "url": "https://en.wikipedia.org/wiki?curid=50593", "title": "BNF", "text": "BNF may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "50595", "revid": "11555324", "url": "https://en.wikipedia.org/wiki?curid=50595", "title": "Flash memory", "text": "Electronic non-volatile computer storage device\nFlash memory is an electronic non-volatile computer memory storage medium that can be electrically erased and reprogrammed. The two main types of flash memory, NOR flash and NAND flash, are named for the NOR and NAND logic gates. Both use the same cell design, consisting of floating-gate MOSFETs. They differ at the circuit level, depending on whether the state of the bit line or word lines is pulled high or low; in NAND flash, the relationship between the bit line and the word lines resembles a NAND gate; in NOR flash, it resembles a NOR gate.\nFlash memory, a type of floating-gate memory, was invented by Fujio Masuoka at Toshiba in 1980 and is based on EEPROM technology. Toshiba began marketing flash memory in 1987. EPROMs had to be erased completely before they could be rewritten. NAND flash memory, however, may be erased, written, and read in blocks (or pages), which generally are much smaller than the entire device. NOR flash memory allows a single machine word to be written\u00a0\u2013 to an erased location\u00a0\u2013 or read independently. A flash memory device typically consists of one or more flash memory chips (each holding many flash memory cells), along with a separate flash memory controller chip.\nThe NAND type is found mainly in memory cards, USB flash drives, solid-state drives (those produced since 2009), feature phones, smartphones, and similar products, for general storage and transfer of data. NAND or NOR flash memory is also often used to store configuration data in digital products, a task previously made possible by EEPROM or battery-powered static RAM. A key disadvantage of flash memory is that it can endure only a relatively small number of write cycles in a specific block.\nNOR flash is known for its direct random access capabilities, making it apt for executing code directly. Its architecture allows for individual byte access, facilitating faster read speeds compared to NAND flash. NAND flash memory operates with a different architecture, relying on a serial access approach. This makes NAND suitable for high-density data storage, but less efficient for random access tasks. NAND flash is often employed in scenarios where cost-effective, high-capacity storage is crucial, such as in USB drives, memory cards, and solid-state drives (SSDs).\nThe primary differentiator lies in their use cases and internal structures. NOR flash is optimal for applications requiring quick access to individual bytes, as in embedded systems for program execution. NAND flash, on the other hand, shines in scenarios demanding cost-effective, high-capacity storage with sequential data access.\nFlash memory is used in computers, PDAs, digital audio players, digital cameras, mobile phones, synthesizers, video games, scientific instrumentation, industrial robotics, and medical electronics. Flash memory has a fast read access time but is not as fast as static RAM or ROM. In portable devices, it is preferred to use flash memory because of its mechanical shock resistance, since mechanical drives are more prone to mechanical damage.\nBecause erase cycles are slow, the large block sizes used in flash memory erasing give it a significant speed advantage over non-flash EEPROM when writing large amounts of data. As of 2019,[ [update]] flash memory costs much less than byte-programmable EEPROM and has become the dominant memory type wherever a system required a significant amount of non-volatile solid-state storage. EEPROMs, however, are still used in applications that require only small amounts of storage, e.g. in SPD implementations on computer-memory modules.\nFlash memory packages can use die stacking with through-silicon vias and several dozen layers of 3D TLC NAND cells (per die) simultaneously to achieve capacities of up to 1 tebibyte per package using 16 stacked dies and an integrated flash controller as a separate die inside the package.\nHistory.\nBackground.\nThe origins of flash memory can be traced to the development of the floating-gate MOSFET (FGMOS), also known as the floating-gate transistor. The original MOSFET was invented at Bell Labs between 1959 and 1960. Dawon Kahng went on to develop a variation, the floating-gate MOSFET, with Taiwanese-American engineer Simon Min Sze at Bell Labs in 1967. They proposed that it could be used as floating-gate memory cells for storing a form of programmable read-only memory (PROM) that is both non-volatile and re-programmable.\nEarly types of floating-gate memory included EPROM (erasable PROM) and EEPROM (electrically erasable PROM) in the 1970s. However, early floating-gate memory required engineers to build a memory cell for each bit of data, which proved to be cumbersome, slow, and expensive, restricting floating-gate memory to niche applications in the 1970s, such as military equipment and the earliest experimental mobile phones.\nModern EEPROM based on Fowler-Nordheim tunnelling to erase data was invented by Bernward and patented by Siemens in 1974. It was further developed between 1976 and 1978 by Eliyahou Harari at Hughes Aircraft Company, as well as by George Perlegos and others at Intel.\nInvention and commercialization.\nFujio Masuoka invented flash memory at Toshiba in 1980. The improvement between EEPROM and flash is that flash is programmed in blocks while EEPROM is programmed in bytes. According to Toshiba, the name \"flash\" was suggested by Masuoka's colleague, Sh\u014dji Ariizumi, because the erasure process of the memory contents reminded him of the flash of a camera. Masuoka and colleagues presented the invention of NOR flash in 1984, and then NAND flash at the \"IEEE 1987 International Electron Devices Meeting\" (IEDM) held in San Francisco.\nToshiba commercially launched NAND flash memory in 1987. Intel Corporation introduced the first commercial NOR type flash chip in 1988. NOR-based flash has long erase and write times, but provides full address and data buses, allowing random access to any memory location. This makes it a suitable replacement for older read-only memory (ROM) chips, which are used to store program code that rarely needs to be updated, such as a computer's BIOS or the firmware of set-top boxes. Its endurance may be from as little as 100 erase cycles for an on-chip flash memory, to a more typical 10,000 or 100,000 erase cycles, up to 1,000,000 erase cycles. NOR-based flash was the basis of early flash-based removable media; CompactFlash was originally based on it, although later cards moved to less expensive NAND\u00a0flash.\nNAND flash has reduced erase and write times, and requires less chip area per cell, thus allowing greater storage density and lower cost per bit than NOR\u00a0flash. However, the I/O interface of NAND\u00a0flash does not provide a random-access external address bus. Rather, data must be read on a block-wise basis, with typical block sizes of hundreds to thousands of bits. This makes NAND\u00a0flash unsuitable as a drop-in replacement for program ROM, since most microprocessors and microcontrollers require byte-level random access. In this regard, NAND\u00a0flash is similar to other secondary data storage devices, such as hard disks and optical media, and is thus highly suitable for use in mass-storage devices, such as memory cards and solid-state drives (SSD). For example, SSDs store data using multiple NAND flash memory chips.\nThe first NAND-based removable memory card format was SmartMedia, released in 1995. Many others followed, including MultiMediaCard, Secure Digital, Memory Stick, and xD-Picture Card.\nLater developments.\nA new generation of memory card formats, including RS-MMC, miniSD and microSD, feature extremely small form factors. For example, the microSD card has an area of just over 1.5\u00a0cm2, with a thickness of less than 1\u00a0mm.\nNAND flash has achieved significant levels of memory density as a result of several major technologies that were commercialized during the late 2000s to early 2010s.\nNOR flash was the most common type of Flash memory sold until 2005, when NAND flash overtook NOR flash in sales.\nMulti-level cell (MLC) technology stores more than one bit in each memory cell. NEC demonstrated multi-level cell (MLC) technology in 1998, with an 80Mb flash memory chip storing 2 bits per cell. STMicroelectronics also demonstrated MLC in 2000, with a 64MB NOR flash memory chip. In 2009, Toshiba and SanDisk introduced NAND flash chips with QLC technology storing 4 bits per cell and holding a capacity of 64Gb. Samsung Electronics introduced triple-level cell (TLC) technology storing 3-bits per cell, and began mass-producing NAND chips with TLC technology in 2010.\nCharge trap flash.\nCharge trap flash (CTF) technology replaces the polysilicon floating gate, which is sandwiched between a blocking gate oxide above and a tunneling oxide below it, with an electrically insulating silicon nitride layer; the silicon nitride layer traps electrons. In theory, CTF is less prone to electron leakage, providing improved data retention.\nBecause CTF replaces the polysilicon with an electrically insulating nitride, it allows for smaller cells and higher endurance (lower degradation or wear). However, electrons can become trapped and accumulate in the nitride, leading to degradation. Leakage is exacerbated at high temperatures since electrons become more excited with increasing temperatures. CTF technology, however, still uses a tunneling oxide and blocking layer, which are the weak points of the technology, since they can still be damaged in the usual ways (the tunnel oxide can be degraded due to extremely high electric fields and the blocking layer due to Anode Hot Hole Injection (AHHI).\nDegradation or wear of the oxides is the reason why flash memory has limited endurance. Data retention goes down (the potential for data loss increases) with increasing degradation, since the oxides lose their electrically-insulating characteristics as they degrade. The oxides must insulate against electrons to prevent them from leaking, which would cause data loss.\nIn 1991, NEC researchers, including N. Kodama, K. Oyama and Hiroki Shirai, described a type of flash memory with a charge-trap method. In 1998, Boaz Eitan of Saifun Semiconductors (later acquired by Spansion) patented a flash memory technology named NROM that took advantage of a charge trapping layer to replace the conventional floating gate used in conventional flash memory designs. In 2000, an Advanced Micro Devices (AMD) research team led by Richard M. Fastow, Egyptian engineer Khaled Z. Ahmed and Jordanian engineer Sameer Haddad (who later joined Spansion) demonstrated a charge-trapping mechanism for NOR flash memory cells. CTF was later commercialized by AMD and Fujitsu in 2002. 3D V-NAND (vertical NAND) technology stacks NAND flash memory cells vertically within a chip using 3D charge trap flash (CTP) technology. 3D V-NAND technology was first announced by Toshiba in 2007, and the first device, with 24 layers, was commercialized by Samsung Electronics in 2013.\n3D integrated circuit technology.\n3D integrated circuit (3D IC) technology stacks integrated circuit (IC) chips vertically into a single 3D IC package. Toshiba introduced 3D IC technology to NAND flash memory in April 2007, when they debuted a 16GB eMMC compliant (product number THGAM0G7D8DBAI6, often abbreviated THGAM on consumer websites) embedded NAND flash memory package, which was manufactured with eight stacked 2GB NAND flash chips. In September 2007, Hynix Semiconductor (now SK Hynix) introduced 24-layer 3D IC technology, with a 16GB flash memory package that was manufactured with 24 stacked NAND flash chips using a wafer bonding process. Toshiba also used an eight-layer 3D IC for their 32GB THGBM flash package and in 2008. In 2010, Toshiba used a 16-layer 3D IC for their 128GB THGBM2 flash package, which was manufactured with 16 stacked 8GB chips. In the 2010s, 3D ICs came into widespread commercial use for NAND flash memory in mobile devices.\nIn 2016, Micron and Intel introduced a technology known as CMOS Under the Array/CMOS Under Array (CUA), Core over Periphery (COP), Periphery Under Cell (PUA), or Xtacking, in which the control circuitry for the flash memory is placed under or above the flash memory cell array. This has allowed for an increase in the number of planes or sections a flash memory chip has, increasing from two planes to four, without increasing the area dedicated to the control or periphery circuitry. This increases the number of IO operations per flash chip or die, but it also introduces challenges when building capacitors for charge pumps used to write to the flash memory. Some flash dies have as many as 6 planes.\nAs of August 2017, microSD cards with a capacity up to 400 GB (400 billion bytes) were available. Samsung combined 3D IC chip stacking with its 3D V-NAND and TLC technologies to manufacture its 512GB KLUFG8R1EM flash memory package with eight stacked 64-layer V-NAND chips. In 2019, Samsung produced a 1024GB flash package, with eight stacked 96-layer V-NAND package and with QLC technology.\nIn 2025, researchers announced experimental success with a device a 400-picosecond write time.\nPrinciples of operation.\nFlash memory stores information in an array of memory cells made from floating-gate transistors. In single-level cell (SLC) devices, each cell stores only one bit of information. Multi-level cell (MLC) devices, including triple-level cell (TLC) devices, can store more than one bit per cell.\nThe floating gate may be conductive (typically polysilicon in most kinds of flash memory) or non-conductive (as in SONOS flash memory).\nFloating-gate MOSFET.\nIn flash memory, each memory cell resembles a standard metal\u2013oxide\u2013semiconductor field-effect transistor (MOSFET) except that the transistor has two gates instead of one. The cells can be seen as an electrical switch in which current flows between two terminals (source and drain) and is controlled by a floating gate (FG) and a control gate (CG). The CG is similar to the gate in other MOS transistors, but below this is the FG, which is insulated all around by an oxide layer. The FG is interposed between the CG and the MOSFET channel. Because the FG is electrically isolated by its insulating layer, electrons placed on it are trapped. When the FG is charged with electrons, this charge screens the electric field from the CG, thus increasing the threshold voltage (VT) of the cell. This means that the VT of the cell can be changed between the \"uncharged FG threshold voltage\" (VT1) and the higher \"charged FG threshold voltage\" (VT2) by changing the FG charge. In order to read a value from the cell, an intermediate voltage (VI) between VT1 and VT2 is applied to the CG. If the channel conducts at VI, the FG must be uncharged (if it were charged, there would not be conduction because VI is less than VT2). If the channel does not conduct at the VI, it indicates that the FG is charged. The binary value of the cell is sensed by determining whether there is current flowing through the transistor when VI is asserted on the CG. In a multi-level cell device, which stores more than one bit per cell, the amount of current flow is sensed (rather than simply its presence or absence), in order to determine more precisely the level of charge on the FG.\nFloating gate MOSFETs are so named because there is an electrically insulating tunnel oxide layer between the floating gate and the silicon, so the gate \"floats\" above the silicon. The oxide keeps the electrons confined to the floating gate. Degradation or wear (and the limited endurance of floating gate Flash memory) occurs due to the extremely high electric field (10 million volts per centimeter) experienced by the oxide. Such high voltage densities can break atomic bonds over time in the relatively thin oxide, gradually degrading its electrically insulating properties and allowing electrons to be trapped in and pass through freely (leak) from the floating gate into the oxide, increasing the likelihood of data loss since the electrons (the quantity of which is used to represent different charge levels, each assigned to a different combination of bits in MLC Flash) are normally in the floating gate. This is why data retention goes down and the risk of data loss increases with increasing degradation. The silicon oxide in a cell degrades with every erase operation. The degradation increases the amount of negative charge in the cell over time due to trapped electrons in the oxide and negates some of the control gate voltage. Over time, this also makes erasing the cell slower; to maintain the performance and reliability of the NAND chip, the cell must be retired from use. Endurance also decreases with the number of bits in a cell. With more bits in a cell, the number of possible states (each represented by a different voltage level) in a cell increases and is more sensitive to the voltages used for programming. Voltages may be adjusted to compensate for degradation of the silicon oxide, and as the number of bits increases, the number of possible states also increases and thus the cell is less tolerant of adjustments to programming voltages, because there is less space between the voltage levels that define each state in a cell.\nFowler\u2013Nordheim tunneling.\nThe process of moving electrons from the control gate and into the floating gate is called Fowler\u2013Nordheim tunneling, and it fundamentally changes the characteristics of the cell by increasing the MOSFET's threshold voltage. This, in turn, changes the drain-source current that flows through the transistor for a given gate voltage, which is ultimately used to encode a binary value. The Fowler-Nordheim tunneling effect is reversible, so electrons can be added to or removed from the floating gate, processes traditionally known as writing and erasing.\nInternal charge pumps.\nDespite the need for relatively high programming and erasing voltages, virtually all flash chips today require only a single supply voltage and produce the high voltages that are required using on-chip charge pumps.\nOver half the energy used by a 1.8\u00a0V-NAND flash chip is lost in the charge pump itself. Since boost converters are inherently more efficient than charge pumps, researchers developing low-power SSDs have proposed returning to the dual Vcc/Vpp supply voltages used on all early flash chips, driving the high Vpp voltage for all flash chips in an SSD with a single shared external boost converter.\nIn spacecraft and other high-radiation environments, the on-chip charge pump is the first part of the flash chip to fail, although flash memories will continue to work\u00a0\u2013 in read-only mode\u00a0\u2013 at much higher radiation levels.\nNOR flash.\nIn both NOR and NAND flash memories, the cells are arranged in a grid. We can think of the memory as consisting of \"words\" of a certain number of bits (or cells), with each word being confined to a particular column of the grid, and the bits being in different rows. All the bits of a particular word are linked by a wordline, a conductor connecting to the control gates of all the bits of that word. All the first bits of a certain number of adjacent words (columns) are linked by a bitline, as are all the second bits and so on. The bitlines connect to one of the terminals (source or drain) of the cells. By manipulating the voltages on the wordlines one can read a certain bit by measuring the voltage on the corresponding bitline. The way to do this depends on whether the memory chip is a NOR or a NAND flash.\nIn NOR flash, each cell has one end connected directly to ground, and the other end connected directly to a bit line. This arrangement is called \"NOR flash\" because it acts like a NOR\u00a0gate \u00a0\u2013 if any of the word lines (connected to the CG of the cells) is brought high, the corresponding storage transistor may act to pull the output bit line low, but this depends on the charge in the floating gate. Since several words are connected by the bit line, the output does not depend on only two (the bitline staying high if neither the first NOR the second wordline is high) but on all (the bitline remaining high if NONE of the wordlines is high). So to read a bit of a certain word, all the wordlines except that of the desired word are put low.\nNOR flash continues to be the technology of choice for embedded applications requiring a discrete non-volatile memory device. The low read latencies characteristic of NOR\u00a0devices allow for both direct code execution and data storage in a single memory product.\nProgramming.\nA single-level NOR flash cell in its default state is logically equivalent to a binary \"1\" value, because current will flow through the channel under application of an appropriate voltage to the control gate, so that the bitline voltage is pulled down. A NOR\u00a0flash cell can be programmed, or set to a binary \"0\" value, by the following procedure:\nErasing.\nTo erase a NOR flash cell (resetting it to the \"1\" state), a large voltage \"of the opposite polarity\" is applied between the CG and source terminal, pulling the electrons off the FG through Fowler\u2013Nordheim tunneling (FN tunneling). This is known as Negative gate source source erase. Newer NOR memories can erase using negative gate channel erase, which biases the wordline on a NOR memory cell block and the P-well of the memory cell block to allow FN tunneling to be carried out, erasing the cell block. Older memories used source erase, in which a high voltage was applied to the source and then electrons from the FG were moved to the source. Modern NOR\u00a0flash memory chips are divided into erase segments (often called blocks or sectors). The erase operation can be performed only on a block-wise basis; all the cells in an erase segment must be erased together. Programming of NOR cells, however, generally can be performed one byte or word at a time.\nNAND flash.\nNAND flash also uses a grid of floating-gate transistors (see above), but they are connected in a way that resembles a NAND\u00a0gate: the transistors corresponding to a given bit of several words are connected in series, and the bitline is pulled low if all the word lines are pulled high (above the transistors' VT). To read the bit of a particular word, its wordline is put low and all the other wordlines are put high, and then the bitline will reflect the state of the floating gate of the desired cell. These groups are then connected via some additional transistors to a NOR-style bit line array in the same way that single transistors are linked in NOR\u00a0flash.\nCompared to NOR flash, replacing single transistors with serial-linked groups adds an extra level of addressing. Whereas NOR\u00a0flash might address memory by page then word, NAND\u00a0flash might address it by page, word and bit. Bit-level addressing suits bit-serial applications (such as hard disk emulation), which access only one bit at a time. Execute-in-place applications, on the other hand, require every bit in a word to be accessed simultaneously. This requires word-level addressing. In any case, both bit and word addressing modes are possible with either NOR or NAND\u00a0flash.\nTo read data, first the desired group is selected (in the same way that a single transistor is selected from a NOR array). Next, most of the word lines are pulled up above VT2, while one of them is pulled up to VI. The series group will conduct (and pull the bit line low) if the selected bit has not been programmed.\nDespite the additional transistors, the reduction in ground wires and bit lines allows a denser layout and greater storage capacity per chip. (The ground wires and bit lines are actually much wider than the lines in the diagrams.) In addition, NAND\u00a0flash is typically permitted to contain a certain number of faults (NOR\u00a0flash, as is used for a BIOS\u00a0ROM, is expected to be fault-free). Manufacturers try to maximize the amount of usable storage by shrinking the size of the transistors or cells, however the industry can avoid this and achieve higher storage densities per die by using 3D NAND, which stacks cells on top of each other.\nNAND flash cells are read by analysing their response to various voltages.\nWriting and erasing.\nNAND flash uses tunnel injection for writing and tunnel release for erasing. NAND\u00a0flash memory forms the core of the removable USB storage devices known as USB flash drives, as well as most memory card formats and solid-state drives available today.\nThe hierarchical structure of NAND flash starts at a cell level which establishes strings, then pages, blocks, planes and ultimately a die. A string is a series of connected NAND cells in which the source of one cell is connected to the drain of the next one. Depending on the NAND technology, a string typically consists of 32 to 128 NAND cells. Strings are organised into pages which are then organised into blocks in which each string is connected to a separate line called a bitline. All cells with the same position in the string are connected through the control gates by a wordline. A plane contains a certain number of blocks that are connected through the same bitline. A flash die consists of one or more planes, and the peripheral circuitry that is needed to perform all the read, write, and erase operations.\nThe architecture of NAND flash means that data can be read and programmed (written) in pages, typically between 4 KiB and 16 KiB in size, but can only be erased at the level of entire blocks consisting of multiple pages. When a block is erased, all the cells are logically set to 1. Data can only be programmed in one pass to a page in a block that was erased. The programming process is set one or more cells from 1 to 0. Any cells that have been set to 0 by programming can only be reset to 1 by erasing the entire block. This means that before new data can be programmed into a page that already contains data, the current contents of the page plus the new data must all be copied to a new, erased page. If a suitable erased page is available, the data can be written to it immediately. If no erased page is available, a block must be erased before copying the data to a page in that block. The old page is then marked as invalid and is available for erasing and reuse. This is different from operating system LBA view, for example, if operating system writes 1100 0011 to the flash storage device (such as SSD), the data actually written to the flash memory may be 0011 1100.\nVertical NAND.\nVertical NAND (V-NAND) or 3D NAND memory stacks memory cells vertically and uses a charge trap flash architecture. The vertical layers allow larger areal bit densities without requiring smaller individual cells. It is also sold under the trademark \"BiCS Flash\", which is a trademark of Kioxia Corporation (formerly Toshiba Memory Corporation). 3D NAND was first announced by Toshiba in 2007. V-NAND was first commercially manufactured by Samsung Electronics in 2013.\nStructure.\nV-NAND uses a charge trap flash geometry (which was commercially introduced in 2002 by AMD and Fujitsu) that stores charge on an embedded silicon nitride film. Such a film is more robust against point defects and can be made thicker to hold larger numbers of electrons. V-NAND wraps a planar charge trap cell into a cylindrical form. As of 2020, 3D NAND flash memories by Micron and Intel instead use floating gates, however, Micron 128 layer and above 3D NAND memories use a conventional charge trap structure, due to the dissolution of the partnership between Micron and Intel. Charge trap 3D NAND flash is thinner than floating gate 3D NAND. In floating gate 3D NAND, the memory cells are completely separated from one another, whereas in charge trap 3D NAND, vertical groups of memory cells share the same silicon nitride material. \nAn individual memory cell is made up of one planar polysilicon layer containing a hole filled by multiple concentric vertical cylinders. The hole's polysilicon surface acts as the gate electrode. The outermost silicon dioxide cylinder acts as the gate dielectric, enclosing a silicon nitride cylinder that stores charge, in turn enclosing a silicon dioxide cylinder as the tunnel dielectric that surrounds a central rod of conducting polysilicon which acts as the conducting channel.\nMemory cells in different vertical layers do not interfere with each other, as the charges cannot move vertically through the silicon nitride storage medium, and the electric fields associated with the gates are closely confined within each layer. The vertical collection is electrically identical to the serial-linked groups in which conventional NAND\u00a0flash memory is configured. There is also string stacking, which builds several 3D NAND memory arrays or \"plugs\" separately, but stacked together to create a product with a higher number of 3D NAND layers on a single die. Often, two or 3 arrays are stacked. The misalignment between plugs is in the order of 30 to 10nm.\nConstruction.\nGrowth of a group of V-NAND cells begins with an alternating stack of conducting (doped) polysilicon layers and insulating silicon dioxide layers.\nThe next step is to form a cylindrical hole through these layers. In practice, a 128\u00a0Gbit V-NAND chip with 24 layers of memory cells requires about 2.9 billion such holes. Next, the hole's inner surface receives multiple coatings, first silicon dioxide, then silicon nitride, then a second layer of silicon dioxide. Finally, the hole is filled with conducting (doped) polysilicon.\nPerformance.\nAs of 2013,[ [update]] V-NAND flash architecture allows read and write operations twice as fast as conventional NAND and can last up to 10 times as long, while consuming 50 percent less power. They offer comparable physical bit density using 10-nm lithography but may be able to increase bit density by up to two orders of magnitude, given V-NAND's use of up to several hundred layers. As of 2020, V-NAND chips with 160 layers are under development by Samsung. As the number of layers increases, the capacity and endurance of flash memory may be increased.\nCost.\nThe wafer cost of a 3D NAND is comparable with scaled down (32\u00a0nm or less) planar NAND flash. However, with planar NAND scaling stopping at 16\u00a0nm, the cost per bit reduction can continue by 3D NAND starting with 16 layers. However, due to the non-vertical sidewall of the hole etched through the layers; even a slight deviation leads to a minimum bit cost, i.e., minimum equivalent design rule (or maximum density), for a given number of layers; this minimum bit cost layer number decreases for smaller hole diameter.\nLimitations.\nBlock erasure.\nOne limitation of flash memory is that it can be erased only a block at a time. This generally sets all bits in the block to 1. Starting with a freshly erased block, any location within that block can be programmed. However, once a bit has been set to 0, only by erasing the entire block can it be changed back to 1. In other words, flash memory (specifically NOR\u00a0flash) offers random-access read and programming operations but does not offer arbitrary random-access rewrite or erase operations. A location can, however, be rewritten as long as the new value's 0 bits are a superset of the over-written values. For example, a nibble value may be erased to 1111, then written as 1110. Successive writes to that nibble can change it to 1010, then 0010, and finally 0000. Essentially, erasure sets all bits to 1, and programming can only clear bits to 0.\nSome file systems designed for flash devices make use of this rewrite capability, for example YAFFS1, to represent sector metadata. Other flash file systems, such as YAFFS2, never make use of this \"rewrite\" capability \u2013 they do a lot of extra work to meet a \"write once rule\".\nAlthough data structures in flash memory cannot be updated in completely general ways, this allows members to be \"removed\" by marking them as invalid. This technique may need to be modified for multi-level cell devices, where one memory cell holds more than one bit.\nCommon flash devices such as USB flash drives and memory cards provide only a block-level interface, or flash translation layer (FTL), which writes to a different cell each time to wear-level the device. This prevents incremental writing within a block; however, it does help the device from being prematurely worn out by intensive write patterns.\nData retention.\nData stored on flash cells is steadily lost due to electron detrapping. The rate of loss increases exponentially as the absolute temperature increases. For example: For a 45\u00a0nm NOR flash, at 1000 hours, the threshold voltage (Vt) loss at 25\u00b0C is about half that at 90\u00b0C.\nMemory wear.\nAnother limitation is that flash memory has a finite number of program\u2013erase cycles (typically written as P/E\u00a0cycles). Micron Technology and Sun Microsystems announced an SLC\u00a0NAND flash memory chip rated for 1,000,000\u00a0P/E\u00a0cycles on 17 December 2008.\nThe guaranteed cycle count may apply only to block zero (as is the case with TSOP\u00a0NAND devices), or to all blocks (as in NOR). This effect is mitigated in some chip firmware or file system drivers by counting the writes and dynamically remapping blocks in order to spread write operations between sectors; this technique is called wear leveling. Another approach is to perform write verification and remapping to spare sectors in case of write failure, a technique called bad block management (BBM). For portable consumer devices, these wear out management techniques typically extend the life of the flash memory beyond the life of the device itself, and some data loss may be acceptable in these applications. For high-reliability data storage, however, it is not advisable to use flash memory that would have to go through a large number of programming cycles. This limitation also exists for \"read-only\" applications such as thin clients and routers, which are programmed only once or at most a few times during their lifetimes, due to \"read disturb\" (see below).\nIn December 2012, Taiwanese engineers from Macronix revealed their intention to announce at the 2012 IEEE International Electron Devices Meeting that they had figured out how to improve NAND\u00a0flash storage read/write cycles from 10,000 to 100 million cycles using a \"self-healing\" process that used a flash chip with \"onboard heaters that could anneal small groups of memory cells.\" The built-in thermal annealing was to replace the usual erase cycle with a local high temperature process that not only erased the stored charge, but also repaired the electron-induced stress in the chip, giving write cycles of at least 100 million. The result was to be a chip that could be erased and rewritten over and over, even when it should theoretically break down. As promising as Macronix's breakthrough might have been for the mobile industry, however, there were no plans for a commercial product featuring this capability to be released any time in the near future.\nRead disturb.\nThe method used to read NAND\u00a0flash memory can cause nearby cells in the same memory block to change over time (become programmed). This is known as read disturb. The threshold number of reads is generally in the hundreds of thousands of reads between intervening erase operations. If reading continually from one cell, that cell will not fail but rather one of the surrounding cells will on a subsequent read. To avoid the read disturb problem the flash controller will typically count the total number of reads to a block since the last erase. When the count exceeds a target limit, the affected block is copied over to a new block, erased, then released to the block pool. The original block is as good as new after the erase. If the flash controller does not intervene in time, however, a read disturb error will occur with possible data loss if the errors are too numerous to correct with an error-correcting code.\nX-ray effects.\nMost flash ICs come in ball grid array (BGA) packages, and even the ones that do not are often mounted on a PCB next to other BGA packages. After PCB assembly, boards with BGA packages are often X-rayed to see if the balls are making proper connections to the proper pad, or if the BGA needs rework. These X-rays can erase programmed bits in a flash chip (convert programmed \"0\" bits into erased \"1\" bits). Erased bits (\"1\" bits) are not affected by X-rays.\nSome manufacturers are now making X-ray-proof SD and USB memory devices.\nLow-level access.\nThe low-level interface to flash memory chips differs from those of other memory types such as DRAM, ROM, and EEPROM, which support bit-alterability (both zero to one and one to zero) and random access via externally accessible address buses.\nNOR memory has an external address bus for reading and programming. For NOR memory, reading and programming are random-access, and unlocking and erasing are block-wise. For NAND memory, reading and programming are page-wise, and unlocking and erasing are block-wise.\nNOR memories.\nReading from NOR flash is similar to reading from random-access memory, provided the address and data bus are mapped correctly. Because of this, most microprocessors can use NOR\u00a0flash memory as execute in place (XIP) memory, meaning that programs stored in NOR\u00a0flash can be executed directly from the NOR\u00a0flash without needing to be copied into RAM first. NOR\u00a0flash may be programmed in a random-access manner similar to reading. Programming changes bits from a logical one to a zero. Bits that are already zero are left unchanged. Erasure must happen a block at a time, and resets all the bits in the erased block back to one. Typical block sizes are 64, 128, or 256\u00a0KiB.\nBad block management is a relatively new feature in NOR\u00a0chips. In older NOR devices not supporting bad block management, the software or device driver controlling the memory chip must correct for blocks that wear out, or the device will cease to work reliably.\nThe specific commands used to lock, unlock, program, or erase NOR memories differ for each manufacturer. To avoid needing unique driver software for every device made, special Common Flash Memory Interface (CFI) commands allow the device to identify itself and its critical operating parameters.\nBesides its use as random-access ROM, NOR\u00a0flash can also be used as a storage device, by taking advantage of random-access programming. Some devices offer read-while-write functionality so that code continues to execute even while a program or erase operation is occurring in the background. For sequential data writes, NOR\u00a0flash chips typically have slow write speeds, compared with NAND\u00a0flash.\nTypical NOR flash does not need an error correcting code.\nNAND memories.\nNAND flash architecture was introduced by Toshiba in 1989. These memories are accessed much like block devices, such as hard disks. Each block consists of a number of pages. The pages are typically 512, 2,048, or 4,096 bytes in size. Associated with each page are a few bytes (typically 1/32 of the data size) that can be used for storage of an error correcting code (ECC) checksum.\nTypical block sizes include:\nModern NAND flash may have erase block size between 1 MiB to 128 MiB. While reading and programming is performed on a page basis, erasure can only be performed on a block basis. Since changing a cell from 0 to 1 requires erasing an entire block instead of just modifying some pages, making changes to the data of a block may in reality be a read-erase-write process, where the new data is actually moved to another block. In addition, on a NVM Express Zoned Namespaces SSD, it usually uses flash block size as the zone size.\nNAND devices also require bad block management by the device driver software or by the flash memory controller chip. Some SD\u00a0cards, for example, include controller circuitry to perform bad block management and wear leveling. When a logical block is accessed by high-level software, it is mapped to a physical block by the device driver or controller. A number of blocks on the flash chip may be set aside for storing mapping tables to deal with bad blocks, or the system may simply check each block at power-up to create a bad block map in RAM. The overall memory capacity gradually shrinks as more blocks are marked as bad.\nNAND relies on ECC to compensate for bits that may spontaneously fail during normal device operation. A typical ECC will correct a one-bit error in each 2048\u00a0bits (256\u00a0bytes) using 22\u00a0bits of ECC, or a one-bit error in each 4096\u00a0bits (512\u00a0bytes) using 24\u00a0bits of ECC. If the ECC cannot correct the error during read, it may still detect the error. When doing erase or program operations, the device can detect blocks that fail to program or erase and mark them bad. The data is then written to a different, good block, and the bad block map is updated.\nHamming codes are the most commonly used ECC for SLC\u00a0NAND flash. Reed\u2013Solomon codes and BCH codes (Bose\u2013Chaudhuri\u2013Hocquenghem codes) are commonly used ECC for MLC\u00a0NAND flash. Some MLC\u00a0NAND flash chips internally generate the appropriate BCH error correction codes.\nMost NAND devices are shipped from the factory with some bad blocks. These are typically marked according to a specified bad block marking strategy. By allowing some bad blocks, manufacturers achieve far higher yields than would be possible if all blocks had to be verified to be good. This significantly reduces NAND\u00a0flash costs and only slightly decreases the storage capacity of the parts.\nWhen executing software from NAND memories, virtual memory strategies are often used: memory contents must first be paged or copied into memory-mapped RAM and executed there (leading to the common combination of NAND + RAM). A memory management unit (MMU) in the system is helpful, but this can also be accomplished with overlays. For this reason, some systems will use a combination of NOR and NAND memories, where a smaller NOR memory is used as software ROM and a larger NAND memory is partitioned with a file system for use as a non-volatile data storage area.\nNAND sacrifices the random-access and execute-in-place advantages of NOR. NAND is best suited to systems requiring high capacity data storage. It offers higher densities, larger capacities, and lower cost. It has faster erases, sequential writes, and sequential reads.\nStandardization.\nA group called the Open NAND Flash Interface Working Group (ONFI) has developed a standardized low-level interface for NAND\u00a0flash chips. This allows interoperability between conforming NAND devices from different vendors. The ONFI specification version 1.0 was released on 28 December 2006. It specifies:\nThe ONFI group is supported by major NAND flash manufacturers, including Hynix, Intel, Micron Technology, and Numonyx, as well as by major manufacturers of devices incorporating NAND\u00a0flash chips.\nTwo major flash device manufacturers, Toshiba and Samsung, have chosen to use an NAND flash interface of their own design known as Toggle Mode (and now Toggle). This interface isn't pin-to-pin compatible with the ONFI specification. The result is that a product designed for one vendor's devices may not be able to use another vendor's devices.\nA group of vendors, including Intel, Dell, and Microsoft, formed a Non-Volatile Memory Host Controller Interface (NVMHCI) Working Group. The goal of the group is to provide standard software and hardware programming interfaces for nonvolatile memory subsystems, including the \"flash cache\" device connected to the PCI Express bus.\nDistinction between NOR and NAND flash.\nNOR and NAND flash differ in two important ways:\nNOR and NAND flash get their names from the structure of the interconnections between memory cells. In NOR\u00a0flash, cells are connected in parallel to the bit lines, allowing cells to be read and programmed individually. The parallel connection of cells resembles the parallel connection of transistors in a CMOS NOR gate. In NAND\u00a0flash, cells are connected in series, resembling a CMOS NAND gate. The series connections consume less space than parallel ones, reducing the cost of NAND\u00a0flash. It does not, by itself, prevent NAND cells from being read and programmed individually.\nEach NOR flash cell is larger than a NAND\u00a0flash cell\u00a0\u2013 10\u00a0F2 vs 4\u00a0F2\u00a0\u2013 even when using exactly the same semiconductor device fabrication and so each transistor, contact, etc. is exactly the same size\u00a0\u2013 because NOR\u00a0flash cells require a separate metal contact for each cell.\nBecause of the series connection and removal of wordline contacts, a large grid of NAND\u00a0flash memory cells will occupy perhaps only 60% of the area of equivalent NOR cells (assuming the same CMOS process resolution, for example, 130\u00a0nm, 90\u00a0nm, or 65\u00a0nm). NAND\u00a0flash's designers realized that the area of a NAND chip, and thus the cost, could be further reduced by removing the external address and data bus circuitry. Instead, external devices could communicate with NAND\u00a0flash via sequential-accessed command and data registers, which would internally retrieve and output the necessary data. This design choice made random-access of NAND\u00a0flash memory impossible, but the goal of NAND\u00a0flash was to replace mechanical hard disks, not to replace ROMs. \nThe first GSM phones and many feature phones had NOR flash memory, from which processor instructions could be executed directly in an execute-in-place architecture and allowed for short boot times. With smartphones, NAND flash memory was adopted as it has larger storage capacities and lower costs, but causes longer boot times because instructions cannot be executed from it directly, and must be copied to RAM memory first before execution.\nWrite endurance.\nThe write endurance of SLC floating-gate NOR flash is typically equal to or greater than that of NAND\u00a0flash, while MLC\u00a0NOR and NAND\u00a0flash have similar endurance capabilities. Examples of endurance cycle ratings listed in datasheets for NAND and NOR\u00a0flash, as well as in storage devices using flash memory, are provided.\nHowever, by applying certain algorithms and design paradigms such as wear leveling and memory over-provisioning, the endurance of a storage system can be tuned to serve specific requirements.\nIn order to compute the longevity of the NAND\u00a0flash, one must account for the size of the memory chip, the type of memory (e.g. SLC/MLC/TLC), and use pattern. Industrial NAND and server NAND are in demand due to their capacity, longer endurance and reliability in sensitive environments.\nAs the number of bits per cell increases, performance and life of NAND flash may degrade, increasing random read times to 100\u03bcs for TLC NAND which is 4 times the time required in SLC NAND, and twice the time required in MLC NAND, for random reads.\nFlash file systems.\nBecause of the particular characteristics of flash memory, it is best used with either a controller to perform wear leveling and error correction or specifically designed flash file systems, which spread writes over the media and deal with the long erase times of NOR\u00a0flash blocks. The basic concept behind flash file systems is the following: when the flash store is to be updated, the file system will write a new copy of the changed data to a fresh block, remap the file pointers, then erase the old block later when it has time.\nIn practice, flash file systems are used only for memory technology devices (MTDs), which are embedded flash memories that do not have a controller. Removable flash memory cards, SSDs, eMMC/eUFS chips and USB flash drives have built-in controllers to perform wear leveling and error correction so use of a specific flash file system may not add benefit.\nCapacity.\nMultiple chips are often arrayed or die stacked to achieve higher capacities for use in consumer electronic devices such as multimedia players or GPSs. The capacity scaling (increase) of flash chips used to follow Moore's law because they are manufactured with many of the same integrated circuits techniques and equipment. Since the introduction of 3D NAND, scaling is no longer necessarily associated with Moore's law since ever smaller transistors (cells) are no longer used.\nConsumer flash storage devices typically are advertised with usable sizes expressed as a small integer power of two (2, 4, 8, etc.) and a conventional designation of megabytes (MB) or gigabytes (GB); e.g., 512\u00a0MB, 8\u00a0GB. This includes SSDs marketed as hard drive replacements, in accordance with traditional hard drives, which use decimal prefixes. Thus, an SSD marked as \"64\u00a0GB\" is at least 64 \u00d7 10003 bytes (64\u00a0GB). Most users will have slightly less capacity than this available for their files, due to the space taken by file system metadata and because some operating systems report SSD capacity using binary prefixes which are somewhat larger than conventional prefixes .\nThe flash memory chips inside them are sized in strict binary multiples, but the actual total capacity of the chips is not usable at the drive interface. It is considerably larger than the advertised capacity in order to allow for distribution of writes (wear leveling), for sparing, for error correction codes, and for other metadata needed by the device's internal firmware.\nIn 2005, Toshiba and SanDisk developed a NAND\u00a0flash chip capable of storing 1\u00a0GB of data using multi-level cell (MLC) technology, capable of storing two bits of data per cell. In September 2005, Samsung Electronics announced that it had developed the world's first 2\u00a0GB chip.\nIn March 2006, Samsung announced flash hard drives with capacity of 4\u00a0GB, essentially the same order of magnitude as smaller laptop hard drives, and in September 2006, Samsung announced an 8\u00a0GB chip produced using a 40\u00a0nm manufacturing process.\nIn January 2008, SanDisk announced availability of their 16\u00a0GB MicroSDHC and 32\u00a0GB SDHC Plus cards.\nMore recent flash drives (as of 2012) have much greater capacities, holding 64, 128, and 256\u00a0GB.\nA joint development at Intel and Micron will allow the production of 32-layer 3.5 terabyte (TB) NAND\u00a0flash sticks and 10\u00a0TB standard-sized SSDs. The device includes 5 packages of 16 \u00d7 48\u00a0GB\u00a0TLC dies, using a floating gate cell design.\nFlash chips continue to be manufactured with capacities under or around 1\u00a0MB (e.g. for BIOS-ROMs and embedded applications).\nIn July 2016, Samsung announced the 4\u00a0TB Samsung 850 EVO which utilizes their 256\u00a0Gbit 48-layer TLC 3D V-NAND. In August 2016, Samsung announced a 32\u00a0TB 2.5-inch SAS\u00a0SSD based on their 512\u00a0Gbit 64-layer TLC 3D\u00a0V-NAND. Further, Samsung expects to unveil SSDs with up to 100\u00a0TB of storage by 2020.\nTransfer rates.\nFlash memory devices are typically much faster at reading than writing. Performance also depends on the quality of storage controllers, which become more critical when devices are partially full. Even when the only change to manufacturing is die-shrink, the absence of an appropriate controller can result in degraded speeds.\nApplications.\nSerial flash.\nSerial flash is a small, low-power flash memory that provides only serial access to the data - rather than addressing individual bytes, the user reads or writes large contiguous groups of bytes in the address space serially. Serial Peripheral Interface Bus (SPI) is a typical protocol for accessing the device. \nWhen incorporated into an embedded system, serial flash requires fewer wires on the PCB than parallel flash memories, since it transmits and receives data one bit at a time. This may permit a reduction in board space, power consumption, and total system cost.\nThere are several reasons why a serial device, with fewer external pins than a parallel device, can significantly reduce overall cost:\nThere are two major SPI flash types. The first type is characterized by small blocks and one internal SRAM block buffer allowing a complete block to be read to the buffer, partially modified, and then written back (for example, the Atmel AT45 \"DataFlash\" or the Micron Technology Page Erase NOR\u00a0Flash). The second type has larger sectors where the smallest sectors typically found in this type of SPI flash are 4\u00a0KB, but they can be as large as 64\u00a0KB. Since this type of SPI flash lacks an internal SRAM buffer, the complete block must be read out and modified before being written back, making it slow to manage. However, the second type is cheaper than the first and is therefore a good choice when the application is code shadowing.\nThe two types are not easily exchangeable, since they do not have the same pinout, and the command sets are incompatible.\nMost FPGAs are based on SRAM configuration cells and require an external configuration device, often a serial flash chip, to reload the configuration bitstream every power cycle.\nFirmware storage.\nWith the increasing speed of modern CPUs, parallel flash devices are often much slower than the memory bus of the computer they are connected to. Conversely, modern SRAM offers access times below 10\u00a0ns, while DDR2 SDRAM offers access times below 20\u00a0ns. Because of this, it is often desirable to shadow code stored in flash into RAM; that is, the code is copied from flash into RAM before execution, so that the CPU may access it at full speed. Device firmware may be stored in a serial flash chip, and then copied into SDRAM or SRAM when the device is powered-up. Using an external serial flash device rather than on-chip flash removes the need for significant process compromise (a manufacturing process that is good for high-speed logic is generally not good for flash and vice versa). Once it is decided to read the firmware in as one big block it is common to add compression to allow a smaller flash chip to be used. Since 2005, many devices use serial NOR flash to deprecate parallel NOR flash for firmware storage. Typical applications for serial NOR flash include storing firmware for hard drives, BIOS, Option ROM of expansion cards, DSL modems, etc.\nFlash memory as a replacement for hard drives.\nOne more recent application for flash memory is as a replacement for hard disks. Flash memory does not have the mechanical limitations and latencies of hard drives, so a solid-state drive (SSD) is attractive in terms of speed, noise, power consumption, and reliability. Flash drives are gaining traction as mobile device secondary storage devices; they are also used as substitutes for hard drives in high-performance desktop computers and some servers with RAID and SAN architectures.\nThere remain some aspects of flash-based SSDs that make them unattractive. The cost per gigabyte of flash memory remains significantly higher than that of hard disks. Also, flash memory has a finite number of P/E (\"program/erase\") cycles, but this seems to be currently under control since warranties on flash-based SSDs are approaching those of current hard drives. In addition, deleted files on SSDs can remain for an indefinite period of time before being overwritten by fresh data; erasure or shred techniques or software that work well on magnetic hard disk drives have no effect on SSDs, compromising security and forensic examination. However, due to the so-called \"TRIM\" command employed by most solid state drives, which marks the logical block addresses occupied by the deleted file as unused to enable garbage collection, data recovery software is not able to restore files deleted from such.\nFor relational databases or other systems that require ACID transactions, even a modest amount of flash storage can offer vast speedups over arrays of disk drives.\nIn May 2006, Samsung Electronics announced two flash-memory based PCs, the Q1-SSD and Q30-SSD were expected to become available in June 2006, both of which used 32\u00a0GB SSDs, and were at least initially available only in South Korea. The Q1-SSD and Q30-SSD launch was delayed and finally was shipped in late August 2006.\nThe first flash-memory based PC to become available was the Sony Vaio UX90, announced for pre-order on 27 June 2006 and began to be shipped in Japan on 3 July 2006 with a 16\u00a0GB flash memory hard drive. In late September 2006 Sony upgraded the flash-memory in the Vaio UX90 to 32\u00a0GB.\nA solid-state drive was offered as an option with the first MacBook Air introduced in 2008, and from 2010 onwards, all models were shipped with an SSD. Starting in late 2011, as part of Intel's Ultrabook initiative, an increasing number of ultra-thin laptops are being shipped with SSDs standard.\nThere are also hybrid techniques such as hybrid drive and ReadyBoost that attempt to combine the advantages of both technologies, using flash as a high-speed non-volatile cache for files on the disk that are often referenced, but rarely modified, such as application and operating system executable files.\nOn smartphones, the NAND flash products are used as file storage device, for example, eMMC and eUFS.\nFlash memory as RAM.\nAs of 2012,[ [update]] there are attempts to use flash memory as the main computer memory, DRAM.\nArchival or long-term storage.\nFloating-gate transistors in the flash storage device hold charge which represents data. This charge gradually leaks over time, leading to an accumulation of logical errors, also known as \"bit rot\" or \"bit fading\".\nData retention.\nIt is unclear how long data on flash memory will persist under archival conditions (i.e., benign temperature and humidity with infrequent access with or without prophylactic rewrite). Datasheets of Atmel's flash-based \"ATmega\" microcontrollers typically promise retention times of 20 years at 85\u00a0\u00b0C (185\u00a0\u00b0F) and 100 years at 25\u00a0\u00b0C (77\u00a0\u00b0F).\nThe retention span varies among types and models of flash storage. When supplied with power and idle, the charge of the transistors holding the data is routinely refreshed by the firmware of the flash storage. The ability to retain data varies among flash storage devices due to differences in firmware, data redundancy, and error correction algorithms.\nAn article from CMU in 2015 states \"Today's flash devices, which do not require flash refresh, have a typical retention age of 1 year at room temperature.\" And that retention time decreases exponentially with increasing temperature. The phenomenon can be modeled by the Arrhenius equation.\nWhile flash storage retains data for a longer time if stored at colder temperatures, a higher but not extreme temperature while writing reduces stress and wear on the drive, given that electrons are able to flow more easily, according to Tim Schulte, Pranav Kalavade, and Johnmichael Hands from Intel.\nFPGA configuration.\nSome FPGAs are based on flash configuration cells that are used directly as (programmable) switches to connect internal elements together, using the same kind of floating-gate transistor as the flash data storage cells in data storage devices.\nIndustry.\nOne source states that, in 2008, the flash memory industry includes about US$9.1 billion in production and sales. Other sources put the flash memory market at a size of more than US$20 billion in 2006, accounting for more than eight percent of the overall semiconductor market and more than 34 percent of the total semiconductor memory market.\nIn 2012, the market was estimated at $26.8 billion. It can take up to 10 weeks to produce a flash memory chip.\nManufacturers.\nThe following were the largest NAND flash memory manufacturers, as of the second quarter of 2023.\nNotes: Samsung remains the largest NAND flash memory manufacturer as of Q1 2022.\nKioxia spun out and got renamed of Toshiba in 2018/2019.\nSK Hynix acquired Intel's NAND business at the end of 2021.\nShipments.\nIn addition to individual flash memory chips, flash memory is also embedded in microcontroller (MCU) chips and system-on-chip (SoC) devices. Flash memory is embedded in ARM chips, which have sold 150billion units worldwide as of 2019[ [update]], and in programmable system-on-chip (PSoC) devices, which have sold 1.1billion units as of 2012[ [update]]. This adds up to at least 151.1billion MCU and SoC chips with embedded flash memory, in addition to the 45.4billion known individual flash chip sales as of 2015[ [update]], totalling at least 196.5billion chips containing flash memory.\nFlash scalability.\nDue to its relatively simple structure and high demand for higher capacity, NAND\u00a0flash memory is the most aggressively scaled technology among electronic devices. The heavy competition among the top few manufacturers only adds to the aggressiveness in shrinking the floating-gate MOSFET design rule or process technology node. While the expected shrink timeline is a factor of two every three years per the original version of Moore's law, this has recently been accelerated in the case of NAND\u00a0flash to a factor of two every two years. \nAs the MOSFET feature size of flash memory cells reaches the 15\u201316\u00a0nm minimum limit, further flash density increases will be driven by TLC (3\u00a0bits/cell) combined with vertical stacking of NAND memory planes. The decrease in endurance and increase in uncorrectable bit error rates that accompany feature size shrinking can be compensated by improved error correction mechanisms. Even with these advances, it may be impossible to economically scale flash to smaller and smaller dimensions as the number of electron holding capacity reduces. Many promising new technologies (such as FeRAM, MRAM, PMC, PCM, ReRAM, and others) are under investigation and development as possible more scalable replacements for flash.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50596", "revid": "5333", "url": "https://en.wikipedia.org/wiki?curid=50596", "title": "San Min Chu I", "text": ""}
{"id": "50597", "revid": "1461430", "url": "https://en.wikipedia.org/wiki?curid=50597", "title": "EEPROM", "text": "Computer memory used for small quantities of data\nEEPROM or E2PROM (electrically erasable programmable read-only memory) is a type of non-volatile memory. It is used in computers, usually integrated in microcontrollers such as smart cards and remote keyless systems, or as a separate chip device, to store relatively small amounts of data by allowing individual bytes to be erased and reprogrammed.\nEEPROMs are organized as arrays of floating-gate transistors. EEPROMs can be programmed and erased in-circuit, by applying special programming signals. Originally, EEPROMs were limited to single-byte operations, which made them slower, but modern EEPROMs allow multi-byte page operations. An EEPROM has a limited life for erasing and reprogramming, reaching a million operations in modern EEPROMs. In an EEPROM that is frequently reprogrammed, the life of the EEPROM is an important design consideration.\nFlash memory is a type of EEPROM designed for high speed and high density, at the expense of large erase blocks (typically 512\u00a0bytes or larger) and limited number of write cycles (often 10,000). There is no clear boundary dividing the two, but the term \"EEPROM\" is generally used to describe non-volatile memory with small erase blocks (as small as one byte) and a long lifetime (typically 1,000,000 cycles). Many past microcontrollers included both (flash memory for the firmware and a small EEPROM for parameters), though the trend with modern microcontrollers is to emulate EEPROM using flash.\nAs of 2020, flash memory costs much less than byte-programmable EEPROM and is the dominant memory type wherever a system requires a significant amount of non-volatile solid-state storage. EEPROMs, however, are still used on applications that only require small amounts of storage, like in serial presence detect.\nHistory.\nEarly attempts.\nIn the early 1970s, some studies, inventions, and development for electrically re-programmable non-volatile memories were performed by various companies and organizations.\nIn 1971, early research was presented at \"the 3rd Conference on Solid State Devices, Tokyo\" in Japan by Yasuo Tarui, Yutaka Hayashi, and Kiyoko Nagai at \"Electrotechnical Laboratory\"; a Japanese national research institute.\nThey fabricated an electrically re-programmable non-volatile memory in 1972, and continued this study for more than 10 years. However this early memory depended on capacitors to work, which modern EEPROM lacks.\nIn 1972 IBM patented an electrically re-programmable non-volatile memory invention. Later that year, an avalanche injection type MOS was patented by Fujio Masuoka, the inventor of flash memory, at Toshiba and IBM patented another later that year.\nIn 1974, NEC patented a electrically erasable carrier injection device. The next year, NEC applied for the trademark \"EEPROM\u00ae\" with the Japan Patent Office. The trademark was granted in 1978.\nThe theoretical basis of these devices is avalanche hot-carrier injection. In general, programmable memories, including EPROM, of early 1970s had reliability and endurance problems such as the data retention periods and the number of erase/write cycles.\nMost of the major semiconductor manufactures, such as\nToshiba,\nSanyo (later, ON Semiconductor),\nIBM,\nIntel,\nNEC (later, Renesas Electronics),\nPhilips (later, NXP Semiconductors),\nSiemens (later, Infineon Technologies),\nHoneywell (later, Atmel),\nTexas Instruments,\nstudied, invented, and manufactured some electrically re-programmable non-volatile devices until 1977.\nModern EEPROM.\nThe first EEPROM that used Fowler-Nordheim tunnelling to erase data was invented by Bernward and patented by Siemens in 1974. In February 1977, Israeli-American Eliyahou Harari at Hughes Aircraft Company patented in the US a modern EEPROM technology, based on Fowler-Nordheim tunnelling through a thin silicon dioxide layer between the floating-gate and the wafer.\nHughes went on to produce this new EEPROM devices.\nIn May 1977, some important research result was disclosed by Fairchild and Siemens. They used \"SONOS\" (polysilicon-oxynitride-nitride-oxide-silicon) structure with thickness of silicon dioxide less than 30 \u00c5, and \"SIMOS\" (stacked-gate injection MOS) structure, respectively, for using \"Fowler-Nordheim tunnelling\" hot-carrier injection.\nAround 1976 to 1978, Intel's team, including George Perlegos, made some inventions to improve this tunneling E2PROM technology.\nIn 1978, they developed a 16K (2K word \u00d7 8) bit \"Intel 2816\" chip with a thin silicon dioxide layer, which was less than 200 \u00c5.\nIn 1980, this structure was publicly introduced as \"FLOTOX\"; floating gate tunnel oxide.\nThe \"FLOTOX\" structure improved reliability of erase/write cycles per byte up to 10,000 times.\nBut this device required additional 20\u201322V VPP bias voltage supply for byte erase, except for 5V read operations.\nIn 1981, Perlegos and 2 other members left Intel to form Seeq Technology,\nwhich used on-device charge pumps to supply the high voltages necessary for programming E2PROMs.\nIn 1984, Perlogos left Seeq Technology to found Atmel, then Seeq Technology was acquired by Atmel.\nElectrically alterable read-only memory (EAROM) is a type of EEPROM that can be modified one or a few bits at a time. Writing is a very slow process and again needs higher voltage (usually around 12 V) than is used for read access. EAROMs are intended for applications that require infrequent and only partial rewriting.\nTheoretical basis of FLOTOX structure.\nAs is described in former section, old EEPROMs are based on avalanche breakdown-based hot-carrier injection with high reverse breakdown voltage. But \"FLOTOX\" theoretical basis is Fowler\u2013Nordheim tunneling hot-carrier injection through a thin silicon dioxide layer between the floating gate and the wafer. In other words, it uses a tunnel junction.\nTheoretical basis of the physical phenomenon itself is the same as today's flash memory. But each FLOTOX structure is in conjunction with another read-control transistor because the floating gate itself is just programming and erasing one data bit.\nIntel's FLOTOX device structure improved EEPROM reliability, in other words, the endurance of the write and erase cycles, and the data retention period. A material of study for single-event effect about FLOTOX is available.\nToday, an academic explanation of the FLOTOX device structure can be found in several sources.\nToday's EEPROM structure.\nNowadays, EEPROM is used for embedded microcontrollers as well as standard EEPROM products.\nEEPROM still requires a 2-transistor structure per bit to erase a dedicated byte in the memory, while flash memory has 1 transistor per bit to erase a region of the memory.\nSecurity protections.\nBecause EEPROM technology is used for some security gadgets, such as credit cards, SIM cards, key-less entry, etc., some devices have security protection mechanisms, such as copy-protection.\nElectrical interface.\nEEPROM devices use a serial or parallel interface for data input/output.\nSerial bus devices.\nThe common serial interfaces are SPI, I\u00b2C, Microwire, UNI/O, and 1-Wire. These use from one to four device pins and allow devices to use packages with eight pins or less.\nA typical EEPROM serial protocol consists of three phases: OP-code phase, address phase and data phase. The OP-code is usually the first 8 bits input to the serial input pin of the EEPROM device (or with most I\u00b2C devices, is implicit); followed by 8 to 24 bits of addressing, depending on the depth of the device, then the read or write data.\nEach EEPROM device typically has its own set of OP-code instructions mapped to different functions. Common operations on SPI EEPROM devices are:\nOther operations supported by some EEPROM devices are:\nParallel bus devices.\nParallel EEPROM devices typically have an 8-bit data bus and an address bus wide enough to cover the complete memory. Most devices have chip select and write protect pins. Some microcontrollers also have integrated parallel EEPROM.\nOperation of a parallel EEPROM is simple and fast when compared to serial EEPROM, but these devices are larger due to the higher pin count (28 pins or more) and have been decreasing in popularity in favor of serial EEPROM or flash.\nOther devices.\nEEPROM memory is used to enable features in other types of products that are not strictly memory products. Products such as real-time clocks, digital potentiometers, digital temperature sensors, among others, may have small amounts of EEPROM to store calibration information or other data that needs to be available in the event of power loss.\nIt was also used on video game cartridges to save game progress and configurations, before the usage of external and internal flash memories.\nFailure modes.\nThere are two limitations of stored information: endurance and data retention.\nDuring rewrites, the gate oxide in the floating-gate transistors gradually accumulates trapped electrons. The electric field of the trapped electrons adds to the electrons in the floating gate, lowering the window between threshold voltages for zeros vs ones. After sufficient number of rewrite cycles, the difference becomes too small to be recognizable, the cell is stuck in programmed state, and endurance failure occurs. The manufacturers usually specify the maximum number of rewrites being 1 million or more.\nDuring storage, the electrons injected into the floating gate may drift through the insulator, especially at increased temperature, and cause charge loss, reverting the cell into erased state. The manufacturers usually guarantee data retention of 10 years or more.\nRelated types.\nFlash memory is a later form of EEPROM. In the industry, there is a convention to reserve the term EEPROM to byte-wise erasable memories compared to block-wise erasable flash memories. EEPROM occupies more die area than flash memory for the same capacity, because each cell usually needs a read, a write, and an erase transistor, while flash memory erase circuits are shared by large blocks of cells (often 512\u00d78).\nNewer non-volatile memory technologies such as FeRAM and MRAM are slowly replacing EEPROMs in some applications, but are expected to remain a small fraction of the EEPROM market for the foreseeable future.\nComparison with EPROM and EEPROM/flash.\nThe difference between EPROM and EEPROM lies in the way that the memory programs and erases. EEPROM can be programmed and erased electrically using field electron emission (more commonly known in the industry as \"Fowler\u2013Nordheim tunneling\").\nEPROMs can't be erased electrically and are programmed by hot-carrier injection onto the floating gate. Erase is by an ultraviolet light source, although in practice many EPROMs are encapsulated in plastic that is opaque to UV light, making them \"one-time programmable\".\nMost NOR flash memory is a hybrid style\u2014programming is through hot-carrier injection and erase is through Fowler\u2013Nordheim tunneling.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50598", "revid": "2", "url": "https://en.wikipedia.org/wiki?curid=50598", "title": "The shell model", "text": ""}
{"id": "50599", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=50599", "title": "Erasable programmable read-only memory", "text": ""}
{"id": "50601", "revid": "1461430", "url": "https://en.wikipedia.org/wiki?curid=50601", "title": "Cystic fibrosis", "text": "Genetic disorder affecting mostly the lungs\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nCystic fibrosis (CF) is a genetic disorder inherited in an autosomal recessive manner that impairs the normal clearance of mucus from the lungs, which facilitates the colonization and infection of the lungs by bacteria, notably \"Pseudomonas aeruginosa\" and \"Staphylococcus aureus\". CF is a rare genetic disorder that affects mostly the lungs, but also the pancreas, liver, kidneys, and intestine. The hallmark feature of CF is the accumulation of thick mucus in different organs. Long-term issues include difficulty breathing and coughing up mucus as a result of frequent lung infections. Other signs and symptoms may include sinus infections, poor growth, fatty stool, clubbing of the fingers and toes, and infertility in most males. Different people may have different degrees of symptoms. \nCystic fibrosis is inherited in an autosomal recessive manner. It is caused by the presence of mutations in both copies (alleles) of the gene encoding the cystic fibrosis transmembrane conductance regulator (CFTR) protein. Those with a single working copy are carriers and otherwise mostly healthy. CFTR is involved in the production of sweat, digestive fluids, and mucus. When the CFTR is not functional, secretions that are usually thin instead become thick. The condition is diagnosed by a sweat test and genetic testing. The sweat test measures sodium concentration, as people with cystic fibrosis have abnormally salty sweat, which can often be tasted by parents kissing their children. Screening of infants at birth takes place in some areas of the world.\nThere is no known cure for cystic fibrosis. Lung infections are treated with antibiotics which may be given intravenously, inhaled, or by mouth. Sometimes, the antibiotic azithromycin is used long-term. Inhaled hypertonic saline and salbutamol may also be useful. Lung transplantation may be an option if lung function continues to worsen. Pancreatic enzyme replacement and fat-soluble vitamin supplementation are important, especially in the young. Airway clearance techniques such as chest physiotherapy may have some short-term benefit, but long-term effects are unclear. The average life expectancy is between 42 and 50 years in the developed world, with a median of 40.7 years, although improving treatments have contributed to a more optimistic recent assessment of the median in the United States as 59 years. Lung problems are responsible for death in 70% of people with cystic fibrosis.\nCF is most common among people of Northern European ancestry, for whom it affects about 1 out of 3,000 newborns, and among which around 1 out of 25 people is a carrier. It is least common in Africans and Asians, though it does occur in all races. It was first recognized as a specific disease by Dorothy Andersen in 1938, with descriptions that fit the condition occurring at least as far back as 1595. The name \"cystic fibrosis\" refers to the characteristic fibrosis and cysts that form within the pancreas.\nSigns and symptoms.\nCystic fibrosis typically manifests early in life. Newborns and infants with cystic fibrosis tend to have frequent, large, greasy stools (a result of malabsorption) and are underweight for their age. Of newborns, 15\u201320% have their small intestine blocked by meconium, often requiring surgery to correct. Newborns occasionally have neonatal jaundice due to blockage of the bile ducts. Children with cystic fibrosis lose excessive salt in their sweat, and parents often notice salt crystallizing on the skin, or a salty taste when they kiss their child.\nThe primary cause of morbidity and death in people with cystic fibrosis is progressive lung disease, which eventually leads to respiratory failure. This typically begins as a prolonged respiratory infection that continues until treated with antibiotics. Chronic infection of the respiratory tract is nearly universal in people with cystic fibrosis, with \"Pseudomonas aeruginosa\", fungi, and mycobacteria all becoming increasingly common over time. Inflammation of the upper airway results in frequent runny nose and nasal obstruction. Nasal polyps are common, particularly in children and teenagers. As the disease progresses, people tend to have shortness of breath, and a chronic cough that produces sputum. Breathing problems make it increasingly challenging to exercise, and prolonged illness causes those affected to be underweight for their age. In late adolescence or adulthood, people begin to develop severe signs of lung disease: wheezing, digital clubbing, cyanosis, coughing up blood, pulmonary heart disease, and collapsed lung (atelectasis or pneumothorax).\nIn rare cases, cystic fibrosis can manifest itself as a coagulation disorder. Vitamin K is normally absorbed from breast milk, formula, and later, solid foods. This absorption is impaired in some CF patients. Young children are especially sensitive to vitamin K malabsorptive disorders because only a very small amount of vitamin K crosses the placenta, leaving the child with very low reserves and limited ability to absorb vitamin K from dietary sources after birth. Because clotting factors II, VII, IX, and X are vitamin K\u2013dependent, low levels of vitamin K can result in coagulation problems. Consequently, when a child presents with unexplained bruising, a coagulation evaluation may be warranted to determine whether an underlying disease is present.\nLungs and sinuses.\nLung disease results from clogging of the airways due to mucus build-up, decreased mucociliary clearance, and resulting inflammation. In later stages, changes in the architecture of the lung, such as pathology in the major airways (bronchiectasis), further exacerbate difficulties in breathing. Other signs include high blood pressure in the lung (pulmonary hypertension), heart failure, difficulties getting enough oxygen to the body (hypoxia), and respiratory failure requiring support with breathing masks, such as bilevel positive airway pressure machines or ventilators. \"Staphylococcus aureus\", \"Haemophilus influenzae\", and \"Pseudomonas aeruginosa\" are the three most common organisms causing lung infections in CF patients. In addition, opportunistic infection due to \"Burkholderia cepacia\" complex can occur, especially through transmission from patient to patient.\nIn addition to typical bacterial infections, people with CF more commonly develop other types of lung diseases. Among these is allergic bronchopulmonary aspergillosis, in which the body's response to the common fungus \"Aspergillus fumigatus\" causes worsening of breathing problems. Another is infection with \"Mycobacterium avium\" complex, a group of bacteria related to tuberculosis, which can cause lung damage and do not respond to common antibiotics.\nThe mucus in the paranasal sinuses is equally thick and may also cause blockage of the sinus passages, leading to infection. This may cause facial pain, fever, nasal drainage, and headaches. Individuals with CF may develop overgrowth of the nasal tissue (nasal polyps) due to inflammation from chronic sinus infections. Recurrent sinonasal polyps can occur in 10% to 25% of CF patients. These polyps can block the nasal passages and increase breathing difficulties.\nCardiorespiratory complications are the most common causes of death (about 80%) in patients at most CF centers in the United States.\nGastrointestinal.\nDigestive problems are also prevalent in individuals with CF. Approximately 15%-20% of newborns diagnosed with CF experience intestinal blockage (meconium ileus), and other digestive issues may arise due to mucus accumulation in the pancreas. Consequently, there is impaired insulin production, leading to cystic fibrosis-related diabetes mellitus. Moreover, enzyme transport disruption from the pancreas to the intestines results in digestive problems such as recurrent diarrhea or weight loss.\nIn cystic fibrosis, there is impaired chloride secretion due to the mutation of CFTR. This disrupts the ionic balance, causes impaired bicarbonate secretion, and alters the pH. The pancreatic enzymes that work in a specific pH range cannot act as the chyme is not neutralized by bicarbonate ions. This causes impairment of the digestion process.\nThe thick mucus seen in the lungs has a counterpart in thickened secretions from the pancreas, an organ responsible for providing digestive juices that help break down food. These secretions block the exocrine movement of the digestive enzymes into the duodenum and result in irreversible damage to the pancreas, often with painful inflammation (pancreatitis). The pancreatic ducts are totally plugged in more advanced cases, usually seen in older children or adolescents. This causes atrophy of the exocrine glands and progressive fibrosis.\nIn addition, protrusion of internal rectal membranes (rectal prolapse) is more common, occurring in as many as 10% of children with CF, and it is caused by increased fecal volume, malnutrition, and increased intra\u2013abdominal pressure due to coughing.\nIndividuals with CF also have difficulties absorbing the fat-soluble vitamins A, D, E, and K.\nIn addition to the pancreas problems, people with CF experience more heartburn, intestinal blockage by intussusception, and constipation. Older individuals with CF may develop distal intestinal obstruction syndrome, which occurs when feces becomes thick with mucus (inspissated) and can cause bloating, pain, and incomplete or complete bowel obstruction.\nExocrine pancreatic insufficiency occurs in the majority (85\u201390%) of patients with CF. It is mainly associated with \"severe\" CFTR mutations, where both alleles are completely nonfunctional (e.g. \u0394F508/\u0394F508). It occurs in 10\u201315% of patients with one \"severe\" and one \"mild\" CFTR mutation where little CFTR activity still occurs, or where two \"mild\" CFTR mutations exist. In these milder cases, a sufficient pancreatic exocrine function is still present so enzyme supplementation is not required. Usually, no other GI complications occur in pancreas-sufficient phenotypes, and in general, such individuals usually have excellent growth and development. Despite this, idiopathic chronic pancreatitis can occur in a subset of pancreas-sufficient individuals with CF, and is associated with recurrent abdominal pain and life-threatening complications.\nLiver diseases are another common complication in CF patients. The prevalence in studies ranged from 18% at age two to 41% at age 12, with no significant increase thereafter. Another study found that males with CF are more prone to liver diseases compared to females, and those with meconium ileus have an increased risk of liver diseases.\nThickened secretions also may cause liver problems in patients with CF. Bile secreted by the liver to aid in digestion may block the bile ducts, leading to liver damage. Impaired digestion or absorption of lipids can result in steatorrhea. Over time, this can lead to scarring and nodularity (cirrhosis). The liver fails to rid the blood of toxins and does not make important proteins, such as those responsible for blood clotting. Liver disease is the third-most common cause of death associated with CF.\nAround 5\u20137% of people experience liver damage severe enough to cause symptoms: typically gallstones causing biliary colic.\nEndocrine.\nThe pancreas contains the islets of Langerhans, which are responsible for making insulin, a hormone that helps regulate blood glucose. Damage to the pancreas can lead to loss of the islet cells, leading to a type of diabetes unique to those with the disease. This cystic fibrosis-related diabetes shares characteristics of type 1 and type 2 diabetes, and is one of the principal nonpulmonary complications of CF.\nVitamin D is involved in calcium and phosphate regulation. Poor uptake of vitamin D from the diet because of malabsorption can lead to the bone disease osteoporosis in which weakened bones are more susceptible to fractures.\nInfertility.\nInfertility affects both men and women. At least 97% of men with cystic fibrosis are infertile, but not sterile, and can have children with assisted reproductive techniques. The main cause of infertility in men with cystic fibrosis is congenital absence of the vas deferens (which normally connects the testes to the ejaculatory ducts of the penis), but potentially also by other mechanisms causing no sperm, abnormally shaped sperm, and few sperm with poor motility. Many men found to have congenital absence of the vas deferens during evaluation for infertility have a mild, previously undiagnosed form of CF. While females with CF are generally fertile, around 20% of women with CF have fertility difficulties due to thickened cervical mucus or malnutrition. In severe cases, malnutrition disrupts ovulation and causes a lack of menstruation.\nCauses.\nCF is caused by having no functional copies (alleles) of the gene cystic fibrosis transmembrane conductance regulator (\"CFTR\"). As of 2018, over 1,900 mutations leading to CF have been described, but only 5 of them have a frequency greater than 1% among patients. The most common mutant allele, \u0394F508 (also termed F508del), is a deletion (\u0394 signifying deletion) of three nucleotides that results in a loss of the amino-acid residue phenylalanine (F) at the 508th position of the protein. This mutant allele is already present in 1 in 20 to 25 people of Northern European ancestry; it accounts for 70% of CF cases worldwide and 90% of cases in the United States; however, over 700 other mutant alleles, some of which represent new mutations, can produce CF. Although most people have two working copies (alleles) of the \"CFTR\" gene, only one is needed to prevent cystic fibrosis. CF develops when neither allele can produce a functional CFTR protein. Thus, CF is considered an autosomal recessive disease.\nThe \"CFTR\" gene, found at the q31.2 locus of chromosome 7, is 230,000 base pairs long, and encodes a protein that is 1,480 amino acids long. More specifically, the location is between base pair 117,120,016 and 117,308,718 on the long arm of chromosome 7, region 3, band 1, subband 2, represented as 7q31.2. Structurally, the \"CFTR\" is a type of gene known as an ABC gene. The product of this gene (the CFTR protein) is a chloride ion channel important in creating sweat, digestive juices, and mucus. This protein possesses two ATP-hydrolyzing domains, which allows the protein to use energy in the form of ATP. It also contains two domains comprising six alpha helices apiece, which allow the protein to cross the cell membrane. A regulatory binding site on the protein allows activation by phosphorylation, mainly by cAMP-dependent protein kinase. The carboxyl terminal of the protein is anchored to the cytoskeleton by a PDZ domain interaction. Most CFTR in lung passages is produced by rare ion-transporting cells that regulate mucus properties.\nIn addition, the evidence is increasing that genetic modifiers besides \"CFTR\" modulate the frequency and severity of the disease. One example is mannan-binding lectin, which is involved in innate immunity by facilitating phagocytosis of microorganisms. Polymorphisms in one or both mannan-binding lectin alleles that result in lower circulating levels of the protein are associated with a threefold higher risk of end-stage lung disease, as well as an increased burden of chronic bacterial infections.\nCarriers.\nUp to one in 25 individuals of Northern European ancestry is considered a genetic carrier. The disease appears only when two of these carriers have children, as each pregnancy between them has a 25% chance of producing a child with the disease. Although only about one of every 3,000 newborns of the affected ancestry has CF, since the CFTR gene's discovery in 1989, over 2,000 variants have been identified, but only about 700 of these have been recognized as responsible for causing CF. Current tests look for the most common mutations.\nThe mutant alleles screened by the test vary according to a person's ethnic group or by the occurrence of CF already in the family. More than 10 million Americans, including one in 25 white Americans, are carriers of one mutant allele of the CF gene. CF is present in other races, though not as frequently as in white individuals. About one in 46 Hispanic Americans, one in 65 African Americans, and one in 90 Asian Americans carry a mutation of the CF gene.\nPathophysiology.\nThe \"CFTR\" gene regulates the transport of salts and water through cell membranes, providing instructions for creating a pathway that allows the passage of chloride ions. A mutation in the CFTR gene can impair the normal function of chloride channels, leading to abnormal transport of chloride ions and water, resulting in the formation of thick and abnormal mucus.\nIn the pancreatic duct, chloride transport occurs through the voltage-gated chloride channels influenced by CFTR (Cystic Fibrosis transmembrane conductance regulator). These channels are localised in the apical membrane of epithelial cells in the pancreatic duct.\nSeveral mutations in the \"CFTR\" gene can occur, and different mutations cause different defects in the CFTR protein, sometimes causing a milder or more severe disease. These protein defects are also targets for drugs which can sometimes restore their function. \u0394F508-CFTR gene mutation, which occurs in &gt;90% of patients in the U.S., creates a protein that does not fold normally and is not appropriately transported to the cell membrane, resulting in its degradation.\nOther mutations result in proteins that are too short (truncated) because production is ended prematurely. Other mutations produce proteins that do not use energy (in the form of ATP) normally, do not allow chloride, iodide, and thiocyanate to cross the membrane appropriately, and degrade faster than normal. Mutations may also lead to fewer copies of the CFTR protein being produced.\nThe protein created by this gene is anchored to the outer membrane of cells in the sweat glands, lungs, pancreas, and all other remaining exocrine glands in the body.\nThe protein spans this membrane and acts as a channel connecting the inner part of the cell (cytoplasm) to the surrounding fluid. This channel is primarily responsible for controlling the movement of halide anions from inside to outside of the cell; however, in the sweat ducts, it facilitates the movement of chloride from the sweat duct into the cytoplasm. When the CFTR protein does not resorb ions in sweat ducts, chloride, and thiocyanate released from sweat glands are trapped inside the ducts and pumped to the skin.\nAdditionally, hypothiocyanite (OSCN\u2212) cannot be produced by the immune defense system. Because chloride is negatively charged, this modifies the electrical potential inside and outside the cell that normally causes cations to cross into the cell. Sodium is the most common cation in the extracellular space. The excess chloride within sweat ducts prevents sodium resorption by epithelial sodium channels and the combination of sodium and chloride creates the salt, which is lost in high amounts in the sweat of individuals with CF. This lost salt forms the basis for the sweat test.\nMost of the damage in CF is due to blockage of the narrow passages of affected organs with thickened secretions. These blockages lead to remodeling and infection in the lung, damage by accumulated digestive enzymes in the pancreas, blockage of the intestines by thick feces, etc. Several theories have been posited on how the defects in the protein and cellular function cause the clinical effects. The current theory suggests that defective ion transport leads to dehydration in the airway epithelia, thickening mucus. In airway epithelial cells, the cilia exist in between the cell's apical surface and mucus in a layer known as airway surface liquid (ASL). The flow of ions from the cell and into this layer is determined by ion channels such as CFTR. CFTR allows chloride ions to be drawn from the cell and into the ASL, but it also regulates another channel called ENac, which allows sodium ions to leave the ASL and enter the respiratory epithelium. CFTR normally inhibits this channel, but if the CFTR is defective, then sodium flows freely from the ASL and into the cell.\nAs water follows sodium, the depth of ASL will be depleted and the cilia will be left in the mucous layer. As cilia cannot effectively move in a thick, viscous environment, mucociliary clearance is deficient and a buildup of mucus occurs, clogging small airways. The accumulation of more viscous, nutrient-rich mucus in the lungs allows bacteria to hide from the body's immune system, causing repeated respiratory infections.\nThe presence of the same CFTR proteins causes mucous plugging and obstruction pathologies in other organs. In the pancreas, obstruction of the pancreatic duct inhibits secretion of bicarbonate and pancreatic enzymes into the duodenum. The pH of chyme entering the small intestine is not effectively neutralized, degrading what pancreatic enzymes do reach the intestines. Fat in the chyme goes unprocessed, and poor absorption of fat-soluble vitamins results. Obstruction of the biliary tract results in gallstones for up to 15% of CF patients. Increased pressure in the hepatic portal vein can lead to splenomegaly. Increased fluid absorption in the intestinal tract leads to constipation and, in infants, meconium ileus. In sweat glands, the flow of chloride through CFTR channels is reversed compared to other affected organs. In CF, chloride cannot be absorbed back into the body through sweat gland tissues, causing a buildup of chloride in sweat, salty skin, fluid loss, and in severe cases, hyponatremic dehydration.\nChronic infections.\nThe lungs of individuals with cystic fibrosis are colonized and infected by bacteria from an early age. These bacteria, which often spread among individuals with CF, thrive in the altered mucus, which collects in the small airways of the lungs. This mucus leads to the formation of bacterial microenvironments known as biofilms that are difficult for immune cells and antibiotics to penetrate. Viscous secretions and persistent respiratory infections repeatedly damage the lungs by gradually remodeling the airways, which makes infection even more difficult to eradicate. The natural history of CF lung infections and airway remodeling is poorly understood, largely due to the immense spatial and temporal heterogeneity both within and between the microbiomes of CF patients.\nOver time, the types of bacteria and their characteristics change in individuals with CF. In the initial stage, common bacteria such as \"S.\u00a0aureus\" and \"H.\u00a0influenzae\" colonize and infect the lungs. Eventually, \"Pseudomonas aeruginosa\" (and sometimes \"Burkholderia cepacia\") dominates. By 18 years of age, 80% of patients with classic CF harbor \"P.\u00a0aeruginosa\", and 3.5% harbor \"B.\u00a0cepacia\". Once within the lungs, these bacteria adapt to the environment and develop resistance to commonly used antibiotics. \"Pseudomonas\" can develop special characteristics that allow the formation of large colonies, known as \"mucoid\" \"Pseudomonas\", which are rarely seen in people who do not have CF. Scientific evidence suggests the interleukin 17 pathway plays a key role in resistance and modulation of the inflammatory response during \"P.\u00a0aeruginosa\" infection in CF. In particular, interleukin 17-mediated immunity plays a double-edged activity during chronic airways infection; on one side, it contributes to the control of \"P.\u00a0aeruginosa\" burden, while on the other, it propagates exacerbated pulmonary neutrophilia and tissue remodeling.\nInfection can spread by passing between different individuals with CF. In the past, people with CF often participated in summer \"CF camps\" and other recreational gatherings. Hospitals grouped patients with CF into common areas and routine equipment (such as nebulizers) was not sterilized between individual patients. This led to the transmission of more dangerous strains of bacteria among groups of patients. As a result, individuals with CF are now routinely isolated from one another in the healthcare setting, and healthcare providers are encouraged to wear gowns and gloves when examining patients with CF to limit the spread of virulent bacterial strains.\nCF patients may also have their airways chronically colonized by filamentous fungi (such as \"Aspergillus fumigatus\", \"Scedosporium apiospermum\", \"Aspergillus terreus\") and/or yeasts (such as \"Candida albicans\"); other filamentous fungi less commonly isolated include \"Aspergillus flavus\" and \"Aspergillus nidulans\" (occur transiently in CF respiratory secretions) and \"Exophiala dermatitidis\" and \"Scedosporium prolificans\" (chronic airway-colonizers); some filamentous fungi such as \"Penicillium emersonii\" and \"Acrophialophora fusispora\" are encountered in patients almost exclusively in the context of CF. Defective mucociliary clearance characterizing CF is associated with local immunological disorders. In addition, prolonged therapy with antibiotics and corticosteroid treatments may also facilitate fungal growth. Although the clinical relevance of the fungal airway colonization is still a matter of debate, filamentous fungi may contribute to the local inflammatory response and therefore to the progressive deterioration of the lung function, as often happens with allergic bronchopulmonary aspergillosis\"\u00a0\"\u2013 the most common fungal disease in the context of CF, involving a Th2-driven immune response to \"Aspergillus\" species.\nDiagnosis.\nDiagnosis of CF is initially based on clinical findings indicative of respiratory diseases, various digestive problems, meconium ileus, and more. Definitive diagnosis may involve genetic testing based on family history or chloride concentration testing in sweat, which is relatively high (&gt;60mEq/L) in individuals with CF.\nIn many localities all newborns are screened for cystic fibrosis within the first few days of life, typically by blood test for high levels of immunoreactive trypsinogen. Newborns with positive tests or those who are otherwise suspected of having cystic fibrosis based on symptoms or family history, then undergo a sweat test. An electric current is used to drive pilocarpine into the skin, stimulating sweating. The sweat is collected and analyzed for salt levels. Having unusually high levels of chloride in the sweat suggests CFTR is dysfunctional; the person is then diagnosed with cystic fibrosis. Genetic testing is also available to identify the CFTR mutations typically associated with cystic fibrosis. Many laboratories can test for the 30\u201396 most common CFTR mutations, which can identify over 90% of people with cystic fibrosis.\nPeople with CF have less thiocyanate and hypothiocyanite in their saliva and mucus (Banfi et al.). In the case of milder forms of CF, transepithelial potential difference measurements can be helpful. CF can also be diagnosed by the identification of mutations in the CFTR gene.\nIn many cases, a parent makes the diagnosis because the infant tastes salty. Immunoreactive trypsinogen levels can be increased in individuals who have a single mutated copy of the \"CFTR\" gene (carriers) or, in rare instances, in individuals with two normal copies of the \"CFTR\" gene. Due to these false positives, CF screening in newborns can be controversial.\nBy 2010 every US state had instituted newborn screening programs and as of 2016[ [update]] 21 European countries had programs in at least some regions.\nPrenatal.\nWomen who are pregnant or couples planning a pregnancy can have themselves tested for the \"CFTR\" gene mutations to determine the risk that their child will be born with CF. Testing is typically performed first on one or both parents and, if the risk of CF is high, testing on the fetus is performed. The American College of Obstetricians and Gynecologists recommends all people thinking of becoming pregnant be tested to see if they are a carrier.\nBecause the development of CF in the fetus requires each parent to pass on a mutated copy of the \"CFTR\" gene and because CF testing is expensive, testing is often performed initially on one parent. If testing shows that the parent is a \"CFTR\" gene mutation carrier, the other parent is tested to calculate the risk that their children will have CF. CF can result from more than a thousand different mutations. As of 2016[ [update]], typically only the most common mutations are tested for, such as \u0394F508. Most commercially available tests look for 32 or fewer different mutations. If a family has a known uncommon mutation, specific screening for that mutation can be performed. Because not all known mutations are found on current tests, a negative screen does not guarantee that a child will not have CF.\nDuring pregnancy, testing can be performed on the placenta (chorionic villus sampling) or the fluid around the fetus (amniocentesis). However, chorionic villus sampling has a risk of fetal death of one in 100 and amniocentesis of one in 200; a recent study has indicated this may be much lower, about one in 1,600.\nEconomically, for carrier couples of cystic fibrosis, when comparing preimplantation genetic diagnosis (PGD) with natural conception (NC) followed by prenatal testing and abortion of affected pregnancies, PGD provides net economic benefits up to a maternal age around 40 years, after which NC, prenatal testing, and abortion have a higher economic benefit.\nManagement.\nTreatment for CF is diverse, tailored to different symptoms, and includes various devices, inhalation medications to alleviate respiratory difficulties, oral enzyme supplements to address exocrine pancreatic insufficiency, and, in some cases, surgical interventions for conditions such as meconium ileus. While treatment alleviates symptoms and prevents potential complications, there is currently no cure for the disease.\nThe management of CF has improved significantly over the past 70 years. While infants born with it 70 years ago would have been unlikely to live beyond their first year, infants today are likely to live well into adulthood. Advances in the treatment of cystic fibrosis have meant that people with cystic fibrosis can live a fuller life less encumbered by their condition. The cornerstones of management are the proactive treatment of airway infection, encouragement of good nutrition, and an active lifestyle. Pulmonary rehabilitation as a management of CF continues throughout a person's life, and is aimed at maximizing organ function, and therefore the quality of life. Occupational therapists use energy conservation techniques in the rehabilitation process for patients with cystic fibrosis. Examples of energy conservation techniques are ergonomic principles, pursed lip breathing, and diaphragmatic breathing. People with CF tend to have fatigue and dyspnoea due to chronic pulmonary infections, so reducing the amount of energy spent during activities can help people feel better and gain more independence. At best, current treatments delay the decline in organ function. Because of the wide variation in disease symptoms, treatment typically occurs at specialist multidisciplinary centers and is tailored to the individual. Targets for therapy are the lungs, gastrointestinal tract (including pancreatic enzyme supplements), the reproductive organs (including assisted reproductive technology), and psychological support.\nThe most consistent aspect of therapy in CF is limiting and treating the lung damage caused by thick mucus and infection, with the goal of maintaining quality of life. Intravenous, inhaled, and oral antibiotics are used to treat chronic and acute infections. Mechanical devices and inhalation medications are used to alter and clear the thickened mucus. These therapies, while effective, can be extremely time-consuming. Oxygen therapy at home is recommended in those with significantly low oxygen levels. Many people with CF use probiotics, which are thought to be able to correct intestinal dysbiosis and inflammation, but the clinical trial evidence regarding the effectiveness of probiotics for reducing pulmonary exacerbations in people with CF is uncertain.\nAntibiotics.\nMany people with CF are on one or more antibiotics at all times, even when healthy, to prophylactically suppress infection. The choice of antibiotics for cystic fibrosis depends on the specific bacteria that are causing the infection, as well as the patient's age, weight, and other medical conditions. Antibiotics are necessary whenever pneumonia is suspected or a noticeable decline in lung function is seen, and are usually chosen based on the results of a sputum analysis and the person's past response. This prolonged therapy often necessitates hospitalization and insertion of a more permanent IV such as a peripherally inserted central catheter or Port-a-Cath. Inhaled therapy with antibiotics such as tobramycin, colistin, and aztreonam is often given for months at a time to improve lung function by impeding the growth of colonized bacteria. Inhaled antibiotic therapy helps lung function by fighting infection, but also has significant drawbacks such as development of antibiotic resistance, tinnitus, and changes in the voice. Inhaled levofloxacin may be used to treat \"Pseudomonas aeruginosa\" in people with cystic fibrosis who are infected.\nAntibiotics by mouth such as ciprofloxacin or azithromycin are given to help prevent infection or to control ongoing infection. The aminoglycoside antibiotics (e.g. tobramycin) used can cause hearing loss, damage to the balance system in the inner ear or kidney failure with long-term use. To prevent these side-effects, the amount of antibiotics in the blood is routinely measured and adjusted accordingly.\nCurrently, no reliable clinical trial evidence shows the effectiveness of antibiotics for pulmonary exacerbations in people with cystic fibrosis and \"Burkholderia cepacia\" complex or for the use of antibiotics to treat nontuberculous mycobacteria in people with CF.\n\"Pseudomonas aeruginosa\".\nThe early management of \"Pseudomonas aeruginosa\" infection is usually suggested using nebulised antibiotics with or without oral antibiotics to remove the bacteria from the person's airways for some time. When choosing antibiotics to treat lung infections caused by \"Pseudomonas aeruginosa\" in people with cystic fibrosis, it is still unclear whether the choice of antibiotics should be based on the results of testing antibiotics separately (one at a time) or in combination with each other. It is also unclear if these treatment approaches for the \"Pseudomonas aeruginosa\" infection improve the person's quality of life or lifespan. The negative side effects of antibiotics for this infection are also poorly studied. Intravenous antibiotic therapy to treat \"Pseudomonas aeruginosa\" infections is not any better than antibiotics taken orally.\nMethicillin-resistant \"Staphylococcus aureus\".\nMethicillin-resistant \"Staphylococcus aureus\" (MRSA) infections can be dangerous for people with cystic fibrosis and can worsen lung damage leading to more rapid decline. Early antibiotic treatment is standard; however, further research is needed to determine longer-term effects and benefits (3\u20136 months after the treatment or longer) and survival rates associated with different treatment options.\nAntibiotic adjuvant therapy.\nFactors related to antibiotic use, the chronicity of the disease, and the emergence of resistant bacteria demand more exploration for different strategies such as antibiotic adjuvant therapy. Antibiotic adjuvant therapy refers to therapeutic approaches that aim to improve the action of antibiotics such a pharmaceutical agents or supplements that impact the virulence of the bacterium or that change the susceptibility of the organism to the antibiotic so that the antibiotics are more effective. There is no strong evidence to recommend specific antibiotic adjuvant therapies such as \u03b2-carotene, nitric oxide, zinc supplements, or KB001-A.\nOther medication.\nAerosolized medications that help loosen secretions include dornase alfa and hypertonic saline. Dornase alfa is a recombinant human deoxyribonuclease, which breaks down DNA in the sputum, thus decreasing its viscosity. Dornase alfa may improve lung function; however, there is no strong evidence that it is better than other hyperosmolar therapies.\nDenufosol, an investigational drug, opens an alternative chloride channel, helping to liquefy mucus. Whether inhaled corticosteroids are useful is unclear, but stopping inhaled corticosteroid therapy is safe. There is weak evidence that corticosteroid treatment may cause harm by interfering with growth. Pneumococcal vaccination has not been studied as of 2014[ [update]]. As of 2014[ [update]], there is no clear evidence from randomized controlled trials that the influenza vaccine is beneficial for people with cystic fibrosis.\nIvacaftor is a medication taken by mouth for the treatment of CF due to several specific mutations responsive to ivacaftor-induced CFTR protein enhancement. It improves lung function by about 10%; however, as of 2014[ [update]] it is expensive. The first year it was on the market, the list price was over $300,000 per year in the United States. In July 2015, the U.S. Food and Drug Administration approved lumacaftor/ivacaftor. In 2018, the FDA approved the combination ivacaftor/tezacaftor; the manufacturer announced a list price of $292,000 per year. Tezacaftor helps move the CFTR protein to the correct position on the cell surface, and is designed to treat people with the F508del mutation.\nIn 2019, the combination drug elexacaftor/ivacaftor/tezacaftor, marketed as Trikafta and described as modulator therapy, was approved for CF patients over the age of 12 in the United States, extended to age 6 in 2021. In Europe this drug was approved in 2020 and marketed as Kaftrio. It is used in those who have a f508del mutation, found in about 90% of patients with cystic fibrosis. According to the Cystic Fibrosis Foundation, \"this medicine represents the single greatest therapeutic advancement in the history of CF, offering a treatment for the underlying cause of the disease that could eventually bring modulator therapy to 90 percent of people with CF.\" In a clinical trial, participants who were administered the combination drug experienced a subsequent 63% decrease in pulmonary exacerbations and a 41.8\u00a0mmol/L decrease in sweat chloride concentration. By mitigating a repertoire of symptoms associated with cystic fibrosis, the combination drug significantly improved quality-of-life metrics among patients with the disease as well. The combination drug is also known to interact with CYP3A inducers, such as carbamazepine used in the treatment of bipolar disorder, causing elexacaftor/ivacaftor/tezacaftor to circulate in the body at decreased concentrations. As such, concurrent use is not recommended. The list price in the US is going to be $311,000 per year; however, insurance may cover much of the cost of the drug.\nUrsodeoxycholic acid, a bile salt, has been used; however, a 2021 study aimed at evaluating whether the incidence of severe liver disease differed between CF centers routinely prescribing or not prescribing UDCA found no reduction in portal hypertension.\nThe combination vanzacaftor/tezacaftor/deutivacaftor (Alyftrek) was approved for medical use in the United States in December 2024.\nNutrient supplementation.\nIt is uncertain whether vitamin A or beta-carotene supplementation has any effect on eye and skin problems caused by vitamin A deficiency.\nThere is no strong evidence that people with cystic fibrosis can prevent osteoporosis by increasing their intake of vitamin D.\nFor people with vitamin E deficiency and cystic fibrosis, there is evidence that vitamin E supplementation may improve vitamin E levels, although it is still uncertain what effect supplementation has on vitamin E-specific deficiency disorders or on lung function.\nRobust evidence regarding the effects of vitamin K supplementation in people with cystic fibrosis is lacking as of 2020.\nVarious studies have examined the effects of omega-3 fatty acid supplementation for people with cystic fibrosis but the evidence is uncertain whether it has any benefits or adverse effects.\nProcedures.\nSeveral mechanical techniques are used to dislodge sputum and encourage its expectoration. One technique good for short-term airway clearance is chest physiotherapy where a respiratory therapist percusses an individual's chest by hand several times a day, to loosen up secretions. This \"percussive effect\" can be administered also through specific devices that use chest wall oscillation or intrapulmonary percussive ventilator. Other methods such as biphasic cuirass ventilation, and associated clearance mode available in such devices, integrate a cough assistance phase, as well as a vibration phase for dislodging secretions. These are portable and adapted for home use.\nAnother technique is positive expiratory pressure physiotherapy which consists of providing back pressure to the airways during expiration. This effect is provided by devices that consist of a mask or a mouthpiece in which resistance is applied only during the expiration phase. Operating principles of this technique seem to be the increase of gas pressure behind mucus through collateral ventilation along with a temporary increase in functional residual capacity preventing the early collapse of small airways during exhalation.\nAs lung disease worsens, mechanical breathing support may become necessary. Individuals with CF may need to wear special masks at night to help push air into their lungs. These machines, known as bilevel positive airway pressure (BiPAP) ventilators, help prevent low blood oxygen levels during sleep. Non-invasive ventilators may be used during physical therapy to improve sputum clearance. It is not known if this type of therapy has an impact on pulmonary exacerbations or disease progression. It is unknown what role non-invasive ventilation therapy has in improving exercise capacity in people with cystic fibrosis. However, the authors noted that \"non-invasive ventilation may be a useful adjunct to other airway clearance techniques, particularly in people with cystic fibrosis who have difficulty expectorating sputum\". During severe illness, a tube may be placed in the throat (a procedure known as a tracheostomy) to enable breathing supported by a ventilator.\nFor children, preliminary studies show massage therapy may help people and their families' quality of life.\nSome lung infections require surgical removal of the infected part of the lung. If this is necessary many times, lung function is severely reduced. The most effective treatment options for people with CF who have spontaneous or recurrent pneumothoraces is not clear.\nTransplantation.\nLung transplantation may become necessary for individuals with CF as lung function and exercise tolerance decline. Although single lung transplantation is possible in other diseases, individuals with CF must have both lungs replaced because the remaining lung might contain bacteria that could infect the transplanted lung. A pancreatic or liver transplant may be performed at the same time to alleviate liver disease and/or diabetes. Lung transplantation is considered when lung function declines to the point where assistance from mechanical devices is required or survival is threatened. According to \"Merck Manual\", \"bilateral lung transplantation for severe lung disease is becoming more routine and more successful with experience and improved techniques. Among adults with CF, median survival posttransplant is about 9 years.\"\nOther aspects.\nNewborns with intestinal obstruction typically require surgery, whereas adults with distal intestinal obstruction syndrome typically do not. Treatment of pancreatic insufficiency by replacement of missing digestive enzymes allows the duodenum to properly absorb nutrients and vitamins that would otherwise be lost in the feces. However, the best dosage and form of pancreatic enzyme replacement are unclear, as are the risks and long-term effectiveness of this treatment.\nSo far, no large-scale research involving the incidence of atherosclerosis and coronary heart disease in adults with cystic fibrosis has been conducted. This is likely because the vast majority of people with cystic fibrosis do not live long enough to develop clinically significant atherosclerosis or coronary heart disease.\nDiabetes is the most common nonpulmonary complication of CF. It mixes features of type 1 and type 2 diabetes and is recognized as a distinct entity, cystic fibrosis-related diabetes. While oral antidiabetic drugs are sometimes used, the recommended treatment is the use of insulin injections or an insulin pump, and, unlike in type 1 and 2 diabetes, dietary restrictions are not recommended. While \"Stenotrophomonas maltophilia\" is relatively common in people with cystic fibrosis, the evidence about the effectiveness of antibiotics for \"S. maltophilia\" is uncertain.\nBisphosphonates taken by mouth or intravenously can be used to improve bone mineral density in people with cystic fibrosis, but there is no proof that this reduces fractures or increases survival rates. When taking bisphosphates intravenously, adverse effects such as pain and flu-like symptoms can be an issue. The adverse effects of bisphosphates taken by mouth on the gastrointestinal tract are unknown.\nPoor growth may be avoided by insertion of a feeding tube for increasing food energy through supplemental feeds or by administration of injected growth hormone.\nSinus infections are treated by prolonged courses of antibiotics. The development of nasal polyps or other chronic changes within the nasal passages may severely limit airflow through the nose, and over time reduce the person's sense of smell. Sinus surgery is often used to alleviate nasal obstruction and to limit further infections. Nasal steroids such as fluticasone propionate are used to decrease nasal inflammation.\nFemale infertility may be overcome by assisted reproduction technology, particularly embryo transfer techniques. Male infertility caused by the absence of the vas deferens may be overcome with testicular sperm extraction, collecting sperm cells directly from the testicles. If the collected sample contains too few sperm cells to likely have spontaneous fertilization, intracytoplasmic sperm injection can be performed. Third party reproduction is also a possibility for women with CF. Whether taking antioxidants affects outcomes is unclear.\nPhysical exercise is usually part of outpatient care for people with cystic fibrosis. Aerobic exercise seems to be beneficial for aerobic exercise capacity, lung function, and health-related quality of life; however, the quality of the evidence was poor.\nDue to the use of aminoglycoside antibiotics, ototoxicity is common. Symptoms may include \"tinnitus, hearing loss, hyperacusis, aural fullness, dizziness, and vertigo\".\nGastrointestinal.\nProblems with the gastrointestinal system including constipation and obstruction of the gastrointestinal tract including distal intestinal obstruction syndrome are frequent complications for people with cystic fibrosis. Treatment of gastrointestinal problems is required in order to prevent a complete obstruction, reduce other CF symptoms, and improve the quality of life. While stool softeners, laxatives, and prokinetics (GI-focused treatments) are often suggested, there is no clear consensus from experts as to which approach is the best and comes with the least risks. Mucolytics or systemic treatments aimed at dysfunctional CFTR are also sometimes suggested to improve symptoms. The evidence supporting these recommendations is very weak and more research is needed to understand how to prevent and treat GI problems in people with CF. In addition, there is a risk of gastrointestinal malignancy, especially in the transplanted patient, and screening procedures may be considered at an earlier age.\nPrognosis.\nThe prognosis for cystic fibrosis has improved due to earlier diagnosis through screening and better treatment and access to health care. In 1959, the median age of survival of children with CF in the United States was six months.\nIn 2010, survival is estimated to be 37 years for women and 40 for men. In Canada, median survival increased from 24 years in 1982 to 47.7 in 2007. In the United States those born with CF in 2016 have a predicted life expectancy of 47.7 when cared for in specialty clinics. Due to the recent development of new treatments, such as CFTR modulators, life expectancy has increased rapidly during recent years. In 2020 the median predicted life expectancy was around 59 years, although there are uncertainties in the estimates due to the low number of annual deaths for persons with cystic fibrosis.\nIn the US, of those with CF who are more than 18 years old as of 2009, 92% had graduated from high school, 67% had at least some college education, 46% were in full-time or part-time employment, 56% were single, and 39% were married or living with a partner.\nQuality of life.\nChronic illnesses can be difficult to manage. CF is a chronic illness that affects the \"digestive and respiratory tracts resulting in generalized malnutrition and chronic respiratory infections.\" The thick secretions clog the airways in the lungs, which often cause inflammation and severe lung infections. If it is compromised, it affects the quality of life of someone with CF and their ability to complete activities of daily living (ADLs).\nAccording to Schmitz and Goldbeck (2006), CF significantly increases emotional stress on both the individual and the family, \"and the necessary time-consuming daily treatment routine may have further negative effects on quality of life\". However, Havermans and colleagues (2006) have established that young outpatients with CF who have participated in the Cystic Fibrosis Questionnaire-Revised \"rated some quality of life domains higher than did their parents\". Consequently, outpatients with CF have a more positive outlook for themselves. As Merck Manual notes, \"with appropriate support, most patients can make an age-appropriate adjustment at home and school. Despite myriad problems, the educational, occupational, and marital successes of patients are impressive.\"\nFurthermore, there are many ways to enhance the quality of life in CF patients. Exercise is promoted to increase lung function. Integrating an exercise regimen into the CF patient's daily routine can significantly improve quality of life. No definitive cure for CF is known, but diverse medications are used, such as mucolytics, bronchodilators, steroids, and antibiotics, that have the purpose of loosening mucus, expanding airways, decreasing inflammation, and fighting lung infections, respectively.\nEpidemiology.\nCystic fibrosis is the most common life-limiting autosomal recessive disease among people of European heritage. In the United States, about 30,000 individuals have CF; most are diagnosed by six months of age. In Canada, about 4,000 people have CF. Around 1 in 25 people of European descent, and one in 30 of white Americans, is a carrier of a CF mutation. Although CF is less common in these groups, roughly one in 46 Hispanics, one in 65 Africans, and one in 90 Asians carry at least one abnormal \"CFTR\" gene. Ireland has the world's highest prevalence of CF, at one in 1353; Japan's prevalence of CF is among the lowest in the world, at one in 350,000.\nAlthough technically a rare disease, CF is ranked as one of the most widespread life-shortening genetic diseases. It is most common among nations in the Western world. An exception is Finland, where only one in 80 people carries a CF mutation. The World Health Organization states, \"In the European Union, one in 2000\u20133000 newborns is found to be affected by CF\". In the United States, one in 3,500 children is born with CF. In 1997, about one in 3,300 white children in the United States was born with CF. In contrast, only one in 15,000 African American children have it, and in Asian Americans, the rate was even lower at one in 32,000.\nCystic fibrosis is diagnosed equally in males and females. For reasons that remain unclear, data have shown that males tend to have a longer life expectancy than females, though recent studies suggest this gender gap may no longer exist, perhaps due to improvements in health care facilities. A recent study from Ireland identified a link between the female hormone estrogen and worse outcomes in CF.\nThe distribution of CF alleles varies among populations. The frequency of \u0394F508 carriers has been estimated at one in 200 in northern Sweden, one in 143 in Lithuanians, and one in 38 in Denmark. No \u0394F508 carriers were found among 171 Finns and 151 Saami people. \u0394F508 does occur in Finland, but it is a minority allele there. CF is known to occur in only 20 families (pedigrees) in Finland.\nEvolution.\nThe \u0394F508 mutation is estimated to have occurred up to 52,000 years ago. Numerous hypotheses have been advanced as to why such a lethal allele has persisted and spread in the human population. Other common autosomal recessive diseases such as sickle-cell anemia have been found to protect carriers from other diseases, an evolutionary trade-off known as heterozygote advantage. Resistance to the following have all been proposed as possible sources of heterozygote advantage:\nHistory.\nCF is supposed to have appeared about 3,000 BC because of the migration of people, gene mutations, and new conditions in nourishment. Although the entire clinical spectrum of CF was not recognized until the 1930s, certain aspects of CF were identified much earlier. Indeed, literature from Germany and Switzerland in the 18th century warned (\"Woe to the child who tastes salty from a kiss on the forehead, for he is bewitched and soon must die\"), recognizing the association between the salt loss in CF and illness.\nIn the 19th century, Carl von Rokitansky described a case of fetal death with meconium peritonitis, a complication of meconium ileus associated with CF. Meconium ileus was first described in 1905 by Karl Landsteiner. In 1936, Guido Fanconi described a connection between celiac disease, cystic fibrosis of the pancreas, and bronchiectasis.\nIn 1938, Dorothy Hansine Andersen published an article, \"Cystic Fibrosis of the Pancreas and Its Relation to Celiac Disease: a Clinical and Pathological Study\", in the \"American Journal of Diseases of Children\". She was the first to describe the characteristic cystic fibrosis of the pancreas and to correlate it with the lung and intestinal disease prominent in CF. She also first hypothesized that CF was a recessive disease and first used pancreatic enzyme replacement to treat affected children. In 1952, Paul di Sant'Agnese discovered abnormalities in sweat electrolytes; a sweat test was developed and improved over the next decade.\nThe first linkage between CF and another marker (paraoxonase) was found in 1985 by Hans Eiberg, indicating that only one locus exists for CF. In 1988, the first mutation for CF, \u0394F508, was discovered by Francis Collins, Lap-Chee Tsui, and John R. Riordan on the seventh chromosome. Subsequent research has found over 1,000 different mutations that cause CF.\nBecause mutations in the \"CFTR\" gene are typically small, classical genetics techniques have been unable to accurately pinpoint the mutated gene. Using protein markers, gene-linkage studies were able to map the mutation to chromosome 7. Chromosome walking and chromosome jumping techniques were then used to identify and sequence the gene. In 1989, Lap-Chee Tsui led a team of researchers at the Hospital for Sick Children in Toronto that discovered the gene responsible for CF. CF represents a classic example of how a human genetic disorder was elucidated strictly by the process of forward genetics.\nResearch.\nPeople with CF may be listed in a disease registry that allows researchers and doctors to track health results and identify candidates for clinical trials.\nGene therapy.\nGene therapy has been explored as a potential cure for CF. Results from clinical trials have shown limited success as of 2016[ [update]], and using gene therapy as routine therapy is not suggested. A small study published in 2015 found a small benefit.\nThe focus of much CF gene therapy research is aimed at trying to place a normal copy of the \"CFTR\" gene into affected cells. Transferring the normal \"CFTR\" gene into the affected epithelial cells would result in the production of functional CFTR protein in all target cells, without adverse reactions or an inflammation response; this is known as somatic cell therapy. To prevent the lung manifestations of CF, only 5\u201310% of the normal amount of CFTR gene expression is needed. Multiple approaches have been tested for gene transfer, such as liposomes and viral vectors in animal models and clinical trials. However, both methods were found to be relatively inefficient treatment options, mainly because very few cells take up the vector and express the gene, so the treatment has little effect. Additionally, problems have been noted in cDNA recombination, such that the gene introduced by the treatment is rendered unusable. There has been a functional repair in culture of CFTR by CRISPR/Cas9 in intestinal stem cell organoids of cystic fibrosis patients.\nBacteriophage therapy.\nBacteriophage therapy (phage therapy) is being studied for multidrug-resistant bacteria in people with CF. Bacteriophage therapy is a treatment method that uses viruses, known as bacteriophages, to target and destroy harmful bacteria in the body. Unlike antibiotics, which can kill a wide range of bacteria and potentially disrupt the body's normal flora, phage therapy is highly specific, targeting only the harmful bacteria while leaving the beneficial ones unharmed. As such, bacteriophage therapy is a promising alternative for treating infections caused by multidrug-resistant bacteria, such as Staphylococcus aureus, Haemophilus influenzae, and Pseudomonas aeruginosa in CF patients, which are often protected by biofilms and thus resistant to conventional antibiotics.\nBacteriophage therapy uses viruses as antimicrobial agents to overcome the antibiotic resistance in bacteria with biofilms Phage therapy is used to treat the Pseudomonas aeruginosa infection in the lungs, which is frequently seen in cystic fibrosis patients, as these bacteria produce biofilms which give them multi-drug resistance.\nGene modulators.\nSeveral small molecules that aim at compensating various mutations of the \"CFTR\" gene are under development. CFTR modulator therapies has been used instead of other types of genetic therapies. These therapies focus on the expression of a genetic mutation instead of the mutated gene itself. Modulators are split into two classes: potentiators and correctors. Potentiators act on the CFTR ion channels that are embedded in the cell membrane, and these drugs help open up the channel to allow transmembrane flow. Correctors are meant to assist in the transportation of nascent proteins, proteins that are formed by ribosomes before it is morphed into a specific shape, to the cell surface to be implemented into the cell membrane.\nMost target the transcription stage of genetic expression. One approach has been to try and develop medication that get the ribosome to overcome the stop codon and produce a full-length CFTR protein. About 10% of CF results from a premature stop codon in the DNA, leading to early termination of protein synthesis and truncated proteins. These drugs target nonsense mutations such as G542X, which consists of the amino acid glycine in position 542 being replaced by a stop codon. Aminoglycoside antibiotics interfere with protein synthesis and error correction. In some cases, they can cause the cell to overcome a premature stop codon by inserting a random amino acid, thereby allowing the expression of a full-length protein. Future research for these modulators is focused on the cellular targets that can be affected by a change in a gene's expression. Otherwise, genetic therapy will be used as a treatment when modulator therapies do not work given that 10% of people with cystic fibrosis are not affected by these drugs.\nElexacaftor/ivacaftor/tezacaftor was approved in the United States in 2019 for cystic fibrosis. This combination of previously developed medicines can treat up to 90% of people with cystic fibrosis. This medication restores some effectiveness of the CFTR protein so that it can work as an ion channel on the cell's surface.\nEcological therapy.\nIt has previously been shown that inter-species interactions are an important contributor to the pathology of CF lung infections. Examples include the production of antibiotic degrading enzymes such as \u03b2-lactamases and the production of metabolic by-products such as short-chain fatty acids (SCFAs) by anaerobic species, which can enhance the pathogenicity of traditional pathogens such as \"Pseudomonas aeruginosa\". Due to this, it has been suggested that the direct alteration of CF microbial community composition and metabolic function would provide an alternative to traditional antibiotic therapies.\nAntisense therapy.\nAntisense therapy is being researched to treat a subset of mutations that have limited or no response to CFTR modulators. Such mutations fall into two classes: splicing (e.g., c.3718-2477C&gt;T) and nonsense (e.g., G542X, W1282X), both of which result in very low expression of CFTR protein, although the protein itself is usually unaffected. This is contrary to the more common mutations such as \u0394F508 which have normal CFTR expression but in a non-functional form. Modulators serve only to correct these aberrant proteins and are of little to no benefit in the case of insufficient expression. Antisense oligonucleotides (ASOs) can solve this problem through the promotion of mRNA degradation or by changing pre-mRNA splicing, nonsense-mediated mRNA decay, or translation, thus increasing CFTR expression.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50603", "revid": "1387145", "url": "https://en.wikipedia.org/wiki?curid=50603", "title": "Multiple sclerosis", "text": "Disease that damages the myelin sheaths around nerves\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nMultiple sclerosis (MS) is an autoimmune disease resulting in damage to myelin which is the insulating covers of nerve cells in the brain and spinal cord. As a demyelinating disease, MS disrupts the nervous system's ability to transmit signals, resulting in a range of signs and symptoms, including physical, mental, and sometimes psychiatric problems. Symptoms include double vision, vision loss, eye pain, muscle weakness, and loss of sensation or coordination.\nMS takes several forms of presentation:\nWhile its cause is unclear, the underlying mechanism is thought to be due to either destruction by the immune system or inactivation of myelin-producing cells. Proposed causes for this include immune dysregulation, genetics, and environmental factors, such as viral infections. The McDonald criteria are a frequently updated set of guidelines used to establish an MS diagnosis.\nThere is no cure for MS. Current treatments aim to reduce inflammation and resulting symptoms from acute flares and prevent further attacks with disease-modifying medications, aiming at slowing prognosis and improving quality of life. Physical therapy and occupational therapy, along with patient-centered symptom management, can help with people's ability to function. The long-term outcome is difficult to predict; better outcomes are more often seen in women, those who develop the disease early in life, those with a relapsing course, and those who initially experienced few attacks.\nNew evidence suggests an important role of lifestyle factors in the prognosis of MS, where multiple lifestyle factors (including smoking, alcohol consumption, exercise, diet and vitamin D levels) have been linked to affecting the expanded disability status scale (EDSS) score depending on patients' age, gender and disease duration.\nMS is the most common immune-mediated disorder affecting the central nervous system (CNS). In 2020, about 2.8 million people were affected by MS globally, with rates varying widely in different regions and among different populations. The disease usually begins between the ages of 20 and 40 and is almost three times more common in females than in males (3:1 ratio). \nMS was first described in 1868 by French neurologist Jean-Martin Charcot. The name \"multiple sclerosis\" is short for multiple cerebro-spinal sclerosis, which refers to the numerous glial scars (or sclerae \u2013 essentially plaques or lesions) that develop on the white matter of the brain and spinal cord.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nSigns and symptoms.\nMS lesions can affect any part of the central nervous system so a person with MS can have almost any neurological signs or symptoms.\nFatigue is one of the most common symptoms of MS. Roughly 65% of people with MS experience fatigue. Of these, some 15\u201340% report fatigue as their most disabling symptom.\nAutonomic, visual, motor, and sensory problems are also among the most common symptoms.\nThe specific symptoms depend on the locations of the lesions within the nervous system and may include loss of sensitivity or changes in sensation in the limbs, such as tingling, \"pins and needles,\" or numbness; limb motor weakness or pain, blurred vision, pronounced reflexes, muscle spasms, difficulty walking, or with coordination or balance (ataxia); problems with speech or swallowing, visual problems (optic neuritis manifesting as eye pain &amp; vision loss, or nystagmus manifesting as double vision), fatigue, and bladder and bowel difficulties (such as urinary or fecal incontinence or retention), among others. When MS is more advanced, walking difficulties lead to a higher risk of falling.\nDifficulties in thinking and emotional problems such as depression or unstable mood are also common. The primary deficit in cognitive function that people with MS experience is slowed information-processing speed, with memory also commonly affected, and executive function less commonly. Intelligence, language, and semantic memory are usually preserved, and the level of cognitive impairment varies considerably between people with MS.\nUhthoff's phenomenon, a reversible exacerbation of patient symptoms following a rise in body temperature, and Lhermitte's sign, an electrical sensation that runs down the back when flexing the neck, are particularly characteristic of MS, although may not always be present. 60\u201380% of MS patients find that symptoms, such as fatigue, are affected by changes in body temperature. MS may also present with eye movement impairments such as internuclear ophthalmoplegia or sixth nerve palsy.\nMeasures of disability.\nThe main measure of disability and severity is the expanded disability status scale (EDSS), with other measures such as the multiple sclerosis functional composite being increasingly used in research. EDSS is also correlated with falls in people with MS. While it is a popular measure, EDSS has been criticized for some of its limitations, such as overreliance on walking.\nDisease course.\nProdromal phase.\nMS may have a prodromal phase in the years leading up to its manifestation, characterized by psychiatric issues, cognitive impairment, and increased use of healthcare.\nOnset.\n85% of cases begin as a clinically isolated syndrome (CIS) over a number of days with 45% having motor or sensory problems, 20% having optic neuritis, and 10% having symptoms related to brainstem dysfunction, while the remaining 25% have more than one of the aforementioned difficulties. With optic neuritis as the most common presenting symptom, people with MS notice sub-acute loss of vision, often associated with pain worsening on eye movement, and reduced color vision. Early diagnosis of MS-associated optic neuritis helps timely initiation of targeted treatments. However, it is crucial to adhere to established diagnostic criteria when treating optic neuritis due to the broad range of alternative causes, such as neuromyelitis optica spectrum disorder (NMOSD), and other autoimmune or infectious conditions. The course of symptoms occurs in two main patterns initially: either as episodes of sudden worsening that last a few days to months (called relapses, exacerbations, bouts, attacks, or flare-ups) followed by improvement (85% of cases) or as a gradual worsening over time without periods of recovery (10\u201315% of cases). A combination of these two patterns may also occur, or people may start in a relapsing and remitting course that then becomes progressive later on.\nRelapses.\nRelapses are usually unpredictable, occurring without warning. Exacerbations rarely occur more frequently than twice per year. Some relapses, however, are preceded by common triggers and they occur more frequently during spring and summer. Similarly, viral infections such as the common cold, influenza, or gastroenteritis increase their risk. Stress may also trigger an attack.\nMany events do not affect rates of relapse requiring hospitalization including vaccination, breast feeding, physical trauma, and Uhthoff's phenomenon.\nPregnancy.\nMany women with MS who become pregnant experience lower symptoms during pregnancy. During the first months after delivery, the risk increases. Overall, pregnancy does not seem to influence long-term disability.\nCauses.\nMS is an autoimmune disease with a combination of genetic and environmental causes underlying it. Both T-cells and B-cells are involved, although T-cells are often considered to be the driving force of the disease. The causes of the disease are not fully understood. The Epstein-Barr Virus (EBV) has been shown to be directly present in the brain of most cases of MS and the virus is transcriptionally active in infected cells. EBV nuclear antigens are believed to be involved in the pathogenesis of multiple sclerosis, but not all people with MS have signs of EBV infection. Dozens of human peptides have been identified in different cases of the disease, and while some have plausible links to infectious organisms or known environmental factors, others do not.\nImmune dysregulation.\nMS usually begins when some of the immune cells known as T-cells and B-cells erroneously attack the body's own nervous system. T-cells and B-cells, as far as we know, do not attack the body's own cells, and so they release signals that will cause the central nervous system to become inflamed. This inflammation leads to the damage that we observe in MS. Damage In MS, some B cells may be involved, and some support this B-cell theory by citing the presence of certain antibodies (oligoclonal IgG bands) that are found in the spinal fluid of most MS patients and are often used to help confirm the diagnosis.\nInfectious agents.\nEarly evidence suggested the association between several viruses with human demyelinating encephalomyelitis, and the occurrence of demyelination in animals caused by some viral infections. One such virus, Epstein-Barr virus (EBV), can cause infectious mononucleosis and infects about 95% of adults, though only a small proportion of those infected later develop MS. A study of more than 10 million US military members compared 801 people who developed MS to 1,566 matched controls who did not. The study found a 32-fold increased risk of MS development following EBV infection. It did not find an increased risk after infection with other viruses, including the similar cytomegalovirus. These findings strongly suggest that EBV plays a role in MS onset, although EBV alone may be insufficient to cause it.\nThe nuclear antigen of EBV, which is the most consistent marker of EBV infection across all strains, has been identified as a direct source of autoreactivity in the human body. These antigens appear more likely to promote autoimmunity in vitamin D-deficient persons. The exact nature of this relationship is poorly understood.\nGenetics.\nMS is not considered a hereditary disease, but several genetic variations have been shown to increase its risk. Some of these genes appear to have higher expression levels in microglial cells than expected by chance. The probability of developing MS is higher in relatives of an affected person, with a greater risk among those more closely related. An identical twin of an affected individual has a 30% chance of developing MS, 5% for a nonidentical twin, 2.5% for a sibling, and an even lower chance for a half-sibling. MS is also more common in some ethnic groups than others.\nSpecific genes linked with MS include differences in the human leukocyte antigen (HLA) system\u2014a group of genes on chromosome 6 that serves as the major histocompatibility complex (MHC). The contribution of HLA variants to MS susceptibility has been known since the 1980s, and it has also been implicated in the development of other autoimmune diseases, such as type 1 diabetes and systemic lupus erythematosus. The most consistent finding is the association between higher risk MS development and the MHC allele \"DR15\", which is present in 30% of the U.S. and Northern European population. Other loci exhibit a protective effect, such as \"HLA-C554 \"and \"HLA-DRB1*11\". HLA differences account for an estimated 20 to 60% of the genetic predisposition. Genome-wide association studies have revealed at least 200 MS-associated variants outside the HLA locus.\nGeography.\nThe prevalence of MS from a geographic standpoint resembles a gradient, with it being more common in people who live farther from the equator (e.g., those who live in northern regions of the world), although exceptions exist. As of 2019, the north\u2013south gradient of incidence is still present and is increasing. Exceptions include ethnic groups that are at low risk and that live far from the equator, such as the Sami, Amerindians, Canadian Hutterites, New Zealand M\u0101ori, and Canada's Inuit, as well as groups that have a relatively high risk and that live closer to the equator such as Sardinians, inland Sicilians, Palestinians, and Parsi.\nEnvironmental factors during childhood may play a role, with several studies finding that people who move to a different region of the world before the age of 15 acquire the new region's risk of MS. If migration takes place after age 15, the person retains the risk of their childhood region. However, some evidence indicates that the effect of moving may apply to people older than 15.\nThe cause of this geographical pattern is not clear, it could be due to either genetic factors, or exposure to ultraviolet B (UVB) radiation which would increase vitamin D levels. On the one hand, MS is more common in regions with northern European populations, so the geographic variation may simply reflect the distribution of these higher-risk populations. On the other hand, those who live in northern regions of the world have less exposure to UVB radiation and lower levels of vitamin D, and a higher risk for developing MS. Inversely, those who live in areas of higher sun exposure and increased UVB radiation have a decreased risk of developing MS. Several studies have found a negative correlation between Vitamin D levels and MS risk, suggesting there is a causal relationship between low vitamin D levels and an increased risk of developing MS. The benefits of vitamin D supplementation are being investigated, but there is yet not enough evidence for a consensus.\nOther.\nSmoking is a risk factor for MS. Stress may also be a risk factor, although the evidence to support this is weak. \nEnvironmental risk factor reviews have correlated lower sun exposure with higher MS rates though the effect does not completely align with earth's solar irradiance latitude gradient. Regional perturbations exist indicating involvement of additional, more influential localized MS risk factors. See also: Multiple sclerosis#Geography.\nOrganic solvent exposure and night shift work are linked to increased risk of MS, but are not as established as other risk factors.\nVaccinations were studied as causal factors; most studies, though, show no association. Several other possible risk factors, such as diet and hormone intake, have been evaluated, but evidence on their relation with the disease is \"sparse and unpersuasive\". Gout occurs less than would be expected and lower levels of uric acid have been found in people with MS. This has led to the theory that uric acid is protective, although its exact importance remains unknown. Obesity during adolescence and young adulthood is a risk factor for MS.\nPathophysiology.\nMultiple sclerosis is an autoimmune disease, primarily mediated by T-cells. The three main characteristics of MS are the formation of lesions in the central nervous system (also called plaques), inflammation, and the destruction of myelin sheaths of neurons. These features interact in a complex and not yet fully understood manner to produce the breakdown of nerve tissue, and in turn, the signs and symptoms of the disease. Damage is believed to be caused, at least in part, by attack on the nervous system by a person's own immune system.\nImmune dysregulation.\nAs briefly detailed in the causes section of this article, MS is currently thought to stem from a failure of the body's immune system to kill off autoreactive T-cells &amp; B-cells. Currently, the T-cell subpopulations that are thought to drive the development of MS are autoreactive CD8+ T-cells, CD4+ helper T-cells, and TH17 cells. These autoreactive T-cells produce substances called cytokines that induce an inflammatory immune response in the CNS, leading to the development of the disease. Recent research indicates that vitamin D deficiency may exacerbate MS by promoting TH17 cell differentiation and activity. Supplementation with vitamin D has been shown to modulate TH17 responses, potentially influencing disease progression.More recently, however, the role of autoreactive B-cells has been elucidated. Evidence of their contribution to the development of MS is implicated through the presence of oligoclonal IgG bands (antibodies produced by B-cells) in the CSF of patients with MS. The presence of these oligoclonal bands has been used as supportive evidence in clinching a diagnosis of MS. As similarly described before, B-cells can also produce cytokines that induce an inflammatory immune response via activation of autoreactive T-cells. As such, higher levels of these autoreactive B-cells are associated with an increased number of lesions &amp; neurodegeneration as well as worse disability.\nAnother cell population that is becoming increasingly implicated in MS is microglia. These cells are resident to &amp; keep watch over the CNS, responding to pathogens by shifting between pro- &amp; anti-inflammatory states. Microglia are involved in the formation of MS lesions and be involved in other diseases that primarily affect the CNS white matter. However, because of their ability to switch between pro- &amp; anti-inflammatory states, microglia have also been shown to be able to assist in remyelination &amp; subsequent neuron repair. As such, microglia are thought to be participating in both acute &amp; chronic MS lesions, with 40% of phagocytic cells in early active MS lesions being proinflammatory microglia.\nLesions.\nThe name multiple sclerosis refers to the scars (sclerae \u2013 better known as plaques or lesions) that form in the nervous system. These lesions most commonly affect the white matter in the optic nerve, brain stem, basal ganglia, and spinal cord, or white matter tracts close to the lateral ventricles. The function of white matter cells is to carry signals between grey matter areas, where the processing is done, and the rest of the body. The peripheral nervous system is rarely involved.\nTo be specific, MS involves the loss of oligodendrocytes, the cells responsible for creating and maintaining a fatty layer\u2014known as the myelin sheath\u2014which helps the neurons carry electrical signals (action potentials). This results in a thinning or complete loss of myelin, and as the disease advances, the breakdown of the axons of neurons. When the myelin is lost, a neuron can no longer effectively conduct electrical signals. A repair process, called remyelination, takes place in the early phases of the disease, but the oligodendrocytes are unable to completely rebuild the cell's myelin sheath. Repeated attacks lead to successively less effective remyelinations, until a scar-like plaque is built up around the damaged axons. These scars are the origin of the symptoms and during an attack magnetic resonance imaging (MRI) often shows more than 10 new plaques. This could indicate that some number of lesions exist, below which the brain is capable of repairing itself without producing noticeable consequences. Another process involved in the creation of lesions is an abnormal increase in the number of astrocytes due to the destruction of nearby neurons. A number of lesion patterns have been described.\nInflammation.\nApart from demyelination, the other sign of the disease is inflammation. Fitting with an immunological explanation, the inflammatory process is caused by T cells, a kind of lymphocytes that plays an important role in the body's defenses. T cells gain entry into the brain as a result of disruptions in the blood\u2013brain barrier. The T cells recognize myelin as foreign and attack it, explaining why these cells are also called \"autoreactive lymphocytes\".\nThe attack on myelin starts inflammatory processes, which trigger other immune cells and the release of soluble factors like cytokines and antibodies. A further breakdown of the blood-brain barrier, in turn, causes many other damaging effects, such as swelling, activation of macrophages, and more activation of cytokines and other destructive proteins. Inflammation can potentially reduce transmission of information between neurons in at least three ways. The soluble factors released might stop neurotransmission by intact neurons. These factors could lead to or enhance the loss of myelin, or they may cause the axon to break down completely.\nBlood-brain barrier.\nThe blood-brain barrier (BBB) is a part of the capillary system that prevents the entry of T cells into the central nervous system. It may become permeable to these types of cells secondary to an infection by a virus or bacteria. After it repairs itself, typically once the infection has cleared, T cells may remain trapped inside the brain. Gadolinium cannot cross a normal BBB, so gadolinium-enhanced MRI is used to show BBB breakdowns.\nMS fatigue.\nThe pathophysiology and mechanisms causing MS fatigue are not well understood. MS fatigue can be affected by body heat. Fatigability, defined as \"decline in physical performance over time\", correlates with perceived fatigue, but the limited correlation suggests they are distinct constructs and warrant independent assessment in clinical studies.\nDiagnosis.\nMultiple sclerosis is typically diagnosed based on the presenting signs and symptoms, in combination with supporting medical imaging and laboratory testing. It can be difficult to confirm, especially early on, since the signs and symptoms may be similar to those of other medical problems.\nMcDonald criteria.\nThe McDonald criteria, which focus on clinical, laboratory, and radiologic evidence of lesions at different times and in different areas, is the most commonly used method of diagnosis with the Schumacher and Poser criteria being of mostly historical significance. The McDonald criteria states that patients with multiple sclerosis should have lesions which are disseminated in time (DIT) and disseminated in space (DIS), i.e. lesions which have appeared in different areas in the brain and at different times. Below is an abbreviated outline of the 2017 McDonald Criteria for diagnosis of MS (these criteria have since been expanded with the 2024 McDonald criteria to allow earlier diagnosis, though the underlying principles remain unchanged).\nAs of 2017[ [update]], no single test (including biopsy) can provide a definitive diagnosis.\nMRI.\nMagnetic resonance imaging (MRI) of the brain and spine may show areas of demyelination (lesions or plaques). Gadolinium can be administered intravenously as a contrast agent to highlight active plaques, and by elimination, demonstrate the existence of historical lesions not associated with symptoms at the moment of the evaluation.\nCentral vein signs (CVSs) have been proposed as a good indicator of MS in comparison with other conditions causing white lesions. One small study found fewer CVSs in older and hypertensive people. Further research on CVS as a biomarker for MS is ongoing.\nIn vivo vs postmortem lesion visibility in MRI scans.\nOnly postmortem MRI allows visualization of sub-millimetric lesions in cortical layers and in the cerebellar cortex.\nCerebrospinal fluid (lumbar puncture).\nTesting of cerebrospinal fluid obtained from a lumbar puncture can provide evidence of chronic inflammation in the central nervous system. The cerebrospinal fluid is tested for oligoclonal bands of IgG on electrophoresis, which are inflammation markers found in 75\u201385% of people with MS.\nDifferential diagnosis.\nSeveral diseases present similarly to MS. Medical professionals use a patient's specific presentation, history, and exam findings to make an individualized differential. Red flags are findings that suggest an alternate diagnosis, although they do not rule out MS. Red flags include a patient younger than 15 or older than 60, less than 24 hours of symptoms, involvement of multiple cranial nerves, involvement of organs outside of the nervous system, and atypical lab and exam findings.\nIn an emergency setting, it is important to rule out a stroke or bleeding in the brain. Intractable vomiting, severe optic neuritis, or bilateral optic neuritis raises suspicion for neuromyelitis optica spectrum disorder (NMOSD). Infectious diseases that may look similar to multiple sclerosis include HIV, Lyme disease, and syphilis. Autoimmune diseases include neurosarcoidosis, lupus, Guillain-Barr\u00e9 syndrome, acute disseminated encephalomyelitis, and Beh\u00e7et's disease. Psychiatric conditions such as anxiety or conversion disorder may also present in a similar way. Other rare diseases on the differential include CNS lymphoma, congenital leukodystrophies, and anti-MOG-associated myelitis.\nTypes and variants.\nSeveral phenotypes (commonly termed \"types\"), or patterns of progression, have been described. Phenotypes use the past course of the disease in an attempt to predict the future course. They are important not only for prognosis but also for treatment decisions.\nThe International Advisory Committee on Clinical Trials of MS describes four types of MS (revised in 2013) in what is known as the Lublin classification:\nCIS can be characterised as a single lesion seen on MRI which is associated with signs or symptoms found in MS. Due to the McDonald criteria, it does not completely fit the criteria to be diagnosed as MS, hence being named \"clinically isolated syndrome\". CIS can be seen as the first episode of demyelination in the central nervous system. To be classified as CIS, the attack must last at least 24 hours and be caused by inflammation or demyelination of the central nervous system. Patients who suffer from CIS may or may not go on to develop MS, but 30 to 70% of persons who experience CIS will later develop MS.\nRRMS is characterized by unpredictable relapses followed by periods of months to years of relative quiet (remission) with no new signs of disease activity. Deficits that occur during attacks may either resolve or leave problems, the latter in about 40% of attacks and being more common the longer a person has had the disease. This describes the initial course of 80% of individuals with MS.\nPPMS occurs in roughly 10\u201320% of individuals with the disease, with no remission after the initial symptoms. It is characterized by progression of disability from onset, with no, or only occasional and minor, remissions and improvements. The usual age of onset for the primary progressive subtype is later than that of the relapsing-remitting subtype. It is similar to the age that secondary progressive usually begins in RRMS, around 40 years of age.\nSPMS occurs in around 65% of those with initial RRMS, who eventually have progressive neurologic decline between acute attacks without any definite periods of remission. Occasional relapses and minor remissions may appear. The most common length of time between disease onset and conversion from RRMS to SPMS is 19 years.\nSpecial courses.\nIndependently of the types published by the MS associations, regulatory agencies such as the FDA often consider special courses, trying to reflect some clinical trial results on their approval documents. Some examples could be \"highly active MS\" (HAMS), \"active secondary MS\" (similar to the old progressive-relapsing) and \"rapidly progressing PPMS\".\nAlso, deficits always resolving between attacks is sometimes referred to as \"benign\" MS, although people still build up some degree of disability in the long term. On the other hand, the term malignant multiple sclerosis is used to describe people with MS having reached a significant level of disability in a short period.\nAn international panel has published a standardized definition for the course HAMS.\nVariants.\nAtypical variants of MS have been described; these include tumefactive multiple sclerosis, Balo concentric sclerosis, Schilder's diffuse sclerosis, and Marburg multiple sclerosis. Debate remains on whether they are MS variants or different diseases. Some diseases previously considered MS variants, such as Devic's disease, are now considered outside the MS spectrum.\nManagement.\nAlthough no cure for multiple sclerosis has been found, several therapies have proven helpful. Several effective treatments can decrease the number of attacks and the rate of progression. The primary aims of therapy are returning function after an attack, preventing new attacks, and preventing disability. Starting medications is generally recommended in people after the first attack when more than two lesions are seen on MRI.\nThe first approved medications used to treat MS were modestly effective, though were poorly tolerated and had many adverse effects. Several treatment options with better safety and tolerability profiles have been introduced, improving the prognosis of MS.\nAs with any medical treatment, medications used in the management of MS have several adverse effects. Alternative treatments are pursued by some people, despite the shortage of supporting evidence of efficacy.\nInitial management of acute flare.\nDuring symptomatic attacks, administration of high doses of intravenous corticosteroids, such as methylprednisolone, is the usual therapy, with oral corticosteroids seeming to have a similar efficacy and safety profile. Although effective in the short term for relieving symptoms, corticosteroid treatments do not appear to have a significant impact on long-term recovery. The long-term benefit is unclear in optic neuritis as of 2020. The consequences of severe attacks that do not respond to corticosteroids might be treatable by plasmapheresis.\nChronic management.\nRelapsing-remitting multiple sclerosis.\nMultiple disease-modifying medications were approved by regulatory agencies for RRMS; they are modestly effective at decreasing the number of attacks. Interferons and glatiramer acetate are first-line treatments and are roughly equivalent, reducing relapses by approximately 30%. Early-initiated long-term therapy is safe and improves outcomes.\nTreatment of CIS with interferons decreases the chance of progressing to clinical MS. Efficacy of interferons and glatiramer acetate in children has been estimated to be roughly equivalent to that of adults. The role of some newer agents such as fingolimod, teriflunomide, and dimethyl fumarate, is not yet entirely clear. Making firm conclusions about the best treatment is difficult, especially regarding the long\u2010term benefit and safety of early treatment, given the lack of studies directly comparing disease-modifying therapies or long-term monitoring of patient outcomes.\nThe relative effectiveness of different treatments is unclear, as most have only been compared to placebo or a small number of other therapies. Direct comparisons of interferons and glatiramer acetate indicate similar effects or only small differences in effects on relapse rate, disease progression, and MRI measures. There is high confidence that natalizumab, cladribine, or alemtuzumab are decreasing relapses over two years for people with RRMS. Natalizumab and interferon beta-1a (Rebif) may reduce relapses compared to both placebo and interferon beta-1a (Avonex) while Interferon beta-1b (Betaseron), glatiramer acetate, and mitoxantrone may also prevent relapses. Evidence on relative effectiveness in reducing disability progression is unclear. There is moderate confidence that a two-year treatment with natalizumab slows disability progression for people with RRMS. All medications are associated with adverse effects that may influence their risk-to-benefit profiles.\nUblituximab was approved for medical use in the United States in December 2022.\nMedications.\nOverview of medications available for MS.\nProgressive multiple sclerosis.\nIn 2011, mitoxantrone was the first medication approved for secondary progressive MS. In this population, tentative evidence supports mitoxantrone moderately slowing the progression of the disease and decreasing rates of relapses over two years.\nNew approved medications continue to emerge. In March 2017, the FDA approved ocrelizumab as a treatment for primary progressive MS in adults, the first drug to gain that approval, with requirements for several Phase IV clinical trials. It is also used for the treatment of relapsing forms of multiple sclerosis, to include clinically isolated syndrome, relapsing-remitting disease, and active secondary progressive disease in adults. According to a 2021 Cochrane review, ocrelizumab may reduce worsening of symptoms for primary progressive MS and probably increases unwanted effects but makes little or no difference to the number of serious unwanted effects.\nIn 2019, siponimod and cladribine were approved in the United States for the treatment of secondary progressive multiple sclerosis (SPMS). Subsequently, ozanimod was approved in 2020, and ponesimod was approved in 2021, which were both approved for management of CIS, relapsing MS, and SPMS in the U.S., and RRMS in Europe.\nOcrelizumab/hyaluronidase was approved for medical use in the United States in September 2024.\nAdverse effects.\nThe disease-modifying treatments have several adverse effects. One of the most common is irritation at the injection site for glatiramer acetate and the interferons (up to 90% with subcutaneous injections and 33% with intramuscular injections). Over time, a visible dent at the injection site, due to the local destruction of fat tissue, known as lipoatrophy, may develop. Interferons may produce flu-like symptoms; some people taking glatiramer experience a post-injection reaction with flushing, chest tightness, heart palpitations, and anxiety, which usually lasts less than thirty minutes. More dangerous but much less common are liver damage from interferons, systolic dysfunction (12%), infertility, and acute myeloid leukemia (0.8%) from mitoxantrone, and progressive multifocal leukoencephalopathy occurring with natalizumab (occurring in 1 in 600 people treated).\nFingolimod may give rise to hypertension and slowed heart rate, macular edema, elevated liver enzymes, or a reduction in lymphocyte levels. Tentative evidence supports the short-term safety of teriflunomide, with common side effects including headaches, fatigue, nausea, hair loss, and limb pain. There have also been reports of liver failure and PML with its use and it is dangerous for fetal development. Most common side effects of dimethyl fumarate are flushing and gastrointestinal problems. While dimethyl fumarate may lead to a reduction in the white blood cell count there were no reported cases of opportunistic infections during trials.\nAssociated symptoms.\nBoth medications and neurorehabilitation have been shown to improve some symptoms, though neither changes the course of the disease. Some symptoms have a good response to medication, such as bladder spasticity, while others are little changed. Equipment such as catheters for neurogenic bladder dysfunction or mobility aids can help improve functional status.\nA multidisciplinary approach is important for improving quality of life; however, it is difficult to specify a 'core team' as many health services may be needed at different points in time. Multidisciplinary rehabilitation programs increase activity and participation of people with MS but do not influence impairment level. Studies investigating information provision in support of patient understanding and participation suggest that while interventions (written information, decision aids, coaching, educational programmes) may increase knowledge, the evidence of an effect on decision making and quality of life is mixed and low certainty. There is limited evidence for the overall efficacy of individual therapeutic disciplines, though there is good evidence that specific approaches, such as exercise, and psychological therapies are effective. Cognitive training, alone or combined with other neuropsychological interventions, may show positive effects for memory and attention though firm conclusions are not possible given small sample numbers, variable methodology, interventions and outcome measures. The effectiveness of palliative approaches in addition to standard care is uncertain, due to lack of evidence. The effectiveness of interventions, including exercise, specifically for the prevention of falls in people with MS is uncertain, while there is some evidence of an effect on balance function and mobility. Cognitive behavioral therapy has shown to be moderately effective for reducing MS fatigue. The evidence for the effectiveness of non-pharmacological interventions for chronic pain is insufficient to recommend such interventions alone, however their use in combination with medications may be reasonable.\nNon-pharmaceutical.\nThere is some evidence that aquatic therapy is a beneficial intervention.\nThe spasticity associated with MS can be difficult to manage because of the progressive and fluctuating course of the disease. Although there is no firm conclusion on the efficacy in reducing spasticity, PT interventions can be a safe and beneficial option for patients with multiple sclerosis. Physical therapy including vibration interventions, electrical stimulation, exercise therapy, standing therapy, and radial shock wave therapy (RSWT), were beneficial for limiting spasticity, helping limit excitability, or increasing range of motion.\nAlternative treatments.\nOver 50% of people with MS may use complementary and alternative medicine, although percentages vary depending on how alternative medicine is defined. Regarding the characteristics of users, they are more frequently women, have had MS for a longer time, tend to be more disabled and have lower levels of satisfaction with conventional healthcare. The evidence for the effectiveness for such treatments in most cases is weak or absent. Treatments of unproven benefit used by people with MS include dietary supplementation and regimens, vitamin D, relaxation techniques such as yoga, herbal medicine (including medical cannabis), hyperbaric oxygen therapy, self-infection with hookworms, reflexology, acupuncture, and mindfulness. Evidence suggests vitamin D supplementation, irrespective of the form and dose, provides no benefit for people with MS; this includes for measures such as relapse recurrence, disability, and MRI lesions while effects on health\u2010related quality of life and fatigue are unclear. There is insufficient evidence supporting high-dose biotin and some evidence for increased disease activity and higher risk of relapse with its use. A 2022 review found that nabiximols (tetrahydrocannabinol and cannabidiol) can reduce the severity of spasticity in the short term, but may have unwanted neurological effects.\nPrognosis.\nThe availability of treatments that modify the course of multiple sclerosis beginning in the 1990s, known as disease-modifying therapies (DMTs), has improved prognosis. These treatments can reduce relapses and slow progression, but there is no cure.\nThe prognosis of MS depends on the subtype of the disease, and there is considerable individual variation in the progression of the disease. In relapsing MS, the most common subtype, a 2016 cohort study found that after a median of 16.8 years from onset, one in ten needed a walking aid, and almost two in ten transitioned to secondary progressive MS, a form characterized by more progressive decline. With treatments available in the 2020s, relapses can be eliminated or substantially reduced. However, \"silent progression\" of the disease still occurs.\nIn addition to secondary progressive MS (SPMS), a small proportion of people with MS (10\u201315%) experience progressive decline from the onset, known as primary progressive MS (PPMS). Most treatments have been approved for use in relapsing MS; there are fewer treatments with lower efficacy for progressive forms of MS. The prognosis for progressive MS is worse, with faster accumulation of disability, though with considerable individual variation. In untreated PPMS, the median time from onset to requiring a walking aid is estimated as seven years. In SPMS, a 2014 cohort study reported that people required a walking aid after an average of five years from the onset of SPMS, and were chair or bed-bound after an average of fifteen years.\nAfter diagnosis of MS, characteristics that predict a worse course are male sex, older age, and greater disability at the time of diagnosis; female sex is associated with a higher relapse rate. Currently, no biomarker can accurately predict disease progression in every patient. Spinal cord lesions, abnormalities on MRI, and more brain atrophy are predictive of a worse course, though brain atrophy as a predictor of disease course is experimental and not used in clinical practice. Early treatment leads to a better prognosis, but a higher relapse frequency when treated with DMTs is associated with a poorer prognosis. A 60-year longitudinal population study conducted in Norway found that those with MS had a life expectancy seven years shorter than the general population. Median life expectancy for RRMS patients was 77.8 years and 71.4 years for PPMS, compared to 81.8 years for the general population. Life expectancy for men was five years shorter than for women.\nEpidemiology.\nMS is the most common autoimmune disorder of the central nervous system. The latest estimation of the total number of people with MS was 2.9 million globally as of 2023, with a prevalence of 36 per 100,000 people. Moreover, prevalence varies widely in different regions around the world. In Africa, there are 5 people per 100,000 diagnosed with MS, compared to South East Asia where the prevalence is 9 per 100,000, 112 per 100,000 in the Americas, and 133 per 100,000 in Europe. Nearly one million people in the United States have MS.\nIncreasing rates of MS may be explained simply by better diagnosis. Studies on population and geographical patterns have been common and have led to a number of theories about the cause.\nMS usually appears in adults in their late twenties or early thirties but it can rarely start in childhood and after 50 years of age. The primary progressive subtype is more common in people in their fifties. Similarly to many autoimmune disorders, the disease is more common in women, and the trend may be increasing. As of 2020, globally it is about two times more common in women than in men, and the ratio of women to men with MS is as high as 4:1 in some countries. In children, it is even more common in females than males, while in people over fifty, it affects males and females almost equally.\nHistory.\nMedical discovery.\nRobert Carswell (1793\u20131857), a British professor of pathology, and Jean Cruveilhier (1791\u20131873), a French professor of pathologic anatomy, described and illustrated many of the disease's clinical details, but did not identify it as a separate disease. Specifically, Carswell described the injuries he found as \"a remarkable lesion of the spinal cord accompanied with atrophy\". Under the microscope, Swiss pathologist Georg Eduard Rindfleisch (1836\u20131908) noted in 1863 that the inflammation-associated lesions were distributed around blood vessels.\nThe French neurologist Jean-Martin Charcot (1825\u20131893) was the first person to recognize multiple sclerosis as a distinct disease in 1868. Summarizing previous reports and adding his own clinical and pathological observations, Charcot called the disease \"sclerose en plaques\".\nDiagnosis history.\nThe first attempt to establish a set of diagnostic criteria was also due to Charcot in 1868. He published what now is known as the \"Charcot triad\", consisting of nystagmus, intention tremor, and telegraphic speech (scanning speech). Charcot also observed cognition changes, describing his patients as having a \"marked enfeeblement of the memory\" and \"conceptions that formed slowly\".\nThe diagnosis was based on Charcot triad and clinical observation until Schumacher made the first attempt to standardize criteria in 1965 by introducing some fundamental requirements: Dissemination of the lesions in time (DIT) and space (DIS), and that \"signs and symptoms cannot be explained better by another disease process\". The DIT and DIS requirement was later inherited by the Poser and McDonald criteria, whose 2017 revision is in use.\nDuring the 20th century, theories about the cause and pathogenesis were developed and effective treatments began to appear in the 1990s. Since the beginning of the 21st century, refinements of the concepts have taken place. The 2010 revision of the McDonald criteria allowed for the diagnosis of MS with only one proved lesion (CIS).\nIn 1996, the US National Multiple Sclerosis Society (NMSS) (Advisory Committee on Clinical Trials) defined the first version of the clinical phenotypes that is in use. In this first version, they provided standardized definitions for four MS clinical courses: relapsing-remitting (RR), secondary progressive (SP), primary progressive (PP), and progressive relapsing (PR). In 2010, PR was dropped and CIS was incorporated. Three years later, the 2013 revision of the \"phenotypes for the disease course\" were forced to consider CIS as one of the phenotypes of MS, making obsolete some expressions like \"conversion from CIS to MS\". Other organizations have proposed later new clinical phenotypes, like HAMS (Highly Active MS).\nHistorical cases.\nThere are several historical accounts of people who probably had MS and lived before or shortly after the disease was described by Charcot.\nA young woman called Halldora who lived in Iceland around 1200 suddenly lost her vision and mobility but recovered them seven days after. Saint Lidwina of Schiedam (1380\u20131433), a Dutch nun, may be one of the first clearly identifiable people with MS. From the age of 16 until her death at 53, she had intermittent pain, weakness of the legs and vision loss: symptoms typical of MS. Both cases have led to the proposal of a \"Viking gene\" hypothesis for the dissemination of the disease.\nAugustus Frederick d'Este (1794\u20131848), son of Prince Augustus Frederick, Duke of Sussex and Lady Augusta Murray and a grandson of George\u00a0III of the United Kingdom, almost certainly had MS. D'Este left a detailed diary describing his 22 years living with the disease. His diary began in 1822 and ended in 1846, although it remained unknown until 1948. His symptoms began at age 28 with a sudden transient visual loss (amaurosis fugax) after the funeral of a friend. During his disease, he developed weakness in the legs, clumsiness of the hands, numbness, dizziness, bladder disturbance and erectile dysfunction. In 1844, he began to use a wheelchair. Despite his illness, he kept an optimistic view of life. Another early account of MS was kept by the British diarist W. N. P. Barbellion, pen name of Bruce Frederick Cummings (1889\u20131919), who maintained a detailed log of his diagnosis and struggle. His diary was published in 1919 as \"The Journal of a Disappointed Man\". Charles Dickens, a keen observer, described possible bilateral optic neuritis with reduced contrast vision and Uhthoff's phenomenon in the main female character of \"Bleak House\" (1852\u20131853), Esther Summerson.\nResearch.\nEpstein\u2013Barr virus.\nAs of 2022, the pathogenesis of MS, as it relates to Epstein\u2013Barr virus (EBV), is actively investigated, as are disease-modifying therapies; understanding of how risk factors combine with EBV to initiate MS is sought. Whether EBV is the only cause of MS might be better understood if an EBV vaccine is developed and shown to prevent MS as well.\nEven though a variety of studies showed the connection between an EBV infection and a later development of multiple sclerosis, the mechanisms behind this correlation are not completely clear, and several theories have been proposed to explain the relationship between the two diseases. It is thought that the involvement of EBV-infected B-cells (B lymphocytes) and the involvement of anti-EBNA antibodies, which appear to be significantly higher in multiple sclerosis patients, play a crucial role in the development of the disease. This is supported by the fact that treatment against B-cells, e.g. ocrelizumab, reduces the symptoms of multiple sclerosis: annual relapses appear less frequently and the disability progression is slower. A 2022 Stanford University study has shown that during an EBV infection, molecular mimicry can occur, where the immune system will produce antibodies against the EBNA1 protein, which at the same time is able to bind to GlialCAM in the myelin. Additionally, they observed a phenomenon which is uncommon in healthy individuals but often detected in multiple sclerosis patients \u2013 B-cells are trafficking to the brain and spinal cord, where they are producing oligoclonal antibody bands. A majority of these oligoclonal bands do have an affinity to the viral protein EBNA1, which is cross-reactive to GlialCAM. These antibodies are abundant in approximately 20\u201325% of multiple sclerosis patients and worsen the autoimmune demyelination which leads consequently to a pathophysiological exacerbation of the disease. Furthermore, the intrathecal oligoclonal expansion with a constant somatic hypermutation is unique in multiple sclerosis when compared to other neuroinflammatory diseases. In the study, there was also the abundance of antibodies with IGHV 3\u20137 genes measured, which appears to be connected to the disease progress. Antibodies which are IGHV3\u20137-based are binding with a high affinity to EBNA1 and GlialCAM. This process is actively thriving the demyelination. It is probable that B-cells, expressing IGHV 3\u20137 genes entered the CSF and underwent affinity maturation after facing GlialCAM, which led consequently to the production of high-affinity anti-GlialCAM antibodies. This was additionally shown in the EAE mouse model where immunization with EBNA1 lead to a strong B-cell response against GlialCAM, which worsened the EAE.\nHuman endogenous retroviruses.\nTwo members of the human endogenous retroviruses-W (HERV-W) family, namely, ERVWE1 and MS-associated retrovirus (MSRV), may be co-factors in MS immunopathogenesis. HERVs constitute up to 8% of the human genome; most are epigenetically silent, but can be reactivated by exogenous viruses, proinflammatory conditions or oxidative stress.\nMedications.\nMedications that influence voltage-gated sodium ion channels are under investigation as a potential neuroprotective strategy because of hypothesized role of sodium in the pathological process leading to axonal injury and accumulating disability. There is insufficient evidence of an effect of sodium channel blockers for people with MS.\nPathogenesis.\nMS is a clinically defined entity with several atypical presentations. Some auto-antibodies have been found in atypical MS cases, giving birth to separate disease families and restricting the previously wider concept of MS.\nAnti-AQP4 autoantibodies were found in neuromyelitis optica (NMO), which was previously considered a MS variant. A spectrum of diseases named NMOSD (NMO spectrum diseases) or anti-AQP4 diseases has been accepted. Some cases of MS were presenting anti-MOG autoantibodies, mainly overlapping with the Marburg variant. Anti-MOG autoantibodies were found to be also present in ADEM, and a second spectrum of separated diseases is being considered. This spectrum is named inconsistently across different authors, but it is normally something similar to anti-MOG demyelinating diseases.\nA third kind of auto-antibodies is accepted. There are several anti-neurofascin auto-antibodies that damage the Ranvier nodes of the neurons. These antibodies are more related to the peripheral nervous demyelination, but they were also found in chronic progressive PPMS and combined central and peripheral demyelination (CCPD, which is considered another atypical MS presentation).\nIn addition to the significance of auto-antibodies in MS, four different patterns of demyelination have been reported, opening the door to consider MS as a heterogeneous disease.\nBiomarkers.\nSince disease progression is the result of degeneration of neurons, the roles of proteins showing loss of nerve tissue such as neurofilaments, tau, and N-acetylaspartate are under investigation.\nImprovement in neuroimaging techniques such as positron emission tomography (PET) or MRI carry a promise for better diagnosis and prognosis predictions. Regarding MRI, there are several techniques that have already shown some usefulness in research settings and could be introduced into clinical practice, such as double-inversion recovery sequences, magnetization transfer, diffusion tensor, and functional magnetic resonance imaging. These techniques are more specific for the disease than existing ones, but still lack some standardization of acquisition protocols and the creation of normative values. This is particularly the case for proton magnetic resonance spectroscopy, for which a number of methodological variations observed in the literature may underlie continued inconsistencies in central nervous system metabolic abnormalities, particularly in N-acetyl aspartate, myoinositol, choline, glutamate, GABA, and GSH, observed for multiple sclerosis and its subtypes. There are other techniques under development that include contrast agents capable of measuring levels of peripheral macrophages, inflammation, or neuronal dysfunction, and techniques that measure iron deposition that could serve to determine the role of this feature in MS, or that of cerebral perfusion.\nCOVID-19.\nThe hospitalization rate was found to be higher among individuals with MS and COVID-19 infection, at 10%, while the pooled infection rate is estimated at 4%. The pooled prevalence of death in hospitalized individuals with MS is estimated as 4%.\nMetformin.\nA 2019 study on rats and a 2024 study on mice showed that a first-line medication for the treatment of type 2 diabetes, metformin, could promote remyelination. The promising drug is currently being researched on humans in the Octopus trials, a multi-arm, multi-stage trial, focussed on testing existing drugs for other conditions on patients with MS. Currently, clinical trials on humans are ongoing in Belgium, for patients with non-active progressive MS, in the U.K., in combination with clemastine for the treatment of relapsing-remitting MS, and Canada, for MS patients up to 25 years old.\nOther emerging theories.\nOne emerging hypothesis, referred to as the hygiene hypothesis, suggests that early-life exposure to infectious agents helps to develop the immune system and reduces susceptibility to allergies and autoimmune disorders. The hygiene hypothesis has been linked with MS and microbiome hypotheses.\nIt has also been proposed that certain bacteria found in the gut use molecular mimicry to infiltrate the brain via the gut\u2013brain axis, initiating an inflammatory response and increasing blood-brain barrier permeability. Vitamin D levels have also been correlated with MS; lower levels of vitamin D correspond to an increased risk of MS, suggesting a reduced prevalence in the tropics \u2013 an area with more Vitamin D-rich sunlight \u2013 strengthening the impact of geographical location on MS development. MS mechanisms begin when peripheral autoreactive effector CD4+ T cells get activated and move into the CNS. Antigen-presenting cells localize the reactivation of autoreactive effector CD4-T cells once they have entered the CNS, attracting more T cells and macrophages to form the inflammatory lesion. In MS patients, macrophages and microglia assemble at locations where demyelination and neurodegeneration are actively occurring, and microglial activation is more apparent in the normal-appearing white matter of MS patients. Astrocytes generate neurotoxic chemicals like nitric oxide and TNF\u03b1, attract neurotoxic inflammatory monocytes to the CNS, and are responsible for astrogliosis, the scarring that prevents the spread of neuroinflammation and kills neurons inside the scarred area.\nIn 2024, scientists shared research on their findings of ancient migration to northern Europe from the Yamnaya area of culture, tracing MS-risk gene variants dating back around 5,000 years. The MS-risk gene variants protected ancient cattle herders from animal diseases, but modern lifestyles, diets and better hygiene, have allowed the gene to develop, resulting in the higher risk of MS today.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50604", "revid": "31026899", "url": "https://en.wikipedia.org/wiki?curid=50604", "title": "Interacting boson model", "text": "The interacting boson model (IBM) is a model in nuclear physics in which\nnucleons (protons or neutrons) pair up, essentially\nacting as a single particle with boson properties, with\nintegral spin of either 2 (d-boson) or 0 (s-boson). They correspond to a quintuplet and singlet, i.e. 6 states.\nIt is sometimes known as the Interacting boson approximation (IBA).\nThe IBM1/IBM-I model treats both types of nucleons the same and considers only pairs of nucleons coupled to\ntotal angular momentum 0 and 2, called respectively, s and d bosons.\nThe IBM2/IBM-II model treats protons and neutrons separately.\nBoth models are restricted to nuclei with even numbers of protons and neutrons.\nThe model can be used to predict vibrational and rotational modes of non-spherical nuclei.\nHistory.\nThis model was invented by Akito Arima and Francesco Iachello in 1974. while working at the Kernfysisch Versneller Instituut(KVI) in Groningen, Netherlands. KVI is now property of Universitair Medisch Centrum Groningen (https://umcgresearch.org/).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50605", "revid": "43960941", "url": "https://en.wikipedia.org/wiki?curid=50605", "title": "Cerebral palsy", "text": "Movement disorders that appear in early childhood\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nCerebral palsy (CP) is a group of movement disorders that appear in early childhood. Signs and symptoms vary among people and over time, but include poor coordination, stiff muscles, weak muscles, and tremors. There may be problems with sensation, vision, hearing, and speech. Often, babies with cerebral palsy do not roll over, sit, crawl or walk as early as other children. Other symptoms may include seizures and problems with thinking or reasoning. While symptoms may get more noticeable over the first years of life, underlying problems do not worsen over time.\nCerebral palsy is caused by abnormal development or damage to the parts of the brain that control movement, balance, and posture. Most often, the problems occur during pregnancy, but may occur during childbirth or shortly afterwards. Often, the cause is unknown. Risk factors include preterm birth, being a twin, certain infections or exposure to methylmercury during pregnancy, a difficult delivery, and head trauma during the first few years of life. A study published in 2024 suggests that inherited genetic causes play a role in 25% of cases, where formerly it was believed that 2% of cases were genetically determined.\nSub-types are classified, based on the specific problems present. For example, those with stiff muscles have spastic cerebral palsy, poor coordination in locomotion have ataxic cerebral palsy, and writhing movements have dyskinetic cerebral palsy. Diagnosis is based on the child's development. Blood tests and medical imaging may be used to rule out other possible causes.\nSome causes of CP are preventable through immunization of the mother, and efforts to prevent head injuries in children such as improved safety. There is no known cure for CP, but supportive treatments, medication and surgery may help individuals. This may include physical therapy, occupational therapy and speech therapy. Mouse NGF has been shown to improve outcomes and has been available in China since 2003. Medications such as diazepam, baclofen and botulinum toxin may help relax stiff muscles. Surgery may include lengthening muscles and cutting overly active nerves. Often, external braces and Lycra splints and other assistive technology are helpful with mobility. Some affected children can achieve near normal adult lives with appropriate treatment. While alternative medicines are frequently used, there is no evidence to support their use. Potential treatments are being examined, including stem cell therapy. However, more research is required to determine if it is effective and safe.\nCerebral palsy is the most common movement disorder in children, occurring in about 2.1 per 1,000 live births. It has been documented throughout history, with the first known descriptions occurring in the work of Hippocrates in the 5th century BCE. Extensive study began in the 19th century by William John Little, after whom spastic diplegia was called \"Little's disease\". William Osler named it \"cerebral palsy\" from the German (cerebral child-paralysis). Historical literature and artistic representations referencing symptoms of cerebral palsy indicate that the condition was recognized in antiquity, characterizing it as an \"old disease\".\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nSigns and symptoms.\nCerebral palsy is defined as \"a group of permanent disorders of the development of movement and posture, causing activity limitation, that are attributed to non-progressive disturbances that occurred in the developing fetal or infant brain.\" While movement problems are the central feature of CP, difficulties with thinking, learning, feeling, communication and behavior often co-occur, with 28% having epilepsy, 58% having difficulties with communication, at least 42% having problems with their vision, and 23\u201356% having learning disabilities. Muscle contractions in people with cerebral palsy-related high muscle tone are commonly thought to arise from overactivation. Although most people with CP have problems with increased muscle tone, some have low muscle tone instead. High muscle tone can either be due to spasticity or dystonia.\nCerebral palsy is characterized by abnormal muscle tone, reflexes, or motor development and coordination. The neurological lesion is primary and permanent while orthopedic manifestations are secondary to high muscle tone and progressive. In cerebral palsy with high muscle tone, unequal growth between muscle-tendon units and bone eventually leads to bone and joint deformities. At first, deformities are dynamic. Over time, deformities tend to become static, and joint contractures develop. Deformities in general and static deformities in specific (joint contractures) cause increasing gait difficulties in the form of tip-toeing gait, due to tightness of the Achilles tendon, and scissoring gait, due to tightness of the hip adductors. These gait patterns are among the most common gait abnormalities in children with cerebral palsy. However, orthopaedic manifestations of cerebral palsy are diverse. Additionally, crouch gait (also described as knee flexion gait) is prevalent among children who possess the ability to walk. The effects of cerebral palsy fall on a continuum of motor dysfunction, which may range from slight clumsiness at the mild end of the spectrum to impairments so severe that they render coordinated movement virtually impossible at the other end of the spectrum.\nBabies born with severe cerebral palsy often have irregular posture; their bodies may be either very floppy or very stiff. Birth defects, such as spinal curvature, a small jawbone, or a small head sometimes occur along with CP. Symptoms may appear or change as a child gets older. Babies born with cerebral palsy do not immediately present with symptoms. Classically, CP becomes evident when the baby reaches the developmental stage at 6 to 9 months and is starting to mobilise, where preferential use of limbs, asymmetry, or gross motor developmental delay is seen.\nDrooling is common among children with cerebral palsy, which can have a variety of impacts including social rejection, impaired speaking, damage to clothing and books, and mouth infections. It can additionally cause choking.\nAn average of 55.5% of people with cerebral palsy experience lower urinary tract symptoms, more commonly excessive storage issues than voiding issues. Those with voiding issues and pelvic floor overactivity can deteriorate as adults and experience upper urinary tract dysfunction.\nChildren with CP may also have sensory processing issues. Adults with cerebral palsy have a higher risk of respiratory failure.\nSkeleton.\nFor bones to attain their normal shape and size, they require the stresses from normal musculature. People with cerebral palsy are at risk of low bone mineral density. The shafts of the bones are often thin (gracile), and become thinner during growth. When compared to these thin shafts (diaphyses), the centres (metaphyses) often appear quite enlarged (ballooning). Due to more than normal joint compression caused by muscular imbalances, articular cartilage may atrophy, leading to narrowed joint spaces. Depending on the degree of spasticity, a person with the spastic form of CP may exhibit a variety of angular joint deformities. Because vertebral bodies need vertical gravitational loading forces to develop properly, spasticity and an abnormal gait can hinder proper or full bone and skeletal development. People with CP tend to be shorter in height than the average person because their bones are not allowed to grow to their full potential. Sometimes bones grow to different lengths, so the person may have one leg longer than the other.\nChildren with CP are prone to low trauma fractures, particularly children with higher Gross Motor Function Classification System (GMFCS) levels who cannot walk. This further affects a child's mobility, strength, and experience of pain, and can lead to missed schooling or child abuse suspicions. These children generally have fractures in the legs, whereas non-affected children mostly fracture their arms in the context of sporting activities.\nHip dislocation and ankle equinus or plantar flexion deformity are the two most common deformities among children with cerebral palsy. Additionally, flexion deformity of the hip and knee can occur. Torsional deformities of long bones such as the femur and tibia are also encountered, among others. Children may develop scoliosis before the age of 10 \u2013 estimated prevalence of scoliosis in children with CP is between 21% and 64%. Higher levels of impairment on the GMFCS are associated with scoliosis and hip dislocation. Scoliosis can be corrected with surgery, but CP makes surgical complications more likely, even with improved techniques. Hip migration can be managed by soft tissue procedures such as adductor musculature release. Advanced degrees of hip migration or dislocation can be managed by more extensive procedures such as femoral and pelvic corrective osteotomies. Both soft tissue and bony procedures aim at prevention of hip dislocation in the early phases or aim at hip containment and restoration of anatomy in the late phases of disease. Equinus deformity is managed by conservative methods especially when dynamic. If fixed/static deformity ensues surgery may become mandatory.\nGrowth spurts during puberty can make walking more difficult for people with CP and high muscle tone.\nEating.\nDue to sensory and motor impairments, those with CP may have difficulty preparing food, holding utensils, or chewing and swallowing. An infant with CP may not be able to suck, swallow or chew. Gastro-oesophageal reflux is common in children with CP. Children with CP may have too little or too much sensitivity around and in the mouth. Poor balance when sitting, lack of control of the head, mouth, and trunk, not being able to bend the hips enough to allow the arms to stretch forward to reach and grasp food or utensils, and lack of hand-eye coordination can make self-feeding difficult. Feeding difficulties are related to higher GMFCS levels. Dental problems can also contribute to difficulties with eating. Pneumonia is also common where eating difficulties exist, caused by undetected aspiration of food or liquids. Fine finger dexterity, like that needed for picking up a utensil, is more frequently impaired than gross manual dexterity, like that needed for spooning food onto a plate. Grip strength impairments are less common.\nChildren with severe cerebral palsy, particularly with oropharyngeal issues, are at risk of undernutrition. Triceps skin fold tests have been found to be a very reliable indicator of malnutrition in children with cerebral palsy. Due to challenges in feeding, evidence has shown that children with cerebral palsy are at a greater risk of malnutrition.\nLanguage.\nSpeech and language disorders are common in people with cerebral palsy. The incidence of dysarthria is estimated to range from 31% to 88%, and around a quarter of people with CP are non-verbal. Speech problems are associated with poor respiratory control, laryngeal and velopharyngeal dysfunction, and oral articulation disorders that are due to restricted movement in the oral-facial muscles. There are three major types of dysarthria in cerebral palsy: spastic, dyskinetic (athetotic), and ataxic.\nEarly use of augmentative and alternative communication systems may assist the child in developing spoken language skills. Overall language delay is associated with problems of cognition, deafness, and learned helplessness. Children with cerebral palsy are at risk of learned helplessness and becoming passive communicators, initiating little communication. Early intervention with this clientele, and their parents, often targets situations in which children communicate with others so that they learn that they can control people and objects in their environment through this communication, including making choices, decisions, and mistakes.\nPain and sleep.\nPain is common and may result from the inherent deficits associated with the condition, along with the numerous procedures children typically face. When children with cerebral palsy are in pain, they experience worse muscle spasms. Pain is associated with tight or shortened muscles, abnormal posture, stiff joints, unsuitable orthosis, etc. Hip migration or dislocation is a recognizable source of pain in CP children and especially in the adolescent population. Nevertheless, the adequate scoring and scaling of pain in CP children remains challenging. Pain in CP has a number of different causes, and different pains respond to different treatments.\nThere is also a high likelihood of chronic sleep disorders secondary to both physical and environmental factors. Children with cerebral palsy have significantly higher rates of sleep disturbance than typically developing children. Babies with cerebral palsy who have stiffness issues might cry more and be harder to put to sleep than non-disabled babies, or \"floppy\" babies might be lethargic. Chronic pain is under-recognized in children with cerebral palsy, even though three out of four children with cerebral palsy experience pain. Adults with CP also experience more pain than the general population.\nAssociated disorders.\nAssociated disorders include intellectual disabilities, seizures, muscle contractures, abnormal gait, osteoporosis, communication disorders, malnutrition, sleep disorders, and mental health disorders, such as depression and anxiety. Epilepsy is often found in the child before they are 1 year old, or also before they are four or five. In addition to these, functional gastrointestinal abnormalities contributing to bowel obstruction, vomiting, and constipation may also arise. Adults with cerebral palsy may have ischemic heart disease, cerebrovascular disease, cancer, and trauma more often. Obesity in people with cerebral palsy or a more severe Gross Motor Function Classification System assessment in particular are considered risk factors for multimorbidity. Other medical issues can be mistaken for being symptoms of cerebral palsy, and so may not be treated correctly.\nRelated conditions can include apraxia, sensory impairments, urinary incontinence, fecal incontinence, or behavioural disorders.\nSeizure management is more difficult in people with CP as seizures often last longer. Epilepsy and asthma are common co-occurring diseases in adults with CP. The associated disorders that co-occur with cerebral palsy may be more disabling than the motor function problems.\nManaging respiratory illnesses in children with severe CP is considered complex due to the need to manage oropharyngeal dysphagia of both food/drink and saliva, gastroesophageal reflux, motor disorders, upper airway obstruction during sleep, malnutrition, among other factors.\nCauses.\nCerebral palsy is due to abnormal development or damage occurring to the developing brain. This damage can occur during pregnancy, delivery, the first month of life, or less commonly in early childhood. Structural problems in the brain are seen in 80% of cases, most commonly within the white matter.\nMore than three-quarters of cases are believed to result from issues that occur during pregnancy. Most children who are born with cerebral palsy have more than one risk factor associated with CP. Cerebral palsy is not contagious and cannot be contracted in adulthood. CP is almost always developed in utero, or prior to birth.\nWhile in certain cases there is no identifiable cause, typical causes include problems in intrauterine development (e.g. exposure to radiation, infection, fetal growth restriction), hypoxia of the brain (thrombotic events, placental insufficiency, umbilical cord prolapse), birth trauma during labor and delivery, and complications around birth or during childhood.\nIn Africa birth asphyxia, high bilirubin levels, and infections in newborns of the central nervous system are main cause. Many cases of CP in Africa could be prevented with better resources available.\nPreterm birth.\nBetween 40% and 50% of all children who develop cerebral palsy were born prematurely. Most of these cases (75\u201390%) are believed to be due to issues that occur around the time of birth, often just after birth. Multiple-birth infants are also more likely than single-birth infants to have CP. They are also more likely to be born with a low birth weight.\nIn those who are born with a weight between 1\u00a0kg (2.2 lbs) and 1.5\u00a0kg (3.3 lbs) CP occurs in 6%. Among those born before 28\u00a0weeks of gestation it occurs in 8%. Genetic factors are believed to play an important role in prematurity and cerebral palsy generally. In those who are born between 34 and 37\u00a0weeks the risk is 0.4% (three times normal).\nTerm infants.\nIn babies who are born at term risk factors include problems with the placenta, birth defects, low birth weight, breathing meconium into the lungs, a delivery requiring either the use of instruments or an emergency Caesarean section, birth asphyxia, seizures just after birth, respiratory distress syndrome, low blood sugar, and infections in the baby.\nAs of 2013[ [update]], it was unclear how much of a role birth asphyxia plays as a cause. It is unclear if the size of the placenta plays a role. As of 2015[ [update]] it is evident that in advanced countries, most cases of cerebral palsy in term or near-term neonates have explanations other than asphyxia.\nGenetics.\nCerebral palsy is not commonly considered a genetic disease. About 2% of all CP cases are expected to be inherited, with glutamate decarboxylase-1 being one of the possible enzymes involved. Most inherited cases are autosomal recessive. However, the vast majority of CP cases are connected to brain damage during birth and in infancy. There is a small percentage of CP cases caused by brain damage that stemmed from the prenatal period, which is estimated to be less than 5% of CP cases overall. Moreover, there is no one reason why some CP cases come from prenatal brain damage, and it is not known if those cases have a genetic basis.\nCerebellar hypoplasia is sometimes genetic and can cause ataxic cerebral palsy.\nEarly childhood.\nAfter birth, other causes include toxins, severe jaundice, lead poisoning, physical brain injury, stroke, abusive head trauma, incidents involving hypoxia to the brain (such as near drowning), and encephalitis or meningitis.\nOthers.\nInfections in the mother, even those not easily detected, can triple the risk of the child developing cerebral palsy. Infection of the fetal membranes known as chorioamnionitis increases the risk.\nIntrauterine and neonatal insults (many of which are infectious) increase the risk.\nRh blood type incompatibility can cause the mother's immune system to attack the baby's red blood cells.\nIt has been hypothesised that some cases of cerebral palsy are caused by the death in very early pregnancy of an identical twin.\nDiagnosis.\nThe diagnosis of cerebral palsy has historically rested on the person's history and physical examination and is generally assessed at a young age. A general movements assessment, which involves measuring movements that occur spontaneously among those less than four months of age, appears most accurate. Children who are more severely affected are more likely to be noticed and diagnosed earlier. Abnormal muscle tone, delayed motor development and persistence of primitive reflexes are the main early symptoms of CP. Symptoms and diagnosis typically occur by the age of two, although depending on factors like malformations and congenital issues, persons with milder forms of cerebral palsy may be over the age of five, if not in adulthood, when finally diagnosed.\nCognitive assessments and medical observations are also useful to help confirm a diagnosis. Additionally, evaluations of the child's mobility, speech and language, hearing, vision, gait, feeding and digestion are also useful to determine the extent of the disorder. Early diagnosis and intervention are seen as being a key part of managing cerebral palsy. It is a developmental disability.\nOnce a person is diagnosed with cerebral palsy, further diagnostic tests are optional. Neuroimaging with CT or MRI is warranted when the cause of a person's cerebral palsy has not been established. An MRI is preferred over CT, due to diagnostic yield and safety. When abnormal, evidence from neuroimaging may suggest the timing of the initial damage. The CT or MRI is also capable of revealing treatable conditions, such as hydrocephalus, porencephaly, arteriovenous malformation, subdural hematomas and hygromas, and a vermian tumour (which a few studies suggest are present 5\u201322% of the time). Furthermore, abnormalities detected by neuroimaging may indicate a high likelihood of associated conditions, such as epilepsy and intellectual disability. There is a small risk associated with sedating children to facilitate a clear MRI.\nThe age when CP is diagnosed is important, but medical professionals disagree over the best age to make the diagnosis. The earlier CP is diagnosed correctly, the better the opportunities are to provide the child with physical and educational help, but there might be a greater chance of confusing CP with another problem, especially if the child is 18 months of age or younger. Infants may have temporary problems with muscle tone or control that can be confused with CP, which is permanent. A metabolism disorder or tumors in the nervous system may appear to be CP; metabolic disorders, in particular, can produce brain problems that look like CP on an MRI. Disorders that deteriorate the white matter in the brain and problems that cause spasms and weakness in the legs, may be mistaken for CP if they first appear early in life. However, these disorders get worse over time, and CP does not (although it may change in character). In infancy it may not be possible to tell the difference between them. In the UK, not being able to sit independently by the age of 8 months is regarded as a clinical sign for further monitoring. Fragile X syndrome (a cause of autism and intellectual disability) and general intellectual disability must also be ruled out. Cerebral palsy specialist John McLaughlin recommends waiting until the child is 36 months of age before making a diagnosis because, by that age, motor capacity is easier to assess.\nClassification.\nCP is classified by the types of motor impairment of the limbs or organs, and by restrictions to the activities an affected person may perform. The Gross Motor Function Classification System-Expanded and Revised and the Manual Ability Classification System are used to describe mobility and manual dexterity in people with cerebral palsy, and recently the Communication Function Classification System, and the Eating and Drinking Ability Classification System have been proposed to describe those functions. There are three main CP classifications by motor impairment: spastic, ataxic, and dyskinetic. Additionally, there is a mixed type that shows a combination of features of the other types. These classifications reflect the areas of the brain that are damaged.\nCerebral palsy is also classified according to the topographic distribution of muscle spasticity. This method classifies children as diplegic, (bilateral involvement with leg involvement greater than arm involvement), hemiplegic (unilateral involvement), or quadriplegic (bilateral involvement with arm involvement equal to or greater than leg involvement).\nSpastic.\nSpastic cerebral palsy is the type of cerebral palsy characterized by spasticity or high muscle tone often resulting in stiff, jerky movements. Itself an umbrella term encompassing spastic hemiplegia, spastic diplegia, spastic quadriplegia and \u2013 where solely one limb or one specific area of the body is affected \u2013 spastic monoplegia. Spastic cerebral palsy affects the motor cortex of the brain, a specific portion of the cerebral cortex responsible for the planning and completion of voluntary movement. Spastic CP is the most common type of overall cerebral palsy, representing about 80% of cases. Botulinum toxin is effective in decreasing spasticity. It can help increase range of motion which could help mitigate CP's effects on the growing bones of children. There may be an improvement in motor functions in the children and ability to walk. However, the main benefit derived from botulinum toxin A comes from its ability to reduce muscle tone and spasticity and thus prevent or delay the development of fixed muscle contractures.\nAtaxic.\nAtaxic cerebral palsy is observed in approximately 5\u201310% of all cases of cerebral palsy, making it the least frequent form of cerebral palsy. Ataxic cerebral palsy is caused by damage to cerebellar structures. Because of the damage to the cerebellum, which is essential for coordinating muscle movements and balance, patients with ataxic cerebral palsy experience problems in coordination, specifically in their arms, legs, and trunk. Ataxic cerebral palsy is known to decrease muscle tone. The most common manifestation of ataxic cerebral palsy is intention (action) tremor, which is especially apparent when carrying out precise movements, such as tying shoe laces or writing with a pencil. This symptom gets progressively worse as the movement persists, making the hand shake. As the hand gets closer to accomplishing the intended task, the trembling intensifies, which makes it even more difficult to complete.\nDyskinetic.\nDyskinetic cerebral palsy (sometimes abbreviated DCP) is primarily associated with damage to the basal ganglia and the substantia nigra in the form of lesions that occur during brain development due to bilirubin encephalopathy and hypoxic-ischemic brain injury. DCP is characterized by both hypertonia and hypotonia, due to the affected individual's inability to control muscle tone. Clinical diagnosis of DCP typically occurs within 18 months of birth and is primarily based upon motor function and neuroimaging techniques.\nDyskinetic cerebral palsy is an extrapyramidal form of cerebral palsy. Dyskinetic cerebral palsy can be divided into two different groups; choreoathetosis and dystonia. Choreo-athetotic CP is characterized by involuntary movements, whereas dystonic CP is characterized by slow, strong contractions, which may occur locally or encompass the whole body.\nMixed.\nMixed cerebral palsy has symptoms of dyskinetic, ataxic and spastic CP appearing simultaneously, each to varying degrees, and both with and without symptoms of each. Mixed CP is the most difficult to treat as it is extremely heterogeneous and sometimes unpredictable in its symptoms and development over the lifespan.\nGait classification.\nIn patients with spastic hemiplegia or diplegia, various gait patterns can be observed, the exact form of which can only be described with the help of complex gait analysis systems. In order to facilitate interdisciplinary communication in the interdisciplinary team between those affected, doctors, physiotherapists and orthotists, a simple description of the gait pattern is useful. J. Rodda and H. K. Graham already described in 2001 how gait patterns of CP patients can be more easily recognized and defined gait types which they compared in a classification. They also described that gait patterns can vary with age. Building on this, the Amsterdam Gait Classification was developed at the free university in Amsterdam, the VU medisch centrum.\nA special feature of this classification is that it makes different gait patterns very easy to recognize and can be used in CP patients in whom only one leg and both legs are affected. According to the Amsterdam Gait Classification, five gait types are described. To assess the gait pattern, the patient is viewed visually or via a video recording from the side of the leg to be assessed. At the point in time at which the leg to be viewed is in mid stance and the leg not to be viewed is in mid swing, the knee angle and the contact of the foot with the ground are assessed on the one hand.\nClassification of the gait pattern according to the Amsterdam Gait Classification: In gait type 1, the knee angle is normal and the foot contact is complete. In gait type 2, the knee angle is hyperextended and the foot contact is complete. In gait type 3, the knee angle is hyperextended and foot contact is incomplete (only on the forefoot). In gait type 4, the knee angle is bent and foot contact is incomplete (only on the forefoot). With gait type 5, the knee angle is bent and the foot contact is complete.\nGait types 5 is also known as crouch gait.\nPrevention.\nBecause the causes of CP are varied, a broad range of preventive interventions have been investigated.\nElectronic fetal monitoring has not helped to prevent CP, and in 2014 the American College of Obstetricians and Gynecologists, the Royal Australian and New Zealand College of Obstetricians and Gynaecologists, and the Society of Obstetricians and Gynaecologists of Canada have acknowledged that there are no long-term benefits of electronic fetal monitoring. Before this, electronic fetal monitoring was widely used to prop up obstetric litigation.\nIn those at risk of an early delivery, magnesium sulphate appears to decrease the risk of cerebral palsy. It is unclear if it helps those who are born at term. In those at high risk of preterm labor a review found that moderate to severe CP was reduced by the administration of magnesium sulphate, and that adverse effects on the babies from the magnesium sulphate were not significant. Mothers who received magnesium sulphate could experience side effects such as respiratory depression and nausea. However, guidelines for the use of magnesium sulfate in mothers at risk of preterm labour are not strongly adhered to; in 2017 only 2 in 3 eligible women in the UK received the medication despite it being recommended by NICE guidelines. An NHS quality improvement programme increased its usage in England from 71% in 2018 to 83% in 2020.\nCaffeine is used to treat apnea of prematurity and reduces the risk of cerebral palsy in premature babies, but there are also concerns of long term negative effects. A moderate quality level of evidence indicates that giving women antibiotics during preterm labor before her membranes have ruptured (water is not yet not broken) may increase the risk of cerebral palsy for the child. Additionally, for preterm babies for whom there is a chance of fetal compromise, allowing the birth to proceed rather than trying to delay the birth may lead to an increased risk of cerebral palsy in the child. Corticosteroids are sometimes taken by pregnant women expecting a preterm birth to provide neuroprotection to their baby. Taking corticosteroids during pregnancy is shown to have no significant correlation with developing cerebral palsy in preterm births.\nCooling high-risk full-term babies shortly after birth may reduce disability, but this may only be useful for some forms of the brain damage that causes CP.\nManagement.\nOver time, the approach to CP management has shifted away from narrow attempts to fix individual physical problems \u2013 such as spasticity in a particular limb \u2013 to making such treatments part of a larger goal of maximizing the person's independence and community engagement. However, the evidence base for the effectiveness of intervention programs reflecting the philosophy of independence has not yet caught up: effective interventions for body structures and functions have a strong evidence base, but evidence is lacking for effective interventions targeted toward participation, environment, or personal factors. There is also no good evidence to show that an intervention that is effective at the body-specific level will result in an improvement at the activity level or vice versa. Although such cross-over benefit might happen, not enough high-quality studies have been done to demonstrate it.\nBecause cerebral palsy has \"varying severity and complexity\" across the lifespan, it can be considered a collection of conditions for management purposes. A multidisciplinary approach for cerebral palsy management is recommended, focusing on \"maximising individual function, choice and independence\" in line with the International Classification of Functioning, Disability and Health's goals. The team may include a paediatrician, a health visitor, a social worker, a physiotherapist, an orthotist, a speech and language therapist, an occupational therapist, a teacher specialising in helping children with visual impairment, an educational psychologist, an orthopaedic surgeon, a neurologist and a neurosurgeon.\nVarious forms of therapy are available to people living with cerebral palsy as well as caregivers and parents. Treatment may include one or more of the following: physical therapy; occupational therapy; speech therapy; water therapy; drugs to control seizures, alleviate pain, or relax muscle spasms (e.g. benzodiazepines); surgery to correct anatomical abnormalities or release tight muscles; braces and other orthotic devices; rolling walkers; and communication aids such as computers with attached voice synthesisers. Intensive rehabilitation is practiced in certain countries, but obtaining reliable data on its medium and long-term effectiveness is challenging.\nSurgical intervention in CP children may include various orthopaedic or neurological surgeries to improve quality of life, such as tendon releases, hip rotation, spinal fusion, (selective dorsal rhizotomy) or placement of an intrathecal baclofen pump.\nA Cochrane review published in 2004 found a trend toward the benefit of speech and language therapy for children with cerebral palsy but noted the need for high-quality research. A 2013 systematic review found that many of the therapies used to treat CP have no good evidence base; the treatments with the best evidence are medications (anticonvulsants, botulinum toxin, bisphosphonates, diazepam), therapy (bimanual training, casting, constraint-induced movement therapy, context-focused therapy, fitness training, goal-directed training, hip surveillance, home programmes, occupational therapy after botulinum toxin, pressure care) and surgery. There is also research on whether the sleeping position might improve hip migration, but there are not yet high-quality evidence studies to support that theory. Research papers also call for an agreed consensus on outcome measures which will allow researchers to cross-reference research. Also, the terminology used to describe orthoses needs to be standardised to ensure studies can be reproduced and readily compared and evaluated.\nOrthotics in the concept of therapy.\nTo improve the gait pattern, orthotics can be included in the therapy concept. An orthosis can support physiotherapeutic treatment in setting the right motor impulses in order to create new cerebral connections. The orthosis must meet the requirements of the medical prescription. In addition, the orthosis must be designed by the orthotist in such a way that it achieves the effectiveness of the necessary levers, matching the gait pattern, in order to support the proprioceptive approaches of physiotherapy. The characteristics of the stiffness of the orthosis shells and the adjustable dynamics in the ankle joint are important elements of the orthosis to be considered.\nDue to these requirements, the development of orthoses has changed significantly in recent years, especially since around 2010. At about the same time, care concepts were developed that deal intensively with the orthotic treatment of the lower extremities in cerebral palsy. Modern materials and new functional elements enable the rigidity to be specifically adapted to the requirements that fits to the gait pattern of the CP patient. The adjustment of the stiffness has a decisive influence on the gait pattern and on the energy cost of walking. It is of great advantage if the stiffness of the orthosis can be adjusted separately from one another via resistances of the two functional elements in the two directions of movement, dorsiflexion and plantar flexion.\nPrognosis.\nCP is not a progressive disorder (meaning the brain damage does not worsen), but the symptoms can become more severe over time. A person with the disorder may improve somewhat during childhood if he or she receives extensive care, but once bones and musculature become more established, orthopedic surgery may be required. People with CP can have varying degrees of cognitive impairment or none whatsoever. The full intellectual potential of a child born with CP is often not known until the child starts school. People with CP are more likely to have learning disorders but have normal intelligence. Intellectual level among people with CP varies from genius to intellectually disabled, as it does in the general population, and experts have stated that it is important not to underestimate the capabilities of a person with CP and to give them every opportunity to learn.\nThe ability to live independently with CP varies widely, depending partly on the severity of each person's impairment and partly on the capability of each person to self-manage the logistics of life. Some individuals with CP require personal assistant services for all activities of daily living. Others only need assistance with certain activities, and still others do not require any physical assistance. But regardless of the severity of a person's physical impairment, a person's ability to live independently often depends primarily on the person's capacity to manage the physical realities of his or her life autonomously. In some cases, people with CP recruit, hire, and manage a staff of personal care assistants (PCAs). PCAs facilitate the independence of their employers by assisting them with their daily personal needs in a way that allows them to maintain control over their lives.\nPuberty in young adults with cerebral palsy may be precocious or delayed. Delayed puberty is thought to be a consequence of nutritional deficiencies. There is currently no evidence that CP affects fertility, although some of the secondary symptoms have been shown to affect sexual desire and performance. Adults with CP were less likely to get routine reproductive health screening as of 2005. Gynecological examinations may have to be performed under anesthesia due to spasticity, and equipment is often not accessible. Breast self-examination may be difficult, so partners or carers may have to perform it. Men with CP have higher levels of cryptorchidism at the age of 21.\nCP can significantly reduce a person's life expectancy, depending on the severity of their condition and the quality of care they receive. 5\u201310% of children with CP die in childhood, particularly where seizures and intellectual disability also affect the child. The ability to ambulate, roll, and self-feed has been associated with increased life expectancy. While there is a lot of variation in how CP affects people, it has been found that \"independent gross motor functional ability is a very strong determinant of life expectancy\". According to the Australian Bureau of Statistics, in 2014, 104 Australians died of cerebral palsy. The most common causes of death in CP are related to respiratory causes, but in middle age cardiovascular issues and neoplastic disorders become more prominent.\nSelf-care.\nFor many children with CP, parents are heavily involved in self-care activities. Self-care activities, such as bathing, dressing, and grooming, can be difficult for children with CP, as self-care depends primarily on the use of the upper limbs. For those living with CP, impaired upper limb function affects almost 50% of children and is considered the main factor contributing to decreased activity and participation. As the hands are used for many self-care tasks, sensory and motor impairments of the hands make daily self-care more difficult. Motor impairments cause more problems than sensory impairments. The most common impairment is that of finger dexterity, which is the ability to manipulate small objects with the fingers. Compared to other disabilities, people with cerebral palsy generally need more help in performing daily tasks. Occupational therapists are healthcare professionals that help individuals with disabilities gain or regain their independence through the use of meaningful activities.\nProductivity.\nThe effects of sensory, motor, and cognitive impairments affect self-care occupations in children with CP and productivity occupations. Productivity can include but is not limited to, school, work, household chores, or contributing to the community.\nPlay is included as a productive occupation as it is often the primary activity for children. If play becomes difficult due to a disability, like CP, this can cause problems for the child. These difficulties can affect a child's self-esteem. In addition, the sensory and motor problems experienced by children with CP affect how the child interacts with their surroundings, including the environment and other people. Not only do physical limitations affect a child's ability to play, the limitations perceived by the child's caregivers and playmates also affect the child's play activities. Some children with disabilities spend more time playing by themselves. When a disability prevents a child from playing, there may be social, emotional and psychological problems, which can lead to increased dependence on others, less motivation, and poor social skills.\nIn school, students are asked to complete many tasks and activities, many of which involve handwriting. Many children with CP have the capacity to learn and write in the school environment. However, students with CP may find it difficult to keep up with the handwriting demands of school and their writing may be difficult to read. In addition, writing may take longer and require greater effort on the student's part. Factors linked to handwriting include postural stability, sensory and perceptual abilities of the hand, and writing tool pressure.\nSpeech impairments may be seen in children with CP depending on the severity of brain damage. Communication in a school setting is important because communicating with peers and teachers is very much a part of the \"school experience\" and enhances social interaction. Problems with language or motor dysfunction can lead to underestimating a student's intelligence. In summary, children with CP may experience difficulties in school, such as difficulty with handwriting, carrying out school activities, communicating verbally, and interacting socially.\nLeisure.\nLeisure activities can have several positive effects on physical health, mental health, life satisfaction, and psychological growth for people with physical disabilities like CP. Common benefits identified are stress reduction, development of coping skills, companionship, enjoyment, relaxation and a positive effect on life satisfaction. In addition, for children with CP, leisure appears to enhance adjustment to living with a disability.\nLeisure can be divided into structured (formal) and unstructured (informal) activities. Children and teens with CP engage in less habitual physical activity than their peers. Children with CP primarily engage in physical activity through therapies aimed at managing their CP, or through organized sport for people with disabilities. It is difficult to sustain behavioural change in terms of increasing physical activity of children with CP. Gender, manual dexterity, the child's preferences, cognitive impairment and epilepsy were found to affect children's leisure activities, with manual dexterity associated with more leisure activity. Although leisure is important for children with CP, they may have difficulties carrying out leisure activities due to social and physical barriers.\nChildren with cerebral palsy may face challenges when it comes to participating in sports. This comes with being discouraged from physical activity because of these perceived limitations imposed by their medical condition.\nParticipation and barriers.\nParticipation is involvement in life situations and everyday activities. Participation includes self-care, productivity, and leisure. In fact, communication, mobility, education, home life, leisure, and social relationships require participation, and indicate the extent to which children function in their environment. Barriers can exist on three levels: micro, meso, and macro. First, the barriers at the micro level involve the person. Barriers at the micro level include the child's physical limitations (motor, sensory and cognitive impairments) or their subjective feelings regarding their ability to participate. For example, the child may not participate in group activities due to lack of confidence. Second, barriers at the meso level include the family and community. These may include negative attitudes of people toward disability or lack of support within the family or in the community.\nOne of the main reasons for this limited support appears to be the result of a lack of awareness and knowledge regarding the child's ability to engage in activities despite his or her disability. Third, barriers at the macro level incorporate the systems and policies that are not in place or hinder children with CP. These may be environmental barriers to participation such as architectural barriers, lack of relevant assistive technology, and transportation difficulties due to limited wheelchair access or public transit that can accommodate children with CP.\nA 2013 review stated that outcomes for adults with cerebral palsy without intellectual disability in the 2000s were that \"60\u201380% completed high school, 14\u201325% completed college, up to 61% were living independently in the community, 25\u201355% were competitively employed, and 14\u201328% were involved in long term relationships with partners or had established families\". Adults with cerebral palsy may not seek physical therapy due to transport issues, financial restrictions and practitioners not feeling like they know enough about cerebral palsy to take people with CP on as clients.\nAging.\nChildren with CP may not successfully transition into using adult services because they are not referred to one upon turning 18, and may decrease their use of services. Quality of life outcomes tend to decline for adults with cerebral palsy. Because children with cerebral palsy are often told that it is a non-progressive disease, they may be unprepared for the greater effects of the aging process as they head into their 30s. Young adults with cerebral palsy experience problems with aging that non-disabled adults experience \"much later in life\". 25% or more adults with cerebral palsy who can walk experience increasing difficulties walking with age. Hand function does not seem to have similar declines. Chronic disease risk, such as obesity, is also higher among adults with cerebral palsy than the general population. Common problems include increased pain, reduced flexibility, increased spasms and contractures, post-impairment syndrome and increasing problems with balance. Increased fatigue is also a problem. When adulthood and cerebral palsy is discussed, as of 2011[ [update]], it is not discussed in terms of the different stages of adulthood. About half of people with CP report some loss of function as of their 40s.\nLike they did in childhood, adults with cerebral palsy experience psychosocial issues related to their CP, chiefly the need for social support, self-acceptance, and acceptance by others. Workplace accommodations may be needed to enhance continued employment for adults with CP as they age. Rehabilitation or social programs that include salutogenesis may improve the coping potential of adults with CP as they age.\nEpidemiology.\nCerebral palsy occurs in about 2.1 per 1000 live births. In those born at term rates are lower at 1 per 1000 live births. Within a population it may occur more often in poorer people. The rate is higher in males than in females; in Europe it is 1.3 times more common in males.\nThere was a \"moderate, but significant\" rise in the prevalence of CP between the 1970s and 1990s. This is thought to be due to a rise in low birth weight of infants and the increased survival rate of these infants. The increased survival rate of infants with CP in the 1970s and 1980s may be indirectly due to the disability rights movement challenging perspectives around the worth of infants with a disability, as well as the Baby Doe Law. Between 1990 and 2003, rates of cerebral palsy remained the same.\nAs of 2005, advances in the care of pregnant mothers and their babies did not result in a noticeable decrease in CP. This is generally attributed to medical advances in areas related to the care of premature babies (which results in a greater survival rate). Only the introduction of quality medical care to locations with less-than-adequate medical care has shown any decreases. The incidence of CP increases with premature or very low-weight babies regardless of the quality of care. As of 2016[ [update]], there is a suggestion that both incidence and severity are slightly decreasing \u2013 more research is needed to find out if this is significant, and if so, which interventions are effective. It has been found that high-income countries have lower rates of children born with cerebral palsy than low or middle-income countries.\nPrevalence of cerebral palsy is best calculated around the school entry age of about six years; the prevalence in the U.S. is estimated to be 2.4 out of 1000 children.\nHistory.\nCerebral palsy has affected humans since antiquity. A decorated grave marker dating from around the 15th to 14th century BCE shows a figure with one small leg and using a crutch, possibly due to cerebral palsy. The oldest likely physical evidence of the condition comes from the mummy of Siptah, an Egyptian Pharaoh who ruled from about 1196 to 1190\u00a0BCE and died at about 20 years of age. The presence of cerebral palsy has been suspected due to his deformed foot and hands.\nThe medical literature of the ancient Greeks discusses paralysis and weakness of the arms and legs; the modern word \"palsy\" comes from the Ancient Greek words \"\u03c0\u03b1\u03c1\u03ac\u03bb\u03c5\u03c3\u03b9\u03c2\" or \"\u03c0\u03ac\u03c1\u03b5\u03c3\u03b9\u03c2\", meaning paralysis or paresis respectively. In ancient Greece, Hippocrates (c. 460\u2013c. 390 B.C.), often referred to as the Father of Medicine, made early observations regarding the relationship between pregnancy complications and neonatal outcomes. In his treatise \"On the Eight-Month Foetus\", he discussed associations between prematurity, maternal illness, and prenatal stress in the development of congenital conditions. He noted that infants born to mothers who experienced fever, unexplained weight loss, or other health issues during pregnancy were more likely to suffer from physical or neurological impairments. Hippocrates also described increased morbidity and mortality in children he referred to as having \"intrauterine disease\", suggesting an early understanding of fetal distress and its consequences The works of the school of Hippocrates (460\u2013c. 370\u00a0BCE), and the manuscript \"On the Sacred Disease\" in particular, describe a group of problems that matches up very well with the modern understanding of cerebral palsy. The Roman Emperor Claudius (10 BCE\u201354 CE) is suspected of having CP, as historical records describe him as having several physical problems in line with the condition. Medical historians have begun to suspect and find depictions of CP in much later art. Several paintings from the 16th century and later show individuals with problems consistent with it, such as Jusepe de Ribera's 1642 painting \"The Clubfoot\".\nThe modern understanding of CP as resulting from problems within the brain began in the early decades of the 1800s with a number of publications on brain abnormalities by Johann Christian Reil, Claude Fran\u00e7ois Lallemand and Philippe Pinel. Later physicians used this research to connect problems in the brain with specific symptoms. The English surgeon William John Little (1810\u20131894) was the first person to study CP extensively. In his doctoral thesis he stated that CP was a result of a problem around the time of birth. He later identified a difficult delivery, a preterm birth and perinatal asphyxia in particular as risk factors. The spastic diplegia form of CP came to be known as Little's disease. At around this time, a German surgeon was also working on cerebral palsy, and distinguished it from polio. In the 1880s British neurologist William Gowers built on Little's work by linking paralysis in newborns to difficult births. He named the problem \"birth palsy\" and classified birth palsies into two types: peripheral and cerebral.\nWorking in the US in the 1880s, Canadian-born physician William Osler (1849\u20131919) reviewed dozens of CP cases to further classify the disorders by the site of the problems on the body and by the underlying cause. Osler made further observations tying problems around the time of delivery with CP, and concluded that problems causing bleeding inside the brain were likely the root cause. Osler also suspected polioencephalitis as an infectious cause. Through the 1890s, scientists commonly confused CP with polio.\nBefore moving to psychiatry, Austrian neurologist Sigmund Freud (1856\u20131939) made further refinements to the classification of the disorder. He produced the system still being used today. Freud's system divides the causes of the disorder into problems present at birth, problems that develop during birth, and problems after birth. Freud also made a rough correlation between the location of the problem inside the brain and the location of the affected limbs on the body and documented the many kinds of movement disorders.\nIn the early 20th century, the attention of the medical community generally turned away from CP until orthopedic surgeon Winthrop Phelps became the first physician to treat the disorder. He viewed CP from a musculoskeletal perspective instead of a neurological one. Phelps developed surgical techniques for operating on the muscles to address issues such as spasticity and muscle rigidity. Hungarian physical rehabilitation practitioner Andr\u00e1s Pet\u0151 developed a system to teach children with CP how to walk and perform other basic movements. Pet\u0151's system became the foundation for conductive education, widely used for children with CP today. Through the remaining decades, physical therapy for CP has evolved, and has become a core component of the CP management program.\nIn 1997, Robert Palisano \"et al.\" introduced the Gross Motor Function Classification System (GMFCS) as an improvement over the previous rough assessment of limitation as either mild, moderate, or severe. The GMFCS grades limitation based on observed proficiency in specific basic mobility skills such as sitting, standing, and walking, and takes into account the level of dependency on aids such as wheelchairs or walkers. The GMFCS was further revised and expanded in 2007.\nSociety and culture.\nEconomic impact.\nIt is difficult to directly compare the cost and cost-effectiveness of interventions to prevent cerebral palsy or the cost of interventions to manage CP. Access Economics has released a report on the economic impact of cerebral palsy in Australia. The report found that, in 2007, the financial cost of cerebral palsy (CP) in Australia was A$1.47 billion or 0.14% of GDP. Of this:\nThe value of lost well-being (disability and premature death) was a further A$2.4 billion.\nIn per capita terms, this amounts to a financial cost of A$43,431 per person with CP per annum. Including the value of lost well-being, the cost is over $115,000 per person per annum.\nIndividuals with CP bear 37% of the financial costs, and their families and friends bear a further 6%. The federal government bears around one-third (33%) of the financial costs (mainly through taxation revenues forgone and welfare payments). State governments bear under 1% of the costs, while employers bear 5% and the rest of society bears the remaining 19%. If the burden of disease (lost well-being) is included, individuals bear 76% of the costs.\nThe average lifetime cost for people with CP in the US is US$921,000 per individual, including lost income.\nIn the United States, many states allow Medicaid beneficiaries to use their Medicaid funds to hire their own PCAs, instead of forcing them to use institutional or managed care.\nIn India, the government-sponsored program called \"NIRAMAYA\" for the medical care of children with neurological and muscular deformities has proved to be an ameliorating economic measure for persons with such disabilities. It has shown that persons with mental or physically debilitating congenital disabilities can lead better lives if they have financial independence.\nUse of the term.\n\"Cerebral\" means \"of, or pertaining to, the cerebrum or the brain\" and \"palsy\" means \"paralysis, generally partial, whereby a local body area is incapable of voluntary movement\". It has been proposed to change the name to \"cerebral palsy spectrum disorder\" to reflect the diversity of presentations of CP.\nMany people would rather be referred to as a person with a disability (people-first language) instead of as \"handicapped\". \"Cerebral Palsy: A Guide for Care\" at the University of Delaware offers the following guidelines:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe term \"spastic\" denotes the attribute of spasticity in types of spastic CP. In 1952 a UK charity called The Spastics Society was formed. The term \"spastics\" was used by the charity as a term for people with CP. The word \"spastic\" has since been used extensively as a general insult to disabled people, which some see as extremely offensive. They are also frequently used to insult non-disabled people when they seem overly uncoordinated, anxious, or unskilled in sports. The charity changed its name to Scope in 1994. In the United States the word spaz has the same usage as an insult but is not generally associated with CP.\nMedia.\nMaverick documentary filmmaker Kazuo Hara criticises the mores and customs of Japanese society in an unsentimental portrait of adults with cerebral palsy in his 1972 film Goodbye CP. Focusing on how people with cerebral palsy are generally ignored or disregarded in Japan, Hara challenges his society's taboos about physical handicaps. Using a deliberately harsh style, with grainy black-and-white photography and out-of-sync sound, Hara brings a stark realism to his subject.\n\"Spandan\" (2012), a film by Vegitha Reddy and Aman Tripathi, delves into the dilemma of parents whose child has cerebral palsy. While films made with children with special needs as central characters have been attempted before, the predicament of parents dealing with the stigma associated with the condition and beyond is dealt in \"Spandan\". In one of the songs of \"Spandan\" \"Chal chaal chaal tu bala\" more than 50 CP kids have acted. The famous classical singer Devaki Pandit has given her voice to the song penned by Prof. Jayant Dhupkar and composed by National Film Awards winner Isaac Thomas Kottukapally.\n\"My Left Foot\" (1989) is a drama film directed by Jim Sheridan and starring Daniel Day-Lewis. It tells the true story of Christy Brown, an Irishman born with cerebral palsy, who could control only his left foot. Christy Brown grew up in a poor, working-class family, and became a writer and artist. It won the Academy Award for Best Actor (Daniel Day-Lewis) and Best Actress in a Supporting Role (Brenda Fricker). It was also nominated for Best Director, Best Picture and Best Writing, Screenplay Based on Material from Another Medium. It also won the New York Film Critics Circle Award for Best Film for 1989.\n\"Call the Midwife\" (2012\u2013) has featured two episodes with actor Colin Young, who himself has cerebral palsy, playing a character with the same disability. His storylines have focused on the segregation of those with disabilities in the UK in the 1950s, and also romantic relationships between people with disabilities.\nMicah Fowler, an American actor with CP, stars in the ABC sitcom \"Speechless\" (2016\u20132019), which explores both the serious and humorous challenges a family faces with a teenager with CP.\n\"9-1-1\" (2018\u2013) is a procedural drama series on Fox. From season 2 onwards, it features Gavin McHugh (who himself has cerebral palsy) in the recurring role as Christopher Diaz \u2013 a young child who has cerebral palsy.\n\"Special\" (2019) is a comedy series that premiered on Netflix on 12 April 2019. It was written, produced and stars Ryan O'Connell as a young gay man with mild cerebral palsy. It is based on O'Connell's book \"I'm Special: And Other Lies We Tell Ourselves\".\nAustralian drama serial \"The Heights\" (2019\u2013) features a character with mild cerebral palsy, teenage girl Sabine Rosso, depicted by an actor who herself has mild cerebral palsy, Bridie McKim.\n\"6,000 Waiting\" (2021) is a documentary by Michael Joseph McDonald. It is the first film to depict a person with cerebral palsy parachuting. It tells the story of three men with cerebral palsy seeking to live in their communities instead of institutions. Upon seeing the film, American politician Stacey Abrams interviewed one of the film's protagonists and publicly stated that her top priority was deinstitutionalization through Medicaid expansion.\nLitigation.\nBecause of the perception that cerebral palsy is mostly caused by trauma during birth, as of 2005, 60% of obstetric litigation was about cerebral palsy, which Alastair MacLennan, Professor of Obstetrics and Gynaecology at the University of Adelaide, regards as causing an exodus from the profession. In the latter half of the 20th century, obstetric litigation about the cause of cerebral palsy became more common, leading to the practice of defensive medicine.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50606", "revid": "962684227", "url": "https://en.wikipedia.org/wiki?curid=50606", "title": "Liquid drop model", "text": ""}
{"id": "50608", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=50608", "title": "Parkinsonism", "text": "Syndrome characterized by tremor, slowed movements, rigidity, and imbalance\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nParkinsonism is a clinical syndrome characterized by tremor, bradykinesia (slowed movements), rigidity, and postural instability. \nBoth hypokinetic features (bradykinesia and akinesia) and hyperkinetic features (cogwheel rigidity and tremors at rest) are displayed in parkinsonism. These are the four motor signs that are found in Parkinson's disease (PD)\u00a0\u2013 after which Parkinsonism is named\u00a0\u2013 and in dementia with Lewy bodies (DLB), Parkinson's disease dementia (PDD), and many other conditions. \nThis set of signs occurs in a wide range of conditions and may have many causes, including neurodegenerative conditions, drugs, toxins, metabolic diseases, and neurological conditions other than Parkinson's disease.\nSigns and symptoms.\nParkinsonism is a clinical syndrome characterized by the four motor signs that are found in Parkinson's disease: tremor, bradykinesia (slowed movements), rigidity, and postural instability.\nParkinsonism gait problems can lead to falls and serious physical injuries. Other common signs and symptoms include:\nConditions.\nParkinsonism occurs in many conditions.\nNeurological.\nNeurodegenerative conditions and Parkinson-plus syndromes that can cause parkinsonism include:\nToxins.\nEvidence exists to show a link between exposure to pesticides and herbicides and PD; a two-fold increase in risk was seen with paraquat or maneb/mancozeb exposure.\nChronic manganese (Mn) exposure has been shown to produce a parkinsonism-like illness characterized by movement abnormalities. This condition is not responsive to typical therapies used in the treatment of PD, suggesting an alternative pathway than the typical dopaminergic loss within the substantia nigra. Manganese may accumulate in the basal ganglia, leading to the abnormal movements that characterize parkinsonism. A mutation of the SLC30A10 gene, a manganese efflux transporter necessary for decreasing intracellular Mn, has been linked with the development of this parkinsonism-like disease. The Lewy bodies typical to PD are not seen in Mn-induced parkinsonism.\nAgent Orange may be a cause of parkinsonism, although evidence is inconclusive and further research is needed.\nOther toxins that have been associated with parkinsonism are:\nVascular.\nVascular Parkinsonism is typically caused by mini strokes. It typically affects gait, often marked with rigidity. Multiple conditions related to Vascular Parkinsonism include:\nDifferential diagnosis.\nSecondary parkinsonism, including vascular parkinsonism and drug-induced parkinsonism.\nDrug-induced parkinsonism.\nAbout 7% of people with parkinsonism developed symptoms as a result of side effects of medication, mainly neuroleptic antipsychotics, especially the phenothiazines (such as perphenazine and chlorpromazine), thioxanthenes (such as flupentixol and zuclopenthixol) and butyrophenones (such as haloperidol); and rarely, antidepressants. Yet another drug that can induce parkinsonism is the antihistaminic medication cinnarizine, usually prescribed for motion sickness; this is because besides antagonizing histamine receptors this drug antagonizes the dopamine D2 receptors. The incidence of drug-induced parkinsonism increases with age. Drug-induced parkinsonism tends to remain at its presenting level and does not worsen like Parkinson's disease.\nImplicated medications include:\nSociety and culture.\nIn the United States, the 2021 National Defense Authorization Act (NDAA) added parkinsonism to the list of presumptive conditions associated with Agent Orange exposure, enabling affected service members to receive Veterans Affairs disability benefits.\u00a0\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50609", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=50609", "title": "Nuclear shell model", "text": "Model of the atomic nucleus\nIn nuclear physics, atomic physics, and nuclear chemistry, the nuclear shell model utilizes the Pauli exclusion principle to model the structure of atomic nuclei in terms of energy levels. The first shell model was proposed by Dmitri Ivanenko (together with E. Gapon) in 1932. The model was developed in 1949 following independent work by several physicists, most notably Maria Goeppert Mayer and J. Hans D. Jensen, who received the 1963 Nobel Prize in Physics for their contributions to this model, and Eugene Wigner, who received the Nobel Prize alongside them for his earlier foundational work on atomic nuclei.\nThe nuclear shell model is partly analogous to the atomic shell model, which describes the arrangement of electrons in an atom, in that a filled shell results in better stability. When adding nucleons (protons and neutrons) to a nucleus, there are certain points where the binding energy of the next nucleon is significantly less than the last one. This observation that there are specific magic quantum numbers of nucleons (2, 8, 20, 28, 50, 82, and 126) that are more tightly bound than the following higher number is the origin of the shell model.\nThe shells for protons and neutrons are independent of each other. Therefore, there can exist both \"magic nuclei\", in which one nucleon type or the other is at a magic number, and \"doubly magic quantum nuclei\", where both are. Due to variations in orbital filling, the upper magic numbers are 126 and, speculatively, 184 for neutrons, but only 114 for protons, playing a role in the search for the so-called island of stability. Some semi-magic numbers have been found, notably \"Z\"\u00a0=\u00a040, which gives the nuclear shell filling for the various elements; 16 may also be a magic number.\nTo get these numbers, the nuclear shell model starts with an average potential with a shape somewhere between the square well and the harmonic oscillator. To this potential, a spin-orbit term is added. Even so, the total perturbation does not coincide with the experiment, and an empirical spin-orbit coupling must be added with at least two or three different values of its coupling constant, depending on the nuclei being studied.\nThe magic numbers of nuclei, as well as other properties, can be arrived at by approximating the model with a plus a spin\u2013orbit interaction. A more realistic but complicated potential is known as the Woods\u2013Saxon potential.\nModified harmonic oscillator model.\nConsider a . This would give, for example, in the first three levels (\"\u2113\" is the angular momentum quantum number):\nNuclei are built by adding protons and neutrons. These will always fill the lowest available level, with the first two protons filling level zero, the next six protons filling level one, and so on. As with electrons in the periodic table, protons in the outermost shell will be relatively loosely bound to the nucleus if there are only a few protons in that shell because they are farthest from the center of the nucleus. Therefore, nuclei with a full outer proton shell will have a higher nuclear binding energy than other nuclei with a similar total number of protons. The same is true for neutrons.\nThis means that the magic numbers are expected to be those in which all occupied shells are full. In accordance with the experiment, we get 2 (level 0 full) and 8 (levels 0 and 1 full) for the first two numbers. However, the full set of magic numbers does not turn out correctly. These can be computed as follows:\nIn particular, the first six shells are:\nwhere for every \"\u2113\" there are 2\"\u2113\"+1 different values of \"ml\" and 2 values of \"ms\", giving a total of 4\"\u2113\"+2 states for every specific level.\nThese numbers are twice the values of triangular numbers from the Pascal Triangle: 1,\u00a03,\u00a06,\u00a010,\u00a015,\u00a021,\u00a0...\nIncluding a spin-orbit interaction.\nWe next include a spin\u2013orbit interaction. First, we have to describe the system by the quantum numbers \"j\", \"mj\" and parity instead of \"\u2113\", \"ml\" and \"ms\", as in the hydrogen\u2013like atom. Since every even level includes only even values of \"\u2113\", it includes only states of even (positive) parity. Similarly, every odd level includes only states of odd (negative) parity. Thus we can ignore parity in counting states. The first six shells, described by the new quantum numbers, are\nwhere for every \"j\" there are different states from different values of \"mj\".\nDue to the spin\u2013orbit interaction, the energies of states of the same level but with different \"j\" will no longer be identical. This is because in the original quantum numbers, when formula_4 is parallel to formula_5, the interaction energy is positive, and in this case \"j\" = \"\u2113\" + \"s\" = \"\u2113\" + . When formula_4 is anti-parallel to formula_5 (i.e. aligned oppositely), the interaction energy is negative, and in this case . Furthermore, the strength of the interaction is roughly proportional to \"\u2113\".\nFor example, consider the states at level 4:\nChanging the profile of the potential.\nThe harmonic oscillator potential formula_8 grows infinitely as the distance from the center \"r\" goes to infinity. A more realistic potential, such as the Woods\u2013Saxon potential, would approach a constant at this limit. One main consequence is that the average radius of nucleons' orbits would be larger in a realistic potential. This leads to a reduced term formula_9 in the Laplace operator of the Hamiltonian operator. Another main difference is that orbits with high average radii, such as those with high \"n\" or high \"\u2113\", will have a lower energy than in a harmonic oscillator potential. Both effects lead to a reduction in the energy levels of high \"\u2113\" orbits.\nPredicted magic numbers.\nTogether with the spin\u2013orbit interaction, and for appropriate magnitudes of both effects, one is led to the following qualitative picture: at all levels, the highest \"j\" states have their energies shifted downwards, especially for high \"n\" (where the highest \"j\" is high). This is both due to the negative spin\u2013orbit interaction energy and to the reduction in energy resulting from deforming the potential into a more realistic one. The second-to-highest \"j\" states, on the contrary, have their energy shifted up by the first effect and down by the second effect, leading to a small overall shift. The shifts in the energy of the highest \"j\" states can thus bring the energy of states of one level closer to the energy of states of a lower level. The \"shells\" of the shell model are then no longer identical to the levels denoted by \"n\", and the magic numbers are changed.\nWe may then suppose that the highest \"j\" states for \"n\" = 3 have an intermediate energy between the average energies of \"n\" = 2 and \"n\" = 3, and suppose that the highest \"j\" states for larger \"n\" (at least up to \"n\" = 7) have an energy closer to the average energy of . Then we get the following shells (see the figure)\nand so on.\nNote that the numbers of states after the 4th shell are doubled triangular numbers plus two. Spin\u2013orbit coupling causes so-called \"intruder levels\" to drop down from the next higher shell into the structure of the previous shell. The sizes of the intruders are such that the resulting shell sizes are themselves increased to the next higher doubled triangular numbers from those of the harmonic oscillator. For example, 1f2p has 20 nucleons, and spin\u2013orbit coupling adds 1g9/2 (10 nucleons), leading to a new shell with 30 nucleons. 1g2d3s has 30 nucleons, and adding intruder 1h11/2 (12 nucleons) yields a new shell size of 42, and so on.\nThe magic numbers are then\nand so on. This gives all the observed magic numbers and also predicts a new one (the so-called \"island of stability\") at the value of 184 (for protons, the magic number 126 has not been observed yet, and more complicated theoretical considerations predict the magic number to be 114 instead).\nAnother way to predict magic (and semi-magic) numbers is by laying out the idealized filling order (with spin\u2013orbit splitting but energy levels not overlapping). For consistency, s is split into \"j\" = and \"j\" = \u2212 components with 2 and 0 members respectively. Taking the leftmost and rightmost total counts within sequences bounded by / here gives the magic and semi-magic numbers.\nThe rightmost predicted magic numbers of each pair within the quartets bisected by / are double tetrahedral numbers from the Pascal Triangle: 2,\u00a08,\u00a020,\u00a040,\u00a070,\u00a0112,\u00a0168,\u00a0240 are 2x 1,\u00a04,\u00a010,\u00a020,\u00a035,\u00a056,\u00a084,\u00a0120,\u00a0..., and the leftmost members of the pairs differ from the rightmost by double triangular numbers: 2\u00a0\u2212\u00a02\u00a0=\u00a00, 8\u00a0\u2212\u00a06\u00a0=\u00a02, 20\u00a0\u2212\u00a014\u00a0=\u00a06, 40\u00a0\u2212\u00a028\u00a0=\u00a012, 70\u00a0\u2212\u00a050\u00a0=\u00a020, 112\u00a0\u2212\u00a082\u00a0=\u00a030, 168\u00a0\u2212\u00a0126\u00a0=\u00a042, 240\u00a0\u2212\u00a0184\u00a0=\u00a056, where 0,\u00a02,\u00a06,\u00a012,\u00a020,\u00a030,\u00a042,\u00a056,\u00a0... are 2\u00a0\u00d7 0,\u00a01,\u00a03,\u00a06,\u00a010,\u00a015,\u00a021,\u00a028,\u00a0...\u00a0.\nOther properties of nuclei.\nThis model also predicts or explains with some success other properties of nuclei, in particular spin and parity of nuclei ground states, and to some extent their excited nuclear states as well. Take 178O (oxygen-17) as an example: Its nucleus has eight protons filling the first three proton \"shells\", eight neutrons filling the first three neutron \"shells\", and one extra neutron. All protons in a complete proton shell have zero total angular momentum, since their angular momenta cancel each other. The same is true for neutrons. All protons in the same level (\"n\") have the same parity (either +1 or \u22121), and since the parity of a pair of particles is the product of their parities, an even number of protons from the same level (\"n\") will have +1 parity. Thus, the total angular momentum of the eight protons and the first eight neutrons is zero, and their total parity is +1. This means that the spin (i.e. angular momentum) of the nucleus, as well as its parity, are fully determined by that of the ninth neutron. This one is in the first (i.e. lowest energy) state of the 4th shell, which is a d-shell (\"\u2113\" = 2), and since \"p\" = (\u22121)\"\u2113\", this gives the nucleus an overall parity of\u00a0+1. This 4th d-shell has a \"j\" = , thus the nucleus of 178O is expected to have positive parity and total angular momentum , which indeed it has.\nThe rules for the ordering of the nucleus shells are similar to Hund's Rules of the atomic shells, however, unlike its use in atomic physics, the completion of a shell is not signified by reaching the next \"n\", as such the shell model cannot accurately predict the order of excited nuclei states, though it is very successful in predicting the ground states. The order of the first few terms are listed as follows: 1s, 1p, 1p, 1d, 2s, 1d... For further clarification on the notation refer to the article on the Russell\u2013Saunders term symbol.\nFor nuclei farther from the magic quantum numbers one must add the assumption that due to the relation between the strong nuclear force and total angular momentum, protons or neutrons with the same \"n\" tend to form pairs of opposite angular momentum. Therefore, a nucleus with an even number of protons and an even number of neutrons has 0 spin and positive parity. A nucleus with an even number of protons and an odd number of neutrons (or vice versa) has the parity of the last neutron (or proton), and the spin equal to the total angular momentum of this neutron (or proton). By \"last\" we mean the properties coming from the highest energy level.\nIn the case of a nucleus with an odd number of protons and an odd number of neutrons, one must consider the total angular momentum and parity of both the last neutron and the last proton. The nucleus parity will be a product of theirs, while the nucleus spin will be one of the possible results of the sum of their angular momenta (with other possible results being excited states of the nucleus).\nThe ordering of angular momentum levels within each shell is according to the principles described above \u2013 due to spin\u2013orbit interaction, with high angular momentum states having their energies shifted downwards due to the deformation of the potential (i.e. moving from a harmonic oscillator potential to a more realistic one). For nucleon pairs, however, it is often energetically favourable to be at high angular momentum, even if its energy level for a single nucleon would be higher. This is due to the relation between angular momentum and the strong nuclear force.\nThe nuclear magnetic moment of neutrons and protons is partly predicted by this simple version of the shell model. The magnetic moment is calculated through \"j\", \"\u2113\" and \"s\" of the \"last\" nucleon, but nuclei are not in states of well-defined \"\u2113\" and \"s\". Furthermore, for odd-odd nuclei, one has to consider the two \"last\" nucleons, as in deuterium. Therefore, one gets several possible answers for the nuclear magnetic moment, one for each possible combined \"\u2113\" and \"s\" state, and the real state of the nucleus is a superposition of them. Thus the real (measured) nuclear magnetic moment is somewhere in between the possible answers.\nThe electric dipole of a nucleus is always zero, because its ground state has a definite parity. The matter density (\"\u03c8\"2, where \"\u03c8\" is the wavefunction) is always invariant under parity. This is usually the situation with the atomic electric dipole.\nHigher electric and magnetic multipole moments cannot be predicted by this simple version of the shell model for reasons similar to those in the case of deuterium.\nIncluding residual interactions.\nFor nuclei having two or more valence nucleons (i.e. nucleons outside a closed shell), a residual two-body interaction must be added. This residual term comes from the part of the inter-nucleon interaction not included in the approximative average potential. Through this inclusion, different shell configurations are mixed, and the energy degeneracy of states corresponding to the same configuration is broken.\nThese residual interactions are incorporated through shell model calculations in a truncated model space (or valence space). This space is spanned by a basis of many-particle states where only single-particle states in the model space are active. The Schr\u00f6dinger equation is solved on this basis, using an effective Hamiltonian specifically suited for the model space. This Hamiltonian is different from the one of free nucleons as, among other things, it has to compensate for excluded configurations.\nOne can do away with the average potential approximation entirely by extending the model space to the previously inert core and treating all single-particle states up to the model space truncation as active. This forms the basis of the no-core shell model, which is an ab initio method. It is necessary to include a three-body interaction in such calculations to achieve agreement with experiments.\nCollective rotation and the deformed potential.\nIn 1953 the first experimental examples were found of rotational bands in nuclei, with their energy levels following the same J(J+1) pattern of energies as in rotating molecules. Quantum mechanically, it is impossible to have a collective rotation of a sphere, so this implied that the shape of these nuclei was non-spherical. In principle, these rotational states could have been described as coherent superpositions of particle-hole excitations in the basis consisting of single-particle states of the spherical potential. But in reality, the description of these states in this manner is intractable, due to a large number of valence particles\u2014and this intractability was even greater in the 1950s when computing power was extremely rudimentary. For these reasons, Aage Bohr, Ben Mottelson, and Sven G\u00f6sta Nilsson constructed models in which the potential was deformed into an ellipsoidal shape. The first successful model of this type is now known as the Nilsson model. It is essentially the harmonic oscillator model described in this article, but with anisotropy added, so the oscillator frequencies along the three Cartesian axes are not all the same. Typically the shape is a prolate ellipsoid, with the axis of symmetry taken to be z. Because the potential is not spherically symmetric, the single-particle states are not states of good angular momentum J. However, a Lagrange multiplier formula_10, known as a \"cranking\" term, can be added to the Hamiltonian. Usually the angular frequency vector \u03c9 is taken to be perpendicular to the symmetry axis, although tilted-axis cranking can also be considered. Filling the single-particle states up to the Fermi level produces states whose expected angular momentum along the cranking axis formula_11 is the desired value.\nRelated models.\nIgal Talmi developed a method to obtain the information from experimental data and use it to calculate and predict energies which have not been measured. This method has been successfully used by many nuclear physicists and has led to a deeper understanding of nuclear structure. The theory which gives a good description of these properties was developed. This description turned out to furnish the shell model basis of the elegant and successful interacting boson model.\nA model derived from the nuclear shell model is the alpha particle model developed by Henry Margenau, Edward Teller, J. K. Pering, T. H. Skyrme, also sometimes called the Skyrme model. Note, however, that the Skyrme model is usually taken to be a model of the nucleon itself, as a \"cloud\" of mesons (pions), rather than as a model of the nucleus as a \"cloud\" of alpha particles.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50614", "revid": "25511559", "url": "https://en.wikipedia.org/wiki?curid=50614", "title": "Pope Leo XIII", "text": "Head of the Catholic Church from 1878 to 1903\nPope Leo XIII (; born Gioacchino Vincenzo Raffaele Luigi Pecci; 2March 1810\u00a0\u2013 20July 1903) was head of the Catholic Church from 1878 until his death in 1903. He had the fourth-longest reign of any pope, behind those of Peter the Apostle, Pius IX (his predecessor), and John Paul II.\nBorn in Carpineto Romano, near Rome, Leo XIII is well known for his intellectualism and his attempts to define the position of the Catholic Church with regard to modern thinking. In his 1891 encyclical \"Rerum novarum\", Pope Leo outlined the rights of workers to a fair wage, safe working conditions, and the formation of trade unions, while affirming the rights to property and free enterprise, opposing both atheistic socialism and \"laissez-faire\" capitalism. With that encyclical, he became popularly called the \"Social Pope\" and the \"Pope of the Workers\", also having created the foundations for modern thinking in the social doctrines of the Catholic Church, influencing his successors. He influenced the Mariology of the Catholic Church and promoted both the rosary and the scapular. Upon his election, he immediately sought to revive Thomism, the theological system of Augustine of Hippo and Thomas Aquinas, wishing to make it the official political, theological, and philosophical foundation of the Catholic Church. As a result, he sponsored the \"Editio Leonina\" in 1879.\nLeo XIII is remembered for his belief that pastoral activity in political sociology is also a vital mission of the church as a vehicle of social justice and maintaining the rights and dignities of the human person. He issued a record eleven papal encyclicals on the rosary, earning him the title \"Rosary Pope\". He also approved two new Marian scapulars. He was the first pope never to have held any control over the Papal States, which had been dissolved by 1870, since Stephen II in the 8th century. Similarly, many of his policies were oriented toward mitigating the loss of the Papal States in an attempt to overcome the loss of temporal power, but nonetheless continuing the Roman Question. After his death in 1903, he was buried in the Vatican Grottoes. In 1924, his remains were transferred to the Archbasilica of Saint John Lateran.\nEarly life and education (1810\u20131836).\nGioacchino Vincenzo Raffaele Luigi Pecci was born in Carpineto Romano, near Rome, the sixth of the seven children of Count Domenico Ludovico Pecci (2 June 1767 \u2013 8 March 1833), Patrician of Siena, Colonel of the French Army under Napoleon, and his wife Anna Francesca Prosperi-Buzzi (1773 \u2013 9 August 1824). His uncle Giuseppe Pecci was a protonotary apostolic and referendary of the Signature of Justice and died in 1806. His brothers included Giuseppe and Giovanni Battista or Giambattista Pecci (26 October 1802 \u2013 28 March 1882), 1st Count Pecci (\"Comes Romanus\" by Papal brief in 1880), who married on 8 August 1851 Angela Salina (7 February 1830 \u2013 9 October 1899) and had issue, and sister Anna Maria Pecci, wife of Michelangelo Pecci. Until 1818, he lived at home with his family \"in which religion counted as the highest grace on earth, as through her, salvation can be earned for all eternity\". Together with Giuseppe, he studied in the Jesuit College in Viterbo until 1824. He enjoyed Latin and was known to have written his own Latin poems at the age of eleven. Leo was a descendant of the Italian leader Cola di Rienzo on his mother's side.\nHis siblings were:\nIn 1824, he and Giuseppe were called to Rome, where their mother was dying. Count Pecci wanted his children near him after the loss of his wife and so they stayed with him in Rome and attended the Jesuit Collegium Romanum.\nIn 1828, the 18-year-old Vincenzo decided in favour of secular clergy, and Giuseppe entered the Jesuit order. Vincenzo studied at the Academia dei Nobili, mainly diplomacy and law. In 1834, he gave a student presentation, attended by several cardinals, on papal judgments. For his presentation, he received awards for academic excellence and gained the attention of Vatican officials. Cardinal Secretary of State Luigi Lambruschini introduced him to Vatican congregations. During a cholera epidemic in Rome, he assisted Cardinal Giuseppe Antonio Sala in his duties as overseer of all the city hospitals. In 1836, he received his doctorate in theology and doctorates of civil and Canon Law in Rome.\nProvincial administrator (1837\u20131843).\nOn 14 February 1837, Pope Gregory XVI appointed the 27-year-old Pecci as personal prelate even before he was ordained a priest on 31 December 1837 by the Cardinal Vicar Carlo Odescalchi. He celebrated his first Mass with his priest brother Giuseppe. Shortly thereafter, Gregory XVI appointed Pecci as Papal legate (provincial administrator) to Benevento, the smallest Papal province, with a population of about 20,000.\nThe main problems facing Pecci were a decaying local economy, insecurity from widespread bandits, and pervasive Mafia or Camorra structures, which were often allied with aristocratic families. Pecci arrested the most powerful aristocrat in Benevento his troops captured others, who were either killed or imprisoned by him. With public order restored, he turned to the economy and a reform of the tax system to stimulate trade with the neighboring provinces.\nPecci was first destined for Spoleto, a province of 100,000. On 17 July 1841, he was sent to Perugia with 200,000 inhabitants. His immediate concern was to prepare the province for a papal visitation in the same year. Pope Gregory XVI visited hospitals and educational institutions for several days, asking for advice and listing questions. The fight against corruption continued in Perugia, where Pecci investigated several incidents. When it was claimed that a bakery was selling bread below the prescribed pound weight, he personally went there, had all bread weighed and confiscated it if below legal weight. The confiscated bread was distributed to the poor.\nNuncio to Belgium (1843\u20131846).\nIn 1843, Pecci, at only 33, was appointed Apostolic Nuncio to Belgium, a position that guaranteed the cardinal's hat after completion of the tour.\nOn 27 April 1843, Pope Gregory XVI appointed Pecci Archbishop and asked his Cardinal Secretary of State Lambruschini to consecrate him. Pecci developed excellent relations with the royal family and used the location to visit neighboring Germany, where he was particularly interested in the architectural completion of the Cologne Cathedral.\nIn 1844, upon his initiative, a Belgian College in Rome was opened; 102 years later, in 1946, the future Pope John Paul II would begin his Roman studies there. Pecci spent several weeks in England with Bishop Nicholas Wiseman, carefully reviewing the condition of the Catholic Church in that country.\nIn Belgium, the school question was sharply debated between the Catholic majority and the liberal minority. Pecci encouraged the struggle for Catholic schools, but he was able to win the good will of the Court not only of the pious Queen Louise but also of King Leopold I, who was strongly liberal in his views. The new nuncio succeeded in uniting Catholics. At the end of his mission, the King granted him the Grand Cordon in the Order of Leopold.\nArchbishop-Bishop of Perugia (1846\u20131878).\nPapal assistant.\nIn 1843, Pecci had been named papal assistant. From 1846 to 1877, he was considered a popular and successful Archbishop of Perugia. In 1847, after Pope Pius IX granted unlimited freedom for the press in the Papal States, Pecci, who had been highly popular in the first years of his episcopate, became the object of attacks in the media and at his residence. In 1848, revolutionary movements developed throughout Western Europe, including France, Germany and Italy. Austrian, French and Spanish troops reversed the revolutionary gains but at a price for Pecci and the Catholic Church, who could not regain their former popularity.\nProvincial council.\nPecci called a provincial council in 1849 to reform the religious life in his dioceses in Spoleto and it was in this council that the need for a Syllabus of Errors was discussed. He invested in enlarging the seminary for future priests and in hiring new and prominent professors, preferably Thomists. He called on his brother Giuseppe Pecci, a noted Thomist scholar, to resign his professorship in Rome and to teach in Perugia instead. His own residence was next to the seminary, which facilitated his daily contacts with the students.\nCharitable activities.\nWhile archbishop, Pecci developed several activities in support of various Catholic charities. He founded homeless shelters for boys, girls and elderly women. Throughout his dioceses, he opened branches of a \"Bank, Monte di Piet\u00e0\", which focused on low-income people and provided low-interest loans. He created soup kitchens, which were run by the Capuchins. Upon his elevation to the cardinalate in late 1853, and in light of continuing earthquakes and floods, he donated all resources for the festivities of his elevation to the victims. Much of the public attention turned on the conflict between the Papal States and Italian nationalism, which aimed at the Papal States' annihilation to achieve the Unification of Italy.\nCardinalate.\nIn the consistory of 19 December 1853, he was elevated to the College of Cardinals, as Cardinal-Priest of San Crisogono. Pope Gregory XVI originally intended to name him as a cardinal; however, his death in 1846 put pause to that idea while the events that characterized the beginning of the papacy of Pius IX further postponed the idea of Pecci's elevation. By the time that Gregory XVI died, Leopold II repeatedly asked that Pecci be named as a cardinal. While Pius IX strongly desired having Pecci as close to Rome as possible, and repeatedly offered him a suburbicarian diocese, Pecci continually refused due to his preference for Perugia. It is possible that the archbishop did not share the views of the Cardinal Secretary of State, Giacomo Antonelli. It is not true that Pius IX deliberately sent him to Perugia as a way of exiling him from Rome simply because Pecci's views were perceived to be liberalistic and conciliatory, as opposed to the conservatism of the papal court.\nAllegedly, Pecci had been a cardinal reserved \"in pectore\" by Gregory XVI in the consistory of 19 January 1846, with the pope's death just over four months later invalidating the appointment since his name was never actually revealed publicly.\nDefending the papacy.\nPecci defended the papacy and its claims. When Italian authorities expropriated convents and monasteries of Catholic orders, turning them into administration or military buildings, Pecci protested but acted moderately. When the Italian state took over Catholic schools, Pecci, fearing for his theological seminary, simply added all secular topics from other schools and opened the seminary to non-theologians. The new government also levied taxes on the Catholic Church and issued legislation according to which all episcopal or papal utterances were to be approved by the government before their publication.\nOrganization of the First Vatican Council.\nOn 8 December 1869, an ecumenical council, which became known as the First Vatican Council, was to take place in the Vatican per Pope Pius IX. Pecci was likely well informed since the pope named his brother Giuseppe to help prepare the event.\nDuring the 1870s, in his last years in Perugia, Pecci addressed the role of the church in modern society several times, defining the church as \"the mother of material civilization\" because it upheld human dignity of working people, opposed the excesses of industrialization, and developed large-scale charities for the needy.\nIn August 1877, on the death of Cardinal Filippo de Angelis, Pope Pius IX appointed him Camerlengo, which required him to reside in Rome. Reportedly, Pius IX is alleged to have said to Pecci: \"Monsignor, I have decided to summon you to the Senate of the Church. I feel sure this will be the first act of my pontificate that you will not feel called upon to criticize.\" These comments were reported to have been said due to the stories that Pecci and Pius IX had a mutual animosity for each other and disagreed with each other in terms of policy; however, this purported animosity has never been proven. It was further alleged that by this stage Pecci desired a change of scenery from Perugia and hoped for either the bishopric of Albano or the position of datary of the Apostolic Dataria. It has also been said that Pecci was reportedly in line to succeed Cardinal Alessandro Barnab\u00f2 as the prefect for Propaganda Fide; however, it was stymied by his opponent, Cardinal Antonelli.\nPapacy (1878\u20131903).\nElection.\nPope Pius IX died on 7 February 1878, In the conclave, the cardinals faced varied questions and discussed issues like church\u2013state relations in Europe, specifically Italy; divisions in the church; and the status of the First Vatican Council. It was also debated that the conclave be moved elsewhere, but Pecci decided otherwise in his capacity as the camerlengo. On 18 February 1878, the conclave assembled in Rome. Cardinal Pecci was elected on the third ballot and chose the name Leo XIII. He was crowned on 3 March 1878.\nDuring the conclave, he secured his election on the third scrutiny with 44 out of 61 votes, more than the requisite two-thirds majority. While the 1878 conclave was characterized by fewer political influences than in previous conclaves due to a variety of European political crises, it was generally believed that the long papacy of the conservative Pius IX led many of the cardinals to vote for Pecci because his age and health created the expectation that his papacy would be somewhat brief. Following the conclave, John Henry Newman is reported to have said: \"In the successor of Pius I recognize a depth of thought, a tenderness of heart, a winning simplicity, and a power answering to the name of Leo, which prevent me from lamenting that Pius is no longer here.\" In the conclave, Pecci was perceived as the main \"papabile\" candidate; however, Cardinals Flavio Chigi and Tommaso Martinelli were also considered as potential candidates. But some cardinals who opposed Pecci, and were alarmed at the rising votes he was securing, banded together to cast their ballots for Cardinal Alessandro Franchi; however, Franchi secured no votes in the final ballot that saw Pecci duly elected. Allegedly, those who were dedicated to thwarting his election were Cardinals Luigi Oreglia di Santo Stefano, Pietro Giannelli, Chigi, Lorenzo Ilarione Randi, Carlo Sacconi, Raffaele Monaco La Valletta, Luigi Amat di San Filippo e Sorso, and Johann Baptist Franzelin. It was also suggested that, before his death, Pius IX heavily favored Cardinal Luigi Bilio to succeed him, and while many of the cardinals created by the late pope intended to vote for Bilio to honor the man who elevated them in the first place, they feared that voting for an ultra-conservative could potentially evoke a veto from one of the European powers and stall the election more than was necessary. To that end, there had been early talks about Austria possibly vetoing Bilio; however, this never occurred. Before the conclave, Cardinals Domenico Bartolini, Monaco, Bilio, Henry Edward Manning, Lorenzo Nina, and Franchi (proposed by Pecci's opponents) all agreed on supporting Pecci's candidacy, also determining that the next pope needed to be an Italian. Both Manning and Edward Henry Howard agreed to persuade the foreign cardinals to back Pecci's candidacy.\nUpon his election, he announced that he would assume the name \"Leo\" in memory of Pope Leo XII due to his admiration for the late pope's interest in education and his conciliatory attitude toward foreign governments. When asked what name he would take, the new pope responded: \"As Leo XIII, in remembrance of Leo XII, whom I have always venerated\". His election was formally announced to the people of Rome and the world at 1:15pm.\nHe retained the administration of the Perugia see until 1880.\nPontificate.\nAs soon as he was elected to the papacy, Leo XIII worked to encourage understanding between the church and the modern world. When he firmly reasserted the scholastic doctrine that science and religion coexist, he required the study of Thomas Aquinas and opened the Vatican Secret Archives to qualified researchers, among whom was the noted historian of the Papacy Ludwig von Pastor. He also refounded the Vatican Observatory\n\"so that everyone might see clearly that the Church and her Pastors are not opposed to true and solid science, whether human or divine, but that they embrace it, encourage it, and promote it with the fullest possible devotion.\"\nLeo XIII brought normality back to the Catholic Church after the tumultuous years of Pius IX. Leo's intellectual and diplomatic skills helped regain much of the prestige lost with the fall of the Papal States. He tried to reconcile the church with the working class, particularly by dealing with the social changes that were sweeping Europe. The new economic order had resulted in the growth of an impoverished working class who had increasing anticlerical and socialist sympathies. Leo helped reverse that trend.\nAlthough Leo XIII was no radical in either theology or politics, his papacy moved the Catholic Church back to the mainstream of European life. Considered a great diplomat, he managed to improve relations with Russia, Germany, France, Britain and other countries.\nPope Leo XIII was able to reach several agreements in 1896 that resulted in better conditions for the faithful and additional appointments of bishops. During the fifth cholera pandemic in 1891, he ordered the construction of a hospice inside the Vatican. That building would be torn down in 1996 to make way for construction of the Domus Sanctae Marthae.\nLeo was a drinker of the cocaine-infused wine tonic Vin Mariani, a precursor drink to Coca-Cola. He awarded a Vatican gold medal to the wine's creator, Angelo Mariani, and also appeared on a poster endorsing it. Leo XIII was a semi-vegetarian. In 1903, he attributed his longevity to the sparing use of meat and the consumption of eggs, milk and vegetables.\nHis favourite poets were Virgil and Dante.\nForeign relations.\nRussia.\nPope Leo XIII began his pontificate with a friendly letter to Tsar Alexander II in which he reminded the Russian monarch of the millions of Catholics living in his empire who would like to be good Russian subjects if their dignity were respected.\nAfter the assassination of Alexander II, the pope sent a high ranking representative to the coronation of his successor, Alexander III, who was grateful and asked for all religious forces to unify. He asked the pope to ensure that his bishops abstain from political agitation. Relations improved further when Pope Leo XIII, because of Italian considerations, distanced the Vatican from the Rome-Vienna-Berlin alliance, and helped to facilitate a rapprochement between Paris and St. Petersburg.\nGermany.\nUnder Otto von Bismarck, the anti-Catholic \"Kulturkampf\" in Prussia led to significant restrictions on the Catholic Church in the German Empire, including the Jesuits Law of 1872. During Leo's papacy, compromises were informally reached and the anti-Catholic attacks subsided.\nThe Centre Party in Germany represented Catholic interests and was a force for social change. It was encouraged by Leo's support for social welfare legislation and the rights of working people. Leo's forward-looking approach encouraged Catholic Action in other European countries, where the social teachings of the church were incorporated into the agenda of Catholic parties, particularly the Christian democratic parties, which became an acceptable alternative to socialist parties. Leo's social teachings were reiterated throughout the 20th century by his successors.\nIn his \"Memoirs\", Emperor Wilhelm II discussed the \"friendly, trustful relationship that existed between me and Pope Leo XIII.\" During Wilhelm's third visit to Leo: \"It was of interest to me that the Pope said on this occasion that Germany must be the sword of the Catholic Church. I remarked that the old Roman Empire of the German nation no longer existed, and that conditions had changed. But he adhered to his words.\"\nFrance.\nLeo XIII possessed a great affection for France, and feared that the Third Republic would take advantage of the fact that most French Catholics were Royalists to abolish the Concordat of 1801. At the advisement of Cardinal Rampolla, he urged French Catholics to \"rally\" to the republic. Leo's decision upset many French monarchists, who felt they were being forced to betray their king for their faith. Ultimately, this move split the French Church politically and decreased its influence in France. Leo's move also failed to prevent the Concordat's eventual repealment, as it was later abrogated by the 1905 French law on the Separation of the Churches and the State.\nItaly.\nIn the light of a climate hostile to the Catholic Church, Leo continued the policies of Pius IX towards Italy without major modifications. In his relations with the Italian state, Leo continued the Papacy's self-imposed incarceration-in-the-Vatican stance and continued to insist that Italian Catholics should not vote in Italian elections or hold any elected office. In his first consistory in 1879, he elevated his older brother, Giuseppe, to the cardinalate. He had to defend the freedom of the church against what Catholics considered Italian persecution and discrimination in the area of education, expropriation and violation of Catholic Churches, legal measures against the church and acts of terrorism such as anticlerical groups attempting to throw the corpse of Pope Pius IX into the Tiber on 13 July 1881. The pope even considered moving his residence to Trieste or Salzburg, two cities in Austria, an idea that Emperor Franz Joseph I gently rejected.\nUnited Kingdom.\nAmong the activities of Leo XIII that were important for the English-speaking world, he restored the Scottish hierarchy in 1878. The following year, on 12 May 1879, he raised to the rank of cardinal the convert theologian John Henry Newman, who would eventually be beatified by Pope Benedict XVI in 2010 and canonized by Pope Francis in 2019. In British India, too, Leo established a Catholic hierarchy in 1886 and regulated some longstanding conflicts with the Portuguese authorities. A papal rescript (20 April 1888) condemned the Irish Plan of Campaign and all clerical involvement in it as well as boycotting, followed in June by the papal encyclical \"Saepe Nos\" that was addressed to all the Irish bishops. Of outstanding significance, not least for the English-speaking world, was Leo's encyclical \"Apostolicae curae\" on the invalidity of the Anglican orders, published in 1896. In 1899, he declared the Venerable Bede a Doctor of the Church.\nSpain.\nIn 1880, the Santa Maria de Montserrat Abbey in Catalonia celebrated 1000 years of existence. On 11 September 1881, to coincide with the Catalan national day, Leo XIII proclaimed the Virgin of Montserrat to be Patron of Catalonia. This had implications beyond the purely religious sphere, influencing the development of Catalan nationalism.\nBulgaria.\nLeo XIII welcomed the elevation of Prince Ferdinand of Saxe-Coburg (the later Ferdinand I of Bulgaria) to Prince of Bulgaria in 1886. A fellow Catholic, whose wife was a member of the Italian House of Bourbon-Parma, the two had a lot in common. However, relations between the two degenerated when Ferdinand expressed his intention to allow his eldest son Crown Prince Boris (later Tsar Boris III) to convert to Orthodoxy, the majority religion of Bulgaria. Leo strongly condemned the action, and when Ferdinand went through with the conversion anyway, Leo excommunicated him.\nUnited States.\nThe United States frequently attracted his attention and admiration. He confirmed the decrees of the Third Plenary Council of Baltimore (1884) and raised James Gibbons, the archbishop of that city, to the cardinalate in 1886.\nOn 10 April 1887, a pontifical charter from Pope Leo XIII founded the Catholic University of America, establishing the national university of the Catholic Church in the United States.\nAmerican newspapers criticized Pope Leo because they claimed that he was attempting to gain control of American public schools. One cartoonist drew Leo as a fox unable to reach grapes that were labeled for American schools; the caption read \"Sour grapes!\"\nIn 1892, Pope Leo XIII opened the Vatican archives to William Eleroy Curtis, a special envoy planning the commemoration of Christopher Columbus at the 1893 World's Columbian Exposition.\nBrazil.\nPope Leo XIII is remembered for the \"First Plenary Council of Latin America\" held at Rome in 1899, and for his encyclical of 1888 to the bishops of Brazil, \"In plurimis\", on the abolition of slavery. In 1897 he published the Apostolic Letter \"Trans Oceanum\", which dealt with the privileges and ecclesiastical structure of the Catholic Church in Latin America.\nChile.\nHe bestowed his pontifical benediction over Chilean troops on the eve of the Battle of Chorrillos during the War of the Pacific in January 1881. The Chilean soldiers looted the cities of Chorrillos and Barranco, including the churches, and their chaplains headed the robbery at the Biblioteca Nacional del Per\u00fa, where the soldiers ransacked various items along with much capital, and Chilean priests coveted rare and ancient editions of the Bible that were stored there.\nIndia.\nPope Leo XIII urged \"Filii tui India, administri tibi salutis\" (Your own sons, O India, will be the heralds of your salvation) and founded the national seminary, called the Papal Seminary. He entrusted this task to the then Apostolic Delegate to India Ladislaus Michael Zaleski, who founded the Seminary in 1893.\nPhilippines.\nLeo XIII was pope during the Spanish\u2013American War in 1898, in which the United States, a then largely Protestant nation, took control of the Philippines from Spain. In a 1902 meeting with the American Governor-General William Howard Taft, Leo XIII refused to allow the United States government to buy land from Catholic friars in the Philippines.\nEvangelization.\nPope Leo XIII sanctioned the missions to Eastern Africa beginning in 1884. In 1887, he approved the foundation of Missionaries of St. Charles Borromeo, which were organized by the Bishop of Piacenza, Giovanni Battista Scalabrini. The missionaries were sent to North and South America to do pastoral care for Italian immigrants. In 1879 Catholic missionaries associated with the White Father Congregation (Society of the Missionaries of Africa) came to Uganda and others went to Tanganyika (present-day Tanzania) and Rwanda.\nTheology.\nLeo XIII also approved a number of Scapulars. In 1885, he approved the Scapular of the Holy Face, (also known as \"The Veronica\") and elevated the \"Priests of the Holy Face\" to an archconfraternity. He also approved the Scapular of Our Lady of Good Counsel and the Scapular of St. Joseph, both in 1893, and the Scapular of the Sacred Heart in 1900.\nThomism.\nAs pope, he used all his authority for a revival of the theology of Thomas Aquinas. On 4 August 1879, Leo XIII promulgated the encyclical \"Aeterni Patris\" (\"Eternal Father\") \u2014 which, more than any other single document, provided a charter for the revival of Thomism, the medieval theological system based on the thought of Aquinas \u2013 as the official philosophical and theological system of the Catholic Church. It was to be normative not only in the training of priests but also in the education of the laity at universities.\nPope Leo XIII later created the Pontifical Academy of St. Thomas Aquinas on 15 October 1879 and ordered the publication of the critical edition, the so-called Leonine Edition, of the complete works of the \"doctor angelicus\". The superintendence of the Leonine edition was entrusted to Tommaso Maria Zigliara, professor and rector of the \"Collegium Divi Thomae de Urbe\", the future Pontifical University of Saint Thomas Aquinas, today called \"Angelicum\". Leo also founded the \"Angelicum\"'s Faculty of Philosophy in 1882 and its Faculty of Canon Law in 1896.\nConsecration of the world to the Sacred Heart.\nLeo entered new theological territory in consecrating the world to the Sacred Heart of Jesus. After he had received many letters from Sister Mary of the Divine Heart, the countess of Droste zu Vischering and Mother Superior in the Convent of the Good Shepherd Sisters in Porto, Portugal, asking him to consecrate the entire world to the Sacred Heart of Jesus, he commissioned a group of theologians to examine the petition on the basis of revelation and sacred tradition. The outcome of this investigation was positive and so in the encyclical letter \"Annum sacrum\" (on 25 May 1899), he decreed that the consecration of the entire human race to the Sacred Heart of Jesus should take place on 11 June 1899.\nThe encyclical letter also encouraged the entire Catholic episcopate to promote the First Friday Devotions, established June as the Month of the Sacred Heart, and included the Prayer of Consecration to the Sacred Heart.\nPrayer.\nLeo introduced the promotion of monthly prayer intentions in 1890, which he entrusted to the Apostleship of Prayer (now the Pope's Worldwide Prayer Network).\nScriptures.\nIn his 1893 encyclical \"Providentissimus Deus\", he described the importance of scriptures for theological study. It was an important encyclical for Catholic theology and its relation to the Bible, as Pope Pius XII pointed out 50 years later in his encyclical \"Divino afflante Spiritu\".\nEastern Rite Catholics.\nHe devoted his encyclical \"Orientalium dignitas\" of 1894 to preserving Eastern Rite liturgies.\nTheological research.\nLeo XIII is credited with great efforts in the areas of scientific and historical analysis. He opened the Vatican Archives and personally fostered a 20-volume comprehensive scientific study of the Papacy by Ludwig von Pastor, an Austrian historian.\nMariology.\nHis predecessor, Pope Pius IX, became known as the Pope of the Immaculate Conception because of his dogmatization in 1854. Leo XIII, in light of his unprecedented promulgation of the rosary in 11 encyclicals, was called the Rosary Pope because he promulgated Marian devotion. In his encyclical on the 50th anniversary of the Dogma of the Immaculate Conception, he stresses Mary's role in the redemption of humanity and calls her Mediatrix and Co-Redemptrix. While allowing the title \"Mediatrix\", recent popes, following on the Second Vatican Council, have warned away from the term \"co-redemptrix\" as derogating from the one mediator, Jesus Christ.\nSocial teachings.\n\"Rerum novarum\".\nHis encyclicals changed the church's relations with temporal authorities; the 1891 encyclical \"Rerum novarum\", for the first time, addressed social inequality and social justice issues with papal authority by focusing on the rights and duties of capital and labour. He was greatly influenced by Wilhelm Emmanuel von Ketteler, a German bishop who propagated siding with the suffering working classes in his book \"Die Arbeiterfrage und das Christentum\". Since Leo XIII, many papal teachings have expanded on the rights and obligations of workers. Leo argued that both capitalism and communism are flawed. \"Rerum novarum\" introduced the idea of subsidiarity, the principle that political and social decisions should be taken at a local level, if possible, rather than by a central authority, into Catholic social thought.\nConsistories.\nThroughout his pontificate, Leo XIII elevated 147 cardinals in 27 consistories. While the limit of the College of Cardinals had been set at 70 since the papacy of Pope Sixtus V, Leo XIII never exceeded nor reached the limit, only ever coming close at 67 in 1901. Amongst the noteworthy cardinals whom he elevated, he named John Henry Newman as a cardinal while also elevating his own brother Giuseppe Pecci, though not a nepotistic act (it was based purely on recommendation and merit), in the same consistory. In 1893, he elevated Giuseppe Melchiorre Sarto to the cardinalate, who would go on to be his immediate successor, Pope Pius X in 1903. The pope also nominated the brothers, Serafino and Vincenzo Vannutelli and the cousins Luigi and Angelo Jacobini to the Sacred College. Other noteworthy inclusions were Andrea Carlo Ferrari (later beatified in 1987) and Girolamo Maria Gotti.\nOf the 147 cardinals he elevated, 85 were Italian since Leo XIII nominated cardinals from beyond Europe, including the first cardinals from Australia, Canada, Slovenia, and Armenia, the latter of which would be the first Oriental selection since 1439.\nIn 1880, the pope named three cardinals \"in pectore\", announcing them in 1882 and 1884. In 1882, he named another cardinal \"in pectore\", announcing the name later that same year. On 30 December 1889, Leo XIII named only one cardinal whom he reserved \"in pectore\", only announcing the name roughly six months later. In early 1893, he named another two cardinals \"in pectore\", announcing their names in 1894 and 1895, while in April 1901 announcing the names of another two cardinals whom he had reserved \"in pectore\" in June 1899. In June 1896, Leo XIII named two other cardinals in pectore, announcing in March 1898 that both had died, hence, vacating the red hats he would have bestowed upon them.\nWith the elevation of Newman in 1879, it was widely praised throughout the English-speaking world, not simply on the account of Newman's virtues and reputation, but on the basis that Leo XIII had a broader episcopal vision in mind than Pius IX ever did. His similar appointments of two prominent participants of the First Vatican Council, Lajos Haynald and Friedrich Egon von F\u00fcrstenberg both in 1879 was also noteworthy due to their roles in the short-lived Council. It was even alleged that F\u00e9lix Antoine Philibert Dupanloup, a vocal opponent of papal infallibility like Newman, would have been elevated to the cardinalate in 1879 had he not died in October 1878. Additionally, in 1884, the Polish priest and former Curial official Stefan Pawlicki was offered but refused an offer of elevation. Leo XIII later intended to name the Archbishop of Santiago Mariano Santiago Casanova Casanova as a cardinal in 1895; however, the pope abandoned the idea after the Peruvian Church objected that the Archbishop of Lima was the Primate of South America and hence the one that needed to be made a cardinal. In order to avoid a conflict between Chile and Peru, the pope abandoned the idea reluctantly.\nIn 1897, the pope intended to name the Archbishop of Turin Davide Riccardi as a cardinal but the cardinal died before the promotion could take place. In 1891 and again in 1897, the pope offered the cardinalate to Johannes Montel Edler von Treuenfels, the dean of the Sacred Rota, though he refused the honor (he refused again in 1908 when invited by Pope Pius X). In 1899, Leo XIII hoped to nominate the Dominican procurator general Hyacinthe-Marie Cormier (later beatified) to the cardinalate; however, he was unable to do so because the French government did not favor a cardinal from a religious order to seek its best interests as a Curial member. In 1901, he planned to name Agapito Panici as a cardinal at the next consistory, but Panici died before the nomination could take place in 1903. Allegedly, before deciding to name him, Leo XIII asked his brother Diomede to renounce his claim to the red hat, but when Agapito died in 1902, the pope informed Diomede that he would ignore his previous missive asking him to renounce his claim to the red hat, a position that Diomede was never then given. According to witnesses, Leo XIII failed three times to invite Vincenzo Tarozzi (whose cause for beatification has since been launched) to receive the red hat. According to a conversation in 1904 between Pope Pius X and Antonio Mele-Virdis, the former is alleged to have said, \"he should have been in my place\".\nCanonizations and beatifications.\nLeo XIII canonized the following saints during his pontificate:\nLeo XIII beatified several of his predecessors: Urban II (14 July 1881), Victor III (23 July 1887) and Innocent V (9 March 1898). He canonized Adrian III on 2 June 1891.\nHe also beatified the following:\nHe approved the cult of Cosmas of Aphrodisia. He beatified several of the English martyrs in 1895.\nDoctors of the Church.\nLeo XIII named four individuals as Doctors of the Church:\nAudiences.\nOne of the first audiences that Leo XIII granted was to the professors and students of the Collegio Capranica, where in the first row knelt in front of him the young seminarian Giacomo Della Chiesa, the future Pope Benedict XV, who would be pope from 1914 to 1922.\nOn a pilgrimage with her father and sister in 1887, Th\u00e9r\u00e8se of Lisieux attended a general audience with Pope Leo XIII and asked him to allow her to enter the Carmelite order. Even though she was strictly forbidden to speak to him because she was told that it would prolong the audience too much, she addressed him with the Pope telling her: \"If it is God's will that you should enter the Convent, then it shall be\".[a story of a soul]\nIn July 1884 Pope Leo received the French author Jules Verne and his family in a private audience; he was aware of Verne's scientific style of writing.\nSt. Michael Prayer and alleged vision.\nThere are several versions of a story of how Leo came to compose the Prayer to Saint Michael. Various dates are given. A common account says that on the morning of 13 October 1884, Leo XIII celebrated Mass but as he finished, he turned to step down the stairs and allegedly collapsed, falling into what was originally thought to be a coma, but was rather a mystical ecstasy. As the priests and cardinals rushed to his side, Leo XIII rose and visibly shaken, brushed off his aides and rushed back towards his apartment where he immediately wrote the Prayer to Saint Michael the Archangel. Leo XIII reportedly saw a vision of demons being released from Hell, and as the vision ended, he saw Saint Michael charge in and drive them all back into Hell. Leo XIII mandated that the prayer be said after every Low Mass from that point forth.&lt;ref name=\"Vision/St. Michael\"&gt;&lt;/ref&gt;&lt;ref name=\"Low Mass/St. Benedict\"&gt;&lt;/ref&gt;\nIn 1934, a German writer, Fr. Bers, tried to trace the origin of the story and declared that, though the story was widespread, nowhere could he find a trace of proof. Sources close to the institution of the prayer in 1886, including an account of a conversation with Leo XIII about his decision, say nothing of the alleged vision. Bers concluded that the story was a later invention that spread like a virus.\nHealth.\nAt the time of his election in 1878, the pope had started to experience a slight tremor in his hand due to a poorly undertaken bloodletting procedure for a previous malady.\nIn March 1899, it had been believed that the pope was gravely ill and that he was nearing death. Originally, it was presumed that the pope was suffering from a violent case of pneumonia and that the alarm was raised regarding his health. However, it was soon discovered that the reason for the pope's illness was the sudden inflammation of a cyst which had been troubling him for almost thirty years and which had never been previously removed. The only reason it had never been of any particular concern was due to incisions designed for pain relief. While Leo XIII strongly rejected the notion of surgery at first, he was persuaded by Cardinal Mariano Rampolla del Tindaro that it was necessary to ensure his good health. Before the pope was taken for surgery, he asked that his chaplain celebrate Mass in his private chapel while the operation was taking place. Reportedly, the cyst removed \"was the size of an ordinary-sized orange\".\nTowards the end of his life, Leo XIII resorted to using a gold-headed cane when going on walks, as he often found it difficult to do so. While Leo XIII was certainly able to walk without it, he only walked without a cane if he truly felt comfortable doing so. When there were ever rumors about his health, Leo XIII was known to mischievously walk about briskly to dispel the rumors.\nDeath.\nOn 30 June 1903, Leo XIII reported slight feelings of dyspepsia and said that he would take a dose of castor oil to help himself recuperate, shrugging off concerns about his health. While it seemed to work, and the pope resumed his duties with a renewed vigor, it was not to last.\nLeo XIII originally contracted a cold while taking an outing in the Vatican Gardens on 3 July 1903; however, his condition rapidly deteriorated to the point that he had contracted pneumonia. That night, he immediately went to bed and lost consciousness. Originally, the pope refused his doctor's desire to secure a second opinion from a colleague, insisting on a doctor who had previously tended to him in 1899 when he suffered a previous serious illness. When the doctor was immediately summoned to the pope's bedside, he determined that the castor oil had disturbed his stomach and exacerbated his condition. The pope's nephews were immediately notified of their uncle's illness, as were Cardinals Mariano Rampolla del Tindaro and Luigi Oreglia di Santo Stefano in their capacities as the Secretary of State and Camerlengo respectively. On 4 July, the pope made his last confession to Cardinal Serafino Vannutelli and later was barely able to recite the profession of faith. That same day, he experienced a loss of appetite and suffered from shortness of breath. On 5 July, the doctor reported that the hepatisation affected the upper and middle lobes of the right lung, while Leo XIII suffered from considerable cardiac weakness and difficulties in breathing, while reporting the absence of any fever or coughing fits. That same day, after having received the sacraments, the pope said, \"I am now near my end. I do not know if all I have done has been good, but I certainly obeyed my conscience and our faith\".\nOn 6 July 1903, he was administered an injection to ease the pain that he was experiencing, while it was reported that the pneumonia he had contracted was starting to spread to the left lung. The pope, who had an imperceptible pulse, had a restless night and was given oxygen by his doctors. When given the oxygen, Leo XIII replied, \"That is much better. Before I felt as though I had lost my liberty\". That morning, he intimated to those with him that he would prefer it if Cardinal Girolamo Maria Gotti succeeded him in the next conclave. When doctors ordered him to rest, so as not to further aggravate his declining health, Leo XIII said: \"If it were only of any use, but I do not believe it would be. The brief remainder of my life must be given to God's Church, not to my own poor comfort\". The pope lost consciousness but was awake to receive the sacraments at 9:00pm before experiencing yet another restless night, marveling, \"God's will be done. Who would have believed it when only ten days ago I was presiding over a public consistory?\" Leo XIII only slept three hours but severe pain saw him immediately awaken, complaining of pain on both sides of the thorax that forced doctors to move his frail form for better comfort. His situation had previously been critical that afternoon when he was given the Last Rites, while his doctors apprised him of his sudden deterioration. On 7 July, the feeble pope asked that the shutters of his window be opened, saying \"I wish to see once more, perhaps for the last time, the rays of the sun\". In the nights following, the pope suffered from several coughing fits, perspiring heavily due to his rising fever. The pope felt slightly better enough on 10 July to receive a group of Hungarian pilgrims; however, the pope was exhausted and collapsed after the meeting.\nLeo XIII deteriorated further until he died at 3:55pm on 20 July 1903, whispering a final blessing before he died. However, Vatican officials gave the time of his death as 4:04pm when officials officially confirmed that the pope had died. Officially, Leo XIII had died of pneumonia, followed by hemorrhagic pleurisy.\nLeo XIII was the first pope to be born in the 19th century and was also the first to die in the 20th century, living to the age of 93. He is the oldest verified pope to have served in the office. There are three other popes that are claimed to have lived longer than Pope Leo XIII: Pope St Agatho (574\u2013681), who died at the age of 107; Pope Gregory IX (1145\u20131241), who died at the age of 96; and Pope Adrian I (700\u2013795), who died at the age of 95. However, although there is some contemporary documentation attesting to their ages, there is not sufficient evidence for them to be verified with complete certainty; this is due to the poor record keeping typical of the era in which they lived.\nAt the time of his death, Leo XIII was the third-longest-reigning pope (25 years), exceeded only by his immediate predecessor, Pius IX (31 years), and Saint Peter (38 years).\nHe was entombed in Saint Peter's Basilica only briefly after his funeral; he was later moved to the Basilica of Saint John Lateran, his cathedral church as the Bishop of Rome, and a church in which he took a particular interest. He was moved there in late 1924. Leo was the last pope not to be buried in St. Peter's Basilica until Pope Francis was interred at Santa Maria Maggiore in 2025.\nTributes.\nPope Paul VI described Leo XIII as \"great and wise\", his \"first teacher\", from whom he had inherited \"a pastoral outlook and a pastoral approach\".\nUpon his election in 2025, Cardinal Robert Francis Prevost assumed the name Leo XIV in honor of Leo XIII. Leo XIV stated that one of the main reasons he chose his papal name was because of the social justice encyclical \"Rerum novarum\" that was written by Pope Leo XIII.\nSaint Leo University in Saint Leo, Florida, is partially named for Pope Leo XIII, as well as for Pope Leo I.\nIn sound recording and film.\nLeo XIII was the first pope whose voice was recorded. The recording can be found on a compact disc of Alessandro Moreschi's singing; a recording of his praying of the Ave Maria is available on the web. He was also the first pope to be filmed by a motion picture camera. He was filmed in 1898 by inventor W. K. Dickson, and blessed the camera while being filmed. The video contains three segments: the pope on a throne, the pope arriving in a horse-drawn carriage, and the pope taking a seat on a bench. Born in 1810, he might also be the earliest-born known person to appear in a film.\nIn the 2024 film \"Cabrini\", Pope Leo XIII is depicted by Giancarlo Giannini in several scenes offering his support to Mother Cabrini for her mission in the United States in 1889 and thereafter.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "50619", "revid": "1123", "url": "https://en.wikipedia.org/wiki?curid=50619", "title": "Fibonacci code", "text": ""}
