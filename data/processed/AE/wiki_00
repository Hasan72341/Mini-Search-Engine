{"id": "43945", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=43945", "title": "Massage", "text": "Manual kneading of the body's soft tissues\nMassage is the rubbing or kneading of the body's soft tissues. Massage techniques are commonly applied with hands, fingers, elbows, knees, forearms, feet, or a device. The purpose of massage is generally for the treatment of body stress or pain. In English-speaking European countries, traditionally a person professionally trained to give massages is known by the gendered French loanwords \"masseur\" (male) or \"masseuse\" (female). In the United States, these individuals are often referred to as \"massage therapists.\" In some provinces of Canada, they are called \"registered massage therapists.\"\nIn professional settings, clients are treated while lying on a massage table, sitting in a massage chair, or lying on a mat on the floor. There are many different modalities in the massage industry, including (but not limited to): deep tissue, manual lymphatic drainage, medical, sports, structural integration, Swedish, Thai and trigger point.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nEtymology.\nThe word comes from the French 'friction of kneading', which, in turn, comes either from the Arabic word \"massa\" meaning 'to touch, feel', the Portuguese 'knead', from the Latin meaning 'mass, dough', or the Greek verb () 'to handle, touch, to work with the hands, to knead dough'.\nThe ancient Greek word for massage was and the Latin was .\nHistory.\nAncient times.\nArchaeological evidence of massage has been found in many ancient civilizations including China, India, Japan, Egypt, Rome, Greece, and Mesopotamia.\n2330 BC: The Tomb of Akmanthor (also known as \"The Tomb of the Physician\") in Saqqara, Egypt, depicts two men having work done on their feet and hands, possibly depicting a massage.\n1363\u2013912 BC: The word \"mu\u0161\u0161u\u02beu\" (\"massage\") is written for the first time on a Middle Assyrian tablet. Its use is described in a list of recipes concerning diseases of the foot.\n722\u2013481 BC: \"Huangdi Neijing\" is composed during the Chinese Spring and Autumn period. The Nei-jing is a compilation of medical knowledge known up to that date, and is the foundation of traditional Chinese medicine. Massage is referred to in 30 different chapters of the Nei Jing. It specifies the use of different massage techniques and how they should be used in the treatment of specific ailments, and injuries. Also known as \"The Yellow Emperor's Inner Canon,\" the text refers to previous medical knowledge from the time of the Yellow Emperor (c.), misleading some into believing the text itself was written during the time of the Yellow Emperor (which would predate written history).\n762 BC: In the Iliad and the Odyssey, massage with oils and aromatic substances is mentioned as a means to relax the tired limbs of warriors and as a way to help the treatment of wounds.\n700 BC: Bian Que, the earliest known Chinese physician, uses massage in medical practice.\n500 BC: J\u012bvaka Komarabh\u0101cca was an Indian physician who according to the P\u0101li Buddhist Canon was Shakyamuni Buddha's physician. Jivaka is sometimes credited with founding and developing a style of massage that led to the type of massage practiced in modern Thailand. Though this claim is disputed.\n493 BC: A possible biblical reference documents daily \"treatments\" with oil of myrrh as a part of the beauty regimen of the wives of Xerxes (Esther, 2:12).\n460 BC: Hippocrates wrote \"The physician must be experienced in many things, but assuredly in rubbing.\"\n300 BC: Charaka Samhita, sometimes dated to 800 BCE, is one of the oldest of the three ancient treatises of Ayurvedic medicine, including massage. Sanskrit records indicate that massage had been practiced in India long before the beginning of recorded history.\nAD 1st or 2nd: Galen mentioned Diogas (\u0394\u03b9\u03cc\u03b3\u03b1\u03c2) who was an \"iatralipta\" (\u1f30\u03b1\u03c4\u03c1\u03b1\u03bb\u03b5\u03af\u03c0\u03c4\u03b7\u03c2) (rubber and anointer/physiotherapist).\nAD 581: China establishes a department of massage therapy within the Office of Imperial Physicians.\nMiddle Ages.\nOne of the greatest Persian medics was Avicenna, also known as Ibn Sina, who lived from 980 AD to 1037 AD. His works included a comprehensive collection and systematization of the fragmentary and unorganized Greco-Roman medical literature that had been translated Arabic by that time, augmented by notes from his own experiences. One of his books, \"Al-Q\u0101n\u016bn f\u012b a\u1e6d-\u1e6cibb\" (The Canon of Medicine) has been called the most famous single book in the history of medicine in both East and West. Avicenna excelled in the logical assessment of conditions and comparison of symptoms and took special note of analgesics and their proper use as well as other methods of relieving pain, including massage.\nAD 1150: Evidence of massage abortion, involving the application of pressure to the pregnant abdomen, can be found in one of the bas reliefs decorating the temple of Angkor Wat in Cambodia. It depicts a demon performing such an abortion upon a woman who has been sent to the underworld. This is the oldest known visual representation of abortion.\nIn Southeast Asia, massage traditions and techniques have already been entrenched in the people's diverse cultures for centuries before trade contact with Europe in the 16th century. In the Philippines, a distinct massage and healing tradition called hilot developed, while in Thailand, the tradition of massage that developed was called nuad thai. Nuad thai was declared in 2019 as a UNESCO intangible cultural heritage.\n18th and 19th centuries.\nAD 1776: Jean Joseph Marie Amiot and Pierre-Martial Cibot, French missionaries in China translate summaries of Huangdi Neijing, including a list of medical plants, exercises, and elaborate massage techniques, into the French language, thereby introducing Europe to the highly developed Chinese system of medicine, medical-gymnastics, and medical-massage.\nAD 1776: Pehr Henrik Ling, a Swedish physical therapist and teacher of medical-gymnastics, is born. Ling has often been erroneously credited for having invented \"Classic Massage\", also known as \"Swedish Massage\", and has been called the \"Father of Massage\".\nAD 1779: Frenchman Pierre-Martial Cibot publishes \"Notice du Cong-fou des Bonzes Tao-see\", also known as \"The Cong-Fou of the Tao-Tse\", a French language summary of medical techniques used by Taoist priests. According to English historian of China Joseph Needham, Cibot's work \"was intended to present the physicists and physicians of Europe with a sketch of a system of medical gymnastics which they might like to adopt\u2014or if they found it at fault they might be stimulated to invent something better. This work has long been regarded as of cardinal importance in the history of physiotherapy because it almost certainly influenced the Swedish founder of the modern phase of the art, Pehr Hendrik Ling. Cibot had studied at least one Chinese book but also got much from a Christian neophyte who had become expert in the subject before his conversion.\"\nAD 1813: The Royal Gymnastic Central Institute for the training of gymnastic instructors was opened in Stockholm, Sweden, with Pehr Henrik Ling appointed as principal. Ling developed what he called the \"Swedish Movement Cure\". Ling died in 1839, having previously named his pupils as the repositories of his teaching. Ling and his assistants left a little proper written account of their methods.\nAD 1868: Dutch massage practitioner Johan Georg Mezger applies French terms to name five basic massage techniques, and coins the phrase \"Swedish massage system\". These techniques are still known by their French names (effleurage (long, gliding strokes), petrissage (lifting and kneading the muscles), friction (firm, deep, circular rubbing movements), tapotement (brisk tapping or percussive movements) and vibration (rapidly shaking or vibrating specific muscles)).\nModern times.\nChina.\nAs of 2005, with the city of Shanghai alone there were an estimated 1,300\u20132,000 foot massage centers, with more than 3,000 in Shenzhen. It was also estimated that there were nearly 30,000 massage workers in Shanghai and over 40,000 in Shenzhen. The average rate of pay for a worker in the massage industry in China is over 10,000 yuan per month, making them a well-paying job in China's service sector.\nUnited States.\nMassage started to become popular in the United States in the middle part of the 19th century and was introduced by two New York physicians, George and Charles Taylor, based on Pehr Henrik Ling's techniques developed in Sweden.\nDuring the 1930s and 1940s, massage's influence decreased as a result of medical advancements of the time, while in the 1970s massage's influence grew once again with a notable rise among athletes. Until the 1970s, nurses used massage to reduce pain and aid sleep. Popular books and videos, such as Massage for Relaxation, helped introduce massage to popular culture outside of a health setting. The massage therapy industry is continuously increasing. In 2009, U.S. consumers spent between $4 and $6\u00a0billion on visits to massage therapists. In 2015, research estimates that massage therapy was a $12.1\u00a0billion industry.\nAll but five states require massage therapists to be licensed, and licensure requires the applicant to receive training at an accredited school, and to pass a comprehensive exam. Those states that require licensure also typically require continuing education in massage techniques and in ethics.\nUnited Kingdom.\nThe service of massage or \"physiological shampooing\" was advertised in \"The Times\" from as early as 1880. Adverts claimed it as a cure for obesity amongst other chronic ailments.\nSports, business and organizations.\nMassage developed alongside athletics in both Ancient China and Ancient Greece. Taoist priests developed massage in concert with their Kung Fu gymnastic movements, while Ancient Greek Olympians used a specific type of trainer (\"aleiptes\") who would rub their muscles with oil. Pehr Ling's introduction to massage also came about directly as a result of his study of gymnastic movements.\nThe 1984 Summer Olympics in Los Angeles was the first time that massage therapy was televised as it was being performed on the athletes. And then, during the 1996 Summer Olympics in Atlanta massage therapy was finally offered as a core medical service to the US Olympic Team. Massage has been employed by businesses and organizations such as the U.S. Department of Justice, Boeing and Reebok. Athletes such as Michael Jordan and LeBron James have personal massage therapists that at times even travel with them.\nTypes and methods.\nAcupressure.\nAcupressure [from Latin acus \"needle\" (see acuity) + pressure (n.)] is a technique similar in principle to acupuncture. It is based on the concept of life energy which flows through \"meridians\" in the body. In treatment, physical pressure is applied to acupuncture points with the aim of clearing blockages in those meridians. Pressure may be applied by fingers, palm, elbow, toes or with various devices.\nSome medical studies have suggested that acupressure may be effective at helping manage nausea and vomiting, for helping lower back pain, tension headaches, stomach ache, among other things, although such studies have been found to have a high likelihood of bias.\nAshiatsu.\nIn ashiatsu, the practitioner uses their feet to deliver treatment. The name comes from the Japanese, \"ashi\" for foot and \"atsu\" for pressure. This technique typically uses the heel, sesamoid, arch, and/or whole plantar surface of foot, and offers large compression, tension and shear forces with less pressure than an elbow and is ideal for large muscles, such as in thigh, or for long-duration upper trapezius compressions. Other manual therapy techniques using the feet to provide treatment include Keralite, Barefoot Lomilomi, and Chavutti Thirumal.\nAyurvedic massage.\nAyurvedic massage is known as \"Abhyangam\" in Sanskrit. According to the Ayurvedic Classics \"Abhyangam\" is an important dincharya (Daily Regimen) that is needed for maintaining a healthy lifestyle. The massage technique used during Ayurvedic Massage aims to stimulate the lymphatic system. Practitioners claim that the benefits of regular Ayurvedic massage include pain relief, reduction of fatigue, improved immune system and improved longevity.\nBurmese massage.\n\"Known in Myanmar as Yoe Yar Nhake Nal Chin, meaning 'traditional massage', Burmese massage has its ancient origins from Thai, Chinese and Indian medicine. It includes the use of local natural ingredients such as Thanaka which helps to promote smooth skin and prevents sunburn.\"\nBurmese massage is a full body massage technique that starts from head to toes, drawing on acupuncture, reflexology and kneading. Signature massage strokes include acupressure using the elbows, quick gentle knocking of acupressure points, and slow kneading of tight muscles. The massage aims to improve blood circulation and quality of sleep, while at the same time help to promote better skin quality.\nBiomechanical stimulation (BMS) massage.\nBiomechanical stimulation (BMS) is a term generally used for localised biomechanical oscillation methods, whereby local muscle groups are stimulated directly or via the associated tendons by means of special hand held mechanical vibration devices. Biomechanical oscillation therapy and training is offered in a variety of areas such as competitive sports, fitness, rehabilitation, medicine, prevention, beauty and used to improve performance of the muscles and to improve coordination and balance. It is often used in myofascial trigger point therapy to invoke reciprocal inhibition within the musculoskeletal system. Beneficial effects from this type of stimulation have been found to exist.\nBiodynamic massage.\nBiodynamic massage was created by Gerda Boyesen as part of Biodynamic Psychotherapy. It uses a combination of hands-on work and \"energy work\" and also uses a stethoscope to hear the peristalsis.\nCraniosacral therapy.\nCraniosacral therapy (CST) is a pseudoscience that aims to improve fluid movement and cranial bone motion by applying light touch to the skull, face, spine, and pelvis.\nErotic massage.\nA type of massage that is done in an erotic way via the use of massage techniques by a person on another person's erogenous zones to achieve or enhance their sexual excitation or arousal and to achieve orgasm.\nIt was also once used for medical purposes as well as for the treatment of \"female hysteria\" and \"womb disease\".\nNuru massage is a Japanese form of erotic massage.\nHammam massage.\nIn the traditional Hammam, massage involves not just vigorous muscle kneading, but also joint cracking, \"not so much a tender working of the flesh as a pummeling, a cracking of joints, a twisting of limbs...\" An 18th-century traveler reported:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...one of the attendants begins to press and handle the tops of the shoulders, the muscles of the arm, and successively the whole body; first gently, then by degrees increasing the pressure, till he comes to handle pretty roughly, but without giving pain. This is repeated at short intervals till the skin is perfectly softened. The attendant then taking hold of the bather's fingers, with a dexterous jerk makes each joint crack successively; after which, laying him flat on his back, and bringing the arms across the breast, the shoulder joints are made to crack in like manner.\u2014\u200a\nLomilomi and indigenous massage of Oceania.\n\"Lomilomi\" is the traditional massage of Hawaii. As an indigenous practice, it varies by island and by family. The word \"lomilomi\" also is used for massage in Samoa and East Futuna. In Samoa, it is also known as \"lolomi\" and \"milimili\". In East Futuna, it is also called \"milimili\", \"fakasolosolo\", \"amoamo\", \"lusilusi\", \"kinikini\", \"fai'ua\". The M\u0101ori call it \"romiromi\" and \"mirimiri\". In Tonga massage is \"fotofota\", \"tolotolo\", and \"amoamo\". In Tahiti it is \"rumirumi\". On Nanumea in Tuvalu, massage is known as \"popo\", pressure application is \"kukumi\", and heat application is \"tutu\". Massage has also been documented in Tikopia in the Solomon Islands, in Rarotonga, in Pukapuka and in Western Samoa.\nLymphatic drainage.\nManual lymphatic drainage is a technique used to gently work and stimulate the lymphatic system, to assist in reduction of localized swelling. The lymphatic system is a network of slow moving vessels in the body that carries cellular waste toward the liver, to be filtered and removed. Lymph also carries lymphocytes and other immune system agents. Manual lymphatic drainage claims to improve waste removal and immune function.\nMedical massage.\nMedical massage is a controversial term in the massage profession. Many use it to describe a specific technique. Others use it to describe a general category of massage and many methods such as deep tissue massage, myofascial release and trigger-point therapy, as well as osteopathic techniques, cranial-sacral techniques and many more can be used to work with various medical conditions.\nMassage used in the medical field includes decongestive therapy used for lymphedema which can be used in conjunction with the treatment of breast cancer. Light massage is also used in pain management and palliative care. Carotid sinus massage is used to diagnose carotid sinus syncope and is sometimes useful for differentiating supraventricular tachycardia (SVT) from ventricular tachycardia. It, like the valsalva maneuver, is a therapy for SVT. However, it is less effective than management of SVT with medications.\nA 2004 systematic review found single applications of massage therapy \"reduced state anxiety, blood pressure, and heart rate but not negative mood, immediate assessment of pain, and cortisol level,\" while \"multiple applications reduced delayed assessment of pain,\" and found improvements in anxiety and depression similar to effects of psychotherapy. A subsequent systematic review published in 2008 found that there is little evidence supporting the use of massage therapy for depression in high quality studies from randomized controlled trials.\nMyofascial release.\nMyofascial release refers to the manual massage technique that claims to release adhered fascia and muscles with the goal of eliminating pain, increasing range of motion and equilibrioception. Myofascial release usually involves applying shear compression or tension in various directions, cross fiber friction or by skin rolling.\nReflexology.\nReflexology, also known as \"zone therapy\", is an alternative medicine involving application of pressure to the feet and hands with specific thumb, finger, and hand techniques without the use of oil or lotion. It is based on a pseudoscientific belief in a system of zones and reflex areas that purportedly reflect an image of the body on the feet and hands, with the premise that such work effects a physical change to the body.\nShiatsu.\nShiatsu (\u6307\u5727) (\"shi\" meaning finger and \"atsu\" meaning pressure) is a form of Japanese bodywork based on concepts in traditional Chinese medicine such as qi meridians. It consists of finger, palm pressure, stretches, and other massage techniques. There is no convincing data available to suggest that shiatsu is an effective treatment for any medical condition.\nSports massage.\nSports massage is the use of specific massage therapy techniques in an athletic context to improve recovery time, enhance performance and reduce the risk of injury. This is accomplished using techniques that stimulate the flow of blood and lymph to and from muscles. Sports massage is often delivered before or after physical activity depending on the subject's needs, preferences and goals. Sports massages may help with flexibility, pain and recovery but the scientific evidence is mixed.\nStructural Integration.\nStructural Integration's aim is to unwind the strain patterns in the body's myofascial system, restoring it to its natural balance, alignment, length and ease. This is accomplished by hands-on manipulation, coupled with movement re-education. While the promotion and practice of Structural Integration are generally regarded as quackery, there are approximately 15 schools dedicated to its teachings as recognized by the International Association of Structural Integration, including the Dr. Ida Rolf Institute (with the brand Rolfing), Hellerwork, Guild for Structural Integration, Aston Patterning, Soma, and Kinesis Myofascial Integration. \nSwedish massage.\nThe most widely recognized and commonly used category of massage is Swedish massage. The Swedish massage techniques vary from light to vigorous. Swedish massage uses five styles of strokes. The five basic strokes are effleurage (sliding or gliding), petrissage (kneading), tapotement (rhythmic tapping), friction (cross fiber or with the fibers) and vibration/shaking.\nThe development of Swedish massage is often inaccurately credited to Per Henrik Ling, though the Dutch practitioner Johann Georg Mezger applied the French terms to name the basic strokes. The term \"Swedish massage\" is actually only recognized in English- and Dutch-speaking countries, and in Hungary and Israel. Elsewhere the style is referred to as \"classic massage\".\nClinical studies have found that Swedish massage can reduce chronic pain, fatigue, joint stiffness and improve function in patients with osteoarthritis of the knee.\nThai massage.\nKnown in Thailand as \"Nuat phaen boran\", meaning \"ancient/traditional massage\", traditional Thai massage is generally based on a combination of Indian and Chinese traditions of medicine.\nThai massage combines both physical and energetic aspects. It is a deep, full-body massage progressing from the feet up, and focusing on sen or energy lines throughout the body, with the aim of clearing blockages in these lines, and thus stimulating the flow of blood and lymph throughout the body. It draws on yoga, acupressure and reflexology.\nThai massage is a popular massage therapy that is used for the management of conditions such as musculoskeletal pain and fatigue. Thai massage involves a number of stretching movements that improve body flexibility, joint movement and also improve blood circulation throughout the body. In one study scientists found that Thai massage showed comparable efficacy as the painkiller ibuprofen in the reduction of joint pain caused by osteoarthritis (OA) of the knee.\nTraditional Chinese massage.\nMassage of Chinese Medicine is known as \"An Mo\" (\u6309\u6469) (pressing and rubbing) or Qigong Massage and is the foundation of Japan's Anma. Categories include \"Pu Tong An Mo\" (\u666e\u901a\u6309\u6469) (general massage), \"Tui Na An Mo\" (\u63a8\u62ff\u6309\u6469) (pushing and grasping massage), Dian Xue An Mo (cavity pressing massage), and \"Qi An Mo\" (\u6c23\u6309\u6469 ) (energy massage). Tui na (\u63a8\u62ff) focuses on pushing, stretching, and kneading muscles, and \"Zhi Ya\"(\u6307\u58d3) focuses on pinching and pressing at acupressure points. Technique such as friction and vibration are used as well.\nTrigger point therapy.\nSometimes confused with pressure point massage, this involves deactivating trigger points that may cause local pain or refer pain and other sensations, such as headaches, in other parts of the body. Manual pressure, vibration, injection, or other treatment is applied to these points to relieve myofascial pain. Trigger points were first discovered and mapped by Janet G. Travell (President Kennedy's physician) and David Simons. Trigger points have been photomicrographed and measured electrically and in 2007 a paper was presented showing images of Trigger Points using MRI. These points relate to dysfunction in the myoneural junction, also called neuromuscular junction (NMJ), in muscle, and therefore this technique is different from reflexology acupressure and pressure point massage.\nTui na.\nTui na is a Chinese manual therapy technique that includes many different types of strokes, aimed to improve the flow of chi through the meridians.\nWatsu.\nWatsu, developed by Harold Dull at Harbin Hot Springs, California, is a type of aquatic bodywork performed in near-body-temperature water, and characterized by continuous support by the practitioner and gentle movement, including rocking, stretching of limbs, and massage. The technique combines hydrotherapy floating and immersion with shiatsu and other massage techniques. Watsu is used as a form of aquatic therapy for deep relaxation and other therapeutic intent. Related forms include Waterdance, Healing Dance, and Jahara technique.\nFacilities, equipment, and supplies.\nMassage tables and chairs.\nSpecialized massage tables and chairs are used to position recipients during massages. A typical commercial massage table has an easily cleaned, heavily padded surface, and horseshoe-shaped head support that allows the client to breathe easily while lying face down and can be stationary or portable, while home versions are often lighter weight or designed to fold away easily. An orthopedic pillow or bolster can be used to correct body positioning.\nErgonomic chairs serve a similar function as a massage table. Chairs may be either stationary or portable models. Massage chairs are easier to transport than massage tables, and recipients do not need to disrobe to receive a chair massage. Due to these two factors, chair massage is often performed in settings such as corporate offices, outdoor festivals, shopping malls, and other public locations.\nWarm-water therapy pools.\nTemperature-controlled warm-water therapy pools are used to perform aquatic bodywork. For example, Watsu requires a warm-water therapy pool that is approximately chest-deep (depending on the height of the therapist) and temperature-controlled to about 35\u00a0\u00b0C (95\u00a0\u00b0F).\nDry-water massage tables.\nA dry-water massage table uses jets of water to perform the massage of the patient's muscles. These tables differ from a Vichy shower in that the client usually stays dry. Two common types are one in which the client lies on a waterbed-like mattress which contains warm water and jets of water and air bubbles and one in which the client lies on a foam pad and is covered by a plastic sheet and is then sprayed by jets of warm water, similar to a Vichy shower. The first type is sometimes seen available for use in shopping centers for a small fee.\nVichy showers.\nA Vichy shower is a form of hydrotherapy that uses a series of shower nozzles that spray large quantities of water over the client while they lie in a shallow wet bed, similar to a massage table, but with drainage for the water. The nozzles may usually be adjusted for height, direction, and temperature to suit the patient's needs.\nCremes, lotions, gels, and oils.\nMany different types of massage cremes, lotions, gels, and oils are used to lubricate and moisturize the skin and reduce the friction between skin (hands of technician and client).\nMassage tools.\nThese instruments or devices are sometimes used during massages. Some tools are for use by individuals, others by the therapist.\nTools used by massage therapists.\nInstrument-assisted soft-tissue massage can deploy stainless-steel devices to manipulate tissue in a way that augments hands-on work.\nA body rock is a serpentine-shaped tool, usually carved out of stone. It is used to amplify the therapist' strength and focus pressure on certain areas. It can be used directly on the skin with a lubricant such as oil or corn starch or directly over clothing.\nBamboo and rosewood tools are also commonly used. They originate from practices in southeast Asia, Thailand, Cambodia, and Burma. Some of them may be heated, oiled, or wrapped in cloth.\nCupping massage is often carried out using plastic cups and a manual hand-pump to create the vacuum. The vacuum draws the soft tissue perpendicular to the skin, providing a tensile force, which can be left in one site or moved along the tissue during the massage.\nTools used by both individuals and massagers.\nHand-held battery-operated massaging and vibrating instruments are available, including devices for massaging the scalp following a haircut.\nVibrating massage pads come in a range of sizes, some with the option of heating.\nVibrating massage chairs can provide an alternative for therapy at home.\nThere is a widespread market in erotic massage instruments, including electric dildos and vibrators such as the massage wand.\nMedical and therapeutic use.\nThe main professionals that provide therapeutic massage are massage therapists, athletic trainers, physical therapists, and practitioners of many traditional Chinese and other eastern medicines. Massage practitioners work in a variety of medical settings and may travel to private residences or businesses. Certain medical conditions either require modification of technique or avoidance of massage in specific areas. For example, direct massage over a limb affected by deep vein thrombosis (DVT) is considered an absolute contraindication due to the risk of dislodging a clot and causing pulmonary embolism. Massage during anticoagulant therapy (for example, warfarin use) should be applied with caution and often limited to lighter pressure techniques to reduce the risk of bruising or internal bleeding. Likewise, clients with osteoporosis, recent fractures, bone fragility, or certain cancer treatments may require reduced pressure or avoidance of massage over vulnerable areas. Fever or systemic infection is generally regarded as a contraindication until the condition resolves.\nBeneficial effects.\nPeer-reviewed medical research has shown that the benefits of massage include pain relief, reduced trait anxiety and depression, temporarily reduced blood pressure, heart rate, and state of anxiety. Additional testing has shown an immediate increase in, and expedited recovery periods for, muscle performance. Theories behind what massage might do include: enhanced skeletal muscle regrowth and remodeling, blocking nociception (gate control theory), activating the parasympathetic nervous system (which may stimulate the release of endorphins and serotonin, preventing fibrosis or scar tissue), increasing the flow of lymph, and improving sleep.\nInfant massage has been found to hold therapeutic benefits for premature infants and their parents. Premature infants are susceptible to low birth weight and decreased immune function; massage has been found to counter these effects, causing weight increase, reduced pain, and increased immune function. Administering infant massage also reduces stress and increased oxytocin in parental figures regardless of gender, and overall improves emotional attachment with their child.\nMassage research is hindered from reaching the gold standard of scientific inquiry, which includes placebo-controlled and double blind clinical trials. Developing a placebo manual therapy for massage would be difficult, since even light touch massage could have effects on a subject. It would also be difficult to find a subject that would not notice that they were getting less of a massage, and it would be impossible to blind the therapist. Massage research can employ randomized controlled trials, which are published in peer reviewed medical journals. This type of study could increase the credibility of the profession because it displays that purported therapeutic effects are reproducible.\nNeuromuscular effects.\nMassage has been shown to reduce neuromuscular excitability by measuring changes in the Hoffman's reflex (H-reflex) amplitude. A decrease in peak-to-peak H-reflex amplitude suggests a decrease in motoneuron excitability. Others explain, \"H-reflex is considered to be the electrical analogue of the stretch reflex... and the reduction\" is due to a decrease in spinal reflex excitability. Field (2007) confirms that the inhibitory effects are due to deep tissue receptors and not superficial cutaneous receptors, as there was no decrease in H-reflex when looking at light fingertip pressure massage. It has been noted that \"the receptors activated during massage are specific to the muscle being massaged,\" as other muscles did not produce a decrease in H-reflex amplitude.\nGlobal regulation and practice.\nBecause the art and science of massage is a globally diverse phenomenon, different legal jurisdictions sometimes recognize and license individuals with titles, while other areas do not. Examples are:\nIn some jurisdictions, practicing without a license is a crime. One such jurisdiction is Washington state, where any health professionals practicing without a license can be issued a fine and charged with a misdemeanor offense.\nCanada.\nIn regulated provinces massage therapists are known as Registered Massage Therapists, in Canada six provinces regulate massage therapy: British Columbia, Ontario, Newfoundland and Labrador, Prince Edward Island, Saskatchewan, and New Brunswick. Registered Massage Therapy in British Columbia is regulated by the College of Massage Therapists of British Columbia (CMTBC). Regulated provinces have, since 2012, established inter-jurisdiction competency standards. Quebec is not provincially regulated. Massage therapists may obtain a certification with one of the various associations operating. There is the Professional Association of Specialized Massage Therapists of Quebec, also named Mon R\u00e9seau Plus, which represents 6,300 massage therapists (including ortho therapist, natural therapists, and others), the Quebec Federation of massage therapists (FMQ), and the Association qu\u00e9b\u00e9coise des th\u00e9rapeutes naturals; however, none of these are regulated by provincial law.\nCanadian educational institutions undergo a formal accreditation process through the Canadian Massage Therapy Council for Accreditation (CMTCA).\nChina.\nMost types of massage, with the exception of some traditional Chinese medicine, are not regulated in China. Although illegal in China, some of the smaller massage parlors are sometimes linked to the sex industry and the government has taken a number of measures in recent times to curb this. In a nationwide crackdown known as the yellow sweep (\"Yellow\" in Mandarin Chinese refers to sexual activities or pornographic content), limitations on the design and operation of massage parlors have been placed, going so far as requiring identification from customers who visit massage establishments late at night and logging their visits with the local police.\nFrance.\nFrance requires three years of study and two final exams in order to apply for a license.\nGermany.\nIn Germany, massage is regulated by the government on a federal and national level. Only someone who has completed 3,200 hours of training (theoretical and practical) can use the professional title \"Masseur und Medizinischer Bademeister\" 'Masseur and Medical Spa Therapist'. This person can prolong his training depending on the length of professional experience to a Physiotherapist (1 year to 18 months additional training). The Masseur is trained in Classical Massage, Myofascial Massage, Exercise, and Movement Therapy. During the training, they will study anatomy, physiology, pathology, gynecology, podiatry, psychiatry, psychology, surgery, dermiatry, and orthopedics. They are trained in Electrotherapy and Hydrotherapy. Hydrotherapy includes Kneipp, Wraps, underwater massage, therapeutic washing, Sauna, and Steambath. A small part of their training will include special forms of massage which are decided by the local college, for example, foot reflex zone massage, Thai Massage, etc. Finally, a graduate is allowed to treat patients under the direction of a doctor. Graduates are regulated by the professional body which regulates Physiotherapists. This includes restrictions on advertising and the oath of confidentiality to clients.\nIndia.\nIn India, massage therapy is licensed by The Department of Ayurveda, Yoga &amp; Naturopathy, Unani, Siddha, and Homoeopathy (AYUSH) under the Ministry of Health and Family Welfare (India) in March 1995. Massage therapy is based on Ayurveda, the ancient medicinal system that evolved around 600 BC. In ayurveda, massage is part of a set of holistic medicinal practices, contrary to the independent massage system popular in some other systems. In Siddha, Tamil traditional medicine from south India, massage is termed as \"Thokkanam\" and is classified into nine types, each for a specific variety of diseases.\nJapan.\nIn Japan, shiatsu is regulated but oil massage and Thai massage are not. Prostitution in Japan is not heavily policed, and prostitutes posing as massage therapists in \"fashion health\" shops and \"pink salons\" are fairly common in the larger cities.\nMyanmar.\nIn Myanmar, massage is unregulated. However, it is necessary to apply for a spa license with the government to operate a massage parlor in major cities such as Yangon. Blind and visually impaired people can become masseurs, but they are not issued licenses. There are a few professional spa training schools in Myanmar but these training centers are not accredited by the government.\nMexico.\nIn Mexico massage therapists, called \"sobadores\", combine massage using oil or lotion with a form of acupuncture and faith. \"Sobadores\" are used to relieve digestive system problems as well as knee and back pain. Many of these therapists work out of the back of a truck, with just a curtain for privacy. By learning additional holistic healer's skills in addition to massage, the practitioner may become a \"curandero\".\nIn some jurisdictions, prostitution in Mexico is legal, and prostitutes are allowed to sell sexual massages. These businesses are often confined to a specific area of the city, such as the Zona Norte in Tijuana.\nNew Zealand.\nIn New Zealand, massage is unregulated. There are two levels of registration with Massage New Zealand, the professional body for massage therapists within New Zealand, although neither of these levels are government recognized. Registration at the certified massage therapist level denotes competency in the practice of relaxation massage. Registration at the remedial massage therapist denotes competency in the practice of remedial or orthopedic massage. Both levels of registration are defined by agreed minimum competencies and minimum hours.\nSouth Africa.\nIn South Africa, massage is regulated, but enforcement is poor. The minimum legal requirement to be able to practice as a professional massage therapist is a two-year diploma in therapeutic massage and registration with the Allied Health Professions Council of SA (AHPCSA). The qualification includes 240 credits, about 80 case studies, and about 100 hours of community service.\nSouth Korea.\nIn South Korea, only blind and visually impaired people can become licensed masseurs.\nThailand.\nIn Thailand, Thai massage is officially listed as one of the branches of traditional Thai medicine, recognized and regulated by the government. It is considered to be a medical discipline in its own right and is used for the treatment of a wide variety of ailments and conditions. Massage schools, centers, therapists, and practitioners are increasingly regulated by the Ministries of Education and Public Health in Thailand.\nUnited Kingdom.\nTo practice commercial massage or massage therapy in the UK, an ITEC or VTCT certificate must be obtained through training which includes Beauty and Spa Therapy, Hairdressing, Complementary Therapies, Sports &amp; Fitness Training and Customer Service.\nTherapists with appropriate paperwork and insurance may join the Complementary and Natural Healthcare Council (CNHC), a voluntary, government regulated, professional register. Its key aim is to protect the public.\nIn addition, there are many professional bodies that have a required minimum standard of education and hold relevant insurance policies including the Federation of Holistic Therapists (FHT), the Complementary Therapists Association (CThA), and the Complementary Health Professionals (CHP). In contrast to the CNHC these bodies exist to support therapists rather than clients.\nUnited States.\nAccording to research done by the American Massage Therapy Association, as of 2012 in the United States, there are between 280,000 and 320,000 massage therapists and massage school students. As of 2022, there are an estimated 872 state-approved massage training programs operating in the U.S. Most states have licensing requirements that must be met before a practitioner can use the title \"massage therapist\", and some states and municipalities require a license to practice any form of massage. If a state does not have any massage laws then a practitioner need not apply for a license with the state. Training programs in the US are typically 500 hours to 1000 hours in total training time and can award a certificate, diploma, or degree depending on the particular school. Study will often include anatomy and physiology, kinesiology, massage techniques, first aid and CPR, business, ethical and legal issues, and hands-on practice along with continuing education requirements if regulated. The Commission on Massage Therapy Accreditation (COMTA) is one of the organizations that works with massage schools in the U.S. and there are almost 300 schools that are accredited through this agency.\nForty-seven states, Puerto Rico, and the District of Columbia offer some type of credential to professionals in the massage and bodywork field\u2014usually licensure, certification or registration. Forty-five states require some type of licensing for massage therapists. There are two nationally recognized tests to gain a massage therapy license, as well as state-specific exams. In the US, 38 states accept the National Certification Board for Therapeutic Massage and Bodywork's (NCBTMB) later unavailable certification program as a basis for granting licenses either by rule or statute. The NCBTMB formerly offered the designation Nationally Certified in Therapeutic Massage and Bodywork (NCTMB) but only offers its certificate program, Board Certification in Therapeutic Massage and Bodywork (BCTMB) which does not qualify for licensure. Forty-three states, as well as Puerto Rico and the District of Columbia, accept the Massage &amp; Bodywork Licensing Examination (MBLEx), administered by the Federation of State Massage Therapy Boards (FSMTB). Between 10% and 20% of towns or counties independently regulate the profession. These local regulations can range from prohibition on opposite sex massage, fingerprinting and venereal checks from a doctor, to prohibition on house calls because of concern regarding sale of sexual services.\nIn the US, licensure is the highest level of regulation and this restricts anyone without a license from practicing massage therapy or calling themselves by that protected title. Certification allows only those who meet certain educational criteria to use the protected title and registration only requires a listing of therapists who apply and meet an educational requirement. In the US, most certifications are locally based. A massage therapist may be certified, but not licensed. Licensing requirements vary per state, and often require additional criteria be met in addition to attending an accredited massage therapy school and passing a required state-specified exam. Only Kansas, Minnesota, and Wyoming, California and Vermont do not require a license or a certification at the state level. Some states allow license reciprocity, where licensed massage therapists who relocate can relatively easily obtain a license in their new state.\nIn New York State in 2024, a man was arrested and charged with three counts of third-degree Sexual Abuse and three counts of Forcible Touching, as well as New York State Education Department Law violations, for providing massage therapy services without a New York State license to do so.\nIn 1997 there were an estimated 114 million visits to massage therapists in the US. Massage therapy is the most used type of alternative medicine in hospitals in the United States. Between July 2010 and July 2011 roughly 38 million adult Americans (18 percent) had a massage at least once. People state that they use massage because they believe that it relieves pain from musculoskeletal injuries and other causes of pain, reduces stress and enhances relaxation, rehabilitates sports injuries, decreases feelings of anxiety and depression, and increases general well-being.\nIn a poll of 25\u201335-year-olds, 79% said they would like their health insurance plan to cover massage. In 2006 Duke University Health System opened up a center to integrate medical disciplines with CAM disciplines such as massage therapy and acupuncture. There were 15,500 spas in the United States in 2007, with about two-thirds of the visitors being women.\nThe number of visits rose from 91 million in 1999 to 136\u00a0million in 2003, generating a revenue that equals $11\u00a0billion. Job outlook for massage therapists was also projected to grow at 20% between 2010 and 2020 by the Bureau of Labor Statistics, faster than the average.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43946", "revid": "40826289", "url": "https://en.wikipedia.org/wiki?curid=43946", "title": "Biofilm", "text": "Film of microorganisms on a surface\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n IUPAC definition\n \"Aggregate\" of microorganisms in which cells that are frequently embedded within a self-produced matrix of extracellular polymeric substances (EPSs) adhere to each other and/or to a surface.\nA biofilm is a syntrophic community of microorganisms in which cells stick to each other and often also to a surface. These adherent cells become embedded within a slimy extracellular matrix that is composed of extracellular polymeric substances (EPSs). The cells within the biofilm produce the EPS components, which are typically a polymeric combination of extracellular polysaccharides, proteins, lipids and DNA. Because they have a three-dimensional structure and represent a community lifestyle for microorganisms, they have been metaphorically described as \"cities for microbes\".\nBiofilms may form on living (biotic) or non-living (abiotic) surfaces and can be common in natural, industrial, and hospital settings. They may constitute a microbiome or be a portion of it. The microbial cells growing in a biofilm are physiologically distinct from planktonic cells of the same organism, which, by contrast, are single cells that may float or swim in a liquid medium. Biofilms can form on the teeth of most animals as dental plaque, where they may cause tooth decay and gum disease.\nMicrobes form a biofilm in response to a number of different factors, which may include cellular recognition of specific or non-specific attachment sites on a surface, nutritional cues, lack of light or in some cases, by exposure of planktonic cells to sub-inhibitory concentrations of antibiotics. A cell that switches to the biofilm mode of growth undergoes a phenotypic shift in behavior in which large suites of genes are differentially regulated.\nA biofilm may also be considered a hydrogel, which is a complex polymer that contains many times its dry weight in water. Biofilms are not just bacterial slime layers but biological systems; the bacteria organize themselves into a coordinated functional community. Biofilms can attach to a surface such as a tooth or rock, and may include a single species or a diverse group of microorganisms. Subpopulations of cells within the biofilm differentiate to perform various activities for motility, matrix production, and sporulation, supporting the overall success of the biofilm. The biofilm bacteria can share nutrients and are sheltered from harmful factors in the environment, such as desiccation, antibiotics, and a host body's immune system. A biofilm usually begins to form when a free-swimming, planktonic bacterium attaches to a surface.\nOrigin and formation.\nOrigin of biofilms.\nBiofilms are thought to have arisen during primitive Earth as a defense mechanism for prokaryotes, as the conditions at that time were too harsh for their survival. They can be found very early in Earth's fossil records (about 3.25\u00a0billion years ago) as both Archaea and Bacteria, and commonly protect prokaryotic cells by providing them with homeostasis, encouraging the development of complex interactions between the cells in the biofilm.\nFormation of biofilms.\nThe formation of a biofilm begins with the attachment of free-floating microorganisms to a surface. The first colonist bacteria of a biofilm may adhere to the surface initially by the weak van der Waals forces and hydrophobic effects. If the colonists are not immediately separated from the surface, they can anchor themselves more permanently using cell adhesion structures such as pili. A unique group of Archaea that inhabit anoxic groundwater have similar structures called hami. Each hamus is a long tube with three hook attachments that are used to attach to each other or to a surface, enabling a community to develop. Hyperthermophilic archaeon \"Pyrobaculum calidifontis\" produce bundling pili which are homologous to the bacterial TasA filaments, a major component of the extracellular matrix in bacterial biofilms, which contribute to biofilm stability. TasA homologs are encoded by many other archaea, suggesting mechanistic similarities and evolutionary connection between bacterial and archaeal biofilms.\nHydrophobicity can also affect the ability of bacteria to form biofilms. Bacteria with increased hydrophobicity have reduced repulsion between the substratum and the bacterium. Some bacteria species are not able to attach to a surface on their own successfully due to their limited motility but are instead able to anchor themselves to the matrix or directly to other, earlier bacteria colonists. Non-motile bacteria cannot recognize surfaces or aggregate together as easily as motile bacteria.\nDuring surface colonization bacteria cells are able to communicate using quorum sensing (QS) products such as N-acyl homoserine lactone (AHL). Once colonization has begun, the biofilm grows by a combination of cell division and recruitment. Polysaccharide matrices typically enclose bacterial biofilms. The matrix exopolysaccharides can trap QS autoinducers within the biofilm to prevent predator detection and ensure bacterial survival. In addition to the polysaccharides, these matrices may also contain material from the surrounding environment, including but not limited to minerals, soil particles, and blood components, such as erythrocytes and fibrin. \nThe development of a biofilm may allow for an aggregate cell colony to be increasingly tolerant or resistant to antibiotics. Cell-cell communication or quorum sensing has is involved in the formation of biofilm in several bacterial species.\nDevelopment.\nBiofilms are the product of a microbial developmental process. The process is summarized by five major stages of biofilm development, as shown in the diagram below:\nDispersal.\nDispersal of cells from the biofilm colony is an essential stage of the biofilm life cycle. Dispersal enables biofilms to spread and colonize new surfaces. Enzymes that degrade the biofilm extracellular matrix, such as dispersin B and deoxyribonuclease, may contribute to biofilm dispersal. Enzymes that degrade the biofilm matrix may be useful as anti-biofilm agents. Evidence has shown that a fatty acid messenger, \"cis\"-2-decenoic acid, is capable of inducing dispersion and inhibiting growth of biofilm colonies. Secreted by \"Pseudomonas aeruginosa\", this compound induces cyclo heteromorphic cells in several species of bacteria and the yeast \"Candida albicans\".\nNitric oxide has also been shown to trigger the dispersal of biofilms of several bacteria species at sub-toxic concentrations. Nitric oxide has potential as a treatment for patients that have chronic infections caused by biofilms.\nIt was generally assumed that cells dispersed from biofilms immediately go into the planktonic growth phase. However, studies have shown that the physiology of dispersed cells from \"Pseudomonas aeruginosa\" biofilms is highly different from that of planktonic and biofilm cells. Hence, the dispersal process is a unique stage during the transition from biofilm to planktonic lifestyle in bacteria. Dispersed cells are found to be highly virulent against macrophages and \"Caenorhabditis elegans\", but highly sensitive towards iron stress, as compared with planktonic cells.\nFurthermore, \"Pseudomonas aeruginosa\" biofilms undergo distinct spatiotemporal dynamics during biofilm dispersal or disassembly, with contrasting consequences in recolonization and disease dissemination. Biofilm dispersal induced bacteria to activate dispersal genes to actively depart from biofilms as single cells at consistent velocities but could not recolonize fresh surfaces. In contrast, biofilm disassembly by degradation of a biofilm exopolysaccharide released immotile aggregates at high initial velocities, enabling the bacteria to recolonize fresh surfaces and cause infections in the hosts efficiently. Hence, biofilm dispersal is more complex than previously thought, where bacterial populations adopting distinct behavior after biofilm departure may be the key to survival of bacterial species and dissemination of diseases.\nProperties.\nBiofilms are usually found on solid substrates submerged in or exposed to an aqueous solution, although they can form as floating mats on liquid surfaces and also on the surface of leaves, particularly in high humidity climates. Given sufficient resources for growth, a biofilm will quickly grow to be macroscopic (visible to the naked eye). Biofilms can contain many different types of microorganism, e.g. bacteria, archaea, protozoa, fungi and algae; each group performs specialized metabolic functions. However, some organisms will form single-species films under certain conditions. The social structure (cooperation/competition) within a biofilm depends highly on the different species present.\nExtracellular matrix.\nThe EPS matrix consists of exopolysaccharides, proteins and nucleic acids. A large proportion of the EPS is more or less strongly hydrated, however, hydrophobic EPS also occur; one example is cellulose which is produced by a range of microorganisms. This matrix encases the cells within it and facilitates communication among them through biochemical signals as well as gene exchange. The EPS matrix also traps extracellular enzymes and keeps them in close proximity to the cells. Thus, the matrix represents an external digestion system and allows for stable synergistic microconsortia of different species. Some biofilms have been found to contain water channels that help distribute nutrients and signalling molecules. This matrix is strong enough that under certain conditions, biofilms can become fossilized (stromatolites).\nBacteria living in a biofilm usually have significantly different properties from free-floating bacteria of the same species, as the dense and protected environment of the film allows them to cooperate and interact in various ways. One benefit of this environment is increased resistance to detergents and antibiotics, as the dense extracellular matrix and the outer layer of cells protect the interior of the community. In some cases antibiotic resistance can be increased up to 5,000 times. Lateral gene transfer is often facilitated within bacterial and archaeal biofilms and can lead to a more stable biofilm structure. Extracellular DNA is a major structural component of many different microbial biofilms. Enzymatic degradation of extracellular DNA can weaken the biofilm structure and release microbial cells from the surface.\nHowever, biofilms are not always less susceptible to antibiotics. For instance, the biofilm form of \"Pseudomonas aeruginosa\" has no greater resistance to antimicrobials than do stationary-phase planktonic cells, although when the biofilm is compared to logarithmic-phase planktonic cells, the biofilm does have greater resistance to antimicrobials. This resistance to antibiotics in both stationary-phase cells and biofilms may be due to the presence of persister cells.\nHabitats.\nBiofilms are ubiquitous in organic life. Nearly every species of microorganism have mechanisms by which they can adhere to surfaces and to each other. Biofilms will form on virtually every non-shedding surface in non-sterile aqueous or humid environments. Biofilms can grow in the most extreme environments: from, for example, the extremely hot, briny waters of hot springs ranging from very acidic to very alkaline, to frozen glaciers.\nBiofilms can be found on rocks and pebbles at the bottoms of most streams or rivers and often form on the surfaces of stagnant pools of water. Biofilms are important components of food chains in rivers and streams and are grazed by the aquatic invertebrates upon which many fish feed. Biofilms are found on the surface of and inside plants. They can either contribute to crop disease or, as in the case of nitrogen-fixing rhizobia on root nodules, exist symbiotically with the plant. Examples of crop diseases related to biofilms include citrus canker, Pierce's disease of grapes, and bacterial spot of plants such as peppers and tomatoes.\nPercolating filters.\nPercolating filters in sewage treatment works are highly effective removers of pollutants from settled sewage liquor. They work by trickling the liquid over a bed of hard material which is designed to have a very large surface area. A complex biofilm develops on the surface of the medium which absorbs, adsorbs and metabolises the pollutants. The biofilm grows rapidly and when it becomes too thick to retain its grip on the media it washes off and is replaced by newly grown film. The washed off (\"sloughed\" off) film is settled out of the liquid stream to leave a highly purified effluent.\nSlow sand filter.\nSlow sand filters are used in water purification for treating raw water to produce a potable product. They work through the formation of a biofilm called the hypogeal layer or \"Schmutzdecke\" in the top few millimetres of the fine sand layer. The \"Schmutzdecke\" is formed in the first 10\u201320 days of operation and consists of bacteria, fungi, protozoa, rotifera and a range of aquatic insect larvae. As an epigeal biofilm ages, more algae tend to develop and larger aquatic organisms may be present including some bryozoa, snails and annelid worms. The surface biofilm is the layer that provides the effective purification in potable water treatment, the underlying sand providing the support medium for this biological treatment layer. As water passes through the hypogeal layer, particles of foreign matter are trapped in the mucilaginous matrix and soluble organic material is adsorbed. The contaminants are metabolised by the bacteria, fungi and protozoa. The water produced from an exemplary slow sand filter is of excellent quality with 90\u201399% bacterial cell count reduction.\nRhizosphere.\nPlant-beneficial microbes can be categorized as plant growth-promoting rhizobacteria. These plant growth-promoters colonize the roots of plants, and provide a wide range of beneficial functions for their host including nitrogen fixation, pathogen suppression, anti-fungal properties, and the breakdown of organic materials. One of these functions is the defense against pathogenic, soil-borne bacteria and fungi by way of induced systemic resistance (ISR) or induced systemic responses triggered by pathogenic microbes (pathogen-induced systemic acquired resistance). Plant exudates act as chemical signals for host specific bacteria to colonize. Rhizobacteria colonization steps include attractions, recognition, adherence, colonization, and growth. Bacteria that have been shown to be beneficial and form biofilms include \"Bacillus, Pseudomonas,\" and \"Azospirillum\". Biofilms in the rhizosphere often result in pathogen or plant induced systemic resistances. Molecular properties on the surface of the bacterium cause an immune response in the plant host. These microbe associated molecules interact with receptors on the surface of plant cells, and activate a biochemical response that is thought to include several different genes at a number of loci. Several other signaling molecules have been linked to both induced systemic responses and pathogen-induced systemic responses, such as jasmonic acid and ethylene. Cell envelope components such as bacterial flagella and lipopolysaccharides, which are recognized by plant cells as components of pathogens. Certain iron metabolites produced by \"Pseudomonas\" have also been shown to create an induced systemic response. This function of the biofilm helps plants build stronger resistance to pathogens.\nPlants that have been colonized by PGPR forming a biofilm have gained systemic resistances and are primed for defense against pathogens. This means that the genes necessary for the production of proteins that work towards defending the plant against pathogens have been expressed, and the plant has a \"stockpile\" of compounds to release to fight off pathogens. A primed defense system is much faster in responding to pathogen induced infection, and may be able to deflect pathogens before they are able to establish themselves. Plants increase the production of lignin, reinforcing cell walls and making it difficult for pathogens to penetrate into the cell, while also cutting off nutrients to already infected cells, effectively halting the invasion. They produce antimicrobial compounds such as phytoalexins, chitinases, and proteinase inhibitors, which prevent the growth of pathogens. These functions of disease suppression and pathogen resistance ultimately lead to an increase in agricultural production and a decrease in the use of chemical pesticides, herbicides, and fungicides because there is a reduced amount of crop loss due to disease. Induced systemic resistance and pathogen-induced systemic acquired resistance are both potential functions of biofilms in the rhizosphere, and should be taken into consideration when applied to new age agricultural practices because of their effect on disease suppression without the use of dangerous chemicals.\nMammalian gut.\nStudies in 2003 discovered that the immune system supports biofilm development in the large intestine. This was supported mainly with the fact that the two most abundantly produced molecules by the immune system also support biofilm production and are associated with the biofilms developed in the gut. This is especially important because the appendix holds a mass amount of these bacterial biofilms. This discovery helps to distinguish the possible function of the appendix and the idea that the appendix can help reinoculate the gut with good gut flora. However, modified or disrupted states of biofilms in the gut have been connected to diseases such as inflammatory bowel disease and colorectal cancer.\nHuman environment.\nIn the human environment, biofilms can grow in showers very easily since they provide a moist and warm environment for them to thrive. Mold biofilms on ceilings may form due to roof leaks. They can form inside water and sewage pipes and cause clogging and corrosion. On floors and counters, they can make sanitation difficult in food preparation areas. In soil, they can cause bioclogging. In cooling- or heating-water systems, they are known to reduce heat transfer. Biofilms in marine engineering systems, such as pipelines of the offshore oil and gas industry, can lead to substantial corrosion problems. Corrosion is mainly due to abiotic factors; however, at least 20% of corrosion is caused by microorganisms that are attached to the metal subsurface (i.e., microbially influenced corrosion).\nShip fouling.\nBacterial adhesion to boat hulls serves as the foundation for biofouling of seagoing vessels. Once a film of bacteria forms, it is easier for other marine organisms such as barnacles to attach. Such fouling can reduce maximum vessel speed by up to 20%, prolonging voyages and consuming fuel. Time in dry dock for refitting and repainting reduces the productivity of shipping assets, and the useful life of ships is also reduced due to corrosion and mechanical removal (scraping) of marine organisms from ships' hulls.\nStromatolites.\nStromatolites are layered accretionary structures formed in shallow water by the trapping, binding and cementation of sedimentary grains by microbial biofilms, especially of cyanobacteria. Stromatolites include some of the most ancient records of life on Earth, and are still forming today.\nDental plaque.\nWithin the human body, biofilms are present on the teeth as dental plaque, where they may cause tooth decay and gum disease. These biofilms can either be in an uncalcified state that can be removed by dental instruments, or a calcified state which is more difficult to remove. Removal techniques can also include antimicrobials.\nDental plaque is an oral biofilm that adheres to the teeth and consists of many species of both bacteria and fungi (such as \"Streptococcus mutans\" and \"Candida albicans\"), embedded in salivary polymers and microbial extracellular products. The accumulation of microorganisms subjects the teeth and gingival tissues to high concentrations of bacterial metabolites which results in dental disease. Biofilm on the surface of teeth is frequently subject to oxidative stress and acid stress. Dietary carbohydrates can cause a dramatic decrease in pH in oral biofilms to values of 4 and below (acid stress). A pH of 4 at body temperature of 37\u00a0\u00b0C causes depurination of DNA, leaving apurinic (AP) sites in DNA, especially loss of guanine.\nDental plaque biofilm can result in dental caries if it is allowed to develop over time. An ecologic shift away from balanced populations within the dental biofilm is driven by certain (cariogenic) microbiological populations beginning to dominate when the environment favors them. The shift to an acidogenic, aciduric, and cariogenic microbiological population develops and is maintained by frequent consumption of fermentable dietary carbohydrate. The resulting activity shift in the biofilm (and resulting acid production within the biofilm, at the tooth surface) is associated with an imbalance of demineralization over remineralization, leading to net mineral loss within dental hard tissues (enamel and then dentin), the symptom being a carious lesion, or cavity. By preventing the dental plaque biofilm from maturing or by returning it back to a non-cariogenic state, dental caries can be prevented and arrested. This can be achieved through the behavioral step of reducing the supply of fermentable carbohydrates (i.e. sugar intake) and frequent removal of the biofilm (i.e., toothbrushing).\nIntercellular communication.\nA peptide pheromone quorum sensing signaling system in \"S. mutans\" includes the competence stimulating peptide (CSP) that controls genetic competence. Genetic competence is the ability of a cell to take up DNA released by another cell. Competence can lead to genetic transformation, a form of sexual interaction, favored under conditions of high cell density and/or stress where there is maximal opportunity for interaction between the competent cell and the DNA released from nearby donor cells. This system is optimally expressed when \"S. mutans\" cells reside in an actively growing biofilm. Biofilm grown \"S. mutans\" cells are genetically transformed at a rate 10- to 600-fold higher than \"S. mutans\" growing as free-floating planktonic cells suspended in liquid.\nWhen the biofilm, containing \"S. mutans\" and related oral streptococci, is subjected to acid stress, the competence regulon is induced, leading to resistance to being killed by acid. As pointed out by Michod et al., transformation in bacterial pathogens likely provides for effective and efficient recombinational repair of DNA damages. It appears that \"S. mutans\" can survive the frequent acid stress in oral biofilms, in part, through the recombinational repair provided by competence and transformation.\nPredator-prey interactions\nPredator-prey interactions between biofilms and bacterivores, such as the soil-dwelling nematode \"Caenorhabditis elegans,\" had been extensively studied. Via the production of sticky matrix and formation of aggregates, \"Yersinia pestis\" biofilms can prevent feeding by obstructing the mouth of \"C. elegans\". Moreover, \"Pseudomonas aeruginosa\" biofilms can impede the slithering motility of \"C. elegans\", termed as 'quagmire phenotype', resulting in trapping of \"C. elegans\" within the biofilms and preventing the exploration of nematodes to feed on susceptible biofilms. This significantly reduced the ability of predator to feed and reproduce, thereby promoting the survival of biofilms. \"Pseudomonas aeruginosa\" biofilms can also mask their chemical signatures, where they reduced the diffusion of quorum sensing molecules into the environment and prevented the detection of \"C. elegans\".\nTaxonomic diversity.\nMany different bacteria form biofilms, including gram-positive (e.g. \"Bacillus\" spp, \"Listeria monocytogenes\", \"Staphylococcus\" spp, and lactic acid bacteria, including \"Lactobacillus plantarum\" and \"Lactococcus lactis\") and gram-negative species (e.g. \"Escherichia coli\", or \"Pseudomonas aeruginosa\"). Cyanobacteria also form biofilms in aquatic environments.\nBiofilms are formed by bacteria that colonize plants, e.g. \"Pseudomonas putida\", \"Pseudomonas fluorescens\", and related pseudomonads which are common plant-associated bacteria found on leaves, roots, and in the soil, and the majority of their natural isolates form biofilms. Several nitrogen-fixing symbionts of legumes such as \"Rhizobium leguminosarum\" and \"Sinorhizobium meliloti\" form biofilms on legume roots and other inert surfaces.\nAlong with bacteria, biofilms are also generated by archaea and by a range of eukaryotic organisms, including fungi e.g. \"Cryptococcus laurentii\" and microalgae. Among microalgae, one of the main progenitors of biofilms are diatoms, which colonise both fresh and marine environments worldwide.\nFor other species in disease-associated biofilms and biofilms arising from eukaryotes, see below.\nInfectious diseases.\nBiofilms have been found to be involved in a wide variety of microbial infections in the body, by one estimate 80% of all infections. Infectious processes in which biofilms have been implicated include common problems such as bacterial vaginosis, urinary tract infections, catheter infections, middle-ear infections, formation of dental plaque, gingivitis, coating contact lenses, and less common but more lethal processes such as endocarditis, infections in cystic fibrosis, and infections of permanent indwelling devices such as joint prostheses, heart valves, and intervertebral disc. The first visual evidence of a biofilm was recorded after spine surgery. It was found that in the absence of clinical presentation of infection, impregnated bacteria could form a biofilm around an implant, and this biofilm can remain undetected via contemporary diagnostic methods, including swabbing. Implant biofilm is frequently present in \"aseptic\" pseudarthrosis cases. Furthermore, it has been noted that bacterial biofilms may impair cutaneous wound healing and reduce topical antibacterial efficiency in healing or treating infected skin wounds. The diversity of \"P. aeruginosa\" cells within a biofilm is thought to make it harder to treat the infected lungs of people with cystic fibrosis. Early detection of biofilms in wounds is crucial to successful chronic wound management. Although many techniques have developed to identify planktonic bacteria in viable wounds, few have been able to quickly and accurately identify bacterial biofilms. Future studies are needed to find means of identifying and monitoring biofilm colonization at the bedside to permit timely initiation of treatment.\nIt has been shown that biofilms are present on the removed tissue of 80% of patients undergoing surgery for chronic sinusitis. The patients with biofilms were shown to have been denuded of cilia and goblet cells, unlike the controls without biofilms who had normal cilia and goblet cell morphology. Biofilms were also found on samples from two of 10 healthy controls mentioned. The species of bacteria from intraoperative cultures did not correspond to the bacteria species in the biofilm on the respective patient's tissue. In other words, the cultures were negative though the bacteria were present. New staining techniques are being developed to differentiate bacterial cells growing in living animals, e.g. from tissues with allergy-inflammations.\nResearch has shown that sub-therapeutic levels of \u03b2-lactam antibiotics induce biofilm formation in \"Staphylococcus aureus\". This sub-therapeutic level of antibiotic may result from the use of antibiotics as growth promoters in agriculture, or during the normal course of antibiotic therapy. The biofilm formation induced by low-level methicillin was inhibited by DNase, suggesting that the sub-therapeutic levels of antibiotic also induce extracellular DNA release. \n\"Pseudomonas aeruginosa\".\n\"P. aeruginosa\" represents a commonly used biofilm model organism since it is involved in different types of biofilm-associated chronic infections. Examples of such infections include chronic wounds, chronic otitis media, chronic prostatitis and chronic lung infections in cystic fibrosis (CF) patients. About 80% of CF patients have chronic lung infection, caused mainly by \"P. aeruginosa\" growing in a non-surface attached biofilms surround by PMN. The infection remains present despite aggressive antibiotic therapy and is a common cause of death in CF patients due to constant inflammatory damage to the lungs. In patients with CF, one therapy for treating early biofilm development is to employ DNase to structurally weaken the biofilm.\nBiofilm formation of \"P. aeruginosa\", along with other bacteria, is found in 90% of chronic wound infections, which leads to poor healing and high cost of treatment estimated at more than US$25 billion every year in the United States. In order to minimize the \"P. aeruginosa\" infection, host epithelial cells secrete antimicrobial peptides, such as lactoferrin, to prevent the formation of the biofilms.\n\"Streptococcus pneumoniae\".\n\"Streptococcus pneumoniae\" is the main cause of community-acquired pneumonia and meningitis in children and the elderly, and of sepsis in HIV-infected persons. When \"S. pneumoniae\" grows in biofilms, genes are specifically expressed that respond to oxidative stress and induce competence. Formation of a biofilm depends on competence stimulating peptide (CSP). CSP also functions as a quorum-sensing peptide. It not only induces biofilm formation, but also increases virulence in pneumonia and meningitis.\nIt has been proposed that competence development and biofilm formation is an adaptation of \"S. pneumoniae\" to survive the defenses of the host. In particular, the host's polymorphonuclear leukocytes produce an oxidative burst to defend against the invading bacteria, and this response can kill bacteria by damaging their DNA. Competent \"S. pneumoniae\" in a biofilm have the survival advantage that they can more easily take up transforming DNA from nearby cells in the biofilm to use for recombinational repair of oxidative damages in their DNA. Competent \"S. pneumoniae\" can also secrete an enzyme (murein hydrolase) that destroys non-competent cells (fratricide) causing DNA to be released into the surrounding medium for potential use by the competent cells.\nThe insect antimicrobial peptide cecropin A can destroy planktonic and sessile biofilm-forming uropathogenic \"E. coli\" cells, either alone or when combined with the antibiotic nalidixic acid, synergistically clearing infection in vivo (in the insect host \"Galleria mellonella\") without off-target cytotoxicity. The multi-target mechanism of action involves outer membrane permeabilization followed by biofilm disruption triggered by the inhibition of efflux pump activity and interactions with extracellular and intracellular nucleic acids.\n\"Escherichia coli\".\n\"Escherichia coli\" biofilms are responsible for many intestinal infectious diseases. The Extraintestinal group of \"E. coli\" (ExPEC) is the dominant bacterial group that attacks the urinary system, which leads to urinary tract infections. The biofilm formation of these pathogenic \"E. coli\" is hard to eradicate due to the complexity of its aggregation structure, and it has a significant contribution to developing aggressive medical complications, increase in hospitalization rate, and cost of treatment. The development of \"E. coli\" biofilm is a common leading cause of urinary tract infections (UTI) in hospitals through its contribution to developing medical device-associated infections. Catheter-associated urinary tract infections (CAUTI) represent the most common hospital-acquired infection due to the formation of the pathogenic \"E. coli biofilm\" inside the catheters.\n\"Staphylococcus aureus\".\n\"Staphylococcus aureus\" pathogen can attack skin and lungs, leading to skin infection and pneumonia. Moreover, the biofilm infections network of \"S. aureus\" plays a critical role in preventing immune cells, such as macrophages from eliminating and destroying bacterial cells. Furthermore, biofilm formation by bacteria, such as \"S. aureus\", not only develops resistance against antibiotic medication but also develop internal resistance toward antimicrobial peptides (AMPs), leading to preventing the inhibition of the pathogen and maintaining its survival.\n\"Serratia marcescens\".\n\"Serratia marcescens\" is a fairly common opportunistic pathogen that can form biofilms on various surfaces, including medical devices such as catheters and implants, as well as natural environments like soil and water. The formation of biofilms by \"S. marcescens\" is a serious concern because of its ability to adhere to and colonize surfaces, protecting itself from host immune responses and antimicrobial agents. This strength makes infections caused by \"S. marcescens\" challenging to treat, specifically in hospitals where the bacterium can cause severe, and specific, infections.\nResearch suggests that biofilm formation by S. marcescens is a process controlled by both nutrient cues and the quorum-sensing system. Quorum sensing influences the bacterium's ability to adhere to surfaces and establish mature biofilms, whereas the availability of specific nutrients can enhance or inhibit biofilm development.\n\"S. marcescens\" creates biofilms that ultimately develop into a highly porous, thread-like structure composed of chains of cells, filaments, and cell clusters. Research has shown that \"S. marcescens\" biofilms exhibit complex structural organization, including the formation of microcolonies and channels that facilitate nutrient and waste exchange. The production of extracellular polymeric substances (EPS) is a key factor in biofilm development, contributing to the bacterium's adhesion and resistance to antimicrobial agents. In addition to its role in healthcare-associated infections, \"S. marcescens\" biofilms have been implicated in the deterioration of industrial equipment and processes. For example, biofilm growth in cooling towers can lead to biofouling and reduced efficiency.\nEfforts to control and prevent biofilm formation by \"S. marcescens\" involve the use of antimicrobial coatings on medical devices, the development of targeted biofilm disruptors, and improved sterilization protocols. Further research into the molecular mechanisms governing \"S. marcescens\" biofilm formation and persistence is crucial for developing effective strategies to combat its associated risks. The use of indole compounds has been studied to be used as protection against biofilm formation.\nUses and impact.\nIn medicine.\nIt is suggested that around two-thirds of bacterial infections in humans involve biofilms. Infections associated with the biofilm growth usually are challenging to eradicate. This is mostly due to the fact that mature biofilms display antimicrobial tolerance, and immune response evasions. Biofilms often form on the inert surfaces of implanted devices such as catheters, prosthetic cardiac valves and intrauterine devices. Some of the most difficult infections to treat are those associated with the use of medical devices.\nThe rapidly expanding worldwide industry for biomedical devices and tissue engineering related products is already at $180\u00a0billion per year, yet this industry continues to suffer from microbial colonization. No matter the sophistication, microbial infections can develop on all medical devices and tissue engineering constructs. 60\u201370% of hospital-acquired infections are associated with the implantation of a biomedical device. This leads to 2 million cases annually in the U.S., costing the healthcare system over $5\u00a0billion in additional healthcare expenses.\nThe level of antibiotic resistance in a biofilm is much greater than that of non-biofilm bacteria, and can be as much as 5,000 times greater. The extracellular matrix of biofilm is considered one of the leading factors that can reduce the penetration of antibiotics into a biofilm structure and contributes to antibiotic resistance. Further, it has been demonstrated that the evolution of resistance to antibiotics may be affected by the biofilm lifestyle. Bacteriophage therapy can disperse the biofilm generated by antibiotic-resistant bacteria.\nIt has been shown that the introduction of a small current of electricity to the liquid surrounding a biofilm, together with small amounts of antibiotic can reduce the level of antibiotic resistance to levels of non-biofilm bacteria. This is termed the bioelectric effect. The application of a small DC current on its own can cause a biofilm to detach from its surface. A study showed that the type of current used made no difference to the bioelectric effect.\nIn industry.\nBiofilms can also be harnessed for constructive purposes. For example, many sewage treatment plants include a secondary treatment stage in which waste water passes over biofilms grown on filters, which extract and digest organic compounds. In such biofilms, bacteria are mainly responsible for removal of organic matter (BOD), while protozoa and rotifers are mainly responsible for removal of suspended solids (SS), including pathogens and other microorganisms. Slow sand filters rely on biofilm development in the same way to filter surface water from lake, spring or river sources for drinking purposes. What is regarded as clean water is effectively a waste material to these microcellular organisms. Biofilms can help eliminate petroleum oil from contaminated oceans or marine systems. The oil is eliminated by the hydrocarbon-degrading activities of communities of hydrocarbonoclastic bacteria (HCB).\nBiofilms are used in microbial fuel cells (MFCs) to generate electricity from a variety of starting materials, including complex organic waste and renewable biomass.\nBiofilms are also relevant for the improvement of metal dissolution in bioleaching industry, and aggregation of microplastics pollutants for convenient removal from the environment.\nFood industry.\nBiofilms have become problematic in several food industries due to the ability to form on plants and during industrial processes. Bacteria can survive long periods of time in water, animal manure, and soil, causing biofilm formation on plants or in the processing equipment. The buildup of biofilms can affect the heat flow across a surface and increase surface corrosion and frictional resistance of fluids. These can lead to a loss of energy in a system and overall loss of products. Along with economic problems, biofilm formation on food poses a health risk to consumers due to the ability to make the food more resistant to disinfectants As a result, from 1996 to 2010 the Centers for Disease Control and Prevention estimated 48 million foodborne illnesses per year. Biofilms have been connected to about 80% of bacterial infections in the United States.\nIn produce, microorganisms attach to the surfaces and biofilms develop internally. During the washing process, biofilms resist sanitization and allow bacteria to spread across the produce, especially via kitchen utensils. This problem is also found in ready-to-eat foods, because the foods go through limited cleaning procedures before consumption Due to the perishability of dairy products and limitations in cleaning procedures, resulting in the buildup of bacteria, dairy is susceptible to biofilm formation and contamination. The bacteria can spoil the products more readily and contaminated products pose a health risk to consumers. One species of bacteria that can be found in various industries and is a major cause of foodborne disease is \"Salmonella\". Large amounts of Salmonella contamination can be found in the poultry processing industry as about 50% of \"Salmonella\" strains can produce biofilms on poultry farms. \"Salmonella\" increases the risk of foodborne illnesses when the poultry products are not cleaned and cooked correctly. \"Salmonella\" is also found in the seafood industry where biofilms form from seafood borne pathogens on the seafood itself as well as in water. Shrimp products are commonly affected by \"Salmonella\" because of unhygienic processing and handling techniques The preparation practices of shrimp and other seafood products can allow for bacteria buildup on the products.\nNew forms of cleaning procedures are being tested to reduce biofilm formation in these processes which will lead to safer and more productive food processing industries. These new forms of cleaning procedures also have a profound effect on the environment, often releasing toxic gases into the groundwater reservoirs. As a response to the aggressive methods employed in controlling biofilm formation, there are a number of novel technologies and chemicals under investigation that can prevent either the proliferation or adhesion of biofilm-secreting microbes. Latest proposed biomolecules presenting marked anti-biofilm activity include a range of metabolites such as bacterial rhamnolipids and even plant- and animal-derived alkaloids.\nIn aquaculture.\nIn shellfish and algal aquaculture, biofouling microbial species tend to block nets and cages and ultimately outcompete the farmed species for space and food. Bacterial biofilms start the colonization process by creating microenvironments that are more favorable for biofouling species. In the marine environment, biofilms could reduce the hydrodynamic efficiency of ships and propellers, lead to pipeline blockage and sensor malfunction, and increase the weight of appliances deployed in seawater. Numerous studies have shown that biofilm can be a reservoir for potentially pathogenic bacteria in freshwater aquaculture. Moreover, biofilms are important in establishing infections on the fish. As mentioned previously, biofilms can be difficult to eliminate even when antibiotics or chemicals are used in high doses. The role that biofilm plays as reservoirs of bacterial fish pathogens has not been explored in detail but it certainly deserves to be studied.\nEukaryotic.\nAlong with bacteria, biofilms are often initiated and produced by eukaryotic microbes. The biofilms produced by eukaryotes is usually occupied by bacteria and other eukaryotes alike, however the surface is cultivated and EPS is secreted initially by the eukaryote. Both fungi and microalgae are known to form biofilms in such a way. Biofilms of fungal origin are important aspects of human infection and fungal pathogenicity, as the fungal infection is more resistant to antifungals.\nIn the environment, fungal biofilms are an area of ongoing research. One key area of research is fungal biofilms on plants. For example, in the soil, plant associated fungi including mycorrhiza have been shown to decompose organic matter and protect plants from bacterial pathogens.\nBiofilms in aquatic environments are often founded by diatoms. The exact purpose of these biofilms is unknown, however there is evidence that the EPS produced by diatoms facilitates both cold and salinity stress. These eukaryotes interact with a diverse range of other organisms within a region known as the phycosphere, but importantly are the bacteria associated with diatoms, as it has been shown that although diatoms excrete EPS, they only do so when interacting with certain bacteria species.\nHorizontal gene transfer.\nHorizontal gene transfer is the lateral transfer of genetic material between cellular organisms. It happens frequently in prokaryotes, and less frequently in eukaryotes. In bacteria, horizontal gene transfer can occur through transformation (uptake of free floating DNA in the environment), transduction (virus mediated DNA uptake), or conjugation (transfer of DNA between pili structures of two adjacent bacteria). Recent studies have also uncovered other mechanisms, such as membrane vesicle transmission or gene transfer agents. Biofilms promote horizontal gene transfer in a variety of ways.Bacterial conjugation has been shown to accelerate biofilm formation in difficult environment due to the robust connections established by the conjugative pili. These connections can often foster cross-species transfer events due to the diverse heterogeneity of many biofilms. Additionally, biofilms are structurally confined by a polysaccharide matrix, providing the close spatial requirements for conjugation. Transformation is also frequently observed in biofilms. Bacterial autolysis is a key mechanism in biofilm structural regulation, providing an abundant source of competent DNA primed for transformative uptake. In some instances, inter-biofilm quorum sensing can enhance the competence of free floating eDNA, further promoting transformation. Stx gene transfer through bacteriophage carriers has been witnessed within biofilms, which suggests that biofilms are also a suitable environment for transduction. Membrane vesicles HGT occurs when released membrane vesicles (containing genetic information) fuse with a recipient bacteria, and release genetic material into the bacteria's cytoplasm. Recent research has revealed that membrane vesicle HGT can promote single-strain biofilm formation, yet the role membrane vesicle HGT plays in the formation of multistrain biofilms is still unknown. GTAs, or gene transfer agents, are phage-like particles produced by the host bacteria and contain random DNA fragments from the host bacteria genome. HGT within biofilms can confer antibiotic resistance or increased pathogenicity across the biofilms' population, promoting biofilm homeostasis.\nExamples.\nConjugative plasmids may encode biofilm-associated proteins, such as PtgA, PrgB, or PrgC which promote cell adhesion (required for early biofilm formation). Genes encoding type III fimbriae are found in pOLA52 (\"Klebsiella pneumoniae\" plasmid) which promote conjugative-pilus-dependent biofilm formation.\nTransformation commonly occurs within biofilms. A phenomenon called fratricide can be seen among streptococcal species in which cell-wall degrading enzymes are released, lysing neighboring bacteria and releasing their DNA. This DNA can then be taken up by the surviving bacteria (transformation). Competence stimulating peptides may play an important role in biofilm formation among \"S. pneumoniae\" and \"S. mutans\" as well. Among \"V. cholerae\", the competence pilus itself promotes cell aggregation through pilus-pilus interactions at the beginning of biofilm formation.\nPhage invasion may play a role in biofilm life cycles, lysing bacteria and releasing their eDNA, which strengthens biofilm structures and can be taken up by neighboring bacteria in transformation. Biofilm destruction caused by the \"E. coli\" phage Rac and the \"P. aeruginosa\" prophage Pf4 causes detachment of cells from the biofilm. Detachment is a biofilm phenomenon which requires more study, but is hypothesized to proliferate the bacterial species that comprise the biofilm.\nMembrane vesicle HGT has been witnessed occurring in marine environments, among \"Neisseria gonorrhoeae\", \"Pseudomonas aeruginosa\", \"Helicobacter pylori\", and among many other bacterial species. Even though membrane vesicle HGT has been shown as a contributing factor in biofilm formation, research is still required to prove that membrane vesicle mediated HGT occurs within biofilms. Membrane vesicle HGT has also been shown to modulate phage-bacteria interactions in \"Bacillus subtilis\" SPP1 phage-resistant cells (lacking the SPP1 receptor protein). Upon exposure to vesicles containing receptors, transduction of pBT163 (a cat-encoding plasmid) occurs, resulting in the expression of the SPP1 receptor protein, opening the receptive bacteria to future phage infection.\nRecent research has shown that the archaeal species \"H. volcanii\" has some biofilm phenotypes similar to bacterial biofilms such as differentiation and HGT, which required cell-cell contact and involved formation of cytosolic bridges and cellular fusion events.\nCultivation devices.\nThere is a wide variety of biofilm cultivation devices to mimic natural or industrial environments. Although it is important to consider that the particular experimental platform for biofilm research determines what kind of biofilm is cultivated and the data that can be extracted. These devices can be grouped into the following:\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "43947", "revid": "1266132258", "url": "https://en.wikipedia.org/wiki?curid=43947", "title": "Protium (disambiguation)", "text": "Protium or hydrogen-1 is the most common isotope of the element hydrogen, with one proton, one electron, and no neutrons.\nProtium may also refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "43948", "revid": "45203278", "url": "https://en.wikipedia.org/wiki?curid=43948", "title": "Star formation", "text": "Gravitational process studied in astronomy\nStar formation is the process by which dense regions within molecular clouds in The \"medium\" is present further soon.--&gt;interstellar space\u2014sometimes referred to as \"stellar nurseries\" or \"star-forming regions\"\u2014collapse and form stars. As a branch of astronomy, star formation includes the study of the interstellar medium (ISM) and giant molecular clouds (GMC) as precursors to the star formation process, and the study of protostars and young stellar objects as its immediate products. It is closely related to planet formation, another branch of astronomy. Star formation theory, as well as accounting for the formation of a single star, must also account for the statistics of binary stars and the initial mass function. Most stars do not form in isolation but as part of a group of stars referred as star clusters or stellar associations.\nFirst stars.\nStar formation is divided into three groups called \"Populations\". Population III stars formed from primordial hydrogen after the Big Bang. These stars are poorly understood but should contain only hydrogen and helium. Population II stars formed from the debris of the first stars and they in turn created more higher atomic number chemical elements. Population I stars are young metal-rich (contain elements other than hydrogen and helium) stars like the Sun.\nThe initial star formation was driven by gravitational attraction of hydrogen within local areas of higher gravity called dark matter halos. As the hydrogen lost energy through atomic or molecular energy transitions, the temperature of local clumps fell allowing more gravitational condensation. Eventually the process leads to collapse into a star. Details of the dynamics of the Population III stars is now believed to be as complex as star formation today.\nStellar nurseries.\nInterstellar clouds.\nSpiral galaxies like the Milky Way contain stars, stellar remnants, and a diffuse interstellar medium (ISM) of gas and dust. The interstellar medium consists of 104 to 106 particles per cm3, and is typically composed of roughly 70% hydrogen, 28% helium, and 1.5% heavier elements by mass. The trace amounts of heavier elements were and are produced within stars via stellar nucleosynthesis and ejected as the stars pass beyond the end of their main sequence lifetime. Higher density regions of the interstellar medium form clouds, or \"diffuse nebulae\", where star formation takes place. In contrast to spiral galaxies, elliptical galaxies lose the cold component of its interstellar medium within roughly a billion years, which hinders the galaxy from forming diffuse nebulae except through mergers with other galaxies.\nIn the dense nebulae where stars are produced, much of the hydrogen is in the molecular (H2) form, so these nebulae are called molecular clouds. The Herschel Space Observatory has revealed that filaments, or elongated dense gas structures, are truly ubiquitous in molecular clouds and central to the star formation process. They fragment into gravitationally bound cores, most of which will evolve into stars. Continuous accretion of gas, geometrical bending, and magnetic fields may control the detailed manner in which the filaments are fragmented. Observations of supercritical filaments have revealed quasi-periodic chains of dense cores with spacing comparable to the filament inner width, and embedded protostars with outflows.\nObservations indicate that the coldest clouds tend to form low-mass stars, which are first observed via the infrared light they emit inside the clouds, and then as visible light when the clouds dissipate. Giant molecular clouds, which are generally warmer, produce stars of all masses. These giant molecular clouds have typical densities of 100 particles per cm3, diameters of , masses of up to 6\u00a0million solar masses (M\u2609), or six million times the mass of the Sun. The average interior temperature is .\nAbout half the total mass of the Milky Way's galactic ISM is found in molecular clouds and the galaxy includes an estimated 6,000 molecular clouds, each with more than 100,000\u00a0M\u2609. The nebula nearest to the Sun where massive stars are being formed is the Orion Nebula, away. However, lower mass star formation is occurring about 400\u2013450 light-years distant in the \u03c1 Ophiuchi cloud complex.\nA more compact site of star formation is the opaque clouds of dense gas and dust known as Bok globules, so named after the astronomer Bart Bok. These can form in association with collapsing molecular clouds or possibly independently. The Bok globules are typically up to a light-year across and contain a few solar masses. They can be observed as dark clouds silhouetted against bright emission nebulae or background stars. Over half the known Bok globules have been found to contain newly forming stars.\nCloud collapse.\nAn interstellar cloud of gas will remain in hydrostatic equilibrium as long as the kinetic energy of the gas pressure is in balance with the potential energy of the internal gravitational force. Mathematically this is expressed using the virial theorem, which states that, to maintain equilibrium, the gravitational potential energy must equal twice the internal thermal energy. If a cloud is massive enough that the gas pressure is insufficient to support it, the cloud will undergo gravitational collapse. The mass above which a cloud will undergo such collapse is called the Jeans mass. The Jeans mass depends on the temperature and density of the cloud, but is typically thousands to tens of thousands of solar masses. During cloud collapse dozens to tens of thousands of stars form more or less simultaneously which is observable in so-called embedded clusters. The end product of a core collapse is an open cluster of stars.\nIn \"triggered star formation\", one of several events might occur to compress a molecular cloud and initiate its gravitational collapse. Molecular clouds may collide with each other, or a nearby supernova explosion can be a trigger, sending shocked matter into the cloud at very high speeds. (The resulting new stars may themselves soon produce supernovae, producing self-propagating star formation.) Alternatively, galactic collisions can trigger massive starbursts of star formation as the gas clouds in each galaxy are compressed and agitated by tidal forces. The latter mechanism may be responsible for the formation of globular clusters.\nA supermassive black hole at the core of a galaxy may serve to regulate the rate of star formation in a galactic nucleus. A black hole that is accreting infalling matter can become active, emitting a strong wind through a collimated relativistic jet. This can limit further star formation. Massive black holes ejecting radio-frequency-emitting particles at near-light speed can also block the formation of new stars in aging galaxies. However, the radio emissions around the jets may also trigger star formation. Likewise, a weaker jet may trigger star formation when it collides with a cloud.\nAs it collapses, a molecular cloud breaks into smaller and smaller pieces in a hierarchical manner, until the fragments reach stellar mass. In each of these fragments, the collapsing gas radiates away the energy gained by the release of gravitational potential energy. As the density increases, the fragments become opaque and are thus less efficient at radiating away their energy. This raises the temperature of the cloud and inhibits further fragmentation. The fragments now condense into rotating spheres of gas that serve as stellar embryos.\nComplicating this picture of a collapsing cloud are the effects of turbulence, macroscopic flows, rotation, magnetic fields and the cloud geometry. Both rotation and magnetic fields can hinder the collapse of a cloud. Turbulence is instrumental in causing fragmentation of the cloud, and on the smallest scales it promotes collapse.\nProtostar.\nA protostellar cloud will continue to collapse as long as the gravitational binding energy can be eliminated. This excess energy is primarily lost through radiation. However, the collapsing cloud will eventually become opaque to its own radiation, and the energy must be removed through some other means. The dust within the cloud becomes heated to temperatures of 60\u2013100 K, and these particles radiate at wavelengths in the far infrared where the cloud is transparent. Thus the dust mediates the further collapse of the cloud.\nDuring the collapse, the density of the cloud increases towards the center and thus the middle region becomes optically opaque first. This occurs when the density is about 10\u221213 g / cm3. A core region, called the first hydrostatic core, forms where the collapse is essentially halted. It continues to increase in temperature as determined by the virial theorem. The gas falling toward this opaque region collides with it and creates shock waves that further heat the core.\nWhen the core temperature reaches about 2000 K, the thermal energy dissociates the H2 molecules. This is followed by the ionization of the hydrogen and helium atoms. These processes absorb the energy of the contraction, allowing it to continue on timescales comparable to the period of collapse at free fall velocities. After the density of infalling material has reached about 10\u22128 g / cm3, that material is sufficiently transparent to allow energy radiated by the protostar to escape. The combination of convection within the protostar and radiation from its exterior allow the star to contract further. This continues until the gas is hot enough for the internal pressure to support the protostar against further gravitational collapse\u2014a state called hydrostatic equilibrium. When this accretion phase is nearly complete, the resulting object is known as a protostar.\nAccretion of material onto the protostar continues partially from the newly formed circumstellar disc. When the density and temperature are high enough, deuterium fusion begins, and the outward pressure of the resultant radiation slows (but does not stop) the collapse. Material comprising the cloud continues to \"rain\" onto the protostar. In this stage bipolar jets are produced called Herbig\u2013Haro objects. This is probably the means by which excess angular momentum of the infalling material is expelled, allowing the star to continue to form.\nWhen the surrounding gas and dust envelope disperses and accretion process stops, the star is considered a pre-main-sequence star (PMS star). The energy source of these objects is (gravitational contraction) Kelvin\u2013Helmholtz mechanism, as opposed to hydrogen burning in main sequence stars. The PMS star follows a Hayashi track on the Hertzsprung\u2013Russell (H\u2013R) diagram. The contraction will proceed until the Hayashi limit is reached, and thereafter contraction will continue on a Kelvin\u2013Helmholtz timescale with the temperature remaining stable. Stars with less than 0.5\u00a0M\u2609 thereafter join the main sequence. For more massive PMS stars, at the end of the Hayashi track they will slowly collapse in near hydrostatic equilibrium, following the Henyey track.\nFinally, hydrogen begins to fuse in the core of the star, and the rest of the enveloping material is cleared away. This ends the protostellar phase and begins the star's main sequence phase on the H\u2013R diagram.\nThe stages of the process are well defined in stars with masses around 1\u00a0M\u2609 or less. In high mass stars, the length of the star formation process is comparable to the other timescales of their evolution, much shorter, and the process is not so well defined. The later evolution of stars is studied in stellar evolution.\nObservations.\nKey elements of star formation are only available by observing in wavelengths other than the optical. The protostellar stage of stellar existence is almost invariably hidden away deep inside dense clouds of gas and dust left over from the GMC. Often, these star-forming cocoons known as Bok globules, can be seen in silhouette against bright emission from surrounding gas. Early stages of a star's life can be seen in infrared light, which penetrates the dust more easily than visible light. \nObservations from the Wide-field Infrared Survey Explorer (WISE) have thus been especially important for unveiling numerous galactic protostars and their parent star clusters. Examples of such embedded star clusters are FSR 1184, FSR 1190, Camargo 14, Camargo 74, Majaess 64, and Majaess 98.\nThe structure of the molecular cloud and the effects of the protostar can be observed in near-IR extinction maps (where the number of stars are counted per unit area and compared to a nearby zero extinction area of sky), continuum dust emission and rotational transitions of CO and other molecules; these last two are observed in the millimeter and submillimeter range. The radiation from the protostar and early star has to be observed in infrared astronomy wavelengths, as the extinction caused by the rest of the cloud in which the star is forming is usually too big to allow us to observe it in the visual part of the spectrum. This presents considerable difficulties as the Earth's atmosphere is almost entirely opaque from 20\u03bcm to 850\u03bcm, with narrow windows at 200\u03bcm and 450\u03bcm. Even outside this range, atmospheric subtraction techniques must be used.\nX-ray observations have proven useful for studying young stars, since X-ray emission from these objects is about 100\u2013100,000 times stronger than X-ray emission from main-sequence stars. The earliest detections of X-rays from T Tauri stars were made by the Einstein X-ray Observatory. For low-mass stars X-rays are generated by the heating of the stellar corona through magnetic reconnection, while for high-mass O and early B-type stars X-rays are generated through supersonic shocks in the stellar winds. Photons in the soft X-ray energy range covered by the Chandra X-ray Observatory and XMM-Newton may penetrate the interstellar medium with only moderate absorption due to gas, making the X-ray a useful wavelength for seeing the stellar populations within molecular clouds. X-ray emission as evidence of stellar youth makes this band particularly useful for performing censuses of stars in star-forming regions, given that not all young stars have infrared excesses. X-ray observations have provided near-complete censuses of all stellar-mass objects in the Orion Nebula Cluster and Taurus Molecular Cloud.\nThe formation of individual stars can only be directly observed in the Milky Way Galaxy, but in distant galaxies star formation has been detected through its unique spectral signature.\nInitial research indicates star-forming clumps start as giant, dense areas in turbulent gas-rich matter in young galaxies, live about 500 million years, and may migrate to the center of a galaxy, creating the central bulge of a galaxy.\nOn February 21, 2014, NASA announced a http:// for tracking polycyclic aromatic hydrocarbons (PAHs) in the universe. According to scientists, more than 20% of the carbon in the universe may be associated with PAHs, possible starting materials for the formation of life. PAHs seem to have been formed shortly after the Big Bang, are widespread throughout the universe, and are associated with new stars and exoplanets.\nIn February 2018, astronomers reported, for the first time, a signal of the reionization epoch, an indirect detection of light from the earliest stars formed \u2013 about 180 million years after the Big Bang.\nAn article published on October 22, 2019, reported on the detection of 3MM-1, a massive star-forming galaxy about 12.5 billion light-years away that is obscured by clouds of dust. At a mass of about 1010.8 solar masses, it showed a star formation rate about 100 times as high as in the Milky Way.\nLow mass and high mass star formation.\nStars of different masses are thought to form by slightly different mechanisms. The theory of low-mass star formation, which is well-supported by observation, suggests that low-mass stars form by the gravitational collapse of rotating density enhancements within molecular clouds. As described above, the collapse of a rotating cloud of gas and dust leads to the formation of an accretion disk through which matter is channeled onto a central protostar. For stars with masses higher than about 8\u00a0M\u2609, however, the mechanism of star formation is not well understood.\nMassive stars emit copious quantities of radiation which pushes against infalling material. In the past, it was thought that this radiation pressure might be substantial enough to halt accretion onto the massive protostar and prevent the formation of stars with masses more than a few tens of solar masses. Recent theoretical work has shown that the production of a jet and outflow clears a cavity through which much of the radiation from a massive protostar can escape without hindering accretion through the disk and onto the protostar. Present thinking is that massive stars may therefore be able to form by a mechanism similar to that by which low mass stars form.\nThere is mounting evidence that at least some massive protostars are indeed surrounded by accretion disks. Disk accretion in high-mass protostars, similar to their low-mass counterparts, is expected to exhibit bursts of episodic accretion as a result of a gravitationally instability leading to clumpy and in-continuous accretion rates. Recent evidence of accretion bursts in high-mass protostars has indeed been confirmed observationally. Several other theories of massive star formation remain to be tested observationally. Of these, perhaps the most prominent is the theory of competitive accretion, which suggests that massive protostars are \"seeded\" by low-mass protostars which compete with other protostars to draw in matter from the entire parent molecular cloud, instead of simply from a small local region.\nAnother theory of massive star formation suggests that massive stars may form by the coalescence of two or more stars of lower mass.\nFilamentary nature of star formation.\nRecent studies have emphasized the role of filamentary structures in molecular clouds as the initial conditions for star formation. Findings from the Herschel Space Observatory highlight the ubiquitous nature of these filaments in the cold interstellar medium (ISM). The spatial relationship between cores and filaments indicates that the majority of prestellar cores are located within 0.1 pc of supercritical filaments. This supports the hypothesis that filamentary structures act as pathways for the accumulation of gas and dust, leading to core formation.\nBoth the core mass function (CMF) and filament line mass function (FLMF) observed in the California GMC follow power-law distributions at the high-mass end, consistent with the Salpeter initial mass function (IMF). Current results strongly support the existence of a connection between the FLMF and the CMF/IMF, demonstrating that this connection holds at the level of an individual cloud, specifically the California GMC. The FLMF presented is a distribution of local line masses for a complete, homogeneous sample of filaments within the same cloud. It is the local line mass of a filament that defines its ability to fragment at a particular location along its spine, not the average line mass of the filament. This connection is more direct and provides tighter constraints on the origin of the CMF/IMF.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43949", "revid": "51046548", "url": "https://en.wikipedia.org/wiki?curid=43949", "title": "Antipyretic", "text": "Substance that reduces fever\nAn antipyretic (, from \"anti-\" 'against' and \"pyretic\" 'feverish') is a substance that reduces fever. Antipyretics cause the hypothalamus to override a prostaglandin-induced increase in temperature. The body then works to lower the temperature, which results in a reduction in fever.\nMost antipyretic medications have other purposes. The most common antipyretics in the US are usually ibuprofen and aspirin, which are nonsteroidal anti-inflammatory drugs (NSAIDs) used primarily as anti-inflammatories and analgesics (pain relievers), but which also have antipyretic properties; and paracetamol (acetaminophen), an analgesic without anti-inflammatory properties.\nThere is some debate over the appropriate use of such medications, since fever is part of the body's immune response to infection. A study published by the Royal Society claims that fever suppression causes at least 1% more influenza deaths in the United States, or 700 extra deaths per year.\nNon-pharmacological treatment.\nBathing or sponging with lukewarm or cool water can effectively reduce body temperature in those with heat illness, but not usually in those with fever. The use of alcohol baths is not an appropriate cooling method, because there have been reported adverse events associated with systemic absorption of alcohol.\nMedications.\nThe list of medications with antipyretic effects includes many common drugs that also have analgesic and anti-inflammatory activity, several of which are commonly sold over-the-counter (OTC).\nUse in children.\nThe U.S. Food and Drug Administration (FDA) notes that improper dosing is one of the biggest problems in giving acetaminophen (paracetamol) to children. The effectiveness of acetaminophen alone as an antipyretic in children is uncertain, with some evidence showing it is no better than physical methods. Therapies involving alternating doses of acetaminophen and ibuprofen have shown greater antipyretic effect than either drug alone. One meta-analysis indicated that ibuprofen is more effective than acetaminophen in children at similar doses when both are given alone.\nDue to concerns about Reye syndrome, it is recommended that aspirin and combination products that contain aspirin not be given to children or teenagers during episodes of fever-causing illnesses.\nTraditional medicine.\nTraditional use of vascular plants with antipyretic properties is a common worldwide feature of many ethnobotanical cultures. In ethnobotany, a plant with naturally occurring antipyretic properties is commonly referred to as a \"febrifuge\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43950", "revid": "488581", "url": "https://en.wikipedia.org/wiki?curid=43950", "title": "Interstate Highway System", "text": "Network of freeways in the United States\n&lt;templatestyles src=\"Infobox road/styles.css\" /&gt;\nThe Dwight D. Eisenhower National System of Interstate and Defense Highways, commonly known as the Interstate Highway System, or the Eisenhower Interstate System, is a network of controlled-access highways that forms part of the National Highway System in the United States. The system extends throughout the contiguous United States and has routes in Hawaii, Alaska, and Puerto Rico.\nIn the 20th century, the United States Congress began funding roadways through the Federal Aid Road Act of 1916, and started an effort to construct a national road grid with the passage of the Federal Aid Highway Act of 1921. In 1926, the United States Numbered Highway System was established, creating the first national road numbering system for cross-country travel. The roads were funded and maintained by U.S. states, and there were few national standards for road design. United States Numbered Highways ranged from two-lane country roads to multi-lane freeways. After Dwight D. Eisenhower became president in 1953, his administration developed a proposal for an interstate highway system, eventually resulting in the enactment of the Federal-Aid Highway Act of 1956.\nUnlike the earlier United States Numbered Highway System, the interstates were designed to be all freeways, with nationally unified standards for construction and signage. While some older freeways were adopted into the system, most of the routes were completely new. In dense urban areas, the choice of routing destroyed many well-established neighborhoods, often intentionally as part of a program of \"urban renewal\". In the two decades following the 1956 Highway Act, the construction of the freeways displaced one million people, and as a result of the many freeway revolts during this era, several planned Interstates were abandoned or re-routed to avoid urban cores.\nConstruction of the original Interstate Highway System was proclaimed complete in 1992, despite deviations from the original 1956 plan and several stretches that did not fully conform with federal standards. The construction of the Interstate Highway System cost approximately $114\u00a0billion (equivalent to $ in 2024). The system has continued to expand and grow as additional federal funding has provided for new routes to be added, and many future Interstate Highways are currently either being planned or under construction.\nThough heavily funded by the federal government, Interstate Highways are owned by the state in which they were built. With few exceptions, all Interstates must meet specific standards, such as having controlled access, physical barriers or median strips between lanes of oncoming traffic, breakdown lanes, avoiding at-grade intersections, no traffic lights, and complying with federal traffic sign specifications. Interstate Highways use a numbering scheme in which primary Interstates are assigned one- or two-digit numbers, and shorter routes which branch off from longer ones are assigned three-digit numbers where the last two digits match the parent route. The Interstate Highway System is partially financed through the Highway Trust Fund, which itself is funded by a combination of a federal fuel tax and transfers from the Treasury's general fund. Though federal legislation initially banned the collection of tolls, some Interstate routes are toll roads, either because they were grandfathered into the system or because subsequent legislation has allowed for tolling of Interstates in some cases.\nAs of 2022[ [update]], about one quarter of all vehicle miles driven in the country used the Interstate Highway System, which has a total length of . In 2022 and 2023, the number of fatalities on the Interstate Highway System amounted to more than 5,000 people annually, with nearly 5,600 fatalities in 2022.\nHistory.\nPlanning.\nThe United States government's efforts to construct a national network of highways began on an \"ad hoc\" basis with the passage of the Federal Aid Road Act of 1916, which provided $75\u00a0million over a five-year period for matching funds to the states for the construction and improvement of highways. The nation's revenue needs associated with World War I prevented any significant implementation of this policy, which expired in 1921.\nIn December 1918, E. J. Mehren, a civil engineer and the editor of \"Engineering News-Record\", presented his \"A Suggested National Highway Policy and Plan\" during a gathering of the State Highway Officials and Highway Industries Association at the Congress Hotel in Chicago. In the plan, Mehren proposed a system, consisting of five east\u2013west routes and 10 north\u2013south routes. The system would include two percent of all roads and would pass through every state at a cost of , providing commercial as well as military transport benefits.\nIn 1919, the US Army sent an expedition across the US to determine the difficulties that military vehicles would have on a cross-country trip. Leaving from the Ellipse near the White House on July 7, the Motor Transport Corps convoy needed 62 days to drive on the Lincoln Highway to the Presidio of San Francisco along the Golden Gate. The convoy suffered many setbacks and problems on the route, such as poor-quality bridges, broken crankshafts, and engines clogged with desert sand.\nDwight Eisenhower, then a 28-year-old brevet lieutenant colonel, accompanied the trip \"through darkest America with truck and tank,\" as he later described it. Some roads in the West were a \"succession of dust, ruts, pits, and holes.\"\nAs the landmark 1916 law expired, new legislation was passed\u2014the Federal Aid Highway Act of 1921 (Phipps Act). This new road construction initiative once again provided for federal matching funds for road construction and improvement, $75\u00a0million allocated annually. Moreover, this new legislation for the first time sought to target these funds to the construction of a national road grid of interconnected \"primary highways\", setting up cooperation among the various state highway planning boards.\nThe Bureau of Public Roads asked the Army to provide a list of roads that it considered necessary for national defense. In 1922, General John J. Pershing, former head of the American Expeditionary Force in Europe during the war, complied by submitting a detailed network of of interconnected primary highways\u2014the so-called Pershing Map.\nA boom in road construction followed throughout the decade of the 1920s, with such projects as the New York parkway system constructed as part of a new national highway system. As automobile traffic increased, planners saw a need for such an interconnected national system to supplement the existing, largely non-freeway, United States Numbered Highways system. By the late 1930s, planning had expanded to a system of new superhighways.\nIn 1938, President Franklin D. Roosevelt gave Thomas MacDonald, chief at the Bureau of Public Roads, a hand-drawn map of the United States marked with eight superhighway corridors for study. In 1939, Bureau of Public Roads Division of Information chief Herbert S. Fairbank wrote a report called \"Toll Roads and Free Roads\", \"the first formal description of what became the Interstate Highway System\" and, in 1944, the similarly themed \"Interregional Highways\".\nFederal Aid Highway Act of 1956.\nThe Interstate Highway System gained a champion in President Dwight D. Eisenhower, who was influenced by his experiences as a young Army officer crossing the country in the 1919 Motor Transport Corps convoy that drove in part on the Lincoln Highway, the first road across America. He recalled that, \"The old convoy had started me thinking about good two-lane highways... the wisdom of broader ribbons across our land.\" Eisenhower also gained an appreciation of the Reichsautobahn system, the first \"national\" implementation of modern Germany's Autobahn network, as a necessary component of a national defense system while he was serving as Supreme Commander of Allied Forces in Europe during World War II. In 1954, Eisenhower appointed General Lucius D. Clay to head a committee charged with proposing an interstate highway system plan. Summing up motivations for the construction of such a system, Clay stated,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It was evident we needed better highways. We needed them for safety, to accommodate more automobiles. We needed them for defense purposes, if that should ever be necessary. And we needed them for the economy. Not just as a public works measure, but for future growth.\nClay's committee proposed a 10-year, $100\u00a0billion program &amp;lpar;&amp;dollar;\u00a0in &lt;templatestyles src=\"Template:Tooltip/styles.css\" /&gt;), which would build of divided highways linking all American cities with a population of greater than 50,000. Eisenhower initially preferred a system consisting of toll roads, but Clay convinced Eisenhower that toll roads were not feasible outside of the highly populated coastal regions. In February 1955, Eisenhower forwarded Clay's proposal to Congress. The bill quickly won approval in the Senate, but House Democrats objected to the use of public bonds as the means to finance construction. Eisenhower and the House Democrats agreed to instead finance the system through the Highway Trust Fund, which itself would be funded by a gasoline tax. In June 1956, Eisenhower signed the Federal Aid Highway Act of 1956 into law. Under the act, the federal government would pay for 90 percent of the cost of construction of Interstate Highways. Each Interstate Highway was required to be a freeway with at least four lanes and no at-grade crossings.\nThe publication in 1955 of the \"General Location of National System of Interstate Highways\", informally known as the \"Yellow Book\", mapped out what became the Interstate Highway System. Assisting in the planning was Charles Erwin Wilson, who was still head of General Motors when President Eisenhower selected him as Secretary of Defense in January 1953.\nConstruction.\nSome sections of highways that became part of the Interstate Highway System actually began construction earlier.\nThree states have claimed the title of first Interstate Highway. Missouri claims that the first three contracts under the new program were signed in Missouri on August 2, 1956. The first contract signed was for upgrading a section of US Route 66 to what is now designated Interstate 44. On August 13, 1956, work began on US 40 (now I-70) in St. Charles County.\nKansas claims that it was the first to start paving after the act was signed. Preliminary construction had taken place before the act was signed, and paving started September 26, 1956. The state marked its portion of I-70 as the first project in the United States completed under the provisions of the new Federal-Aid Highway Act of 1956.\nThe Pennsylvania Turnpike could also be considered one of the first Interstate Highways, and is nicknamed \"Grandfather of the Interstate System\". On October 1, 1940, of the highway now designated I\u201170 and I\u201176 opened between Irwin and Carlisle. The Commonwealth of Pennsylvania refers to the turnpike as the Granddaddy of the Pikes, a reference to turnpikes.\nMilestones in the construction of the Interstate Highway System include:\nThe initial cost estimate for the system was $25\u00a0billion over 12\u00a0years; it ended up costing $114\u00a0billion (equivalent to $425\u00a0billion in 2006 or $ in 2024) and took 35\u00a0years.\n1992\u2013present.\nDiscontinuities.\nThe system was proclaimed complete in 1992, but two of the original Interstates\u2014I-95 and I-70\u2014were not continuous: both of these discontinuities were due to local opposition, which blocked efforts to build the necessary connections to fully complete the system. I-95 was made a continuous freeway in 2018, and thus I-70 remains the only original Interstate with a discontinuity.\nI-95 was discontinuous in New Jersey because of the cancellation of the Somerset Freeway. This situation was remedied when the construction of the Pennsylvania Turnpike/Interstate 95 Interchange Project started in 2010 and partially opened on September 22, 2018, which was already enough to fill the gap.\nHowever, I-70 remains discontinuous in Pennsylvania, because of the lack of a direct interchange with the Pennsylvania Turnpike at the eastern end of the concurrency near Breezewood. Traveling in either direction, I-70 traffic must exit the freeway and use a short stretch of US\u00a030 (which includes a number of roadside services) to rejoin I-70. The interchange was not originally built because of a legacy federal funding rule, since relaxed, which restricted the use of federal funds to improve roads financed with tolls. Solutions have been proposed to eliminate the discontinuity, but they have been blocked by local opposition, fearing a loss of business.\nExpansions and removals.\nThe Interstate Highway System has been expanded numerous times. The expansions have both created new designations and extended existing designations. For example, I-49, added to the system in the 1980s as a freeway in Louisiana, was designated as an expansion corridor, and FHWA approved the expanded route north from Lafayette, Louisiana, to Kansas City, Missouri. The freeway exists today as separate completed segments, with segments under construction or in the planning phase between them.\nIn 1966, the FHWA designated the entire Interstate Highway System as part of the larger Pan-American Highway System, and at least two proposed Interstate expansions were initiated to help trade with Canada and Mexico spurred by the North American Free Trade Agreement (NAFTA). Long-term plans for I-69, which currently exists in several separate completed segments (the largest of which are in Indiana and Texas), is to have the highway route extend from Tamaulipas, Mexico to Ontario, Canada. The planned I-11 will then bridge the Interstate gap between Phoenix, Arizona and Las Vegas, Nevada, and thus form part of the CANAMEX Corridor (along with I-19, and portions of I-10 and I-15) between Sonora, Mexico and Alberta, Canada.\nOpposition, cancellations, and removals.\nPolitical opposition from residents canceled many freeway projects around the United States, including:\nIn addition to cancellations, removals of freeways are planned:\nStandards.\nThe American Association of State Highway and Transportation Officials (AASHTO) has defined a set of standards that all new Interstates must meet unless a waiver from the Federal Highway Administration (FHWA) is obtained. One almost absolute standard is the controlled access nature of the roads. With few exceptions, traffic lights (and cross traffic in general) are limited to toll booths and ramp meters (metered flow control for lane merging during rush hour).\nSpeed limits.\nBeing freeways, Interstate Highways usually have the highest speed limits in a given area. Speed limits are determined by individual states. From 1975 to 1986, the maximum speed limit on any highway in the United States was , in accordance with federal law.\nTypically, lower limits are established in Northeastern and coastal states, while higher speed limits are established in inland states west of the Mississippi River. For example, the maximum speed limit is in northern Maine, varies between from southern Maine to New Jersey, and is in New York City and the District of Columbia. Currently, rural speed limits elsewhere generally range from . Several portions of various highways such as I-10 and I-20 in rural western Texas, I-80 in Nevada between Fernley and Winnemucca (except around Lovelock) and portions of I-15, I-70, I-80, and I-84 in Utah have a speed limit of . Other Interstates in Idaho, Montana, Oklahoma, South Dakota and Wyoming also have the same high speed limits.\nIn some areas, speed limits on Interstates can be significantly lower in areas where they traverse significantly hazardous areas. The maximum speed limit on I-90 is in downtown Cleveland because of two sharp curves with a suggested limit of in a heavily congested area; I-70 through Wheeling, West Virginia, has a maximum speed limit of through the Wheeling Tunnel and most of downtown Wheeling; and I-68 has a maximum speed limit of through Cumberland, Maryland, because of multiple hazards including sharp curves and narrow lanes through the city. In some locations, low speed limits are the result of lawsuits and resident demands; after holding up the completion of I-35E in St. Paul, Minnesota, for nearly 30\u00a0years in the courts, residents along the stretch of the freeway from the southern city limit to downtown successfully lobbied for a speed limit in addition to a prohibition on any vehicle weighing more than gross vehicle weight. I-93 in Franconia Notch State Park in northern New Hampshire has a speed limit of because it is a parkway that consists of only one lane per side of the highway. On the other hand, Interstates 15, 80, 84, and 215 in Utah have speed limits as high as within the Wasatch Front, Cedar City, and St. George areas, and I-25 in New Mexico within the Santa Fe and Las Vegas areas along with I-20 in Texas along Odessa and Midland and I-29 in North Dakota along the Grand Forks area have higher speed limits of .\nOther uses.\nAs one of the components of the National Highway System, Interstate Highways improve the mobility of military troops to and from airports, seaports, rail terminals, and other military bases. Interstate Highways also connect to other roads that are a part of the Strategic Highway Network, a system of roads identified as critical to the US Department of Defense.\nThe system has also been used to facilitate evacuations in the face of hurricanes and other natural disasters. An option for maximizing traffic throughput on a highway is to reverse the flow of traffic on one side of a divider so that all lanes become outbound lanes. This procedure, known as contraflow lane reversal, has been employed several times for hurricane evacuations. After public outcry regarding the inefficiency of evacuating from southern Louisiana prior to Hurricane Georges' landfall in September 1998, government officials looked towards contraflow to improve evacuation times. In Savannah, Georgia, and Charleston, South Carolina, in 1999, lanes of I-16 and I-26 were used in a contraflow configuration in anticipation of Hurricane Floyd with mixed results.\nIn 2004, contraflow was employed ahead of Hurricane Charley in the Tampa, Florida area and on the Gulf Coast before the landfall of Hurricane Ivan; however, evacuation times there were no better than previous evacuation operations. Engineers began to apply lessons learned from the analysis of prior contraflow operations, including limiting exits, removing troopers (to keep traffic flowing instead of having drivers stop for directions), and improving the dissemination of public information. As a result, the 2005 evacuation of New Orleans, Louisiana, prior to Hurricane Katrina ran much more smoothly.\nAccording to urban legend, early regulations required that one out of every five miles of the Interstate Highway System must be built straight and flat, so as to be usable by aircraft during times of war. There is no evidence of this rule being included in any Interstate legislation. It is also commonly believed the Interstate Highway System was built for the sole purpose of evacuating cities in the event of nuclear warfare. While military motivations were present, the primary motivations were civilian.\nNumbering system.\nPrimary (one- and two-digit) Interstates.\nThe numbering scheme for the Interstate Highway System was developed in 1957 by the American Association of State Highway and Transportation Officials (AASHTO). The association's present numbering policy dates back to August 10, 1973. Within the contiguous United States, primary Interstates\u2014also called main line Interstates or two-digit Interstates\u2014are assigned numbers less than 100.\nWhile numerous exceptions do exist, there is a general scheme for numbering Interstates. Primary Interstates are assigned one- or two-digit numbers, while shorter routes (such as spurs, loops, and short connecting roads) are assigned three-digit numbers where the last two digits match the parent route (thus, I-294 is a loop that connects at both ends to I-94, while I-787 is a short spur route attached to I-87). In the numbering scheme for the primary routes, east\u2013west highways are assigned even numbers and north\u2013south highways are assigned odd numbers. Odd route numbers increase from west to east, and even-numbered routes increase from south to north (to avoid confusion with the US Highways, which increase from east to west and north to south). This numbering system usually holds true even if the local direction of the route does not match the compass directions. Numbers divisible by five are intended to be major arteries among the primary routes, carrying traffic long distances. Primary north\u2013south Interstates increase in number from I-5 between Canada and Mexico along the West Coast to I\u201195 between Canada and Miami, Florida along the East Coast. Major west\u2013east arterial Interstates increase in number from I-10 between Santa Monica, California, and Jacksonville, Florida, to I-90 between Seattle, Washington, and Boston, Massachusetts, with two exceptions. There are no I-50 and I-60, as routes with those numbers would likely pass through states that currently have US Highways with the same numbers, which is generally disallowed under highway administration guidelines.\nSeveral two-digit numbers are shared between unconnected road segments at opposite ends of the country for various reasons. Some such highways are incomplete Interstates (such as I-69 and I-74) and some just happen to share route designations (such as I-76, I-84, I\u201186, I-87, and I-88). Some of these were due to a change in the numbering system as a result of a new policy adopted in 1973. Previously, letter-suffixed numbers were used for long spurs off primary routes; for example, western I\u201184 was I\u201180N, as it went north from I\u201180. The new policy stated, \"No new divided numbers (such as I-35W and I-35E, etc.) shall be adopted.\" The new policy also recommended that existing divided numbers be eliminated as quickly as possible; however, an I-35W and I-35E (East and West) still exist in the Dallas\u2013Fort Worth metroplex in Texas, and an I-35W and I-35E that run through Minneapolis and Saint Paul, Minnesota, still exist. Additionally, due to Congressional requirements, three sections of I-69 in southern Texas will be divided into I-69W, I-69E, and I-69C (for Central).\nAASHTO policy allows dual numbering to provide continuity between major control points. This is referred to as a concurrency or overlap. For example, I\u201175 and I\u201185 share the same roadway in Atlanta; this section, called the Downtown Connector, is labeled both I\u201175 and I\u201185. Concurrencies between Interstate and US Highway numbers are also allowed in accordance with AASHTO policy, as long as the length of the concurrency is reasonable. In rare instances, two highway designations sharing the same roadway are signed as traveling in opposite directions; one such wrong-way concurrency is found between Wytheville and Fort Chiswell, Virginia, where I\u201181 north and I\u201177 south are equivalent (with that section of road traveling almost due east), as are I\u201181 south and I\u201177 north.\nAuxiliary (three-digit) Interstates.\nAuxiliary Interstate Highways are circumferential, radial, or spur highways that principally serve urban areas. These types of Interstate Highways are given three-digit route numbers, which consist of a single digit prefixed to the two-digit number of its parent Interstate Highway. Spur routes deviate from their parent and do not return; these are given an odd first digit. Circumferential and radial loop routes return to the parent, and are given an even first digit. Unlike primary Interstates, three-digit Interstates are signed as either east\u2013west or north\u2013south, depending on the general orientation of the route, without regard to the route number. For instance, I-190 in Massachusetts is labeled north\u2013south, while I-195 in New Jersey is labeled east\u2013west. Some looped Interstate routes use inner\u2013outer directions instead of compass directions, when the use of compass directions would create ambiguity. Due to the large number of these routes, auxiliary route numbers may be repeated in different states along the mainline. Some auxiliary highways do not follow these guidelines, however.\nAlaska, Hawaii, and Puerto Rico.\nThe Interstate Highway System also extends to Alaska, Hawaii, and Puerto Rico, even though they have no direct land connections to any other states or territories. However, their residents still pay federal fuel and tire taxes.\nThe Interstates in Hawaii, all located on the most populous island of Oahu, carry the prefix H. There are three one-digit routes in the state (H-1, H-2, and H-3) and one auxiliary route (H-201). These Interstates connect several military and naval bases together, as well as the important communities spread across Oahu, and especially within the urban core of Honolulu.\nBoth Alaska and Puerto Rico also have public highways that receive 90\u00a0percent of their funding from the Interstate Highway program. The Interstates of Alaska and Puerto Rico are numbered sequentially in order of funding without regard to the rules on odd and even numbers. They also carry the prefixes A and PR, respectively. However, these highways are signed according to their local designations, not their Interstate Highway numbers. Furthermore, these routes were neither planned according to nor constructed to the official Interstate Highway standards.\nMile markers and exit numbers.\nOn one- or two-digit Interstates, the mile marker numbering almost always begins at the southern or western state line. If an Interstate originates within a state, the numbering begins from the location where the road begins in the south or west. As with all guidelines for Interstate routes, however, numerous exceptions exist. For instance, I-86 dips into Pennsylvania for just 1.5 miles at exit 60 which maintains mile marker numbering for New York.\nThree-digit Interstates with an even first number that form a complete circumferential (circle) bypass around a city feature mile markers that are numbered in a clockwise direction, beginning just west of an Interstate that bisects the circumferential route near a south polar location. In other words, mile marker\u00a01 on I-465, a route around Indianapolis, is just west of its junction with I-65 on the south side of Indianapolis (on the south leg of I-465), and mile marker\u00a053 is just east of this same junction. An exception is I-495 in the Washington metropolitan area, with mileposts increasing counterclockwise because part of that road is also part of I-95.\nMost Interstate Highways use distance-based exit numbers so that the exit number is the same as the nearest mile marker. If multiple exits occur within the same mile, letter suffixes may be appended to the numbers in alphabetical order starting with A. A small number of Interstate Highways (mostly in the Northeastern United States) use sequential-based exit numbering schemes (where each exit is numbered in order starting with 1, without regard for the mile markers on the road). One Interstate Highway, I-19 in Arizona, is signed with kilometer-based exit numbers. In the state of New York, most Interstate Highways use sequential exit numbering, with some exceptions.\nBusiness routes.\nAASHTO defines a category of special routes separate from primary and auxiliary Interstate designations. These routes do not have to comply to Interstate construction or limited-access standards but are routes that may be identified and approved by the association. The same route marking policy applies to both US Numbered Highways and Interstate Highways; however, business route designations are sometimes used for Interstate Highways. Known as Business Loops and Business Spurs, these routes principally travel through the corporate limits of a city, passing through the central business district when the regular route is directed around the city. They also use a green shield instead of the red and blue shield. An example would be Business Loop Interstate 75 at Pontiac, Michigan, which follows surface roads into and through downtown. Sections of BL I-75's routing had been part of US\u00a010 and M-24, predecessors of I-75 in the area.\nFinancing.\nInterstate Highways and their rights-of-way are owned by the state in which they were built. The last federally owned portion of the Interstate System was the Woodrow Wilson Bridge on the Washington Capital Beltway. The new bridge was completed in 2009 and is collectively owned by Virginia and Maryland. Maintenance is generally the responsibility of the state department of transportation. However, there are some segments of Interstate owned and maintained by local authorities.\nTaxes and user fees.\nAbout 70\u00a0percent of the construction and maintenance costs of Interstate Highways in the United States have been paid through user fees, primarily the fuel taxes collected by the federal, state, and local governments. To a much lesser extent they have been paid for by tolls collected on toll highways and bridges. The federal gasoline tax was first imposed in 1932 at one cent per gallon; during the Eisenhower administration, the Highway Trust Fund, established by the Highway Revenue Act in 1956, prescribed a three-cent-per-gallon fuel tax, soon increased to 4.5\u00a0cents per gallon. Since 1993 the tax has remained at 18.4\u00a0cents per gallon. Other excise taxes related to highway travel also accumulated in the Highway Trust Fund. Initially, that fund was sufficient for the federal portion of building the Interstate system, built in the early years with \"10 cent dollars\", from the perspective of the states, as the federal government paid 90% of the costs while the state paid 10%. The system grew more rapidly than the rate of the taxes on fuel and other aspects of driving (e. g., excise tax on tires).\nThe rest of the costs of these highways are borne by general fund receipts, bond issues, designated property taxes, and other taxes. The federal contribution is funded primarily through fuel taxes and through transfers from the Treasury's general fund. Local government contributions are overwhelmingly from sources besides user fees. As decades passed in the 20th century and into the 21st century, the portion of the user fees spent on highways themselves covers about 57\u00a0percent of their costs, with about one-sixth of the user fees being sent to other programs, including the mass transit systems in large cities. Some large sections of Interstate Highways that were planned or constructed before 1956 are still operated as toll roads, for example the Massachusetts Turnpike (I-90), the New York State Thruway (I-87 and I-90), and Kansas Turnpike (I-35, I-335, I-470, I-70). Others have had their construction bonds paid off and they have become toll-free, such as the Connecticut Turnpike (I\u201195, I-395), the Richmond-Petersburg Turnpike in Virginia (also I\u201195), and the Kentucky Turnpike (I\u201165).\nAs American suburbs have expanded, the costs incurred in maintaining freeway infrastructure have also grown, leaving little in the way of funds for new Interstate construction. This has led to the proliferation of toll roads (turnpikes) as the new method of building limited-access highways in suburban areas. Some Interstates are privately maintained (for example, the VMS company maintains I\u201135 in Texas) to meet rising costs of maintenance and allow state departments of transportation to focus on serving the fastest-growing regions in their states.\nParts of the Interstate System might have to be tolled in the future to meet maintenance and expansion demands, as has been done with adding toll HOV/HOT lanes in cities such as Atlanta, Dallas, and Los Angeles. Although part of the tolling is an effect of the SAFETEA\u2011LU act, which has put an emphasis on toll roads as a means to reduce congestion, present federal law does not allow for a state to change a freeway section to a tolled section for all traffic.\nTolls.\nAbout of toll roads are included in the Interstate Highway System. While federal legislation initially banned the collection of tolls on Interstates, many of the toll roads on the system were either completed or under construction when the Interstate Highway System was established. Since these highways provided logical connections to other parts of the system, they were designated as Interstate highways. Congress also decided that it was too costly to either build toll-free Interstates parallel to these toll roads, or directly repay all the bondholders who financed these facilities and remove the tolls. Thus, these toll roads were grandfathered into the Interstate Highway System.\nToll roads designated as Interstates (such as the Massachusetts Turnpike) were typically allowed to continue collecting tolls, but are generally ineligible to receive federal funds for maintenance and improvements. Some toll roads that did receive federal funds to finance emergency repairs (notably the Connecticut Turnpike (I-95) following the Mianus River Bridge collapse) were required to remove tolls as soon as the highway's construction bonds were paid off. In addition, these toll facilities were grandfathered from Interstate Highway standards. A notable example is the western approach to the Benjamin Franklin Bridge in Philadelphia, where I-676 has a surface street section through a historic area.\nPolicies on toll facilities and Interstate Highways have since changed. The Federal Highway Administration has allowed some states to collect tolls on existing Interstate Highways, while a recent extension of I-376 included a section of Pennsylvania Route\u00a060 that was tolled by the Pennsylvania Turnpike Commission before receiving Interstate designation. Also, newer toll facilities (like the tolled section of I-376, which was built in the early 1990s) must conform to Interstate standards. A new addition of the \"Manual on Uniform Traffic Control Devices\" in 2009 requires a black-on-yellow \"Toll\" sign to be placed above the Interstate trailblazer on Interstate Highways that collect tolls.\nLegislation passed in 2005 known as SAFETEA-LU encouraged states to construct new Interstate Highways through \"innovative financing\" methods. SAFETEA-LU facilitated states to pursue innovative financing by easing the restrictions on building interstates as toll roads, either through state agencies or through public\u2013private partnerships. However, SAFETEA-LU left in place a prohibition of installing tolls on existing toll-free Interstates, and states wishing to toll such routes to finance upgrades and repairs must first seek approval from Congress. Many states have started using High-occupancy toll lane and other partial tolling methods, whereby certain lanes of highly congested freeways are tolled, while others are left free, allowing people to pay a fee to travel in less congested lanes. Examples of recent projects to add HOT lanes to existing freeways include the Virginia HOT lanes on the Virginia portions of the Capital Beltway and other related interstate highways (I-95, I-495, I-395) and the addition of express toll lanes to Interstate 77 in North Carolina in the Charlotte metropolitan area.\nChargeable and non-chargeable Interstate routes.\nInterstate Highways financed with federal funds are known as \"chargeable\" Interstate routes, and are considered part of the network of highways. Federal laws also allow \"non-chargeable\" Interstate routes, highways funded similarly to state and US Highways to be signed as Interstates, if they both meet the Interstate Highway standards and are logical additions or connections to the system. These additions fall under two categories: routes that already meet Interstate standards, and routes not yet upgraded to Interstate standards. Only routes that meet Interstate standards may be signed as Interstates once their proposed number is approved, unless they are granted a design waiver by the Federal Highway Administration (FHWA).\nSignage.\nInterstate shield.\nInterstate Highways are signed by a number placed on a red, white, and blue sign. The shield design itself is a registered trademark of the American Association of State Highway and Transportation Officials. The colors red, white, and blue were chosen because they are the colors of the American flag. In the original design, the name of the state was displayed above the highway number, but in many states, this area is now left blank, allowing for the printing of larger and more-legible digits. Signs with the shield alone are placed periodically throughout each Interstate as reassurance markers. These signs usually measure high, and are wide for two-digit Interstates or for three-digit Interstates.\nInterstate business loops and spurs use a special shield in which the red and blue are replaced with green, the word \"BUSINESS\" appears instead of \"INTERSTATE\", and the word \"SPUR\" or \"LOOP\" usually appears above the number. The green shield is employed to mark the main route through a city's central business district, which intersects the associated Interstate at one (spur) or both (loop) ends of the business route. The route usually traverses the main thoroughfare(s) of the city's downtown area or other major business district. A city may have more than one Interstate-derived business route, depending on the number of Interstates passing through a city and the number of significant business districts therein.\nOver time, the design of the Interstate shield has changed. In 1957 the Interstate shield designed by Texas Highway Department employee Richard Oliver was introduced, the winner of a contest that included 100\u00a0entries; at the time, the shield color was a dark navy blue and only wide. The \"Manual on Uniform Traffic Control Devices\" (MUTCD) standards revised the shield in the 1961, 1971, and 1978 editions.\nExit numbering.\nThe majority of Interstates have exit numbers. Like other highways, Interstates feature guide signs that list control cities to help direct drivers through interchanges and exits toward their desired destination. All traffic signs and lane markings on the Interstates are supposed to be designed in compliance with the Manual on Uniform Traffic Control Devices (MUTCD). There are, however, many local and regional variations in signage.\nFor many years, California was the only state that did not use an exit numbering system. It was granted an exemption in the 1950s due to having an already largely completed and signed highway system; placing exit number signage across the state was deemed too expensive. To control costs, California began to incorporate exit numbers on its freeways in 2002\u2014Interstate, US, and state routes alike. Caltrans commonly installs exit number signage only when a freeway or interchange is built, reconstructed, retrofitted, or repaired, and it is usually tacked onto the top-right corner of an already existing sign. Newer signs along the freeways follow this practice as well. Most exits along California's Interstates now have exit number signage, particularly in rural areas. California, however, still does not use mileposts, although a few exist for experiments or for special purposes. \nIn 2010\u20132011, the Illinois State Toll Highway Authority posted all new mile markers to be uniform with the rest of the state on I\u201190 (Jane Addams Memorial/Northwest Tollway) and the I\u201194 section of the Tri\u2011State Tollway, which previously had matched the I\u2011294 section starting in the south at I\u201180/I\u201194/IL Route 394. This also applied to the tolled portion of the Ronald Reagan Tollway (I-88). The tollway also added exit number tabs to the exits.\nExit numbers correspond to Interstate mileage markers in most states. On I\u201119 in Arizona, however, length is measured in kilometers instead of miles because, at the time of construction, a push for the United States to change to a metric system of measurement had gained enough traction that it was mistakenly assumed that all highway measurements would eventually be changed to metric (and some distance signs retain metric distances); proximity to metric-using Mexico may also have been a factor, as I\u201119 indirectly connects I\u201110 to the Mexican Federal Highway system via surface streets in Nogales. Mileage count increases from west to east on most even-numbered Interstates; on odd-numbered Interstates mileage count increases from south to north.\nSome highways, including the New York State Thruway, use sequential exit-numbering schemes. Exits on the New York State Thruway count up from Yonkers traveling north, and then west from Albany. I\u201187 in New York State is numbered in three sections. The first section makes up the Major Deegan Expressway in the Bronx, with interchanges numbered sequentially from 1 to 14. The second section of I\u201187 is a part of the New York State Thruway that starts in Yonkers (exit\u00a01) and continues north to Albany (exit\u00a024); at Albany, the Thruway turns west and becomes I\u201190 for exits\u00a025 to 61. From Albany north to the Canadian border, the exits on I\u201187 are numbered sequentially from 1 to 44 along the Adirondack Northway. This often leads to confusion as there is more than one exit on I\u201187 with the same number. For example, exit\u00a04 on Thruway section of I\u201187 connects with the Cross County Parkway in Yonkers, but exit\u00a04 on the Northway is the exit for the Albany airport. These two exits share a number but are located apart.\nMany northeastern states label exit numbers sequentially, regardless of how many miles have passed between exits. States in which Interstate exits are still numbered sequentially are Connecticut, Delaware, New Hampshire, New York, and Vermont; as such, three of the main Interstate Highways that remain completely within these states (87, 88, 89) have interchanges numbered sequentially along their entire routes. Maine, Massachusetts, Pennsylvania, Virginia, Georgia, and Florida followed this system for a number of years, but have since converted to mileage-based exit numbers. Georgia renumbered in 2000, while Maine did so in 2004. Massachusetts converted its exit numbers in 2021, and most recently Rhode Island in 2022. The Pennsylvania Turnpike uses both mile marker numbers and sequential numbers. Mile marker numbers are used for signage, while sequential numbers are used for numbering interchanges internally. The New Jersey Turnpike, including the portions that are signed as I\u201195 and I\u201178, also has sequential numbering, but other Interstates within New Jersey use mile markers.\nSign locations.\nThere are four common signage methods on Interstates:\nImpact and reception.\nFollowing the passage of the Federal Aid Highway Act of 1956, passenger rail declined sharply as did freight rail for a short time, but the trucking industry expanded dramatically and the cost of shipping and travel fell sharply. Suburbanization became possible, with the rapid growth of larger, sprawling, and more car-dependent housing than was available in central cities, enabling racial segregation by white flight. A sense of isolationism developed in suburbs, with suburbanites wanting to keep urban areas disconnected from the suburbs. Tourism dramatically expanded, creating a demand for more service stations, motels, restaurants and visitor attractions. The Interstate System was the basis for urban expansion in the Sun Belt, and many urban areas in the region are thus very car-dependent. The highways may have contributed to increased economic productivity in, and thereby increased migration to, the Sun Belt. In rural areas, towns and small cities off the grid lost out as shoppers followed the interstate and new factories were located near them.\nThe system had a profound effect on interstate shipping. The Interstate Highway System was being constructed at the same time as the intermodal shipping container made its debut. These containers could be placed on trailers behind trucks and shipped across the country with ease. A new road network and shipping containers that could be easily moved from ship to train to truck, meant that overseas manufacturers and domestic startups could get their products to market quicker than ever, allowing for accelerated economic growth. Forty years after its construction, the Interstate Highway system returned on investment, making $6 for every $1 spent on the project. According to research by the FHWA, \"from 1950 to 1989, approximately one-quarter of the nation's productivity increase is attributable to increased investment in the highway system.\"\nThe system had a particularly strong effect in Southern states, where major highways were inadequate. The new system facilitated the relocation of heavy manufacturing to the South and spurred the development of Southern-based corporations like Walmart (in Arkansas) and FedEx (in Tennessee).\nThe Interstate Highway System also dramatically affected American culture, contributing to cars becoming more central to the American identity. Before, driving was considered an excursion that required some amount of skill and could have some chance of unpredictability. With the standardization of signs, road widths and rules, certain unpredictabilities lessened. Justin Fox wrote, \"By making road more reliable and by making Americans more reliant on them, they took away most of the adventure and romance associated with driving.\"\nThe Interstate Highway System has been criticized for contributing to the decline of some cities that were divided by Interstates, and for displacing minority neighborhoods in urban centers. Between 1957 and 1977, the Interstate System alone displaced over 475,000 households and one million people across the country. Highways have also been criticized for increasing racial segregation by creating physical barriers between neighborhoods, and for overall reductions in available housing and population in neighborhoods affected by highway construction. Other critics have blamed the Interstate Highway System for the decline of public transportation in the United States since the 1950s, which minorities and low-income residents are three to six times more likely to use. Previous highways, such as US 66, were also bypassed by the new Interstate system, turning countless rural communities along the way into ghost towns. The Interstate System has also contributed to continued resistance against new public transportation. \nThe Interstate Highway System had a negative impact on minority groups, especially in urban areas. Even though the government used eminent domain to obtain land for the Interstates, it was still economical to build where land was cheapest. This cheap land was often located in predominately minority areas. Not only were minority neighborhoods destroyed, but in some cities the Interstates were used to divide white and minority neighborhoods. These practices were common in cities both in the North and South, including Nashville, Miami, Chicago, Detroit, and many other cities. The division and destruction of neighborhoods led to the limitation of employment and other opportunities, which deteriorated the economic fabric of neighborhoods. Neighborhoods bordering Interstates have a much higher level of particulate air pollution and are more likely to be chosen for polluting industrial facilities.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "43951", "revid": "488581", "url": "https://en.wikipedia.org/wiki?curid=43951", "title": "United States Numbered Highway System", "text": "Highway system of the United States of America\n&lt;templatestyles src=\"Infobox road/styles.css\" /&gt;\nThe United States Numbered Highway System (often called U.S. Routes or U.S. Highways) is an integrated network of roads and highways numbered within a nationwide grid in the contiguous United States. As the designation and numbering of these highways were coordinated among the states, they are sometimes called Federal Highways, but the roadways were built and have always been maintained by state or local governments since their initial designation in 1926.\nThe route numbers and locations are coordinated by the American Association of State Highway and Transportation Officials (AASHTO). The only federal involvement in AASHTO is a nonvoting seat for the United States Department of Transportation. Generally, most north-to-south highways are odd-numbered, with the lowest numbers in the east and the highest in the west, while east-to-west highways are typically even-numbered, with the lowest numbers in the north, and the highest in the south, though the grid guidelines are not rigidly followed, and many exceptions exist. Major north\u2013south routes generally have numbers ending in \"1\", while major east\u2013west routes usually have numbers ending in \"0\". Three-digit numbered highways are generally spur routes of parent highways; for example, U.S. Route 421 (US\u00a0421) is a spur off US\u00a021. Some divided routes, such as US\u00a019E/US\u00a019W and US\u00a025E/US\u00a025W, exist to provide two alignments for one route. Special routes, which can be labeled as alternate, bypass or business, depending on the intended use, provide a parallel routing to the mainline U.S. Highway\u2014an example being US\u00a074 and its many special routes.\nBefore the U.S. Routes were designated, auto trails designated by auto trail associations were the main means of marking roads through the United States. These were private organizations, and the system of road marking at the time was haphazard and not uniform. In 1925, the Joint Board on Interstate Highways, recommended by the American Association of State Highway Officials (AASHO), worked to form a national numbering system to rationalize the roads. After several meetings, a final report was approved by the U.S. Department of Agriculture in November 1925. After getting feedback from the states, they made several modifications; the U.S. Highway System was approved on November 11, 1926.\nExpansion of the U.S. Highway System continued until 1956, when the Interstate Highway System was laid out and began construction under the administration of President Dwight D. Eisenhower. After the national implementation of the Interstate Highway System, many U.S. Routes that had been bypassed or overlaid with Interstate Highways were decommissioned and removed from the system. In some places, the U.S. Routes remain alongside the Interstates and serve as a means for interstate travelers to access local services and as secondary feeder roads or as important major arteries in their own right. In other places, where there are no nearby Interstate Highways, the U.S. Routes often remain as the most well-developed roads for long-distance travel. While the system's growth has slowed in recent decades, the U.S. Highway System remains in place to this day and new routes are occasionally added to the system.\nSystem details.\nIn general, U.S. Routes do not have a minimum design standard, unlike the later Interstate Highways, and are not usually built to freeway standards. Some stretches of U.S. Routes do meet those standards. Many are designated using the main streets of the cities and towns through which they run. New additions to the system, however, must \"substantially meet the current AASHTO design standards\". As of 1989,[ [update]] the United States Numbered Highways system had a total length of .\nExcept for toll bridges and tunnels, very few U.S. Routes are toll roads. AASHTO policy says that a toll road may only be included as a special route, and that \"a toll-free routing between the same termini shall continue to be retained and marked as a part of the U.S. Numbered System.\" US\u00a03 meets this obligation; in New Hampshire, it does not follow tolled portions of the Everett Turnpike. However, U.S. Routes in the system do use parts of five toll roads:\nNumbering.\nU.S. Routes in the contiguous United States follow a grid pattern, in which odd-numbered routes run generally north to south and even-numbered routes run generally east to west, though three-digit spur routes can be either-or. However, some exceptions exist within the two-digit routes. These primarily occur when a route does not definitively run in a single direction. For example, US 35 runs northeast-southwest; it is signed east-west in Ohio, but north-south everywhere else. Usually, one- and two-digit routes are major routes, and three-digit routes are numbered as shorter spur routes from a main route. Odd numbers generally increase from east to west; US\u00a01 follows the Atlantic Coast and US\u00a0101 follows the Pacific Coast. (US\u00a0101 is one of the many exceptions to the standard numbering grid; its first \"digit\" is \"10\", and it is a main route on its own and not a spur of US\u00a01.) Even numbers tend to increase from north to south; US\u00a02 closely follows the Canadian border, and US\u00a098 hugs the Gulf Coast. The longest routes connecting major cities are generally numbered to end in a 1 or a 0; however, extensions and truncations have made this distinction largely meaningless. These guidelines are very rough, and exceptions to all of the basic numbering rules exist.\nThe numbering system also extended beyond the borders of the United States in an unofficial manner. Many Canadian highways were renumbered in the 1940s and 1950s to adopt the same number as the U.S. Route they connected to \u2013 mostly in the western provinces. Examples include British Columbia's highways 93, 95, 97, and 99; Manitoba's highways 59, 75, and 83; or Ontario King's Highway 71. The reverse happened with U.S. Route 57, originally a Texas state highway numbered to match Mexican Federal Highway 57.\nIn the 1950s, the numbering grid for the new Interstate Highway System was established as intentionally opposite from the U.S. grid insofar as the direction the route numbers increase. Interstate Highway numbers increase from west-to-east and south-to-north, to keep identically numbered routes geographically apart in order to keep them from being confused with one another, and it omits 50 and 60 which would potentially conflict with US\u00a050 and US\u00a060.\nIn the U.S. Highway system, three-digit numbers are assigned to spurs of one or two-digit routes. US\u00a0201, for example, splits from US\u00a01 at Brunswick, Maine, and runs north to Canada. Not all spurs travel in the same direction as their \"parents\"; some are connected to their parents only by other spurs, or not at all, instead only traveling near their parents, Also, a spur may travel in different cardinal directions than its parent, such as US\u00a0522, which is a north\u2013south route, unlike its parent US\u00a022, which is east\u2013west. As originally assigned, the first digit of the spurs increased from north to south and east to west along the parent; for example, US\u00a060 had spurs, running from east to west, designated as US\u00a0160 in Missouri, US\u00a0260 in Oklahoma, US\u00a0360 in Texas, and US\u00a0460 and US\u00a0560 in New Mexico. As with the two-digit routes, three-digit routes have been added, removed, extended and shortened; the \"parent-child\" relationship is not always present.\nAASHTO guidelines specifically prohibit Interstate Highways and U.S. Routes from sharing a number within the same state. As with other guidelines, exceptions exist across the U.S.\nSome two-digit numbers have never been applied to any U.S. Route, including 37, 39, 47, 86, and 88.\nSignage.\nRoute numbers are displayed on a distinctively-shaped white shield with large black numerals in the center. Often, the shield is displayed against a black square or rectangular background. Each state manufactures their own signage, and as such subtle variations exist all across the United States. Individual states may use cut-out or rectangular designs, some have black outlines, and California prints the letters \"US\" above the numerals. One- and two-digit shields generally feature the same large, bold numerals on a square-dimension shield, while 3-digit routes may either use the same shield with a narrower font, or a wider rectangular-dimension shield. Special routes may be indicated with a banner above the route number, or with a letter suffixed to the route number. Signs are generally displayed in several different locations. First, they are shown along the side of the route at regular intervals or after major intersections (called reassurance markers), which shows the route and the nominal direction of travel. Second, they are displayed at intersections with other major roads, so that intersecting traffic can follow their chosen course. Third, they can be displayed on large green guide signs that indicate upcoming interchanges on freeways and expressways.\nDivided and special routes.\nSince 1926, some divided routes were designated to serve related areas, and designate roughly-equivalent splits of routes. For instance, US\u00a011 splits into US\u00a011E (east) and US\u00a011W (west) in Bristol, Virginia, and the routes rejoin in Knoxville, Tennessee. Occasionally only one of the two routes is suffixed; US\u00a06N in Pennsylvania does not rejoin US\u00a06 at its west end. AASHTO has been trying to eliminate these since 1934; its current policy is to deny approval of new split routes and to eliminate existing ones \"as rapidly as the State Highway Department and the Standing Committee on Highways can reach agreement with reference thereto\".\nSpecial routes\u2014those with a banner such as alternate or bypass\u2014are also managed by AASHTO. These are sometimes designated with lettered suffixes, like A for alternate or B for business.\nNaming.\nThe official route log, last published by AASHTO in 1989, has been named \"United States Numbered Highways\" since its initial publication in 1926. Within the route log, \"U.S. Route\" is used in the table of contents, while \"United States Highway\" appears as the heading for each route. All reports of the Special Committee on Route Numbering since 1989 use \"U.S. Route\", and federal laws relating to highways use \"United States Route\" or \"U.S. Route\" more often than the \"Highway\" variants. The use of U.S. Route or U.S. Highway on a local level depends on the state, with some states such as Delaware using \"route\" and others such as Colorado using \"highway\".\nHistory.\nEarly auto trails.\nIn 1903, Horatio Nelson Jackson became the first documented person to drive an automobile from San Francisco to New York using only a connection of dirt roads, cow paths, and railroad beds. His journey, covered by the press, became a national sensation and called for a system of long-distance roads.\nIn the early 1910s, auto trail organizations\u2014most prominently the Lincoln Highway\u2014began to spring up, marking and promoting routes for the new recreation of long-distance automobile travel. The Yellowstone Trail was another of the earliest examples. While many of these organizations worked with towns and states along the route to improve the roadways, others simply chose a route based on towns that were willing to pay dues, put up signs, and did little else.\nPlanning.\nWisconsin was the first state in the U.S. to number its highways, erecting signs in May 1918. Other states soon followed. In 1922, the New England states got together to establish the six-state New England Interstate Routes.\nBehind the scenes, the federal aid program had begun with the passage of the Federal Aid Road Act of 1916, providing 50% monetary support from the federal government for improvement of major roads. The Federal Aid Highway Act of 1921 limited the routes to 7% of each state's roads, while 3 in every 7 roads had to be \"interstate in character\". Identification of these main roads was completed in 1923.\nThe American Association of State Highway Officials (AASHO), formed in 1914 to help establish roadway standards, began to plan a system of marked and numbered \"interstate highways\" at its 1924 meeting. AASHO recommended that the Secretary of Agriculture work with the states to designate these routes.\nSecretary Howard M. Gore appointed the \"Joint Board on Interstate Highways\", as recommended by AASHO, on March 2, 1925. The Board was composed of 21 state highway officials and three federal Bureau of Public Roads officials. At the first meeting, on April 20 and 21, the group chose the name \"U.S. Highway\" as the designation for the routes. They decided that the system would not be limited to the federal-aid network; if the best route did not receive federal funds, it would still be included. The tentative design for the U.S. Route shield was also chosen, based on the shield found on the Great Seal of the United States.\nThe auto trail associations rejected the elimination of the highway names. Six regional meetings were held to hammer out the details\u2014May 15 for the West, May 27 for the Mississippi Valley, June 3 for the Great Lakes, June 8 for the South, June 15 for the North Atlantic, and June 15 for New England. Representatives of the auto trail associations were not able to formally address the meetings. However, as a compromise, they talked with the Joint Board members. The associations finally settled on a general agreement with the numbering plans, as named trails would still be included. The tentative system added up to 81,000 miles (130,000\u00a0km), 2.8% of the public road mileage at the time.\nThe second full meeting was held August 3 and 4, 1925. At that meeting, discussion was held over the appropriate density of routes. William F. Williams of Massachusetts and Frederick S. Greene of New York favored a system of only major transcontinental highways, while many states recommended a large number of roads of only regional importance. Greene in particular intended New York's system to have four major through routes as an example to the other states. Many states agreed in general with the scope of the system, but believed the Midwest to have added too many routes to the system. The group adopted the shield, with few modifications from the original sketch, at that meeting, as well as the decision to number rather than name the routes. A preliminary numbering system, with eight major east\u2013west and ten major north\u2013south routes, was deferred to a numbering committee \"without instructions\".\nAfter working with states to get their approval, the committee expanded the highway system to 75,800 miles (122,000\u00a0km), or 2.6% of total mileage, over 50% more than the plan approved August 4. The skeleton of the numbering plan was suggested on August 27 by Edwin Warley James of the BPR, who matched parity to direction, and laid out a rough grid. Major routes from the earlier map were assigned numbers ending in 0, 1 or 5 (5 was soon relegated to less-major status), and short connections received three-digit numbers based on the main highway from which they spurred. The five-man committee met September 25, and submitted the final report to the Joint Board secretary on October 26. The board sent the report to the Secretary of Agriculture on October 30, and he approved it November 18, 1925.\nDisagreement and refinement, 1925\u201326.\nThe new system was both praised and criticized by local newspapers, often depending on whether that city was connected to a major route. While the Lincoln Highway Association understood and supported the plan, partly because they were assured of getting the US\u00a030 designation as much as possible, most other trail associations lamented their obsolescence. At their January 14\u201315, 1926 meeting, AASHO was flooded with complaints.\nIn the Northeast, New York held out for fewer routes designated as U.S. Highways. The Pennsylvania representative, who had not attended the local meetings, convinced AASHO to add a dense network of routes, which gave six routes termini along the state line. (Only US\u00a0220 still ends near the state line, and now it ends at an intersection with future I-86.) Because US\u00a020 seemed indirect, passing through Yellowstone National Park, Idaho and Oregon requested that US\u00a030 be swapped with US\u00a020 to the Pacific coast.\nMany local disputes arose related to the committee's choices between designation of two roughly equal parallel routes, which were often competing auto trails. At their January meeting, AASHO approved the first two of many split routes (specifically US\u00a040 between Manhattan, Kansas and Limon, Colorado and US\u00a050 between Baldwin City, Kansas and Garden City, Kansas). In effect, each of the two routes received the same number, with a directional suffix indicating its relation to the other. These splits were initially shown in the log as\u2014for instance\u2014US\u00a040 North and US\u00a040 South, but were always posted as simply US\u00a040N and US\u00a040S.\nThe most heated argument, however, was the issue of US\u00a060. The Joint Board had assigned that number to the Chicago-Los Angeles route, which ran more north\u2013south than west\u2013east in Illinois, and then angled sharply to the southwest to Oklahoma City, from where it ran west to Los Angeles. Kentucky strongly objected to this designated route, as it had been left off any of the major east\u2013west routes, instead receiving the US\u00a062 designation. In January 1926, the committee designated this, along with the part of US\u00a052 east of Ashland, Kentucky, as US\u00a060. They assigned US\u00a062 to the Chicago-Los Angeles route, contingent on the approval of the states along the former US\u00a060. But Missouri and Oklahoma did object\u2014Missouri had already printed maps, and Oklahoma had prepared signs. A compromise was proposed, in which US\u00a060 would split at Springfield, Missouri, into US\u00a060E and US\u00a060N, but both sides objected. The final solution resulted in the assignment of US\u00a066 to the Chicago-Los Angeles portion of the U.S. highway, which did not end in zero, but was still seen as a satisfyingly round number. Route 66 came to have a prominent place in popular culture, being featured in song and films.\nWith 32\u00a0states already marking their routes, the plan was approved by AASHO on November 11, 1926. This plan included a number of directionally split routes, several discontinuous routes (including US\u00a06, US\u00a019 and US\u00a050), and some termini at state lines. By the time the first route log was published in April 1927, major numbering changes had been made in Pennsylvania in order to align the routes to the existing auto trails. In addition, US\u00a015 had been extended across Virginia.\nMuch of the early criticism of the U.S. Highway System focused on the choice of numbers to designate the highways, rather than names. Some thought a numbered highway system to be cold compared to the more colorful names and historic value of the auto trail systems. \"The New York Times\" wrote, \"The traveler may shed tears as he drives the Lincoln Highway or dream dreams as he speeds over the Jefferson Highway, but how can he get a 'kick' out of 46, 55 or 33 or 21?\" (A popular song later promised, \"Get your kicks on Route 66!\") The writer Ernest McGaffey was quoted as saying, \"Logarithms will take the place of legends, and 'hokum' for history.\"\nExpansion and adjustment, 1926\u20131956.\nWhen the U.S. numbered system was started in 1925, a few optional routings were established which were designated with a suffixed letter after the number indicating \"north\", \"south\", \"east\", or \"west\". While a few roads in the system are still numbered in this manner, AASHO believes that they should be eliminated wherever possible, by the absorption of one of the optional routes into another route.\nIn 1934, AASHO tried to eliminate many of the split routes by removing them from the log, and designating one of each pair as a three-digit or alternate route, or in one case US\u00a037. AASHO described its renumbering concept in the October 1934 issue of \"American Highways\":\n\"Wherever an alternate route is not suitable for its own unique two-digit designation, standard procedure assigns the unqualified number to the older or shorter route, while the other route uses the same number marked by a standard strip above its shield carrying the word 'Alternate'.\"Most states adhere to this approach. However, some maintain legacy routes that violate the rules in various ways. Examples can be found in California, Mississippi, Nebraska, Oregon, and Tennessee. In 1952, AASHO permanently recognized the splits in US\u00a011, US\u00a019, US\u00a025, US\u00a031, US\u00a045, US\u00a049, US\u00a073, and US\u00a099.\nFor the most part, the U.S. Routes were the primary means of inter-city vehicle travel; the main exceptions were toll roads such as the Pennsylvania Turnpike and parkway routes such as the Merritt Parkway. Many of the first high-speed roads were U.S. Highways: the Gulf Freeway carried US\u00a075, the Pasadena Freeway carried US\u00a066, and the Pulaski Skyway carries US\u00a01 and US\u00a09.\nInterstate era, 1956\u2013present.\nThe Federal Aid Highway Act of 1956 appropriated funding for the Interstate Highway System, to construct a vast network of freeways across the country. By 1957, AASHO had decided to assign a new grid to the new routes, to be numbered in the opposite directions as the U.S. Highway grid. Though the Interstate numbers were to supplement\u2014rather than replace\u2014the U.S. Route numbers, in many cases (especially in the West) the U.S. Highways were rerouted along the new Interstates. Major decommissioning of former routes began with California's highway renumbering in 1964. The 1985 removal of US\u00a066 is often seen as the end of an era of U.S. Highways.\nA few major connections not served by Interstate Highways include US\u00a06 from Hartford, Connecticut, to Providence, Rhode Island and US\u00a093 from Phoenix, Arizona to Las Vegas, Nevada, though the latter is planned to be upgraded to Interstate 11. Three state capitals in the contiguous U.S. are served only by U.S. Routes: Dover, Delaware; Jefferson City, Missouri; and Pierre, South Dakota.\nIn 1995, the National Highway System was defined to include both the Interstate Highway System and other roads designated as important to the nation's economy, defense, and mobility.\nAASHTO is eliminating all intrastate U.S. Highways less than in length \"as rapidly as the State Highway Department and the Standing Committee on Highways of the American Association of State Highway and Transportation Officials can reach agreement with reference thereto\". New additions to the system must serve more than one state and \"substantially meet the current AASHTO design standards\". A version of this policy has been in place since 1937.\nThe 1925 routes.\nThe original major transcontinental routes in 1925, along with the auto trails which they roughly replaced, were as follows:\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nUS\u00a010, US\u00a060, and US\u00a090 only ran about two thirds of the way across the country, while US\u00a011 and US\u00a060 ran significantly diagonally. US\u00a060's violation of two of the conventions would prove to be one of the major sticking points; US\u00a060 eventually was designated as US\u00a066 in 1926, and later it became a part of popular culture. US\u00a0101 continues east and then south to end at Olympia, Washington. The western terminus of US\u00a02 is now at Everett, Washington.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "43953", "revid": "19089174", "url": "https://en.wikipedia.org/wiki?curid=43953", "title": "Speed trap", "text": ""}
{"id": "43956", "revid": "11385830", "url": "https://en.wikipedia.org/wiki?curid=43956", "title": "Erlenmeyer flask", "text": "Laboratory flask with a flat bottom\nAn Erlenmeyer flask, also known as a conical flask (British English) or a titration flask, is a type of laboratory flask with a flat bottom, a conical body, and a cylindrical neck. It is named after the German chemist Emil Erlenmeyer (1825\u20131909), who invented it in 1860.\nErlenmeyer flasks have wide bases and narrow necks. They may be graduated, and often have spots of ground glass or enamel where they can be labeled with a pencil. It differs from the beaker in its tapered body and narrow neck. Depending on the application, they may be constructed from glass or plastic, in a wide range of volumes.\nThe mouth of the Erlenmeyer flask may have a beaded lip that can be stoppered or covered. Alternatively, the neck may be fitted with ground glass or other connector for use with more specialized stoppers or attachment to other apparatus. A B\u00fcchner flask is a common design modification for filtration under vacuum.\nUses.\nIn chemistry.\nThe slanted sides and narrow neck of this flask allow the contents of the flask to be mixed by swirling, without risk of spillage, making them suitable for titrations by placing it under the burette and adding solvent and the indicator in the Erlenmeyer flask. Such features similarly make the flask suitable for boiling liquids. Hot vapour condenses on the upper section of the Erlenmeyer flask, reducing solvent loss. Erlenmeyer flasks' narrow necks can also support filter funnels.\nThe final two attributes of Erlenmeyer flasks make them especially appropriate for recrystallization. The sample to be purified is heated to a boil, and sufficient solvent is added for complete dissolution. The receiving flask is filled with a small amount of solvent, and heated to a boil. The hot solution is filtered through a fluted filter paper into the receiving flask. Hot vapors from the boiling solvent keep the filter funnel warm, avoiding the premature crystallization.\nLike beakers, Erlenmeyer flasks are not normally suitable for accurate volumetric measurements. Their stamped volumes are approximate within about 5% accuracy.\nIn biology.\nErlenmeyer flasks are also used in microbiology for the preparation of microbial cultures. Erlenmeyer flasks used in cell culture are sterilized and may feature vented closures to enhance gas exchange during incubation and shaking. The use of minimal liquid volumes, typically no more than one fifth of the total flask volume, and baffles molded into the flask's internal surface both serve to maximize gas transfer and promote chaotic mixing when the flasks are orbitally shaken. The oxygen transfer rate in Erlenmeyer flasks depends on the agitation speed, the liquid volume, and the shake-flask design. The shaking frequency has the most significant impact on oxygen transfer.\nOxygenation and mixing of liquid cultures further depend on rotation of the liquid \"in-phase\", meaning the synchronous movement of the liquid with the shaker table. Under certain conditions the shaking process leads to a breakdown of liquid motion \u2013 called \"out-of-phase phenomenon\". This phenomenon has been intensively characterized for shake flask bioreactors. Out-of-phase conditions are associated with a strong decrease in mixing performance, oxygen transfer, and power input. Main factor for out-of-phase operation is the viscosity of the culture medium, but also the vessel diameter, low filling levels and/or a high number of baffles.\nLegal restriction.\nTo impede illicit drug manufacturers, the state of Texas previously restricted the sale of Erlenmeyer flasks to those who have the requisite permits. On September 1, 2019, SB 616 amended the law so that permits are no longer required, but accurate inventory of this and certain other pieces of lab equipment must still be maintained, loss or theft must still be reported, and the owner must still allow audits of their records and equipment to be made.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43957", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=43957", "title": "Benzene ring", "text": ""}
{"id": "43958", "revid": "38455", "url": "https://en.wikipedia.org/wiki?curid=43958", "title": "Laboratory glassware", "text": "Variety of equipment usually made of glass used for scientific experiments\nLaboratory glassware is a variety of equipment used in scientific work, traditionally made of glass. Glass may be blown, bent, cut, molded, or formed into many sizes and shapes. It is commonly used in chemistry, biology, and analytical laboratories. Many laboratories have training programs to demonstrate how glassware is used and to alert first\u2013time users to the safety hazards involved with using glassware.\nHistory.\nAncient era.\nThe history of glassware dates back to the Phoenicians who fused obsidian together in campfires, making the first glassware. Glassware evolved as other ancient civilizations including the Syrians, Egyptians, and Romans refined the art of glassmaking. Mary the Jewess, an alchemist in Alexandria during the 1st century AD, is credited for the creation of some of the first glassware for chemical such as the \"kerotakis\" which was used for the collection of fumes from a heated material. Despite these creations, glassware for chemical uses was still limited during this time because of the low thermal stability necessary for experimentation, so equipment was primarily made using copper or ceramic materials instead.\nEarly modern era.\nGlassware improved once again during the 14th-16th century, with the skill and knowledge of glass makers in Venice. During this time, the Venetians gathered knowledge about glassmaking from the East with information coming from Syria and the Byzantine Empire. Along with knowledge about glassmaking, glassmakers in Venice also received higher quality raw materials from the East such as imported plant ash which contained higher soda content compared to plant ash from other areas. This combination of better raw materials and information from the East led to the production of clearer and higher thermal and chemical durability leading towards the shift to the use of glassware in laboratories.\nModern era.\nMany glasses that were produced in bulk in the 1830s would quickly become unclear and dirty because of the low quality glass being used.\nDuring the 19th century, more chemists began to recognize the importance of glassware due to its transparency, and the ability to control the conditions of experiments. J\u00f6ns Jacob Berzelius, who invented the test tube, and Michael Faraday both contributed to the rise of chemical glassblowing. Faraday published \"Chemical Manipulation\" in 1827 which detailed the process for creating many types of small tube glassware and some experimental techniques for tube chemistry. Berzelius wrote a similar textbook titled \"Chemical Operations and Apparatus\" which provided a variety of chemical glassblowing techniques. The rise of this chemical glassblowing widened the availability of chemical experimentation and led to a shift towards the dominant use of glassware in laboratories. With the emergence of glassware in laboratories, the need for organization and standards arose. The \"Prussian Society for the Advancement of Industry\" was one of the earliest organizations to support the collaborative improvement of the quality of glass used.\nFollowing the development of borosilicate glass by Otto Schott in the late 19th century, most laboratory glassware was manufactured in Germany up until the start of World War I. Before World War I, glass producers in the United States had difficulty competing with German laboratory glassware manufacturers because laboratory glassware was classified as educational material and was not subject to an import tax. During World War I, the supply of laboratory glassware to the United States was cut off.\nIn 1915 Corning Glassworks developed their own borosilicate glass, introduced under the name Pyrex. This was a boon to the war effort in the United States. Though many laboratories turned back to imports after the war ended, research into better glassware flourished. Glassware became more resistant to thermal shock while maintaining chemical inertness.\nDuring the 1920s efforts to standardise the dimensions of laboratory glassware began, particularly for ground glass joints, with some manufacturer specific standardisation beginning to occur around this time. Commercial standards began development around 1930, allowing the compatibility of joints between different manufacturers for the first time, along with other features. This quickly led to the high degree of standardisation and modularity seen in modern glassware.\nLaboratory glassware selection.\nLaboratory glassware is typically selected by a person in charge of a particular laboratory analysis to match the needs of a given task. The task may require a piece of glassware made with a specific type of glass. The task may be readily performed using low cost, mass-produced glassware, or it may require a specialized piece created by a glass blower. The task may require controlling the flow of fluid. The task may have distinctive quality assurance requirements.\nType of glass.\nLaboratory glassware may be made from several types of glass, each with different capabilities and used for different purposes. Borosilicate glass is a type of transparent glass that is composed of boron oxide and silica, its main feature is a low coefficient of thermal expansion making it more resistant to thermal shock than most other glasses. Quartz glass can withstand very high temperatures and is transparent in certain parts of the electromagnetic spectrum. Darkened brown or amber (actinic) glass can block ultraviolet and infrared radiation. Heavy-wall glass can withstand pressurized applications. Fritted glass is finely porous glass through which gas or liquid may pass. Coated glassware is specially treated to reduce the occurrence of breakage or failure. Silanized (siliconized) glassware is specially treated to prevent organic samples from sticking to the glass.\nScientific glass blowing.\nScientific glass blowing, which is practiced in some larger laboratories, is a specialized field of glassblowing. Scientific glassblowing involves precisely controlling the shape and dimension of glass, repairing expensive or difficult-to-replace glassware, and fusing together various glass parts. Many parts are available fused to a length of glass tubing to create highly specialized piece of laboratory glassware.\nControlling fluid flow.\nWhen using glassware it is often necessary to control the flow of fluid. It is commonly stopped with a stopper. Fluid may be transported between connected pieces of glassware. Types of interconnecting components include glass tubing, T-connectors, Y-connectors, and glass adapters. For a leak-tight connection a ground glass joint is used (possibly reinforced using a clamping method such as a Keck clips). Another way to connect glassware is with a hose barb and flexible tubing. Fluid flow can be switched selectively using a valve, of which a stopcock is a common type fused to the glassware. Valves made entirely of glass may be used to restrict fluid flows. Fluid, or any material which flows, can be directed into a narrow opening using a funnel.\nQuality assurance.\nMetrology.\nLaboratory glassware can be used for high precision volumetric measurements. With high precision measurements, such as those made in a testing laboratory, the metrological grade of the glassware becomes important. The metrological grade then can be determined by both the confidence interval around the nominal value of measurement marks and the traceability of the calibration to an NIST standard. Periodically it may be necessary to check the calibration of the laboratory glassware.\nDissolved silica.\nLaboratory glassware is composed of silica, which is considered insoluble in most substances, with a few exceptions such as hydrofluoric acid or strong alkali hydroxides. Though insoluble, a minute quantity of silica will dissolve in neutral water, which may affect high precision, low threshold measurements of silica in water.\nCleaning.\nCleaning laboratory glassware is a frequent necessity and may be done using multiple methods depending on the nature of the contamination and the purity requirements of its use. Glassware can be soaked in a detergent solution to remove grease and loosen most contaminations, these contaminations are then scrubbed with a brush or scouring pad to remove particles which cannot be rinsed. Sturdy glassware may be able to withstand sonication as an alternative to scrubbing. Solvents are used to remove organic residues that soap cannot remove, and inorganic residues that do not dissolve in water can often be dissolved with a dilute acid. When cleaning is finished it is common practice to rinse glassware multiple times, often finally with deionised water, before suspending it upside down on drying racks. Specialised dishwashers can be used to automate these cleaning methods.\nResistant residues may require more powerful cleaning methods. Base baths are commonly used for organic residues, although the strong alkaline conditions do slowly dissolve the glass itself, and concentrated hydrochloric acid is common for removing inorganic residues. Even more severe methods exist, such as acidic peroxide (piranha solution), aqua regia, and chromic acid, but these are considered somewhat of a last resort due to the hazards of using them, and their use by students is restricted in many institutions.\nFor certain sensitive experiments glassware may require specialised procedures and ultra-pure water or solvents to dissolve trace quantities of specific contaminations known to interfere with an experiment.\nExamples.\nThere are many different kinds of laboratory glassware items:\nExamples of glassware containers include:\nExamples of glassware used for measurements include:\nOther examples of glassware includes:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43959", "revid": "949717", "url": "https://en.wikipedia.org/wiki?curid=43959", "title": "Beaker", "text": "Beaker may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "43960", "revid": "6056090", "url": "https://en.wikipedia.org/wiki?curid=43960", "title": "Varangian glaciation", "text": ""}
{"id": "43961", "revid": "40213808", "url": "https://en.wikipedia.org/wiki?curid=43961", "title": "Clozapine", "text": "Atypical antipsychotic medication\n&lt;templatestyles src=\"Infobox drug/styles.css\"/&gt;\nClozapine, sold under the brand name Clozaril among others, is a psychiatric medication and was the first atypical antipsychotic to be discovered. It is used primarily to treat people with schizophrenia and schizoaffective disorder who have had an inadequate response to two other antipsychotics, or who have been unable to tolerate other drugs due to extrapyramidal side effects. In the US, clozapine is also approved for use in people with recurrent suicidal behavior in people with schizophrenia or schizoaffective disorder. It is also used for the treatment of psychosis in Parkinson's disease.\nClozapine is recommended by multiple international treatment guidelines, after resistance to two other antipsychotic medications, and is the only treatment likely to result in improvement if two (or one) other antipsychotic has not had a satisfactory effect. Long term follow-up studies from Finland show significant improvements in terms of overall mortality including from suicide and all causes. Clozapine is on the World Health Organization's List of Essential Medicines. It is available as a generic medication. Common adverse effects include drowsiness, constipation, hypersalivation (increased saliva production), tachycardia, low blood pressure, blurred vision, significant weight gain, and dizziness. Clozapine is not normally associated with tardive dyskinesia and is recommended as the drug of choice when this is present, although some case reports describe clozapine-induced tardive dyskinesia. Serious adverse effects include agranulocytosis, seizures, myocarditis (inflammation of the heart), and hyperglycemia (high blood glucose levels). The use of clozapine may result rarely in clozapine-induced, gastric hypomotility syndrome, which may lead to bowel obstruction and death. The mechanism of action is not clear.\nMedical uses.\nSchizophrenia.\nThe role of clozapine in treatment-resistant schizophrenia was established by a 1988 landmark multicenter double blind study in which clozapine (up to 900\u00a0mg/d) showed marked benefits compared to chlorpromazine (up to 1800\u00a0mg/d) in a group of patients with protracted psychosis who had already shown an inadequate response to at least three previous antipsychotics including a prior single blind trial of haloperidol (mean 61+/\u2212 14\u00a0mg/d for six weeks). While there are significant side effects, clozapine remains the most effective treatment when one or more other antipsychotics have had an inadequate response. The use of clozapine is associated with multiple improved outcomes, including a reduced rate of all-cause mortality, suicide and hospitalization. In a 2013 network comparative meta-analysis of 15 antipsychotic drugs, clozapine was found to be significantly more effective than all other drugs. In a 2021 UK study, the majority of patients (over 85% of respondents) who took clozapine preferred it to their previous therapies, felt better on it and wanted to keep taking it. In a 2000 Canadian survey of 130 patients, the majority reported better satisfaction, quality of life, compliance with treatment, thinking, mood, and alertness. UK studies into the perspectives of people taking clozapine and their families following treatment with and discontinuation of clozapine describe significant stress and fearfulness of clozapine being stopped.\nClozapine is usually used for people diagnosed with schizophrenia who have had an inadequate response to other antipsychotics or who have been unable to tolerate other drugs due to extrapyramidal side effects. The US FDA authorisation also includes clozapine for the treatment of people exhibiting suicidal behaviour who have schizophrenia or schizoaffective disorder. It is also used for the treatment of psychosis in Parkinson's disease. It is regarded as the gold-standard treatment when other medication has been insufficiently effective and its use is recommended by multiple international treatment guidelines, supported by systematic reviews and meta-analysis. While the guidelines reserve clozapine for individuals in whom two other antipsychotics have already been tried, evidence indicates that clozapine might instead be used as a second-line medication. Clozapine treatment has been demonstrated to produce improved outcomes in multiple domains, including: a reduced risk of hospitalisation, a reduced risk of drug discontinuation, a reduction in overall symptoms, and improved efficacy in the treatment of positive psychotic symptoms of schizophrenia. Despite a range of side effects patients report good levels of satisfaction and long term adherence is favourable compared to other antipsychotics. Very long term follow-up studies reveal multiple benefits in terms of reduced mortality, with a particularly strong effect for reduced death by suicide, clozapine is the only antipsychotic known to have an effect reducing the risk of suicide or attempted suicide. Clozapine has a significant anti-aggressive effect. \nPersonality disorder.\nClozapine is widely used in secure and forensic mental health settings where improvements in aggression, shortened admission and reductions in restrictive practice such as seclusion have been found. In secure hospitals and other settings clozapine has also been used in the treatment of borderline and antisocial personality disorder when this has been associated with violence or self-harm.\nBipolar disorder.\nOn the basis of systematic reviews clozapine is recommended in some treatment guidelines as a third or fourth line treatment for bipolar disorder. A long term follow-up study showed efficacy in terms of both psychiatric and somatic hospitialisation, but with bipolar disorder this effect was not as strong as with some other treatments (olanzapine long-acting injection (LAI) (aHR = 0.54, 95% CI 0.37\u20130.80), haloperidol LAI (aHR = 0.62, 0.47\u20130.81), zuclopenthixol LAI (aHR = 0.66, 95% CI 0.52\u20130.85), lithium (aHR = 0.74, 95% CI 0.71\u20130.76) and clozapine (aHR = 0.75, 95% CI 0.64\u20130.87)). Bipolar disorder is an off-label indication for clozapine.\nAdministration.\nInitiation.\nWhilst clozapine is usually initiated in hospital setting community initiation is also available. Before clozapine can be initiated multiple assessments and baseline investigations are performed. In the UK and Ireland there must be an assessment that the patient satisfies the criteria for prescription; treatment resistant schizophrenia, intolerance due to extrapyramidal symptoms of other antipsychotics or psychosis in Parkinson's disease. Establishing a history of treatment resistance may include careful review of the medication history including the durations, doses and compliance of previous antipsychotic therapy and that these did not have an adequate clinical effect. A diagnostic review may also be performed. That could include review of antipsychotic plasma concentrations if available. The prescriber, patient, pharmacy and the laboratory performing blood counts are all registered with a specified clozapine provider who must be advised that there is no history of neutropenia from any cause. The clozapine providers collaborate by sharing information regarding patients who have had clozapine related neutropenia or agranulocytosis so that clozapine cannot be used again on license. Clozapine may only be dispensed after a satisfactory blood result has been received by the risk monitoring agency at which point an individual prescription may be released to an individual patient only.\nBaseline tests usually also include; a physical examination including baseline weight, waist circumference and BMI, assessments of renal function and liver function, an ECG and other baseline bloods may also be taken to facilitate monitoring of possible myocarditis, these might include C reactive protein (CRP) and troponin. In Australia and New Zealand pre-clozapine echocardiograms are also commonly performed. A number of service protocols are available and there are variations in the extent of pre-clozapine work ups. Some might also include fasting lipids, HbA1c and prolactin. At the Maudsley Hospital in the UK the Treat service also routinely performs a wide variety of other investigations including multiple investigations for other causes of psychosis and comorbidities including; MRI brain imaging, thyroid function tests, B12, folate and serum calcium levels, infection screening for blood borne viruses including Hepatitis B and C, HIV and syphilis as well as screening for autoimmune psychosis by anti-NMDA, anti-VGKC and Anti-nuclear antibody screening. Investigations used to monitor the possibility of clozapine related side effects such as myocarditis are also performed including baseline troponin, CRP and BNP, and for neuroleptic malignant syndrome, a CK level may also be drawn.\nOther clozapine initiation schedules exist. In 2023 the Treatment Response and Resistance in Psychosis Working Group published consensus guidelines on clozapine optimisation including initiation. The Team Daniel (https://) includes a much slower than usual titration (25\u00a0mg increments per week rather than per day) combined with the prescription of a variety of other medications to manage side effects such as nausea, hypersalivation, acid reflux, tachycardia, nocturnal enuresis, metformin and lamotrigine.\nThe dose of clozapine is initially low and gradually increased over a number of weeks. Initial doses may range from 6.5 to 12.5\u00a0mg/d, increasing stepwise typically, to doses in the range of 250\u2013350\u00a0mg per day, at which point an assessment of response will be performed. In the UK, the average clozapine dose is 450\u00a0mg/d. But response is highly variable and some patients respond at much lower doses, and vice versa. A genome wide association study from the MRC Centre for Neuropsychiatric Genetics and Genomics in Cardiff, UK has shown significant interethnic variation in clozapine metabolism due to variation in the frequency of CYP alleles involved in clozapine metabolism such as UGT1A and CYP1A1/1A2. This found faster average clozapine metabolism in people of sub-Saharan African ancestry than in those of European ancestry and that individuals with east Asian or southwest Asian ancestry were more likely to be slow clozapine metabolisers than those with European ancestry.\nEnforced.\nAlthough oral administration is the standard route for clozapine, it has occasionally been administered under compulsion using either nasogastric delivery or a short-acting injection. In nearly half of the approximately 100 reported cases, patients agreed to resume oral medication before the coercive intervention was carried out. \nClozapine has also been used off-label to treat catatonia, achieving a favorable response in more than 80% of reported cases.\nTreatment optimization.\nAs with other antipsychotics, and in contrast to received wisdom, responses to clozapine are typically seen soon after initiation and often within the first week. That said responses, especially those which are partial, can be delayed. Quite what an adequate trial of clozapine is, is uncertain, but a recommendation is that this should be for at least 8 weeks on a plasma trough level above 350-400 micro g/L. There is considerable inter-individual variation. A significant number of patients respond at lower and also much higher plasma concentrations and some patients, especially young male smokers may never achieve these plasma levels even at doses of 900\u00a0mg/day. Options then include either increasing the dose above the licensed maximum or the addition of a drug that inhibits clozapine metabolism. Avoiding unnecessary polypharmacy is a general principle in drug treatment. However, what constitutes \"unnecessary\" is important, because antipsychotics are associated with metabolic syndrome and a corresponding increased risk of type 2 diabetes and atherosclerotic cardiovascular disease, especially with long-term treatment. Polypharmacy with metformin, along with statins and ACE inhibitors, have the potential to significantly attenuate this risk. However, statins may increase blood glucose levels themselves, therefore necessitating polypharmacy with metformin whenever a statin is initiated. Together, this combination may have the potential to negate the negative metabolic and cardiovascular effects associated with antipsychotics, but further research is needed.\nBlood sampling.\nThe neutrophil cut off for clozapine have shown an exceptional ability to mitigate the risk of neutropenia and agranulocytosis. There is a significant margin of safety. Some patients may have marginal neutrophil counts before and after initiation and they are at risk of premature clozapine discontinuation. A knowledge of neutrophil biology allows blood sampling optimisation. Neutrophils show a diurnal variation in response to the natural cycle of G-CSF production, they are increased in the afternoons, they are also mobilised into the circulation after exercise and smoking. Simply shifting blood sampling has been shown to avoid unnecessary discontinuations, especially in black populations. However this is a disruption to usual hospital practice. Other practical steps are to ensure that blood results become available in hours and when senior staff are available.\nBenign ethnic neutropenia.\nBenign ethnic neutropenia (BEN) is not a pathological neutropenia but a normal variation in neutrophil counts associated with a specific genetic variant. Its name has been criticised as an example of medical racism for pathologising normal traits common in people of African ancestry.\nBenign reductions in neutrophil counts occur in individuals of many ethnic backgrounds. BEN refers to neutropenia without immune dysfunction or increased susceptibility to infection and is not caused by impaired neutrophil production. It results from a genetic adaptation most prevalent among people of West African ancestry but also present in populations in the Middle East, North Africa and South Asia. The adaptation involves non-expression of the Duffy antigen receptor for chemokines (DARC), encoded by the \"ACKR1\" gene, due to a promoter variant (rs2814778) that silences gene transcription. The Duffy-null phenotype provides relative resistance to certain forms of malaria.\nA clinical challenge arises because standard neutrophil reference ranges were established largely in White European populations. For many Black patients, these thresholds historically excluded them from clozapine treatment even though their lower neutrophil counts were normal for their genotype. Since 2002, clozapine monitoring in the UK has used reference ranges 0.5 \u00d7 109/L lower for patients with haematologically confirmed BEN, with similar though more restrictive adjustments in the United States. Nonetheless, some patients with BEN remain ineligible for clozapine despite having no increased risk of drug-induced neutropenia.\nThe Duffy-null polymorphism strongly predicts BEN. In the UK, the Royal College of Psychiatrists recommends Duffy typing when considering clozapine in people of Black or Middle Eastern ancestry; testing is available from the International Blood Group Reference Laboratory in Bristol.\nIndividuals with this variant are not at increased risk of clozapine-related or other idiosyncratic drug-induced neutropenias but remain at risk of restricted access to effective therapy because of misinterpretation of their baseline counts.\nAdverse effects.\nClozapine may cause serious and potentially fatal adverse effects. Clozapine carries boxed warnings, including severe neutropenia (low levels of neutrophils); orthostatic hypotension (low blood pressure upon changing positions), including slow heart rate and fainting; seizures; myocarditis (inflammation of the heart); and risk of death when used in elderly people with dementia-related psychosis. Lowering of the seizure threshold may be dose related. Increasing the dose slowly may decrease the risk for seizures and orthostatic hypotension.\nHowever overall mortality for people with schizophrenia prescribed clozapine is lower than those prescribed other drugs and much lower than those who are unmedicated.\nCommon effects include constipation, bed-wetting, night-time drooling, muscle stiffness, sedation, tremors, orthostatic hypotension, high blood sugar, increased rate of infections, and weight gain. The risk of developing extrapyramidal symptoms, such as tardive dyskinesia, is below that of typical antipsychotics; this may be due to clozapine's anticholinergic effects. Extrapyramidal symptoms may subside somewhat after a person switches from another antipsychotic to clozapine. Sexual problems, such as retrograde ejaculation and priapism, have been reported while taking clozapine. Rare adverse effects include periorbital edema and hematological malignancy. Despite the risk for numerous side effects, many side effects can be managed while continuing to take clozapine.\nMortality.\nThe overall all cause mortality for people with serious psychotic illnesses such as schizophrenia who are prescribed clozapine is lower than those who take other treatments and much lower than those who take no drug treatments at all. Reductions are particularly marked for death by suicide but also from all natural causes. This is demonstrated by studies which have used whole-population databases, such as those completed in Sweden, Finland, Denmark and Taiwan and following systematic review and meta-analysis.\nNeutropenia and agranulocytosis.\nClozapine was first linked to serious blood dyscrasias in the 1970s, when eight deaths from agranulocytosis were reported in Finland. At the time, it was unclear whether this exceeded background rates seen with other antipsychotics, but the reports led to restrictions on clozapine use. Recognition of this risk prompted the introduction of mandatory blood monitoring in many countries from 1990 onwards. This risk management has substantially reduced the risk of death from clozapine-related agranulocytosis to about 1 in 7,700 patients treated.\nMeta-analyses have found no evidence that clozapine is intrinsically more likely to cause neutropenia or agranulocytosis than other antipsychotics, nor that the incidence changed after mandatory monitoring began. Clozapine treatment overall is associated with reduced all-cause mortality, especially from suicide, a major contributor to premature death in schizophrenia.\nClozapine-induced neutropenia (CIN) occurs in about 3.8% of patients, and clozapine-induced agranulocytosis (CIA) in about 0.4%. Both can be serious; CIA may lead to life-threatening infection. Almost all such reactions occur in the first year of therapy, most within the first 18 weeks. After the first year, the risk falls to about 0.01% (\u22481 in 10,000), similar to that with other antipsychotics, and the mortality risk is lower still.\nTo mitigate early-treatment risk, clozapine is prescribed with mandatory absolute neutrophil count (ANC) monitoring\u2014e.g., under the U.S. REMS program. Thresholds and schedules vary internationally. Historically, U.S. thresholds for neutrophil counts have been lower than those in the UK and Australasia. Monitoring enables early detection: if ANC falls below threshold, clozapine is stopped immediately, usually leading to resolution.\nClozapine carries a U.S. black box warning for agranulocytosis, but evidence suggests that CIN and CIA are not uniquely clozapine-specific, contrary to long-held assumptions. Rapid point-of-care tests may in future simplify monitoring.\nPharmacogenetics.\nCIA is a type-B idiosyncratic adverse drug reaction, unrelated to therapeutic dose or mechanism, and one of several non-chemotherapy drug-induced agranulocytoses (IDINs). It likely involves a combination of toxic, immunological, and genetic factors, including reactive drug metabolites and HLA-activated T helper cells that stimulate B-cell production of drug-dependent antineutrophil antibodies.\nSevere life-threatening CIA often shows a distinctive pattern: rapid ANC decline to near-zero over 2\u201315 days, followed by a prolonged nadir of similar duration.\nGenetic studies implicate specific HLA types and certain drug-transporter genes as risk factors, but these are not yet sufficiently predictive for clinical use and vary across ethnic groups.\nCIN and CIA were once thought to be points on a continuum, with CIN a precursor to CIA, but evidence suggests they are distinct phenomena: most CIN cases are incidental findings of intensive monitoring rather than early CIA. Mortality from IDINs overall has fallen to about 5% owing to early recognition and the availability of hematopoietic growth factors such as G-CSF.\nCost-effectiveness monitoring.\nInternational practice varies widely in both monitoring frequency and ANC thresholds. For example, Iceland prescribes clozapine without routine full blood count monitoring and shows no increase in risk, whereas Japan has the most intensive requirements. U.S. and UK thresholds were aligned until 2015, when the U.S. Food and Drug Administration lowered ANC cut-offs by 0.5 \u00d7 109/L and dropped requirements for white cell, eosinophil, and platelet counts. Similar relaxed or extended-interval policies in parts of Europe (e.g. the Netherlands) have not increased adverse outcomes.\nRoutine long-term monthly monitoring after the first year is of questionable value, as it is unlikely to detect the rapid ANC decline characteristic of true CIA, and economic analyses suggest poor cost-effectiveness. By contrast, other widely used drugs with similar agranulocytosis risks, such as carbimazole, are prescribed without mandatory full blood count monitoring.\nIn 2021 the U.S. FDA removed the mandatory REMS registry, considering it an unnecessary barrier to clozapine use.\nRestarting (rechallenge).\nClozapine can often be safely restarted after a prior neutrophil-related discontinuation if the low ANC was due to previously unrecognised Benign ethnic neutropenia (BEN) or would have been acceptable under revised U.S. thresholds.\nIn settings with higher cut-offs than those in the U.S., a practical approach is to reintroduce clozapine using the U.S. thresholds and monitoring. In a London hospital cohort, of 115 patients whose clozapine had been stopped under local criteria, only 7 would have met the stricter U.S. discontinuation threshold; of 62 rechallenged, 59 continued clozapine successfully, with only one ANC drop below the U.S. cut-off.\nAdjunctive measures such as lithium or granulocyte colony-stimulating factor (G-CSF) may be used to support neutrophil counts during rechallenge..\nCardiac toxicity.\nClozapine can rarely cause myocarditis and cardiomyopathy. A large meta-analysis of clozapine exposure to over 250,000 people revealed that these occurred in approximately 7 in 1000 patients treated and resulted in death in 3 and 4 in 10,000 patients exposed respectively and although myocarditis occurred almost exclusively within the first 8 weeks of treatment, cardiomyopathy can occur much later on. First manifestations of illness are fever which may be accompanied by symptoms associated with upper respiratory tract, gastrointestinal or urinary tract infection. Typically C-reactive protein (CRP) increases with the onset of fever, and rises in the cardiac enzyme, troponin, occur up to 5 days later. Monitoring guidelines advise checking CRP and troponin at baseline and weekly for the first 4 weeks after clozapine initiation and observing the patient for signs and symptoms of illness. Signs of heart failure are less common and may develop with the rise in troponin. A recent case-control study found that the risk of clozapine-induced myocarditis is increased with increasing rate of clozapine dose titration, increasing age and concomitant sodium valproate. A large electronic health register study has revealed that nearly 90% of cases of suspected clozapine related myocarditis are false positives. Rechallenge after clozapine induced myocarditis has been performed and a protocol for this specialist approach has been published. A systematic review of rechallenge after myocarditis has shown success in over 60% of reported cases.\nGastrointestinal hypomotility.\nAnother underrecognized and potentially life-threatening effect spectrum is gastrointestinal hypomotility, which may manifest as severe constipation, fecal impaction, paralytic ileus, bowel obstruction, acute megacolon, ischemia or necrosis. Colonic hypomotility has been shown to occur in up to 80% of people prescribed clozapine when gastrointestinal function is measured objectively using radiopaque markers. Clozapine-induced gastrointestinal hypomotility currently has a higher mortality rate than the better known side effect of agranulocytosis. A Cochrane review found little evidence to help guide decisions about the best treatment for gastrointestinal hypomotility caused by clozapine and other antipsychotic medication. Monitoring bowel function and the preemptive use of laxatives for all clozapine-treated people has been shown to improve colonic transit times and reduce serious sequelae.\nHypersalivation.\nHypersalivation, or the excessive production of saliva, is one of the most common adverse effects of clozapine (30\u201380%). The saliva production is especially bothersome at night and first thing in the morning, as the immobility of sleep precludes the normal clearance of saliva by swallowing that occurs throughout the day. While clozapine is a muscarinic antagonist at the M1, M2, M3, and M5 receptors, clozapine is a full agonist at the M4 subset. Because M4 is highly expressed in the salivary gland, its M4 agonist activity is thought to be responsible for hypersalivation. clozapine-induced hypersalivation is likely a dose-related phenomenon, and tends to be worse when first starting the medication. Besides decreasing the dose or slowing the initial dose titration, other interventions that have shown some benefit include systemically absorbed anticholinergic medications such as hyoscine, diphenhydramine and topical anticholinergic medications like ipratropium bromide. Mild hypersalivation may be managed by sleeping with a towel over the pillow at night.\nCentral nervous system.\nCNS side effects include drowsiness, vertigo, headache, tremor, syncope, sleep disturbances, nightmares, restlessness, akinesia, agitation, seizures, rigidity, akathisia, confusion, fatigue, insomnia, hyperkinesia, weakness, lethargy, ataxia, slurred speech, depression, myoclonic jerks, and anxiety. Rarely seen are delusions, hallucinations, delirium, amnesia, libido increase or decrease, paranoia and irritability, abnormal EEG, worsening of psychosis, paresthesia, status epilepticus, and obsessive compulsive symptoms. Similar to other antipsychotics, clozapine rarely has been known to cause neuroleptic malignant syndrome.\nUrinary incontinence.\nClozapine is linked to urinary incontinence, though its appearance may be under-recognized. This side-effect may be amendable to bethanechol.\nWithdrawal.\nAbrupt withdrawal may lead to cholinergic rebound effects, such as indigestion, diarrhea, nausea/vomiting, overabundance of saliva, profuse sweating, insomnia, and agitation. Abrupt withdrawal can also cause severe movement disorders, catatonia, and psychosis. Doctors have recommended that patients, families, and caregivers be made aware of the symptoms and risks of abrupt withdrawal of clozapine. When discontinuing clozapine, gradual dose reduction is recommended to reduce the intensity of withdrawal effects.\nWeight gain and diabetes.\nIn addition to hyperglycemia, significant weight gain is frequently experienced by patients treated with clozapine. Impaired glucose metabolism and obesity have been shown to be constituents of the metabolic syndrome and may increase the risk of cardiovascular disease. The data suggest that clozapine may be more likely to cause adverse metabolic effects than some of the other atypical antipsychotics. For people who gain weight because of clozapine, taking metformin may reportedly improve three of the five components of the metabolic syndrome: waist circumference, fasting glucose, and fasting triglycerides.\nPneumonia.\nInternational adverse drug effect databases indicate that clozapine use is associated with a significantly increased incidence of and death from pneumonia and this may be one of the most significant adverse events. The mechanisms for this are unknown although it has been speculated that it may be related to hypersalivation or the immune effects of clozapine's effects on the resolution of inflammation.\nOverdose.\nSymptoms of overdose can be variable, but often include; sedation, confusion, tachycardia, seizures and ataxia. Fatalities have been reported due to clozapine overdose, though overdoses of greater than 5000\u00a0mg have been survived.\nDrug interactions.\nFluvoxamine inhibits the metabolism of clozapine leading to significantly increased blood levels of clozapine.\nWhen carbamazepine is concurrently used with clozapine, it has been shown to decrease plasma levels of clozapine significantly thereby decreasing the beneficial effects of clozapine. Patients should be monitored for \"decreased therapeutic effects of clozapine if carbamazepine\" is started or increased. If carbamazepine is discontinued or the dose of carbamazepine is decreased, therapeutic effects of clozapine should be monitored. The study recommends carbamazepine to not be used concurrently with clozapine due to increased risk of agranulocytosis.\nCiprofloxacin is an inhibitor of CYP1A2 and clozapine is a major CYP1A2 substrate. Randomized study reported elevation in clozapine concentration in subjects concurrently taking ciprofloxacin. Thus, the prescribing information for clozapine recommends \"reducing the dose of clozapine by one-third of original dose\" when ciprofloxacin and other CYP1A2 inhibitors are added to therapy, but once ciprofloxacin is removed from therapy, it is recommended to return clozapine to original dose.\nSmoking induces CYP1A2 enzyme activity, which accelerates the metabolism of clozapine and reduces its plasma concentrations. Smoking on average reduced the concentration by 30%, but some people may see as much as a 50% reduction.\nThe FDA warns that caution should be used when combining clozapine with drugs that depress the central nervous system (alcohol, benzodiazepines, and opioids) As using these drugs together can lead to a potentially life threatening complication known as Respiratory depression. \nPharmacology.\nPharmacodynamics.\nClozapine is classified as an atypical antipsychotic drug because it binds to serotonin as well as dopamine receptors. It acts as an antagonist at both receptors.\nClozapine is an inverse agonist at the 5-HT2A subtype of the serotonin receptor, putatively improving depression, anxiety, and the negative cognitive symptoms associated with schizophrenia.\nA direct interaction of clozapine with the GABAB receptor has also been shown. GABAB receptor-deficient mice exhibit increased extracellular dopamine levels and altered locomotor behaviour equivalent to that in schizophrenia animal models. GABAB receptor agonists and positive allosteric modulators reduce the locomotor changes in these models.\nClozapine induces the release of glutamate and D-serine, an agonist at the glycine site of the NMDA receptor, from astrocytes, and reduces the expression of astrocytic glutamate transporters. These are direct effects that are also present in astrocyte cell cultures not containing neurons. Clozapine prevents impaired NMDA receptor expression caused by NMDA receptor antagonists.\nPharmacokinetics.\nThe absorption of clozapine is almost complete following oral administration, but the oral bioavailability is only 60 to 70% due to first-pass metabolism. The time to peak concentration after oral dosing is about 2.5 hours, and food does not appear to affect the bioavailability of clozapine. However, it was shown that co-administration of food decreases the rate of absorption. The elimination half-life of clozapine is about 14 hours at steady state conditions (varying with daily dose).\nClozapine is extensively metabolized in the liver, via the cytochrome P450 system, to polar metabolites suitable for elimination in the urine and feces. The major metabolite, \"norclozapine\" (desmethyl-clozapine), is pharmacologically active. The cytochrome P450 isoenzyme 1A2 is primarily responsible for clozapine metabolism, but 2C, 2D6, 2E1 and 3A3/4 appear to play roles as well. Agents that induce (e.g., cigarette smoke) or inhibit (e.g., theophylline, ciprofloxacin, fluvoxamine) CYP1A2 may increase or decrease, respectively, the metabolism of clozapine. For example, the induction of metabolism caused by smoking means that smokers require up to double the dose of clozapine compared with non-smokers to achieve an equivalent plasma concentration.\nClozapine and norclozapine (desmethyl-clozapine) plasma levels may also be monitored, though they show a significant degree of variation and are higher in women and increase with age. Monitoring of plasma levels of clozapine and norclozapine has been shown to be useful in assessment of compliance, metabolic status, prevention of toxicity, and in dose optimisation.\nChemistry.\nClozapine is a dibenzodiazepine that is structurally very similar to loxapine (originally deemed a typical antipsychotic). It is slightly soluble in water, soluble in acetone, and highly soluble in chloroform. Its solubility in water is 0.1889\u00a0mg/L (25\u00a0\u00b0C). Its manufacturer, Novartis, claims a solubility of &lt;0.01% in water (&lt;100\u00a0mg/L).\nHistory.\nClozapine was synthesized in 1958 by Wander AG, a Swiss pharmaceutical company, based on the chemical structure of the tricyclic antidepressant imipramine. The first test in humans in 1962 was considered a failure. Trials in Germany in 1965 and 1966 as well as a trial in Vienna in 1966 were successful. In 1967, Wander AG was acquired by Sandoz. Further trials took place in 1972 when clozapine was released in Switzerland and Austria as Leponex. Two years later, it was released in West Germany and in Finland in 1975. Early testing was performed in the United States around the same time. In 1975, 16 cases of agranulocytosis leading to 8 deaths in clozapine-treated patients, reported from 6 hospitals mostly in southwestern Finland, led to concern. Analysis of the Finnish cases revealed that all the agranulocytosis cases had occurred within the first 18 weeks of treatment and the authors proposed blood monitoring during this period. The rate of agranulocytosis in Finland appeared to be 20 times higher than in the rest of the world and there was speculation that this may have been due a unique genetic variant in the region. Whilst the drug continued to be manufactured by Sandoz, and remained available in Europe, development in the U.S. halted.\nInterest in clozapine continued in an investigational capacity in the United States because, even in the 1980s, the duration of hospitalization, especially in state hospitals for those with treatment resistant schizophrenia, might often be measured in years rather than days. The role of clozapine in treatment-resistant schizophrenia was established by the landmark Clozaril Collaborative Study Group Study #30 in which clozapine showed marked benefits compared to chlorpromazine in a group of patients with protracted psychosis and who had already shown an inadequate response to other antipsychotics. This involved both stringent blood monitoring and a double-blind design with the power to demonstrate superiority over standard antipsychotic treatment. The inclusion criteria were patients who had failed to respond to at least three previous antipsychotics and had then not responded to a single blind treatment with haloperidol (mean dose 61\u00a0mg +/\u2212 14\u00a0mg/d). Two hundred and sixty-eight were randomised were to double blind trials of clozapine (up to 900\u00a0mg/d) or chlorpromazine (up to 1800\u00a0mg/d). 30% of the clozapine patients responded compared to 4% of the controls, with significantly greater improvement on the Brief Psychiatric Rating Scale, Clinical Global Impression Scale, and Nurses' Observation Scale for Inpatient Evaluation; this improvement included \"negative\" as well as positive symptom areas. Following this study, the US Food and Drug Administration (FDA) approved its use in 1990. Cautious of this risk, however, the FDA required a black box warning for specific side effects including agranulocytosis, and took the unique step of requiring patients to be registered in a formal system of tracking so that blood count levels could be evaluated on a systematic basis.\nIn December 2002, clozapine was approved in the US for people with schizophrenia or schizoaffective disorder judged to be at chronic risk for suicidal behavior. In 2005, the FDA approved criteria to allow reduced blood monitoring frequency. In 2015, the individual manufacturer Patient Registries were consolidated by request of the FDA into a single shared patient registry called The Clozapine Risk Evaluation and Mitigation Strategy (REMS) Registry. As of 24 February 2025, the FDA no longer requires participation in the Clozapine REMS, but blood monitoring is still recommended. Despite the demonstrated safety of the 2005 FDA monitoring requirements, which have lower neutrophil levels and do not include total white cell counts, international monitoring has not been standardized.\nSociety and culture.\nUnderuse.\nClozapine is widely recognised as being underused with wide variation in prescribing, especially in patients with African heritage.\nPsychiatrists' prescribing practices have been found to be the most significant variable regarding variance in its use. Surveys of psychiatrists' attitudes to clozapine have found that many had little experience in its use, overestimated the incidence of side effects, and did not appreciate that many patients prefer to take clozapine over other antipsychotics. In contrast to many psychiatrists' expectations most patients believe that the blood testing and other difficulties are worth the multiple benefits that they perceive. Whilst psychiatrists fear the severe adverse effects such as agranulocytosis, patients are more concerned about hypersalivation. Clozapine is no longer actively marketed and this may also be one of the explanations for its underuse.\nDespite the strong evidence and universal endorsement by national and international treatment guidelines and the experiences of patients themselves, most people eligible for clozapine are not treated with it. A large study in England found that approximately 30% of those eligible for clozapine were being treated with it. Those patients that do start clozapine usually face prolonged delay, multiple episodes of psychosis and treatments such as high dose antipsychotics or polypharmacy. Instead of two previous antipsychotics many will have been exposed to ten or more drugs which were not effective. A study of 120 patients conducted in four hospitals in South-East London found a mean of 9.2 episodes of antipsychotic prescription before clozapine was initiated and the mean delay in using clozapine was 5 years. Treatments that have no evidence base or are regarded as actively harmful are used instead.\nAs well as variation within counties there is massive variation in the use of clozapine internationally. An international study of 17 counties found greatest use in Finland (189/100,000 persons) and New Zealand (116/100,000), and least in the Japanese cohort (0.6/100,000) and in the privately insured US cohort (14/100,000).\nRacial disparity.\nA general finding in healthcare provision is that minority groups receive inferior treatment; this is a particular finding in the US. In the US a general finding is that compared to their white peers African American people are less likely to be prescribed the second generation antipsychotics, which are more expensive than alternatives and this was even apparent and especially so for clozapine when comparison was made in the Veterans Affairs medical system and when differences regarding socioeconomic factors were taken into account. As well as being less likely to start clozapine black patients are more likely to stop clozapine, possibly on account of benign ethnic neutropenia.\nEconomics.\nDespite the expense of the risk monitoring and management systems required, clozapine use is highly cost effective, with a number of studies suggesting savings of tens of thousands of dollars per patient per year compared to other antipsychotics, as well as advantages regarding improvements in quality of life. Clozapine is available as a generic medication.\nResearch.\nSevere personality disorders.\nClozapine is also used in borderline personality disorder and a randomized controlled trial was conducted but was unable to recruit a sufficiently large sample. Clozapine is recognised as a treatment option for severe personality disorder by some NHS trust treatment guidelines. \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "43962", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=43962", "title": "Collating", "text": ""}
{"id": "43963", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=43963", "title": "Psychosurgery", "text": "Neurosurgical treatment of mental disorders\nPsychosurgery, also called neurosurgery for mental disorder (NMD), is the neurosurgical treatment of mental disorders. Psychosurgery has always been a controversial medical field. The modern history of psychosurgery begins in the 1880s under the Swiss psychiatrist Gottlieb Burckhardt. The first significant foray into psychosurgery in the 20th century was conducted by the Portuguese neurologist Egas Moniz who, during the mid-1930s, developed the operation known as leucotomy. The practice was enthusiastically taken up in the United States by the neuropsychiatrist Walter Freeman and the neurosurgeon James W. Watts who devised what became the standard prefrontal procedure and named their operative technique lobotomy, although the operation was called leucotomy in the United Kingdom. In spite of the award of the Nobel Prize to Moniz in 1949, the use of psychosurgery declined during the 1950s. By the 1970s the standard Freeman-Watts type of operation was very rare, but other forms of psychosurgery, although used on a much smaller scale, survived. Some countries have abandoned psychosurgery altogether; in others, for example the US and the UK, it is only used in a few centres on small numbers of people with depression or obsessive-compulsive disorder (OCD).\nIn some countries it is also used in the treatment of schizophrenia and other disorders.\nPsychosurgery is a collaboration between psychiatrists and neurosurgeons. During the operation, which is carried out under a general anaesthetic and using stereotactic methods, a small piece of brain is destroyed or removed. The most common types of psychosurgery in current or recent use are anterior capsulotomy, cingulotomy, subcaudate tractotomy and limbic leucotomy. Lesions are made by radiation, thermo-coagulation, freezing or cutting. About a third of patients show significant improvement in their symptoms after operation. Advances in surgical technique have greatly reduced the incidence of death and serious damage from psychosurgery; the remaining risks include seizures, incontinence, decreased drive and initiative, weight gain, and cognitive and affective problems.\nCurrently, interest in the neurosurgical treatment of mental illness is shifting from ablative psychosurgery (where the aim is to destroy brain tissue) to deep brain stimulation (DBS) where the aim is to stimulate areas of the brain with implanted electrodes.\nMedical uses.\nAll the forms of psychosurgery in use today (or used in recent years) target the limbic system, which involves structures such as the amygdala, hippocampus, certain thalamic and hypothalamic nuclei, prefrontal and orbitofrontal cortex, and cingulate gyrus\u2014all connected by fibre pathways and thought to play a part in the regulation of emotion. There is no international consensus on the best target site.\nAnterior cingulotomy was first used by Hugh Cairns in the UK, and developed in the US by H.T. Ballantine Jr. In recent decades it has been the most commonly used psychosurgical procedure in the US. The target site is the anterior cingulate cortex; the operation disconnects the thalamic and posterior frontal regions and damages the anterior cingulate region.\nAnterior capsulotomy was developed in Sweden, where it became the most frequently used procedure. It is also used in Scotland and Canada. The aim of the operation is to disconnect the orbitofrontal cortex and thalamic nuclei by inducing a lesion in the anterior limb of internal capsule.\nSubcaudate tractotomy was the most commonly used form of psychosurgery in the UK from the 1960s to the 1990s. It targets the lower medial quadrant of the frontal lobes, severing connections between the limbic system and supra-orbital part of the frontal lobe.\nLimbic leucotomy is a combination of subcaudate tractotomy and anterior cingulotomy. It was used at Atkinson Morley Hospital London in the 1990s and also at Massachusetts General Hospital.\nAmygdalotomy, which targets the amygdala, was developed as a treatment for aggression by Hideki Narabayashi in 1961 and is still used occasionally, for example at the Medical College of Georgia.\nThere is debate about whether deep brain stimulation (DBS) should be classed as a form of psychosurgery.\nEffectiveness.\nSuccess rates for anterior capsulotomy, anterior cingulotomy, subcaudate tractotomy, and limbic leucotomy in treating depression and OCD have been reported as between 25 and 70 percent. The quality of outcome data is poor and the Royal College of Psychiatrists in their 2000 report concluded that there were no simple answers to the question of modern psychosurgery's clinical effectiveness; studies suggested improvements in symptoms following surgery but it was impossible to establish the extent to which other factors contributed to this improvement. Research into the effects of psychosurgery has not been able to overcome a number of methodological problems, including the problems associated with non-standardised diagnoses and outcome measurements, the small numbers treated at any one centre, and positive publication bias. Controlled studies are very few in number and there have been no placebo-controlled studies. There are no systematic reviews or meta-analyses.\nModern techniques have greatly reduced the risks of psychosurgery, although risks of adverse effects still remain. Whilst the risk of death or vascular injury has become extremely small, there remains a risk of seizures, fatigue, and personality changes following operation.\nA 2012 follow-up study of eight depressed patients who underwent anterior capsulotomy in Vancouver, Canada, classified five of them as responders at two to three years after surgery. Results on neuropsychological testing were unchanged or improved, although there were isolated deficits and one patient was left with long-term frontal psychobehavioral changes and fatigue. One patient, aged 75, was left mute and akinetic for a month following surgery and then developed dementia.\nBy country.\nChina.\nIn China, psychosurgical operations which make a lesion in the nucleus accumbens are used in the treatment of drug and alcohol dependence. Stereotactic surgery is used to locate and damage the target.\nPsychosurgery is also used in the treatment of schizophrenia, depression, and other mental disorders. One patient diagnosed with schizophrenia underwent as many as 10 surgeries, without effect on the condition but leaving him with a partially limp right arm and slurred speech. The use of psychosurgery in China has been criticised in the West.\nAccording to the Wall Street Journal, psychosurgery for drug addiction is banned in China since 2004, but other forms of the surgery were not as of 2007. \"Science\" reports that psychosurgery was only allowed for refractory OCD, depression, and brain disorders since 2008, and that neurosurgeons were pushing to reverse the ban in 2011.\nThe ban appears to have been lifted for schizophrenia some time before 2017, when \"People's Daily Online\" reposted an article about psychosurgery for schizophrenia in Shanghai from \"Xinmin Evening News\". In 2024, Chinese scholars published the \"Chinese Expert Consensus on Surgical Treatment of Mental Illnesses (2024)\", with intervention method and targets and evidence/recommendation levels listed for several conditions.\nIndia.\nIndia had an extensive psychosurgery programme until the 1980s, using it to treat addiction, and aggressive behaviour in adults and children, as well as depression and OCD.\nCingulotomy and capsulotomy for depression and OCD continue to be used, for example at the BSES MG Hospital in Mumbai.\nJapan.\nIn Japan the first lobotomy was performed in 1939 and the operation was used extensively in mental hospitals. However, psychosurgery fell into disrepute in the 1970s, partly due to its use on children with behavioural problems.\nAustralia and New Zealand.\nIn the 1980s there were 10\u201320 operations a year in Australia and New Zealand. The number had decreased to one or two a year by the 1990s. In Victoria, there were no operations between 2001 and 2006, but between 2007 and 2012 the Victoria Psychosurgery Review Board dealt with 12 applications, all of them for DBS.\nEurope.\nIn the 20-year period 1971\u20131991 the Committee on Psychosurgery in the Netherlands and Belgium oversaw 79 operations. Since 2000 there has been only one centre in Belgium performing psychosurgery, carrying out about 8 or 9 operations a year (some capsulotomies and some DBS), mostly for OCD.\nIn France about five people a year were undergoing psychosurgery in the early 1980s.\nIn 2005 the Health Authority recommended the use of ablative psychosurgery and DBS for OCD.\nIn the early 2000s in Spain about 24 psychosurgical operations (capsulotomy, cingulotomy, subcaudate tractotomy, and hypothalamotomy) a year were being performed. OCD was the most common diagnosis, but psychosurgery was also being used in the treatment of anxiety and schizophrenia, and other disorders.\nIn the UK between the late 1990s and 2009 there were just two centres using psychosurgery: a few stereotactic anterior capsulotomies are performed every year at the University Hospital of Wales, Cardiff, while anterior cingulotomies are carried out by the Advanced Interventions Service at Ninewells Hospital, Dundee. The patients have diagnoses of depression, obsessive-compulsive disorder, and anxiety. Ablative psychosurgery was not performed in England between the late 1990s and 2009, although a couple of hospitals have been experimenting with DBS. In 2010, Frenchay Hospital in Bristol performed an anterior cingulotomy on a woman who had previously undergone DBS.\nIn Russia in 1998 the Institute of the Human Brain (Russian Academy of Sciences) started a programme of stereotactic cingulotomy for the treatment of drug addiction. About 85 people, all under the age of 35, were operated on annually. In the Soviet Union, leucotomies were used for the treatment of schizophrenia in the 1940s, but the practice was prohibited by the Ministry of Health in 1950.\nNorth America.\nIn the United States, the Massachusetts General Hospital has a psychosurgery program. Operations are also performed at a few other centres.\nIn Mexico, psychosurgery is used in the treatment of anorexia and aggression.\nIn Canada, anterior capsulotomies are used in the treatment of depression and OCD.\nSouth America.\nVenezuela has three centres performing psychosurgery. Capsulotomies, cingulotomies and amygdalotomies are used to treat OCD and aggression.\nHistory.\nEarly psychosurgery.\nEvidence of trepanning (or trephining)\u2014the practice of drilling holes in the skull\u2014has been found in a skull from a Neolithic burial site in France, dated to about 5100 BC although it was also used to treat brain cranial trauma. There have also been archaeological finds in South America, while in Europe trepanation was carried out in classical and medieval times.\nThe first systematic attempt at psychosurgery is commonly attributed to the Swiss psychiatrist Gottlieb Burckhardt. In December 1888 Burckhardt operated on the brains of six patients (one of whom died a few days after the operation) at the Pr\u00e9fargier Asylum, cutting out a piece of cerebral cortex. He presented the results at the Berlin Medical Congress and published a report, but the response was hostile and he did no further operations.\nEarly in the 20th century, Russian neurologist Vladimir Bekhterev and Estonian neurosurgeon Ludvig Puusepp operated on three patients with mental illness, with discouraging results.\n1930s\u20131950s.\nAlthough there had been earlier attempts to treat psychiatric disorders with brain surgery, it was Portuguese neurologist Egas Moniz who was responsible for introducing the operation into mainstream psychiatric practice. He also coined the term psychosurgery. Moniz developed a theory that people with mental illnesses, particularly \"obsessive and melancholic cases\", had a disorder of the synapses which allowed unhealthy thoughts to circulate continuously in their brains. Moniz hoped that by surgically interrupting pathways in their brain he could encourage new healthier synaptic connections. In November 1935, under Moniz's direction, surgeon Pedro Almeida Lima drilled a series of holes on either side of a woman's skull and injected ethanol to destroy small areas of subcortical white matter in the frontal lobes. After a few operations using ethanol, Moniz and Almeida Lima changed their technique and cut out small cores of brain tissue. They designed an instrument which they called a leucotome and called the operation a leucotomy (cutting of the white matter). After twenty operations, they published an account of their work. The reception was generally not friendly but a few psychiatrists, notably in Italy and the US, were inspired to experiment for themselves.\nIn the US, psychosurgery was taken up and zealously promoted by neurologist Walter Freeman and neurosurgeon James Watts. They started a psychosurgery program at George Washington University in 1936, first using Moniz's method but then devised a method of their own in which the connections between the prefrontal lobes and deeper structures in the brain were severed by making a sweeping cut through a burr hole on either side of the skull. They called their new operation a lobotomy.\nFreeman went on to develop a new form of lobotomy which could be dispensed without the need for a neurosurgeon. He hammered an ice pick-like instrument, an orbitoclast, through the eye socket and swept through the frontal lobes. The transorbital or \"ice pick\" lobotomy was done under local anesthesia or using electroconvulsive therapy to render the patient unconscious and could be performed in mental hospitals lacking surgical facilities. Such was Freeman's zeal that he began to travel around the nation in his own personal van, which he called his \"lobotomobile\", demonstrating the procedure in psychiatric hospitals. Freeman's patients included 19 children, one of whom was 4 years old.\nThe 1940s saw a rapid expansion of psychosurgery, in spite of the fact that it involved a significant risk of death and severe personality changes. By the end of the decade, up to 5000 psychosurgical operations were being carried out annually in the US. In 1949, Moniz was awarded the Nobel Prize for Physiology or Medicine.\nBeginning in the 1940s various new techniques were designed in the hope of reducing the adverse effects of the operation. These techniques included William Beecher Scoville's orbital undercutting, Jean Talairach's anterior capsulotomy, and Hugh Cairn's bilateral cingulotomy. Stereotactic techniques made it possible to place lesions more accurately, and experiments were done with alternatives to cutting instruments such as radiation. Psychosurgery nevertheless went into rapid decline in the 1950s, due to the introduction of new drugs and a growing awareness of the long-term damage caused by the operations, as well as doubts about its efficacy. By the 1970s, the standard or transorbital lobotomy had been replaced with other forms of psychosurgical operations.\n1960s to the present.\nDuring the 1960s and 1970s, psychosurgery became the subject of increasing public concern and debate, culminating in the US with congressional hearings. Particularly controversial in the United States was the work of Harvard neurosurgeon Vernon Mark and psychiatrist Frank Ervin, who carried out amygdalotomies in the hope of reducing violence and \"pathologic aggression\" in patients with temporal lobe seizures and wrote a book entitled \"Violence and the Brain\" in 1970. The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research in 1977 endorsed the continued limited use of psychosurgical procedures. Since then, a few facilities in some countries, such as the US, have continued to use psychosurgery on small numbers of patients. In the US and other Western countries, the number of operations has further declined over the past 30 years, a period during which there had been no major advances in ablative psychosurgery.\nEthics.\nPsychosurgery has a controversial history, and despite modifications, still raises serious questions about benefit, risks, and the adequacy with which consent is obtained. Its continued use is defended by references to the \"therapeutic imperative\" to do something in the case of psychiatric patients who have not responded to other forms of treatment, and the evidence that some patients see improvement in their symptoms following surgery. There remain however problems concerning the rationale, indications and efficacy of psychosurgery, and the results of the operation raise questions of \"identity, spirit, relationships, integrity and human flourishing\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43964", "revid": "62", "url": "https://en.wikipedia.org/wiki?curid=43964", "title": "Consoles", "text": ""}
{"id": "43967", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=43967", "title": "Meteors", "text": ""}
{"id": "43968", "revid": "12331483", "url": "https://en.wikipedia.org/wiki?curid=43968", "title": "Dalton", "text": "Dalton may refer to: \n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "43970", "revid": "13263935", "url": "https://en.wikipedia.org/wiki?curid=43970", "title": "Calorimeter", "text": "Instrument for measuring heat\nA calorimeter is a device used for calorimetry, or the process of measuring the heat of chemical reactions or physical changes as well as heat capacity. Differential scanning calorimeters, isothermal micro calorimeters, titration calorimeters and accelerated rate calorimeters are among the most common types. A simple calorimeter just consists of a thermometer attached to a metal container full of water suspended above a combustion chamber. It is one of the measurement devices used in the study of thermodynamics, chemistry, and biochemistry.\nTo find the enthalpy change per mole of a substance A in a reaction between two substances A and B, the substances are separately added to a calorimeter and the initial and final temperatures (before the reaction has started and after it has finished) are noted. Multiplying the temperature change by the mass and specific heat capacities of the substances gives a value for the energy given off or absorbed during the reaction. Dividing the energy change by how many moles of A were present gives its enthalpy change of reaction.\nformula_1 \nwhere q is the amount of heat according to the change in temperature measured in joules and \"C\"v is the heat capacity of the calorimeter which is a value associated with each individual apparatus in units of energy per temperature (joules/kelvin).\nHistory.\nIn 1761 Joseph Black introduced the idea of latent heat which led to the creation of the first ice calorimeters. In 1780, Antoine Lavoisier used the heat released by the respiration of a guinea pig to melt snow surrounding his apparatus, showing that respiratory gas exchange is a form of combustion, similar to the burning of a candle. Lavoisier named this apparatus \"calorimeter\", based on both Greek and Latin roots. One of the first ice calorimeters was used in the winter of 1782\u201383 by Lavoisier and Pierre-Simon Laplace. It relied on the heat required for the melting of ice to measure the heat released in various chemical reactions.\nAdiabatic calorimeters.\nAn adiabatic calorimeter is a calorimeter used to examine a runaway reaction. Since the calorimeter runs in an adiabatic environment, any heat generated by the material sample under test causes the sample to increase in temperature, thus fueling the reaction.\nNo adiabatic calorimeter is fully adiabatic\u00a0\u2013 some heat will be lost by the sample to the sample holder. A mathematical correction factor, known as the phi-factor, can be used to adjust the calorimetric result to account for these heat losses. The phi-factor is the ratio of the thermal mass of the sample and sample holder to the thermal mass of the sample alone.\nReaction calorimeters.\nA reaction calorimeter is a calorimeter in which a chemical reaction is initiated within a closed insulated container. Reaction heats are measured and the total heat is obtained by integrating heat flow versus time. This is the standard used in industry to measure heats since industrial processes are engineered to run at constant temperatures. Reaction calorimetry can also be used to determine maximum heat release rate for chemical process engineering and for tracking the global kinetics of reactions. There are four main methods for measuring the heat in reaction calorimeter:\nHeat flow calorimeter.\nThe cooling/heating jacket controls either the temperature of the process or the temperature of the jacket. Heat is measured by monitoring the temperature difference between heat transfer fluid and the process fluid. In addition, fill volumes (i.e. wetted area), specific heat, heat transfer coefficient have to be determined to arrive at a correct value. It is possible with this type of calorimeter to do reactions at reflux, although it is very less accurate.\nHeat balance calorimeter.\nThe cooling/heating jacket controls the temperature of the process. Heat is measured by monitoring the heat gained or lost by the heat transfer fluid.\nPower compensation.\nPower compensation uses a heater placed within the vessel to maintain a constant temperature. The energy supplied to this heater can be varied as reactions require and the calorimetry signal is purely derived from this electrical power.\nConstant flux.\nConstant flux calorimetry (or COFLUX as it is often termed) is derived from heat balance calorimetry and uses specialized control mechanisms to maintain a constant heat flow (or flux) across the vessel wall.\nBomb calorimeters.\nA bomb calorimeter is a type of constant-volume calorimeter used in measuring the heat of combustion of a particular reaction. Bomb calorimeters have to withstand the large pressure within the calorimeter as the reaction is being measured. Electrical energy is used to ignite the fuel; as the fuel is burning, it will heat up the surrounding air, which expands and escapes through a tube that leads the air out of the calorimeter. When the air is escaping through the copper tube it will also heat up the water outside the tube. The change in temperature of the water allows for calculating calorie content of the fuel.\nIn more recent calorimeter designs, the whole bomb, pressurized with excess pure oxygen (typically at ) and containing a weighed mass of a sample (typically 1\u20131.5 g) and a small fixed amount of water (to saturate the internal atmosphere, thus ensuring that all water produced is liquid, and removing the need to include enthalpy of vaporization in calculations), is submerged under a known volume of water (c.\u00a02000 ml) before the charge is electrically ignited. The bomb, with the known mass of the sample and oxygen, form a closed system\u200a\u2014\u200ano gases escape during the reaction. The weighed reactant put inside the steel container is then ignited. Energy is released by the combustion and heat flow from this crosses the stainless steel wall, thus raising the temperature of the steel bomb, its contents, and the surrounding water jacket. The temperature change in the water is then accurately measured with a thermometer. This reading, along with a bomb factor (which is dependent on the heat capacity of the metal bomb parts), is used to calculate the energy given out by the sample burn. A small correction is made to account for the electrical energy input, the burning fuse, and acid production (by titration of the residual liquid). After the temperature rise has been measured, the excess pressure in the bomb is released.\nAt its core, a bomb calorimeter consists of a small cup to contain the sample, oxygen, a stainless steel bomb, water, a stirrer, a thermometer, the dewar or insulating container (to prevent heat flow from the calorimeter to its surroundings) and an ignition circuit connected to the bomb. By using stainless steel for the bomb, the reaction will occur with no volume change observed.\nSince there is no heat exchange between the calorimeter and surroundings (Q = 0) (adiabatic), no work is performed (W = 0)\nThus, the total internal energy change\n formula_2\nAlso, total internal energy change\n formula_3\n formula_4\n (constant volume formula_5)\nwhere formula_6 is heat capacity of the bomb\nBefore the bomb can be used to determine heat of combustion of any compound, it must be calibrated. The value of formula_6 can be estimated by\n formula_8\n formula_9 and formula_10 can be measured;\n formula_11\n formula_12\nIn the laboratory, formula_6 is determined by running a compound with known heat of combustion value: formula_14\nCommon compounds are benzoic acid (formula_15) or p-methyl benzoic acid (formula_16).\nTemperature (T) is recorded every minute and formula_17\nA small factor contributes to the correction of the total heat of combustion is the fuse wire. Nickel fuse wire is often used and has heat of combustion: 981.2cal/g.\nIn order to calibrate the bomb, a small amount (~ 1g) of benzoic acid, or p-methyl benzoic acid is weighed. \nA length of nickel fuse wire (~10\u00a0cm) is weighed both before and after the combustion process. Mass of fuse wire burned formula_18\nThe combustion of sample (benzoic acid) inside the bomb\n formula_19\n formula_20\nOnce formula_6 value of the bomb is determined, the bomb is ready to use to calculate heat of combustion of any compounds by \nformula_22\nCombustion of non-flammables.\nThe higher pressure and concentration of O2 in the bomb system can render combustible some compounds that are not normally flammable. Some substances do not combust completely, making the calculations harder as the remaining mass has to be taken into consideration, making the possible error considerably larger and compromising the data.\nWhen working with compounds that are not as flammable (that might not combust completely) one solution would be to mix the compound with some flammable compounds with a known heat of combustion and make a pallet with the mixture. Once the &amp;NoBreak;}&amp;NoBreak; of the bomb is known, the heat of combustion of the flammable compound (C\"FC\"), of the wire (C\"W\") and the masses (m\"FC\" and m\"W\"), and the temperature change (\u0394\"T\"), the heat of combustion of the less flammable compound (C\"LFC\") can be calculated with:\n\"C\"LFC = \"C\"v \u0394\"T\" \u2212 \"C\"FC \"m\"FC \u2212 \"C\"W \"m\"W\nCalvet-type calorimeters.\nThe detection is based on a three-dimensional fluxmeter sensor. The fluxmeter element consists of a ring of several thermocouples in series. The corresponding thermopile of high thermal conductivity surrounds the experimental space within the calorimetric block. The radial arrangement of the thermopiles guarantees an almost complete integration of the heat. This is verified by the calculation of the efficiency ratio that indicates that an average value of 94% \u00b1 1% of heat is transmitted through the sensor on the full range of temperature of the Calvet-type calorimeter. In this setup, the sensitivity of the calorimeter is not affected by the crucible, the type of purgegas, or the flow rate. The main advantage of the setup is the increase of the experimental vessel's size and consequently the size of the sample, without affecting the accuracy of the calorimetric measurement.\nThe calibration of the calorimetric detectors is a key parameter and has to be performed very carefully. For Calvet-type calorimeters, a specific calibration, so called Joule effect or electrical calibration, has been developed to overcome all the problems encountered by a calibration done with standard materials. The main advantages of this type of calibration are as follows:\nAn example of Calvet-type calorimeter is the C80 Calorimeter (reaction, isothermal and scanning calorimeter).\nAdiabatic and Isoperibol calorimeters.\nSometimes referred to as constant-pressure calorimeters, adiabatic calorimeters measure the change in enthalpy of a reaction occurring in solution during which the no heat exchange with the surroundings is allowed (adiabatic) and the atmospheric pressure remains constant.\nAn example is a coffee-cup calorimeter, which is constructed from two nested Styrofoam cups, providing insulation from the surroundings, and a lid with two holes, allowing insertion of a thermometer and a stirring rod. The inner cup holds a known amount of a solvent, usually water, that absorbs the heat from the reaction. When the reaction occurs, the outer cup provides insulation. Then\n formula_23\nwhere\nformula_24, Specific heat at constant pressure\nformula_25, Enthalpy of solution\nformula_26, Change in temperature\nformula_27, mass of solvent\nformula_28, molecular mass of solvent\nThe measurement of heat using a simple calorimeter, like the coffee cup calorimeter, is an example of constant-pressure calorimetry, since the pressure (atmospheric pressure) remains constant during the process. Constant-pressure calorimetry is used in determining the changes in enthalpy occurring in solution. Under these conditions the change in enthalpy equals the heat.\nCommercial calorimeters operate in a similar way. The semi-adiabatic (isoperibol) calorimeters measure temperature changes up to 10\u22126\u00b0C and account for heat loss through the walls of the reaction vessel to the environment, hence, semi-adiabatic. The reaction vessel is a dewar flask which is immersed in a constant temperature bath. This provides a constant heat leak rate that can be corrected through the software. The heat capacity of the reactants (and the vessel) are measured by introducing a known amount of heat using a heater element (voltage and current) and measuring the temperature change.\nAdiabatic calorimeters most commonly used in materials science research to study reactions that occur at a constant pressure and volume. They are particularly useful for determining the heat capacity of substances, measuring the enthalpy changes of chemical reactions, and studying the thermodynamic properties of materials.\nDifferential scanning calorimeter.\nIn a differential scanning calorimeter (DSC), heat flow into a sample\u2014usually contained in a small aluminium capsule or 'pan'\u2014is measured differentially, i.e., by comparing it to the flow into an empty reference pan.\nIn a heat flux DSC, both pans sit on a small slab of material with a known (calibrated) heat resistance K. The temperature of the calorimeter is raised linearly with time (scanned), i.e., the heating rate \n \"dT\"/\"dt\" = \"\u03b2\"\nis kept constant. This time linearity requires good design and good (computerized) temperature control. Of course, controlled cooling and isothermal experiments are also possible.\nHeat flows into the two pans by conduction. The flow of heat into the sample is larger because of its heat capacity \"C\"p. The difference in flow \"dq\"/\"dt\" induces a small temperature difference \u0394\"T\" across the slab. This temperature difference is measured using a thermocouple. The heat capacity can in principle be determined from this signal:\n formula_29\nNote that this formula (equivalent to Newton's law of heat flow) is analogous to, and much older than, Ohm's law of electric flow:\n \u0394\"V\" = \"R\" = \"RI\".\nWhen suddenly heat is absorbed by the sample (e.g., when the sample melts), the signal will respond and exhibit a peak.\n formula_30\nFrom the integral of this peak the enthalpy of melting can be determined, and from its onset the melting temperature.\nDifferential scanning calorimetry is a workhorse technique in many fields, particularly in polymer characterization.\nA modulated temperature differential scanning calorimeter (MTDSC) is a type of DSC in which a small oscillation is imposed upon the otherwise linear heating rate.\nThis has a number of advantages. It facilitates the direct measurement of the heat capacity in one measurement, even in (quasi-)isothermal conditions. It permits the simultaneous measurement of heat effects that respond to a changing heating rate (reversing) and that don't respond to the changing heating rate (non-reversing). It allows for the optimization of both sensitivity and resolution in a single test by allowing for a slow average heating rate (optimizing resolution) and a fast changing heating rate (optimizing sensitivity).\nA DSC may also be used as an initial safety screening tool. In this mode the sample will be housed in a non-reactive crucible (often gold, or gold-plated steel), and which will be able to withstand pressure (typically up to 100 bar). The presence of an exothermic event can then be used to assess the stability of a substance to heat. However, due to a combination of relatively poor sensitivity, slower than normal scan rates (typically 2\u20133\u00a0\u00b0C per min) due to much heavier crucible, and unknown activation energy, it is necessary to deduct about 75\u2013100\u00a0\u00b0C from the initial start of the observed exotherm to suggest a maximum temperature for the material. A much more accurate data set can be obtained from an adiabatic calorimeter, but such a test may take 2\u20133 days from ambient at a rate of 3\u00a0\u00b0C increment per half hour.\nIsothermal titration calorimeter.\nIn an isothermal titration calorimeter, the heat of reaction is used to follow a titration experiment. This permits determination of the midpoint (stoichiometry) (N) of a reaction as well as its enthalpy (delta H), entropy (delta S) and of primary concern the binding affinity (Ka)\nThe technique is gaining in importance particularly in the field of biochemistry, because it facilitates determination of substrate binding to enzymes. The technique is commonly used in the pharmaceutical industry to characterize potential drug candidates.\nContinuous Reaction Calorimeter.\nThe Continuous Reaction Calorimeter is especially suitable to obtain thermodynamic information for a scale-up of continuous processes in tubular reactors. This is useful because the released heat can strongly depend on the reaction control, especially for non-selective reactions. With the Continuous Reaction Calorimeter an axial temperature profile along the tube reactor can be recorded and the specific heat of reaction can be determined by means of heat balances and segmental dynamic parameters. The system must consist of a tubular reactor, dosing systems, preheaters, temperature sensors and flow meters.\nIn traditional heat flow calorimeters, one reactant is added continuously in small amounts, similar to a semi-batch process, in order to obtain a complete conversion of the reaction. In contrast to the tubular reactor, this leads to longer residence times, different substance concentrations and flatter temperature profiles. Thus, the selectivity of not well-defined reactions can be affected. This can lead to the formation of by-products or consecutive products which alter the measured heat of reaction, since other bonds are formed. The amount of by-product or secondary product can be found by calculating the yield of the desired product.\nIf the heat of reaction measured in the HFC (Heat flow calorimetry) and PFR calorimeter differ, most probably some side reactions have occurred. They could for example be caused by different temperatures and residence times. The totally measured Qr is composed of partially overlapped reaction enthalpies (\u0394Hr) of main and side reactions, depending on their degrees of conversion (U).\nCalorimetry in Geothermal Reactors.\nCalorimeters can be used to measure the efficiency of geothermal energy conversion processes. Through measuring the heat input and output of the process, engineers can determine how effective the plant is at converting geothermal energy into usable electricity or other forms of energy.\nCalorimeters can also monitor the quality of the steam extracted from the geothermal resource. By analyzing the heat content of the steam, engineers can ensure that the resource meets the required specifications for efficient energy production.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43971", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=43971", "title": "Disulfide bond", "text": ""}
{"id": "43972", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=43972", "title": "Partial pressure", "text": "Pressure of a component gas in a mixture\nIn a mixture of gases, each constituent gas has a partial pressure which is the notional pressure of that constituent gas as if it alone occupied the entire volume of the original mixture at the same temperature. The total pressure of an ideal gas mixture is the sum of the partial pressures of the gases in the mixture (Dalton's Law).\nIn respiratory physiology, the partial pressure of a dissolved gas in liquid (such as oxygen in arterial blood) is also defined as the partial pressure of that gas as it would be undissolved in gas phase yet in equilibrium with the liquid. This concept is also known as blood gas tension. In this sense, the diffusion of a gas liquid is said to be driven by differences in partial pressure (not concentration). In chemistry and thermodynamics, this concept is generalized to non-ideal gases and instead called fugacity. The partial pressure of a gas is a measure of its thermodynamic activity. Gases dissolve, diffuse, and react according to their partial pressures and not according to their concentrations in a gas mixture or as a solute in solution. This general property of gases is also true in chemical reactions of gases in biology.\nSymbol.\nThe symbol for pressure is usually \"p\" or \"pp\" which may use a subscript to identify the pressure, and gas species are also referred to by subscript. When combined, these subscripts are applied recursively.\nExamples:\nDalton's law of partial pressures.\nDalton's law expresses the fact that the total pressure of a mixture of ideal gases is equal to the sum of the partial pressures of the individual gases in the mixture. This equality arises from the fact that in an ideal gas, the molecules are so far apart that they do not interact with each other. Most actual real-world gases come very close to this ideal. For example, given an ideal gas mixture of nitrogen (N2), hydrogen (H2) and ammonia (NH3):\nformula_9\nwhere:\nIdeal gas mixtures.\nIdeally the ratio of partial pressures equals the ratio of the number of molecules. That is, the mole fraction formula_14 of an individual gas component in an ideal gas mixture can be expressed in terms of the component's partial pressure or the moles of the component:\nformula_15\nand the partial pressure of an individual gas component in an ideal gas can be obtained using this expression:\nformula_16\nThe mole fraction of a gas component in a gas mixture is equal to the volumetric fraction of that component in a gas mixture.\nThe ratio of partial pressures relies on the following isotherm relation:\nformula_17\nPartial volume (Amagat's law of additive volume).\nThe partial volume of a particular gas in a mixture is the volume of one component of the gas mixture. It is useful in gas mixtures, e.g. air, to focus on one particular gas component, e.g. oxygen.\nIt can be approximated both from partial pressure and molar fraction:\nformula_18\nVapor pressure.\nVapor pressure is the pressure of a vapor in equilibrium with its non-vapor phases (i.e., liquid or solid). Most often the term is used to describe a liquid's tendency to evaporate. It is a measure of the tendency of molecules and atoms to escape from a liquid or a solid. A liquid's atmospheric pressure boiling point corresponds to the temperature at which its vapor pressure is equal to the surrounding atmospheric pressure and it is often called the normal boiling point.\nThe higher the vapor pressure of a liquid at a given temperature, the lower the normal boiling point of the liquid.\nThe vapor pressure chart displayed has graphs of the vapor pressures versus temperatures for a variety of liquids. As can be seen in the chart, the liquids with the highest vapor pressures have the lowest normal boiling points.\nFor example, at any given temperature, methyl chloride has the highest vapor pressure of any of the liquids in the chart. It also has the lowest normal boiling point (\u221224.2\u00a0\u00b0C), which is where the vapor pressure curve of methyl chloride (the blue line) intersects the horizontal pressure line of one atmosphere (atm) of absolute vapor pressure. At higher altitudes, the atmospheric pressure is less than that at sea level, so boiling points of liquids are reduced. At the top of Mount Everest, the atmospheric pressure is approximately 0.333\u00a0atm, so by using the graph, the boiling point of diethyl ether would be approximately 7.5\u00a0\u00b0C versus 34.6\u00a0\u00b0C at sea level (1\u00a0atm).\nEquilibrium constants of reactions involving gas mixtures.\nIt is possible to work out the equilibrium constant for a chemical reaction involving a mixture of gases given the partial pressure of each gas and the overall reaction formula. For a reversible reaction involving gas reactants and gas products, such as:\n&lt;chem display=\"block\"&gt;{\\mathit{a}A} + {\\mathit{b}B} &lt;=&gt; {\\mathit{c}C} + {\\mathit{d}D}&lt;/chem&gt;\nthe equilibrium constant of the reaction would be:\nformula_19\nFor reversible reactions, changes in the total pressure, temperature or reactant concentrations will shift the equilibrium so as to favor either the right or left side of the reaction in accordance with Le Chatelier's Principle. However, the reaction kinetics may either oppose or enhance the equilibrium shift. In some cases, the reaction kinetics may be the overriding factor to consider.\nHenry's law and the solubility of gases.\nGases will dissolve in liquids to an extent that is determined by the equilibrium between the undissolved gas and the gas that has dissolved in the liquid (called the \"solvent\"). The equilibrium constant for that equilibrium is:\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nwhere:\nThe form of the equilibrium constant shows that the concentration of a solute gas in a solution is directly proportional to the partial pressure of that gas above the solution. This statement is known as Henry's law and the equilibrium constant formula_20 is quite often referred to as the Henry's law constant.\nHenry's law is sometimes written as:\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nwhere formula_26 is also referred to as the Henry's law constant. As can be seen by comparing equations (1) and (2) above, formula_26 is the reciprocal of formula_20. Since both may be referred to as the Henry's law constant, readers of the technical literature must be quite careful to note which version of the Henry's law equation is being used.\nHenry's law is an approximation that only applies for dilute, ideal solutions and for solutions where the liquid solvent does not react chemically with the gas being dissolved.\nIn diving breathing gases.\nIn underwater diving the physiological effects of individual component gases of breathing gases are a function of partial pressure.\nUsing diving terms, partial pressure is calculated as:\npartial pressure = (total absolute pressure) \u00d7 (volume fraction of gas component)\nFor the component gas \"i\":\npi = P \u00d7 Fi\nFor example, at underwater, the total absolute pressure is (i.e., 1 bar of atmospheric pressure + 5 bar of water pressure) and the partial pressures of the main components of air, oxygen 21% by volume and nitrogen approximately 79% by volume are:\npN2 = 6 bar \u00d7 0.79 = 4.7 bar absolute\npO2 = 6 bar \u00d7 0.21 = 1.3 bar absolute\nThe minimum safe lower limit for the partial pressures of oxygen in a breathing gas mixture for diving is absolute. Hypoxia and sudden unconsciousness can become a problem with an oxygen partial pressure of less than 0.16 bar absolute. Oxygen toxicity, involving convulsions, becomes a problem when oxygen partial pressure is too high. The NOAA Diving Manual recommends a maximum single exposure of 45 minutes at 1.6 bar absolute, of 120 minutes at 1.5 bar absolute, of 150 minutes at 1.4 bar absolute, of 180 minutes at 1.3 bar absolute and of 210 minutes at 1.2 bar absolute. Oxygen toxicity becomes a risk when these oxygen partial pressures and exposures are exceeded. The partial pressure of oxygen also determines the maximum operating depth of a gas mixture.\nNarcosis is a problem when breathing gases at high pressure. Typically, the maximum total partial pressure of narcotic gases used when planning for technical diving may be around 4.5\u00a0bar absolute, based on an equivalent narcotic depth of .\nThe effect of a toxic contaminant such as carbon monoxide in breathing gas is also related to the partial pressure when breathed. A mixture which may be relatively safe at the surface could be dangerously toxic at the maximum depth of a dive, or a tolerable level of carbon dioxide in the breathing loop of a diving rebreather may become intolerable within seconds during descent when the partial pressure rapidly increases, and could lead to panic or incapacitation of the diver.\nIn medicine.\nThe partial pressures of particularly oxygen (formula_29) and carbon dioxide (formula_30) are important parameters in tests of arterial blood gases, but can also be measured in, for example, cerebrospinal fluid. \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43974", "revid": "10289486", "url": "https://en.wikipedia.org/wiki?curid=43974", "title": "SS General von Steuben", "text": "German military transport ship; sank 1945, killing thousands\nSS \"General von Steuben was a German passenger liner and later an armed transport ship of the German Navy that was sunk in the Baltic Sea during World War II. She was launched in 1923 as M\u00fcnchen (after the German city, sometimes spelled Muenchen), renamed General von Steuben in 1930 (after the famous German officer of the American Revolutionary War), and renamed Steuben\" in 1938.\nDuring World War II, the ship served as a troop accommodation vessel, and from 1944 as an armed transport. On 10 February 1945, while evacuating German military personnel, wounded soldiers, and civilian refugees during Operation Hannibal, the ship was torpedoed by the Soviet submarine \"S-13\" and sank. An estimated 4,000 people lost their lives in the sinking.\nEarly history.\nIn 1923, \"M\u00fcnchen\" became the first German trans-Atlantic passenger liner to be launched, and also the first to enter New York Harbor, since the end of World War I. She arrived in July 1923 on her maiden transatlantic voyage.\n1930 fire and sinking.\nOn 11 February 1930, after \"M\u00fcnchen\" docked in New York City and discharged passengers and most of her crew from a voyage from Bremen, Germany, a fire broke out in a paint locker on board and quickly spread to another storage hold. The massive fire and explosion resulted in a five-alarm fire and all of the city's fire equipment was sent to the burning ship. The fire could not be controlled and the ship sank next to the wharf where it had docked.\nIn one of the largest shipping salvage efforts of its time, \"M\u00fcnchen\" was raised, towed to a dry dock, repaired, and returned to service. Shortly afterwards, the ship's owner renamed her \"General von Steuben.\"\nWorld War II.\nThe ship, now called \"Steuben\", was commissioned in 1939 as a \"Kriegsmarine\" accommodation ship. In 1944, she was pressed into service as an armed transport ship, taking German troops to eastern Baltic ports and returning wounded troops to Kiel.\nOperation Hannibal.\nAlong with the and numerous other vessels, \"Steuben\" was part of the largest evacuation by sea in modern times. The Operation Hannibal evacuations surpassed the British evacuation at Dunkirk in both size of the operation and number of people evacuated.\nBy early January 1945, Grossadmiral Karl D\u00f6nitz realized that Germany was soon to be defeated. Wishing to save his submariners, he radioed a coded message on 23 January 1945 to the Baltic Sea port of Gotenhafen (the Polish city and port of Gdynia under German occupation) to evacuate to the West, under the code name \"Operation Hannibal\".\nSubmariners at that point were schooled and housed in ships floating in the Baltic ports, most of them at Gotenhafen. Among the ships were , , \"Hansa\", and \"Wilhelm Gustloff\".\nNotwithstanding the losses suffered during the operation, over two million people were evacuated ahead of the Red Army's advance into East Prussia and Danzig (now Gda\u0144sk, Poland).\nIn the winter of 1945, East Prussian refugees headed west, away from the city of K\u00f6nigsberg and ahead of the Soviet advance into the Baltic States and East Prussia. Thousands fled to the Baltic seaport at Pillau (now Baltiysk, Russia), hoping to board ships that would carry them to the relative safety of Western Germany. \"Steuben\" was part of the fleet sent for the purpose.\nFinal voyage.\nOn 9 February 1945, the 14,660-ton \"Steuben\" sailed from Pillau, near K\u00f6nigsberg on the Baltic coast, for Swinem\u00fcnde (now \u015awinouj\u015bcie, Poland). Official reports listed 2,800 wounded German soldiers; 800 civilians; 100 returning soldiers; 270 navy medical personnel (including doctors, nurses and auxiliaries); 12 nurses from Pillau; 64 crew for the ship's anti-aircraft guns, 61 naval personnel, radio operators, signal men, machine operators and administrators, plus 160 merchant navy crewmen, for a total of 4,267 people on board. Due to the rapid evacuation ahead of the Red Army's advance, many Eastern German and Baltic refugees boarded the \"Steuben\" without being registered, increasing the number of those on board to approximately 5,200.\nJust before midnight on 9 February, the Soviet submarine \"S-13\", commanded by Alexander Marinesko, fired two torpedoes 14 seconds apart at the \"Steuben\"; both hit her starboard bow, just below the bridge, where many of the crew were sleeping. Most were killed by the impact of the torpedoes. According to survivors, the \"Steuben\" sank by the bow and listed severely to starboard before taking her final plunge, within about 20 minutes of the torpedo impacts. An estimated 4,500 people died in the sinking. German torpedo boat \"T-196\" hastily pulled up beside \"Steuben\" as she sank; its crew pulled about 300 survivors straight from \"Steuben\"'s slanting decks and brought them to Kolberg in Pomerania (today Ko\u0142obrzeg, Poland). A total of 650 people were rescued from the \"Steuben\".\nWreck.\nThe \"Steuben\" wreck was found and identified in May 2004 by Polish Navy hydrographical vessel ORP \"Arctowski\". Pictures and graphics appeared in a 2005 \"National Geographic\" article.\nThe wreck lies on its port side at about in depth, and the hull reaches up to in depth. The ship was mostly intact when it was found.\nIn July 2021, the German news magazine \"Der Spiegel\" reported that the wreck had been plundered and severely damaged in the process. The wreck is an official war grave, and entering it is illegal. Due to international treaties, the wreck remains property of the German state, but Poland is responsible for its protection. Over the past decade, looting has become one of the biggest reasons for the deteriorating condition of shipwrecks in the Baltic sea.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43975", "revid": "5839510", "url": "https://en.wikipedia.org/wiki?curid=43975", "title": "Yes (band)", "text": "English progressive rock band\nYes are an English progressive rock band formed in London in 1968. Comprising 20 full-time musicians over their career, their most notable members include lead singer Jon Anderson, bassist Chris Squire, guitarists Steve Howe and Trevor Rabin, drummers Bill Bruford and Alan White, and keyboardists Tony Kaye and Rick Wakeman. The band have explored several musical styles and are often regarded as progressive rock pioneers. Since February 2023, the band's line-up consists of Howe, keyboardist Geoff Downes, bassist Billy Sherwood, singer Jon Davison, and drummer Jay Schellen.\nFounded by Anderson, Squire, Bruford, Kaye, and guitarist Peter Banks, Yes began performing a mix of original songs and covers of rock, pop, blues, and jazz songs, as showcased on their first two albums, \"Yes\" (1969) and \"Time and a Word\" (1970). A change of direction in 1970 after the replacement of Banks with Howe led to a series of successful progressive rock albums, with four consecutive US platinum or multi-platinum sellers: \"The Yes Album\" (1971); \"Fragile\" (1971), which included the successful single \"Roundabout\"; \"Close to the Edge\" (1972); and the live album \"Yessongs\" (1973). Further albums \"Tales from Topographic Oceans\" (1973), \"Relayer\" (1974), \"Going for the One\" (1977), and \"Tormato\" (1978) were also commercially successful. Yes earned a reputation for their elaborate stage sets, light displays, and album covers designed by Roger Dean. During this time, Kaye and Bruford were replaced by Wakeman and White respectively, while keyboardist Patrick Moraz joined for \"Relayer\" and its subsequent tour. In 1980, growing musical differences led to Anderson and Wakeman's departures; Yes recruited Downes and singer Trevor Horn for the album \"Drama\" (1980) before disbanding in 1981.\nIn 1983, Squire, White, Anderson, and Kaye reformed Yes with Rabin joining. Rabin's songwriting moved the band toward a more pop-oriented sound, which resulted in their highest-selling album \"90125\" (1983) featuring the band's only US number-one single, \"Owner of a Lonely Heart\", and the successful follow-up album \"Big Generator\" (1987). In 1989, the offshoot group Anderson Bruford Wakeman Howe formed and released a self-titled album. At the suggestion of the record company, the groups merged into a short-lived eight-piece line-up for \"Union\" (1991) and its tour. Yes regularly released studio albums from 1994 to 2001 with varying levels of success, beginning a second hiatus in 2004. After a 2008 world tour was cancelled, Yes enlisted Beno\u00eet David as the new lead singer, then Davison in 2012. Squire died in 2015, leaving the band with no original members. White, the longest-tenured member at that point, died in 2022. Former members Anderson, Rabin, and Wakeman toured from 2016 to 2018. Yes's latest album, \"Mirror to the Sky\", was released in 2023.\nYes are one of the most successful, influential, and longest-lasting progressive rock bands. Their discography spans 23 studio albums, with 13.5 million Recording Industry Association of America (RIAA)-certified albums sold in the US and more than 30 million worldwide. In 1985, they won a Grammy Award for Best Rock Instrumental Performance with \"Cinema\". They were ranked No. 94 on VH1's \"100 Greatest Artists of Hard Rock\". In April 2017, Yes\u2014represented by Anderson, Bruford, Kaye, Howe, Wakeman, White, and Rabin, with Squire honored posthumously\u2014were inducted into the Rock and Roll Hall of Fame.\nHistory.\n1968\u20131970: Formation, first album and \"Time and a Word\".\nIn late 1967, bassist Chris Squire and guitarist Peter Banks, both formerly of the Syn, joined the psychedelic rock band Mabel Greer's Toyshop, which had been formed in 1966 by Clive Bayley and Robert Hagger. They played at the Marquee Club in Soho, London where Jack Barrie, owner of the nearby La Chasse club, saw them perform. He later recalled: \"the musicianship was very good but it was obvious they weren't going anywhere\". Barrie introduced Squire to singer Jon Anderson, a worker at the bar in La Chasse, who found they shared interests in Simon &amp; Garfunkel and harmony singing. That evening they wrote \"Sweetness\", which was included on the first Yes album, and Anderson joined as lead vocalist. During this time, the band rehearsed in the basement of The Lucky Horseshoe cafe on Shaftesbury Avenue between 10 June and 9 July 1968. In June 1968, Hagger was replaced by Bill Bruford, who had placed an advertisement in \"Melody Maker\", while in July the classically trained organist and pianist Tony Kaye, of Johnny Taylor's Star Combo and the Federals, became the keyboardist. Meanwhile, Banks had left Mabel Greer's Toyshop to join Neat Change, but he was dismissed by this group on 14 July 1968 and was recalled by Squire, replacing Bayley as guitarist.\nHaving considered the experience of Mabel Greer's Toyshop concluded, the group exchanged ideas for a new name. Sources disagree on the origin of the name, but generally attribute it to Banks. According to the \"Financial Times\", Anderson suggested \"Life\" and Squire thought of \"World\"; Banks said simply, \"Yes\", and that was how the band was named. Welch states that Squire suggested the name over a phone call to Banks, with Banks replying, \"But that was my idea!\" According to Banks, it was initially used as a temporary name, but \"nobody has thought of anything better yet.\"\nAfter rehearsals between 31 July and 2 August, the first gig as Yes followed at a youth camp in East Mersea, Essex on 3 August. Early sets were formed of cover songs from artists such as the Beatles, The 5th Dimension and Traffic. On 16 September, Yes performed at Blaise's club in London as a substitute for Sly and the Family Stone, who had failed to turn up. They were well received by the audience, including the host Roy Flynn, who became the band's manager that night. That month, Bruford decided to quit performing to study at the University of Leeds. His replacement, Tony O'Reilly of the Koobas, struggled to perform with the rest of the group on stage and former Warriors and future King Crimson drummer Ian Wallace subbed for one gig on 5 November 1968. After Bruford was refused a year's sabbatical leave from Leeds, Anderson and Squire convinced him to return for Yes's supporting slot for Cream's farewell concert at the Royal Albert Hall on 26 November.\nAfter seeing an early King Crimson gig in 1969, Yes realised that there was suddenly stiff competition on the London gigging circuit, and they needed to be much more technically proficient, starting regular rehearsals. They subsequently signed a deal with Atlantic Records, and, that August, released their debut album \"Yes\". Compiled of mostly original material, the record includes renditions of \"Every Little Thing\" by the Beatles and \"I See You\" by The Byrds. Although the album failed to break into the UK album charts, \"Rolling Stone\" critic Lester Bangs complimented the album's \"sense of style, taste and subtlety\". \"Melody Maker\" columnist Tony Wilson chose Yes and Led Zeppelin as the two bands \"most likely to succeed\".\nFollowing a tour of Scandinavia with Faces, Yes performed a solo concert at the Queen Elizabeth Hall on 21 March 1970. The second half consisted of excerpts from their second album \"Time and a Word\", accompanied by a 20-piece youth orchestra. Banks left the group on 18 April 1970, just three months before the album's release. Having expressed dissatisfaction with the idea of recording with an orchestra as well as the sacking of Flynn earlier in the year, Banks later indicated that he was fired by Anderson and Squire, and that Kaye and Bruford had no prior knowledge that it would be happening. Similar to the first album, \"Time and a Word\" features original songs and two new covers\u2013\"Everydays\" by Buffalo Springfield and \"No Opportunity Necessary, No Experience Needed\" by Richie Havens. The album broke into the UK charts, peaking at number 45. Banks' replacement was Tomorrow guitarist Steve Howe, who appears in the photograph of the group on the American issue despite not having played on it.\n1970\u20131974: \"The Yes Album\", \"Fragile\", \"Close to the Edge\" and \"Tales from Topographic Oceans\".\nThe band retreated to a rented farmhouse in Devon to write and rehearse new songs for their following album. Howe established himself as an integral part of the group's sound with his Gibson ES-175 and variety of acoustic guitars. With producer and engineer Eddy Offord, recording sessions lasted as long as 12 hours with each track being assembled from small sections at a time, which were pieced together to form a complete track. The band would then learn to play the song through after the final mix was complete. Released in February 1971, \"The Yes Album\" peaked at number 4 in the UK and number 40 on the US \"Billboard\" 200 charts.\nYes embarked on a 28-day tour of Europe with Iron Butterfly in January 1971. The band purchased Iron Butterfly's entire public address system, which improved their on-stage performance and sound. Their first date in North America followed on 24 June in Edmonton, Alberta, Canada, supporting Jethro Tull. Friction arose between Howe and Kaye on tour; this, along with Kaye's reported reluctance to play the Mellotron and the Minimoog synthesizer, preferring to stick exclusively to piano and Hammond organ, led to the keyboardist being fired from the band in the summer of 1971. Anderson recalled in a 2019 interview: \"Steve and Chris came over and said, 'Look, Tony Kaye... great guy.' But, you know, we'd just seen Rick Wakeman about a month earlier. And I said, 'There's that Rick Wakeman guy,' and we've got to get on with life and move on, you know, rather than keep going on, set in the same circle. And that's what happens with a band.\" Wakeman, a classically trained player who had left the folk rock group Strawbs earlier in the year, was already a noted studio musician, with credits including T. Rex, David Bowie, Cat Stevens and Elton John. Squire commented that he could play \"a grand piano for three bars, a Mellotron for two bars and a Moog for the next one absolutely spot on\", which gave Yes the orchestral and choral textures that befitted their new material.\nReleased on 12 November 1971, the band's fourth album \"Fragile\" showcased their growing interest in the structures of classical music, with an excerpt of \"The Firebird\" by Igor Stravinsky being played at the start of their concerts since the album's 1971\u20131972 tour. Each member performed a solo track on the album, and it marked the start of their long collaboration with artist Roger Dean, who designed the group's logo, album art and stage sets. \"Fragile\" peaked at number 7 in the UK and number 4 in the US after it was released there in January 1972, and was their first record to reach the top ten in North America. A shorter version of the opening track, \"Roundabout\", was released as a single that peaked at number 13 on the \"Billboard\" Hot 100 singles chart.\nIn February 1972, Yes recorded a cover version of \"America\" by Simon &amp; Garfunkel and released it in July. The single reached number 46 on the US singles chart. The track subsequently appeared on \"The New Age of Atlantic\", a 1972 compilation album of several bands signed to Atlantic Records, and again in the 1975 compilation \"Yesterdays\".\nReleased in September 1972, \"Close to the Edge\", the band's fifth album, was their most ambitious work so far. At 19 minutes, the title track took up an entire side on the vinyl record and combined elements of classical music, psychedelic rock, pop and jazz. The album reached number 3 in the US and number 4 on the UK charts. \"And You and I\" was released as a single that peaked at number 42 in the US The growing critical and commercial success of the band was not enough to retain Bruford, who left Yes in the summer of 1972, before the album's release, to join King Crimson. The band considered several possible replacements, including Aynsley Dunbar (who was playing with Frank Zappa at the time), and decided on former Plastic Ono Band drummer Alan White, a friend of Anderson and Offord who had once sat in with the band weeks before Bruford's departure. White learned the band's repertoire in three days before embarking on their 1972\u20131973 tour.\nBy this point, Yes were beginning to enjoy worldwide commercial and critical success. Their early touring with White was featured on \"Yessongs\", a triple live album released in May 1973 that documented shows from 1972. The album reached number 7 in the UK and number 12 in the US A concert film of the same name premiered in 1975 that documented their shows at London's Rainbow Theatre in December 1972.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nIt is a fragmented masterpiece, assembled with loving care and long hours in the studio. Brilliant in patches, but often taking far too long to make its various points, and curiously lacking in warmth or personal expression ...\"Ritual\" is a dance of celebration and brings the first enjoyable moments, where Alan's driving drums have something to grip on to and the lyrics of la la la speak volumes. But even this cannot last long and cohesion is lost once more to the gods of drab self indulgence.\n \u2014\"Melody Maker\" review of \"Tales from Topographic Oceans\", 1973\n\"Tales from Topographic Oceans\" was the band's sixth studio album, released on 7 December 1973. It marked a change in their fortunes and polarised fans and critics alike. The double vinyl set was based on Anderson's interpretation of the Shastric scriptures from a footnote within Paramahansa Yogananda's book \"Autobiography of a Yogi\". The album became the first LP in the UK to ship gold before the record arrived at retailers. It went on to top the UK charts for two weeks while reaching number 6 in the US, and became the band's fourth consecutive gold album. Wakeman was not pleased with the record and is critical of much of its material. He felt sections were \"bled to death\" and contained too much musical padding. Wakeman left the band after the 1973\u20131974 tour; his solo album \"Journey to the Centre of the Earth\" topped the UK charts in May 1974. The tour included five consecutive sold-out shows at the Rainbow Theatre, the first time a rock band achieved this.\n1974\u20131980: \"Relayer\", \"Going for the One\", \"Tormato\" and the Paris sessions.\nSeveral musicians were approached to replace Wakeman, including Vangelis Papathanassiou, Eddie Jobson of Roxy Music and former Atlantis/Cat Stevens keyboardist Jean Roussel. Howe says he also asked Keith Emerson, who did not want to leave Emerson, Lake &amp; Palmer. Yes ultimately chose Swiss keyboardist Patrick Moraz of Refugee, who arrived in August 1974 during the recording sessions for \"Relayer\", which took place at Squire's home in Virginia Water, Surrey. Released in November that year, \"Relayer\" showcased a jazz fusion-influenced direction the band were pursuing. The album features the 22-minute track titled \"The Gates of Delirium\", which highlights a battle initially inspired by \"War and Peace\" by Leo Tolstoy. Its closing section, \"Soon\", was subsequently released as a single. The album reached No. 4 in the UK and No. 5 in the US Yes embarked on their 1974\u20131975 tour to support \"Relayer\". The compilation album \"Yesterdays\", released in 1975, contained tracks from Yes's first two albums, the B-side track from their \"Sweet Dreams\" single from 1970 titled \"Dear Father\", and the original ten-minute version of their cover of \"America\".\nBetween 1975 and 1976, each member of the band released a solo album. Their subsequent 1976 tour of North America with Peter Frampton featured some of the band's most-attended shows. The show of 12 June, also supported by Gary Wright and Pousette-Dart Band at John F. Kennedy Stadium in Philadelphia, attracted over 100,000 people.\n Roger Dean's brother Martyn was the main designer behind the tour's \"Crab Nebula\" stage set, while Roger and fabric designer Felicity Youette provided the backgrounds.\nIn late 1976, the band travelled to Switzerland and started recording for their album \"Going for the One\" at Mountain Studios, Montreux. It was then that Anderson sent early versions of \"Going for the One\" and \"Wonderous Stories\" to Wakeman, who felt he could contribute to such material better than the band's past releases. Moraz was let go, after Wakeman was booked initially on a session musician basis, before being convinced by Squire to re-join the band full time. Upon its release in July 1977, \"Going for the One\" topped the UK album charts for two weeks and reached number 8 in the US \"Wonderous Stories\" and \"Going for the One\" were released as singles in the UK and reached numbers 7 and 25, respectively. Although the album's cover was designed by Hipgnosis, it still features their Roger Dean \"bubble\" logotype. The band's 1977 tour spanned across six months.\n\"Tormato\" was released in September 1978 at the height of punk rock in England, during which the music press criticised Yes as representing the bloated excesses of early-1970s progressive rock. The album saw the band continuing their movement towards shorter songs; no track runs longer than eight minutes. Wakeman replaced his Mellotrons with the Birotron, a tape replay keyboard, and Squire experimented with harmonisers and Mu-tron pedals with his bass. Production was handled collectively by the band and saw disagreements at the mixing stage among the members. With heavy commercial rock-radio airplay, the album reached number 8 in the UK and number 10 in the US charts, and was also certified platinum (1 million copies sold) by the RIAA. Despite internal and external criticisms of the album, the band's 1978\u20131979 tour was a commercial success. Concerts were performed in the round with a \u00a350,000 revolving stage and a 360-degree sound system fitted above it. Their dates at Madison Square Garden earned Yes a Golden Ticket Award for grossing over $1 million in box office receipts.\nIn October 1979, the band convened in Paris with producer Roy Thomas Baker. At the time, Anderson and Wakeman favoured a more fantastical and delicate approach while the rest preferred a heavier rock sound. Howe, Squire and White liked none of the music Anderson was offering at the time as they felt it was too lightweight and lacking in the heaviness that they were generating in their own writing sessions. The Paris sessions abruptly ended in December after White broke his foot while rollerskating in a roller disco.\nWhen the band, minus Wakeman (who had only committed to recording keyboard overdubs once new material would be ready to record), reconvened in February to resume work on the project, their growing musical differences, combined with internal dissension, obstructed progress. Journalist Chris Welch, after attending a rehearsal, noted that Anderson \"was singing without his usual conviction and seemed disinclined to talk\". By late March, Howe, Squire and White had begun demoing material as an instrumental trio, increasingly uncertain about Anderson's future involvement. Eventually, a serious band dispute over finance saw Anderson leave Yes, with a dispirited Wakeman departing at around the same time.\n1980\u20131981: \"Drama\" and split.\nIn 1980, pop duo The Buggles (singer Trevor Horn and keyboardist Geoff Downes) secured the services of Brian Lane, who had managed Yes since 1970, as their manager. The Buggles were best known for their 1979 hit single \"Video Killed the Radio Star\" from their album \"The Age of Plastic\". At this point, the departure of Anderson and Wakeman had been kept secret from everyone outside the Yes inner circle. Seeing an option of continuing the band with new creative input and expertise, Squire revealed the situation to Horn and Downes and suggested that they join Yes as full-time members. Horn and Downes accepted the invitation and the reconfigured band recorded the \"Drama\" album, which was released in August 1980. The record displayed a heavier, harder sound than the material Yes recorded with Anderson and Wakeman in 1979, opening with the lengthy hard rocker \"Machine Messiah\". The album received substantial radio airplay in the late summer\u2013fall of 1980, and peaked at number 2 in the UK and number 18 in the US, though it was the first Yes album to not be certified Gold by the RIAA since 1971. Their 1980 tour of North America and the UK received a mixed reaction from audiences. They were well received in the United States and were awarded with a commemorative certificate after they performed a record 16 consecutive sold-out concerts at Madison Square Garden since 1974.\nAfter the \"Drama\" tour, Yes reconvened in England to decide the band's next step, beginning by dismissing Lane as their manager. Horn was also dismissed, and went on to pursue a career in music production, with White and Squire next to depart. Left as the sole remaining members, Downes and Howe opted not to continue with the group and went their own separate ways in December 1980.\n\"Yesshows\", a live album recorded during 1976 to 1978, mixed in mid-1979 and originally intended for release in late 1979, was released in November 1980, peaking at number 22 in the UK charts and number 43 in the US.\nAn announcement came from the group's management in March 1981 confirming that Yes no longer existed. Downes and Howe soon reunited to form Asia with former King Crimson bassist and vocalist John Wetton, and drummer Carl Palmer from Emerson, Lake &amp; Palmer. Squire and White continued to work together, initially recording sessions with Jimmy Page for a proposed band called XYZ (short for \"ex-Yes-and-Zeppelin\") in the spring of 1981. Page's former bandmate Robert Plant was also to be involved as the vocalist but he lost enthusiasm, citing his ongoing grieving for recently deceased Led Zeppelin drummer John Bonham. The short-lived group produced a few demo tracks, elements of which would appear in Page's band the Firm and on future Yes tracks \"Mind Drive\" and \"Can You Imagine?\". In late 1981, Squire and White released \"Run with the Fox\", a Christmas single with Squire on vocals which received radio airplay through the 1980s and early 1990s during the Christmas periods. A second Yes compilation album, \"Classic Yes,\" was released in November 1981.\n1982\u20131988: First reformation, \"90125\" and \"Big Generator\".\nAt the beginning of 1982, Phil Carson of Atlantic Records introduced Squire and White to guitarist and singer Trevor Rabin, who had initially made his name with the South African supergroup Rabbitt, subsequently releasing three solo albums, working as a record producer and even briefly considered being a member of Asia. The three teamed up in a new band called Cinema, for which Squire also recruited the original Yes keyboard player Tony Kaye. Later in 1982, Cinema entered the studio to record their debut album. Although Rabin and Squire initially shared lead vocals for the project, Trevor Horn was briefly brought into Cinema as a potential singer, but soon opted to become the band's producer instead.\nHorn worked well with the band. However, his clashes with Tony Kaye (complicated by the fact that Rabin was playing most of the keyboards during the recording sessions) led to Kaye's departure during the recording, though some of his playing was kept on the final album and he had returned by the time it was released. Meanwhile, Squire encountered Jon Anderson (who, since leaving Yes, had released two solo albums and had success with the Jon and Vangelis project) at a Los Angeles party and, encouraged by Atlantic Records vice-president Phil Carson, played Anderson the Cinema demo tracks. Anderson was then invited into the project as lead singer and joined in April 1983 during the last few weeks of the sessions, having comparatively little creative input beyond adding his lead vocals and re-writing some lyrics.\nAt the suggestion of Carson and other Atlantic executives, Cinema then changed their name to Yes in June 1983. Rabin initially objected to this, as he now found that he had inadvertently joined a reunited band with a history and expectations, rather than help launch a new group. However, with four of the five members having been members of Yes (with three of them being original members, including the distinctive lead singer) it suggested that the name change was sound commercial strategy. The new album marked a significant change in style as the revived Yes had adopted more of a pop rock sound with few moments that recalled their progressive rock past. This incarnation of the band has sometimes been informally referred to as \"Yes-West\", reflecting the band's new base in Los Angeles rather than London.\nYes released their comeback album \"90125\" (named after its catalogue serial number on Atco Records) in November 1983. It became their biggest-selling album, certified by the RIAA at triple-platinum (3 million copies) in sales in the US, and introduced the band to younger fans. \"Owner of a Lonely Heart\" topped the Hot Mainstream Rock Tracks chart for four weeks and went on to reach the number-one spot on the \"Billboard\" Hot 100 singles chart, the only single from Yes to do so, for two weeks in January 1984. Kaye's short-term replacement on keyboards, Eddie Jobson, appeared briefly in the original video but was edited out as much as possible once Kaye had been persuaded to return to the band.\nIn 1984, two further singles from the album \"Leave It\" and \"It Can Happen\" reached number 24 and 57, respectively. Yes also earned their only Grammy Award for Best Rock Instrumental Performance in 1985 for the two-minute track \"Cinema\". They were also nominated for an award for Best Pop Performance by a Duo or Group with Vocals with \"Owner of a Lonely Heart\", and a Best Rock Performance by a Duo or Group with Vocal award with \"90125\". The band's 1984\u20131985 tour was the most lucrative in their history and spawned the home video release \"9012Live\", a concert film directed by Steven Soderbergh with added special effects from Charlex that cost $1 million. Issued in 1985, an accompanying live album also appeared that year, \"\", which earned Yes a nomination for a second Grammy Award for Best Rock Instrumental Performance for Squire's solo track, a rendition of \"Amazing Grace\".\nYes began recording for their twelfth album, \"Big Generator\", in 1985, initially with Trevor Horn returning as producer. The sessions underwent many starts and stops due to the use of multiple recording locations in Italy, London and Los Angeles, with interpersonal problems leading to Horn leaving the sessions partway through, all of which kept the album from timely completion (the album was intended for a 1986 release, but by the end of that year it was still incomplete). Eventually Rabin took over final production. The album was released in September 1987, and immediately began receiving heavy radio airplay, with sales reaching number 17 in the UK and number 15 in the US \"Big Generator\" earned Yes a nomination for a second Grammy Award for Best Rock Performance by a Duo or Group with Vocal in 1988, and was also certified platinum (with 1 million-plus in sales) by the RIAA. The single \"Love Will Find a Way\" topped the Mainstream Rock chart, while \"Rhythm of Love\" reached number 2 and \"Shoot High Aim Low\" number 11. The 1987\u20131988 tour ended with an appearance at Madison Square Garden on 14 May 1988 as part of Atlantic Records 40th anniversary concert.\n1988\u20131995: \"Anderson Bruford Wakeman Howe\", \"Union\" and \"Talk\".\nBy the end of 1988, Anderson felt creatively sidelined by Rabin and Squire and had grown tired of the musical direction of the \"Yes-West\" line-up. He took leave of the band, asserting that he would never stay in Yes purely for the money, and started work in Montserrat on a solo project that eventually involved Wakeman, Howe and Bruford. This collaboration led to suggestions that there would be some kind of reformation of the \"classic\" Yes, although from the start the project had included bass player Tony Levin, whom Bruford had worked with in King Crimson. The project, rather than taking over or otherwise using the Yes name, was called Anderson Bruford Wakeman Howe (ABWH).\nTheir eponymous album, released in June 1989, featured \"Brother of Mine\", which became an MTV hit and went gold in the United States. It later emerged that the four band members had not all recorded together; Anderson and producer Chris Kimsey slotted their parts into place. Howe has stated publicly that he was unhappy with the mix of his guitars on the album, though a version of \"Fist of Fire\" with more of Howe's guitars left intact appeared on the \"\" box set in 2002. ABWH toured in 1989 and 1990 as \"An Evening of Yes Music\" which featured Levin, keyboardist Julian Colbeck, and guitarist Milton McDonald as support musicians. A live album and home video were recorded and released in 1993, both titled \"An Evening of Yes Music Plus\" that featured Jeff Berlin on bass due to Levin suffering from illness. The tour was also dogged by legal battles sparked by Atlantic Records due to the band's references to Yes in promotional materials and the tour title.\nFollowing the tour, the group returned to the recording studio to produce their second album, tentatively called \"Dialogue\". After hearing the tracks, Arista Records refused to release the album as they felt the initial mixes were weak. They encouraged the group to seek outside songwriters, preferably ones who could help them deliver hit singles. Anderson approached Rabin about the situation, and Rabin sent Anderson a demo tape with three songs, indicating that ABWH could have one but had to send the others back. Arista listened to them and wanted all of them, proposing to create a combined album with both Yes factions.\nMeanwhile, the \"Yes-West\" group had been working on a follow-up to \"Big Generator\" and had been shopping around for a new singer, auditioning Roger Hodgson of Supertramp, Steve Walsh of Kansas, Billy Sherwood of World Trade and solo pop/dance singer Robbie Nevil (who'd scored a US #2 hit in 1986 with \"C'est la Vie\"). Walsh only spent one day with the band, but Sherwood and Squire quickly established a rapport and continued with writing sessions, although Sherwood ultimately chose not to formally join the group or become the lead singer. Arista now suggested that the \"Yes-West\" group, with Anderson on vocals, record the songs from Rabin's demo tape and add them to the incomplete ABWH album, which would then be released as a full album under the Yes name.\n\"Union\" was released in April 1991 and is the thirteenth studio album from Yes. Each group played their own songs, with Anderson singing on all tracks. Squire sang background vocals on a few of the ABWH tracks, with Tony Levin playing all the bass on those songs. The album does not feature all eight members playing at once. The track \"Masquerade\" earned Yes a Grammy Award nomination for Best Rock Instrumental Performance in 1992. Howe described the nomination for a track he had recorded solo at home as \"pure justice\", following the difficulties in making the album. \"Union\" sold approximately 1.5\u00a0million copies worldwide, and peaked at number 7 in the UK and number 15 in the US charts. Two singles from the album were released. \"Lift Me Up\" topped the Mainstream Rock charts in May 1991 for six weeks, while \"Saving My Heart\" peaked at number 9.\nAlmost the entire band have openly stated their dislike of \"Union\". Bruford has disowned the album entirely, and Wakeman was reportedly unable to recognise any of his keyboard work in the final edit and threw his copy of the album out of his limousine. He has since referred to the album as \"Onion\" because it makes him cry when he thinks about it. \"Union\" co-producer Jonathan Elias later stated publicly in an interview that Anderson, as the associate producer, knew of the session musicians' involvement. He added that he and Anderson had even initiated their contributions, because hostility between some of the band members at the time was preventing work from being accomplished. The 1991\u20131992 Union tour united all eight members on a revolving circular stage. Following the tour's conclusion in 1992, Bruford chose not to remain involved with Yes and returned to his jazz project \"Earthworks\". Howe also ceased his involvement with the band at this time. In August 1991, while the \"Union\" tour was underway, Atlantic released \"Yesyears\", a four-CD box set anthology. Two accompanying home videos, \"Yesyears\" and \"Greatest Video Hits\", were also released during 1991.\nIn 1993, the album \"Symphonic Music of Yes\" was released, featuring orchestrated Yes tracks arranged by Dee Palmer. Howe, Bruford and Anderson perform on the record, joined by the London Philharmonic Orchestra, the English Chamber Orchestra and the London Community Gospel Choir. Howe and Bruford performed together on television (presented as \"Yes\") to promote the album, marking Bruford's final performance under the Yes name before retiring from performing.\nThe next Yes studio album, as with \"Union\", was masterminded by a record company, rather than by the band itself. Victory Music approached Rabin with a proposal to produce an album solely with the \"90125\" line-up. Rabin initially countered by requesting that Wakeman also be included. Rabin began assembling the album at his home, using the then-pioneering concept of a digital home studio, and used material written by himself and Anderson. The new album was well into production in 1993, but Wakeman's involvement had finally been cancelled, as his refusal to leave his long-serving management created insuperable legal problems.\n\"Talk\" was released in March 1994 and is the band's fourteenth studio release. Its cover was designed by pop artist Peter Max. The record was largely composed and performed by Rabin, with the other band members following Rabin's tracks for their respective instrumentation. It was digitally recorded and produced by Rabin with engineer Michael Jay, using 3.4 GB of hard disk storage split among four networked Apple Macintosh computers running Digital Performer. The album blended elements of radio-friendly rock with a more structurally ambitious approach taken from the band's progressive blueprint, with the fifteen-minute track \"Endless Dream\". The album reached number 20 in the UK and number 33 in the US The track \"The Calling\" reached number 2 on the \"Billboard\" Hot Mainstream Rock Tracks chart and \"Walls\", which Rabin had written with former Supertramp songwriter and co-founder Roger Hodgson, peaked at number 24. It also became Yes's second-last-charting single. Rabin and Hodgson wrote a lot of material together and became close friends. Yes performed \"Walls\" on Late Show with David Letterman on 20 June 1994.\nThe 1994 tour (for which the band employed Billy Sherwood as a support musician on additional guitar, bass, vocals and keyboards) used a sound system developed by Rabin named Concertsonics which allowed the audience located in certain seating areas to tune portable FM radios to a specific frequency, so they could hear the concert with headphones.\nIn early 1995, following the tour, disagreements and dissatisfactions forced another change in the band. 1990s Yes manager Jon Brewer has stated that Squire had not appreciated the \"Talk\" production process: \"(he) didn't like that. He didn't think it was what Yes was all about; he was very much against a computerised, digital sound at that time. So Trevor and Chris moved away from one another for quite a while.\" For his part, Rabin felt that he had achieved his highest ambitions with \"Talk\" and lamented its disappointing reception, feeling that this was due to the fact that it \"just wasn't what people wanted to hear at the time.\" Having remarked at the conclusion of the tour \"I think I'm done\", Rabin quit the band and returned to Los Angeles, where he shifted his focus to composing for films. Kaye also left Yes to pursue other projects.\n1995\u20132000: \"Keys to Ascension\", \"Open Your Eyes\" and \"The Ladder\".\nIn November 1995, Anderson, Squire and White resurrected the \"classic\" 1970s line-up of Yes by inviting Wakeman and Howe back to the band, recording two new lengthy tracks called \"Be the One\" and \"That, That Is\". In March 1996 Yes performed three live shows at the Fremont Theater in San Luis Obispo, California which were recorded and released, along with the new studio tracks, that October on CMC International Records as the \"Keys to Ascension\" album, which peaked at number 48 in the UK and number 99 in the US A same-titled live video of the shows was also released that year.\nYes continued to record new tracks in the studio, drawing some material written around the time of the XYZ project. At one point the new songs were to be released as a studio album, but commercial considerations meant that the new tracks were eventually packaged with the remainder of the 1996 San Luis Obispo shows in November 1997 on \"Keys to Ascension 2\". The record managed to reach number 62 in the UK, but failed to chart in the US Disgruntled at the way a potential studio album had been sacrificed in favour of the \"Keys to Ascension\" releases (as well as the way in which a Yes tour was being arranged without his input or agreement), Wakeman left the group again. (The studio material from both albums would eventually be compiled and re-released without the live tracks onto a single CD, 2001's \"Keystudio\".)\nWith Yes in disarray again, Squire turned to Billy Sherwood (by now the band's engineer) for help. Both men had been working on a side project called Conspiracy and reworked existing demos and recordings from there to turn them into Yes songs, and also worked on new material with Anderson and White. (Howe's involvement at this stage was minimal, mainly taking place towards the end of the sessions.) Sherwood's integral involvement with the writing, production, and performance of the music led to his finally joining Yes as a full member (taking on the role of harmony singer, keyboardist and second guitarist).\nThe results of the sessions were released in November 1997 as the seventeenth Yes studio album, \"Open Your Eyes\" (on the Beyond Music label, who ensured that the group had greater control in packaging and naming). The music (mainly at Sherwood's urging) attempted to bridge the differing Yes styles of the 1970s and 1980s. (Sherwood: \"My goal was to try to break down those partisan walls\u2026\u00a0For that, I am proud\u2014to have aligned planets for a moment in time.\") However, \"Open Your Eyes\" was not a chart success; the record peaked at number 151 on the \"Billboard\" 200 but failed to enter the charts in the UK. The title single managed to reach number 33 on the mainstream rock chart.\nFor the 1997/1998 \"Open Your Eyes\" tour, Yes hired Russian keyboard player Igor Khoroshev, who had played on some of the album tracks. Significantly, the tour setlist featured only a few pieces from the new album, and mostly concentrated on earlier material. Anderson and Howe, who had been less involved with the writing and production on \"Open Your Eyes\" than they'd wished, would express dissatisfaction about the album later.\nBy the time the band came to record their eighteenth studio album \"The Ladder\" with producer Bruce Fairbairn, Khoroshev had become a full-time member (with Sherwood now concentrating on songwriting, vocal arrangements and second guitar). With Khoroshev's classically influenced keyboard style, and with all members now making more or less equal writing contributions, the band's sound found a balance between its eclectic 1970s progressive rock style and the more polished pop sound sought on the previous album. \"The Ladder\" also featured Latin music ingredients and clear world music influences, mostly brought in by Alan White (although Fairbairn's multi-instrumentalist colleague Randy Raine-Reusch made a strong contribution to the album's textures). One of the album tracks, \"Homeworld (The Ladder)\", was written for Relic Entertainment's Homeworld, a real-time strategy computer game, and was used as the credits and outro theme. Pleased with the result of the album's creation, the band had been in tentative discussions to continue work with Fairbairn on future projects, but he died suddenly during the final mixing sessions of the album.\n\"The Ladder\" was released in September 1999, peaking at number 36 in the UK and number 99 in the US While on tour in 1999 and early 2000, Yes recorded their performance at the House of Blues in Las Vegas on 31 October 1999, releasing it in September 2000 as a live album and DVD called \"\". As Sherwood saw his role in Yes as creating and performing new music, and the rest of the band now wished to concentrate on performing the back catalogue, he amicably resigned from Yes at the end of the tour.\nIn summer 2000, Yes embarked on the three-month Masterworks tour of the United States, on which they performed only material which had been released between 1970 and 1974 (\"The Yes Album\" through to \"Relayer\"). While on tour, Khoroshev was involved in a backstage incident of sexual assault with a female security guard at Nissan Pavilion in Bristow, Virginia on 23 July 2000 and parted company with the band at the end of the tour.\n2001\u20132008: \"Magnification\", Anniversary touring, and Anderson's departure.\nFollowing the departures of Sherwood and Khoroshev and the death of Fairbairn, Yes once again set about reinventing themselves, this time choosing to record without a keyboardist, opting instead to include a 60-piece orchestra conducted by Larry Group\u00e9; the first time the band used an orchestra since \"Time and a Word\" in 1970. The result was their nineteenth studio album, 2001's \"Magnification\". The record was not a chart success; it peaked at number 71 in the UK and number 186 in the US The Yes Symphonic Tour ran from July to December 2001 and had the band performing on stage with an orchestra and American keyboardist Tom Brislin. Their two shows in Amsterdam, in November, were recorded for their 2002 DVD and 2009 CD release \"Symphonic Live\". The band invited Wakeman to play with them for the filming, but he was on a solo tour at the time.\nFollowing Wakeman's announcement of his return in April 2002, Yes embarked on their Full Circle Tour in 2002\u20132003 that included their first performances in Australia since 1973. The band's appearance in Montreux on this tour was documented on the album and DVD \"Live at Montreux 2003\", released in 2007. In 2002, Rhino Records issued ', a five CD box set of classic, rare and unreleased tracks from the band's history, including some from the 1979 Paris sessions, followed a year later by the compilation album ', which reached number 10 in the UK charts, their highest-charting album since 1991, and number 131 in the US During 2003 and 2004, Rhino also released remastered editions of all Yes' studio albums up to, and including, \"90125\", all featuring rare and previously unreleased bonus tracks. These editions would be collected in 2013 as \"The Studio Albums 1969\u20131987\" box set, with \"Big Generator\" also receiving the same treatment. On 18 March 2003, minor planet (7707) Yes was named in honour of the band.\nOn 26 January 2004, the film \"Yesspeak\" premiered in a number of select theatres, followed by a closed-circuit live acoustic performance of the group. Both \"Yesspeak\" and the acoustic performance, titled \"\", were released on DVD later that year. A 35th anniversary tour followed in 2004 which was documented on the DVD \"Songs from Tsongas\", released in 2005. After their 35th Anniversary Tour, Yes described themselves as \"on hiatus\".\nDuring the hiatus, Yes members continued to collaborate. Squire, Howe and White reunited for one night only with former members Trevor Horn, Trevor Rabin and Geoff Downes during a show celebrating Horn's career, performing three Yes songs. The show video was released in DVD in 2008 under the name \"Trevor Horn and Friends: Slaves to the Rhythm\". Anderson toured jointly with Wakeman, for concerts focused largely on Yes material, White joined fellow Yes-men Tony Kaye and Billy Sherwood in Circa, and Howe reunited to record, release and tour with once-and-future Yes bandmate Geoff Downes in the reunion of the original Asia line-up.\nIn May 2008, a fortieth-anniversary Close to the Edge and Back Tour\u2014which was to feature Oliver Wakeman on keyboards\u2014was announced. Anderson has said that they had been preparing four new \"lengthy, multi-movement compositions\" for the world tour, but he had expressed disinterest in producing a new studio album after the low sales of \"Magnification\", suggesting that recording one was not \"logical anymore\". The tour was abruptly cancelled prior to rehearsals, after Anderson suffered an asthma attack and was diagnosed with acute respiratory failure, and was advised by doctors to avoid touring for six months.\nIn September 2008, the remaining three members, eager to resume touring regardless of Anderson's availability, announced the In the Present Tour billed as Steve Howe, Chris Squire and Alan White of Yes, with Canadian Beno\u00eet David, the singer in a Yes cover band, and Oliver Wakeman on keyboards. According to Anderson, he was removed from the band against his will; he expressed wanting to rejoin the band after his recovery, and initially disputed the continuation of the band as \"Yes\". As Anderson was a co-owner of the Yes trademark, the remaining members agreed at the time not to tour with the Yes name.\n2009\u20132015: Second reformation, \"Fly from Here\", \"Heaven &amp; Earth\", and Squire's death.\nIn October 2009, Squire declared that the new line-up from the In the Present Tour \"is now Yes\", and the tour, with the band now billed as Yes, continued through 2010. Their 2010 studio sessions would yield material eventually to be released as \"From a Page\".\nIn August 2010, it was announced that new material had been written for \"Fly from Here\", Yes's twentieth studio album. Yes signed a deal with Frontiers Records and began recording in Los Angeles. Trevor Horn served as producer, and Geoff Downes was brought back to replace Oliver Wakeman on keyboards; much of the album material was extrapolated from a pair of songs written by Horn and Downes around the time that they had been Yes members. Asserting that all studio recording was to be carried out by \"the line-up that actually ... does the work\", Howe dispelled rumours that an invitation to sing on the record had been extended to Anderson, who subsequently announced a new project as an ongoing collaboration with former Yes members Wakeman and Rabin.\nUpon completion in March 2011, and post-production a month later, \"Fly from Here\" was released worldwide in July, peaking at number 30 in the UK and 36 in the US Yes embarked on their Rite of Spring and Fly from Here tours, with Styx and Procol Harum supporting on select dates. The live Yes album and DVD, \"In the Present \u2013 Live from Lyon\", taken from the band's previous tour, were released in the same year.\nIn February 2012, David contracted a respiratory illness and was replaced by Glass Hammer singer Jon Davison. Davison had been recommended to Squire by their common friend Taylor Hawkins, drummer for the Foo Fighters. Davison would join Yes to complete the band's scheduled dates across the year.\nAccording to Anderson, he was healthy enough to sing for the 2012 dates, and had offered to return to the band. In November 2013, Anderson again expressed a wish to return to Yes, saying \"it's really great music, but it's going to feel different because\u2026\u00a0leading the band\u2026 I had this certain energy, and it's missing.\" On Anderson's potential return to Yes, Howe commented: \u201cOne never wants to say never, but basically I can\u2019t see it. I love Jon. I'm a lot older now, and so is he, and the only terms I work on is that I'm happy working on this. I'm not going to take a sudden load on my back that I either don't need or want. My music\u2019s always guided me, and it\u2019s not telling me to do those things. It's telling me to go forwards.\"\nOn 7 March 2013, founding guitarist Peter Banks died of heart failure.\nFrom March 2013 to June 2014, Yes completed the Three Album Tour (performing \"The Yes Album\", \"Close to the Edge\" and \"Going for the One\" in their entirety), a progressive-rock themed cruise titled \"Cruise to the Edge\", and a second cruise in April 2014. The show on 11 May 2014 in Bristol was released as a live video album, \"\".\n\"Heaven &amp; Earth\", the band's twenty-first studio album and first with Davison, was recorded between January and March 2014, at Neptune Studios in Los Angeles with Roy Thomas Baker as producer and former band member Billy Sherwood as engineer, backing vocals, and mixer. Squire described Baker as a \"force in the studio\" (Baker had previously worked with the group in the late 70s on a project that had ultimately been scrapped). Howe reflected that he \"tried to slow down\" the album production in hopes that \"maybe we could refine it ...\" and compared it to the success of the band's classic works in which they \"arranged the hell out of\" the material. He wrote later that Baker behaved erratically and was difficult to work with, and was dissatisfied with the final mixes of the album. To promote \"Heaven &amp; Earth\", Yes toured between July and November 2014 in North America, Europe, Australia, New Zealand and Japan. The show in Mesa, Arizona was released as \"\".\nIn May 2015, news of Squire's diagnosis with acute erythroid leukaemia was made public. This resulted in former guitarist Billy Sherwood replacing him for their 2015 summer North American tour with Toto between August\u2013September, and their third annual Cruise to the Edge voyage in November, while Squire was receiving treatment. His condition deteriorated soon after, and he died on 27 June at his home in Phoenix, Arizona. Downes first announced Squire's death on Twitter. Squire asked White and Sherwood to continue the legacy of the band, which Sherwood recalled \"was paramount in his mind ... so I'm happy to be doing that.\" Yes performed without Squire, for the first time in their 47-year history, on 7 August 2015 in Mashantucket, Connecticut. In November 2015, they completed their annual Cruise to the Edge voyage.\n2016\u20132023: 50th Anniversary, Hall of Fame induction, \"The Quest\", and White's death.\nFollowing Squire's death, former Yes members Anderson, Rabin and Wakeman announced a new group, \"Anderson, Rabin and Wakeman\" (ARW) in January 2016 and began writing new material. They toured as An Evening of Yes Music and More from 2016 to 2017, with drummer Lou Molino III and bassist Lee Pomeroy. Meanwhile, the main Yes group continued touring, performing \"Fragile\" and \"Drama\" in their entirety as well as other songs on their 2016 European tour. White stopped touring to recover from back surgery, and was replaced by American drummer Jay Schellen for various periods of time until the following February. The 2016 tour was released as a live album, \"Topographic Drama \u2013 Live Across America\" in late 2017 and was Yes's first album not to feature Squire. Yes toured in February, August, and September 2017, but the touring was cut short following the unexpected death of Howe's son Virgil.\nHaving been eligible to be inducted into the Rock and Roll Hall of Fame since 1994, Yes were inducted into the 2017 class by Geddy Lee and Alex Lifeson of Rush in a ceremony held in New York City on 7 April 2017. The musicians inducted were Anderson, Howe, Rabin, Squire, Wakeman, Kaye, Bruford, and White, the same line-up featured on \"Union\" and its tour. Having failed to pass the nomination stage twice previously, the announcement of their forthcoming induction was made on 20 December 2016. In the ceremony, Anderson, Howe, Rabin, Wakeman, and White performed \"Roundabout\" with Lee on bass, followed by \"Owner of a Lonely Heart\" with Howe on bass. Bruford attended the ceremony but did not perform, while Kaye did not attend. Dylan Howe (Steve's son) described how at the ceremony the two groups\u2014Yes and ARW\u2014were seated at adjacent tables but ignored each other.\nPrior to Squire's death, the name \"Yes\", had been owned jointly by Squire, White, and Anderson. With the permission of Squire's wife, and following Yes's induction into the Rock and Roll Hall of Fame on 7 April 2017, Anderson, Rabin &amp; Wakeman renamed themselves Yes Featuring Jon Anderson, Trevor Rabin, Rick Wakeman. Both groups toured to celebrate the fiftieth anniversary of Yes in 2018, something that media outlets noted as creating some confusion among fans. Schellen continued to play as a second drummer to support White, who had a bacterial infection in his joints from November 2017. Following the touring, Yes Featuring ARW disbanded after two years.\nYes continued touring between 2018 and 2020. Yes's 50th anniversary tour dates in London coincided with the release of \"Fly from Here \u2013 Return Trip\", a new version of the album with new lead vocals and mixes by Horn. The tour included guests Dylan Howe (Steve's son), Trevor Horn, Tony Kaye, Tom Brislin, and Patrick Moraz, who had last performed with Yes in 1976.\nThe live album \"Yes 50 Live\" was released in 2019. Yes also headlined the Royal Affair Tour in 2019 with artists Asia, John Lodge, Carl Palmer's ELP Legacy, and Arthur Brown and was released as \"\". This was followed by the previously unreleased music release \"From a Page\", mostly written by Oliver Wakeman. Further planned 2020 tours were postponed due to the COVID-19 pandemic. Later in 2020, Davison and Sherwood formed Arc of Life, a new group featuring Schellen and keyboardist Dave Kerzner.\nYes worked on new material for their twenty-second studio album \"The Quest\", from late 2019 through 2021. The lockdowns brought on by the COVID-19 pandemic resulted in members recording their parts in separate studios and sending them to Howe and engineer Curtis Schwartz in England. In 2021, Howe, Davison and Downes got together and completed the album. \"The Quest\" was released on 1 October 2021, and the opening two tracks, \"The Ice Bridge\" and \"Dare to Know\", were released as digital singles. The album reached No. 20 in the UK. Yes discussed plans regarding a follow-up album.\nYes announced that White would step down from touring due to health issues on 22 May 2022. White died four days later on 26 May. A tribute concert for White was held in Seattle on 2 October, featuring special guests and former Yes guitarist Trevor Rabin.\nIn January 2023, Warner Music Group acquired the recorded music rights and associated income streams relating to 12 studio albums from 1969 to 1987, and several live and compilation releases. In February, Schellen (who had officially replaced White on drums) joined the band as a permanent member.\n2023\u2013present: \"Mirror to the Sky\" and Continued Touring.\nThe band's 2022 tour was to commemorate the 50th anniversary of \"Close to the Edge\", but after White's death, European dates for the tour were rescheduled for 2023 and the program changed. The tour was again delayed again to 2024 due to insurance incentives related to COVID-19 and casus belli coverage; some dates were rescheduled and became The Classic Tales of Yes Tour 2024.\nAnderson toured North America in Spring 2023, Spring/Summer 2024, and Spring/Summer 2025 under the title \"Yes Epics and Classics\" with a setlist primarily devoted to early 70s Yes material backed by The Band Geeks and expressed \"In my mind\u2026 I'm still in Yes.\" While Anderson has stated a desire for a reunion multiple times since the band re-formed without him in 2008, following the 2024 release of \"True\" said \"I\u2019ve got the Yes that I wanted\" and described these activities in their \"Live - Perpetual Change\" album liner notes as \"keeping the true Yes flag flying.\"\nYes released their new studio album, \"Mirror to the Sky\", on 19 May 2023, releasing the opening track, \"Cut from the Stars\" and \"All Connected\" as a digital singles. The album continued the creative process from \"The Quest\". The band began working on a follow-up album and continued touring under the \"Album Series\" banner, this time focusing on \"Fragile\" \u2013\u00a0material which Howe describes as representative of a period when Yes was \"at the height of our creativity, determined for success.\"\nMusical style and influences.\nMusic critics Jim DeRogatis and Stephen Thomas Erlewine of AllMusic cite Yes as the \"definitive English progressive rock band,\" and as \"epitomizing\" the genre. Erlewine credited the band with bringing the genre to mainstream audiences. He described the band's early sound as an amalgamation of \"pastoral folk\", \"Baroque classical\" and \"muscular rock &amp; roll\". He also noted that the band's compositions utilised odd time signatures, and were \"structured like mini-suites.\" He described some of the band's later output as \"steely, shiny [...] album-oriented rock.\" Chris Roberts of \"Classic Rock\" said Yes \"pioneered 70s progressive and symphonic rock, and dominated 80s stadium pop-rock.\" Yes have also been described as an art rock group. According to Nick Spacek of \"The Pitch\", \"the band has changed its sound and its lineups, but the emphasis on forward-thinking composition has remained strong.\" According to DeRogatis, the band \"rocked harder than many of its peers, maintaining a vital pulse and delivering memorable riffs in between the showy solos.\" Chris Dahlen of Pitchfork wrote that albums such as \"Fragile\" and \"Close to the Edge\" balanced extended instrumental passages with clear compositional direction, while later works such as \"Tales from Topographic Oceans\" were marked by what he described as excessive length and abstraction. In his review he highlighted the prominence of Chris Squire's bass lines, Bill Bruford's precise drumming and Rick Wakeman's keyboard textures as central to the group's sound and appeal.\nJon Anderson, who served as the original lead vocalist and co-founder of Yes, said that the band incorporated elements of progressive music, symphonic music, jazz, fusion, and world music into their material. He mentioned that the classical composition structure inspired him to craft longer pieces of music and cited the works of Russian composer Igor Stravinsky, Finnish composer Jean Sibelius and English composer Gustav Holst (namely \"The Planets\") as some of the band's influences. Anderson has also cited The Beatles, Frank Zappa and The Beach Boys as influences. Sean Murphy of \"PopMatters\" wrote, \"While rightly castigated for bringing inane lyrics to an almost holy level, listening to Yes is like listening to opera: the words are, or may as well be, in a different language. It\u2019s all about the \"sounds\": that voice, those instruments, that composition.\"\nDiscography.\nStudio albums\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43976", "revid": "16303", "url": "https://en.wikipedia.org/wiki?curid=43976", "title": "FYROM", "text": ""}
{"id": "43977", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=43977", "title": "Military history of Poland during World War II", "text": "Aspect of military history\nIn World War II, the Polish armed forces were the fourth largest Allied forces in Europe, after those of the Soviet Union, United States and Britain.&lt;templatestyles src=\"Citation/styles.css\"/&gt;[a] Poles made substantial contributions to the Allied effort throughout the war, fighting on land, sea, and in the air.\nPolish forces in the east, fighting alongside the Red army and under Soviet high command, took part in the Soviet offensives across Belarus and Ukraine into Poland and across the Vistula and Oder Rivers to the Battle of Berlin.\nIn the west, Polish paratroopers from the 1st Independent Polish Parachute Brigade fought in the Battle of Arnhem / Operation Market Garden; while ground troops were present in the North Africa Campaign (siege of Tobruk); the Italian campaign (including the capture of the monastery hill at the Battle of Monte Cassino); and in battles following the invasion of France (the battle of the Falaise pocket; and an armored division in the Western Allied invasion of Germany).\nParticularly well-documented was the service of 145 Polish pilots flying British planes under British Command during the Battle of Britain, 79 in mixed squadrons under the RAF after July 1940, 32 in wholly Polish Squadron 303 after 31 August 1940 and 34 in entirely Polish Squadron 302. Other instances of service flying French planes in the Polish Air Force took place during the Battle of Britain at the same time, and from 1944 the Polish Air Force (also with British planes) was established in Britain.\nSome Polish contributions were less visible, notably the prewar and wartime decrypting of German Enigma-machine ciphers by cryptologists Marian Rejewski, Henryk Zygalski, and Jerzy R\u00f3\u017cycki. An extensive Polish intelligence network also proved of great value to Allied intelligence.\nThe European Theatre of World War II opened with the German invasion of Poland on Friday September 1, 1939, followed by the Soviet invasion of Poland on September 17, 1939. On 6 October, following the Polish defeat at the Battle of Kock, German and Soviet forces gained full control over Poland. The success of the invasion marked the end of the Second Polish Republic, though Poland never formally surrendered. A Polish Underground State with a government-in-exile that would eventually set up headquarters in London resumed the struggle against the occupying powers. The Polish forces in the West, as well as in the East and an intelligence service were established outside of Poland, and contributed to the Allied effort throughout the war.\nInvasion of Poland.\nThe invasion of Polish Second Republic by the military forces of Nazi Germany on September 1, 1939, marked the beginning of World War II in Europe. The Soviets invaded Poland on September 17 as had been agreed with Nazi Germany in the Molotov-Ribbentrop Pact.\nIn keeping with the terms of the of the Molotov\u2013Ribbentrop Pact Germany informed the Soviet Union that its forces were nearing the Soviet interest zone in Poland and so urged the Soviet Union to move into its zone. The Soviets had been taken by surprise by the speed of the German advance as they had expected to have several weeks to prepare for an invasion rather than merely a few days. They did promise to move as quickly as possible. On September 17 the Soviets invaded eastern Poland, forcing the Polish government and military to abandon their plans for a long-term defense in the Romanian bridgehead area. The last remaining Polish Army units capitulated in early October.\nIn accordance with their treaty obligations, the United Kingdom and France declared war on Germany on September 3. Hitler had gambled, incorrectly, that France and Britain would allow him to annex parts of Poland without military reaction. The campaign began on September 1, 1939, one week after the signing of the Molotov\u2013Ribbentrop Pact containing a secret protocol for the division of Northern and Central Europe into German and Soviet spheres of influence. It ended on October 6, 1939, with Germany and the Soviet Union occupying the entirety of Poland.\nGerman losses included about 16,000 killed in action, 28,000 wounded, 3,500 missing, over 200 aircraft, and 30% of their armored vehicles. The Polish casualties were about 66,000 dead and 694,000 captured.\nGerman losses in the Polish campaign amounted to 50% of all casualties they would suffer until their invasion of USSR in 1941; and the campaign that lasted about a month consumed eight months worth of supplies.\nAid to Jews.\nA substantial number of Poles risked their lives in the German occupation to save Jews. German-occupied Poland was the only European territory where the Germans punished any kind of help to Jews with death for the helper and his entire family. Even so, Poland was also the only German-occupied country to establish an organization specifically to aid Jews. Known by the cryptonym \"\u017begota\", it provided food, shelter, medical care, money, and false documents to Jews. Most of \u017begota's funds came directly from the Polish Government-in-Exile in Great Britain.\nMost Jews who survived the German occupation of Poland were saved by Poles unconnected with \u017begota. Estimates of Jewish survivors in Poland range from 40,000 to 50,000 to 100,000\u2013120,000. Scholars estimate that it took the work of ten people to save the life of one Polish Jew. Of the individuals awarded medals of \"Righteous among the Nations\" (given by the State of Israel to non-Jews who saved Jews from extermination in the Holocaust) those who were Polish citizens number the greatest. There are 6,339 Polish men and women recognized as \"Righteous\" to this day, amounting to over 25 percent of the total number of 22,765 honorary titles awarded already.\nPolish resistance.\nThe main resistance force in German-occupied Poland was the Armia Krajowa (\"Home Army\"; abbreviated \"AK\"), which numbered some 400,000 fighters at its peak as well as many more sympathizers. Throughout most of the war, AK was one of the three largest resistance movements in the war.&lt;templatestyles src=\"Citation/styles.css\"/&gt;[b] The AK coordinated its operations with the exiled Polish Government in London and its activity concentrated on sabotage, diversion and intelligence gathering. Its combat activity was low until 1943 as the army was avoiding suicidal warfare and preserved its very limited resources for later conflicts that sharply increased when the Nazi war machine started to crumble in the wake of the successes of the Red Army in the Eastern Front. Then the AK started a nationwide uprising (Operation Tempest) against Nazi forces. Before that, AK units carried out thousands of raids, intelligence operations, bombed hundreds of railway shipments, participated in many clashes and battles with the German police and Wehrmacht units and conducted tens of thousands of acts of sabotage against German industry The AK also conducted \"punitive\" operations to assassinate Gestapo officials responsible for Nazi terror. Following the 1941 German attack on the USSR, the AK assisted the Soviet Union's war effort by sabotaging the German advance into Soviet territory and provided intelligence on the deployment and movement of German forces. After 1943, its direct combat activity increased sharply. German losses to the Polish partisans averaged 850\u20131,700 per month in early 1944 compared to about 250\u2013320 per month in 1942.\nIn addition to the Home Army, there was an underground ultra-nationalist resistance force called \"Narodowe Si\u0142y Zbrojne\" (NSZ or \"National Armed Forces\"), with a fiercely anti-communist stance. It participated in fighting German units, winning many skirmishes. From 1943 onwards, some units took part in battling the \"Gwardia Ludowa\" and the Polish People's Army PAL, both communist resistance movement. From 1944, the advancing Red Army was also seen as a foreign occupation force, prompting skirmishes with the Soviets as well as Soviet-backed partisans. In the later part of the war, when Soviet partisans started attacking Polish partisans, sympathizers and civilians, all non-communist Polish formations were (to an increasing extent) becoming involved in actions against the Soviets.\nThe \"Armia Ludowa\", a Soviet proxy fighting force was another resistance group that was unrelated to the Polish Government in Exile, allied instead to the Soviet Union. As of July, 1944 it incorporated a similar organization, the \"Gwardia Ludowa\" and the Polish People's Army PAL, and numbered about 6,000 soldiers (although estimates vary).\nThere were separate resistance groups organized by Polish Jews: the right-wing \"\u017bydowski Zwi\u0105zek Walki\" (\"Jewish Fighting Union\") (\u017bZW) and the more Soviet-leaning \"\u017bydowska Organizacja Bojowa\" (\"Jewish Combat Organization\") (\u017bOB). These organisations cooperated little with each other and their relationship with the Polish resistance varied between occasional cooperation (mainly between ZZW and AK) to armed confrontations (mostly between \u017bOB and NZS). \nOther notable Polish resistance organizations included the \"Bataliony Ch\u0142opskie\" (BCh), a mostly peasant-based organization allied to the AK. At its height the BCh included 115,543 members (1944; with additional LSB and PKB-AK Guard, for the estimated total of 150,250 men, not confirmed).\nThroughout the war the German state was forced to divert a substantial part of its military forces to keep control over Poland:\nIntelligence.\nPolish intelligence supplied valuable intelligence to the Allies; 48% of all reports received by the British secret services from continental Europe in between 1939 and 1945 came from Polish sources. The total number of those reports is estimated at 80,000, and 85% of them were deemed high or better quality. Despite Poland becoming occupied, the Polish intelligence network not only survived but grew rapidly, and near the end of the war had over 1,600 registered agents (Another estimate gave about 3,500).\nWestern Allies had limited intelligence assets in Central and Eastern Europe, and extensive Polish intelligence network in place proved to be a major asset, even described as \"the only allied intelligence assets on the Continent\" following the French capitulation. According to Marek Ney-Krwawicz, for the Western Allies, the intelligence provided by the Home Army was considered to be the best source of information on the Eastern Front.\nIn a period of more than six and a half years, from late December 1932 to the outbreak of World War II, three mathematician-cryptologists (Marian Rejewski, Henryk Zygalski and Jerzy R\u00f3\u017cycki) at the Polish General Staff's Cipher Bureau in Warsaw had developed a number of techniques and devices\u2014 including the \"grill\" method, R\u00f3\u017cycki's \"clock\", Rejewski's \"cyclometer\" and \"card catalog\", Zygalski's \"perforated sheets\", and Rejewski's \"cryptologic bomb\" (in Polish, \"\"bomba\"\", precursor to the later British \"Bombe\", named after its Polish predecessor)\u2014 to facilitate decryption of messages produced on the German \"Enigma\" cipher machine. Just five weeks before the outbreak of World War II, on July 25, 1939, near Pyry in the Kabaty Woods south of Warsaw, Poland disclosed her achievements to France and the United Kingdom, which had, up to that time, failed in all their own efforts to crack the German military Enigma cipher. Had Poland not shared her Enigma-decryption results at Pyry, the United Kingdom might have been unable to read Enigma ciphers. In the event, intelligence gained from this source, codenamed Ultra, was extremely valuable to the Allied prosecution of the war. While ULTRA's precise influence on its course remains a subject of debate, ULTRA undoubtedly altered the course of the war.\nAs early as 1940, Polish agents (including Witold Pilecki) penetrated German concentration camps, including Auschwitz, and informed the world about Nazi atrocities. Jan Karski is another important Polish resistance fighter who reported to the Polish government in exile and the Western Allies on the situation in German-occupied Poland, especially the destruction of the Warsaw Ghetto, and the secretive German-Nazi extermination camps.\nPolish Home Army (\"Armia Krajowa\", \"AK\") intelligence was vital to locating and destroying (18 August 1943) the German rocket facility at Peenem\u00fcnde and to gathering information about Germany's V-1 flying bomb and V-2 rocket. The Home Army delivered to the United Kingdom key V-2 parts after a rocket, fired on 30 May 1944, crashed near a German test facility at Sarnaki on the Bug River and was recovered by the Home Army. On the night of 25\u201326 July 1944 the crucial parts were flown from occupied Poland to the United Kingdom in an RAF plane, along with detailed drawings of parts too large to fit in the plane (see \"Home Army and V1 and V2\"). Analysis of the German rocket became vital to improving Allied anti-V-2 defenses (see Operation Most III).\nOperations of the II Bureau, the intelligence service of the Polish government in exile, extended beyond Poland and even beyond Europe. Polish agents provided reports on German war production, morale and troop movements, including information on German submarine operations. The II Bureau is reported to have had two agents in the upper levels of the German high command. Polish intelligence monitored the French fleet at Toulon. Mieczys\u0142aw Zygfryd S\u0142owikowski has been described as \"the only allied agent with a network in North Africa\". In July 1941 Mieczys\u0142aw S\u0142owikowski (codenamed \"\"Rygor\"\"\u2014Polish for \"Rigor\") set up \"Agency Africa\", one of World War II's most successful intelligence organizations. His Polish allies in these endeavors included Lt. Col. Gwido Langer and Major Maksymilian Ci\u0119\u017cki (prewar heads, respectively, of Poland's \"Biuro Szyfr\u00f3w\", Cipher Bureau, and of its German section, \"B.S.-4\", which broke Germany's Enigma ciphers). The information gathered by the Agency was used by the Americans and British in planning the amphibious November 1942 Operation Torch landings in North Africa. These were the first large-scale Allied landings of the war, and their success in turn paved the way for the Allies' Italian campaign.\nSome Poles also served in other Allied intelligence services, including the celebrated Krystyna Skarbek (\"Christine Granville\") in the United Kingdom's Special Operations Executive.\nThe researchers who produced the first Polish-British in-depth monograph on Home Army intelligence \"(Intelligence Co-operation Between Poland and Great Britain During World War II: Report of the Anglo-Polish Historical Committee\" of 2005) and who described contributions of Polish intelligence to Allied victory as \"disproportionally large\" have also argued that \"the work performed by Home Army intelligence undoubtedly supported the Allied armed effort much more effectively than subversive and guerilla activities.\"\nPolish Forces (West).\nArmy.\nAfter the country's defeat in the 1939 campaign, the Polish government in exile quickly organized in France a new army of about 75,000 men. In 1940 a Polish Highland Brigade took part in the Battle of Narvik (Norway), and two Polish divisions (First Grenadier Division, and Second Infantry Fusiliers Division) took part in the defense of France, while a Polish motorized brigade and two infantry divisions were in process of forming. A Polish Independent Carpathian Brigade was formed in French Mandate Syria, to which many Polish troops had escaped from Romania. The Polish Air Force in France had 86 aircraft with one and a half of the squadrons fully operational, and the remaining two and a half in various stages of training.\nBy the fall of France, numerous Polish personnel had died in the fighting (some ) or had been interned in Switzerland (some ). Nevertheless, about 19,000 Polish\u2014about 25% of which were aircrew\u2014were evacuated from France, most alongside other troops transported from western France to the United Kingdom. In 1941, following an agreement between the Polish government in exile and Joseph Stalin, the Soviets released Polish citizens, from whom a 75,000-strong army was formed in the USSR under General W\u0142adys\u0142aw Anders. Without any support from the Soviets to train, equip and maintain this army, the Polish government in exile followed Anders' advice for a transfer of some (and about civilians), in March and August 1942, across the Caspian Sea to Iran permitting Soviet divisions in occupation there to be released for action. In the Middle East, this \"Anders' Army\" joined the British Eighth Army, where it formed Polish II Corps.\nThe Polish Armed Forces in the West fought under British command and numbered 195,000 in March 1944 and 165,000 at the end of that year, including about 20,000 personnel in the Polish Air Force and 3,000 in the Polish Navy. At the end of World War II, the Polish Armed Forces in the west numbered 195,000 and by July 1945 had increased to 228,000, most of the newcomers being released prisoners of war and ex-labor camp inmates.\nAir force.\nThe Polish Air Force first fought in the 1939 Invasion of Poland. Significantly outnumbered and with its fighters outmatched by more advanced German fighters, remained active up to the second week of the campaign, inflicting significant damage on the \"Luftwaffe\". The \"Luftwaffe\" lost, to all operational causes, 285 aircraft, with 279 more damaged, while the Poles lost 333 aircraft.\nAfter the fall of Poland many Polish pilots escaped via Hungary to France. The Polish Air Force fought in the Battle of France as one fighter squadron GC 1/145, several small units detached to French squadrons, and numerous flights of industry defence (in total, 133 pilots, who achieved 53\u201357 victories for a loss of 8 men in combat, what was 7.93% of allied victories).\nLater, Polish pilots fought in the Battle of Britain, where the Polish 303 Fighter Squadron claimed the highest number of kills of any Allied squadron. From the very beginning of the war, the Royal Air Force (RAF) had welcomed foreign pilots to supplement the dwindling pool of British pilots. On 11 June 1940, the Polish Government in Exile signed an agreement with the British Government to form a Polish Army and Polish Air Force in the United Kingdom. The first two (of an eventual ten) Polish fighter squadrons went into action in August 1940. Four Polish squadrons eventually took part in the Battle of Britain (300 and 301 Bomber Squadrons; 302 and 303 Fighter Squadrons), with 89 Polish pilots. Together with more than 50 Poles fighting in British squadrons, a total of 145 Polish pilots defended British skies. Polish pilots were among the most experienced in the battle, most of them having already fought in the 1939 September Campaign in Poland and the 1940 Battle of France. Additionally, prewar Poland had set a very high standard of pilot training. The 303 Squadron, named after the Polish\u2013American hero, General Tadeusz Ko\u015bciuszko, claimed the highest number of kills (126) of all fighter squadrons engaged in the Battle of Britain, even though it only joined the combat on August 30, 1940 These Polish pilots, constituting 5% of the pilots active in the Battle of Britain, were responsible for 12% of total victories in the Battle.\nThe Polish Air Force also fought in 1943 in Tunisia\u2014the Polish Fighting Team (nicknamed \"Skalski's Circus\")\u2014and in raids on Germany (1940\u201345). In the second half of 1941 and early 1942, Polish bomber squadrons formed a sixth of the forces available to RAF Bomber Command but later they suffered heavy losses, with little replenishment possibilities. Polish aircrew losses serving with Bomber Command from 1940 to 1945 were 929 killed.\nUltimately eight Polish fighter squadrons were formed within the RAF and had claimed 629 Axis aircraft destroyed by May 1945. By the end of the war, about 19,400 Poles were serving in the RAF.\nPolish squadrons in the United Kingdom:\nNavy.\nJust on the eve of war, three destroyers\u2014representing most of the major Polish Navy ships\u2014had been sent for safety to the United Kingdom (Operation Peking). There they fought alongside the Royal Navy. At various stages of the war, the Polish Navy comprised two cruisers and a large number of smaller ships. The Polish navy was given a number of British ships and submarines which would otherwise have been unused due to the lack of trained British crews. The Polish Navy fought with great distinction alongside the other Allied navies in many important and successful operations, including those conducted against the . In the war the Polish Navy operated a total of 27 ships: 2 cruisers, 9 destroyers, 5 submarines and 11 torpedo boats. They sailed a total of 1.2 million nautical miles, escorted 787 convoys, conducted 1,162 patrols and combat operations, sank 12 enemy ships (including 5 submarines) and 41 merchant vessels, damaged 24 more (including 8 submarines) and shot down 20 aircraft. 450 seamen out of the over 4,000 who served with the Navy lost their lives in action.\nThis does not include a number of minor ships, transports, merchant-marine auxiliary vessels, and patrol boats. Polish Merchant Navy contributed about 137,000 BRT to Allied shipping; losing 18 ships (with capacity of 76,000 BRT) and over 200 sailors in the war.\nPolish Forces (East).\nAfter the Polish government-in-exile organized the \"Anders Army\" in 1941 in the Soviet Union in the aftermath of the Operation Barbarossa and evacuated it to the West, Polish communists sought to create a new army, under communist control, out of the many ethnic Poles that remained in the Soviet Union. These were primarily citizens of the prewar Second Polish Republic that had been deported and often imprisoned by the Soviets following the Soviet annexation of Poland's eastern territories, as per the Molotov-Ribbentrop Pact. The Soviet Union created the Union of Polish Patriots (ZPP) in 1943, a communist Polish organization intended to represent the interest of Poles on Soviet soil and organize this new army. The relocated Poles, along with numbers of Byelorussians, Ukrainians, and Polish Jews, were organized into a division, the nucleus of a force known as the Polish People's Army (\"Ludowe Wojsko Polskie\", LWP) but colloquially known as the \"Berling Army\" after its first commander, Zygmunt Berling. The division made its combat debut in October 1943 at the Battle of Lenino. Afterwards, it was rapidly expanded into the 1st Polish Corps, which in turn grew by 1944 into the 1st Polish Army. In 1945, 2nd Polish Army was added to the LWP. By the end of the war, the LWP numbered about 200,000 front-line soldiers. The Polish communist guerilla force, the Armia Ludowa, was integrated with the Polish People's Army in January 1944.\nThe Polish First Army was integrated in the 1st Belorussian Front with which it entered Poland from Soviet territory in 1944. In the 1944 Warsaw Uprising it liberated the suburb of Praga, but otherwise sat out most of the battle, aside from a series of unsuccessful crossings of the Vistula in mid-September. It took part in battles for Bydgoszcz (Bromberg), Kolobrzeg (Kolberg), Gda\u0144sk (Danzig) and Gdynia, losing about 17,500 killed in action over the course of the war. In April\u2013May 1945 the 1st Army fought in the final capture of Berlin. The Polish Second Army fought as part of the Soviet 1st Ukrainian Front and took part in the Prague Offensive. In the final operations of the war the casualties of the two armies of the LWP amounted to about 67,000.\nPoles in the German Armed Forces.\nHundreds of thousands of former Polish citizens, particularly residents of parts of Poland annexed to Germany, were conscripted into the German Armed Forces. Also, a number of former Polish citizens, especially members of the prewar German minority in Poland (see \"Volksliste\"), volunteered for service in the German Armed Forces.\nThese were mostly members of the German minority in Poland who were considered by the Nazi authorities to be ethnically German (Volksdeutsche). In 1939 in the Invasion of Poland they created the paramilitary organisation Volksdeutscher Selbstschutz, and actively supported German forces in occupied Poland.\nOn the Western Front, German military personnel of Polish ethnicity, held in prisoner-of-war camps, became a substantial source of manpower for the Polish Armed Forces in the West. Nearly 90,000 former German military personnel were eventually recruited into the Polish Armed Forces in the West. By Victory Day (9 May) in 1945, a third of Polish service members in the West were former members of the German Armed Forces.\nBattles.\nMajor battles and campaigns in which Polish regular forces took part:\nTechnology.\nWeapons.\nPolish engineers who escaped German-occupied Poland contributed to weapon developments during the war. A Polish/Czech/British team brought the 20 mm Polsten to fruition as a simpler and cheaper to produce but as effective derivative of the Oerlikon 20 mm cannon.\nThe Polish Home Army was probably the only World War II resistance movement to manufacture large quantities of weaponry and munitions. In addition to production of pre-war designs they developed and produced in the war the B\u0142yskawica submachine gun, Bechowiec, KIS and Polski Sten (from the British Sten) machine pistols as well as the filipinka and sidol\u00f3wka hand grenades. In the Warsaw Uprising Polish engineers built several armoured cars, such as the Kubu\u015b, which also took part in the fighting.\nThe KIS was designed and made in the Jan Piwnik's \"Ponury\" (\"Grim\") guerrilla unit that was operating in Holy Cross Mountains region. It was probably the only kind of modern firearm that could be manufactured in the forest without the need for sophisticated tools and factory equipment in the Second World War.\nNotes.\na &lt;templatestyles src=\"Citation/styles.css\"/&gt;^ Numerous sources state that Polish Army was the fourth biggest Allied fighting contingent. Steven J. Zaloga wrote that \"by the war's end the Polish Army was the fourth largest contingent of the Allied coalition after the armed forces of the Soviet Union, the United States and Great Britain.\" Jerzy Jan Lerski writes \"All in all, the Polish units, although divided and controlled by different political orientation, constituted the fourth largest Allied force, after the American, British and Soviet Armies.\" M. K. Dziewanowski has noted that \"if Polish forces fighting in the east and west were added to the resistance fighters, Poland had the fourth largest Allied army in the war (after the USSR, the U.S. and Britain)\".\nb &lt;templatestyles src=\"Citation/styles.css\"/&gt;^ Sources vary with regards to what was the largest resistance movement in World War II. As the war progressed, some resistance movements grew larger\u2014and others diminished. Polish territories were mostly freed from Nazi German control in the years 1944\u20131945, eliminating the need for their respective (anti-Nazi) partisan forces in Poland (although the cursed soldiers continued to fight against the Soviets). Several sources note that Polish Armia Krajowa was the largest resistance movement in Nazi-occupied Europe. For example, Norman Davies wrote \"Armia Krajowa (Home Army), the AK, which could fairly claim to be the largest of European resistance\"; Gregor Dallas wrote \"Home Army (Armia Krajowa or AK) in late 1943 numbered about 400,000, making it the largest resistance organization in Europe\"; Mark Wyman wrote \"Armia Krajowa was considered the largest underground resistance unit in wartime Europe\". Certainly, Polish resistance was the largest resistance until the German invasion of Yugoslavia and the invasion of the Soviet Union in 1941. After that point, the numbers of Soviet partisans and Yugoslav partisans grew rapidly. The number of Soviet partisans quickly caught up and were very similar to that of the Polish resistance. The number of Tito's Yugoslav partisans were roughly similar to those of the Polish and Soviet partisans in the first years of the war (1941\u20131942), but grew rapidly in the latter years, outnumbering the Polish and Soviet partisans by 2:1 or more (estimates give Yugoslavian forces about 800,000 in 1945, to Polish and Soviet forces of 400,000 in 1944).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "43979", "revid": "50915234", "url": "https://en.wikipedia.org/wiki?curid=43979", "title": "T\u00f3rshavn", "text": "Capital of the Faroe Islands\nT\u00f3rshavn (; lit.\u2009'Thor's harbour'; Danish: \"Thorshavn\"), locally referred to as Havn, is the capital and largest city of the Faroe Islands. It is located in the southern part on the east coast of Streymoy. To the northwest of the city lies the mountain H\u00fasareyn, and to the southwest, the Kirkjub\u00f8reyn. They are separated by the Sand\u00e1 River. The city itself has a population of 14,223 (2024), and the greater urban area has a population of 22,444, including the suburbs of Hoyv%C3%ADk and Argir.\nThe Norse (Scandinavians) established their parliament on the Tinganes peninsula in AD 850. T\u00f3rshavn thus became the capital of the Faroe Islands and has remained so ever since. Early on, T\u00f3rshavn became the centre of the islands' trade monopoly, thereby being the only legal place for the islanders to sell and buy goods. In 1856, the trade monopoly was abolished and the islands were left open to free trade.\nHistory.\nEarly history.\nIt is not known whether the site of T\u00f3rshavn was of interest to the Irish monks who were probably the first settlers in the Faroes. However, there is absolutely no trace of Irish monks in the Faroe Islands, which is why it is doubtful whether this is anything more than a myth. The Viking settlers in the 9th century established their own parliaments, called \"tings\", in different parts of the islands, it being the tradition in each case to hold the \"ting\" at a neutral and thus uninhabited place, so no one location gave anyone an advantage. According to romantics, the main \"ting\" for the islands was convoked in T\u00f3rshavn in 825, on Tinganes, the peninsula that divides the harbour into two parts: \"Eystarav\u00e1g\" and \"Vestarav\u00e1g\".\nThe settlers would thus meet on the flat rocks of Tinganes every summer, as the most central place on the islands, although there was no settlement at Tinganes at that time. The F\u00e6reyinga Saga says: \"the place of the \"ting\" of the Faroese was on Streymoy, and there is the harbour that is called T\u00f3rshavn\". The Viking age ended in 1035. The \"ting\" was followed by a market which gradually grew into a permanent trading area.\nAll through the Middle Ages, the narrow peninsula jutting out into the sea made up the main part of T\u00f3rshavn. It belonged to the outfield of two farmers. Unlike other Faroese villages, T\u00f3rshavn was never a distinct farming community. During the 12th century, all trade between Norway and the Faroes, along with other tributary islands to the west, became centralised in Bergen.\nIn 1271, a royal trade monopoly was established in T\u00f3rshavn by the Norwegian Crown. According to a document from 1271, two ships would sail regularly to T\u00f3rshavn from Bergen with cargoes of salt, timber and cereal. T\u00f3rshavn therefore had more contact with the outside world than the other villages did. Under the Norwegian, and then Danish rule, government officials made T\u00f3rshavn their home. All of these things, combined with the fact that T\u00f3rshavn was the seat of the \"ting\" of the islands, influenced the town's development.\n1500\u20131800.\nSources do not mention a built-up area in T\u00f3rshavn until after the Protestant reformation in 1539. In c.\u20091580 a small fort, Skansin, was built by the Faroese naval hero and trader Magnus Heinason at the north end of the harbour. Later, small fortifications were built at Tinganes.\nIn 1584, T\u00f3rshavn had 101 inhabitants. The population was divided into three equally large groups made up of farmers, their families and servants, trade and government officials and people who owned no land and therefore not much else; this included the landless proletariat from the villages that during this period came to T\u00f3rshavn in search of work. They were set to guard duty on Skansin without pay, and for clothing and food they depended on the bounty of the farmers.\nIn 1655, king Frederick III of Denmark granted the Faroe Islands to his favourite statesman Kristoffer Gabel; the rule of the von Gabel Family (lasting between 1655 and 1709), is known as \"Gablat\u00ed\u00f0in\". It is the darkest chapter in the history of T\u00f3rshavn. Gabel's administration suppressed the islanders in various ways. The trade monopoly was in the family's hands and it was not designed for the needs of the Faroese people. People across the country brought products into town and had to be satisfied with whatever price they were given. At the same time, imported goods were limited and expensive. There came considerable complaints from the islands' inhabitants of unjust treatment by the civil administration in T\u00f3rshavn. These not only included the persons in charge of the monopoly trade, but also the bailiff and others. It was during this period, in 1673, that Tinganes was ravaged by a fire after a store of gunpowder kept at Tinganes had blown up. Many old houses burnt to the ground and old Faroese records were lost as were Gabel's documents.\nConditions improved in T\u00f3rshavn when the trade monopoly became a royal monopoly in 1709. The Danish royal trade monopoly was supplied with goods from Copenhagen three times a year. However, T\u00f3rshavn was hit by a plague of smallpox in 1709, killing nearly the entire population. The town had dissipated reached a population of 300 before the outbreak; 250 of the inhabitants died from the disease. Still, it was during the latter half of the 18th century that T\u00f3rshavn started to develop into a small town. This was while Niels Ryberg was in charge of the trade monopoly. From 1768 (and during the next 20 years onwards) Ryberg was allowed to carry on an entrepot trade which was mainly based on smuggling to England. Because of the French-British conflict there was room for this kind of operation. In T\u00f3rshavn his warehouses filled up with goods. Ryberg was the first person who thought of making a financial profit from fishing, which later became the most important economic factor to the islands. He experimented with salted cod and herring but at this point in time nothing much beyond this happened.\nT\u00f3rshavn Cathedral was first built in 1788 and partly rebuilt in 1865. Since 1990, it has been the seat of the Bishop of the Faroe Islands (in the Church of the Faroe Islands).\n1800\u2013present.\nOn 30 March 1808, during the Anglo-Danish Gunboat War, the entered T\u00f3rshavn and briefly captured the fort at Skansin. The fort surrendered without firing a shot as the landing party approached. The \"Clio\"'s men spiked the fort's eight 18-pounder guns and took all the smaller guns and weapons before leaving. Shortly after 6 May, a German privateer who had assumed the name \"Baron von Hompesch\" plundered the defenceless city and seized the property of the Danish Crown Monopoly. The Admiralty Prize Court, however, refused to condemn it as a lawful prize.\nIn 1856, free trade came to the Faroe Islands. By opening the islands to the world, it transformed the economy, with T\u00f3rshavn at its centre.\nIn 1866, T\u00f3rshavn's town council was founded. The town has been the capital of the Faroe Islands ever since. Later, in 1909, T\u00f3rshavn became a market town with the same municipal charter as Danish market towns. In 1913, the Danish Folketing granted DKK 810,000 to construction of a harbour in T\u00f3rshavn. Local waves are , the waters are ice free and have a tidal variation of , and storms from the west are mitigated by the gentle eastwards slope of the mountains. Other harbours were also benefitted with an 80% grant to a total build cost of DKK 1.6\u00a0million. In 1927, T\u00f3rshavn had a modern harbour built. This made it possible for larger ships to berth.\nDuring the British occupation of the Faroe Islands in World War II, Skansin was used as the headquarters of the Royal Navy Command, and two 5.5-inch guns used aboard before World War II were deployed.\nIn 1974, the neighbouring villages Hoyv\u00edk and Hv\u00edtanes were made part of the town area. Later, even more municipalities joined the T\u00f3rshavn municipality. In 1978 Kaldbak, in 1997 Argir, in 2001 Kollafj\u00f8r\u00f0ur, and finally in 2005, Kirkjub\u00f8ur, Hestur, and N\u00f3lsoy.\nClimate.\nT\u00f3rshavn features a subpolar oceanic climate (\"Cfc\"), with strong moderation from the Atlantic Ocean's Norwegian Current. In winter, T\u00f3rshavn tends to be under direct influence of the Icelandic Low, which usually brings overcast and stormy weather to the Faroe Islands. Because of its cloudiness and the ice-free water surrounding T\u00f3rshavn, its winter temperatures are exceptionally mild for such a northerly location, with winter daytime temperatures usually oscillating around . However, summer temperatures are much lower than those found in Scandinavia on similar latitudes, and barely exceed daily highs in the warmest month. The moderation also causes the extremes amplitude to be very low: in the period from 1961 to 2021, there was a mere difference between the absolute warmest and coldest temperatures. Temperatures below freezing may occur in any non-summer month, but even in winter, the average daily lows stay well above .\nAverage monthly precipitation is highest in autumn and winter, peaking in January, due to the activity of the Icelandic Low. May, June and July, on the other hand, are markedly drier but still receive substantial rainfall.\nPolitics and government.\nT\u00f3rshavn is the capital of the Faroe Islands, and as such is the seat of the Faroes\u2019 self rule government. The government holds the executive power in local government affairs. Today a part of the government is located on the Tinganes peninsula of T\u00f3rshavn. The Prime Minister's office is there and the Ministry of Internal Affairs was also there until it was closed in 2013. The other ministries are located in other office buildings in various places in T\u00f3rshavn, i.e. the Ministry of Health and the Ministry of Social Affairs are located near the Hospital of the Faroes in Eirargar\u00f0ur, and the Ministry of Finance is located in Argir in a building called Albert Hall on the street Kv\u00edggjart\u00fan. The parliament, the L\u00f8gting, which was originally located on Tinganes, was relocated to the town square, Vagli\u00f0, in 1856.\nSport.\nT\u00f3rshavn, as the capital city, is the centre of sport in the islands; the largest sports centre is located in the Gundadalur district of T\u00f3rshavn. Also, the largest football stadium, T\u00f3rsv\u00f8llur, is located here, seating 6,000 spectators. The stadium serves as home to the Faroe Islands national football team. Around the city there are also two other football pitches, indoor tennis courts, badminton courts and a swimming pool.\nThe city has several football clubs, including three Premier League teams: HB T\u00f3rshavn, B36 T\u00f3rshavn and Argja B\u00f3ltfelag. Other football clubs with connections to the city are FF Giza (N\u00f3lsoy), FC Hoyv\u00edk and Undri\u00f0 FF. Handball is the second most popular sport in T\u00f3rshavn. The city's handball teams are Kyndil, Neistin and \u00cdtr\u00f3ttafelagi\u00f0 H71 and the Faroe Island's national handball team practice in the city. T\u00f3rshavn city has several popular rowing clubs, including, Havnar R\u00f3\u00f0rarfelag and R\u00f3\u00f0rarfelagi\u00f0 Kn\u00f8rrur.\nEvery year in July the Tour of Faroe Islands, which is a road bicycle race, is held around the islands. The race, called \"Kring F\u00f8royar\" (Tour de Faroe / Around the Faroes), starts in Klaksv\u00edk and ends in T\u00f3rshavn.\nMusic.\nThe T\u00f3rshavn Jazz Festival has been held annually since 1983. It attracts musicians from all over North America and Europe and has become a popular tourist event.\nTransport.\nThe harbour is served by the Smyril Line international ferry service to Denmark and Iceland. The harbour is also used by domestic ferry services of Strandfaraskip Landsins within the Faroe Islands, chiefly on the route to Tv\u00f8royri.\nThe town is served by Busslei\u00f0in \u2013 a network of local buses, with the service identified by its red livery. Busslei\u00f0in has five routes and is operated under contract by Gundurs Bussar P/F. Buses within T\u00f3rshavn have been completely free of charge since 2007. In addition, there is a helipad by the coast.\nTwin cities.\nT\u00f3rshavn is twinned with:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43980", "revid": "12845131", "url": "https://en.wikipedia.org/wiki?curid=43980", "title": "Reading, Berkshire", "text": "Town and borough in Berkshire, England\nReading ( ) is a borough in Berkshire, England, and the county town of Berkshire. It is Berkshire's largest town, with a total built-up area population of 355,596. Most of its built-up area lies within the Borough of Reading, although some outer suburbs are parts of neighbouring local authority areas. It is located in the Thames Valley at the confluence of the rivers Thames and Kennet.\nReading is a major commercial centre, especially for information technology and insurance. It is also a regional retail centre, serving a large area of the Thames Valley with its shopping centres, including the Oracle, the Broad Street Mall, and the pedestrianised area around Broad Street. It is home to the University of Reading. Every year it hosts the Reading Festival, one of England's biggest music festivals. Reading has a professional association football team, Reading F.C., and participates in many other sports.\nReading dates from the 8th century. It was a trading and ecclesiastical centre in the Middle Ages, the site of Reading Abbey, one of the largest and richest monasteries of medieval England with royal connections, of which the 12th-century abbey gateway and significant ancient ruins remain. By 1525, Reading was the largest town in Berkshire, and tenth in England for taxable wealth. The town was seriously affected by the English Civil War, with a major siege and loss of trade, but played a pivotal role in the Glorious Revolution, whose only significant military action was fought on its streets. The 18th century saw the beginning of a major ironworks in the town and the growth of the brewing trade for which Reading was to become famous. The 19th century saw the coming of the Great Western Railway and the development of the town's brewing, baking and seed-growing businesses, and the town grew rapidly as a manufacturing centre.\nEtymology.\nThe earliest known name for Reading is \"Readingas\", from the 8th century. The name probably comes from the \"Readingas\", an Anglo-Saxon tribe whose name means \"Reada's People\" in Old English (the Anglo-Saxons often had the same name for a place and its inhabitants).\nThe demonym for a person from Reading is \"Redingensian\", giving the name of the local rugby team Redingensians, based in Sonning, and of former members of Reading School.\nHistory.\nOrigins.\nOccupation at the site of Reading may date back to the Roman period, possibly in the form of a trading port for Calleva Atrebatum. However, the first clear evidence for Reading as a settlement dates from the 8th century, when the town came to be known as \"Readingas\". In late 870, an army of Danes invaded the kingdom of Wessex and set up camp at Reading. On 4 January 871, in the first Battle of Reading, King Ethelred and his brother Alfred the Great attempted unsuccessfully to breach the Danes' defences. The battle is described in the \"Anglo-Saxon Chronicle\", and that account provides the earliest known written record of the existence of Reading. The Danes remained in Reading until late in 871, when they retreated to their winter quarters in London.\nAfter the Battle of Hastings and the Norman conquest of England, William the Conqueror gave land in and around Reading to his foundation of Battle Abbey. In its 1086 Domesday Book listing, the town was explicitly described as a borough. The presence of six mills is recorded: four on land belonging to the king and two on the land given to Battle Abbey. Reading Abbey was founded in 1121 by Henry I, who is buried within the Abbey grounds. As part of his endowments, he gave the abbey his lands in Reading, along with land at Cholsey.\nThe town grew around a crossing of the River Kennet, about upstream from its confluence with the River Thames. In 1312, King Edward II directed that its bridges should be kept in good order. It is not known how badly Reading was affected by the Black Death that swept through England in the 14th century, but it is known that the abbot, Henry of Appleford, was one of its victims in 1361, and that nearby Henley lost 60% of its population. The Abbey was largely destroyed in 1538 during Henry VIII's dissolution of the monasteries. The last abbot, Hugh Faringdon, was subsequently tried and convicted of high treason and hanged, drawn and quartered in front of the Abbey Church.\nBy 1525, Reading was the largest town in Berkshire and the tenth largest town in England when measured by taxable wealth reported in tax returns. By 1611, it had a population of over 5,000 and had grown rich on its trade in cloth, as instanced by the fortune made by local merchant John Kendrick. Reading played a role during the English Civil War. Despite its fortifications, it had a Royalist garrison imposed on it in 1642. The subsequent Siege of Reading by Parliamentary forces succeeded in April 1643. The town's cloth trade was especially badly damaged, and the town's economy did not fully recover until the 20th century. Reading played a significant role during the Glorious Revolution: the second Battle of Reading was the only substantial military action of the campaign.\nThe 18th century saw the beginning of a major iron works in the town and the growth of the brewing trade for which Reading was to become famous. Reading's trade benefited from better designed turnpike roads which helped it establish its location on the major coaching routes from London to Oxford and the West Country. In 1723, despite considerable local opposition, the Kennet Navigation opened the River Kennet to boats as far as Newbury. Opposition stopped when it became apparent that the new route benefited the town. After the opening of the Kennet and Avon Canal in 1810, one could go by barge from Reading to the Bristol Channel. From 1714, and probably earlier, the role of county town of Berkshire was shared between Reading and Abingdon. In the eighteenth and nineteenth centuries it was one of the southern termini of the Hatfield and Reading Turnpike that allowed travellers from the north to continue their journey to the west without going through the congestion of London.\nDuring the 19th century, the town grew rapidly as a manufacturing centre. The Great Western Railway arrived in 1841, followed by the South Eastern Railway in 1849 and the London and South Western Railway in 1856. After the Summer Assizes (courts of assize) were moved from Abingdon to Reading in 1867, the privy council made Reading the sole county town of Berkshire in 1869. The town became county borough under the Local Government Act 1888. In the 19th and 20th centuries, the town's three largest industries were known as the \"Three Bs\": beer (1785\u20132010, H &amp; G Simonds), bulbs (1837\u20131974, Suttons Seeds), and biscuits (1822\u20131976, Huntley and Palmers).\n20th century.\nThe town continued to expand in the 20th century, annexing Caversham across the River Thames in Oxfordshire in 1911, as well as most of Tilehurst to the west at the same time. Reading suffered much less physical damage than many other English towns and cities during the two world wars of the 20th century, although many citizens were killed or injured. In one significant air raid on 10 February 1943 a single Luftwaffe plane strafed and bombed the town centre, causing 41 deaths and over 100 injuries.\nThe Lower Earley development, begun in 1977, was one of the largest private housing developments in Europe, extending the urban area of Reading as far as the M4 Motorway. Further housing developments have increased the number of modern houses and hypermarkets in the outskirts of Reading. A major town-centre shopping centre, The Oracle, opened in 1999, is named after the 17th-century Oracle workhouse, which once occupied a small part of the site. It provides three storeys of shopping space and boosted the local economy by providing 4,000 jobs.\n21st century.\nAs one of the largest urban areas in the United Kingdom without city status, Reading has unsuccessfully bid for city status four times\u00a0\u2013 in 2000 to celebrate the new millennium; in 2002 to celebrate the Golden Jubilee of Queen Elizabeth II; in 2012 for the Diamond Jubilee; and in 2022 to mark the Platinum Jubilee.\nGovernance.\nLocal government for the borough is provided by Reading Borough Council, which has been a unitary authority providing all local government functions since 1998. There are no civil parishes in the borough. Some of the built-up area's outer suburbs are outside the borough boundaries in West Berkshire and Wokingham. These outer suburbs belong to civil parishes, in some cases with their own town status.\nReading has elected at least one Member of Parliament to every Parliament since 1295. Since the 2024 general election, the borough of Reading has been divided between the parliamentary constituencies of Reading Central, Reading West and Mid Berkshire (which also covers part of West Berkshire), and Earley and Woodley (which also covers part of the borough of Wokingham).\nReading is the site of venues for both the Crown Court, administering criminal justice, and the County Court, responsible for civil cases. Lesser matters are dealt with in a local magistrates' court.\nAdministrative history.\nReading was an ancient borough, being described as a borough by the time of the Domesday Book in 1086. The borough was initially controlled by Reading Abbey as its manorial owner. The town gradually gained a degree of independence from the abbey from the 13th century onwards, particularly after the town's gild merchants were granted a royal charter in 1253. Following the dissolution of the abbey in 1538 the borough was granted a new charter in 1542. The borough boundaries were then set out in a subsequent charter from Elizabeth I in 1560. The borough covered the whole of the parish of St Laurence and parts of the parishes of St Giles and St Mary. The part of St Giles' parish outside the borough was known as the hamlet of Whitley, and the part of St Mary's parish outside the borough was known as the tithing of Southcote.\nThe borough was reformed in 1836 to become a municipal borough under the Municipal Corporations Act 1835, which standardised how most boroughs operated across the country. The borough boundaries, which had not been changed since 1560, were enlarged in 1887 to take in Southcote, Whitley, the north-western parts of Earley, and the eastern end of the parish of Tilehurst. When elected county councils were established in 1889 under the Local Government Act 1888, Reading was considered large enough for its existing borough council to provide county-level services, and so Reading was made a county borough, independent from Berkshire County Council.\nThe borough boundaries were enlarged again in 1911 to take in Caversham on the north bank of the Thames from Oxfordshire (except the Caversham Park area, which was transferred to the parish of Eye and Dunsden), and most of the parish of Tilehurst (including the main village at Tilehurst Triangle and the area around the parish church at Churchend) to the west.\nLocal government was reformed in 1974 under the Local Government Act 1972, which saw Reading redesignated as a non-metropolitan district, with Berkshire County Council providing county-level services in the borough for the first time. Ahead of those reforms, the borough council campaigned to have Reading's boundaries enlarged to take in Earley, Woodley, Purley on Thames, the residual Tilehurst parish (covering the parts of Tilehurst which had not been transferred into the borough in 1911), and the eastern part of the parish of Theale. The government decided to make no change to Reading's boundaries, leaving them as they had been since last reviewed in 1911. Shortly after the 1974 reforms came into effect, a more limited review of the borough's boundaries north of the Thames was carried out, which saw the Caversham Park area and part of the parish of Mapledurham on the western side of Caversham transferred into the borough of Reading in 1977.\nThe borough council became a unitary authority in 1998, when the county council was abolished under the Banham Review, which saw the borough council take over county-level functions, effectively restoring the council to the powers it had held when Reading was a county borough prior to 1974. As part of those reforms, the Local Government Commission had initially recommended expanding Reading's boundaries to include Earley, Tilehurst parish, Purley on Thames and the parts of the parishes of Shinfield, Burghfield and Theale north of the M4 motorway, but it was ultimately decided to leave Reading's boundaries unchanged.\nReading's boundaries south of the Thames therefore have not changed since 1911, despite the urban area having now expanded well beyond the borough boundaries. Cross-boundary working between the borough council and the neighbouring councils which cover the suburban and adjoining rural areas is sometimes criticised, particularly over matters such as transport and school catchment areas.\nPrior to the 16th century, civic administration for the town of Reading was situated in the \"Yield Hall\", a guild hall situated by the River Kennet near today's Yield Hall Lane. After a brief stay in what later became Greyfriars Church, the town council created a new town hall by inserting an upper floor into the refectory of the Hospitium of St John, the former hospitium of Reading Abbey. For some 400 years up to the 1970s, this was to remain the site of Reading's civic administration through the successive rebuilds that eventually created today's Town Hall. In 1976, Reading Borough Council moved to the new Civic Centre. In 2014, they moved again to civic offices in a refurbished existing office building on Bridge Street, in order to facilitate the demolition and redevelopment of the previous site.\nGeography.\nReading is north of the English south coast, 40 miles west of London and 40 miles east of Swindon. The centre of Reading is on a low ridge between the River Thames and River Kennet, close to their confluence, reflecting the town's history as a river port. Just above the confluence, the Kennet cuts through a narrow steep-sided gap in the hills forming the southern flank of the Thames flood plain. The Kennet, which naturally divided into multiple shallow streams through the centre of Reading, was embanked as part of the construction of the Kennet and Avon Canal in the 18th century, allowing the development of wharves. The floodplains adjoining Reading's two rivers are subject to occasional flooding. Natural England divides Reading between its Chilterns (110) and Thames Valley (115) national character areas.\nAs Reading has grown, its suburbs have spread: to the west between the two rivers into the foothills of the Berkshire Downs as far as Calcot, Tilehurst and Purley; to the south and south-east on the south side of the River Kennet as far as Whitley Wood and Lower Earley and as far north of the Thames into the Chiltern Hills as far as Caversham Heights, Emmer Green and Caversham Park Village. Outside the central area, the floors of the valleys containing the two rivers remain largely unimproved floodplain. Apart from the M4 curving to the south there is only one road across the Kennet flood plain. All other routes between the three built-up areas are in the central area.\nClimate.\nLike the rest of the United Kingdom, Reading has a maritime climate, with limited seasonal temperature ranges and generally moderate rainfall throughout the year. The nearest official Met Office weather station is located at the Reading University Atmospheric Observatory on the Whiteknights Campus, which has recorded atmospheric measurements and meteorological observations since 1970. The local absolute maximum temperature of was recorded on 19 July 2022 and the local absolute minimum temperature of was recorded in January 1982.\nDemography.\nIn mid-2018, the area covered by the Borough of Reading had 182,907 inhabitants and a population density of . Meanwhile, the wider urban area had a population of 318,014 in the 2011 census, ranking 23rd in the United Kingdom. This grew to an estimated 337,108 by mid-2018. According to the 2011 census, 74.8% of the borough's population were described as White (65.3% White British), 9.1% as South Asian, 6.7% as Black, 3.9% Mixed, 4.5% as Chinese and 0.9% as other ethnic group. In 2010, it was reported that Reading had 150 different spoken languages within its population. Reading has a large Polish community, which dates back over 30 years, and in October 2006 the \"Reading Chronicle\" printed 5,000 copies of a Polish edition called the \"Kronika Reading\".\nEconomy.\nReading is a commercial centre in the Thames Valley and Southern England. The town hosts the headquarters of several British companies and the United Kingdom offices of foreign multinationals, as well as being a major retail centre. Whilst located close enough to London to be sometimes regarded as part of the London commuter belt, Reading is a net inward destination for commuters. During the morning peak period, there are some 30,000 inward arrivals in the town, compared to 24,000 departures. Major companies Microsoft, Oracle and Hibu (formerly Yell Group) have their headquarters in the Reading area. The insurance company Prudential has an administration centre in the town. PepsiCo and Wrigley also have offices in the town.\nGlobal pharmaceutical giant Bayer Life Sciences relocated to Reading's Green Park Business Park in 2016. Reading has a significant historical involvement in the information technology industry, largely as a result of the early presence in the town of sites of International Computers Limited and Digital Equipment Corporation. Other technology companies with a significant presence in the town include Huawei Technologies, Pegasystems, Access IS, CGI Inc., Agilent Technologies, Cisco, Ericsson, Symantec, Verizon Business, and Commvault. These companies are distributed around Reading or just outside the borough boundary, some in business parks including Thames Valley Park in nearby Earley, Green Park Business Park and Arlington Business Park.\nReading town centre is a major shopping centre. In 2007, an independent poll placed Reading 16th in a league table of best performing retail centres in the United Kingdom. The main shopping street is Broad Street, which runs between The Oracle in the east and Broad Street Mall in the west and was pedestrianised in 1995. The smaller Friars Walk in Friar Street is closed and will be demolished if the proposed Station Hill redevelopment project goes ahead. There are three major department stores in Reading: John Lewis &amp; Partners (known as \"Heelas\" until 2001), Debenhams (now closed down), and House of Fraser (also now closed down). The Broad Street branch of bookseller Waterstone's is a conversion of a nonconformist chapel dating from 1707. Besides the two major shopping malls, Reading has three smaller shopping arcades, the Bristol and West Arcade, Harris Arcade and The Walk, which contain smaller specialist stores. An older form of retail facility is represented by Union Street, popularly known as \"Smelly Alley\". Reading has no indoor market, but there is a street market in Hosier Street. A farmers' market operates on two Saturdays a month. The old Victorian Corn Exchange now provides an alternative access to a shopping centre.\nCulture.\nFestivals.\nEvery year Reading hosts the Reading Festival, which has been running since 1971. The festival takes place on the Friday, Saturday and Sunday of the August bank holiday weekend and is the largest of its kind in the United Kingdom aside from the Glastonbury Festival. Reading Festival takes place at Little Johns Farm in Reading, Richfield Avenue. For some twenty years until 2006, Reading was also known for its WOMAD Festival until it moved to Charlton Park in Malmesbury, Wiltshire.\nThe Reading Beer Festival was first held in 1994 and has now grown to one of the largest beer festivals in the United Kingdom. It is held at King's Meadow for the five days immediately preceding the May Day bank holiday every year. Reading also holds Reading Pride, an annual LGBT festival in Kings Meadow.\nVenues.\nThe Frank Matcham-designed Royal County Theatre, built in 1895, was located on the south side of Friar Street. It burned down in 1937. Within the town hall is a 700-seat concert hall that houses a Father Willis organ. Reading theatre venues include The Hexagon and South Street Arts Centre. Reading Repertory Theatre is based at Reading College: its Royal Patron is Prince Edward, Duke of Edinburgh.\nAmateur theatre venues in Reading include Progress Theatre, a self-governing, self-funding theatre group and registered charity founded in 1947 that operates and maintains its own 97-seat theatre. Rabble Theatre in Caversham and Reading Rep on London Road offer classic and contemporary performances. Jelly is an artist-led organisation that has been committed to improving access to the arts since 1993.\nCultural references.\nJane Austen attended Reading Ladies Boarding School, based in the Abbey Gateway, in 1784\u20131786. Mary Russell Mitford lived in Reading for a number of years and then spent the rest of her life just outside the town at Three Mile Cross and Swallowfield. The fictional \"Belford Regis\" of her eponymous novel, first published in 1835, is largely based on Reading. Described with topographical accuracy, it is still possible to follow the steps of the novel's characters in present-day Reading. Reading also appears in the works of Thomas Hardy where it is called 'Aldbrickham'. It features most heavily in his final novel, Jude the Obscure, as the temporary home of Jude Fawley and Sue Bridehead.\nOscar Wilde was imprisoned in Reading Gaol from 1895 to 1897. While there, he wrote his letter \"De Profundis\". After his release, he lived in exile in France and wrote \"The Ballad of Reading Gaol\", based on his experience of the execution of Charles Wooldridge, carried out in Reading Gaol whilst he was imprisoned there. In March 2021, street artist Banksy claimed responsibility for a painting on the wall of the jail. It depicted an inmate escaping with bedsheets and a typewriter, said to resemble Oscar Wilde.\nReading was the location of the world's first commercial studio for photograph printing, which was set up by William Henry Fox Talbot in 1844.\nRicky Gervais, who is from Reading, made the film \"Cemetery Junction\", which, although filmed elsewhere in the United Kingdom, is set in 1970s Reading and is named after a busy junction in East Reading. Jasper Fforde's Nursery Crimes Division novels, \"The Big Over Easy\" and \"The Fourth Bear\", are also placed in Reading. The BBC Two sitcom \"Beautiful People\", based on the memoirs of Simon Doonan, is set in Reading in the late 1990s.\nLandmarks.\nThe \"Maiwand Lion\" in Forbury Gardens, an unofficial symbol of Reading, commemorates the 328 officers of the Royal Berkshire Regiment who died in the Battle of Maiwand in 1880. There are a number of other works of public art in Reading. The Blade, a fourteen-storey building completed in 2009, is tall and can be seen from the surrounding area. Jacksons Corner with its prominent sign, former home of Jacksons department store, occupies the corner of Kings Road and High Street, just south of the Market Place.\nReading has two scheduled monuments, six Grade I, 22 Grade II* and 853 Grade II listed buildings, in a wide variety of architectural styles that range from the medieval to the 21st century. The scheduled monuments are Reading Abbey and High Bridge, whilst the Grade I listed buildings are Reading Abbey, the Abbey Gateway, Greyfriars Church, St Laurence's Church, Reading Minster, and the barn at Chazey Farmhouse on the Warren.\nMedia.\nReading has a local newspaper, the \"Reading Chronicle\", published on Thursdays. The town's other local newspaper, the \"Reading Post\", ceased publication on paper in December 2014, in order to transition to an online only format under the title \"getreading\". As of 2018, \"getreading\" joined the InYourArea local news network. A local publishing company, the Two Rivers Press, has published over 70 book titles, many on the topic of local history and art. Three local radio stations broadcast from Reading: BBC Radio Berkshire, Heart South and Greatest Hits Radio Berkshire and North Hampshire. Local news and television programmes are provided by BBC South and ITV Meridian, BBC London &amp; ITV London can also be received. Reading has one local television station, That's Thames Valley, which broadcasts local news throughout the Greater Reading area.\nPublic services.\nParks and open spaces.\nReading has over 100 parks and playgrounds, including of riverside paths. In the town centre is Forbury Gardens, a public park built on the site of the outer court of Reading Abbey. The largest public park in Reading is Prospect Park, an estate in west Reading previously owned by Frances Kendrick but acquired by Reading Corporation in 1901. This is complemented by Palmer Park, a purpose built public park in east Reading gifted to the town by the proprietors of Huntley &amp; Palmers in 1889.\nA string of open spaces stretch along one or other side of the River Thames throughout its passage through Reading. From west to east these are Thameside Promenade, Caversham Court, Christchurch Meadows, Hills Meadow, View Island and King's Meadow. Reading also has five local nature reserves: Clayfield Copse in Caversham, with the other four McIlroy Park, Blundells Copse, Lousehill Copse and Round Copse all in Tilehurst\nHealthcare.\nThe principal National Health Service (NHS) hospital in Reading is the Royal Berkshire Hospital, founded in 1839 and much enlarged and rebuilt since. A second major NHS general hospital, the Battle Hospital, closed in 2005. Berkshire Healthcare NHS Foundation Trust runs a NHS hospital, Prospect Park Hospital, which specialises in the provision of care for people with mental health and learning disabilities. Reading has three private hospitals: the Berkshire Independent Hospital in Coley Park, the Dunedin Hospital situated on the main A4 Bath Road, and the Circle Hospital at Kennet Island.\nUtilities.\nMains water and sewerage services are provided by Thames Water Utilities Limited, a private sector water supply company, whilst water abstraction and disposal is regulated by the Environment Agency. Reading's water supply is largely derived from underground aquifers, and as a consequence the water is hard.\nThe commercial energy supplier for electricity and gas is at the consumer's choice. SSEN runs the local electricity distribution network, while SGN runs the gas distribution network. A notable part of the local energy infrastructure is the presence of a 2 megawatt (peak) Enercon wind turbine at Green Park Business Park, with the potential to produce 2.7\u00a0million kWh of electricity a year, enough to power over a thousand homes. Additionally, Reading Hydro runs a micro hydroelectric power station on the Thames. Reading had its own power station in Vastern Road from 1895 to the 1960s. The power station was initially owned and operated by the Reading Electric Supply Company Limited, then from 1933 by the Reading Corporation until the nationalisation of the British electricity supply industry in 1948.\nThe dialling code for fixed-line telephones in Reading is 0118. BT provides fixed-line telephone coverage throughout the town and ADSL broadband internet connection to most areas. Parts of Reading are cabled by Virgin Media, supplying cable television, telephone and broadband internet connections. Hyperoptic also has a presence in the town, supplying Fibre-to-the-Premises (FTTP) broadband internet connections at speeds of up to 1\u00a0Gbit/s.\nEducation.\nReading School (a state grammar school), founded in 1125, is the 16th oldest school in England. There are six other state secondary schools and 38 state primary schools within the borough, together with a number of private schools and nurseries. Alfred Sutton Boys' School closed in the mid-1980s. Reading College has provided further education in Reading since 1955, with over 8,500 local learners on over 900 courses. English language schools in Reading include Gateway Languages, the English Language Centre, ELC London Street and Eurospeak Language School.\nThe University of Reading was established in 1892 as an affiliate of Oxford University. It moved to its London Road Campus in 1904 and to its new Whiteknights Campus in 1947. It took over the Bulmershe College of Higher Education, a teacher training college, in 1989, becoming Bulmershe Court Campus. The Henley Management College, situated in Buckinghamshire and about from Reading, was taken over in 2008, becoming Greenlands Campus. The University of West London maintains a presence in the town for its higher education students, principally in nursing, but has now divested itself of its previous ownership of Reading College and its further education students.\nLibraries and museums.\nThe Reading Borough Libraries service dates back to 1877. Initially housed in Reading Town Hall, the central branch of the library was relocated to a new building on King's Road in 1985.\nThe Reading Museum opened in 1883 in the town's municipal buildings. It contains galleries relating to the history of Reading and to the excavations of Calleva Atrebatum, together with a full-size bowdlerised replica of the Bayeux Tapestry, an art collection, and galleries relating to Huntley and Palmers. The Museum of English Rural Life, in East Reading, is a museum dedicated to recording the changing face of farming and the countryside in England. It houses designated collections of national importance. It is owned and run by the University of Reading, as are the Ure Museum of Greek Archaeology, the Cole Museum of Zoology and the Harris Botanic Gardens, all of which can be found on the university's Whiteknights Campus. The small Riverside Museum at Blake's Lock tells the story of Reading's two rivers. The Museum of Berkshire Aviation has a collection of aircraft and other artefacts relating to the aircraft industry in the town.\nTransport.\nReading's location in the Thames Valley to the west of London has made the town a significant element in the nation's transport system.\nRiver.\nThe town grew up as a river port at the confluence of the River Thames and the River Kennet. Both of these rivers are navigable, and Caversham Lock, Blake's Lock, County Lock, Fobney Lock and Southcote Lock are all within the borough. Today, navigation is predominantly for purposes of leisure: private and hire boats dominate traffic, while scheduled boat services operate on the Thames from wharves on the Reading side of the river near Caversham Bridge.\nRoad.\nReading was a major staging point on the old Bath Road (A4) from London to Avonmouth near Bristol. This road still carries local traffic, but has now been replaced for long-distance traffic by the M4 motorway, which closely skirts the borough and serves it with three junctions, J10-J12. Other main roads serving Reading include the A33, A327, A329, A4074 and A4155. Within Reading there is the Inner Distribution Road (IDR), a ring road for local traffic. The IDR is linked with the M4 by the A33 relief road. The Thames is crossed by both Reading and Caversham road bridges, while several road bridges cross the Kennet, the oldest surviving one of which is High Bridge.\nReading has two operational park and ride sites. Mereoak, a short distance south of Junction 11 of the M4, is also a stop for National Express Coaches between London and the West. A site outside the Winnersh Triangle railway station opened in 2015 and is easily accessed from the junction where the A329(M) becomes the A3290.\nRail.\nReading is a major junction point of the National Rail system, and hence Reading station is a transfer point and terminus. In a project that finished in 2015, Reading station was redeveloped at a cost of \u00a3850m, with grade separation of some conflicting traffic flows, and extra platforms, to relieve severe congestion at this station. Railway lines link Reading to both Paddington and Waterloo stations in London. Other stations in the Reading area are Reading West, Reading Green Park, Tilehurst and Earley.\nReading is a western terminus of the Elizabeth line, which provides stopping services to London Paddington, and means Reading is featured on the London Tube map. Cross-London connections are possible from Reading to Abbey Wood and Shenfield in the east.\nAir.\nThere have been two airfields in or near Reading, one at Coley Park and one at Woodley, but they have both closed. The nearest international airport is London Heathrow, away. An express bus service named RailAir links Reading with Heathrow, or the airport can be accessed by rail by taking the Elizabeth line to Hayes &amp; Harlington and changing for a connecting service to Heathrow. This journey takes around 45 minutes by rail. London City Airport can be reached via a direct train to Custom House on the Elizabeth line followed by a short bus connection. Gatwick Airport can be accessed via a direct local train operating via Guildford, and Luton and Stansted airports can be accessed with one change in Central London. Further afield, Southampton Airport can be accessed directly by rail in around 50\u201370 minutes depending on the service, or reached by road in approximately the same timeframe.\nPublic transport.\nToday local public transport is largely by road, which is often affected by peak hour congestion in the borough. A frequent local bus network within the borough, and a less frequent network in the surrounding area, are provided by Reading Buses - one of the few remaining municipal bus companies in the country - and its subsidiaries Newbury &amp; District and Thames Valley Buses. Other bus operators serving Reading include Carousel Buses, Thames Travel and RedRose. ReadiBus provides an on-demand transport service for people with restricted mobility in the area.\nBike sharing.\nIn March 2011, Reading Borough Council approved a bike sharing scheme similar to London Cycle Hire Scheme, with 1,000 bicycles available at up to 150 docking stations across Reading. However this scheme came to an end in March 2019, with the operator unable to cover the operational costs or find a sponsor to do so.\nReligion.\nReading Minster (the Minster Church of St Mary the Virgin) is Reading's oldest ecclesiastical foundation, known to have been founded by the 9th century and possibly earlier. Although eclipsed in importance by the later abbey, Reading Minster has regained its importance since the destruction of the abbey. Reading Abbey was founded by Henry I in 1121. He was buried there, as were parts of his daughter Empress Matilda, William of Poitiers, Constance of York, and Princess Isabella of Cornwall, among others. The abbey was one of the pilgrimage centres of medieval England; it held over 230 relics including the hand of St. James. Today all that remains of the abbey are the inner rubble cores of the walls of many of the major buildings of the abbey, together with a much restored inner gateway and the intact hospitium.\nThe medieval borough of Reading was served by three parish churches: Reading Minster, St Giles' Church, and St Laurence's Church. All are still in use by the Church of England. The Franciscan friars built a friary in the town in 1311. After the friars were expelled in 1538, the building was used as a hospital, a poorhouse, and a jail, before being restored as the Church of England parish church of Greyfriars Church in 1863. The Bishop of Reading is a suffragan bishop within the Church of England's Diocese of Oxford. The bishop is based in Reading, and is responsible for the archdeaconry of Berkshire. There are a total of 18 Church of England parish churches in Reading.\nSt James's Church was built on a portion of the site of the abbey between 1837 and 1840, and marked the return of the Roman Catholic faith to Reading. Reading was also the site of the death of Blessed Dominic Barberi, the Catholic missionary to England in the 19th century who received John Henry Newman into the Catholic faith. There are now eight Roman Catholic parish churches in Reading. Kings Road Baptist Church was founded in Reading in 1640 or 1641. In addition to Catholicism and the Church of England, the Seventh-Day Adventist denomination is also represented in the town, particularly by Reading West SDA Church on Loverock Road, Reading Central SDA Church on Tilehurst Road, and various other churches around Reading.\nReading has had an organised Jewish community since 1886. At least one Jewish family living in the area has been traced back as far as 1842. The group grew to 13 families, who in 1886 declared themselves a community and commenced building a synagogue. On 31 October 1900, Reading Hebrew Congregation officially opened in a solemn public ceremony, packed to capacity with dignitaries, led by the Chief Rabbi Hermann Adler. Reading Hebrew Congregation, which still stands on its original site at the junction of Goldsmid Road and Clifton Street near the town centre, is a Grade II-listed building, built to a traditional design in the Moorish style. The community is affiliated with the Orthodox United Hebrew Congregations of the Commonwealth. Reading also has a Liberal Jewish community which convenes in the Reading Quaker Meeting House, a Modern Orthodox Judaism community, an active Jewish Society for students at the university, as well as being served by a Reform Jewish community which convenes in nearby Maidenhead Synagogue.\nThere are presently three mosques in Reading, initially just having the Central Reading Mosque on Waylen Street. The \u00a33\u20134m Abu Bakr Islamic Centre, on Oxford Road in West Reading, was granted planning permission in 2002. The community-funded project began construction in 2007, and opened its doors in July 2013 - the holy month of Ramadan for this year. A second Islamic centre in eastern Reading has also been granted planning permission. This \u00a34m project has garnered some controversy. Reading also has places of worship of other religions: the Shantideva Mahayana Buddhist centre, a Hindu temple, a Sikh gurdwara, a Salvation Army citadel, a Quaker meeting house, and a Christadelphian Hall.\nSport.\nFootball.\nReading is the home of Reading Football Club, an association football club nicknamed \"The Royals\", formed in 1871. Formerly nicknamed 'The Biscuitmen' and based at Elm Park, the club plays at the 24,161 capacity Select Car Leasing Stadium, first named after chairman Sir John Madejski which opened in 1998, and later renamed \"Select Car Leasing Stadium\" in 2021, after a sponsor. After winning the 2005\u201306 Football League Championship with a record of 106 points, Reading spent two seasons in the Premier League before being relegated to The Championship. For the 2012\u20132013 season, the club again competed in the Premier League, after securing first place in the Championship in the 2011\u20132012 season, but were relegated back down to the Championship at season's end. Reading Town Football Club, formed in 1966, played at Scours Lane and were playing in the Hellenic League Premier Division but were dissolved in 2016, while fellow non-league football club Reading City Football Club now play at Scours Lane after moving from Palmer Park Stadium at the end of the 2015\u201316 season. Scours Lane was also renamed to Rivermoor Stadium in 2016.\nOther Sports.\nReading is home to three senior semi-professional rugby clubs: Reading Abbey RFC, Rams RFC and Reading RFC. The Reading Rockets are the town's semi-professional basketball team. They compete in the second tier English Basketball League Division 1, though they have tried several times in recent years to move up to the top tier British Basketball League. They play home games at Loddon Valley Leisure Centre, and are coached by Samit Nuruzade. In 2016\u201317 the club embarked on an 18-game winning streak. During the 24-25 Season, They were able to win 3 out of the 4 available Domestic Trophies. The town hosts Australian Rules football team Reading Kangaroos and American football team Berkshire Renegades. Palmer Park Stadium has a velodrome and athletics track. It is used by Reading Athletic Club and the Berkshire Renegades for training. Reading Hockey Club enter teams in both the Men's and Women's England Hockey Leagues.\nRowing is pursued by the Reading Rowing Club and the Reading University Boat Club, both next to Caversham Bridge, whilst Reading Blue Coat School trains at Sonning adjacent to the Redgrave Pinsent Rowing Lake in Caversham, which provides training facilities for the Great Britain National Squad. However, almost all club rowing is done on the River Thames. The annual Reading Town Regatta takes place near Thames Valley Park, with the Reading Amateur Regatta taking place in June, usually two weeks before the Henley Royal Regatta. The town was home to a motorcycle speedway team, Reading Racers. Speedway came to Reading in 1968 at Tilehurst Stadium, until the team moved to Smallmead Stadium in Whitley, which was demolished at the end of 2008. The team is inactive pending the building of a new stadium, which was once hoped to be completed in 2012. The Reading Racers reformed in 2016 and joined the new Southern Developmental League upon its formation in 2017 winning its inaugural season undefeated. The team started back up in Eastbourne and currently races in Swindon awaiting return to a track in Reading.\nThe Reading Half Marathon is held on the streets of Reading in March of each year, with 16,000 competitors from elite to fun runners. It was first run in 1983 and has taken place in every subsequent year except 2001, when it was cancelled because of concerns over that year's outbreak of foot-and-mouth disease, 2018, when it was cancelled on the morning of the race due to heavy overnight snowfall, and 2020, when it was cancelled due to the COVID-19 pandemic. The British Triathlon Association was formed at the town's former \"Mall\" health club on 11 December 1982. Britain's first ever triathlon took place just outside Reading at Kirtons's Farm in Pingewood in 1983 and was revived 10 years' later by Banana Leisure with one of the original organisers as Event Director. Thames Valley Triathletes, based in the town, is Britain's oldest triathlon club, having its origins in the 1984 event at nearby Heckfield, when a relay team raced under the name \"Reading Triathlon Club\". The Hexagon was home to snooker's Grand Prix tournament, one of the sport's \"Big Four\", from 1984 to 1994.\nTwin towns.\nReading is twinned with:\nThough not twinned with Reading, two suburbs of the New Zealand city of Dunedin \u2014\u00a0Caversham and Forbury \u2014 were named after places in and around Reading by early New Zealand settler and Reading native William Henry Valpy.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "43982", "revid": "2051880", "url": "https://en.wikipedia.org/wiki?curid=43982", "title": "Plumbing", "text": "Systems for conveying fluids\nPlumbing is any system that conveys fluids for a wide range of applications. Plumbing uses pipes, valves, plumbing fixtures, tanks, and other apparatuses to convey fluids. Heating and cooling (HVAC), waste removal, and potable water delivery are among the most common uses for plumbing, but it is not limited to these applications. The word derives from the Latin for lead, \"plumbum\", as the first effective pipes used in the Roman era were lead pipes.\nIn the developed world, plumbing infrastructure is critical to public health and sanitation.\nBoilermakers and pipefitters are not plumbers although they work with piping as part of their trade and their work can include some plumbing.\nHistory.\nPlumbing originated during ancient civilizations, as they developed public baths and needed to provide potable water and wastewater removal for larger numbers of people.\nThe Mesopotamians introduced the world to clay sewer pipes around 4000 BCE, with the earliest examples found in the Temple of Bel at Nippur and at Eshnunna, used to remove wastewater from sites, and capture rainwater, in wells. The city of Uruk contains the oldest known examples of brick constructed Latrines, constructed atop interconnecting fired clay sewer pipes, c.\u20093200 BCE. Clay pipes were later used in the Hittite city of Hattusa. They had easily detachable and replaceable segments, and allowed for cleaning.\nStandardized earthen plumbing pipes with broad flanges making use of asphalt for preventing leakages appeared in the urban settlements of the Indus Valley civilization by 2700 BC.\nCopper piping appeared in Egypt by 2400 BCE, with the Pyramid of Sahure and adjoining temple complex at Abusir, found to be connected by a copper waste pipe.\nThe word \"plumber\" dates from the Roman Empire. The Latin for lead is \"\". Roman roofs used lead in conduits and drain pipes and some were also covered with lead. Lead was also used for piping and for making baths.\nPlumbing reached its early apex in ancient Rome, which saw the introduction of expansive systems of aqueducts, tile wastewater removal, and widespread use of lead pipes. The Romans used lead pipe inscriptions to prevent water theft. With the Fall of Rome both water supply and sanitation stagnated\u2014or regressed\u2014for well over 1,000 years. Improvement was very slow, with little effective progress made until the growth of modern densely populated cities in the 1800s. During this period, public health authorities began pressing for better waste disposal systems to be installed, to prevent or control epidemics of disease. Earlier, the waste disposal system had consisted of collecting waste and dumping it on the ground or into a river. Eventually the development of separate, underground water and sewage systems eliminated open sewage ditches and cesspools.\nIn post-classical Kilwa the wealthy enjoyed indoor plumbing in their stone homes.\nMost large cities today pipe solid wastes to sewage treatment plants in order to separate and partially purify the water, before emptying into streams or other bodies of water. For potable water use, galvanized iron piping was commonplace in the United States from the late 1800s until around 1960. After that period, copper piping took over, first soft copper with flared fittings, then with rigid copper tubing using soldered fittings.\nThe use of lead for potable water declined sharply after World War II because of increased awareness of the dangers of lead poisoning. At this time, copper piping was introduced as a better and safer alternative to lead pipes.\nSystems.\nThe major categories of plumbing systems or subsystems are:\nWater pipes.\nA \"water pipe\" is a pipe or tube, frequently made of plastic or metal, that carries pressurized and treated fresh water to a building (as part of a municipal water system), as well as inside the building.\nHistory.\nLead was the favoured material for water pipes for many centuries because its malleability made it practical to work into the desired shape. Such use was so common that the word \"plumbing\" derives from \"plumbum\", the Latin word for lead. This was a source of lead-related health problems in the years before the health hazards of ingesting lead were fully understood; among these were stillbirths and high rates of infant mortality. Lead water pipes were still widely used in the early 20th century and remain in many households. Lead-tin alloy solder was commonly used to join copper pipes, but modern practice uses tin-antimony alloy solder instead in order to eliminate lead hazards.\nDespite the Romans' common use of lead pipes, their aqueducts rarely poisoned people. Unlike other parts of the world where lead pipes cause poisoning, the Roman water had so much calcium in it that a layer of plaque prevented the water contacting the lead itself. What often causes confusion is the large amount of evidence of widespread lead poisoning, particularly amongst those who would have had easy access to piped water, an unfortunate result of lead being used in cookware and as an additive to processed food and drink (for example as a preservative in wine). Roman lead pipe inscriptions provided information on the owner to prevent water theft.\nWooden pipes were used in London and elsewhere during the 16th and 17th centuries. The pipes were hollowed-out logs which were tapered at the end with a small hole in which the water would pass through. The multiple pipes were then sealed together with hot animal fat. Wooden pipes were used in Philadelphia, Boston, and Montreal in the 1800s. Built-up wooden tubes were widely used in the US during the 20th century. These pipes (used in place of corrugated iron or reinforced concrete pipes) were made of sections cut from short lengths of wood. Locking of adjacent rings with hardwood dowel pins produced a flexible structure. About 100,000 feet of these wooden pipes were installed during WW2 in drainage culverts, storm sewers and conduits, under highways and at army camps, naval stations, airfields and ordnance plants.\nCast iron and ductile iron pipe was long a lower-cost alternative to copper before the advent of durable plastic materials but special non-conductive fittings must be used where transitions are to be made to other metallic pipes (except for terminal fittings) in order to avoid corrosion owing to electrochemical reactions between dissimilar metals (see galvanic cell).\nBronze fittings and short pipe segments are commonly used in combination with various materials.\nDifference between pipes and tubes.\nThe difference between pipes and tubes is a matter of sizing. For instance, PVC pipe for plumbing applications and galvanized steel pipe are measured in iron pipe size (IPS). Copper tube, CPVC, PeX and other tubing is measured nominally, basically an average diameter. These sizing schemes allow for universal adaptation of transitional fittings. For instance, 1/2\" PeX tubing is the same size as 1/2\" copper tubing. 1/2\" PVC on the other hand is not the same size as 1/2\" tubing, and therefore requires either a threaded male or female adapter to connect them. When used in agricultural irrigation, the singular form \"pipe\" is often used as a plural.\nPipe is available in rigid \"joints\", which come in various lengths depending on the material. Tubing, in particular copper, comes in rigid hard tempered joints or soft tempered (annealed) rolls. PeX and CPVC tubing also comes in rigid joints or flexible rolls. The temper of the copper, whether it is a rigid joint or flexible roll, does not affect the sizing.\nThe thicknesses of the water pipe and tube walls can vary. Because piping and tubing are commodities, having a greater wall thickness implies higher initial cost. Thicker walled pipe generally implies greater durability and higher pressure tolerances. Pipe wall thickness is denoted by various schedules or for large bore polyethylene pipe in the UK by the Standard Dimension Ratio (SDR), defined as the ratio of the pipe diameter to its wall thickness. Pipe wall thickness increases with schedule, and is available in schedules 20, 40, 80, and higher in special cases. The schedule is largely determined by the operating pressure of the system, with higher pressures commanding greater thickness. Copper tubing is available in four wall thicknesses: type DWV (thinnest wall; only allowed as drain pipe per UPC), type 'M' (thin; typically only allowed as drain pipe by IPC code), type 'L' (thicker, standard duty for water lines and water service), and type 'K' (thickest, typically used underground between the main and the meter).\nWall thickness does not affect pipe or tubing size. 1/2\" L copper has the same outer diameter as 1/2\" K or M copper. The same applies to pipe schedules. As a result, a slight increase in pressure losses is realized due to a decrease in flowpath as wall thickness is increased. In other words, 1 foot of 1/2\" L copper has slightly less volume than 1 foot of 1/2 M copper.\nMaterials.\nWater systems of ancient times relied on gravity for the supply of water, using pipes or channels usually made of clay, lead, bamboo, wood, or stone. Hollowed wooden logs wrapped in steel banding were used for plumbing pipes, particularly water mains. Logs were used for water distribution in England close to 500 years ago. US cities began using hollowed logs in the late 1700s through the 1800s. Today, most plumbing supply pipe is made out of steel, copper, and plastic; most waste (also known as \"soil\") out of steel, copper, plastic, and cast iron.\nThe straight sections of plumbing systems are called \"pipes\" or \"tubes\". A pipe is typically formed via casting or welding, whereas a tube is made through extrusion. Pipe normally has thicker walls and may be threaded or welded, while tubing is thinner-walled and requires special joining techniques such as brazing, compression fitting, crimping, or for plastics, solvent welding. These joining techniques are discussed in more detail in the piping and plumbing fittings article.\nSteel.\nGalvanized steel potable water supply and distribution pipes are commonly found with nominal pipe sizes from to . It is rarely used today for new construction residential plumbing. Steel pipe has National Pipe Thread (NPT) standard tapered male threads, which connect with female tapered threads on elbows, tees, couplers, valves, and other fittings. Galvanized steel (often known simply as \"galv\" or \"iron\" in the plumbing trade) is relatively expensive, and difficult to work with due to weight and requirement of a pipe threader. It remains in common use for repair of existing \"galv\" systems and to satisfy building code non-combustibility requirements typically found in hotels, apartment buildings and other commercial applications. It is also extremely durable and resistant to mechanical abuse. Black lacquered steel pipe is the most widely used pipe material for fire sprinklers and natural gas.\nMost typical single family home systems will not require supply piping larger than due to expense as well as steel piping's tendency to become obstructed from internal rusting and mineral deposits forming on the inside of the pipe over time once the internal galvanizing zinc coating has degraded. In potable water distribution service, galvanized steel pipe has a service life of about 30 to 50 years, although it is not uncommon for it to be less in geographic areas with corrosive water contaminants.\nCopper.\nCopper pipe and tubing was widely used for domestic water systems in the latter half of the twentieth century. Demand for copper products has fallen due to the dramatic increase in the price of copper, resulting in increased demand for alternative products including PEX and stainless steel.\nPlastic.\nPlastic pipe is in wide use for domestic water supply and drain-waste-vent (DWV) pipe. Principal types include:\nPolyvinyl chloride (PVC) was produced experimentally in the 19th century but did not become practical to manufacture until 1926, when Waldo Semon of BF Goodrich Co. developed a method to plasticize PVC, making it easier to process. PVC pipe began to be manufactured in the 1940s and was in wide use for Drain-Waste-Vent piping during the reconstruction of Germany and Japan following WWII. In the 1950s, plastics manufacturers in Western Europe and Japan began producing acrylonitrile butadiene styrene (ABS) pipe. The method for producing cross-linked polyethylene (PEX) was also developed in the 1950s. Plastic supply pipes have become increasingly common, with a variety of materials and fittings employed.\nPresent-day water-supply systems use a network of high-pressure pumps, and pipes in buildings are now made of copper, brass, plastic (particularly cross-linked polyethylene called PEX, which is estimated to be used in 60% of single-family homes), or other nontoxic material. Due to its toxicity, most cities moved away from lead water-supply piping by the 1920s in the United States, although lead pipes were approved by national plumbing codes into the 1980s, and lead was used in plumbing solder for drinking water until it was banned in 1986. Drain and vent lines are made of plastic, steel, cast iron, or lead.\nComponents.\nIn addition to lengths of pipe or tubing, pipe fittings such as valves, elbows, tees, and unions. are used in plumbing systems. Pipe and fittings are held in place with pipe hangers and strapping.\nPlumbing fixtures are exchangeable devices that use water and can be connected to a building's plumbing system. They are considered to be \"fixtures\", in that they are semi-permanent parts of buildings, not usually owned or maintained separately. Plumbing fixtures are seen by and designed for the end-users. Some examples of fixtures include water closets (also known as toilets), urinals, bidets, showers, bathtubs, utility and kitchen sinks, drinking fountains, ice makers, humidifiers, air washers, fountains, and eye wash stations.\nSealants.\nThreaded pipe joints are sealed with thread seal tape or pipe dope. Many plumbing fixtures are sealed to their mounting surfaces with plumber's putty.\nEquipment and tools.\nPlumbing equipment includes devices often behind walls or in utility spaces which are not seen by the general public. It includes water meters, pumps, expansion tanks, back flow preventers, water filters, UV sterilization lights, water softeners, water heaters, heat exchangers, gauges, and control systems.\nThere are many tools a plumber needs to do a good plumbing job. While many simple plumbing tasks can be completed with a few common hand held tools, other more complex jobs require specialised tools, designed specifically to make the job easier.\nSpecialized plumbing tools include pipe wrenches, flaring pliers, pipe vise, pipe bending machine, pipe cutter, dies, and joining tools such as soldering torches and crimp tools. New tools have been developed to help plumbers fix problems more efficiently. For example, plumbers use video cameras for inspections of hidden leaks or other problems; they also use hydro jets, and high pressure hydraulic pumps connected to steel cables for trench-less sewer line replacement.\nFlooding from excessive rain or clogged sewers may require specialized equipment, such as a heavy duty pumper truck designed to vacuum raw sewage.\nProblems.\nBacteria have been shown to live in \"premises plumbing systems\". The latter refers to the \"pipes and fixtures within a building that transport water to taps after it is delivered by the utility\". Community water systems have been known for centuries to spread waterborne diseases like typhoid and cholera. However, \"opportunistic premises plumbing pathogens\" have been recognized only more recently: Legionella pneumophila, discovered in 1976, Mycobacterium avium, and Pseudomonas aeruginosa are the most commonly tracked bacteria, which people with depressed immunity can inhale or ingest and may become infected with.\nSome of the locations where these opportunistic pathogens can grow include faucets, shower heads, water heaters and along pipe walls. Reasons that favor their growth are \"high surface-to-volume ratio, intermittent stagnation, low disinfectant residual, and warming cycles\". A high surface-to-volume ratio, i.e. a relatively large surface area allows the bacteria to form a biofilm, which protects them from disinfection.\nRegulation.\nMuch of the plumbing work in populated areas is regulated by government or quasi-government agencies due to the direct impact on the public's health, safety, and welfare. Plumbing installation and repair work on residences and other buildings generally must be done according to plumbing and building codes to protect the inhabitants of the buildings and to ensure safe, quality construction to future buyers. If permits are required for work, plumbing contractors typically secure them from the authorities on behalf of home or building owners.\nAustralia.\nIn Australia, the national governing body for plumbing regulation is the Australian Building Codes Board. They are responsible for the creation of the National Construction Code (NCC), Volume 3 of which, the Plumbing Regulations 2008 and the Plumbing Code of Australia, pertains to plumbing.\nEach Government at the state level has their own Authority and regulations in place for licensing plumbers. They are also responsible for the interpretation, administration and enforcement of the regulations outlined in the NCC. These Authorities are usually established for the sole purpose of regulating plumbing activities in their respective states/territories. However, several state level regulation acts are quite outdated, with some still operating on local policies introduced more than a decade ago. This has led to an increase in plumbing regulatory issues not covered under current policy, and as such, many policies are currently being updated to cover these more modern issues. The updates include changed to the minimum experience and training requirements for licensing, additional work standards for new and more specific kinds of plumbing, as well as adopting the Plumbing Code of Australia into state regulations in an effort to standardise plumbing regulations across the country.\nNorway.\nIn Norway, new domestic plumbing installed since 1997 has had to satisfy the requirement that it should be easily accessible for replacement after installation. This has led to the development of the pipe-in-pipe system as a de facto requirement for domestic plumbing.\nUnited Kingdom.\nIn the United Kingdom the professional body is the Chartered Institute of Plumbing and Heating Engineering (educational charity status) and it is true that the trade still remains virtually ungoverned; there are no systems in place to monitor or control the activities of unqualified plumbers or those home owners who choose to undertake installation and maintenance works themselves, despite the health and safety issues which arise from such works when they are undertaken incorrectly; see \"Health Aspects of Plumbing (HAP)\" published jointly by the World Health Organization (WHO) and the World Plumbing Council (WPC). WPC has subsequently appointed a representative to the World Health Organization to take forward various projects related to Health Aspects of Plumbing.\nUnited States.\nIn the United States, plumbing codes and licensing are generally controlled by state and local governments. At the national level, the Environmental Protection Agency has set guidelines about what constitutes lead-free plumbing fittings and pipes, in order to comply with the Safe Drinking Water Act.\nSome widely used Standards in the United States are:\nCanada.\nIn Canada, plumbing is a regulated trade requiring specific technical training and certification. Standards and regulations for plumbing are overseen at the provincial and territorial level, each having its distinct governing body:\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43983", "revid": "14095878", "url": "https://en.wikipedia.org/wiki?curid=43983", "title": "Yitzhak Rabin", "text": "Prime Minister of Israel (1974\u20131977; 1992\u20131995)\nYitzhak Rabin (; , ; 1 March 1922 \u2013 4 November 1995) was an Israeli statesman and general who was the prime minister of Israel, having served two terms in office, 1974\u20131977, and from 1992 until his assassination in 1995. He was the first prime minister to have been born in Mandatory Palestine.\nRabin was born in Jerusalem to Jewish immigrants from Eastern Europe and was raised in a Labor Zionist household. He learned agriculture in school and excelled as a student. As a teenager, he joined the Palmach, the commando force of the Yishuv. He eventually rose through its ranks to become its chief of operations during the 1948 Arab\u2013Israeli War. In late 1948, he joined the newly formed Israel Defense Forces and continued to rise as a promising officer, with a 27-year career as a professional soldier. He ultimately attained the rank of Rav Aluf, the most senior rank in the Israeli Defense Force (often translated as lieutenant general). In the 1950s, Rabin helped shape the training doctrine of the IDF and he led its Operations Directorate from 1959 to 1963. He was appointed chief of the general staff in 1964 and oversaw Israel's victory in the 1967 Six-Day War.\nRabin served as Israel's ambassador to the United States from 1968 to 1973, during a period of deepening U.S.\u2013Israel ties. He was appointed Prime Minister of Israel in 1974 after the resignation of Golda Meir. In his first term, Rabin signed the Sinai Interim Agreement and ordered the Entebbe raid. He resigned in 1977 in the wake of a financial scandal. Rabin was Israel's minister of defense for much of the 1980s, including during the outbreak of the First Intifada.\nIn 1992, Rabin was re-elected as prime minister on a platform embracing the Israeli\u2013Palestinian peace process. He signed several historic agreements with the Palestinian leadership as part of the Oslo Accords. In 1994, Rabin won the Nobel Peace Prize together with long-time political rival Shimon Peres and Palestinian leader Yasser Arafat. Rabin also signed a peace treaty with Jordan in 1994. In November 1995, he was assassinated by Yigal Amir, an extremist who opposed the terms of the Oslo Accords. Amir was convicted of Rabin's murder and sentenced to life imprisonment. Rabin was the first native-born prime minister of Israel, the only prime minister to be assassinated, and the second to die in office after Levi Eshkol. Rabin has become a symbol of the Israeli\u2013Palestinian peace process.\nPersonal life.\nFamily background.\nRabin was born at Shaare Zedek Medical Center in Jerusalem on 1 March 1922, Mandatory Palestine, to Nehemiah (1886 \u2013 1 December 1971) and Rosa (n\u00e9e Cohen; 1890 \u2013 12 November 1937) Rabin, immigrants of the Third Aliyah, the third wave of Jewish immigration to Palestine from Europe. Nehemiah was born Nehemiah Rubitzov in the shtetl Sydorovychi near Ivankiv in the southern Pale of Settlement (present-day Ukraine). His father Menachem died when he was a boy, and Nehemiah worked to support his family from an early age. At the age of 18, he emigrated to the United States, where he joined the Poale Zion party and changed his surname to Rabin. In 1917, Nehemiah Rabin went to Mandatory Palestine with a group of volunteers from the Jewish Legion.\nYitzhak's mother, Rosa Cohen, was born in 1890 in Mogilev in Belarus. Her father, a rabbi, opposed the Zionist movement and sent Rosa to a Christian high school for girls in Gomel, which gave her a broad general education. Early on, Rosa took an interest in political and social causes. In 1919, she traveled to Palestine on the steamship \"Ruslan\". After working on a kibbutz on the shores of the Sea of Galilee, she moved to Jerusalem.\nRabin's parents met in Jerusalem during the 1920 Nebi Musa riots. They moved to Tel Aviv's Chlenov Street near Jaffa in 1923. Nehemiah became a worker for the Palestine Electric Corporation and Rosa was an accountant and local activist. She became a member of the Tel Aviv City Council. The family moved again in 1931 to a two-room apartment on Hamagid Street in Tel Aviv.\nEarly life and education.\nYitzhak (Isaac) Rabin grew up in Tel Aviv, where the family relocated when he was one year old. He enrolled in the Tel Aviv Beit Hinuch Leyaldei Ovdim (\u05d1\u05d9\u05ea \u05d7\u05d9\u05e0\u05d5\u05da \u05dc\u05d9\u05dc\u05d3\u05d9 \u05e2\u05d5\u05d1\u05d3\u05d9\u05dd, \"School House for Workers' Children\") in 1928 and completed his studies there in 1935. The school taught the children agriculture as well as Zionism. Rabin mostly received good marks in school, but he was so shy that few people knew he was intelligent.\nIn 1935, Rabin enrolled at an agricultural school on kibbutz Givat Hashlosha that his mother founded. It was here in 1936 at the age of 14 that Rabin joined the Haganah and received his first military training, learning how to use a pistol and stand guard. He joined a socialist-Zionist youth movement, HaNoar HaOved.\nIn 1937, he enrolled at the two-year Kadoorie Agricultural High School. He excelled in a number of agriculture-related subjects but disliked studying English language\u2014the language of the British \"enemy\". He originally aspired to be an irrigation engineer, but his interest in military affairs intensified in 1938, when the ongoing Arab revolt worsened. A young Haganah sergeant named Yigal Allon, later a general in the IDF and prominent politician, trained Rabin and others at Kadoorie. Rabin finished at Kadoorie in August 1940. For part of 1939, the British closed Kadoorie, and Rabin joined Allon as a security guard at Kibbutz Ginosar until the school re-opened. When he finished school, Rabin considered studying irrigation engineering on scholarship at the University of California, Berkeley, although he ultimately decided to stay and fight in Palestine.\nMarriage and family.\nRabin married Leah Schlossberg during the 1948 Arab\u2013Israeli War. Leah Rabin was working at the time as a reporter for a Palmach newspaper. They had two children, Dalia (born 19 March 1950) and Yuval (born 18 June 1955). Similar to the entire Israeli elite of the time, Rabin adhered to a secular-national understanding of Jewish identity, and was non-religious. American diplomat Dennis Ross described him as \"the most secular Jew he had met in Israel\".\nMilitary career.\nPalmach.\nIn 1941, during his practical training at kibbutz Ramat Yohanan, Rabin joined the newly formed Palmach section of the Haganah, under the influence of Yigal Allon. Rabin could not yet operate a machine gun, drive a car, or ride a motorcycle, but Moshe Dayan accepted the new recruit. The first operation he participated in was assisting Allied forces in the Syria\u2013Lebanon campaign against Vichy French forces during World War II (the same operation in which Dayan lost his eye) in June\u2013July 1941. Allon continued to train the young Palmach forces.\nAs a Palmachnik, Rabin and his men had to lie low to avoid arousing inquiry from the British administration. They spent most of their time farming, training secretly part-time. They wore no uniforms and received no public recognition during this time. In 1943, Rabin took command of a platoon at Kfar Giladi. He trained his men in modern tactics and how to conduct lightning attacks.\nAfter the end of the war the relationship between the Palmach and the British authorities became strained, especially with respect to the treatment of Jewish immigration. In October 1945 Rabin planned a Palmach raid on the Atlit detainee camp in which 208 Jewish illegal immigrants who had been interned there were freed. In the Black Shabbat, a massive British operation against the leaders of the Jewish Establishment in the British Mandate of Palestine and the Palmach, Rabin was arrested and detained for five months. After his release he became the commander of the second Palmach battalion and rose to the position of Chief Operations Officer of the Palmach in October 1947.\nIDF service.\nDuring the 1948 Arab\u2013Israeli War, Rabin directed Israeli operations in Jerusalem and fought the Egyptian army in the Negev. During the beginning of the war he was the commander of the Harel Brigade, which fought on the road to Jerusalem from the coastal plain, including the Israeli \"Burma Road\", as well as many battles in Jerusalem, such as securing the southern side of the city by recapturing kibbutz Ramat Rachel.\nDuring the Rabin commanded IDF forces on the beach of Tel Aviv confronting the Irgun during the tragic Altalena Affair. The Altalena ship carried volunteers from abroad coming to fight in War of Independence and large amounts of weapons and ammunition for the war. It was organized by Hillel Kook of the Irgun. The day after much of the contents were offloaded at Kfar Vitkin the ship was attacked at Ben Gurion's orders off the Tel Aviv shore, set on fire, later towed out to sea and sunk. Large number of volunteers were killed on board and after jumping in the sea. Rabin called the gun on shore \"The Holy Gun\". \"Despite the tension and bloodshed, Begin went on the radio calling on members of the Irgun not to fight the IDF: \"Do not raise a hand against a brother, not even today. It is forbidden for a Hebrew weapon to be used against Hebrew fighters.\"\" This probably prevented the likelihood of civil war. Hillel Kook was arrested.\nIn the following period he was the deputy commander of Operation Danny, the largest scale operation to that point, which involved four IDF brigades. The cities of Ramle and Lydda were captured, as well as the major airport in Lydda, as part of the operation. Following the capture of the two towns there was an expulsion of their Arab population. Rabin signed the expulsion order, which included the following:\n... 1. The inhabitants of Lydda must be expelled quickly without attention to age. ... 2. Implement immediately.\nLater, Rabin was chief of operations for the Southern Front and participated in the major battles ending the fighting there, including Operation Yoav and Operation Horev.\nIn the beginning of 1949 he was a member of the Israeli delegation to the armistice talks with Egypt that were held on the island of Rhodes. The result of the negotiations were the 1949 Armistice Agreements, which ended the official hostilities of the 1948 Arab\u2013Israeli War. Following the demobilization at the end of the war he was the most senior (former) member of the Palmach that remained in the IDF.\nLike many Palmach leaders, Rabin was politically aligned with the left wing pro-Soviet Ahdut HaAvoda party and later Mapam. These officers were distrusted by Prime Minister David Ben-Gurion and several resigned from the army in 1953 after a series of confrontations. Those members of Mapam who remained, such as Rabin, Haim Bar-Lev and David Elazar, had to endure several years in staff or training posts before resuming their careers.\nRabin headed Israel's Northern Command from 1956 to 1959. In 1964 he was appointed chief of staff of the Israel Defense Forces (IDF) by Levi Eshkol, who had replaced David Ben-Gurion as Prime Minister and Minister of Defence. Since Eshkol did not have much military experience and trusted Rabin's judgement, he had a very free hand. According to the memoirs of Eshkol's military secretary, Eshkol followed Rabin \"with closed eyes\".\nUnder his command, the IDF achieved victory over Egypt, Syria and Jordan in the Six-Day War in 1967. After the Old City of Jerusalem was captured by the IDF, Rabin was among the first to visit the Old City, and delivered a famous speech on Mount Scopus, at the Hebrew University. In the days leading up to the war, it was reported that Rabin suffered a nervous breakdown and was unable to function. After this short hiatus, he resumed full command over the IDF.\nAmbassador to the United States (1968\u20131973).\nFollowing his retirement from the IDF he became ambassador to the United States beginning in 1968, serving for five years. In this period the US became the major weapon supplier of Israel and in particular he managed to get the embargo on the F-4 Phantom fighter jets lifted. During the 1973 Yom Kippur War he served in no official capacity.\nMinister of Labour.\nIn the elections held at the end of 1973, Rabin was elected to the Knesset as a member of the Alignment. He was appointed Israeli Minister of Labour in March 1974 in the short-lived Golda Meir-led 16th government.\nFirst term as Prime Minister (1974\u20131977).\nFollowing Golda Meir's resignation in April 1974, Rabin was elected party leader, after he defeated Shimon Peres. The rivalry between these two Labour leaders remained fierce and they competed several times in the next two decades for the leadership role, and even for who deserved credit for government achievements. Rabin succeeded Golda Meir as Prime Minister of Israel on 3 June 1974. This was a coalition government, including Ratz, the Independent Liberals, Progress and Development and the Arab List for Bedouins and Villagers. This arrangement, with a bare parliamentary majority, held for a few months and was one of the few periods in Israel's history where the religious parties were not part of the coalition. The National Religious Party joined the coalition on 30 October 1974 and Ratz left on 6 November.\nIn foreign policy, the major development at the beginning of Rabin's term was the Sinai Interim Agreement between Israel and Egypt, signed on 1 September 1975. Both countries declared that the conflict between them and in the Middle East shall not be resolved by military force but by peaceful means. This agreement followed Henry Kissinger's shuttle diplomacy and a threatened \"reassessment\" of the United States' regional policy and its relations with Israel. Rabin notes it was \"an innocent-sounding term that heralded one of the worst periods in American\u2013Israeli relations.\" But the agreement was an important step towards the Camp David Accords of 1978 and the peace treaty with Egypt signed in 1979.\nOperation Entebbe was perhaps the most dramatic event during Rabin's first term of office. On his orders, the IDF performed a long-range undercover raid to rescue passengers of an airliner hijacked by militants belonging to the Popular Front for the Liberation of Palestine's Wadie Haddad faction and the German Revolutionary Cells (RZ), who had been brought to Idi Amin's Uganda. The operation was generally considered a tremendous success, and its spectacular character has made it the subject of much continued comment and study.\nTowards the end of 1976 his coalition government with the religious parties suffered a crisis: A motion of no confidence had been brought by Agudat Yisrael over a breach of the Sabbath on an Israeli Air Force base when four F-15 jets were delivered from the US and the National Religious Party had abstained. Rabin dissolved his government and decided on new elections, which were to be held in May 1977.\nRabin was narrowly reelected as party leader over Shimon Peres in February 1977.\nFollowing the March 1977 meeting between Rabin and U.S. President Jimmy Carter, Rabin publicly announced that the U.S. supported the Israeli idea of defensible borders; Carter then issued a clarification. A \"fallout\" in U.S./Israeli relations ensued. It is thought that the fallout contributed to the Israeli Labor Party's defeat in the May 1977 elections. On 15 March 1977, \"Haaretz\" journalist Dan Margalit revealed that a joint dollar account in the names of Yitzhak and Leah Rabin, opened in a Washington, D.C., bank during Rabin's term of office as Israel ambassador (1968\u201373), was still open, in breach of Israeli law. According to Israeli currency regulations at the time, it was illegal for citizens to maintain foreign bank accounts without prior authorization. Rabin resigned on 7 April 1977, following the revelation by \"Maariv\" journalist S. Isaac Mekel that the Rabins held two accounts in Washington, not one, containing $10,000, and that a Finance Ministry administrative penalty committee fined them IL150,000. Rabin withdrew from the party leadership and candidacy for prime minister.\nOpposition Knesset member (1977\u20131984).\nFollowing Labour Party's defeat in the 1977 election, Likud's Menachem Begin became prime minister, and Labor (which was part of the Alignment alliance) entered the opposition. Until 1984 Rabin, as a member of Knesset, sat on the Foreign Affairs and Defense Committee.\nRabin unsuccessfully challenged Shimon Peres for Israeli Labor Party leadership in the 1980 Israeli Labor Party leadership election.\nMinister of Defense (1984\u20131990).\nFrom 1984 until 1990, Labor was in government as part of the coalitions which formed the 21st and 22nd governments during the 11th Knesset and the 23rd government during the first portion of the 10th Knesset.\nFrom 1984 to 1990, Rabin served as Minister of Defense in several national unity governments led by prime ministers Yitzhak Shamir and Shimon Peres. When Rabin came to office, Israeli troops were still deep in Lebanon. Rabin ordered their withdrawal to a \"Security Zone\" on the Lebanese side of the border. The South Lebanon Army was active in this zone, along with the Israeli Defence Forces.\nOn 4 August 1985 Minister of Defence Rabin introduced an Iron Fist policy in the West Bank, reviving the use of British Mandate era legislation to detain people without trial, demolish houses, close newspapers and institutions as well as deporting activists. The change in policy came after a sustained public campaign demanding a tougher policy following the May 1985 prisoner exchange in which 1,150 Palestinians had been released.\nIn December 1987, the most significant series of demonstrations and riots by Palestinians since the start of the Israeli broke out, soon transforming into a sustained popular uprising known as the First Intifada and marked by civil disobediance, strikes, boycotts of Israeli goods and institutions, and the creation of underground local institutions like classrooms and cooperatives. After initially failing to recognise the seriousness of the situation while out of the country on a diplomatic trip to the United States, Rabin adopted harsh measures to stop the uprising, ordering the Israeli military to use \"force, might, and beatings\" on Palestinian demonstrators. The measures led to significant international criticism, with the derogative term \"bone breaker\" was used as a critical international slogan. The combination of the failure of the \"Iron Fist\" policy, Israel's deteriorating international image, and Jordan cutting legal and administrative ties to the West Bank with the U.S.'s recognition of the PLO as the representative of the Palestinian people forced Rabin to seek an end to the violence through negotiation and dialogue with the PLO.\nIn 1988 Rabin was responsible for the assassination of Abu Jihad in Tunis and two weeks later he personally supervised the destruction of the Hizbullah stronghold in Meidoun during Operation Law and Order, in which the IDF said 40\u201350 Hizbullah fighters were killed. Three Israeli soldiers were killed and seventeen wounded.\nMinister of Defence Rabin planned and executed the 27 July 1989 abduction of the Hizbullah leader Sheikh Abdel Karim Obeid and two of his aides from Jibchit in South Lebanon. Hizbullah responded by announcing the execution of Colonel Higgins, a senior American officer working with UNIFIL who had been kidnapped in February 1988.\nOpposition Knesset member (1990\u20131992).\nIn \"the dirty trick\", the Labor Party left the coalition of the 23rd government in an effort to form a new coalition to be led by Peres. This failed as Yitzhak Shamir formed the 24th government with Labor in the opposition for the remainder of the 10th Knesset.\nFrom 1990 to 1992, Rabin again sat on the Knesset's Foreign Affairs and Defense Committee.\nFollowing the backfiring of \"the dirty trick\" on Peres and the Labor Party, Rabin unsuccessfully attempted to persuade the party to schedule a leadership election in 1990. A prospective leadership race in 1990 had looked promising to Rabin. Peres was weakened from the backfiring of \"the dirty trick\", and polling showed Rabin to be the nation's most popular politician. Additionally, many of Peres' longtime backers in the party had begun shifting their support to Rabin. In July 1990, the Labor Party's 120 member Leadership Bureau voted to recommend that the party hold an immediate leadership election. However, one week later, on 22 July 1990, the 1,400 member Labor Party Central Committee voted 54 to 46% against holding an immediate leadership contest. This set the party up to not hold a leadership election until at least following year, unless the next Knesset election were to have been scheduled earlier than the anticipated 1992. The committee's vote to reject Rabin's push for a 1990 leadership contest was regarded as an upset result.\nReturn to party leadership.\nIn its 1992 leadership election, Rabin was elected as chairman of the Labor Party, unseating Shimon Peres.\nSecond term as Prime Minister.\nIn the 1992 Israeli legislative election, the Labor Party, led by Rabin, strongly focused on his popularity. The party managed to win a clear victory over the Likud of incumbent Prime Minister Yitzhak Shamir. However, the left-wing bloc in the Knesset only won an overall narrow majority, facilitated by the failure of small nationalist parties to pass the electoral threshold. Rabin formed the first Labor-led government in fifteen years, supported by a coalition with Meretz, a left wing party, and Shas, a Mizrahi ultra-orthodox religious party.\nOn 25 July 1993, after Hezbollah fired rockets into northern Israel, Rabin authorized a week-long military operation in Lebanon. Rabin played a leading role in the signing of the Oslo Accords, which created the Palestinian National Authority and granted it partial control over parts of the Gaza Strip and West Bank. Prior to the signing of the accords, Rabin received a letter from PLO chairman Yasser Arafat renouncing violence and officially recognizing Israel, and on the same day, 9 September 1993, Rabin sent Arafat a letter officially recognizing the PLO. Two days earlier, Rabin explained that his main motive for negotiating with Palestinians was that, \"The Palestinians will be better at it than we were, ... because they will allow no appeals to the Supreme Court\nand will prevent the Israeli Association of Civil Rights from criticizing the conditions there by denying it access to the area. They will rule by their own methods, freeing, and this is most important, the Israeli army soldiers from having to do what they will do.\" \nAfter the announcement of the Oslo Accords there were many protest demonstrations in Israel objecting to the Accords. As these protests dragged on, Rabin insisted that as long as he had a majority in the Knesset he would ignore the protests and the protesters. In this context he said, \"they (the protesters) can spin around and around like propellers\" but he would continue on the path of the Oslo Accords. Rabin's parliamentary majority rested on non-coalition member Arab support. Rabin also denied the right of American Jews to object to his plan for peace, calling any such dissent \"chutzpah\". The Oslo agreement was also opposed by Hamas and other Palestinian factions, which launched suicide bombings at Israel.\nAfter the historical handshake with Yasser Arafat, Rabin said, on behalf of the Israeli people, \n\"We who have fought against you, the Palestinians, we say to you today, in a loud and a clear voice; Enough of blood and tears. Enough!\"\nDuring this term of office, Rabin also oversaw the signing of the Israel\u2013Jordan peace treaty in 1994.\nEconomic and social reforms.\nRabin significantly reformed Israel's economy, as well as its education and healthcare systems. His government significantly expanded the privatization of business, moving away from the country's traditionally socialized economy. The scheme was described by Moshe Arens as a \"privatization frenzy\". In 1993, his government set up the \"Yozma\" program, under which attractive tax incentives were offered to foreign venture capital funds that invested in Israel and promised to double any investment with government funding. As a result, foreign venture capital funds invested heavily in the growing Israeli high-tech industry, contributing to Israel's economic growth and status as a world leader in high-tech. In 1995, the National Health Insurance Law was passed. The law created Israel's universal health care system, moving away from the traditionally Histadrut-dominated health insurance system. Doctors' wages were also raised by 50%. Education spending was raised by 70%, with new colleges being built in Israel's peripheral areas, and teachers' wages rising by one-fifth. His government also launched new public works projects such as the Cross-Israel Highway and an expansion of Ben Gurion Airport.\nNobel Peace Prize.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nI always believed that most of the people want peace and are ready to take a risk for it.\n\u2014Rabin declared to the rally in 1995, shortly before his death.\nFor his role in the creation of the Oslo Accords, Rabin was awarded the 1994 Nobel Peace Prize, along with Yasser Arafat and Shimon Peres. According to Israeli political scientist Efraim Inbar, the road for Israel to Oslo began with Rabin. While not committed to Palestinian statehood, he called for a peaceful coexistence between Israel as a Jewish state next to a Palestinian entity. Likewise, according to Efraim Karsh, \"many Palestinians viewed the peace treaty with Israel as a temporary measure only\". The two sides agreed on certain principles, setting the terms for further negotiations, with the promise of a permanent resolution within a number of years.\nMilitary cemeteries in every corner of the world are silent testimony to the failure of national leaders to sanctify human life.\n\u2014 Yitzhak Rabin, 1994 Nobel Peace Prize lecture, 10 December 1994\nAssassination and aftermath.\nOn the evening of 4 November 1995 (12th of Heshvan on the Hebrew calendar), Rabin was assassinated by Yigal Amir, a law student and right-wing extremist who opposed the signing of the Oslo Accords. Rabin had been attending a mass rally at the Kings of Israel Square (now Rabin Square) in Tel Aviv, held in support of the Oslo Accords. When the rally ended, Rabin walked down the city hall steps towards the open door of his car, at which point Amir fired three shots at Rabin with a semi-automatic pistol. Two shots hit Rabin, and the third lightly injured Yoram Rubin, one of Rabin's bodyguards. Rabin was taken to the nearby Ichilov Hospital, where he died on the operating table of blood loss and two punctured lungs. Amir was immediately seized by Rabin's bodyguards and police. He was later tried, found guilty, and sentenced to life imprisonment. After an emergency cabinet meeting, Israel's foreign minister, Shimon Peres, was appointed as acting Israeli prime minister.\nRabin's assassination shocked the Israeli public and much of the rest of the world. Hundreds of thousands of Israelis gathered at the square where Rabin was assassinated to mourn his death. Young people, in particular, turned out in large numbers, lighting memorial candles and singing peace songs. On 6 November 1995, he was buried on Mount Herzl. Rabin's funeral was attended by many world leaders, among them U.S. president Bill Clinton, Australian Prime Minister Paul Keating, Egyptian president Hosni Mubarak, and King Hussein of Jordan. Clinton delivered a eulogy whose final words were in Hebrew \u2013 \"Shalom, haver\" ().\nThe square where he was assassinated, \"Kikar Malkhei Yisrael\" (Kings of Israel Square), was renamed Rabin Square in his honor. Many other streets and public institutions in Israel have also subsequently been named after him. After his assassination, Rabin was hailed as a national symbol and came to embody the ethos of the \"Israeli peace camp\", despite his military career and hawkish views earlier in life. In November 2000, his wife Leah died and was buried alongside him.\nAfter the murder, it was revealed that Avishai Raviv, a well-known right-wing extremist at the time, was a Shin Bet agent-informer codenamed Champagne. Raviv was later acquitted in court of charges that he failed to prevent the assassination. The court ruled there was no evidence that Raviv knew Amir was plotting to kill Rabin. After Rabin's assassination, his daughter Dalia Rabin-Pelossof entered politics and was elected to the Knesset in 1999 as part of the Center Party. In 2001, she served as Israel's deputy minister of defense.\nOverview of offices held.\nRabin twice served as prime minister (Israel's head of government). His first stint spanned from 3 June 1974 through 20 June 1977, leading the 17th government during the 8th Knesset. His second stint lasted from 13 July 1992 until his assassination on 4 November 1995, leading the 25th government during the 13th Knesset. Rabin was a member of the Knesset from 1974 until his assassination. For several months in 1992, Rabin served as the Knesset's opposition leader, at the time an unofficial and honorary role. Rabin also served as ambassador of Israel to the United States from 1968 until 1973.\nLabor Party leadership.\nPeres twice served as leader of the Israeli Labor Party."}
{"id": "43984", "revid": "1310947747", "url": "https://en.wikipedia.org/wiki?curid=43984", "title": "Johann Friedrich Struensee", "text": "Danish physician, philosopher and statesman (1737\u20131772)\nLensgreve Johann Friedrich Struensee (5 August 1737 \u2013 28 April 1772) was a German-Danish physician, philosopher and statesman. He became royal physician to the mentally ill King Christian VII of Denmark-Norway and a minister in the Danish government. He rose in power to a position of \"de facto\" regent of the country, and he tried to carry out widespread reforms. His affair with Queen Caroline Matilda (\"Caroline Mathilde\") caused a scandal, especially after the birth of a daughter, Princess Louise Augusta, and was the catalyst for the intrigues and power play that caused his downfall and dramatic death.\nUpbringing and early career.\nBorn at Halle an der Saale and baptized at St. Moritz on 7 August 1737, Struensee was the third child of six born to Pietist theologian and minister Adam Struensee (baptized in Neuruppin on 8 September 1708 \u2013 Rendsburg, 20 June 1791) and his wife Maria Dorothea Carl (Berleburg, 31 July 1716 \u2013 Schleswig, 31 December 1792). The elder Struensee attended the University of Halle and served in a number of pastoral postings before being appointed Royal General Superintendent of Schleswig and Holstein between 1760 and 1791. The Struensees were a respectable middle-class family that believed in religious tolerance. Three of the Struensee sons went to University, but none became theologians like their father; two of the daughters married ministers.\nJohann Friedrich entered the University of Halle on 5 August 1752 at the age of fifteen where he studied medicine, and graduated as a Doctor in Medicine (\"Dr. Med.\") on 12 December 1757. The university exposed him to Age of Enlightenment ideals, and social and political critique and reform. He supported these new ideas, becoming a proponent of atheism, the writings of Claude Adrien Helv\u00e9tius, and other French materialists.\nWhen Adam and Maria Dorothea Struensee moved to Altona in 1758, where the elder Struensee became pastor of Trinitatiskirche (Trinity's Church), Johann Friedrich moved with them. He was soon employed as a public doctor in Altona, in the estate of Count Rantzau, and in the Pinneberg District. His wages were meager and he expected to supplement them with private practice.\nHis parents moved to Rendsburg in 1760 where Adam Struensee became first superintendent (comparable to bishop) for the duchy, and subsequently superintendent-general of Schleswig-Holstein. Struensee, now 23 years old, had to set up his own household for the first time. His lifestyle expectations were not matched by his economics. His perceived intelligence and manner, however, soon made him fashionable in the better circles, and he entertained his contemporaries with his controversial opinions.\nStruensee was ambitious and petitioned the Danish government through Minister of Foreign Affairs Count Johann Hartwig Ernst von Bernstorff for funds. He tried his hand at writing Enlightenment treatises and published many of them in his journal \"Zum Nutzen und Vergn\u00fcgen\" (\"For benefit and enjoyment\").\nPhysician to King Christian VII.\nDuring Struensee's near ten-year residence in Altona he came into contact with a circle of aristocrats who had been sent away from the royal court in Copenhagen. Among them were Enevold Brandt and Count Schack Carl Rantzau, who were supporters of the Enlightenment. Rantzau recommended Struensee to the court as a physician to attend King Christian VII on his forthcoming tour to princely and royal courts in western Germany, the Netherlands, England, and France.\nStruensee received the appointment in April 1768. The king and his entourage set forth on 6 May. While in England Struensee received the honorary degree of Doctor in Medicine from the University of Cambridge.\nDuring the eight-month tour, he gained the king's confidence and affection. The king's ministers, Bernstorff and Finance Minister H. C. Schimmelmann, were pleased with Struensee's influence on the king, who began making fewer embarrassing \"scenes\". Upon the court's return to Copenhagen in January 1769, Struensee was appointed personal physician to the king. In May, he was given the honorary title of State Councillor, which advanced him to the class of the third rank at court. Struensee wrote an important report on the mental health of the King.\nRise to power.\nFirst he reconciled the king and queen. At first Caroline Matilda disliked Struensee, but she was unhappy in her marriage, neglected and spurned by the king, and affected by his illness. However, Struensee was one of the few people who paid attention to the lonely queen, and he seemed to do his best to alleviate her troubles. Over time her affection for the young doctor grew and by spring 1770 he became her lover; a successful vaccination of the baby crown prince in May still further increased his influence.\nStruensee was very involved with the upbringing of Crown Prince Frederick along the principles of Enlightenment, such as outlined by Jean-Jacques Rousseau's challenge to return to nature. However, he had his own interpretation of Rousseau's ideas and preferred isolating the child and encouraging him to manage things largely on his own. He also took Rousseau's advice about cold being beneficial for children literally, and the Crown Prince was thus only sparsely clothed even during wintertime.\nIn control of the government.\nStruensee was named royal adviser (forel\u00e6ser) and konferensr\u00e5d on 5 May 1770. As in the course of the year the king sank into a condition of mental torpor, Struensee's authority became paramount. On 15 September the 16-month period generally referred to as the \"Time of Struensee\" began.\nAt first, Struensee kept a low profile as he began to control the political machine. However, as the royal court and government spent the summer of 1770 in Schleswig-Holstein (Gottorp, Traventhal, and Ascheberg) his power grew. In December 1770, he grew impatient and on the 10th of that month, he abolished the council of state. A week later, he appointed himself \"ma\u00eetre des requ\u00eates\". It became his official duty to present reports from the various departments of state to the king. Because King Christian was scarcely responsible for his actions, Struensee dictated whatever answers he pleased. Next, he dismissed all department heads, and abolished the Norwegian viceroyship. Henceforth, the cabinet with himself as its motive power became the one supreme authority in the state. Struensee held absolute sway for almost thirteen months, between 18 December 1770 and 16 January 1772. During that time, he issued no fewer than 1,069 cabinet orders, or more than three a day.\nReforms initiated by Struensee included:\nOther reforms included the abolition of capital punishment for theft; the doing away with such demoralizing abuses as perquisites; and of \"lackey-ism\", the appointment of powerful men's domestic staff to lucrative public posts.\nCritics of Struensee thought that he did not respect native Danish and Norwegian customs, saw them as prejudices and wanted to eliminate them in favour of abstract principles. He also did not speak Danish and conducted his business in German. To ensure obedience, he dismissed entire staffs of public departments, without pensions or compensation, and substituted with nominees of his own. The new officials were in many cases inexperienced men who knew little or nothing of the country that they were supposed to govern.\nInitially, the Danish people favored his reforms, but they began to turn against him. When Struensee abolished all censorship of the press, it mostly resulted in a flood of anti-Struensee pamphlets.\nDuring the initial months of his rule, middle-class opinion was in his favour. What incensed the people most against him was the way in which he put the king completely on one side, and the feeling was all the stronger as, outside a very narrow court circle, nobody seems to have believed that Christian VII was really mad, but only that his will had been weakened by habitual ill usage. That opinion was confirmed by the publication of the cabinet order of 14 July 1771, which appointed Struensee \"gehejme kabinetsminister\" or \"Geheimekabinetsminister\", with authority to issue cabinet orders which were to have the force of royal ordinances, even if unprovided with the royal sign manual.\nStruensee's relations with the queen were offensive to a nation which had a traditional veneration for the royal House of Oldenburg, and Caroline Matilda's conduct in public scandalized the populace. The society which daily gathered round the king and queen excited the derision of the foreign ambassadors. The unhappy king was little more than the butt of his environment, but occasionally, the king would put up a show of obstinacy and refuse to carry out Brandt's or Struensee's orders. Once, when he threatened his keeper, Brandt, with a flogging for some impertinence, Brandt ended up in a struggle with the King and he struck the King in the face.\nArrest and execution.\nStruensee's dismissal of many government officials and officers brought him numerous political enemies. On 30 November 1771, he declared himself and Brandt counts. Those actions stirred feelings of unease and dissatisfaction in the populace of Denmark and Norway.\nChristian VII along with his queen, Struensee, Brandt, and members of the royal court, spent the summer of 1771 at Hirschholm Palace north of Copenhagen. They stayed there until late in the autumn. On 7 July, the queen gave birth to a daughter, Louise Augusta, widely believed then and by historians to be the daughter of Struensee. The court moved to Frederiksberg Palace just west of Copenhagen on 19 November.\nThe general ill will against Struensee, which had been smouldering all through the autumn of 1771, found expression in a conspiracy against him, headed by Schack Carl Rantzau and others, in the name of the Queen Dowager Juliana Maria, to wrest power away from the king, and secure her and her son's positions of power.\nThe court returned to Christiansborg Palace on 8 January 1772. The season's first masquerade ball was held at the Court Theatre on 16 January.\nA palace coup took place in the early morning of 17 January 1772, Struensee, Brandt and Queen Caroline Matilda were arrested in their respective bedrooms, and the perceived liberation of the king, who was driven round Copenhagen by his deliverers in a gold carriage, was received with universal rejoicing. The chief charge against Struensee was that he had usurped the royal authority in contravention of the Royal Law (\"Kongelov\"). He defended himself with considerable ability and, at first, confident that the prosecution would not dare to lay hands on the queen, he denied that their liaison had ever been criminal. The queen was taken as prisoner of state to Kronborg Castle.\nOn 27 April/28 April, Struensee and Brandt were condemned first to lose their right hands and then to be beheaded. Their bodies were afterwards to be drawn and quartered. The \"Kongelov\" had no provisions for a mentally-ill ruler who was unfit to govern. However, as a commoner who had imposed himself in the circles of nobility, Struensee was condemned as being guilty of \"l\u00e8se majest\u00e9\" and usurpation of the royal authority, both of which were capital offences according to Paragraphs 2 and 26 of the \"Kongelov\".\nStruensee awaited his execution at Kastellet, Copenhagen. The sentences were carried out on 28 April 1772, with Brandt being executed first.\nThe king himself considered Struensee a great man, even after his death. Written in German on a drawing the king made in 1775, three years after Struensee's execution, was the following: \"Ich h\u00e4tte gern beide gerettet\" (\"I would have liked to have saved them both\"), referring to Struensee and Brandt.\nCultural depictions.\nStruensee, his affair with the queen and his relation with the king have been featured in many artistic works:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nIn Danish, Swedish or German.\nPrimary sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "43986", "revid": "17619453", "url": "https://en.wikipedia.org/wiki?curid=43986", "title": "Evil Empire speech", "text": "1983 anti-Soviet speech by Ronald Reagan\nThe \"Evil Empire\" speech was a speech delivered by then-United States president Ronald Reagan to the National Association of Evangelicals on March 8, 1983, at the height of the Cold War and the Soviet\u2013Afghan War. In that speech, Reagan referred to the Soviet Union as an \"evil empire\" and as \"the focus of evil in the modern world\". Reagan explicitly rejected the notion that the United States and the Soviet Union were equally responsible for the Cold War and the ongoing nuclear arms race between the two nations; rather, he asserted that the conflict was a battle between good and evil.\nBackground.\nReagan's chief speechwriter at the time, Anthony R. Dolan, coined the phrase \"evil empire\" for Reagan's use. Dolan included similar language in a draft for Reagan's June 1982 speech before the British House of Commons in London, but reviewers flagged and struck the phrasing. On June 19, 1981, during a meeting with Singapore\u2019s Lee Kuan Yew, Lee referred to the Soviet Union as an \u201cempire which extended across Eurasia.\u201d According to Lee\u2019s memoirs, \u201cReagan\u2019s ears pricked up at the word \u2018empire.\u2019 He told Richard Allen to use that word more frequently when describing the Soviet domain.\u201d Dolan included the phrase \"evil empire\" in drafts for Reagan's speech at the National Association of Evangelicals' 41st annual convention. White House staffers who saw drafts of the speech, including David Gergen, repeatedly struck the \"evil empire\" portion; the speech eventually reached Reagan with the \"evil empire\" portion included, staffer critics concluding the event would be minor and unlikely to attract attention.\nWhen Reagan reviewed and edited the draft himself, he extended the material on domestic matters. Dolan had included a reference to \"abortion on demand\" as a \"great moral evil\"; Reagan cut the line and added a remark asserting that \"until it can be proven that the unborn child is not a living entity\" its \"right to life, liberty &amp; the pursuit of happiness must be protected\". Reagan left the \"evil empire\" phrase and did not substantially alter the draft's strongly anti-communist tone.\nSpeech.\nReagan spoke at the 41st annual convention of the National Association of Evangelicals on March 8, 1983, in the Citrus Crown Ballroom of the Sheraton Twin Towers Hotel in Orlando, Florida. The speech, marking his first recorded use of the phrase \"evil empire\" to refer to the Soviet Union, has become known as the \"Evil Empire\" speech. In that speech, Reagan said:\nYes, let us pray for the salvation of all of those who live in that totalitarian darkness\u2014pray they will discover the joy of knowing God. But until they do, let us be aware that while they preach the supremacy of the State, declare its omnipotence over individual man, and predict its eventual domination of all peoples on the earth, they are the focus of evil in the modern world\u00a0...\nSo, in your discussions of the nuclear freeze proposals, I urge you to beware the temptation of pride\u2014the temptation of blithely declaring yourselves above it all and label both sides equally at fault, to ignore the facts of history and the aggressive impulses of an \"evil empire\", to simply call the arms race a giant misunderstanding and thereby remove yourself from the struggle between right and wrong and good and evil.\nThe audience applauded Reagan's speech. A band played him off with the song \"Onward, Christian Soldiers\".\nReception.\nContemporaneous press criticized the speech as inflammatory, and critics worried the speech portended negatively for arms negotiations with the Soviet Union. \"The Christian Science Monitor\" argued that Reagan's rhetoric would encourage an arms race and \"would some day, in logic, point toward war\". During a 1984 presidential debate, Reagan reiterated his assessment of the Soviet Union, saying he \"believe[d] that many of the things that they have done are evil in any concept of morality that we have\", while also emphasizing pragmatism, adding, \"I also recognize that as the two great superpowers in the world, we have to live with each other\".\nThe Soviet Union, for its part, alleged that the United States was an imperialist superpower seeking to dominate the entire world, and that the Soviet Union was fighting against it \"in the name of humanity\". In Moscow, the Soviet state-run press agency TASS said the \"evil empire\" words demonstrated that the Reagan administration \"can think only in terms of confrontation and bellicose, lunatic anti-communism\".\nDuring his second term in office, in May\u2013June 1988, more than five years after using the term \"evil empire\", Reagan visited Mikhail Gorbachev, at the time General Secretary of the Soviet Union and a reformist, in Moscow. When asked by a reporter whether he still thought the Soviet Union was an evil empire, Reagan responded that he no longer did, and that when he used the term it was \"another time, another era\". In a speech, Gorbachev said of Reagan's statement that the Soviet Union \"t[ook] note of that\"; journalist Lou Cannon concluded that Gorbachev \"listened carefully to the message of peace that Reagan had brought with him to Moscow\".\nInterpretation.\nG. Thomas Goodnight characterized the \"evil empire\" speech, along with the \"Zero Option\" and \"Star Wars\" speeches, as part of the rhetorical side of the Cold War and reshaped public perceptions of nuclear warfare. In the former, Reagan depicted nuclear warfare as an extension of an \"age old struggle between good and evil\". By characterizing the Soviet Union as an \"evil empire\" and therefore irrational and untrustworthy, the speech justified demurrals on peace proposals. Historian John Lewis Gaddis called the speech the \"complet[ion of] a rhetorical offensive designed to expose what Reagan saw as the central error of d\u00e9tente: the idea that the Soviet Union had earned geopolitical, ideological, economic, and moral legitimacy\" and argued that it \"could not have been better calculated to feed the anxieties\" afflicting Soviet leadership at the time. According to literature professor Leerom Medovoi, on top of opposing the Soviet Union, the \"Evil Empire\" speech directed the Evangelical audience's attention to domestic policy and characterized American liberals as being additional enemies in a culture war that Reagan called \"a test of moral will and faith\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43989", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=43989", "title": "Royal Observatory, Greenwich", "text": "Observatory in London, England\nObservatory\nThe Royal Observatory, Greenwich (ROG; known as the Old Royal Observatory from 1957 to 1998, when the working Royal Greenwich Observatory, RGO, temporarily moved south from Greenwich to Herstmonceux) is an observatory situated on a hill in Greenwich Park in south east London, overlooking the River Thames to the north. It played a major role in the history of astronomy and navigation, and because the Prime Meridian passed through it, it gave its name to Greenwich Mean Time, the precursor to today's Coordinated Universal Time (UTC). The ROG has the IAU observatory code of 000, the first in the list. ROG, the National Maritime Museum, the Queen's House and the clipper ship \"Cutty Sark\" are collectively designated Royal Museums Greenwich.\nThe observatory was commissioned in 1675 by King Charles II, with the foundation stone being laid on 10 August. The old hilltop site of Greenwich Castle was chosen by Sir Christopher Wren, a former Savilian Professor of Astronomy; as Greenwich Park was a royal estate, no new land needed to be bought. At that time the King also created the position of Astronomer Royal, to serve as the director of the observatory and to \"apply himself with the most exact care and diligence to the rectifying of the tables of the motions of the heavens, and the places of the fixed stars, so as to find out the so much desired longitude of places for the perfecting of the art of navigation.\" He appointed John Flamsteed as the first Astronomer Royal. The building was completed in the summer of 1676. The building was often called \"Flamsteed House\", in reference to its first occupant.\nThe scientific work of the observatory was relocated elsewhere in stages in the first half of the 20th century, and the Greenwich site is now maintained almost exclusively as a museum, although the AMAT telescope became operational for astronomical research in 2018.\nHistory.\nSite.\nThere had been significant buildings on this land since the reign of William I. Greenwich Palace, on the site of the present-day National Maritime Museum, was the birthplace of both Henry VIII and his daughters Mary I and Elizabeth I; the Tudors used Greenwich Castle, which stood on the hilltop that the Observatory presently occupies, as a hunting lodge. Greenwich Castle was reportedly a favourite place for Henry VIII to house his mistresses, so that he could easily travel from the Palace to see them.\nIn 1676 the main building of the observatory, now known as Flamsteed House, was completed on Greenwich hill.\nEstablishment.\nThe establishment of a Royal Observatory was proposed in 1674 by Sir Jonas Moore who, in his role as Surveyor-General of the Ordnance, persuaded King Charles II to create the observatory, with John Flamsteed installed as its director. The Ordnance Office was given responsibility for building the Observatory, with Moore providing the key instruments and equipment for the observatory at his own personal cost. Flamsteed House, the original part of the Observatory, was designed by Sir Christopher Wren, probably assisted by Robert Hooke, and was the first purpose-built scientific research facility in Britain. It was built for a cost of \u00a3520 (\u00a320 over budget; ) out of largely recycled materials on the foundations of Duke Humphrey's Tower, the forerunner of Greenwich Castle, which resulted in the alignment being 13 degrees away from true North, somewhat to Flamsteed's chagrin.\nMoore donated two clocks, built by Thomas Tompion, which were installed in the 20-foot-high Octagon Room, the principal room of the building. They were of unusual design, each with a pendulum in length mounted above the clock face, giving a period of four seconds and an accuracy, then unparalleled, of seven seconds per day.\nThe original observatory housed the Astronomer Royal, his assistant and his family as well as the scientific instruments to be used by Flamsteed in his work on stellar tables. Over time the institution became a more established institution, thanks to its links to long-lasting government boards (the Board of Ordnance and Board of Longitude) and oversight by a Board of Visitors, founded in 1710 and made up of the President and Members of the council of the Royal Society. By the later 18th century it incorporated additional responsibilities such as publishing \"The Nautical Almanac\", advising government on technical matters, disseminating time, making meteorological and magnetic observations and undertaking astrophotography and spectroscopy. The physical site and the numbers of staff increased over time as a result.\nPositional astronomy and star charts.\nWhen the observatory was founded in 1675, one of the best star catalogues was Tycho Brahe's 1000-star catalogue from 1598. However, this catalogue was not accurate enough to determine longitudes. One of Flamsteed's first orders of business was creating more accurate charts suitable for this purpose.\nOne of the noted charts made at Greenwich was by the Astronomer Royal James Bradley, who between 1750 and 1762 charted sixty thousand stars, so accurately his catalogues were used even in the 1940s. Bradley was the third Astronomer Royal, and his tenure started in 1742.\nIn the early 19th century, the main positional devices were the Troughton Transit instrument and a mural circle, but after George Biddell Airy took over as Astronomer Royal in 1835, he embarked on a plan to have better instruments at Greenwich observatory.\nPositional astronomy was one of the primary functions of Greenwich for the Admiralty. Astronomer Royal Airy was an advocate of this and the transit circle instrument he had installed in 1851 was used for a century for positional astronomy. One of the difficulties with positional astronomy, is accounting for the refraction of light through Earth's atmosphere. Sources of error include the precision of the instrumentation, and then there has to be accounting for precession, nutation, and aberration. Sources of error in the instrument have to be tracked down and accounted for to produce more accurate results.\nThe transit circle makes two measurements; along with a clock, the time a star passed a certain point in the sky as the Earth rotates, and the vertical angle of the location of the star. The instrument can be used to plot the locations of stars, or alternately, with an accurate star chart, the time at the location of the instrument.\n1832 transit of Mercury.\nThe Shuckburgh telescope of the Royal Observatory in Greenwich was used for the 1832 transit of Mercury. It was equipped with a filar micrometer by Peter Dollond and was used to provide a report of the events as seen through the small refractor. By observing the transit in combination with timing it and taking measures, a diameter for the planet was taken. They also reported the peculiar effects that they compared to pressing a coin into the Sun. The observer remarked:\nGreenwich Meridian.\nBritish astronomers have long used the Royal Observatory as a basis for measurement. Four separate meridians have passed through the buildings, defined by successive instruments. The basis of longitude, the meridian that passes through the Airy transit circle, first used in 1851, was adopted as the world's Prime Meridian at the International Meridian Conference at Washington, DC, on 22 October 1884 (voting took place on 13 October). Subsequently, nations across the world used it as their standard for mapping and timekeeping. The Prime Meridian was marked by a brass (later replaced by stainless steel) strip in the Observatory's courtyard once the buildings became a museum in 1960, and, since 16 December 1999, has been marked by a powerful green laser shining north across the London night sky.\nSince the first triangulation of Great Britain in the period 1783\u20131853, Ordnance Survey maps have been based on an earlier version of the Greenwich meridian, defined by the transit instrument of James Bradley. When the Airy circle (5.79 m to the east) became the reference for the meridian, the difference resulting from the change was considered small enough to be neglected. When a new triangulation was done between 1936 and 1962, scientists determined that in the Ordnance Survey system the longitude of the international Greenwich meridian was not 0\u00b0 but 0\u00b000'00.417\" (about 8\u00a0m) east. Besides the change of the reference line, imperfections of the surveying system added another discrepancy to the definition of the origin, so that the Bradley line itself is now 0\u00b000'00.12\" east of the Ordnance Survey Zero Meridian (about 2.3\u00a0m).\nThis old astronomical prime meridian has been replaced by a more precise prime meridian. When Greenwich was an active observatory, geographical coordinates were referred to a local oblate spheroid called a datum known as a geoid, whose surface closely matched local mean sea level. Several datums were in use around the world, all using different spheroids, because mean sea level undulates by as much as 100 metres worldwide. Modern geodetic reference systems, such as the World Geodetic System and the International Terrestrial Reference Frame, use a single oblate spheroid, fixed to the Earth's gravitational centre. The shift from several local spheroids to one worldwide spheroid caused all geographical coordinates to shift by many metres, sometimes as much as several hundred metres. The Prime Meridian of these modern reference systems is the IERS Reference Meridian, in full the International Earth Rotation and Reference Systems Service Reference Meridian (in short called the IRM), which is 102.5 metres east of the Airy Greenwich astronomical meridian represented by the stainless steel strip, which is now 5.31\u00a0arcseconds west. The modern location of the Airy Transit is as the IRM is at 0 degree in longitude nowadays.\nInternational time from the end of the 19th century until UT1 was based on Simon Newcomb's equations, giving a mean sun about 0.18 seconds behind UT1 (the equivalent of 2.7 arcseconds) as of 2013; it coincided in 2013 with a meridian halfway between Airy's circle and the IERS origin: .\nGreenwich Mean Time.\nA key instrument for determining time was the Airy Transit Circle (ATC), which was used primarily from 1851 to 1938. It was agreed that the (Prime) \"meridian line marked by the cross-hairs in the Airy Transit Circle eyepiece would indicate 0\u00b0 longitude and the start of the Universal Day\". (Note, however, that this Prime Meridian is obsolete; the ITRF Zero Meridian, which is more than 100 meters east, is the modern standard defining longitude.) The time was determined by marking the time a star of known location would pass through the aimpoint of the telescope. In a reverse case, this type of instrument was also used for making star charts. The stars whose position was known precisely enough for being used for time determination, were called \"clock stars\".\nBy 1925, confusion about whether GMT was reckoned from noon or from midnight led (in 1928) to the IAU retiring GMT for astronomical and chronological purposes, replacing it with Universal Time (UT). In 1929, UT was redefined as a statistical combination of multiple observatories. In 1948, the Office of the Astronomer Royal was moved to Herstmonceux in East Sussex and in 1957, the observatory closed, ceasing time measurement operations.\nThe term \"GMT\" continues to be promoted by the Observatory and the UK in general, despite no longer being measured in any way. Coordinated Universal Time (UTC) forms the basis of modern civil time, and is based on the best attributes of UT1 (the modern form of UT, now measured from extra-galactic radio sources) and International Atomic Time (TAI, time kept by accurate clocks).\nGreenwich Time Ball.\nThe red time ball of Greenwich was established in 1833, and is noted as a public time signal. The time ball in modern times is normally in a lowered position, then starting at 12:55pm, the ball begins to rise, then at 12:58 it reaches the top; at 1pm the ball drops.\nTo help mariners at the port and others in line of sight of the observatory to synchronise their clocks to GMT, in 1833 Astronomer Royal John Pond installed a very visible time ball that drops precisely at 1pm (13:00) every day atop the observatory. Initially it was dropped by an operator; from 1852 it was released automatically via an electric impulse from the Shepherd Master Clock. The ball is still dropped daily at 13:00 (GMT in winter, BST in summer).\nThe original time ball system was built by Messrs Maudslay and Field, and cost \u00a3180. The five-foot diameter ball was made of wood and leather. In the original ball system, it was hoisted by a rope up from the Octagon room, and there was a catch at the top to hold it. This could then be triggered by hand, while observing the time on an astronomical month clock, that was regulated to the mean solar time.\nBy dropping the ball, the public, mariners, and clock makers could then get a time signal by viewing it from afar. The ball drop would be repeated at 2pm also if possible.\nThe reason why 12 noon was not chosen was because astronomers at the observatory would record when the Sun crossed the meridian at that time on that day.\nIn rare occasions where the ball could get stuck due to icing or snow, and if the wind was too high it would not be dropped. In 1852, it was established to distribute a time signal by the telegraph wires also.\nThe time ball was extremely popular with the public, chronometers, railways, mariners, and there was a petition to have another time ball established in Southampton also.\n1890s.\nThe 1890s marked the addition of a new larger refractor, the 28-inch Grubb in the Great Equatorial Dome. Because the new telescope was longer than the old Great Refractor, the new dome had to be bigger; thus the famous \"onion dome\" that expands beyond the diameter of the turret was established. For the tricentennial, it was revitalized with a fibre-glass dome; the old one made of papier-m\u00e2ch\u00e9 and iron had been taken down.\nThe telescope was installed by 1893, with 28-inch diameter glass doublet lens made by Grubb from Chance of Birmingham glass. The new dome was made by T. Cooke and Sons. This replaced a smaller drum-shaped dome.\nThe Lassell two-foot reflector was a famous metal-mirror telescope that had been used to discover the Moons Triton (orbiting Neptune) and Hyperion (orbiting Saturn). It was donated to the observatory in the 1880s, but was taken down in the 1890s.\nThe 1890s also saw the construction of the Altazimuth Pavilion, completed in 1896 and designed by William Crisp.\nIn 1898 the Christie Enclosure was established to house sensitive magnetic instruments that had been disrupted by the use of iron at the main facility.\nThe Observatory underwent an attempted bombing on 15 February 1894. This was possibly the first \"international terrorist\" incident in Britain. The bomb was accidentally detonated while being held by 26-year-old French anarchist Martial Bourdin in Greenwich Park, near the Observatory building. Bourdin died about 30 minutes later. It is not known why he chose the observatory, or whether the detonation was intended to occur elsewhere. The novelist Joseph Conrad used the incident in his 1907 novel \"The Secret Agent\".\nEarly 20th century.\nFor major parts of the twentieth century, the Royal Greenwich Observatory was not at Greenwich, because it moved to Herstmonceux in East Sussex in 1957. The last time that all departments were in Greenwich was 1924: in that year electrification of the railways affected the readings of the Magnetic and Meteorological Departments, and the Magnetic Observatory moved to Abinger in Surrey. Prior to this, the observatory had had to insist that the electric trams in the vicinity could not use an earth return for the traction current.\nAfter the onset of World War II in 1939, many departments were temporarily evacuated out of range of German bombers, to Abinger, Bradford on Avon, Bristol, and Bath, and activities in Greenwich were reduced to the bare minimum.\nOn 15 October 1940, during the Blitz, the Courtyard gates were destroyed by a direct bomb hit. The wall above the Gate Clock collapsed, and the clock's dial was damaged. The damage was repaired after the war.\nThe Royal Observatory at Herstmonceux.\nAfter the Second World War, in 1947, the decision was made to move the Royal Observatory to Herstmonceux Castle and 320 adjacent acres (1.3\u00a0km2), 70\u00a0km south-southeast of Greenwich near Hailsham in East Sussex, due to light pollution in London. The Observatory was officially known as the \"Royal Greenwich Observatory, Herstmonceux\". Although the Astronomer Royal Harold Spencer Jones moved to the castle in 1948, the scientific staff did not move until the observatory buildings were completed, in 1957. Shortly thereafter, other previously dispersed departments were reintegrated at Herstmonceux, such as the Nautical Almanac Office, Chronometer Department, the library, and observing equipment.\nThe largest telescope at Greenwich at that time, the Yapp telescope 36-inch reflector, was moved out to Herstmonceux in 1958. There it was reconstructed in Dome B of the facility. There it was used for astronomy in the 1960s, 1970s, and 1980s. It was left behind at Herstmonceux in 1990 in its dome when the organization moved once again.\nThe tricentennial of Sir Isaac Newton had passed during the Second World War, delaying festivities. One of the ground-swells was to build a 'big better' telescope in honour of the celebrated inventor of the Newtonian reflecting telescope. Some two decades of development led to the commissioning of the Isaac Newton Telescope at Herstmonceux. It proved so successful that the cloudy weather was felt to be a bottleneck to its productivity, and plans were made to get it to a higher spot with better weather.\nOn 1 December 1967, the Isaac Newton Telescope of the Royal Greenwich Observatory at Herstmonceux was inaugurated by Queen Elizabeth II. The telescope was the biggest telescope by aperture in the British Isles. It was moved to Roque de los Muchachos Observatory in Spain's Canary Islands in 1979. In 1990 the RGO moved to Cambridge. At Herstmonceux, the castle grounds became the home of the International Study Centre of Queen's University, Kingston, Canada, and the Observatory Science Centre, which is operated by an educational charity Science Project.\nThe Observatory Science Centre opened in April 1995. Some of the remaining telescopes, which were left behind in the move, have public observation events as part of operations of the centre. The centre has established itself as a noted tourist and education attraction in its own right, featuring many old observatory items as exhibits. It was getting 60,000 visitors per year in the early 21st century.\nThe Royal Observatory at Cambridge.\nIn 1990 the Royal Observatory moved from Herstmonceux to a new site at Cambridge, adjacent to the University's Institute of Astronomy, where it occupied Greenwich House just to the north of the Cambridge Observatory. By now, the RGO's focus had moved from carrying out observations from the British Isles to providing technical support, acting as a conduit between scientists in British universities and the powerful British-owned telescopes (such as the Isaac Newton Telescope, the Anglo-Dutch Jacobus Kapteyn Telescope, and the William Herschel Telescope) on the Canary Islands and Hawaii.\nAfter abandoning a plan to privatise the RGO and the Royal Observatory Edinburgh, the Particle Physics and Astronomy Research Council (PPARC) as the RGO's funding body made the decision to close the institution and the Cambridge site by 1998. When the RGO was closed as an institution, the HM Nautical Almanac Office transferred to the Rutherford Appleton Laboratory (Harwell Science and Innovation Campus, Chilton, Oxfordshire), while other work went to the UK Astronomy Technology Centre in Edinburgh. The old observatory site at Greenwich returned to its original name \u2013 the Royal Observatory, Greenwich \u2013 and was made part of the National Maritime Museum.\nIn 2002 the UK joined the European Southern Observatory, building the VISTA infrared telescope at the Paranal Observatory as an in-kind contribution.\nThe Astronomer Royal Martin Rees called PPARC \"irresponsible\" for how it handled the RGO.\nGreenwich site returns to active use.\nIn 2018 the Annie Maunder Astrographic Telescope (AMAT) was installed at the ROG in Greenwich. AMAT is a cluster of four separate instruments, to be used for astronomical research; it had achieved first light by June 2018, and contains:\nThe telescopes and the works at the site required to operate them cost about \u00a3150,000, from grants, museum members and patrons, and public donations.\nThe telescope was installed in the Altazimuth Pavilion, from which the multi-purpose telescope is controlled by a computer system.\nMagnetic observations.\nThe first magnetic observation was taken in 1680 by the first Astronomer Royal, John Flamsteed, using a magnetic needle from the Royal Society. The second and third Astronomers Royal, Edmond Halley and then James Bradley, also took some magnetic measurements during their tenure.\nIn the 19th century George Airy established the Magnetical and Meteorological Department.\nThe first Magnetic House was built next to the observatory but by 1900 a second, about 300\u2013400 metres from the main observatory, was built to reduce magnetic interference. Both houses were made of non-magnetic materials. The older building was called the Magnet House, but iron added to buildings in the 1890s at the observatory was throwing off measurements, so the instruments were moved to the Magnetic Pavilion. A new Magnetograph House was also completed by 1914.\nOne of the special events that occurred in the study of magnetism was when Fran\u00e7ois Arago and Alexander von Humboldt took magnetic observations at Greenwich in 1822. In 1825 Arago won the Copley Gold Medal for this research (see also Arago's rotations).\nObservatory museum.\nThe observatory buildings at Greenwich became a museum of astronomical and navigational tools, which is part of the Royal Museums Greenwich. Notable exhibits include John Harrison's pioneering chronometer, known as H4, for which he received a large reward from the Board of Longitude, and his three earlier marine timekeepers; all four are the property of the Ministry of Defence. Many additional horological artefacts are displayed, documenting the history of precision timekeeping for navigational and astronomical purposes, including the mid-20th-century Russian-made F.M. Fedchenko clock (the most accurate pendulum clock ever built in multiple copies). It also houses the astronomical instruments used to make meridian observations and the 28-inch equatorial Grubb refracting telescope of 1893, the largest of its kind in the UK. The Shepherd Clock outside the observatory gate is an early example of an electric slave clock.\nIn 1997 the observatory site was getting 400,000 visitors per year.\nIn February 2005 a \u00a316\u00a0million redevelopment comprising a new planetarium and additional display galleries and educational facilities was started; the ROG reopened on 25 May 2007 with the new 120-seat Peter Harrison Planetarium.\nFor a year between 2016 and 2017 the Museum reported 2.41 million visitors.\nIn July 2024, Royal Museums Greenwich announced plans for a redevelopment of the Royal Observatory site to improve the visitor experience.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43990", "revid": "43009014", "url": "https://en.wikipedia.org/wiki?curid=43990", "title": "Charing Cross Road", "text": "Street in central London\nCharing Cross Road is a street in central London running immediately north of St Martin-in-the-Fields to St Giles Circus (the intersection with Oxford Street), which then merges into Tottenham Court Road. It leads from the north in the direction of Charing Cross at the south side of Trafalgar Square. It connects via St Martin's Place and the motorised east side of the square.\nHistory.\nCharing Cross road was originally two narrow streets in the West End, Crown Street and Castle Street. The development of Regent Street (parallel to the west) in the mid-18th century coincided with not only the building up of great fields west of the area but also Westminster Bridge which was built as central London and the wider estuary's second bridge after more than a century of pressure, in 1750.\nThese pressures therefore congested the north\u2013south axis of the inner West End almost as much as the relieved London Bridge area. Specifically a major increase in traffic occurred around Piccadilly Circus, Charing Cross and Oxford Street, much of it destined from/to Tottenham Court Road, Bloomsbury and nearby routes to all northerly directions.\nCharing Cross Road was therefore developed, in conjunction with Shaftesbury Avenue, by the Metropolitan Board of Works under an 1877 Act of Parliament. The Act's total costs, including demolition and rebuilding of many rows of buildings across London was \u00a3778,238. The two streets and others such as the Thames Embankment, Northumberland Avenue and the Kingsway-Aldwych superstructure were built to improve traffic flow through central London. The scheme abolished some of the worst slums in London which delayed progress in construction while the inhabitants were rehoused.\nBookshops.\nCharing Cross Road is renowned for its specialist and second-hand bookshops. The section from Leicester Square Underground station to Cambridge Circus is home to specialist bookshops, and more general second-hand and antiquarian shops such as Quinto Bookshop, Henry Pordes and Any Amount of Books. Zwemmer's Bookshop, an arts bookshop founded in 1922, was present at 79 Charing Cross Road until 2002. Smaller second-hand and specialist antiquarian bookshops can be found on the adjoining Cecil Court.\nThe northern section between Cambridge Circus and Oxford Street includes more generalist bookshops such as the venerable Foyles. A long-standing correspondence between New York City-based author Helene Hanff and the staff of a bookshop on the street, Marks &amp; Co., was the inspiration for the book \"84, Charing Cross Road\" (1970). The book was made into a 1987 film starring Anne Bancroft and Anthony Hopkins and also into a play and a BBC radio drama. As of 2022[ [update]] the building is a restaurant at street level, entered around the corner in Cambridge Circus, but its upper levels of the building remain as originally constructed. A brass plaque on the stone pilaster facing Charing Cross Road commemorates the former bookshop and Hanff's book.\nFeatures.\nThe London Astoria music venue was located here before its demolition in 2009, as is one of the sites of St Martin's Arts College, opening in 1939. To the northeast of Charing Cross Road are the music shops on Denmark Street (known as Britain's Tin Pan Alley).\nA number of theatres are on or near Charing Cross Road, such as the Phoenix Theatre (which has its entrance on the adjoining Phoenix Street), the Garrick Theatre and Wyndham's Theatre.\nBeneath the grille in the traffic island between Charing Cross Road's junction with Old Compton Street, in the middle of the road, a road sign reading Little Compton Street can be seen, which was a historic name for the eastern end of Old Compton Street beyond its junction with Greek Street.\nOn the east side of the road's southern end, at the joining of St Martins Lane, is a statue of Edith Cavell. Towards the north end is the Phoenix Garden, an environmental garden run by local residents.\nIn popular culture.\nIn the \"Harry Potter\" books, the Leaky Cauldron pub is located on Charing Cross Road. Author J.K. Rowling chose this road because \"it is famous for its bookshops, both modern and antiquarian. This is why I wanted it to be the place where those in the know go to enter a different world.\"\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43991", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=43991", "title": "Big Ball Of Mud", "text": ""}
{"id": "43992", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=43992", "title": "Code and fix", "text": ""}
{"id": "43993", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=43993", "title": "Chloroplasts", "text": ""}
{"id": "43994", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=43994", "title": "Bell Laboratories", "text": ""}
{"id": "43995", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=43995", "title": "1700s BC", "text": ""}
{"id": "43996", "revid": "5183450", "url": "https://en.wikipedia.org/wiki?curid=43996", "title": "Supreme Court", "text": ""}
{"id": "43997", "revid": "12418561", "url": "https://en.wikipedia.org/wiki?curid=43997", "title": "Alyson Hannigan", "text": "American actress and television presenter (born 1974)\nAllison Lee Hannigan (born March 24, 1974), known professionally as Alyson Hannigan, is an American actress and television presenter. She began her film career with supporting roles in the comedy films \"Impure Thoughts\" (1986) and \"My Stepmother Is an Alien\" (1988), receiving a Young Artist Award nomination for the latter. In 1999, she began starring in the \"American Pie\" film series as Michelle Flaherty, the films' primary love interest, appearing in every film in the series from 1999 to 2012. For her role in the series, she was nominated for three Teen Choice Awards and won a Young Hollywood Award. She went on to star in the parody film \"Date Movie\" (2006), the slasher film \"You Might Be the Killer\" (2018), and the superhero film \"Flora &amp; Ulysses\" (2021).\nHannigan got her start in television starring in the short-lived sitcom \"Free Spirit\" from 1989 to 1990, for which she earned a Young Artist Award nomination. After several minor roles in television films and other series, she appeared in her breakout role as teenage witch Willow Rosenberg in the supernatural drama series \"Buffy the Vampire Slayer\", appearing in every episode from 1997 to 2003. Her role on the show was critically acclaimed and won her the Saturn Award for Best Supporting Actress on Television and a Teen Choice Award. From 2005 to 2014, she starred as Lily Aldrin in the sitcom \"How I Met Your Mother\", for which she won two People's Choice Awards. Hannigan hosted the television show \"\" (2016\u20132023), and provided the voice of Claire Clancy in the Disney Junior animated series \"Fancy Nancy\" (2018\u20132022).\nEarly life and education.\nHannigan was born on March 24, 1974 in Washington, D.C., the only child of Emilie (Posner) Haas, a real-estate agent, and Alan Hannigan, a Teamsters trucker. Her father is of Irish ancestry and her mother is Jewish. At age four, Hannigan began appearing in commercials. After spending her childhood in her mother's hometown of Atlanta, Georgia, Hannigan moved to Hollywood at age 11 after securing an agent. As a teenager, Hannigan babysat for the children of her future \"How I Met Your Mother\" co-star, Bob Saget.\nLiving with her mother and attending North Hollywood High School, she successfully auditioned for agents while visiting her father in Santa Barbara. After high school, she attended California State University, Northridge, where she was a member of the Alpha Chi Omega sorority and earned a degree in psychology.\nCareer.\n1986\u20132004: Career beginnings and breakthrough.\nHannigan's first major film role was in \"My Stepmother Is an Alien\", a science-fiction comedy released in 1988; one of her co-stars in the film was actor Seth Green, who later joined her in the regular cast of \"Buffy the Vampire Slayer\" as her on-screen boyfriend. In 1989, her first regular role on a television series came when she was cast in the short-lived ABC sitcom \"Free Spirit\".\nIn 1997, Hannigan was cast to play Willow Rosenberg, Buffy Summers' best friend, on the supernatural television series \"Buffy the Vampire Slayer\". The show became a success, and Hannigan gained recognition, subsequently appearing in several films aimed at teenage audiences, including \"Boys and Girls\" (2000). She had a supporting role as Michelle Flaherty in the comedy film \"American Pie\" (1999), and appeared in a much larger role in its sequels \"American Pie 2\" (2001) and \"American Wedding\" (2003). In 2017, \"Forbes\" reported that the \"American Pie\" films have grossed $989.5 million at the worldwide box office, and became a pop culture phenomenon.\nShe also had a recurring guest spot on the \"Buffy the Vampire Slayer\" spin-off, \"Angel\", reprising her role of Willow. In early 2004, Hannigan made her West End debut, starring in a stage adaptation of \"When Harry Met Sally...\" at the Theatre Royal Haymarket, opposite Luke Perry.\n2005\u20132014: Success with \"How I Met Your Mother\".\nIn early 2005, she had a recurring guest role as Trina Echolls in three episodes of UPN's teen mystery series \"Veronica Mars.\" In September 2005, Hannigan returned to starring in a regular television series, taking the main role of Lily Aldrin in CBS' sitcom \"How I Met Your Mother\". The series followed architect Ted Mosby and his group of friends in New York City. Ted recounts to his children the events that led him to meet their mother. Hannigan's character Lily was a kindergarten teacher and amateur painter, who eventually married lawyer Marshall Eriksen, portrayed by Jason Segel. Hannigan won the People's Choice Award for Favorite TV Comedy Actress in 2010. Known for its unique structure, humor, and incorporation of dramatic elements, \"How I Met Your Mother\" was popular throughout its run. The series ran for nine seasons and the one-hour series finale aired on March 31, 2014.\nIn February 2006, she starred as Julia Jones in \"Date Movie\", a parody of romantic comedies. She was also a guest star on the ABC animated sitcom \"The Goode Family\" in 2009.\nHannigan joined forces with Emily Deschanel, Jaime King, Minka Kelly, and Katharine McPhee in a \"video slumber party\" featured on FunnyorDie.com to promote regular breast cancer screenings for the organization Stand Up 2 Cancer. Hannigan reprised the role of Michelle in the comedy film \"American Reunion\" (2012). The film followed the friends attending a high school reunion thirteen years after graduating from high school. The film was a success at the box office, and grossed $235 million worldwide. For her role in the film, she was nominated for Choice Movie Actress: Romantic Comedy award at the 2012 Teen Choice Awards.\n2015\u2013present: Television hosting.\nHannigan hosted the television series \"\" from 2016 to 2023. Hannigan played Ann Possible, Kim's mother, in the Disney Channel original film \"Kim Possible\" (2019), based on the animated series. She voiced the role of Claire Nancy in Disney Junior's animated series \"Fancy Nancy\" (2018\u20132022). The show ran for three seasons and the series finale aired on February 18, 2022.\nIn September 2023, Hannigan was announced as one of the contestants on season 32 of \"Dancing with the Stars\", partnering with Sasha Farber. The couple made it to the finals and finished in fifth place.\nPersonal life.\nHannigan married her \"Buffy the Vampire Slayer\" and \"Angel\" co-star Alexis Denisof at Two Bunch Palms Resort in Desert Hot Springs, California, on October 11, 2003. The couple live in Encino, Los Angeles, with their two daughters. Their home was used as a set for \"This Is Us\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "43998", "revid": "50483892", "url": "https://en.wikipedia.org/wiki?curid=43998", "title": "United States Secretary of Defense", "text": "Head of the US Department of Defense\nThe United States secretary of defense (SecDef), secondarily titled the secretary of war (SecWar), is the head of the United States Department of Defense (DoD), the executive department of the U.S. Armed Forces, and is a high-ranking member of the cabinet of the United States. The secretary of defense's position of command and authority over the military is second only to that of the president of the United States, who is the commander-in-chief. This position corresponds to what is generally known as a defense minister in many other countries. The president appoints the secretary of defense with the advice and consent of the Senate, and is by custom a member of the Cabinet and by law a member of the National Security Council.\nSubject only to the orders of the president, the secretary of defense is in the chain of command and exercises command and control, for both operational and administrative purposes, over all DoD-administered service branches \u00a0\u2013 the Army, Marine Corps, Navy, Air Force, and Space Force\u00a0\u2013 as well as the Coast Guard when its command and control is transferred to the Department of Defense. Only the secretary of defense (or the president or Congress) can authorize the transfer of operational control of forces between the three military departments (Department of the Army, the Navy, and the Air Force) and the eleven Unified Combatant Commands.\nTo ensure civilian control of the military, U.S. law provides that the secretary of defense cannot have served as an active-duty commissioned officer in the military in the preceding seven years except for generals and admirals, who cannot have served on active duty within the previous ten years. Congress can legislatively waive this restriction and has done so three times, for George C. Marshall Jr., James N. Mattis, and Lloyd J. Austin III. The chairman of the Joint Chiefs of Staff is the principal military adviser to the secretary of defense and the president; while the chairman may assist the secretary and president in their command functions, the chairman is not in the chain of command.\nBecause the secretary of defense is vested with legal powers that exceed those of any commissioned officer, and is second only to the president in the military hierarchy, its incumbent has sometimes unofficially been referred to as \"deputy commander-in-chief\". The secretary of state, the secretary of the treasury, the secretary of defense, and the attorney general are generally regarded as the four most important (and are officially the four most senior and oldest) cabinet officials because of the size and importance of their respective departments.\nThe current secretary of defense is Pete Hegseth, who was nominated by President Donald Trump and was confirmed by the Senate on 25 January 2025.\nHistory.\nAn Army, Navy, and Marine Corps were established in 1775, in concurrence with the American Revolution. The War Department, headed by the secretary of war, was created by Act of Congress in 1789 and was responsible for both the Army and Navy until the founding of a separate Department of the Navy in 1798.\nBased on the experiences of World War II, proposals were soon made on how to more effectively manage the large combined military establishment. The Army generally favored centralization while the Navy had institutional preferences for decentralization and the status quo. The resulting National Security Act of 1947 was largely a compromise between these divergent viewpoints. It renamed the Department of War the Department of the Army, and added both it and the Department of the Navy to a newly established National Military Establishment (NME). The act also separated the Army Air Forces from the Army to become its own branch of service, the United States Air Force.\nA new title was coined by the act for the head of the NME: Secretary of Defense. At first, each of the service secretaries maintained cabinet status. The first secretary of defense, James Forrestal, who in his previous capacity as the secretary of the Navy had opposed the creation of the new position, found it difficult to exercise authority over the other branches with the limited powers his office had at the time. To address this and other problems, the National Security Act was amended in 1949 to further consolidate the national defense structure in order to reduce interservice rivalry, directly subordinate the secretaries of the Army, the Navy and the Air Force to the secretary of defense in the chain of command, and rename the National Military Establishment as the Department of Defense, making it one Executive Department. The position of the deputy secretary of defense, the number two position in the department, was also created at this time.\nThe general trend since 1949 has been to further centralize management in the Department of Defense, elevating the status and authorities of civilian OSD appointees and defense-wide organizations at the expense of the military departments and the services within them. The last major revision of the statutory framework concerning the position was done in the Goldwater\u2013Nichols Department of Defense Reorganization Act of 1986. In particular, it elevated the status of joint service for commissioned officers, making it in practice a requirement before appointments to general officer and flag officer grades could be made.\nAs the secretary of defense is a civilian position intended to be independent of the active-duty leadership, a secretary is required to have been retired from service for at least seven (originally ten) years unless a waiver is approved by Congress. Since the creation of the position in 1947, such a waiver has been approved only three times, for Army general George Marshall in 1950, Marine Corps General Jim Mattis in 2017, and retired Army general Lloyd Austin in 2021.\nPowers and functions.\nThe secretary of defense, appointed by the president with the advice and consent of the Senate, is by federal law (\u00a0https://) the head of the Department of Defense, \"the principal assistant to the President in all matters relating to Department of Defense\", and has \"authority, direction and control over the Department of Defense\". Because the Constitution vests all military authority in Congress and the president, the statutory authority of the secretary of defense is derived from their constitutional authorities. Since it is impractical for either Congress or the president to participate in every piece of Department of Defense affairs, the secretary of defense and the secretary's subordinate officials generally exercise military authority.\nAs the head of DoD, all officials, employees and service members are \"under\" the secretary of defense. Some of those high-ranking officials, civil and military (outside of OSD and the Joint Staff) are: the secretary of the Army, secretary of the Navy, and secretary of the Air Force, Army chief of staff, commandant of the Marine Corps, chief of naval operations, Air Force chief of staff, chief of space operations, and chief of the National Guard Bureau and the combatant commanders of the Combatant Commands. All these high-ranking positions, civil and military, require Senate confirmation.\nThe Department of Defense is composed of the Office of the Secretary of Defense (OSD), the Joint Chiefs of Staff (JCS) and the Joint Staff (JS), Office of the Inspector General (DODIG), the Combatant Commands, the Military Departments (Department of the Army (DA), Department of the Navy (DON) &amp; Department of the Air Force (DAF)), the Defense Agencies and DoD Field Activities, the National Guard Bureau (NGB), and such other offices, agencies, activities, organizations, and commands established or designated by law, or by the president or by the secretary of defense.\nDepartment of Defense Directive 5100.01 describes the organizational relationships within the department and is the foundational issuance for delineating the major functions of the department. The latest version, signed by former secretary of defense Robert Gates in December 2010, is the first major re-write since 1987.\nOffice of the Secretary of Defense.\nThe secretary's principally civilian staff element is called the Office of the Secretary of Defense (OSD) and is composed of the deputy secretary of defense (DEPSECDEF) and six under secretaries of defense in the fields of acquisition &amp; sustainment, research &amp; engineering, comptroller/chief financial officer, intelligence, personnel &amp; readiness, and policy; several assistant secretaries of defense; other directors and the staffs under them. The Secretary of Defense is issuing through the Office of the Secretary of Defense the National Defense Strategy, a major policy document.\nThe name of the principally military staff organization, organized under the chairman of the Joint Chiefs of Staff, is the Joint Staff (JS).\nAwards and decorations.\nThe Defense Distinguished Service Medal (DDSM), the Defense Superior Service Medal (DSSM), the Defense Meritorious Service Medal (DMSM), the Joint Service Commendation Medal (JSCM) and the Joint Service Achievement Medal (JSAM) are awarded, to military personnel for service in joint duty assignments, in the name of the secretary of defense. In addition, there is the Joint Meritorious Unit Award (JMUA), which is the only ribbon (as in non-medal) and unit award issued to joint DoD activities, also issued in the name of the secretary of defense.\nThe DDSM is analogous to the distinguished services medals issued by the military departments (i.e. Army Distinguished Service Medal, Navy Distinguished Service Medal &amp; Air Force Distinguished Service Medal), the DSSM corresponds to the Legion of Merit, the DMSM to the Meritorious Service Medal, the JSCM to the service commendation medals, and the JSAM to the achievement medals issued by the services. While the approval authority for DSSM, DMSM, JSCM, JSAM and JMUA is delegated to inferior DoD officials: the DDSM can be awarded only by the secretary of defense.\nRecommendations for the Medal of Honor (MOH), formally endorsed in writing by the secretary of the military department concerned and the chairman of the Joint Chiefs of Staff, are processed through the under secretary of defense for personnel and readiness, and such recommendations be must approved by the secretary of defense before it can be handed over to the president, who is the final approval authority for the MOH, although it is awarded in the name of Congress.\nThe secretary of defense, with the concurrence of the secretary of state, is the approval authority for the acceptance and wear of NATO medals issued by the secretary general of NATO and offered to the U.S. permanent representative to NATO in recognition of U.S. servicemembers who meet the eligibility criteria specified by NATO.\nCongressional committees.\nAs the head of the department, the secretary of defense is the chief witness for the congressional committees with oversight responsibilities over the Department of Defense. The most important committees, with respect to the entire department, are the two authorizing committees, the Senate Armed Services Committee (SASC) and the House Armed Services Committee (HASC), and the two appropriations committees, the Senate Appropriations Committee and the House Appropriations Committee.\nFor the DoD intelligence programs the Senate Select Committee on Intelligence and the House Permanent Select Committee on Intelligence have the principal oversight role.\nNational Security Council.\nThe secretary of defense is a statutory member of the National Security Council. As one of the principals, the secretary along with the vice president, secretary of state and the assistant to the president for national security affairs participates in biweekly Principals Committee (PC) meetings, preparing and coordinating issues before they are brought before full NSC sessions chaired by the president.\nRole in the military justice system.\nThe secretary is one of only five or six civilians\u00a0\u2013 the others being the president, the three \"service secretaries\" (the secretary of the Army, secretary of the Navy, and secretary of the Air Force), and the secretary of homeland security (when the United States Coast Guard is under the United States Department of Homeland Security and has not been transferred to the Department of the Navy under the Department of Defense)\u00a0\u2013 authorized to act as convening authority in the military justice system for General Courts-Martial (\u00a0https://: article 22, UCMJ), Special Courts-Martial (\u00a0https://: article 23, UCMJ), and Summary Courts-Martial (\u00a0https://: article 24 UCMJ).\nSalary.\nThe secretary of defense is a Level I position in the Executive Schedule, thus earning a salary of US$246,400, as of October 2024.\nList of secretaries of defense.\nThe longest-serving secretary of defense is Robert McNamara, who served for a total of 7years, 39 days. Combining his two non-sequential services as the secretary of defense, the second-longest serving is Donald Rumsfeld, who served just ten days fewer than McNamara. The second-longest unbroken tenure was Caspar Weinberger's, at 6years, 306 days.\nThe shortest-serving secretary of defense is Elliot Richardson, who served 114 days and then was appointed U.S. attorney general amid the resignations of the Watergate Scandal (this is not counting deputy secretaries of defense William P. Clements and William Howard Taft IV, who each served a few weeks as temporary/acting secretary of defense).\nFor precursors to this position prior to the establishment of the Department of Defense, see the lists of secretaries of the Navy and secretaries of war prior to 1947.\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Democratic\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Republican\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Independent / Unknown\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Denotes an acting secretary of defense\nSuccession.\nPresidential succession.\nThe secretary of defense is sixth in the presidential line of succession, following the secretary of the treasury and preceding the attorney general.\nSecretary succession.\nOn 10 December 2020, President Donald Trump modified the order of succession for the office of Secretary of Defense in Executive Order 13963. The order of succession is:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44000", "revid": "12608568", "url": "https://en.wikipedia.org/wiki?curid=44000", "title": "United States Secretary of War", "text": "Position in the United States Cabinet from 1789 to 1947\nThe secretary of war was a member of the U.S. Cabinet, beginning with George Washington's administration. A similar position, called either \"Secretary at War\" or \"Secretary of War\", had been appointed to serve the Congress of the Confederation under the Articles of Confederation between 1781 and 1789. Benjamin Lincoln and later Henry Knox held the position. When Washington was inaugurated as the first president under the Constitution, he appointed Knox to continue serving as secretary of war.\nThe secretary of war was the head of the War Department. At first, he was responsible for the United States Army and the Navy. In 1798, the secretary of the Navy was created by statute, and the scope of responsibility for the War Department was reduced to the Army. From 1886 onward, the secretary of war was in the line of succession to the presidency, after the vice president of the United States, the Speaker of the House of Representatives, the president pro tempore of the Senate and the secretary of state.\nIn 1947, with the passing of the National Security Act of 1947, the secretary of war was replaced by the secretary of the Army and the secretary of the Air Force and a new secretary, the secretary of defense, was created for coordination of the services. Since 1949, the service secretaries, Army, Air Force, and Navy, have been non-Cabinet subordinates under the secretary of defense. The secretary of the Army's office is generally considered the direct successor to the secretary of war's office, with the new secretary of defense taking the secretaries of war and navy positions in the Cabinet, and the line of succession to the presidency.\nList of secretaries.\nSecretary at War (1781\u20131789).\nThe office of secretary at war was modeled upon Great Britain's secretary at war, who was William Barrington, 2nd Viscount Barrington, at the time of the American Revolution. The office of secretary at war was meant to replace both the commander-in-chief and the Board of War, and like the president of the board, the secretary wore no special insignia. The inspector general, quartermaster general, commissary general, and adjutant general served on the secretary's staff. However, the Army itself under Secretary Henry Knox only consisted of 700 men.\nSecretary of War (1789\u20131947).\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Federalist (4)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Democratic-Republican (8)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Democratic (14)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Whig (5)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Republican (25)\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44001", "revid": "1839637", "url": "https://en.wikipedia.org/wiki?curid=44001", "title": "United States Secretary of the Navy", "text": "Statutory office and the head of the U.S. Department of the Navy\nThe secretary of the Navy (SECNAV) is a statutory officer (\u00a0https://) and the head (chief executive officer) of the Department of the Navy, a military department within the United States Department of Defense. On March 25, 2025, John Phelan was confirmed as Secretary of the Navy.\nBy law, the secretary of the Navy must be a civilian at least seven years removed from active military service (\u00a0https://). The secretary is appointed by the president and requires confirmation by the Senate.\nHistory.\nThe position of Secretary of the Navy was created in 1798. It was a member of the president's Cabinet until 1949, when the secretary of the Navy (and the secretaries of the Army and Air Force) were by amendments to the National Security Act of 1947 made subordinate to the secretary of defense.\nFrom 2001 to 2019, proposals to rename the Department of the Navy to the Department of the Navy and Marine Corps, which would have also renamed the secretary of the Navy to the secretary of the Navy and Marine Corps, were introduced with wide support in the United States Congress, but failed due to the opposition of Senator and retired U.S. Navy officer John McCain.\nResponsibilities.\nThe Department of the Navy (DoN) consists of two uniformed services: the United States Navy and the United States Marine Corps. The secretary of the Navy is responsible for, and has statutory authority (\u00a0https://) to \"conduct all the affairs of the Department of the Navy\", i.e. as its chief executive officer, subject to the limits of the law, and the directions of the president and the secretary of defense. In effect, all authority within the Navy and Marine Corps, unless specifically exempted by law, is derivative of the authority vested in the secretary of the Navy.\nSpecifically enumerated responsibilities of the SECNAV in the aforementioned section are: recruiting, organizing, supplying, equipping, training, mobilizing, and demobilizing. The secretary also oversees the construction, outfitting, and repair of naval ships, equipment, and facilities. SECNAV is responsible for the formulation and implementation of policies and programs that are consistent with the national security policies and objectives established by the president or the secretary of defense.\nThe secretary of the Navy is a member of the Defense Acquisition Board (DAB), chaired by the under secretary of defense for acquisition, technology and logistics. Furthermore, the secretary has several statutory responsibilities under the Uniform Code of Military Justice (UCMJ) with respect to the administration of the military justice system for the Navy &amp; the Marine Corps, including the authority to convene general courts-martial and to commute sentences.\nThe principal military advisers to the SECNAV are the two service chiefs of the naval services: for matters regarding the Navy the chief of naval operations (CNO), and for matters regarding the Marine Corps the commandant of the Marine Corps (CMC). The CNO and the Commandant act as the principal executive agents of the SECNAV within their respective services to implement the orders of the secretary.\nNavy regulations.\nThe United States Navy Regulations is the principal regulatory document of the Department of the Navy, and all changes to it must be approved by the secretary of the Navy.\nU.S. Coast Guard.\nWhenever the United States Coast Guard operates as a service within the Department of the Navy, the secretary of the Navy has the same powers and duties with respect to the Coast Guard as the secretary of homeland security when the Coast Guard is not operating as a service in the Department of the Navy.\nNavy Secretariat.\nThe Office of the Secretary of the Navy, also known within DoD as the \"Navy Secretariat\" or simply just as the \"Secretariat\" in a DoN setting, is the immediate headquarters staff that supports the secretary in discharging his duties. The principal officials of the Secretariat include the Under Secretary of the Navy (the secretary's principal civilian deputy), the assistant secretaries of the Navy (ASN), the general counsel of the Navy, the judge advocate general of the Navy (JAG), the Naval inspector general (NIG), the chief of Legislative Affairs, and the chief of naval research. The Office of the Secretary of the Navy has sole responsibility within the Department of the Navy for acquisition, auditing, financial and information management, legislative affairs, and public affairs.\nPursuant to SecNavInst 5090.5F, the Department of the Navy \"Environmental Programs Manual\", the secretary of the Navy and chief of naval operations recognize a number of commands annually for achievements in such areas as environmental quality, environmental cleanup, natural resources conservation, cultural resources management, pollution prevention, and recycling. \nThe chief of naval operations and the commandant of the Marine Corps have their own separate staffs, the \"Office of the Chief of Naval Operations\" (also known by its acronym OPNAV) and \"Headquarters Marine Corps\".\nSecretaries of the Navy.\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Denotes acting secretaries\nContinental Congress.\n\"(Post of Secretary of Marine created but remained vacant)\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44002", "revid": "2304267", "url": "https://en.wikipedia.org/wiki?curid=44002", "title": "United States Attorney General", "text": "Head of the US Department of Justice\nThe United States attorney general (AG) is the head of the United States Department of Justice (DOJ) and serves as the chief law enforcement officer of the federal government. The attorney general acts as the principal legal advisor to the president of the United States on all legal matters. The attorney general is also a statutory member of the Cabinet of the United States and a member of the United States National Security Council. Additionally, the attorney general is seventh in the presidential line of succession. The attorney general is the only cabinet department head who is not given the title Secretary.\nUnder the Appointments Clause of the United States Constitution, the officeholder is nominated by the president of the United States, and, following a confirmation hearing before the Senate Judiciary Committee, will take office if confirmed by the majority of the full United States Senate. The attorney general is supported by the Office of the Attorney General, which includes executive staff and several deputy attorneys general.\nThe attorney general is a Level I position in the Executive Schedule and thus earns the salary prescribed for that level: $250,600, as of January 2025.\nName.\nThe title Attorney General is an example of a noun (\"attorney\") followed by a postpositive adjective (\"general\"). \"General\" is a description of the type of attorney, not a title or rank in itself (as it would be in the military). Even though the attorney general (and the similarly titled solicitor general) is occasionally referred to as \"General\" or \"General [last name]\" by senior government officials, this is considered incorrect in standard American English usage. For the same reason, the correct American English plural form is \"attorneys general\" rather than \"attorney generals\".\nHistory.\nCongress passed the Judiciary Act of 1789 which, among other things, established the Office of the Attorney General. The original duties of this officer were \"to prosecute and conduct all suits in the Supreme Court in which the United States shall be concerned, and to give his advice and opinion upon questions of law when required by the president of the United States, or when requested by the heads of any of the departments\". Some of these duties have since been transferred to the United States solicitor general and the White House counsel.\nThe Department of Justice was established in 1870 to support the attorneys general in the discharge of their responsibilities.\nThe secretary of state, the secretary of the treasury, the secretary of defense, and the attorney general are regarded as the four most important Cabinet officials in the United States because of the size and importance of their respective departments.\nDuties and responsibilities.\nThe attorney general's duties and responsibilities as the chief law enforcement officer of the federal government include overseeing the United States Department of Justice, enforcing federal laws, and providing both formal and informal legal advice and opinions to the president of the United States, the cabinet, and the heads of executive departments and agencies. The attorney general represents the federal government in legal matters and supervises the administration and operation of the Department of Justice, which includes the Federal Bureau of Investigation, the Drug Enforcement Administration, the Bureau of Alcohol, Tobacco, Firearms and Explosives, the Office of Justice Programs, U.S. Attorneys, and the United States Marshals Service.\nAdditionally, the attorney general advises the president of the United States on appointments to federal judicial positions and Department of Justice roles, including U.S. Attorneys and U.S. Marshals. While the attorney general may represent the United States in the Supreme Court and other courts, this is typically handled by the solicitor general. The attorney general also performs or supervises other duties as required by statute or executive order.\nPresidential transition.\nIt is the practice for the attorney general, along with the other Cabinet secretaries and high-level political appointees of the president, to tender a resignation with effect at noon on the Inauguration Day (January 20) of a new president. The deputy attorney general is also expected to tender a resignation, but is commonly requested to stay on and act as the attorney general, pursuant to \u00a0https://, pending the confirmation by the Senate of the new attorney general.\nFor example, upon the inauguration of President Donald Trump at noon on January 20, 2017, then-Attorney General Loretta Lynch left her position, so then-Deputy Attorney General Sally Yates, who had also tendered her resignation, was asked to stay on to serve as the acting attorney general, pursuant to \u00a0https://, until the confirmation of the new attorney general Jeff Sessions, who had been nominated for the office in November 2016 by then-President-elect Donald Trump.\nList of attorneys general.\nParties.\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Federalist (4)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Democratic-Republican (5)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Democratic (33)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Whig (4)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Republican (40)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Independent / Unknown (1)\nStatus.\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Denotes acting capacity.\nLine of succession.\n\u00a0https:// establishes the first two positions in the line of succession, while allowing the attorney general to designate other high-ranking officers of the Department of Justice as subsequent successors. Furthermore, the most recent Executive Order pertaining to the line of succession, Executive Order 14136 titled \"Providing an Order of Succession Within the Department of Justice\" that was signed by President Joe Biden on January 3, 2025, and published in the Federal Register on January 13, 2025, but was revoked by President Donald Trump on January 20, 2025 and has yet to be replaced with another executive order pertaining to the line of succession, defines subsequent positions. The most recent line of succession was:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44003", "revid": "50935948", "url": "https://en.wikipedia.org/wiki?curid=44003", "title": "Dysphemism", "text": "Expression with derogatory connotations\nA dysphemism is an expression with connotations that are derogatory either about the subject matter or to the audience. Dysphemisms contrast with neutral or euphemistic expressions. For example, expressing disapproval by calling a person a \"snake\" is a dysphemism. Dysphemism may be motivated by fear, distaste, hatred, contempt, humour and abuse.\nEtymology.\nThe word \"dysphemism\" was composed from the Greek elements 'mis-' and 'speech, voice, reputation' in the late 19th century. Related terms include \"malphemism\" (from the Latin 'bad'), \"cacophemism\" (from the Greek 'bad') and \"pyrophemism\" (from the Greek 'fire')\nUsage.\nA dysphemism is a marked form (standing out as unusual or divergent) which expresses a speaker's view or attitude towards the listener or group.\nTypes.\nDysphemistic epithets.\nAnimal names are frequently used as dysphemistic epithets. By using one, the speaker attempts to offend or antagonize the listener by targeting their humanity. Examples include \"bitch\", \"pig\", \"swine\", \"chicken\", \"weasel\", \"sheep\", \"snake\", \"rat\", and \"jackass\".\nName dysphemism.\nUsed when someone uses another's given name, disrespectfully or otherwise inappropriately, rather than a kinship term, style of office, or honorific to address someone specifically.\" The speaker uses a more casual or lower style than is appropriate \"given the social context\". One example is calling one's mother by her first name rather than \"Mom\".\nMany languages, to a greater extent than in English, indicate respect with verb tenses and thus provide more scope for such dysphemism and require care by non-native speakers to avoid causing offence by unintentional dysphemism.\nThis use of language may not constitute dysphemism if the choice of words used by the speaker is welcomed by the listener, such as a father who prefers being called by his given name as opposed to \"Dad/Father\". In that case it would appeal to the listener's positive face rather than damage it and would thus not be a dysphemism.\nSimilarly, being more formal with someone than expected may be a type of dysphemism. For example, if a child usually calls their father \"dad\" or \"papa\", calling him \"father\" may be a way of offending or antagonizing him, through coldness or distance (in other words, one might formally refer to one's father as \"father\", but when speaking to him one would use a particularly endearing term), or that he is merely his role, if a child usually called Billy is addressed by a parent as \"William\".\nDysphemism may also be indicated by the disuse or substitution of someone's name or title. For instance, someone named Teresa who made overstated claims for a company-paid trip could be described as \"the little witch who charmed the boss into approving that phony expense report\".\nAnger or dissatisfaction with the listener (or group of people) may compel a speaker to use a name dysphemism or term of address dysphemism.\nCross-cultural dysphemism.\nVarious slang terms that are dysphemistic in one culture may not be if they hold a different meaning in another culture. For instance, the word \"fag\" when used in American English is typically a slur against gay men. However, in British English, the word \"fag\" can be an inoffensive term used to refer to a cigarette, or, previously, a junior boy who serves a senior boy in a British public school. Likewise, the word \"fanny\" when used in American English is a euphemism for one's buttocks, so benign that children use it. However, in British, Australian, New Zealand, and South African English, the word \"fanny\" is slang for vulva and is considered to be vulgar.\nContext and drift.\nSome phrases that are euphemisms in certain contexts can be considered dysphemistic in others. These are often referred to as X-phemisms: whether the utterance is dysphemistic or not depends on the context of the utterance. For example, many X-phemisms regarding sexual intercourse could be considered euphemistic within peer groups yet dysphemistic in certain audiences. One might be more likely to say that one \"got laid\" to a friend than to one's grandparents.\nThere may also be instances in which conflicting definitions of the same word may lead to unintentional dysphemism. The pejorative use of the word terrorist is a salient example, as definitions of the word terrorist may vary across cultures and even among individuals in the same culture. Typically, the word \"terrorist\" refers to one who uses violence and fear as a means to pursue political, religious or ideological aims. This definition is ambiguous, and many groups that refer to themselves as \"freedom fighters\", \"revolutionaries\", \"rebels\" or \"liberators\" are referred to as \"terrorists\" by dissenting parties. Labeling groups as terrorist draws associations with other groups labeled as such even when no direct connection might be present. In 2003, the Philippine government's intention to label the Moro Islamic Liberation Front as a terrorist organization was indicated by the organization to be an escalation of hostilities. It was their belief that by calling their organization a terrorist organization they were being directly compared to Al-Qaeda, with whom they claim no connection. Naming groups in this way has been described, \"A name will place emphasis on certain aspects and characteristics of an object, while neglecting or omitting other key areas\".\nThe interpretation and the production of a text (whether it be written, verbal, or multi-modal) depends on the previous knowledge and experience of the interpreter or producer. The individual compares matching features with representations stored in their long-term memory. Certain lexical items can be used to activate these representations, conjuring stereotypical images which then become the prototype in the listener's mind. Dysphemic terms activate negative stereotypes present in the listener's memory and affect their interpretation of the given text.\nMove from euphemism to dysphemism.\nThe process of pejoration leads to words that were once considered euphemisms to now be considered dysphemisms. In American culture, words like \"colored\" were once considered euphemisms, but have since been replaced by terms like \"Black\" and \"African American\". Sometimes slight modifications of dysphemisms can make them acceptable: while \"colored people\" is considered dysphemistic, \"people of color\" does not carry the same connotations. The words \"idiot\" and \"moron\" were once polite terms to refer to people with mental disabilities, but they are now rarely used without dysphemism. Likewise, the word \"retarded\" was introduced as a new polite form once the previous terms became dysphemistic; since then, \"retarded\" has itself become dysphemistic. Often a word with both euphemistic and dysphemistic uses becomes restricted to the dysphemistic use alone. The term \"euphemism treadmill\", coined by Steven Pinker, describes this process, in which terms with an emotionally charged referent that were once euphemisms become dysphemistic by association with the referent.\nReclamation of dysphemisms.\n\"Nigger\" would typically be dysphemistic; however, if used between African Americans it may be seen as neutral (although extremely casual) by the listener, depending on their social distance from the speaker and perceived status relative to the other party; see \"nigga\".\nReclamations of dysphemistic terms have been both successful and unsuccessful. The term \"chicano\" was a derogatory term and has been successfully reclaimed. Some terms like \"Yankee\" (for an American) or \"punk\" (for a late 1970s rocker), began as derogatory but were not considered such and adopted proudly by the named group. There have also been movements to reclaim words for gay, lesbian, bisexual, and otherwise non-heterosexual people, such as \"queer\", \"fag\" and \"dyke\".\nOther historic examples of dysphemism reclamation include the term Impressionism, which originated as a critical remark that \"Monet's \"Impression, Sunrise\" was not art, it was an impression\", but was adopted to be the formal name of the style and was accepted by the artists themselves.\nTaboo terms.\nTaboo terms are used as insults, epithets, and expletives because they damage the listener's face, which might destroy social harmony\u2014especially if the speaker and listener are socially distant from each other. For this reason, terms of insult are socially taboo and dysphemistic. Breaking a social taboo can act as an emotional release, with the illocutionary act of expressing a feeling or attitude.\nBad or taboo words for many things far outnumber the \"good\" words. Hugh Rawson notices in his book \"Wicked Words\" that when looking at \"Roget's International Thesaurus\", there are \"89 synonyms for drunk, compared to 16 for sober, and 206 for bad person compared to 82 for good person. The synonyms for unchastity in the Thesaurus fill 140 lines, occupying exactly four times as much space as those for chastity. For unchaste woman, 34 synonyms are listed; for unchaste man, 24. No synonyms at all are given for chaste woman and chaste man.\"\nReferences to bodily excretions are often used in dysphemisms. Many communities historically believed that bodily effluvia such as feces, spittle, blood, nail-parings, and hair-clippings were cursed. Such revulsion is apparently learned: children and animals are not put off by bodily effluvia (unless they have a foul smell). In a study done at Monash and La Trobe Universities in Melbourne, Australia, subjects rated bodily effluvia according to how revolting they found them. Feces, vomit, semen and menstrual blood were rated as most revolting while nail parings, breath, blood from a wound, hair clippings, and breast milk were rated as least revolting. This continuum of the level of revulsion is apparent in certain dysphemism such as \"shitter\" for 'toilet', \"to come\" for 'to ejaculate', and \"puke hole\" for 'tavern' or 'toilet'.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44004", "revid": "8028355", "url": "https://en.wikipedia.org/wiki?curid=44004", "title": "United States Secretary of the Interior", "text": "Head of the United States Department of the Interior\nThe United States secretary of the interior is the head of the United States Department of the Interior. The secretary and the Department of the Interior are responsible for the management and conservation of most federal land along with natural resources, leading such agencies as the Bureau of Land Management, the United States Geological Survey, the Bureau of Indian Affairs and the National Park Service. The secretary also serves on and appoints the private citizens on the National Park Foundation Board. The secretary is a member of the United States Cabinet and reports to the president of the United States. The function of the U.S. Department of the Interior is different from that of the interior minister designated in many other countries.\nAs the policies and activities of the Department of the Interior and many of its agencies have a substantial impact in the Western United States, the secretary of the interior has typically come from a western state; only one secretary since 1949, Rogers Morton, was not a resident or native of a state lying west of the Mississippi River.\nSecretary of the Interior is a Level I position in the Executive Schedule, thus earning a salary of US$246,400, as of January 2024.\nThe current interior secretary is Doug Burgum, who was sworn in on February 1, 2025.\nLine of succession.\nThe line of succession for the secretary of the interior is as follows:\nList of secretaries of the interior.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44005", "revid": "1319291888", "url": "https://en.wikipedia.org/wiki?curid=44005", "title": "The English Patient", "text": "1992 novel\nThe English Patient is a 1992 novel by Michael Ondaatje. The book follows four dissimilar people brought together at an Italian villa during the Italian campaign of World War II: an unrecognizably burned man\u2014the eponymous patient who is presumed to be English\u2014; his Canadian Army nurse; a Sikh sapper; and a Canadian self-described thief. The story is primarily set during the North African campaign and centers on the incremental revelations of the patient's actions prior to his injuries, and the emotional effects of these revelations on the other characters. The story is told through the characters' perspectives and \"authors\" of books the characters are reading.\nThe book is a sequel to the 1987 novel \"In the Skin of a Lion\", which continues the story of characters of his stories of Hana and Caravaggio; as well as revealing the fate of the latter's main character, Patrick Lewis. It won the 1992 Booker Prize, the 1992 Governor General's Award and the 2018 Golden Man Booker.\n\"The English Patient\" was adapted into a 1996 film of the same name. It was in early development in August 2021 for a new BBC television series, co-produced by Miramax Television and Paramount Television Studios.\nIn 2022, the novel was included on the \"Big Jubilee Read\" list of 70 books by Commonwealth authors, selected to celebrate the Platinum Jubilee of Elizabeth II.\nPlot synopsis.\nThe novel's historical backdrop is the North African and Italian campaigns of World War II. The story is told out of sequence, moving back and forth between the severely burned \"English\" patient's memories from before his accident and current events at the bomb-damaged Church of San Girolamo in Fiesole, where he is being cared for by Hana, a troubled young Canadian Army nurse. A few chapters are also devoted to Kip, a Sikh soldier, during his time in England training and working as a sapper on unexploded ordnance.\nThe patient's only possession is a well-worn and heavily annotated copy of Herodotus's \"The Histories\" that has survived the fiery parachute drop. Hearing the book constantly being read aloud to him brings about detailed recollections of his desert explorations, yet he is unable to recall his own name. Instead, he chooses to believe the assumption by others that he is an Englishman based on his accent. Caravaggio, the fourth person in the villa, suspects the patient is in fact Ladislaus de Alm\u00e1sy, a Hungarian count and desert explorer who was part of a British cartography group.\nCaravaggio, an Italian-Canadian working for British intelligence, is a friend of Hana\u2019s father, Patrick and her stepmother, Clara. He had remained in North Africa to spy when the German forces gain control and then transfers to Italy. He is eventually caught, interrogated, and tortured, resulting in his thumbs being cut off. He is prematurely released and is standing on the Ponte Santa Trinita bridge when it is destroyed. He recovers at a hospital for over four months before he accidentally overhears about the patient and Hana. Caravaggio bears physical and psychological scars from his painful war experience.\nDuring a thunderstorm, Kip and another soldier arrive at the villa while Hana is playing on the piano. Kip decides to stay at the villa to attempt to clear it of unexploded ordnance. Kip and the English patient become friends due to the latter's extensive knowledge on both Allied and Axis weaponry and a detailed topography of Tuscany. At one point, Hana risks her life while Kip is defusing a bomb telling him later that at the time she had hoped both of them would die. Shortly after, Kip and Hana develop feelings for one another and begin a relationship.\nThe English patient, sedated by morphine, begins to reveal everything: he fell in love with the Englishwoman Katharine Clifton who, with her husband Geoffrey, accompanied Alm\u00e1sy's desert exploration team. Alm\u00e1sy was mesmerised by Katharine's voice as she read Herodotus' tale of Candaules aloud by the campfire. They soon began a very intense affair, but she cut it short, claiming that Geoffrey would go mad if he were to discover them.\nAs the war begins and the archaeological expedition is forced to abandon camp, Katharine's husband, Geoffrey, discovers her affair with Alm\u00e1sy. Mad with jealousy, Geoffrey flies to pick up Alm\u00e1sy, but brings Katharine with him in the passenger seat. In a murder-suicide attempt, he deliberately crashes the plane into Alm\u00e1sy's camp on the ground.\nGeoffrey is killed instantly. Alm\u00e1sy survives, but Katharine is mortally wounded with severe internal injuries. Alm\u00e1sy carries her to the shelter of the Cave of Swimmers, promising to return with help. He then makes a brutal three-day trek on foot to the British-occupied town of El Tag. When he arrives, the British officers dismiss his frantic story about a dying woman and, seeing his foreign-sounding name, arrest him as a potential spy.\nAfter escaping, and driven only by the need to get back to Katharine, Alm\u00e1sy makes a deal with the Germans: he trades them his priceless, hand-drawn maps of the desert in exchange for a plane. He flies back to the Cave of Swimmers, only to find Katharine's body; she has already died. Heartbroken, he carries her body into the plane to fly her out of the desert. Shortly after taking off, the plane is hit by enemy ground fire and shot down. Trapped in the flaming wreckage, Alm\u00e1sy is horribly burned before being rescued from the crash by passing Bedouin.\nTowards the end of the novel, Kip learns through his headset that the US has bombed Hiroshima and Nagasaki and a situation develops where he nearly shoots Alm\u00e1sy. Hana calms him down and Caravaggio reflects that they would not have dropped that kind of bomb on a white nation. Kip departs from the villa, estranged from his white companions, and returns to India. He marries and has two children though he still thinks of Hana.\nCharacters.\nAlm\u00e1sy.\nCount Ladislaus de Alm\u00e1sy is the titular character who comes under Hana's care in Italy after being burned unrecognisably in Africa. Although Hungarian by birth, because he has lived without government identification or many verifiable long-term interactions, his accent prompts the authorities around him to perceive an English affiliation and to refer to him as the English patient. Alm\u00e1sy serves as a blank canvas onto which the other characters project their experience during this time in Italy. For example, Hana treats him tenderly to redeem herself for not being by the side of her father when he was engulfed in flames and died. She provides comfort to the English Patient that she could not provide to her own father.\nHis lack of a national identity enables Alm\u00e1sy to rationalise his duplicitous actions with his associates. He socialises with, and is a mapmaker for, the British before the war, then uses that information to smuggle German spies across northern Africa. Alm\u00e1sy is portrayed in a sympathetic light, partly because he tells his own story, but also because he always adheres to his own moral code.\nAlm\u00e1sy is also at the centre of one of the novel's love stories. He is involved in an adulterous relationship with Katharine Clifton, which eventually leads to her death and the death of her husband, Geoffrey Clifton. Katharine is the figure who leads Alm\u00e1sy to sensuality. He falls in love with her voice as she reads Herodotus. Sensuality, both sexual and observational, is a major theme in the novel.\nThe character is loosely based on L\u00e1szl\u00f3 Alm\u00e1sy, a well-known desert explorer in 1930s Egypt, who helped the German side in the Second World War. Alm\u00e1sy did not suffer burns or die in Italy, but survived the war and lived until 1951.\nHana.\nHana is a twenty-year-old Canadian Army nurse torn between her youth and her maturity. Being a good nurse, she quickly learns that she cannot become emotionally attached to her patients. She calls them all \"buddy,\" and forgets them immediately once they die. Her lover, a Canadian officer, is killed and because of this, Hana comes to believe that she is cursed and that all those around her are doomed to die.\nIn contrast, upon hearing of her father's death Hana has an emotional breakdown. She then puts all of her energy into caring for the English Patient. She washes his wounds, reads to him and provides him with morphine. When the hospital is abandoned, Hana refuses to leave, staying with her patient. She sees Alm\u00e1sy as saint-like and falls in love with his pure nature.\nIn addition to her relationship with Alm\u00e1sy, Hana also forms a strong relationship with Kip during his stay at the villa.\nHana seems to not be able to acknowledge or even come to terms with her father's death. As she almost sees no reason in returning home and her excuse to stay in the now abandoned hospital is to take proper care of the English patient, due to Almasy not being able to move because of how severe his burns are externally and internally as well. On top of this Hana fails to reply or write back her step-mother, whom she loves and is the only living family she has left. Clara writes to Hana for a year whilst she is in Italy; Hana keeps every letter, but fails to write back even with such woe and guilt filling her heart.\nHana seems to be putting off her life as a young adult and at times shows her immaturity throughout the novel in ignoring Caravaggio's advice or suggestions or simply not facing the reality that awaits her back home. She seems as if escaping reality and being completely isolated from the rest of society is better than growing up. Hana escapes reality simply by stalling in taking care of the patient, rearranging her set up inside the deteriorating villa, listening to what Alm\u00e1sy has to say or the stories he tells, and by reading books to him over and over again.\nHana claims to have changed and grown up mentally throughout being a nurse during the war, as one would expect, but her \"growing up\" seems to be much more of building up a wall and being stuck in this continuous process of trying to heal an already dead body.\nKip.\nKirpal (Kip) Singh is an Indian Sikh who has volunteered with the British military for sapper bomb disposal training under Lord Suffolk. This act of patriotism is not shared by his Indian nationalist brother; the scepticism of his unit's white peers discourages a sense of community for Kip.\nLord Suffolk, an eccentric English nobleman, has developed techniques to dismantle complicated, unexploded bombs in what is a very dangerous occupation. Kip feels a sense of belonging in a community when he is welcomed into the Suffolk household and regards Lord Suffolk as a father figure. Lord Suffolk and his sapper team are killed while attempting to dismantle a new type of bomb. Their deaths cause Kip's emotional withdrawal to become more pronounced. Charles Howard, 20th Earl of Suffolk, was a real person who did dismantle bombs and was killed while attempting to dismantle one.\nKip is transferred to another unit in Italy where he and his partner hear a piano playing. As they enter the villa, they come across Hana while she is playing on a piano during a thunderstorm. Kip stays on at the villa to clear any remaining unexploded bombs, mines, or other booby-traps. Kip feels a sense of community and confidence when he becomes Hana's lover. Kip sees the interactions of the Westerners at the villa as those of a group that disregards nationality. They get together and celebrate Hana's twenty-first birthday, a symbol of their friendship and Kip's acceptance. However, when he learns of the nuclear bombing of Hiroshima Kip is thoroughly shocked. He leaves immediately while Caravaggio reflects that Westerners would never use such a weapon on their own race. Kip goes back to India and never returns, he marries and has two children though he never stops recalling the effect of Hana in his life.\nDavid Caravaggio.\nDavid Caravaggio is a Canadian thief whose profession is legitimised by the war, as the Allies needed crafty people to steal Axis documents. He is a long-time friend of Hana's father and becomes known as \"the man with bandaged hands\" when he arrives at the villa; the bandages cover his severed thumbs, the result of an interrogation by the Italians in Florence. He recalls that Ranuccio Tommasoni ordered the interrogation tactic. This is a reference to a man by the same name who was murdered by the historical Caravaggio in 1606.\nThe mental and physical outcome of the torture is that Caravaggio has \"lost his nerve\" and ability to steal. Hana remembers him as a very human thief. He would always be distracted by the human element while doing a job. For instance, if an advent calendar was on the wrong day, he would fix it. She also has deep feelings of love for Caravaggio. At times, Caravaggio seems to display a romantic love towards Hana, but also at one point wishes she would marry Kip. Caravaggio and Alm\u00e1sy share a morphine addiction. Caravaggio works this to his advantage to confirm his suspicion that Alm\u00e1sy is not English.\nKatharine Clifton.\nKatharine is the childhood friend and newly-wed wife of Geoffrey Clifton, whom she marries after their days at Oxford University. The day after their wedding, she and Geoffrey fly to join Alm\u00e1sy's expedition. She entertains the camp in the evening by reading aloud from Alm\u00e1sy's copy of Herodotus' \"Histories\", after which she and Alm\u00e1sy begin an affair. At one point Katharine stabs and punches Alm\u00e1sy repeatedly because she is angry that he doesn't want to change. Geoffrey discovers the affair after she has ended it, and she is wracked with guilt. Geoffrey attempts to kill all three of them by crashing his plane while they are flying. After Geoffrey is killed in the crash, Katharine admits that she always loved Alm\u00e1sy.\nGeoffrey Clifton.\nGeoffrey is Katharine's husband, on a secret mission for the British government to make detailed aerial maps of North Africa; his joining the Alm\u00e1sy expedition is only a ruse. The plane he claims to be his own was appropriated by the Crown, and he leaves his wife with the other expedition members while on his mission, leading to her infidelity.\nAnalysis.\nChristopher McVey has discussed the nature of Ondaatje's use of metaphysical aspects of body, history and nation in the novel. Amy Novak and Mirja Lobnik have separately analysed aspects of the treatment of memory in the novel. Thomas Harrison and Rachel Friedman have each examined the references and use of Herodotus in the novel. Madhumalati Adhikari has critiqued the treatment of the Second World War and its effects on the characters of the novel.\nA major symbol of the novel is the desert. It serves as a representation of the characters' war experiences and how they came to gather in the villa. A passage in the novel notes \"The desert could not be claimed or owned.\" Caravaggio had stepped away from the war for a brief time when he drifted into the villa and encountered an old flame, Hana. Kip elects to stay in the villa, a straggler from his unit, to continue searching for explosives. He also finds there is a serene sense of acceptance in the villa and that the people need him. Hana is devoted to her patients, to the very last. Thus, she stays behind in the villa hospital when numerous others abandon it. Alm\u00e1sy himself is forced into the villa, essentially because the desert took him when his plane was shot down.\nA psychoanalytic analysis of \"The English Patient\" helps us to understand the meaning of Michael Ondaatje's emphasis on his characters' differences and appearances. He may have been thinking about how melting pot civilisations begin by different cultures working together in spite of each other's background. Note how each central character living in the reconstructed villa is almost as opposite of each other in appearance as they could be. Hana was young, healthy, and capable of caring for more than one person at a time, but she mainly attended to the English patient. In contrast to Hana, the English patient was handicapped and on his death bed. But little did Hana know, in the English patient's past, he had worked with the Germans on other desert expeditions way before their paths had crossed. However, his amnesia could not allow him to remember such things at the moment. In other words, Hana was caring for someone who was partly responsible for her village's demise. The moral of this is that Hana, the English patient, Kip and Caravaggio had fewer physical resemblances to each other than they had had of humanistic desires. Thus, Michael Ondaatje may have wanted us to see that what's on the outside does not matter as much as what's on the inside when rebuilding a village, city or country.\nThe emotional heart of this novel is found at the core of the character's want and need to survive, which in turn is the eternal damnation they find by everything seeming so bleak. Within this, the desert is a large symbol. As the Villa San Girolamo is an abandoned, war ridden place, it is also a place that seems like a cage, with no chance at happiness in sight. The war may be over, but the characters feel trapped in a sense. The desert within the novel is a place of freedom, a place that cannot be claimed or owned by any one person. The desert is everlasting, and can never be wavered. This is unlike the war that these characters had become extremely traumatised from. It is a vast nothingness that will always remain nation-less. A place that these characters can seek out in their minds, when there is nowhere else to turn for hope.\nAwards.\nThe novel won the 1992 Booker Prize, the 1992 Governor General's Award and the 2018 Golden Man Booker award.\nFilm adaptation.\nThe novel was adapted into the 1996 film with the same title by Anthony Minghella, starring Ralph Fiennes, Kristin Scott Thomas, Willem Dafoe, Colin Firth, Naveen Andrews and Juliette Binoche. The film received nine Academy Awards\u2014including Best Picture and Director\u2014at the 69th Academy Awards.\nCanceled television adaptation.\nA television adaptation of the book was planned by the BBC. The project was to be written by Emily Ballou and co-produced between Miramax Television and Paramount Television Studios. However, in March 2023, it was reported that it was no longer moving forward.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44008", "revid": "20841863", "url": "https://en.wikipedia.org/wiki?curid=44008", "title": "ATRAC", "text": "Audio codec by Sony\nAdaptive Transform Acoustic Coding (ATRAC) is a family of proprietary audio compression algorithms developed by Sony. MiniDisc was the first commercial product to incorporate ATRAC, in 1992. ATRAC allowed a relatively small disc like MiniDisc to have the same running time as a CD while storing audio information with minimal perceptible loss in quality. Improvements to the codec in the form of ATRAC3, ATRAC3plus, and ATRAC Advanced Lossless followed in 1999, 2002, and 2006 respectively.\nFiles in ATRAC3 format originally had the extension; however, in most cases, the files would be stored in an OpenMG Audio container using the extension . Previously, files that were encrypted with OpenMG had the extension, which was replaced by starting in SonicStage v2.1. Encryption is no longer compulsory as of v3.2.\nOther MiniDisc manufacturers such as Sharp and Panasonic also implemented their own versions of the ATRAC codec.\nHistory.\nATRAC was developed for Sony's MiniDisc format. ATRAC was updated with version 2, then version 3, version 4, version 4.5, and Type R and Type S.\nThe first major update was ATRAC3 (not to be confused with version 3 of original ATRAC) in 1999. ATRAC3 was used on MiniDisc as well as the Network Walkman and Vaio Music Clip. ATRAC3plus was launched in 2003 for Hi-MD, but was also compatible with some PlayStation, VAIO and Xplod devices.\nOn 31 March 2008 Sony all but dropped the ATRAC-related codecs in the United States and Europe, and in their SonicStage powered Connect Music Store (Sony's equivalent of iTunes and iTunes Music Store). This was partly due to low adoption of the format, with a source claiming that 90% of European Walkman users did not use ATRAC. Walkman digital players outside Japan no longer worked with ATRAC after September 2007.\nUntil 1 October 2012, ATRAC was the only codec available to download music from mora until they transitioned to a DRM free model and began offering FLAC files the next year.\nATRAC9 was designed for PlayStation audio and debuted with the PlayStation Vita.\nBitrate quality.\nATRAC's 292\u00a0kbit/s bitrate used on the original MiniDiscs was designed to be near to CD audio quality. Years later ATRAC was improved over earlier versions at similar bitrates. For comparison, CDs are encoded at 1411.2\u00a0kbit/s, and lossless encoders can encode most CDs below 1000\u00a0kbit/s, with further bitrate reduction for easier-to-encode content such as voice.\nPerformance.\nATRAC algorithms were developed in close cooperation with LSI integrated circuit development engineers within Sony in order to deliver a product that could encode at high speeds and with minimal power consumption. This contrasts with other codecs developed on computers without regard for the constraints of portable hardware. This is reflected in the design of the ATRAC codecs, which emphasize processing smaller groups of samples at a time to save memory at the cost of compression efficiency and additional multiplies. These trade-offs are logical for DSP systems, where memory was often at a premium compared to multiplier performance.\nSony Walkmans offer better battery life when playing ATRAC files than when playing MP3 files. However, as Sony only pushed ATRAC compatibility in Sony Ericsson Walkman series phones in the Japanese market, it is not supported in GSM/UMTS market phones. Sony's Xplod series of car audio CD players support ATRAC CDs. Minidiscs with ATRAC format songs have, in the past, been supported on Eclipse brand car stereos.\nFormats.\nATRAC (1) (versions 1.0\u20134.5, Type R/S).\nATRAC1 was first used in Sony's own theater format SDDS system in the 1990s, and in this context is a direct competitor to Dolby Digital (AC3) and DTS. SDDS uses ATRAC1 with 8 channel encoding, and with a total encoding rate over all the channels of 1168\u00a0kbit/s.\nTwo stacked quadrature mirror filters split the signal into 3 parts:\nFull stereo (i.e., independent channel) encoding with a data rate of 292\u00a0kbit/s.\nHigh-frequency lowpass depends on the complexity of the material; some encodings have content clear up to 22.05\u00a0kHz.\nATRAC1 can also be used in mono (one channel) mode, doubling recording time.\nFFmpeg has an implementation of an ATRAC1 decoder.\nATRAC3 (LP2 and LP4 Modes).\nLike ATRAC1 and MP3, ATRAC3 is also a hybrid subband-MDCT encoder, but with several differences.\nIn ATRAC3, Three stacked QMF split the signal into 4 parts:\nThe four subbands are then MDCT encoded using a fixed-length transform. Unlike nearly all modern formats, the transform length cannot be varied to optimize coding transients. Instead, a simpler transient encoding technique called gain control is used, in which the gain of different subbands is varied during a transient prior to MDCT and then restored during decoding after the inverse MDCT to try to smooth over transients. Additionally, prior to quantization, tonal components are subtracted from the signal and independently quantized. During decoding, they are separately reconstructed and added back to reform the original MDCT coefficients.\nSony claims the major advantage of ATRAC3 is its coding efficiency, which was tuned for portable DSP which provides less computing power and battery life. However, as ATRAC is a hybrid subband-MDCT codec that is algorithmically very similar to MP3, any advantage is probably exaggerated. Compared to newer formats such as Ogg Vorbis which use a simple MDCT rather than a hybrid, ATRAC3 must perform an additional computationally expensive inverse-QMF, although the hybrid system significantly reduces memory usage, which was likely a factor given the limited memory available when ATRAC was first developed.\nThis uses a 132\u00a0kbit/s data rate, the quality of which is advertised to be similar to that of MP3 encoded at a similar bit rate.\nHowever, in an independent double-blind test (2004/05) without format encoding parameters reference against Ogg Vorbis, AAC, and LAME VBR MP3, ATRAC3 came last. \nThis reduces the data rate to 66\u00a0kbit/s (half that of LP2), partly by using joint stereo coding and a lowpass filter around 13.5\u00a0kHz. It allows 324 minutes to be recorded on an 80-minute MiniDisc, with the same padding required as LP2.\nFFmpeg has an implementation of an ATRAC3 decoder, which was converted to fixed precision and implemented in the Rockbox series of firmware for ARM, Coldfire and MIPS processors. RealAudio8 is a high-bitrate implementation of ATRAC3 (up to 352.8kbit/s). Atracdenc is an open source implementation of ATRAC3 compatible encoder which also can use RealAudio container.\nThe PlayStation 3 video game \"\" uses 224 simultaneous streams of ATRAC3 compressed audio, with between one and eight channels per stream at sample rates between 24 and 48\u00a0kHz, each filtered using 512 frequency bands of adaptive equalisation, routed via six reverb units running on the same SPU co-processor (one of eight on the PS3's Cell chip), alongside 7.1 channel hybrid third-order Ambisonic mixing.\nATRAC3plus.\nThis codec is used in Sony Hi-MD Walkman devices (e.g., \"Hi-LP and Hi-SP\"), Network Walkman players, Memory Stick players, VAIO Pocket, PS3 and PSP console, and ATRAC CD players. It is a hybrid subband/MDCT codec based on a 16 channel QMF followed by a 128-point MDCT. Prior to MDCT coding, Generalized Harmonic Analysis (GHA) is used to extract tonal components, an improved version of the process used in ATRAC3. As in previous ATRAC versions, gain control is used to control preecho rather than variable sized transforms, although different MDCT windows are apparently possible.\nSonicStage version 3.4, released in February 2006, introduced ripping CDs in bitrates 320 and 352. The available bitrates are: 48, 64, 96, 128, 160, 192, 256, 320 and 352\u00a0kbit/s. The newer bitrates are not always compatible with all older hardware decoders, however, some of the older hardware has been found to be compatible with certain newer ATRAC3plus bitrates.\nMiniDiscs recorded in this format are incompatible with older players.\nIn a test conducted by an independent firm, but financed by Sony, it was concluded that ATRAC3plus at 64\u00a0kbit/s is equal in subjective sound quality to an obsolete MP3 encoder at 128\u00a0kbit/s. Performance against modern high quality MP3 encoders was not evaluated.\nATRAC Advanced Lossless.\nATRAC Advanced Lossless is a \"scalable\" lossless audio codec that records a lossy ATRAC3 or ATRAC3plus stream, and supplements it with a stream of correction information stored within the file itself that allows the original signal to be reproduced, if desired. A player/decoder can extract and use just the ATRAC3 or ATRAC3plus data, or it can combine that with the correction stream to perfectly reproduce the original audio information. This allows the file to be decoded as either lossless or lossy. It is implemented in such a way that allows the file size to be smaller than uncompressed or compressed versions of the same file. Compression is approximately 30\u201380% of the original file. Benefits of scalable compression include providing backward compatibility, such that older devices that are not AAL-aware can still have the ATRAC3 stream available for playback without understanding the AAL format, and faster transfer speed between portable audio devices and PC.\nATRAC Advanced Lossless is widely supported in older Walkman players and SonicStage version 4 or later. SonicStage 4 allows download of ATRAC Advanced Lossless to MiniDisc Players, PlayStation Portable, and PlayStation 3. Recent Walkman players do not support ATRAC Advanced Lossless/ATRAC.\nAAL's use of a \"core\" (lossy) and \"residual\" (correction) stream is similar to the idea behind Opus, MPEG-4 SLS, DTS-HD Master Audio, Dolby TrueHD and Ogg Vorbis bitrate peeling. In fact, AAL was the first to be released in the commercial market with this scheme for backward compatibility.\nWavPack hybrid mode and OptimFROG DualStream are in the same category, but store the correction stream in a separate file.\nATRAC9.\nAccording to Sony ATRAC9 is a high-compression audio codec optimized for games, offering low delay (granularity) and low CPU and memory usage.\nIt is used in the PS5, PS4 and PS Vita consoles. Audio middleware such as FMOD and Audiokinetic Wwise supports it.\nFFmpeg has an implementation of an ATRAC9 decoder.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44009", "revid": "50595076", "url": "https://en.wikipedia.org/wiki?curid=44009", "title": "MiniDisc", "text": "Magneto-optical storage medium, mainly for audio (1992\u20132013)\nMiniDisc (MD) is a discontinued erasable magneto-optical disc-based data storage format offering a capacity of 60, 74, or 80 minutes of digitized audio.\nSony announced the MiniDisc in September 1992 and released it in November of that year for sale in Japan and in December in Europe, North America, and other countries. The music format was based on ATRAC audio data compression, Sony's own proprietary compression code. Its successor, Hi-MD, would later introduce the option of linear PCM digital recording to meet audio quality comparable to that of a compact disc. MiniDiscs were very popular in Japan and found moderate success in Europe. Although it was designed to succeed the cassette tape, it did not manage to supplant it globally.\nBy March 2011, Sony had sold 22 million MD players, but discontinued further development. Sony ceased manufacturing and sold the last of the players by March 2013. On January 23, 2025, Sony announced they would end the production of recordable MD media in February 2025.\nMarket history.\nIn 1983, just a year after the introduction of the compact disc, Kees Schouhamer Immink and Joseph Braat presented the first experiments with erasable magneto-optical compact discs during the 73rd AES Convention in Eindhoven. It took almost 10 years, however, before their idea was commercialized.\nSony's MiniDisc was one of two rival digital systems introduced in 1992 that were intended to replace the Philips Compact Cassette analog audio tape system: the other was the Digital Compact Cassette (DCC), created by Philips and Matsushita (now Panasonic). Sony had originally intended the Digital Audio Tape (DAT) to be the dominant home digital audio recording format, replacing the analog cassette. Because of technical delays, the DAT was not launched until 1989, and by then the U.S. dollar had fallen so far against the yen that the introductory DAT machine Sony had intended to market for about $400 in the late 1980s then had to retail for $800 or even $1,000 to break even, putting it out of reach of most users.\nRelegating DAT to professional use, Sony set to work to come up with a simpler, more economical digital home format. By the time Sony came up with the MiniDisc in late 1992, Philips had introduced a competing system, DCC, on a magnetic tape cassette. This created marketing confusion very similar to the videocassette format war of the late 1970s and early 1980s. Sony licensed MD technology to other manufacturers, with JVC, Sharp, Pioneer, Panasonic and others producing their own MD products. However, non-Sony machines were not widely available in North America, and companies such as Technics and Radio Shack tended to promote DCC instead.\nDespite having a loyal customer base largely of musicians and audio enthusiasts, the MiniDisc met with only limited success in the United States. It was very popular in Japan and parts of Asia, and relatively so in Europe during the 1990s and into the 2000s, but did not enjoy comparable sales success in other markets. Meanwhile, recordable CDs, flash memory and HDD and solid-state-based digital audio players such as iPods became increasingly popular as playback devices.\nThe slow uptake of MiniDisc was attributed to the small number of pre-recorded albums available on MD, because relatively few record labels embraced the format. The initial high cost of equipment and blank media was also a factor. Additionally, home MiniDisc decks were less widely available, with most consumers instead connecting a portable MD device to their hi-fi system in order to record.\nMiniDisc technology was faced with new competition from the recordable compact disc (CD-R) when it became more affordable to consumers beginning around 1996. Initially, Sony believed that it would take around a decade for CD-R prices to become affordable \u2013 the cost of a typical blank CD-R disc was around $12 in 1994 \u2013 but CD-R prices fell much more rapidly than envisioned, to the point where CD-R blanks sank below $1 per disc by the late 1990s, compared to at least $2 for the cheapest 80-minute MiniDisc blanks.\nThe biggest competition for MiniDisc came with the emergence of MP3 players. With the Diamond Rio player in 1998 and the Apple iPod in 2001, the mass market began to eschew physical media in favor of more convenient file-based systems.\nBy 2007, because of the waning popularity of the format and the increasing popularity of solid-state MP3 players, Sony was producing only one model, the Hi-MD MZ-RH1, available as the MZ-M200 in North America packaged with a Sony microphone and limited macOS software support.\nThe MZ-RH1 allowed users to freely move uncompressed digital recordings back and forth from the MiniDisc to a computer without the copyright protection limitations previously imposed upon the NetMD series. This allowed the MiniDisc to better compete with HD recorders and MP3 players. However, most pro users like broadcasters and news reporters had already abandoned MiniDisc in favor of solid-state recorders, because of their extended recording time, open digital content sharing, high-quality digital recording capabilities and reliable, lightweight design.\nOn 7 July 2011, Sony announced that it would no longer ship MiniDisc Walkman products as of September 2011, effectively killing the format.\nOn 1 February 2013, Sony issued a press release on the Nikkei stock exchange that it would cease shipment of all MD devices, with last of the players to be sold in March 2013. However, it would continue to sell blank discs and offer repair services. Other manufacturers continued to release MiniDisc players long after Sony stopped, with TEAC &amp; TASCAM producing new decks up until 2020 when both its consumer and professional products, TEAC MD-70CD and TASCAM MD-CD1MKIII, were discontinued. In January 2025 Sony announced, that production of blank MiniDiscs (together BD-R and MiniDV) will be discontinued.\nDesign.\nPhysical characteristics.\nThe disc is fixed in a cartridge (68\u00d772\u00d75\u00a0mm) with a sliding door, similar to the casing of a 3.5\" floppy disk. This shutter is opened automatically when inserted into a drive. MiniDiscs can either be blank or prerecorded. Recordable MiniDiscs use a magneto-optical system to write data: a laser below the disc heats a spot to its Curie point, making the material in the disc susceptible to a magnetic field. A magnetic head above the disc then alters the polarity of the heated area, recording the digital data onto the disk. Playback is accomplished with the laser alone: taking advantage of the magneto-optic Kerr effect, the player senses the polarization of the reflected light as a 1 or a 0. Recordable MDs can be rerecorded repeatedly, with Sony claiming up to one million times. By May 2005, there were 60-minute, 74-minute and 80-minute discs available. 60-minute blanks, which were widely available in the early years of the format's introduction, were phased out.\nMiniDiscs use a mastering process and optical playback system that is very similar to CDs. The recorded signal of the premastered pits and of the recordable MD are also very similar. Eight-to-Fourteen Modulation (EFM) and a modification of CD's CIRC code, called Advanced Cross Interleaved Reed-Solomon Code (ACIRC) are employed.\nDifferences from cassette and CDs.\nMiniDiscs use rewritable magneto-optical storage to store data. Unlike DCC or the analog Compact Cassette, MiniDisc is a random-access medium, making seek time very fast. MiniDiscs can be edited very quickly even on portable machines. Tracks can be split, combined, moved or deleted with ease either on the player or uploaded to a PC with Sony's SonicStage V4.3 software and edited there. Transferring data from an MD unit to a non-Windows PC can only be done in real time, preferably via optical I/O, by connecting the audio out port of the MD to an available audio in port of the computer. With the release of the Hi-MD format, Sony began to use Mac OS X-compatible software. However, the Mac OS X-compatible software was still not compatible with legacy MD formats (SP, LP2, LP4). This means that an MD recorded on a legacy unit or in a legacy format still requires a Windows PC for faster than real-time transfers.\nThe beginning of the disc has a table of contents (TOC, the System File area), which stores the start positions of the various tracks, as well as metadata (title, artist) and free blocks. Unlike a conventional cassette, a recorded song does not need to be stored as one piece on the disc and can be scattered in fragments, similar to a hard drive. Early MiniDisc equipment had a fragment granularity of four seconds of audio. Fragments smaller than the granularity are not monitored, which may lead to the usable capacity of a disc shrinking over time. No means of defragmenting the disc is provided in consumer-grade equipment.\nAll consumer-grade MiniDisc devices have a copy-protection scheme called the Serial Copy Management System. An unprotected disc or song can be copied without limit, but the copies can no longer be digitally copied. However, as a concession, the last Hi-MD players can upload to PC a digitally recorded file which can be resaved as a WAV (PCM) file and thus replicated.\nAudio data compression.\nThe digitally encoded audio signal on a MiniDisc has traditionally been data-compressed using the ATRAC (Adaptive Transform Acoustic Coding) format.\nATRAC was devised to allow MiniDisc to have the same runtime as a CD. ATRAC reduces the 1.4\u00a0Mbit/s of a CD to a 292\u00a0kbit/s data stream, roughly a 5:1 reduction. ATRAC was also used on nearly all flash memory Walkman devices until the 8 series.\nThe ATRAC codec differs from uncompressed PCM in that it is a psychoacoustic lossy audio data reduction scheme. Like other lossy audio compression formats, it is intended to be acoustically transparent.\nThere have been four versions of ATRAC, each claimed by Sony to more accurately reflect the original audio. Early players are guaranteed to play later version ATRAC audio. Version\u00a01 could only be copied on consumer equipment three or four times before artifacts became objectionable, as the ATRAC on the recorder attempted to compress the already compressed data. By version\u00a04, the potential number of generations of copy had increased to around 15 to 20 depending on audio content.\nThe latest versions of Sony's ATRAC are ATRAC3 and ATRAC3plus. Original ATRAC3 at 132\u00a0kbit/s (also known as ATRAC-LP2 mode) was the format that was used by Sony's defunct Connect audio download store. ATRAC3plus was not used in order to retain backwards compatibility with earlier NetMD players.\nIn the MiniDisc's final iteration, Hi-MD, uncompressed CD-quality linear PCM audio recording and playback is offered, placing Hi-MD on par with CD-quality audio. Hi-MD also supports both ATRAC3 and ATRAC3plus at various bitrates.\nAnti-skip.\nMiniDisc has a feature that prevents disc skipping under all but the most extreme conditions. Older CD players had been a source of annoyance to users as they were prone to mistracking from vibration and shock. MiniDisc solved this problem by reading the data into a memory buffer at a higher speed than was required before being read out to the digital-to-analog converter at the standard rate of the format. The size of the buffer varies by model.\nIf a MiniDisc player is bumped, playback continues unimpeded while the laser repositions itself to continue reading data from the disc. This feature allows the player to stop the spindle motor for significant periods, increasing battery life.\nA buffer of at least six seconds is required on all MiniDisc players, whether portable or full-sized units. This ensures uninterrupted playback in the presence of file fragmentation.\nOperation.\nThe data structure and operation of a MiniDisc is similar to that of a computer's hard disk drive. The bulk of the disc contains audio data, and a small section contains the table of contents (TOC), providing the playback device with vital information about the number and location of tracks on the disc. Tracks and discs can be named. Tracks may easily be added, erased, combined and divided, and their preferred order of playback modified. Erased tracks are not physically erased, but are only marked as deleted. When a disc becomes full, the recorder can simply direct the data into sections where erased tracks reside. This can lead to fragmentation but unless many erasures and replacements are performed, the only likely problem is excessive searching, reducing battery life.\nThe data structure of the MiniDisc, where music is recorded in a single stream of bytes while the TOC contains pointers to track positions, allows for gapless playback of music, something which competing portable players such as most MP3 players, fail to implement properly. Notable exceptions are CD players, as well as all recent iPods.\nAt the end of recording, after the \"Stop\" button has been pressed, the MiniDisc may continue to write music data for a few seconds from its memory buffers. During this time, it may display a message (\"Data Save\", on at least some models) and the case will not open. After the audio data is written out, the final step is to write the TOC track denoting the start and endpoints of the recorded data. Sony points out in the manual that the power should not be interrupted or the unit exposed to undue physical shock during this time.\nCopy protection.\nAll MiniDisc recorders (except professional models) use the SCMS copy protection system which uses two bits in the S/PDIF digital audio stream and on disc to differentiate between \"protected\" vs. \"unprotected\" audio, and between \"original\" vs. \"copy\":\nRecording from an analogue source resulted in a disc marked \"protected\" and \"original\" allowing one further copy to be made (this contrasts with the SCMS on the Digital Compact Cassette where analogue recording was marked as \"unprotected\").\nIn recorders that could be connected to a PC via USB, it was possible to transfer audio from the PC to the MiniDisc recorder, but for many years it was not possible to transfer audio in the other direction. This restriction existed in both the SonicStage software and in the MiniDisc player itself. SonicStage V3.4 was the first version of the software where this restriction was removed, but it still required a MiniDisc recorder/player that also had the restriction removed. The Hi-MD model MZ-RH1 was the only such player available.\nFormat extensions.\nMD Data.\nMD Data, a format for storing computer data, was announced by Sony in 1993. Its media stored 140 MB and were generally incompatible with standard audio MiniDiscs. MD Data cannot be written to audio MDs; it can only be written to the considerably more expensive data blanks. It did see some success in a small number of multi-track recorders such as Sony's MDM-X4, Tascam's 564 (which could also record using standard audio MD discs, albeit only two tracks), and Yamaha's MD8, MD4, &amp; MD4S.\nMD Data2.\nIn 1997, MD Data2 blanks were introduced with 650\u00a0MB. They were only implemented in Sony's short-lived MD-based camcorder, the DCM-M1.\nMDLP.\nIn 2000, Sony announced MDLP (MiniDisc Long Play), which added new recording modes based on the new codec ATRAC3. In addition to the standard, high-quality mode, now called SP, MDLP adds LP2 mode, which doubles the recording time \u2013 160 minutes on an 80-minute disc \u2013 of good-quality stereo sound, and LP4, which allows four times more recording time \u2013 320 minutes on an 80-minute disc \u2013 of medium-quality stereo sound.\nThe bitrate of the standard SP mode is 292\u00a0kbit/s, and it uses separate stereo coding with discrete left and right channels. LP2 mode uses a bitrate of 132\u00a0kbit/s and also uses separate stereo coding. The third mode, LP4, has a bitrate of 66\u00a0kbit/s and uses joint stereo coding. The sound quality is noticeably degraded compared to the other two modes, but is sufficient for many uses.\nTracks recorded in LP2 or LP4 mode play back as silence on non-MDLP players.\nNetMD.\nDebuting in late 2001, NetMD recorders allow music files to be transferred from a computer to a recorder (but not in the other direction) over a USB connection. In LP4 mode, speeds of up to 32\u00d7 real-time are possible and three Sony NetMD recorders (MZ-N10, MZ-N910, and MZ-N920) are capable of speeds up to 64\u00d7 real-time. NetMD recorders all support MDLP.\nWhen transferring music in SP mode using NetMD with SonicStage, what is transferred is actually padded LP2. That is to say that the quality of the music is that of LP2 but recorded as SP.\nNetMD is a proprietary protocol that initially required proprietary software such as SonicStage. A free *nix based implementation, libnetmd, has been developed. The library allows the user to upload SP files in full quality. In 2019, a programmer named Stefano Brilli compiled the linux-minidisc CLI into a web browser-based application, allowing users to transfer music via USB on modern devices.\nHi-MD.\nHi-MD is a further development of the MiniDisc format. Hi-MD media will not play on non-Hi-MD equipment, including NetMD players. The Hi-MD format, introduced in 2004, marked a return to the data storage arena with its 1\u00a0GB discs and ability to act as a USB drive. Hi-MD units allow the recording and playback of audio and data on the same disc, and can write both audio and data to standard MiniDisc media \u2013 an 80-minute MiniDisc blank could be formatted to store 305\u00a0MB of data.\nRecording and transfer modes.\nModes marked in green are available for recordings made on the player, while those marked in red are available for music transferred from a PC. Capacities are official Sony figures; real world figures are usually slightly higher. Native MP3 support was added in second-generation Hi-MD players in the spring of 2005. SonicStage version 3.4, released in Feb 2006, introduced ripping CDs in bitrates 320 and 352 and added track transfer in ATRAC 192\u00a0kbit/s to Hi-MD devices.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44012", "revid": "248192", "url": "https://en.wikipedia.org/wiki?curid=44012", "title": "Anton Bruckner", "text": "Austrian composer (1824\u20131896)\nJoseph Anton Bruckner (; ; 4 September 1824\u00a0\u2013 11 October 1896) was an Austrian composer and organist best known for his symphonies and sacred music, which includes Masses, Te Deum and motets. The symphonies are considered emblematic of the final stage of Austro-German Romanticism because of their rich harmonic language, strongly polyphonic character, and considerable length. Bruckner's compositions helped to define contemporary musical radicalism, owing to their dissonances, unprepared modulations, and roving harmonies.\nUnlike other musical radicals such as Richard Wagner and Hugo Wolf, Bruckner showed respect, even humility, before other famous musicians, Wagner in particular. This apparent dichotomy between Bruckner the man and Bruckner the composer hampers efforts to describe his life in a way that gives a straightforward context for his music. The German conductor Hans von B\u00fclow described him as \"half genius, half simpleton\". Bruckner was critical of his own work and often reworked his compositions. There are several versions of many of his works.\nHis works, the symphonies in particular, had detractors, most notably the influential Austrian critic Eduard Hanslick and other supporters of the German composer Johannes Brahms, who pointed to their large size and use of repetition, as well as to Bruckner's propensity for revising many of his works, often with the assistance of colleagues, and his apparent indecision about which versions he preferred. On the other hand, Bruckner was greatly admired by subsequent composers, including his friend Gustav Mahler.\nLife and career.\nEarly life.\nAnton Bruckner was born in Ansfelden (then a village, now almost a suburb of Linz) on 4 September 1824. The ancestors of Bruckner's family were farmers and craftsmen; their history can be traced as far back as the 16th century. They lived near a bridge south of Sindelburg, which led to their being called \"Bruckhner an der Bruckhen\" (bridgers on the bridge). Bruckner's grandfather was appointed schoolmaster in Ansfelden in 1776; this position was inherited by Bruckner's father, Anton Bruckner Sr., in 1823. It was a poorly paid but well-respected position in the rural environment. Bruckner Sr. married Theresia Helm, and they had eleven children, Anton Bruckner being the eldest.\nMusic was part of the school curriculum, and Bruckner's father was his first music teacher. Bruckner learned to play the organ as a child. He was very dedicated to the instrument just as he was later in life in composing, often practising for 12 hours a day. He entered school when he was six, proved to be a hard-working student, and was promoted to upper class early. While studying, Bruckner also helped his father in teaching the other children. After Bruckner received his confirmation in 1833, Bruckner's father sent him to another school in H\u00f6rsching. The schoolmaster, Johann Baptist Wei\u00df, was a music enthusiast and respected organist. Here, Bruckner completed his school education and refined his skills as an organist. Around 1835 Bruckner wrote his first composition, a \"Pange lingua\"\u00a0\u2013 one of the compositions which he revised at the end of his life. When his father became ill, Anton returned to Ansfelden to help him in his work.\nTeacher's education.\nBruckner's father died in 1837, when Bruckner was 13 years old. The teacher's position and house were given to a successor, and Bruckner was sent to the Augustinian monastery in Sankt Florian to become a choirboy. In addition to choir practice, his education included violin and organ lessons. Bruckner was in awe of the monastery's great organ, which was built during the late baroque era and rebuilt in 1837, and he sometimes played it during church services. From October 1840 to July 1841, Bruckner undertook further training at the teacher-training school in Linz. His teacher of harmony and choral singing was August Durrnberger, who became a friend and would later persuade Bruckner to take up the role of a cathedral organist.\nAfter completing the seminar with an excellent grade, Bruckner was sent as an assistant teacher to a school in Windhaag. The living standards and pay were appalling and Bruckner was constantly humiliated by his superior, teacher Franz Fuchs. Despite the difficult situation, Bruckner never complained or rebelled; a belief in his own inferiority was to remain one of Bruckner's main personal traits during his whole life. He stayed at Windhaag from age 17 to 19, teaching general subjects.\nPrelate Michael Arneth noticed Bruckner's bad situation in Windhaag and awarded him an assistant teacher position in the vicinity of the monastic town of Sankt Florian, sending him to Kronstorf an der Enns for two years. Here he would be able to have more of a part in musical activity. The time in Kronstorf was a much happier one for Bruckner. Between 1843 and 1845, Bruckner was the pupil of Leopold von Zenetti in Enns. Compared to the few works he wrote in Windhaag, the Kronstorf compositions from 1843 to 1845 show a significantly improved artistic ability, and finally the beginnings of what could be called \"the Bruckner style\". Among the Kronstorf works is the vocal piece \"Asperges me\" (WAB 4), which the young assistant teacher, out of line given his position, signed with \"Anton Bruckner m.p.ria. Comp[onist]\". This has been interpreted as a lone early sign of Bruckner's artistic ambitions. Otherwise, little is known of Bruckner's life plans and intentions.\nOrganist in Sankt Florian.\nAfter the Kronstorf period, Bruckner returned to Sankt Florian in 1845 where, for the next 10 years, he would work as a teacher and an organist. In May 1845, Bruckner passed an examination which allowed him to work as an assistant teacher in one of the village schools of Sankt Florian. He continued to improve his education by taking further courses, passing an examination giving him permission to also teach in higher education institutes, receiving the grade \"very good\" in all disciplines. In 1848 Bruckner was appointed an organist in Sankt Florian and in 1851 this was made a regular position. In Sankt Florian, most of the repertoire consisted of the music of Michael Haydn, Johann Georg Albrechtsberger and Franz Joseph Aumann. During his stay in Sankt Florian, Bruckner continued to work with Zenetti.\nStudy period.\nIn 1855, Bruckner, aspiring to become a student of the famous Vienna music theorist Simon Sechter, showed the master his \"Missa solemnis\" (WAB 29), written a year earlier, and was accepted. The education, which included skills in music theory and counterpoint among others, took place mostly via correspondence, but also included long in-person sessions in Vienna. Sechter's teaching would have a profound influence on Bruckner. Later, when Bruckner began teaching music himself, he would base his curriculum on Sechter's book \"Die Grunds\u00e4tze der musikalischen Komposition\" (Leipzig 1853/54).\nLargely self-taught as a composer, Bruckner only started composing seriously at age 37 in 1861. Bruckner studied further with Otto Kitzler, who was nine years younger than him and who introduced him to the music of Richard Wagner, which Bruckner studied extensively from 1863 onwards. Bruckner considered the earliest orchestral works (the \"study\" Symphony in F minor, the three orchestral pieces, the March in D minor and the Overture in G minor, which he composed in 1862\u20131863), mere school exercises, done under the supervision of Otto Kitzler. He continued his studies to the age of 40. Broad fame and acceptance did not come until he was over 60 (after the premiere of his Seventh Symphony in 1884). In 1861, he had already made the acquaintance of Franz Liszt, whom Bruckner idolised. Like Bruckner, Liszt was of the Catholic faith and a harmonic innovator, and, alongside Wagner, he initiated the New German School. In May 1861 he made his concert debut, as both composer and conductor of his \"Ave Maria\", set in seven parts. Soon after Bruckner had ended his studies under Sechter and Kitzler, he wrote his Mass in D Minor. From 1861 to 1868, he alternated his time between Vienna and Sankt Florian. He wished to ensure he knew how to make his music modern, but he also wanted to spend time in a more religious setting.\nThe Vienna period.\nIn 1868, after Sechter's death, Bruckner hesitantly took over his post as a teacher of music theory at the Vienna Conservatory, during which time he concentrated most of his energy on writing symphonies. These symphonies were poorly received, at times considered \"wild\" and \"nonsensical\". His students at the Conservatory included Richard Robert, Hans Rott, Felix Mottl, Heinrich Schenker, Mathilde Kralik, Franz Schalk, Joseph Schalk, and Ferdinand L\u00f6we. His student Friedrich Klose wrote a book about his impressions of Bruckner as a composer and a teacher.\nHe later accepted a post at the University of Vienna in 1875, where he tried to make music theory a part of the curriculum. Overall, he was unhappy in Vienna, which was musically dominated by the critic Eduard Hanslick. At the time, there was a feud between advocates of the music of Wagner and Johannes Brahms; by aligning himself with Wagner, Bruckner made an unintentional enemy out of Hanslick. He was not without supporters, though. \"Deutsche Zeitung\"'s music critic Theodor Helm, and famous conductors such as Arthur Nikisch and Franz Schalk constantly tried to bring his music to the public, and for this purpose proposed \"improvements\" for making Bruckner's music more acceptable to the public. Bruckner bequeathed his original scores to the Austrian National Library in Vienna.\nIn addition to his symphonies, Bruckner wrote Masses, motets and other sacred choral works, and a few chamber works, including a string quintet. Unlike his romantic symphonies, some of Bruckner's choral works are often conservative and contrapuntal in style; however, the Te Deum, Helgoland, Psalm 150 and at least one Mass demonstrate innovative and radical uses of chromaticism.\nBiographers generally characterise Bruckner as a \"simple\" provincial man, and many of them have complained that there is huge discrepancy between Bruckner's life and his work. For example, Karl Grebe said: \"his life doesn't tell anything about his work, and his work doesn't tell anything about his life, that's the uncomfortable fact any biography must start from.\" Anecdotes abound as to Bruckner's dogged pursuit of his chosen craft and his humble acceptance of the fame that eventually came his way. Once, after a rehearsal of his Fourth Symphony in 1881, the well-meaning Bruckner tipped the Austrian-Hungarian conductor Hans Richter: \"When the symphony was over\", Richter related, \"Bruckner came to me, his face beaming with enthusiasm and joy. I felt him press a coin into my hand. 'Take this' he said, 'and drink a glass of beer to my health.'\" Richter accepted the coin, a Maria Theresa thaler, and wore it on his watch-chain ever after.\nBruckner was a renowned organist in his day, impressing audiences in France in 1869, and the United Kingdom in 1871, giving six recitals on a new Henry Willis organ at the Royal Albert Hall in London and five more at the Crystal Palace. Though he wrote no major works for the organ, his improvisation sessions sometimes yielded ideas for the symphonies. He taught organ performance at the Conservatory; amongst his students were Hans Rott and Franz Schmidt. Gustav Mahler, who called Bruckner his \"forerunner\", attended the conservatory at this time.\nBruckner was a lifelong bachelor who made numerous unsuccessful marriage proposals to teenage girls. One such was the daughter of a friend, called Louise; in his grief he is believed to have written the cantata \"Entsagen\" (Renunciation). His affection for teenage girls led to an accusation of impropriety where he taught music, and while he was exonerated, he decided to concentrate on teaching boys afterwards. His calendar for 1874 details the names of girls who appealed to him, and the list of such girls in all his diaries was very long. In 1880 he fell for a 17-year-old peasant girl in the cast of the Oberammergau Passion Play. His unsuccessful proposals to teenagers continued when he was past his 70th birthday; one prospect, a hotel chambermaid in Berlin named Ida Buhz, came near to marrying him but broke off the engagement when she refused to convert to Catholicism. He suffered from periodic attacks of depression, with his numerous failed attempts to find a female companion only adding to his unhappiness.\nIn July 1886, the Emperor decorated him with the Order of Franz Joseph. He most likely retired from his position at the University of Vienna in 1892, at the age of 68. He wrote a great deal of music that he used to help teach his students.\nBruckner died in Vienna in 1896 at the age of 72. He is buried in the crypt of the monastery church at Sankt Florian, immediately below his favorite organ. He had always had a fascination with death and dead bodies, and left explicit instructions regarding the embalming of his corpse.\nThe Anton Bruckner Private University for Music, Drama, and Dance, an institution of higher education in Linz, close to his native Ansfelden, was named after him in 1932 (as the \"Bruckner Conservatory Linz\" until 2004). The Bruckner Orchestra Linz was also named in his honor.\nCompositions.\nSometimes Bruckner's works are referred to by WAB numbers, from the \"Werkverzeichnis Anton Bruckner\", a catalogue of Bruckner's works edited by Renate Grasberger.\nThe revision issue has generated controversy. A common explanation for the multiple versions is that Bruckner was willing to revise his work on the basis of harsh, uninformed criticism from his colleagues. \"The result of such advice was to awaken immediately all the insecurity in the non-musical part of Bruckner's personality\", the musicologist Deryck Cooke writes. \"Lacking all self-assurance in such matters, he felt obliged to bow to the opinions of his friends, 'the experts,' to permit ... revisions and even to help make them in some cases.\" This explanation was widely accepted when it was championed by the Bruckner scholar Robert Haas, who was the chief editor of the first critical editions of Bruckner's works published by the International Bruckner Society; it continues to be found in the majority of program notes and biographical sketches concerning Bruckner. Haas's work was endorsed by the Nazis and so fell out of favour after the war as the Allies enforced denazification. Haas's rival Leopold Nowak was appointed to produce a whole new critical edition of Bruckner's works. He and others such as Benjamin Korstvedt and the American conductor Leon Botstein argued that Haas's explanation is at best idle speculation, at worst a shady justification of Haas's own editorial decisions. Also, it has been pointed out that Bruckner often started work on a symphony just days after finishing the one before. As Cooke writes, \"In spite of continued opposition and criticism, and many well-meaning exhortations to caution from his friends, he looked neither to right nor left, but simply got down to work on the next symphony.\"\nSymphonies.\n\"Bruckner expanded the concept of the symphonic form in ways that have never been witnessed before or since. ... When listening to a Bruckner symphony, one encounters some of the most complex symphonic writing ever created. As scholars study Bruckner's scores they continue to revel in the complexity of Bruckner's creative logic.\"\nBruckner composed eleven symphonies, the first, the Study Symphony in F minor in 1863, the last, the unfinished Symphony No. 9 in D minor in 1887\u201396. With the exception of Symphony No. 4 (\"Romantic\"), none of Bruckner's symphonies originally had a subtitle and in the case of those that now do, the nicknames or subtitles did not originate with the composer.\nStyle.\nBruckner's symphonies are scored for a fairly standard orchestra of woodwinds in pairs, four horns, two or three trumpets, three trombones, tuba (from the second version of the Fourth), timpani and strings. The later symphonies increase this complement, but not by much. Notable is the use of Wagner tubas in his last three symphonies. Only the Eighth has harp, and percussion besides timpani in all versions. (The Seventh, in some versions, features a single cymbal crash alongside a triangle roll at the climax of the second movement). Bruckner's style of orchestral writing was criticised by his Viennese contemporaries (Eduard Hanslick and his circle), but by the middle of the twentieth century, musicologists recognised that his orchestration was modelled after the sound of his primary instrument, the pipe organ, \"i.e.\", alternating between two groups of instruments, as when changing from one manual of the organ to another.\nStructure.\nThe structure of Bruckner's symphonies is in a way an extension of that of Ludwig van Beethoven's symphonies. Bruckner's symphonies are in four movements.\nNicholas Temperley writes in \"The New Grove Dictionary of Music and Musicians\" (1980) that Bruckner\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;alone succeeded in creating a new school of symphonic writing... Some have classified him as a conservative, some as a radical. Really he was neither, or alternatively was a fusion of both... [H]is music, though Wagnerian in its orchestration and in its huge rising and falling periods, patently has its roots in older styles. Bruckner took Beethoven's Ninth Symphony as his starting-point... The introduction to the first movement, beginning mysteriously and climbing slowly with fragments of the first theme to the gigantic full statement of that theme, was taken over by Bruckner; so was the awe-inspiring coda of the first movement. The scherzo and slow movement, with their alternation of melodies, are models for Bruckner's spacious middle movements, while the finale with a grand culminating hymn is a feature of almost every Bruckner symphony.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Bruckner is the first composer since Schubert about whom it is possible to make such generalizations. His symphonies deliberately followed a pattern, each one building on the achievements of its predecessors... His melodic and harmonic style changed little, and it had as much of Schubert in it as of Wagner... His technique in the development and transformation of themes, learnt from Beethoven, Liszt and Wagner, was unsurpassed, and he was almost the equal of Brahms in the art of melodic variation.\nDeryck Cooke adds, also in the \"New Grove\",\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Despite its general debt to Beethoven and Wagner, the \"Bruckner Symphony\" is a unique conception, not only because of the individuality of its spirit and its materials, but even more because of the absolute originality of its formal processes. At first, these processes seemed so strange and unprecedented that they were taken as evidence of sheer incompetence... Now it is recognized that Bruckner's unorthodox structural methods were inevitable... Bruckner created a new and monumental type of symphonic organism, which abjured the tense, dynamic continuity of Beethoven, and the broad, fluid continuity of Wagner, in order to express something profoundly different from either composer, something elemental and metaphysical.\nIn a concert review Bernard Holland described parts of the first movements of Bruckner's sixth and seventh symphonies as follows: \"There is the same slow, broad introduction, the drawn-out climaxes that grow, pull back and then grow some more \u2013 a sort of musical coitus interruptus.\"\nIn the 2001 second edition of the \"New Grove\", Mark Evan Bonds called the Bruckner symphonies \"monumental in scope and design, combining lyricism with an inherently polyphonic design... Bruckner favored an approach to large-scale form that relied more on large-scale thematic and harmonic juxtaposition. Over the course of his output, one senses an ever-increasing interest in cyclic integration that culminates in his masterpiece, the Symphony No. 8 in C minor, a work whose final page integrates the main themes of all four movements simultaneously.\"\nIn 1990 the American artist Jack Ox gave a paper called \"The Systematic Translation of Anton Bruckner's Eighth Symphony into a series of Thirteen Paintings\" at the Bruckner Symposium in Linz Austria; here she structurally analysed all of the Eighth Symphony's themes. She then proceeded to show how she mapped this musical data into a series of twelve large, painted visualisations. The conference report was published in 1993.\nThe Bruckner Problem.\n\"The Bruckner Problem\" refers to the difficulties and complications resulting from the numerous contrasting versions and editions that exist for most of the symphonies. The term gained currency following the publication (in 1969) of an article dealing with the subject, \"The Bruckner Problem Simplified\" by the musicologist Deryck Cooke, which brought the issue to the attention of English-speaking musicians.\nThe first versions of Bruckner's symphonies often presented an instrumental, contrapuntal and rhythmic complexity (Brucknerian rhythm \"2 + 3\", use of quintuplets), the originality of which has not been understood and which were considered unperformable by the musicians. In order to make them \"performable\", the symphonies, except Symphonies No. 5, No. 6 and No. 7, have been revised several times. Consequently, there are several versions and editions, mainly of Symphonies 3, 4 and 8, which have been deeply emended by Bruckner's friends and associates, and it is not always possible to tell whether the emendations had Bruckner's direct authorisation.\nLooking for authentic versions of the symphonies, Robert Haas produced during the 1930s a first critical edition of Bruckner's works based on the original scores. After World War II other scholars (Leopold Nowak, William Carragan, Benjamin-Gunnar Cohrs \"et al.\") carried on with this work.\nSacred choral works.\nBruckner was a devoutly religious man, and composed numerous sacred works. He wrote a Te Deum, five psalm settings (including Psalm 150 in the 1890s), a Festive cantata, a Magnificat, about forty motets (among them eight settings of \"Tantum ergo\", and three settings of both \"Christus factus est\" and \"Ave Maria\"), and at least seven Masses.\nThe three early Masses (\"Windhaager Messe\", \"Kronstorfer Messe\" and \"Messe f\u00fcr den Gr\u00fcndonnerstag\"), composed between 1842 and 1844, were short Austrian \"Landmessen\" for use in local churches and did not always set all the numbers of the ordinary. His Requiem in D minor of 1849 is . It shows the clear influence of Mozart's Requiem (also in D minor) and similar works of Michael Haydn. The seldom performed \"Missa solemnis\", composed in 1854 for Friedrich Mayer's installation, was the last major work Bruckner composed before he started to study with Simon Sechter, with the possible exception of Psalm 146, a large work, for SATB soloists, double choir and orchestra.\nThe three Masses which Bruckner wrote in the 1860s and revised later on in his life are more often performed. The Masses numbered 1 in D minor and 3 in F minor are for solo singers, mixed choir, organ \"ad libitum\" and orchestra, while No. 2 in E minor is for mixed choir and a small group of wind instruments, and was written in an attempt to meet the Cecilians halfway. The Cecilians wanted to rid church music of instruments entirely. No. 3 was clearly meant for concert, rather than liturgical performance, and it is the only one of his Masses in which he set the first line of the Gloria, \"Gloria in excelsis Deo\", and of the Credo, \"Credo in unum Deum\", to music. In concert performances of the other Masses, these lines are intoned by a tenor soloist in the way a priest would, with a line of plainsong.\nSecular vocal works.\nAs a young man Bruckner sang in men's choirs and wrote music for them. Bruckner's secular choral music was mostly written for choral societies. The texts are always in German. Some of these works were written specifically for private occasions such as weddings, funerals, birthdays or name-days, many of these being dedicated to friends and acquaintances of the composer. This music is rarely performed. The biographer Derek Watson characterises the pieces for men's choir as being \"of little concern to the non-German listener\". Of about 30 such pieces, a most unusual and evocative composition is the song \"Abendzauber\" (1878) for men's choir, man soloist, yodelers and four horns.\nBruckner also composed 20 Lieder, of which only a few have been published. The Lieder that Bruckner composed in 1861\u20131862 during his tuition by Otto Kitzler have not been WAB classified. In 2013 the Austrian National Library was able to acquire a facsimile of the \"Kitzler-Studienbuch\", the autograph manuscript hitherto unavailable to the public. The facsimile is edited by Paul Hawkshaw and Erich Wolfgang Partsch in Band XXV of Bruckner's \"\".\nBruckner composed also five name-day cantatas, as well as two patriotic cantatas, \"Germanenzug\" and \"Helgoland\", on texts by August Silberstein. \"Germanenzug\" (WAB 70), composed in 1863\u20131864, was Bruckner's first published work. \"Helgoland\" (WAB 71), for TTBB men's choir and large orchestra, was composed in 1893 and was Bruckner's last completed composition and the only secular vocal work that he thought worthy enough to bequeath to the Austrian National Library.\nOther works.\nDuring his apprenticeship with Otto Kitzler, Bruckner composed three short orchestral pieces and a March in D minor as orchestration exercises. At that time he also wrote an Overture in G minor. These works, which are occasionally included in recordings of the symphonies, show already hints of Bruckner's emerging style.\nA String Quartet in C minor and the additional Rondo in C minor, also composed in 1862, were discovered decades after Bruckner's death. The later String Quintet in F Major of 1879, contemporaneous with the Fifth and Sixth symphonies, has been frequently performed. The Intermezzo in D minor, which was intended to replace its scherzo, is not frequently performed.\nA \"Symphonisches Pr\u00e4ludium\" (Symphonic Prelude) in C minor was discovered by Mahler scholar Paul Banks in the Austrian National Library in 1974 in a piano duet transcription. Banks ascribed it to Gustav Mahler, and had it orchestrated by Albrecht G\u00fcrsching. In 1985 Wolfgang Hiltl, who had retrieved the original score by Rudolf Krzyzanowski, had it published by Doblinger (issued in 2002). According to the scholar Benjamin-Gunnar Cohrs, the stylistic examination of this \"prelude\" shows that it is all Bruckner's. Possibly Bruckner had given a draft-score to his pupil Krzyzanowski, which already contained the string parts and some important lines for woodwind and brass, as an exercise in instrumentation.\nBruckner's Two Aequali of 1847 for three trombones are solemn, brief works. The Military march of 1865 is an occasional work as a gesture of appreciation for the \"Milit\u00e4r-Kapelle der J\u00e4ger-Truppe\" of Linz. \"Abendkl\u00e4nge\" of 1866 is a short character piece for violin and piano.\nBruckner also wrote a Lancer-Quadrille (c.\u20091850) and a few other small works for piano. Most of this music was written for teaching purposes. Sixteen other pieces for piano, which Bruckner composed in 1862 during his tuition by Kitzler, have not been WAB classified. A facsimile of these pieces is found in the \"Kitzler-Studienbuch\".\nBruckner was a renowned organist at the St Florian's Priory, where he improvised frequently. Those improvisations were usually not transcribed, so that only a few of his works for organ has survived. The five Preludes in E-flat major (1836\u20131837), classified WAB 127 and WAB 128, as well as a few other WAB-unclassified works, which have been found in Bruckner's \"Pr\u00e4ludienbuch\", are probably not by Bruckner.\nBruckner never wrote an opera, and as much as he was a fan of Wagner's music dramas, he was uninterested in drama. In 1893 he thought about writing an opera called \"Astra\" based on a novel by Gertrud Boll\u00e9-Hellmund. Although he attended performances of Wagner's operas, he was much more interested in the music than the plot. After seeing Wagner's \"G\u00f6tterd\u00e4mmerung\", he asked: \"Tell me, why did they burn the woman at the end?\" Nor did Bruckner ever write an oratorio.\n\"Bruckner Gesamtausgabe\".\nPublished by Musikwissenschaftlicher Verlag in Vienna, the \"\" (Bruckner's Critical Complete Edition) comprises three successive editions.\nReception in the 20th century.\nBecause of the long duration and vast orchestral canvas of much of his music, Bruckner's popularity has greatly benefited from the introduction of long-playing media and from improvements in recording technology.\nDecades after his death, the leadership of the Nazi Party and Nazi Germany strongly approved of Bruckner's music because they saw it as expressing the \"zeitgeist\" of the German \"volk\", and Adolf Hitler even consecrated a bust of Bruckner in a widely photographed ceremony in 1937 at the Walhalla in Regensburg. Bruckner's music was among the most popular in Nazi Germany.\nNear the end of World War II, Hitler became enamoured with Bruckner's music, and planned to convert St. Florian Monastery in Linz\u2014where Bruckner had played the organ, and where he was buried\u2014into a repository of Bruckner's manuscripts. Hitler evicted the monks from the monastery and personally paid for the restoration of the organ and the institution of a Bruckner study centre there. He also paid for the Haas collection of Bruckner's works to be published, and himself purchased material for the proposed library. Additionally, Hitler caused the founding of the Bruckner Symphony Orchestra, which began presenting concerts in late 1943. His plan for one of the bell towers in Linz to play a theme from Bruckner's Fourth Symphony never came to pass. The Adagio from Bruckner's Seventh Symphony was broadcast by German radio (Deutscher Reichsrundfunk) when it announced the news of Hitler's death on 1 May 1945.\nToday the Brucknerhaus in Linz, which opened in 1974, is named after him.\nThe approval by Hitler and the Nazis of his music did not hurt Bruckner's standing in the postwar media, and several films and television productions in Europe and the United States have used excerpts from his music ever since the 1950s, as they already did in the 1930s. The Israel Philharmonic Orchestra have never banned Bruckner's music as they have Wagner's, even recording his Eighth Symphony with the Indian conductor Zubin Mehta.\nBruckner's symphonic works, much maligned in Vienna in his lifetime, now have an important place in the tradition and musical repertoire of the Vienna Philharmonic Orchestra.\nIn popular culture.\nThe life of Bruckner was portrayed in Jan Schmidt-Garre's 1995 film \"Bruckner's Decision\", which focuses on his recovery in an Austrian spa. Ken Russell's television film \"The Strange Affliction of Anton Bruckner\", starring Peter Mackriel, also fictionalises Bruckner's real-life stay at a sanatorium because of obsessive\u2013compulsive disorder (or 'numeromania' as it was then described).\nLuchino Visconti used Bruckner's music for his film \"Senso\" (1954), its plot concerned with the war Italy waged against Austria in 1866. The score by Carl Davis for the restoration of the 1925 film \"Ben-Hur\" takes \"inspiration from Bruckner to achieve reverence in biblical scenes.\"\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFurther reading.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "44013", "revid": "4480889", "url": "https://en.wikipedia.org/wiki?curid=44013", "title": "Julus", "text": "Julus may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "44014", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=44014", "title": "Henry Hudson", "text": "English explorer (c. 1565 \u2013 after 1611)\nHenry Hudson (c. 1565\u00a0\u2013 disappeared 23 June 1611) was an English sea explorer and navigator during the early 17th century, best known for his explorations of present-day Canada and parts of the Northeastern United States.\nIn 1607 and 1608, Hudson made two attempts on behalf of English merchants to find a rumoured Northeast Passage to Cathay via a route above the Arctic Circle. In 1609, he landed in North America on behalf of the Dutch East India Company and explored the region around the modern New York metropolitan area. Looking for a Northwest Passage to Asia on his ship \"Halve Maen\" (\"Half Moon\"), he sailed up the Hudson River, which was later named after him, and thereby laid the foundation for Dutch colonization of the region. His contributions to the exploration of the New World were significant and lasting. His voyages helped to establish European contact with the native peoples of North America and contributed to the development of trade and commerce. \nOn his final expedition, while still searching for the Northwest Passage, Hudson became the first European to see Hudson Strait and the immense Hudson Bay. In 1611, after wintering on the shore of James Bay, Hudson wanted to press on to the west, but most of his crew mutinied. The mutineers cast Hudson, his son, and six others adrift; what then happened to the Hudsons and their companions is unknown.\nEarly life.\nVirtually nothing of Hudson's early life is known for certain. His year of birth is variously estimated between 1560 and 1570. He may have been born in London and it is possible that his father was an alderman of that city. When Hudson first entered the historical record in 1607, he was already an experienced mariner with sufficient credentials to be commissioned the leader of an expedition charged with a search for a trade route across the North Pole.\nExploration.\nExpeditions of 1607 and 1608.\nIn 1607, the Muscovy Company of England hired Hudson to find a northerly route to the Pacific coast of Asia. At the time, the English were engaged in an economic battle with the Dutch for control of northwest routes. It was thought that, because the sun shone for three months in the northern latitudes in the summer, the ice would melt, and a ship could make it across the \"top of the world\".\nOn 1 May 1607, Hudson sailed with a crew of ten men and a boy on the 80-ton \"Hopewell\". They reached the east coast of Greenland on 13 May, coasting northward until 22 May. Here the party named a headland \"Young's Cape\", a \"very high mount, like a round castle\" near it \"Mount of God's Mercy\" and land at 73\u00b0\u00a0north latitude \"Hold with Hope\". After turning east, they sighted \"Newland\" (Spitsbergen) on 27 May near the mouth of the great bay Hudson later simply named the \"Great Indraught\" (Isfjorden).\nOn 13 July, Hudson and his crew estimated that they had sailed as far north as 80\u00b0\u00a023\u2032\u00a0N, but had more likely only reached 79\u00b0\u00a023\u2032\u00a0N. The following day they entered what Hudson later in the voyage named \"Whales Bay\" (Krossfjorden and Kongsfjorden), naming its northwestern point \"Collins Cape\" (Kapp Mitra) after his boatswain, William Collins. They sailed north the following two days. On 16 July, they reached as far north as Hakluyt's Headland (which Thomas Edge says Hudson named on this voyage) at 79\u00b0\u00a049\u2032\u00a0N, thinking they saw the land continue to 82\u00b0\u00a0N (Svalbard's northernmost point is 80\u00b0\u00a049\u2032\u00a0N) when really it trended to the east. Encountering ice packed along the north coast, they were forced to turn back south. Hudson wanted to make his return \"by the north of Greenland to Davis his Streights (Davis Strait), and so for Kingdom of England\", but ice conditions would have made this impossible. The expedition returned to Tilbury Hope on the River Thames on 15\u00a0September.\nHudson reported large numbers of whales in Spitsbergen waters during this voyage. Many authors credit his reports as the catalyst for several nations sending whaling expeditions to the islands. This claim is contentious; others have pointed to strong evidence that it was Jonas Poole's reports in 1610, that led to the establishment of English whaling, and voyages of Nicholas Woodcock and Willem Cornelisz van Muyden in 1612, which led to the establishment of Dutch, French and Spanish whaling. The whaling industry was built by neither Hudson nor Poole\u2014both were dead by 1612.\nIn 1608, English merchants of the East India and Muscovy Companies again sent Hudson in the \"Hopewell\" to attempt to locate a passage to the Indies, this time to the east around northern Russia. Leaving London on 22\u00a0April, the ship travelled almost , making it to Novaya Zemlya well above the Arctic Circle in July, but even in the summer they found the ice impenetrable and turned back, arriving at Gravesend on 26\u00a0August.\nAlleged discovery of Jan Mayen.\nAccording to Thomas Edge, \"William [\"sic\"] Hudson\" in 1608 discovered an island he named \"Hudson's Tutches\" (Touches) at 71\u00b0\u00a0N, the latitude of Jan Mayen. However, records of Hudson's voyages suggest that he could only have come across Jan Mayen in 1607 by making an illogical detour, and historians have pointed out that Hudson himself made no mention of it in his journal. There is also no cartographical proof of this supposed discovery.\nJonas Poole in 1611 and Robert Fotherby in 1615 both had possession of Hudson's journal while searching for his elusive Hold-with-Hope\u2014which is now believed to have been on the east coast of Greenland\u2014but neither had any knowledge of any discovery of Jan Mayen, an achievement which was only later attributed to Hudson. Fotherby eventually stumbled across Jan Mayen, thinking it a new discovery and naming it \"Sir Thomas Smith's Island\", though the first verifiable records of the discovery of the island had been made a year earlier, in 1614.\nExpedition of 1609.\nIn 1609, Hudson was chosen by merchants of the Dutch East India Company in the Netherlands to find an easterly passage to Asia. While awaiting orders and supplies in Amsterdam, he heard rumours of a northwest route to the Pacific through North America. Hudson had been told to sail through the Arctic Ocean north of Russia, into the Pacific and so to the Far East. Hudson departed Amsterdam on 4\u00a0April, in command of the Dutch ship (English: Half Moon). He could not complete the specified (eastward) route because ice blocked the passage, as with all previous such voyages, and he turned the ship around in mid-May while somewhere east of Norway's North Cape. At that point, acting outside his instructions, Hudson pointed the ship west and decided to try to seek a westerly passage through North America.\nThey reached the Grand Banks of Newfoundland on 2\u00a0July, and in mid-July made landfall near the LaHave area of Nova Scotia. Here they encountered Indigenous people who were accustomed to trading with the French; they were willing to trade beaver pelts, but apparently no trades occurred. The ship stayed in the area about ten days, the crew replacing a broken mast and fishing for food. On the 25 July, a dozen men from the \"Halve Maen\", using muskets and small cannon, went ashore and assaulted the village near their anchorage. They drove the people from the settlement and took their boat and other property\u2014probably pelts and trade goods.\nOn 4 August, the ship was at Cape Cod, from which Hudson sailed south to the entrance of the Chesapeake Bay. Rather than entering the Chesapeake he explored the coast to the north, finding Delaware Bay but continuing on north. On 3\u00a0September, he reached the estuary of the river that initially was called the \"North River\" or \"Mauritius\" and now carries his name. He was not the first European to discover the estuary, though, as it had been known since the voyage of Giovanni da Verrazzano in 1524.\nOn 6 September 1609, John Colman of his crew was killed by natives with an arrow to his neck. Hudson sailed into the Upper New York Bay on 11\u00a0September, and the following day encountered a group of 28 Lenape canoes, buying oysters and beans from the Native Americans, and then began a journey up what is now known as the Hudson River. Over the next ten days his ship ascended the river, reaching a point near Stuyvesant Landing (Old Kinderhook), and the ship's boat with five crew members ventured to the vicinity of present-day Albany.\nOn 23 September, Hudson decided to return to Europe. He put in at Dartmouth, England on 7\u00a0November, and was detained by authorities who wanted access to his log. He managed to pass the log to the Dutch ambassador to England, who sent it, along with his report, to Amsterdam.\nWhile exploring the river, Hudson had traded with several native groups, mainly obtaining furs. His voyage was used to establish Dutch claims to the region and to the fur trade that prospered there when a trading post was established at Albany in 1614. New Amsterdam on Manhattan Island became the capital of New Netherland in 1625.\nExpedition of 1610\u20131611.\nIn 1610, Hudson obtained backing for another voyage, this time under the English flag. The funding came from the Virginia Company and the British East India Company. At the helm of his new ship, the , he stayed to the north (some claim he had deliberately stayed too far south on his Dutch-funded voyage), reached Iceland on 11\u00a0May, the south of Greenland on 4\u00a0June, and rounded the southern tip of Greenland.\nOn 25 June, the explorers reached what is now the Hudson Strait at the northern tip of Labrador. Following the southern coast of the strait on 2\u00a0August, the ship entered Hudson Bay. Excitement was very high due to the expectation that the ship had finally found the Northwest Passage through the continent. Hudson spent the following months mapping and exploring its eastern shores, but he and his crew did not find a passage to Asia. In November, the ship became trapped in the ice in James Bay, and the crew moved ashore for the winter.\nMutiny.\nWhen the ice cleared in the spring of 1611, Hudson planned to use his \"Discovery\" to further explore Hudson Bay with the continuing goal of discovering the Passage; however, most of the members of his crew ardently desired to return home. Matters came to a head and much of the crew mutinied in June. Descriptions of the successful mutiny are one-sided, because the only survivors who could tell their story were the mutineers and those who went along with the mutiny.\nIn the latter class was ship's navigator, Abacuk Pricket, a survivor who kept a journal that was to become one of the sources for the narrative of the mutiny. According to Pricket, the leaders of the mutiny were Henry Greene and Robert Juet. The latter, a navigator, had accompanied Hudson on the 1609 expedition, and his account is said to be \"the best contemporary record of the voyage\". Pricket's narrative tells how the mutineers set Hudson, his teenage son John, and seven crewmen\u2014men who were either sick and infirm or loyal to Hudson\u2014adrift from the \"Discovery\" in a small shallop, an open boat, effectively marooning them in Hudson Bay. The Pricket journal reports that the mutineers provided the castaways with clothing, powder and shot, some pikes, an iron pot, some food, and other miscellaneous items. \nDisappearance.\nAfter the mutiny, Hudson's shallop broke out oars and tried to keep pace with the \"Discovery\" for some time. Pricket recalled that the mutineers finally tired of the pursuit and unfurled additional sails aboard the \"Discovery\", enabling the larger vessel to leave the tiny open boat behind. Hudson and the other seven aboard the shallop were never seen by Europeans again. Despite subsequent searches, including those conducted by Thomas Button in 1612 and by Zachariah Gillam in 1668\u20131670, their fate is unknown.\nPricket's reliability.\nWhile Pricket's account is one of the few surviving records of the voyage, its reliability has been questioned by some historians. Pricket's journal and testimony have been severely criticized for bias, on two grounds. Firstly, prior to the mutiny the alleged leaders of the uprising, Greene and Juet, had been friends and loyal seamen of Hudson. Secondly, Greene and Juet did not survive the return voyage to England (Juet, who had been the navigator on the return journey, died of starvation a few days before the company reached Ireland). Pricket knew he and the other survivors of the mutiny would be tried in England for piracy, and it would have been in his interest, and the interest of the other survivors, to put together a narrative that would place the blame for the mutiny upon men who were no longer alive to defend themselves.\nThe Pricket narrative became the controlling story of the expedition's disastrous end. Only eight of the thirteen mutinous crewmen survived the return voyage to Europe. They were arrested in England, and some were put on trial, but no punishment was imposed for the mutiny. One theory holds that the survivors were considered too valuable as sources of information to execute, as they had travelled to the New World and could describe sailing routes and conditions.\nLater developments.\nIn 1612, Nicolas de Vignau claimed he saw wreckage of an English ship on the shores of James Bay, located on the southern end of Hudson Bay\u2014while this was discounted at the time by Samuel de Champlain, historians believe it may have credence.\nBritish-born Canadian author Dorothy Harley Eber (1925\u20132022) collected Inuit testimonies that she thought made reference to Hudson and his son after the mutiny. According to these, an old man with a long white beard and a young boy arrived in a small wooden boat. The Inuit had never seen a white person before, but they took them to an encampment and fed them. After the old man died, the Inuit tethered the boy to one of their houses so he would not run away. Despite the long time passed, the story might be given some credence after long-ignored Inuit testimonies proved reliable enough to lead to the discovery of the wrecks of the two ships of Franklin's lost expedition of 1845, and , in the 2010s. Charles Francis Hall, who searched for Franklin in the mid-19th century, also collected Inuit stories that he interpreted as references to the even earlier expedition of Martin Frobisher, who explored the area and mined fool's gold in 1578.\nIn the late 1950s, a stone near Deep River, Ontario, which is approximately south of James Bay, was found to have carving on it with Hudson's initials (H. H.), the year 1612, and the word \"captive\". While lettering on the stone was consistent with English maps of the 17th century, the Geological Survey of Canada was unable to determine when the carving was made.\nLegacy.\nThe bay visited by and named after Hudson is three times the size of the Baltic Sea, and its many large estuaries afford access to otherwise landlocked parts of Western Canada and the Arctic. This allowed the Hudson's Bay Company to exploit a lucrative fur trade along its shores for more than two centuries, growing powerful enough to influence the history and present international boundaries of western North America.\nAlong with Hudson Bay and Hudson Strait in Canada, many other topographical features and landmarks are named for Hudson. The Hudson River in New York and New Jersey is named after him, as are Hudson County, New Jersey, the Henry Hudson Bridge, the Henry Hudson Parkway, and the city of Hudson, New York.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "44017", "revid": "22249012", "url": "https://en.wikipedia.org/wiki?curid=44017", "title": "Candle", "text": "Wick embedded in solid flammable substance\nA candle is an ignitable wick embedded in wax, or another flammable solid substance such as tallow, that provides light, and in some cases, a fragrance. A candle can also provide heat or a method of keeping time. Candles have been used for over two millennia around the world, and were a significant form of indoor lighting until the invention of other types of light sources. Although electric light has largely made candle use nonessential for illumination, candles are still commonly used for functional, symbolic and aesthetic purposes and in specific cultural and religious settings.\nSome early candles were made of beeswax, but these candles were expensive and their use was limited to the elite and the churches. Tallow was a cheaper but less aesthetically pleasing alternative. In the modern era, various materials have been developed for candle making, including paraffin wax. This, combined with efficient production techniques, made candles affordable for the general public. Various devices can be used to hold candles, including candlesticks, candelabras, chandeliers, lanterns, and sconces. A person who makes candles is traditionally known as a chandler.\nThe combustion of the candle proceeds in a self-sustaining manner. As the wick of a candle is lit, the heat melts and ignites a small amount of solid fuel (the wax), which vaporizes and combines with oxygen in the air to form a flame. The flame then melts the top of the mass of solid fuel, which moves upward through the wick via capillary action to be continually burnt, thereby maintaining a constant flame. The candle shortens as the solid fuel is consumed, so does the wick. Wicks of pre-19th century candles required regular trimming with scissors or \"snuffers\" to promote steady burning and prevent smoking. In modern candles, the wick is constructed so that it curves over as it burns, and the end of the wick gets trimmed by itself through incineration by fire.\nEtymology.\nThe word candle comes from Middle English , from Old English and from Anglo-Norman , both from Latin , from 'to shine'.\nHistory.\nPrior to the invention of candles, ancient people used open fire, torches, splinters of resinous wood, and lamps to provide artificial illumination at night. Primitive oil lamps in which a lit wick rested in a pool of oil or fat were used from the Paleolithic period, and pottery and stone lamps from the Neolithic period have been found. Because candle making requires a reliable supply of animal or vegetable fats, it is certain that candles could not have developed before the early Bronze Age; however, it is unclear when and where candles were first used. Objects that could be candlesticks have been found in Babylonian and middle Minoan cultures, as well in the tomb of Tutankhamun. The \"candles\" used in these early periods would not have resembled the current forms; more likely they were made of plant materials dipped in animal fat.\nEarly evidence of candle use may be found in Italy, where a depiction of a candlestick exists in an Etruscan tomb at Orvieto, and the earliest excavated Etruscan candlestick dates from the 7th century BC. Candles may have evolved from taper with wick of oakum and other plant fibre soaked in fat, pitch or oil and burned in lamps or pots. Candles of antiquity were made from various forms of natural fat, tallow, and wax, and Romans made true dipped candles from tallow and beeswax. Beeswax candles were expensive and their use was limited to the wealthy, so oil lamps were the more commonly used lighting devices in Roman times. Ancient Greece used torches and oil lamps, and likely adopted candle use in a later period from Rome. Early record in China suggests that candles were used in the Qin dynasty before 200\u00a0BC. These early Chinese candles may have been made from whale fat.\nIn Christianity, candles gained significance in their decorative, symbolic and ceremonial uses in churches. Wax candles, or \"candela cerea\" recorded at the end of the 3rd century, were documented as Easter candles in Spain and Italy in the fourth century, the Christian festival Candlemas was named after it, and Pope Sergius I instituted the procession of lighted candles. Papal bulls decreed that tallow be excluded for use in altar candles, and a high beeswax content is necessary for candles of the high altar.\nIn medieval Europe, candles were initially used primarily in Christian churches. Their use spread later to the households of the wealthy as a luxury item. In Northern Europe, especially England, rushlights made of greased rushes were commonly used, but tallow candles were used during the Middle Ages, with a mention of tallow candles in English appearing in 1154. Beeswax was widely used in church ceremonies. Compared to animal-based tallow, it burns cleanly without smoky flame, and does not release an unpleasant smell like tallow. Beeswax candles were expensive, and relatively few people could afford to burn them in their homes in medieval Europe.\nThe candles were produced using a number of methods: dipping the wick in molten fat or wax, rolling the candle by hand around a wick, or pouring fat or wax onto a wick to build up the candle. In the 14th century Sieur de Brez introduced the technique of using a mould, but real improvement for the efficient production of candles with mould was only achieved in the 19th century. Wax and tallow candles were made in monasteries in the medieval period, and in rural households, tallow candles were made at home. By the 13th century, candle making had become a guild craft in England and France, with a French guild documented as early as 1061. The candle makers (chandlers) went from house to house making candles from the kitchen fats saved for that purpose, or made and sold their own candles from small candle shops.\nBy the 16th century, beeswax candles were appearing as luxury household items among the wealthy. Candles were widely used in the 17th and 18th centuries, and a party in Dresden was said to have been lit by 14,000 candles in 1779.\nIn the Middle East, during the Abbasid and Fatimid Caliphates, beeswax was the dominant material used for candle making. Beeswax was often imported from long distances; for example, candle makers from Egypt used beeswax from Tunis. As in Europe, these candles were expensive and limited to the elite, and most commoners used oil lamps instead. According to legend, the practice of using lamps and candles in mosque started with Tamim al-Dari who lit a lamp he brought from Syria in the Prophet's Mosque in Medina. The Umayyad caliph Al-Walid II was known to have used candles in the court in Damascus, while the Abbasid caliph al-Mutawakkil was said to have spent 1.2\u00a0million silver dirhams annually on candles for his royal palaces.\nIn early modern Syria, candles were in high demand by all socioeconomic classes because they were customarily lit during marriage ceremonies. There were candle makers' guilds in the Safavid capital of Isfahan during the 1500s and 1600s. However, candle makers had a relatively low social position in Safavid Iran, comparable to barbers, bathhouse workers, fortune tellers, bricklayers, and porters.\nIn the 18th and 19th centuries, spermaceti, a waxy substance produced by the sperm whale, was used to produce a superior candle that burned longer, brighter and gave off no offensive smell. Later in the 18th century, colza oil and rapeseed oil came into use as much cheaper substitutes.\nModern era.\nA number of improvements were made to the candle in the 19th century. In older candles, the wick of a burning candle was not in direct contact with air, so it charred instead of being burnt. The charred wick inhibited further burning and produced black smoke, so the wick needed to be constantly trimmed or \"snuffed\". In 1825, a French man M. Cambac\u00e9r\u00e8s introduced the plaited wick soaked with mineral salts, which when burnt, curled towards the outer edge of the flame and become incinerated by it, thereby trimming itself. These are referred to as \"self-trimming\" or \"self-consuming\" wicks. In 1823, Michel Eug\u00e8ne Chevreul and Joseph Louis Gay-Lussac separate out stearin in animal fats, and obtained a patent in 1825 to produce candles that are harder and can burn brighter.\nThe manufacture of candles became an industrialized mass market in the mid 19th century. In 1834, Joseph Morgan, a pewterer from Manchester, England, patented a machine that revolutionised candle making. It allowed for continuous production of molded candles by using a cylinder with a moveable piston to eject candles as they solidified. This more efficient mechanized production produced about 1,500\u00a0candles per hour. This allowed candles to be an affordable commodity for the masses.\nIn the mid-1850s, James Young succeeded in distilling paraffin wax from coal and oil shales at Bathgate in West Lothian and developed a commercially viable method of production. Paraffin could be used to make inexpensive candles of high quality. It was a bluish-white wax, which burned cleanly and left no unpleasant odor, unlike tallow candles. By the end of the 19th century, candles were made from paraffin wax and stearic acid.\nBy the late 19th century, Price's Candles, based in London, was the largest candle manufacturer in the world. Founded by William Wilson in 1830, the company pioneered the implementation of the technique of steam distillation, and was thus able to manufacture candles from a wide range of raw materials, including skin fat, bone fat, fish oil and industrial greases.\nDespite advances in candle making, the candle industry declined rapidly upon the introduction of superior methods of lighting, including kerosene lamps and the 1879 invention of the incandescent light bulb. From this point on, candles came to be marketed as more of a decorative item.\nUse.\nBefore the invention of electric lighting, candles and oil lamps were commonly used for illumination. In areas without electricity, they are still used routinely. In the developed world today, candles are used mainly for their aesthetic value and scent, particularly to set a soft, warm, or romantic ambiance, or for emergency lighting during electrical power failures. They are also still commonly used in religious and ceremonial contexts. Examples include votive candles, Paschal candles and yahrzeit candles. In the days leading to Christmas, some people burn a candle a set amount to represent each day, as marked on the candle. The type of candle used in this way is called the \"Advent candle\", although this term is also used to refer to candles that are used in an Advent wreath.\nSymbolic use of candles has extended from the religious to the secular, for example, a candlelight vigil may be held in remembrance for a person, for a cause or an event, or as a form of political action or protest. In a social setting, candles are commonly used on birthday cakes.\nIn the 21st century, there has been an increase in sales of scented candles in recent years, particularly during the COVID-19 pandemic and the ensuing lockdowns, with scented candles, diffusers and room sprays becoming popular.\nOther uses.\nWith the fairly consistent and measurable burning of a candle, a common use of candles was to tell the time. The candle designed for this purpose might have time measurements, usually in hours, marked along the wax. The Song dynasty in China (960\u20131279) used candle clocks.\nBy the 18th century, candle clocks were being made with weights set into the sides of the candle. As the candle melted, the weights fell off and made a noise as they fell into a bowl.\nComponents.\nWax.\nFor most of recorded history candles were made from tallow (rendered from beef or mutton-fat) or beeswax. From the mid-1800s, they were also made from spermaceti, a waxy substance derived from the Sperm whale, which in turn spurred demand for the substance. Candles were also made from stearin (initially manufactured from animal fats but now produced almost exclusively from palm waxes). Today, most candles are made from paraffin wax, a byproduct of petroleum refining.\nCandles can also be made from microcrystalline wax, beeswax (a byproduct of honey collection), gel (a mixture of polymer and mineral oil), or some plant waxes (generally palm, carnauba, bayberry, or soybean wax). In the Far East, stillingia tallow and Japan wax from plants have been used for centuries. They also used Chinese wax produced from insects.\nThe size of the flame and corresponding rate of burning is controlled largely by the candle wick. The kind of wax also affects the burn rate, with beeswax and coconut wax burning longer than paraffin or soy wax.\nProduction methods utilize extrusion moulding. More traditional production methods entail melting the solid fuel by the controlled application of heat. The liquid is then poured into a mould, or a wick is repeatedly immersed in the liquid to create a dipped tapered candle. Often fragrance oils, essential oils or aniline-based dye is added.\nWick.\nA candle wick works by capillary action, drawing (\"wicking\") the melted wax or fuel up to the flame. When the liquid fuel reaches the flame, it vaporizes and combusts. The candle wick influences how the candle burns. Important characteristics of the wick include diameter, stiffness, fire resistance, and tethering.\nA candle wick is a piece of string or cord that holds the flame of a candle. Commercial wicks are made from braided cotton. The wick's capillarity determines the rate at which the melted hydrocarbon is conveyed to the flame. If the capillarity is too great, the molten wax streams down the side of the candle. Wicks are often infused with a variety of chemicals to modify their burning characteristics. For example, it is usually desirable that the wick not glow after the flame is extinguished. Typical agents are ammonium nitrate and ammonium sulfate.\nCharacteristics.\nLight.\nBased on measurements of a taper-type, paraffin wax candle, a modern candle typically burns at a steady rate of about 0.1\u00a0g/min, releasing heat at roughly 80\u00a0W. The light produced is about 13\u00a0lumens, for a luminous efficacy of about 0.16\u00a0lumens per watt (luminous efficacy of a source)\u00a0\u2013 almost a hundred times lower than an incandescent light bulb. If a 1\u00a0candela source emitted uniformly in all directions, the total radiant flux would be only about 18.40\u00a0mW.\nThe luminous intensity of a typical candle is approximately one candela. The SI unit, candela, was in fact based on an older unit called the \"candlepower\", which represented the luminous intensity emitted by a candle made to particular specifications (a \"standard candle\"). The modern unit is defined in a more precise and repeatable way, but was chosen such that a candle's luminous intensity is still about one candela.\nTemperature.\nThe hottest part of a candle flame is just above the very dull blue part to one side of the flame, at the base. At this point, the flame is about . However, this part of the flame is very small and releases little heat energy. The blue color is due to chemiluminescence, while the visible yellow color is due to radiative emission from hot soot particles. The soot is formed through a series of complex chemical reactions, leading from the fuel molecule through molecular growth, until multi-carbon ring compounds are formed. The thermal structure of a flame is complex, hundreds of degrees over very short distances leading to extremely steep temperature gradients. On average, the flame temperature is about . The color temperature is approximately 1,000\u00a0K.\nCombustion.\nFor a candle to burn, a heat source (commonly a naked flame from a match or lighter) is used to light the candle's wick, which melts and vaporizes a small amount of fuel (the wax). Once vaporized, the fuel combines with oxygen in the atmosphere to ignite and form a constant flame. This flame provides sufficient heat to keep the candle burning via a self-sustaining chain of events: the heat of the flame melts the top of the mass of solid fuel; the liquefied fuel then moves upward through the wick via capillary action; the liquefied fuel finally vaporizes to burn within the candle's flame.\nAs the fuel (wax) is melted and burned, the candle becomes shorter. The end of the plaited wick bends and get consumed in the flame. The incineration of the wick limits the length of the exposed portion of the wick, thus maintaining a constant burning temperature and rate of fuel consumption. Pre-19th century wicks required regular trimming with scissors (or a specialized wick trimmer), usually to about one-quarter inch (~0.7\u00a0cm), to promote steady burning and to prevent it from releasing black smoke. Special candle scissors called \"snuffers\" were produced for this purpose in the 20th century and were often combined with an extinguisher. In modern candles, the wick is made in such a way that it curves over as it burns, which ensures that the end of the wick gets incinerated by fire, thereby trimming itself.\nCandle flame.\nA candle flame is formed because wax vaporizes on burning. A candle flame is widely recognized as having between three and five regions or \"zones\":\nThe main determinant of the height of a candle flame is the diameter of the wick. This is evidenced in tealights where the wick is very thin and the flame is very small. Candles whose main purpose is illumination use a much thicker wick.\nHistory of study.\nOne of Michael Faraday's significant works was \"The Chemical History of a Candle\", where he gives an in-depth analysis of the evolutionary development, workings and science of candles.\nHazards.\nAccording to the National Fire Protection Association, candles are a leading source of residential fires in the United States with almost 10% of civilian injuries and 6% of fatalities from fire attributed to candles.\nA candle flame that is longer than its laminar smoke point will emit soot. Proper wick trimming will reduce soot emissions from most candles.\nThe liquid wax is hot and can cause skin burns, but the amount and temperature are generally rather limited and the burns are seldom serious. The best way to avoid getting burned from splashed wax is to use a candle snuffer instead of blowing directly on the flame. A candle snuffer is usually a small metal cup on the end of a long handle. Placing the snuffer over the flame cuts off the oxygen supply. Snuffers were common in the home when candles were the main source of lighting before electric lights were available. Ornate snuffers, often combined with a taper for lighting, are still found in those churches which regularly use large candles.\nGlass candleholders are sometimes cracked by thermal shock from the candle flame, particularly when the candle burns down to the end. When burning candles in glass holders or jars, users should avoid lighting candles with chipped or cracked containers and discontinue use once a half inch or less of wax remains.\nA former worry regarding the safety of candles was that a lead core was used in the wicks to keep them upright in container candles. Without a stiff core, the wicks of a container candle could sag and drown in the deep wax pool. Concerns rose that the lead in these wicks would vaporize during the burning process, releasing lead vapors\u00a0\u2013 a known health and developmental hazard. Lead core wicks have not been common since the 1970s. Today, most metal-cored wicks use zinc or a zinc alloy, which has become the industry standard. Wicks made from specially treated paper and cotton are also available.\nCandles emit volatile organic compounds into the environment, which releases carbon into the air. The combustion process of lighting a candle includes the release of light, heat, carbon dioxide and water vapor, to fuel the flame. Candle use can be unsafe if fragrances are inhaled at high doses Non-toxic candles have been created as an alternative to prevent these volatile organic compounds from being released into the environment. Candle companies such as \"The Plant Project\" have created candles that are more environmentally sustainable and better for lung health. These alternatives include non-toxic wax blends, safe fragrances and eco-friendly packaging. Safer candles include candles made from coconut, soy, vegetable, and beeswax.\nUsers who seek the aesthetics of a candle sometimes install an electric flameless candle to avoid the hazards.\nRegulation.\nInternational markets have developed a range of standards and regulations to ensure compliance, while maintaining and improving safety, including:\nAccessories.\nCandle holders.\nDecorative candleholders, especially those shaped as a pedestal, are called candlesticks; if multiple candle tapers are held, the term \"candelabra\" is also used. The root form of \"chandelier\" is from the word for candle, but now often refers to an electric fixture. The word \"chandelier\" is used to describe a hanging fixture designed to hold multiple lights. Other forms of candle holders include the wall-mounted sconces, lanterns, and girandoles.\nMany candle holders use a friction-tight socket to keep the candle upright. In this case, a candle that is slightly too wide will not fit in the holder, and a candle that is slightly too narrow will wobble. Candles that are too big can be trimmed to fit with a knife; candles that are too small can be fitted with aluminium foil. Traditionally, the candle and candle holders were made in the same place, so they were appropriately sized, but international trade has combined the modern candle with existing holders, which makes the ill-fitting candle more common. This friction-tight socket is only needed for the federals and the tapers. \nFor tea light candles, there is a variety of candle holders, including small glass holders and elaborate multi-candle stands. The same is true for votives. Wall sconces are available for tea light and votive candles. For pillar-type candles, the assortment of candle holders is broad. A fireproof plate, such as a glass plate or small mirror, can be a candle holder for a pillar-style candle. A pedestal of any kind, with the appropriate-sized fireproof top, is another option. A large glass bowl with a large flat bottom and tall mostly vertical curved sides is called a hurricane. The pillar-style candle is placed at the bottom center of the hurricane. A hurricane on a pedestal is sometimes sold as a unit.\nA bob\u00e8che is a drip-catching ring, which may also be affixed to a candle holder, or used independently of one. Bob\u00e8ches can range from ornate metal or glass to simple plastic, cardboard, or wax paper. Use of paper or plastic bob\u00e8ches is common at events where candles are distributed to a crowd or audience, such as Christmas carolers or people at other concerts or festivals.\nCandle snuffers.\nCandle snuffers are instruments used to extinguish burning candles by smothering the flame with a small metal cup that is suspended from a long handle, and thus depriving it of oxygen. An older meaning refers to a scissor-like tool used to trim the wick of a candle. With skill, this could be done without extinguishing the flame. The instrument now known as a candle snuffer was formerly called an \"extinguisher\" or \"douter\".\nCandle followers.\nThese are glass or metal tubes with an internal stricture partway along, which sit around the top of a lit candle. As the candle burns, the wax melts and the follower holds the melted wax in, whilst the stricture rests on the topmost solid portion of wax. Candle followers are often deliberately heavy or weighted to ensure they move down as the candle burns lower, maintaining a seal and preventing wax escape. The purpose of a candle follower is threefold:\nCandle followers are often found in churches on altar candles.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44019", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=44019", "title": "205", "text": "Calendar year\nYear 205 (CCV) was a common year starting on Tuesday of the Julian calendar. At the time, it was known as the Year of the Consulship of Aurelius and Geta (or, less frequently, year 958 \"Ab urbe condita\"). The denomination 205 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44020", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=44020", "title": "DSP", "text": "DSP may refer to: \n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "44021", "revid": "45625665", "url": "https://en.wikipedia.org/wiki?curid=44021", "title": "Utopian and dystopian fiction", "text": "Genres of literature that explore social and political structures\nUtopian and dystopian fiction are subgenres of speculative fiction that explore extreme forms of social and political structures. A utopia is a setting that agrees with the author's ethos, having various attributes of another reality intended to appeal to readers. A dystopia offers the opposite: the portrayal of a setting that completely disagrees with the author's ethos. Some novels depict both types of society to more directly contrast their properties. Both utopias and dystopias are commonly found in science fiction and other types of speculative fiction.\nMore than 400 utopian works in the English language were published prior to the year 1900, with more than a thousand others appearing during the 20th century. This increase is partially associated with the rise in popularity of science fiction and young adult fiction more generally, but also larger scale social change that brought awareness of larger societal or global issues, such as technology, climate change, and growing human population. Some of these trends have created distinct subgenres such as climate fiction, young adult dystopian novels, and feminist dystopian novels.\nUtopian fiction in general.\nUtopian Literature sets itself aside as a literature form of utopian thought and desire. Its characteristics can be described as the thought of a better or ideal society compared to current society, these ideas being formed into a literary medium, the overall concept of utopian ideas encourages the reader to act towards bettering their current society or moves them to understand and recognize current issues critically, and that utopian thought emerges from the desire for a better life and society.\nThe word \"utopia\" was first used in direct context by Thomas More in his 1516 work \"Utopia\". The word\n\"utopia\" resembles both the Greek words \"outopos\" (\"no place\"), and \"eutopos\" (\"good place\").\nExamples.\nThomas More's 1516 book \"Utopia\", written in Latin, sets out a vision of an ideal society. As the title suggests, the work presents an ambiguous and ironic projection of the ideal state. The whimsical nature of the text can be confirmed by the narrator of \"Utopia\"'s second book, Raphael Hythloday. The Greek root of the name \"Hythloday\" suggests an 'expert in nonsense.' Thomas More's idea of a utopia stems from the current economic and societal issues in Tudor England. More directly confronts the issues of rising population, oppressive landlords, and civilians turning to crime through Hythloday's perspective in Book I of his novel.\nAn earlier example of a Utopian work from classical antiquity is Plato's \"Republic\", in which he outlines what he sees as the ideal society and its political system. Later, Tommaso Campanella was influenced by Plato's work and wrote \"The City of the Sun\" (1623), which describes a modern utopian society built on equality. Other examples include Samuel Johnson's \"The History of Rasselas, Prince of Abissinia\" (1759) and Samuel Butler's \"Erewhon\" (1872), which uses an anagram of \"nowhere\" as its title. This, like much of utopian literature, can be seen as satire; Butler inverts illness and crime, with punishment for the former and treatment for the latter.\nOne example of the utopian genre's meaning and purpose is described in Fredric Jameson's \"Archeologies of the Future\" (2005)\",\" which addresses many utopian varieties defined by their program or impulse. He describes the fundamental dynamic of utopias lying in \"identity and difference.\" Jameson states that the core of utopian thought and politics lies in an imagined system that is thoroughly different from an original, real one.\nAnother early work of utopian but satirical fiction would be the English philosopher and writer Margaret Cavendish\u2019s \"The Description of a New World, Called the Blazing World\" (1666). This is an early example of what would later be called science fiction writing. There is debate about to what degree Cavendish's work can be called feminist. For example, Rachel Trubowitz describes \"A Blazing World\" as a feminist utopia due to how much it challenges traditional gender roles; however, Sujata Iyengar says that Cavendish\u2019s work reinforces ideas of racial and feminine inferiority. Vanessa Rapatz focuses more on Cavendish's subsequent impact and argues that her writings provide a context for understanding contemporary feminist authors such as Toni Morrison and Octavia Butler. Because Cavendish often broke the boundaries of conventional female writing and behavior, many people have been dismissive of her utopian vision. Samuel Pepys described Cavendish as being a \u201cmad, conceited\u201d and \u201cridiculous woman\u201d. Virginia Woolf wrote that her work lacked discipline and \u201cher ideas [were] poured out higgledy-piggledy in torrents of prose, poetry, and philosophy.\u201d\nDystopian fiction.\nA dystopia is a society characterized by a focus on that which is contrary to the author's ethos, such as mass poverty, public mistrust and suspicion, a police state or oppression. Most authors of dystopian fiction explore at least one reason why things are that way, often as an analogy for similar issues in the real world. Dystopian literature serves to \"provide fresh perspectives on problematic social and political practices that might otherwise be taken for granted or considered natural and inevitable\".\nSome dystopias claim to be utopias. Samuel Butler's \"Erewhon\" can be seen as a dystopia because of the way sick people are punished as criminals while thieves are \"cured\" in hospitals, which the inhabitants of Erewhon see as natural and right, i.e., utopian (as mocked in Voltaire's \"Candide\").\nDystopias usually extrapolate elements of contemporary society, and thus can be read as political warnings.\nEschatological literature is a form of literature that can go hand-in-hand with dystopian literature. This is a form of literature that specifically focuses on some form of apocalypse, such as the collapse of a society, the end of an era of human history, or the end of the world itself.\nExamples.\nThe 1921 novel \"We\" by Yevgeny Zamyatin portrays a post-apocalyptic future in which society is entirely based on logic and modeled after mechanical systems. George Orwell was influenced by \"We\" when he wrote \"Nineteen Eighty-Four\" (published in 1949), a novel about Oceania, a state at perpetual war, its population controlled through propaganda. Big Brother and the daily Two Minutes Hate set the tone for an all-pervasive self-censorship. Aldous Huxley's 1932 novel \"Brave New World\" started as a parody of utopian fiction, and projected into the year 2540 industrial and social changes he perceived in 1931, leading to industrial success by a coercively persuaded population divided into five castes. Karin Boye's 1940 novel \"Kallocain\" is set in a totalitarian world state where a drug is used to control the individual's thoughts.\nAnthony Burgess' 1962 novel \"A Clockwork Orange\" is set in a future England that has a subculture of extreme youth violence, and details the protagonist's experiences with the state intent on changing his character at its whim. Margaret Atwood's \"The Handmaid's Tale\" (1985) describes a future United States governed by a totalitarian theocracy, where women have no rights, and Stephen King's \"The Long Walk\" (1979) describes a similar totalitarian scenario, but depicting the participation of teenage boys in a deadly contest. Examples of young-adult dystopian fiction include (notably all published after 2000) \"The Hunger Games\" series by Suzanne Collins, the \"Divergent\" series by Veronica Roth, \"The Power of Five\" series by Anthony Horowitz, \"The Maze Runner\" series by James Dashner, and the \"Uglies\" series by Scott Westerfeld. Video games often include dystopias as well; notable examples include the \"Fallout\" series, \"BioShock\", and the later games of the \"Half-Life\" series.\nHistory of dystopian fiction.\nThe history of dystopian literature can be traced back to the reaction to the French Revolution of 1789 and the prospect that mob rule would produce dictatorship. Until the late 20th century, it was usually anti-collectivist. Dystopian fiction emerged as a response to the utopian. Its early history is traced in Gregory Claeys' \"Dystopia: A Natural History\" (Oxford University Press, 2017).\nThe beginning of technological dystopian fiction can be traced back to E. M. Forster's \"The Machine Stops\" (1909). M Keith Booker states that \"The Machine Stops,\" \"We\" (1921) and \"Brave New World\" (1932) are \"the great defining texts of the genre of dystopian fiction, both in [the] vividness of their engagement with real-world social and political issues and in the scope of their critique of the societies on which they focus.\"\nAnother important figure in dystopian literature is H. G. Wells, whose work \"The Time Machine\" (1895) is also widely seen as a prototype of dystopian literature. Wells' work draws on the social structure of the 19th century, providing a critique of the British class structure at the time. Post World War II, even more dystopian fiction was produced. These works of fiction were interwoven with political commentary: the end of World War II brought about fears of an impending Third World War and a consequent apocalypse.\nModern dystopian fiction draws not only on topics such as totalitarian governments and anarchism, but also pollution, global warming, climate change, health, the economy and technology. Modern dystopian themes are common in the young adult (YA) genre of literature.\nSubgenres.\nCombinations.\nMany works combine elements of both utopias and dystopias. Typically, an observer from our world will journey to another place or time and see one society the author considers ideal and another representing the worst possible outcome. Usually, the point is that our choices may lead to a better or worse potential future world. Ursula K. Le Guin's \"Always Coming Home\" fulfills this model, as does Marge Piercy's \"Woman on the Edge of Time\". In Starhawk's \"The Fifth Sacred Thing\" there is no time-travelling observer. However, her ideal society is invaded by a neighbouring power embodying evil repression. In Aldous Huxley's \"Island\", in many ways a counterpoint to his better-known \"Brave New World\", the fusion of the best parts of Buddhist philosophy and Western technology is threatened by the \"invasion\" of oil companies. As another example, in the \"Unwanteds\" series by Lisa McMann, a paradox occurs where the outcasts from a complete dystopia are treated to absolute utopia. They believe that those who were privileged in said dystopia were the unlucky ones.\nIn another literary model, the imagined society journeys between elements of utopia and dystopia over the course of the novel or film. \"The Giver\" by Lois Lowry begins in a seemingly perfect society without pain, conflict, or inequality. The world is described as a utopia. However, as the book progresses, the dark aspects of this world emerge: strict control over individuals' lives, emotional suppression, lack of personal choice and erasure of memories and agency. These reveal the society's dystopian core, where stability is maintained through dehumanization and the denial of fundamental human freedoms. As such, \"The Giver\" is ultimately considered a dystopian novel rather than a utopian one.\nJonathan Swift's \"Gulliver's Travels\" is also sometimes linked with both utopian and dystopian literatures, because it shares the general preoccupation with ideas of good and bad societies. Of the countries Lemuel Gulliver visits, Brobdingnag and Country of the Houyhnhnms approach a utopia; the others have significant dystopian aspects.\nEcotopian fiction.\nIn ecotopian fiction, the author posits either a utopian or dystopian world revolving around environmental conservation or destruction. Danny Bloom coined the term \"cli-fi\" in 2006, with a Twitter boost from Margaret Atwood in 2011, to cover climate change-related fiction, but the theme has existed for decades. Novels dealing with overpopulation, such as Harry Harrison's \"Make Room! Make Room!\" (made into movie \"Soylent Green\"), were popular in the 1970s, reflecting widespread concerns with the effects of overpopulation on the environment and on individuals' quality of life. The novel \"Nature's End\" by Whitley Strieber and James Kunetka (1986) posits a future in which overpopulation, pollution, climate change, and resulting superstorms, have led to a popular mass-suicide political movement. Some other examples of ecological dystopias are depictions of Earth in the films \"Wall-E\" and \"Avatar\".\nWhile eco-dystopias are more common, a small number of works depicting what might be called eco-utopia, or eco-utopian trends, have also been influential. These include Ernest Callenbach's \"Ecotopia\", an important 20th century example of this genre. Another are Kim Stanley Robinson's works. He has written several books dealing with environmental themes, including the Mars trilogy. Most notably, however, his \"Three Californias Trilogy\" contrasted an eco-dystopia with an eco-utopia and a sort of middling-future. Robinson has also edited an anthology of short ecotopian fiction, called \"\". Another impactful piece of Robinson's is \"New York 2140\" which focuses on a society dealing with the aftermath after a major flooding event, and can be seen through both a utopian and dystopian lens.\nThere are a few dystopias that have an \"anti-ecological\" theme. These are often characterized by a government that is overprotective of nature or a society that has lost most modern technology and struggles for survival. A fine example of this is the novel \"Riddley Walker\".\nFeminist utopias.\nAnother subgenre is \"feminist utopias\" and the overlapping category of feminist science fiction. According to the author Sally Miller Gearhart, \"A feminist utopian novel is one which \"a.\" contrasts the present with an envisioned idealized society (separated from the present by time or space), \"b.\" offers a comprehensive critique of present values/conditions, \"c.\" sees men or male institutions as a major cause of present social ills, \"d.\" presents women as not only at least the equals of men but also as the sole arbiters of their reproductive functions.\"\nUtopias have explored the ramification of gender being either a societal construct or a hard-wired imperative. In Mary Gentle's \"Golden Witchbreed\", gender is not chosen until maturity, and gender has no bearing on social roles. In contrast, Doris Lessing's \"The Marriages Between Zones Three, Four and Five\" (1980) suggests that men's and women's values are inherent to the sexes and cannot be changed, making a compromise between them essential. In \"My Own Utopia\" (1961) by Elisabeth Mann Borgese, gender exists but is dependent upon age rather than sex \u2014 genderless children mature into women, some of whom eventually become men. Marge Piercy's novel \"Woman on the Edge of Time\" keeps human biology, but removes pregnancy and childbirth from the gender equation by resorting to assisted reproductive technology while allowing both women and men the nurturing experience of breastfeeding.\nUtopic single-gender worlds or single-sex societies have long been one of the primary ways to explore implications of gender and gender-differences. One solution to gender oppression or social issues in feminist utopian fiction is to remove men, either showing isolated all-female societies as in Charlotte Perkins Gilman's \"Herland\", or societies where men have died out or been replaced, as in Joanna Russ's \"A Few Things I Know About Whileaway\", where \"the poisonous binary gender\" has died off. In speculative fiction, female-only worlds have been imagined to come about by the action of disease that wipes out men, along with the development of a technological or mystical method that allows female parthenogenetic reproduction. The resulting society is often shown to be utopian by feminist writers. Many influential feminist utopias of this sort were written in the 1970s; the most often studied examples include Joanna Russ's \"The Female Man and\" Suzy McKee Charnas's \"The Holdfast Chronicles\". Such worlds have been portrayed most often by lesbian or feminist authors; their use of female-only worlds allows the exploration of female independence and freedom from patriarchy. The societies may not necessarily be lesbian, or sexual at all \u2014 \"Herland\" (1915) by Charlotte Perkins Gilman is a famous early example of a sexless society. Charlene Ball writes in \"Women's Studies Encyclopedia\" that use of speculative fiction to explore gender roles has been more common in the United States than in Europe and elsewhere.\nUtopias imagined by male authors have generally included equality between sexes rather than separation.\nCultural impact.\n\u00c9tienne Cabet's work \"Travels in Icaria\" caused a group of followers, the Icarians, to leave France in 1848, and travel to the United States to start a series of utopian settlements in Texas, Illinois, Iowa, California, and elsewhere. These groups lived in communal settings and lasted until 1898.\nDuring the first decades of the 20th century, utopian science fiction literature was very popular in Russia due to more citizens wanting to engage with fantasies of the future (as well as the fact that it was a new, up-and-coming genre of literature). During the Cold War, utopian science fiction became popular among Soviet leaders. As well, many Soviet Union citizens became dependent on this type of literature because it provided an escape from the real world, which was not ideal at the time. Utopian science fiction allowed readers to fantasize about how it would be to live in a \"perfect\" world.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44022", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=44022", "title": "206", "text": "Calendar year\nYear 206 (CCVI) was a common year starting on Wednesday of the Julian calendar. At the time, it was known as the Year of the Consulship of Umbrius and Gavius (or, less frequently, year 959 \"Ab urbe condita\"). The denomination 206 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nRoman Empire.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44024", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=44024", "title": "207", "text": "Calendar year\nYear 207 (CCVII) was a common year starting on Thursday of the Julian calendar. At the time, it was known in Rome as the Year of the Consulship of Maximus and Severus (or, less frequently, year 960 \"Ab urbe condita\"). The denomination 207 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44025", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=44025", "title": "208", "text": "Calendar year\nYear 208 (CCVIII) was a leap year starting on Friday of the Julian calendar. At the time, it was known as the Year of the Consulship of Aurelius and Geta (or, less frequently, year 961 \"Ab urbe condita\"). The denomination 208 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nParthia.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44026", "revid": "27613779", "url": "https://en.wikipedia.org/wiki?curid=44026", "title": "United States National Security Council", "text": "U.S. federal executive national security and intelligence forum\nThe United States National Security Council (NSC) is the national security council used by the president of the United States for consideration of national security, military, and foreign policy matters. Based in the White House, it is part of the Executive Office of the President of the United States, and composed of senior national security advisors and Cabinet officials.\nSince its inception in 1947 by President Harry S. Truman, the function of the council has been to advise and assist the president on national security and foreign policies. It also serves as the president's principal arm for coordinating these policies among various government agencies. The council has subsequently played a key role in most major events in U.S. foreign policy, from the Korean War to the war on terror.\nHistory.\nThe immediate predecessor to the National Security Council was the National Intelligence Authority (NIA), which was established by President Harry S. Truman's Executive Letter of January 22, 1946, to oversee the Central Intelligence Group, the CIA's predecessor. The NIA was composed of the secretary of state, the secretary of war, the secretary of the navy, and the chief of staff to the commander in chief.\nThe National Security Council was created in 1947 by the National Security Act. It was created because policymakers felt that the diplomacy of the State Department was no longer adequate to contain the Soviet Union in light of the tension between the Soviet Union and the United States. The intent was to ensure coordination and concurrence among the Army, Marine Corps, Navy, Air Force and other instruments of national security policy such as the Central Intelligence Agency (CIA), also created in the National Security Act.\nIn 1953, the Eisenhower administration's NSC wrote three policy papers on opposing the People's Republic of China. NSC 146 proposed backing Republic of China maritime raids and raids against the Chinese mainland.88 NSC 148 proposed to foster and support anti-communist Chinese elements both inside and outside of the country. NSC 166 proposed strategies to deny the PRC full status in the international community, pursuant to the view that making any concessions would strengthen the PRC.88\nIn 2004, the position of director of national intelligence (DNI) was created, taking over the responsibilities previously held by the head of the CIA, the director of central intelligence, as a cabinet-level position to oversee and coordinate activities of the Intelligence Community\nOn May 26, 2009, President Barack Obama merged the White House staff supporting the Homeland Security Council (HSC) and the National Security Council into one National Security Staff (NSS). The HSC and NSC each continue to exist by statute as bodies supporting the president. The name of the staff organization was changed back to National Security Council Staff in 2014.\nThe Directorate of Global Health Security and Biodefense was formed in 2016 under the Obama administration, disbanded in 2018 under the first Trump administration, and reinstated in January 2021 during the presidency of Joe Biden.\nAccording to a White House memorandum in January 2017, the chairman of the Joint Chiefs of Staff and director of national intelligence will only sit on the Principals Committee as and when matters pertaining to them arise, but will remain part of the full National Security Council. The reorganization also placed the administrator of the United States Agency for International Development as a permanent member of the Deputies Committee, winning moderate praise.\nOn January 29, 2017, newly elected President Donald Trump restructured the Principals Committee (a subset of the full National Security Council), while at the same time altering the attendance of the chairman of the Joint Chiefs of Staff and director of national intelligence. According to \"National Security Presidential Memorandum 2\", the chairman of the Joint Chiefs of Staff and director of national intelligence were to only sit on the Principals Committee as and when matters pertaining to them arise, but will remain part of the full National Security Council. However, Chief of Staff Reince Priebus clarified the next day that they still are invited to attend meetings.\nWith \"National Security Presidential Memorandum 4\" in April 2017, the director of national intelligence and the chairman of the Joint Chiefs of Staff \"shall\" attend Principals Committee meetings and the director of the Central Intelligence Agency was included as a regular attendee. The reorganization also placed the administrator of the United States Agency for International Development as a permanent member of the Deputies Committee, while the White House chief strategist was removed.\nAccording to a report by Reuters, the United States military ran a propaganda campaign to spread disinformation about the Sinovac Chinese COVID-19 vaccine, including using fake social media accounts saying that the Sinovac vaccine contained pork-derived ingredients and was therefore \"haram\" under Islamic law. The campaign was described as \"payback\" for COVID-19 disinformation by China directed against the U.S. The disinformation campaign began in 2020. In spring 2021, the NSC ordered the military to stop spreading anti-vaccine messages. The campaign continued until summer 2021 before terminating.\nIn August 2025, the Financial Times observed that \"in Trump\u2019s second term, the NSC has been drastically pared back, with dozens of foreign policy and national security experts [having been] ousted from their jobs\", and quoted an official with the assessment that \"the traditional Washington foreign policy process led by the NSC has largely broken down in this administration.\"\nAuthority and powers.\nThe National Security Council was established by the National Security Act of 1947 (PL 235 \u2013 61 Stat. 496; U.S.C. 402), amended by the National Security Act Amendments of 1949 (63 Stat. 579; 50 U.S.C. 401 et seq.). Later in 1949, as part of the Reorganization Plan, the council was placed in the Executive Office of the President.\nThe High Value Detainee Interrogation Group also reports to the NSC.\nKill authorizations.\nOne of the tasks of the National Security Council is to determine and identify people, including United States citizens who are deemed to be threats to national security and add them to a \"kill list\". In this case, no public record of this decision or any operation to kill the suspect will be made available. The panel's actions are justified by \"two principal legal theories\": They \"were permitted by Congress when it authorized the use of military forces against militants in the wake of the attacks of September 11, 2001; and they are permitted under international law if a country is defending itself.\"\nHomeland Security Advisor John O. Brennan, who helped codify targeted killing criteria by creating the Disposition Matrix database, has described the Obama Administration targeted killing policy by stating that \"in order to ensure that our counterterrorism operations involving the use of lethal force are legal, ethical, and wise, President Obama has demanded that we hold ourselves to the highest possible standards and processes\".\nReuters reported that Anwar al-Awlaki, an American citizen, was on such a kill list and was killed accordingly.\nMembership.\nThe National Security Council, as of 2021[ [update]] and as per statute and National Security Memorandum\u20132, is chaired by the president. Its members are the vice president (statutory), the secretary of state (statutory), the secretary of the treasury (statutory), the secretary of defense (statutory), the secretary of energy (statutory), the assistant to the president for national security affairs (non-statutory), the assistant to the president and director of the Office of Science and Technology Policy (non-statutory), the attorney general (non-statutory), the secretary of homeland security (non-statutory), and the representative of the United States to the United Nations (non-statutory).\nThe chairman of the Joint Chiefs of Staff is the military advisor to the council, the director of national intelligence is the intelligence advisor, and the director of national drug control policy is the drug control policy advisor. The chief of staff to the president, White House counsel, and the assistant to the president for economic policy are also regularly invited to attend NSC meetings. The attorney general, the director of the Office of Management and Budget and the director of the Central Intelligence Agency are invited to attend meetings pertaining to their responsibilities. The heads of other executive departments and agencies, as well as other senior officials, are invited to attend meetings of the NSC when appropriate.\nPrincipals Committee.\nThe Principals Committee of the National Security Council is the Cabinet-level senior interagency forum for consideration of national security policy issues. The Principals Committee is convened and chaired by the national security advisor. The regular attendees of the Principals Committee are the secretary of state, the secretary of the treasury, the secretary of defense, the attorney general, the secretary of energy, the secretary of homeland security, the White House chief of staff, the director of national intelligence, the chairman of the Joint Chiefs of Staff, the director of the Central Intelligence Agency, the homeland security advisor, and the United States ambassador to the United Nations.\nThe White House counsel, the deputy counsel to the president for national security affairs, the director of the Office of Management and Budget, the deputy national security advisor, the deputy national security advisor for strategy, the national security advisor to the vice president, and the NSC executive secretary may also attend all meetings of the Principals Committee. When considering international economic issues, the Principals Committee's regular attendees will include the secretary of commerce, the United States trade representative, and the assistant to the president for economic policy.\nDeputies Committee.\nThe National Security Council Deputies Committee is the senior sub-Cabinet interagency forum for consideration of national security policy issues. The Deputies Committee is also responsible for reviewing and monitoring the interagency national security process including for establishing and directing the Policy Coordination Committees. The Deputies Committee is convened and chaired by the deputy national security advisor or the deputy homeland security advisor.\nRegular members of the Deputies Committee are the deputy national security advisor for strategy, the deputy secretary of state, deputy secretary of the treasury, the deputy secretary of defense, the deputy attorney general, the deputy secretary of energy, the deputy secretary of homeland security, the deputy director of the Office of Management and Budget, the deputy director of national intelligence, the vice chairman of the Joint Chiefs of Staff, the national security advisor to the vice president, the administrator of the United States Agency for International Development, and the deputy director of the Central Intelligence Agency. Invitations to participate in or attend specific meetings are extended to deputy or under secretary level of executive departments and agencies and to other senior officials when relevant issues are discussed. The executive secretary and the deputy White House counsel also attend. The relevant senior director on the National Security Council staff is also invited to attend when relevant.\nPolicy Coordination Committees.\nThe Policy Coordination Committees of the National Security Council, established and directed by the Deputies Committee, are responsible for the management of the development and implementation of national security policies through interagency coordination. Policy Coordination Committees are the main day-to-day for interagency coordination of national security policy development, implementation and analysis in aide of the Deputies Committee and the Principals Committee. Policy Coordination Committees are chaired by senior directors on the National Security Council staff, or sometimes National Economic Council staff, with assistant secretary\u2013level officials from the relevant executive department or agency acting as co-chairs.\nDirectorate of Global Health Security and Biodefense.\nThe Directorate of Global Health Security and Biodefense was created by Barack Obama in 2016 in response to the 2014 Ebola outbreak. Its goal was \"to prepare for the next disease outbreak and prevent it from becoming an epidemic or pandemic.\" The directorate was disbanded when a May 2018 change in organizational structure by John Bolton, Trump's recently appointed head of the National Security Council, resulted in the effective elimination of the office then led by Rear Admiral Tim Ziemer, Sr. Director for Global Health Security and Biothreats. Remaining staff were moved to other NSC departments, prompting Ziemer's resignation, thus completing the elimination of the office.\nThe responsibilities that formerly belonged to the directorate, along with those of arms control and nonproliferation, and of weapons of mass destruction terrorism, were absorbed into a single new directorate, counterproliferation and biodefense, and assigned to Tim Morrison in July 2018 as director. Morrison characterized the consolidation as part of an overall NSC \"reduction of force\" and called it \"specious\" to say the office was \"dissolved\", describing the previous size of the organization as \"bloat\", and stating \"That is why Trump began streamlining the NSC staff in 2017.\" Trump defended the 2018 cuts, describing the financial motivation, when questioned in a February 2020 press conference, suggesting that people on a pandemic response team are unnecessary between pandemics, saying \"Some of the people we cut, they haven't been used for many, many years.\" No source of information could be found to support the president's statement, likely because the team was created in 2016 and disbanded in 2018. He continued: \"And rather than spending the money\u2014and I'm a business person\u2014I don't like having thousands of people around when you don't need them.\" The size of the team before cuts was estimated at 430 people, but the \"thousands\" referenced by the president also included reduction in the staff numbers of the CDC.\nIn January 2021, the directorate was reinstated by President Joe Biden, who appointed Elizabeth Cameron as Senior Director for Global Health Security and Biodefense, a position she had previously held under the Obama administration and briefly under the Trump administration.\nNew members.\nDuring his presidential transition, President-elect Joe Biden announced the creation of the position of U.S. Special Presidential Envoy for Climate, the occupant of which was to be a member of the National Security Council.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n\u00a0This article incorporates https:// from \n\u00a0This article incorporates public domain material from \n\u00a0This article incorporates public domain material from \n\u00a0This article incorporates public domain material from \nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\n\u00a0This article incorporates public domain material from "}
{"id": "44027", "revid": "50382244", "url": "https://en.wikipedia.org/wiki?curid=44027", "title": "Permutation", "text": "Mathematical version of an order change\n \nIn mathematics, a permutation of a set can mean one of two different things:\nAn example of the first meaning is the six permutations (orderings) of the set {1, 2, 3}: written as tuples, they are (1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), and (3, 2, 1). Anagrams of a word whose letters are all different are also permutations: the letters are already ordered in the original word, and the anagram reorders them. The study of permutations of finite sets is an important topic in combinatorics and group theory.\nPermutations are used in almost every branch of mathematics and in many other fields of science. In computer science, they are used for analyzing sorting algorithms; in quantum physics, for describing states of particles; and in biology, for describing RNA sequences.\nThe number of permutations of \"n\" distinct objects is \"n\"\u00a0factorial, usually written as \"n\"!, which means the product of all positive integers less than or equal to \"n\".\nAccording to the second meaning, a permutation of a set \"S\" is defined as a bijection from \"S\" to itself. That is, it is a function from \"S\" to \"S\" for which every element occurs exactly once as an image value. Such a function formula_1 is equivalent to the rearrangement of the elements of \"S\" in which each element \"i\" is replaced by the corresponding formula_2. For example, the permutation (3, 1, 2) corresponds to the function formula_3 defined as\nformula_4\nThe collection of all permutations of a set form a group called the symmetric group of the set. The group operation is the composition of functions (performing one rearrangement after the other), which results in another function (rearrangement).\nIn elementary combinatorics, the \"k\"-permutations, or partial permutations, are the ordered arrangements of \"k\" distinct elements selected from a set. When \"k\" is equal to the size of the set, these are the permutations in the previous sense.\nHistory.\nPermutation-like objects called hexagrams were used in China in the I Ching (Pinyin: Yi Jing) as early as 1000 BC.\nIn Greece, Plutarch wrote that Xenocrates of Chalcedon (396\u2013314 BC) discovered the number of different syllables possible in the Greek language. This would have been the first attempt on record to solve a difficult problem in permutations and combinations.\nAl-Khalil (717\u2013786), an Arab mathematician and cryptographer, wrote the \"Book of Cryptographic Messages\". It contains the first use of permutations and combinations, to list all possible Arabic words with and without vowels.\nThe rule to determine the number of permutations of \"n\" objects was known in Indian culture around 1150 AD. The \"Lilavati\" by the Indian mathematician Bh\u0101skara II contains a passage that translates as follows:\nThe product of multiplication of the arithmetical series beginning and increasing by unity and continued to the number of places, will be the variations of number with specific figures.\nIn 1677, Fabian Stedman described factorials when explaining the number of permutations of bells in change ringing. Starting from two bells: \"first, \"two\" must be admitted to be varied in two ways\", which he illustrates by showing 1 2 and 2 1. He then explains that with three bells there are \"three times two figures to be produced out of three\" which again is illustrated. His explanation involves \"cast away 3, and 1.2 will remain; cast away 2, and 1.3 will remain; cast away 1, and 2.3 will remain\". He then moves on to four bells and repeats the casting away argument showing that there will be four different sets of three. Effectively, this is a recursive process. He continues with five bells using the \"casting away\" method and tabulates the resulting 120 combinations. At this point he gives up and remarks:\nNow the nature of these methods is such, that the changes on one number comprehends the changes on all lesser numbers, ... insomuch that a compleat Peal of changes on one number seemeth to be formed by uniting of the compleat Peals on all lesser numbers into one entire body;\nStedman widens the consideration of permutations; he goes on to consider the number of permutations of the letters of the alphabet and of horses from a stable of 20.\nA first case in which seemingly unrelated mathematical questions were studied with the help of permutations occurred around 1770, when Joseph Louis Lagrange, in the study of polynomial equations, observed that properties of the permutations of the roots of an equation are related to the possibilities to solve it. This line of work ultimately resulted, through the work of \u00c9variste Galois, in Galois theory, which gives a complete description of what is possible and impossible with respect to solving polynomial equations (in one unknown) by radicals. In modern mathematics, there are many similar situations in which understanding a problem requires studying certain permutations related to it.\nThe study of permutations as substitutions on n elements led to the notion of group as algebraic structure, through the works of Cauchy (1815 memoir).\nPermutations played an important role in the cryptanalysis of the Enigma machine, a cipher device used by Nazi Germany during World War II. In particular, one important property of permutations, namely, that two permutations are conjugate exactly when they have the same cycle type, was used by cryptologist Marian Rejewski to break the German Enigma cipher in turn of years 1932-1933.\nDefinition.\nIn mathematics texts it is customary to denote permutations using lowercase Greek letters.\nA permutation can be defined as a bijection (an invertible mapping, a one-to-one and onto function) from a set \"S\" to itself: formula_5\nThe identity permutation is defined by formula_6 for all elements formula_7, and can be denoted by the number formula_8, by formula_9, or by a single 1-cycle (x).\nThe set of all permutations of a set with \"n\" elements forms the symmetric group formula_10, where the group operation is composition of functions. Thus for two permutations formula_3 and formula_12 in the group formula_10, their product formula_14 is defined by \nformula_15\nComposition is usually written without a dot or other sign. In general, composition of two permutations is not commutative; that is, typically the permutations formula_16 and formula_17 are not equal.\nAs a bijection from a set to itself, a permutation is a function that \"performs\" a rearrangement of a set, termed an \"active permutation\" or \"substitution\". An older viewpoint sees a permutation as an ordered arrangement or list of all the elements of \"S\", called a \"passive permutation\". According to this definition, all permutations in are passive. This meaning is subtly distinct from how passive (i.e. \"alias\") is used in Active and passive transformation and elsewhere, which would consider all permutations open to passive interpretation (regardless of whether they are in one-line notation, two-line notation, etc.).\nA permutation formula_3 can be decomposed into one or more disjoint \"cycles\" which are the orbits of the cyclic group formula_19 acting on the set \"S\". A cycle is found by repeatedly applying the permutation to an element: formula_20, where we assume formula_21 . A cycle consisting of \"k\" elements is called a \"k\"-cycle. (See below.)\nA fixed point of a permutation formula_3 is an element \"x\" which is taken to itself, that is formula_23, forming a 1-cycle formula_24. A permutation with no fixed points is called a derangement. A permutation exchanging two elements (a single 2-cycle) and leaving the others fixed is called a transposition.\nNotations.\n Several notations are widely used to represent permutations conveniently. The properties of permutations do not depend on the nature of the elements being permuted, only on their number, so one often considers the standard set formula_25. \"Cycle notation\" is a popular choice, as it is compact and shows the permutation's structure clearly. This article will use cycle notation unless otherwise specified.\nTwo-line notation.\nCauchy's \"two-line notation\" lists the elements of \"S\" in the first row, and the image of each element below it in the second row. For example, the permutation of \"S\" = {1, 2, 3, 4, 5, 6} given by the functionformula_26can be written as\n formula_27\nThe elements of \"S\" may appear in any order in the first row, so this permutation could also be written:\n formula_28\nOne-line notation.\nIf there is a \"natural\" order for the elements of \"S\", say formula_29, then one uses this for the first row of the two-line notation:\n formula_30\nUnder this assumption, one may omit the first row and write the permutation in \"one-line notation\" as\n formula_31,\nthat is, as an ordered arrangement of the elements of \"S\". Care must be taken to distinguish one-line notation from the cycle notation described below: a common usage is to omit parentheses or other enclosing marks for one-line notation, while using parentheses for cycle notation. The one-line notation is also called the \"word representation\".\nThe example above would then be:formula_32 (It is typical to use commas to separate these entries only if some have two or more digits.)\nThis compact form is common in elementary combinatorics and computer science. It is especially useful in applications where the permutations are to be compared as larger or smaller using lexicographic order.\nCycle notation.\nCycle notation describes the effect of repeatedly applying the permutation on the elements of the set \"S\", with an orbit being called a \"cycle\". The permutation is written as a list of cycles; since distinct cycles involve disjoint sets of elements, this is referred to as \"decomposition into disjoint cycles\".\nTo write down the permutation formula_3 in cycle notation, one proceeds as follows:\nAlso, it is common to omit 1-cycles, since these can be inferred: for any element \"x\" in \"S\" not appearing in any cycle, one implicitly assumes formula_40.\nFollowing the convention of omitting 1-cycles, one may interpret an individual cycle as a permutation which fixes all the elements not in the cycle (a cyclic permutation having only one cycle of length greater than 1). Then the list of disjoint cycles can be seen as the composition of these cyclic permutations. For example, the one-line permutation formula_41 can be written in cycle notation as:formula_42This may be seen as the composition formula_43 of cyclic permutations:formula_44 While permutations in general do not commute, disjoint cycles do; for example:formula_45Also, each cycle can be rewritten from a different starting point; for example,formula_46Thus one may write the disjoint cycles of a given permutation in many different ways.\nA convenient feature of cycle notation is that inverting the permutation is given by reversing the order of the elements in each cycle. For example, formula_47\nCanonical cycle notation.\nIn some combinatorial contexts it is useful to fix a certain order for the elements in the cycles and of the (disjoint) cycles themselves. Mikl\u00f3s B\u00f3na calls the following ordering choices the \"canonical cycle notation:\"\nFor example, formula_48 is a permutation of formula_49 in canonical cycle notation.\nRichard Stanley calls this the \"standard representation\" of a permutation, and Martin Aigner uses \"standard form\". Sergey Kitaev also uses the \"standard form\" terminology, but reverses both choices; that is, each cycle lists its minimal element first, and the cycles are sorted in decreasing order of their minimal elements.\nComposition of permutations.\nThere are two ways to denote the composition of two permutations. In the most common notation, formula_50 is the function that maps any element \"x\" to formula_51. The rightmost permutation is applied to the argument first,\nbecause the argument is written to the right of the function.\nA \"different\" rule for multiplying permutations comes from writing the argument to the left of the function, so that the leftmost permutation acts first.\nIn this notation, the permutation is often written as an exponent, so \"\u03c3\" acting on \"x\" is written \"x\"\"\u03c3\"; then the product is defined by formula_52. This article uses the first definition, where the rightmost permutation is applied first.\nThe function composition operation satisfies the axioms of a group. It is associative, meaning formula_53, and products of more than two permutations are usually written without parentheses. The composition operation also has an identity element (the identity permutation formula_54), and each permutation formula_3 has an inverse formula_56 (its inverse function) with formula_57.\nOther uses of the term \"permutation\".\nThe concept of a permutation as an ordered arrangement admits several generalizations that have been called \"permutations\", especially in older literature.\n\"k\"-permutations of \"n\".\nIn older literature and elementary textbooks, a k\"-permutation of \"n (sometimes called a partial permutation, sequence without repetition, variation, or arrangement) means an ordered arrangement (list) of a \"k\"-element subset of an \"n\"-set. The number of such \"k\"-permutations (\"k\"-arrangements) of formula_58 is denoted variously by such symbols as formula_59, formula_60, formula_61, formula_62, formula_63, or formula_64, computed by the formula:\n formula_65,\nwhich is 0 when \"k\" &gt; \"n\", and otherwise is equal to\n formula_66\nThe product is well defined without the assumption that formula_58 is a non-negative integer, and is of importance outside combinatorics as well; it is known as the Pochhammer symbol formula_68 or as the formula_69-th falling factorial power formula_70:formula_71This usage of the term \"permutation\" is closely associated with the term \"combination\" to mean a subset. A \"k-combination\" of a set \"S\" is a \"k-\"element subset of \"S\": the elements of a combination are not ordered. Ordering the \"k\"-combinations of \"S\" in all possible ways produces the \"k\"-permutations of \"S\". The number of \"k\"-combinations of an \"n\"-set, \"C\"(\"n\",\"k\"), is therefore related to the number of \"k\"-permutations of \"n\" by:\n formula_72\nThese numbers are also known as binomial coefficients, usually denoted formula_73:formula_74\nPermutations with repetition.\nOrdered arrangements of \"k\" elements of a set \"S\", where repetition is allowed, are called \"k\"-tuples. They have sometimes been referred to as permutations with repetition, although they are not permutations in the usual sense. They are also called words or strings over the alphabet \"S\". If the set \"S\" has \"n\" elements, the number of \"k\"-tuples over \"S\" is formula_75\nPermutations of multisets.\nIf \"M\" is a finite multiset, then a multiset permutation is an ordered arrangement of elements of \"M\" in which each element appears a number of times equal exactly to its multiplicity in \"M\". An anagram of a word having some repeated letters is an example of a multiset permutation. If the multiplicities of the elements of \"M\" (taken in some order) are formula_76, formula_77, ..., formula_78 and their sum (that is, the size of \"M\") is \"n\", then the number of multiset permutations of \"M\" is given by the multinomial coefficient,\nformula_79\nFor example, the number of distinct anagrams of the word MISSISSIPPI is:\nformula_80.\nA \"k\"-permutation of a multiset \"M\" is a sequence of \"k\" elements of \"M\" in which each element appears \"a number of times less than or equal to\" its multiplicity in \"M\" (an element's \"repetition number\").\nCircular permutations.\nPermutations, when considered as arrangements, are sometimes referred to as \"linearly ordered\" arrangements. If, however, the objects are arranged in a circular manner this distinguished ordering is weakened: there is no \"first element\" in the arrangement, as any element can be considered as the start. An arrangement of distinct objects in a circular manner is called a circular permutation. These can be formally defined as equivalence classes of ordinary permutations of these objects, for the equivalence relation generated by moving the final element of the linear arrangement to its front.\nTwo circular permutations are equivalent if one can be rotated into the other. The following four circular permutations on four letters are considered to be the same.\nThe circular arrangements are to be read counter-clockwise, so the following two are not equivalent since no rotation can bring one to the other.\nThere are (\"n\"\u2009\u2013\u20091)! circular permutations of a set with \"n\" elements.\nProperties.\nThe number of permutations of \"n\" distinct objects is \"n\"!.\nThe number of \"n\"-permutations with \"k\" disjoint cycles is the signless Stirling number of the first kind, denoted formula_81 or formula_82.\nCycle type.\nThe cycles (including the fixed points) of a permutation formula_3 of a set with n elements partition that set; so the lengths of these cycles form an integer partition of n, which is called the cycle type (or sometimes cycle structure or cycle shape) of formula_3. There is a \"1\" in the cycle type for every fixed point of formula_3, a \"2\" for every transposition, and so on. The cycle type of formula_86 is formula_87\nThis may also be written in a more compact form as [112231].\nMore precisely, the general form is formula_88, where formula_89 are the numbers of cycles of respective length. The number of permutations of a given cycle type is\n formula_90.\nThe number of cycle types of a set with n elements equals the value of the partition function formula_91.\nPolya's cycle index polynomial is a generating function which counts permutations by their cycle type.\nConjugating permutations.\nIn general, composing permutations written in cycle notation follows no easily described pattern \u2013 the cycles of the composition can be different from those being composed. However the cycle type is preserved in the special case of conjugating a permutation formula_3 by another permutation formula_93, which means forming the product formula_94. Here, formula_94 is the \"conjugate\" of formula_3 by formula_93 and its cycle notation can be obtained by taking the cycle notation for formula_3 and applying formula_93 to all the entries in it. It follows that two permutations are conjugate exactly when they have the same cycle type.\nOrder of a permutation.\nThe order of a permutation formula_3 is the smallest positive integer \"m\" so that formula_101. It is the least common multiple of the lengths of its cycles. For example, the order of formula_102 is formula_103.\nParity of a permutation.\nEvery permutation of a finite set can be expressed as the product of transpositions.\nAlthough many such expressions for a given permutation may exist, either they all contain an even number of transpositions or they all contain an odd number of transpositions. Thus all permutations can be classified as even or odd depending on this number.\nThis result can be extended so as to assign a \"sign\", written formula_104, to each permutation. formula_105 if formula_3 is even and formula_107 if formula_3 is odd. Then for two permutations formula_3 and formula_93\n formula_111\nIt follows that formula_112\nThe sign of a permutation is equal to the determinant of its permutation matrix (below).\nMatrix representation.\nA \"permutation matrix\" is an \"n\" \u00d7 \"n\" matrix that has exactly one entry 1 in each column and in each row, and all other entries are 0. There are several ways to assign a permutation matrix to a permutation of {1, 2, ..., \"n\"}. One natural approach is to define formula_113 to be the linear transformation of formula_114 which permutes the standard basis formula_115 by formula_116, and define formula_117 to be its matrix. That is, formula_117 has its \"j\"th column equal to the n \u00d7 1 column vector formula_119: its (\"i\", \"j\") entry is to 1 if \"i\" = \"\u03c3\"(\"j\"), and 0 otherwise. Since composition of linear mappings is described by matrix multiplication, it follows that this construction is compatible with composition of permutations:formula_120. For example, the one-line permutations formula_121 have product formula_122, and the corresponding matrices are:formula_123\nIt is also common in the literature to find the inverse convention, where a permutation \"\u03c3\" is associated to the matrix formula_124 whose (\"i\", \"j\") entry is 1 if \"j\" = \"\u03c3\"(\"i\") and is 0 otherwise. In this convention, permutation matrices multiply in the opposite order from permutations, that is, formula_125. In this correspondence, permutation matrices act on the right side of the standard formula_126 row vectors formula_127: formula_128.\nThe Cayley table on the right shows these matrices for permutations of 3 elements.\nPermutations of totally ordered sets.\nIn some applications, the elements of the set being permuted will be compared with each other. This requires that the set \"S\" has a total order so that any two elements can be compared. The set {1, 2, ..., \"n\"} with the usual \u2264 relation is the most frequently used set in these applications.\nA number of properties of a permutation are directly related to the total ordering of \"S,\" considering the permutation written in one-line notation as a sequence formula_129.\nAscents, descents, runs, exceedances, records.\nAn \"ascent\" of a permutation\u00a0\"\u03c3\" of \"n\" is any position \"i\"\u00a0&lt;\u00a0\"n\" where the following value is bigger than the current one. That is, \"i\" is an ascent if formula_130. For example, the permutation 3452167 has ascents (at positions) 1, 2, 5, and 6.\nSimilarly, a \"descent\" is a position \"i\"\u00a0&lt;\u00a0\"n\" with formula_131, so every \"i\" with formula_132 is either an ascent or a descent.\nAn \"ascending run\" of a permutation is a nonempty increasing contiguous subsequence that cannot be extended at either end; it corresponds to a maximal sequence of successive ascents (the latter may be empty: between two successive descents there is still an ascending run of length\u00a01). By contrast an \"increasing subsequence\" of a permutation is not necessarily contiguous: it is an increasing sequence obtained by omitting some of the values of the one-line notation.\nFor example, the permutation 2453167 has the ascending runs 245, 3, and 167, while it has an increasing subsequence 2367.\nIf a permutation has \"k\"\u00a0\u2212\u00a01 descents, then it must be the union of \"k\" ascending runs.\nThe number of permutations of \"n\" with \"k\" ascents is (by definition) the Eulerian number formula_133; this is also the number of permutations of \"n\" with \"k\" descents. Some authors however define the Eulerian number formula_133 as the number of permutations with \"k\" ascending runs, which corresponds to \"k\" \u2212 1 descents.\nAn exceedance of a permutation \"\u03c3\"1\"\u03c3\"2...\"\u03c3\"\"n\" is an index \"j\" such that \"\u03c3\"\"j\" &gt; \"j\". If the inequality is not strict (that is, \"\u03c3\"\"j\" \u2265 \"j\"), then \"j\" is called a \"weak exceedance\". The number of \"n\"-permutations with \"k\" exceedances coincides with the number of \"n\"-permutations with \"k\" descents.\nA \"record\" or \"left-to-right maximum\" of a permutation \"\u03c3\" is an element \"i\" such that \"\u03c3\"(\"j\") &lt; \"\u03c3\"(\"i\") for all \"j &lt; i\".\nFoata's transition lemma.\nFoata's \"fundamental bijection\" transforms a permutation \u03c3 with a given canonical cycle form into the permutation formula_135 whose one-line notation has the same sequence of elements with parentheses removed. For example:\nformula_136\nformula_137\nHere the first element in each canonical cycle of \u03c3 becomes a record (left-to-right maximum) of formula_138. Given formula_138, one may find its records and insert parentheses to construct the inverse transformation formula_140. Underlining the records in the above example: formula_141, which allows the reconstruction of the cycles of \u03c3.\nThe following table shows formula_142 and \u03c3 for the six permutations of \"S\" = {1, 2, 3}, with the bold text on each side showing the notation used in the bijection: one-line notation for formula_142 and canonical cycle notation for \u03c3.\nformula_144\nAs a first corollary, the number of \"n\"-permutations with exactly \"k\" records is equal to the number of \"n\"-permutations with exactly \"k\" cycles: this last number is the signless Stirling number of the first kind, formula_145. Furthermore, Foata's mapping takes an \"n\"-permutation with \"k\" weak exceedances to an \"n\"-permutation with \"k\" \u2212 1 ascents. For example, (2)(31) = 321 has \"k =\" 2 weak exceedances (at index 1 and 2), whereas \"f\"(321) \n 231 has \"k\" \u2212 1 = 1 ascent (at index 1; that is, from 2 to 3).\nInversions.\nAn \"inversion\" of a permutation\u00a0\"\u03c3\" is a pair (\"i\", \"j\") of positions where the entries of a permutation are in the opposite order: formula_146 and formula_147. Thus a descent is an inversion at two adjacent positions. For example, \"\u03c3\" \n 23154 has (\"i\", \"j\") = (1, 3), (2, 3), and (4, 5), where (\"\u03c3\"(\"i\"), \"\u03c3\"(\"j\")) = (2, 1), (3, 1), and (5, 4).\nSometimes an inversion is defined as the pair of values (\"\u03c3\"(\"i\"), \"\u03c3\"(\"j\")); this makes no difference for the \"number\" of inversions, and the reverse pair (\"\u03c3\"(\"j\"), \"\u03c3\"(\"i\")) is an inversion in the above sense for the inverse permutation \"\u03c3\"\u22121.\nThe number of inversions is an important measure for the degree to which the entries of a permutation are out of order; it is the same for \"\u03c3\" and for \"\u03c3\"\u22121. To bring a permutation with \"k\" inversions into order (that is, transform it into the identity permutation), by successively applying (right-multiplication by) adjacent transpositions, is always possible and requires a sequence of \"k\" such operations. Moreover, any reasonable choice for the adjacent transpositions will work: it suffices to choose at each step a transposition of \"i\" and \"i\" + 1 where \"i\" is a descent of the permutation as modified so far (so that the transposition will remove this particular descent, although it might create other descents). This is so because applying such a transposition reduces the number of inversions by\u00a01; as long as this number is not zero, the permutation is not the identity, so it has at least one descent. Bubble sort and insertion sort can be interpreted as particular instances of this procedure to put a sequence into order. Incidentally this procedure proves that any permutation \"\u03c3\" can be written as a product of adjacent transpositions; for this one may simply reverse any sequence of such transpositions that transforms \"\u03c3\" into the identity. In fact, by enumerating all sequences of adjacent transpositions that would transform \"\u03c3\" into the identity, one obtains (after reversal) a \"complete\" list of all expressions of minimal length writing \"\u03c3\" as a product of adjacent transpositions.\nThe number of permutations of \"n\" with \"k\" inversions is expressed by a Mahonian number. This is the coefficient of formula_148 in the expansion of the product\nformula_149\nThe notation formula_150 denotes the q-factorial. This expansion commonly appears in the study of necklaces.\nLet formula_151 such that formula_152 and formula_153.\nIn this case, say the weight of the inversion formula_154 is formula_155.\nKobayashi (2011) proved the enumeration formula \nformula_156\nwhere formula_157 denotes Bruhat order in the symmetric groups. This graded partial order often appears in the context of Coxeter groups.\nPermutations in computing.\nNumbering permutations.\nOne way to represent permutations of \"n\" things is by an integer \"N\" with 0\u00a0\u2264\u00a0\"N\"\u00a0&lt;\u00a0\"n\"!, provided convenient methods are given to convert between the number and the representation of a permutation as an ordered arrangement (sequence). This gives the most compact representation of arbitrary permutations, and in computing is particularly attractive when \"n\" is small enough that \"N\" can be held in a machine word; for 32-bit words this means \"n\"\u00a0\u2264\u00a012, and for 64-bit words this means \"n\"\u00a0\u2264\u00a020. The conversion can be done via the intermediate form of a sequence of numbers \"d\"\"n\", \"d\"\"n\"\u22121, ..., \"d\"2, \"d\"1, where \"d\"\"i\" is a non-negative integer less than \"i\" (one may omit \"d\"1, as it is always 0, but its presence makes the subsequent conversion to a permutation easier to describe). The first step then is to simply express \"N\" in the \"factorial number system\", which is just a particular mixed radix representation, where, for numbers less than \"n\"!, the bases (place values or multiplication factors) for successive digits are (\"n\" \u2212 1)!, (\"n\" \u2212 2)!, ..., 2!, 1!. The second step interprets this sequence as a Lehmer code or (almost equivalently) as an inversion table.\nIn the Lehmer code for a permutation\u00a0\"\u03c3\", the number \"d\"\"n\" represents the choice made for the first term\u00a0\"\u03c3\"1, the number \"d\"\"n\"\u22121 represents the choice made for the second term\n\"\u03c3\"2 among the remaining \"n\" \u2212 1 elements of the set, and so forth. More precisely, each \"d\"\"n\"+1\u2212\"i\" gives the number of \"remaining\" elements strictly less than the term \"\u03c3\"\"i\". Since those remaining elements are bound to turn up as some later term \"\u03c3\"\"j\", the digit \"d\"\"n\"+1\u2212\"i\" counts the \"inversions\" (\"i\",\"j\") involving \"i\" as smaller index (the number of values \"j\" for which \"i\"\u00a0&lt;\u00a0\"j\" and \"\u03c3\"\"i\"\u00a0&gt;\u00a0\"\u03c3\"\"j\"). The inversion table for\u00a0\"\u03c3\" is quite similar, but here \"d\"\"n\"+1\u2212\"k\" counts the number of inversions (\"i\",\"j\") where \"k\"\u00a0=\u00a0\"\u03c3\"\"j\" occurs as the smaller of the two values appearing in inverted order.\nBoth encodings can be visualized by an \"n\"\u00a0by\u00a0\"n\" Rothe diagram (named after Heinrich August Rothe) in which dots at (\"i\",\"\u03c3\"\"i\") mark the entries of the permutation, and a cross at (\"i\",\"\u03c3\"\"j\") marks the inversion (\"i\",\"j\"); by the definition of inversions a cross appears in any square that comes both before the dot (\"j\",\"\u03c3\"\"j\") in its column, and before the dot (\"i\",\"\u03c3\"\"i\") in its row. The Lehmer code lists the numbers of crosses in successive rows, while the inversion table lists the numbers of crosses in successive columns; it is just the Lehmer code for the inverse permutation, and vice versa.\nTo effectively convert a Lehmer code \"d\"\"n\", \"d\"\"n\"\u22121, ..., \"d\"2, \"d\"1 into a permutation of an ordered set \"S\", one can start with a list of the elements of \"S\" in increasing order, and for \"i\" increasing from 1 to \"n\" set \"\u03c3\"\"i\" to the element in the list that is preceded by \"d\"\"n\"+1\u2212\"i\" other ones, and remove that element from the list. To convert an inversion table \"d\"\"n\", \"d\"\"n\"\u22121, ..., \"d\"2, \"d\"1 into the corresponding permutation, one can traverse the numbers from \"d\"1 to \"d\"\"n\" while inserting the elements of \"S\" from largest to smallest into an initially empty sequence; at the step using the number \"d\" from the inversion table, the element from \"S\" inserted into the sequence at the point where it is preceded by \"d\" elements already present. Alternatively one could process the numbers from the inversion table and the elements of \"S\" both in the opposite order, starting with a row of \"n\" empty slots, and at each step place the element from \"S\" into the empty slot that is preceded by \"d\" other empty slots.\nConverting successive natural numbers to the factorial number system produces those sequences in lexicographic order (as is the case with any mixed radix number system), and further converting them to permutations preserves the lexicographic ordering, provided the Lehmer code interpretation is used (using inversion tables, one gets a different ordering, where one starts by comparing permutations by the \"place\" of their entries 1 rather than by the value of their first entries). The sum of the numbers in the factorial number system representation gives the number of inversions of the permutation, and the parity of that sum gives the signature of the permutation. Moreover, the positions of the zeroes in the inversion table give the values of left-to-right maxima of the permutation (in the example 6, 8, 9) while the positions of the zeroes in the Lehmer code are the positions of the right-to-left minima (in the example positions the 4, 8, 9 of the values 1, 2, 5); this allows computing the distribution of such extrema among all permutations. A permutation with Lehmer code \"d\"\"n\", \"d\"\"n\"\u22121, ..., \"d\"2, \"d\"1 has an ascent \"n\" \u2212 \"i\" if and only if \"d\"\"i\" \u2265 \"d\"\"i\"+1.\nAlgorithms to generate permutations.\nIn computing it may be required to generate permutations of a given sequence of values. The methods best adapted to do this depend on whether one wants some randomly chosen permutations, or all permutations, and in the latter case if a specific ordering is required. Another question is whether possible equality among entries in the given sequence is to be taken into account; if so, one should only generate distinct multiset permutations of the sequence.\nAn obvious way to generate permutations of \"n\" is to generate values for the Lehmer code (possibly using the factorial number system representation of integers up to \"n\"!), and convert those into the corresponding permutations. However, the latter step, while straightforward, is hard to implement efficiently, because it requires \"n\" operations each of selection from a sequence and deletion from it, at an arbitrary position; of the obvious representations of the sequence as an array or a linked list, both require (for different reasons) about \"n\"2/4 operations to perform the conversion. With \"n\" likely to be rather small (especially if generation of all permutations is needed) that is not too much of a problem, but it turns out that both for random and for systematic generation there are simple alternatives that do considerably better. For this reason it does not seem useful, although certainly possible, to employ a special data structure that would allow performing the conversion from Lehmer code to permutation in \"O\"(\"n\" log \"n\") time.\nRandom generation of permutations.\nFor generating random permutations of a given sequence of \"n\" values, it makes no difference whether one applies a randomly selected permutation of \"n\" to the sequence, or chooses a random element from the set of distinct (multiset) permutations of the sequence. This is because, even though in case of repeated values there can be many distinct permutations of \"n\" that result in the same permuted sequence, the number of such permutations is the same for each possible result. Unlike for systematic generation, which becomes unfeasible for large \"n\" due to the growth of the number \"n\"!, there is no reason to assume that \"n\" will be small for random generation.\nThe basic idea to generate a random permutation is to generate at random one of the \"n\"! sequences of integers \"d\"1,\"d\"2...,\"d\"\"n\" satisfying 0 \u2264 \"d\"\"i\" &lt; \"i\" (since \"d\"1 is always zero it may be omitted) and to convert it to a permutation through a bijective correspondence. For the latter correspondence one could interpret the (reverse) sequence as a Lehmer code, and this gives a generation method first published in 1938 by Ronald Fisher and Frank Yates.\nWhile at the time computer implementation was not an issue, this method suffers from the difficulty sketched above to convert from Lehmer code to permutation efficiently. This can be remedied by using a different bijective correspondence: after using \"d\"\"i\" to select an element among \"i\" remaining elements of the sequence (for decreasing values of \"i\"), rather than removing the element and compacting the sequence by shifting down further elements one place, one swaps the element with the final remaining element. Thus the elements remaining for selection form a consecutive range at each point in time, even though they may not occur in the same order as they did in the original sequence. The mapping from sequence of integers to permutations is somewhat complicated, but it can be seen to produce each permutation in exactly one way, by an immediate induction. When the selected element happens to be the final remaining element, the swap operation can be omitted. This does not occur sufficiently often to warrant testing for the condition, but the final element must be included among the candidates of the selection, to guarantee that all permutations can be generated.\nThe resulting algorithm for generating a random permutation of codice_1 can be described as follows in pseudocode:\n for \"i\" from \"n\" downto 2 do\n swap \"a\"[\"di\"] and \"a\"[\"i\" \u2212 1]\nThis can be combined with the initialization of the array codice_2 as follows\n for \"i\" from 0 to \"n\"\u22121 do\n \"a\"[\"i\"] \u2190 \"a\"[\"d\"\"i\"+1]\n \"a\"[\"d\"\"i\"+1] \u2190 \"i\"\nIf \"d\"\"i\"+1 = \"i\", the first assignment will copy an uninitialized value, but the second will overwrite it with the correct value \"i\".\nHowever, Fisher-Yates is not the fastest algorithm for generating a permutation, because Fisher-Yates is essentially a sequential algorithm and \"divide and conquer\" procedures can achieve the same result in parallel.\nGeneration in lexicographic order.\nThere are many ways to systematically generate all permutations of a given sequence.\nOne classic, simple, and flexible algorithm is based upon finding the next permutation in lexicographic ordering, if it exists. It can handle repeated values, for which case it generates each distinct multiset permutation once. Even for ordinary permutations it is significantly more efficient than generating values for the Lehmer code in lexicographic order (possibly using the factorial number system) and converting those to permutations. It begins by sorting the sequence in (weakly) increasing order (which gives its lexicographically minimal permutation), and then repeats advancing to the next permutation as long as one is found. The method goes back to Narayana Pandita in 14th century India, and has been rediscovered frequently.\nThe following algorithm generates the next permutation lexicographically after a given permutation. It changes the given permutation in-place.\nFor example, given the sequence [1, 2, 3, 4] (which is in increasing order), and given that the index is zero-based, the steps are as follows:\nFollowing this algorithm, the next lexicographic permutation will be [1, 3, 2, 4], and the 24th permutation will be [4, 3, 2, 1] at which point \"a\"[\"k\"] &lt; \"a\"[\"k\" + 1] does not exist, indicating that this is the last permutation.\nThis method uses about 3 comparisons and 1.5 swaps per permutation, amortized over the whole sequence, not counting the initial sort.\nGeneration with minimal changes.\nAn alternative to the above algorithm, the Steinhaus\u2013Johnson\u2013Trotter algorithm, generates an ordering on all the permutations of a given sequence with the property that any two consecutive permutations in its output differ by swapping two adjacent values. This ordering on the permutations was known to 17th-century English bell ringers, among whom it was known as \"plain changes\". One advantage of this method is that the small amount of change from one permutation to the next allows the method to be implemented in constant time per permutation. The same can also easily generate the subset of even permutations, again in constant time per permutation, by skipping every other output permutation.\nAn alternative to Steinhaus\u2013Johnson\u2013Trotter is Heap's algorithm, said by Robert Sedgewick in 1977 to be the fastest algorithm of generating permutations in applications.\nThe following figure shows the output of all three aforementioned algorithms for generating all permutations of length formula_158, and of six additional algorithms described in the literature.\nGeneration of permutations in nested swap steps.\nExplicit sequence of swaps (transpositions, 2-cycles formula_160), is described here, each swap applied (on the left) to the previous chain providing a new permutation, such that all the permutations can be retrieved, each only once. This counting/generating procedure has an additional structure (call it nested), as it is given in steps: after completely retrieving formula_161, continue retrieving formula_162 by cosets formula_163 of formula_161 in formula_165, by appropriately choosing the coset representatives formula_166 to be described below. Since each formula_167 is sequentially generated, there is a \"last element\" formula_168. So, after generating formula_161 by swaps, the next permutation in formula_162 has to be formula_171 for some formula_172. Then all swaps that generated formula_161 are repeated, generating the whole coset formula_174, reaching the last permutation in that coset formula_175; the next swap has to move the permutation to representative of another coset formula_176. \nContinuing the same way, one gets coset representatives formula_177 for the cosets of formula_161 in formula_165; the ordered set formula_180 (formula_181) is called the set of coset beginnings. Two of these representatives are in the same coset if and only if formula_182, that is, formula_183. Concluding, permutations formula_184 are all representatives of distinct cosets if and only if for any formula_185, formula_186 (no repeat condition). In particular, for all generated permutations to be distinct it is not necessary for the formula_187 values to be distinct. In the process, one gets that formula_188 and this provides the recursion procedure. \nEXAMPLES: obviously, for formula_189 one has formula_190; to build formula_191 there are only two possibilities for the coset beginnings satisfying the no repeat condition; the choice formula_192 leads to formula_193. To continue generating formula_194 one needs appropriate coset beginnings (satisfying the no repeat condition): there is a convenient choice: formula_195, leading to formula_196. Then, to build formula_197 a convenient choice for the coset beginnings (satisfying the no repeat condition) is formula_198, leading to formula_199. \nFrom examples above one can inductively go to higher formula_69 in a similar way, choosing coset beginnings of formula_201 in formula_202, as follows: for formula_69 even choosing all coset beginnings equal to 1 and for formula_69 odd choosing coset beginnings equal to formula_205. With such choices the \"last\" permutation is formula_206 for formula_69 odd and formula_208 for formula_69 even (formula_210). Using these explicit formulae one can easily compute the permutation of certain index in the counting/generation steps with minimum computation. For this, writing the index in factorial base is useful. For example, the permutation for index formula_211 is: formula_212 formula_213formula_214, yelding finally, formula_215.\nBecause multiplying by swap permutation takes short computing time and every new generated permutation requires only one such swap multiplication, this generation procedure is quite efficient. Moreover as there is a simple formula, having the last permutation in each formula_165 can save even more time to go directly to a permutation with certain index in fewer steps than expected as it can be done in blocks of subgroups rather than swap by swap.\nApplications.\nPermutations are used in the interleaver component of the error detection and correction algorithms, such as turbo codes, for example 3GPP Long Term Evolution mobile telecommunication standard uses these ideas (see 3GPP technical specification 36.212).\nSuch applications raise the question of fast generation of permutations satisfying certain desirable properties. One of the methods is based on the permutation polynomials. Also as a base for optimal hashing in Unique Permutation Hashing.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44028", "revid": "51030968", "url": "https://en.wikipedia.org/wiki?curid=44028", "title": "National Security Advisor (United States)", "text": "White House advisory position\nThe Assistant to the President for National Security Affairs (APNSA), commonly referred to as the National Security Advisor (NSA), is a senior aide in the Executive Office of the President, based at the West Wing of the White House.\nThe national security advisor serves as the principal advisor to the president of the United States on all national security issues. The national security advisor participates in meetings of the National Security Council (NSC) and usually chairs meetings of the principals committee of the NSC with the secretary of state and secretary of defense (those meetings not attended by the president). The NSA also sits on the Homeland Security Council (HSC). The national security advisor is supported by NSC staff who produce classified research and briefings for the national security advisor to review and present, either to the NSC or the president.\nThe national security advisor is appointed by the president and does not require confirmation by the United States Senate. An appointment of a three- or four-star general to the role requires Senate confirmation to maintain that rank in the new position. The acting National Security Advisor has been Marco Rubio since May 1, 2025. \nRole.\nThe influence and role of the national security advisor varies from administration to administration and depends not only on the qualities of the person appointed to the position, but also on the style and management philosophy of the incumbent president. ideally, the national security advisor serves as an honest broker of policy options for the president in the field of national security, rather than as an advocate for his or her own policy agenda.\nThe national security advisor is a staff position in the Executive Office of the President and does not have line or budget authority over either the Department of State or the Department of Defense, unlike the secretary of state and the secretary of defense, who are Senate-confirmed officials with statutory authority over their departments. The national security advisor is able to offer daily advice (due to the proximity) to the president independently of the vested interests of the large bureaucracies and clientele of those departments.\nIn times of crisis, the national security advisor is likely to operate from the White House Situation Room or the Presidential Emergency Operations Center (as on September 11, 2001), updating the president on the latest events in a crisis situation.\nHistory.\nThe National Security Council was created at the start of the Cold War under the National Security Act of 1947 to coordinate defense, foreign affairs, international economic policy, and intelligence; this was part of a large reorganization that saw the creation of the Department of Defense and the Central Intelligence Agency. The Act did not create the position of the national security advisor per se, but it did create an executive secretary in charge of the staff. In 1949, the NSC became part of the Executive Office of the President.\nRobert Cutler was the first national security advisor in 1953, and held the job twice, both times during the Eisenhower administration. The system has remained largely unchanged since then, particularly since President John Kennedy, with powerful national security advisors and strong staff but a lower importance given to formal NSC meetings. This continuity persists despite the tendency of each new president to replace the advisor and senior NSC staff.\nPresident Richard Nixon's national security advisor, Henry Kissinger, enhanced the importance of the role, controlling the flow of information to the president and meeting with him multiple times per day. Kissinger also holds the distinction of serving as national security advisor and secretary of state at the same time from September 22, 1973, until November 3, 1975. He holds the record for longest term of service (2,478 days); Michael Flynn holds the record for shortest term, at just 24 days.\nBrent Scowcroft held the job in two non-consecutive administrations: the Ford administration and the George H. W. Bush administration.\nList.\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Democratic\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Republican\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Independent\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44029", "revid": "19404073", "url": "https://en.wikipedia.org/wiki?curid=44029", "title": "Executive Office of the President of the United States", "text": "U.S. government executive agency\nThe Executive Office of the President of the United States (EOP) comprises the offices and agencies that support the work of the president at the center of the executive branch of the United States federal government. The office consists of several offices and agencies, such as the White House Office (the staff working closest with the president, including West Wing staff), the National Security Council, Homeland Security Council, Office of Management and Budget, Council of Economic Advisers, and others. The Eisenhower Executive Office Building houses most staff.\nThe office is also referred to as a \"permanent government\", since many policy programs, and the people who are charged with implementing them, continue between presidential administrations.\nThe civil servants who work in the Executive Office of the President are regarded as nonpartisan and politically neutral, so they are capable of providing objective and impartial advice.\nWith the increase in technological and global advancement, the size of the White House staff has increased to include an array of policy experts responsible with managing various federal governmental functions and policy areas. As of 2015, it included approximately 1,800 positions, most of which did not require confirmation from the U.S. Senate.\nThe office is overseen by the White House chief of staff. Since January 20, 2025, that position has been held by Susie Wiles, who was appointed by President Donald Trump. She is the first woman to hold the title.\nHistory.\nIn 1937, the Brownlow Committee, which was a presidentially commissioned panel of political science and public administration experts, recommended sweeping changes to the executive branch of the U.S. federal government, including the creation of the Executive Office of the President. Based on these recommendations, President Franklin D. Roosevelt in 1939 lobbied Congress to approve the Reorganization Act of 1939. The Act led to Reorganization Plan No. 1, which created the office, which reported directly to the president.\nThe office encompassed two subunits at its outset, the White House Office (WHO) and the Bureau of the Budget, the predecessor to today's Office of Management and Budget, which was created in 1921 and originally located in the Treasury Department. It absorbed most of the functions of the National Emergency Council. Initially, the new staff system appeared more ambitious on paper than in practice; the increase in the size of the staff was quite modest at the start. However, it laid the groundwork for the large and organizationally complex White House staff that emerged during the presidencies of Roosevelt's successors.\nRoosevelt's efforts are also notable in contrast to those of his predecessors in office. During the 19th century, presidents had few staff resources. Thomas Jefferson had one messenger and one secretary at his disposal, both of whose salaries were paid by the president personally. It was not until 1857 that Congress appropriated money ($2,500) for the hiring of one clerk.\nBy Ulysses S. Grant's presidency (1869\u20131877), the staff had grown to three. By 1900, the White House staff included one \"secretary to the president\" (then the title of the president's chief aide), two assistant secretaries, two executive clerks, a stenographer, and seven other office personnel. Under Warren G. Harding, there were thirty-one staff, although most were in clerical positions.\nDuring Herbert Hoover's presidency, two additional secretaries to the president were added by Congress, one of whom Hoover designated as his press secretary. From 1933 to 1939, as he greatly expanded the scope of the federal government's policies and powers in response to the Great Depression, Roosevelt relied on his \"brain trust\" of top advisers, who were often appointed to vacant positions in agencies and departments, from which they drew their salaries since the White House lacked statutory or budgetary authority to create new staff positions.\nAfter World War II, in particular, during the Eisenhower presidency, the staff was expanded and reorganized. Eisenhower, a former U.S. Army general, had been Supreme Allied Commander during the war and reorganized the Executive Office to suit his leadership style.\nAs of 2009, the staff is much bigger. Estimates indicate some 3,000 to 4,000 persons serve in office staff positions with policy-making responsibilities, with a budget of $300 to $400 million (George W. Bush's budget request for Fiscal Year 2005 was for $341 million in support of 1,850 personnel).\nSome observers have noted a problem of control for the president due to the increase in staff and departments, making coordination and cooperation between the various departments of the Executive Office more difficult.\nOrganization.\nThe president had the power to reorganize the Executive Office due to the 1949 Reorganization Act which gave the president considerable discretion, until 1983 when it was renewed due to President Reagan's administration allegedly encountering \"disloyalty and obstruction\".\nThe chief of staff is the head of the Executive Office and can therefore ultimately decide what the president needs to deal with personally and what can be dealt with by other staff.\nSenior staff within the Executive Office of the President have the title Assistant to the President, second-level staff have the title Deputy Assistant to the President, and third-level staff have the title Special Assistant to the President.\nThe core White House staff appointments, and most Executive Office officials generally, are not required to be confirmed by the U.S. Senate, although there are a handful of exceptions (e.g., the director of the Office of Management and Budget, the chair of the Council of Economic Advisers, and the United States Trade Representative).\nThe information in the following table is current as of January 20, 2025. Only principal executives are listed; for subordinate officers, see individual office pages.\nWhite House offices.\nThe White House Office (including its various offices listed below) is a sub-unit of the Executive Office of the President (office). The various agencies of the office are listed above.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCongress.\nCongress as well as the president has some control over the Executive Office of the President. Some of this authority stems from its appropriation powers given by the Constitution, such as the \"power of the purse\", which affects the Office of Management and Budget and the funding of the rest of federal departments and agencies. Congress also has the right to investigate the operation of the Executive Office, normally holding hearings bringing forward individual personnel to testify before a congressional committee.\nThe Executive Office often helps with legislation by filling in specific points understood and written by experts, as Congressional legislation sometimes starts in broad terms.\nBudget history.\nThis table specifies the budget of the Executive Office for the years 2008\u20132017, and the actual outlays for the years 1993\u20132007.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44030", "revid": "23520465", "url": "https://en.wikipedia.org/wiki?curid=44030", "title": "Office of Management and Budget", "text": "Office in the Executive Office of the US President\nThe Office of Management and Budget (OMB) is the largest office within the Executive Office of the President of the United States and is responsible for implementing the president's agenda across the executive branch.\nIn 1921, Congress passed legislation to create the Bureau of the Budget to assist the president in developing his budget to be enacted or rejected by the House of Representatives under Article One of the Constitution. In 1970, President Richard Nixon led the reorganization of the bureau into its current form as the OMB reporting directly to the president.\nOriginally intended to be a politically neutral and analytical organization, the 1970 restructuring transformed the OMB from a simple budget office to one of the most powerful institutions directly under the president's control. Successive presidents have expanded the scope of duties and power of the OMB, with occasional but limited pushback from Congress. Most notably, Congress enacted legislation in 1974 to form a congressional counterpart to the OMB, the Congressional Budget Office along with other laws including to limit presidential impoundment.\nRussell Vought is the current director of the OMB since he was appointed by Donald Trump in February 2025.\nHistory.\nThe Bureau of the Budget, OMB's predecessor, was established in 1921 as a part of the Department of the Treasury by the Budget and Accounting Act of 1921, which President Warren G. Harding signed into law. The Bureau of the Budget was moved to the Executive Office of the President in 1939 and was run by Harold D. Smith during the government's rapid expansion of spending during World War II. James L. Sundquist, a staffer at the Bureau of the Budget, called the relationship between the president and the bureau extremely close and subsequent bureau directors have been politicians, not public administrators.\nThe bureau was reorganized into the Office of Management and Budget in 1970 during the Nixon administration. The first OMB included Roy Ash (head), Paul O'Neill (assistant director), Fred Malek (deputy director), Frank Zarb (associate director) and two dozen others.\nIn the 1990s, OMB was reorganized to remove the distinction between management staff and budgetary staff by combining the dual roles into each given program examiner within the Resource Management Offices.\nPurpose.\nOMB prepares the president's budget proposal to Congress and supervises the administration of the executive branch agencies. It evaluates the effectiveness of agency programs, policies, and procedures, assesses competing funding demands among agencies, and sets funding priorities. OMB ensures that agency reports, rules, testimony, and proposed legislation are consistent with the president's budget and administration policies.\nOMB also oversees and coordinates the administration's procurement, financial management, information, and regulatory policies. In each of these areas, OMB's role is to help improve administrative management, develop better performance measures and coordinating mechanisms, and reduce unnecessary burdens on the public.\nOMB's critical missions are:\nStructure.\nOverview.\nOMB is made up mainly of career appointed staff who provide continuity across changes of party and administration in the White House. Six positions within OMB\u00a0\u2013 the director, the deputy director, the deputy director for management, and the administrators of the Office of Information and Regulatory Affairs, the Office of Federal Procurement Policy, and the Office of Federal Financial Management\u00a0\u2013 are presidentially appointed and Senate-confirmed positions.\nOMB's largest components are the five Resource Management Offices, which are organized along functional lines mirroring the federal government, each led by an OMB associate director. Approximately half of all OMB staff are assigned to these offices, the majority of whom are designated as program examiners. Program examiners can be assigned to monitor one or more federal agencies or may be deployed by a topical area, such as monitoring issues relating to U.S. Navy warships. These staff have dual responsibility for both management and budgetary issues, as well as for giving expert advice on all aspects relating to their programs. Each year they review federal agency budget requests and help decide what resource requests will be sent to Congress as part of the president's budget. They perform in-depth program evaluations with the Program Assessment Rating Tool, review proposed regulations and agency testimony, analyze pending legislation, and oversee the aspects of the president's management agenda including agency management scorecards. They are often called upon to provide analysis information to EOP staff. They also provide important information to those assigned to the statutory offices within OMB: the Office of Information and Regulatory Affairs, the Office of Federal Procurement Policy, the Office of Federal Financial Management, and the Office of E-Government &amp; Information Technology, which specializes in issues such as federal regulations and procurement policy and law.\nOther components are OMB-wide support offices, including the Office of General Counsel, the Office of Legislative Affairs, the Budget Review Division (BRD), and the Legislative Reference Division. The BRD performs government-wide budget coordination and is largely responsible for the technical aspects relating to the release of the president's budget each February. With respect to the estimation of spending for the executive branch, the BRD serves a purpose parallel to that of the Congressional Budget Office (which was created in response to the OMB) for estimating Congressional spending, the Department of the Treasury for estimating executive branch revenue, and the Joint Committee on Taxation for estimating Congressional revenue.\nThe Legislative Reference Division is the federal government's central clearing house for proposed legislation or testimony by federal officials. It distributes proposed legislation and testimony to all relevant federal reviewers and distills the comments into a consensus opinion of the administration about the proposal. It is also responsible for writing an Enrolled Bill Memorandum to the president once a bill is presented by both chambers of Congress for the president's signature. The Enrolled Bill Memorandum details the bill's particulars, opinions on the bill from relevant federal departments, and an overall opinion about whether it should be signed into law or vetoed. It also issues Statements of Administration Policy that let Congress know the White House's official position on proposed legislation.\nRole in the executive budget process.\nIn practice, the president has assigned the OMB certain responsibilities when it comes to the budget and hiring authorities who play key roles in developing it. OMB coordinates the development of the president's budget proposal by issuing circulars, memoranda, and guidance documents to the heads of executive agencies. The OMB works very closely with executive agencies in making sure the budget process and proposal is smooth.\nThe development of the budget within the executive branch has many steps and takes nearly a year to complete. The first step is the OMB informing the president of the country's economic situation. The next step is known as the Spring Guidance: the OMB gives executive agencies instructions on policy guidance to use when coming up with their budget requests along with due dates for them to submit their requests. The OMB then works with the agencies to discuss issues in the upcoming budget. In July, the OMB issues circular A-11 to all agencies, which outlines instructions for submitting the budget proposals, which the agencies submit by September. The fiscal year begins October1 and OMB staff meet with senior agency representatives to find out whether their proposals are in line with the president's priorities and policies and identify constraints within the budget proposal until late November. The OMB director then meets with the president and EOP advisors to discuss the agencies' budget proposals and recommends a federal budget proposal, and the agencies are notified of the decisions about their requests. They can appeal to OMB and the president in December if they are dissatisfied with the decisions. After working together to resolve issues, agencies and OMB prepare a budget justification document to present to relevant congressional committees, especially the Appropriations Committee. Finally, by the first Monday in February, the president must review and submit the final budget to Congress to approve.\nOMB is also responsible for the preparation of Statements of Administrative Policy (SAPs) with the president. These statements allow the OMB to communicate the president's and agencies' policies to the government as a whole and set forth policymakers' agendas. During the review of the federal budget, interest groups can lobby for policy change and affect the budget for the new year. OMB plays a key role in policy conflicts by making sure legislation and agencies' actions are consistent with the executive branch's. OMB has a powerful and influential role in the government, basically making sure its day-to-day operations run. Without a budget, federal employees could not be paid, federal buildings could not open and federal programs would come to a halt in a government shutdown. Shutdowns can occur when Congress refuses to pass a budget.\nSuspension and debarment.\nThe Interagency Suspension and Debarment Committee (ISDC) was created as an OMB committee by President Ronald Reagan's Executive Order 12549 in 1986, for the purpose of monitoring the implementation of the order. This order mandates executive departments and agencies to:\nCirculars.\nCirculars are instructions or information the OMB issues to federal agencies that are indexed by major category: Budget, State and Local Governments, Educational and Non-Profit Institutions, Federal Procurement, Federal Financial Management, Federal Information Resources / Data Collection and Other Special Purpose.\nCircular NO. A-119\nCircular A-119 is for federal participation in the development and use of voluntary consensus standards and in conformity assessment activities. A-119 instructs its agencies to adopt voluntary consensus standards before relying upon industry standards and reducing to a minimum the reliance by agencies on government standards. Adoption of international standards is widely followed by U.S. agencies. This includes:\nList of directors.\nList of OMB directors.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44031", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=44031", "title": "Perfect matching", "text": "Matching which covers every node of the graph\nIn graph theory, a perfect matching in a graph is a matching that covers every vertex of the graph. More formally, given a graph G with edges E and vertices V, a perfect matching in G is a subset M of E, such that every vertex in V is adjacent to exactly one edge in M. The adjacency matrix of a perfect matching is a symmetric permutation matrix.\nA perfect matching is also called a 1-factor; see Graph factorization for an explanation of this term. In some literature, the term complete matching is used. \nEvery perfect matching is a maximum-cardinality matching, but the opposite is not true. For example, consider the following graphs:\nIn graph (b) there is a perfect matching (of size 3) since all 6 vertices are matched; in graphs (a) and (c) there is a maximum-cardinality matching (of size 2) which is not perfect, since some vertices are unmatched.\nA perfect matching is also a minimum-size edge cover. If there is a perfect matching, then both the matching number and the edge cover number equal . \nA perfect matching can only occur when the graph has an even number of vertices. A near-perfect matching is one in which exactly one vertex is unmatched. This can only occur when the graph has an odd number of vertices, and such a matching must be maximum. In the above figure, part (c) shows a near-perfect matching. If, for every vertex in a graph, there is a near-perfect matching that omits only that vertex, the graph is also called factor-critical.\nCharacterizations.\nHall's marriage theorem provides a characterization of bipartite graphs which have a perfect matching.\nTutte's theorem on perfect matchings provides a characterization for arbitrary graphs.\nA perfect matching is a spanning 1-regular subgraph, a.k.a. a 1-factor. In general, a spanning \"k\"-regular subgraph is a \"k\"-factor.\nA spectral characterization for a graph to have a perfect matching is given by Hassani Monfared and Mallik as follows: Let formula_1 be a graph on even formula_2 vertices and formula_3 be formula_4 distinct nonzero purely imaginary numbers. Then formula_1 has a perfect matching if and only if there is a real skew-symmetric matrix formula_6 with graph formula_1 and eigenvalues formula_8. Note that the (simple) graph of a real symmetric or skew-symmetric matrix formula_6 of order formula_2 has formula_2 vertices and edges given by the nonzero off-diagonal entries of formula_6.\nComputation.\nDeciding whether a graph admits a perfect matching can be done in polynomial time, using any algorithm for finding a maximum cardinality matching.\nHowever, counting the number of perfect matchings, even in bipartite graphs, is #P-complete. This is because computing the permanent of an arbitrary 0\u20131 matrix (another #P-complete problem) is the same as computing the number of perfect matchings in the bipartite graph having the given matrix as its biadjacency matrix. \nA theorem of Pieter Kasteleyn states that the number of perfect matchings in a planar graph can be computed exactly in polynomial time via the FKT algorithm.\nThe number of perfect matchings in a complete graph \"Kn\" (with \"n\" even) is given by the double factorial: formula_13\nConnection to Graph Coloring.\nAn edge-colored graph can induce a number of (not necessarily proper) vertex colorings equal to the number of perfect matchings, as every vertex is covered exactly once in each matching. This property has been investigated in quantum physics and computational complexity theory.\nPerfect matching polytope.\nThe perfect matching polytope of a graph is a polytope in R|E| in which each corner is an incidence vector of a perfect matching."}
{"id": "44032", "revid": "39635320", "url": "https://en.wikipedia.org/wiki?curid=44032", "title": "Corporation for Public Broadcasting", "text": "American publicly funded non-profit corporation\nThe Corporation for Public Broadcasting (CPB; stylized in all lowercase as cpb) is an American non-profit corporation created under the Public Broadcasting Act of 1967 to promote and help support public broadcasting in the United States. The corporation's mission was to ensure universal access to non-commercial, high-quality educational, cultural, and other content and telecommunications services. \nCPB received annual funding from Congress from 1967. As of 2015, it had distributed more than 70 percent of its funding to more than 1,500 locally owned public radio and television stations, including PBS and NPR stations. In particular, CPB funding was a key part of small and rural public media station budgets. \nThe CPB is set to dissolve following a new law of the U.S. government in July 2025 which halted all funding to the CPB.\nFunding and operations.\nThe CPB's annual budget is composed almost entirely of an annual appropriation from Congress plus interest on those funds. Under the establishing law, no more than 5% of the appropriation may be used for administrative expenses. CPB allocates the funds to content development, community services, and other local station and system needs.\nFor fiscal year 2025[ [update]], its operating budget included US$535million of federal appropriation and $10million in interest revenue. Its budgeted expenses were as follows:\nPublic broadcasting stations are funded by a combination of private donations from listeners and viewers, foundations and corporations. Funding for public television comes in roughly equal parts from government (at all levels) and the private sector.\nStations that receive CPB funds must meet certain requirements, such as the maintenance or provision of open meetings, open financial records, a community advisory board, equal employment opportunity, and lists of donors and political activities.\nA 2007 Government Accountability Office (GAO) report and 2025 Congressional Research Service (CRS) report both found that public broadcasting stations in smaller and rural media markets had a greater dependence on federal funding. In 2023, rural stations received 45% of the CPB appropriation, while CPB grants accounted for at least 25% of station revenue for at least half of rural stations and more than 50% of revenue for some stations. A 2011 FCC report noted that less than one-fourth of funds disbursed through grants by the CPB to public broadcasters were used for programming while the overwhelming majority was used for support of station infrastructure.\nAfter administrative costs and system support programs, the 2025 CRS report noted that the entire federal appropriation to the CPB was used to provide grants to qualifying public broadcasting stations and program producers. The Public Broadcasting Act prohibits the CPB from owning or operating stations, and from producing, scheduling, or distributing programming. As PBS and NPR were incorporated as station-owned membership organizations, PBS and NPR received only a small fraction of their total revenue from the CPB directly, with 16% and 1% respectively of their total revenue coming directly from all federal sources in total and the majority coming from member stations, distribution revenue and services, corporate underwriting and institutional support, and individual contributions. PBS and NPR member stations are owned and operated by colleges and universities, public school districts, other private non-profit corporations, or state government agencies. Along with the 2007 GAO report about public television specifically, the 2025 CRS report noted that while NPR is authorized to produce programming for its member stations, programming included in the PBS National Programming Service (NPS) is not produced by PBS itself but by its member stations, external production companies, and independent producers, and PBS and NPR member stations retain ultimate editorial control over which programming from the NPS and NPR they wish to broadcast.\nPublic television stations participate in the Emergency Alert System (which includes Amber alerts) and the pilot program for the Digital Emergency Alert System. The CPB is the sole eligible recipient of funding through the Next Generation Warning System Grant Program within the Integrated Public Alert and Warning System.\nHistory.\nEstablishment.\nThe Corporation for Public Broadcasting was created on November 7, 1967, when U.S. president Lyndon B. Johnson signed the Public Broadcasting Act of 1967 (PBA).\nThe new organization initially collaborated with the National Educational Television network (NET)\u2014which would be replaced by the Public Broadcasting Service (PBS). Ward Chamberlin Jr. was the first operating officer. On March 27, 1968, it was registered as a nonprofit corporation in the District of Columbia. In 1969, the CPB talked to private groups to start PBS, an entity intended by the CPB to circumvent controversies engendered by certain NET public affairs programs that aired in the late 1960s and engendered opposition by politically conservative public figures, potentially threatening the medium's future viability. President Nixon was well known for his dislike of PBS and the CPB and wanted to kill the congressional funding for it.\nOn February 26, 1970, the CPB formed National Public Radio (NPR), a network of public-radio stations that began operating the following year. Unlike PBS, NPR produces \"and\" distributes programming.\nPublic interest programming.\nUnder the Public Broadcasting Act, the congressional declaration of policy stated that it was in the public interest for the CPB to facilitate the development of educational, cultural, and other programming not provided by commercial broadcasters, as well as programming for audiences that were unserved or underserved by commercial broadcasters. The House and Senate reports that accompanied the PBA as a bill suggested that such programming was not provided by commercial broadcasters due to market failure, and that by providing seed funding through federal grants administered by the CPB, public broadcasters would contribute to a better-informed citizenry through high-quality national and local programming. Under the Radio Act of 1927 and the Communications Act of 1934, Congress had established that broadcast licensees did not own the radio frequency assigned to them and that the radio spectrum as a whole belonged to the public, and as such, broadcasters were required to serve the public interest in order to receive a license. In 1929, the Federal Radio Commission issued a regulatory ruling that held that broadcasters were expected to provide a balanced program schedule that included programming for \"education and instruction, important public events, discussions of public questions\u2026 and news\".\nIn 1939, the Federal Communications Commission (FCC) required all radio stations to locate their main offices and studios in the community they were licensed to serve. In 1946, the FCC issued its Public Service Responsibility of Broadcast Licensees report that recommended that stations produce programming of local interest and to determine such programming through a community ascertainment process. In 1949, the FCC promulgated the fairness doctrine which required broadcasters to present programming that covered controversial issues of public importance with the opportunity for contrasting viewpoints to be aired. In 1960, the FCC issued a policy statement that listed 14 categories of programming considered necessary for a station to be operating in the public interest which included educational programs, public affairs programs, and news programs. However, the FCC only once rejected a license renewal application for failure to meet public interest programming obligations before the PBA was passed, and even though the FCC only took preliminary action on 2 to 3 percent of the approximately 5,000 fairness doctrine complaints it received annually (with only 15 to 20 per year in total resulting in any adverse finding for licensees), many broadcasters would avoid presenting controversial public issues altogether to avoid sanctions or risk losing a license.\nIn 2011, the FCC issued a report that concluded that growth in the number of media outlets in the United States from satellite radio and television, cable television, and the internet had not offset reductions in local news reporting with public interest, civics, or investigative journalism coverage caused by the decline of newspapers and local news in radio broadcasting. While local television stations were broadcasting a greater total number of news hours and had become some of the largest providers of local news online, most coverage was of crime and courthouses, accidents and disasters, and human interest topics while the depth and quantity of public interest, civics, and investigative journalism coverage declined, and broadcast and internet news media remained heavily reliant on reporting about the latter topics from the declining number of newspapers through fair use exemptions in copyright law. However, even though total advertising spending in the United States had shifted to television and cable from newspapers by the 1990s, the 2011 FCC report noted that local television stations were also seeing declining newsroom staffing alongside newspapers, with some stations outsourcing, reducing, or ending their local news programming and more frequently in smaller media markets.\nAlso, the total number of local cable news channels nationally was not growing (and possibly declining in some regions) since most channels were only attempting to break-even rather than be profitable and most cable operators did not invest in local cable news channels and had no plans to do so. Conversely, the 2011 FCC report noted that two-fifths of public radio listening hours was for news, 185 NPR member stations used an all-news format (with another 480 featuring news as part of mixed programming format), and the number of NPR member stations featuring local news had increased to 681 in 2009. One-third of all NPR programming was locally produced while less than 15% of the news and public affairs programming on commercial news/talk radio was local programming. A 2017 Congressional Research Service (CRS) report noted that 90 percent of public radio stations provided local newscasts and about half carried local news on weekends. While the 2011 FCC report noted that the news and public affairs programming of public television was mostly national programming, PBS programming was noted to provide greater in-depth coverage and journalistic documentaries than commercial television.\nThe 2011 FCC report also noted that NPR had 17 international bureaus and a greater number of foreign correspondents than NBC, CBS, Fox News, or MSNBC, and that children's programming on cable television was dominated by entertainment programming while educational programming for children remained chiefly provided by public television. When surveyed by the Government Accountability Office (GAO) in reports released in 2004 and 2007, majorities of public television licensees expressed the view that they did not produce enough local programming to serve the needs of their communities due to a lack of funds and that cutting the CPB appropriation would lead to a reduction in local programming. In light of various changes in consumer preferences and market dynamics in the news industry, a 2023 GAO report suggested along with the 2011 FCC report that local public interest journalism is at risk of market failure due to having the non-excludable and non-rivalrous features of a public good that generates positive externalities and is vulnerable to free riding. Along with other policy proposals, the 2023 GAO report suggested increasing the federal CPB appropriation to address the market failure.\nDigital broadcasting initiative.\nOn May 31, 2002, the CPB, through special appropriation funding, helped public television stations making the transition to digital broadcasting; this was complete by 2009.\nObjectivity and balance concerns in the 2000s.\nThe Public Broadcasting Act of 1967 requires the CPB to operate with a \"strict adherence to objectivity and balance in all programs or series of programs of a controversial nature\". It also requires it to regularly review national programming for objectivity and balance, and to report on \"its efforts to address concerns about objectivity and balance\". In 2004 and 2005, people from PBS and NPR complained that the CPB was starting to push a conservative agenda. Board members replied that they were merely seeking balance.\nKenneth Tomlinson, chair of the CPB board from September 2003 until September 2005, angered PBS and NPR supporters by unilaterally commissioning a conservative colleague to conduct a study of alleged bias in the PBS show \"NOW with Bill Moyers\", and by appointing two conservatives as CPB Ombudsmen. On November 3, 2005, Tomlinson resigned from the board, prompted by a report of his tenure by the CPB Inspector General, Kenneth Konz, requested by Democrats in the U.S. House of Representatives. The report stated:\nWe found evidence that the Corporation for Public Broadcasting (CPB) former Chairman violated statutory provisions and the Director's Code of Ethics by dealing directly with one of the creators of a new public affairs program during negotiations with the Public Broadcasting Service (PBS) and the CPB over creating the show. Our review also found evidence that suggests \"political tests\" were a major criteria [\"sic\"] used by the former Chairman in recruiting a President/Chief Executive Officer (CEO) for CPB, which violated statutory prohibitions against such practices.\nThreat to funding in 2023.\nIn July 2023, the appropriations bill for FY 2024 included no money for CPB when it passed out of the US House Appropriations Subcommittee on Labor, Health and Human Services, Education, and Related Agencies. However, the corresponding bill considered by the Senate Appropriations Committee planned to continue funding for the CPB, though at 7 percent less than what President Biden requested.\nSecond Trump administration.\nRescissions Act of 2025.\nOn June 3, President Trump filed a request for a rescission bill that included the congressional appropriation for the CPB. The next day, Office of Management and Budget Director Russell Vought testified before the House Appropriations Subcommittee on Financial Services and General Government on the rescission request and the administration's 2026 fiscal year budget request. Before the rescission request, PBS CEO Paula Kerger, NPR CEO Katherine Maher, and the CEO of Alaska Public Media testified on March 26 before the House Oversight Subcommittee on Delivering on Government Efficiency about the CPB appropriation, the journalistic standards and alleged bias of the organizations, and public broadcasting's educational programming and participation in emergency alert systems in rural areas. On June 6, House Majority Leader Steve Scalise introduced a rescission bill including the CPB appropriation in the House of Representatives.\nThe House passed the bill on June 12 along party lines by a vote of 214 to 212. On June 25, Vought testified before the Senate Appropriations Committee on the rescission bill. The Senate received the House bill on July 10 and it was referred to the Appropriations and Budget Committees. On July 15, the Senate passed motions to discharge the House bill from the Appropriations and Budget Committees and to proceed to debate with Vice President JD Vance casting tie-breaking votes on each motion. In the morning of July 17, the Senate passed the bill by a vote of 51 to 48 and with an amendment, requiring the bill to be transmitted back to the House for a second vote. The House approved the amended bill after midnight on July 18 by a vote of 216 to 213. President Trump signed the bill into law on July 24.\nCritics of the rescission bill, such as Nevada U.S. Representative Mark Amodei and New York U.S. Representative Dan Goldman, noted that the CPB appropriation amounted to less than 0.01% (1/10,000) of the U.S. federal budget. Polls conducted by YouGov from 2022 through 2025 showed PBS and NPR to be among the most trusted media institutions in the United States and that trust in PBS and NPR was growing, while five surveys conducted by YouGov and the Pew Research Center from February through July 2025 found consistent majorities or pluralities of Americans supported continuing federal funding for PBS and NPR. Previously, in every year from 2004 through 2021, surveys of Americans had shown PBS to have been consistently ranked as the most trusted institution in comparison to commercial broadcast and cable television, newspapers, and streaming services, and in January 2021, Americans valued tax dollars spent on PBS behind only military defense and oversight of food and drug safety.\nAfter the passage of the rescission bill, the CPB announced on August 1, 2025, that it would lay off the majority of its staff by the end of the fiscal year on September 30, with only a skeleton crew staying on board until January 2026 to distribute any remaining funds and royalties.\nBoard composition.\nThe CPB is governed by a nominally nine-member board of directors selected by the president of the United States and confirmed by the Senate; they serve six-year terms, and are allowed to continue serving until the end of the calendar year that their term ends or until their successor is seated on the board. Under the terms of the Public Broadcasting Act of 1967, the president cannot appoint persons of the same political party to more than five of the nine CPB board seats. The current board has only three members as new selections have not been made to replace members whose terms have ended.\nThe Board of Directors governs the CPB, sets policy, and establishes programming priorities. The Board appoints the president and chief executive officer, who then names the other corporate officers.\nBoard members.\nThe current CPB board as of \u00a010, 2025[ [update]]:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44033", "revid": "48911350", "url": "https://en.wikipedia.org/wiki?curid=44033", "title": "JAXP", "text": ""}
{"id": "44034", "revid": "12109580", "url": "https://en.wikipedia.org/wiki?curid=44034", "title": "Public Broadcasting System", "text": ""}
{"id": "44035", "revid": "48621552", "url": "https://en.wikipedia.org/wiki?curid=44035", "title": "Franco-Prussian War", "text": "European conflict from 1870 to 1871\nThe Franco-Prussian War or Franco-German War, often referred to in France as the War of 1870, was a conflict between the Second French Empire and the North German Confederation led by the Kingdom of Prussia. Lasting from 19 July 1870 to 28 January 1871, the conflict was caused primarily by France's determination to reassert its dominant position in continental Europe, which appeared in question following the decisive Prussian victory over Austria in 1866. \nAfter a prince of the Roman Catholic branch Hohenzollern-Sigmaringen had been offered the vacant Spanish throne in 1870 and had withdrawn his acceptance, the French ambassador approached Prussian King Wilhelm I at his vacationing site in Ems demanding Prussia renounce any future claims, which Wilhelm rejected. The internal Ems dispatch reported this to Berlin on July 13; Prussian chancellor Otto von Bismarck quickly then made it public with altered wording. Thus the French newspapers for July 14, the French national holiday contained translations of Bismarck's press release, but not a report from their own ambassador. A crowd in the streets of Paris demanded war, and soon French mobilization was ordered. \nAccording to some historians, Prussian chancellor Otto von Bismarck deliberately provoked the French into declaring war on Prussia in order to induce four independent southern German states\u2014Baden, W\u00fcrttemberg, Bavaria and Hesse-Darmstadt\u2014to join the North German Confederation. Other historians contend that Bismarck exploited the circumstances as they unfolded. All agree that Bismarck recognized the potential for new German alliances, given the situation as a whole.\nFrance mobilised its army on 15 July 1870, leading the North German Confederation to respond with its own mobilisation later that day. On 16 July 1870, the French parliament voted to declare war on Prussia; France invaded German territory on 2 August. The German coalition mobilised its troops much more effectively than the French and invaded northeastern France on 4 August. German forces were superior in numbers, training, and leadership and made more effective use of modern technology, particularly railways and artillery.\nA series of hard-fought Prussian and German victories in eastern France, culminating in the Siege of Metz and the Battle of Sedan, resulted in the capture of the French Emperor Napoleon III and the decisive defeat of the army of the Second Empire; a Government of National Defense was formed in Paris on 4 September and continued the war for another five months. German forces fought and defeated new French armies in northern France, then besieged Paris for over four months before it fell on 28 January 1871, effectively ending the war.\nIn the final days of the war, with German victory all but assured, the German states proclaimed their union as the German Empire under the Prussian king Wilhelm I and Chancellor Bismarck. With the notable exceptions of Austria and German Switzerland, the vast majority of German-speakers were united under a nation-state for the first time. Following an armistice with France, the Treaty of Frankfurt was signed on 10 May 1871, giving Germany billions of francs in war indemnity, as well as most of Alsace and parts of Lorraine, which became the Imperial Territory of Alsace-Lorraine ().\nThe war had a lasting impact on Europe. By hastening German unification, the war significantly altered the balance of power on the continent, with the new German state supplanting France as the dominant European land power. Bismarck maintained great authority in international affairs for two decades, developing a reputation for \"Realpolitik\" that raised Germany's global stature and influence. In France, it brought a final end to imperial rule and began the first lasting republican government. Resentment over the French government's handling of the war and its aftermath triggered the Paris Commune, a revolutionary uprising which seized and held power for two months before its suppression; the event would influence the politics and policies of the Third Republic.\nCauses.\nThe causes of the Franco-Prussian War are rooted in the events surrounding the lead up to the unification of the German states under Otto von Bismarck. France had gained the status of being the dominant power of continental Europe as a result of the Franco-Austrian War of 1859. During the Austro-Prussian War of 1866, the Empress Eug\u00e9nie, Foreign Minister Drouyn de Lhuys and War Minister Jacques Louis Randon were concerned that the power of Prussia might overtake that of France. They unsuccessfully urged Napoleon to mass troops at France's eastern borders while the bulk of the Prussian armies were still engaged in Bohemia as a warning that no territorial changes could be effected in Germany without consulting France.\nAs a result of Prussia's annexation of several German states which had sided with Austria during the war and the formation of the North German Confederation under Prussia's aegis, French public opinion stiffened and now demanded more firmness as well as territorial compensations. As a result, Napoleon demanded from Prussia a return to the French borders of 1814, with the annexation of Luxembourg, most of Saarland, and the Bavarian Palatinate. Bismarck flatly refused what he disdainfully termed France's (\"tipping policy\"). He then communicated Napoleon III's written territorial demands to Bavaria and the other southern German states of W\u00fcrttemberg, Baden and Hesse-Darmstadt, which hastened the conclusion of defensive military alliances with these states. France had been strongly opposed to any further alliance of German states, which would have threatened French continental dominance.\nThe only result of French policy was the consent of Prussia to nominal independence for Saxony, Bavaria, Wurttemberg, Baden, and Hessia-Darmstadt. This was a small victory, and one without appeal to a French public which wanted territory and a French army which wanted revenge. The situation did not suit either France, which unexpectedly found itself next to the militarily powerful Prussian-led North German Confederation, or Prussia, whose foremost objective was to complete the process of uniting the German states under its control. Thus, war between the two powers since 1866 was only a matter of time.\nIn Prussia, some officials considered a war against France both inevitable and necessary to arouse German nationalism in those states that would allow the unification of a great German empire. This aim was epitomized by Prussian Chancellor Otto von Bismarck's later statement: \"I did not doubt that a Franco-German war must take place before the construction of a United Germany could be realised.\" Bismarck also knew that France should be the aggressor in the conflict to bring the four southern German states to side with Prussia, hence giving Germans numerical superiority. He was convinced that France would not find any allies in her war against Germany for the simple reason that \"France, the victor, would be a danger to everybody\u2014Prussia to nobody,\" and he added, \"That is our strong point.\" Many Germans also viewed the French as the traditional destabilizer of Europe, and sought to weaken France to prevent further breaches of the peace.\nThe immediate cause of the war was the candidacy of Leopold of Hohenzollern-Sigmaringen to the throne of Spain after the fall of Isabella II in 1868. France feared an encirclement resulting from an alliance between Prussia and Spain. The Hohenzollern prince's candidacy was withdrawn under French diplomatic pressure, but Otto von Bismarck goaded the French into declaring war by releasing an altered summary of the Ems Dispatch, a telegram sent by Wilhelm I rejecting French demands that Prussia never again support a Hohenzollern candidacy. Bismarck's summary, as mistranslated by the French press Havas, made it sound as if the king had treated the French envoy in a demeaning fashion, which inflamed public opinion in France.\nFrench historians Fran\u00e7ois Roth and Pierre Milza argue that Napoleon III was pressured by a bellicose press and public opinion and thus sought war in response to France's diplomatic failures to obtain any territorial gains following the Austro-Prussian War. Napoleon III believed he would win a conflict with Prussia. Many in his court, such as Empress Eug\u00e9nie, also wanted a victorious war to resolve growing domestic political problems, restore France as the undisputed leading power in Europe, and ensure the long-term survival of the House of Bonaparte. A national plebiscite held on 8 May 1870, which returned results overwhelmingly in favor of the Emperor's domestic agenda gave the impression that the regime was politically popular and in a position to confront Prussia. Within days of the plebiscite, France's pacifist Foreign Minister Napol\u00e9on, comte Daru, was replaced by Agenor, duc de Gramont, a fierce opponent of Prussia who, as French Ambassador to Austria in 1866, had advocated an Austro-French military alliance against Prussia. Napoleon III's worsening health problems made him less and less capable of reining in Empress Eug\u00e9nie, Gramont and the other members of the war party, known collectively as the \"mameluks\". For Bismarck, the nomination of Gramont was seen as \"a highly bellicose symptom\".\nThe Ems telegram of 13 July 1870 had exactly the effect on French public opinion that Bismarck had intended. \"This text produced the effect of a red flag on the Gallic bull\", Bismarck later wrote. Gramont, the French foreign minister, declared that he felt \"he had just received a slap\". The leader of the monarchists in Parliament, Adolphe Thiers, spoke for moderation, arguing that France had won the diplomatic battle and there was no reason for war, but he was drowned out by cries that he was a traitor and a Prussian. Napoleon's new prime minister, Emile Ollivier, declared that France had done all that it could humanly and honorably do to prevent the war, and that he accepted the responsibility \"with a light heart\". A crowd of 15,000\u201320,000 people, carrying flags and patriotic banners, marched through the streets of Paris, demanding war. French mobilization was ordered early on 15 July. Upon receiving news of the French mobilization, the North German Confederation mobilized on the night of 15\u201316 July, while Bavaria and Baden did likewise on 16 July and W\u00fcrttemberg on 17 July. On 19 July 1870, the French sent a declaration of war to the Prussian government. The southern German states immediately sided with Prussia.\nNapoleonic France had no documented alliance with other powers and entered the war virtually without allies. The calculation was for a victorious offensive, which, as the French Foreign Minister Gramont stated, was \"the only way for France to lure the wary Austrians, Italians and Danes into the French alliance\". The involvement of Russia on the side of France was not considered by her at all, since Russia made the lifting of restrictions on its naval construction on the Black Sea imposed on Russia by the Treaty of Paris following the Crimean War a precondition for the union. But Imperial France was not ready to do this. \"Bonaparte did not dare to encroach on the Paris Treaty: the worse things turned out in the present, the more precious the heritage of the past became\".\nOpposing forces.\nFrench.\nThe French Army consisted in peacetime of approximately 426,000 soldiers, some of them regulars, others conscripts who until March 1869 were selected by ballot and served for the comparatively long period of seven years. Some of them were veterans of previous French campaigns in the Crimean War, Algeria, the Franco-Austrian War in Italy, and in the Mexican campaign. However, following the \"Seven Weeks War\" between Prussia and Austria four years earlier, it had been calculated that, with commitments in Algeria and elsewhere, the French Army could field only 288,000 men to face the Prussian Army, when potentially 1,000,000 would be required. Under Marshal Adolphe Niel, urgent reforms were made. Universal conscription and a shorter period of service gave increased numbers of reservists, who would swell the army to a planned strength of 800,000 on mobilisation. Those who for any reason were not conscripted were to be enrolled in the \"Garde Mobile\", a militia with a nominal strength of 400,000. However, the Franco-Prussian War broke out before these reforms could be completely implemented. The mobilisation of reservists was chaotic and resulted in large numbers of stragglers, while the \"Garde Mobile\" were generally untrained and often mutinous.\nFrench infantry were equipped with the breech-loading Chassepot rifle, one of the most modern mass-produced firearms in the world at the time, with 1,037,555 available in French inventories. With a rubber ring seal and a smaller bullet, the Chassepot had a maximum effective range of some with a short reloading time. French tactics emphasised the defensive use of the Chassepot rifle in trench-warfare style fighting\u2014the so-called \"feu de bataillon\". The artillery was equipped with rifled, muzzle-loaded La Hitte guns. The army also possessed a precursor to the machine-gun: the mitrailleuse, which could unleash significant, concentrated firepower but nevertheless lacked range and was comparatively immobile, and thus prone to being easily overrun. The mitrailleuse was mounted on an artillery gun carriage and grouped in batteries in a similar fashion to cannon.\nThe army was nominally led by Napoleon III, with Marshals Fran\u00e7ois Achille Bazaine and Patrice de MacMahon in command of the field armies. However, there was no previously arranged plan of campaign in place. The only campaign plan prepared between 1866 and 1870 was a defensive one.\nPrussians/Germans.\nThe German army comprised that of the North German Confederation led by the Kingdom of Prussia, and the South German states drawn in under the secret clause of the preliminary peace of Nikolsburg, 26 July 1866, and formalised in the Treaty of Prague, 23 August 1866.\nRecruitment and organisation of the various armies were almost identical, and based on the concept of conscripting annual classes of men who then served in the regular regiments for a fixed term before being moved to the reserves. This process gave a theoretical peace time strength of 382,000 and a wartime strength of about 1,189,000.\nGerman tactics emphasised encirclement battles like Cannae and using artillery offensively whenever possible. Rather than advancing in a column or line formation, Prussian infantry moved in small groups that were harder to target by artillery or French defensive fire. The sheer number of soldiers available made encirclement \"en masse\" and destruction of French formations relatively easy.\nThe army was equipped with the Dreyse needle gun renowned for its use at the Battle of K\u00f6niggr\u00e4tz, which was by this time showing the age of its 25-year-old design. The rifle had a range of only and lacked the rubber breech seal that permitted aimed shots. The deficiencies of the needle gun were more than compensated for by the famous Krupp 6-pounder steel breech-loading cannons being issued to Prussian artillery batteries. Firing a contact-detonated shell, the Krupp gun had a longer range and a higher rate of fire than the French bronze muzzle loading cannon, which relied on time fuses.\nThe Prussian army was controlled by the General Staff, under General Helmuth von Moltke. The Prussian army was unique in Europe for having the only such organisation in existence, whose purpose in peacetime was to prepare the overall war strategy, and in wartime to direct operational movement and organise logistics and communications. The officers of the General Staff were hand-picked from the Prussian \"Kriegsakademie\" (War Academy). Moltke embraced new technology, particularly the railroad and telegraph, to coordinate and accelerate mobilisation of large forces.\nFrench Army incursion.\nPreparations for the offensive.\nOn 28 July 1870 Napoleon III left Paris for Metz and assumed command of the newly titled Army of the Rhine, some 202,448 strong and expected to grow as the French mobilization progressed. Marshal MacMahon took command of I Corps (4 infantry divisions) near Wissembourg; Marshal Fran\u00e7ois Canrobert brought VI Corps (4 infantry divisions) to Ch\u00e2lons-sur-Marne in northern France as a reserve and to guard against a Prussian advance through Belgium.\nA pre-war plan laid down by the late Marshal Niel called for a strong French offensive from Thionville towards Trier and into the Prussian Rhineland. This plan was discarded in favour of a defensive plan by Generals Charles Frossard and Bart\u00e9lemy Lebrun, which called for the Army of the Rhine to remain in a defensive posture near the German border and repel any Prussian offensive. As Austria, along with Bavaria, W\u00fcrttemberg, and Baden were expected to join in a revenge war against Prussia, I Corps would invade the Bavarian Palatinate and proceed to \"free\" the four South German states in concert with Austro-Hungarian forces. VI Corps would reinforce either army as needed.\nUnfortunately for Frossard's plan, the Prussian army mobilised far more rapidly than expected. The Austro-Hungarians, still reeling after their defeat by Prussia in the Austro-Prussian War, were treading carefully before stating that they would only side with France if the south Germans viewed the French positively. This did not materialize as the four South German states had come to Prussia's aid and were mobilizing their armies against France.\nOccupation of Saarbr\u00fccken.\nNapoleon III was under substantial domestic pressure to launch an offensive before the full might of Moltke's forces was mobilized and deployed. Reconnaissance by Frossard's forces had identified only the Prussian 16th Infantry Division guarding the border town of Saarbr\u00fccken, right before the entire Army of the Rhine. Accordingly, on 31 July the Army marched forward toward the Saar River to seize Saarbr\u00fccken.\nGeneral Frossard's II Corps and Marshal Bazaine's III Corps crossed the German border on 2 August, and began to force the Prussian 40th Regiment of the 16th Infantry Division from the town of Saarbr\u00fccken with a series of direct attacks. The Chassepot rifle proved its worth against the Dreyse rifle, with French riflemen regularly outdistancing their Prussian counterparts in the skirmishing around Saarbr\u00fccken. However the Prussians resisted strongly, and the French suffered 86 casualties to the Prussian 83 casualties. Saarbr\u00fccken also proved to be a major obstacle in terms of logistics. Only one railway there led to the German hinterland but could be easily defended by a single force, and the only river systems in the region ran along the border instead of inland. While the French hailed the invasion as the first step towards the Rhineland and later Berlin, General Edmond Le B\u0153uf and Napoleon III were receiving alarming reports from foreign news sources of Prussian and Bavarian armies massing to the southeast in addition to the forces to the north and northeast.\nMoltke had indeed massed three armies in the area\u2014the Prussian First Army with 50,000 men, commanded by General Karl von Steinmetz opposite Saarlouis, the Prussian Second Army with 134,000 men commanded by Prince Friedrich Karl opposite the line Forbach-Spicheren, and the Prussian Third Army with 120,000 men commanded by Crown Prince Friedrich Wilhelm, poised to cross the border at Wissembourg.\nPrussian Army advance.\nBattle of Wissembourg.\nUpon learning from captured Prussian soldiers and a local area police chief that the Prussian Crown Prince's Third Army was just north from Saarbr\u00fccken near the Rhine river town Wissembourg, General Le B\u0153uf and Napoleon III decided to retreat to defensive positions. General Frossard, without instructions, hastily withdrew his elements of the Army of the Rhine in Saarbr\u00fccken back across the river to Spicheren and Forbach.\nMarshal MacMahon, now closest to Wissembourg, spread his four divisions to react to any Prussian-Bavarian invasion. This organization was due to a lack of supplies, forcing each division to seek out food and forage from the countryside and from the representatives of the army supply arm that was supposed to furnish them with provisions. What made a bad situation much worse was the conduct of General Auguste-Alexandre Ducrot, commander of the 1st Division. He told General Abel Douay, commander of the 2nd Division, on 1 August that \"The information I have received makes me suppose that the enemy has no considerable forces very near his advance posts, and has no desire to take the offensive\". Two days later, he told MacMahon that he had not found \"a single enemy post\u00a0... it looks to me as if the menace of the Bavarians is simply bluff\". Even though Ducrot shrugged off the possibility of an attack by the Germans, MacMahon tried to warn his other three division commanders, without success.\nThe first action of the Franco-Prussian War took place on 4 August 1870. This battle saw the unsupported division of General Douay of I Corps, with some attached cavalry, which was posted to watch the border, attacked in overwhelming but uncoordinated fashion by the German 3rd Army. During the day, elements of a Bavarian and two Prussian corps became engaged and were aided by Prussian artillery, which blasted holes in the city defenses. Douay held a very strong position initially, thanks to the accurate long-range rapid fire of the Chassepot rifles, but his force was too thinly stretched to hold it. Douay was killed in the late morning when a caisson of the divisional mitrailleuse battery exploded near him; the encirclement of the town by the Prussians then threatened the French avenue of retreat.\nThe fighting within the town had become extremely intense, becoming a door to door battle of survival. Despite an unceasing attack from Prussian infantry, the soldiers of the 2nd Division kept to their positions. The people of the town of Wissembourg finally surrendered to the Germans. The French troops who did not surrender retreated westward, leaving behind 1,000 dead and wounded and another 1,000 prisoners and all of their remaining ammunition. The final attack by the Prussian troops also cost c.\u20091,000 casualties. The German cavalry then failed to pursue the French and lost touch with them. The attackers had an initial superiority of numbers, a broad deployment which made envelopment highly likely but the effectiveness of French Chassepot-rifle fire inflicted costly repulses on infantry attacks, until the French infantry had been extensively bombarded by the Prussian artillery.\nBattle of Spicheren.\npx; overflow: hidden;\"&gt;\npx; left: -px; width: px\"&gt;\n Lithograph, after Jules F\u00e9rat, of the Battle of Spicheren (also called the Battle of Forbach) \nThe Battle of Spicheren on 5 August was the second of three critical French defeats. Moltke had originally planned to keep Bazaine's army on the Saar River until he could attack it with the 2nd Army in front and the 1st Army on its left flank, while the 3rd Army closed towards the rear. The aging General von Steinmetz made an overzealous, unplanned move, leading the 1st Army south from his position on the Moselle. He moved straight toward the town of Spicheren, cutting off Prince Frederick Charles from his forward cavalry units in the process.\nOn the French side, planning after the disaster at Wissembourg had become essential. General Le B\u0153uf, flushed with anger, was intent upon going on the offensive over the Saar and countering their loss. However, planning for the next encounter was more based upon the reality of unfolding events rather than emotion or pride, as Intendant General Wolff told him and his staff that supply beyond the Saar would be impossible. Therefore, the armies of France would take up a defensive position that would protect against every possible attack point, but also left the armies unable to support each other.\nWhile the French army under General MacMahon engaged the German 3rd Army at the Battle of W\u00f6rth, the German 1st Army under Steinmetz finished their advance west from Saarbr\u00fccken. A patrol from the German 2nd Army under Prince Friedrich Karl of Prussia spotted decoy fires nearby and Frossard's army farther off on a distant plateau south of the town of Spicheren, and took this as a sign of Frossard's retreat. Ignoring Moltke's plan again, both German armies attacked Frossard's French 2nd Corps, fortified between Spicheren and Forbach.\nThe French were unaware of German numerical superiority at the beginning of the battle as the German 2nd Army did not attack all at once. Treating the oncoming attacks as merely skirmishes, Frossard did not request additional support from other units. By the time he realized what kind of a force he was opposing, it was too late. Seriously flawed communications between Frossard and those in reserve under Bazaine slowed down so much that by the time the reserves received orders to move out to Spicheren, German soldiers from the 1st and 2nd armies had charged up the heights. Because the reserves had not arrived, Frossard erroneously believed that he was in grave danger of being outflanked, as German soldiers under General von Glume were spotted in Forbach. Instead of continuing to defend the heights, by the close of battle after dusk he retreated to the south. The German casualties were relatively high due to the advance and the effectiveness of the Chassepot rifle. They were quite startled in the morning when they had found out that their efforts were not in vain\u2014Frossard had abandoned his position on the heights.\nBattle of W\u00f6rth.\nThe Battle of W\u00f6rth began when the two armies clashed again on 6 August near W\u00f6rth in the town of Fr\u0153schwiller, about from Wissembourg. The Crown Prince of Prussia's 3rd army had, on the quick reaction of his Chief of Staff General von Blumenthal, drawn reinforcements which brought its strength up to 140,000 troops. The French had been slowly reinforced and their force numbered only 35,000. Although badly outnumbered, the French defended their position just outside Fr\u0153schwiller. By afternoon, the Germans had suffered c.\u200910,500 killed or wounded and the French had lost a similar number of casualties and another c.\u20099,200 men taken prisoner, a loss of about 50%. The Germans captured Fr\u00f6schwiller which sat on a hilltop in the centre of the French line. Having lost any hope for victory and facing a massacre, the French army disengaged and retreated in a westerly direction towards Bitche and Saverne, hoping to join French forces on the other side of the Vosges mountains. The German 3rd army did not pursue the French but remained in Alsace and moved slowly south, attacking and destroying the French garrisons in the vicinity.\nBattle of Mars-La-Tour.\nAbout 160,000 French soldiers were besieged in the fortress of Metz following the defeats on the frontier. A retirement from Metz to link up with French forces at Ch\u00e2lons was ordered on 15 August and spotted by a Prussian cavalry patrol under Major Oskar von Blumenthal. Next day a grossly outnumbered Prussian force of 30,000 men of III Corps (of the 2nd Army) under General Constantin von Alvensleben, found the French Army near Vionville, east of Mars-la-Tour.\nDespite odds of four to one, the III Corps launched a risky attack. The French were routed and the III Corps captured Vionville, blocking any further escape attempts to the west. Once blocked from retreat, the French in the fortress of Metz had no choice but to engage in a fight that would see the last major cavalry engagement in Western Europe. The battle soon erupted, and III Corps was shattered by incessant cavalry charges, losing over half its soldiers. The German Official History recorded 15,780 casualties and French casualties of 13,761 men.\nOn 16 August, the French had a chance to sweep away the key Prussian defense, and to escape. Two Prussian corps had attacked the French advance guard, thinking that it was the rearguard of the retreat of the French Army of the Meuse. Despite this misjudgment the two Prussian corps held the entire French army for the whole day. Outnumbered 5 to 1, the extraordinary \u00e9lan of the Prussians prevailed over gross indecision by the French. The French had lost the opportunity to win a decisive victory.\nBattle of Gravelotte.\nThe Battle of Gravelotte, or Gravelotte\u2013St. Privat (18 August), was the largest battle in the Franco-Prussian War. It was fought about west of Metz, where on the previous day, having intercepted the French army's retreat to the west at the Battle of Mars-La-Tour, the Prussians were now closing in to complete the destruction of the French forces. The combined German forces, under Field Marshal Count Helmuth von Moltke, were the Prussian First and Second Armies of the North German Confederation numbering about 210 infantry battalions, 133 cavalry squadrons, and 732 artillery pieces totaling 188,332 officers and men. The French Army of the Rhine, commanded by Marshal Fran\u00e7ois-Achille Bazaine, numbering about 183 infantry battalions, 104 cavalry squadrons, backed by 520 artillery pieces, totaling 112,800 officers and men, dug in along high ground with their southern left flank at the town of Roz\u00e9rieulles, and their northern right flank at St. Privat.\nOn 18 August, the battle began when at 08:00 Moltke ordered the First and Second Armies to advance against the French positions. The French were dug in with trenches and rifle pits with their artillery and their mitrailleuses in concealed positions. Backed by artillery fire, Steinmetz's VII and VIII Corps launched attacks across the Mance ravine, all of which were defeated by French rifle and mitrailleuse firepower, forcing the two German corps' to withdraw to Rezonville. The Prussian 1st Guards Infantry Division assaulted French-held St. Privat and was pinned down by French fire from rifle pits and trenches. The Second Army under Prince Frederick Charles used its artillery to pulverize the French position at St. Privat. His XII Corps took the town of Roncourt and helped the Guard conquer St. Privat, while Eduard von Fransecky's II Corps advanced across the Mance ravine. The fighting died down at 22:00.\nThe next morning the French Army of the Rhine retreated to Metz where they were besieged and forced to surrender two months later. A grand total of 20,163 German troops were killed, wounded or missing in action during the August 18 battle. The French losses were 7,855 killed and wounded along with 4,420 prisoners of war (half of them were wounded) for a total of 12,275.\nSiege of Metz.\nWith the defeat of Marshal Bazaine's Army of the Rhine at Gravelotte, the French retreated to Metz, where they were besieged by over 150,000 Prussian troops of the First and Second Armies. Further military operations on the part of the army under Bazaine's command have drawn numerous criticisms from historians against its commander. It was later stated with derogatory irony that his occupation at that time was writing orders on hygiene and discipline, as well as playing dominoes. Bazaine's surprising inactivity was a great relief to Moltke, who now had time to improve his lines around Metz and intensify the hunt for MacMahon.\nAt this time, Napoleon III and MacMahon formed the new French Army of Ch\u00e2lons to march on to Metz to rescue Bazaine. Napoleon III personally led the army with Marshal MacMahon in attendance. The Army of Ch\u00e2lons marched northeast towards the Belgian border to avoid the Prussians before striking south to link up with Bazaine. The Prussians took advantage of this maneuver to catch the French in a pincer grip. Moltke left the Prussian First and Second Armies besieging Metz, except three corps detached to form the Army of the Meuse under the Crown Prince of Saxony. With this army and the Prussian Third Army, Moltke marched northward and caught up with the French at Beaumont on 30 August. After a sharp fight in which they lost 5,000 men and 40 cannons, the French withdrew toward Sedan. Having reformed in the town, the Army of Ch\u00e2lons was immediately isolated by the converging Prussian armies. Napoleon III ordered the army to break out of the encirclement immediately. With MacMahon wounded on the previous day, General Auguste Ducrot took command of the French troops in the field.\nBattle of Sedan.\nOn 1 September 1870, the battle opened with the Army of Ch\u00e2lons, with 202 infantry battalions, 80 cavalry squadrons and 564 guns, attacking the surrounding Prussian Third and Meuse Armies totaling 222 infantry battalions, 186 cavalry squadrons and 774 guns. General Emmanuel F\u00e9lix de Wimpffen, the commander of the French V Corps in reserve, hoped to launch a combined infantry and cavalry attack against the Prussian XI Corps. But by 11:00, Prussian artillery took a toll on the French while more Prussian troops arrived on the battlefield. The struggle in the conditions of encirclement turned out to be absolutely impossible for the French\u2014their front was shot through with artillery fire from three sides. The French cavalry, commanded by General Margueritte, launched three desperate attacks on the nearby village of Floing where the Prussian XI Corps was concentrated. Margueritte was mortally wounded leading the very first charge, dying 4 days later, and the two additional charges led to nothing but heavy losses. By the end of the day, with no hope of breaking out, Napoleon III called off the attacks. The French lost over 17,000 men, killed or wounded, with 21,000 captured. The Prussians reported their losses at 2,320 killed, 5,980 wounded and 700 captured or missing. By the next day, on 2 September, Napoleon III surrendered and was taken prisoner with 104,000 of his soldiers. It was an overwhelming victory for the Prussians, who had captured an entire French army and the leader of France. They subsequently paraded the defeated French army in view of the besieged army in Metz, which had an impact on the morale of the defenders. The defeat of the French at Sedan had decided the war in Prussia's favour. One French army was now immobilised and besieged in the city of Metz, and nothing was preventing a Prussian invasion. This defeat was humiliating for the already morally defeated French army and paved the way for the Siege of Paris.\nSurrender of Metz.\nBazaine, a well-known Bonapartist, at this time allowed himself to be carried away by illusory plans for a political role in France. Unconventional military plans were put forth (by which the Germans would allow the army under Bazaine's command to withdraw from the fortress of Metz to retreat to the south of France, where it would remain until the German armies captured Paris) which were to eliminate the political usurpers and make room for the legitimate imperial authorities with the support of Bazaine's army. Even ignoring moral issues and potential public outcry, this plan seems completely unrealistic. Bismarck and Moltke answered Bazaine's offer of \"cooperation\" against the \"republican menace\" with an indifferent shrug. The German press, undoubtedly at the instigation of Bismarck, widely covered this topic, and reported the details of Bazaine's negotiations. The French press could only remain completely silent on this issue. With whom Bazaine negotiated still raises questions among historians. \"For a decade, the French were considered him (M. Edmond Regnier) a sinister figure, almost certainly an agent of Bismarck. They would have been more justified in thinking him a buffoon\". Undoubtedly, the politically motivated actions of Commander Bazaine led to the passivity of the encircled army at Metz and contributed to the defeat of not only this army, but the country as a whole. Bazaine's army surrendered on 26 October. 173,000 people surrendered, with the Prussians capturing the huge amount of military equipment located in Metz. After the war, Marshal Bazaine was convicted by a French military court.\nWar of the Government of National Defence.\nGovernment of National Defence.\nWhen news of Napoleon III's surrender at Sedan arrived in Paris, the Second Empire was overthrown by a popular uprising. On 4 September, Jules Favre, L\u00e9on Gambetta, and General Louis-Jules Trochu proclaimed a provisional government called the Government of National Defence and a Third Republic. After the German victory at Sedan, most of the French standing army was either besieged in Metz or held prisoner by the Germans, who hoped for an armistice and an end to the war. Bismarck wanted an early peace but had difficulty finding a legitimate French authority with whom to negotiate. The Emperor was a captive and the Empress in exile, but there had been no abdication \"de jure\" and the army was still bound by an oath of allegiance to the defunct imperial regime; on the other hand, the Government of National Defence had no electoral mandate.\nPrussia's intention was to weaken the political position of France abroad. The defensive position of the new French authorities, who offered Germany an honorable peace and reimbursement of the costs of the war, was presented by Prussia as aggressive; they rejected the conditions put forward and demanded the annexation of the French provinces of Alsace and part of Lorraine. Bismarck was dangling the Emperor over the republic's head, calling Napoleon III \"the legitimate ruler of France\" and dismissing Gambetta's new republic as no more than \"un coup de parti\" (\"a partisan coup\"). This policy was to some extent successful; the European press discussed the legitimacy of the French authorities, and Prussia's aggressive position was to some extent understood. Only the United States and Spain recognized the Government of National Defence immediately after the announcement; other countries refused to do this for some time.\nThe question of legitimacy is rather strange for France after the coup d'\u00e9tat of 1851, since Louis-Napoleon himself only overthrew the Second Republic and rose to the imperial throne by means of a coup d'\u00e9tat.\nThe Germans expected to negotiate an end to the war, but while the republican government was amenable to war reparations or ceding colonial territories in Africa or Southeast Asia, it would go no further. On behalf of the Government of National Defense, Favre declared on 6 September that France would not \"yield an inch of its territory nor a stone of its fortresses\". The republic then renewed the declaration of war, called for recruits in all parts of the country, and pledged to drive the German troops out of France by a ('overwhelming attack'). The Germans continued the war, yet could not pin down any proper military opposition in their vicinity. As the bulk of the remaining French armies was digging in near Paris, the German leaders decided to put pressure upon their enemy by attacking there. By 15 September, German troops had reached the outskirts and Moltke issued the orders to surround the city. On 19 September, the Germans surrounded it and erected a blockade, as already established at Metz, completing the encirclement on 20 September. Bismarck met Favre on 18 September at the Ch\u00e2teau de Ferri\u00e8res and demanded a frontier immune to a French war of revenge, which included Strasbourg, Alsace, and most of the Moselle department in Lorraine, of which Metz was the capital. In return for an armistice for the French to elect a National Assembly, Bismarck demanded the surrender of Strasbourg and the fortress city of Toul. To allow supplies into Paris, one of the perimeter forts had to be handed over. Favre was unaware that Bismarck's real aim in making such extortionate demands was to establish a durable peace on Germany's new western frontier, preferably by a peace with a friendly government, on terms acceptable to French public opinion. An impregnable military frontier was an inferior alternative to him, favoured only by the militant nationalists on the German side.\nWhen the war had begun, European public opinion heavily favoured the Germans; many Italians attempted to sign up as volunteers at the Prussian embassy in Florence and a Prussian diplomat visited Giuseppe Garibaldi in Caprera. Bismarck's demand that France surrender sovereignty over Alsace caused a dramatic shift in that sentiment in Italy, which was best exemplified by the reaction of Garibaldi soon after the revolution in Paris, who told the \"Movimento\" of Genoa on 7 September 1870 that \"Yesterday I said to you: war to the death to Bonaparte. Today I say to you: rescue the French Republic by every means.\" Garibaldi went to France and assumed command of the Army of the Vosges, with which he operated around Dijon until the end of the war.\nThe energetic actions of a part of the government (delegation) in Tours under Gambetta's leadership led to significant success in the formation of a new army. In less than four months, with persistent battles at the front, eleven new corps were formed (Nos. XVI\u2013XXVI). The average success of the formation was equal to six thousand infantrymen and two batteries per day. This success was achieved despite the fact that the military industry and warehouses were concentrated mainly in Paris; all supplies in the province\u2014chiefs, weapons, camps, uniforms, ammunition, equipment, baggage\u2014had to be improvised anew. Many branches of the military industry were re-established in the province. Freedom of communication with foreign markets brought significant benefits; it was possible to make large purchases on foreign markets, mainly English, Belgian, and American. The artillery created by Gambetta in four months\u2014238 batteries\u2014was one and a half times larger than the artillery of imperial France. In the end, eight corps participated in the battles, and three were ready only by the end of January, when a truce was already concluded.\nWhile the Germans had a 2:1 numerical advantage before Napoleon III's surrender, this French recruitment gave them a 2:1 or 3:1 advantage. The French more than tripled their forces during the war, while the Germans did not increase theirs as much; the number of 888,000 mobilized by the North German Union in August increased by only 2% after &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3+1\u20442 months, and by the end of the war, six months later, only by 15%, which did not even balance the losses incurred. Prussia was completely unaware of the feverish activity of permanent mobilization. This disparity in forces created a crisis for the Germans at the front in November 1870, which only the release of the large forces besieging the fortress of Metz allowed them to overcome.\nSiege of Paris.\nPrussian forces commenced the siege of Paris on 19 September 1870. Faced with the blockade, the new French government called for the establishment of several large armies in the French provinces. These new bodies of troops were to march towards Paris and attack the Germans there from various directions at the same time. Armed French civilians were to create a guerilla force\u2014the so-called \"Francs-tireurs\"\u2014for the purpose of attacking German supply lines.\nBismarck was an active supporter of the bombardment of the city. He sought to end the war as soon as possible, very much fearing a change in the international situation unfavorable to Prussia, as he himself called it \"the intervention of neutrals\". Therefore, Bismarck constantly and actively insisted on the early start of the bombardment, despite all the objections of the military command. Von Blumenthal, who commanded the siege, was opposed to the bombardment on moral grounds. In this he was backed by other senior military figures such as the Crown Prince and Moltke. Nevertheless, in January, the Germans fired some 12,000 shells (300\u2013400 daily) into the city.\nThe siege of the city caused great hardships for the population, especially for the poor from cold and hunger.\nLoire campaign.\nDispatched from Paris as the republican government emissary, L\u00e9on Gambetta flew over the German lines in a balloon inflated with coal gas from the city's gasworks and organized the recruitment of the Arm\u00e9e de la Loire. Rumors about an alleged German \"extermination\" plan infuriated the French and strengthened their support of the new regime. Within a few weeks, five new armies totalling more than 500,000 troops were recruited.\nThe Germans dispatched some of their troops to the French provinces to detect, attack and disperse the new French armies before they could become a menace. The Germans were not prepared for an occupation of the whole of France.\nOn 10 October, hostilities began between German and French republican forces near Orl\u00e9ans. At first, the Germans were victorious but the French drew reinforcements and defeated a Bavarian force at the Battle of Coulmiers on 9 November. After the surrender of Metz, more than 100,000 well-trained and experienced German troops joined the German 'Southern Army'. The French were forced to abandon Orl\u00e9ans on 4 December, and were finally defeated at the Battle of Le Mans (10\u201312 January). A second French army which operated north of Paris was turned back at the Battle of Amiens (27 November), the Battle of Bapaume (3 January 1871) and the Battle of St. Quentin (13 January).\nNorthern campaign.\nFollowing the Army of the Loire's defeats, Gambetta turned to General Faidherbe's Army of the North. The army had achieved several small victories at towns such as Ham, La Hallue, and Amiens and was protected by the belt of fortresses in northern France, allowing Faidherbe's men to launch quick attacks against isolated Prussian units, then retreat behind the fortresses. Despite access to the armaments factories of Lille, the Army of the North suffered from severe supply difficulties, which depressed morale. In January 1871, Gambetta forced Faidherbe to march his army beyond the fortresses and engage the Prussians in open battle. The army was severely weakened by low morale, supply problems, the terrible winter weather and low troop quality, whilst general Faidherbe was unable to command due to his poor health, the result of decades of campaigning in West Africa. At the Battle of St. Quentin, the Army of the North suffered a crushing defeat and was scattered, releasing thousands of Prussian soldiers to be relocated to the East.\nEastern campaign.\nFollowing the destruction of the French Army of the Loire, remnants of the Loire army gathered in eastern France to form the Army of the East, commanded by general Charles-Denis Bourbaki. In a final attempt to cut the German supply lines in northeast France, Bourbaki's army marched north to attack the Prussian siege of Belfort and relieve the defenders.\nThe French troops had a significant advantage (110 thousand soldiers against 40 thousand). The French offensive took the Germans by surprise and by mid-January 1871, the French had reached the Lisaine River, just a few kilometers from the besieged fortress of Belfort.\nIn the battle of the Lisaine, Bourbaki's men failed to break through German lines commanded by General August von Werder. Bringing in the German 'Southern Army', General von Manteuffel then drove Bourbaki's army into the mountains near the Swiss border. Bourbaki attempted to commit suicide, though survived his wound. Facing annihilation, the last intact French army of 87,000 men (now commanded by General Justin Clinchant) crossed the border and was disarmed and interned by the neutral Swiss near Pontarlier (1 February).\nThe besieged fortress of Belfort continued to resist until the signing of the armistice, repelling a German attempt to capture the fortress on 27 January, which was some consolation for the French in this stubborn and unhappy campaign.\nArmistice.\nOn 26 January 1871, the Government of National Defence based in Paris negotiated an armistice with the Prussians. With Paris starving, and Gambetta's provincial armies reeling from one disaster after another, French foreign minister Favre went to Versailles on 24 January to discuss peace terms with Bismarck. Bismarck agreed to end the siege and allow food convoys to immediately enter Paris (including trains carrying millions of German army rations), on condition that the Government of National Defence surrender several key fortresses outside Paris to the Prussians. Without the forts, the French Army would no longer be able to defend Paris.\nAlthough public opinion in Paris was strongly against any form of surrender or concession to the Prussians, the Government realised that it could not hold the city for much longer, and that Gambetta's provincial armies would probably never break through to relieve Paris. President Trochu resigned on 25 January and was replaced by Favre, who signed the surrender two days later at Versailles, with the armistice coming into effect at midnight.\nOn 28 January, a truce was concluded for 21 days, after the exhaustion of food and fuel supplies, the Paris garrison capitulated, the National Guard retained its weapons, while German troops occupied part of the forts of Paris to prevent the possibility of resuming hostilities. But military operations continued in the eastern part of the country, in the area of operation of the Bourbaki army. The French side, having no reliable information about the outcome of the struggle, insisted on excluding this area from the truce in the hope of a successful outcome of the struggle. The Germans did not dissuade the French.\nSeveral sources claim that in his carriage on the way back to Paris, Favre broke into tears, and collapsed into his daughter's arms as the guns around Paris fell silent at midnight. At Bordeaux, Gambetta received word from Paris on 29 January that the Government had surrendered. Furious, he refused to surrender. Jules Simon, a member of the Government arrived from Paris by train on 1 February to negotiate with Gambetta. Another group of three ministers arrived in Bordeaux on 5 February and the following day Gambetta stepped down and surrendered control of the provincial armies to the Government of National Defence, which promptly ordered a cease-fire across France.\nWar at sea.\nBlockade.\nWhen the war began, the French government ordered a blockade of the North German coasts, which the small North German Federal Navy with only five ironclads and various minor vessels could do little to oppose. For most of the war, the three largest German ironclads were out of service with engine troubles; only the turret ship was available to conduct operations. By the time engine repairs had been completed, the French fleet had already departed. The blockade proved only partially successful due to crucial oversights by the planners in Paris. Reservists that were supposed to be at the ready in case of war, were working in the Newfoundland fisheries or in Scotland. Only part of the 470-ship French Navy put to sea on 24 July. Before long, the French navy ran short of coal, needing per day and having a bunker capacity in the fleet of only . A blockade of Wilhelmshaven failed, and conflicting orders about operations in the Baltic Sea or a return to France made the French naval efforts futile. Spotting a blockade-runner became unwelcome because of the ; pursuit of Prussian ships quickly depleted the coal reserves of the French ships. But the main reason for the only partial success of the naval operation was the fear of the French command to risk political complications with Great Britain. This deterred the French command from trying to interrupt German trade under the British flag. Despite the limited measures of the blockade, it still created noticeable difficulties for German trade. \"The actual captures of German ships were eighty in number\".\nTo relieve pressure from the expected German attack into Alsace-Lorraine, Napoleon III and the French high command planned a seaborne invasion of northern Germany as soon as war began. The French expected the invasion to divert German troops and to encourage Denmark to join in the war, with its 50,000-strong army and the Royal Danish Navy. They discovered that Prussia had recently built defences around the big North German ports, including coastal artillery batteries with Krupp heavy artillery, which with a range of , had double the range of French naval guns. The French Navy lacked the heavy guns to engage the coastal defences and the topography of the Prussian coast made a seaborne invasion of northern Germany impossible.\nThe French Marines intended for the invasion of northern Germany were dispatched to reinforce the French Army of Ch\u00e2lons and fell into captivity at Sedan along with Napoleon III. A shortage of officers, following the capture of most of the professional French army at the siege of Metz and at the Battle of Sedan, led to naval officers being sent from their ships to command hastily assembled reservists of the \"Garde Mobile\". As the autumn storms of the North Sea forced the return of more of the French ships, the blockade of the north German ports diminished and in September 1870 the French navy abandoned the blockade for the winter. The rest of the navy retired to ports along the English Channel and remained in port for the rest of the war.\nPacific and Caribbean.\nOutside Europe, the French corvette \"Dupleix\" blockaded the German corvette in Nagasaki and the Battle of Havana took place between the Prussian gunboat and the French aviso \"Bouvet\" off Havana, Cuba, in November 1870.\nWar crimes.\nThe Franco-Prussian War of 1870\u201371 resulted in numerous war crimes committed by the Prussian army. One notable war crime committed during the conflict was the execution of prisoners of war. Reports indicate that several hundred French prisoners were summarily executed by Prussian soldiers. This included the execution of a group of over 200 French soldiers at the village of Dornach, which was subsequently referred to as the \"Dornach atrocities\".\nIn the small town of Bazeilles, near Sedan, French marines and partisans put up a resistance against a force of Bavarian soldiers. After the initial French resistance was overcome, the Bavarian troops shelled the village with artillery before sending in infantry to continue the assault. In battle, some surrendering soldiers were shot on the spot, and over 400 buildings were destroyed. The Bavarian troops detained around one hundred civilians, believing they illegally took part in the battle, only to release them unharmed the next day. After the war investigations established that 39 civilians were killed or wounded during the battle.\nPrussian soldiers were also accused of committing acts of violence against civilians, including murder, rape, and the destruction of property.\nAftermath.\nAnalysis.\nThe quick German victory over the French stunned neutral observers, many of whom had expected a French victory and a long war. The strategic advantages the Germans had were not appreciated outside Germany until after hostilities had ceased. Other countries quickly discerned the advantages given to the Germans by their military system, and adopted many of their innovations, particularly the general staff, universal conscription, and highly detailed mobilization systems.\nThe Prussian General Staff developed by Moltke proved to be extremely effective, in contrast to the traditional French school. This was in large part because the Prussian General Staff was created to study previous Prussian operations and learn to avoid mistakes. The structure also greatly strengthened Moltke's ability to control large formations spread out over significant distances. The Chief of the General Staff, effectively the commander in chief of the Prussian army, was independent of the minister of war and answered only to the monarch. The French General Staff\u2014along with those of every other European military\u2014was little better than a collection of assistants for the line commanders. This disorganization hampered the French commanders' ability to exercise control of their forces.\nIn addition, the Prussian military education system was superior to the French model; Prussian staff officers were trained to exhibit initiative and independent thinking. Indeed, this was Moltke's expectation. The French, meanwhile, suffered from an education and promotion system that stifled intellectual development. According to the military historian Dallas Irvine, the system: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;was almost completely effective in excluding the army's brain power from the staff and high command. To the resulting lack of intelligence at the top can be ascribed all the inexcusable defects of French military policy.\nAlbrecht von Roon, the Prussian Minister of War from 1859 to 1873, put into effect a series of reforms of the Prussian military system in the 1860s. Among these were two major reforms that substantially increased the military power of Germany. The first was a reorganization of the army that integrated the regular army and the \"Landwehr\" reserves. The second was the provision for the conscription of every male Prussian of military age in the event of mobilization. Thus, although the population of France was greater than the population of all of the Northern German states that participated in the war, the Germans mobilized more soldiers for battle.\nAt the start of the Franco-Prussian War, 462,000 German soldiers concentrated on the French frontier while only 270,000 French soldiers could be moved to face them, the French army having lost 100,000 stragglers before a shot was fired, through poor planning and administration. This was partly due to the peacetime organisations of the armies. Each Prussian Corps was based within a \"Kreis\" (literally \"circle\") around the chief city in an area. Reservists rarely lived more than a day's travel from their regiment's depot. By contrast, French regiments generally served far from their depots, which in turn were not in the areas of France from which their soldiers were drawn. Reservists often faced several days' journey to report to their depots, and then another long journey to join their regiments. Large numbers of reservists choked railway stations, vainly seeking rations and orders.\nThe effect of these differences was accentuated by the peacetime preparations. The Prussian General Staff had drawn up minutely detailed mobilization plans using the railway system, which in turn had been partly laid out in response to recommendations of a Railway Section within the General Staff. The French railway system, with competing companies, had developed purely from commercial pressures and many journeys to the front in Alsace and Lorraine involved long diversions and frequent changes between trains. There was no system of military control of the railways and officers simply commandeered trains as they saw fit. Rail sidings and marshalling yards became choked with loaded wagons, with nobody responsible for unloading them or directing them to the destination.\nFrance also suffered from an outdated tactical system. Although referred to as \"Napoleonic tactics\", this system was developed by Antoine-Henri Jomini during his time in Russia. Surrounded by a rigid aristocracy with a \"Sacred Social Order\" mentality, Jomini's system was equally rigid and inflexible. His system simplified several formations that were meant for an entire army, using battalions as the building blocks. His system was simple, but only strong enough to attack in one direction. The system was adopted by the Bourbons to prevent a repeat of when Napoleon I had returned to France, and Napoleon III retained the system upon his ascension to power (hence why they became associated with his family name). The Prussians in contrast did not use battalions as their basic tactical unit, and their system was much more flexible. Companies were formed into columns and attacked in parallel, rather than as a homogeneous battalion-sized block. Attacking in parallel allowed each company to choose its own axis of advance and make the most of local cover. It also permitted the Prussians to fire at oblique angles, raking the French lines with rifle fire. Thus, even though the Prussians had inferior rifles, they still inflicted more casualties with rifle fire than the French, with 53,900 French killed by the Dreyse (70% of their war casualties) versus 25,475 Germans killed by the Chassepot (96% of their war casualties).\nAlthough Austria-Hungary and Denmark had both wished to avenge their recent military defeats against Prussia, they chose not to intervene in the war due to a lack of confidence in the French. These countries did not have a documented alliance with France, and they were too late to start a war. After the rapid and stunning victories of Prussia, they preferred to abandon any plans to intervene in the war altogether. Napoleon III also failed to cultivate alliances with the Russian Empire and the United Kingdom, partially due to the diplomatic efforts of the Prussian chancellor Otto von Bismarck. Bismarck had bought Tsar Alexander II's complicity by promising to help restore his naval access to the Black Sea and Mediterranean (cut off by the treaties ending the Crimean War), other powers were less biddable. \"Seizing upon the distraction of the Franco-Prussian War, Russia in November 1870 had begun rebuilding its naval bases in the Black Sea, a clear violation of the treaty that had ended the Crimean War fourteen years earlier\". After the peace of Frankfurt in 1871, a rapprochement between France and Russia was born. \"Instead of forging ties with Russia in the east and further crippling France in the west, Bismarck's miscalculation had opened the door to future relations between Paris and St. Petersburg. The culmination of this new relationship will finally be the Franco-Russian Alliance of 1894; an alliance that explicitly refers to the perceived threat of Germany and its military response\".\nThe United Kingdom saw nothing wrong with the strengthening of Prussia on the European continent, viewing France as its traditional rival in international affairs. Lord Palmerston, the head of the British cabinet in 1865, wrote: \"The current Prussia is too weak to be honest and independent in its actions. And, taking into account the interests of the future, it is highly desirable for Germany as a whole became strong, so she was able to keep the ambitious and warlike nation, France, and Russia, which compress it from the West and the East\". English historians criticize the then British policy, pointing out that Palmerston misunderstood Bismarck's policy due to his adherence to outdated ideas. Over time, Britain began to understand that the military defeat of France meant a radical change in the European balance of power. In the future, the development of historical events is characterized by a gradual increase in Anglo-German contradictions. \"The colonial quarrels, naval rivalry and disagreement over the European balance of power which drove Britain and Germany apart, were in effect the strategical and geopolitical manifestations of the relative shift in the economic power of these two countries between 1860 and 1914\".\nAfter the Peace of Prague in 1866, the nominally independent German states of Saxony, Bavaria, W\u00fcrttemberg, Baden and Hesse-Darmstadt (the southern part that was not included in the North German Union) remained. Despite the fact that there was a strong opposition to Prussia in the ruling circles and in the war of 1866 they participated on the side of Austria against Prussia, they were forced to reckon with a broad popular movement in favor of German unity and were also afraid of angering their strong neighbor in the form of Prussia. After the diplomatic provocation in Bad Ems, these states had no room for maneuver, the war was presented by Bismarck as a war for national independence against an external enemy. All these states joined the Prussian war from the very beginning of hostilities. In January 1871, these states became part of the German Empire.\nThe French breech-loading rifle, the Chassepot, had a longer range than the German needle gun; compared to . The French also had an early machine-gun type weapon, the mitrailleuse, which could fire its thirty-seven barrels at a range of around . It was developed in such secrecy that little training with the weapon had occurred, leaving French gunners with little experience; the gun was treated like artillery and in this role it was ineffective. Worse still, once the small number of soldiers who had been trained how to use the new weapon became casualties, there were no replacements who knew how to operate the mitrailleuse.\nThe French were equipped with bronze, rifled muzzle-loading artillery, while the Prussians used new steel breech-loading guns, which had a far longer range and a faster rate of fire. Prussian gunners strove for a high rate of fire, which was discouraged in the French army in the belief that it wasted ammunition. In addition, the Prussian artillery batteries had 30% more guns than their French counterparts (8 guns per Prussian battery compared to 6 French guns). The Prussian guns typically opened fire at a range of , beyond the range of French artillery or the Chassepot rifle. The Prussian batteries could thus destroy French artillery with impunity, before being moved forward to directly support infantry attacks. The Germans fired 30,000,000 rounds of small arms ammunition and 362,662 field artillery rounds.\nEffects on military thought.\nThe events of the Franco-Prussian War had great influence on military thinking over the next forty years. Lessons drawn from the war included the need for a general staff system, the scale and duration of future wars and the tactical use of artillery and cavalry. The bold use of artillery by the Prussians, to silence French guns at long range and then to directly support infantry attacks at close range, proved to be superior to the defensive doctrine employed by French gunners. Likewise, the war showed that breech-loading cannons were superior to muzzle-loaded cannons, just as the Austro-Prussian War of 1866 had demonstrated for rifles. The Prussian tactics and designs were adopted by European armies by 1914, exemplified in the French 75, an artillery piece optimised to provide direct fire support to advancing infantry. Most European armies ignored the evidence of the Russo-Japanese War of 1904\u20131905 which suggested that infantry armed with new smokeless-powder rifles could engage gun crews effectively in the open. This forced gunners to fire at longer range using indirect fire, usually from a position of cover. The heavy use of fortifications and dugouts in the Russo-Japanese war also greatly undermined the usefulness of field artillery which was not designed for indirect fire.\nAt the Battle of Mars-La-Tour, the Prussian 12th Cavalry Brigade, commanded by General Adalbert von Bredow, conducted a charge against a French artillery battery. The attack was a costly success and came to be known as \"von Bredow's Death Ride\", but which nevertheless was held to prove that cavalry charges could still prevail on the battlefield. Use of traditional cavalry on the battlefields of 1914 proved to be disastrous, due to accurate, long-range rifle fire, machine-guns and artillery. Bredow's attack had succeeded only because of an unusually effective artillery bombardment just before the charge, along with favorable terrain that masked his approach.\nA third influence was the effect on notions of entrenchment and its limitations. While the American Civil War had famously involved entrenchment in the final years of the war, the Prussian system had overwhelmed French attempts to use similar tactics. With Prussian tactics seeming to make entrenchment and prolonged offensive campaigns ineffective, the experience of the American Civil War was seen as that of a musket war, not a rifle war. Many European armies were convinced of the viability of the \"cult of the offensive\" because of this, and focused their attention on aggressive bayonet charges over infantry fire. These would needlessly expose men to artillery fire in 1914, and entrenchment would return with a vengeance.\nCasualties.\nThe Germans deployed a total of 33,101 officers and 1,113,254 men into France, of whom they lost 1,046 officers and 16,539 enlisted men killed in action. Another 671 officers and 10,050 men died of their wounds, for total battle deaths of 28,306. Disease killed 207 officers and 11,940 men, with typhoid accounting for 6,965. 4,009 were missing and presumed dead; 290 died in accidents and 29 committed suicide. Among the missing and captured were 103 officers and 10,026 men. The wounded amounted to 3,725 officers and 86,007 men.\nFrench battle deaths were 77,000, of which 41,000 were killed in action and 36,000 died of wounds. More than 45,000 died of sickness. Total deaths were 138,871, with 136,540 being suffered by the army and 2,331 by the navy. The wounded totaled 137,626; 131,000 for the army and 6,526 for the navy. French prisoners of war numbered 383,860. In addition, 90,192 French soldiers were interned in Switzerland and 6,300 in Belgium.\nDuring the war the International Committee of the Red Cross (ICRC) established an international tracing agency in Basel for prisoners of that war. The holdings of the \"Basel Agency\" were later transferred to the ICRC headquarters in Geneva and integrated into the ICRC archives, where they are accessible today.\nSubsequent events.\nPrussian reaction and withdrawal.\nThe Prussian Army, under the terms of the armistice, held a brief victory parade in Paris on 1 March; the city was silent and draped with black and the Germans quickly withdrew. Bismarck honoured the armistice, by allowing train loads of food into Paris and withdrawing Prussian forces to the east of the city, prior to a full withdrawal once France agreed to pay a five billion franc war indemnity. The indemnity was proportioned, according to population, to be the exact equivalent to the indemnity imposed by Napoleon on Prussia in 1807. At the same time, Prussian forces were concentrated in the provinces of Alsace and Lorraine. An exodus occurred from Paris as some 200,000 people, predominantly middle-class, went to the countryside.\nParis Commune.\nDuring the war, the Paris National Guard, particularly in the working-class neighbourhoods of Paris, had become highly politicised and units elected officers; many refused to wear uniforms or obey commands from the national government. National guard units tried to seize power in Paris on 31 October 1870 and 22 January 1871. On 18 March 1871, when the regular army tried to remove cannons from an artillery park on Montmartre, National Guard units resisted and killed two army generals. The national government and regular army forces retreated to Versailles and a revolutionary government was proclaimed in Paris. A commune was elected, which was dominated by socialists, anarchists and revolutionaries. The red flag replaced the French tricolour and a civil war began between the Commune and the regular army, which attacked and recaptured Paris from 21\u201328 May in the (\"bloody week\").\nDuring the fighting, the Communards killed around 500 people, including Georges Darboy, the Archbishop of Paris, and burned down many government buildings, including the Tuileries Palace and the Hotel de Ville. Communards captured with weapons were routinely shot by the army and Government troops killed between 7,000 and 30,000 Communards, both during the fighting and in massacres of men, women, and children during and after the Commune. More recent histories, based on studies of the number buried in Paris cemeteries and in mass graves after the fall of the Commune, put the number killed at between 6,000 and 10,000. Twenty-six courts were established to try more than 40,000 people who had been arrested, which took until 1875 and imposed 95 death sentences, of which 23 were inflicted. Forced labour for life was imposed on 251 people, 1,160 people were transported to \"a fortified place\" and 3,417 people were transported . About 20,000 Communards were held in prison hulks until released in 1872 and a great many Communards fled abroad to the United Kingdom, Switzerland, Belgium or the United States. The survivors were amnestied by a bill introduced by Gambetta in 1880 and allowed to return.\n1871 Kabyle revolt.\nIn 1830, the French army invaded and conquered the Beylik of Algiers. Afterwards, France colonized the country, setting up its own administration over Algeria. The withdrawal of a large proportion of the army stationed in French Algeria to serve in the Franco-Prussian War had weakened France's control of the territory, while reports of defeats undermined French prestige amongst the indigenous population. The most serious native insurrection since the time of Emir Abdelkader was the 1871 Mokrani Revolt in the Kabylia, which spread through much of Algeria. By April 1871, 250 tribes had risen, or nearly a third of Algeria's population.\nGerman unification and power.\nThe creation of a unified German Empire (which excluded Austria) greatly disturbed the balance of power that had been created with the Congress of Vienna after the end of the Napoleonic Wars. Germany had established itself as a major power in continental Europe, boasting one of the most powerful and professional armies in the world. Although the UK remained the dominant world power overall, British involvement in European affairs during the late 19th century was limited, owing to its focus on colonial empire-building, allowing Germany to exercise great influence over the European mainland. Anglo-German straining of tensions was somewhat mitigated by several prominent relationships between the two powers, such as the Crown Prince's marriage with the daughter of Queen Victoria.\n\"Einheit\"\u2014unity\u2014was achieved at the expense of \"Freiheit\"\u2014freedom. According to Karl Marx, the German Empire became \"a military despotism cloaked in parliamentary forms with a feudal ingredient, influenced by the bourgeoisie, festooned with bureaucrats and guarded by police.\" Likewise, many historians would see Germany's \"escape into war\" in 1914 as a flight from all of the internal-political contradictions forged by Bismarck at Versailles in the fall of 1870.\nFrench reaction and Revanchism.\nThe defeat in the Franco-Prussian War led to the birth of Revanchism (literally, \"revenge-ism\") in France, characterised by a deep sense of bitterness, hatred and demand for revenge against Germany. This was particularly manifested in loose talk of another war with Germany in order to reclaim Alsace and Lorraine. It also led to the development of nationalist ideologies emphasising \"the ideal of the guarded, self-referential nation schooled in the imperative of war\", an ideology epitomised by figures such as General Georges Ernest Boulanger in the 1880s. Paintings that emphasized the humiliation of the defeat became in high demand, such as those by Alphonse de Neuville.\nRevanchism was not a major cause of war in 1914 because it faded after 1880. J.F.V. Keiger says, \"By the 1880s Franco-German relations were relatively good.\" The French public had very little interest in foreign affairs and elite French opinion was strongly opposed to war with its more powerful neighbor. The elites were now calm and considered it a minor issue. The Alsace-Lorraine issue remained a minor theme after 1880, and Republicans and Socialists systematically downplayed the issue. Return did not become a French war aim until after World War I began.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBooks.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nJournals.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nWebsites.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\nBooks and journals.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nCaricatures and editorial cartoons.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "44039", "revid": "29615425", "url": "https://en.wikipedia.org/wiki?curid=44039", "title": "Fugue (music)", "text": ""}
{"id": "44040", "revid": "4899266", "url": "https://en.wikipedia.org/wiki?curid=44040", "title": "Fugue (psychology)", "text": ""}
{"id": "44041", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=44041", "title": "Solvation", "text": "Association of molecules of a solvent with molecules or ions of a solute\nSolvations describes the interaction of a solvent with dissolved molecules. Both ionized and uncharged molecules interact strongly with a solvent, and the strength and nature of this interaction influence many properties of the solute, including solubility, reactivity, and color, as well as influencing the properties of the solvent such as its viscosity and density. If the attractive forces between the solvent and solute particles are greater than the attractive forces holding the solute particles together, the solvent particles pull the solute particles apart and surround them. The surrounded solute particles then move away from the solid solute and out into the solution. Ions are surrounded by a concentric shell of solvent. Solvation is the process of reorganizing solvent and solute molecules into solvation complexes and involves bond formation, hydrogen bonding, and van der Waals forces. Solvation of a solute by water is called hydration.\nSolubility of solid compounds depends on a competition between lattice energy and solvation, including entropy effects related to changes in the solvent structure.\nDistinction from solubility.\nBy an IUPAC definition, solvation is an interaction of a solute with the solvent, which leads to stabilization of the solute species in the solution. In the solvated state, an ion or molecule in a solution is surrounded or complexed by solvent molecules. Solvated species can often be described by coordination number, and the complex stability constants. The concept of the solvation interaction can also be applied to an insoluble material, for example, solvation of functional groups on a surface of ion-exchange resin.\nSolvation is, in concept, distinct from solubility. Solvation or dissolution is a kinetic process and is quantified by its rate. Solubility quantifies the dynamic equilibrium state achieved when the rate of dissolution equals the rate of precipitation. The consideration of the units makes the distinction clearer. The typical unit for dissolution rate is mol/s. The units for solubility express a concentration: mass per volume (mg/mL), molarity (mol/L), etc.\nSolvents and intermolecular interactions.\nSolvation involves different types of intermolecular interactions: \nWhich of these forces are at play depends on the molecular structure and properties of the solvent and solute. The similarity or complementary character of these properties between solvent and solute determines how well a solute can be solvated by a particular solvent.\nSolvent polarity is the most important factor in determining how well it solvates a particular solute. Polar solvents have molecular dipoles, meaning that part of the solvent molecule has more electron density than another part of the molecule. The part with more electron density will experience a partial negative charge while the part with less electron density will experience a partial positive charge. Polar solvent molecules can solvate polar solutes and ions because they can orient the appropriate partially charged portion of the molecule towards the solute through electrostatic attraction. This stabilizes the system and creates a solvation shell (or hydration shell in the case of water) around each particle of solute. The solvent molecules in the immediate vicinity of a solute particle often have a much different ordering than the rest of the solvent, and this area of differently ordered solvent molecules is called the cybotactic region. Water is the most common and well-studied polar solvent, but others exist, such as ethanol, methanol, acetone, acetonitrile, and dimethyl sulfoxide. Polar solvents are often found to have a high dielectric constant, although other solvent scales are also used to classify solvent polarity. Polar solvents can be used to dissolve inorganic or ionic compounds such as salts. The conductivity of a solution depends on the solvation of its ions. Nonpolar solvents cannot solvate ions, and ions will be found as ion pairs.\nHydrogen bonding among solvent and solute molecules depends on the ability of each to accept H-bonds, donate H-bonds, or both. Solvents that can donate H-bonds are referred to as protic, while solvents that do not contain a polarized bond to a hydrogen atom and cannot donate a hydrogen bond are called aprotic. H-bond donor ability is classified on a scale (\u03b1). Protic solvents can solvate solutes that can accept hydrogen bonds. Similarly, solvents that can accept a hydrogen bond can solvate H-bond-donating solutes. The hydrogen bond acceptor ability of a solvent is classified on a scale (\u03b2). Solvents such as water can both donate and accept hydrogen bonds, making them excellent at solvating solutes that can donate or accept (or both) H-bonds.\nSome chemical compounds experience solvatochromism, which is a change in color due to solvent polarity. This phenomenon illustrates how different solvents interact differently with the same solute. Other solvent effects include conformational or isomeric preferences and changes in the acidity of a solute.\nSolvation energy and thermodynamic considerations.\nThe solvation process will be thermodynamically favored only if the overall Gibbs energy of the solution is decreased, compared to the Gibbs energy of the separated solvent and solid (or gas or liquid). This means that the change in enthalpy minus the change in entropy (multiplied by the absolute temperature) is a negative value, or that the Gibbs energy of the system decreases. A negative Gibbs energy indicates a spontaneous process but does not provide information about the rate of dissolution.\nSolvation involves multiple steps with different energy consequences. First, a cavity must form in the solvent to make space for a solute. This is both entropically and enthalpically unfavorable, as solvent ordering increases and solvent-solvent interactions decrease. Stronger interactions among solvent molecules leads to a greater enthalpic penalty for cavity formation. Next, a particle of solute must separate from the bulk. This is enthalpically unfavorable since solute-solute interactions decrease, but when the solute particle enters the cavity, the resulting solvent-solute interactions are enthalpically favorable. Finally, as solute mixes into solvent, there is an entropy gain.\nThe enthalpy of solution is the solution enthalpy minus the enthalpy of the separate systems, whereas the entropy of solution is the corresponding difference in entropy. The solvation energy (change in Gibbs free energy) is the change in enthalpy minus the product of temperature (in Kelvin) times the change in entropy. Gases have a negative entropy of solution, due to the decrease in gaseous volume as gas dissolves. Since their enthalpy of solution does not decrease too much with temperature, and their entropy of solution is negative and does not vary appreciably with temperature, most gases are less soluble at higher temperatures.\nEnthalpy of solvation can help explain why solvation occurs with some ionic lattices but not with others. The difference in energy between that which is necessary to release an ion from its lattice and the energy given off when it combines with a solvent molecule is called the enthalpy change of solution. A negative value for the enthalpy change of solution corresponds to an ion that is likely to dissolve, whereas a high positive value means that solvation will not occur. It is possible that an ion will dissolve even if it has a positive enthalpy value. The extra energy required comes from the increase in entropy that results when the ion dissolves. The introduction of entropy makes it harder to determine by calculation alone whether a substance will dissolve or not. A quantitative measure for solvation power of solvents is given by donor numbers.\nAlthough early thinking was that a higher ratio of a cation's ion charge to ionic radius, or the charge density, resulted in more solvation, this does not stand up to scrutiny for ions like iron(III) or lanthanides and actinides, which are readily hydrolyzed to form insoluble (hydrous) oxides. As these are solids, it is apparent that they are not solvated.\nStrong solvent\u2013solute interactions make the process of solvation more favorable. One way to compare how favorable the dissolution of a solute is in different solvents is to consider the free energy of transfer. The free energy of transfer quantifies the free energy difference between dilute solutions of a solute in two different solvents. This value essentially allows for comparison of solvation energies without including solute-solute interactions.\nIn general, thermodynamic analysis of solutions is done by modeling them as reactions. For example, if you add sodium chloride to water, the salt will dissociate into the ions sodium(+aq) and chloride(-aq). The equilibrium constant for this dissociation can be predicted by the change in Gibbs energy of this reaction.\nThe Born equation is used to estimate Gibbs free energy of solvation of a gaseous ion.\nRecent simulation studies have shown that the variation in solvation energy between the ions and the surrounding water molecules underlies the mechanism of the Hofmeister series.\nMacromolecules and assemblies.\nSolvation (specifically, hydration) is important for many biological structures and processes. For instance, solvation of ions and/or of charged macromolecules, like DNA and proteins, in aqueous solutions influences the formation of heterogeneous assemblies, which may be responsible for biological function. As another example, protein folding occurs spontaneously, in part because of a favorable change in the interactions between the protein and the surrounding water molecules. Folded proteins are stabilized by 5-10 kcal/mol relative to the unfolded state due to a combination of solvation and the stronger intramolecular interactions in the folded protein structure, including hydrogen bonding. Minimizing the number of hydrophobic side chains exposed to water by burying them in the center of a folded protein is a driving force related to solvation.\nSolvation also affects host\u2013guest complexation. Many host molecules have a hydrophobic pore that readily encapsulates a hydrophobic guest. These interactions can be used in applications such as drug delivery, such that a hydrophobic drug molecule can be delivered in a biological system without needing to covalently modify the drug in order to solubilize it. Binding constants for host\u2013guest complexes depend on the polarity of the solvent.\nHydration affects electronic and vibrational properties of biomolecules.\nImportance of solvation in computer simulations.\nDue to the importance of the effects of solvation on the structure of macromolecules, early computer simulations which attempted to model their behaviors without including the effects of solvent (\"in vacuo\") could yield poor results when compared with experimental data obtained in solution. Small molecules may also adopt more compact conformations when simulated \"in vacuo\"; this is due to favorable van der Waals interactions and intramolecular electrostatic interactions which would be dampened in the presence of a solvent.\nAs computer power increased, it became possible to try and incorporate the effects of solvation within a simulation and the simplest way to do this is to surround the molecule being simulated with a \"skin\" of solvent molecules, akin to simulating the molecule within a drop of solvent if the skin is sufficiently deep.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44042", "revid": "7098284", "url": "https://en.wikipedia.org/wiki?curid=44042", "title": "Rubi", "text": "Rub\u00ed or Rubi may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "44043", "revid": "41042136", "url": "https://en.wikipedia.org/wiki?curid=44043", "title": "Rawa", "text": "Rawa may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "44044", "revid": "30292728", "url": "https://en.wikipedia.org/wiki?curid=44044", "title": "Oceanography", "text": "Study of physical, chemical, and biological processes in the ocean\nOceanography (from grc \" ' ()\"\u00a0'ocean' and \" ' ()\"\u00a0'writing'), also known as oceanology, sea science, ocean science, and marine science, is the scientific study of the ocean, including its physics, chemistry, biology, and geology. \nIt is an Earth science, which covers a wide range of topics, including ocean currents, waves, and geophysical fluid dynamics; fluxes of various chemical substances and physical properties within the ocean and across its boundaries; ecosystem dynamics; and plate tectonics and seabed geology. \nOceanographers draw upon a wide range of disciplines to deepen their understanding of the world\u2019s oceans, incorporating insights from astronomy, biology, chemistry, geography, geology, hydrology, meteorology and physics.\nHistory.\nEarly history.\nHumans first acquired knowledge of the waves and currents of the seas and oceans in pre-historic times. Observations on tides were recorded by Aristotle and Strabo in 384\u2013322 BC. Early exploration of the oceans was primarily for cartography and mainly limited to its surfaces and of the animals that fishermen brought up in nets, though depth soundings by lead line were taken.\nThe Portuguese campaign of Atlantic navigation is the earliest example of a systematic scientific large project, sustained over many decades, studying the currents and winds of the Atlantic.\nThe work of Pedro Nunes (1502\u20131578) is remembered in the navigation context for the determination of the loxodromic curve: the shortest course between two points on the surface of a sphere represented onto a two-dimensional map. When he published his \"Treatise of the Sphere\" (1537), mostly a commentated translation of earlier work by others, he included a treatise on geometrical and astronomic methods of navigation. There he states clearly that Portuguese navigations were not an adventurous endeavour:\n\"nam se fezeram indo a acertar: mas partiam os nossos mareantes muy ensinados e prouidos de estromentos e regras de astrologia e geometria que sam as cousas que os cosmographos ham dadar apercebidas (...) e leuaua cartas muy particularmente rumadas e na ja as de que os antigos vsauam\" (were not done by chance: but our seafarers departed well taught and provided with instruments and rules of astrology (astronomy) and geometry which were matters the cosmographers would provide (...) and they took charts with exact routes and no longer those used by the ancient).\nHis credibility rests on being personally involved in the instruction of pilots and senior seafarers from 1527 onwards by Royal appointment, along with his recognized competence as mathematician and astronomer.\nThe main problem in navigating back from the south of the Canary Islands (or south of Boujdour) by sail alone, is due to the change in the regime of winds and currents: the North Atlantic gyre and the Equatorial counter current will push south along the northwest bulge of Africa, while the uncertain winds where the Northeast trades meet the Southeast trades (the doldrums) leave a sailing ship to the mercy of the currents. Together, prevalent current and wind make northwards progress very difficult or impossible. It was to overcome this problem and clear the passage to India around Africa as a viable maritime trade route, that a systematic plan of exploration was devised by the Portuguese. The return route from regions south of the Canaries became the 'volta do largo' or 'volta do mar'. The 'rediscovery' of the Azores islands in 1427 is merely a reflection of the heightened strategic importance of the islands, now sitting on the return route from the western coast of Africa (sequentially called 'volta de Guin\u00e9' and 'volta da Mina'); and the references to the Sargasso Sea (also called at the time 'Mar da Baga'), to the west of the Azores, in 1436, reveals the western extent of the return route. This is necessary, under sail, to make use of the southeasterly and northeasterly winds away from the western coast of Africa, up to the northern latitudes where the westerly winds will bring the seafarers towards the western coasts of Europe.\nThe secrecy involving the Portuguese navigations, with the death penalty for the leaking of maps and routes, concentrated all sensitive records in the Royal Archives, completely destroyed by the Lisbon earthquake of 1775. However, the systematic nature of the Portuguese campaign, mapping the currents and winds of the Atlantic, is demonstrated by the understanding of the seasonal variations, with expeditions setting sail at different times of the year taking different routes to take account of seasonal predominate winds. This happens from as early as late 15th century and early 16th: Bartolomeu Dias followed the African coast on his way south in August 1487, while Vasco da Gama would take an open sea route from the latitude of Sierra Leone, spending three months in the open sea of the South Atlantic to profit from the southwards deflection of the southwesterly on the Brazilian side (and the Brazilian current going southward - Gama departed in July 1497); and Pedro \u00c1lvares Cabral (departing March 1500) took an even larger arch to the west, from the latitude of Cape Verde, thus avoiding the summer monsoon (which would have blocked the route taken by Gama at the time he set sail). Furthermore, there were systematic expeditions pushing into the western Northern Atlantic (Teive, 1454; Vogado, 1462; Teles, 1474; Ulmo, 1486).\nThe documents relating to the supplying of ships, and the ordering of sun declination tables for the southern Atlantic for as early as 1493\u20131496, all suggest a well-planned and systematic activity happening during the decade long period between Bartolomeu Dias finding the southern tip of Africa, and Gama's departure; additionally, there are indications of further travels by Bartolomeu Dias in the area. The most significant consequence of this systematic knowledge was the negotiation of the Treaty of Tordesillas in 1494, moving the line of demarcation 270 leagues to the west (from 100 to 370 leagues west of the Azores), bringing what is now Brazil into the Portuguese area of domination. The knowledge gathered from open sea exploration allowed for the well-documented extended periods of sail without sight of land, not by accident but as pre-determined planned route; for example, 30 days for Bartolomeu Dias culminating on Mossel Bay, the three months Gama spent in the South Atlantic to use the Brazil current (southward), or the 29 days Cabral took from Cape Verde up to landing in Monte Pascoal, Brazil.\nThe Danish expedition to Arabia 1761\u201367 can be said to be the world's first oceanographic expedition, as the ship Gr\u00f8nland had on board a group of scientists, including naturalist Peter Forssk\u00e5l, who was assigned an explicit task by the king, Frederik V, to study and describe the marine life in the open sea, including finding the cause of mareel, or milky seas. For this purpose, the expedition was equipped with nets and scrapers, specifically designed to collect samples from the open waters and the bottom at great depth.\nAlthough Juan Ponce de Le\u00f3n in 1513 first identified the Gulf Stream, and the current was well known to mariners, Benjamin Franklin made the first scientific study of it and gave it its name. Franklin measured water temperatures during several Atlantic crossings and correctly explained the Gulf Stream's cause. Franklin and Timothy Folger printed the first map of the Gulf Stream in 1769\u20131770.\nInformation on the currents of the Pacific Ocean was gathered by explorers of the late 18th century, including James Cook and Louis Antoine de Bougainville. James Rennell wrote the first scientific textbooks on oceanography, detailing the current flows of the Atlantic and Indian oceans. During a voyage around the Cape of Good Hope in 1777, he mapped \"the banks and currents at the Lagullas\". He was also the first to understand the nature of the intermittent current near the Isles of Scilly, (now known as Rennell's Current). The tides and currents of the ocean are distinct. Tides are the rise and fall of sea levels created by the combination of the gravitational forces of the Moon along with the Sun (the Sun just in a much lesser extent) and are also caused by the Earth and Moon orbiting each other. An ocean current is a continuous, directed movement of seawater generated by a number of forces acting upon the water, including wind, the Coriolis effect, breaking waves, cabbeling, and temperature and salinity differences.\nSir James Clark Ross took the first modern sounding in deep sea in 1840, and Charles Darwin published a paper on reefs and the formation of atolls as a result of the second voyage of HMS \"Beagle\" in 1831\u20131836. Robert FitzRoy published a four-volume report of \"Beagle\"'s three voyages. In 1841\u20131842 Edward Forbes undertook dredging in the Aegean Sea that founded marine ecology.\nThe first superintendent of the United States Naval Observatory (1842\u20131861), Matthew Fontaine Maury devoted his time to the study of marine meteorology, navigation, and charting prevailing winds and currents. His 1855 textbook \"Physical Geography of the Sea\" was one of the first comprehensive oceanography studies. Many nations sent oceanographic observations to Maury at the Naval Observatory, where he and his colleagues evaluated the information and distributed the results worldwide.\nModern oceanography.\nKnowledge of the oceans remained confined to the topmost few fathoms of the water and a small amount of the bottom, mainly in shallow areas. Almost nothing was known of the ocean depths. The British Royal Navy's efforts to chart all of the world's coastlines in the mid-19th century reinforced the vague idea that most of the ocean was very deep, although little more was known. As exploration ignited both popular and scientific interest in the polar regions and Africa, so too did the mysteries of the unexplored oceans.\nThe seminal event in the founding of the modern science of oceanography was the 1872\u20131876 \" Challenger\" expedition. As the first true oceanographic cruise, this expedition laid the groundwork for an entire academic and research discipline. In response to a recommendation from the Royal Society, the British Government announced in 1871 an expedition to explore world's oceans and conduct appropriate scientific investigation. Charles Wyville Thomson and Sir John Murray launched the \"Challenger\" expedition. , leased from the Royal Navy, was modified for scientific work and equipped with separate laboratories for natural history and chemistry. Under the scientific supervision of Thomson, \"Challenger\" travelled nearly surveying and exploring. On her journey circumnavigating the globe, 492\u00a0deep sea soundings, 133\u00a0bottom dredges, 151\u00a0open water trawls and 263\u00a0serial water temperature observations were taken. Around 4,700\u00a0new species of marine life were discovered. The result was the \"Report Of The Scientific Results of the Exploring Voyage of H.M.S. Challenger during the years 1873\u201376\". Murray, who supervised the publication, described the report as \"the greatest advance in the knowledge of our planet since the celebrated discoveries of the fifteenth and sixteenth centuries\". He went on to found the academic discipline of oceanography at the University of Edinburgh, which remained the centre for oceanographic research well into the 20th century. Murray was the first to study marine trenches and in particular the Mid-Atlantic Ridge, and map the sedimentary deposits in the oceans. He tried to map out the world's ocean currents based on salinity and temperature observations, and was the first to correctly understand the nature of coral reef development.\nIn the late 19th century, other Western nations also sent out scientific expeditions (as did private individuals and institutions). The first purpose-built oceanographic ship, \"Albatros\", was built in 1882. In 1893, Fridtjof Nansen allowed his ship, \"Fram\", to be frozen in the Arctic ice. This enabled him to obtain oceanographic, meteorological and astronomical data at a stationary spot over an extended period.\nIn 1881 the geographer John Francon Williams published a seminal book, \"Geography of the Oceans\". Between 1907 and 1911 Otto Kr\u00fcmmel published the \"Handbuch der Ozeanographie\", which became influential in awakening public interest in oceanography. The four-month 1910 North Atlantic expedition headed by John Murray and Johan Hjort was the most ambitious research oceanographic and marine zoological project ever mounted until then, and led to the classic 1912 book \"The Depths of the Ocean\".\nThe first acoustic measurement of sea depth was made in 1914. Between 1925 and 1927 the \"Meteor\" expedition gathered 70,000 ocean depth measurements using an echo sounder, surveying the Mid-Atlantic Ridge.\nIn 1934, Easter Ellen Cupp, the first woman to have earned a PhD (at Scripps) in the United States, completed a major work on diatoms that remained the standard taxonomy in the field until well after her death in 1999. In 1940, Cupp was let go from her position at Scripps. Sverdrup specifically commended Cupp as a conscientious and industrious worker and commented that his decision was no reflection on her ability as a scientist. Sverdrup used the instructor billet vacated by Cupp to employ Marston Sargent, a biologist studying marine algae, which was not a new research program at Scripps. Financial pressures did not prevent Sverdrup from retaining the services of two other young post-doctoral students, Walter Munk and Roger Revelle. Cupp's partner, Dorothy Rosenbury, found her a position teaching high school, where she remained for the rest of her career. (Russell, 2000)\nSverdrup, Johnson and Fleming published \"The Oceans\" in 1942, which was a major landmark. \"The Sea\" (in three volumes, covering physical oceanography, seawater and geology) edited by M.N. Hill was published in 1962, while Rhodes Fairbridge's \"Encyclopedia of Oceanography\" was published in 1966.\nThe Great Global Rift, running along the Mid Atlantic Ridge, was discovered by Maurice Ewing and Bruce Heezen in 1953 and mapped by Heezen and Marie Tharp using bathymetric data; in 1954 a mountain range under the Arctic Ocean was found by the Arctic Institute of the USSR. The theory of seafloor spreading was developed in 1960 by Harry Hammond Hess. The Ocean Drilling Program started in 1966. Deep-sea vents were discovered in 1977 by Jack Corliss and Robert Ballard in the submersible .\nIn the 1950s, Auguste Piccard invented the bathyscaphe and used the bathyscaphe to investigate the ocean's depths. The United States nuclear submarine made the first journey under the ice to the North Pole in 1958. In 1962 the FLIP (Floating Instrument Platform), a spar buoy, was first deployed.\nIn 1968, Tanya Atwater led the first all-woman oceanographic expedition. Until that time, gender policies restricted women oceanographers from participating in voyages to a significant extent.\nFrom the 1970s, there has been much emphasis on the application of large scale computers to oceanography to allow numerical predictions of ocean conditions and as a part of overall environmental change prediction. Early techniques included analog computers (such as the Ishiguro Storm Surge Computer) generally now replaced by numerical methods (e.g. SLOSH.) An oceanographic buoy array was established in the Pacific to allow prediction of El Ni\u00f1o events.\n1990 saw the start of the World Ocean Circulation Experiment (WOCE) which continued until 2002. Geosat seafloor mapping data became available in 1995.\nStudy of the oceans is critical to understanding shifts in Earth's energy balance along with related global and regional changes in climate, the biosphere and biogeochemistry. The atmosphere and ocean are linked because of evaporation and precipitation as well as thermal flux (and solar insolation). Recent studies have advanced knowledge on ocean acidification, ocean heat content, ocean currents, sea level rise, the oceanic carbon cycle, the water cycle, Arctic sea ice decline, coral bleaching, marine heatwaves, extreme weather, coastal erosion and many other phenomena in regards to ongoing climate change and climate feedbacks.\nIn general, understanding the world ocean through further scientific study enables better stewardship and sustainable utilization of Earth's resources. The Intergovernmental Oceanographic Commission reports that 1.7% of the total national research expenditure of its members is focused on ocean science.\nBranches.\nThe study of oceanography is divided into these five branches:\nBiological oceanography.\nBiological oceanography investigates the ecology and biology of marine organisms in the context of the physical, chemical and geological characteristics of their ocean environment.\nChemical oceanography.\nChemical oceanography is the study of the chemistry of the ocean. Whereas chemical oceanography is primarily occupied with the study and understanding of seawater properties and its changes, ocean chemistry focuses primarily on the geochemical cycles. The following is a central topic investigated by chemical oceanography.\nOcean acidification.\nOcean acidification describes the decrease in ocean pH that is caused by anthropogenic carbon dioxide (CO2) emissions into the atmosphere. Seawater is slightly alkaline and had a preindustrial pH of about 8.2. More recently, anthropogenic activities have steadily increased the carbon dioxide content of the atmosphere; about 30\u201340% of the added CO2 is absorbed by the oceans, forming carbonic acid and lowering the pH (now below 8.1) through ocean acidification. The pH is expected to reach 7.7 by the year 2100.\nAn important element for the skeletons of marine animals is calcium, but calcium carbonate becomes more soluble with pressure, so carbonate shells and skeletons dissolve below the carbonate compensation depth. Calcium carbonate becomes more soluble at lower pH, so ocean acidification is likely to affect marine organisms with calcareous shells, such as oysters, clams, sea urchins and corals, and the carbonate compensation depth will rise closer to the sea surface. Affected planktonic organisms will include pteropods, coccolithophorids and foraminifera, all important in the food chain. In tropical regions, corals are likely to be severely affected as they become less able to build their calcium carbonate skeletons, in turn adversely impacting other reef dwellers.\nThe current rate of ocean chemistry change seems to be unprecedented in Earth's geological history, making it unclear how well marine ecosystems will adapt to the shifting conditions of the near future. Of particular concern is the manner in which the combination of acidification with the expected additional stressors of higher ocean temperatures and lower oxygen levels will impact the seas.\nGeological oceanography.\nGeological oceanography is the study of the geology of the ocean floor including plate tectonics and paleoceanography.\nPhysical oceanography.\nPhysical oceanography studies the ocean's physical attributes including temperature-salinity structure, mixing, surface waves, internal waves, surface tides, internal tides, and currents. The following are central topics investigated by physical oceanography.\nOcean currents.\nSince the early ocean expeditions in oceanography, a major interest was the study of ocean currents and temperature measurements. The tides, the Coriolis effect, changes in direction and strength of wind, salinity, and temperature are the main factors determining ocean currents. The thermohaline circulation (THC) (\"thermo-\" referring to temperature and \"-haline\" referring to salt content) connects the ocean basins and is primarily dependent on the density of sea water. It is becoming more common to refer to this system as the 'meridional overturning circulation' because it more accurately accounts for other driving factors beyond temperature and salinity. \nOcean heat content.\nOceanic heat content (OHC) refers to the extra heat stored in the ocean from changes in Earth's energy balance. The increase in the ocean heat play an important role in sea level rise, because of thermal expansion. Ocean warming accounts for 90% of the energy accumulation associated with global warming since 1971.\nPaleoceanography.\nPaleoceanography is the study of the history of the oceans in the geologic past with regard to circulation, chemistry, biology, geology and patterns of sedimentation and biological productivity. Paleoceanographic studies using environment models and different proxies enable the scientific community to assess the role of the oceanic processes in the global climate by the reconstruction of past climate at various intervals. Paleoceanographic research is also intimately tied to palaeoclimatology.\nOceanographic institutions.\nThe earliest international organizations of oceanography were founded at the turn of the 20th century, starting with the International Council for the Exploration of the Sea created in 1902, followed in 1919 by the Mediterranean Science Commission. Marine research institutes were already in existence, starting with the Stazione Zoologica Anton Dohrn in Naples, Italy (1872), the Biological Station of Roscoff, France (1876), the Arago Laboratory in Banyuls-sur-mer, France (1882), the Laboratory of the Marine Biological Association in Plymouth, UK (1884), the Norwegian Institute for Marine Research in Bergen, Norway (1900), the Laboratory f\u00fcr internationale Meeresforschung, Kiel, Germany (1902). On the other side of the Atlantic, the Scripps Institution of Oceanography was founded in 1903, followed by the Woods Hole Oceanographic Institution in 1930, the Virginia Institute of Marine Science in 1938, the Lamont\u2013Doherty Earth Observatory at Columbia University in 1949, and later the School of Oceanography at University of Washington. In Australia, the Australian Institute of Marine Science (AIMS), established in 1972 soon became a key player in marine tropical research.\nIn 1921 the International Hydrographic Bureau, called since 1970 the International Hydrographic Organization, was established to develop hydrographic and nautical charting standards.\nRelated disciplines.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44048", "revid": "48328727", "url": "https://en.wikipedia.org/wiki?curid=44048", "title": "Northern Province", "text": "Northern Province or North Province may refer to:\nIn fiction, \"North Province\" may refer to:\nSee also.\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about distinct geographical locations with the same name. "}
{"id": "44049", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=44049", "title": "Chiricahua", "text": "Band of Apache Native Americans\nChiricahua ( ) is a band of Apache Native Americans.\nBased in the Southern Plains and Southwestern United States, the Chiricahua historically shared a common area, language, customs, and intertwined family relations with their fellow Apaches. At the time of European contact, they had a territory of in Southwestern New Mexico and Southeastern Arizona in the United States and in Northern Sonora and Chihuahua in Mexico.\nToday Chiricahua live in Northern Mexico and in the United States where they are primarily enrolled in three federally recognized tribes: the Fort Sill Apache Tribe, located near Apache, Oklahoma, with a small reservation outside Deming, New Mexico; the Mescalero Apache Tribe of the Mescalero Reservation near Ruidoso, New Mexico; and the San Carlos Apache Tribe in southeastern Arizona.\nName.\nThe Chiricahua Apache, also written as \"Chiricagui\", \"Apaches de Chiricahui\", \"Chiricahues\", \"Chilicague\", \"Chilecagez\", and \"Chiricagua\", were given that name by the Spanish. The White Mountain Coyotero Apache, including the \"Cibecue\" and \"Bylas\" groups of the Western Apache, referred to the Chiricahua by the name Ha'i\u2019\u0105\u0301h\u00e1, while the San Carlos Apache called them H\u00e1k'\u0105\u0301y\u00e9 which means \u2033Eastern Sunrise\u2033, or \u2033People in the East\u2033. Sometimes they adapted this appellation and referred to themselves also as Ha\u2019ishu Na gukande ('Sunrise People'). The Mescalero Apache called the Western Apache and Chiricahua bands to their west Sh\u00e1'i'\u00e1\u00f5de (\"Western Apache People\", \"The People of the Sunset\", \"The People of the West\"), when referring only to Chiricahuas they used Ch'\u00fak'\u00e2n\u00e9\u00f5de (\"People of a ridge or mountainside [made of loose rocks]\") or sometimes T\u00e3'aa'ji k'ee'd\u00e9\u00f5kaa'\u00f5de (\"The Ones who are Covered [with breech cloths]\"). Navajo refer to the Chiricahua as \"Ch\u00edsh\u00ed\" (\"Southern People\").\nThe Chiricahua autonym, or name by which they refer to themselves, is simply (depending on dialect) \"Nde, Ne, N\u00e9nd\u00e9, H\u00e9nd\u00e9\", \"Hen-de\" or \"\u00f5ne\" (\"The People, Men\", \"the People of\"); they never called themselves \u2033Apaches\". The Chiricahua referred to outsiders, such as Americans, Mexicans or other Indians, as \"Enee\", \"\u207fd\u00e1a\" or \"Indah / N'daa\". This word has two possible meanings, the first being \"strange people, non-Apache people\" or \"enemy\", but another being \"eye\". Sometimes it is said that all Apaches referred to the Americans and European settlers (with exception of the Mexicans) as \"Bi'ndah-Li'ghi' / Bi'nda-li'ghi'o'yi\" (\"White Eyes\"), but this seems a name from Mescalero and Lipan Apache bands, as the Chiricahua bands called them \"Daadatlijende\", meaning \"Blue/green eye people\" or \"Indaa\u026big\u00e1\u00ed / Indaa\u026big\u00e1nde\" meaning \"White skinned or pale colored people\" or literally \"Strange, non-Apache people, which are white-skinned\"). \"\u0141ig\u00e1\u00ed\" means \"it is white\" or it can be translate as \"it is pale colored\". The \u00ed on the end usually translates as \"the one that is\", but in the context of human beings, can mean \"the group who are\".\nLanguage.\nThe Chiricahua language (n'dee biyat'i) is a Southern Athabaskan language from the Na-dene language family. It is very closely related to Mescalero, and more distantly related to Western Apache. It's considered a national language of Mexico and is regulated by the Instituto Nacional de Lenguas Ind\u00edgenas.\nCulture and organization.\nSeveral loosely affiliated bands of Apache came improperly to be usually known as the Chiricahuas. These included the \"Chokonen\" (recte: Tsokanende), the \"Chihenne\" (recte: Tchihende), the \"Nednai\" (\"Nednhi\") and \"Bedonkohe\" (recte, both of them together: Ndendahe). Today, all are commonly referred to as Chiricahua, but they were not historically a single band nor the same Apache division, being more correctly identified, all together, as \"Central Apaches\".\nMany other bands and groups of Apachean language-speakers ranged over eastern Arizona and the American Southwest. The bands that are grouped under the Chiricahua term today had much history together: they intermarried and lived alongside each other, and they also occasionally fought with each other. They formed short-term as well as longer alliances that have caused scholars to classify them as one people.\nThe Apachean groups and the Navajo peoples were part of the Athabaskan migration into the North American continent from Asia, across the Bering Strait from Siberia. As the people moved south and east into North America, groups splintered off and became differentiated by language and culture over time. Some anthropologists believe that the Lipan Apache and the Navajo were pushed south and west into what is now New Mexico and Arizona by pressure from other Great Plains Indians, such as the Comanche and Kiowa. Among the last of such splits were those that resulted in the formation of the different Apachean bands whom the later Europeans encountered: the southwestern Apache groups and the Navajo. Although both speaking forms of Southern Athabaskan, the Navajo and Apache have become culturally distinct.\nThe \"Chihenne (Tchihende)\", \"Nednai/Nednhi (Ndendahe)\" and \"Bedonkohe\" intermarried sometimes with Mescalero Bands of New Mexico and Chihuahua and formed alliances with them; therefore their Mescalero kin did know the names of Chiricahua bands and local groups: \"Ch\u00edh\u00e9\u00f5de\" (\"The People of Red Ceremonial Paint\", \"The Red Ceremonial Paint People\"), \"Nd\u00e9'ndaa'\u00f5de / Nd\u00e9'ndaa\u00f5de\" (\"The Apache People (who live among) Enemies\") and \"Bid\u00e1\u00f5'ka\u00f5de / Bid\u00e1\u00f5'kah\u00e9\u00f5de\" (\"The People whom We Met\", \"The People whom We Came Upon\"), The Mescalero use the term -\u00f5de, -\u00e9\u00f5de, -n\u00e9\u00f5de, or -h\u00e9\u00f5de (\"the people of\") instead of the Chiricahua Nde, Ne, N\u00e9nd\u00e9, H\u00e9nd\u00e9, Hen-de or \u00f5ne (\"the people of\").\nDances.\nChiricahuas from Mexico participate every year in the \"Fiesta de los Remedios\" in Comonfort, Guanajuato representing and performing their traditional dances and other ceremonies.\nReligion.\nThe major Chiricahuan deity is called Ussen, an all-powerful creator figure. Other figures in Chiricahuan mythology include White Painted Woman, a virgin who offered herself in sacrifice to end a drought, and her son, Child of the Waters.\n\"Hoddentin\", ceremonially prepared cattail pollen, is used in many Chiricahuan rituals. John Gregory Bourke recorded that the Chiricahua offered \"hoddentin\" to the sun, threw it after snakes, and used it in medicine dances and around dying people.\nOther traditional practices include death rituals and puberty ceremonies for young women. Caves, waterways, and birthplaces hold special spiritual significance.\nHistory.\nGreat Migration.\nThe Athabaskan ancestors of the Chiricahua people migrated south from Canada along the Rocky Mountains. Historians disagree on the exact dates of the migration, with estimates ranging from the early 1100s to about 1500. Historian Jack D. Forbes speculates that there may have been two or more mass migrations during this time period.\n18th century.\nThe Tsokanende (Chiricahua) Apache division was once led, from the beginning of the 18th century, by chiefs such as Pisago Cabez\u00f3n, Relles, Posito Moraga, Yrigollen, Tapil\u00e1, Teboca, V\u00edvora, Miguel Narbona, Esquinaline, and finally Cochise (whose name was derived from the Apache word \"Cheis,\" meaning \"having the quality of oak\") and, after his death, his sons Tahzay and, later, Naiche, under the guardianship of Cochise's war chief and brother-in-law Nahilzay, and the independent chiefs Chihuahua, Ulzana, Skinya and Pionsenay; Tchihende (Mimbre\u00f1o) people was led, during the same period, by chiefs as Juan Jos\u00e9 Compa, Fuerte also known as Soldado Fiero, Mangas Coloradas, Cuchillo Negro, Delgadito, Ponce, Nana, Victorio, Loco, Mangus; Ndendahe (Mogoll\u00f3n and Carrizale\u00f1o / Janero) Apache people, in the meanwhile, was led by Mahko and, after him, Mano Mocha, Coleto Amarillo, Luis, Laceres, Felipe, Natiza, and finally Juh and \"Goyaa\u0142\u00e9\" (known to the Americans as Geronimo). After Victorio's death, Nana, Ger\u00f3nimo, Mangus (youngest Mangas Coloradas' son) and youngest Cochise's son \"Naiche\" were the last leaders of the Central Apaches, and their mixed Apache group was the last to continue to resist U.S. government control of the American Southwest.\nEuropean-Apache relations.\nFrom the beginning of European-Apache relations, there was conflict between them. The two groups contested the control of land and trade routes in Apacheria, and their cultural differences made it oftentimes difficult to negotiate treaties and policies between. Their encounters were preceded by more than 100 years of Spanish colonial and Mexican incursions and settlement on the Apache lands, which pushed Apache tribes northward and exacerbated the martial nature of their society. The United States settlers were newcomers to the competition for land and resources in the Southwest, but they inherited its complex history, and brought their own attitudes with them about American Indians and how to use the land. By the Treaty of Guadalupe Hidalgo of 1848, the US took on the responsibility to prevent and punish cross-border incursions by Apache who were raiding in Mexico.\nThe Apache viewed the United States colonists with ambivalence, and in some cases enlisted them as allies in the early years against the Mexicans. In 1852, the US and some of the Chiricahua signed a treaty, but it had little lasting effect. During the 1850s, American miners and settlers began moving into Chiricahua territory, beginning encroachment that had been renewed in the migration to the Southwest of the previous two decades.\nThis forced the Apachean people to change their lives as nomads, free on the land. The US Army defeated them and forced them into the confinement of reservation life, on lands ill-suited for subsistence farming, which the US proffered as the model of civilization. Today, the Chiricahua are preserving their culture as much as possible, while forging new relationships with the peoples around them. The Chiricahua are a living and vibrant culture, a part of the greater American whole and yet distinct based on their history and culture.\nHostilities.\nAlthough they had lived peaceably with most Americans in the New Mexico Territory up to about 1860, the Chiricahua became increasingly hostile to American encroachment in the Southwest after a number of provocations had occurred between them.\nIn 1835, Mexico had placed a bounty on Apache scalps which further inflamed the situation. In 1837 Warm Springs Mimbre\u00f1os' head chief and famed raider Soldado Fiero also known as Fuerte was killed by Mexican soldiers of the garrison at Janos (only two days' travel from Santa Rita del Cobre), and his son Cuchillo Negro succeeded him as head chief and went to war against Chihuahua for revenge. In the same 1837, the American John (also known as James) Johnson invited the Coppermine Mimbre\u00f1os in the Pinos Altos area to trade with his party (near the mines at Santa Rita del Cobre, New Mexico) and, when they gathered around a blanket on which \"pinole\" (a ground corn flour) had been placed for them, Johnson and his men opened fire on the Chihenne with rifles and a concealed cannon loaded with scrap iron, glass, and a length of chain. They killed about 20 Apache, including the chief Juan Jos\u00e9 Comp\u00e1. Mangas Coloradas is said to have witnessed this attack, which inflamed his and other Apache warriors' desires for vengeance for many years; he led the survivors to safety and subsequently, together with Cuchillo Negro, took Mimbre\u00f1o revenge. The historian Rex W. Strickland argued that the Apache had come to the meeting with their own intentions of attacking Johnson's party, but were taken by surprise. In 1839 scalp-hunter James Kirker was employed by Robert McKnight to re-open the road to Santa Rita del Cobre.\nAfter the conclusion of the US/Mexican War (1848) and the Gadsden Purchase (1853), Americans began to enter the territory in greater numbers. This increased the opportunities for incidents and misunderstandings. The Apaches, including Mangas Coloradas and Cuchillo Negro, were not at first hostile to the Americans, considering them enemies of their own Mexican enemies.\nCuchillo Negro, with Ponce, Delgadito, Victorio and other Mimbre\u00f1o chiefs, signed a treaty at Fort Webster in April 1853, but, during the spring of 1857 the U.S. Army set out on a campaign, led by Col. Benjamin L.E. deBonneville, Col. Dixon S. Miles (3\u00b0Cavalry from Fort Thorn) and Col. William W. Loring (commanding a Mounted Rifles Regiment from Albuquerque), against Mogollon and Coyotero Apaches: Loring's Pueblo Indian scouts found and attacked an Apache rancheria in the Canyon de Los Muertos Carneros (May 25, 1857), where Cuchillo Negro and some Mimbre\u00f1o Apache were resting after a raid against the Navahos. Some Apaches, including Cuchillo Negro himself, were killed.\nIn December 1860, after several bad incidents provoked by the miners led by James H. Tevis in the Pinos Altos area, \"Mangas Coloradas\" went to Pinos Altos, New Mexico to try to convince the miners to move away from the area he loved and to go to the Sierra Madre and seek gold there, but they tied him to a tree and whipped him badly. His Mimbre\u00f1o and Ndendahe followers and related Chiricahua bands were incensed by the treatment of their respected chief. Mangas had been just as great a chief in his prime (during the 1830s and 1840s), along with Cuchillo Negro, as Cochise was then becoming.\nIn 1861, the US Army seized and killed some of Cochise's relatives near Apache Pass, in what became known as the Bascom Affair. Remembering how Cochise had escaped, the Chiricahua called the incident \"cut the tent.\" In 1863, Gen. James H. Carleton set out leading a new campaign against the Mescalero Apache, and Capt. Edmund Shirland (10\u00b0California Cavalry) invited Mangas Coloradas for a \"parley\" but, after he entered the U.S. camp to negotiate a peace, the great Mimbre\u00f1o chief was arrested and convicted in Fort McLane, where, probably on Gen. Joseph R. West's orders, Mangas Coloradas was killed by American soldiers (Jan. 18, 1863). His body was mutilated by the soldiers, and his people were enraged by his murder. The Chiricahuas began to consider the Americans as \"enemies we go against them.\" From that time, they waged almost constant war against US settlers and the Army for the next 23 years. Cochise, his brother-in-law Nahilzay (war chief of Cochise's people), Chihuahua, Skinya, Pionsenay, Ulzana and other warring chiefs became a nightmare to settlers and military garrisons and patrols. In the meantime, the great Victorio, Delgadito (soon killed in 1864), Nana, Loco, young Mangus (last son of Mangas Coloradas) and other minor chiefs led on the warpath the Mimbre\u00f1os, Chiricahuas' cousins and allies, and Juh led the Ndendahe (Nednhi and Bedonkohe together).\nIn 1872, General Oliver O. Howard, with the help of Thomas Jeffords, succeeded in negotiating a peace with Cochise. On December 14, 1872, President Ulysses Grant issued an Executive Order establishing the Chiricahua Reservation in the southeast Arizona Territory encompassing the Chiricahua Mountains, Mexico\u2013United States border, and New Mexico Territory border. Jeffords and John Clum were designated as the U.S. Indian Agents for the Chiricahua Reservation residing near Apache Pass, Arizona and Fort Bowie. It remained open for about 4 years, during which the chief Cochise died (from natural causes). In 1876, about two years after Cochise's death, the US moved the Chiricahua and some other Apache bands to the San Carlos Apache Indian Reservation, still in Arizona. This was in response to public outcry after the killings of Orizoba Spence and Nicholas Rogers at Sulpher Springs. The mountain people hated the desert environment of San Carlos, and some frequently began to leave the reservation and sometimes raided neighboring settlers.\nThey surrendered to General Nelson Miles in 1886. The best-known warrior leader of the \"renegades\", although he was not considered a 'chief', was the forceful and influential Geronimo. He and \"Naiche\" (the son of Cochise and hereditary leader after Tahzay's death) together led many of the resisters during those last few years of freedom.\nThey made a stronghold in the Chiricahua Mountains, part of which is now inside Chiricahua National Monument, and across the intervening Willcox Playa to the northeast, in the Dragoon Mountains (all in southeastern Arizona). In late frontier times, the Chiricahua ranged from San Carlos and the White Mountains of Arizona, to the adjacent mountains of southwestern New Mexico around what is now Silver City, and down into the mountain sanctuaries of the Sierra Madre (of northern Mexico). There they often joined with their \"Nednai\" Apache kin.\nGeneral George Crook, then General Miles' troops, aided by Apache scouts from other groups, pursued the exiles until they gave up. Mexico and the United States had negotiated an agreement allowing their troops in pursuit of the Apache to continue into each other's territories. This prevented the Chiricahua groups from using the border as an escape route, and as they could gain little time to rest and consider their next move, the fatigue, attrition and demoralization of the constant hunt led to their surrender.\nThe final 34 hold-outs, including Geronimo and Naiche, surrendered to units of General Miles' forces in September 1886. From Bowie Station, Arizona, they were entrained, along with most of the other remaining Chiricahua (as well as the Army's Apache scouts), and exiled to Fort Marion, Florida. At least two Apache warriors, Massai and Gray Lizard, escaped from their prison car and made their way back to San Carlos Arizona in a journey to their ancestral lands.\nAfter a number of Chiricahua deaths at the Fort Marion prison near St. Augustine, Florida, the survivors were moved, first to Alabama, and later to Fort Sill, Oklahoma. Geronimo's surrender ended the Indian Wars in the United States. However, another group of Chiricahua (also known as the \"Nameless Ones\" or \"Bronco Apache\") were not captured by U.S. forces and refused to surrender. They escaped over the border to Mexico, and settled in the remote Sierra Madre mountains. There they built hidden camps, raided homes for cattle and other food supplies, and engaged in periodic firefights with units of the Mexican Army and police. Most were eventually captured or killed by soldiers or by private ranchers armed and deputized by the Mexican government.\nEventually, the surviving Chiricahua prisoners were moved to the Fort Sill military reservation in Oklahoma. In August 1912, by an act of the U.S. Congress, they were released from their prisoner of war status as they were thought to be no further threat. Although promised land at Fort Sill, they met resistance from local non-Apache. They were given the choice to remain at Fort Sill or to relocate to the Mescalero reservation near Ruidoso, New Mexico. Two-thirds of the group, 183 people, elected to go to New Mexico, while 78 remained in Oklahoma. Their descendants still reside in these places. At the time, they were not permitted to return to Arizona because of hostility from the long wars.\nin 1912 many different Apache bands returned to San Carlos Apache lands after their release from Fort Sill Apache Reservation.\nBands.\nIn the Chiricahua culture, the \"band\" as a unit was much more important than the\nAmerican or European concept of \"tribe\". The Chiricahua had no name for themselves (autonym) as a people. The name Chiricahua is most likely the Spanish rendering of the Opata word \"Chihuicahui or Chiguicagui\" ('mountain of the wild turkey') for the Chiricahua Mountains, later corrupted into Chiricahui/Chiricahua. The Chiricahua tribal territory encompassed today's SE Arizona, SW New Mexico, NE Sonora and NW Chihuahua. The Chiricahua range extended to the east as far as the Rio Grande Valley in New Mexico and to the west as far as the San Pedro River Valley in Arizona, north of Magdalena just below present day Hwy I-40 corridor in New Mexico and with the town Ciudad Madera (276\u00a0km northwest of the state capital, Chihuahua, and 536\u00a0km southwest of Ciudad Ju\u00e1rez (formerly known as Paso del Norte) on the Mexico\u2013United States border), as their southernmost range.\nAccording to Morris E. Opler (1941), the Chiricahuas consisted of three bands:\nSchroeder (1947) lists five bands:\nThe Chiricahua-Warm Springs Fort Sill Apache tribe in Oklahoma say they have four bands in Fort Sill: (some of the Arizona Apaches did not return to San Carlos or Fort Apache, White Mountain Apache warrior Eyelash is buried in Fort Sill cememtry, Southern Tonto Apache Chief/Scout Hosay is buried in Fort Apache cememtery, Hosay has family in Fort Sill and San Carlos today)\nToday they use the word Chidik\u00e1\u00e1gu (derived from the Spanish word \"Chiricahua\") to refer to the Chiricahua in general, and the word Ind\u00e9, to refer to the Apache in general.\nOther sources list these and additional bands (only the Chokonen and Chihuicahui local groups of the Chokonen band were considered by Chiricahua tribal members to be \"the real Chiricahua people\"):\nThe Chokonen, Chihenne, Nednhi, and Bedonkohe had probably up to three other groups, named respectively after their leaders or homelands. By the end of the 19th century, surviving Apache no longer identified these groups. They may have been wiped out (like the Pinale\u00f1o-Nednhi) or had joined more powerful groups. For instance, the remnant of the Carrizale\u00f1o-Nedhni camped together with their northern kin, the Janero-Nednhi.\nThe Carrizale\u0148o-Nednhi shared overlapping territory in the surroundings of Casas Grandes and Aguas Nuevas with the \"Tsebekin\u00e9nd\u00e9\", a southern Mescalero band (which was often called \"Aguas Nuevas\" by the Spanish). The Spanish referred to the Apache band by the same name of Tsebekin\u00e9nd\u00e9. These two different Apache bands were often confused with each other. (Similar confusion arose over distinguishing the Janeros-Nednhi of the Chiricahua (\"Dzilthdaklizh\u00e9nd\u00e9\") and the \"Dzithinahnd\u00e9\" of the Mescalero.\nNotable Chiricahua Apache people.\nFor people after the 19th century, see the pages of specific tribes: Fort Sill Apache Tribe, Mescalero Apache Tribe of the Mescalero Reservation, and San Carlos Apache Tribe.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "44050", "revid": "949717", "url": "https://en.wikipedia.org/wiki?curid=44050", "title": "John Abbott (disambiguation)", "text": "John Abbott (1821\u20131893) was Prime Minister of Canada, 1891\u20131892.\nJohn Abbott or Abbot may also refer to:\nSee also.\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about people with the same name. "}
{"id": "44052", "revid": "1250350664", "url": "https://en.wikipedia.org/wiki?curid=44052", "title": "Democratic Republic of Congo", "text": ""}
{"id": "44055", "revid": "310173", "url": "https://en.wikipedia.org/wiki?curid=44055", "title": "Measurable function", "text": "Kind of mathematical function\nIn mathematics, and in particular measure theory, a measurable function is a function between the underlying sets of two measurable spaces that preserves the structure of the spaces: the preimage of any measurable set is measurable. This is in direct analogy to the definition that a continuous function between topological spaces preserves the topological structure: the preimage of any open set is open. In real analysis, measurable functions are used in the definition of the Lebesgue integral. In probability theory, a measurable function on a probability space is known as a random variable.\nFormal definition.\nLet formula_1 and formula_2 be measurable spaces, meaning that formula_3 and formula_4 are sets equipped with respective formula_5-algebras formula_6 and formula_7 A function formula_8 is said to be measurable if for every formula_9 the pre-image of formula_10 under formula_11 is in formula_6; that is, for all formula_13\nformula_14\nThat is, formula_15 where formula_16 is the \u03c3-algebra generated by f. If formula_8 is a measurable function, one writes\nformula_18\nto emphasize the dependency on the formula_5-algebras formula_6 and formula_7\nTerm usage variations.\nThe choice of formula_5-algebras in the definition above is sometimes implicit and left up to the context. For example, for formula_23 formula_24 or other topological spaces, the Borel algebra (generated by all the open sets) is a common choice. Some authors define measurable functions as exclusively real-valued ones with respect to the Borel algebra.\nIf the values of the function lie in an infinite-dimensional vector space, other non-equivalent definitions of measurability, such as weak measurability and Bochner measurability, exist.\nNon-measurable functions.\nReal-valued functions encountered in applications tend to be measurable; however, it is not difficult to prove the existence of non-measurable functions. Such proofs rely on the axiom of choice in an essential way, in the sense that Zermelo\u2013Fraenkel set theory without the axiom of choice does not prove the existence of such functions.\nIn any measure space \"formula_25\" with a non-measurable set formula_53 formula_54 one can construct a non-measurable indicator function: \nformula_55\nwhere formula_56 is equipped with the usual Borel algebra. This is a non-measurable function since the preimage of the measurable set formula_57 is the non-measurable formula_58 \u00a0\nAs another example, any non-constant function formula_59 is non-measurable with respect to the trivial formula_5-algebra formula_61 since the preimage of any point in the range is some proper, nonempty subset of formula_62 which is not an element of the trivial formula_63\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44056", "revid": "628775", "url": "https://en.wikipedia.org/wiki?curid=44056", "title": "MD Data", "text": "Type of magneto-optical medium\nMD Data is a type of magneto-optical medium derived from MiniDisc. \nIn developing and marketing it, Sony was trying to set the new standard for removable media to replace the 3\u00bd-inch diskette it had also helped create. MD Data competed in a format war with other disks such as SyQuest's EZ 135, Imation's SuperDisk, and the Iomega Zip. Ultimately neither MD Data nor any of its competitors succeeded in becoming the de facto new universal standard fully replacing the 3.5 inch diskette; with recordable CDs coming closest to filling the role, followed by USB flash drives.\nOverview.\nMD Data disks can be fully read-only, fully rewritable, or be a hybrid of the two, with a portion of a disk being read-only and while another is rewritable.\nWith 140 MB disks, MD Data offered about 100 times as much storage capacity as ordinary diskettes, and more than its competitors like the Zip (100 MB), SuperDisk (120 MB), and EZ 135 (135 MB), in a physically smaller medium.\nThe format was featured in products such as still cameras, a PDA, document scanners, and image storage and editing systems.\nAnother use was in 4- and 8-track multitrack recording decks. Meant as a step up from the popular 4-track cassette-based studios, these recorders enjoyed a brief prominence before they were replaced by relatively affordable and far more flexible direct-to-hard drive recording on Windows and Macintosh based computers. Some examples of products that used the format are a few multitrack \"portastudio\"-style audio recorders such as Sony's MDM-X4 and Tascam's 564.\nSony's MDH-10 MD Data disk drive, meant for use with Windows and Mac PCs, could also play back audio MiniDiscs. However, the drive was expensive compared to the Zip drive and others. \nMD Data2.\nIn 1997, Sony introduced the MD Data2 format at 650 MB. The only product that used the format was Sony's DCM-M1 camcorder (capable of still images and MPEG-2 video).\nHi-MD.\nHi-MD, introduced in 2004 allows 340MB or 1GB of any type of data to be stored on a Hi-MD formatted MiniDisc, succeeding MD Data and MD Data2.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44057", "revid": "1281421188", "url": "https://en.wikipedia.org/wiki?curid=44057", "title": "Galactic astronomy", "text": "Study of the Milky Way galaxy and its contents\nGalactic astronomy is the study of the Milky Way galaxy and all its contents. This is in contrast to extragalactic astronomy, which is the study of everything outside our galaxy, including all other galaxies.\nGalactic astronomy should not be confused with galaxy formation and evolution, which is the general study of galaxies, their formation, structure, components, dynamics, interactions, and the range of forms they take.\nThe Milky Way galaxy, where the Solar System is located, is in many ways the best-studied galaxy, although important parts of it are obscured from view in visible wavelengths by regions of cosmic dust. The development of radio astronomy, infrared astronomy and submillimetre astronomy in the 20th century allowed the gas and dust of the Milky Way to be mapped for the first time.\nSubcategories.\nA standard set of subcategories is used by astronomical journals to split up the subject of Galactic Astronomy:"}
{"id": "44058", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=44058", "title": "Big Bang nucleosynthesis", "text": "Process during the early universe\nIn physical cosmology, Big Bang nucleosynthesis (also known as primordial nucleosynthesis, and abbreviated as BBN) is a model for the production of the light nuclei 2H, 3He, 4He, and 7Li between 0.01s and 200s in the lifetime of the universe.\nThe model uses a combination of thermodynamic arguments and results from equations for the expansion of the universe to define a changing temperature and density, then analyzes the rates of nuclear reactions at these temperatures and densities to predict the nuclear abundance ratios. Refined models agree very well with observations with the exception of the abundance of 7Li. The model is one of the key concepts in standard cosmology.\nElements heavier than lithium are thought to have been created later in the life of the universe by stellar nucleosynthesis, through the formation, evolution and death of stars.\nCharacteristics.\nThe Big Bang nucleosynthesis (BBN) model assumes a homogeneous plasma, at a temperature corresponding to 1 MeV, consisting of electrons annihilating with positrons to produce photons. In turn, the photons pair to produce electrons and positrons: formula_1.\nThese particles are in equilibrium. A similar number of neutrinos, also at 1 MeV, have just dropped out of equilibrium at this density. Finally, there is a very low density of baryons (neutrons and protons). The BBN model follows the nuclear reactions of these baryons as the temperature and pressure drops due to expansion of the universe.\nThe basic model makes two simplifying assumptions: \nThese assumptions are based on the intense flux of high energy photons in the plasma. Above 0.1 MeV every nucleus created is blasted apart by a photon.\nThus the model first determines the ratio of neutrons to protons and uses this as an input to calculate the hydrogen, deuterium, tritium, and 3He.\nThe model follows nuclear reaction rates as the temperature and density drops.\nThe evolving density and temperature follow from the Friedmann-Robertson-Walker model.\nAround formula_2 MeV, the density of neutrinos drops, and reactions like\nformula_3\nwhich maintained neutron and proton equilibrium, slow down.\nThe neutron-to-proton ratio decreases to around 1/7.\nAs the temperature and density continue to fall, reactions involving combinations of protons and neutrons shift towards heavier nuclei. These include\nformula_4\nDue to the higher binding energy of He, the free neutrons and the deuterium nuclei are largely consumed, leaving mostly protons and helium.\nThe fusion of nuclei occurred between roughly 10 seconds to 20 minutes after the Big Bang; this corresponds to the temperature range when the universe was cool enough for deuterium to survive, but hot and dense enough for fusion reactions to occur at a significant rate.\nThe key parameter which allows one to calculate the effects of Big Bang nucleosynthesis is the baryon/photon number ratio, which is a small number of order 6 \u00d7 10\u221210. This parameter corresponds to the baryon density and controls the rate at which nucleons collide and react; from this it is possible to calculate element abundances after nucleosynthesis ends. Although the baryon per photon ratio is important in determining element abundances, the precise value makes little difference to the overall picture. Without major changes to the Big Bang theory itself, BBN will result in mass abundances of about 75% of hydrogen-1, about 25% helium-4, about 0.01% of deuterium and helium-3, trace amounts (on the order of 10\u221210) of lithium, and negligible heavier elements. That the observed abundances in the universe are generally consistent with these abundance numbers is considered strong evidence for the Big Bang theory.\nHistory.\nThe history of Big Bang nucleosynthesis research began with a proposal in the 1940s by George Gamow that nuclear reactions during a hot initial phase of the universe produced the observed hydrogen and helium. Calculations by his student Ralph Alpher were published in the famous Alpher\u2013Bethe\u2013Gamow paper outlined a theory of light-element production in the early universe. The first detailed calculations of the primordial isotopic abundances came in 1966 and have been refined over the years using updated estimates of the input nuclear reaction rates. The first systematic Monte Carlo study of how nuclear reaction rate uncertainties impact isotope predictions, over the relevant temperature range, was carried out in 1993.\nImportant parameters.\nThe creation of light elements during BBN was dependent on a number of parameters; among those was the neutron\u2013proton ratio (calculable from Standard Model physics) and the baryon-photon ratio.\nNeutron\u2013proton ratio.\nThe neutron\u2013proton ratio was set by Standard Model physics before the nucleosynthesis era, \nessentially within the first 1-second after the Big Bang. \nNeutrons can react with positrons or electron neutrinos to create protons and other products in one of the following reactions:\n&lt;chem&gt;n \\ + e+ &lt;=&gt; \\overline{\\nu}_e + p &lt;/chem&gt;\n&lt;chem&gt;n \\ + \\nu_{e} &lt;=&gt; p + e- &lt;/chem&gt;\nAt times much earlier than 1 sec, these reactions were fast and maintained the n/p ratio close to 1:1. As the temperature dropped, the equilibrium shifted in favour of protons due to their slightly lower mass, and the n/p ratio smoothly decreased. \nThese reactions continued until the decreasing temperature and density caused the reactions to become too slow, which occurred at about T = 0.7 MeV (time around 1 second) and is called the freeze out temperature. At freeze out, the neutron\u2013proton ratio was about 1:6. However, free neutrons are unstable with a mean life of 880 sec; some neutrons decayed in the next few minutes before fusing into any nucleus, so the ratio of total neutrons to protons after nucleosynthesis ends is about 1:7. Almost all neutrons that fused instead of decaying ended up combined into helium-4, due to the fact that helium-4 has the highest binding energy per nucleon among light elements. This predicts that about 8% of all atoms should be helium-4, leading to a mass fraction of helium-4 of about 25%, which is in line with observations. Small traces of deuterium and helium-3 remained as there was insufficient time and density for them to react and form helium-4.\nBaryon\u2013photon ratio.\nThe baryon\u2013photon ratio, \u03b7, is the key parameter determining the abundances of light elements after nucleosynthesis ends. Baryons and light elements can fuse in the following main reactions:\nalong with some other low-probability reactions leading to 7Li or 7Be. \n(An important feature is that there are no stable nuclei with mass 5 or 8, which implies that reactions adding one baryon to 4He, or fusing two 4He, do not occur). \nMost fusion chains during BBN ultimately terminate in 4He (helium-4), while \"incomplete\" reaction chains lead to small amounts of left-over 2H or 3He; the amount of these decreases with increasing baryon-photon ratio. That is, the larger the baryon-photon ratio the more reactions there will be and the more efficiently deuterium will be eventually transformed into helium-4. This result makes deuterium a very useful tool in measuring the baryon-to-photon ratio.\nSequence.\nBig Bang nucleosynthesis began roughly 20 seconds after the big bang, when the universe had cooled sufficiently to allow deuterium nuclei to survive disruption by high-energy photons. (Note that the neutron\u2013proton freeze-out time was earlier). This time is essentially independent of dark matter content, since the universe was highly radiation dominated until much later, and this dominant component controls the temperature/time relation. At this time there were about six protons for every neutron, but a small fraction of the neutrons decay before fusing in the next few hundred seconds, so at the end of nucleosynthesis there are about seven protons to every neutron, and almost all the neutrons are in Helium-4 nuclei.\nOne feature of BBN is that the physical laws and constants that govern the behavior of matter at these energies are very well understood, and hence BBN lacks some of the speculative uncertainties that characterize earlier periods in the life of the universe. Another feature is that the process of nucleosynthesis is determined by conditions at the start of this phase of the life of the universe, and proceeds independently of what happened before.\nAs the universe expands, it cools. Free neutrons are less stable than helium nuclei, and the protons and neutrons have a strong tendency to form helium-4. However, forming helium-4 requires the intermediate step of forming deuterium. Before nucleosynthesis began, the temperature was high enough for many photons to have energy greater than the binding energy of deuterium; therefore any deuterium that was formed was immediately destroyed (a situation known as the \"deuterium bottleneck\"). Hence, the formation of helium-4 was delayed until the universe became cool enough for deuterium to survive (at about T = 0.1 MeV); after which there was a sudden burst of element formation. However, very shortly thereafter, around twenty minutes after the Big Bang, the temperature and density became too low for any significant fusion to occur. At this point, the elemental abundances were nearly fixed, and the only changes were the result of the radioactive decay of the two major unstable products of BBN, tritium and beryllium-7.\nHeavy elements.\nBig Bang nucleosynthesis produced very few nuclei of elements heavier than lithium due to a bottleneck: the absence of a stable nucleus with 8 or 5 nucleons. This deficit of larger atoms also limited the amounts of lithium-7 produced during BBN. In stars, the bottleneck is passed by triple collisions of helium-4 nuclei, producing carbon (the triple-alpha process). However, this process is very slow and requires much higher densities, taking tens of thousands of years to convert a significant amount of helium to carbon in stars, and therefore it made a negligible contribution in the minutes following the Big Bang.\nThe predicted abundance of CNO isotopes produced in Big Bang nucleosynthesis is expected to be on the order of 10\u221215 that of H, making them essentially undetectable and negligible. Indeed, none of these primordial isotopes of the elements from beryllium to oxygen have yet been detected, although those of beryllium and boron may be able to be detected in the future. So far, the only stable nuclides known experimentally to have been made during Big Bang nucleosynthesis are protium, deuterium, helium-3, helium-4, and lithium-7.\nHelium-4.\nBig Bang nucleosynthesis predicts a primordial abundance of about 25% helium-4 by mass, irrespective of the initial conditions of the universe. As long as the universe was hot enough for protons and neutrons to transform into each other easily, their ratio, determined solely by their relative masses, was about 1 neutron to 7 protons (allowing for some decay of neutrons into protons). Once it was cool enough, the neutrons quickly bound with an equal number of protons to form first deuterium, then helium-4. Helium-4 is very stable and is nearly the end of this chain if it runs for only a short time, since helium neither decays nor combines easily to form heavier nuclei (since there are no stable nuclei with mass numbers of 5 or 8, helium does not combine easily with either protons, or with itself). Once temperatures are lowered, out of every 16 nucleons (2 neutrons and 14 protons), 4 of these (25% of the total particles and total mass) combine quickly into one helium-4 nucleus. This produces one helium for every 12 hydrogens, resulting in a universe that is a little over 8% helium by number of atoms, and 25% helium by mass.\n\"One analogy is to think of helium-4 as ash, and the amount of ash that one forms when one completely burns a piece of wood is insensitive to how one burns it.\" The resort to the BBN theory of the helium-4 abundance is necessary as there is far more helium-4 in the universe than can be explained by stellar nucleosynthesis. In addition, it provides an important test for the Big Bang theory. If the observed helium abundance is significantly different from 25%, then this would pose a serious challenge to the theory. This would particularly be the case if the early helium-4 abundance was much smaller than 25% because it is hard to destroy helium-4. For a few years during the mid-1990s, observations suggested that this might be the case, causing astrophysicists to talk about a Big Bang nucleosynthetic crisis, but further observations were consistent with the Big Bang theory.\nDeuterium.\nDeuterium is in some ways the opposite of helium-4, in that while helium-4 is very stable and difficult to destroy, deuterium is only marginally stable and easy to destroy. The temperatures, time, and densities were sufficient to combine a substantial fraction of the deuterium nuclei to form helium-4 but insufficient to carry the process further using helium-4 in the next fusion step. BBN did not convert all of the deuterium in the universe to helium-4 due to the expansion that cooled the universe and reduced the density, and so cut that conversion short before it could proceed any further. One consequence of this is that, unlike helium-4, the amount of deuterium is very sensitive to initial conditions. The denser the initial universe was, the more deuterium would be converted to helium-4 before time ran out, and the less deuterium would remain.\nThere are no known post-Big Bang processes which can produce significant amounts of deuterium. Hence observations about deuterium abundance suggest that the universe is not infinitely old, which is in accordance with the Big Bang theory.\nDuring the 1970s, there were major efforts to find processes that could produce deuterium, but those revealed ways of producing isotopes other than deuterium. The problem was that while the concentration of deuterium in the universe is consistent with the Big Bang model as a whole, it is too high to be consistent with a model that presumes that most of the universe is composed of protons and neutrons. If one assumes that all of the universe consists of protons and neutrons, the density of the universe is such that much of the currently observed deuterium would have been burned into helium-4. The standard explanation now used for the abundance of deuterium is that the universe does not consist mostly of baryons, but that non-baryonic matter (also known as dark matter) makes up most of the mass of the universe. This explanation is also consistent with calculations that show that a universe made mostly of protons and neutrons would be far more \"clumpy\" than is observed.\nIt is very hard to come up with another process that would produce deuterium other than by nuclear fusion. Such a process would require that the temperature be hot enough to produce deuterium, but not hot enough to produce helium-4, and that this process should immediately cool to non-nuclear temperatures after no more than a few minutes. It would also be necessary for the deuterium to be swept away before it reoccurs.\nProducing deuterium by fission is also difficult. The problem here again is that deuterium is very unlikely due to nuclear processes, and that collisions between atomic nuclei are likely to result either in the fusion of the nuclei, or in the release of free neutrons or alpha particles. During the 1970s, cosmic ray spallation was proposed as a source of deuterium. That theory failed to account for the abundance of deuterium, but led to explanations of the source of other light elements.\nLithium.\nLithium-7 and lithium-6 produced in the Big Bang are on the order of: lithium-7 to be 10\u22129 of all primordial nuclides; and lithium-6 around 10\u221213.\nMeasurements and status of theory.\nThe theory of BBN gives a detailed mathematical description of the production of the light \"elements\" deuterium, helium-3, helium-4, and lithium-7. Specifically, the theory yields precise quantitative predictions for the mixture of these elements, that is, the primordial abundances at the end of the big-bang.\nIn order to test these predictions, it is necessary to reconstruct the primordial abundances as faithfully as possible, for instance by observing astronomical objects in which very little stellar nucleosynthesis has taken place (such as certain dwarf galaxies) or by observing objects that are very far away, and thus can be seen in a very early stage of their evolution (such as distant quasars).\nAs noted above, in the standard picture of BBN, all of the light element abundances depend on the amount of ordinary matter (baryons) relative to radiation (photons). Since the universe is presumed to be homogeneous, it has one unique value of the baryon-to-photon ratio. For a long time, this meant that to test BBN theory against observations one had to ask: can \"all\" of the light element observations be explained with a \"single value\" of the baryon-to-photon ratio? Or more precisely, allowing for the finite precision of both the predictions and the observations, one asks: is there some \"range\" of baryon-to-photon values which can account for all of the observations?\nMore recently, the question has changed: Precision observations of the cosmic microwave background radiation with the Wilkinson Microwave Anisotropy Probe (WMAP) and Planck give an independent value for the baryon-to-photon ratio. \nThe present measurement of helium-4 indicates good agreement, and yet better agreement for helium-3. But for lithium-7, there is a significant discrepancy between BBN and WMAP/Planck, and the abundance derived from Population II stars. The discrepancy, called the \"cosmological lithium problem\", is a factor of 2.4\u20154.3 below the theoretically predicted value. that have resulted in revised calculations of the standard BBN based on new nuclear data, and to various reevaluation proposals for primordial proton\u2013proton nuclear reactions, especially the abundances of 7Be + n \u2192 7Li + p, versus 7Be + 2H \u2192 8Be + p.\nNon-standard scenarios.\nIn addition to the standard BBN scenario there are numerous non-standard BBN scenarios. These should not be confused with non-standard cosmology: a non-standard BBN scenario assumes that the Big Bang occurred, but inserts additional physics in order to see how this affects elemental abundances. These pieces of additional physics include relaxing or removing the assumption of homogeneity, or inserting new particles such as massive neutrinos.\nThere have been, and continue to be, various reasons for researching non-standard BBN. The first, which is largely of historical interest, is to resolve inconsistencies between BBN predictions and observations. This has proved to be of limited usefulness in that the inconsistencies were resolved by better observations, and in most cases trying to change BBN resulted in abundances that were more inconsistent with observations rather than less. The second reason for researching non-standard BBN, and largely the focus of non-standard BBN in the early 21st century, is to use BBN to place limits on unknown or speculative physics. For example, standard BBN assumes that no exotic hypothetical particles were involved in BBN. One can insert a hypothetical particle (such as a massive neutrino) and see what has to happen before BBN predicts abundances that are very different from observations. This has been done to put limits on the mass of a stable tau neutrino.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "44059", "revid": "32142854", "url": "https://en.wikipedia.org/wiki?curid=44059", "title": "Harrison Ford", "text": "American actor (born 1942)\nHarrison Ford (born July 13, 1942) is an American actor. Regarded as a cinematic cultural icon, he has starred in many films over seven decades, and is one of the highest-grossing actors in the world. Ford's accolades include nominations for an Academy Award, a British Academy Film Award, an Emmy Award, five Golden Globe Awards, and two Screen Actors Guild Awards. He is the recipient of the AFI Life Achievement Award, Cecil B. DeMille Award, Honorary C\u00e9sar, and Honorary Palme d'Or, and he was honored as a Disney Legend in 2024.\nAfter making his screen debut in 1966 and early supporting roles in the films \"American Graffiti\" (1973) and \"The Conversation\" (1974), Ford achieved global stardom for portraying Han Solo in the space opera film \"Star Wars\" (1977), a role he reprised in five films for the eponymous franchise spanning the next four decades. He also received recognition for his portrayal of the titular character in the \"Indiana Jones\" franchise (1981\u20132023); Rick Deckard in the \"Blade Runner\" franchise (1982\u20132017); and Jack Ryan in the action thriller films \"Patriot Games\" (1992); and \"Clear and Present Danger\" (1994). These roles established him as an action hero and one of Hollywood's most bankable stars from the late 1970s into the early 2000s.\nFord's performance in the thriller film \"Witness\" (1985) earned him his sole Oscar nomination for Best Actor. His other films include \"The Mosquito Coast\" (1986); \"Working Girl\" (1988); \"Presumed Innocent\" (1990); \"The Fugitive\" (1993); \"Sabrina\" (1995); \"The Devil's Own\" (1997); \"Air Force One\" (1997); \"Six Days, Seven Nights\" (1998); \"What Lies Beneath\" (2000); ' (2002); \"Cowboys &amp; Aliens\" (2011); \"42\" (2013), \"The Age of Adaline\" (2015), \"The Call of the Wild\" (2020); and ' (2025). Ford has also starred in the Paramount+ western series \"1923\" (2022\u20132025) and the Apple TV+ comedy series \"Shrinking\" (since 2023), earning a Primetime Emmy Award nomination for the latter.\nOutside acting, Ford is a licensed pilot. He has often assisted the emergency services in rescue missions near his home in Wyoming, and he chaired an aviation education program for youth from 2004 to 2009. Ford is also an environmental activist, having served as the inaugural vice chair of Conservation International since 1991.\nEarly life.\nHarrison Ford was born at the Swedish Covenant Hospital in Chicago, Illinois, on July 13, 1942, to former radio actress Dorothy (n\u00e9e Nidelman) and advertising executive and former actor John William \"Christopher\" Ford.\nHis younger brother, Terence, was born in 1945. Their father was a Catholic of Irish descent, while their mother was an Ashkenazi Jew whose parents were emigrants from Minsk, Belarus, then in the Russian Empire. When asked in which religion he and his brother were raised, Ford jokingly responded \"Democrat\" and more seriously stated that they were raised to be \"liberals of every stripe\". When asked about what influence his Jewish and Irish Catholic ancestry may have had on him, he quipped, \"As a man I've always felt Irish, as an actor I've always felt Jewish.\"\nFord was a Boy Scout, achieving the second-highest rank of Life Scout. He worked at Napowan Adventure Base Scout Camp as a counselor for the Reptile Study merit badge. Because of this, he and director Steven Spielberg later decided to depict the young Indiana Jones as a Life Scout in \"Indiana Jones and the Last Crusade\" (1989). Ford graduated in 1960 from Maine East High School in Park Ridge, Illinois. His voice was the first student voice broadcast on his high school's new radio station, WMTH, and he was its first sportscaster during his senior year. He attended Ripon College in Ripon, Wisconsin, where he was a philosophy major and a member of the Sigma Nu fraternity. A self-described \"late bloomer\", Ford took a drama class in the final quarter of his senior year to get over his shyness and became fascinated with acting. Ford was expelled from college for plagiarism four days before graduation.\nCareer.\n1964\u20131976: Early work.\nIn 1964, after a season of summer stock with the Belfry Players in Wisconsin, Ford traveled to Los Angeles and eventually signed a contract with Columbia Pictures' new talent program. His first known role was an uncredited one as a bellhop in \"Dead Heat on a Merry-Go-Round\" (1966). There is little record of his non-speaking (or \"extra\") roles in film. Ford was at the bottom of the hiring list, having offended producer Jerry Tokofsky. According to one anecdote, Tokofsky told Ford that when actor Tony Curtis delivered a bag of groceries, he could tell that Curtis was a movie star whereas Ford wasn't; Ford immediately retorted that if Curtis was truly a talented actor, he would've delivered them like a bellhop. Ford was apparently fired soon after.\nHis speaking roles continued next with \"Luv\" (1967), though he was still uncredited. He was finally credited as \"Harrison J. Ford\" in the 1967 Western film \"A Time for Killing\", starring Glenn Ford, George Hamilton and Inger Stevens, but the \"J\" did not stand for anything since he has no middle name. It was added to avoid confusion with a silent film actor named Harrison Ford, who appeared in more than 80 films between 1915 and 1932 and died in 1957. Ford later said that he was unaware of the existence of the earlier actor until he came upon a star with his own name on the Hollywood Walk of Fame. Ford soon dropped the \"J\" and worked for Universal Studios, playing minor roles in many television series throughout the late 1960s and early 1970s, including \"Gunsmoke\", \"Ironside\", \"The Virginian\", \"The F.B.I.\", \"Love, American Style\" and \"Kung Fu\". He appeared in the western \"Journey to Shiloh\" (1968) and had an uncredited, non-speaking role in Michelangelo Antonioni's 1970 film \"Zabriskie Point\" as an arrested student protester. In 1968, he also worked as a camera operator for one of the Doors' tours. French filmmaker Jacques Demy chose Ford for the lead role of his first American film, \"Model Shop\" (1969), but the head of Columbia Pictures thought Ford had \"no future\" in the film business and told Demy to hire a more experienced actor. The part eventually went to Gary Lockwood. Ford later commented that the experience had been nevertheless a positive one because Demy was the first to show such faith in him.\nNot happy with the roles offered to him, Ford became a self-taught professional carpenter to support his then-wife and two young sons. Clients at this time included the writers Joan Didion and John Gregory Dunne, who lived on the beach at Malibu. Ford appears in the documentary \"\". He and his wife became friends of the writers. Casting director and fledgling producer Fred Roos championed the young Ford and secured him an audition with George Lucas for the role of Bob Falfa, which Ford went on to play in \"American Graffiti\" (1973). Ford's relationship with Lucas profoundly affected his career later. After director Francis Ford Coppola's film \"The Godfather\" was a success, he hired Ford to expand his office and gave him small roles in his next two films, \"The Conversation\" (1974) and \"Apocalypse Now\" (1979); in the latter film, Ford played an army colonel named \"G. Lucas\".\n1977\u20131997: Worldwide stardom and acclaim.\nFord's work in \"American Graffiti\" eventually landed him his first starring film role, when Lucas hired him to read lines for actors auditioning for roles in Lucas's upcoming epic space-opera film \"Star Wars\" (1977). Lucas was eventually won over by Ford's performance during these line reads and cast him as Han Solo. \"Star Wars\" became one of the most successful and groundbreaking films of all time, and brought Ford, and his co-stars Mark Hamill and Carrie Fisher, widespread recognition. Ford began to be cast in bigger roles in films throughout the late 1970s, including \"Heroes\" (1977), \"Force 10 from Navarone\" (1978) and \"Hanover Street\" (1979). He also co-starred alongside Gene Wilder in the buddy-comedy western \"The Frisco Kid\" (1979), playing a bank robber with a heart of gold. Ford returned to star in the successful \"Star Wars\" sequels \"The Empire Strikes Back\" (1980) and \"Return of the Jedi\" (1983), as well as the \"Star Wars Holiday Special\" (1978). Ford wanted Lucas to kill off Han Solo at the end of \"Return of the Jedi\", saying, \"That would have given the whole film a bottom,\" but Lucas refused.\nFord's status as a leading actor was solidified with \"Raiders of the Lost Ark\" (1981), an action-adventure collaboration between Lucas and Steven Spielberg that gave Ford his second franchise role as the heroic, globe-trotting archaeologist Indiana Jones. Like \"Star Wars\", the film was massively successful; it became the highest-grossing film of the year. Both Spielberg and Lucas were hesitant in casting Ford in the beginning according to Howard Kazanjian in his book \"A Producer's Life\". Lucas's reasons were due to having already worked with him on both \"American Graffiti\" and \"Star Wars\". Lucas relented after Tom Selleck was unable to accept and Spielberg due to the same and seeing his performance in \"The Empire Strikes Back\". Ford went on to reprise the role throughout the rest of the decade in the prequel \"Indiana Jones and the Temple of Doom\" (1984), and the sequel \"Indiana Jones and the Last Crusade\" (1989). During the June 1983 filming of \"Temple of Doom\" in London, Ford herniated a disc in his back. The 40-year-old actor was forced to fly back to Los Angeles for surgery and returned six weeks later.\nFollowing his leading-man success as Indiana Jones, Ford played Rick Deckard in Ridley Scott's dystopian science-fiction film \"Blade Runner\" (1982). Compared to his experiences on the \"Star Wars\" and \"Indiana Jones\" films, Ford had a difficult time with the production. He recalled to \"Vanity Fair\", \"It was a long slog. I didn't really find it that physically difficult\u2014I thought it was mentally difficult.\" Ford and Scott also had differing views on the nature of his character, Deckard, that persist decades later. While not initially a success, \"Blade Runner\" became a cult classic and one of Ford's most highly regarded films. Ford proved his versatility throughout the 1980s with dramatic parts in films such as \"Witness\" (1985), \"The Mosquito Coast\" (1986), and \"Frantic\" (1988), as well as the romantic male lead opposite Melanie Griffith and Sigourney Weaver in the comedy-drama \"Working Girl\" (1988). \"Witness\" and \"The Mosquito Coast\" allowed Ford to explore his potential as a dramatic actor, and both performances were widely acclaimed. Ford later recalled that working with director Peter Weir on \"Witness\" and \"The Mosquito Coast\" were two of the best experiences of his career.\nIn late 1991, Ford was scheduled to star in an action-historical film titled \"Night Ride Down\", where he would have portrayed a Pullman Company executive whose daughter was kidnapped during a labor strike of the 1930s. Paramount Pictures shelved the project, after Ford quit the film over script changes he disagreed with. In the next few years, Ford became the second actor to portray Jack Ryan in two films of the film series based on the literary character created by Tom Clancy: \"Patriot Games\" (1992) and \"Clear and Present Danger\" (1994), both co-starring Anne Archer and James Earl Jones. Ford took over the role from Alec Baldwin, who had played Ryan in \"The Hunt for Red October\" (1990). This led to long-lasting resentment from Baldwin, who said that he had wanted to reprise the role but Ford had negotiated with Paramount behind his back. Ford played leading roles in other action-based thrillers throughout the decade, such as \"The Fugitive \"(1993), \"The Devil's Own\" (1997), and \"Air Force One\" (1997). For his performance in \"The Fugitive\", which co-starred Tommy Lee Jones, Ford received some of the best reviews of his career, including from Roger Ebert, who concluded that, \"Ford is once again the great modern movie everyman. As an actor, nothing he does seems merely for show, and in the face of this melodramatic material he deliberately plays down, lays low, gets on with business instead of trying to exploit the drama in meaningless acting flourishes.\"\nFord played more straight dramatic roles in \"Presumed Innocent\" (1990) and \"Regarding Henry\" (1991), and another romantic lead role in \"Sabrina\" (1995), a remake of the classic 1954 film of the same name. Ford established working relationships with many well-regarded directors during this time, including Weir, Alan J. Pakula, Mike Nichols, Phillip Noyce, and Sydney Pollack, collaborating twice with each of them. This was the most lucrative period of Ford's career. From 1977 to 1997, he appeared in 14 films that reached the top 15 in the yearly domestic box-office rankings, 12 of which reached the top ten. Six of the films he appeared in during this time were nominated for the Academy Award for Best Picture, among other awards: \"Star Wars\", \"Apocalypse Now\", \"Raiders of the Lost Ark\", \"Witness\", \"Working Girl\", and \"The Fugitive\".\n1998\u20132014: Established career.\nIn the late 1990s, Ford started appearing in several critically derided and commercially disappointing films that failed to match his earlier successes, including \"Six Days, Seven Nights\" (1998), \"Random Hearts\" (1999), \"\" (2002), \"Hollywood Homicide\" (2003), \"Firewall\" (2006) and \"Extraordinary Measures\" (2010). One exception was \"What Lies Beneath\" (2000), which grossed over $155million in the United States and $291million worldwide. Ford served as an executive producer on \"K-19: The Widowmaker\" and \"Extraordinary Measures\", both of which were based on true events.\nIn 2004, Ford declined a chance to star in the thriller \"Syriana\", later commenting that \"I didn't feel strongly enough about the truth of the material and I think I made a mistake.\" The role went to George Clooney, who won an Oscar and a Golden Globe for his work. Before that, Ford had passed on a role in another Stephen Gaghan-written film, that of Robert Wakefield in \"Traffic\", which went to Michael Douglas.\nIn 2008, Ford enjoyed success with the release of \"Indiana Jones and the Kingdom of the Crystal Skull\", the first Indiana Jones film in 19 years and another collaboration with Lucas and Spielberg. The film received generally positive reviews and was the second-highest-grossing film worldwide in 2008. Ford later said he would like to star in another sequel \"if it didn't take another 20 years to digest.\"\nOther 2008 work included \"Crossing Over\", directed by Wayne Kramer. In the film, Ford plays an ICE/Homeland Security Investigations Special Agent, working alongside Ashley Judd and Ray Liotta. He also narrated a feature documentary film about the Dalai Lama, \"Dalai Lama Renaissance\". Ford filmed the medical drama \"Extraordinary Measures\" in 2009 in Portland, Oregon. Released on January 22, 2010, the film also starred Brendan Fraser and Alan Ruck. Also in 2010, he co-starred in the film \"Morning Glory\", along with Rachel McAdams, Diane Keaton and Patrick Wilson. Although the film was a disappointment at the box office, Ford's performance was well received by critics, some of whom thought it was his best role in years. In July 2011, Ford starred alongside Daniel Craig and Olivia Wilde in the science-fiction/western hybrid film \"Cowboys &amp; Aliens\". To promote the film, he appeared at San Diego Comic-Con and, apparently surprised by the warm welcome, told the audience, \"I just wanted to make a living as an actor. I didn't know about this.\" Also in 2011, Ford starred in Japanese commercials advertising the video game \"\" for the PlayStation 3.\n2013 began a trend that saw Ford accepting more diverse supporting roles. That year, he co-starred in the corporate espionage thriller \"Paranoia\" with Liam Hemsworth and Gary Oldman, whom he had previously worked with in \"Air Force One\", and also appeared in \"Ender's Game\", \"42\" and \"\".\nFord's performance as Branch Rickey in the film \"42\" was praised by many critics and garnered Ford a nomination as best supporting actor for the Satellite Awards. Initially, Brian Helgeland was hesitant to cast Ford, seeking a character actor for the role of Rickey. However, Ford's persistence and dedication to the role, including studying Rickey's life and adopting significant physical transformations, won Helgeland over. Ford's commitment to embodying Rickey involved wearing a fat suit, prosthetics, and mastering Rickey's distinctive voice and mannerisms. He researched Rickey's life, listened to recordings from the Baseball Hall of Fame, and worked with a voice coach to capture Rickey's distinct speech. \"I loved the language of the guy, I loved his style,\" Ford noted. In a 2023 interview with James Hibberd of \"The Hollywood Reporter\", Ford said Branch Rickey is one of his roles he is most proud of.\nIn 2014, he appeared in \"The Expendables 3\", and the following year, co-starred with Blake Lively in the romantic drama \"The Age of Adaline\" to positive reviews.\nSince 2015: Return to franchise roles and \"Shrinking\".\nFord reprised the role of Han Solo in the long-awaited Star Wars sequel ' (2015), which was highly successful, like its predecessors. During filming on June 11, 2014, Ford suffered what was said to be a fractured ankle when a hydraulic door fell on him. He was airlifted to John Radcliffe Hospital in Oxford, England, for treatment. Ford's son Ben Ford released details on his father's injury, saying that his ankle would likely need a plate and screws, and that filming could be altered slightly, with the crew needing to shoot Ford from the waist up for a short time until he recovered. Ford made his return to filming in mid-August, after a two-month layoff as he recovered from his injury. Ford's character was killed off in \"The Force Awakens\", but it was subsequently announced, via a casting call, that Ford would return in some capacity as Solo in \"Episode VIII\". In February 2016, when the cast for \"Episode VIII\" was confirmed, it was indicated that Ford would not reprise his role in the film after all. When Ford was asked whether Solo could come back in \"some form\", he replied, \"Anything is possible in space.\" He eventually made an uncredited appearance as a vision in ' (2019).\nOn February 26, 2015, Alcon Entertainment announced Ford would reprise his role as Rick Deckard in Denis Villeneuve's science fiction sequel film \"Blade Runner 2049\". The film, and Ford's performance, was very well received by critics upon its release in October 2017. Scott Collura of IGN called it a \"deep, rich, smart film that's visually awesome and full of great sci-fi concepts\" and Ford's role \"a quiet, sort of gut-wrenching interpretation to Deckard and what he must've gone through in the past three decades.\" The film grossed $259.3million worldwide, short of the estimated $400million that it needed to break even. In 2019, Ford had his first voice role in an animated film, as a dog named Rooster in \"The Secret Life of Pets 2\". With filming of a fifth \"Indiana Jones\" film delayed by a year, Ford headlined a big-budget adaptation of Jack London's \"The Call of the Wild\", playing prospector John Thornton. The film was released in February 2020 to a mixed critical reception and its theatrical release was shortened due to the impact of the COVID-19 pandemic on the film industry.\nIn 2022, Ford was cast to star alongside Helen Mirren in the Paramount+ western drama series \"1923\". The two had previously starred together 36 years earlier in \"The Mosquito Coast\". The series premiered in December 2022 to positive reviews, and it is set to run for a total of two seasons. That same year, it was announced that Ford would star in the Apple TV+ comedy drama series \"Shrinking\". The series premiered in January 2023 to positive reviews, with Ford receiving praise for his performance. In a 2023 interview with \"The Hollywood Reporter\", it was revealed that he accepted the roles in both \"1923\" and \"Shrinking\" despite there not being a script at the time. For his work in the series', Ford was nominated for several awards including a Golden Globe for Best Supporting Actor, a Critics' Choice Television Award for Best Supporting Actor in a Comedy Series, his first Screen Actors Guild Award for Outstanding Performance by a Male Actor in a Comedy Series, and his first Emmy Award for Outstanding Supporting Actor in a Comedy Series.\nFord reprised the role of Indiana Jones in \"Indiana Jones and the Dial of Destiny\" (2023), which he later stated would be his last appearance as the character. The film received generally positive reviews, with many critics highlighting Ford's performance. In February 2025, Ford starred alongside Anthony Mackie (the new Captain America) as Thaddeus Ross in the Marvel Cinematic Universe film \"\", replacing William Hurt after the latter's death. That same month, he brought attention to an ongoing strike by video game actors when he voiced support for Troy Baker playing the role of Indiana Jones in the video game \"Indiana Jones and the Great Circle\", speaking out against the use of artificial intelligence.\nPersonal life.\nFord has been married three times and has four biological children and one adopted child. He was first married to Mary Marquardt from 1964 until their divorce in 1979. They had two sons, born in 1966 and 1969. The older son co-owns Ford's Filling Station, a gastropub located at Terminal 5 in Los Angeles International Airport. The younger son is owner of the Ludwig Clothing company and previously owned Strong Sports Gym and the Kim Sing Theater.\nFord's second marriage was to screenwriter Melissa Mathison from March 1983 until their separation in 2000; they divorced in 2004. They had a son, born in 1987, and a daughter, born in 1990. Mathison died in 2015.\nFord began dating actress Calista Flockhart after they met at the 2002 Golden Globe Awards. He proposed to Flockhart over Valentine's Day weekend in 2009. They married on June 15, 2010, in Santa Fe, New Mexico, where Ford was filming \"Cowboys &amp; Aliens\". They are the parents of a son, born in 2001, whom Flockhart had adopted before meeting Ford. Ford and Flockhart live on an ranch in Jackson, Wyoming, where he has lived since the 1980s and approximately half of which he has donated as a nature reserve. They retain a base in the Brentwood neighborhood of Los Angeles. Ford is one of Hollywood's most private actors, guarding much of his personal life. Although Ford's fans have speculated that he has social anxiety disorder, he said in 2023 that he instead has \"an abhorrence of boring situations\".\nIn her 2016 autobiography \"The Princess Diarist\", Carrie Fisher wrote that she and Ford had a three-month affair in 1976 during the filming of \"Star Wars\".\nAviation.\nFord is a licensed pilot of both fixed-wing aircraft and helicopters. On several occasions, he has provided emergency helicopter services at the request of local authorities in Wyoming. In 2000, he airlifted an EMT to a 20-year-old hiker who was suffering from dehydration on Table Mountain. The following year, he was flagged down in his helicopter by a 13-year-old Boy Scout who got lost near Yellowstone National Park.\nFord began flight training in the 1960s at Wild Rose Idlewild Airport in Wild Rose, Wisconsin, flying in a Piper PA-22 Tri-Pacer, but at $15 an hour (), he could not afford to continue the training. In the mid-1990s, he bought a used Gulfstream II and asked one of his pilots, Terry Bender, to give him flying lessons. They started flying a Cessna 182 Skylane out of Jackson, Wyoming, later switching to Teterboro Airport in Teterboro, New Jersey, flying a Cessna 206 in which he made his first solo flight.\nFord's aircraft are kept at Santa Monica Airport. His Bell 407 helicopter is often hangered at Jackson and has been used by Ford in two mountain rescues during his assigned duty time with Teton County Search and Rescue. During one of the rescues, Ford recovered a lost and disoriented hiker. She boarded his helicopter and promptly vomited into one of the rescuers' caps, unaware of who the pilot was until much later; \"I can't believe I barfed in Harrison Ford's helicopter!\" she said later.\nFord flies his de Havilland Canada DHC-2 Beaver (registration N28S) more than any of his other aircraft, and has repeatedly said that he likes this aircraft and the sound of its Pratt &amp; Whitney R-985 radial engine. According to Ford, it had been flown in the CIA's Air America operations and was riddled with bullet holes that had to be patched up.\nIn March 2004, Ford became chairman of the Experimental Aircraft Association (EAA)'s Young Eagles program, founded by then-EAA president Tom Poberezny and fellow actor-pilot Cliff Robertson. Ford was asked to take the position by Greg Anderson, Senior Vice President of the EAA at the time, to replace General Chuck Yeager, who was vacating the post that he had held for many years. Ford at first was hesitant, but later accepted the offer and has made appearances with the Young Eagles at the EAA AirVenture Oshkosh gathering at Oshkosh, Wisconsin, for two years. In July 2005, at the gathering in Oshkosh, Ford agreed to accept the position for another two years. He has flown over 280 children as part of the Young Eagles program, usually in his DHC-2 Beaver, which can seat the actor and five children. Ford stepped down as program chairman in 2009 and was replaced by Captain Chesley Sullenberger and First Officer Jeff Skiles. He is involved with the EAA chapter in Driggs, Idaho, just over the Teton Range from Jackson, Wyoming. On July 28, 2016, Ford flew the two millionth Young Eagle at the EAA AirVenture convention, making it the most successful youth aviation introduction program in history.\nAs of 2009, Ford appears in Internet advertisements for General Aviation Serves America, a campaign by the advocacy group Aircraft Owners and Pilots Association (AOPA). He has also appeared in several independent aviation documentaries, including \"Wings Over the Rockies\" (2009), \"\" (2014), and \"Living in the Age of Airplanes\" (2015).\nFord is an honorary board member of the humanitarian aviation organization Wings of Hope, and has made several trips to Washington, D.C., to fight for pilots' rights. He has also donated substantial funds to aerobatic champion Sean Tucker's charitable program, The Bob Hoover Academy (named after legendary aviator Bob Hoover), which educates at-risk teens in central California and teaches them how to fly.\nIncidents.\nOn August 22, 1987, Ford was traveling as a passenger with Clint Eastwood and Sondra Locke aboard a Gulfstream III when the jet developed an engine fire and stuck landing gear during a Paris-to-L.A. flight and was forced to land in Bangor, Maine. The charter company owning the G-3 sent another jet and mechanics to Bangor, and the group flew out on that plane the next day.\nOn October 23, 1999, Ford was involved in the crash of a Bell 206L4 LongRanger helicopter. The NTSB accident report states that Ford was piloting the aircraft over the Lake Piru riverbed near Santa Clarita, California, on a routine training flight. While making his second attempt at an autorotation with powered recovery, the aircraft was unable to recover power after the sudden drop in altitude. It landed hard and skidded forward in the loose gravel before flipping onto its side. Neither Ford nor the instructor pilot suffered any injuries, though the helicopter was seriously damaged.\nOn March 5, 2015, Ford's plane, believed to be a Ryan PT-22 Recruit, made an emergency landing on the Penmar Golf Course in Venice, California, after it lost engine power. He was taken to Ronald Reagan UCLA Medical Center, where he was reported to be in fair to moderate condition. Ford suffered a broken pelvis and broken ankle during the accident, as well as other injuries.\nOn February 13, 2017, Ford landed an Aviat Husky at John Wayne Airport in Orange County, California, on the taxiway left of runway 20L. A Boeing 737 was holding short of the runway on the taxiway when Ford overflew them.\nOn April 24, 2020, at the Los Angeles Hawthorne Airport while piloting his Husky, Ford crossed a runway where another aircraft was landing. According to the FAA, the two planes were about 3,600 feet from each other and there was no danger of collision. A representative of Ford later said that he \"misheard\" an instruction given to him by air traffic control.\nActivism.\nEnvironmental work.\nFord is vice-chair of Conservation International, an American nonprofit environmental organization headquartered in Arlington, Virginia. The organization's intent is to protect nature. Since 1992, Ford has lent his voice to a series of public service messages promoting environmental involvement for EarthShare, an American federation of environmental and conservation charities. He has acted as a spokesperson for Restore Hetch Hetchy, a non-profit organization dedicated to restoring Yosemite National Park's Hetch Hetchy Valley to its original condition. Ford also appears in the documentary series \"Years of Living Dangerously\", which reports on people affected by and seeking solutions to climate change.\nIn 1993, the arachnologist Norman Platnick named a new species of spider \"Calponia harrisonfordi\", and in 2002 the entomologist Edward O. Wilson named a new ant species \"Pheidole harrisonfordi\" (in recognition of Harrison's work as Vice Chairman of Conservation International). The Peruvian snake species \"Tachymenoides harrisonfordi\" was named for Ford in 2023.\nIn September 2013, Ford, while filming an environmental documentary in Indonesia, interviewed the Indonesian Forestry Minister, Zulkifli Hasan. After the interview, Ford and his crew were accused of \"harassing state institutions\" and publicly threatened with deportation. Questions within the interview concerned the Tesso Nilo National Park, Sumatra. It was alleged the Minister of Forestry was given no prior warning of questions nor the chance to explain the challenges of catching illegal loggers. Ford was provided an audience with the Indonesian President, Susilo Bambang Yudhoyono, during which he expressed concerns regarding Indonesia's environmental degradation and the government efforts to address climate change. In response, the President explained Indonesia's commitment to preserving its oceans and forests.\nIn 2019, on behalf of Conservation International, Ford gave an impassioned speech during the United Nations' Climate Action Summit in New York on the destruction of the Amazon rainforest and its effect on climate change for the rest of the world. Ford urged his audience to listen to 'angry young people' trying to make a difference in the situation, emphasizing, \"The most important thing we can do for them is to get the hell out of their way.\"\nIn 2025, the E.O. Wilson Biodiversity Foundation gave Ford its inaugural E.O. Wilson Legacy Award for Transformative Conservation Leadership.\nPolitical views.\nLike his parents, Ford is a lifelong Democrat.\nOn September 7, 1995, Ford testified before the U.S. Senate Foreign Relations Committee in support of the Dalai Lama and an independent Tibet. In 2007, he narrated the documentary \"Dalai Lama Renaissance\".\nIn 2000, Ford donated $1,000 to the presidential campaigns of Bill Bradley, Al Gore, and John McCain.\nIn 2003, he publicly condemned the Iraq War and called for \"regime change\" in the United States. He also criticized Hollywood for making movies which were \"more akin to video games than stories about human life and relationships\", and he called for more gun control in the United States.\nIn 2009, Ford signed a petition calling for the release of film director Roman Polanski, who had been arrested in Switzerland in relation to his 1977 charge for drugging and raping a 13-year-old girl.\nAfter Republican presidential candidate Donald Trump said his favorite role of Ford's was \"Air Force One\" because he \"stood up for America\", Ford responded that it was just a film and made critical statements against Trump's presidential bid.\nFord endorsed Joe Biden's 2020 presidential campaign against Trump. He said that he wanted to \"encourage people to support candidates that will support the environment\" and felt that under Trump, the U.S. had \"lost some of our credibility in the world\". Along with Mark Hamill, Ford worked with the anti-Trump Republican group The Lincoln Project to produce and narrate a 2020 election ad attacking Trump's disparaging of Anthony Fauci.\nOn November 2, 2024, he endorsed Kamala Harris's 2024 presidential campaign.\nArchaeology.\nFollowing on his success portraying the archaeologist Indiana Jones, Ford also plays a part in supporting the work of professional archaeologists. He serves as a General Trustee on the Governing Board of the Archaeological Institute of America (AIA), North America's oldest and largest organization devoted to the world of archaeology. Ford assists them in their mission of increasing public awareness of archaeology and preventing looting and the illegal antiquities trade.\nActing credits and accolades.\nThroughout his career, Ford has received significant recognition for his work in the entertainment industry. In 1986, he was nominated for Best Actor at the 58th Academy Awards for his performance in \"Witness\", a role for which he also received BAFTA and Golden Globe nominations in the same category. Three additional Golden Globe nominations went to Ford in 1987, 1994 and 1996 for his performances in \"The Mosquito Coast\", \"The Fugitive\" and \"Sabrina\". In 2000, he was the recipient of the AFI Life Achievement Award from the American Film Institute for his body of work, presented to him by two of his closest collaborators and fellow industry giants, George Lucas and Steven Spielberg. In 2002, he was given the Cecil B. DeMille Award, another career achievement honor, from the Hollywood Foreign Press Association at the 59th Golden Globe Awards ceremony. On May 30, 2003, Ford received a star on the Hollywood Walk of Fame.\nIn 2006, he received the Jules Verne Award, given to an actor who has \"encouraged the spirit of adventure and imagination\" throughout their career. He was presented with the first-ever Hero Award at the 2007 Scream Awards for his many iconic roles, including Indiana Jones and Han Solo (both of which earned him a collective three Saturn Awards for Best Actor in 1982, 2024 and 2016, respectively), and in 2008 he received the Spike TV's Guy's Choice Award for \"Brass Balls\". In 2015, Ford received the Albert R. Broccoli Britannia Award for Worldwide Contribution to Entertainment from BAFTA Los Angeles. In 2018, Ford was honored by the SAG-AFTRA Foundation with the Artists Inspiration Award for both his acting and philanthropic work alongside fellow honoree Lady Gaga. SAG-AFTRA Foundation Board President JoBeth Williams in the press release said, \"Harrison Ford is an acting legend in every known galaxy, but what many do not know are the decades of philanthropic service and leadership he has given to Conservation International to help protect our planet.\"\nOther prestigious film honors for Ford include an Honorary Cesar, an Honorary Palme d'Or from the Cannes Film Festival, the Career Achievement Award from the Hollywood Film Awards, the Kirk Douglas Award for Excellence in Film from the Santa Barbara International Film Festival, the Box Office Star of the Century Award from the National Association of Theatre Owners and the Lifetime Achievement Award from both the Locarno Film Festival and the Zurich Film Festival.\nFord has also been honored multiple times for his involvement in general aviation, receiving the Living Legends of Aviation Award and the Experimental Aircraft Association's Freedom of Flight Award in 2009, the Wright Brothers Memorial Trophy in 2010, and the Al Ueltschi Humanitarian Award in 2013. \"Flying\" magazine ranked him number 48 on their 2013 list of the 51 Heroes of Aviation. In 2024, Ford was a recipient of the Disney Legends Award for his outstanding film contributions to The Walt Disney Company.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
