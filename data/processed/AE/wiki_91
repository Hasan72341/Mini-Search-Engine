{"id": "56125", "revid": "6326132", "url": "https://en.wikipedia.org/wiki?curid=56125", "title": "Sioux", "text": "Indigenous people of North America\nThe Sioux or Oceti Sakowin ( ; Dakota/Lakota: ) are groups of Native American tribes and First Nations people from the Great Plains of North America. The Sioux have two major linguistic divisions: the Dakota and Lakota peoples (translation: 'friend, ally' referring to the alliances between the bands). Collectively, they are the , or 'Seven Council Fires'. The term \"Sioux\", an exonym from a French transcription () of the Ojibwe term , can refer to any ethnic group within the Great Sioux Nation or to any of the nation's many language dialects.\nBefore the 17th century, the Santee Dakota (: 'Knife', also known as the Eastern Dakota) lived around Lake Superior with territories in present-day northern Minnesota and Wisconsin. They gathered wild rice, hunted woodland animals, and used canoes to fish. Wars with the Ojibwe throughout the 18th century pushed the Dakota west into southern Minnesota, where the Western Dakota (Yankton, Yanktonai) and Lakota (Teton) lived. In the 19th century, the Dakota signed land cession treaties with the United States for much of their Minnesota lands. The United States' failure to make treaty payments or provide rations on time led to starvation and the Dakota War of 1862, which resulted in the Dakota's exile from Minnesota. They were forced onto reservations in Nebraska, North Dakota, and South Dakota, and some fled to Canada. After 1870, the Dakota people began to return to Minnesota, creating the present-day reservations in the state. The Yankton and Yanktonai Dakota ( and ; 'Village-at-the-end' and 'Little village-at-the-end'), collectively also called by the endonym , lived near the Minnesota River before ceding their land and moving to South Dakota in 1858. Despite ceding their lands, their treaty with the US government allowed them to maintain their traditional role in the as the caretakers of the Pipestone Quarry, a cultural center for Sioux people. Considered the Western Dakota, they have in the past been erroneously classified as Nakota. Nakota are the Assiniboine and Stoney of Western Canada and Montana.\nThe Lakota, also called Teton (; possibly 'dwellers on the prairie'), are the westernmost Sioux, known for their Plains Indians hunting and warrior culture. With the arrival of the horse in the 18th century, the Lakota became a powerful tribe on the Northern Plains by the 1850s. They fought the US Army in the Sioux Wars and defeated the 7th Cavalry Regiment at the Battle of Little Big Horn. The armed conflicts with the US ended with the Wounded Knee Massacre.\nThroughout the 20th and 21st centuries, the Dakota and Lakota continued to fight for their treaty rights, including the Wounded Knee incident, Dakota Access Pipeline protests, and the 1980 Supreme Court case \"United States v. Sioux Nation of Indians\", in which the court ruled that the US government had illegally taken tribal lands covered by the Fort Laramie Treaty of 1868 and that the tribe was owed compensation plus interest. As of 2018, this amounted to more than $1 billion; the Sioux have refused the payment, demanding instead the return of the Black Hills. Today, the Sioux maintain many separate tribal governments across several reservations and communities in North Dakota, South Dakota, Nebraska, Minnesota, and Montana in the United States and reserves in Manitoba and Saskatchewan in Canada.\nEtymology.\nThe Sioux people refer to their whole nation of people (sometimes called the Great Sioux Nation) as the (meaning 'Seven Council Fires'). Each fire symbolizes an (people or nation). Today the seven nations that comprise the are:\nThey are also referred to as the Lakota or Dakota based on dialect differences. In any of the dialects, \"Lakota\" or \"Dakota\" translates as 'friend, ally', referring to the alliances between the bands.\nThe name \"Sioux\" was adopted in English by the 1760s from French. It is abbreviated from the French , first attested by Jean Nicolet in 1640. The name is sometimes said to be derived from (plural ), an Ojibwe-language exonym for the Sioux meaning 'little snakes' or 'enemy' (compare 'big snakes', used for the Iroquois). The French pluralized the Ojibwe singular by adding the French plural suffix to form , which was later shortened to . The Proto-Algonquian form , meaning 'Northern Iroquoian', has reflexes in several daughter languages that refer to a small rattlesnake (massasauga, \"Sistrurus\"). An alternative explanation is derivation from an (Algonquian) exonym, (plural ), from a verb meaning 'to speak a foreign language'. The current Ojibwe term for the Sioux and related groups is (singular ), meaning 'roasters'. Presumably, this refers to the style of cooking the Sioux used in the past.\nIn recent times, some of the tribes have formally or informally reclaimed traditional names: the Rosebud Sioux Tribe is also known as the , and the Oglala often use the name , rather than the formal Oglala Sioux Tribe or OST. The alternative English spelling of \"Ogallala\" is considered incorrect.\nCulture.\nTraditional social structure.\nThe traditional social structure of the strongly relied on kinship ties that extend beyond human interaction and includes the natural and supernatural worlds.\u00a0\"Mit\u00e1kuye Oy\u00e1s\u2019i\u014b\" ('all are related') represents a spiritual belief of how human beings should ideally act and relate to other humans, the natural world, the spiritual world, and to the cosmos. The represents the political and economic structure of traditional society.\n(community) kinship.\nPrior to the arrival of Europeans, the different villages (, 'tribe, nation') consisted of many ('camp circles'), which were large extended families united by kinship (, 'immediate family'). varied in size, were led by a leader appointed by an elder council and were nicknamed after a prominent member or memorable event associated with the band. Dakota ethnographer Ella Cara Deloria noted the kinship ties were all-important, they dictated and demanded all phrases of traditional life:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nDuring the fur trade era, the refused to trade only for economic reasons. Instead the production and trade of goods was regulated by rules of kinship bonds. Personal relationships were pivotal for success: in order for European-Americans to trade with the , social bonds had to be created. The most successful fur traders married into the kinship society, which also raised the status of the family of the woman through access to European goods. Outsiders are also adopted into the kinship through the religious ceremony. Early European explorers and missionaries who lived among the Dakota were sometimes adopted into the (known as \"hu\u014bka relatives\"), such as Louis Hennepin who noted, \"this help'd me to gain credit among these people\". During the later reservation era, districts were often settled by clusters of families from the same .\nReligion.\nThe traditional social system extended beyond human interaction into the supernatural realms. It is believed that \"Wak\u021f\u00e1\u014b Th\u00e1\u014bka\" ('Great Spirit/Great Mystery') created the universe and embodies everything in the universe as one. The preeminent symbol of Sioux religion is the \"\u010cha\u014bgl\u00e9ska Wak\u021fa\u014b\" or medicine wheel ('sacred hoop'), which visually represents the concept that everything in the universe is intertwined. The creation stories of the describe how the various spirits were formed from . Black Elk describes the relationships with as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nPrayer is believed to invoke relationships with one's ancestors or spiritual world. The Lakota word for 'prayer', \"wo\u010dh\u00e9kiye\", means 'to call on for aid, to pray, to claim relationship with'. Their primary cultural prophet is Ptes\u00e1\u014bwi\u014b, White Buffalo Calf Woman, who came as an intermediary between T\u021f\u00e1\u014bka and humankind to teach them how to be good relatives by introducing the Seven Sacred Rites and the \"\u010dha\u014bn\u00fa\u014bpa\" (sacred pipe). The seven ceremonies are \"In\u00edpi\" (purification lodge), (crying for vision), (Sun Dance), (making of relatives), (female puberty ceremony), (throwing of the ball) and (soul keeping). Each part of the sacred pipe (stem, bowl, tobacco, breath, and smoke) is symbolic of the relationships of the natural world, the elements, humans and the spiritual beings that maintain the cycle of the universe.\nDreams can also be a means of establishing relationships with spirits and are important to the . One can gain supernatural powers through dreams. Dreaming of the Wak\u00ed\u014bya\u014b (thunder beings) is believed to involuntarily make someone a \"Hey\u00f3k\u021fa\", a sacred clown. Black Elk, a famous said: \"Only those who have had visions of the thunder beings of the west can act as heyokas. They have sacred power and they share some of this with all the people, but they do it through funny actions\".\nGovernance.\nHistorical leadership organization\nThe of the assembled each summer to hold council, renew kinships, decide tribal matters, and participate in the Sun Dance. The seven divisions selected four leaders known as from among the leaders of each division. Being one of the four leaders was considered the highest honor for a leader; however, the annual gathering meant the majority of tribal administration was cared for by the usual leaders of each division. The last meeting of the Seven Council Fires was in 1850. The historical political organization was based on individual participation and the cooperation of many to sustain the tribe's way of life. Leaders were chosen based upon noble birth and demonstrations of chiefly virtues, such as bravery, fortitude, generosity, and wisdom.\nGender roles.\nWithin the Sioux tribes, there were defined gender roles. The men in the village were tasked as the hunters, traveling outside the village. The women within the village were in charge of making clothing and similar articles while also taking care of, and owning, the house. However, even with these roles, both men and women held power in decision-making tasks and sexual preferences were flexible and allowed. The term \"w\u00ed\u014btke\" refers to men who partook in traditional feminine duties while the term ('crazy woman') was used for women who rejected their roles as either mother or wife to be a prostitute.\nFuneral practices.\nTraditional funeral practices.\nIt is a common belief amongst Siouan communities that the spirit of the deceased travels to an afterlife. In traditional beliefs, this spiritual journey was believed to start once funeral proceedings were complete and spanned over a course of four days. Mourning family and friends took part in that four-day wake in order to accompany the spirit to its resting place. In the past, bodies were not embalmed but put up on a burial tree or scaffold for one year before a ground burial. A platform to rest the body was put up on trees or, alternately, placed on four upright poles to elevate the body from the ground. The bodies were securely wrapped in blankets and cloths, along with many of the deceased personal belongings and were always placed with their head pointed towards the south. Mourning individuals spoke to the body and offer food as if it were still alive. This practice, along with the Ghost Dance, helped individuals mourn and connect the spirits of the deceased with those who were alive. The only time a body was buried in the ground right after their death was if the individual was murdered: the deceased were placed in the ground with their heads towards the south, while faced down along with a piece of fat in their mouth.\nContemporary funeral practices.\nAccording to Pat Janis, director of the Oglala Sioux Tribe's Burial Assistance Program, funeral practices of communities today are often a mix of traditions and contemporary Christian practices. While tree burials and scaffold burials are not practiced anymore, it is also now rare to see families observe a four-day wake period. Instead, the families opt for one- or two-day wake periods which include a funeral feast for all the community. Added to the contemporary funeral practices, it is common to see prayers conducted by a medicine man along with traditional songs often sung with a drum. One member of the family is also required to be present next to the body at all times until the burial. Gifts are placed within the casket to aid with the journey into the afterworld, which is still believed to take up to four days after death.\nHistory.\nCreation stories.\nThere are a number of creation stories within the tribes. One widely noted creation story for Dakota people is at Bd\u00f3te, the area where the Minnesota and Mississippi Rivers meet. Lakota people relate to Wind Cave in South Dakota as their site of emergence.\nAncestral Sioux.\nThe ancestral Sioux most likely lived in the Central Mississippi Valley region and later in Minnesota for at least two or three thousand years. The ancestors of the Sioux arrived in the northwoods of central Minnesota and northwestern Wisconsin from the Central Mississippi River shortly before 800 AD. Archaeologists refer to them as the Woodland Blackduck-Kathio-Clam River Continuum. Around 1300 AD, they adopted the characteristics of a northern tribal society and became known as the Seven Council Fires.\nFirst contact with Europeans.\nThe Dakota are first recorded to have resided at the source of the Mississippi River and the Great Lakes during the seventeenth century. They were dispersed west in 1659 due to warfare with the Iroquois. During the 1600s, the Lakota began their expansion westward into the Plains, taking with them the bulk of people of the . By 1700 the Dakota were living in Wisconsin and Minnesota. As the Sioux nation began expanding with access to horses, the Dakota were put in a weakened position to defend the eastern border: new diseases (smallpox and malaria) and increased intertribal warfare (between the migration of tribes fleeing the Iroquois into their territory of present-day Wisconsin) put a strain on their ability to maintain their territory. As a result, their population in the Mississippi valley is believed to have declined by one-third between 1680 and 1805.\nFrench trade and intertribal warfare.\nLate in the 17th century, the Dakota entered into an alliance with French merchants. The French were trying to gain advantage in the struggle for the North American fur trade against the English, who had recently established the Hudson's Bay Company. Algonquian peoples such as the Ojibwe, Potawatomi and Odawa were among the first to trade with the French as they migrated into the Great Lakes region. Upon their arrival, Dakota were in an economic alliance with them until the Dakota were able to trade directly for European goods with the French. The first recorded encounter between the Sioux and the French occurred when Radisson and Groseilliers reached what is now Wisconsin during the winter of 1659\u201360. Later visiting French traders and missionaries included Claude-Jean Allouez, Daniel Greysolon Duluth, and Pierre-Charles Le Sueur who wintered with Dakota bands in early 1700.\nThe Dakota began to resent the Ojibwe trading with the hereditary enemies of the Sioux, the Cree and Assiniboine. Tensions rose in the 1720s into a prolonged war in 1736. The Dakota lost their traditional lands around Leech Lake and Mille Lacs as they were forced south along the Mississippi River and St. Croix River Valley as a result of the battles. These intertribal conflicts also made it dangerous for European fur traders: whichever side they traded with, they were viewed as enemies from the other. For example, in 1736 a group of Sioux killed Jean Baptiste de La V\u00e9rendrye and twenty other men on an island in Lake of the Woods for such reasons. However, trade with the French continued until the French gave up North America in 1763. Europeans repeatedly tried to make truce between the warring tribes in order to protect their interests.\nOne of the larger battles between the Dakota and Ojibwe took place in 1770 fought at the Dalles of the St. Croix. According to William Whipple Warren, a M\u00e9tis historian, the fighting began when the Meskwaki (Fox) engaged the Ojibwe (their hereditary enemies) around St. Croix Falls. The Sioux were the former enemies of the Meskwaki and were enlisted to make a joint attack against the Ojibwe. The Meskwaki were first to engage with the large Ojibwe war party led by Waubojeeg: the Meskwaki allegedly boasted to the Dakota to hold back as they would quickly destroy their enemies. When the Dakota joined the battle, they had the upper hand until Sandy Lake Ojibwe reinforcements arrived. The Dakota were driven back and Warren states: \"Many were driven over the rocks into the boiling floods below, there to find a watery grave. Others, in attempting to jump into their narrow wooden canoes, were capsized into the rapids\". While Dakota and Ojibwe suffered heavy losses, the Meskwaki were left with the most dead and forced to join their relatives, the Sauk people. The victory for the Ojibwe secured control of the Upper St. Croix and created an informal boundary between the Dakota and Ojibwe around the mouth of the Snake River.\nAs the Lakota entered the prairies, they adopted many of the customs of the neighboring Plains tribes, creating new cultural patterns based on the horse and fur trade. Meanwhile, the Dakota retained many of their Woodlands features. By 1803, the three divisions of the Sioux (Western/Eastern Dakota and Lakota) were established in their different environments and had developed their own distinctive lifeways. However, due to the prevalent cultural concept of thiy\u00f3\u0161paye (community), the three divisions maintained strong ties throughout the changing times to present day.\nTreaties and reservation period beginnings.\nIn 1805, the Dakota signed their first treaty with the American government. Zebulon Pike negotiated for 100,000 acres of land at the confluence of the St. Croix River about what now is Hastings, Minnesota and the confluence of the Minnesota River and Mississippi River about what now is St. Paul, Minnesota. The Americans wanted to establish military outposts and the Dakota wanted a new source of trading. An American military post was not established at the confluence of the St. Croix with the Mississippi, but Fort Snelling was established in 1819 along the Minnesota and Mississippi rivers. In return, Dakota were promised the ability to \"pass and repass, hunt, or make other uses of the said districts as they have formerly done\".\nIn an attempt to stop intertribal warfare and to better able to negotiate with tribes, the American government signed the 1825 Treaty of Prairie du Chien with the Dakota, Ojibwe, Menominee, Ho-Chunk, Sac and Fox, Iowa, Potawatomi, and Odawa tribes. In the 1830 Treaty of Prairie de Chien, the Western Dakota (Yankton, Yanktonai) ceded their lands along the Des Moines river to the American government. Living in what is now southeastern South Dakota, the leaders of the Western Dakota signed the Treaty of April 19, 1858, which created the Yankton Sioux Reservation. Pressured by the ongoing arrival of Europeans, Yankton chief Struck by the Ree told his people, \"The white men are coming in like maggots. It is useless to resist them. They are many more than we are. We could not hope to stop them. Many of our brave warriors would be killed, our women and children left in sorrow, and still we would not stop them. We must accept it, get the best terms we can get and try to adopt their ways.\" Despite ceding their lands, the treaty allowed the Western Dakota to maintain their traditional role in the O\u010dh\u00e9thi \u0160ak\u00f3wi\u014b as the caretakers of the Pipestone Quarry, which is the cultural center of the Sioux people.\nWith the creation of Minnesota Territory by the US in 1849, the Eastern Dakota (Sisseton, Wahpeton, Mdewakanton, and Wahpekute) people were pressured to cede more of their land. The reservation period for them began in 1851 with the signing of the Treaty of Mendota and the Treaty of Traverse des Sioux. The Treaty of Mendota was signed near Pilot Knob on the south bank of the Minnesota River and within sight of Fort Snelling. The treaty stipulated that the Mdewakanton and Wahpekute bands were to receive US$1,410,000 in return for relocating to the Lower Sioux Agency on the Minnesota River near present-day Morton, Minnesota along with giving up their rights to a significant portion of southern Minnesota. In the Treaty of Traverse des Sioux, the Sisseton and Wahpeton bands of the Dakota ceded 21 million acres for $1,665,000, or about 7.5 cents an acre. However, the American government kept more than 80% of the funds with only the interest (5% for 50 years) being paid to the Dakota.\nThe US set aside two reservations for the Sioux along the Minnesota River, each about wide and long. Later the government declared these were intended to be temporary, in an effort to force the Sioux out of Minnesota. The Upper Sioux Agency for the Sisseton and Wahpeton bands was established near Granite Falls, Minnesota, while the Lower Sioux Agency for the Mdewakanton and Wahpekute bands was established about thirty miles downstream near what developed as Redwood Falls, Minnesota. The Upper Sioux were not satisfied with their reservation because of low food supplies, but as it included several of their old villages, they agreed to stay. The Lower Sioux were displaced from their traditional woodlands and were dissatisfied with their new territory of mostly prairie.\nThe US intended the treaties to encourage the Sioux to convert from their nomadic hunting lifestyle into more European-American settled farming, offering them compensation in the transition. By 1858, the Dakota only had a small strip of land along the Minnesota River, with no access to their traditional hunting grounds. They had to rely on treaty payments for their survival, which were often late. The forced change in lifestyle and the much lower than expected payments from the federal government caused economic suffering and increased social tensions within the tribes. By 1862, many Dakota were starving and tensions erupted in the Dakota War of 1862.\nDakota War of 1862 and the Dakota diaspora.\nBy 1862, shortly after a failed crop the year before and a winter starvation, the federal payment was late. The local traders refused to issue any credit to the Dakota. One trader, Andrew Myrick, went so far as to say, \"If they're hungry, let them eat grass.\"\nOn August 16, 1862, the treaty payments to the eastern Dakota arrived in St. Paul, Minnesota, and were brought to Fort Ridgely the next day. However, they arrived too late to prevent the war. On August 17, 1862, the Dakota War began when a few Santee men murdered a white farmer and most of his family. They inspired further attacks on white settlements along the Minnesota River. On August 18, 1862, Little Crow of the Mdewakanton band led a group that attacked the Lower Sioux Agency (or Redwood Agency) and trading post located there. Later, settlers found Myrick among the dead with his mouth stuffed full of grass. Many of the upper Dakota (Sisseton and Wahpeton) wanted no part in the attacks with the majority of the 4,000 members of the Sisseton and Wahpeton opposed to the war. Thus their bands did not participate in the early killings. Historian Mary Wingerd has stated that it is \"a complete myth that all the Dakota people went to war against the United States\" and that it was rather \"a faction that went on the offensive\".\nMost of Little Crow's men surrendered shortly after the Battle of Wood Lake at Camp Release on September 26, 1862. Little Crow was forced to retreat sometime in September 1862. He stayed briefly in Canada but soon returned to the western Minnesota. He was killed on July 3, 1863, near Hutchinson, Minnesota while gathering raspberries with his teenage son. The pair had wandered onto the land of a settler Nathan Lamson, who shot at them to collect bounties. Once it was discovered that the body was of Little Crow, his skull and scalp were put on display by the Minnesota Historical Society in St. Paul, Minnesota. The State held the trophies until 1971 when it returned the remains to Little Crow's grandson. For killing Little Crow the state increased the bounty to $500 when it paid Lamson.\nOn November 5, 1862, a military tribunal found 303 mostly Mdewakanton tribesmen guilty of rape, murder and atrocities of hundreds of Minnesota settlers. They were sentenced to be hanged. The men had no attorneys or defense witnesses, and many were convicted in less than five minutes. President Abraham Lincoln commuted the death sentences of 284 of the warriors, while signing off on the hanging of 38 Santee men on December 26, 1862, in Mankato, Minnesota. It was the largest mass-execution in US history, on US soil. The men remanded by order of President Lincoln were sent to a prison in Iowa, where more than half died.\nAfterwards, the US Congress annulled all treaty agreements with the eastern Dakota and expelled the eastern Dakota with the Forfeiture Act of February 16, 1863, meaning all lands held by the eastern Dakota, and all annuities due to them, were forfeited to the US government. During and after the hostilities, the majority of eastern Dakota fled Minnesota for the Dakota territory or Canada. Some settled in the James River Valley in a short-lived reservation before being forced to move to Crow Creek Reservation on the east bank of the Missouri River. There were as few as 50 eastern Dakota left in Minnesota by 1867. Many had fled to the Santee Sioux Reservation in Nebraska (created 1863), the Flandreau Reservation (created 1869 from members who left the Santee Reservation), the Lake Traverse and Spirit Lake Reservations (both created 1867). Those who fled to Canada throughout the 1870s now have descendants residing on nine small Dakota Reserves, five of which are located in Manitoba (Sioux Valley, Dakota Plain, Dakota Tipi, Birdtail Creek, and Canupawakpa Dakota) and the remaining four (Standing Buffalo, White Cap, Round Plain , and Wood Mountain) in Saskatchewan. A few Dakota joined the Yanktonai and moved further west to join with the Lakota bands to continue their struggle against the United States military, later settling on the Fort Peck Reservation in Montana.\nWestward expansion of the Lakota.\nPrior to the 1650s, the division of the known as the Lakota was noted as being located east of the Red River, and living on the fringes of the prairies and woods of the prairies of southern Minnesota and the eastern Dakotas by at least 1680. According to Baptiste Good's winter count, the Lakota had horses by 1700. While the Dakota continued a subsistence cycle of corn, wild rice and hunting woodland animals, the Lakota increasingly became reliant on bison for meat and its by-products (housing, clothing, tools) as they expanded their territory westward with the arrival of the horse. After their adoption of horse culture, Lakota society centered on the buffalo hunt on horseback.\nBy the 19th century, the typical year of the Lakota was a communal buffalo hunt as early in spring as their horses had recovered from the rigors of the winter. In June and July, the scattered bands of the tribes gathered together into large encampments, which included ceremonies such as the Sun Dance. These gatherings afforded leaders to meet to make political decisions, plan movements, arbitrate disputes, and organize and launch raiding expeditions or war parties. In the fall, people split into smaller bands to facilitate hunting to procure meat for the long winter. Between the fall hunt and the onset of winter was a time when Lakota warriors could undertake raiding and warfare. With the coming of winter snows, the Lakota settled into winter camps, where activities of the season, ceremonies and dances as well as trying to ensure adequate winter feed for their horses.\nThey began to dominate the prairies east of the Missouri river by the 1720s. At the same time, the Lakota branch split into two major sects, the Sa\u00f4ne who moved to the Lake Traverse area on the South Dakota\u2013North Dakota\u2013Minnesota border, and the Ogl\u00e1la-Si\u010dh\u00e1\u014b\u01e7u who occupied the James River valley. However, by about 1750 the Sa\u00f4ne had moved to the east bank of the Missouri River, followed 10 years later by the Ogl\u00e1la and Si\u010dh\u00e1\u014b\u01e7u (Brul\u00e9). By 1750, they had crossed the Missouri River and encountered Lewis and Clark in 1804. Initial United States contact with the Lakota during the Lewis and Clark Expedition of 1804\u20131806 was marked by a standoff. Lakota bands refused to allow the explorers to continue upstream, and the expedition prepared for battle, which never came. In 1776, the Lakota defeated the Cheyenne for the Black Hills, who had earlier taken the region from the Kiowa. The Cheyenne then moved west to the Powder River country, and the Lakota made the Black Hills their home.\nAs their territory expanded, so did the number of rival groups they encountered. They secured an alliance with the Northern Cheyenne and Northern Arapaho by the 1820s as intertribal warfare on the plains increased amongst the tribes for access to the dwindling population of buffalo. The alliance fought the Mandan, Hidatsa and Arikara for control of the Missouri River in North Dakota. By the 1840s, their territory expanded to the Powder River country in Montana, in which they fought with the Crow. Their victories over these tribes during this time period were aided by the fact those tribes were decimated by European diseases. Most of the Mandan, Hidatsa and Arikara were killed by smallpox and almost half the population of the Crow were killed due to smallpox, cholera and other diseases. In 1843, the southern Lakotas attacked Pawnee Chief Blue Coat's village near the Loup in Nebraska, killing many and burning half of the earth lodges, and 30 years later, the Lakota again inflicted a blow so severe on the Pawnee during the Massacre Canyon battle near Republican River. By the 1850s, the Lakota were known as the most powerful tribe on the Plains.\nFort Laramie Treaty of 1851.\nThe Fort Laramie Treaty of 1851 was signed on September 17, 1851, between US treaty commissioners and representatives of the Cheyenne, Sioux, Arapaho, Crow, Assiniboine, Mandan, Hidatsa, and Arikara Nations. The treaty was an agreement between nine more or less independent parties. The treaty set forth traditional territorial claims of the tribes as among themselves. The United States acknowledged that all the land covered by the treaty was Indian territory and did not claim any part of it. The boundaries agreed to in the Fort Laramie treaty of 1851 were used to settle a number of claims cases in the 20th century. The tribes guaranteed safe passage for settlers on the Oregon Trail and allowed roads and forts to be built in their territories in return for promises of an annuity in the amount of fifty thousand dollars for fifty years. The treaty should also \"make an effective and lasting peace\" among the eight tribes, each of them often at odds with a number of the others.\nThe treaty was broken almost immediately after its inception by the Lakota and Cheyenne attacking the Crow over the next two years. In 1858, the failure of the United States to prevent the mass immigration of miners and settlers into Colorado during the Pike's Peak Gold Rush, also did not help matters. They took over Indian lands in order to mine them, \"against the protests of the Indians,\" and founded towns, started farms, and improved roads. Such immigrants competed with the tribes for game and water, straining limited resources and resulting in conflicts with the emigrants. The US government did not enforce the treaty to keep out the immigrants.\nThe situation escalated with the Grattan affair in 1854 when a detachment of US soldiers illegally entered a Sioux encampment to arrest those accused of stealing a cow, and in the process sparked a battle in which Chief Conquering Bear was killed.\nThough intertribal fighting had existed before the arrival of white settlers, some of the post-treaty intertribal fighting can be attributed to mass killings of bison by white settlers and government agents. The US Army did not enforce treaty regulations and allowed hunters onto Native land to slaughter buffalo, providing protection and sometimes ammunition. One hundred thousand buffalo were killed each year until they were on the verge of extinction, which threatened the tribes' subsistence. These mass killings affected all tribes thus the tribes were forced onto each other's hunting grounds, where fighting broke out.\nOn July 20, 1867, an act of Congress created the Indian Peace Commission \"to establish peace with certain hostile Indian tribes\". The Indian Peace Commission was generally seen as a failure, and violence had reignited even before it was disbanded in October 1868. Two official reports were submitted to the federal government, ultimately recommending that the US cease recognizing tribes as sovereign nations, refrain from making treaties with them, employ military force against those who refused to relocate to reservations, and move the Bureau of Indian Affairs from the Department of the Interior to the Department of War. The system of treaties eventually deteriorated to the point of collapse, and a decade of war followed the commission's work. It was the last major commission of its kind.\nFrom 1866 to 1868, the Lakota fought the United States Army in the Wyoming Territory and the Montana Territory in what is known as Red Cloud's War (also referred to as the Bozeman War). The war is named after Red Cloud, a prominent Lakota chief who led the war against the United States following encroachment into the area by the US military. The Sioux victory in the war led to their temporarily preserving their control of the Powder River country. The war ended with the Treaty of Fort Laramie of 1868.\nFort Laramie Treaty of 1868.\nThe Treaty of Fort Laramie (also the Sioux Treaty of 1868) was an agreement between the US and the Oglala, Miniconjou, and Sicangu bands of Lakota people, Yanktonai Dakota and Arapaho Nation, following the failure of the first Fort Laramie treaty, signed in 1851. It established the Great Sioux Reservation including ownership of the Black Hills, and set aside additional lands as \"unceded Indian territory\" in areas of South Dakota, Wyoming, and Nebraska, and possibly Montana. It established that the US government would hold the authority to punish not only white settlers who committed crimes against the tribes but also tribe members who committed crimes and who were to be delivered to the government rather than face charges in tribal courts. It stipulated that the government would abandon forts along the Bozeman Trail, and included a number of provisions designed to encourage a transition to farming, and move the tribes \"closer to the white man's way of life.\" The treaty protected specified rights of third parties not partaking in the negotiations, and effectively ended Red Cloud's War.\nThe treaty overall, and in comparison with the 1851 agreement, represented a departure from earlier considerations of tribal customs, and demonstrated instead the government's \"more heavy-handed position with regard to tribal nations, and ... desire to assimilate the Sioux into American property arrangements and social customs.\" According to one source, \"animosities over the treaty arose almost immediately\" when a group of Miniconjou were informed they were no longer welcome to trade at Fort Laramie, being south of their newly established territory. This was notwithstanding that the treaty did not make any stipulation that the tribes could not travel outside their land, only that they would not permanently occupy outside land. The only travel expressly forbidden by the treaty was that of white settlers onto the reservation.\nThe government eventually broke the terms of the treaty following the Black Hills Gold Rush and an expedition into the area by George Armstrong Custer in 1874 and failed to prevent white settlers from moving onto tribal lands. Rising tensions eventually lead again to open conflict in the Great Sioux War of 1876. The 1868 treaty was modified three times by the US Congress between 1876 and 1889, each time taking more land originally granted, including unilaterally seizing the Black Hills in 1877. The treaty formed the basis of the 1980 Supreme Court case, \"United States v. Sioux Nation of Indians\", in which the court ruled that tribal lands covered under the treaty had been taken illegally by the US government, and the tribe was owed compensation plus interest. As of 2018, this amounted to more than $1 billion. The Sioux have refused the payment, demanding instead the return of their land.\nGreat Sioux War of 1876 and the Wounded Knee Massacre.\nThe ongoing raids and battles on the northern Plains that lasted from 1850 to 1890 are collectively known as the Sioux Wars. Included are the Dakota War of 1862 (1862\u20131864), Red Cloud's War (1866\u20131868) and the Black Hills War which includes the Battle of the Little Bighorn(1876\u20131877); the Massacre at Wounded Knee in 1890 is considered the end of the Sioux wars and the beginning of a new era for Dakota and Lakota people.\nThe Great Sioux War of 1876, also known as the Black Hills War, was a series of battles and negotiations that occurred in 1876 and 1877 between the Lakota, Northern Cheyenne, and the United States. The cause of the war was the desire of the US government to obtain ownership of the Black Hills. Gold had been discovered in the Black Hills and settlers began to encroach onto tribal lands, and the Sioux and Cheyenne refused to cede ownership to the United States. The earliest engagement was the Battle of Powder River, and the final battle was the Wolf Mountain. Included are the Battle of the Rosebud, Battle of Warbonnet Creek, Battle of Slim Buttes, Battle of Cedar Creek, and the Dull Knife Fight.\nAmong the many battles and skirmishes of the war was the Battle of the Little Bighorn, often known as Custer's Last Stand, the most storied of the many encounters between the US army and mounted Plains tribes. The Battle of the Little Bighorn, known to the Lakota as the Battle of the Greasy Grass and also commonly referred to as Custer's Last Stand, was an armed engagement between combined forces of the Lakota, Northern Cheyenne, and Arapaho tribes and the 7th Cavalry Regiment of the United States Army. The battle, which resulted in the defeat of US forces, was the most significant action of the Great Sioux War of 1876. It took place on June 25\u201326, 1876, along the Little Bighorn River in the Crow Indian Reservation in southeastern Montana Territory.\nThe fight was an overwhelming victory for the Lakota, Northern Cheyenne, and Arapaho, who were led by several major war leaders, including Crazy Horse and Chief Gall, and had been inspired by the visions of Sitting Bull. The US 7th Cavalry, a force of 700 men, suffered a major defeat while under the command of Lieutenant Colonel George Armstrong Custer. Five of the 7th Cavalry's twelve companies were annihilated and Custer was killed. The total US casualty count included 268 dead and 55 severely wounded (six died later from their wounds), including four Crow scouts and at least two Arikara scouts. The Little Bighorn Battlefield National Monument honors those who fought on both sides. That victory notwithstanding, the US leveraged national resources to force the tribes to surrender, primarily by attacking and destroying their encampments and property. The Great Sioux War took place under the presidencies of Ulysses S. Grant and Rutherford B. Hayes. The Agreement of 1877 (19\u00a0Stat.\u00a0https://, enacted February 28, 1877) officially annexed Sioux land and permanently established Indian reservations.\nThe Wounded Knee Massacre was the last major armed conflict between the Lakota and the United States. It was described as a massacre by General Nelson A. Miles in a letter to the Commissioner of Indian Affairs. On December 29, 1890, five hundred troops of the 7th Cavalry Regiment, supported by four Hotchkiss guns (a lightweight artillery piece capable of rapid fire), surrounded an encampment of the Lakota bands of the Miniconjou and Hunkpapa with orders to escort them to the railroad for transport to Omaha, Nebraska. By the time it was over, 25 troopers and more than 150 Lakota Sioux lay dead, including men, women, and children. It remains unknown which side was responsible for the first shot; some of the soldiers are believed to have been the victims of \"friendly fire\" because the shooting took place at point-blank range in chaotic conditions. Around 150 Lakota are believed to have fled the chaos, many of whom may have died from hypothermia.\nFollowing a three-day blizzard, the military hired civilians to bury the dead Lakota. The burial party found the deceased frozen; they were gathered up and placed in a mass grave on a hill overlooking the encampment from which some of the fire from the Hotchkiss guns originated. It was reported that four infants were found alive, wrapped in their deceased mothers' shawls. In all, 84 men, 44 women, and 18 children reportedly died on the field, while at least seven Lakota were mortally wounded.\nFor this 1890 offensive, the American army awarded twenty Medals of Honor, its highest commendation. Contemporary Native American activists have urged the medals to be withdrawn, calling them \"medals of dishonor\". According to Lakota William Thunder Hawk, \"The Medal of Honor is meant to reward soldiers who act heroically. But at Wounded Knee, they didn't show heroism; they showed cruelty\". In 2001, the National Congress of American Indians passed two resolutions condemning the Medals of Honor awards and called on the US government to rescind them.\n1890\u20131920s: Assimilation era.\nLand allotment.\nBy the 1880s, the Dakota and Lakota tribes were fragmented onto reservations which diminished in size over time. They lost hundreds of thousands of acres by the 1920s. In 1887, the United States Congress passed the General Allotment Act (Dawes Act), which began the assimilation of Dakota and Lakota people by forcing them to give up their traditional way of life. The Dawes Act ended traditional systems of land tenure, forcing tribes to adapt government-imposed systems of private property and to \"assume a capitalist and proprietary relationship with property\" that did not previously exist. In 1889, North Dakota and South Dakota were holding statehood conventions and demanded reduction of the Great Sioux Reservation, which was established by the Fort Laramie Treaty of 1868. Just months before those states were admitted to the Union in November 1889, Congress had passed an act which partitioned the Great Sioux Reservation into five smaller reservations. Tribal leaders such as John Grass, Gall, and Sitting Bull opposed the bill, which created the following five reservations:\nAfter the boundaries of these five reservations was established, the government opened up approximately , one-half of the former Great Sioux Reservation, for public purchase for ranching and homesteading. Much of the area was not homesteaded until the 1910s, after the Enlarged Homestead Act increased allocations to for \"semi-arid land\".\nBoarding schools.\nBesides the loss of land, the Dawes Act also \"outlawed Native American culture and established a code of Indian offenses regulating individual behavior according to Euro-American norms of conduct.\" Any violations of this code were to be \"tried in a Court of Indian Offenses on each reservation.\" Included with the Dawes Act were \"funds to instruct Native Americans in Euro-American patterns of thought and behavior through Indian Service schools\" which forced many of the tribes into sending their children to boarding schools.\nBoarding schools were intended to \"kill the Indian to save the man\", which meant the destruction of Dakota and Lakota societies: children were taken away from their families, their traditional culture and kinship roles. They were dressed in Eurocentric clothing, given English names, had their hair cut and were forbidden to speak their languages. Their religions and ceremonies were also outlawed and forbidden. The goal was to teach academic studies in English, vocational skills suited to Euro-American society such as farming in order to replace traditional lifeways. These schools were overcrowded and had poor sanitary conditions, which led to infectious diseases and students running away or dying while at the schools. The schools achieved mixed outcomes of traumatic experiences for many while others such as Charles Eastman, Ella Cara Deloria, Luther Standing Bear and Zitkala-Sa were able to use the education to their advantage to help their people.\n1930s\u20131960s: Reorganization Act and Relocation Act.\nThe Indian Reorganization Act (IRA) sought to overturn many of the policies of the Dawes Act by reversing the traditional goal of cultural assimilation of the tribes into American society. The IRA \"ended land allotment, prohibited non-consensual land seizure, recognized tribal governments, encouraged the writing of tribal constitutions, and empowered Native people to manage their own resources\". Between 1934 and 1945, the tribes voted on their government constitutions. The Yankton Sioux Tribe is the only tribe in South Dakota that did not comply with the IRA and chose to keep its traditional government, whose constitution was ratified in 1891. The Spirit Lake Tribe and Standing Rock Tribe also voted against the IRA. Because their constitution are not written under the authority of the IRA, they had to established tribal corporations which are managed separately from the tribal government in order to apply for loans. In Minnesota, the IRA recognized the Dakota tribes as communities, allowing them to reestablish their reservations and to repurchase land lost during the Dakota War of 1862. The Lower Sioux and Prairie Island reservations formed constitutions in 1936, the Upper Sioux formed as a community in 1938 and wrote a constitution in 1995, and the Shakopee Mdewakanton officially formed an IRA government in 1969.\nDespite the IRA giving more land rights to the tribes, the federal government seized thousands of acres of land through the Flood Control Act of 1944 by creating the Oahe Dam. As a result of the dam's construction the Cheyenne River Indian Reservation lost bringing it down to today. The Standing Rock Sioux Reservation lost leaving it with . Much of the land was taken by eminent domain claims made by the Bureau of Reclamation. Over and above the land loss, most of the reservations' prime agricultural land was included in the loss. Most of the land was unable to be harvested (to allow the trees to be cut down for wood) before the land was flooded over with water. One visitor to the reservations later asked why there were so few older Indians on the reservations and was told that \"the old people had died of heartache\" after the construction of the dam and the loss of the reservations' land. As of 2015, poverty remains a problem for the displaced populations in the Dakotas, who are still seeking compensation for the loss of the towns submerged under Lake Oahe, and the loss of their traditional ways of life.\nThe Indian Relocation Act of 1956 encouraged many tribal members to leave their reservation homes for cities. Some tribes had a dramatic loss of population: the Yankton Sioux Tribe fell to only 1,000 members living on the reservation in the 1950s; the Santee Sioux Reservation lost 60 percent of its population (by 1962, only 2,999, mostly elderly people remained).\nRoosevelt's New Deal and Johnson's war on poverty brought new schools, roads, health clinics, and housing to the reservations.\n1970s: Wounded Knee incident.\nConflicting political values from \"traditionalists\" against the new form of government promoted through the Indian Reorganization Act created long-lasting tensions on the reservations. The accusations of corruption by tribal leaders would lead to the Wounded Knee incident which began on February 27, 1973, when the town of Wounded Knee, South Dakota was seized by followers of the American Indian Movement (AIM). The occupiers controlled the town for 71 days while various state and federal law enforcement agencies such as the Federal Bureau of Investigation and the United States Marshals Service laid siege.\nThe members of AIM were protesting what they said was the local corrupt government, along with federal issues affecting Indian reservation communities, as well as the lack of justice from border counties. Native Americans from many other communities, primarily urban areas, mobilized to come and join the occupation. The FBI dispatched agents and US Marshals to cordon off the site. Later a higher-ranking DOJ representative took control of the government's response. Through the resulting siege that lasted for 71 days, twelve people were wounded, including an FBI agent left paralyzed. In April at least two people died of gunfire, after which the Oglala Lakota called an end to the occupation). Additionally, two other people, one of them an African American civil rights activist, Ray Robinson, went missing, and are believed to have been killed during the occupation, though their bodies have never been found. Afterward, 1200 American Indians were arrested. Wounded Knee drew international attention to the plight of American Indians and AIM leaders were tried in a Minnesota federal court. The court dismissed their case on the basis of governmental prosecutorial misconduct. However, Leonard Peltier was convicted of murdering two FBI agents in a June 26, 1975, shooting on the Pine Ridge Reservation in South Dakota.\n1980s\u2013present: Self-determination.\nAfter the Wounded Knee Incident, the Dakota and Lakota continued to push for their tribal rights and self-determination.\nBlack Hills Land claims.\nThe Sioux never accepted the legitimacy of the forced deprivation of their Black Hills reservation. Throughout the 1920s\u20131950s, they pushed their Black Hills land claim into federal court. After 60 years of litigation in the Court of Claims, the Indian Claims Commission, the US Congress, the Supreme Court heard the case in 1980 and ruled that the federal government had illegally taken the Black Hills and awarded more than $100 million in reparations to the tribes. Stating that the land was never for sale, the tribes have refused to accept the money which is now over one billion dollars.\nRepublic of Lakotah.\nAfter the Wounded Knee Incident in 1973, the International Indian Treaty Council was formed to support grassroots Indigenous struggles for human rights, self-determination and environmental justice through information dissemination, networking, coalition building, advocacy and technical assistance. This influenced activists who declared that they had founded the Republic of Lakotah in 2007. The Lakota Freedom Delegation, a group of controversial Native American activists, declared on December 19, 2007, the Lakota were withdrawing from all treaties signed with the United States to regain sovereignty over their nation. One of the activists, Russell Means, claimed that the action was legal and cites natural, international and US law. The group considers Lakota to be a sovereign nation, although as yet the state is generally unrecognized. The proposed borders reclaim thousands of square kilometres of North and South Dakota, Wyoming, Nebraska and Montana. Not all leaders of the Lakota Tribal Governments support or recognize the declaration.\nFoster care system.\nThroughout the decades, thousands of Native American children were forcibly removed from their homes and sent to boarding schools with a primary objective of assimilating Native American children and youth into Euro-American culture, while at the same time providing a basic education in Euro-American subject matters. Many children lost knowledge of their culture and languages, as well as faced physical and sexual abuse at these schools. In 1978, the government tried to put an end to these boarding schools (and placement into foster families) with the Indian Child Welfare Act (ICWA), which says except in the rarest circumstances, Native American children must be placed with their relatives or tribes. It also says states must do everything it can to keep native families together.\nIn 2011, the Lakota made\u00a0national news when NPR's investigative series called \"Lost Children, Shattered Families\" aired. It exposed what many critics consider to be the \"kidnapping\" of Lakota children from their homes by the state of South Dakota's Department of Social Services. The NPR investigation found South Dakota has the most cases which fail to abide by the ICWA. In South Dakota, Native American children make up less than 15 percent of the child population, yet they make up more than half of the children in foster care. The state receives thousands of dollars from the federal government for every child it takes from a family, and in some cases, the state gets even more money if the child is Native American.\nLakota activists Madonna Thunder Hawk and Chase Iron Eyes worked with the Lakota People's Law Project as they sought to end what they claimed were unlawful seizures of Native American Lakota children in South Dakota and to stop the state practice of placing these children in non-Native homes. They are currently working to redirect federal funding away from the state of South Dakota's Department of Social Systems to a new tribal foster care programs. In 2015, in response to the investigative reports by NPR, the Lakota People's Law Project as well as the coalition of all nine Lakota/Dakota reservations in South Dakota, the Bureau of Indian Affairs updated the ICWA guidelines to give more strength to tribes to intervene on behalf of the children, stating, \"The updated guidelines establish that an Indian child, parent or Indian custodian, or tribe may petition to invalidate an action if the Act or guidelines have been violated, regardless of which party's rights were violated. This approach promotes compliance with ICWA and reflects that ICWA is intended to protect the rights of each of these parties.\" The new guidelines also not only prevent courts from taking children away based on socioeconomic status but give a strict definition of what is to be considered harmful living conditions. Previously, the state of South Dakota used \"being poor\" as harmful.\nProtest against the Dakota Access oil pipeline.\n In the summer of 2016, Sioux Indians and the Standing Rock Sioux Tribe began a protest against construction of the Dakota Access oil pipeline, also known as the Bakken pipeline, which, if completed, is designed to carry hydrofracked crude oil from the Bakken oil fields of North Dakota to the oil storage and transfer hub of Patoka, Illinois. The pipeline travels only half a mile north of the Standing Rock Sioux reservation and is designed to pass underneath the Missouri River and upstream of the reservation, causing many concerns over the tribe's drinking water safety, environmental protection, and harmful impacts on culture. The pipeline company claims that the pipeline will provide jobs, reduce American dependence on foreign oil and reduce the price of gas.\nThe conflict sparked a nationwide debate and much news media coverage. Thousands of indigenous and non-indigenous supporters joined the protest, and several camp sites were set up south of the construction zone. The protest was peaceful, and alcohol, drugs and firearms were not allowed at the campsite or the protest site. On August 23, Standing Rock Sioux Tribe released a list of 87 tribal governments who wrote resolutions, proclamations and letters of support stating their solidarity with Standing Rock and the Sioux people. Since then, many more Native American organizations, environmental groups and civil rights groups have joined the effort in North Dakota, including the Black Lives Matter movement, Vermont Senator Bernie Sanders, the 2016 Green Party presidential candidate Jill Stein and her running mate Ajamu Baraka, and many more. \"The Washington Post\" called it a \"National movement for Native Americans.\"\nReturn of Artifacts.\nIn November 2022, 150 sacred artifacts were repatriated to the Lakota Sioux peoples. They were stored for more than a century at the Founders Museum in Barre, Massachusetts. However, these are just a small fraction of circa 870,000 Native American artifacts (including nearly 110,000 human remains) that are still at prestigious colleges, museums and the federal government.\nLanguage.\nThe Sioux comprise three closely related language groups:\nThe earlier linguistic three-way division of the Sioux language identified \"Lakota\", \"Dakota\", and \"Nakota\" as varieties of a single language, where Lakota = Teton, Dakota = Santee-Sisseton and Nakota = Yankton-Yanktonai. However, the latest studies show that Yankton-Yanktonai never used the autonym \"Nakh\u00f3ta\", but pronounced their name roughly the same as the Santee (i.e. \"Dak\u021f\u00f3ta\").\nThese later studies identify Assiniboine and Stoney as two separate languages, with Sioux being the third language. Sioux has three similar dialects: Lakota, Western Dakota (Yankton-Yanktonai) and Eastern Dakota (Santee-Sisseton). Assiniboine and Stoney speakers refer to themselves as \"Nakh\u00f3ta\" or \"Nakh\u00f3da\" (cf. Nakota).\nThe term \"Dakota\" has also been applied by anthropologists and governmental departments to refer to all Sioux groups, resulting in names such as \"Teton Dakota\", \"Santee Dakota\", etc. This was mainly because of the misrepresented translation of the Odawa word from which \"Sioux\" is derived.\nEthnic and modern geographical divisions.\nThe Sioux are divided into three ethnic groups, the larger of which are divided into sub-groups, and further branched into bands. The earliest known European record of the Sioux identified them in Minnesota, Iowa, and Wisconsin. After the introduction of the horse in the early 18th century, the Sioux dominated larger areas of land\u2014from present-day Central Canada to the Platte River, from Minnesota to the Yellowstone River, including the Powder River country.\nThe Sioux maintain many separate tribal governments scattered across several reservations and communities in North America: in the Dakotas, Minnesota, Nebraska, and Montana in the United States; and in Manitoba, and southern Saskatchewan in Canada. Today, many Sioux also live outside their reservations.\n(Santee or Eastern Dakota).\nIn the past, they were a woodland people who thrived on hunting, fishing, and farming.\nMigrations of Ojibwe from the east in the 17th and 18th centuries, with muskets supplied by the French and British, pushed the Dakota further into Minnesota and west and southward. The US gave the name \"Dakota Territory\" to the northern expanse west of the Mississippi River and up to its headwaters. Today, the Santee live on reservations, reserves, and communities in Minnesota, Nebraska, South Dakota, North Dakota, and Canada. However, after the Dakota war of 1862 many Santee were sent to Crow Creek Indian Reservation and in 1864 some from the Crow Creek Reservation were sent to the Santee Sioux Reservation.\n(Yankton-Yanktonai or Western Dakota).\nThe , also known by the anglicized names \"Yankton\" (: 'End village') and \"Yanktonai\" (: 'Little end village'), consist of two bands or two of the Seven Council Fires. According to \"Nasunatanka\" and \"Matononpa\" in 1880, the Yanktonai are divided into two sub-groups known as the Upper Yanktonai and the Lower Yanktonai (Hunkpatina). Today, most of the Yanktons live on the Yankton Indian Reservation in southeastern South Dakota. Some Yankton live on the Lower Brule Indian Reservation and Crow Creek Indian Reservation. The Yanktonai are divided into Lower Yanktonai, who occupy the Crow Creek Reservation; and Upper Yanktonai, who live in the northern part of Standing Rock Indian Reservation, on the Spirit Lake Tribe in central North Dakota, and in the eastern half of the Fort Peck Indian Reservation in northeastern Montana. In addition, they reside at several Canadian reserves, including Birdtail, Oak Lake, and Moose Woods.\nThey were involved in quarrying pipestone. The Yankton-Yanktonai moved into northern Minnesota. In the 18th century, they were recorded as living in the Mankato region of Minnesota.\n(Teton or Lakota).\nPrior to obtaining horses in the 17th century, the Lakota were located near present-day Minnesota. Dominating the northern Great Plains with their light cavalry, the western Sioux quickly expanded their territory to the Rocky Mountains (which they call , 'white mountains') by the 1800s.\nTheir traditional diet includes bison and corn. They traditionally acquired corn mostly through trade with the eastern Sioux and their linguistic cousins, the Mandan and Hidatsa along the Missouri River prior to the reservation era. The name \"Teton\" or is archaic among the people, who prefer to call themselves . Today, the Lakota are the largest and westernmost of the three groups, occupying lands in both North and South Dakota.\nReservations and reserves.\nIn the late 19th century, railroads wanted to build tracks through Indian lands. The railroad companies hired hunters to exterminate the bison herds, the Plains Indians' primary food supply. The Dakota and Lakota were forced to accept US-defined reservations in exchange for the rest of their lands and farming and ranching of domestic cattle, as opposed to a nomadic, hunting economy. During the first years of the Reservation Era, the Sioux people depended upon annual federal payments guaranteed by treaty for survival.\nIn Minnesota, the treaties of Traverse des Sioux and Mendota in 1851 left the Dakota with a reservation wide on each side of the Minnesota River.\nToday, half of all enrolled Sioux in the United States live off-reservation. Enrolled members in any of the Sioux tribes in the United States are required to have ancestry that is at least 1/4 degree Sioux (the equivalent to one grandparent).\nIn Canada, the Canadian government recognizes the tribal community as First Nations. The land holdings of these First Nations are called Indian reserves.\nPopulation history.\nIn year 1762 lieutenant James Gorrell complained about a lack of funds to disperse adequate presents to the 30,000 Sioux warriors for whom he estimated he had responsibility, which would indicate a total population of around 150,000 people (on average 5 persons per one warrior). Such high population appears to be confirmed by French Jesuits who visited 40 Sioux villages in 1660 and counted 5,000 men only in five of them (on average 1,000 men per village). Almost a century after Gorrell's estimate, in 1841, George Catlin estimated the Sioux as up to 50,000 people, and mentioned that they had just lost approx. 8,000 dead to smallpox a few years prior. Alexander Ramsey (Indian Affairs 1849) estimated that in 1846 the Sioux had 5,000 lodges averaging over 10 people per lodge, indicating a population of over 50,000. During the second half of the 19th century Sioux population further declined. In 1865 the Sioux were estimated at up to 40,000 people. Indian Affairs 1880 returned 31,747 people. The census of 1890 returned 25,675. Indian Affairs 1900 returned 27,169. The census of 1910 returned 23,318 (including 14,284 Tetons). In addition Canadian Indian Affairs counted 2,000 Sioux in Canada in 1886.\nDuring the 20th and 21st centuries Sioux population has rebounded, reaching 207,456 in the USA according to the 2020 census.\nNotable Sioux.\nContemporary.\nContemporary Sioux people are listed under the tribes to which they belong.\n* Hunkpapa\n* Oglala\n* Sicangu\n* Sisseton Wahpeton Oyate of the Lake Traverse Indian Reservation\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "56126", "revid": "2723875", "url": "https://en.wikipedia.org/wiki?curid=56126", "title": "Battle of the Little Bighorn", "text": "1876 battle of the Great Sioux War\nThe Battle of the Little Bighorn, known to the Lakota and other Plains Indians as the Battle of the Greasy Grass, and commonly referred to as Custer's Last Stand, was an armed engagement between combined forces of the Lakota Sioux, Northern Cheyenne, and Arapaho tribes and the 7th Cavalry Regiment of the United States Army. It took place on June 25\u201326, 1876, along the Little Bighorn River in the Crow Indian Reservation in southeastern Montana Territory. The battle, which resulted in the defeat of U.S. forces, was the most significant action of the Great Sioux War of 1876.\nMost battles in the Great Sioux War, including the Battle of the Little Bighorn, were on lands those natives had taken from other tribes since 1851. The Lakotas were there without consent from the local Crow tribe, which had a treaty claim on the area. Already in 1873, Crow chief Blackfoot had called for U.S. military actions against the native intruders. The steady Lakota incursions into treaty areas belonging to the smaller tribes were a direct result of their displacement by the United States in and around Fort Laramie, as well as in reaction to white encroachment into the Black Hills, which the Lakota consider sacred. This pre-existing Indian conflict provided a useful wedge for colonization and ensured the United States a firm Indian alliance with the Arikaras and the Crows during the Lakota Wars.\nThe fight was an overwhelming victory for the Lakota, Northern Cheyenne, and Arapaho, who were led by several major war leaders, including Crazy Horse and Chief Gall, and had been inspired by the visions of Sitting Bull (). The U.S. 7th Cavalry, a force of 700 men commanded by Lieutenant Colonel George Armstrong Custer (a brevetted major general during the American Civil War), suffered a major defeat. Five of the 7th Cavalry's twelve companies were wiped out and Custer was killed, as were two of his brothers, his nephew, and his brother-in-law. The total U.S. casualty count included 268 dead and 55 severely wounded (six died later from their wounds), including four Crow Indian scouts and at least two Arikara Indian scouts.\nPublic response to the Great Sioux War varied in the immediate aftermath of the battle. Custer's widow Libbie Custer soon began to work to burnish her husband's memory, and during the following decades, Custer and his troops came to be widely considered to be heroic figures in U.S. history. The battle and Custer's actions in particular have been studied extensively by historians. Custer's heroic public image began to tarnish after the death of his widow in 1933 and the publication in 1934 of \"Glory Hunter - The Life of General Custer\" by Frederic F. Van de Water, which was the first book to depict Custer in unheroic terms. These two events, combined with the cynicism of an economic depression and historical revisionism, led to a more realistic view of Custer and his defeat on the banks of the Little Bighorn River. Little Bighorn Battlefield National Monument honors those who fought on both sides.\nBackground.\nBattlefield and surrounding areas.\nIn 1805, fur trader Fran\u00e7ois Antoine Larocque reported joining a Crow camp in the Yellowstone area. On the way he noted that the Crow hunted buffalo on the \"Small Horn River\". St. Louis-based fur trader Manuel Lisa built Fort Raymond in 1807 for trade with the Crow. It was located near the confluence of the Yellowstone and Bighorn rivers, about north of the future battlefield. The area is first noted in the 1851 Treaty of Fort Laramie.\nIn the latter half of the 19th century, tensions increased between the Native inhabitants of the Great Plains of the US and encroaching settlers. This resulted in a series of conflicts known as the Sioux Wars, which took place from 1854 to 1890. While some of the indigenous people eventually agreed to relocate to ever-shrinking reservations, a number of them resisted, sometimes fiercely.\nOn May 7, 1868, the valley of the Little Bighorn became a tract in the eastern part of the new Crow Indian Reservation in the center of the old Crow country. There were numerous skirmishes between the Sioux and Crow tribes, so when the Sioux were in the valley in 1876 without the consent of the Crow tribe, the Crow supported the US Army to expel the Sioux (e.g., Crows enlisted as Army scouts and Crow warriors would fight in the nearby Battle of the Rosebud).\nThe geography of the battlefield is very complex, consisting of dissected uplands, rugged bluffs, the Little Bighorn River, and adjacent plains, all areas close to one another. Vegetation varies widely from one area to the next.\nThe battlefield is known as \"Greasy Grass\" to the Lakota Sioux, Dakota Sioux, Cheyenne, and most other Plains Indians; however, in contemporary accounts by participants, it was referred to as the \"Valley of Chieftains\".\n1876 Sun Dance ceremony.\nAmong the Plains Indians, the long-standing ceremonial tradition known as the Sun Dance was the most important religious event of the year. It is a time for prayer and personal sacrifice for the community, as well as for making personal vows and resolutions. Towards the end of spring in 1876, the Lakota and the Cheyenne held a Sun Dance that was also attended by some \"agency Indians\" who had slipped away from their reservations. During a Sun Dance around June 5, 1876, on Rosebud Creek in Montana, Sitting Bull, the spiritual leader of the Hunkpapa Lakota, reportedly had a vision of \"soldiers falling into his camp like grasshoppers from the sky.\" At the same time US military officials were conducting a summer campaign to force the Lakota and the Cheyenne back to their reservations, using infantry and cavalry in a so-called \"three-pronged approach\".\n1876 U.S. military campaign.\nCol. John Gibbon's column of six companies (A, B, E, H, I, and K) of the 7th Infantry and four companies (F, G, H, and L) of the 2nd Cavalry marched east from Fort Ellis in western Montana on March 30 to patrol the Yellowstone River. Brig. Gen. George Crook's column of ten companies (A, B, C, D, E, F, G, I, L, and M) of the 3rd Cavalry, five companies (A, B, D, E, and I) of the 2nd Cavalry, two companies (D and F) of the 4th Infantry, and three companies (C, G, and H) of the 9th Infantry moved north from Fort Fetterman in the Wyoming Territory on May 29, marching toward the Powder River area. Brig. Gen. Alfred Terry's column, including twelve companies (A, B, C, D, E, F, G, H, I, K, L, and M) of the 7th Cavalry under Lt. Col. George Armstrong Custer's immediate command, Companies C and G of the 17th Infantry, and the Gatling gun detachment of the 20th Infantry departed westward from Fort Abraham Lincoln in the Dakota Territory on May 17. They were accompanied by teamsters and packers with 150 wagons and a large contingent of pack mules that reinforced Custer. Companies C, D, and I of the 6th Infantry moved along the Yellowstone River from Fort Buford on the Missouri River to set up a supply depot and joined Terry on May 29 at the mouth of the Powder River. They were later joined there by the steamboat \"Far West\", which was loaded with 200 tons of supplies from Fort Abraham Lincoln.\n7th Cavalry organization.\nThe 7th Cavalry had been created just after the American Civil War (1861\u20131865). Many men were veterans of the war, including most of the leading officers. A significant portion of the regiment had previously served 4\u00bd years at Fort Riley, in Kansas, during which time it fought one major engagement and numerous skirmishes, experiencing casualties of 36 killed and 27 wounded. Six other troopers had died of drowning and 51 in cholera epidemics. In November 1868, while stationed in Kansas, the 7th Cavalry under Custer had routed Black Kettle's Southern Cheyenne camp on the Washita River in the Battle of Washita River, an attack which was at the time labeled a \"massacre of innocent Indians\" by the Indian Bureau.\nBy the time of the Battle of the Little Bighorn, half of the 7th Cavalry's companies had just returned from 18 months of constabulary duty in the Deep South, having been recalled to Fort Abraham Lincoln, Dakota Territory to reassemble the regiment for the campaign. About 20% of the troopers had been enlisted in the prior seven months (139 of an enlisted roll of 718), were only marginally trained and had no combat or frontier experience. About 60% of these recruits were American, the rest were European immigrants (primarily Irish and German)\u2014just as many of the veteran troopers had been before their enlistments. Archaeological evidence suggests that many of these troopers were malnourished and in poor physical condition, despite being the best-equipped and supplied regiment in the Army.\nOf the 45 officers and 718 troopers then assigned to the 7th Cavalry (including a second lieutenant detached from the 20th Infantry and serving in Company L), 14 officers (including the regimental commander) and 152 troopers did not accompany the 7th during the campaign. The regimental commander, Colonel Samuel D. Sturgis, was on detached duty as the Superintendent of Mounted Recruiting Service and commander of the Cavalry Depot in St. Louis, Missouri, which left Lieutenant Colonel Custer in command of the regiment. The ratio of troops detached for other duty (approximately 22%) was not unusual for an expedition of this size, and part of the officer shortage was chronic and was due to the Army's rigid seniority system: Three of the regiment's twelve captains were permanently detached, and two had never served a day with the 7th since their appointment in July 1866. Three second lieutenant vacancies (in E, H, and L Companies) were also unfilled.\nBattle of the Rosebud.\nThe Army's coordination and planning began to go awry on June 17, 1876, when Crook's column retreated after the Battle of the Rosebud, to the southeast of the eventual Little Bighorn battlefield. Surprised and according to some accounts astonished by the unusually large numbers of Native Americans, Crook held the field at the end of the battle but felt compelled by his losses to pull back, regroup, and wait for reinforcements. Unaware of Crook's battle, Gibbon and Terry proceeded, joining forces in early June near the mouth of Rosebud Creek. They reviewed Terry's plan calling for Custer's regiment to proceed south along the Rosebud while Terry and Gibbon's united forces would move in a westerly direction toward the Bighorn and Little Bighorn Rivers. As this was the likely location of Native encampments, all army elements had been instructed to converge there around June 26 or 27 in an attempt to engulf the Native Americans. On June 22, Terry ordered the 7th Cavalry, composed of 31 officers and 566 enlisted men under Custer, to begin a reconnaissance in force and pursuit along the Rosebud, with the prerogative to \"depart\" from orders if Custer saw \"sufficient reason\". Custer had been offered the use of Gatling guns but declined, believing they would slow his rate of march.\nLittle Bighorn.\nWhile the Terry\u2013Gibbon column was marching toward the mouth of the Little Bighorn, on the evening of June 24, Custer's Indian scouts arrived at an overlook known as the Crow's Nest, east of the Little Bighorn River. At sunrise on June 25, Custer's scouts reported they could see a massive pony herd and signs of the Native American village roughly in the distance. After a night's march, the tired officer who was sent with the scouts could see neither, and when Custer joined them, he was also unable to make the sighting. Custer's scouts also spotted the regimental cooking fires that could be seen from away, disclosing the regiment's position.\nCuster contemplated a surprise attack against the encampment the following morning of June 26, but he then received a report informing him several \"hostiles\" [\"sic\"] had discovered the trail left by his troops. Assuming his presence had been exposed, Custer decided to attack the village without further delay. On the morning of June 25, Custer divided his 12 companies into three battalions in anticipation of the forthcoming engagement. Three companies were placed under the command of Major Marcus Reno (A, G, and M) and three were placed under the command of Captain Frederick Benteen (H, D, and K). Five companies (C, E, F, I, and L) remained under Custer's immediate command. The 12th, Company B under Captain Thomas McDougall, had been assigned to escort the slower pack train carrying provisions and additional ammunition.\nUnknown to Custer, the group of Native Americans seen on his trail was actually leaving the encampment and did not alert the rest of the village. Custer's scouts warned him about the size of the village, with Mitch Bouyer reportedly saying, \"General, I have been with these Indians for 30 years, and this is the largest village I have ever heard of.\" Custer's overriding concern was that the Native American group would break up and scatter. The command began its approach to the village at noon and prepared to attack in full daylight.\nWith an impending sense of doom, the Crow scout Half Yellow Face prophetically warned Custer (speaking through the interpreter Mitch Bouyer), \"You and I are going home today by a road we do not know.\"\nPrelude.\nMilitary assumptions prior to the battle.\nNumber of Indian warriors.\nAs the Army moved into the field on its expedition, it was operating with incorrect assumptions as to the number of Indians it would encounter. These assumptions were based on inaccurate information provided by the Indian Agents that no more than 800 \"hostiles\" were in the area. The Indian Agents based this estimate on the number of Lakota that Sitting Bull and other leaders had reportedly led off the reservation in protest of U.S. government policies. It was in fact a correct estimate until several weeks before the battle when the \"reservation Indians\" joined Sitting Bull's ranks for the summer buffalo hunt. The agents did not consider the many thousands of these \"reservation Indians\" who had unofficially left the reservation to join their \"uncooperative non-reservation cousins led by Sitting Bull\". Thus, Custer unknowingly faced thousands of Indians, including the 800 non-reservation \"hostiles\". All Army plans were based on the incorrect numbers. Although Custer was criticized after the battle for not having accepted reinforcements and for dividing his forces, it appears that he had accepted the same official government estimates of hostiles in the area which Terry and Gibbon had also accepted. Historian James Donovan notes, however, that when Custer later asked interpreter Fred Gerard for his opinion on the size of the opposition, he estimated the force at 1,100 warriors.\nAdditionally, Custer was more concerned with preventing the escape of the Lakota and Cheyenne than with fighting them, as reported by John Martin (born in Italy as Giovanni Martino).\nMartin was temporarily assigned to serve as one of Custer's trumpeter-orderlies. As Custer and nearly 210 troopers and scouts began their final approach to the massive Indian village located in the Little Bighorn River Valley, Martin was dispatched with an urgent note for reinforcements and ammunition. Newspaper accounts of the period referred to him as \"Custer massacre survivor\" and \"the last white man to see Custer alive\".\nFrom his observation, Custer assumed the warriors had been sleeping in on the morning of the battle, to which virtually every native account attested later, giving Custer a false estimate of what he was up against. When he and his scouts first looked down on the village from the Crow's Nest across the Little Bighorn River, they could see only the herd of ponies. Later, looking from a hill away after parting with Reno's command, Custer could observe only women preparing for the day, and young boys taking thousands of horses out to graze south of the village. Custer's Crow scouts told him it was the largest native village they had ever seen. When the scouts began changing back into their native dress right before the battle, Custer released them from his command. While the village was enormous, Custer still thought there were far fewer warriors to defend the village.\nFinally, Custer may have assumed when he encountered the Native Americans that his subordinate Benteen, who was with the pack train, would provide support. Rifle volleys were a standard way of telling supporting units to come to another unit's aid. In a subsequent official 1879 Army investigation requested by Major Reno, the Reno Board of Inquiry (RCOI), Benteen and Reno's men testified that they heard distinct rifle volleys as late as 4:30 pm during the battle.\nCuster had initially wanted to take a day to scout the village before attacking; however, when men who went back looking for supplies accidentally dropped by the pack train, they discovered that their track had already been discovered by Indians. Reports from his scouts also revealed fresh pony tracks from ridges overlooking his formation. It became apparent that the warriors in the village were either aware or would soon be aware of his approach. Fearing that the village would break up into small bands that he would have to chase, Custer began to prepare for an immediate attack.\nRole of Indian noncombatants in Custer's strategy.\nCuster's field strategy was designed to engage non-combatants at the encampments on the Little Bighorn to capture women, children, and the elderly or disabled to serve as hostages to convince the warriors to surrender and comply with federal orders to relocate. Custer's battalions were poised to \"ride into the camp and secure non-combatant hostages\", and \"forc[e] the warriors to surrender\". Author Evan S. Connell observed that if Custer could occupy the village before widespread resistance developed, the Sioux and Cheyenne warriors \"would be obliged to surrender, because if they started to fight, they would be endangering their families.\"\nIn Custer's book \"My Life on the Plains\", published two years before the Battle of the Little Bighorn, he asserted:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Indians contemplating a battle, either offensive or defensive, are always anxious to have their women and children removed from all danger ... For this reason I decided to locate our [military] camp as close as convenient to [Chief Black Kettle's Cheyenne] village, knowing that the close proximity of their women and children, and their necessary exposure in case of conflict, would operate as a powerful argument in favor of peace, when the question of peace or war came to be discussed.\nOn Custer's decision to advance up the bluffs and descend on the village from the east, Lt. Edward Godfrey of Company K surmised:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[Custer] expected to find the squaws and children fleeing to the bluffs on the north, for in no other way do I account for his wide detour. He must have counted upon Reno's success, and fully expected the \"scatteration\" of the non-combatants with the pony herds. The probable attack upon the families and capture of the herds were in that event counted upon to strike consternation in the hearts of the warriors and were elements for success upon which General Custer fully counted.\nThe Sioux and Cheyenne fighters were acutely aware of the danger posed by the military engagement of non-combatants and that \"even a semblance of an attack on the women and children\" would draw the warriors back to the village, according to historian John S. Gray. Such was their concern that an apparent reconnaissance by Capt. Yates' E and F Companies at the mouth of Medicine Tail Coulee (Minneconjou Ford) caused hundreds of warriors to disengage from the Reno valley fight and return to deal with the threat to the village.\nBased on archaeological evidence and reviews of native testimony, some authors and historians speculate that Custer attempted to cross the river at a point farther north that they refer to as Ford D. According to Richard A. Fox, James Donovan, and others, Custer proceeded with a wing of his battalion (Yates' E and F companies) north and opposite the Cheyenne circle at that crossing, which provided \"access to the [women and children] fugitives.\" Yates's force \"posed an immediate threat to fugitive Indian families...\" gathering at the north end of the huge encampment; he then persisted in his efforts to \"seize women and children\" even as hundreds of warriors were massing around Keogh's wing on the bluffs. Yates' wing, descending to the Little Bighorn River at Ford D, encountered \"light resistance\", undetected by the Indian forces ascending the bluffs east of the village. Custer was almost within \"striking distance of the refugees\" before abandoning the ford and returning to Custer Ridge.\nLone Teepee.\nThe \"Lone Teepee\" (or \"Tipi\") was a landmark along the 7th Cavalry's march. It was where the Indian encampment had been a week earlier during the Battle of the Rosebud on June 17, 1876. The Indians had left a single teepee standing (some reports mention a second that had been partially dismantled), and in it was the body of a Sans Arc warrior, Old She-Bear, who had been wounded in the battle. He had died after the Rosebud battle, and it was the custom of the Indians to move camp when a warrior died and leave possessions with the body. The Lone Teepee was an important location during the Battle of the Little Bighorn for several reasons, including:\nBattle.\nReno's attack.\nThe first group to attack was Major Reno's second detachment (Companies A, G, and M) after receiving orders from Custer written out by Lt. William W. Cooke, as Custer's Crow scouts reported Sioux tribe members were alerting the village. Ordered to charge, Reno began that phase of the battle. The orders, made without accurate knowledge of the village's size, location, or the warriors' propensity to stand and fight, had been to pursue the Native Americans and \"bring them to battle.\" Reno's force crossed the Little Bighorn at the mouth of what is today Reno Creek around 3:10 pm on June 25. They immediately realized that the Lakota and Northern Cheyenne were present \"in force and not running away.\"\nReno advanced rapidly across the open field towards the northwest, his movements masked by the thick belt of trees that ran along the southern banks of the Little Bighorn River. The same trees on his front right shielded his movements across the wide field over which his men rapidly rode, first with two approximately forty-man companies abreast and eventually with all three charging abreast. The trees also obscured Reno's view of the Native American village until his force had passed that bend on his right front and was suddenly within arrow-shot of the village. The tepees in that area were occupied by the Hunkpapa Sioux. Neither Custer nor Reno had much idea of the length, depth and size of the encampment they were attacking, as the village was hidden by the trees. When Reno came into the open in front of the south end of the village, he sent his Arikara/Ree and Crow Indian scouts forward on his exposed left flank. Realizing the full extent of the village's width, Reno quickly suspected what he would later call \"a trap\" and stopped a few hundred yards short of the encampment.\nHe ordered his troopers to dismount and deploy in a skirmish line, according to standard army doctrine. In this formation, every fourth trooper held the horses for the troopers in firing position, with separating each trooper, officers to their rear and troopers with horses behind the officers. This formation reduced Reno's firepower by 25 per cent. As Reno's men fired an enfilade onto the village, and by some accounts killed several wives and children of the Sioux chief Gall (in Lakota, ), the mounted warriors began streaming out to meet the attack. With Reno's men anchored on their right by the protection of the tree line and bend in the river, the Indians rode against the center and exposed left end of Reno's line. After about 20 minutes of long-distance firing, Reno had taken only one casualty, but the odds against him had risen (Reno estimated five to one), and Custer had not reinforced him. Trooper Billy Jackson reported that by then, the Indians had begun massing in the open area shielded by a small hill to the left of Reno's line and to the right of the Indian village. From this position the Indians mounted an attack of more than 500 warriors against the left and rear of Reno's line, turning Reno's exposed left flank. This forced a hasty withdrawal into the timber along the bend in the river. Here the Native Americans pinned Reno and his men down and tried to set fire to the brush to try to drive the soldiers out of their position.\nReno's Arikara scout Bloody Knife was shot in the head, splattering brains and blood onto Reno's face. The shaken Reno ordered his men to dismount and mount again. He then said, \"All those who wish to make their escape follow me.\" Abandoning the wounded, he led a disorderly rout for a mile next to the river. He made no attempt to engage the Indians to prevent them from picking off men in the rear. The retreat was immediately disrupted by Cheyenne attacks at close quarters. A steep bank some high awaited the mounted men as they crossed the river; some horses fell back onto others below them. Indians fired on the soldiers from a distance, and within close quarters pulled them off their horses and clubbed their heads. Later, Reno reported that three officers and 29 troopers had been killed during the retreat and subsequent fording of the river. Another officer and 13\u201318 men were missing. Most of these missing men were left behind in the timber, although many eventually rejoined the detachment.\nReno and Benteen on Reno Hill.\nAtop the bluffs near what is known today as Reno Hill, Reno's depleted and shaken troops were joined by Captain Benteen's column while Reno's men were still retreating up from the valley. (Companies D, H, and K), arriving from the south. This force had been returning from a lateral scouting mission when it had been summoned by Custer's messenger, Italian immigrant bugler John Martin (Giovanni Martino) with the handwritten message: \"Benteen. Come on, Big Village, Be quick, Bring packs. P.S. Bring Packs.\" This message made no sense to Benteen, as his men would be needed more in a fight than the packs carried by herd animals. Though both men inferred that Custer was engaged in battle, Reno refused to move until the packs arrived so his men could resupply. The detachments were later reinforced by McDougall's Company B and the pack train. The 14 officers and 340 troopers on the bluffs organized an all-around defense and dug rifle pits using whatever implements they had among them, including knives. This practice had become standard during the last year of the American Civil War, as Union and Confederate troops used knives, eating utensils, mess plates, and pans to dig effective battlefield fortifications.\nDespite hearing heavy gunfire from the north, including distinct volleys at 4:20 pm, Benteen concentrated on reinforcing Reno's badly wounded and hard-pressed detachment rather than continuing on toward Custer's position. Benteen's apparent reluctance to reach Custer prompted later criticism that he had failed to follow orders. Around 5:00 pm, Capt. Thomas Weir and Company D moved out to contact Custer. Capt. Weir remained on the bluffs, while D moved to the right down Cedar Coulee (RCOI figure 8), but they soon looped back around to the bluffs. Lt Luther Rector Hare, sent by Reno to Weir, and troops M, K and H also had moved north from the Reno retreat area. D, M and K advanced a mile to what is today Weir Peaks or Weir Point, and dismounted. From his vantage point on the bluffs, Weir could see that the Indian camps comprised some 1,800 lodges. Behind them he saw through the dust and smoke hills that were oddly red in color; he later learned that this was a massive assemblage of Indian ponies. By this time, roughly 5:25 pm, Custer's battle may have concluded. From high ground at Weir Peaks, looking though his spyglass, Weir witnessed many Indians on horseback and on foot shooting at items on the ground, perhaps killing wounded soldiers and firing at dead bodies on the \"Last Stand Hill\" at the northern end of the Custer battlefield. Realizing these were Indians, the three troops remained on the peaks and the hill to the east. Some historians have suggested that what Weir witnessed was a fight on what is now called Calhoun Hill some minutes earlier. The destruction of Keogh's battalion may have begun with the collapse of L, I, and C Company (half of it) following the combined assaults led by Crazy Horse, White Bull, Hump, Gall, and others. Other native accounts contradict this understanding, however, and the time element remains a subject of debate. The other companies had eventually left the area near Reno Hill and followed Weir by assigned battalions: first Benteen, then M troop, Reno's command, and the pack train and wounded. Strung along the bluffs behind D/M/K, Benteen and H soon returned to meet Reno's command at the high point called Capt. Weir's Hill (RCOI figure 7) and deployed along the ridge/bluffs there. Benteen informed Reno of their bad position. Weir also returned from the Peaks to the command at that location. The three troops (D, M, K) which had dismounted and remained at Weir Peaks (RCOI figure 9) were soon attacked by natives, increasingly coming from the concluded Custer engagement. Following Benteen's advice, Reno via Hare ordered the withdrawal of the three advance troops, and all seven companies eventually fell back to Reno Hill before the pack train had moved even a quarter mile (). Lt. Edward Settle Godfrey, Lt. Hare and troop K set up a skirmish line where Reno had retreated up from the valley, south of Weir's Hill, to halt the pursuing Indians, who took the surrounding high ground and hills. The companies remained pinned down on the bluff, fending off the Indians for three hours until night fell. The soldiers dug crude trenches as the Indians performed their war dance.\nBenteen was hit in the heel of his boot by an Indian bullet. At one point, he led a counterattack to push back Indians who had continued to crawl through the grass closer to the soldiers' positions.\nCuster's fight.\nThe precise details of Custer's fight and his movements before and during the battle are largely conjectural since none of the men who went forward with Custer's battalion (the five companies under his immediate command) survived the battle. Later accounts from surviving Indians are useful but are sometimes conflicting and unclear.\nWhile the gunfire heard on the bluffs by Reno and Benteen's men during the afternoon of June 25 was probably from Custer's fight, the soldiers on Reno Hill were unaware of what had happened to Custer until General Terry's arrival two days later on June 27. They were reportedly stunned by the news. When the army examined the Custer battle site, soldiers could not determine fully what had transpired. Custer's force of roughly 210 men had been engaged by the Lakota and Northern Cheyenne about to the north of Reno and Benteen's defensive position. Evidence of organized resistance included an apparent skirmish line on Calhoun Hill and apparent breastworks made of dead horses on Custer Hill. By the time troops came to recover the bodies, the Lakota and Cheyenne had already removed most of their own dead from the field. The troops found most of Custer's dead men stripped of their clothing, ritually mutilated, and in a state of decomposition, making identification of many impossible. The soldiers identified the 7th Cavalry's dead as well as they could and hastily buried them where they had fallen.\nCuster's body was found with two gunshot wounds, one to his left chest and the other to his left temple. Either wound would have been fatal, though he appeared to have bled from only the chest wound; some scholars believe his head wound may have been delivered postmortem. Some Lakota oral histories assert that Custer, having sustained a wound, committed suicide to avoid capture and subsequent torture. This would be inconsistent with his known right-handedness, but that does not rule out assisted suicide (other native accounts note several soldiers committing suicide near the end of the battle). Custer's body was found near the top of Custer Hill, which also came to be known as \"Last Stand Hill\". There the United States erected a tall memorial obelisk inscribed with the names of the 7th Cavalry's casualties.\nSeveral days after the battle, Curley, Custer's Crow scout who had left Custer near Medicine Tail Coulee (a drainage which led to the river), recounted the battle, reporting that Custer had attacked the village after attempting to cross the river. He was driven back, retreating toward the hill where his body was found. As the scenario seemed compatible with Custer's aggressive style of warfare and with evidence found on the ground, it became the basis of many popular accounts of the battle.\nAccording to Pretty Shield, the wife of Goes-Ahead (another Crow scout for the 7th Cavalry), Custer was killed while crossing the river: \"...and he died there, died in the water of the Little Bighorn, with Two-bodies, and the blue soldier carrying his flag\". In this account, Custer was allegedly killed by a Lakota called Big-nose. However, in Chief Gall's version of events, as recounted to Lt. Edward Settle Godfrey, Custer did not attempt to ford the river and the nearest that he came to the river or village was his final position on the ridge. Chief Gall's statements were corroborated by other Indians, notably the wife of Spotted Horn Bull. Given that no bodies of men or horses were found anywhere near the ford, Godfrey himself concluded \"that Custer did not go to the ford with any body of men\".\nCheyenne oral tradition credits Buffalo Calf Road Woman with striking the blow that knocked Custer off his horse before he died.\nCuster at Minneconjou Ford.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"Hurrah boys, we've got them! We'll finish them up and then go home to our station\".\n\u2014 Reported words of Lieutenant Colonel Custer at the battle's outset.\nHaving isolated Reno's force and driven them away from their encampment, the bulk of the native warriors were free to pursue Custer. The route taken by Custer to his \"Last Stand\" remains a subject of some debate. One possibility is that after ordering Reno to charge, Custer continued down Reno Creek to within about a half-mile (800 m) of the Little Bighorn, but then turned north and followed a ridge towards the bluffs, reaching them near the same spot to which Reno would soon retreat. A half mile farther, he reached the high ground and ridge, near the high point called Weir's Hill (2500\u2032 above Weir Peaks). From this high pinnacle where the bluff was tight to the river, he could see part of the big village in the valley on the other side. After passing over the high ridge (which connected Weir's Hill to Sharpshooter's Hill, sometimes referred to as \"Martin's Ridge\"), Custer and his troops descended Cedar Coulee (RCOI figure 8) and into Medicine Tail Coulee. Some historians believe that part of Custer's force descended the coulee, going west to the river and attempting unsuccessfully to cross into the village. According to some accounts, a small contingent of Indian sharpshooters effectively opposed this crossing.\nWhite Cow Bull claimed to have shot a leader wearing a buckskin jacket off his horse in the river. While no other Indian account supports this claim, if White Bull did shoot a buckskin-clad leader off his horse, some historians have argued that Custer may have been seriously wounded by him. Some Indian accounts claim that besides wounding one of the leaders of this advance, a soldier carrying a company guidon was also hit. Troopers had to dismount to help the wounded men back onto their horses. The fact that either of the non-mutilation wounds to Custer's body (a bullet wound below the heart and a shot to the left temple) would have been instantly fatal casts doubt on his being wounded and remounted.\nReports of an attempted fording of the river at Medicine Tail Coulee might explain Custer's purpose for Reno's attack, that is, a coordinated \"hammer-and-anvil\" maneuver, with Reno's holding the Indians at bay at the southern end of the camp, while Custer drove them against Reno's line from the north. Other historians have noted that if Custer did attempt to cross the river near Medicine Tail Coulee, he may have believed it was the north end of the Indian camp, only to discover that it was the middle. Some Indian accounts, however, place the Northern Cheyenne encampment and the north end of the overall village to the left (and south) of the opposite side of the crossing. The precise location of the north end of the village remains in dispute, however.\nIn 1908, Edward Curtis, the famed ethnologist and photographer of the Native American Indians, made a detailed personal study of the battle, interviewing many of those who had fought or taken part in it. First, he went over the ground covered by the troops with the three Crow scouts White Man Runs Him, Goes Ahead, and Hairy Moccasin, and then again with Two Moons and a party of Cheyenne warriors. He also visited the Lakota country and interviewed Red Hawk, \"whose recollection of the fight seemed to be particularly clear\". Then, he went over the battlefield once more with the three Crow scouts, but also accompanied by General Charles Woodruff \"as I particularly desired that the testimony of these men might be considered by an experienced army officer\". Finally, Curtis visited the country of the Arikara and interviewed the scouts of that tribe who had been with Custer's command. Based on all the information he gathered, Curtis concluded that Custer had indeed ridden down the Medicine Tail Coulee and then towards the river where he probably planned to ford it. However, \"the Indians had now discovered him and were gathered closely on the opposite side\". They were soon joined by a large force of Sioux who (no longer engaging Reno) rushed down the valley. This was the beginning of their attack on Custer, who was forced to turn and head for the hill where he would make his famous \"last stand\". Thus, wrote Curtis, \"Custer made no attack, the whole movement being a retreat\".\nOther views of Custer's actions at Minneconjou Ford.\nOther historians claim, from testimony of Lt. Edward Settle Godfrey, that Custer never approached the river, but rather continued north across the coulee and up the other side, where he gradually came under attack. According to this theory, by the time Custer realized he was badly outnumbered, it was too late to retreat to the south where Reno and Benteen could have provided assistance. Two men from the 7th Cavalry, the young Crow scout \"Ashishishe\" (known in English as Curley) and the trooper Peter Thompson, claimed to have seen Custer engage the Indians. The accuracy of their recollections remains controversial; accounts by battle participants and assessments by historians almost universally discredit Thompson's claim.\nArchaeological evidence and reassessment of Indian testimony have led to a new interpretation of the battle. In the 1920s, battlefield investigators discovered hundreds of .45-70 shell cases along the ridge line known today as Nye-Cartwright Ridge, between South Medicine Tail Coulee and the next drainage at North Medicine Tail (also known as Deep Coulee). Some historians believe Custer divided his detachment into two (and possibly three) battalions, retaining personal command of one while presumably delegating Captain George W. Yates to command the second.\nEvidence from the 1920s supports the theory that at least one of the companies made a feint attack southwest from Nye-Cartwright Ridge straight down the center of the \"V\" formed by the intersection at the crossing of Medicine Tail Coulee on the right and Calhoun Coulee on the left. The intent may have been to relieve pressure on Reno's detachment (according to the Crow scout Curley, possibly viewed by both Mitch Bouyer and Custer) by withdrawing the skirmish line into the timber near the Little Bighorn River. Had the U.S. troops come straight down Medicine Tail Coulee, their approach to the Minneconjou Crossing and the northern area of the village would have been masked by the high ridges running on the northwest side of the Little Bighorn River.\nThat they might have come southwest, from the center of Nye-Cartwright Ridge, seems to be supported by Northern Cheyenne accounts of seeing the approach of the distinctly white-colored horses of Company E, known as the Grey Horse Company. Its approach was seen by Indians at that end of the village. Behind them, a second company, further up on the heights, would have provided long-range cover fire. Warriors could have been drawn to the feint attack, forcing the battalion back towards the heights, up the north fork drainage, away from the troops providing cover fire above. The covering company would have moved towards a reunion, delivering heavy volley fire and leaving the trail of expended cartridges discovered 50 years later.\nLast stand.\nIn the end, the hilltop to which Custer had moved was probably too small to accommodate all of the survivors and wounded. Fire from the southeast made it impossible for Custer's men to secure a defensive position all around Last Stand Hill where the soldiers put up their most dogged defense. According to Lakota accounts, far more of their casualties occurred in the attack on Last Stand Hill than anywhere else. The extent of the soldiers' resistance indicated they had few doubts about their prospects for survival. According to Cheyenne and Sioux testimony, the command structure rapidly broke down, although smaller \"last stands\" were apparently made by several groups. Custer's remaining companies (E, F, and half of C) were soon killed.\nBy almost all accounts, the Lakota annihilated Custer's force within an hour of engagement. David Humphreys Miller, who between 1935 and 1955 interviewed the last Lakota survivors of the battle, wrote that the Custer fight lasted less than one-half hour. Other native accounts said the fighting lasted only \"as long as it takes a hungry man to eat a meal.\" The Lakota asserted that Crazy Horse personally led one of the large groups of warriors who overwhelmed the cavalrymen in a surprise charge from the northeast, causing a breakdown in the command structure and panic among the troops. Many of these men threw down their weapons while Cheyenne and Sioux warriors rode them down, \"counting coup\" with lances, coup sticks, and quirts. Some Native accounts recalled this segment of the fight as a \"buffalo run.\"\nCaptain Frederick Benteen, battalion leader of Companies D, H and K, on the 18th day of the \"Reno Court of Inquiry\" gave his observations on the Custer battlefield on June 27, 1876:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I went over the battlefield carefully with a view to determine how the battle was fought. I arrived at the conclusion then, as I have now, that it was a rout, a panic, until the last man was killed ...\nThat there was no line formed on the battlefield. You can take a handful of corn and scatter it over the floor, and make just such lines, there were none. The only approach to a line was where 5 or 6 [dead] horses found at equal distances, like skirmishers [part of Lt. Calhoun's Company L]. Ahead of those 5 or 6 [dead] horses there were 5 or 6 men at about the same distances, showing that the horses were killed and the riders jumped off and were all heading to get where General Custer was. That was the only approach to a line on the field. There were more than 20 [troopers] killed there to the right. There were 4 or 5 at one place, all within a space of 20 to 30 yards. That was the condition all over the field and in the [gorge].\nI think, in all probability, that the men turned their horses loose without any orders to do so. Many orders might have been given, but few obeyed. I think that they were panic stricken; it was a rout, as I said before.\nA Brul\u00e9 Sioux warrior stated: \"In fact, Hollow Horn Bear believed that the troops were in good order at the start of the fight, and kept their organization even while moving from point to point.\" Red Horse, an Oglala Sioux warrior, commented: \"Here [Last Stand Hill] the soldiers made a desperate fight.\" One Hunkpapa Sioux warrior, Moving Robe, noted that \"It was a hotly contested battle\", while another, Iron Hawk, stated: \"The Indians pressed and crowded right in around Custer Hill. But the soldiers weren't ready to die. We stood there a long time.\" In a letter from February 21, 1910, Private William Taylor, Company M, 7th Cavalry, wrote: \"Reno proved incompetent and Benteen showed his indifference\u2014I will not use the uglier words that have often been in my mind. Both failed Custer and he had to fight it out alone.\"\nCuster's final resistance.\nRecent archaeological work at the battlefield indicates that officers on Custer Hill restored some tactical control. E Company rushed off Custer Hill toward the Little Bighorn River but failed to reach it, which resulted in the destruction of that company. This left about 50\u201360 men, mostly from F Company and the staff, on Last Stand Hill. The remainder of the battle took on the nature of a running fight. Modern archaeology and historical Indian accounts indicate that Custer's force may have been divided into three groups, with the Indians attempting to prevent them from effectively reuniting. Indian accounts describe warriors (including women) running up from the village to wave blankets in order to scare off the soldiers' horses. One 7th Cavalry trooper claimed to have found several stone \"mallets\" consisting of a round cobble weighing 8\u201310 pounds (about 4\u00a0kg) with a rawhide handle, which he believed had been used by the Indian women to finish off the wounded. Fighting dismounted, the soldiers' skirmish lines were overwhelmed. Army doctrine would have called for one man in four to be a horseholder behind the skirmish lines and, in extreme cases, one man in eight. Later, the troops would have bunched together in defensive positions and are alleged to have shot their remaining horses as cover. As individual troopers were wounded or killed, initial defensive positions would have been abandoned as untenable.\nUnder threat of attack, the first U.S. soldiers on the battlefield three days later hurriedly buried the troopers in shallow graves, more or less where they had fallen. A couple of years after the battle, markers were placed where men were believed to have fallen, so the placement of troops has been roughly construed. The troops evidently died in several groups, including on Custer Hill, around Captain Myles Keogh, and strung out towards the Little Bighorn River.\nLast break-out attempt.\nAccording to Indian accounts, about forty men on Custer Hill made a desperate stand around Custer, delivering volley fire. The great majority of the Indian casualties were probably suffered during this closing segment of the battle, as the soldiers and Indians on Calhoun Ridge were more widely separated and traded fire at greater distances for most of their portion of the battle than did the soldiers and Indians on Custer Hill.\nModern documentaries suggest that there may not have been a \"Last Stand\", as traditionally portrayed in popular culture. Instead, archaeologists suggest that in the end, Custer's troops were not surrounded but rather overwhelmed by a single charge. This scenario corresponds to several Indian accounts stating Crazy Horse's charge swarmed the resistance, with the surviving soldiers fleeing in panic. Many of these troopers may have ended up in a deep ravine away from what is known today as Custer Hill. At least 28 bodies (the most common number associated with burial witness testimony), including that of scout Mitch Bouyer, were discovered in or near that gulch, their deaths possibly the battle's final actions.\nAlthough the marker for Mitch Bouyer was found accurate through archaeological and forensic testing of remains, it is some 65 yards away from Deep Ravine. Historian Douglas Scott theorized that the \"Deep Gulch\" or \"Deep Ravine\" might have included not only the steep-sided portion of the coulee, but the entire drainage including its tributaries, in which case the bodies of Bouyer and others were found where eyewitnesses had said they were seen.\nOther archaeological explorations done in Deep Ravine found no human remains associated with the battle. Over the years since the battle, skeletal remains that were reportedly recovered from the mouth of the Deep Ravine by various sources have been repatriated to the Little Big Horn National Monument. According to Scott, it is likely that in the 108 years between the battle and Scott's excavation efforts in the ravine, geological processes caused many of the remains to become unrecoverable. For example, near the town of Garryowen, portions of the skeleton of a trooper killed in the Reno Retreat were recovered from an eroding bank of the Little Big Horn, while the rest of the remains had apparently been washed away by the river.\nAftermath.\nAfter the Custer force was annihilated, the Lakota and Northern Cheyenne regrouped to attack Reno and Benteen. The fight continued until dark (approximately 9:00 pm) and for much of the next day, with the outcome in doubt. Reno credited Benteen with repulsing a severe attack on the portion of the perimeter held by Companies H and M. On June 27, the column under General Terry approached from the north, and the natives drew off in the opposite direction. The Crow scout White Man Runs Him was the first to tell General Terry's officers that Custer's force had \"been wiped out.\" Reno and Benteen's wounded troops were given what treatment was available at that time; five later died of their wounds. One of the regiment's three surgeons had been with Custer's column, while another, Dr. DeWolf, had been killed during Reno's retreat. The only remaining doctor was Assistant Surgeon Henry R. Porter.\nWhen the Crows got news of the battle, they went into grief. Crow woman Pretty Shield told how they were \"crying ... for Son-of-the-morning-star [Custer] and his blue soldiers\". With the defeat of Custer, it was still a real threat that the Lakotas would take over the eastern part of the Crow reservation and keep up the invasion. In the end, the U.S. army won the Sioux war. Crow chief Plenty Coups recalled with amazement how his tribe now finally could sleep without fear for Lakota attacks: \"this was the first time I had ever known such a condition.\"\nThe first non-Natives to hear the news of the Custer defeat (outside of Terry's force) were those aboard the steamboat \"Far West,\" which had brought supplies for the expedition. Curley, one of Custer's scouts, rode up to the steamboat and tearfully conveyed the information to Grant Marsh, the boat's captain, and army officers. Marsh converted the \"Far West\" into a floating field hospital to carry the 52 wounded from the battle to Fort Lincoln. Traveling night and day, with a full head of steam, Marsh brought the steamer downriver to Bismarck, Dakota Territory, making the run in the record time of 54 hours and bringing the first news of the military defeat which came to be popularly known as the \"Custer Massacre\". The editor of the Bismarck paper kept the telegraph operator busy for hours transmitting information to the \"New York Herald\" (for which he corresponded). News of the defeat arrived in the East as the U.S. was observing its centennial. The Army began to investigate, although its effectiveness was hampered by a concern for survivors, and the reputation of the officers. Custer's wife, Elizabeth Bacon Custer, in particular, guarded and promoted the ideal of him as the gallant hero, attacking any who cast an ill light on his reputation.\nThe Battle of the Little Bighorn had far-reaching consequences for the Natives. It was essentially the end of the \"Indian Wars\" and has even been referred to as \"the Indians' last stand\" in the area. Within 48 hours of the battle, the large encampment on the Little Bighorn broke up into smaller groups because there was not enough game and grass to sustain a large congregation of people and horses.\nOglala Sioux Black Elk recounted the exodus this way: \"We fled all night, following the Greasy Grass. My two younger brothers and I rode in a pony-drag, and my mother put some young pups in with us. They were always trying to crawl out and I was always putting them back in, so I didn't sleep much.\"\nThe scattered Sioux and Cheyenne feasted and celebrated during July with no threat from soldiers. After their celebrations, many of the Natives returned to the reservation. Soon the number of warriors amounted to only about 600. Both Crook and Terry remained immobile for seven weeks after the battle, awaiting reinforcements and unwilling to venture out against the Sioux and Cheyenne until they had at least 2,000 men. Crook and Terry finally took the field against the Native forces in August. General Nelson A. Miles took command of the effort in October 1876. In May 1877, Sitting Bull escaped to Canada. Within days, Crazy Horse surrendered at Fort Robinson, Nebraska. The Great Sioux War ended on May 7 with Miles' defeat of a remaining band of Miniconjou Sioux.\nOwnership of the Black Hills, which had been a focal point of the 1876 conflict, was determined by an ultimatum issued by the Manypenny Commission, according to which the Sioux were required to cede the land to the United States if they wanted the government to continue supplying rations to the reservations. Threatened with forced starvation, the Natives ceded \"Paha Sapa\" to the United States, but the Sioux never accepted the legitimacy of the transaction. They lobbied Congress to create a forum to decide their claim and subsequently litigated for 40 years; the United States Supreme Court in the 1980 decision \"United States v. Sioux Nation of Indians\" acknowledged that the United States had taken the Black Hills without just compensation. The Sioux refused the money subsequently offered and continue to insist on their right to occupy the land.\nParticipants.\nNative American leaders and warriors.\nThe Lakota had formed a \"Strongheart Society\" of caretakers and providers for the camp, consisting of men who had demonstrated compassion, generosity and bravery. As the purpose of the tribes' gathering was to take counsel, they did not constitute an army or warrior class.\nArapaho participation.\nModern-day accounts include Arapaho warriors in the battle, but the five Arapaho men who were at the encampments were there only by accident. While on a hunting trip they came close to the village by the river and were captured and almost killed by the Lakota who believed the hunters were scouts for the U.S. Army. Two Moons, a Northern Cheyenne leader, interceded to save their lives.\nNotable scouts/interpreters.\nThe 7th Cavalry was accompanied by a number of scouts and interpreters:\nCasualties.\nNative American warriors.\nEstimates of Native American casualties have differed widely, from as few as 36 dead (from Native American listings of the dead by name) to as many as 300. Lakota chief Red Horse told Col. W. H. Wood in 1877 that the Native Americans suffered 136 dead and 160 wounded during the battle. In 1881, Red Horse told Dr. C. E. McChesney the same numbers but in a series of drawings done by Red Horse to illustrate the battle, he drew only sixty figures representing Lakota and Cheyenne casualties. Of those sixty figures, only thirty-some are portrayed with a conventional Plains Indian method of indicating death. In the last 140 years, historians have been able to identify multiple Indian names pertaining to the same individual, which has greatly reduced previously inflated numbers. Today a list of positively known casualties exists that lists 99 names, attributed and consolidated to 31 identified warriors.\nNative American noncombatants.\nSix unnamed Native American women and four unnamed children are known to have been killed at the beginning of the battle during Reno's charge. Among them were two wives and three children of the Hunkpapa Leader (Gall).\n7th Cavalry.\nThe 7th Cavalry suffered 52 percent casualties: 16 officers and 242 troopers killed or died of wounds, 1 officer and 51 troopers wounded. Every soldier of the five companies with Custer was killed (except for some Crow scouts and several troopers that had left that column before the battle or as the battle was starting). Among the dead were Custer's brothers Boston and Thomas, his brother-in-law James Calhoun, and his nephew Henry Reed.\nIn 1878, the army awarded 24 Medals of Honor to participants in the fight on the bluffs for bravery, most for risking their lives to carry water from the river up the hill to the wounded. Few on the non-Indian side questioned the conduct of the enlisted men, but many questioned the tactics, strategy and conduct of the officers. Indian accounts spoke of soldiers' panic-driven flight and suicide by those unwilling to fall captive to the Indians. While such stories were gathered by Thomas Bailey Marquis in a book in the 1930s, it was not published until 1976 because of the unpopularity of such assertions. Although soldiers may have believed captives would be tortured, Indians usually killed men outright and took as captive for adoption only young women and children. Indian accounts also noted the bravery of soldiers who fought to the death.\nLegacy.\nReconstitution of the 7th Cavalry.\nBeginning in July, the 7th Cavalry was assigned new officers and recruiting efforts began to fill the depleted ranks. The regiment, reorganized into eight companies, remained in the field as part of the Terry Expedition, now based on the Yellowstone River at the mouth of the Bighorn and reinforced by Gibbon's column. On August 8, 1876, after Terry was further reinforced with the 5th Infantry, the expedition moved up Rosebud Creek in pursuit of the Lakota. It met with Crook's command, similarly reinforced, and the combined force, almost 4,000 strong, followed the Lakota trail northeast toward the Little Missouri River. Persistent rain and lack of supplies forced the column to dissolve and return to its varying starting points. The 7th Cavalry returned to Fort Abraham Lincoln to reconstitute. The regimental commander, Colonel Samuel D. Sturgis, returned from his detached duty in St. Louis, Missouri. Sturgis led the 7th Cavalry in the campaign against the Nez Perce in 1877.\nExpansion of the U.S. Army.\nThe U.S. Congress authorized appropriations to expand the Army by 2,500 men to meet the emergency after the defeat of the 7th Cavalry. For a session, the Democratic Party-controlled House of Representatives abandoned its campaign to reduce the size of the Army. Word of Custer's fate reached the 44th United States Congress as a conference committee was attempting to reconcile opposing appropriations bills approved by the House and the Republican Senate. They approved a measure to increase the size of cavalry companies to 100 enlisted men on July 24. The committee temporarily lifted the ceiling on the size of the Army by 2,500 on August 15.\n\"Sell or Starve\".\nAs a result of the defeat in June 1876, Congress responded by attaching what the Sioux call the \"sell or starve\" rider (19\u00a0Stat.\u00a0https://) to the Indian Appropriations Act of 1876 (enacted August 15, 1876), which cut off all rations for the Sioux until they terminated hostilities and ceded the Black Hills to the United States. The Agreement of 1877 (19\u00a0Stat.\u00a0https://, enacted February 28, 1877) officially took away Sioux land and permanently established Indian reservations.\nControversies.\nReno's conduct.\nThe Battle of the Little Bighorn was the subject of an 1879 U.S. Army Court of Inquiry in Chicago, held at Reno's request, during which his conduct was scrutinized. Some testimony by non-Army officers suggested that he was drunk and a coward. The court found Reno's conduct to be without fault. After the battle, Thomas Rosser, James O'Kelly, and others continued to question the conduct of Reno for his hastily ordered retreat. Defenders of Reno at the trial noted that, while the retreat was disorganized, Reno did not withdraw from his position until it became apparent that he was outnumbered and outflanked by the Native Americans. Contemporary accounts also point to the fact that Reno's scout, Bloody Knife, was shot in the head, spraying him with blood, possibly increasing his panic and distress.\nCuster's errors.\nGeneral Terry and others claimed that Custer made strategic errors from the start of the campaign. For instance, he refused to use a battery of Gatling guns and turned down General Terry's offer of an additional battalion of the 2nd Cavalry. Custer believed that the Gatling guns would impede his march up the Rosebud and hamper his mobility. His rapid march en route to the Little Bighorn averaged nearly a day, so his assessment appears to have been accurate. Custer planned \"to live and travel like Indians; in this manner the command will be able to go wherever the Indians can\", he wrote in his \"Herald\" dispatch.\nBy contrast, each Gatling gun had to be hauled by four horses, and soldiers often had to drag the heavy guns by hand over obstacles. Each of the heavy, hand-cranked weapons could fire up to 350 rounds a minute, an impressive rate, but they were known to jam frequently. During the Black Hills Expedition two years earlier, a Gatling gun had turned over, rolled down a mountain, and shattered to pieces. Lieutenant William Low, commander of the artillery detachment, was said to have almost wept when he learned he had been excluded from the strike force.\nCuster believed that the 7th Cavalry could handle any Indian force and that the addition of the four companies of the 2nd would not alter the outcome. When offered the 2nd Cavalry, he reportedly replied that the 7th \"could handle anything.\" There is evidence that Custer suspected that he would be outnumbered by the Indians, although he did not know by how much. By dividing his forces, Custer could have caused the defeat of the entire column, had it not been for Benteen's and Reno's linking up to make a desperate yet successful stand on the bluff above the southern end of the camp.\nThe historian James Donovan believed that Custer's dividing his force into four smaller detachments (including the pack train) can be attributed to his inadequate reconnaissance; he also ignored the warnings of his Crow scouts and Charley Reynolds. By the time the battle began, Custer had already divided his forces into three battalions of differing sizes, of which he kept the largest. His men were widely scattered and unable to support each other. Wanting to prevent any escape by the combined tribes to the south, where they could disperse into different groups, Custer believed that an immediate attack on the south end of the camp was the best course of action.\nAdmiration for Custer.\nCriticism of Custer was not universal. While investigating the battlefield, Lieutenant General Nelson A. Miles wrote in 1877, \"The more I study the moves here [on the Little Big Horn], the more I have admiration for Custer.\" Facing major budget cutbacks, the U.S. Army wanted to avoid bad press and found ways to exculpate Custer. They blamed the defeat on the Indians' alleged possession of numerous repeating rifles and the overwhelming numerical superiority of the warriors.\nThe widowed Elizabeth Bacon Custer, who never remarried, wrote three popular books in which she fiercely protected her husband's reputation. She lived until 1933, hindering much serious research until most of the evidence was long gone. In addition, Captain Frederick Whittaker's 1876 book idealizing Custer was hugely successful. Custer as a heroic officer fighting valiantly against savage forces was an image popularized in \"Wild West\" extravaganzas hosted by showman \"Buffalo Bill\" Cody, Pawnee Bill, and others. It was not until over half a century later that historians took another look at the battle and Custer's decisions that led to his death and loss of half his command and found much to criticize.\nGatling gun controversy.\nGeneral Alfred Terry's Dakota column included a single battery of artillery, comprising two 3-inch ordnance rifles and two Gatling guns. (According to historian Evan S. Connell, the precise number of Gatlings has not been established: either two or three.)\nCuster's decision to reject Terry's offer of the rapid-fire Gatlings has raised questions among historians as to why he refused them and what advantage their availability might have conferred on his forces at the Battle of the Little Bighorn.\nOne factor concerned Major Marcus Reno's recent 8-day reconnaissance-in-force of the Powder-Tongue-Rosebud Rivers, June 10 to 18. This deployment had demonstrated that artillery pieces mounted on gun carriages and hauled by horses no longer fit for cavalry mounts (so-called condemned horses) were cumbersome over mixed terrain and vulnerable to breakdowns. Custer, valuing the mobility of the 7th Cavalry and recognizing Terry's acknowledgment of the regiment as \"the primary strike force\" preferred to remain unencumbered by the Gatling guns. Custer insisted that the artillery was superfluous to his success, in that the 7th Cavalry alone was sufficient to cope with any force they should encounter, informing Terry: \"The 7th can handle anything it meets\". In addition to these practical concerns, a strained relationship with Major James Brisbin induced Custer's polite refusal to integrate Brisbin's Second Cavalry unit\u2014and the Gatling guns\u2014into his strike force, as it would disrupt any hierarchical arrangements that Custer presided over.\nHistorians have acknowledged the firepower inherent in the Gatling gun: they were capable of firing 350 .45\u201370 () caliber rounds per minute. Jamming caused by black powder residue could lower that rate, raising questions as to their reliability under combat conditions. Researchers have further questioned the effectiveness of the guns under the tactics that Custer was likely to face with the Lakota and Cheyenne warriors. The Gatlings, mounted high on carriages, required the battery crew to stand upright during its operation, making them easy targets for Lakota and Cheyenne sharpshooters.\nHistorian Robert M. Utley, in a section entitled \"Would Gatling Guns Have Saved Custer?\" presents two judgments from Custer's contemporaries: General Henry J. Hunt, expert in the tactical use of artillery in Civil War, stated that Gatlings \"would probably have saved the command\", whereas General Nelson A. Miles, participant in the Great Sioux War declared \"[Gatlings] were useless for Indian fighting.\"\nWeapons.\nLakota and Cheyenne.\nThe Lakota and Cheyenne warriors that opposed Custer's forces possessed a wide array of weaponry, from war clubs and lances to the most advanced firearms of the day. The typical firearms carried by the Lakota and Cheyenne combatants were muzzleloaders, more often a cap-lock smoothbore, the so-called Indian trade musket or Leman guns distributed to Indians by the US government at treaty conventions. Less common were surplus rifled muskets of American Civil War vintage such as the Pattern 1853 Enfield and Springfield Model 1861. Metal cartridge weapons were prized by native combatants, such as the Henry and the Spencer lever-action rifles, as well as Sharps breechloaders. The Lakota and Cheyenne warriors also used bows and arrows. Effective up to , the arrows could readily maim or disable an opponent.\nSitting Bull's forces had no assured means to supply themselves with firearms and ammunition. Nonetheless, they could usually procure these through post-traders, licensed or unlicensed, and from gunrunners who operated in the Dakota Territory: \"a horse or a mule for a repeater ... buffalo hides for ammunition.\" Custer's highly regarded guide, \"Lonesome\" Charley Reynolds, informed his superior in early 1876 that Sitting Bull's forces were amassing weapons, including numerous Winchester repeating rifles and abundant ammunition.\nOf the guns owned by Lakota and Cheyenne fighters at the Little Bighorn, approximately 200 were .44 caliber Winchester Model 1866 repeating rifles, corresponding to about 1 of 10 of the encampment's 2,000 able-bodied fighters who participated in the battle.\n7th Cavalry.\nThe troops under Custer's command carried two regulation firearms authorized and issued by the U.S. Army in early 1876: the breech-loading, single-shot Springfield Model 1873 carbine, and the 1873 Colt single-action revolver. The regulation Model 1860 saber or \"long knives\" were not carried by troopers upon Custer's order.\nExcept for a number of officers and scouts who opted for personally owned and more expensive rifles and handguns, the 7th Cavalry was uniformly armed.\nAmmunition allotments provided 100 carbine rounds per trooper, carried on a cartridge belt and in saddlebags on their mounts. An additional 50 carbine rounds per man were reserved on the pack train that accompanied the regiment to the battlefield. Each trooper had 24 rounds for his Colt handgun.\nThe opposing forces, though not equally matched in the number and type of arms, were comparably outfitted, and neither side held an overwhelming advantage in weaponry.\nLever-action repeaters vs. single-shot breechloaders.\nTwo hundred or more Lakota and Cheyenne combatants are known to have been armed with Henry, Winchester, or similar lever-action repeating rifles at the battle. Virtually every trooper in the 7th Cavalry fought with the single-shot, breech-loading Springfield carbine and the Colt revolver.\nHistorians have asked whether the repeating rifles conferred a distinct advantage on Sitting Bull's villagers that contributed to their victory over Custer's carbine-armed soldiers.\nHistorian Michael L. Lawson offers a scenario based on archaeological collections at the \"Henryville\" site, which yielded plentiful Henry rifle cartridge casings from approximately 20 individual guns. Lawson speculates that though less powerful than the Springfield carbines, the Henry repeaters provided a barrage of fire at a critical point, driving Lieutenant James Calhoun's L Company from Calhoun Hill and Finley Ridge, forcing it to flee in disarray back to Captain Myles Keogh's I Company and leading to the disintegration of that wing of Custer's Battalion.\nModel 1873 / 1884 Springfield carbine and the U.S. Army.\nAfter exhaustive testing\u2014including comparisons to domestic and foreign single-shot and repeating rifles\u2014the Army Ordnance Board (whose members included officers Marcus Reno and Alfred Terry) authorized the Springfield as the official firearm for the United States Army.\nThe Springfield, manufactured in a .45\u201370 long rifle version for the infantry and a .45\u201355 light carbine version for the cavalry, was judged a solid firearm that met the long-term and geostrategic requirements of the United States fighting forces.\nHistorian Mark Gallear claims that U.S. government experts rejected the lever-action repeater designs, deeming them ineffective in a clash with fully equipped European armies, or in case of an outbreak of another civil conflict. Gallear's analysis dismisses the allegation that rapid depletion of ammunition in lever-action models influenced the decision in favor of the single-shot Springfield. The Indian Wars are portrayed by Gallear as a minor theatre of conflict whose contingencies were unlikely to govern the selection of standard weaponry for an emerging industrialized nation.\nThe Springfield carbine is praised for its \"superior range and stopping power\" by historian James Donovan, and author Charles M. Robinson reports that the rifle could be \"loaded and fired much more rapidly than its muzzle-loading predecessors, and had twice the range of repeating rifles such as the Winchester, Henry and Spencer.\"\nGallear points out that lever-action rifles, after a burst of rapid discharge, still required a reloading interlude that lowered their overall rate of fire; Springfield breechloaders \"in the long run, had a higher rate of fire, which was sustainable throughout a battle.\"\nThe breechloader design patent for the Springfield's Erskine S. Allin trapdoor system was owned by the US government and the firearm could be easily adapted for production with existing machinery at the Springfield Armory in Massachusetts. At time when funding for the post-war Army had been slashed, the prospect for economical production influenced the Ordnance Board member selection of the Springfield option.\nMalfunction of the Springfield carbine extractor mechanism.\nWhether the reported malfunction of the Model 1873 Springfield carbine issued to the 7th Cavalry contributed to their defeat has been debated for years.\nThat the weapon experienced jamming of the extractor is not contested, but its contribution to Custer's defeat is considered negligible. This conclusion is supported by evidence from archaeological studies performed at the battlefield, where the recovery of Springfield cartridge casing, bearing tell-tale scratch marks indicating manual extraction, were rare. The flaw in the ejector mechanism was known to the Army Ordnance Board at the time of the selection of the Model 1873 rifle and carbine, and was not considered a significant shortcoming in the overall worthiness of the shoulder arm. With the ejector failure in US Army tests as low as 1:300, the Springfield carbine was vastly more reliable than the muzzle-loading Springfields used in the Civil War.\nGallear addresses the post-battle testimony concerning the copper .45\u201355 cartridges supplied to the troops in which an officer is said to have cleared the chambers of spent cartridges for a number of Springfield carbines. This testimony of widespread fusing of the casings offered to the Chief of Ordnance at the Reno Court of Inquiry in 1879 conflicts with the archaeological evidence collected at the battlefield. Field data showed that possible extractor failures occurred at a rate of approximately 1:30 firings at the Custer Battlefield and at a rate of 1:37 at the Reno-Benteen Battlefield.\nHistorian Thom Hatch observes that the Model 1873 Springfield, despite the known ejector flaw, remained the standard issue shoulder arm for US troops until the early 1890s.\nSurvivor claims.\nSoldiers under Custer's direct command were annihilated on the first day of the battle, except for three Crow scouts and several troopers (including John Martin (Giovanni Martino)) who had left that column before the battle; one Crow scout, Curly, was the only survivor to leave after the battle had begun. Rumors of other survivors persisted for years.\nOver 120 men and women came forward over the next 70 years claiming they were \"the lone survivor\" of Custer's Last Stand. The phenomenon became so widespread that one historian remarked, \"Had Custer had all of those who claimed to be 'the lone survivor' of his two battalions he would have had at least a brigade behind him when he crossed the Wolf Mountains and rode to the attack.\"\nThe historian Earl Alonzo Brininstool suggested he had collected at least 70 \"lone survivor\" stories. Michael Nunnally, an amateur Custer historian, wrote a booklet describing 30 such accounts. W. A. Graham claimed that even Libby Custer received dozens of letters from men, in shocking detail, about their sole survivor experience. At least 125 alleged \"single survivor\" tales have been confirmed in the historical record as of July 2012.\nFrank Finkel, from Dayton, Washington, had such a convincing story that historian Charles Kuhlman believed the alleged survivor, going so far as to write a lengthy defense of Finkel's participation in the battle. Douglas Ellison\u2014mayor of Medora, North Dakota, and an amateur historian\u2014also wrote a book in support of the veracity of Finkel's claim, but most scholars reject it.\nSome of these survivors held a form of celebrity status in the United States, among them Raymond Hatfield \"Arizona Bill\" Gardner and Frank Tarbeaux. A few even published autobiographies that detailed their deeds at the Little Bighorn.\nA modern historian, Albert Winkler, has asserted that there is some evidence to support the case of Private Gustave Korn being a genuine survivor of the battle: \"While nearly all of the accounts of men who claimed to be survivors from Custer's column at the Battle of the Little Bighorn are fictitious, Gustave Korn's story is supported by contemporary records.\" Several contemporary accounts note that Korn's horse bolted in the early stages of the battle, whilst he was serving with Custer's 'I' company, and that he ended up joining Reno's companies making their stand on Reno Hill.\nAlmost as soon as men came forward implying or directly pronouncing their unique role in the battle, there were others who were equally opposed to any such claims. Theodore W. Goldin, a battle participant who later became a controversial historian on the event, wrote (in regards to Charles Hayward's claim to have been with Custer and taken prisoner):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Indians always insisted that they took no prisoners. If they did\u2014a thing I firmly believe\u2014they were tortured and killed the night of the 25th. As an evidence of this I recall the three charred and burned heads we picked up in the village near the scene of the big war dance, when we visited the village with Capt. Benteen and Lieut. Wallace on the morning of the 27th ... I'm sorely afraid, Tony, that we will have to class Hayward's story, like that of so many others, as pure, unadulterated B. S. As a clerk at headquarters I had occasion to look over the morning reports of at least the six troops at Lincoln almost daily, and never saw his name there, or among the list of scouts employed from time to time ... I am hoping that some day all of these damned fakers will die and it will be safe for actual participants in the battle to admit and insist that they were there, without being branded and looked upon as a lot of damned liars. Actually, there have been times when I have been tempted to deny that I ever heard of the 7th Cavalry, much less participated with it in that engagement ... My Medal of Honor and its inscription have served me as proof positive that I was at least in the vicinity at the time in question, otherwise I should be tempted to deny all knowledge of the event.\nThe only documented and verified survivor of Custer's command (having been actually involved in Custer's part of the battle) was Captain Keogh's horse, Comanche. The wounded horse was discovered on the battlefield by General Terry's troops. Although other cavalry mounts survived, they had been taken by the Indians. Comanche eventually was returned to the fort and became the regimental mascot. Several other badly wounded horses were found and killed at the scene. Writer Evan S. Connell noted in \"Son of the Morning Star\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Comanche was reputed to be the only survivor of the Little Bighorn, but quite a few Seventh Cavalry mounts survived, probably more than one hundred, and there was even a yellow bulldog. Comanche lived on another fifteen years. When he died, he was stuffed and to this day remains in a glass case at the University of Kansas. So, protected from moths and souvenir hunters by his humidity-controlled glass case, Comanche stands patiently, enduring generation after generation of undergraduate jokes. The other horses are gone, and the mysterious yellow bulldog is gone, which means that in a sense the legend is true. Comanche alone survived.\nBattlefield preservation.\nThe site of the battle was first preserved as a United States national cemetery in 1879 to protect the graves of the 7th Cavalry troopers. In 1946, it was re-designated as the \"Custer Battlefield National Monument\", reflecting its association with Custer. In 1967, Major Marcus Reno was re-interred in the cemetery with honors, including an eleven-gun salute. Beginning in the early 1970s, there was concern within the National Park Service over the name Custer Battlefield National Monument failing to adequately reflect the larger history of the battle between two cultures. Hearings on the name change were held in Billings on June 10, 1991, and during the following months Congress renamed the site the \"Little Bighorn Battlefield National Monument\".\nUnited States memorialization of the battlefield began in 1879 with a temporary monument to the U.S. dead. In 1881, the current marble obelisk was erected in their honor. In 1890, marble blocks were added to mark the places where the U.S. cavalry soldiers fell.\nNearly 100 years later, ideas about the meaning of the battle became more inclusive. The United States government acknowledged that Native American sacrifices also deserved recognition at the site. The 1991 bill changing the name of the national monument also authorized an Indian Memorial to be built near Last Stand Hill in honor of Lakota and Cheyenne warriors. The commissioned work by native artist Colleen Cutschall is shown in the photograph at right. On Memorial Day 1999, in consultation with tribal representatives, the U.S. added two red granite markers to the battlefield to note where Native American warriors fell. As of December 2006, a total of ten warrior markers have been added (three at the Reno\u2013Benteen Defense Site and seven on the Little Bighorn Battlefield).\nThe Indian Memorial, themed \"Peace Through Unity\", is an open circular structure that stands from the 7th Cavalry obelisk. Its walls have the names of some Indians who died at the site, as well as native accounts of the battle. The open circle of the structure is symbolic, as for many tribes, the circle is sacred. The \"spirit gate\" window facing the Cavalry monument is symbolic as well, welcoming the dead cavalrymen into the memorial.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "56127", "revid": "977949663", "url": "https://en.wikipedia.org/wiki?curid=56127", "title": "Cleopatra Selene", "text": "Cleopatra Selene may refer to:\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about people with the same name. "}
{"id": "56128", "revid": "49903198", "url": "https://en.wikipedia.org/wiki?curid=56128", "title": "Cheyenne", "text": "Indigenous tribe originating from the Great Plains and Great Lakes of the U.S.\nThe Cheyenne ( ) are an Indigenous people of the Great Plains. The Cheyenne comprise two Native American tribes, the S\u00f3'taeo'o or S\u00f3'ta\u00e9taneo'o (more commonly spelled as Suhtai or Sutaio) and the (also spelled Tsitsistas, ); the tribes merged in the early 19th century. Today, the Cheyenne people are split into two federally recognized nations: the Southern Cheyenne, who are enrolled in the Cheyenne and Arapaho Tribes in Oklahoma, and the Northern Cheyenne, who are enrolled in the Northern Cheyenne Tribe of the Northern Cheyenne Indian Reservation in Montana. The Cheyenne language belongs to the Algonquian language family.\nOver the past 400 years, the Cheyenne have changed their lifestyles from Great Lakes woodlands to Northern Plains and by the mid-19th century, the US government forced them onto reservations. At the time of their first European contact in the 16th century, the Cheyenne lived in what is now Minnesota. They were close allies of the Arapaho and loosely aligned with the Lakota. By the early 18th century, they were forced west by other tribes across the Missouri River and into North and South Dakota, where they adopted the horse culture. Having settled the Black Hills of South Dakota and the Powder River Country of present-day Montana and Wyoming, they introduced the horse culture to Lakota people around 1730. The main group of Cheyenne, the Ts\u00eah\u00e9st\u00e1no, was once composed of ten bands that spread across the Great Plains from southern Colorado to the Black Hills in South Dakota. They fought their historic enemies, the Crow and later (1856\u201379) the United States Army. In the mid-19th century, the bands began to split, with some bands choosing to remain near the Black Hills, while others chose to remain near the Platte Rivers of central Colorado. With the Arapaho, the Cheyenne pushed the Kiowa to the Southern Plains. In turn, they were pushed west by the more numerous Lakota.\nThe Northern Cheyenne, known in Cheyenne either as Notameohm\u00e9s\u0117hese, meaning \"Northern Eaters\" (or simply as Ohm\u00e9s\u0117hese meaning \"Eaters\"), live in southeastern Montana on the Northern Cheyenne Indian Reservation. Tribal enrollment figures, as of late 2014, indicate that there are approximately 10,840 members, of which about 4,939 reside on the reservation. Approximately 91% of the population are Native Americans (full or part race), with 72.8% identifying themselves as Cheyenne. Slightly more than one-quarter of the population five years or older spoke a language other than English. The Southern Cheyenne, known in Cheyenne as He\u00e9v\u00e2hetaneo'o meaning \"Roped People\", together with the Southern Arapaho, form the Cheyenne and Arapaho Tribes, in western Oklahoma. Their combined population is 12,130, as of 2008[ [update]]. In 2003, approximately 8,000 of these identified themselves as Cheyenne, although with continuing intermarriage it has become increasingly difficult to separate the tribes.\nName.\nThe Cheyenne called themselves \"Ts\u00e9ts\u00eah\u00e9st\u00e2hese\" (more commonly as the \"Tsitsistas\"; singular: \"Ts\u00e9ts\u00eah\u00e9staestse\"), which translates to \"those who are like this\". The Suhtai, also called the S\u00f3'taeo'o, S\u00f3'ta\u00e9taneo'o, Sutaio (singular: S\u00f3'ta\u00e9tane) traveled with the Ts\u00e9ts\u00eah\u00e9st\u00e2hese and merged with them after 1832. The Suhtai had slightly different speech and customs from the Ts\u00e9ts\u00eah\u00e9st\u00e2hese.\nThe name \"Cheyenne\" derives from the Lakota Sioux exonym \"\u0160ah\u00edyena\" meaning \"little \"\u0160ah\u00edya\"\". The identity of the \"\u0160ah\u00edya\" is not known, but many Great Plains tribes assume that it means Cree or another people who spoke an Algonquian language related to Cree and Cheyenne. The Cheyenne name for Ojibwe is \"S\u00e1hea'eo'o\", a word that sounds similar to the \"Lakota\" word \"\u0160ah\u00edya\".\nAnother of the common etymologies for \"Cheyenne\" is \"a bit like the [people of an] alien speech\" (literally, \"red-talker\"). According to George Bird Grinnell, the Lakota had referred to themselves and fellow Siouan-language bands as \"white talkers\", and those of other language families, such as the Algonquian Cheyenne, as \"red talkers\" (\"\u0160ah\u00edyena\").\nThe etymology of the name Tsitsistas (Ts\u00e9ts\u0117h\u00e9st\u0227hese), which the Cheyenne call themselves, is uncertain. According to the Cheyenne dictionary offered online by Chief Dull Knife College, there is no consensus and various origins and translation of the word have been proposed. Grinnell's record is typical and states, \"They call themselves Tsistsistas [sic, Tsitsistas is the correct pronunciation], which the books commonly give as meaning \"people\". It most likely means related to one another, similarly bred, like us, our people, or us. The term for the Cheyenne homeland is \"Tsistano\".\nLanguage.\nThe Cheyenne of Montana and Oklahoma speak the Cheyenne language, known as \"Ts\u0117h\u00e9sen\u0117stsest\u022ftse\" (common spelling: Tsisinstsistots). Approximately 800 people speak Cheyenne in Oklahoma. There are only a handful of vocabulary differences between the two locations. The Cheyenne alphabet contains 14 letters. The Cheyenne language is one of the larger Algonquian-language group. Formerly, the S\u00f3'taeo'o (S\u00f3'ta\u00e9taneo'o) or Suhtai (Sutaio) bands of Southern and Northern Cheyenne spoke \"S\u00f3'ta\u00e9ka'\u0117\u0161k\u00f3ne\" or \"S\u00f3'taen\u0117stsest\u022ftse\", a language so close to \"Ts\u0117h\u00e9sen\u0117stsest\u022ftse\" (Cheyenne language), that it is sometimes termed a Cheyenne dialect.\nHistory.\nThe earliest written record of the Cheyenne was in the mid-17th century, when a group of Cheyenne visited the French Fort Crevecoeur, near present-day Peoria, Illinois. The Cheyenne at this time lived between the Mississippi River and Mille Lacs Lake in Minnesota. Their economy was based on the collection of wild rice and hunting, especially of bison, which lived in the prairies 70 to 80 miles west of the Cheyenne villages.\nAccording to tribal history, during the 17th century, the Cheyenne were driven by the Assiniboine (H\u00f3heeheo'o) from the Great Lakes region to present-day Minnesota and North Dakota, where they established villages. The most prominent of the ancient Cheyenne villages is Biesterfeldt Village, in eastern North Dakota along the Sheyenne River. They first reached the Missouri River in 1676. A more recent analysis of early records posits that at least some of the Cheyenne remained in the Mille Lac region of Minnesota until about 1765, when the Ojibwe defeated the Dakota with firearms \u2014 pushing the Cheyenne, in turn, to the Minnesota River, where they were reported in 1766.\nOn the Missouri River, the Cheyenne came into contact with the neighboring Mandan, Hidatsa (Ts\u00e9-he\u0161e'\u00e9m\u00e2he\u00f3nese, \"people who have soil houses\"), and Arikara people (\u00d3noneo'o), adopting many of their cultural characteristics. They were first of the later Plains tribes to move into the Black Hills and Powder River Country. About 1730, they introduced the horse to Lakota bands (Ho'\u00f3homo'eo'o). Conflict with migrating Lakota and Ojibwe people forced the Cheyenne further west, and they, in turn, pushed the Kiowa to the south.\nBy 1776, the Lakota had overwhelmed the Cheyenne and taken over much of their territory near the Black Hills. In 1804, Lewis and Clark visited a surviving Cheyenne village in what is now North Dakota. Such European explorers learned many different names for the Cheyenne and did not realize how the different sections were forming a unified tribe.\nThe Cheyenne tribes today descend from two related tribes, the \"Ts\u00e9ts\u0117h\u00e9st\u0227hese / Tsitsistas\" (Cheyenne proper) and \"S\u00f3'taeo'o / S\u00f3'ta\u00e9taneo'o\" (better known as Suhtai or Sutaio). The latter merged with the Ts\u00e9tsh\u00e9st\u0227hese in the mid-19th century. Their oral history relays that both tribal peoples are characterized, and represented by two cultural heroes or prophets who received divine articles from their god Ma'heo'o, whom the S\u00f3'taeo'o called He'emo.\nThe Ts\u00e9ts\u0117h\u00e9st\u0227hese / Tsitsistas prophet Mots\u00e9'e\u00f3eve (Sweet Medicine Standing, Sweet Root Standing, commonly called Sweet Medicine) received the \"Maah\u00f3tse\" ((Sacred) Arrows Bundle) at \"N\u00f3\u00e1v\u00f3se\" (\u2033medicine(sacred)-hill\u2033, name for Bear Butte, northwest of Rapid City, South Dakota, which they carried when they waged tribal-level war and were kept in the \"maah\u00e9ome\" (Arrow Lodge or Arrow Tepee). He organized the structure of Cheyenne society, their military or war societies led by prominent warriors, their system of legal justice, and the Council of Forty-four peace chiefs. The latter was formed from four \"v\u00e9hoo'o\" (chiefs or leaders) of the ten principal \"manaho\" (bands) and an additional four \u2033Old Man\u2033 meetings to deliberate at regular tribal gatherings, centered around the Sun Dance.\nSweet Medicine is the Cheyenne prophet who predicted the coming of the horse, the cow, the white man, and other new things to the Cheyenne. He was named for \"mots\u00e9'eon\u022ftse\" (sweetgrass), one of the sacred plant medicines used by many Plains peoples in ceremonies.\nThe \"Maah\u00f3tse\" (Sacred Arrows) are symbols of male power. The \"\u00c9sevone / H\u00f3hk\u0117ha'e\" (Sacred Buffalo Hat) is the symbol of female power. The Sacred Buffalo Hat and the Sacred Arrows together form the two great covenants of the Cheyenne Nation. Through these two bundles, Ma'heo'o assures continual life and blessings for the people.\nThe S\u00f3'taeo'o prophet Tom\u022fs\u00e9v\u0117s\u00e9he (\"Erect Horns\") received the \"\u00c9sevone\" (aka \"Is'siwun\" \u2013 \"Sacred (Buffalo) Hat Bundle\") at \"T\u022fh\u00f3on\u00e9vose\" (\u2033Stone Hammer Mountain\u2033) near the Great Lakes in the present state of Minnesota. The \"\u00c9sevone / H\u00f3hk\u0117ha'e (Sacred Buffalo Hat)\" is kept in the \"von\u0227h\u00e9ome\" (old term) or \"h\u00f3hk\u0117ha'\u00e9ome\" (new term) (\"Sacred Hat Lodge, Sacred Hat Tepee\"). Erect Horns gave them the accompanying ceremonies and the Sun Dance. His vision convinced the tribe to abandon their earlier sedentary agricultural traditions to adopt nomadic Plains horse culture. They replaced their earth lodges with portable tipis and switched their diet from fish and agricultural produce, to mainly bison and wild fruits and vegetables. Their lands ranged from the upper Missouri River into what is now Wyoming, Montana, Colorado, and South Dakota.\nThe \"\u00c9sevone / H\u00f3hk\u0117ha'e\" (\"Sacred Buffalo Hat\") is kept among the Northern Cheyenne and Northern S\u00f3'taeo'o. The \"Ts\u00e9\u00e1'en\u014dv\u0227htse\" (\u2033Sacred (Buffalo) Hat Keeper\u2033 or \u2033Keeper of the Sacred (Buffalo) Hat\u2033) must belong to the S\u00f3'taeo'o (Northern or Southern alike). In the 1870s tribal leaders became disenchanted with the keeper of the bundle demanded the keeper Broken Dish give up the bundle; he agreed but his wife did not and desecrated the Sacred Hat and its contents; a ceremonial pipe and a buffalo horn were lost. In 1908 a Cheyenne named Three Fingers gave the horn back to the Hat. The pipe came into possession of a Cheyenne named Burnt All Over who gave it to Hattie Goit of Poteau, Oklahoma who in 1911 gave the pipe to the Oklahoma Historical Society. In 1997 the Oklahoma Historal Society negotiated with the Northern Cheyenne to return the pipe to the tribal keeper of the Sacred Medicine Hat Bundle James Black Wolf.\nExpansion on the Plains.\nAfter being pushed south and westward by the Lakota, the Cheyenne began to establish new territory. Around 1811, the Cheyenne formally allied with the Arapaho people (Hetanevo'eo'o), which would remain strong throughout their history and into the present. The alliance helped the Cheyenne expand their territory that stretched from southern Montana, through most of Wyoming, the eastern half of Colorado, far western Nebraska, and far western Kansas. \nBy 1820, American traders and explorers reported contact with Cheyenne at present-day Denver, Colorado, and on the Arkansas River. The Cheyenne likely hunted and traded in Denver much earlier. They may have migrated to the south for winter. The Hairy Rope band is reputed to have been the first band to move south, capturing wild horses as far south as the Cimarron River Valley. In response to the construction of Bent's Fort by Charles Bent, a non-Native trader and ally, a large portion of the tribe moved further south and stayed around the area. The other part of the tribe continued to live along the headwaters of the North Platte and Yellowstone rivers. The groups became the Southern Cheyenne, or S\u00f3won\u00ed\u0103 (Southerners), and the Northern Cheyenne, or O'm\u01d0's\u01d0s (Eaters). The two divisions maintained regular and close contact.\nIn the southern portion of their territory, the Cheyenne and Arapaho warred with the allied Comanche, Kiowa, and Plains Apache. Numerous battles were fought including a notable fight along the Washita River in 1836 with the Kiowa which resulted in the death of 48 Cheyenne warriors of the Bowstring society. In summer 1838, many Cheyenne and Arapaho attacked a camp of Kiowa and Comanche along Wolf Creek in Oklahoma resulting in heavy losses from both sides. Among the losses were White Thunder (keeper of the Medicine Arrows and Owl Woman's father), Flat-War-Club (Cheyenne), and Sleeping Wolf (Kiowa). \nConflict with the Comanche, Kiowa, and Plains Apache ended in 1840 when the tribes allied with each other. The new alliance allowed the Cheyenne to enter the Llano Estacado in the Texas and Oklahoma panhandles and northeastern New Mexico to hunt bison and trade. Their expansion in the south and alliance with the Kiowa led to their first raid into Mexico in 1853. The raid ended in disaster with heavy resistance from Mexican lancers, resulting in all but three of the war party being killed. \nTo the north, the Cheyenne allied with the Lakota, which allowed them to expand their territory into part of their former lands around the Black Hills. By heading into the Rocky Mountains, they managed to escape the 1837\u201339 smallpox epidemics that swept across the plains from white settlements but were greatly affected by the 1849 cholera epidemic. Contact with Euro-Americans was mostly light, with most contact involving mountain men, traders, explorers, treaty makers, and painters.\nEnemies and warrior culture.\nLike many other Plains Indian nations, the Cheyenne were a horse and warrior people who developed as skilled and powerful mounted warriors. A warrior in Cheyenne society is not a fighter but also a protector, provider, and leader. Warriors gained rank in Cheyenne society by performing and accumulating various acts of bravery in battle known as counting coups. The title of war chief could be earned by any warrior who performs enough of the specific coups required to become a war chief. \nSpecific warrior societies evolved. Each society had selected leaders who would invite those that they saw worthy enough to their society lodge for initiation into the society. Often, societies would have minor rivalries; however, they might work together as a unit when warring with an enemy. Military societies played an important role in Cheyenne government. Society leaders were often in charge of organizing hunts and raids as well as ensuring proper discipline and the enforcement of laws within the nation. Each of the six distinct warrior societies of the Cheyenne took turns leadering the nation. The four original military societies of the Cheyenne were the Swift Fox Society, Elk Horn Scrapper or Crooked Lance Society, Shield Society, and the Bowstring Men Society. The fifth society is split between the Crazy Dog Society and the famous Dog Soldiers. The sixth society is the Contrary Warrior Society, most notable for riding backward into battle as a sign of bravery. All six societies and their various branches exist among the Southern and Northern Cheyenne nations in present times. \nWarriors used a combination of weapons from war clubs, tomahawks, and bows and arrows, and lances to firearms acquired through raiding and trade.\nThe enemies of the Cheyenne included the Aps\u00e1alooke (\u00d3oetaneo'o \u2013 \"crow (bird) people\"), Shoshone (S\u00f3sone'eo'o), Blackfeet (Mo'\u022fht\u00e1v\u0117haht\u00e1taneo'o, same literal meaning), Interior Salish and Kuntenai (K\u0227hkoests\u00e9ataneo'o \u2013 \"flat-headed-people\"), Nez Perce (Otaes\u00e9taneo'o \u2013 \"pierced nose people\"), Arikara, Gros Ventre (Hest\u00f3etaneo'o \u2013 \"beggars for meat\", \"spongers\" or M\u022fh\u00f3nooneo'o \u2013 lit. \"scouting all over ones\"), Assiniboine, and Plains Cree (V\u00f3hkooh\u00e9taneo'o \u2013 \"rabbit people\") to the north and west of Cheyenne territory. By the help of the Medicine Arrows (the Mahuts), the Cheyenne tribe massacred a Crow camp in 1820. To the east of Cheyenne Territory they fought with the Lakota, Dakota, Pawnee, Ponca, Kaw, Iowa, Ho-Chunk, and Omaha (On\u00e9hao'o). The Pawnee captured the Cheyenne's Sacred Arrows during an attack on a hunting camp around 1830. \nSouth of Cheyenne territory they fought with the Kiowa, Comanche, Ute, Plains Apache, Osage, Wichita, various Apache tribes, and Navajo. Many of the enemies the Cheyenne fought were only encountered occasionally, such as on a long-distance raid or hunt. Some of their enemies, particularly the Eastern Plains tribe such as the Pawnee and Osage would act as Indian Scouts for the US Army, providing valuable tracking skills and information regarding Cheyenne habits and fighting strategies to US soldiers. Some of their enemies such as the Lakota would later in their history become their strong allies, helping the Cheyenne fight against the United States Army during Red Cloud's War and the Great Sioux War of 1876. The Comanche, Kiowa and Plains Apache became allies of the Cheyenne towards the end of the Indian wars on the Southern Plains, fighting together during conflicts such as the Red River War.\nRelationship with the Arapaho.\nThe Cheyenne and Arapaho formed an alliance around 1811 that helped them expand their territories and strengthen their presence on the plains. Like the Cheyenne, the Arapaho language is an Algonquian language, although the two languages are not mutually intelligible. The Arapaho remained strong allies with the Cheyenne and helped them fight alongside the Lakota and Dakota during Red Cloud's War and the Great Sioux War of 1876, also known commonly as the Black Hills War. On the Southern Plains, the Arapaho and Cheyenne allied with the Comanche, Kiowa, and Plains Apache to fight invading settlers and US soldiers. \nThe Arapaho were present with the Cheyenne at the Sand Creek Massacre when a peaceful encampment of mostly women, children, and the elderly were attacked and massacred by US soldiers. Both major divisions of the Cheyenne, the Northern Cheyenne and Southern Cheyenne were allies to the Arapaho who like the Cheyenne are split into northern and southern divisions. The Southern Cheyenne and Southern Arapaho were assigned to the same reservation in Oklahoma Indian Territory and remained together as the federally recognized Cheyenne and Arapaho Tribes after the reservation was opened to American settlement and into modern times.\nThe Northern Arapaho were to be assigned a reservation of their own or share one with the Cheyenne; however, the US federal government failed to provide them with either and placed them on the already established Wind River Indian Reservation in Wyoming with their former enemies the Shoshone.\nTreaty of 1825.\nIn the summer of 1825, the tribe was visited on the Upper Missouri River by a US treaty commission consisting of General Henry Atkinson and Indian agent Benjamin O'Fallon, accompanied by a military escort of 476 men. General Atkinson and his fellow commissioner left Fort Atkinson on May 16, 1825. Ascending the Missouri, they negotiated treaties of friendship and trade with tribes of the upper Missouri, including the Arikara, the Cheyenne, the Crow, the Mandan, the Ponca, and several bands of the Lakota and Dakota. At that time, the US had competition on the upper Missouri from British traders, who came south from Canada.\nThe treaties acknowledged that the tribes lived within the United States, vowed perpetual friendship between the US and the tribes, and, recognizing the right of the United States to regulate trade, the tribes promised to deal only with licensed traders. The tribes agreed to forswear private retaliation for injuries, and to return stolen horses or other goods or compensate the owner. The commission's efforts to contact the Blackfoot and the Assiniboine were unsuccessful. During their return to Fort Atkinson at the Council Bluff in Nebraska, the commission had successful negotiations with the Otoe, the Pawnee and the Omaha.\nEffects of the Emigrant Trail.\nIncreased traffic of emigrants along the related Oregon, Mormon and California trails, beginning in the early 1840s, heightened competition with Native Americans for scarce resources of water and game in arid areas. With resource depletion along the trails, the Cheyenne became increasingly divided into the Northern Cheyenne and Southern Cheyenne, where they could have adequate territory for sustenance.\nDuring the California Gold Rush, emigrants brought in cholera. It spread in mining camps and waterways due to poor sanitation. The disease was generally a major cause of death for emigrants, about one-tenth of whom died during their journeys.\nPerhaps from traders, the cholera epidemic reached the Plains Indians in 1849, resulting in severe loss of life during the summer of that year. Historians estimate about 2,000 Cheyenne died, one-half to two-thirds of their population. There were significant losses among other tribes as well, which weakened their social structures. Perhaps because of severe loss of trade during the 1849 season, Bent's Fort was abandoned and burned.\nFort Laramie Treaty of 1851.\nIn 1846, Thomas Fitzpatrick was appointed US Indian agent for the upper Arkansas and Platte River. His efforts to negotiate with the Northern Cheyenne, the Arapaho and other tribes led to a great council at Fort Laramie in 1851. Treaties were negotiated by a commission consisting of Fitzpatrick and David Dawson Mitchell, US Superintendent of Indian Affairs, with the Indians of the northern plains.\nTo reduce intertribal warfare on the Plains, the government officials \"assigned\" territories to each tribe and had them pledge mutual peace. In addition, the government secured permission to build and maintain roads for European-American travelers and traders through Indian country on the Plains, such as the Emigrant Trail and the Santa Fe Trail, and to maintain forts to guard them. The tribes were compensated with annuities of cash and supplies for such encroachment on their territories. The Fort Laramie Treaty of 1851 affirmed the Cheyenne and Arapaho territory on the Great Plains between the North Platte River and the Arkansas. This territory included what is now Colorado, east of the Front Range of the Rockies and north of the Arkansas River; Wyoming and Nebraska, south of the North Platte River; and extreme western Kansas.\nPunitive US expedition of 1857.\nIn April 1856, an incident at the Platte River Bridge (near present-day Casper, Wyoming), resulted in the wounding of a Cheyenne warrior. He returned to the Cheyenne on the plains. During the summer of 1856, Indians attacked travelers along the Emigrant Trail near Fort Kearny. In retaliation, the US Cavalry attacked a Cheyenne camp on Grand Island in Nebraska. They killed ten Cheyenne warriors and wounded eight or more.\nCheyenne parties attacked at least three emigrant settler parties before returning to the Republican River. The Indian agent at Fort Laramie negotiated with the Cheyenne to reduce hostilities, but the Secretary of War ordered the 1st Cavalry Regiment (1855) to carry out a punitive expedition under the command of Colonel Edwin V. Sumner. He went against the Cheyenne in the spring of 1857. Major John Sedgwick led part of the expedition up the Arkansas River, and via Fountain Creek to the South Platte River. Sumner's command went west along the North Platte to Fort Laramie, then down along the Front Range to the South Platte. The combined force of 400 troops went east through the plains searching for Cheyenne.\nUnder the influence of the medicine man White Bull (also called Ice) and Grey Beard (also called Dark), the Cheyenne went into battle believing that strong spiritual medicine would prevent the soldiers' guns from firing. They were told that if they dipped their hands in a nearby spring, they had only to raise their hands to repel army bullets. Hands raised, the Cheyenne surrounded the advancing troops as they advanced near the Solomon River. Sumner ordered a cavalry charge and the troops charged with drawn sabers; the Cheyenne fled. With tired horses after long marches, the cavalry could not engage more than a few Cheyenne, as their horses were fresh.\nThis was the first battle that the Cheyenne fought against the US Army. Casualties were few on each side; J.E.B. Stuart, then a young lieutenant, was shot in the breast while attacking a Cheyenne warrior with a sabre. The troops continued on and two days later burned a hastily abandoned Cheyenne camp; they destroyed lodges and the winter supply of buffalo meat.\nSumner continued to Bent's Fort. To punish the Cheyenne, he distributed their annuities to the Arapaho. He intended further punitive actions, but the Army ordered him to Utah because of an outbreak of trouble with the Mormons (this would be known as the Utah War). The Cheyenne moved below the Arkansas into Kiowa and Comanche country. In the fall, the Northern Cheyenne returned to their country north of the Platte.\nPike's Peak Gold Rush.\nStarting in 1859 with the Colorado Gold Rush, European-American settlers moved into lands reserved for the Cheyenne and other Plains Indians. Travel greatly increased along the Emigrant Trail along the South Platte River and some emigrants stopped before going on to California. For several years there was peace between settlers and Indians. The only conflicts were related to the endemic warfare between the Cheyenne and Arapaho of the plains and the Utes of the mountains.\nUS negotiations with Black Kettle and other Cheyenne favoring peace resulted in the Treaty of Fort Wise: it established a small reservation for the Cheyenne in southeastern Colorado in exchange for the territory agreed to in the Fort Laramie Treaty of 1851. Many Cheyenne did not sign the treaty, and they continued to live and hunt on their traditional grounds in the Smoky Hill and Republican basins, between the Arkansas and the South Platte, where there were plentiful buffalo.\nEfforts to make a wider peace continued, but in the spring of 1864, John Evans, governor of Colorado Territory, and John Chivington, commander of the Colorado Volunteers, a citizens militia, began a series of attacks on Indians camping or hunting on the plains. They killed any Indian on sight and initiated the Colorado War. General warfare broke out and Indians made many raids on the trail along the South Platte, which Denver depended on for supplies. The Army closed the road from August 15 until September 24, 1864.\nSand Creek Massacre.\nOn November 29, 1864, the Colorado Militia attacked a Cheyenne and Arapaho encampment under Chief Black Kettle, although it flew a flag of truce and indicated its allegiance to the US government. The Sand Creek massacre, as it came to be known, resulted in the death of between 150 and 200 Cheyenne, mostly unarmed women and children. The survivors fled northeast and joined the camps of the Cheyenne on the Smoky Hill and Republican rivers. There warriors smoked the war pipe, passing it from camp to camp among the Sioux, Cheyenne and Arapaho.\nIn January 1865, they planned and carried out a retaliatory attack with about 1000 warriors on Camp Rankin, a stage station and fort at Julesburg. The Indians made numerous raids along the South Platte, both east and west of Julesburg, and raided the fort again in early February. They captured much loot and killed many European Americans. Most of the Indians moved north into Nebraska on their way to the Black Hills and the Powder River. (See Battle of Julesburg, Battle of Mud Springs, Battle of Rush Creek, Powder River Expedition, Battle of Platte Bridge)\nBlack Kettle continued to desire peace and did not join in the second raid or in the plan to go north to the Powder River country. He left the large camp and returned with 80 lodges of his tribesmen to the Arkansas River, where he intended to seek peace with the US.\nBattle of Washita River.\nFour years later, on November 27, 1868, George Armstrong Custer and his troops attacked Black Kettle's band at the Battle of Washita River. Although his band was camped on a defined reservation, complying with the government's orders, some of its members had been linked to raiding into Kansas by bands operating out of the Indian Territory. Custer claimed 103 Cheyenne \"warriors\" and an unspecified number of women and children killed whereas different Cheyenne informants named between 11 and 18 men (mostly 10 Cheyenne, 2 Arapaho, 1 Mexican trader) and between 17 and 25 women and children killed in the village.\nThere are conflicting claims as to whether the band was hostile or friendly. Historians believe that Chief Black Kettle, head of the band, was not part of the war party but the peace party within the Cheyenne nation. But, he did not command absolute authority over members of his band and the European Americans did not understand this. When younger members of the band took part in raiding parties, European Americans blamed the entire band for the incidents and casualties.\nBattle of the Little Bighorn.\nThe Northern Cheyenne fought in the Battle of the Little Bighorn, which took place on June 25, 1876. The Cheyenne, together with the Lakota, other Sioux warriors and a small band of Arapaho, killed General George Armstrong Custer and much of his 7th Cavalry contingent of soldiers. Historians have estimated that the population of the Cheyenne, Lakota and Arapaho encampment along the Little Bighorn River was approximately 10,000, making it one of the largest gatherings of Native Americans in North America in pre-reservation times. News of the event traveled across the United States and reached Washington, D.C., just as the nation was celebrating its Centennial. Public reaction arose in outrage against the Cheyenne.\nNorthern Cheyenne Exodus.\nFollowing the Battle of the Little Bighorn, the US Army increased attempts to capture the Cheyenne. In 1879, after the Dull Knife Fight, when Crazy Horse surrendered at Fort Robinson, a few Cheyenne chiefs and their people surrendered as well. They were Morning Star (aka Dull Knife), Standing Elk and Wild Hog with around 130 Cheyenne. Later that year Two Moons surrendered at Fort Keogh, with 300 Cheyenne. The Cheyenne wanted and expected to live on the reservation with the Sioux in accordance to an April 29, 1868 treaty of Fort Laramie, which both Dull Knife and Little Wolf had signed.\nAs part of a US increase in troops following the Battle of the Little Bighorn, the Army reassigned Colonel Ranald S. Mackenzie and his Fourth Cavalry to the Department of the Platte. Stationed initially at Camp Robinson, they formed the core of the Powder River Expedition. It departed in October 1876 to locate the northern Cheyenne villages. On November 25, 1876, his column discovered and defeated a village of Northern Cheyenne in the Dull Knife Fight in Wyoming Territory. After the soldiers destroyed the lodges and supplies and confiscated the horses, the Northern Cheyenne soon surrendered. They hoped to remain with the Sioux in the north but the US pressured them to locate with the Southern Cheyenne on their reservation in Indian Territory. After a difficult council, the Northern Cheyenne eventually agreed to go South.\nWhen the Northern Cheyenne arrived at Indian Territory, conditions were very difficult: rations were inadequate, there were no buffalo near the reservation and, according to several sources, there was malaria among the people. On 9 September 1878, a portion of the Northern Cheyenne, led by Little Wolf and Dull Knife started their trek back to the north. After fighting battles with the U.S. army at Turkey Springs and Punished Woman's Fork and reaching the northern area, they split into two bands. That led by Dull Knife (mostly women, children and elders) surrendered and were taken to Fort Robinson, where subsequent events became known as the Fort Robinson tragedy. Dull Knife's group was first offered food and firewood and then, after a week and a half, they were told to go back to Indian territory. When they said no, they were then locked in the wooden barracks with no food, water or firewood for heat for four days. Most escaped in an estimated forty degrees below zero on January 9, 1879, but all were recaptured or killed.\nEventually the US forced the Northern Cheyenne onto a reservation, in southern Montana.\nNorthern Cheyenne Indian Reservation.\nThe Cheyenne who traveled to Fort Keogh (present-day Miles City, Montana), including Little Wolf, settled near the fort. Many of the Cheyenne worked with the army as scouts. The Cheyenne scouts were pivotal in helping the Army find Chief Joseph and his band of Nez Perc\u00e9 in northern Montana. Fort Keogh became a staging and gathering point for the Northern Cheyenne. Many families began to migrate south to the Tongue River watershed area, where they established homesteads.\nThe US established the Tongue River Indian Reservation, now named the Northern Cheyenne Indian Reservation, of by the executive order of President Chester A. Arthur November 16, 1884. It excluded Cheyenne who had homesteaded further east near the Tongue River. The western boundary is the Crow Indian Reservation. On March 19, 1900, President William McKinley extended the reservation to the west bank of the Tongue River, making a total of . Those who had homesteaded east of the Tongue River were relocated to the west of the river.\nThe Northern Cheyenne, who were sharing the Lakota land at Pine Ridge Indian Reservation were finally allowed to return to the Tongue River on their own reservation. Along with the Lakota and Apache, the Cheyenne were the last nations to be overpowered and forced on reservations. (The Seminole tribe of Florida never made a treaty with the US government.)\nThe Northern Cheyenne were given the right to remain in the north, near the Black Hills, land which they consider sacred. The Cheyenne also managed to retain their culture, religion and language. Today, the Northern Cheyenne Nation is one of the few American Indian nations to have control over the majority of its land base, currently 98%.\nCulture.\nOver the past 400 years, the Cheyenne have changed their lifestyles. In the 16th century, they lived in the regions near the Great Lakes. They farmed corn, squash, and beans, and harvested wild rice like other indigenous peoples of the Northeastern Woodlands. They migrated west in the 18th century and hunted bison on the Great Plains. By the mid-19th century, the US forced them onto reservations.\nThe traditional Cheyenne government system is a politically unified system. The central traditional government system of the Cheyenne is the Arrow Keeper, followed by the Council of Forty-Four. Early in Cheyenne history, three related tribes, known as the \"Heviqsnipahis\", the \"S\u00f3'taeo'o\" and the \"Masikota\", unified themselves to form the \"Ts\u00e9ts\u0117h\u00e9st\u0227hese\" or the \"Like Hearted People\" who are known today as the \"Cheyenne\". The unified tribe then divided themselves into ten principal bands:\nEach of the ten bands had four seated chief delegates; the remaining four chiefs were the principal advisers of the other delegates. Smaller bands or sub-bands had no right to send delegates to the council. This system also regulated the Cheyenne military societies that developed for planning warfare, enforcing rules, and conducting ceremonies.\nAnthropologists debate about Cheyenne societal organization. On the plains, it appears that they had a bilateral band kinship system. However, some anthropologists reported that the Cheyenne had a matrilineal band system. Studies into whether, and if so, how much the Cheyenne developed a matrilineal clan system are continuing.\nHorse culture on the Great Plains.\nWhile they participated in nomadic Plains horse culture, men hunted and occasionally fought with and raided other tribes. The women tanned and dressed hides for clothing, shelter, and other uses. They also gathered roots, berries, and other useful plants. From the products of hunting and gathering, the women also made lodges, clothing, and other equipment. Their lives were active and physically demanding. The Cheyenne held territory in and near the Black Hills, but later all the Great Plains from Dakota to the Arkansas River.\nRole models.\nA Cheyenne woman has a higher status if she is part of an extended family with distinguished ancestors. Also, if she is friendly and compatible with her female relatives and does not have members in her extended family who are alcoholics or otherwise in disrepute. It is expected of all Cheyenne women to be hardworking, chaste, modest, skilled in traditional crafts, knowledgeable about Cheyenne culture and history and speak Cheyenne fluently. Tribal powwow princesses are expected to have these characteristics.\nEthnobotany.\nAn infusion of the pulverized leaves and blossoms of tansy is used for dizziness and weakness. They give dried leaves of \"Sagittaria cuneata\" to horses for urinary troubles and for a sore mouth.\nHistorical Cheyenne Figures.\n\"Please list 20th and 21st-century Cheyenne people under their specific tribes, Cheyenne and Arapaho Tribes and Northern Cheyenne Tribe of the Northern Cheyenne Indian Reservation.\"\nLiving Cheyenne Figures.\nThis is reserved for notable figures of the Cheyenne people, this includes Northern and Southern Cheyenne peoples. Please communicate within the talk section to add or remove notable tribal figures.\nPopulation history.\nIndian agent Thomas S. Twiss in Indian Affairs 1856 estimated the Cheyenne at 2,000 warriors (therefore around 10,000 people) and 1,000 lodges. Indian Affairs 1875 reported them as 4,228 people. Indian Affairs 1900 counted 3,446 (2,037 Southern Cheyenne in Oklahoma and 1,409 Northern Cheyenne in Montana and South Dakota). The 1910 census counted 3,055. In 1921 they numbered 3,281.\nCheyenne population has rebounded in the 20th and 21st centuries. The U.S. census of 2020 counted 22,979.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56129", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=56129", "title": "Noetherian ring", "text": "Mathematical ring with well-behaved ideals\nIn mathematics, a Noetherian ring is a ring that satisfies the ascending chain condition on left and right ideals. If the chain condition is satisfied only for left ideals or for right ideals, then the ring is said left-Noetherian or right-Noetherian respectively. Formally, every increasing sequence formula_1 of left (or right) ideals has a largest element; that is, there exists an formula_2 such that\nformula_3\nEquivalently, a ring is left-Noetherian (respectively right-Noetherian) if every left ideal (respectively right-ideal) is finitely generated. A ring is Noetherian if it is both left- and right-Noetherian.\nNoetherian rings are fundamental in both commutative and noncommutative ring theory since many rings that are encountered in mathematics are Noetherian (in particular the ring of integers, polynomial rings, and rings of algebraic integers in number fields), and many general theorems on rings rely heavily on the Noetherian property (for example, the Lasker\u2013Noether theorem and the Krull intersection theorem).\nNoetherian rings are named after Emmy Noether, but the importance of the concept was recognized earlier by David Hilbert, with the proof of Hilbert's basis theorem (which asserts that polynomial rings are Noetherian) and Hilbert's syzygy theorem.\nCharacterizations.\nFor noncommutative rings, it is necessary to distinguish between three very similar concepts:\nFor commutative rings, all three concepts coincide, but in general they are different. There are rings that are left-Noetherian and not right-Noetherian, and vice versa.\nThere are other, equivalent, definitions for a ring \"R\" to be left-Noetherian:\nSimilar results hold for right-Noetherian rings.\nThe following condition is also an equivalent condition for a ring \"R\" to be left-Noetherian and it is Hilbert's original formulation:\nFor a commutative ring to be Noetherian it suffices that every prime ideal of the ring is finitely generated. However, it is not enough to ask that all the maximal ideals are finitely generated, as there is a non-Noetherian local ring whose maximal ideal is principal (see a counterexample to Krull's intersection theorem at Local ring#Commutative case.)\nExamples.\nRings that are not Noetherian tend to be (in some sense) very large. Here are some examples of non-Noetherian rings:\nHowever, a non-Noetherian ring can be a subring of a Noetherian ring. Since any integral domain is a subring of a field, any integral domain that is not Noetherian provides an example. To give a less trivial example, \nIndeed, there are rings that are right Noetherian, but not left Noetherian, so that one must be careful in measuring the \"size\" of a ring this way. For example, if \"L\" is a subgroup of Q2 isomorphic to Z, let \"R\" be the ring of homomorphisms \"f\" from Q2 to itself satisfying \"f\"(\"L\") \u2282 \"L\". Choosing a basis, we can describe the same ring \"R\" as\nformula_15\nThis ring is right Noetherian, but not left Noetherian; the subset \"I\" \u2282 \"R\" consisting of elements with \"a\" = 0 and \"\u03b3\" = 0 is a left ideal that is not finitely generated as a left \"R\"-module.\nIf \"R\" is a commutative subring of a left Noetherian ring \"S\", and \"S\" is finitely generated as a left \"R\"-module, then \"R\" is Noetherian. (In the special case when \"S\" is commutative, this is known as Eakin's theorem.) However, this is not true if \"R\" is not commutative: the ring \"R\" of the previous paragraph is a subring of the left Noetherian ring \"S\" = Hom(Q2, Q2), and \"S\" is finitely generated as a left \"R\"-module, but \"R\" is not left Noetherian.\nA unique factorization domain is not necessarily a Noetherian ring. It does satisfy a weaker condition: the ascending chain condition on principal ideals. A ring of polynomials in infinitely-many variables is an example of a non-Noetherian unique factorization domain.\nA valuation ring is not Noetherian unless it is a principal ideal domain. It gives an example of a ring that arises naturally in algebraic geometry but is not Noetherian.\nNoetherian group rings.\nConsider the group ring formula_16 of a group formula_17 over a ring formula_18. It is a ring, and an associative algebra over formula_18 if formula_18 is commutative. For a group formula_17 and a commutative ring formula_18, the following two conditions are equivalent.\nThis is because there is a bijection between the left and right ideals of the group ring in this case, via the formula_18-associative algebra homomorphism\nformula_26\nformula_27\nLet formula_17 be a group and formula_18 a ring. If formula_16 is left/right/two-sided Noetherian, then formula_18 is left/right/two-sided Noetherian and formula_17 is a Noetherian group. Conversely, if formula_18 is a Noetherian commutative ring and formula_17 is an extension of a Noetherian solvable group (i.e. a polycyclic group) by a finite group, then formula_16 is two-sided Noetherian. On the other hand, however, there is a Noetherian group formula_17 whose group ring over any Noetherian commutative ring is not two-sided Noetherian.\nKey theorems.\nMany important theorems in ring theory (especially the theory of commutative rings) rely on the assumptions that the rings are Noetherian.\nImplication on injective modules.\nGiven a ring, there is a close connection between the behaviors of injective modules over the ring and whether the ring is a Noetherian ring or not. Namely, given a ring \"R\", the following are equivalent:\nThe endomorphism ring of an indecomposable injective module is local and thus Azumaya's theorem says that, over a left Noetherian ring, each indecomposable decomposition of an injective module is equivalent to one another (a variant of the Krull\u2013Schmidt theorem).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56130", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=56130", "title": "Artinian", "text": "Artinian may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "56133", "revid": "50666884", "url": "https://en.wikipedia.org/wiki?curid=56133", "title": "Battle Angel Alita", "text": "Japanese cyberpunk manga series and its adaptations\nBattle Angel Alita, known in Japan as , is a Japanese cyberpunk manga series created by Yukito Kishiro and originally published in Shueisha's \"Business Jump\" magazine from 1990 to 1995. The second of the comic's nine volumes were adapted in 1993 into a two-part anime original video animation titled \"Battle Angel\" for North American release by ADV Films and the UK and Australian release by Manga Entertainment. Manga Entertainment also handled English dubbing duties for \"Battle Angel Alita\". A live-action film adaptation released by 20th Century Fox, titled \"\", premiered on February 14, 2019.\nThe series is set in the post-apocalyptic future and focuses on Alita (\"Gally\" in the Japanese version, and several other countries), a female cyborg who has lost all memories and is found in a junkyard by a cybernetics doctor who rebuilds and takes care of her. She discovers that there is one thing she remembers, the legendary cyborg martial art Panzer Kunst, which leads to her becoming a Hunter Warrior, or bounty hunter. The story traces Alita's attempts to rediscover her past and the characters whose lives she impacts on her journey. The manga series continued with ' and '.\nPlot.\n\"Battle Angel Alita\" tells the story of Alita, an amnesiac female cyborg. Her intact head and chest, in suspended animation, are found by cyber medic expert Daisuke Ido in the local garbage dump. Ido manages to revive her, and finding she has lost her memory, names her Alita after his recently deceased cat. The rebuilt Alita soon discovers that she instinctively remembers the legendary martial art, Panzer Kunst, although she does not recall anything else. Alita uses her Panzer Kunst to first become a bounty hunter, killing cyborg criminals in the Scrapyard, and then as a star player in the brutal gladiator sport of Motorball. While in combat, Alita awakens memories of her earlier life on Mars. She becomes involved with the floating city of Zalem (Tiphares in some older translations) as one of their agents and is sent to hunt down criminals. Foremost is the mad genius Desty Nova, who has a complex, ever-changing relationship with Alita.\nThe futuristic dystopian world of \"Battle Angel Alita\" revolves around the city of Scrapyard (Kuzutetsu in the Japanese and various other versions), which has grown up around a massive scrap heap that rains down from Zalem. Ground dwellers have no access to Zalem and are forced to make a living in the sprawl below. Many are heavily modified by cybernetics to better cope with their hard life.\nZalem exploits the Scrapyard and surrounding farms, paying bounty hunters (called Hunter-Warriors) to hunt criminals and arranging violent sports to keep the population entertained. Massive tubes connect the Scrapyard to Zalem, and the city uses robots for carrying out errands and providing security on the ground. Occasionally, Zalemites (such as Daisuke Ido and Desty Nova) are exiled and sent to the ground. Aside from the robots and exiles, there is little contact between the two cities.\nThe story takes place in the former United States. According to a map, printed in the eighth volume, Scrapyard/Zalem is near Kansas City, Missouri, and the Necropolis is Colorado Springs, Colorado. Radio KAOS is at Dallas, Texas. Figure's coastal hometown is Alhambra, California. Desty Nova's Granite Inn is built out of a military base\u2014NORAD at Cheyenne Mountain Complex, Colorado.\n\"Battle Angel Alita\" is eventually revealed to take place in the 26th century. The sequel \"Battle Angel Alita: Last Order\" introduces a calendar era called \"Era Sputnik\" which has an epoch of AD 1957. The original \"Battle Angel Alita\" series begins in ES 577 (AD 2533) and ends in ES 590 (AD 2546), \"Battle Angel Alita: Last Order\" is mostly set roughly in ES 591 (AD 2547), and \"Battle Angel Alita: Mars Chronicle\" alternates between ES 373\u2013374 (AD 2329\u20132330) and ES 594 (AD 2550).\nCharacters.\n\"Battle Angel Alita\" features a diverse cast of characters, many of whom shift in and out of focus as the story progresses. Some are never to be seen again following the conclusion of a story arc, while others make recurring appearances. The one character who remains a constant throughout is Alita, the protagonist and title character, a young cyborg with amnesia struggling to uncover her forgotten past through the only thing she remembers from it: by fighting. Early on in the story, Daisuke Ido, a bounty-hunting cybernetic doctor who finds and revives Alita, plays a major role as well, but midway the focus begins to increasingly shift to Desty Nova, an eccentric nanotechnology scientist who has fled from Zalem. Desty Nova is the mastermind behind many of the enemies and trials that Alita faces, but does not make an actual appearance until more than two years into the story, although he is alluded to early on. Finally, Kaos, Desty Nova's son, a frail and troubled radio DJ with psychometric powers, also begins to play a crucial role after he comes in contact with Alita. He broadcasts his popular radio show from the wastelands outside the Scrapyard, staying away from the increasing conflict between Zalem and the rebel army Barjack.\nProduction.\nAlita was originally a female cyborg police officer named Gally in an unpublished comic called \"Rainmaker\". Publishers at Shueisha liked her and asked Kishiro to make a new story with her as the main character. After he had come up with the plot for a storyline he was commissioned to make it a long-running series.\nBesides renaming \"Gally\" to \"Alita\", older North American versions of the manga also changed the city of \"Zalem\" (from Biblical Hebrew \u05e9\u05b8\u05c1\u05dc\u05b5\u05dd \"\u0161\u0101l\u0113m\", \"peace\") to \"Tiphares\" (after \"Tiferet\"). Since Kishiro also used the name \"Jeru\" (after \"Jerusalem\") for the facility atop \"Zalem\", \"Jeru\" was renamed \"Ketheres\" in the translation (after \"Keter\"). More recent versions reverted the cities' names back to Zalem and Jeru. To further develop the Biblical theme in the original series, \"Zalem\"'s main computer was named \"Melchizedek\", \"the king of Salem\" and \"priest to the Most High God\".\nMedia.\nManga.\nThe manga was first published in Shueisha's \"Business Jump\" magazine. It was then serialized from 1990 to 1995 in nine . Yukito Kishiro moved from Shueisha to Kodansha in August 2010. The company acquired the license rights to \"Battle Angel Alita\". A 6-volume special edition titled \"Gunnm: Complete Edition\" was released in Japan from December 18, 1998 to August 18, 2000. The series was released in B5 format and contains the original story, but without the original ending, which was retconned later in 2000 by \"\". Also included are rough sketches, a timeline and the first three \"Battle Angel Alita: Holy Night &amp; Other Stories\" short stories. From October 5 to November 16, 2016, Kodansha republished \"Gunnm\" in three volumes in B5 format. It was later reprinted in A5 format in five volumes from November 21, 2018, to February 22, 2019.\nA spin-off series titled was published in \"Ultra Jump\" from September 1995 to July 1996 issues. It was released in a single volume on June 24, 1998.\nA spin-off series titled was published in \"Ultra Jump\" from January 24, 1997, to December 19, 2006. It was released in a single volume on December 19, 2007. It is composed of four short side stories: \"Holy Night\", \"Sonic Finger\", \"Hometown\" and \"Barjack Rhapsody\".\nIn North America, Viz Media originally released the story in a 25-page comic book, after which it followed the same volume format as its Japanese counterpart. Viz also released the \"Ashen Victor\" spin-off series. Along with the rest of the series, Kishiro's original \"Battle Angel Alita\" manga has been licensed for North American publication through Kodansha USA, who republished it the five-volume omnibus format in 2017 and 2018, with the last volume including \"Ashen Victor\". \"Holy Night &amp; Other Stories\" has also been licensed by Kodansha USA, who published it digitally on October 30, 2018, and as hardcover on November 20. \"Battle Angel Alita\" has also been licensed for international release in a number of languages and regions. It was published in Spain by Planeta DeAgostini, in Brazil by Editora JBC, in France and Netherlands by Glenat, in Poland by JPF, in Germany by Carlsen, in Taiwan by Tong Li Publishing, in Argentina by Editorial Ivrea and in Russia by Xl Media.\nOVA.\nA two-episode original video animation (OVA) was released in 1993, incorporating elements from the second volume of the manga with changes to the characters and storyline. According to Kishiro, only two episodes were originally planned. At the time, he was too busy with the manga \"to review the plan coolly\" and was not serious about an anime adaptation. It remains the only anime adaptation of \"Battle Angel Alita\" to date and there are no plans to revive it.\nA 3-minute 3D-CGI rendered movie clip is included in volume 6 of the Japanese \"Gunnm: Complete Edition\" (1998\u20132000). It showcases Alita in a Third League Motorball race with players from two of her races such as \"Armor\" Togo, Degchalev, and Valdicci, and depicts events from both of those races.\nFilm.\nIn 2010, 20th Century Fox and director James Cameron acquired the film rights to \"Battle Angel\". It was originally brought to Cameron's attention by filmmaker Guillermo del Toro. Cameron is said to be a big fan of the manga, and he was waiting until CGI technology was sufficiently advanced to make a live-action 3D film with effects comparable to \"Avatar\". The film would be a live-action adaptation of the first four volumes of the manga series; \"What I\u2019m going to do is take the spine story and use elements from the first four books. So, the Motorball from books three and four, and parts of the story of one and two will all be in the movie.\"\n\"Alita\" was originally scheduled to be his next production after the TV series \"Dark Angel\", which was influenced by \"Battle Angel Alita\". After \"Avatar\", he stated he would work on \"Avatar\" sequels before starting \"Alita\".\nCameron's producer Jon Landau said, \"I am sure you will get to see \"Battle Angel\". It is one of my favourite stories, a great story about a young woman's journey to self-discovery. It is a film that asks the question: What does it mean to be human? Are you human if you have a heart, a brain or a soul? I look forward to giving the audience the film.\" Landau half-jokingly stated that the project may be titled \"Alita: The Battle Angel\", because of Cameron's tradition in naming his films with either an \"A\" or a \"T\".\nIn October 2015, it was reported that Robert Rodriguez would direct the film with Cameron and Landau producing. On April 26, 2016, both \"The Hollywood Reporter\" and \"Variety\" reported that Maika Monroe, Rosa Salazar, Zendaya and Bella Thorne were in the running for the lead role. Near the end of May 2016, Salazar was cast as Alita, and on February 7, 2017, \"The Hollywood Reporter\" reported that Jennifer Connelly would be joining the cast as one of the villains.\nOn December 8, 2017, the first trailer for \"Battle Angel\" was released to the public, and the film, titled \"\" and directed by Robert Rodriguez, premiered on February 14, 2019.\nNovels.\nA novelization of the manga by Yasuhisa Kawamura was released on April 4, 1997, by Shueisha's JUMP j-BOOKS label.\nIn November 2018, Titan Books published \"Alita: Battle Angel\u2014Iron City\", a prequel novel for the film. The novel was written by Pat Cadigan, a notable science fiction author.\nVideo game.\n' is an action RPG video game for the PlayStation by Banpresto. It is an adaptation of the manga, following Alita (Gally) from her discovery in the Zalem dump heap by Daisuke Ido up through and beyond her career as a TUNED agent. The story includes additional elements that Kishiro had conceived when he ended the original manga in 1995, but was unable to implement at the time, which involved Alita going into outer space. He then expanded the story, which formed the basis for the manga '.\nReception.\nYukito Kishiro's fantasy world garnered widespread acclaim from critics. \"Manga Life\" reviewer Adam Volk described the universe as intricately crafted and deeply engaging, noting that the first volume alone demonstrated Kishiro's mastery of the genre. He highlighted the manga's balance of dynamic action and well-developed, independent characters\u2014a rarity in comics, films, and television\u2014ultimately declaring it a classic tale of life's struggles.\nPatrick King of \"Animefringe\" lauded the grandeur of Kishiro's creation, portraying it as a vivid, unsettling, and eerily plausible vision of humanity's future. He observed that the manga explored themes of human nature and authenticity, distinguishing it from Kishiro's more fantastical Aqua Knight with its grounded realism. While acknowledging the series' graphic violence as unsuitable for younger audiences, King argued that it reinforced the protagonist's motivations.\nRaphael See of THEM Anime Reviews regarded it as one of the finest cyborg-themed anime, praising its seamless integration of cybernetics into the worldbuilding without overshadowing the narrative. While he found the series lacking in innovation, its consistent quality left a strong impression. His sole criticism was its abrupt ending, which suggested a broader, unexplored storyline.\nTheron Martin of Anime News Network commended Kishiro's meticulous worldbuilding and enduring artistic prowess, emphasizing the clarity of the action sequences. JapanVisitor.com noted the influence of Philip K. Dick (\"Do Androids Dream of Electric Sheep?\") and Isaac Asimov (\"I, Robot\") on Kishiro's work.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56134", "revid": "31192532", "url": "https://en.wikipedia.org/wiki?curid=56134", "title": "List of U.S. state songs", "text": "Overview of U.S. regional anthems\nForty-eight of the fifty states in the United States have one or more state songs, a type of regional anthem, which are selected by each state legislature as a symbol (or emblem) of that particular state. Well-known state songs include \"Yankee Doodle\", \"You Are My Sunshine\", \"Rocky Top\", and \"Home on the Range\". A number of others are popular standards, including \"Oklahoma\" (from the Rodgers and Hammerstein musical of the same name), Hoagy Carmichael's \"Georgia on My Mind\", \"Tennessee Waltz\", \"Missouri Waltz\", and \"On the Banks of the Wabash, Far Away\". Many of the others are much less well-known, especially outside the state.\nSome U.S. states have more than one official state song, and may refer to some of their official songs by other names; for example, Arkansas officially has two state songs, plus a state anthem and a state historical song. Tennessee has the most official state songs, with 14 (including an official bicentennial rap).\nTwo individuals, Stephen Foster and John Denver, have written or co-written state songs for two different states. Foster wrote the music and lyrics for \"My Old Kentucky Home\", adopted by Kentucky in 1928, and \"Old Folks at Home\" (better known as \"Swanee Ribber\" or \"Suwannee River\"), adopted by Florida in 1935. John Denver wrote the lyrics and co-wrote the music for \"Rocky Mountain High\", adopted by Colorado in 2007 as one of the state's two official state songs, and co-wrote both lyrics and music for \"Take Me Home, Country Roads\", adopted by West Virginia in 2014 as one of four official state songs. Additionally, Woody Guthrie wrote or co-wrote two state \"folk songs\" \u2013 \"Roll On, Columbia, Roll On\" (Washington) and \"Oklahoma Hills\" (Oklahoma) \u2013 but they have separate status from the official state \"songs\" of both states.\nNew Mexico has two state songs in Spanish: \"As\u00ed Es Nuevo M\u00e9xico\" is the official Spanish state song, while \"New Mexico - Mi Lindo Nuevo Mexico\" is the state bilingual song.\nIowa's \"The Song of Iowa\" uses the tune from the song \"O Tannenbaum\" as its melody. The same tune is used for \"Maryland, My Maryland\" which was Maryland's state song from 1939 to 2021.\nArizona has a song that was written specifically as a state anthem in 1915, as well as the 1981 country hit \"Arizona\", which it adopted as the alternate state anthem in 1982.\nAbsences and removals.\nNew Jersey has never adopted a state song. A resolution to declare the song \"Born to Run\" by Bruce Springsteen as the state song passed the Assembly, but failed in the state Senate as the song's lyrics depict a desire to leave New Jersey.\nOklahoma's state \"rock song\" from 2009 to 2011 was \"Do You Realize??\" by The Flaming Lips, but the state legislature vote was not ratified. The move might have purportedly been due to offensive lyrics and a band member wearing of communist symbols on a shirt.\nMaryland had a state song until 2021. \"Maryland, My Maryland\" was removed due to pro-Confederate language, but no replacement was established.\nVirginia's previous state song, \"Carry Me Back to Old Virginny\", adopted in 1940, was rescinded in 1997 due to language deemed racist by the Virginia General Assembly. In 2015, \"Our Great Virginia\" was made the new state song of Virginia.\nIn 2021, Louisiana made \"You Are My Sunshine\" their only official state song by removing the less-popular \"Give Me Louisiana\". \"You Are My Sunshine\" is so beloved by Louisiana residents that many of them, including state legislators, were unaware that a second official song existed prior to the proposed removal. \"Southern Nights\" was added at the same time as the removal, but given a new designation as a state cultural song.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56135", "revid": "43744280", "url": "https://en.wikipedia.org/wiki?curid=56135", "title": "Touchstone (assaying tool)", "text": "Small tablet of dark stone used for assaying precious metal alloys\nA touchstone is a small tablet of dark stone such as slate or lydite, used for assaying precious metal alloys. It has a finely grained surface on which soft metals leave a visible trace. Basic requirements for a touchstone: hardness on the mineralogical scale 4.6-6.5, the touchstone must be free of cracks and not react with inorganic acids and their mixtures.\nHistory.\nThe touchstone was used during the Harappa period of the Indus Valley civilization ca. 2600\u20131900 BC for testing the purity of soft metals. It was also used in Ancient Greece.\nThe touchstone allowed anyone to easily and quickly determine the purity of a metal sample. This, in turn, led to the widespread adoption of gold as a standard of exchange. Although mixing gold with less expensive materials was common in coinage, using a touchstone one could easily determine the quantity of gold in the coin, and thereby calculate its intrinsic worth.\nOperation.\nDrawing a line with gold on a touchstone will leave a visible trace. Because different alloys of gold have different colors (see gold), the unknown sample can be compared to samples of known purity. This method has been used since ancient times. In modern times, additional tests can be done. The trace will react in different ways to specific concentrations of nitric acid or aqua regia, thereby identifying the quality of the gold: 24 karat gold is not affected but 14 karat gold will show chemical activity.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56136", "revid": "1293398511", "url": "https://en.wikipedia.org/wiki?curid=56136", "title": "Yukito Kishiro", "text": "Japanese manga artist\n is a Japanese manga artist born in Tokyo in 1967 and raised in Chiba. As a teenager he was influenced by the mecha anime \"Armored Trooper Votoms\" and \"Mobile Suit Gundam\", in particular the designs of Yoshikazu Yasuhiko, as well as the works of manga artist Rumiko Takahashi. He began his career at age 17, with his debut manga, \"Space Oddity\", in the \"Weekly Shonen Sunday\". He is best known for the cyberpunk series \"Battle Angel Alita\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56139", "revid": "48838494", "url": "https://en.wikipedia.org/wiki?curid=56139", "title": "Butanol", "text": "Chemical compound family ( C4H9OH)\nButanol (also called butyl alcohol) is a four-carbon alcohol with a formula of C4H9OH, which occurs in five isomeric structures (four structural isomers), from a straight-chain primary alcohol to a branched-chain tertiary alcohol; all are a butyl or isobutyl group linked to a hydroxyl group (sometimes represented as BuOH, sec\"-BuOH, i-BuOH, and t\"-BuOH). These are 1-butanol, two stereoisomers of \"sec\"-butyl alcohol, isobutanol and \"tert\"-butyl alcohol. Butanol is primarily used as a solvent and as an intermediate in chemical synthesis, and may be used as a fuel. Biologically produced butanol is called biobutanol, which may be \"n\"-butanol or isobutanol.\nIsomers.\nThe unmodified term \"butanol\" usually refers to the straight chain isomer with the alcohol functional group at the terminal carbon, which is also known as 1-butanol. The straight chain isomer with the alcohol at an internal carbon is \"sec\"-butyl alcohol or 2-butanol. The branched isomer with the alcohol at a terminal carbon is isobutanol or 2-methyl-1-propanol, and the branched isomer with the alcohol at the internal carbon is \"tert\"-butyl alcohol or 2-methyl-2-propanol.\nThe butanol isomers have different melting and boiling points. 1-Butanol and isobutanol have limited solubility, \"sec\"-butyl alcohol has substantially greater solubility, whereas \"tert\"-butyl alcohol is miscible with water. The hydroxyl group makes the molecule polar, promoting solubility in water, while the longer hydrocarbon chain mitigates the polarity and reduces solubility.\nToxicity.\nButanol exhibits a low order of toxicity in single dose experiments with laboratory animals and is considered safe enough for use in cosmetics. Brief, repeated overexposure with the skin can result in depression of the central nervous system, as with other short-chain alcohols. Exposure may also cause severe eye irritation and moderate skin irritation. The main dangers are from prolonged exposure to the alcohol's vapors. In extreme cases this includes suppression of the central nervous system and even death. Under most circumstances, butanol is quickly metabolized to carbon dioxide. It has not been shown to damage DNA or cause cancer.\nUses.\nPrimary uses.\nButanol is used as a solvent for a wide variety of chemical and textile processes, in organic synthesis, and as a chemical intermediate. It is also used as a paint thinner and a solvent in other coating applications where a relatively slow evaporating latent solvent is preferable, as with lacquers and ambient-cured enamels. It is also used as a component of hydraulic and brake fluids.\nA 50% solution of butanol in water has been used since the 20th century to retard the drying of fresh plaster in fresco painting. The solution is usually sprayed on the wet plaster after the plaster has been trowelled smooth and extends the working period during which frescos can be painted up to 18 hours.\nButanol is used in the synthesis of 2-butoxyethanol. A major application for butanol is as a reactant with acrylic acid to produce butyl acrylate, a primary ingredient of water based acrylic paint.\nIt is also used as a base for perfumes, but on its own has a highly alcoholic aroma.\nSalts of butanol are chemical intermediates; for example, alkali metal salts of \"tert\"-butanol are \"tert\"-butoxides.\nRecreational use.\n2-Methyl-2-butanol is a central nervous system depressant with a similar effect upon ingestion to ethanol. Case reports have been documented demonstrating its potential for abuse.\nBiobutanol.\nButanol (\"n\"-butanol or isobutanol) is a potential biofuel (butanol fuel). Butanol at 85 percent concentration can be used in cars designed for gasoline (petrol) without any change to the engine (unlike 85% ethanol), and it contains more energy for a given volume than ethanol and almost as much as gasoline, and a vehicle using butanol would return fuel consumption more comparable to gasoline than ethanol. Butanol can also be added to diesel fuel to reduce soot emissions. Photoautotrophic microorganisms, like cyanobacteria, can be engineered to produce 1-butanol indirectly from CO2 and water.\nProduction.\nButanols are normally present in fusel alcohol.\nSince the 1950s, most butanol in the United States is produced commercially from fossil fuels. The most common process starts with propene (propylene), which is put through a hydroformylation reaction to form butanal, which is then reduced with hydrogen to 1-butanol and/or 2-butanol. \"tert\"-butanol is derived from isobutane as a co-product of propylene oxide production.\nButanol can also be produced by fermentation of biomass by bacteria. Prior to the 1950s, \"Clostridium acetobutylicum\" was used in industrial fermentation to produce \"n\"-butanol.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56140", "revid": "50615137", "url": "https://en.wikipedia.org/wiki?curid=56140", "title": "History of Norway", "text": "The history of Norway has been influenced to an extraordinary degree by the terrain and the climate of the region. About 10,000 BC, following the retreat inland of the great ice sheets, the earliest inhabitants migrated north into the territory which is now Norway. They traveled steadily northwards along the coastal areas, warmed by the Gulf Stream. They were hunter-gatherers whose diet included seafood and game, particularly reindeer as staple foods. Between 5,000 BC and 4,000 BC the earliest agricultural settlements appeared around the Oslofjord. Gradually, between 1,500 BC and 500 BC, agricultural settlements spread to the entire south Norway, while the inhabitants of the regions north of Tr\u00f8ndelag continued to hunt and fish.\nThe Neolithic period started in 4,000 BC. The Migration Period caused the first chieftains to take control and hilltop forts to be constructed. From the 8th century Norwegians started expanding across the seas to the British Isles and later Iceland and Greenland. The Viking Age also saw the unification of the country. Christianization was completed during the 11th century and Nidaros became an archdiocese. The population expanded quickly until 1349 when it was halved by the Black Death and successive plagues. Bergen became the main trading port, controlled by the Hanseatic League. Norway entered the Kalmar Union with Denmark and Sweden in 1397.\nAfter Sweden left the union in 1523, Norway became the junior partner in Denmark\u2013Norway. The Reformation was introduced in 1537 and absolute monarchy imposed in 1661. In 1814, after being on the losing side of the Napoleonic Wars with Denmark, Norway was ceded to the king of Sweden by the Treaty of Kiel. Norway declared its independence and adopted a constitution. However, no foreign powers recognized the Norwegian independence but supported the Swedish demand for Norway to comply with the treaty of Kiel. After a short war with Sweden, the countries concluded the Convention of Moss, in which Norway accepted a personal union with Sweden, keeping its Constitution, Storting and separate institutions, except for the foreign service. The union was formally established after the extraordinary Storting adopted the necessary amendments to the Constitution and elected Charles XIII of Sweden as king of Norway on 4 November 1814.\nIndustrialization started in the 1840s, and from the 1860s large-scale emigration to North America took place. In 1884 the king appointed Johan Sverdrup as prime minister, thus establishing parliamentarism. The union with Sweden was dissolved in 1905. From the 1880s to the 1920s, Norwegians such as Fridtjof Nansen and Roald Amundsen carried out important polar expeditions.\nShipping and hydroelectricity were important sources of income for the country. The following decades saw a fluctuating economy and the rise of the labor movement. Germany occupied Norway between 1940 and 1945 during the Second World War, after which Norway joined NATO and underwent a period of reconstruction under public planning. Oil was discovered in 1969 and by 1995 Norway was the world's second-largest exporter. This resulted in a large increase of wealth. From the 1980s Norway started deregulation in many sectors, and in 1989\u20131990 experienced a banking crisis.\nBy the 21st century, Norway became one of the world's most prosperous countries with oil and gas production accounting for 20 percent of its economy. By reinvesting its oil revenues, Norway had the world's largest sovereign wealth fund in 2017.\nPrehistory.\nNorway's coastline rose from glaciation with the end of the last glacial period about 12,000 BC. The first immigration took place during this period as the Norwegian coast offered rich opportunities for sealing, fishing, and hunting. These early inhabitants were nomadic, and by 9300 BC they were already settled as far north as Mager\u00f8ya. Increased ice receding from 8000 BC led to settlement along the entire coastline. The Stone Age is evidenced by the Komsa culture in Troms and Finnmark and the Fosna culture further south. The N\u00f8stvet culture took over from the Fosna culture ca. 7000 BC, when a warmer climate led to increased forestation and new species of mammals for hunting. The oldest human skeleton ever discovered in Norway was found in shallow water off Sogne in 1994 and has been carbon dated to 6600 BC. About 4000 BC people in the north started using slate tools, earthenware, skis, sleds and large skin boats.\nThe first farming, and thus the start of the Neolithic period, began ca. 4000 BC around the Oslofjord, with technology from southern Scandinavia. The break-through occurred between 2900 and 2500 BC, when oats, barley, pigs, cattle, sheep and goats became common and spread as far north as Alta. This period also saw the arrival of the Corded Ware culture, which brought new weapons, tools and an Indo-European dialect, from which later the Norwegian language developed.\nNordic Bronze Age (1800\u2013500 BC).\nThe Bronze Age began around 1800 BC and involved innovations such as ploughing fields with ards, permanent farms with houses and yards, especially in the fertile areas around the Oslofjord, Trondheimsfjord, Mj\u00f8sa and J\u00e6ren. Some yields were so high that it allowed farmers to trade furs and skins for luxury items, especially with Jutland. About 1000 BC, speakers of Uralic languages arrived in the north and assimilated with the indigenous population, becoming the Sami people. According to Ante Aikio the formation of the S\u00e1mi language was completed in its southernmost area of usage (central Scandinavia, South S\u00e1pmi) by 500 AD.\nA climate shift with colder weather started about 500 BC. The forests, which had previously consisted of elm, lime, ash and oak, were replaced with birch, pine and spruce. The climate changes also meant that farmers started building more solid structures for shelter. Knowledge of ironworking was introduced from the Celts, resulting in better weapons and tools.\nNordic Iron Age (500 BC\u2013800 AD).\nIron Age tools allowed for more extensive clearing and farming, and thus more areas were cultivated as the population grew with the increased harvests. A new social structure evolved: when sons married, they would remain in the same house; such an extended family was a clan. They would offer protection from other clans; if conflicts arose, the issue would be decided at a \"thing\", a sacred place where all free men from the surrounding area would assemble and could settle disputes and determine sanctions for crimes, such as paying fines in food.\nThe last century BC saw a widespread cultural development. The Norse adapted letters and created their own alphabet, runes. Trading with Romans also took place, largely furs and skins in exchange for luxury goods. Some Scandinavians also served as Roman mercenaries. Some of the most powerful farmers became chieftains. They functioned as priests and accepted sacrifices from farmers which were again used to pay soldiers, creating a hird. Thus they were able to rule an area of several clans and tribes.\nThe chieftains' power increased during the Migration Period between 400 and 550 as other Germanic tribes migrated northwards and local farmers wanted protection. This also resulted in the construction of simple fortifications. A plague hit southern Norway in the 6th century, with hundreds of farms being depopulated. Most were repopulated in the 7th century, which also saw the construction of several fishing hamlets and a boom in trade of iron and soapstone across the North Sea. Some chieftains were able to control most of the trade and grew in power throughout the 8th century.\nArchaeological findings.\nIn February 2020, Secrets of the Ice Program researchers discovered a 1,500-year-old Viking arrowhead dating back to the Germanic Iron Age and locked in a glacier in southern Norway caused by the climate change in the Jotunheimen Mountains. The arrowhead made of iron was revealed with its cracked wooden shaft and a feather, is 17\u00a0cm long and weighs just 28 grams.\nViking Age.\nThe Viking Age was a period of Scandinavian expansion through trade, raids and colonization. One of the first raids was against Lindisfarne in 793 and is considered the beginning of the Viking Age. This was possible because of the development of the longship, suitable for travel across the sea, and advanced navigation techniques.\nVikings were well equipped, had chain mail armor, and were well trained. In addition to gold and silver, an important purpose from the raids was the capture and trading of thralls, which were brought to the Norwegian farms as a slave workforce. Whenever the men were engaged in warfare and voyages, the homestead was run by those remaining at home, supervised by the wife.\nThe lack of suitable farming land in Western Norway caused Norwegians to travel to and colonize sparsely populated areas of Shetland, Orkney, the Faroe Islands and the Hebrides, the latter of which became the Kingdom of the Isles. Norwegian Vikings settled on the east coast of Ireland circa 800 and founded the island's first cities, including Dublin. Their arrival caused the petty Gaelic kings to ally, and by 900 they had driven out the Norwegians.\nThe mid-9th century saw the largest chieftains of the petty kingdoms engaged in major power struggle. Harald Fairhair began the process of unifying Norway when he entered an alliance with the Earls of Lade and was able to unify the country after the decisive Battle of Hafrsfjord (circa 870\u2013900). He set up the basics of a state administration with stewards seated at the most important estates of vanquished or exiled chieftains.\nIceland, then uninhabited, was discovered by Norwegians during the late 9th century. By 930 the island had been divided among 400 Norse chieftains.\nH\u00e5kon the Good \u2013 the son of Harald Fairhair, raised in England \u2013 assumed the crown in 930 and established two large \"things\", assemblies in which the king met with the free men to make decisions: Gulating for Western Norway and Frostating for Tr\u00f8ndelag. He also established the leidang, a mobilization army/navy. Haakon made an unsuccessful attempt to introduce Christianity in Norway. After his death in 960, war broke out between the Fairhair dynasty and the Earls of Lade in alliance with Danish kings.\nLed by Erik the Red, a Norwegian-born man, a group of Icelanders settled on Greenland in the 980s. Erik's son, Leif Ericson, came across Newfoundland in ca. 1000, naming it Vinland. Unlike Greenland, no permanent settlement was established there.\nArchaeological findings.\nSeveral Viking ships in burial mounds have been found and placed in museums, including the Oseberg and Gokstad ships. In October 2018, Norwegian archaeologists headed by the archaeologist Lars Gustavsen announced the discovery of a buried 20 m long Gjellestad Viking ship in Halden Municipality. An ancient well-preserved Viking cemetery for more than 1000 years was discovered using ground-penetrating radar. Archaeologists also revealed at least seven other previously unknown burial mounds and the remnants of five longhouses with the help of the radar survey.\nMiddle Ages.\nChristianization and the abolition of the traditional paganism reflected in Norse mythology was first attempted by H\u00e5kon the Good, and later by Olav Tryggvason, but he was killed in the Battle of Svolder in 1000. Olav Haraldsson, starting in 1015, made the \"things\" pass church laws, destroyed heathen hofs, built churches and created an institution of priests. Many chieftains feared that Christianization would rob them of power as \"Go\u00f0ar\" in traditional Norse paganism, and had Olaf banished from Norway in 1028. When he tried to return in 1030, he was met by the locals in the Battle of Stiklestad, where Olaf was killed, in accordance with the law. The church elevated Olaf I to sainthood, and Nidaros (today Trondheim) became the Christian centre of Norway. Within a few years the Danish rule had become sufficiently unpopular that Norway again united under a Norwegian king, Magnus Olavson the Good, in 1035.\nFrom the 1040s to 1130 the country was at peace. In 1130, a civil war era broke out over succession to the throne, which allowed all the king's sons to rule jointly by dividing Norway into portions for each to rule. At times there were periods of peace, before a lesser son allied himself with a chieftain and started a new conflict. The Archdiocese of Nidaros was created in 1152 in an attempt to control the appointment of kings. The church inevitably took sides in these conflicts, with the church's influence on the king also becoming an issue in the civil wars. The wars ended in 1217 with the appointment of H\u00e5kon H\u00e5konsson, who introduced clear succession laws. He also managed to subject Greenland and Iceland to Norwegian rule; the Icelandic Commonwealth thus came to an end after the Age of the Sturlungs civil war resulted in a pro-Norwegian victory.\nThe population increased from 150,000 in 1000 to 400,000 in 1300, resulting both in more land being cleared and the subdivision of farms. While in the Viking Age all farmers owned their own land, by 1300 seventy percent of the land was owned by the king, the church, or the aristocracy. This was a gradual process where farmers would borrow money in meagre times, often not being able to repay them. However, tenants always remained free men and the large distances and often scattered ownership meant that Norwegian farmers enjoyed much more freedom than continental serfs. In the 13th century about twenty percent of a farmer's yield went to the king, church and landowners.\nDecline and the Kalmar Union.\nThe 13th century is described as Norway's Golden Age, with peace and increase in trade, especially with the British islands, although Germany became increasingly important towards the end of the century. Throughout the High Middle Ages the king established Norway as a sovereign state with a central administration and local representatives.\nIn 1349, the Black Death spread to Norway and within a year killed nearly two-thirds of the population. Later plagues halved the population by 1400. Many communities were entirely wiped out, resulting in an abundance of land, allowing farmers to switch to more animal husbandry. The reduction in taxes weakened the king's position, and many aristocrats lost their surplus income, reducing some to mere farmers. High tithes made the church more powerful, and the archbishop became a member of the Council of State.\nThe Hanseatic League took control of Norwegian trade in the 14th century and established trading posts in most Norwegian port cities, such as Oslo and Bergen, which had the largest German colony. In 1380, Olaf Haakonsson inherited both the Norwegian and Danish thrones, creating a union between the two countries. In 1397, under Margaret I, the Kalmar Union was created between the three Scandinavian countries. She waged war against the Hanse, resulting in a trade blockade and higher taxation on Norwegians, which resulted in a rebellion. However, Norway and its Council of State was too weak to secede from the union.\nMargaret pursued a centralising policy which inevitably favoured Denmark, because it had a greater population than Norway and Sweden combined. Margaret also granted trade privileges to the Hanseatic merchants of L\u00fcbeck in Bergen in return for recognition of her right to rule, and these hurt the Norwegian economy. The Hanseatic merchants formed a state within a state in Bergen for generations. Even worse were the pirates, the \"Victual Brothers\", who launched three devastating raids on the port (the last in 1427).\nNorway slipped ever more into the background under the Oldenburg dynasty (established 1450). There was a revolt under Knut Alvsson in 1502. Norwegians had some affection for king Christian II, who resided in the country for several years. Norway did not take any part in the events which led to Swedish independence from Denmark in the 1520s.\nUnion with Denmark.\nSweden was able to pull out of the Kalmar Union in 1523, thus creating Denmark\u2013Norway under the rule of a king in Copenhagen. King Frederick I favoured Martin Luther's Reformation, but it was not popular in Norway, where the Church was the sole remaining national institution and the country was too poor for the clergy to be very corrupt. Initially, Frederick agreed not to try to introduce Protestantism to Norway but in 1529 he changed his mind. Norwegian resistance was led by Olav Engelbrektsson, Archbishop of Trondheim, who invited the old king Christian II back from his exile in the Netherlands. Christian returned but his army was defeated and he spent the rest of his life in prison.\nThe Puppet State era (\"lydriketiden\").\nWhen Frederick died and a three-way war of succession broke out between the supporters of his eldest son Christian (III), his younger Catholic brother Hans and the followers of Christian II. Olaf Engelbrektsson again tried to lead a Catholic Norwegian resistance movement. Christian III triumphed and Engelbrektsson went into exile and, in 1537, Christian demoted Norway from an independent kingdom to a puppet state, dissolving the Norwegian Council of State. The Reformation was also imposed in 1537, strengthening the king's power. All church valuables were sent to Copenhagen and the forty percent of the land which was owned by the church came under the control of the king. Danish was introduced as a written language, although Norwegian retained distinct dialects. Professional administration was now needed and power shifted from the provincial nobility to the royal administration: district stipendiary magistrates were appointed as judges and the sheriffs became employees of the crown rather than of the local nobility. In 1572 (or 1556), a viceroy was appointed for Norway with a seat at Akershus Fortress in Oslo. In 1628 the Norwegian Army was founded, and professional military officers were employed.\nThe Norwegian economy improved with the introduction of the water-driven saw in the early 16th century. Norway had huge resources of timber but did not have the means to exploit much of it in the Middle Ages as only hand-tools were available. The new saw mills which sprang up in the fjords changed this. In 1544 a deal was struck with the Netherlands (then part of the Holy Roman Empire) and the Dutch controlled the export of Norwegian timber for the next 150 years. Amsterdam was built on piles from Norway. Tree-felling was done in the winter when farm-work was impossible and it was easy to get the felled trees across the snow to the rivers. In the spring, the logs floated down the rivers to the saw mills by the sea. By the mid-16th century the power of the Hanseatic League in Bergen was broken; though German craftsmen remained, they had to accept Danish-Norwegian rule.\nThe 17th century saw a series of wars between Denmark\u2013Norway and Sweden. The Kalmar War between 1611 and 1613 saw 8,000 Norwegian peasants conscripted. Despite lack of training, Denmark\u2013Norway won and Sweden abandoned its claims to the land between Tysfjorden and Varangerfjord. With the Danish participation in the Thirty Years' War in 1618\u201348, a new conscription system was created in which the country was subdivided into 6,000 \"legd\", each required to support one soldier. Denmark\u2013Norway lost the war and was forced to cede J\u00e4mtland and H\u00e4rjedalen to Sweden. The Second Northern War in 1657 to 1660 resulted in Bohusl\u00e4n being ceded to Sweden.\nThe Absolute Monarchy era (\"enevoldstiden\").\nKing Frederick III elevated himself to absolute and hereditary king of Denmark and Norway in 1661, eliminating the power of the nobles. A new administrative system was introduced. Departments organized by portfolio were established in Copenhagen, while Norway was divided into counties, each led by a district governor, and further subdivided into bailiwicks. About 1,600 government officials were appointed throughout the country. Ulrik Fredrik Gyldenl\u00f8ve was the most famous viceroy of Norway (1664\u20131699).\nThe population of Norway increased from 150,000 in 1500 to 900,000 in 1800. By 1500 most deserted farms were repossessed. The period under absolutism increased the ratio of self-owning farmers from twenty to fifty percent, largely through sales of crown land to finance the lost wars. Crofts became common in the absolutism period, especially in Eastern Norway and Tr\u00f8ndelag, with the smallholder living at the mercy of the farmer. There were 48,000 smallholders in 1800. Compared to Denmark, taxes were very low in Norway, typically at four to ten percent of the harvest, although the number of farms per \"legd\" decreased from four to two in the 1670s. Confirmation was introduced in 1736; as it required people to read, elementary education was introduced. \nThe entire period saw mercantilism as the basis for commerce, which involved import regulations and tariffs, monopolies and privileges throughout the county granted to burghers. The lumber industry became important in the 17th century through exports especially to England. To avoid deforestation, a royal decree closed a large number of sawmills in 1688; because this mostly affected farmers with small mills, by the mid 18th century only a handful of merchants controlled the entire lumber industry. Mining increased in the 17th century, the largest being the silver mines in Kongsberg and the copper mines in R\u00f8ros. Fishing continued to be an important income for farmers along the coast, but from the 18th century dried cod started being salted, which required fishermen to buy salt from merchants. The first important period of Norwegian shipping was between 1690 and 1710, but the advantage was lost with Denmark\u2013Norway entering the Great Northern War in 1709. However, Norwegian shipping regained its strength towards the end of the century. Many Norwegians earned a living as sailors in foreign ships, especially Dutch ones. The crews in both sides of the Anglo-Dutch Wars contained Norwegians. Norway benefitted from the many European wars of the 18th century. As a neutral power it was able to expand its share of the shipping market. It also supplied timber to foreign navies.\nThroughout the period, Bergen was the largest town in the country; its population of 14,000 in the mid 18th century was twice the size of Christiania (later Oslo) and Trondheim combined. Eight townships with privileges existed in 1660\u2014by 1800 this had increased to twenty-three. During this period up to two-thirds of the country's audited national income was transferred to Copenhagen. In the last decades of the century, Hans Nielsen Hauge started the Haugean movement, which demanded the right to preach the word of God freely. The University of Oslo was established in 1811.\nUnion with Sweden.\nDenmark\u2013Norway entered the Napoleonic Wars on France's side in 1807. This had a devastating effect on the Norwegian economy as the Royal Navy hindered export by ship and import of food. Sweden invaded Norway the following year, but after several Norwegian victories, a cease-fire was signed in 1809. Following the Battle of Leipzig in 1813, the Treaty of Kiel signed on 14 January 1814 ceded Norway to the king of Sweden.\nChristian Frederik, heir to the Danish and Norwegian crowns, had since 1813 been viceroy of Norway. He spearheaded the Norwegian resistance against the Kiel Treaty and planned to claim the throne as the legitimate heir. He traveled to Trondheim to gain support for his person, and then assembled twenty-one prominent citizens at Eidsvoll Manor on 16 February 1814 to discuss his plans. They rejected a new absolute monarchy and advised him instead to convoke a constituent assembly to draw up a liberal constitution and decide the form of government. Representatives from the entire country were elected to meet at Eidsvoll Manor. The 112 members of the Constituent Assembly gathered and, after six weeks of discussion, concluded the work on the Constitution of Norway on 17 May 1814. Power would be split between the king \u2013 a position to which Christian Frederik was appointed \u2013 and the Parliament of Norway. The Swedish army under Crown prince Carl Johan of Sweden invaded Norway in late July; at the armistice Convention of Moss on 14 August Norway accepted to enter a personal union with Sweden on equal terms, while Sweden accepted the Norwegian Constitution and separate institutions in both states. King Christian Frederik agreed to convoke an extraordinary parliament to revise the Constitution accordingly, and then abdicate. The parliament was convened in Christiania on 7 October, and the necessary amendments were resolved on 4 November 1814. On the same day, king Charles XIII of Sweden was elected king of Norway, thereby establishing the Union.\nThe State of the Officials (\"embedsmannsstaten\").\nThe Napoleonic Wars sent Norway into an economic crisis, as nearly all the merchants had gone bankrupt during the blockade. Recovery was difficult because of export tariffs and the country experienced high inflation. The Norwegian speciedaler was established as a currency by the Bank of Norway when it was established in 1816, financed through a silver tax which lasted until 1842. Under threat of a coup d'\u00e9tat by Carl Johan, Norway reluctantly paid the debt stated in the Treaty of Kiel, despite never having ratified it. Constitution Day on 17 May became an important political rally every year; in 1829 the Swedish governor-general Baltzar von Platen resigned after he used force against demonstrators in the Battle of the Square. The first half of the century was dominated by the ca. 2,000 officials, as there were few bourgeois and no aristocracy following an 1821 decision to abolish nobility. From the 1832 election, farmers became more conscious of electing themselves, resulting in a majority of farmers in Parliament. This resulted in rural tax cuts and higher import tariffs, shifting the tax burden to the cities. They also passed the Local Committees Act, which established elected municipal councils from 1838. Cultural expression from the 1840s to the 1870s was dominated by the romantic nationalism, which emphasized the uniqueness of Norway.\nThe textile industry started in the 1840s, which was followed up with mechanical workshops to build new machinery as the British embargo hindered import of textile machinery. An economic crisis hit the country from 1848, resulting in Marcus Thrane establishing the first trade unions and demanding that equality before the law be independent of social class. Parliament passed a series of laws abandoning economic privileges and easing domestic trade during the 1840s and 1850s. Population increase forced the clearing of new land, although some of the growth came in the cities. The population of Christiania reached 40,000 in 1855. By 1865 the population reached 1.7\u00a0million; the large increase was largely caused by better nutrition from herring and potatoes, a sharp decrease of infant mortality and increased hygiene. Emigration to North America started in 1825, with the first mass emigration commencing in the 1860s. By 1930, 800,000 people had emigrated, the majority settling in the Midwestern United States.\nThe population decrease resulted in a labor shortage in the agriculture, which again resulted in increased use of machinery and thus capital. The government stimulated the process through the creation of the Mortgage Bank in 1851 and the State Agricultural College eight years later. The 19th century saw a large increase of road construction and steamship services commenced along the coast. The first railway, the Trunk Line between Christiania and Eidsvoll opened in 1854, followed a year later by the first telegraph line. Export industry commenced with steam-powered sawmills in the 1860s, followed by canned herring, wood pulp and cellulose. From 1850 to 1880 the Norwegian shipping industry enjoyed a large boom, stimulated by the abolishing of the British Navigation Acts. By 1880 there were 60,000 Norwegian seamen and the country had the world's third-largest merchant marine. As the first coast-to-coast railway, the R\u00f8ros Line connected the capital to Trondheim in 1877. Norway joined the Scandinavian Monetary Union in 1875 and introduced the Norwegian krone with a gold standard, along with the metric system being introduced.\nThe last decades of the Union.\nAnnual parliamentary sessions were introduced from 1869 and in 1872 ministers were, through a constitutional amendment, required to meet in Parliament to defend their policies. The king, despite having no constitutional right to do so, vetoed the amendment in three successive parliaments. The 1882 election saw the first two parties, the Liberals and Conservatives, run for election, and subsequently the majority succeeded at impeaching the cabinet. In 1884, King Oscar II appointed majority leader Johan Sverdrup as prime minister, thus establishing parliamentarism as the first European country. The Liberal Party introduced a series of legal reforms, such as increasing the voting rights to about half of all men, settling the language conflict by establishing two official written standards, Riksm\u00e5l and Landsm\u00e5l, introduced juries, seven years of compulsory education and, as the first European country, universal suffrage for men in 1889.\nThe 1880s and 1890s saw the rise of the labor movement and trade unions became common; the Norwegian Confederation of Trade Unions was established in 1899 and the Norwegian Employers' Confederation the following year. The Labor Party had its first parliamentary members elected in 1903. The women's issue became increasingly dominant through the 1880s and they were gradually permitted to take secondary and tertiary education. Norwegian support of the union decreased towards the end of the 1890s, especially following the 1897 Swedish abolition of the free trade agreement and the lack of a Norwegian foreign minister. Negotiations of independence commenced, but were not effective because of shifting governments and the Swedish threat of war.\nIndependence.\nWith the four-party Michelsen's Cabinet appointed in 1905, Parliament voted to establish a Norwegian consular service. This was rejected by the king and on 7 June Parliament unanimously approved the dissolution of the union. In the following dissolution referendum, only 184 people voted in favor of a union. The government offered the Norwegian crown to Denmark's Prince Carl, who after a plebiscite became Haakon VII. The following ten years, Parliament passed a series of social reforms, such as sick pay, factory inspection, a ten-hour working day and worker protection laws. Waterfalls for hydroelectricity became an important resource in this period and the government secured laws to hinder foreigners from controlling waterfalls, mines and forests. Large industrial companies established in these years were Elkem, Norsk Hydro and Sydvaranger. The Bergen Line was completed in 1909, the Norwegian Institute of Technology was established the following year and women's suffrage was introduced in 1913\u2014as the second country in the world. From the 1880s to the 1920s, Norwegians carried out a series of polar expeditions. The most important explorers were Fridtjof Nansen, Roald Amundsen and Otto Sverdrup. Amundsen's expedition in 1911 became the first to reach the South Pole.\nNorway adopted a policy of neutrality from 1905; during World War I the Norwegian merchant marine was largely used in support of the British, resulting in Norway being classified as The Neutral Ally. Half the Norwegian fleet was sunk and 2,000 seamen were killed by the German Atlantic U-boat Campaign. Some merchants made huge profits from trade and shipping during the war, resulting in an increased division between the classes. The interwar period was dominated by economic instability caused among other by strikes, lock-outs and the monetary policy causing deflation to compensate for too much money having been issued during the war and thus hindering investments. Especially fishermen were hit hard in the period, while farmers retained market prices through organizing regulations. Unemployment peaked at ten percent between 1931 and 1933. Although industrial production increased by eighty percent from 1915 to 1939, the number of jobs remained stable. The Norwegian School of Economics was established in 1936.\nNorway had nine governments between 1918 and 1935, nearly all minority and lasting an average eighteen months. The Agrarian Party was established in 1920, although this period saw a rise of support for the Conservatives. The Labor Party split in 1921, with the left wing establishing the Communist Party. Although strong during the 1920s, they were marginalized through the 1930s. A short-lived Labor Government reigned in 1928, but did not establish a sound parliamentary support until the 1935 Nygaardsvold's Cabinet, based on an alliance with the Agrarian Party. During the 1920s and 1930s, Norway established three dependencies, Bouvet\u00f8ya, Peter I Island and Queen Maud Land, annexed Jan Mayen and secured sovereignty of Svalbard through the Svalbard Treaty. Norway's first civil airport, Stavanger, opened in 1937.\nWorld War II.\nFrom the start of World War II in 1939, Norway maintained a strict neutrality. Both Britain and Germany realized the strategic location; both made plans to invade Norway, regardless of Norwegian opposition. The Germans struck first and invaded Norway on 9 April 1940 in the so called operation \"Weser\u00fcbung\". After furious battles with Norwegian and British forces, Germany prevailed and controlled the country until the end of the war. The German goal was to use Norway to control access to the North Sea and the Atlantic, and to station air and naval forces to stop convoys from Britain to the USSR.\nGovernment in exile.\nThe government in exile, including the royal family, escaped to London. Politics were suspended and the government coordinated action with the Allies, retained control of a worldwide diplomatic and consular service, and operated the huge Norwegian merchant marine. It organized and supervised the resistance within Norway. One long-term impact was the abandonment of a traditional Scandinavian policy of neutrality; Norway became a founding member of NATO in 1949. Norway at the start of the war had the world's fourth largest merchant fleet, at 4.8\u00a0million tons, including a fifth of the world's oil tankers. The Germans captured about 20% of the fleet but the remainder, about 1000 ships, were taken over by the government. Although half the ships were sunk, the earnings paid the expenses of the government.\nQuisling regime.\nVidkun Quisling proclaimed himself prime minister and appointed a government with members from the National Unity Party. He was quickly set aside and replaced by Josef Terboven, but reinstated in 1942. The Norwegian campaign continued in Northern Norway and the government fled to London on 7 June. The German occupation resulted in a brutalization of society and 30,000 people were imprisoned. 55,000 people joined the National Unity Party, which became the only legal party. But the nazification process failed after the Supreme Court resigned and both organized sports and bishops boycotted the new regime. A resistance movement was established and was coordinated from London from 1943. Stokker reports that hostile humour against the Germans helped maintain morale and build a wall against collaboration. Jokes made the rounds dripping with contempt for the oppressors, ridicule of Nazi ideology, stressing the cruelty of the Nazis and mocking their inflated self-image. People on the street asked, \"Do you know the difference between the Nazis and a bucket of manure? The bucket.\" In Post Office lines they explained, \"It's rumored that we're getting new stamps bearing Quisling's likeness, but distribution has been delayed because no one knows which side to spit on.\" The jokes worked to educate Norwegians about the occupation, and encourage a sense of solidarity. At the time of German surrender on 8 May 1945, there were 360,000 German soldiers in the country.\nPostwar.\n1945\u20131950.\nA legal purge took place in Norway after WWII in which 53,000 people were sentenced for treason and 25 were executed. The post-war years saw an increased interest in Scandinavism, resulting in Scandinavian Airlines System in 1946, the Nordic Council in 1952 and the Nordic Passport Union along with the metric system being introduced. Reconstruction after the war gave Norway the highest economic growth in Europe until 1950, partly created through rationing private consumption allowing for higher industrial investments. The Labor Party retained power throughout the period and maintained a policy of public planning. The University of Bergen was created in 1946. The 1950s saw a boom in construction of hydroelectricity and the state built the steel mill Norsk Jernverk and two aluminum works. State banks such as the State Housing Bank, the State Educational Loan Fund and Postbanken allowed for governmental control over private debt. Oslo hosted the 1952 Winter Olympics.\nNorway retained its neutrality policy until 1947, focusing on its membership in the United Nations, where Trygve Lie had become the first secretary-general. However, there was no enthusiasm for the UN at the time. Anti-communism grew with a Soviet proposal for joint control over Svalbard and especially after the 1948 Czechoslovak coup d'\u00e9tat, after which the Communist Party lost all influence. Norway started negotiations for the creation of a Scandinavian defense union, but instead opted to become a founding member of the North Atlantic Treaty Organization (NATO). However, Norway never allowed permanently stationed foreign troops or nuclear weapons on Norwegian soil to avoid agitating the Soviet Union, with which Norway from 1944 shared a land border. NATO financed large parts of the Norwegian military investments, which ultimately resulted in numerous airports being built during the 1950s and 1960s.\nMarshall Plan.\nNorway joined the Marshall Plan (\"ERP\") in 1947, receiving US$400\u00a0million in American support. Given the business background of the Marshall Plan's American leaders, their readiness to work with the Norwegian Labor government's ERP Council disappointed the conservative Norwegian business community. It was represented by the major business organizations, the Norges Industriforbund and the Norsk Arbeidsgiverforening. While reluctant to work with the government, Norwegian business leaders also recognized the dangers of appearing to obstruct the implementation of the Marshall Plan. American acceptance of a role for government in economic planning reflected their New Deal reformist orientation. The opportunities for mediation between conservative Norwegian business interests and the government that arose in the course of administering the Marshall Plan helped establish a base for the emergence of Norwegian corporatism in the 1950s.\n1950 to 1972.\nThe sale of cars was deregulated in October 1960, and in the same year the Norwegian Broadcasting Corporation introduced Norway's first television broadcasts. Norway feared competition from Swedish industry and Danish agriculture and chose not to join any free trade organizations until 1960, when it joined the European Free Trade Association. Throughout the post-war period both fishing and agriculture became more mechanized, the agricultural subsidies rose to the third-highest in the world and the number of small-scale farms and fishermen fell dramatically. The Socialist People's Party was created in 1961 by former Labor politicians who disagreed with the Labor Party's NATO, nuclear and European policies. Following the Kings Bay Affair the Conservative Lyng's Cabinet ruled for a month. The Conservative coalition Borten's Cabinet won the 1965 election, sat for six years and started a trend of shifting Labor and Conservative governments. Norwegianization of Samis halted after the war and Sami rights became an increasing issue, with a council being established in 1964.\nThe completion of the Nordland Line to Bod\u00f8 in 1962 concluded the construction of new railway routes, while the first part of the Oslo Metro opened in 1966. A social security net was gradually introduced after the war, with child allowances introduced in 1946 and the Social Care Act introduced in 1964. The 1960s saw good times for heavy industry and Norway became Europe's largest exporter of aluminum and the world's largest exporter of ferroalloys. The University of Trondheim and the University of Troms\u00f8 both opened in 1968, one year before a network of regional colleges started being opened. Influenced by American culture and similar actions abroad, youth and students started to rebel against cultural norms. The 1960s saw an increased focus on environmentalism, especially through activism, based on ever-more conversion of waterfalls to hydro stations, pollution and the dilapidation of herring stocks. Rondane National Park was created as the country's first in 1962 and the Ministry of the Environment was the first in the world when it was established in 1972. A network of regional airports were built in Western and Northern Norway in the late 1960s and early 1970s. Membership in the European Economic Community was rejected in a 1972 referendum. Economic conditions also improved: By the early 1970s, the Norwegian population had attained one of the highest standards of living in the world. \nOil Age.\nProspecting in the North Sea started in 1966 and in 1969 Phillips Petroleum found oil in the Ekofisk field\u2014which proved to be among the ten largest fields in the world. Operations of the fields was split between foreign operators, the state-owned Statoil, the partially state-owned Norsk Hydro and Saga Petroleum. Ekofisk experienced a major blowout in 1977 and 123 people were killed when the Alexander Kielland accommodation rig capsized in 1980; these incidents led to a strengthening of petroleum safety regulations. The oil industry not only created jobs in production, but a large number of supply and technology companies were established. Stavanger became the center of this industry. High petroleum taxes and dividends from Statoil gave high income from the oil industry to the government.\nNorway established its exclusive economic zone in the 1970s, receiving an area of . A series of border disputes followed; agreements were reached with Denmark and Iceland in the 1990s, but the border in the Barents Sea was not agreed upon until 2010. Between 1973 and 1981 the country was ruled by the Labor Party, who carried out a series of reforms such as new school system. Farmers received increased subsidies and from 1974 women were permitted to inherit farms. Abortion on demand was legalized in 1978. Loans guaranteed in future oil income allowed Norway to avoid a recession during the mid-1970s. But by 1977 high wages had made Norwegian industry uncompetitive and a soaring forced cut-backs in public and private spending. Fish farming became a new, profitable industry along the coast.\nAn immigration surplus was established in the late 1960s, largely from Western Europe and the United States\u2014from the 1970s increasingly expertise in oil. The period also saw an increased immigration of unskilled labor from developing countries, especially Pakistan, and Oslo became the center-point of immigration, although regulations from 1975 slowed this significantly. The Alta controversy started in the 1970s when Statkraft planned to dam the Alta River. The case united the environmental and Sami interest groups; although Alta Power Station was built, the issue shifted the political climate and made large-scale hydroelectricity projects difficult to build. The Sami Parliament was established in 1989.\nThe Conservative Party won the 1981 elections and carried out a large deregulation reform: taxes were cut, local private radio stations were permitted, cable television was established by private companies, regulations on borrowing money were removed and foreigners were permitted to buy securities. An economic crisis hit in 1986 when foreigners started selling Norwegian krone, which ultimately forced an increase in taxes and Prime Minister K\u00e5re Willoch was forced to resign. The Progress Party, located to the right of the Conservatives, had its break-through in the late 1980s. The high wages in the oil industry made low-skill manufacturing industries uncompetitive and the Labor Party closed a number of public industrial companies which were receiving large subsidies. The 1980s saw a trebling of people on disability, largely amongst the oldest in the workforce, and the crime rate rose.\nThe subsea Vard\u00f8 Tunnel opened in 1982 and since the country has built subsea tunnels to connect island communities to the mainland. From the 1980s, the largest cities introduced toll rings to finance new road projects. A banking crisis hit Norway in the late 1980s, causing the largest banks, such as Den norske Bank, Christiania Bank and Fokus Bank, to be nationalized. Norsk Data, a manufacturer of minicomputers, became Norway's second largest company by 1985, just to go bankrupt by 1993. Unemployment reached record-high levels in the early 1990s.\nBy 1990, Norway was Europe's largest oil producer and by 1995 it was the world's second-largest oil exporter. Membership in the European Union was rejected in a 1994 referendum, with Norway instead joining the European Economic Area and later also the Schengen Area. Large public investments in the 1990s were a new National Hospital and Oslo Airport, Gardermoen\u2014connected to the capital with Norway's first high-speed railway, the Gardermoen Line. A number of large government companies, such as Statoil, Telenor and Kongsberg were privatized. Lillehammer hosted the 1994 Winter Olympics. The end of the Cold War resulted in cooperation with Russia and reduced military activity.\n21st century.\nThe Norwegian Armed Forces shifted their focus from defending an invasion to being mobile for use in NATO operations abroad and participated in the War in Afghanistan in 2001, Iraq War in 2003, and in the Libyan Civil War in 2011. They were also involved in the NATO bombing of Yugoslavia in 1999.\nOn 26 December 2004 during a Christmas holiday and Boxing Day celebration, more than 80 of Norwegian people in Thailand and the other part across the South and Southeast Asia were among thousands of people killed by the magnitude 9.0 earthquake and tsunami off Sumatra.\nThe 2011 attacks saw an attack on the Government Headquarters in Oslo and Workers' Youth League camp at the island of Ut\u00f8ya by the Norwegian gunman Anders Behring Breivik, killing 77 people. It was the worst ever gun massacre made by an individual.\nIn the 2013 Storting elections, voters ended eight years of Labor rule led by Prime Minister Jens Stoltenberg. A coalition of the Conservative Party and the Progress Party, was elected. The transition came amid an economy in good condition, with low unemployment. In Norwegian parliamentary election 2017 the center-right government of Prime Minister Erna Solberg won re-election. In January 2018, the Liberal Party joined the government, the Christian Democrats joined them in January 2019. The Progress Party left the coalition in January 2020, but it continued to support the government.\nNorway's new center-left cabinet under Prime Minister Jonas Gahr Stoere, the leader of Norway's center-left Labor Party, took office on 14 October 2021. He formed a minority coalition government with the Centre Party, supported by the Socialist Left Party. The previous center-right government was ousted in the 13 September election after two four-year terms.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56142", "revid": "51025447", "url": "https://en.wikipedia.org/wiki?curid=56142", "title": "Thiruvananthapuram", "text": "Metropolis and capital of Kerala, India\nThiruvananthapuram ( ), also known as Trivandrum, is the capital city of the Indian state of Kerala. As of 2011, the Thiruvananthapuram Municipal Corporation had a population of 957,730 over an area of 214.86 sq. km, making it the largest and most populous city in Kerala. The larger Thiruvananthapuram metropolitan area has over 1.7 million inhabitants within an area of 543 sq. km. Thiruvananthapuram is one of the few cities in India that functions as a capital city, a heritage city, a maritime city, an information technology city, a space research city, a defence city, an automotive tech city, a bioscience city, a tourism city, and a city known for its research and development institutions. It is also among the few cities in the world where both an international airport and an international seaport are located within the city in close proximity to the city center.\nLocated on the west coast of India near the extreme south of the mainland, Thiruvananthapuram is a port city located from a heavily trafficked East-West shipping channel. The city is home to India\u2019s first deep-water trans-shipment port, the Vizhinjam International Seaport Thiruvananthapuram. The city is characterised by its undulating terrain of low coastal hills. Thiruvananthapuram is also known for its cultural heritage, being associated with the musical contributions of Swathi Thirunal Rama Varma and the artistic legacy of painter Raja Ravi Varma. Thiruvananthapuram has contributed to the development of Malayalam literature through individuals like Ulloor S. Parameswara Iyer, Kumaran Asan, C. V. Raman Pillai and Narayana Guru. The city is also known for Sree Padmanabhaswamy Temple, known as the richest temple in the world.\nThe present regions that constitute Thiruvananthapuram were ruled by the Ays who were related to feudatories of the Chera dynasty. In the 12th century, it was conquered by the Kingdom of Venad. In the 18th century, the king Marthanda Varma expanded the territory, founded the princely state of Travancore and made Thiruvananthapuram its capital. Travancore became the most dominant state in Kerala by defeating the powerful Zamorin of Calicut in the battle of Purakkad in 1755. Following India's independence in 1947, Thiruvananthapuram became the capital of Travancore\u2013Cochin state and remained so until the new Indian state of Kerala was formed in 1956.\nThiruvananthapuram is a notable academic and research hub and home to the University of Kerala, APJ Abdul Kalam Technological University, the regional headquarters of Indira Gandhi National Open University, and many other schools and colleges. Thiruvananthapuram is also home to research centres such as the National Institute for Interdisciplinary Science and Technology, Indian Space Research Organisation's Vikram Sarabhai Space Centre, the Indian Institute of Space Science and Technology, National Centre for Earth Science Studies and a campus of the Indian Institutes of Science Education and Research. Thiruvananthapuram is where India's space program began, with the headquarters of Liquid Propulsion Systems Centre located there. The city is home to media institutions like Toonz Animation India and Tata Elxsi Ltd, and also to Chitranjali Film Studio, one of the first film studios in Malayalam Cinema, and Kinfra Film and Video Park at Kazhakoottam, which is India's first infotainment industrial park.\nIn 2012, Thiruvananthapuram was named the best Kerala city to live in, by a field survey conducted by \"The Times of India\". In 2013, the city was ranked the fifteenth best city to live in India, in a survey conducted by \"India Today\". Thiruvananthapuram was ranked the best Indian city for two consecutive years, 2015 and 2016, according to the Annual Survey of India's City-Systems (ASICS) conducted by the Janaagraha Centre for Citizenship and Democracy. The city was also selected as the best governed city in India in a survey conducted by Janaagraha Centre for citizenship and democracy in 2017.\nEtymology.\nThe city takes its name from the Malayalam word \"thiru-anantha-puram\" ( ), meaning \"The City of Lord Ananda\", referring to the deity of the Sri Padmanabhaswamy Temple located in the city. Thiruvananthapuram is also known in literature, and popular reference as \"Ananthapuri\", derived from the Sanskrit word \"Syanandurapuram\", meaning \"The City of Bliss\" in Carnatic kirtanas composed by Swathi Thirunal, erstwhile Maharaja of Travancore. The city was officially referred to as \"Trivandrum\" until 1991 (Trivandrum being the anglicised name of the town), when the government decided to reinstate the city's original name Thiruvananthapuram. The city was also called as \"Anandapatnam\" or \"Anandapatam\" in Tamil and Telugu languages meaning \"The City of Ananda\" which is the same to meaning for the original name.\nHistory.\nPre Historic Period.\nThiruvananthapuram is a relatively modern region with trading traditions dating back to 1000\u00a0BCE. It is believed that the ships of King Solomon landed in a port called Ophir (now Poovar) in Thiruvananthapuram in 1036\u00a0BCE. The city was the trading post of spices, sandalwood and ivory. However, the ancient political and cultural history of the city was almost entirely independent from that of the rest of Kerala.\nAncient Period.\nThe southern region of present-day Kerala state (The coastal belt between Thiruvananthapuram and Alappuzha) was under Ay dynasty, who was more related to the Pandya dynasty of Madurai., The early rulers of the city were the Ays. Vizhinjam, which is now a region in the present-day Thiruvananthapuram, was the capital of the Ay dynasty. Vizhinjam was an important port city from as early as the second century BC. During the Ay dynasty's rule, Thiruvananthapuram witnessed many battles in which the Chola and Pandyan dynasties attempted to capture the port town.\nMiddle Ages.\nAfter the death of king Vikramaditya Varaguna in 925 AD, the glory of the Ays departed and almost all their territories became part of the Chera dynasty. During the tenth century, the Cholas attacked and sacked Vizhinjam and surrounding regions. The port in Vizhinjam and the historic education center of Kanthalloor Sala were also destroyed by Cholas during this period. A branch of the Ay family, which had controlled the Padmanabhaswamy Temple, merged with the Kingdom of Venad in the 12th century.\nPresent-day Thiruvananthapuram city, district, and Kanyakumari district, were parts of the Ay dynasty during ancient and medieval ages, in the southernmost part of the Indian subcontinent. Ay kingdom had experienced attacks and conquests by Cholas and Pandyas in various periods. Later it became a part of Venad in late Middle Ages, which was eventually expanded as the powerful kingdom of Travancore in 18th century CE. The Tamil-Dravidian kind of architecture is also found in Padmanabhaswamy temple, which makes it distinct and unique from the architectural style of temples in northern and central parts of Kerala.\nThe official language of Kerala, based at Kollam, was also identified as Tamil, by the natives of Kerala in those times. and the Chola dynasty, The place names, the dialects of Malayalam spoken, and the customs that exist in Kerala today still reveal a close relationship with Tamil heritage.\nLate Modern Period.\nIn the early 18th century CE, the Travancore royal family adopted some members from the royal family of Kolathunadu based at Kannur. Then, Marthanda Varma who inherited the Kingdom of Venad expanded the kingdom by conquering the kingdoms of Kayamkulam, Kottarakara, Kottayam, Changanassery, Meenachil, Poonjar and Ambalapuzha. In 1729, Marthanda Varma founded the princely state of Thiruvithamkoor and Thiruvananthapuram was made the capital in 1795 after shifting the capital from Padmanabhapuram in Kanyakumari district. Thiruvananthapuram became a prominent city in Kerala under Marthanda Varma. \nAs a result of the annexation of neighbouring chiefdoms, the artists and scholars from these places migrated to Thiruvananthapuram, turning it into a cultural center. Marthanda Varma gave patronage to different temple art forms including \"Koothu\", \"Padhakam\", \"Kathakali\", \"Thullal\", and \"Koodiyattam\". Noted artists such as Ramapurathu Warrier and Kunchan Nambiar amongst others served as his court poets. Travancore became the most dominant state in Kerala by defeating the powerful Zamorin of Kozhikode in the battle of Purakkad in 1755.\nThe city developed into a significant intellectual and artistic centre during this period. The city's golden age was during the mid-19th century under the reign of Maharaja Swathi Thirunal and Maharaja Ayilyam Thirunal. This era saw the establishment of the first English school (1834), the Observatory (1837), the General Hospital (1839), the Oriental Research Institute &amp; Manuscripts Library and the University College (1873). The first mental hospital in the state was started during the same period. Sanskrit College, Ayurveda College, Law College and a second-grade college for women were started by Moolam Thirunal (1885\u20131924).\nContemporary Period.\nThe early 20th century was an age of tremendous political and social changes in the city. The Sree Moolam Popular Assembly, established in 1904, was the first democratically elected legislative council in any Indian state. Despite not being under the direct control of the British Empire at any time, the city featured prominently in India's freedom struggle. The Indian National Congress had a very active presence in Thiruvananthapuram. A meeting of the Indian National Congress presided by Dr Pattabhi Sitaramaiah was held here in 1938.\nThe Thiruvananthapuram Municipality came into existence in 1920 as the first municipality in the Travancore region. The municipality was converted into a corporation on 30 October 1940, during the period of Chitra Thirunal Bala Rama Varma, who took over in 1931. The city witnessed multi-faceted progress during his period. The promulgation of the \"Temple Entry Proclamation\" (1936) was an act that underlined social emancipation. This era also saw the establishment of the University of Travancore in 1937, which later became Kerala University.\nModern Period.\nWith the end of British rule in 1947, Travancore chose to join the Indian union. The first popularly elected ministry, headed by Pattom Thanu Pillai, was installed in office on 24 March 1948. In 1949, Thiruvananthapuram became the capital of Thiru-Kochi, the state formed by the integration of Travancore with its northern neighbour, the Kochi. The king of Travancore, Chitra Thirunal Bala Rama Varma, became the Rajpramukh of the Travancore-Cochin Union from 1 July 1949 until 31 October 1956. When the state of Kerala was formed on 1 November 1956, Thiruvananthapuram became its capital.\nWith the establishment of Thumba Equatorial Rocket Launching Station (TERLS) in 1962, Thiruvananthapuram became the cradle of India's ambitious space programme. The first Indian space rocket was developed and launched from the Vikram Sarabhai Space Centre (VSSC) in the outskirts of the city in 1963. Several establishments of the Indian Space Research Organisation (ISRO) were later established in Thiruvananthapuram.\nA significant milestone in the city's recent history was the establishment of Technopark\u2014India's first IT park\u2014in 1995. Technopark has developed into the largest IT park in the geographical area, employing around 62,000 people in 450 companies.\nGeography.\nThiruvananthapuram is built on seven hills by the seashore and is at on the west coast, near the southern tip of mainland India. The city is on the west coast of India and is bounded by the Laccadive Sea to its west and the Western Ghats to its east. The average elevation of the city is above sea level. The Geological Survey of India has identified Thiruvananthapuram as a moderately earthquake-prone urban centre and categorised the metropolis in the Seismic III Zone. Thiruvananthapuram lies on the shores of Karamana and Killi rivers. Vellayani, Thiruvallam and Aakulam backwaters lie in the city. The soil type in the middle part of the city is a dark brown loamy laterite soil high in phosphates. Laterisation is a result of the heavy rainfall and humid conditions. In western coastal regions of the city, sandy loam soil is found, and on hilly eastern parts of the district, rich dark brown loam of granite origin is found.\nThe Thiruvananthapuram Corporation is spread over . The wider Thiruvananthapuram metropolitan area comprises Thiruvananthapuram corporation, three municipalities and 27 panchayats, as of 2011. Being the largest city in India's southern tip region, it is essential for both military logistics and civil aviation in the southern part of the country. Thiruvananthapuram is the headquarters of the Southern Air Command (SAC) of the Indian Air Force.\nClimate.\nThe city has a climate that lies on the border between a tropical savanna climate (K\u00f6ppen \"Aw\") and a tropical monsoon climate (\"Am\"). As a result, its only distinct seasons relate to rainfall rather than temperature. Temperatures in Thiruvananthapuram remain remarkably stable throughout the year, with an annual mean maximum of about 31\u201332\u00a0\u00b0C (88\u201390\u00a0\u00b0F) and a mean minimum around 23\u201324\u00a0\u00b0C (73\u201375\u00a0\u00b0F). Daytime highs generally stay between 30 and 34\u00a0\u00b0C (86\u201393\u00a0\u00b0F), while nights are warm and humid, averaging approximately 22\u201325\u00a0\u00b0C (72\u201377\u00a0\u00b0F). The temperature rarely falls below something like both 20\u00a0\u00b0C (68\u00a0\u00b0F) and above 35\u00a0\u00b0C (95\u00a0\u00b0F). The humidity is high and rises to about 90% during the monsoon season. Thiruvananthapuram is the first city along the path of the south-west monsoons and gets its first showers in early June. The city receives heavy rainfall of around per year. The city also gets rain from the receding north-east monsoons which hit the city by October. The dry season sets in by December. The lowest temperature recorded in the city core was on 6 January 1974 and it also recorded 15.6\u00a0\u00b0C in Jan 18 in 2015. The highest temperature was on 21 February 2019. At the airport, the lowest temperature recorded was on 15 January 1975 and the highest temperature was on 5 May 1998.\nDemographics.\nAccording to provisional results of the 2011 national census, the Corporation of Thiruvananthapuram, which occupies an area of , had a population of 957,730. The city's population density was . The Urban Agglomeration had a population of 1,687,406 in 2011. The sex ratio is 1,040 females for every 1,000 males, which is higher than the national average. Thiruvananthapuram's literacy rate of 93.72% exceeds the all-India average of 74%.\nIt is a historical city where Malayali form the vast majority of Thiruvananthapuram's population. There are also minorities like the Tamils and North Indians residing here. According to the 2011 census, 68.5% of the population is Hindu, 16.7% Christians and 13.7% Muslims. The remainder of the community includes Jains, Jews, Sikhs, Buddhists and other religions which account for 0.06% of the population; 0.85% did not state a belief in the census.\nMalayalam, the official state language, is the dominant language in Thiruvananthapuram City: English is also used, mainly by the white-collar workforce. Tamil has the most speakers after Malayalam. The city also has a few Tulu, Kannada, Konkani, Dhivehi, Telugu and Hindi speakers. As per the 2001 census, the population below the poverty line in the city was 11,667.\nThiruvananthapuram has witnessed massive immigration of workers from northern India, mainly Punjab, Haryana, and Madhya Pradesh, and Eastern India, mainly West Bengal and Bihar, and from neighbouring countries like Sri Lanka, the Maldives, Nepal and Bangladesh.\nAdministration.\nThe Corporation of Thiruvananthapuram or TMC oversees and manages the civic infrastructure of the city's 100 wards. Each ward elects a councillor to the Corporation of Thiruvananthapuram. TMC has the power to act as the local government of the city. TMC is headed by the Mayor, who is elected from among the councillors. The Mayor is responsible for the overall supervision and control of the administrative functions of the TMC. The corporation discharges its services through standing committees. The corporation secretary is an officer appointed by the government, who serves as the administrative head of the TMC and implements the council's decisions based on the resolutions adopted by the council. The functions of the Municipal Corporation are managed by seven departments\u2014engineering, health, general administration, council, accounts and revenue. For the decentralised role of TMC, eleven Zonal Offices are created. The zonal offices are in Fort, Kadakampally, Nemom, Ulloor, Attipra, Thiruvallom, Kazhakkuttom, Sreekaryam, Kudappanakunnu, Vattiyoorkavu and Vizhinjam. The functions of the TMC include water supply, drainage and sewerage, sanitation, solid-waste management, and building regulation. The Thiruvananthapuram Development Authority is responsible for the statutory planning and development of the greater Thiruvananthapuram region.\nAs the seat of the Government of Kerala, Thiruvananthapuram is home to not only the offices of the local governing agencies but also the Kerala Legislative Assembly and the state secretariat, which is housed in the Kerala Government Secretariat complex. Thiruvananthapuram has two parliamentary constituencies\u2014Attingal and Thiruvananthapuram\u2014and elects five Members of the Legislative Assembly (MLAs) to the state legislature.\nLaw and order.\nThe Thiruvananthapuram City Police is the main law-enforcement agency in the city. It is headed by a commissioner of police. The Thiruvananthapuram city police is a division of the Kerala Police, and the administrative control lies with the Kerala Home Ministry. Thiruvananthapuram city police is the largest police division in Kerala, and it consists of four subdivisional offices and 24 police stations and a sanctioned strength of 3,500 police personnel. The Central Prison is the oldest prison in Kerala and the headquarters of Kerala Prisons and Correctional Services.\nMilitary and diplomatic establishments.\nThe Southern Air Command of the Indian Air Force is headquartered in the city. There are two state armed police battalions and a unit of the Central Reserve Police Force (CRPF) based in Thiruvananthapuram. The CRPF has a Group Headquarters (GHQ) located at Pallipuram. In addition to this, three units of the Central Industrial Security Force (CISF) and Sector Headquarters (SHQ) of the Border Security Force (BSF) are also present. Thiruvananthapuram also houses a large army cantonment in Pangode which houses some regiments of the Indian Army.\nIn the city there is a Consulate of the United Arab Emirates, a Consulate of the Maldives, and Honorary Consulates of Sri Lanka, Russia and Germany.\nUtility services.\nThe Kerala Water Authority supplies the city with water that is sourced from the Karamana River; most of it is drawn from the Aruvikkara and Peppara reservoirs, and it is treated and purified at the Aruvikkara pumping stations. The Wellington Water Works, commissioned in 1933, is one of the oldest city water supply schemes in India. The sewage water is treated at Muttathara sewage-treatment plant, which handles 32\u00a0million litres per day. The city area is divided into seven blocks for the execution of the sewage system. Electricity is supplied by the Kerala State Electricity Board. Fire services are handled by the Kerala Fire And Rescue Services.\nEconomy.\nThiruvananthapuram is strategically located just 10 nautical miles (19\u00a0km; 12\u00a0mi) away from the crucial Suez to Singapore Far East international shipping route, placing it in close proximity to key global maritime traffic. This advantageous location, combined with the availability of reliable electricity, fresh water, and a long coastline, has accelerated industrial growth in the city. Thiruvananthapuram's economy comprises Information Technology, education, plantations, aerospace, commerce and tourism. Thiruvananthapuram district contributes 10.31%, of the state's GDP. With an economic growth rate of 13.83%, Thiruvananthapuram is the fastest-growing district in Kerala. Thiruvananthapuram was listed as one of the top ten cities in India on Vibrancy and Consumption Index by a study conducted by global financial services firm Morgan Stanley. State- and central-government employees make up a large percentage of the city's workforce.\nThiruvananthapuram is a major aerospace research centre in India. The Vikram Sarabhai Space Centre, the most significant and leading centre of ISRO, and several space-related, state-owned ISRO centres such as Thumba Equatorial Rocket Launching Station, Liquid Propulsion Systems Centre, and ISRO Inertial Systems Unit are based in Thiruvananthapuram. The BrahMos Aerospace Trivandrum Limited is one of the leading missile integration and defence production units in India. Other enterprises include Travancore Titanium Products, Kerala Automobiles Limited, MILMA, English Indian Clays, Keltron, Trivandrum Rubber Works and HLL Lifecare Limited.\nThiruvananthapuram is a major IT and ITES hub in India. The city contributes about 40-45% of Kerala's total software exports. Thiruvananthapuram houses major multinational Technology companies like Oracle Corporation, Nissan, HCL Tech, Accenture, Allianz Technology, Envestnet, Tata Consultancy Services, Infosys, UST Global, Ernst &amp; Young, Flytxt, Guidehouse, Tata Elxsi, McKinsey &amp; Company, RR Donnelley and https://. Technopark is the largest information-technology park in India in terms of built-up area. It is the largest employment base campus in Kerala with 52,000 IT/ITES professionals and about 400 companies. Other IT, media and industrial campuses include Kinfra Film and Video Park, Kinfra Apparel Park, B-HUB and Chithranjali Film Complex. Other major IT, biotechnology and industrial campuses include Technocity, Bio 360 Life sciences park and Digital Science Park.\nTourism is a significant economic sector. The presence of natural attractions like beaches, backwaters, hills, and plantations and attractions like heritage, history, Ayurveda, medical tourism and knowledge centres attract many tourists. The city experienced a surge of investment in the real estate, infrastructure and retail sectors in 2016\u201317.\nPort-related activity is low mainly due to the underdevelopment of ports. Vizhinjam International Seaport is India's first deep-water transshipment Port. Vizhinjam port's location is close to the international shipping routes and, it is just 10\u201312 nautical miles from the busy Persian Gulf-Malacca shipping lane. The port also has a natural depth of 18 to 20 metres which can accommodate huge container ships. The berths at Vizhinjam port are designed to cater to vessels of up to 24,000 TEU.\nTourism.\nThiruvananthapuram is a major tourist hub in India. Kovalam and Varkala are popular beach towns near the city. Other important beaches include Poovar, Shankumugham Beach, Azhimala Beach, Vizhinjam Beach and Veli Beach. Other places of interest include Agasthyamala rain forests, Neyyar Wildlife Sanctuary, Kallar, Braemore, Ponmudi hills, Poovar, Anchuthengu backwaters, Varkala Cliffs and Kappil-Edava lakes.\nThe city is also known for its unique style of architecture involving Kerala Architecture with British and Dravidian influences. Napier museum, Thiruvanathapuram Zoo, Padmanabha Swamy temple, Kuthira Malika palace, Kilimanoor palace and The Thiruvananthapuram Golf Club heritage building are examples of this.\nThe main museums include Kerala Science and Technology Museum (with its attached Priyadarsini Planetarium), Napier Museum, Kerala Soil Museum and Koyikkal Palace Museum. Agasthyamala Biosphere Reserve is listed in UNESCO's World Network of Biosphere Reserves.\nCulture.\nThiruvananthapuram is known as the \"Evergreen City of India\" because of its green landscapes and the presence of many public parks. Thiruvananthapuram has historically been a cultural hub in Southern India due to the development of arts, architecture and liberal customs by the rulers of erstwhile Thiruvananthapuram. As a testimony to this, renowned artists like Maharaja Swathi Thirunal and Raja Ravi Varma hail from the city. Prominent social reformers such as Sri Narayana Guru, Chattampi Swamikal, Ayyankali, Vakkom Moulavi and C. V. Raman Pillai also are from Thiruvananthapuram.\nTwo of the three Malayalam triumvirate poets, Ulloor S. Parameswara Iyer and Kumaran Asan are from Thiruvananthapuram. Annual literature festivals like the Kovalam Literary Festival, are held in the city. Literary development is further aided by state institutions such as the State Central Library, one of the oldest public libraries in India, which was established in 1829, and other major libraries including the Thiruvananthapuram Corporation Central library, and the Kerala University Library. Thiruvananthapuram has been a hub of classical music since the days of Maharaja of Travancore, Swathi Thirunal. Thiruvananthapuram is known for many music festivals like the Navarathri Music Festival, one of the oldest festivals of its kind in South India, Swathi Sangeethotsavam, Soorya Music fest, Neelakanta Sivan Music Fest and many other music festivals are organised by various cultural groups. The 111-day-long Soorya Festival is the biggest art and cultural event in Kerala. The Soorya Festival features film festivals, theatre festivals, dance, music, painting and photography exhibitions.\nThe Malayalam film Industry was started in Thiruvananthapuram. The first Malayalam feature film, Vigathakumaran directed by J. C. Daniel was released in Thiruvananthapuram. J. C. Daniel is considered the father of Malayalam film industry. He also established the first film studio in Kerala, the Travancore National Pictures at Thiruvananthapuram in 1926. The International Film Festival of Kerala (IFFK), which is held every year in December, is one of Asia's largest film festivals in terms of viewer participation. In addition to various film festivals, the presence of the Central Board of Film Certification's regional office, many movie studios and production facilities like the Uma Studio, Chitranjali Studio, Merryland Studio, Kinfra Film and Video Park and Vismayas Max contribute to the growth of Thiruvananthapuram as a centre of cinema.\nApart from the famous Padmanabhaswamy Temple, the city's architecture is championed by the Napier Museum and Thiruvananthapuram Zoo, one of the oldest zoos in India. Other architectural landmarks include Kuthira Malika Palace, Kowdiar Palace, Attukal Bhagavathy Temple, Beemapally Mosque, Connemara Market, and the Mateer Memorial Church. Thiruvananthapuram was the main centre of Laurie Baker's architecture.\nAlong with the major festivals of Onam, Vishu, Deepavali, and Navaratri, Christian and Islamic festivals like Christmas, Eid ul-Fitr, Bakrid and Milad-e-sheriff, the diverse ethnic populace of the city celebrates several local festivals like Attukal Pongala, Beemapally Uroos, Vettukaad Church Festival, Padmanabhaswamy Temple Aaraattu and Lakshadeepam festival. During the Onam festival, the state government conducts several cultural events for a week in the city. The Attukal Pongala festival attracts millions of women devotees from across India and abroad. It is the largest gathering of women in the world. Germany's Goethe Zentrum, France's Alliance Fran\u00e7aise and Russia's Gorky Bhavan centres host a wide range of events and programmes throughout the year.\nFashion.\nThiruvananthapuram has a long-standing connection with textile traditions, especially through the Balaramapuram Handlooms industry. Known for its cotton fabrics with kasavu (gold zari borders), the region\u2019s weaving techniques have remained largely unchanged since the 18th century. The handwoven fabrics continue to feature in both traditional attire and contemporary fashion collections, including international showcases.\nModern fashion is also well-represented in the city, with shopping malls like Lulu Mall and Mall of Travancore hosting popular domestic and international clothing brands, reflecting current global trends in apparel and lifestyle.\nCuisine.\nTrivandrum\u2019s cuisine reflects local food traditions shaped by its historical and cultural background, including influences from the former Travancore royal kitchens, coastal trade, and religious diversity. The city\u2019s food culture includes a variety of vegetarian and non-vegetarian dishes, with rice, coconut, and spices forming the basis of most meals.\nStreet food in Trivandrum includes items such as \"kappa\" (tapioca) with fish curry, \"parippu vada\", \"banana chips\", and \"unniyappam\". Small eateries and roadside vendors are widespread throughout the city.The general cuisine of the people is Keralite cuisine, which is generally characterised by an abundance of coconut and spices. Other South Indian cuisines, as well as Chinese and North Indian cuisines, are popular. Thiruvananthapuram has many restaurants offering Arabic, Italian, Thai and Mexican cuisines.\nHealth care.\nThiruvananthapuram, the capital city of Kerala, has a robust healthcare system, with both government and private medical institutions offering comprehensive services. The Government Medical College, one of the oldest medical colleges in India, is a prominent center for medical education and healthcare. The Sree Chitra Tirunal Institute for Medical Sciences and Technology (SCTIMST) is a well-known institution specializing in cardiology, neurology, and biomedical research. Other significant medical institutions include Rajiv Gandhi Centre for Biotechnology (RGCB), which focuses on advanced biotechnological research, and Kerala Institute of Medical Sciences (KIMS), known for its multi-specialty services. Private hospitals like NIMS Hospital, Aster capital, and Lord's Hospital provide advanced care across various specialties, including cardiology, oncology, and orthopedics. Additionally, Ayurvedic treatment centers are prevalent in the city, offering traditional healing methods. The city also provides palliative care services, with initiatives like the Arike Home Daycare Program, which supports patients in need of end-of-life. care at home.\nOther major hospitals in Trivandrum include Ananthapuri Hospitals and Research Institutes (AHRI), SP Fort Hospital, Aster Capitol, Trivandrum International Medical Center, PRS Hospital, NIMS\nTransport.\nPublic transport.\nThe majority of bus services are conducted by government operators. There are also private operators. The city buses operated by Kerala State Road Transport Corporation (KSRTC) are an important and reliable means of public transport available in the city. The main bus stations in the city are the Central Bus Station in Thampanoor, where most of the long-distance buses ply from, and the city bus station in East Fort, where most city buses ply from. Three-wheeled, yellow and black auto-rickshaws and taxis, are other popular forms of public transport. Thiruvananthapuram Metro is a fully elevated metro rail \u2013 rapid transit system planned to ease the congestion in the city.\nMetro.\nThe Thiruvananthapuram Metro is a proposed 42.1\u00a0km Conventional Metro rail system with 37 stations. With 2 primary lines connecting key hubs like Kazhakuttom and Karamana. The idea of the Thiruvananthapuram Metro was first proposed in the early 2000s to cater to the growing population. In 2025, a high-level committee led by the Chief Secretary was formed to examine and finalize the metro\u2019s alignment. Three main routes under consideration are:\nThe alignment plan includes both underground and elevated sections.\nRoad.\nThiruvananthapuram has a well-developed road transport infrastructure. The roads in the city are maintained by the Thiruvananthapuram Roads Development Company Limited (TRDCL) and Kerala PWD. TRDCL manages the 42\u00a0km city roads which come under the Thiruvananthapuram City Roads Improvement Project (TRCIP), which is the first urban road project in India. TRCIP is a public-private partnership project to improve and maintain the existing road network in the city to cater to the needs of rapid urbanisation. TRCIP has won the International Road Federation's Global Road Achievement Awards in 2015. TCRIP has also been selected by United Nations as a replicable public-private partnership model. It was one of the 12 public-private partnership project case studies from across the world which fulfil the Sustainable Development Goals of the UN Agenda 2030. In 2024, Thiruvananthapuram became the first Indian city to win the UN global sustainability award.\nThiruvananthapuram is served by National Highway 66 of India's National Highways system. The city is connected to the North-South Corridor of the National Highway system at Aralvaimozhi, which is 80\u00a0km south of the city. The State Highway 1, which commonly known as the Main Central Road is an arterial highway in the city. Other major highways in the city are State Highway 2 and State Highway 45. The Mahatma Gandhi Road is the main arterial road in the city. Another important road is the Kowdiar Road, which is also known as the Royal Road, as it leads to the Kowdiar Palace.\nRail.\nThiruvananthapuram is a divisional headquarters in the Southern Railway zone of the Indian Railways. Long-distance trains originate from Thiruvananthapuram Central and Thiruvananthapuram North railway terminals. Kochuveli railway terminal is developed to ease congestion on the central station and it acts as a satellite station to Thiruvananthapuram Central. Thiruvananthapuram Central is the busiest railway station in Kerala. Other railway stations in the city are Thiruvananthapuram North, Thiruvananthapuram Pettah, Thiruvananthapuram South railway station, Veli railway station and Kazhakoottam railway station. Being the southernmost municipal corporation in India, many long train services of Indian Railways originate from Thiruvananthapuram like Thiruvananthapuram Rajdhani Express, Thiruvananthapuram - Silchar Superfast Express and Thiruvananthapuram North - Amritsar Weekly Express. There are plans to develop a railway terminal at Thiruvananthapuram South railway station to reduce congestion at Thiruvananthapuram Central.\nAir.\nThiruvananthapuram is served by the Thiruvananthapuram International Airport, located at Chakka, only from the city centre. The airport started operations in 1935 and is the first airport in Kerala. Being one of the gateways to the state, it has direct connectivity to all the major cities in India as well as the Middle East, Malaysia, Singapore, the Maldives and Sri Lanka. As the city is headquarters of the Southern Air Command (SAC) of the Indian Air Force, Thiruvananthapuram International Airport caters to the Indian Air Force (IAF) and the Coast Guard for their strategic operations. IAF has an exclusive apron to handle all their operations. The airport also caters to the Rajiv Gandhi Academy for Aviation Technology which carries out pilot-training activities.\nSea.\nSmall cruise ships often dock at Vizhinjam Harbour. A cruise terminal is under trial run at Vizhinjam Transshipment Terminal and some of the world's largest container vessels had already docked here. Vizhinjam seaport has been designated by the government as an authorised immigration check-post for entry and exit from India for international ships and cruises.\nEducation.\nPrimary and secondary education.\nSchools in Thiruvananthapuram are classified as aided, unaided and Government schools. The government schools are run directly by the Kerala State Education Board and follow the syllabus prescribed by the state government. The aided schools also follow the state syllabus. Malayalam and English are the primary languages of instruction; Tamil and Hindi are also used. The schools are affiliated with The State Council of Educational Research and Training (SCERT), Central Board of Secondary Education (CBSE), Indian Certificate of Secondary Education (ICSE), International General Certificate of Secondary Education (IGCSE) and National Institute of Open Schooling (NIOS). In the National Achievement Survey conducted by the National Council of Educational Research and Training (NCERT), Thiruvananthapuram is ranked as the best city in Kerala.\nThe notable schools in the city include St. Mary's Higher Secondary School, which is considered one of the largest schools in Asia, with the total number of students exceeding 12,000, Government Model Boys Higher Secondary School, Government Higher Secondary School for Girls, Holy Angel's Convent Trivandrum, SMV School, Trivandrum International School, Chinmaya Vidyalayas, Kendriya Vidyalaya, Loyola School, Christ Nagar School, Thiruvananthapuram, Sarvodaya Vidyalaya, Nirmala Bhavan Higher Secondary School, Arya Central School, Jyothi Nilayam School, St. Joseph's Higher Secondary School, St. Thomas Residential School, The Oxford School and VSSC Central School.\nHigher education and research.\nThiruvananthapuram is a major educational and research hub with various institutions in the fields of space science, information technology, physical science, biotechnology, engineering and medicine. There are three universities in Thiruvananthapuram: two state universities and one deemed university. The state universities are the University of Kerala and APJ Abdul Kalam Technological University. Indian Institute of Space Science and Technology (IIST), is a government-aided institute and deemed university. IIST is the first of its kind in the country, to offer graduate courses and research in space sciences, space technology and space applications. The city also houses two Institutes of National Importance; Sree Chitra Tirunal Institute for Medical Sciences and Technology (SCTIMST) and Indian Institute of Science Education and Research (IISER). Thiruvananthapuram is one of the regional headquarters of Indira Gandhi National Open University (IGNOU).\nThe Government Medical College, Thiruvananthapuram is the first and a premier medical school in Kerala, founded in 1951. Other notable medical schools apart from SCTIMST (which provides super-specialty courses in cardiac and neuroscience) and Regional Cancer Centre, Thiruvananthapuram (which provides PG courses in radiotherapy and pathology, and super-specialty courses) includes SUT Academy of Medical Sciences, Sree Gokulam Medical College and Government Ayurveda College.\nThe city houses several prominent legal education institutions. The Government Law College, formed in 1875, is one of the oldest legal education institutions in India. The Kerala Law Academy is another major legal education institution. The major Business schools include Asian School of Business, CET School of Management and Institute of Management in Kerala (IMK). There are over 23 engineering education institutions in Thiruvananthapuram. Apart from IIST and IISER, the other major engineering education institutions include College of Engineering, Trivandrum (CET), which is the first engineering college in Kerala, Government Engineering College BartonHill (GEC), Sree Chitra Thirunal College of Engineering (SCT), ER &amp; DCI Institute of Technology, University College of Engineering, Mohandas college of Engineering and Technology and Mar Baselios College of Engineering and Technology. The University College Thiruvananthapuram established in 1866 and H.H. The Maharaja's College for Women established in 1864 are two of the oldest institutions of higher education in India.\nOther prominent undergraduate and postgraduate colleges include the Government Arts College, Mahatma Gandhi College, Mar Ivanios College, Government Sanskrit College, Loyola College of Social Sciences, St. Xavier's College and All Saints College. Major fine arts colleges are Swathi Thirunal College of Music, which is the first music academy in Kerala and College of Fine Arts Trivandrum. The Lakshmibai National College of Physical Education is one of the two physical education academic institutes of the Sports Authority of India (SAI).\nThe premier research institutes in Thiruvananthapuram include: Indian Institute of Information Technology and Management, Kerala (IIITMK), National Institute of Speech and Hearing (NISH), Rajiv Gandhi Centre for Biotechnology, Centre for Development of Imaging Technology (C-Dit), Centre for Development Studies (CDS), Jawaharlal Nehru Tropical Botanic Garden and Research Institute, National Centre for Earth Science Studies (NCESS), Centre for Development of Advanced Computing (C-DAC) and Oriental Research Institute &amp; Manuscripts Library.\nKerala University is ranked as the best university in Kerala according to the MHRD's National Institutional Ranking Framework (NIRF). Kerala University also ranked top in overall institution rankings in Kerala. In engineering, Indian Institute of Space Science and Technology (IIST) is ranked as the best in Kerala and College of Engineering, Trivandrum (CET) is ranked third in Kerala. College of Engineering, Trivandrum is also ranked fourth in India and first in Kerala in architecture institution rankings. The University College is listed as the best college in Kerala.\nSpace and aerospace.\nThiruvananthapuram is the birthplace of India's space operations. The first rocket launch in India occurred in Thiruvananthapuram in 1963 at the Thumba Equatorial Rocket Launching Station (TERLS). Since then, the city has emerged as a major hub for space research, institutions, and companies.\nInternational relations.\nTrivandrum is the location of the Consulate of the United Arab Emirates and the Consulate of the Maldives. The city also has the Honorary Consulates of Sri Lanka, Russia, and Germany, facilitating diplomatic and cultural engagements.\nMedia.\nThiruvananthapuram has numerous newspaper publications, television and radio stations. Most of the media houses in Kerala are based in Thiruvananthapuram. The first Malayalam channel, Doordarshan Malayalam began broadcasting from the city in 1981. Asianet, the first private channel in Malayalam, also started its telecasting from the city in 1993. The other Malayalam channels based in the city include Asianet News, Amrita TV, Kappa TV, Kairali TV, Kairali We, Mathrubhumi News, Kaumudy TV, JaiHind TV, News18 Kerala and People TV. All major Malayalam channels, including Asianet, Janam TV, Jeevan TV, MediaOne TV and Manorama News have production facilities or offices in the city. TV channels are accessible via cable subscription, direct-broadcast satellite services, or internet-based television. Prominent Direct-to-Home (DTH) entertainment services in Thiruvananthapuram include Sun Direct DTH, DD Direct+, Dish TV, Airtel digital TV and Tata Play.\nMajor Malayalam newspapers available are \"Mathrubhumi\", \"Malayala Manorama\", \"Kerala Kaumudi\", \"Deshabhimani\", Madhyamam, \"Janmabhumi\", \"Chandrika\", \"Thejas\", \"Siraj Daily\", \"Deepika\" and \"Rashtra Deepika\". The English language newspapers with editions from Thiruvananthapuram are \"The New Indian Express\", \"The Hindu\", \"The Deccan Chronicle\" and \"The Times of India\".\nAll India Radio, the national state-owned radio broadcaster, airs Medium wave and Shortwave radio stations in the city. The Vividh Bharati of All India Radio also airs an FM radio station known as Ananthapuri FM. Other FM radio channels broadcast from Thiruvananthapuram are Big FM 92.7\u00a0MHz, Club FM 94.3 MHz, Radio Mirchi 98.3\u00a0MHz, Red FM 93.5\u00a0MHz and Radio DC 90.4\u00a0MHz.\nSports.\nThe most popular sports in Thiruvananthapuram are cricket and football. The city hosted the first international cricket match in Kerala at the University Stadium in 1984. The city also hosted the first Twenty20 International cricket match in Kerala. The Kerala Cricket Association is headquartered in Thiruvananthapuram. Prominent cricketers from Thiruvananthapuram include Sanju Samson, Raiphi Gomez, Ryan Ninan, Aneil Nambiar, K. N. Ananthapadmanabhan, Rohan Prem, Udiramala Subramaniam, P. M. K. Mohandas, Bhaskar Pillai and Padmanabhan Prasanth. The Sports Hub, University Stadium, St Xavier's College Ground, KCA Cricket Stadium Mangalapuram, Medical College ground and Vellyani Agricultural College Ground are the main cricket grounds in the city. The Sports Hub, Trivandrum, commonly known as Greenfield Stadium is one of the largest cricket and football stadiums in India. Thiruvananthapuram hosted the 2015 SAFF Championship at the Greenfield Stadium. SBI Kerala, Titanium FC, KSEB, Kovalam FC and Travancore Royals FC are the major football clubs based in Thiruvananthapuram. Football is usually played in the Greenfield International Stadium (The Sports Hub), Chandrasekharan Nair Stadium and University Stadium. Prominent football players from Thiruvananthapuram include Jobby Justin.\nThe city has facilities to host most types of sports. Thiruvananthapuram was one of the main venues for the 2015 National Games of India. Athletic competitions are usually held at the University Stadium, Chandrasekharan Nair Stadium and Central Stadium. The Trivandrum Marathon is a marathon organised by the Trivandrum runners club every year. There will be two main races; a half marathon of 21\u00a0km and a full marathon of 42.19\u00a0km. A special 2\u00a0km fun run is also organised for public participation. Trivand Run is another marathon conducted every January in the city.\nJimmy George Indoor Stadium is a major indoor stadium in the state. It is used for conducting basketball, volleyball, table tennis, gymnastics, aquatics and martial arts. The stadium has the first altitude-simulated training facility in South India, known as Astra. The major sports training and coaching institutions include the Lakshmibai National College of Physical Education (LNCPE), TOSS Academy and the Tenvic Sports Coaching Academy at the Sports Hub.\nBasketball tournaments are usually conducted by the schools in the city. Thiruvananthapuram hosted the 61st National Shooting Championship at the Vattiyoorkavu Shooting Range. Surfing is also a popular sport on the beaches. Many surfing and standup paddleboarding tournaments are held in the city. The surf competitions are usually held on Kovalam Beach and Varkala Beach. Paragliding is another adventure sport usually seen on Varkala Beach.\nThe SAI Trivandrum golf club, established in 1850, is one of the oldest golf courses in India. It is leased to the Sports Authority of India.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56143", "revid": "2902776", "url": "https://en.wikipedia.org/wiki?curid=56143", "title": "Kochi (disambiguation)", "text": "Kochi is a city in Kerala, India.\nKochi or K\u014dchi may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "56144", "revid": "8087765", "url": "https://en.wikipedia.org/wiki?curid=56144", "title": "Kottayam district", "text": "Kottayam district () is one of 14 districts in the Indian state of Kerala. Kottayam district comprises six municipal towns: Kottayam, Changanassery, Pala, Erattupetta, Ettumanoor, and Vaikom. Situated in the south-central part of Kerala, Kottayam shares its borders with Ernakulam, Idukki, Pathanamthitta, and Alappuzha districts. It is the only district in Kerala that does not border either the Arabian Sea or another Indian state.\nThe district is bordered by hills in the east, and the Vembanad Lake and paddy fields of Kuttanad on the west. The area's geographic features include paddy fields, highlands, and hills. As of the 2011 census, 28.6% of the district's residents live in urban areas, and it reports a 97.2% literacy rate. In 2008, the district became the first tobacco-free district in India. Kottayam registered the lowest Multidimensional Poverty Index (MPI) of zero among all districts of India, indicating no deprivation as per the report published by Oxford Poverty and Human Development Initiative and UNDP for districts across India. The district's headquarters are based in the city of Kottayam.\nHindustan Newsprint Limited and Rubber Board are two central government organizations located in the district. The headquarters of two religious communities in Kerala are also in the Kottayam District: Nair Service Society and the Indian Orthodox Church.\nEtymology.\nThe name Kottayam is a combination of the words \"kotta\" and \"akam\" in the local language of Malayalam, meaning \"interior of a fort\".\nHistory.\nPrehistoric period.\nA substantial portion of Kottayam district may have been under the Arabian Sea during prehistoric times. Marine fossils have been found in an area near Changanassery, thus supporting the hypothesis.\nHowever, there are archaeological evidences of the early human inhabitation period of this district, including ancient fossils, stone inscriptions and monuments, in the archeological sites like the excavation sites, the caves, the temples, etc. The literary works of the Sangam period also help to take a look into the ancient period of the district.\nClassical Antiquity.\nChera dynasty and the Keralaputras of ancient Tamilakam (up to 5th century CE).\nEarly members of the Chera dynasty (first few centuries of the Common Era) had their original headquarters in a region called \"Kuzhamur\" at \"Kuttanad\" in the ancient Tamilakam and were sometimes known as the \"Kuttuvans\". The Chera dynasty is mentioned as \"Keralaputras\" in the inscriptions of the emperor Ashoka of the Maurya Empire (322 BCE \u2013 184 BCE).\nThe province \"Kuttanad\" of the ancient kingdom of \"Keralaputras\" included the modern-day districts of Kottayam, Ernakulam, Idukki, and parts of Alappuzha, which can be defined as the region between the rivers Periyar and Pamba. It was bounded by the Ay kingdom to the south, which included the regions between Pamba River and Kanyakumari (Cape Comorin), and the province of \"Kudanad\", which lies between the rivers Periyar and Chaliyar (modern-day districts of Thrissur, Palakkad, and Malappuram), to the north.\nIt was during the reign of Uthiyan Cheralathan (105\u2013130 CE) that the Chera dynasty began to expand towards the northern and the eastern regions of \"Kuttanad\" by conquering the provinces of \"Kudanadu\" and \"Kongu Nadu\". Afterwards the dynasty got split into three branches and fixed their capitals at Muziris, Tyndis, and Caroura, respectively, as seen in the ancient Greco-Roman travelogues as well as the Old Tamil literary works of the Sangam period. During the reign of \"Narmudi Cheral\", the regions included in the Kingdom of Ezhimala was also added to the Chera empire.\nInvasions and social transformation from 6th century CE to 800 CE.\nThe ancient Chera empire collapsed due to the continuous invasions carried out by the Kalabhras, the Pallavas, the Chalukyas, the Pandyas, and the Rashtrakutas during the period between 500 CE and 800 CE for nearly three centuries. This era marked the migration of Nambudiri Brahmins into the district, which later led to a transformation in the social structure of the region after the 10th century CE. The ancient prominent religions in the district like Buddhism began to vanish after the 10th century CE. Sri Mulavasam was a prominent centre of Buddhism in the Indian peninsula until the early medieval period, prior to the Chera-Chola wars of the 11th century CE.\nMedieval history.\nThe regions included in the modern-day district of Kottayam is described well in the medieval Kerala literature which includes works written in both Malayalam and Sanskrit. The 14th century Sanskrit work \"Sukasandesam\" describes about Kaduthuruthy. Similarly the 17th century Sanskrit work \"Bhramara Sandesam\" contains details about Kumaranalloor and Vaikom. The 18th century Sanskrit literary work \"Chathaka Sandesam\" also contains references to Vaikom.\n\"Unnuneeli Sandesam\", a work which belongs to the Malayalam literature written during early decades of the 14th century CE, contains a short geographical and political description of the regions and the medieval feudal states that lied between Kaduthuruthy and Thiruvananthapuram. It contains details about the medieval kingdoms of Thekkumkur (1102\u20131749) and Vadakkumkur (1102\u20131750) those together constitute the modern district of Kottayam.\nThe writings and the records of the Portuguese as well as the Dutch, who visited and interfered in the political affairs of the district after the Age of Discovery (1498 CE), such as the \"Hortus Malabaricus\", contain significant information about the geographical and the political conditions of the region during the late medieval period.\nThe Chera Perumals of Mahodayapuram (800 \u2013 1102 CE).\nThe area included in the modern-day district of Kottayam was part of three \"Nadus\" (provinces) during the period of the Chera Perumals of Mahodayapuram (800\u20131102 CE) for nearly three centuries. The region around the city of Kottayam was known as \"Munjunadu\", while the Vaikom-Meenachil region, which lies to the north of \"Munjunadu\" was included in a province called \"Vempolinadu\" (known as \"Bimbali Desam\" in Sanskrit). The third province was the \"Nantuzhainadu\" which constitutes the modern-day Taluks of Changanassery and Thiruvalla. This period saw the decline of Buddhism and Jainism, which were once prominent in the region, along with the growth of Hinduism characterised by a large-scale migration of the Nambudiri Brahmins into the region.\nThe territory of the Chera Perumals of Mahodayapuram disintegrated into several small feudal states by early 12th century CE as a result of the continuous war that occurred between the Chera Perumals and the Medieval Cholas throughout the 11th century CE.\nThe Vazhappally copper plate (c. 882/83 CE) is a copper plate inscription written in Old Malayalam language that dates back to the 9th century CE found at Vazhappally in Kottayam district. Recent scholarship puts the date of the plate in c. 882/83 CE. The inscription is engraved on a single copper plate (with five lines on both sides) in an early form of the Old Malayalam language in Vatteluttu script with some Grantha characters. The contents of the plate are incomplete. The inscription was discovered by V. Srinivasa Sastri from \"Thalamana Illam\" near Changanassery. The plate is owned by \"Muvidathu Madom\", Thiruvalla. The record is dated to the twelfth regnal year of Chera Perumal king Rama Rajasekhara (882/83 CE).\nInscriptions related to Rama Kulasekhara (1089\u20131123 CE) of Chera Perumal dynasty can be found at Perunna near Changanassery. The Perunna inscription dates back to the year 1099 CE (the 10th regional year of Rama Kulasekhara).\nThekkumkur dynasty (1102\u20131749 CE).\nThe province \"Vempolinadu\" (\"Bimbali Desam\") of the Chera Perumals of Mahodayapuram attained political autonomy in 1102 CE following the Chera-Chola wars of the 11th century CE. The \"Vempolinadu\" royal family got evolved into two independent branches by the 12th century CE \u2013 the southern branch among them later came to be known as the kingdom of Thekkumkur. It included the modern-day Taluks of Changanassery, Kanjirappally, Kottayam, and Thiruvalla. The kings of the Thekkumkur dynasty are described by the titles \"Bimbaleeshas\" and \"Manikandas\" in the Sanskrit literary works. Vennimala and Manikandapuram were the early headquarters of the Thekkumkur dynasty. Later it was transferred to Thazhathangady near the town of Kottayam. Thazhathangady is one of the places in Kerala where a church, a mosque, and a Hindu temple co-exist together, which points out the religious harmony that existed under the \"Thekkumkur Rajas\". At times, the town of Changanassery acted as headquarters of the Thekkumkur dynasty.\nThe \"Thekkumkur Rajas\" were vassals to the Kingdom of Cochin until the mid-18th century CE. Thekkumkur Rajas also allied with the Kingdom of Cochin and the Kingdom of Odanad (Kayamkulam) against the military invasions of the kingdom of Travancore into its northern kingdoms that occurred during the 1740s. As a result, Anizham Thirunal Marthanda Varma, the architect of the modern Travancore, attacked and annexed the kingdom of Thekkumkur into Travancore in 1749 during the Battle of Changanassery, after his annexation of Kayamkulam in 1746. The Thekkumkur king took refuge in the kingdom of the Zamorin of Calicut following his defeat in the battle.\nVadakkumkur dynasty (1102\u20131750 CE).\nVadakkumkur was the northern branch of the erstwhile province of \"Vempolinadu\" which attained political autonomy in 1102 CE after the collapse of the Chera Perumals of Mahodayapuram. The rulers of this dynasty were also known by the titles \"Bimbaleeshas\" and \"Manikandas\" in the contemporary Sanskrit works just like their Thekkumkur counterparts. The kingdom of Vadakkumkur included the modern-day Taluks of Ettumanoor and Vaikom along with a portion of the Meenachil Taluk. Kaduthuruthy was the earlier headquarters of the Vadakkumkur dynasty which was later transferred into Vaikom. Vadakkumkur was a vassal state of the Kingdom of Cochin until 1750.\nThe Portuguese explorers described Vadakkumkur as \"The Pepper country\" due to the availability and high scale production of good quality pepper there during the 16th century CE. The Dutch Malabar who became an influential power in the territory of Vadakkumkur during the 17th century CE and the first half of the 18th century CE had a trade centre at Vechoor (in Vaikom taluk) in Vadakkumkur. The Kingdom of \"Kizhmalanadu\" (1102\u20131600), which had included the modern-day Taluks of Muvattupuzha and Thodupuzha with its headquarters at Karikode near Thodupuzha, merged with the kingdom of Vadakkumkur around 1600 CE.\nVadakkumkur Raja was also a part of the combined military alliance formed by the kingdoms of Odanad (Kayamkulam), Thekkumkur, and Cochin against the expansion of Travancore into the northern territories. As a result, Anizham Thirunal Marthanda Varma, the architect of the modern Travancore, attacked and annexed Vadakkumkur in 1750. The Vadakkumkur Raja sought asylum in the kingdom of the Zamorin of Calicut. Later he returned back into Travancore.\nPoonjar dynasty (1160\u20131750 CE).\nIn \u00a0CE, Kulothunga Chola, who belonged to the lineage of the Medieval Cholas, entered into a war with Manavikrama Kulasekhara Perumal, who belonged to the Pandya dynasty of Madurai. Upon the failure in the battle, Manavikrama appointed his brother Maravarman Sreevallabha as the monarch of the Pandya dynasty and left Madurai with his family and some of his trusted servants. Manavikrama crossed the Western Ghats and sought political asylum in Kerala. Manavikrama purchased a vast tract of land bordering the Pandyan territories, from the ruler of Thekkumkur which comprised the Meenachil taluk the regions of Poonjar, Erattupeta, Pala, Patthanamthitta, Thodupuzha, etc. along with the High Range region of modern-day Idukki district in 1160 CE, which originally belonged to the Thekkumkur Rajas. This incident commenced the beginning of the Poonjar dynasty. They were a sovereign state. Though disputed, the territory of Poonjar was claimed by the Kingdom of Travancore in 1899 AD. Travancore claimed that the sovereignty reverted to them following the annexation of the principalities of Thekkumkur and Vadakkumkur in 1749\u20131750. The land ownership was not disputed.\nThe Kannan Devan Hills on the High Range region were given on lease on 11 July 1877 by the ruler of the Poonjar dynasty to John Daniel Munroe from London and for tea plantations. The land and the plantations were later resumed by the Government of Kerala through the Kannan Devan Hills (Resumption Of Lands) Act, 1971. However, the act only addressed the issue of sovereignty which was taken over by the State of Kerala with the accession of Travancore to the Union of India. The ownership of the Kannan Devan plantation (125000 acres)leased to John Monroe, and subsequently transferred to Tata Finlay, and finally to Tata Tea was not relinquished by the Poonjar royal family. This was established by a court challenge to the status, which was resolved by a Kerala High Court order in the early 1990s. The order was in favor of the Poonjar royal family establishing ownership. The lease terms are currently being fulfilled with regards to lease payments as per the original deed.\nProgress and Social Reformation during the Travancore era (1750\u20131947).\nEntire portion of the modern-day district of Kottayam became part of the erstwhile British princely state of Travancore by 1750 CE. This era marked considerable progress and social reformation in all spheres.\nThe Church Mission Society press at Kottayam was established in 1821 by Rev. Benjamin Baily, a British missionary, as the first printing press in Kerala. They had also established the CMS College Kottayam in 1815 as the first Western style institute of higher education in India. The region progressed much in its literacy rate by the end of the 19th century CE. It became one of the most literate regions in the British Indian Empire by 1860. Due to its remarkable progress in the fields of literacy, education, and printing, many early newspapers and magazines in Malayalam such as \"Deepika\" (1887) and \"Malayala Manorama\" (1888) were established in Kottayam.\nThe same period also saw the commencement of Kerala reformation movement with an aim to eradicate the Untouchability, inequality, and the irrational practices existed in the Kerala society for many centuries which ultimately led to the movements like the Vaikom Satyagraha (1924). Kottayam has been involved in a number of political movements, including the 'Malayali Memorial' movement. The goal of the movement was to seek more representation for Malayalis in the Travancore civil service irrespective of their caste and religion.\nVaikom Satyagraha, a protest against caste discrimination, took place in Kottayam district in 1924. The district also participated in the protests for responsible government in Travancore, which ended with the overthrow of Sir C. P. Ramaswami Iyer, who was the Divan of the British princely state of Travancore in 1947.\nDuring the Travancorean administration, the British princely state of Travancore was divided into four revenue divisions- the Northern division headquartered at Kottayam, the Central division headquartered at Kollam, the Southern division headquartered at Thiruvananthapuram, and the High Range division with its headquarters at Devikulam.\nKottayam was the headquarters of the northernmost revenue division in Travancore which included the Taluks of North Paravur, Kunnathunad, Muvattupuzha, Thodupuzha, Meenachil, Changanassery, Kottayam, Vaikom, and Cherthala in 1931.\nPost-independence (1947\u2013present).\nAt the time of the integration of the state of Travancore and Cochin into the state of Travancore-Cochin in 1949 following the integration of the British Princely states of Travancore and Cochin into the Dominion of India, the erstwhile revenue divisions were reorganised into districts and the Divan Peshkars gave way to district collectors, paving the way for the birth of the Kottayam district on 1 July 1949.\nThe erstwhile Kingdom of Cochin was reorganized into Thrissur district and Taluks of North Paravur and Kunnathunad were transferred to that district. Similarly the Cherthala Taluk was transferred into the newly formed Kollam district on 1 July 1949. The High Range division of the erstwhile Travancore was merged with the remaining Taluks of the erstwhile Kottayam division to form the Kottayam district as a part of the inauguration of the new Indian state of Travancore-Cochin on 1 July 1949. The new district of Kottayam at that time contained eight Taluks \u2013 Changanassery, Kottayam, Vaikom, Meenachil, Muvattupuzha, Thodupuzha, Devikulam, and Peerumede.\nAs a part of the formation of the new Indian state of Kerala according to the States Reorganisation Act, 1956, many jurisdictional changes were done in the district. Two new Taluks, namely Kanjirappally (from Changanassery and Thiruvalla) and Udumbanchola (from Devikulam and Peerumede) were carved out on 1 October 1956. After a month, a new Taluk called Kuttanad was carved out from Changanassery and Ambalappuzha. The Kuttanad Taluk was transferred into the newly formed Alappuzha district on 17 August 1957. The Taluks of Thodupuzha and Muvattupuzha were transferred into the newly formed Ernakulam district on 1 April 1958.\nOn 26 January 1972, the three High Range Taluks, namely Devikulam, Udumbanchola, and Peerumede, along with Thodupuzha from the Ernakulam district were separated from Kottayam district to form a new district called Idukki. The district of Kottayam took its current shape on 26 January 1972. Now it contains five Taluks- Changanassery, Kottayam, Vaikom, Meenachil, and Kanjirappally.\nThe municipality of Kottayam was declared as the first town in India to achieve 100% literacy in 1989. The Multidimensional Poverty Index prepared by NITI Aayog based on the National Family Health Survey 2015\u201316 declared Kottayam as the first Indian district to achieve zero multidimensional poverty rate.\nClimate.\nThere are no distinct seasons in Kottayam, as it has a tropical climate like that of the rest of Kerala. Humidity is high and rises to about 90% during the rainy season. Kottayam gets rain from two monsoon seasons, the south-west monsoon and the north-east monsoon, and accumulates an average rainfall of around 3600\u00a0mm per year. The south-west monsoon starts in June and ends in September, and the north-east monsoon season is from October to November. Pre-monsoon rains from March to May are accompanied by thunder and lightning; the highest rainfall during this period in Kerala is received in Kottayam. December, January, and February are cooler, while March, April, and May are warmer. The highest temperature recorded in Kottayam was 38.5\u00a0\u00b0C on 6 April 1998, and the lowest was 15\u00a0\u00b0C on 13 December 2000.\nThe Kottayam district experienced intense red rainfall in 2001, during which the rain was colored red, yellow, green, and black.\nTourism and wildlife.\nKottayam has a network of rivers, backwaters, ancient religious places, and hill stations. Local tourist places include:\nMalarikkal and Panachikkad in Kottayam is famous for Ambal fest.\nTransport.\nKottayam is linked by major roads and rail to other prominent cities in Kerala, and also by waterways allowing for waterborne travel. The Kottayam Kumali, Ettumanoor-Ernakulam, Kottayam-Pathanamthitta, Thiruvalla-Kidangoor Central Kerala Bypass, and MC road are the major roads in the district. The nearest airport is the Cochin International Airport. SWTD operates ferry services from different parts of the Kottayam district. The ferry service from Vaikom to Thavanakkadavu in the Alappuzha district is the longest. India's first solar ferry service boat, 'Adhithya', operates from Vaikom.\nAdministration.\nKottayam city is the administrative headquarters of the Kottayam district. The district is divided into two revenue divisions- Kottayam and Pala.\nMunicipal towns.\nThere are 6 municipal towns in the district. They are:\nLegislative representation.\nThere are three Lok Sabha constituencies in Kottayam district: Kottayam (6 assembly constituencies), Pathanamthitta (2 assembly constituencies, i.e., Kanjirappally and Poonjar) and Mavelikara (1 assembly constituency, \ni.e., Changanassery).\nThere are nine Kerala Legislative Assembly seats in Kottayam district.\nTaluks.\nThe district is divided into two revenue divisions which together incorporate five Taluks within them.\nRevenue villages.\nKottayam district is divided into 100 revenue villages for the ease and decentralisation of its revenue administration. They are further incorporated into 5 taluks as eludicated below.\nChanganassery Taluk.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nKanjirappally Taluk.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nKottayam Taluk.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nMeenachil Taluk.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nVaikom Taluk.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nMajor Towns.\nThe major towns of the district include:\nEconomy.\nAgriculture.\nKottayam has a mountainous terrain as well as low-lying areas very close to sea level. Depending on the location, different varieties of food and cash crops are cultivated. Rice is the principal crop extensively cultivated in low-lying regions like Vaikom and Upper Kuttanad. The district occupies third place in the production of rice in Kerala behind Palakkad and Alappuzha.\nAlthough it is the staple food of the people, the area under cultivation is dwindling due to more lucrative cash crops such as rubber plantations for which Kottayam significantly contributes to the overall rubber production in India. Kottayam is India's largest rubber producer. Rubber trees provide a stable income for farmers and the climate is ideal for rubber plantations. Though the highlands are more suitable, cultivation has spread to almost all regions. Other crops cultivated include tapiocas, coconuts, peppers, and vegetables. To enhance rubber productivity, the government of India has set up a Rubber Board as well as a rubber research institute in Kottayam.\nIndustry.\nThe district lacks refineries, ports, and an airport, which are needed for major industries.Aside from two public sector companies, Hindustan Newsprint at Velloor and Travancore Cements at Nattakom, industries in the district consist mostly of small and medium-size operations. These mainly include the publishing and processing of rubber or latex, and manufacturing of rubber-based products.\nConfined mostly to the Vaikom area of the district is an industry of coir processing and making coir products. Consisting of more than twenty cooperatives, it employs around 20,000 people. In the hand-loom sector, eight cooperative societies employ 2,100 persons. The district's forests include varieties of softwood and other varieties of timber providing the raw material for several small enterprises in the production of plywood, packing cases, splints, veneers, and furniture.\nThe first printing press in Kerala, C.M.S. Press, was established in 1821 by Rev. Benjamin Bailey, a British missionary. Malayalam-English and English-Malayalam dictionaries were published in Kottayam in 1846 and 1847. The only cooperative society of writers, authors and publishers (SPCS) for publishing books and periodicals was established in 1945. Kottayam is home to a number of books and periodicals, and is the center of publishing business in the state.\nPublishing houses like Malayala Manorama, Mathrubhumi publications, Labour India Publications Ltd, Mangalam Publications, Deepika, D. C. Books, V Publishers, Vidhyamitram, \"Kerala Kaumudi\" daily and Kerala Kaumudi Flash are also publishers in the district. The city of Kottayam hosts several book exhibitions every year.\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nAccording to the 2011 census Kottayam district has a population of 1,974,551, roughly equal to the nation of Slovenia or the US state of New Mexico. This gives it a ranking of 234th in India (out of a total of 640). The district has a population density of . Its population growth rate over the decade 2001\u201311 was 1.32%. Kottayam has a sex ratio of 1040 females for every 1000 males, and a literacy rate of 97.21%, the highest in the state and 4th highest in India. 28.63% of the population lives in urban areas. Scheduled Castes and Scheduled Tribes make up 7.79% and 1.11% of the population respectively.\nMalayalam is the predominant language, spoken by 98.88% of the population. Tamil is spoken by a small minority in urban areas.\nReligion.\nAccording to the 2011 Indian Census, Hinduism (49.81%) is the largest religion in Kottayam, with a significant Christian minority (43.48%). Syro-Malabar, Orthodox, Jacobites and Pentecostals are the main Christian sects. The Muslim population constitutes 6.41% of the district.\nThe three major religious communities in the Kottayam district are Hinduism, Christianity, and Islam. The Nair Service Society's headquarters are located in the district's town of Perunna, Changanassery. The Mannam memorial, created in memory of social reformer Mannathu Padmanabha Pillai, is also located there.\nThe headquarters of the Malankara Orthodox Syrian Church (Malankara Church/Indian Orthodox Church), is located in Devalokam, Kottayam. It is the official headquarters of the Malankara Metropolitan and the Catholicos of the East.\nThe Madhya Kerala Diocese of the Church of South India has its headquarters in Kottayam.\nThe Knanaya Christian community (both the Catholic and Jacobite factions) also has its headquarters in Kottayam district.\nThe Thazhathangady Juma Mosque, which is one of the oldest \"Masjids\" in the country, is also located at Kottayam.\nKottayam, Thiruvalla, and Chengannur are the railway stations for pilgrims heading to the Hindu holy site of Sabarimala.\nThe pilgrim centers in Kottayam include a number of Hindu temples, Christian churches and Muslim mosques, including:\nEducation.\nIn the 17th century, a Dutch school was started at Kottayam, which was short-lived. The first English school in Kerala, and the first college in India, was established in 1817 by the Church Missionary Society of England under the leadership of Col. John Munro, as CMS College. Later in 1891, the clergies of Catholic Church, under the leadership of Fr Charles Lavigne, established St Berchmans English High School, Changanassery, one of the first residential English High School in Central Travancore. On seeing a need for instituition for higher education in Kottayam - Malabar region, under the leadership of Venerable Mar Thomas Kurialacherry, Bishop of Archeparchy of Changanassery with help of Syro Malabar Catholic Church, established the famous SB College in Changanasserry in 1922. Today CMS College Kottayam and SB College Changanasserry stands as a landmark and has made a huge contribution to education in the district. Thus, Kottayam became India's first district with 100% literacy in 1989.\nNotable educational institutions in the district include:-\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56145", "revid": "125972", "url": "https://en.wikipedia.org/wiki?curid=56145", "title": "Kozhikode", "text": "Metropolis in Kerala, India\nKozhikode (), also known as Calicut, is a city along the Malabar Coast in the state of Kerala in India. The city is also known as the City of Spices.\nIt is the nineteenth largest urban agglomeration in the country and the second largest one in Kerala. Calicut city is the second largest city proper in the state with a population of 609,224 within its municipal boundaries. Calicut is classified as a Tier-2 city by the Government of India.\nIt is the largest city on the Malabar Coast and was the capital of the British-era Malabar district. It was the capital of an independent kingdom ruled by the Samoothiris (Zamorins). The port at Kozhikode acted as the gateway to the medieval South Indian coast for the Chinese, the Persians, the Arabs, and finally the Europeans. In 2023, Kozhikode was recognised by UNESCO as India's first City of Literature.\nEtymology.\nThe exact origin of the name Kozhikode is uncertain. According to many sources, the name Kozhikode is derived from \"Koyil-kota\", meaning \"fortified palace\". \"Koil\" or \"Koyil\" or \"Kovil\" is the Malayalam/Tamil term for a Hindu temple. In the context of Kozhikide, it may refer to the Tali Shiva Temple. Both the terms \"k\u014dyil\" and \"k\u014dvil\" are used interchangeably. The Tamil name of the city is Ka\u1e37\u1e37ikk\u014d\u1e6d\u1e6dai.\nThe name evolved into \"Kolikod\", or its Arabic form \"Q\u0101liq\u016b\u1e6d\" (IPA: q\u02e0a\u02d0liq\u02e0\u02d0u\u02d0t\u02e4) and later its anglicised version Calicut. Chinese merchants called it \"K\u016blifo\".\nThe word \"calico\", a fine hand-woven cotton fabric that was exported from the port of Kozhikode, is believed to be derived from \"Calicut\".\nHistory.\nThe ancient port of Tyndis, located north of Muziris as mentioned in the \"Periplus of the Erythraean Sea\", is believed to have been near Kozhikode. Its exact location is a matter of dispute. The suggested locations are Ponnani, Tanur, Beypore-Chaliyam-Kadalundi-Vallikkunnu, and Koyilandy. Tyndis was a major center of trade, second only to Muziris, between the Cheras and the Roman Empire. Pliny the Elder (1st century CE) states that the port of \"Tyndis\" was located at the northwestern border of \"Keprobotos\" (Chera dynasty). The North Malabar region, which lies north of the port at \"Tyndis\", was ruled by the kingdom of Ezhimala during Sangam period. According to the \"Periplus of the Erythraean Sea\", a region known as \"Limyrike\" began at \"Naura\" and \"Tyndis\". However Ptolemy mentions only \"Tyndis\" as \"Limyrike\"'s starting point. The region probably ended at Kanyakumari; it thus roughly corresponds to the present-day Malabar Coast. The value of Rome's annual trade with the region was estimated at around 50,000,000 sesterces. Pliny the Elder mentioned that \"Limyrike\" was prone to piracy. The Cosmas Indicopleustes mentioned that the \"Limyrike\" was a source of peppers.\nIn the 14th century, Kozhikode conquered large parts of central Kerala after the seizure of the Tirunavaya region from Valluvanad, which was under the control of the king of \"Perumbadappu Swaroopam\" (Cochin). The ruler of Perumpadappu was forced to shift his capital (c. CE 1405) further south from Kodungallur to Kochi. In the 15th century, the status of Cochin was reduced to a vassal state of Kozhikode, thus leading to the emergence of Kozhikode as the most powerful kingdom in medieval Malabar Coast. During the 15th century, Kalaripayattu played a significant role in Malabar's history. Notable warriors included Puthooram Veettil Aromal Chekavar and his sister Unniyarcha.\nThe port at Kozhikode held a superior economic and political position along the medieval Kerala coast, while Kannur, Kollam, and Kochi were commercially important secondary ports where traders from various parts of the world gathered. In the 15th century, Kozhikode was visited several times by ships from China, which became known as Ming treasure voyages.\nKozhikode was the capital of an independent kingdom ruled by the samoothiris (Zamorins) in the Middle Ages and later of the erstwhile Malabar District under British rule. Arab merchants traded with the region as early as 7th century, and Portuguese explorer Vasco da Gama landed at Kozhikode on 20 May 1498, opening a trade route between Europe and India. A Portuguese factory and a fort existed in Kozhikode for a short period (1511\u20131525, until the Fall of Calicut). The English landed in 1615 (constructing a trading post in 1665), followed by the French (1698) and the Dutch (1752). In 1765, Mysore captured Kozhikode as part of its occupation of the Malabar Coast.\nEarly Kozhikode in foreign accounts.\nAccounts of the city and the conditions prevailing then can be gleaned from the chronicles of travellers who visited the port city.\nIbn Battuta (1342\u20131347), who visited six times, gives the earliest glimpses of life in the city. He describes Kozhikode as \"one of the great ports of the district of Malabar\" where \"merchants of all parts of the world are found here\". The king of this place, he says, \"is an infidel, who shaves his chin just as the Haidari Fakeers of Room do... The greater part of the Muslim merchants of this place are so wealthy that one of them can purchase the whole freightage of such vessels put here and fit out others like them\".\nMa Huan (1403), a Chinese sailor who was part of the Imperial Chinese fleet under Cheng Ho (Zheng He) lauds the city as a great emporium of trade frequented by merchants from around the world. He makes note of the 20 or 30 mosques built to cater to the religious needs of the Muslims, the unique system of calculation by the merchants using their fingers and toes (followed to this day) and the matrilineal system of succession.\nAbdur Razzak (1442\u20131443), the ambassador of Persian Emperor Shah Rukh found the city's harbour perfectly secured and notices precious articles from several maritime countries, especially from Abyssinia, Zirbad and Zanzibar.\nThe Italian Niccol\u00f2 de' Conti (1445), one of the earliest known Christian travellers to document Kozhikode, describes the city as abounding in pepper, lac, ginger, a larger kind of cinnamon, myrobalans and zedoary. He calls it a noble emporium for all India, with a circumference of .\nThe Russian traveller Athanasius Nikitin or Afanasy Nikitin (1468\u20131474) calls 'Calecut' a port for the whole Indian sea and describes it as having a \"big bazaar.\"\nOther travellers who visited Kozhikode include the Italian Ludovico di Varthema (1503\u20131508) and Duarte Barbosa.\nZamorins of Calicut.\nKozhikode and its suburbs formed part of the \"Polanad\" kingdom, a vassal state of the \"Kolathunadu\" of North Malabar, ruled by the \"Porlathiri\". The Eradis of Nediyiruppu, based in Kondotty (Eranad, Malappuram district), wanted an outlet to the sea to initiate trade and commerce with distant lands. After a prolonged conflict with the Polathiri lasting 48 years, they conquered the area around Panniankara. Following this, Menokki became the ruler of \"Polanad\" and came to terms with the local troops and people.\nSubsequently, the town of Kozhikode was founded close to the palace at Tali. The Eradis then shifted their headquarters from Nediyiruppu to Kozhikode. The Governor of Ernad built a fort at Velapuram to safeguard their new territory. The fort most likely lent its name to \"Koyil Kotta,\" the precursor to Kozhikode. The city thus came into existence sometime in the 13th century.\nAs the status of the Udaiyavar (king) increased, he became known as Swami Nambiyathiri Thirumulpad, eventually assuming the title Samuri or Samoothiri. European traders referred to this title in a corrupted form as Zamorin.\nAt the peak of their power, the Zamorins ruled over a region from Kollam (Quilon) to Panthalayini Kollam (Koyilandy). Following the discovery of the sea route from Europe to Kozhikode in 1498, the Portuguese began to expand their territories and ruled the seas between Ormus and the Malabar Coast, and as far south as Ceylon. Some prominent Jenmis in Kozhikode were engaged in sea trade and shipping as early as two centuries ago.\nAccording to historian K.V. Krishna Iyer, Kozhikode's rise was both a cause and a consequence of Zamorin's ascendancy in Kerala. By the late 15th century, the Zamorin was at the zenith of his power, with all princes and chieftains of Kerala north of Kochi acknowledging his suzerainty. The Sweetmeat Street (\"Mittayi Theruvu\") was an important trading street under Zamorin's rule.\nThe First Battle of Cannanore in January 1502, fought between the Third Portuguese Armada allied with the Kingdom of Cochin under Jo\u00e3o da Nova and Zamorin of Calicut's navy, marked the beginning of Portuguese conflicts in the Indian Ocean. The defeat of the joint fleet of the Sultan of Gujarat Mahmud Begada, the Maml\u00fbk Burji Sultanate of Egypt, and the Zamorin of Calicut with support from the Republic of Venice and the Ottoman Empire in the Battle of Diu in February 1509 marked the beginning of Portuguese dominance over the spice trade and the Indian Ocean.\nThroughout the 16th century, continuous naval conflicts between the Zamorin's navy, led by Kunjali Marakkar (Fleet Admiral) and the Portuguese significantly reduced the importance of Kozhikode as a centre of trade. Kunjali Marakkar is credited with organizing the first naval defense of the Indian coast.\nBy the early 17th century, the Zamorin expelled the Portuguese with the help of the Dutch East India Company. In 1602, the Zamorin sent envoys to Aceh, promising the Dutch a fort at Kozhikode in exchange for their support in trade. Two factors, Hans de Wolff and Lafer, were sent from Aceh, but the two were captured by the chief of Tanur, and handed over to the Portuguese.\nIn November 1604, a Dutch fleet under Admiral Steven van der Hagen arrived in Kozhikode, marking the beginning of the Dutch presence in Kerala. On 11 November 1604, the Dutch East India Company signed its first treaty with an Indian ruler, forming an alliance with Kozhikode to expel the Portuguese from Malabar. In return, the Dutch were granted trading rights in Kozhikode and Ponnani, including spacious storehouses. By this time, however, the kingdom and port of Kozhikode had lost much of their former prominence.\nBritish Rule.\nThe arrival of the English in Kerala is documented in the year 1615, when a group under the leadership of Captain William Keeling arrived at Kozhikode, aboard three ships. It was in these ships that Sir Thomas Roe went to visit Jahangir, the fourth Mughal emperor, as an English envoy. In 1755, Travancore became the most dominant state in Kerala by defeating the Zamorin of Kozhikode in the battle of Purakkad. In the late 18th century, Kozhikode came under British rule after the Mysorean conquest of Malabar. The British later formed the Thiyyar Regiment to fulfill their military commitments in Malabar.\nKozhikode was the administrative capital of the Malabar District, one of the two districts on the western coast (Malabar Coast) of the Madras presidency. During British rule, Malabar's importance lay in the production of pepper, coconut, tiles, and teak. Kozhikode municipality was formed on 1 November 1866 according to the Madras Act 10 of 1865 (Amendment of the Improvements in Towns act 1850).\nPost Independence.\nKozhikode Municipality was upgraded into Kozhikode Municipal Corporation in 1962, making it the second-oldest Municipal Corporation in the state.\nClimate.\nKozhikode has a tropical monsoon climate (K\u00f6ppen climate classification \"Am\"). A brief spell of pre-monsoon mango showers occurs in April. The primary source of rainfall is the southwest monsoon which begins in early June and lasts until September. The city also receives significant precipitation from the northeast monsoon, which begins in mid-October and continues through November. Winters (December\u2013February) are warmer than summers (June\u2013August), with spring (March\u2013May) being the hottest season.\nDemographics.\nThe total population within the Kozhikode Municipal Corporation limits is 550,440. Males account for 47.7% of the population, while females make up 52.3%.\nKozhikode has been a multi-ethnic and multi-religious town since the early medieval period. The Hindus form the largest religious group, followed by Muslims and Christians. Hindus form the majority at 57.37%(315,807 people), while Muslims form 37.66% (207,298 people).\nKozhikode Municipal Corporation has an average literacy rate of 96.8% (national average is 74.85%). The male literacy rate is 97.93% and female literacy rate is 95.78%.\nHistorically, Kozhikode has been home to diverse communities and regional groups. Many of these communities continued their traditional occupations and customs until the 20th century. Brahmins primarily resided near Hindu temples in the city. Regional groups such as Tamil Brahmins, Gujaratis, and Marwari Jains settled in the city, residing near their shrines.\nThe Nairs formed the rulers, warriors and landed gentry of Kozhikode. The Samoothiri had a ten thousand strong Nair bodyguard called the Kozhikkottu pathinaayiram (The 10,000 of Kozhikode) who defended the capital and supported the administration within the city. He had a larger force of 30,000 Nairs in his capacity as the Prince of Eranadu, called the Kozhikkottu Muppatinaayiram (The 30,000 of Kozhikode). The Nairs also formed the members of the suicide squad (chaver). The Thiyyar formed the \"vaidyars\" (Ayurveda Physicians), local militia, and traders of Kozhikode. The Muslims of Kozhikode are known as Mappilas, and according to the official Kozhikode website \"the great majority of them are Sunnis following the Shafi school of thought. There are some smaller communities among the Muslims such as Dawoodi Bohras of Gujarati origin. Many of the Muslims living in the historic part of the city follow matrilineality and are noted for their piety. Though Christianity is believed to have been introduced in Kerala in the 1st century CE, the size of the community in Malabar (northern Kerala) began to rise only after the arrival of Portuguese missionaries towards the close of the 15th century. A few Christians of Thiruvitankoor and Kochi have lately migrated to the hilly regions of the district and are settled there.\nThe Tamil Brahmins are primarily settled around the Tali Siva temple. They arrived in Kozhikode as dependants of chieftains, working as cooks, cloth merchants and moneylenders. They have retained their Tamil language and dialects as well as caste rituals. The Gujarati community is settled mostly around the Jain temple in and around the Valliyangadi. They owned many establishments, especially textile and sweet shops. They must have arrived in Kozhikode at least from the beginning of the 14th century. They belong to either the Hindu or the Jain community. A few Marwari families are also found in Kozhikode who was basically moneylenders.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nBy language, 97.64% of the population speaks Malayalam and 0.91% Tamil as their first language.\nCivic administration.\nThe city is administered by the Kozhikode Corporation, headed by a mayor. For administrative purposes, the city is divided into 75 wards, from which the members of the corporation council are elected for five years. Recently neighbouring suburbs Beypore, Elathur, Cheruvannur and Nallalam were merged within the municipal corporation.\nKozhikode Corporation is the first City Corporation in Kerala after the creation of the state. Established in 1962, Kozhikode Corporation's first mayor was H Manjunatha Rao. Kozhikode corporation has four assembly constituencies \u2013 Kozhikode North, Kozhikode South, Beypore and Elathur \u2013 all of which are part of Kozhikode.\nLaw and order.\nThe Kozhikode City Police is headed by a commissioner, an Indian Police Service (IPS) officer. The city is divided into six zones each under a circle officer. Apart from regular law and order, the city police comprise the traffic police, bomb squad, dog squad, fingerprint bureau, women's cell, juvenile wing, narcotics cell, riot force, armed reserve camps, district crime records bureau and a women's station. It operates 16 police stations functioning under the Home Ministry of Government of Kerala.\nTransport.\nRoad.\nNational highways.\nNational Highway 66 connects Kozhikode to Mumbai via Mangaluru, Udupi and Goa to the north and Kochi and Kanyakumari near Thiruvananthapuram to the south along the west coast of India. This highway connects the city with the other important towns like, Kasaragod, Kanhangad, Kannur, Thalassery, Mahe, Vadakara, Koyilandy\nRamanattukara, Kottakkal, Valanchery, Kuttippuram, Ponnani, Kodungallur, North Paravur, Ernakulam, Edapally and proceeds to Alappuzha, Thiruvananthapuram and terminates at the southern tip of India, Kanyakumari.\nNational Highway 766 connects Kozhikode to Bangalore through Kollegal in Karnataka via Tirumakudal Narsipur, Mysore, Nanjangud, Gundlupet, Sulthan Bathery, Kalpetta and Thamarassery.\nNational Highway 966 connects Kozhikode to Palakkad through Malappuram and Perinthalmanna. It covers a distance of . At Ramanattukara, a suburb of Kozhikode, it joins NH 66. It passes through major towns like Kondotty, Perinthalmanna, and Mannarkkad and Malappuram. This stretch connects the city and Calicut International Airport.\nState Highways.\nSH 29 passes through the city. It connects NH 766, Malabar Christian College, civil station, Kunnamangalam, Koduvally, Thamarassery, Chellot, Chitragiri and Road to Gudallor from Kerala border.\nState highway 38 starts from Pavangad near passes through Ulliyeri, Perambra, Kuttiady, Nadapuram, Panoor and Koothuparamba and ends at Chovva in Kannur. The highway is107;km long. It is one of the busiest route in the district.\nSH 54 connects the city to Kalpetta. The highway is long. The highway passes through Pavangad, Kozhikode, Ulliyeri, Perambra, Poozhithodu, Peruvannamuzhi and Padinjarethara.\nSH 68 starts from Kappad and ends in Adivaram. The highway is long.\nSH 34 starts from Koyilandy and ends in Edavanna which is 44.0\u00a0km long. This highway passes through Koyilandi, Ulliyeri, Balussery, Thamarassery, Omassery and Mukkam.\nSH 68 starts from Kappad and ends in Adivaram which is 66\u00a0km long. This highway passes through Atholi, Nanminda, Narikkuni, Koduvally, Omassery, Kodenchery and Thusharagiri.\nBuses.\nBuses, predominantly run by individual owners, ply on the routes within the city and to nearby locations. City buses are painted green. Kerala State Road Transport Corporation (KSRTC) runs regular services to many destinations in the state and to the neighboring states. The city has three bus stands. All private buses to the suburban and nearby towns ply from the Palayam Bus Stand. Private buses to adjoining districts start from the Mofussil Bus Stand on Indira Gandhi Road (Mavoor Road). Buses operated by the KSRTC drive from the KSRTC bus stand on Indira Gandhi Road. KSRTC Bus Stand Kozhikode is the largest bus stand in Kerala having a size of 36,036.47 meter square. There are also KSRTC depots in Thamarassery, Thottilpalam, Thiruvambady and Vatakara.\nThere are three routes available to Bangalore. Kozhikode\u2013Sulthan Bathery-Gundlupet\u2013Mysore\u2013Bangalore is the preferred one and is very busy. Another route is Kozhikode-Manathavady-Kutta-Mysore-Bangalore. The third one, less used, is Kozhikode\u2013Gundlupet\u2013Chamarajanagar\u2013Kollegal\u2013Bangalore.\nPrivate tour operators maintain regular luxury bus services to Mumbai, Bangalore, Coimbatore, Chennai, Vellore, Ernakulam, Trivandrum, Ooty, Mysore, etc. and mainly operate from the Palayam area. These are usually night services.\nRail.\nKozhikode has a main railway station, where all passing trains stops. There are other railway stations within the City limits. They are Elathur, West Hill, Vellayil and Kallai. Only local passenger trains stops in these stations. One can travel to almost all destinations within the country from Kozhikode. The history of railways in Kerala dates to 1861 when the first tracks were laid between Tirur and Beypore.\nAir.\nCalicut International Airport is from the city. It began operations in 1988. Domestic services are operated to major Indian cities. It received the status of an international airport in 2006.\nEconomy.\nKozhikode is one of the largest economic hubs in the Indian state of Kerala, with its economy primarily driven by the service sector, followed by industrial activities. The city has a rich banking history, being the birthplace of Nedungadi Bank, the first and oldest bank in modern Kerala, which was established by Appu Nedungadi in 1899. The bank was later merged with Punjab National Bank.\nInformation Technology and Business Sector\nKozhikode is emerging as a major center for information technology (IT) in Kerala. Cyberpark, a Government of Kerala initiative, was established to build, operate, and manage IT parks in the Malabar region to promote investment in IT and IT-enabled services (ITES). It is set to become the third IT hub in Kerala, following Technopark in Thiruvananthapuram and Infopark in Kochi. The Cyberpark initiative, along with its satellite centers in Kannur and Kasaragod, is expected to generate around 100,000 direct job opportunities.\nOther major IT and business hubs in Kozhikode include UL Cyberpark, which is the first IT SEZ (Special Economic Zone) in the Malabar region, Government Cyberpark, and Hilite Business Park, which houses multiple IT firms and corporate offices.\nIndustrial and Infrastructure Development\nKozhikode is also witnessing significant industrial growth, with key upcoming projects such as:\nBirla IT Park (Mavoor) \u2013 A proposed technology and industrial park.\nMalaysian Satellite City (Kinaloor) \u2013 A large-scale industrial park planned by KINFRA, covering .\nKozhikode Bypass Economic Corridor \u2013 A growing commercial and IT corridor near Cyberpark.\nAdditionally, Beypore Port is undergoing development to enhance maritime trade and cargo handling capabilities.\nCultural Recognition\nIn 2012, Kozhikode was officially recognized as the \"City of Sculptures\" (Shilpa Nagaram) due to the numerous architectural sculptures and artistic landmarks found throughout the city.\nWith its growing IT sector, industrial expansion, and infrastructural improvements, Kozhikode continues to develop as a key economic and technological hub in Kerala.\nCulture.\nAccording to data compiled by economics research firm Indicus Analytics in 2009 on residences, earnings and investments, Kozhikode was ranked the second-best city in India to live in. \nShopping.\nThe city has a strong mercantile tradition, with trade and commerce playing a significant role in its economy. Historically, the primary commercial hub was Valiyangadi (Big Bazaar), located near the railway station. This area served as the center of business activity for decades, catering to wholesale and retail traders. Over time, the commercial focus gradually shifted to other parts of the city, with Mittai Theruvu (Sweetmeat Street or S. M. Street) emerging as the new commercial hub. This bustling street is lined with a variety of shops selling textiles, cosmetics, household essentials, and electronics. It is also home to several well-known restaurants and traditional sweetmeat shops that reflect Kozhikode's rich culinary heritage.\nWith urbanization and the growing influence of modern retail culture, Kozhikode has witnessed the rise of shopping malls that offer a mix of retail outlets, entertainment zones, and dining facilities. Some of the major malls in the city include:\nFocus Mall \u2013 The first shopping mall in Kerala, marking the beginning of modern retail spaces in the state. It features a range of branded outlets, a food court, and entertainment facilities.\nHilite Mall Calicut\u2013 The largest shopping mall in the Malabar region, part of the HiLITE City project. The mall houses over 200 retail stores, including international and domestic brands, a multiplex cinema, a large food court, and dedicated entertainment zones.\nGokulam Mall \u2013 A mid-sized shopping complex featuring multiple retail outlets, dining options, and a multiplex.\nAddress Mall \u2013 A modern shopping destination with luxury brand stores, restaurants, and entertainment facilities.\nRP Mall \u2013 A popular retail and entertainment hub, featuring a mix of branded stores, food courts, and a cinema.\nLulu Mall Kozhikode \u2013 Developed by LuLu Group International, this newly established mall in Mankavu is one of the largest retail projects in the region. It brings a world-class shopping experience with a variety of international brands, hypermarkets, and entertainment facilities.\nThe emergence of these malls has significantly transformed Kozhikode's retail landscape, providing residents and visitors with modern shopping and leisure experiences.\nMusic.\nIn addition to the Malabar Mahotsavam, the annual cultural fest of Kozhikode, every year since 1981 the Tyagaraja Aradhana Trust has been conducting a five-day music festival in honour of Tyagaraja. The festival is complete with the Uncchavritti, rendering of Divyanama kritis, Pancharatna Kritis, concerts by professional artistes and students of music from morning to late in the evening.\nKozhikode has a tradition of Ghazal and Hindustani music appreciation. There are many Malayalam Ghazals. The late film director and play back singer M. S. Baburaj, from Kozhikode was influenced by Ghazal and Hindustani.\nMedia.\nNewspapers.\nNewspaper publishing started in Kozhikode with the launch of the English weekly \"West Coast Spectator\" in 1879. Edited by Dr. Keys and printed by Vakil Poovadan Raman from the Spectator Press, it was rechristened the \"Malabar Spectator\" in later years. The first Malayalam newspaper in Kozhikode was \"Kerala Pathrika\" established by Chengalathu Kunhirama Menon in 1884. \"Keralam\", \"Kerala Sanchari\" and \"Bharathivasam\" were among the other newspapers published in Kozhikode in the 19th century. Some of the major newspapers that contributed to the Indian independence movement \"Mathrubhumi\" and \"Mithavadi\", were based in Kozhikode. Now almost all the major newspapers in Malayalam have editions in Kozhikode. English newspapers such as \"The Hindu\" and \"The New Indian Express\" also have Kozhikode editions.\nRadio.\nThe Kozhikode radio station of All India Radio has two transmitters: Kozhikode AM (100 kilowatts) and Kozhikode FM [Vividh Bharathi] (10 kilowatts). Private FM radio stations are Radio Mango 91.9 operated by Malayala Manorama Co. Ltd. Radio Mirchi operated by Entertainment Network India Ltd. and Club FM 104.8 operated by Mathrubhumi group and Red FM 93.5 of the SUN Network. AIR FM radio stations are Kozhikode \u2013 103.6\u00a0MHz; AIR MW radio station is Kozhikode \u2013 684\u00a0kHz.\nTelevision.\nA television transmitter has been functioning in Kozhikode since 3 July 1984, relaying programmes from Delhi and Thiruvananthapuram Doordarshan. Doordarshan has its broadcasting centre in Kozhikode at Medical College. The Malayalam channels based on Kozhikode are the Shalom Television, Darshana TV and Media One TV. All major channels in Malayalam viz. Manorama News, Asianet, Surya TV, Kairali TV, Amrita TV, Jeevan TV, and Jaihind have their studios and news bureaus in the city.\nSatellite television services are available through DD Direct+, Dish TV, Sun Direct DTH and Tata Sky. Asianet Digital TV is popularly known as ACV telecasts daily city news. Spidernet is another local channel. Other local operators include KCL and Citinet.\nThe Calicut Press Club came into existence in 1970. It is the nerve centre of all media activities, both print and electronic. Begun with around 70 members in the roll, this Press Club, became a prestigious and alert media centre in the state with a present membership of over 280.\nEducation.\nThere are 1,237 schools in Kozhikode district including 191 highschools.\nKozhikode is home to two premier educational institutions of national importance: the Indian Institute of Management Kozhikode (IIMK), and the National Institute of Technology Calicut (NITC). Other research institutions located in Kozhikode include National Institute for Research and Development in Defence Shipbuilding (NIRDESH), Indian Institute of Spices Research (IISR), Centre for Water Resources Development and Management (CWRDM) and National Institute of Electronics and Information Technology (NIELIT).\nThe University of Calicut is the largest university in Kerala and is located in Thenjipalam, about south of Calicut. This university was established in 1968 and was the second university set up in Kerala. Most of the colleges offering tertiary education in the region are affiliated to this university. The Calicut Medical College was established in 1957 as the second medical college in Kerala. Since then, the institution has grown into a premier centre of medical education in the state. Presently it is the largest medical institute in the state with a yearly intake of 250 candidates for the undergraduate programme.\nThe Government Law College, Kozhikode situated in Vellimadukunnu on the out skirts of kozhikode town, is owned by the Government of Kerala and affiliated to the University of Calicut. The college caters to the needs of the north Malabar region of Kerala it is the third law college in kerala state founded in 1970.\nMain colleges in calicut city:\nZamurians Guruvayoorappan College, Malabar Christian college, Farook College, Devagiri College, Providence college for women, Govt. Arts &amp; science college, Meenchantha, Kerala Government Polytechnic College, West Hill, Government Engineering College Kozhikode.\nSports.\nThe city of Kozhikode is home to many popular professional sports teams. The most popular sport is football (Gokulam Kerala club \u2013 I-League Champion in 2020\u201321 and 2021\u201322), followed by volleyball (Calicut Heroes \u2013 2024 Champion).\nTwin/sister cities.\nCalicut's sister city or twin city is\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56148", "revid": "50052465", "url": "https://en.wikipedia.org/wiki?curid=56148", "title": "Taranto", "text": "Taranto (; ), historically also called Tarent in English, is a coastal city in Apulia, Southern Italy. It is the capital of the province of Taranto, serving as an important commercial port as well as the main Italian naval base. With a population of 185,909 as of 2025, Taranto is the second-largest city in Apulia.\nFounded by Spartans in the 8th century BC during the period of Greek colonisation, Taranto was among the most important \"poleis\" in Magna Graecia, becoming a cultural, economic and military power that gave birth to philosophers, strategists, writers and athletes such as Archytas, Aristoxenus, Livius Andronicus, Heracleides, Iccus, Cleinias, Leonidas, Lysis and Sosibius. By 500 BC, the city was among the largest in the world, with a population estimated up to 300,000 people. The seven-year rule of Archytas marked the apex of its development and recognition of its hegemony over other Greek colonies of southern Italy.\nDuring the Norman period, it became the capital of the Principality of Taranto, which covered almost all of the heel of Apulia.\nTaranto is now the third-largest continental city in southern Italy (south of Rome, roughly the southern half of the Italian peninsula), with well-developed steel and iron foundries, oil refineries, chemical works, naval shipyards and food-processing factories. Taranto will host the 2026 Mediterranean Games.\nThe islets of \"S. Pietro\" and \"S. Paolo\" (St. Peter and St. Paul), collectively known as Cheradi Islands, protect the bay, called \"Mar Grande\" (\"Big Sea\"), where the commercial port is located. Taranto is known for the large population of dolphins and other cetaceans living near these islands. Another bay, called \"Mar Piccolo\" (\"Little Sea\"), is formed by the peninsula of the old city and has flourishing fishing.\nEtymology.\nThe Greek colonists from Sparta called the city Taras (, ) after the mythical hero Taras, while the Romans, who connected the city to Rome with an extension of the Appian Way, called it Tarentum.\nHistory.\nTaranto was founded in 706 BC by Dorian Greek immigrants hailing from Sparta. Its origin is peculiar: the founders were Partheniae (\"sons of virgins\"), sons of unmarried Spartan women and \"Perioeci\" (free men, but not citizens of Sparta); these out-of-wedlock unions were permitted extraordinarily by the Spartans to increase the prospective number of soldiers (only the citizens of Sparta could become soldiers) during the bloody Messenian Wars, but later they were retroactively nullified, and the sons were then obliged to leave Greece forever. Phalanthus, the Parthenian leader and founder (Oikistes), went to Delphi to consult the oracle: the puzzling answer designated the harbour of Taranto as the new home of the exiles. The Partheniae arrived in Apulia, and founded the city, naming it \"Taras\" after the son of the Greek sea god, Poseidon, and of a local nymph, According to other sources, Heracles founded the city. Another tradition indicates Taras as the founder of the city; the symbol of the Greek city (as well as of the modern city) depicts the legend of Taras being saved from a shipwreck by riding a dolphin that was sent to him by Poseidon. Taranto increased its power, becoming a commercial power and a sovereign city of Magna Graecia.\nPolitically and militarily, Archytas appeared to have been the dominant figure in Tarentum in the first half of the 4th century, somewhat comparable to Pericles in Athens a half-century earlier. The Tarentines elected him \"strategos\" (\"general\") seven years in a row, a step that required them to violate their own rule against successive appointments. Archytas was allegedly undefeated as a general in Tarentine campaigns against their southern Italian neighbors.\nIn 303, Sparta sent Cleonymus, the brother of king Areus I, commanding mercenary armies with official support in order to help Tarentum against Lucanians and the Roman Republic. Tarentum's power and independence came to an end as the Romans expanded throughout Italy. Taranto fought against Rome for the control of Southern Italy: it was helped by Pyrrhus, Molossian king of Greek Epirus, who surprised Rome with the use of war elephants in battle of Heraclea, a thing never seen before by the Romans. After the Pyrrhic victory at the battle of Asculum they lost the battle of Beneventum in 275 BC. Tarentum surrendered to Rome after the death of Pyrrhus in Peloponnese in 272 BC. This subsequently cut off Taranto from the centre of Mediterranean trade, by connecting the Via Appia directly to the port of Brundisium (Brindisi).\nAncient art.\nLike many Greek city states, Taras issued its own coins in the 5th and 4th centuries BC. The denomination was a Nomos, a die-cast silver coin whose weight, size and purity were controlled by the state. The highly artistic coins presented the symbol of the city, Taras being saved by a dolphin, with the reverse side showing the likeness of a hippocamp, a horse-fish amalgam which is depicted in mythology as the beast that drew Poseidon's chariot.\nTaras was also the centre of a thriving decorated Greek pottery industry during the 4th century BC. Most of the South Italian Greek vessels known as Basilican ware were made in different workshops in the city.\nUnfortunately, none of the names of the artists have survived, so modern scholars have been obliged to give the recognizable artistic hands and workshops nicknames based on the subject matter of their works, museums which possess the works, or individuals who have distinguished the works from others. Some of the most famous of the Apulian vase painters at Taras are now called: the Iliupersis Painter, the Lycurgus Painter, the Gioia del Colle Painter, the Darius Painter, the Underworld Painter, and the White Sakkos Painter, among others.\nThe wares produced by these workshops were usually large elaborate vessels intended for mortuary use. The forms produced included volute kraters, loutrophoroi, paterai, oinochoai, lekythoi, fish plates, etc. The decoration of these vessels was red figure (with figures reserved in red clay fabric, while the background was covered in a black gloss), with overpainting (sovradipinto) in white, pink, yellow, and maroon slips.\nOften the style of the drawings is florid and frilly, as was already the fashion in 4th-century Athens. Distinctive South Italian features also begin to appear. Many figures are shown seated on rocks. Floral motifs become very ornate, including spiraling vines and leaves, roses, lilies, poppies, sprays of laurel, acanthus leaves. Often the subject matter consists of naiskos scenes (scenes showing the statue of a deceased person in a naos, a miniature temple or shrine). Most often the naiskos scene occupies one side of the vase, while a mythological scene occupies the other. Images depicting many of the Greek myths are only known from South Italian vases, since Athenian ones seem to have had more limited repertoires of depiction.\nWorld War II.\nThe Battle of Taranto took place on the night of 11\u201312 November 1940 during the Second World War between British naval forces, under Admiral Andrew Cunningham, and Italian naval forces, under Admiral Inigo Campioni. The Royal Navy launched the first all-aircraft ship-to-ship naval attack in history, employing 21 Fairey Swordfish biplane torpedo bombers from the aircraft carrier in the Mediterranean Sea. The attack struck the battle fleet of the \"Regia Marina\" at anchor in the harbour of Taranto, using aerial torpedoes despite the shallowness of the water.\nThe Taranto Prize (Premio Taranto).\nThe Taranto Prize, defined as the \"Biennial of the South\", was a biennial cultural event that took place between 1947 and 1951.\nIt was born on the initiative of thirty-year-old veterans who, returning from the Second World War, gathered in the \u00abCultural Club (Circolo della cultura)\u00bb and the newspaper 'Voce del Popolo'. The coordinator, Antonio Rizzo, was a physicist who graduated with Enrico Fermi. He intended to promote a new cultural impulse of a pacifist nature for the city.\nThe event was structured into two sections: literature and painting. Several artists of international calibre, such as Pier Paolo Pasolini, Carlo Emilio Gadda, and Giorgio de Chirico, participated.\nThe theme of the competition was the sea.\n2006 municipal bankruptcy.\nThe Municipality of Taranto was declared bankrupt effective 31 December 2005, having accrued liabilities of \u20ac357 million. This was one of the biggest financial crises which has ever hit a municipality.\nThe bankruptcy declaration was made on 18 October 2006 by the receiver Tommaso Blonda. He was appointed following the resignation of the mayor, Rossana Di Bello, on account of her sixteen-month prison sentence for abuse of office and forgery of documents relating to investigations into the contract for the management of the city incinerator, awarded to Termomeccanica.\nGeography.\nTaranto faces the Ionian Sea. It is above sea level. It was built on a plain running north/north-west\u2013southeast, and surrounded by the Murgia plateau from the north-west to the east. Its territory extends for and is mostly underwater. It is characterised by three natural peninsulas and a man-made island, formed by digging a ditch during the construction of Aragon Castle. The city is known as the \"city of two seas\" because it is washed by the Big Sea in the bay between Punta Rondinella to the northwest and Capo San Dante to the south, and by the vast reservoir of the Little Sea.\nBig Sea and Little Sea.\nThe Big Sea (or \"Mare Grande\") is frequently known as the \"Big Sea bay\" as that is where ships harbour. It is separated from the Little Sea (or \"Mare Piccolo\") by a cape which closes the gulf, leading to the artificial island. This island formed the heart of the original city and it is connected to the mainland by the Ponte di Porta Napoli and the Ponte Girevole. The Big Sea is separated from the Ionian Sea by the Capo San Vito, the Isole Cheradi of St Peter and St Paul, and the three islands of San Nicolicchio, which are completely incorporated by the ILVA steelworks. The latter form a little archipelago which closes off the arc creating the natural Big Sea bay.\nThe Little Sea is considered to be a lagoon so it presents problems of water exchange. It is virtually divided into two by the Ponte Punta Penna Pizzone, which joins the Punta Penna to the Punta Pizzone. The first of these forms a rough triangle, whose corners are the opening to the east and the Porta Napoli channel linking it to the Big Sea in the west. The second half forms an ellipse whose major axis measures almost from the south-west to the north-east. The Galeso river flows into the first half.\nThe two water bodies have slightly different winds and tides and their underwater springs have different salinities. These affect the currents on the surface and in the depths of the Big Sea and the two halves of the Little Sea. In the Big Sea and in the northern part of the Little Sea, there are some underwater springs called citri, which carry undrinkable freshwater together with salt water. This creates the ideal biological conditions for cultivating Mediterranean mussels, known locally as \"cozze\".\nClimate.\nThe climate of the city, recorded by the weather station situated near the Grottaglie Military Airport, is a hot-summer Mediterranean climate, typical of the Mediterranean with frequent continental features.\nThe spring is usually mild and rainy, but it is not uncommon to have sudden cold spells from the north and east, which often cause snowfall. Average annual precipitation is fairly low (even for southern Italy), measuring just per year.\nThe summer is hot and humid, with temperatures averaging .\nOn 28 November 2012 a large F3 tornado hit the port of Taranto and damaged the Taranto Steel Mill; about 20 workers were injured, and another man was reported missing.\nIt is classified as Geographical zone C and having a degree-day of 30.\nDemographics.\nAs of 2025, the region has 6,079 foreigners, making up 3.3% of the total population of 185,909.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nDialect.\nThe city is the centre of the Tarantino dialect (\"dial\u00e8tte tarand\u00edne\") of the Neapolitan language. As a result of the city's history, it is influenced by Greek, Vulgar Latin, French and many others.\nEnvironment.\nIn 1991 Taranto was declared a high environmental risk area by the Ministry of Environment. As a consequence of the pollutants discharged into the air by the factories in the area, most notably the ILVA steel plant, part of Gruppo Riva. 7% of Taranto's pollution is produced by the public; 93% is produced by factories. In 2005, the European Pollutant Emission Register estimated dioxin emissions from the Taranto ILVA plant were responsible for 83% of Italy's total reported emissions. Every year the city is exposed to of carbon monoxide and of carbon dioxide. In 2014, the Italian National Institute of Emissions and their Sources, stated that Taranto stands third in the world behind China's Linfen, and Cop\u015fa Mic\u0103 in Romania, the most polluted cities in the world due to factories' emissions.\nIn particular, the city produces ninety-two percent of Italy's dioxin. This is 8.8\u00a0percent of the dioxin in Europe. Between 1995 and 2004, leukaemias, myelomas and lymphomas increased by 30 to 40\u00a0percent. Dioxin accumulates over the years. Over 9 kilos of dioxin have been discharged into the city's air by its factories. Grazing is banned within of the ILVA plant.\nIn 2013, the ILVA plant was placed under special administration when its owner, the Riva family, was accused of failing to prevent toxic emissions, which caused at least 400 premature deaths. Emissions of both carbon monoxide, carbon dioxide and dioxin have decreased. Animal species have returned that had left, including swallows, cranes, dolphins, seahorses and the coral reef.\nMain sights.\nTaranto has a number of sites of historic value. Situated at the angle of the canal, Big Sea and \"Piazza Castello\", the Aragon Castle was built between 1486 and 1492 by orders of King Ferdinand II of Aragon to protect the city from the Turks' frequent raids. The castle, which was designed by Italian painter and architect Francesco di Giorgio Martini, replaced a pre-existing 9th-century Byzantine fortress, which was deemed unfit for 15th-century warfare. In 1707 it ceased to be used as a military fortress and was converted to a prison until under Napoleon Bonaparte it reverted to its original military function. To date it is the property of the Italian Navy and is open to the public. Twenty-first-century excavations revealed the castle's earlier Byzantine foundations which can be viewed.\nThere are several Greek temple ruins - some from the 6th century BC - such as the remains of a temple dedicated to Poseidon, with its two surviving Doric columns still visible on Piazza Castello in the \"Citt\u00e0 Vecchia\".\nThe Promenade (\"lungomare\"), named after former Italian king Victor Emmanuel III, overlooks the \"Mar Grande\", the natural harbour and commercial port.\nThe Concattedrale Gran Madre di Dio, designed by Gio Ponti, was built in 1967\u20131971 in reinforced concrete and is one of the most significant late works by the architect. In 2018 it is in poor condition and defaced by graffiti.\nIn the modern districts, but above all in the central \"Borgo Umbertino\", there are also the Fountain of the \"Rosa dei Venti\", Monumento al Marinaio, the War Memorial and the Navy Yard, another symbol of the city, some archeological sites such as the Cripta del Redentore, churches like \"Maria Santissima del Monte Carmelo\", \"San Pasquale\" and \"San Francesco di Paola\" and 18th- and 19th-century palaces such as Palazzo Magnini, Palazzo delle Poste, Palazzo del Governo, Palazzo degli Uffici and Palazzo Savino D'Amelio.\nOn the outskirts and in the countryside there are several traditional ancient country houses called \"masseria\", like Masseria Capitignano.\nOld city.\nThe Old City or \"Citt\u00e0 Vecchia\" is where the Greeks built their acropolis. Today it retains the same street layout of 967, when the Byzantines under Nicephorus Phocas rebuilt what the Saracen troops led by the Slavic Sabir had razed to the ground in 927 AD. There are four main arteries (Corso Vittorio II, Via Duomo, Via di Mezzo and Via Garibaldi) which run in a straight direction however the side streets were purposely built narrow and winding to impede the passage of an invading army.\nIncorporating the Aragon Castle, Doric Columns, City Hall, Clock Tower and Piazza Fontana, it is situated and entirely enclosed on the artificial island between the Big and Little Seas and is reached from the New City\nby crossing the Ponte Girevole (swing bridge) from the south and the Ponte di Porta Napoli from the north. Almost rectangular in shape, it is divided into four (quarters) that are delineated by the cross formed between Via di Mezzo and Via Nuova. These are \"Baglio\" and \"San Pietro\" in the upper section which face the Big Sea; and \"Turipenne\" and \"Ponte\" in the lower part fronting the Little Sea. The nobility, clergy and military personnel made their homes in Baglio and San Pietro, whilst the artisans and fishermen dwelled in Ponte and Turipenne. An Armenian community was present in the 10th and 11th centuries having arrived in Taranto as troops in the Byzantine Army. The \"San't Andrea degli Armeni\" church in Piazza Monteoliveto, located in the Baglio quarter, stands as testimony to the neighbourhood where the Armenians made their homes.\nIn 1746 the entire population of Taranto resided in Old City. This resulted in the necessity of building additional stories on the narrow houses. It is still inhabited with a number of people living in juxtaposition to the old palazzi. By 2013 the population of the Old City was just 1000 at a time when the wider city had more than 200,000 inhabitants.\nThere are a number of 17th and 18th-century \"palazzi\" in Old City. For years, they served as the main residence of local aristocratic families and the clergy. These include Palazzo Cal\u00f2, Palazzo Carducci-Artenisio (1650), Palazzo Galeota (1728), Palazzo Gallo (17th century), P PMalazzo Latagliata, Palazzo Lo Jucco (1793), Palazzo D'Aquino, Palazzo Delli Ponti, Palazzo Gennarini, Palazzo d'Ayala, Palazzo Visconti, Palazzo Galizia, Palazzo Ciura and Palazzo Pantaleo. The 17th century de Beaumont-Bonelli-Bellacicco palace houses the Spartan Museum of Taranto - Hypogeum Bellacicco which extends below street and sea level to the hypogeum that is a crossroads with other hypogeum of Old City which together form the system of subterranean Taranto.\nChurches include the \"San Cataldo Cathedral\" (10th century) in Piazza Duomo, \"San Domenico Maggiore\" (1302), Sant'Andrea degli Armeni (16th century), \"Sant'Agostino\" (1402), \"San Michele\" (1763), \"Sant'Anna\", the \"Madonna della Salute\" sanctuary (1752), and \"San Giuseppe\" (16th century). Close to the San Agostino church, located near Pendio La Riccia, the buried remains of an ancient Greek temple were discovered.\nBeginning in 1934 Benito Mussolini embarked on a project of rejuvenation that involved the demolition of the working class Turipenne along the Via Garibaldi and \"Discesa Vasto\" which contained the homes of local fishermen as well as the old Jewish quarter. The demolitions, which also razed the old medieval wall and three churches out of the four within the area, continued until the outbreak of World War II. Modern edifices and apartment blocks were erected to replace the demolished structures.\nIn addition to the many \"palazzi\", Old City has myriad arched alleyways, \"saliti\", vicoli and small streets, some of which are closed to traffic. Between 2013 and 2014 two Neapolitan urban artists Cyop and Kaf embarked on a project to decorate derelict buildings, walls and doors in the \"piazzi\" and vicoli with 120 representations of street art. It has since become a striking feature of Old City which is described as the abandoned district of Taranto.\nEducation.\nAmong the various school are: Liceo Scientifico Battaglini, Liceo Archita (the most ancient), Liceo Quinto Ennio (in Literature), Liceo Aristosseno (Languages, Science, Humanistic), Galileo Ferraris, ITCS Pitagora da Taranto, Vittorino da Feltre, Cabrini, ITIS Righi and ITIS Pacinotti (in IT) and ITC V. Bachelet (in Commercial and Accounting \u2013 famous for the activities at BIT MILANO).\nCuisine.\nTaranto's cuisine is characterised by local products, especially vegetables and fish like artichokes, eggplants, tomatoes, olives, onions, shrimps, octopus, sardines, squid and, above all, mussels. A very important role is also played by the olive oil and bread produced in the city and in all the villages of its province. Some PDO, PGI and PAT are made in the countryside of Taranto and in the villages around the city: among them we can find some extra-virgin olive oil like Terre Tarentine PDO and Terra d'Otranto PDO, fruits like Uva di Puglia PGI and Clementine del Golfo di Taranto PGI, vegetables like the Barattiere PAT, Pomodorino di Manduria PAT, types of cheese like Burrata di Andria PGI and Ricotta Forte PAT, a type of bread called Pane di Laterza PAT and the Capocollo di Martina Franca PAT, a type of \"capocollo\".\nOther appreciated street foods are the tarallini, the panzerotti, the pucce.\nMussels of Taranto.\nA very important ingredient of the cuisine of Taranto is mussels. They are grown in the Big Sea and, above all, in the Little Sea (see above). They have been inserted in the list of Traditional Food Products by the Italian Ministry of Agricultural, Food and Forestry Policies. The peculiar flavour of Tarantine mussels is given by the special conditions of salinity of the Little Sea which is crossed by the \"citri\", submarine freshwater springs which manage to oxygenate the water, helping the development of the plankton and by the freshwater come from the Galeso river. The piles for the mussels were anciently made with wood from Sila Mountains in Calabria. During the Ancient Greek and Roman times, several authors described the richness and the goodness of the mussels of Taranto. After the tests about the pollution that is present in the first side of the Little Sea, the legal production of mussels has been moved to the second side. The tests and the classifications of the water are made by producers giving the possibility to certify the safety of the product. Some of the most traditional dishes of Taranto are mussels \"alla puppitegna\" (with garlic, extra-virgin olive oil and parsley) or the \"impepata\" (\"full of pepper\" in Italian) or spaghetti with mussels, or Tubettini with mussels.\nSports.\n2026 Mediterranean Games.\nTaranto will host the 2026 Mediterranean Games which will mark the fourth time Italy hosts the Mediterranean Games.\nTransport.\nRail.\nTaranto railway station connects the city with Rome, Naples, Milan, Bologna, Bari, Reggio di Calabria and Brindisi.\nAir.\nTaranto-Grottaglie Airport is located 16\u00a0km away from Taranto, but does not offer any regularly scheduled commercial services. The two closest airports that do offer regularly scheduled commercial services are in Brindisi and Bari, approximately 70\u00a0km and 90\u00a0km away, respectively.\nOther.\nThe Ponte Girevole (swing bridge), built in 1887, runs across the navigable ship canal that joins \"Mar Piccolo\" (\"Little Sea\") with \"Mar Grande\" (\"Big Sea\") and stretches along . When the bridge is open, the two ends of the city are disconnected.\nNotable people.\nThese historical figures have had a relationship with the city. Not all of them were actually born in Taranto.\nTwin towns - sister cities.\nTaranto is twinned with:\nSee also.\nHistory:\nCulture:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56149", "revid": "82835", "url": "https://en.wikipedia.org/wiki?curid=56149", "title": "Vasodilator", "text": ""}
{"id": "56150", "revid": "196446", "url": "https://en.wikipedia.org/wiki?curid=56150", "title": "Mainstream (disambiguation)", "text": ""}
{"id": "56152", "revid": "6058423", "url": "https://en.wikipedia.org/wiki?curid=56152", "title": "Boris III of Bulgaria", "text": "Tsar of Bulgaria from 1918 to 1943\nBoris III (; 30 January\u00a0[O.S. 18 January]\u00a01894\u00a0\u2013 28 August 1943) was the Tsar of the Kingdom of Bulgaria from 1918 until his death in 1943.\nThe eldest son of Ferdinand I, Boris assumed the throne upon the abdication of his father in the wake of Bulgaria's defeat in World War I. Under the 1919 Treaty of Neuilly, Bulgaria was forced to cede various territories, pay crippling war reparations, and greatly reduce the size of its military. That same year, Aleksandar Stamboliyski of the Bulgarian Agrarian National Union became prime minister. After Stamboliyski was overthrown in a coup in 1923, Boris recognized the new government of Aleksandar Tsankov, who harshly suppressed the Bulgarian Communist Party and led the nation through a brief border war with Greece. Tsankov was removed from power in 1926, and a series of prime ministers followed until 1934, when the corporatist \"Zveno\" () movement staged a coup and outlawed all political parties. Boris opposed the \"Zveno\" government and overthrew them in 1935, eventually installing Georgi Kyoseivanov as prime minister. For the remainder of his reign, Boris would rule as a \"de facto\" absolute monarch, with his prime ministers largely submitting to his will.\nFollowing the outbreak of World War II, Bulgaria initially remained neutral. In 1940, Nazi sympathizer Bogdan Filov replaced Kyoseivanov as prime minister, becoming the last prime minister to serve under Boris. In September 1940, with the support of Nazi Germany, Bulgaria received the region of Southern Dobrudja from Romania as part of the Treaty of Craiova. In January 1941, Boris approved the anti-Semitic Law for Protection of the Nation, which denied citizenship to Bulgarian Jews and placed numerous restrictions upon them. In March 1941, Bulgaria joined the Axis and allowed German troops to use Bulgaria as a base from which to invade Yugoslavia and Greece. Bulgaria then received large portions of Yugoslav Macedonia, Pirot County in eastern Serbia and Greek Thrace, which were key targets of Bulgarian irredentism. Bulgaria opted out of participation in the German invasion of the Soviet Union, as allowed by the provisions of the Axis alliance. As part of the Holocaust, Bulgarian authorities deported most Jews from occupied Greek and Yugoslav territories and transferred them to the German extermination camp of Treblinka. Under public pressure, Boris cancelled the deportation of Bulgarian Jews while expelling almost 20,000 Jews to the Bulgarian countryside to be deployed in forced labour camps. In 1942, \"Zveno\", the Agrarian National Union, the Bulgarian Communist Party, and other far-left groups united to form a resistance movement known as the Fatherland Front, which went on to overthrow the government in 1944. In August 1943, shortly after returning from a visit to Germany, Boris died at the age of 49. Following his death, he was succeeded as Tsar by his six-year-old son, Simeon Borisov Saxe-Coburg-Gotha (Bulgarian: \u0421\u0438\u043c\u0435\u043e\u043d \u0411\u043e\u0440\u0438\u0441\u043e\u0432 \u0421\u0430\u043a\u0441\u043a\u043e\u0431\u0443\u0440\u0433\u0433\u043e\u0442\u0441\u043a\u0438), who ascended the throne under the regnal name Simeon II.\nEarly life.\nBoris was born on 30 January 1894 in Sofia to Ferdinand I, Prince of Bulgaria, and his wife Princess Marie Louise of Bourbon-Parma.\nIn February 1896, his father paved the way for the reconciliation of Bulgaria and Russia with the conversion of the infant Prince Boris from Catholicism to Eastern Orthodoxy, a move that earned Ferdinand the frustration of his wife, the animosity of his Catholic Austrian relatives (particularly his uncle Franz Joseph I of Austria) and excommunication by Pope Leo XIII. In order to remedy this difficult situation, Ferdinand had his subsequent children baptised in the Catholic Church. Nicholas II of Russia stood as godfather to Boris and later met the young boy during Ferdinand's official visit to Saint Petersburg in July 1898.\nHe received his initial education in the so-called Palace Secondary School, which Ferdinand had founded in 1908 solely for his sons. Later, Boris graduated from the Military School in Sofia, then took part in the Balkan Wars. During the First World War, he served as liaison officer of the General Staff of the Bulgarian Army on the Macedonian front. In 1916, he was promoted to colonel and attached again as liaison officer to Army Group Mackensen and the Bulgarian Third Army for the operations against Romania. Boris worked hard to smooth the sometimes difficult relations between Field Marshal Mackensen and Lieutenant General Stefan Toshev, the commander of the Third Army. Through his courage and personal example, he earned the respect of the troops and the senior Bulgarian and German commanders, even that of the Generalquartiermeister of the German Army, Erich Ludendorff, who preferred dealing personally with Boris and described him as excellently trained, a thoroughly soldierly person and mature beyond his years. In 1918, Boris was made a major general.\nEarly reign.\nIn September 1918, Bulgaria was defeated in the Vardar Offensive and forced to sue for peace. Ferdinand abdicated in favour of Boris, who became Tsar on 3 October 1918.\nA year after Boris's accession, Aleksandar Stamboliyski (also \"Stambolijski\") of the Bulgarian Agrarian National Union was elected prime minister. Though popular with the large peasant class, Stambolijski earned the animosity of the middle class and military, which led to his toppling in a military coup on 9 June 1923 and assassination. On 14 April 1925, an anarchist group attacked Boris's cavalcade as it passed through the Arabakonak Pass. Two days later, a bomb killed 213 members of the Bulgarian political and military elite in Sofia as they attended the funeral of a murdered general in the Saint Nedelya Church terror assault. Following a further attempt on Boris's life the same year, military reprisals killed several thousand communists and agrarians, including representatives of the intelligentsia. Finally, in October 1925, there was a short border war with Greece, known as the Petrich Incident, which was resolved with the help of the League of Nations. \nIn the coup on 19 May 1934, the Zveno military organisation established a dictatorship, abolished political parties, and reduced Boris to a puppet figurehead. The following year, he staged a counter-coup and retook control of the country. The political process was controlled by the Tsar, but a semi-parliamentary system was re-introduced without restoration of political parties.\nWith the rise of the \"King's government\" in 1935, Bulgaria entered an era of prosperity and astounding growth, which deservedly qualifies it as the Golden Age of the Third Bulgarian Kingdom. It lasted nearly five years. According to Reuben H. Markham, former Balkan correspondent for The Christian Science Monitor, writing in 1941, \"As a ruler, Boris is competent; as a citizen exemplary; as a personality inspiring... His country is to a large extent indebted to him for the comparatively favorable situation it has held in the Balkans, during the last two decades.\" Markham added, \"King Boris is very accessible. He constantly comes into contact with persons of every sort. He drives his car up and down the country with no special guards and often stops to converse with peasants, workers or children. He gives lifts to the humblest pedestrians. Rare is the Bulgarian township that does not boast of at least one person who has ridden with the King.\" \"He is without question one of the best kings in Europe.\"\nBoris visited the United Kingdom in 1927 and 1932, staying with his childhood friend Nadejda Stancioff at her home in Blair Drummond, Doune, Stirling, Scotland. During another visit to the United Kingdom in 1937, Boris made international news for taking the throttle of a London Midland Scotland Railway Coronation Class steam locomotive.\nMarriage and issue.\nBoris married Giovanna of Savoy, daughter of Victor Emmanuel III of Italy, and as he remained Orthodox, it was a Catholic nuptial ceremony outside of Mass. It was held at the Basilica of Saint Francis of Assisi in Assisi, Italy, on 25 October 1930. Benito Mussolini registered the marriage at the town hall immediately after the liturgy.\nTheir marriage produced two children: a daughter, Maria Louisa, on 13 January 1933, later head of the House of Saxe-Coburg and Gotha-Koh\u00e1ry, and a son and heir to the throne, Simeon, on 16 June 1937, who was the last Tsar of Bulgaria as Simeon II (1943-1946).\nSecond World War.\nIn the early days of the Second World War, Bulgaria was neutral, but powerful groups in the country swayed its politics towards Germany (with which Bulgaria had been allied in the First World War). As a result of peace treaties that ended the First World War (the Treaty of Versailles and the Treaty of Neuilly), Bulgaria, which had fought on the losing side, lost two important territories to neighboring countries: the Southern plain of Dobruja to Romania, and Western Thrace to Greece. The Bulgarians considered these treaties an insult and wanted the lands restored. When Adolf Hitler rose to power, he tried to win Bulgarian Tsar Boris III's allegiance. In the summer of 1940, after a year of war, Hitler hosted diplomatic talks between Bulgaria and Romania in Vienna. On 7 September, an agreement was signed for the return of Southern Dobruja to Bulgaria. The Bulgarian nation rejoiced. In March 1941, Boris allied himself with the Axis powers, thus recovering most of Macedonia and Aegean Thrace, as well as protecting his country from being crushed by the German Wehrmacht like neighboring Yugoslavia and Greece. For recovering these territories, Tsar Boris was called the Unifier (Bulgarian: \u0426\u0430\u0440 \u041e\u0431\u0435\u0434\u0438\u043d\u0438\u0442\u0435\u043b). Tsar Boris appeared on the cover of \"Time\" on 20 January 1941 wearing a full military uniform.\nDespite this alliance, and the German presence in Sofia and along the railway line which passed through the Bulgarian capital to Greece, Boris was not willing to provide full and unconditional cooperation with Germany. He refused to send regular Bulgarian troops to fight the Soviet Union on the Eastern Front alongside Germany and the other Axis belligerents, and also refused to allow unofficial volunteers (such as Spain's Blue Division) to participate, although the German legation in Sofia received 1,500 requests from young Bulgarian men who wanted to fight against Bolshevism.\nBut there was a price to be paid for the return of Dobrudja. This was the adoption of the anti-Jewish \"Law for Protection of the Nation\" (\u0417\u0430\u043a\u043e\u043d \u0437\u0430 \u0437\u0430\u0449\u0438\u0442\u0430 \u043d\u0430 \u043d\u0430\u0446\u0438\u044f\u0442\u0430 \u2013 \u0417\u0417\u041d) on 24 December 1940. This law was in accordance with the Nuremberg Laws in Nazi Germany and the rest of Hitler's occupied Europe. Bulgarian Prime Minister Bogdan Filov and Interior Minister Petur Gabrovski, both Nazi sympathisers, were the architects of this law, which restricted Jewish rights, imposed new taxes, and established a quota for Jews in some professions. Many Bulgarians protested in letters to their government.\nThe Holocaust.\nIn early 1943, Hitler's emissary, Theodor Dannecker, arrived in Bulgaria. Dannecker was an \"SS-Hauptsturmf\u00fchrer\" (captain) and one of Adolf Eichmann's associates who guided the campaign for the deportation of the French Jews to concentration camps. In February 1943, Dannecker met with the Commissar for Jewish Affairs in Bulgaria, Aleksandar Belev, notorious for his antisemitic and strong nationalist views. They held closed-door meetings and ended with a secret agreement signed on 22 February 1943 for the deportations of 20,000 Jews \u2013 11,343 from Aegean Thrace and Vardar Macedonia, and 8,000 from Bulgaria proper. These were the territories conquered by Germany, but being under Bulgarian occupation and jurisdiction at the time, although this occupation was never recognized internationally. The Jewish people in these territories were the only ones who were not awarded Bulgarian citizenship in 1941\u20131942, unlike the rest of the population. The remaining 20,000 Bulgarian Jews were to be deported later.\nThe initial roundups began on 9 March 1943, during that month, Bulgarian military and police authorities deported 11,343 Jews from the Bulgarian-occupied regions of Vardar Macedonia, Pomoravlje in occupied Yugoslavia and Aegean Thrace to Auschwitz-Birkenau and Treblinka.\nBoxcars were lined up in Kyustendil, a town near the western border. But as the news about the imminent deportations leaked out, protests arose throughout Bulgaria. On the morning of 9 March, a delegation from Kyustendil, composed of eminent public figures and headed by Dimitar Peshev, the deputy speaker of the National Assembly, met with Interior Minister Petur Gabrovski. Facing strong opposition from within the country, Gabrovski relented. The same day, he sent telegrams to the roundup centers in the pre-war territory of Bulgaria, postponing the deportations to a future, unidentified date. In a report of 5 April 1943, Adolph Hoffman, a German government adviser and police attache at the German legation in Sofia from 1943 to 1944 wrote: \"The Minister of Interior has received instruction from the highest place to stop the planned deportation of Jews from the old borders of Bulgaria\". In fact, Gabrovski's decision was not taken on his own personal initiative, but had come from the highest authority \u2013 Tsar Boris III, who decided under pressure to temporarily stop the deportation of the rest of the Jews. While Jews living in Bulgaria proper were saved, almost all the Jews from Vardar Macedonia and Aegean Thrace perished in the death camps of Treblinka and Majdanek. A telegram dated 4 April 1943 from Germany's foreign minister, Joachim von Ribbentrop, indicated the readiness of King Boris to hand over half of the Jewish population:\nThe King has declared that up to now he has only given his consent for deportation of Jews from Macedonia and Thrace to areas in Eastern Europe. He only wants to deport a limited number of Bolsheviks-Communists from Bulgaria itself. The other 25,000 Jews will be concentrated in camps within the country.\nStill reluctant to comply with the German deportation request, the royal palace used Swiss diplomatic channels to inquire whether it was possible to deport the Jews to British-controlled Palestine by ship rather than to concentration camps in German-occupied Poland by boat and train. This was blocked by the British Foreign Secretary, Anthony Eden. \nAware of Bulgaria's unreliability on the Jewish matter, the Nazis grew more suspicious about the activities of an old friend of Tsar Boris, Monsignor Angelo Roncalli (the future Pope John XXIII), the Papal Nuncio in Istanbul, who was attempting to help European Jews threatened by the Nazis and their allies. Reporting on the humanitarian efforts of Roncalli, his secretary in Venice and in the Vatican, Monsignor Loris F. Capovilla wrote: \"Through his intervention, and with the help of Tsar Boris III of Bulgaria, thousands of Jews from Slovakia, who had first been sent to Hungary and then to Bulgaria, and who were in danger of being sent to Nazi concentration camps, obtained transit visas for Palestine signed by him.\"\nHowever, regarding his actions during the Holocaust, \"like Prime Minister Filov, Boris III seems to have been motivated mainly by considerations of \"Realpolitik\"\", and \"appears to have played a less heroic role than his admirers ascribe to him ... What motivated him was national interest as he understood it, not humanitarian concerns.\"\nMeetings with Hitler.\nNazi pressure on Tsar Boris III continued for the deportation of the Bulgarian Jewry. At the end of March, Hitler invited the Tsar to visit him. Upon returning home, Boris ordered able-bodied Jewish men to join hard labor units to build roads within the interior of his kingdom. Some claim that this was the Tsar's attempt to avoid deporting them.\nDuring May 1943, Dannecker and Belev, the Commissar for Jewish Affairs, planned the deportation of more than 48,000 Bulgarian Jews, who were to be loaded on steamers on the River Danube. Boris continued the cat-and-mouse game that he had long been playing; he insisted to the Nazis that Bulgarian Jews were needed for the construction of roads and railway lines inside his kingdom. Nazi officials requested that Bulgaria deport its Jewish population to German-occupied Poland. The request caused a public outcry, and a campaign whose most prominent leaders were Parliament's deputy speaker Dimitar Peshev and the head of the Bulgarian Orthodox Church, Archbishop Stefan, was organised. Following this campaign, Boris refused to permit the extradition of Bulgaria's nearly 50,000 Jews.\nOn 30 June 1943, Apostolic Delegate Angelo Roncalli wrote to Boris, asking for mercy for \"the sons of the Jewish people.\" He wrote that Tsar Boris should on no account agree to the dishonorable action that Hitler was demanding. \"On the copy of this letter, Roncalli wrote, by hand and in Italian ... \"The king has acted ('Il Re ha fatto qualche cosa') ... but he also has his own difficulties, which he asks us to understand. To deal with individual cases arouses the jealousy of others. But I repeat, he has acted ('Per\u00f2, ripeto, ha fatto').\"\nAn excerpt from the diary of Rabbi Daniel Zion, the spiritual leader of the Jewish community in Bulgaria during the war years, reads:\nDo not be afraid, dear brothers and sisters! Trust in the Holy Rock of our salvation ... Yesterday I was informed by Bishop Stephen about his conversation with the Bulgarian king. When I went to see Bishop Stephen, he said: \"Tell your people, the King has promised, that the Bulgarian Jews shall not leave the borders of Bulgaria.\" When I returned to the synagogue, silence reigned in anticipation of the outcome of my meeting with Bishop Stephen. When I entered, my words were: \"Yes, my brethren, God heard our prayers.\"\nMost irritating for Hitler was the Tsar's refusal to declare war on the Soviet Union or send Bulgarian troops to the Eastern Front. On 9 August 1943, Hitler summoned Boris to a stormy meeting at Rastenburg, East Prussia. Boris arrived by plane from Vrazhdebna on 14 August. The Tsar again asserted his unwillingness to send Bulgarian Jews to death camps in occupied Poland or Germany. While Bulgaria had declared a \"symbolic\" war on the distant United Kingdom and United States, the Tsar was not willing to do more than that. At the meeting, Boris once again refused to get involved in the war against the Soviet Union, giving two major reasons for his unwillingness to send troops to Russia. First, many ordinary Bulgarians had strong pro-Russian sentiments; and second, the political and military position of Turkey remained unclear. The \"symbolic\" war against the Western Allies turned into a disaster for the citizens of Sofia, as the city was heavily bombarded by the US Army Air Force and the British Royal Air Force in 1943 and 1944. (The bombardment of Bulgarian cities was started by the British Royal Air Force in April 1941 without declaring a war.)\nBulgaria's opposition came to a head at this last official meeting between Hitler and Boris. Reports of the meeting indicate that Hitler was furious with the Tsar for refusing either to join the war against the USSR or to deport the Jews within his kingdom. At the end of the meeting, it was agreed that \"the Bulgarian Jews were not to be deported, for Tsar Boris had insisted that the Jews were needed for various laboring tasks including road maintenance.\"\nDeath.\nShortly after returning to Sofia from a meeting with Hitler, Boris died of apparent heart failure on 28 August 1943, at approximately 16:22. Due to its timing and suddenness, as \"soon as the news of the king's illness and death appeared abroad, rumours of assassination spread throughout the world.\" The American newspapers even stated that Hitler had gotten into an argument with the Tsar and attacked him, with the latter suffering a heart attack as a result, with the \"New York Times\" going so far as to publish the \"bizarre story of a police inspector shooting Boris in the Sofia railway station.\"\nOne theory is that Boris was poisoned on the orders of Hitler, who was greatly irritated after his last meeting with the Bulgarian ruler because of his refusal to hand over the Bulgarian Jews and to send troops against the USSR. However, according to the Bulgarian Prime Minister, Bogdan Filov, \"the discussion between Hitler and Boris involved the use of Bulgarian troops only in the Balkans, not in the Soviet Union\". Hitler \"had asked Bulgaria to supply two divisions to fight in northern Greece and eventually in Albania\", but \"Boris promised only one.\" Not only is it \"doubtful that an argument over the use of one division in the Balkans would have provided Hitler with sufficient motive to have Boris assassinated\", there is also \"no evidence that Hitler planned this alleged assassination. In fact, all things point to the contrary: that he was surprised by the king's death.\"\nHis son, Simeon Saxe-Coburg-Gotha, did not reject the theory of a German assassination outright, but pointed out as probable the hypothesis that the USSR was also interested in the Tsar's death, in which case he argued that the NKVD may have been responsible. Princess Marie Louise of Bulgaria stated in an interview that there was no definitive version of what had happened, but that she was convinced that her father had not been poisoned by the Nazis or the British, but by the Russians.\nIn his personal diary, Joseph Goebbels expressed his belief that the Italian government, in the person of Prime Minister Pietro Badoglio, was responsible for Boris III's death. On 10 September 1943, Goebbels wrote:\n\"The Fuehrer told me that it must now be regarded as certain that King Boris was poisoned. The German doctors have reached the conclusion that he was killed by snake poison. It is not yet known who mixed the poison. The German doctors wanted to perform an autopsy; the Bulgarian government agreed, but the royal family refused. I would not regard it as impossible that the poisoning was engineered by the Italians. After their latest act of treachery, I am ready to credit the Badoglio regime and the Italians generally with anything.\"\nThree German doctors had been sent \"to help the Bulgarian physicians\" after Boris fell ill. According to the diary of the German attach\u00e9 in Sofia at the time, Carl-August von Schoenebeck, two of the three German doctors who attended the King \u2013 Sajitz and Hans Eppinger \u2013 both believed that \"poisoning was a possibility ... although they were reluctant to give a scientific opinion without an autopsy.\" According to Schoenebeck, they speculated that he had died from the same poison that Eppinger had allegedly found two years earlier in the postmortem examination of the Greek Prime Minister Ioannis Metaxas. They claimed that this slow poison takes weeks to do its work, and causes the appearance of blotches on the skin of its victim before death. However, \"no solid evidence has ever emerged to definitively prove that Metaxas was murdered. The official medical records are consistent with his death being caused by a severe throat infection, and no forensic investigation or autopsy at the time pointed to foul play.\"\nHitler was convinced that the Italian royal court arranged for the poisoning of Boris III, as he believed that Princess Mafalda of Savoy, sister of Joan of Bulgaria, had visited Bulgaria four weeks before the monarch's death, and that her stay had coincided with the events of 25 July 1943, when Italian Fascist dictator Benito Mussolini was removed from power by King Victor Emmanuel III. However, Princess Mafalda \"arrived in Bulgaria only \"after\" King Boris's death, to attend the funeral\", as contemporary newspaper reports and photographs attest, and \"Hitler's allegation that she came to Bulgaria before the king's illness is absolutely false and has never been taken seriously.\"\nUltimately, there is \"no firm proof\" that Boris's death was \"due to foul play\", and the \"story of an unidentified poison which induces a heart attack a week after its administration leaves one somewhat skeptical. Furthermore, the questions of both motive and culprit cannot be answered with satisfactory\" evidence. However, according to author Robert Bideleux, many Bulgarians \"have no doubt wanted to believe that Boris was poisoned, because that would put both their former tsar and their country in a better light, by suggesting that they were really 'victims' of (rather than 'collaborators' with) Nazism.\"\nFollowing Boris's death, his six-year-old son, Simeon II, acceded to the throne, with a Regency Council appointed to exercise royal authority, headed by Boris\u2019s brother, Prince Kiril of Bulgaria.\nFollowing a large, impressive state funeral at the Alexander Nevsky Cathedral, Sofia, where the streets were lined with weeping crowds, the coffin of Tsar Boris III was taken by train to the mountains and buried in Bulgaria's largest and most important monastery, the Rila Monastery. After taking power in September 1944, the Communist-dominated government had his body exhumed and secretly buried in the courtyard of Vrana Palace, near Sofia. At a later time, the Communist authorities moved the zinc coffin from Vrana to a secret location, which remains unknown to this day. After the fall of communism, an excavation was made at Vrana Palace. Only Boris's heart was found, as it had been put in a glass cylinder outside the coffin. The heart was taken by his widow in 1994 to Rila Monastery, where it was reinterred.\nA wood carving is placed on the left side of his grave in Rila Monastery, made on 10 October 1943 by inhabitants of the village of Osoj, Debar district. The carving bears the following inscription:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;To its Tsar Liberator Boris III, from grateful Macedonia.\nTributes.\nThe \"Los Angeles Times\" reported in 1994 that the Jewish National Fund's Medal of the Legion of Honor was being awarded posthumously to Tsar Boris III, \"the first non-Jew to receive one of the Jewish community's highest honors\".\nIn 1996, Bulgarian Jews in the United States and the Jewish National Fund erected a monument in \"The Bulgarian Forest\" in Israel to honor Tsar Boris as a savior of Bulgarian Jews. In July 2003, a public committee headed by Israeli Chief Justice Moshe Bejski decided to remove the memorial because Bulgaria had consented to the delivery of 11,343 Jews from occupied territory of Macedonia, Thrace and Pirot to the Germans.\nBorisova gradina, the largest park in Sofia and one of the city's biggest boulevards are named after him.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56153", "revid": "32975992", "url": "https://en.wikipedia.org/wiki?curid=56153", "title": "Ophthalmology", "text": "Field of medicine treating eye disorders\nOphthalmology (, ) is the branch of medicine that deals with the diagnosis, treatment, and surgery of eye diseases and disorders.\nAn ophthalmologist is a physician who undergoes subspecialty training in medical and surgical eye care. Following a medical degree, a doctor specializing in ophthalmology must pursue additional postgraduate residency training specific to that field. In the United States, following graduation from medical school, one must complete a four-year residency in ophthalmology to become an ophthalmologist. Following residency, additional specialty training (or fellowship) may be sought in a particular aspect of eye pathology.\nOphthalmologists prescribe medications to treat ailments, such as eye diseases, implement laser therapy, and perform surgery when needed. Ophthalmologists provide both primary and specialty eye care\u2014medical and surgical. Most ophthalmologists participate in academic research on eye diseases at some point in their training, and many include research as part of their career.\nOphthalmology has always been at the forefront of medical research with a long history of advancement and innovation in eye care.\nA former term for this medical branch is oculism.\nDiseases.\nA brief list of some of the most common diseases treated by ophthalmologists:\nThe most-valued pharmaceutical companies worldwide whose leading products are in ophthalmology are Regeneron (United States) for macular degeneration treatment and Bausch Health (Canada).\nDiagnosis.\nEye examination.\nThe following are examples of methods performed during an eye examination that enable diagnosis:\nSpecialized tests.\nOptical coherence tomography (OCT) is a medical technological platform used to assess ocular structures. Physicians then use the information to assess the staging of pathological processes and confirm clinical diagnoses. Subsequent OCT scans are used to assess the efficacy of managing diabetic retinopathy, age-related macular degeneration, and glaucoma.\nOptical coherence tomography angiography (OCTA) and fluorescein angiography to visualize the vascular networks of the retina and choroid.\nElectroretinography (ERG) measures the electrical responses of various cell types in the retina, including the photoreceptors (rods and cones), inner retinal cells (bipolar and amacrine cells), and the ganglion cells.\nElectrooculography (EOG) is a technique for measuring the corneo-retinal standing potential that exists between the front and the back of the human eye. The resulting signal is called the electrooculogram. Primary applications are in ophthalmological diagnosis and in recording eye movements.\nVisual field testing to detect dysfunction in central and peripheral vision which may be caused by various medical conditions such as glaucoma, stroke, pituitary disease, brain tumours or other neurological deficits.\nCorneal topography is a non-invasive medical imaging technique for mapping the anterior curvature of the cornea, the outer structure of the eye.\nUltrasonography of the eyes may be performed by an ophthalmologist.\nOphthalmic surgery.\nEye surgery, also known as ocular surgery, is surgery performed on the eye or its adnexa by an ophthalmologist. The eye is a fragile organ and requires extreme care before, during, and after a surgical procedure. An eye surgeon is responsible for selecting the appropriate surgical procedure for the patient and for taking the necessary safety precautions.\nSubspecialties.\nOphthalmology includes subspecialities that deal either with certain diseases or diseases of certain parts of the eye. Some of them are:\nMedical retina and vitreo-retinal surgery are sometimes combined, and together they are called posterior segment subspecialization.\nEtymology.\nThe Greek roots of the word ophthalmology are \u1f40\u03c6\u03b8\u03b1\u03bb\u03bc\u03cc\u03c2 (, \"eye\") and -\u03bbo\u03b3\u03af\u03b1 (-, \"study, discourse\"), i.e., \"the study of eyes\". The discipline applies to all animal eyes, whether human or not, since the practice and procedures are quite similar with respect to disease processes, although there are differences in the anatomy or disease prevalence.\nHistory.\nAncient near east and the Greek period.\nIn the Ebers Papyrus from ancient Egypt dating to 1550 BC, a section is devoted to eye diseases.\nPrior to Hippocrates, physicians largely based their anatomical conceptions of the eye on speculation, rather than empiricism. They recognized the sclera and transparent cornea running flushly as the outer coating of the eye, with an inner layer with pupil, and a fluid at the centre. It was believed, by Alcamaeon (fifth century BC) and others, that this fluid was the medium of vision and flowed from the eye to the brain by a tube. Aristotle advanced such ideas with empiricism. He dissected the eyes of animals, and discovering three layers (not two), found that the fluid was of a constant consistency with the lens forming (or congealing) after death, and the surrounding layers were seen to be juxtaposed. He and his contemporaries further put forth the existence of three tubes leading from the eye, not one. One tube from each eye met within the skull.\nThe Greek physician Rufus of Ephesus (first century AD) recognized a more modern concept of the eye, with conjunctiva, extending as a fourth epithelial layer over the eye. Rufus was the first to recognise a two-chambered eye, with one chamber from cornea to lens (filled with water), the other from lens to retina (filled with a substance resembling egg whites).\nCelsus the Greek philosopher of the second century AD gave a detailed description of cataract surgery by the couching method.\nThe Greek physician Galen (second century AD) remedied some mistaken descriptions, including about the curvature of the cornea and lens, the nature of the optic nerve, and the existence of a posterior chamber. Although this model was a roughly correct modern model of the eye, it contained errors. Still, it was not advanced upon again until after Vesalius. A ciliary body was then discovered and the sclera, retina, choroid, and cornea were seen to meet at the same point. The two chambers were seen to hold the same fluid, as well as the lens being attached to the choroid. Galen continued the notion of a central canal, but he dissected the optic nerve and saw that it was solid. He mistakenly counted seven optical muscles, one too many. He also knew of the tear ducts.\nAncient India.\nThe \"Sushruta Samhita\" is an ancient Sanskrit text attributed to the Indian surgeon Sushruta. The final volume of the Sushruta Samhita, known as the Uttaratantra, contains the ophthalmic sections of the work, including the method of cataract surgery, and is attributed in the traditions of both India and China to a figure named Nagarjuna, who lived in the early Common Era.\nThe Uttaratantra describes 76 ocular diseases (of these, 51 surgical) as well as several ophthalmological surgical instruments and techniques. His description of cataract surgery was compatible with the method of couching.\nMedieval Islam.\nMedieval Islamic Arabic and Persian scientists (unlike their classical predecessors) considered it normal to combine theory and practice, including the crafting of precise instruments, and therefore found it natural to combine the study of the eye with the practical application of that knowledge. Hunayn ibn Ishaq (a Christian), and others beginning with the medieval Arabic period, taught that the crystalline lens is in the exact center of the eye. This idea was propagated until the end of the 1500s.\nIbn al-Nafis, an Arabic native of Damascus, wrote a large textbook, \"The Polished Book on Experimental Ophthalmology\", divided into two parts, \"On the Theory of Ophthalmology\" and \"Simple and Compounded Ophthalmic Drugs\".\nAvicenna wrote in his Canon \"rescheth\", which means \"retiformis\", and Gerard of Cremona translated this at approximately 1150 into the new term \"retina\".\nModern period.\nIn the 17th and 18th centuries, hand lenses were used by Malpighi, microscopes by Leeuwenhoek, preparations for fixing the eye for study by Ruysch, and later the freezing of the eye by Petit. This allowed for detailed study of the eye and an advanced model. Some mistakes persisted, such as: why the pupil changed size (seen to be vessels of the iris filling with blood), the existence of the posterior chamber, and the nature of the retina. Unaware of their functions, Leeuwenhoek noted the existence of photoreceptors; however, they were not properly described until Gottfried Reinhold Treviranus in 1834.\nJacques Daviel performed the first documented planned primary cataract extraction on 18\u00a0September 1750 in Cologne.\nGeorg Joseph Beer (1763\u20131821) was an Austrian ophthalmologist and leader of the First Viennese School of Medicine. He introduced a flap operation for the treatment of cataracts (Beer's operation) and popularized the instrument used to perform the surgery (Beer's knife).\nIn North America, indigenous healers treated some eye diseases by rubbing or scraping the eyes or eyelids.\nOphthalmic surgery in the United Kingdom.\nThe first ophthalmic surgeon in the UK was John Freke, appointed to the position by the governors of St.\u00a0Bartholomew's Hospital in 1727. A major breakthrough came with the appointment of Baron de Wenzel (1724\u201390), a German who became the oculist to King George\u00a0III of Great Britain in 1772. His skill at removing cataracts legitimized the field. The first dedicated ophthalmic hospital opened in 1805 in London; it is now called Moorfields Eye Hospital. Clinical developments at Moorfields, and the founding of the Institute of Ophthalmology (now part of the University College London) by Sir Stewart Duke-Elder, established the site as the largest eye hospital in the world and a nexus for ophthalmic research.\nCentral Europe.\nIn Berlin, ophthalmologist Albrecht von Graefe introduced iridectomy as a treatment for glaucoma and improved cataract surgery, he is also considered the founding father of the German Ophthalmological Society.\nNumerous ophthalmologists fled Germany after 1933 as the Nazis began to persecute those of Jewish descent. A representative leader was Joseph Igersheimer (1879\u20131965), best known for his discoveries with arsphenamine for the treatment of syphilis. He fled to Turkey in 1933. As one of eight emigrant directors in the Faculty of Medicine at the University of Istanbul, he built a modern clinic and trained students. In 1939, he went to the United States, becoming a professor at Tufts University. German ophthalmologist, Gerhard Meyer-Schwickerath is widely credited with developing the predecessor of laser coagulation, photocoagulation.\nIn 1946, Igersheimer conducted the first experiments on light coagulation. In 1949, he performed the first successful treatment of a retinal detachment with a light beam (light coagulation) with a self-constructed device on the roof of the ophthalmic clinic at the University of Hamburg-Eppendorf.\nPolish ophthalmology dates to the 13th century. The Polish Ophthalmological Society was founded in 1911. A representative leader was Adam Zamenhof (1888\u20131940), who introduced certain diagnostic, surgical, and nonsurgical eye-care procedures. He was executed by the German Nazis in 1940.\nZofia Falkowska (1915\u20131993) head of the Faculty and Clinic of Ophthalmology in Warsaw from 1963 to 1976, was the first to use lasers in her practice.\nContributions by physicists.\nThe prominent physicists of the late 19th and early 20th centuries included Ernst Abbe (1840\u20131905), a co-owner of at the Zeiss Jena factories in Germany, where he developed numerous optical instruments. Hermann von Helmholtz (1821\u20131894) was a polymath who made contributions to many fields of science and invented the ophthalmoscope in 1851. They both made theoretical calculations on image formation in optical systems and studied the optics of the eye.\nProfessional requirements.\nOphthalmologists are physicians (MD/DO in the U.S. or MBBS in the UK and elsewhere, or DO/DOMS/DNB) who typically complete an undergraduate degree at general medical school, followed by a residency in ophthalmology. Ophthalmologists typically perform optical, medical and surgical eye care.\nAustralia and New Zealand.\nIn Australia and New Zealand, the FRACO or FRANZCO is the equivalent postgraduate specialist qualification. The structured training system takes place over five years of postgraduate training. Overseas-trained ophthalmologists are assessed using the pathway published on the RANZCO website. Those who have completed their formal training in the UK and have the CCST or CCT, usually are deemed to be comparable.\nBangladesh.\nIn Bangladesh to be an ophthalmologist the basic degree is an MBBS. They then have to obtain a postgraduate degree or diploma in an ophthalmology specialty. In Bangladesh, these are diploma in ophthalmology, diploma in community ophthalmology, fellow or member of the College of Physicians and Surgeons in ophthalmology, and Master of Science in ophthalmology.\nCanada.\nIn Canada, after medical school an ophthalmology residency is undertaken. The residency typically lasts five years, culminating in fellowship of the Royal College of Surgeons of Canada (FRCSC). Subspecialty training is undertaken by approximately 30% of fellows (FRCSC) in a variety of fields from anterior segment, cornea, glaucoma, vision rehabilitation, uveitis, oculoplastics, medical and surgical retina, ocular oncology, Ocular pathology, or neuro-ophthalmology. Approximately 35 vacancies open per year for ophthalmology residency training in all of Canada. These numbers fluctuate per year, ranging from 30 to 37 spots. Of these, up to ten spots are at French-speaking universities in Quebec. At the end of the five years, the graduating ophthalmologist must pass the oral and written portions of the Royal College exam in either English or French.\nIndia.\nIn India, after completing MBBS degree, postgraduate study in ophthalmology is required. The degrees are doctor of medicine, master of surgery, diploma in ophthalmic medicine and surgery, and diplomate of national board. The concurrent training and work experience are in the form of a junior residency at a medical college, eye hospital, or institution under the supervision of experienced faculty. Further work experience in the form of fellowship, registrar, or senior resident refines the skills of these eye surgeons. All members of the India Ophthalmologist Society and various state-level ophthalmologist societies hold regular conferences and actively promote continuing medical education.\nNepal.\nIn Nepal, to become an ophthalmologist, three years of postgraduate study is required after completing an MBBS degree. The postgraduate degree in ophthalmology is called medical doctor in ophthalmology. Currently, this degree is provided by Tilganga Institute of Ophthalmology, Tilganga, Kathmandu, BPKLCO, Institute of Medicine, TU, Kathmandu, BP Koirala Institute of Health Sciences, Dharan, Kathmandu University, Dhulikhel, and National Academy of Medical Science, Kathmandu. A few Nepalese citizens also study this subject in Bangladesh, China, India, Pakistan, and other countries. All graduates have to pass the Nepal Medical Council Licensing Exam to become a registered ophthalmologists in Nepal. The concurrent residency training is in the form of a PG student (resident) at a medical college, eye hospital, or institution according to the degree providing university's rules and regulations. Nepal Ophthalmic Society holds regular conferences and actively promotes continuing medical education.\nIreland.\nIn Ireland, the Royal College of Surgeons of Ireland grants membership (MRCSI (Ophth)) and fellowship (FRCSI (Ophth)) qualifications in conjunction with the Irish College of Ophthalmologists. Total postgraduate training involves an intern year, a minimum of three years of basic surgical training, and a further 4.5\u00a0years of higher surgical training. Clinical training takes place within public, Health Service Executive-funded hospitals in Dublin, Sligo, Limerick, Galway, Waterford, and Cork. A minimum of 8.5\u00a0years of training is required before eligibility to work in consultant posts. Some trainees take extra time to obtain MSc, MD or PhD degrees and to undertake clinical fellowships in the UK, Australia, and the United States.\nPakistan.\nIn Pakistan, after MBBS, a four-year full-time residency program leads to an exit-level FCPS examination in ophthalmology, held under the auspices of the College of Physicians and Surgeons, Pakistan. The tough examination is assessed by both highly qualified Pakistani and eminent international ophthalmic consultants. As a prerequisite to the final examinations, an intermediate module, an optics and refraction module, and a dissertation written on a research project carried out under supervision is also assessed.\nMoreover, a two-and-a-half-year residency program leads to an MCPS while a two-year training of DOMS is also being offered. For candidates in the military, a stringent two-year graded course, with quarterly assessments, is held under Armed Forces Post Graduate Medical Institute in Rawalpindi.\nThe M.S. in ophthalmology is also one of the specialty programs. In addition to programs for physicians, various diplomas and degrees for allied eyecare personnel are also being offered to produce competent optometrists, orthoptists, ophthalmic nurses, ophthalmic technologists, and ophthalmic technicians in this field. These programs are being offered, notably by the College of Ophthalmology and Allied Vision Sciences in Lahore and the Pakistan Institute of Community Ophthalmology in Peshawar. Subspecialty fellowships also are being offered in the fields of pediatric ophthalmology and vitreoretinal ophthalmology. King Edward Medical University, Al Shifa Trust Eye Hospital Rawalpindi, and Al- Ibrahim Eye Hospital Karachi also have started a degree program in this field.\nPhilippines.\nIn the Philippines, Ophthalmology is considered a medical specialty that uses medicine and surgery to treat diseases of the eye. There is only one professional organization in the country that is duly recognized by the PMA and the PCS: the Philippine Academy of Ophthalmology (PAO). PAO and the state-standard Philippine Board of Ophthalmology (PBO) regulates ophthalmology residency programs and board certification. To become a general ophthalmologist in the Philippines, a candidate must have completed a doctor of medicine degree (MD) or its equivalent (e.g. MBBS), have completed an internship in Medicine, have passed the physician licensure exam, and have completed residency training at a hospital accredited by the Philippine Board of Ophthalmology (accrediting arm of PAO). Attainment of board certification in ophthalmology from the PBO is essential in acquiring privileges in most major health institutions. Graduates of residency programs can receive further training in ophthalmology subspecialties, such as neuro-ophthalmology, retina, etc. by completing a fellowship program that varies in length depending on each program's requirements.\nUnited Kingdom.\nIn the United Kingdom, three colleges grant postgraduate degrees in ophthalmology. The Royal College of Ophthalmologists (RCOphth) and the Royal College of Surgeons of Edinburgh grant MRCOphth/FRCOphth and MRCSEd/FRCSEd, (although membership is no longer a prerequisite for fellowship), the Royal College of Glasgow grants FRCS. Postgraduates work as a specialist registrar, and one of these degrees is required for specialization in eye diseases. Such clinical work is within the NHS, with supplementary private work for some consultants.\nOnly 2.3 ophthalmologists exist per 100,000 population in the UK \u2013 fewer \"pro rata\" than in any nations in the European Union.\nUnited States.\nOphthalmologists typically complete four years of undergraduate studies, four years of medical school, and four years of eye-specific training (residency). Some pursue additional training, known as a fellowship \u2013 typically one to two years. Ophthalmologists are physicians who specialize in the eye and related structures. They perform medical and surgical eye care and may also write prescriptions for corrective lenses. They often manage late-stage eye disease, which typically involves surgery.\nOphthalmologists must complete the requirements of continuing medical education to maintain licensure and for recertification.\nNotable ophthalmologists.\nThe following is a list of physicians who have significantly contributed to the field of ophthalmology:\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56154", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=56154", "title": "Odd molecule", "text": ""}
{"id": "56156", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=56156", "title": "World capital cities", "text": ""}
{"id": "56161", "revid": "372", "url": "https://en.wikipedia.org/wiki?curid=56161", "title": "Battle of Abukir Bay", "text": ""}
{"id": "56162", "revid": "50200192", "url": "https://en.wikipedia.org/wiki?curid=56162", "title": "List of architects", "text": "The following is a list of notable architects \u2013 well-known individuals with a large body of published work or notable structures, which point to an article in the English Wikipedia.\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nEarly architects.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n12th-century architects.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n13th-century architects.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n14th-century architects.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n15th-century architects.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n16th-century architects.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n17th-century architects.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n18th-century architects.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n19th-century architects.\nA\u2013M.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nN\u2013Z.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n20th-century architects.\nA\u2013C.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nD\u2013G.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nH\u2013K.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nL\u2013M.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nN\u2013R.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nS\u2013Z.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n21st-century architects.\nA\u2013M.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nN\u2013Z.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nMythological/fictional architects.\nSeveral architects occur in worldwide mythology, including Daedalus, builder of the Labyrinth, in Greek myth. In the Bible, Nimrod is considered the creator of the Tower of Babel, and King Solomon built Solomon's Temple with the assistance of the architect Hiram. In Hinduism, the palaces of the gods were built by the architect and artisan Vishvakarma. Moreover, Indian epic Mahabharata cites amazing work by architect 'Maya.'\nArchitects also occur in modern fiction. Examples include Howard Roark, protagonist in Ayn Rand's \"The Fountainhead\"; Bloody Stupid Johnson, a parody of Capability Brown who appears in Terry Pratchett's \"Discworld\" novels; and Slartibartfast, designer of planets in Douglas Adams's \"The Hitchhiker's Guide to the Galaxy\". Basil Al Bayati's novel \"The Age of Metaphors\" on the theme of Metaphoric Architecture is also replete with fictional architects. The main characters of Sa'ad, Shiymaa and Sa'im are all architects, as are a number of others who appear throughout the book.\nMany films have included central characters who are architects, including Henry Fonda's character \"Juror 8\" (Davis) in \"12 Angry Men\" (1957), Charles Bronson's character in \"Death Wish\" (1974), John Cassavetes' character in \"Tempest\" (1982), Wesley Snipes' character in \"Jungle Fever\" (1991), Christopher Lloyd's character in \"Suburban Commando\" (1991), Tom Hanks' character in \"Sleepless in Seattle\" (1993), David Strathairn's character in \"The River Wild\" (1994), Michael J. Fox's character in \"The Frighteners\" (1996), Michael Keaton's character in \"White Noise\" (2005) and Jeremy Irons' character in \"High-Rise\" (2015).\nIn television, Mike Brady, father of \"The Brady Bunch\", is an architect; as is Wilbur Post, owner of \"Mister Ed\"; Ted Mosby, from \"How I Met Your Mother\", Marshall Darling from \"Clarissa Explains It All\"; and David Vincent from \"The Invaders\". Adam Cartwright of \"Bonanza\" was an architectural engineer with a university education who designed the sprawling familial ranch-house on the Ponderosa Ranch. The character George Costanza pretends to be an architect named \"Art Vandelay\" in \"Seinfeld\". Architect Halvard Solness is the protagonist of Henrick Ibsen's 1892 play \"The Master Builder\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56163", "revid": "30681431", "url": "https://en.wikipedia.org/wiki?curid=56163", "title": "Starship", "text": "Spacecraft designed for interstellar travel\nA starship, starcraft, or interstellar spacecraft is a theoretical spacecraft designed for traveling between planetary systems. The term is mostly found in science fiction. Reference to a \"star-ship\" appears as early as 1882 in \"\".\nWhile NASA's \"Voyager\" and \"Pioneer\" probes have traveled into local interstellar space, the purpose of these uncrewed craft was specifically interplanetary, and they are not predicted to reach another star system; \"Voyager 1\" probe and Gliese 445 will pass one another within 1.6 light years in about 40,000 years. Several preliminary designs for starships have been undertaken through exploratory engineering, using feasibility studies with modern technology or technology thought likely to be available in the near future.\nIn April 2016, scientists announced Breakthrough Starshot, a Breakthrough Initiatives program, to develop a proof-of-concept fleet of small centimeter-sized light sail spacecraft named \"StarChip\", capable of making the journey to Alpha Centauri, the nearest star system, at speeds of 20% and 15% of the speed of light, taking between 20 and 30 years to reach the star system, respectively, and about 4 years to notify Earth of a successful arrival.\nResearch.\nTo travel between stars in a reasonable time using rocket-like technology requires very high effective exhaust velocity jet and enormous energy to power this, such as might be provided by fusion power or antimatter.\nThere are very few scientific studies that investigate the issues in building a starship. Some examples of this include:\nThe Bussard ramjet is an idea to use nuclear fusion of interstellar gas to provide propulsion.\nExamined in an October 1973 issue of \"Analog\", the Enzmann Starship proposed using a 12,000-ton ball of frozen deuterium to power pulse propulsion units. Twice as long as the Empire State Building is tall and assembled in-orbit, the proposed spacecraft would be part of a larger project preceded by interstellar probes and telescopic observation of target star systems.\nThe NASA Breakthrough Propulsion Physics Program (1996\u20132002) was a professional scientific study examining advanced spacecraft propulsion systems.\nTypes.\nTheoretical possibilities.\nThe Alcubierre drive is a speculative warp drive conjectured by Mexican physicist Miguel Alcubierre in a 1994 paper which has not been peer-reviewed. The paper suggests that space itself could be topographically warped to create a local region of spacetime wherein the region ahead of the \"warp bubble\" is compressed, allowed to resume normalcy within the bubble, and then rapidly expanded behind the bubble creating an effect that results in apparent FTL travel, all in a manner consistent with the Einstein field equations of general relativity and without the introduction of wormholes. However, the actual construction of such a drive would face other serious theoretical difficulties.\nFictional examples.\nThere are widely known vessels in various science fiction franchises. The most prominent cultural use and one of the earliest common uses of the term \"starship\" was in \"\".\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56166", "revid": "45718355", "url": "https://en.wikipedia.org/wiki?curid=56166", "title": "Languages in Star Wars", "text": "Fictional languages and scripts\n\"Star Wars\", a space opera franchise created by George Lucas, features various fictional languages throughout its setting. The \"lingua franca\" of the franchise is known in-universe as Galactic Basic, which refers to the language of the film or work itself, be it English or a language that the work was dubbed or translated into.\nCharacters often speak languages other than Basic, notably Shyriiwook spoken by Chewbacca and other Wookiees, droidspeak spoken by R2-D2 and BB-8, Ewokese spoken by Ewoks, and Huttese spoken by Jabba the Hutt. None of these language names appear in the \"Star Wars\" films themselves.\nThe fictional languages were approached as sound design and developed largely by Ben Burtt, sound designer for both the original and prequel trilogies of films. He created alien dialogue out of the sounds of primarily non-English languages, such as Quechua, Haya, and Tibetan. This methodology was also used in \"\" by Sara Forsberg. Lucas also insisted that written text throughout the films look as dissimilar from the English alphabet as possible, and constructed alphabets were developed.\nCritics contend the languages constructed for the films compared unfavorably with the true constructed languages found in some other fictional works. The usage of heavily accented English for extraterrestrials characters was also criticized as contributing to the suggestion of racial stereotypes.\nDevelopment.\nLanguage development was approached as sound design and was handled by Ben Burtt, sound designer for both the original and prequel trilogies. He created the alien dialogue out of existing non-English language phrases and their sounds, such as Quechua for Greedo in the original \"Star Wars\" film and Haya for the character Nien Nunb in \"Return of the Jedi\". He also used English, as in the original \"Star Wars\", where he synthesized originally English dialogue from a Western film until it sounded alien. Burtt said of the process: \"It usually meant doing some research and finding an existing language or several languages which were exotic and interesting, something that our audience \u2014 99 percent of them \u2014 would never understand.\"\nThis methodology to create the sound of alien languages was carried into production of \"\". Director J. J. Abrams asked Sara Forsberg, who lacked a professional background in linguistics but created the viral video series \"What Languages Sound Like to Foreigners\" on YouTube, to develop alien dialogue spoken by Indonesian actor Yayan Ruhian. Forsberg was asked to listen to \"Euro-Asian languages\", and she drew from Gujarati, Hindi, and other Asian languages as well as Indonesian and Sundanese, Ruhian's native language. She also listened to languages she did not understand to better structure the words and sentences to sound believable.\nDuring production of the prequel trilogy, Lucas insisted that written text throughout the films look as dissimilar from the English alphabet as possible and strongly opposed English-looking characters in screens and signage. In developing typefaces for use in , including Mandalorian and Geonosian scripts, graphic artist Philip Metschan created alphabets that did not have twenty-six letters like the English alphabet.\nGalactic Basic.\nGalactic Basic, often simply Basic, is \"the language of the work itself\" \u2014 in-universe, it is the lingua franca predominantly spoken by the inhabitants of the galaxy.\nAccents.\nLucas intended to balance American accents and British accents between the heroes and villains of the original film. He also strove to keep accents \"very neutral\", noting Alec Guinness and Peter Cushing's particular British accents, which he perceived as \"sort of mid-Atlantic neutral accents\". \nIn critical commentary on , Patricia Williams of \"The Nation\" felt there was a correlation between accent and social class, noting that Jedi speak with \"crisp British accents\" while the \"graceful conquered women of the Naboo\" and \"white slaves\" such as Anakin and Shmi Skywalker \"speak with the brusque, determined innocence of middle-class Americans\".\nTo decide on the sound of Nute Gunray, a Neimoidian character portrayed by Silas Carson, Lucas and Rick McCallum listened to actors from different countries reading Carson's lines. Eventually, they chose a heavily Thai-accented English, and Carson rerecorded the dialogue to mimic the Thai actor's accent. Gunray's accent was described by critics to be \"Hollywood Oriental\" that contributed to criticism of Gunray as an Asian stereotype. Watto's accent was similarly criticized as lending to anti-Semitic and anti-Arab connotations.\nNon-standard Basic.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"When gone am I, the last of the Jedi will you be.\"\n \u2014an example of Yoda's unusual word order from \"Return of the Jedi\"\nYoda characteristically speaks a non-standard syntax of Basic, primarily constructing sentences in object\u2013subject\u2013verb word order rare in natural languages. This sentence construction is cited as a \"clever device for making him seem very alien\" and characterizes his dialogue as \"vaguely riddle-like, which adds to his mystique\". This tendency is noted to be written for an English-speaking audience; the word order is retained in Estonian subtitles, where it is grammatical but unusual and emphatic, and Yoda's dialogue is in subject\u2013object\u2013verb word order in Czech dubs.\nGungan characters, notably Jar Jar Binks, speak in a heavily accented Basic dialect critics described as a \"Caribbean-flavored pidgin\", \"a pidgin mush of West African, Caribbean and African-American linguistic styles\", \"very like Jamaican patois, albeit a notably reductive, even infantilized sort\", and suggestive of stereotypical African-American culture. This was cited as a trait that led to criticism of the Gungan species as a racially offensive stereotype or caricature.\nAurebesh.\nAurebesh is an alphabet used to represent spoken Galactic Basic (i.e. English) and is the most commonly seen form of written language in the \"Star Wars\" franchise; its letters correspond to each English letter, plus certain English digraphs.\nThe alphabet was based on shapes designed by Joe Johnston for the original trilogy, which are briefly featured in screen displays in \"Return of the Jedi\". Johnston's design, called \"Star Wars 76\", was used to create a font and again used in \"Attack of the Clones\" by Metschan, who incorporated the font alongside the later Aurebesh version used in the spin-off products.\nIn the early 1990s, Stephen Crane, art director at West End Games, became intrigued with the shapes as they appeared on the Death Star. He sought to develop them into an alphabet to be used in West End Games' licensed \"Star Wars\" products, primarily to allow players to render their characters' names, and received permission from Lucasfilm to do so as long as it was presented as one of many alphabets in the \"Star Wars\" galaxy, not the sole and exclusive alphabet. After copying the letters from screenshots by hand, he standardized the letters based on shapes similar to the Eurostile font. He named and assigned a value to each letter, and derived the name \"Aurebesh\" from the names of the first two letters: aurek and besh. Once Crane completed the alphabet, Lucasfilm requested a copy to distribute to other licensees.\nIn anticipation of the December 2015 release of \"The Force Awakens\", Google Translate added a feature to render text into Aurebesh in November 2015, which was subsequently removed in February 2016.\nOther languages.\nDathomiri.\nArchaic speech samples are found in \"\" season 3. Mother Talzin, a Witch of Dathomir associated with the Nightsisters, is found speaking Dathomiri while possessing Darth Maul on Dathomir.\nIn April 1994, the then unidentified language first appeared in Dave Wolverton's \"The Courtship of Princess Leia\", when the young Teneniel Djo unleashes a Spell of Storm on Luke Skywalker and Prince Isolder of Hapes. Through retroactive continuity, \"\" (a 1985 made-for-TV film) was the language's first real appearance. In this story, Charal \u2013 a witch later retconned as a Nightsister \u2013 was seen incanting spells over a crystal oscillator.\nBinary.\nBinary is a language consisting of beeps and other synthesized sounds used by some droid characters, such as R2-D2, BB-9E and BB-8. Burtt created R2-D2's dialogue in the original \"Star War\"s with an ARP 2600 analog synthesizer and by processing his own vocalizations via other effects. In \"The Force Awakens\", BB-8's dialogue was created by manipulating the voices of Bill Hader and Ben Schwartz with a talkbox running through a sound effects application on an iPad. Although binary is unintelligible to the viewing audience, many characters in the Star Wars films are able to understand it, most notably Luke Skywalker.\nEwokese.\nThe Ewoks of the forest moon of Endor speak a \"primitive dialect\" of one of the more than six million other forms of communication that C-3PO is familiar with. Ben Burtt, \"Return of the Jedi\"'s sound designer, created the Ewok language Ewokese.\nOn \"Return of the Jedi\" DVD commentary track, Burtt identified the language that he heard in the BBC documentary as Kalmyk Oirat, a tongue spoken by the isolated nomadic Kalmyks. He describes how, after some research, he identified an 80-year-old Kalmyk refugee. He recorded her telling folk stories in her native language, and then used the recordings as a basis for sounds that became the Ewok language and were performed by voice actors who imitated the old woman's voice in different styles. For the scene in which C-3PO speaks Ewokese, actor Anthony Daniels worked with Burtt and invented words, based on the Kalmyk recordings. In a previous scene as C-3PO levitates, the Ewoks also spoke words (such as \"look\", \"this\", and \"beautiful\") of Tagalog.\nMarcia Calkovsky of the University of Lethbridge holds that Tibetan language contributed to Ewok speech along with Kalmyk, starting the story from attempts to use language samples of Native Americans and later turning to nine Tibetan women living in the San Francisco area, as well as one Kalmyk woman. The story behind these languages' choices is referenced in Burtt's 1989 telephone interview, and many of the used Tibetan phrases translated. The initial prayer Ewoks address to C-3PO is the beginning of a Tibetan Buddhist prayer for the benefit of all sentient beings and/or \"brahmavih\u0101ra\"s (or \"apram\u0101\u1e47a\"s). There is also the second quarter of a refuge prayer. People of the Tibetan diaspora were puzzled, as many phrases they understood did not correlate to events on screen.\nGhor.\nGhor is the language of Ghorman, featured in the second season of \"Andor\". A specific language for Ghorman was created to emphasize its sense of community, insularity, pride, and desire to maintain control over itself. Because French actors were cast for Ghorman character, the language was developed by Marina Tyndall based on French and French phonology. Marion Deprez, a French dialogue coach, also contributed to its development. There are two writing systems: Ghorelle (High Ghor) and Dixian (Low Ghor), named after graphic designers Elle McKee and Lauren Dix, respectively.\nRodian.\nIn the original \"Star Wars\" film, Greedo speaks an unspecified alien language understood by Han Solo; it was later identified as Rodian. Bruce Mannheim described Greedo as speaking Southern Quechua in \"morphologically well-formed\" phrases with sentences ultimately meaningless. Allen Sonnefrank, a Quechua speaker and linguistic anthropology student at University of California, Berkeley, claimed Lucasfilm contacted him to record Quechua dialogue for the film. He was told the dialogue was to be played backward for the film. Sonnefrank refused to record the dialogue, feeling it to be a \"potentially exploitative move best made by one whose first language was Quechua, if at all\".\nHuttese.\nA language based on the Quechuan languages, Huttese is a lingua franca in the \"Star Wars\" universe. It is spoken by many groups and species, on Nal Hutta, Nar Shaddaa, Tatooine and other worlds in and around Hutt Space, the region of the galaxy under the Hutts' sphere of influence. In the \"Star Wars Legends\" continuity, the area covers former Hutt Empire dominions.\nIt is spoken in the films by both non-humans (Jabba the Hutt, Watto, Sebulba and others) and humans. Notably The Max Rebo Band communicate and sing in Huttese. Many Huttese alphabets are featured through the franchise, most notably the Boonta alphabet and Nal Huttese. The one considered \"canonical\" by fans is one found on promotional Pizza Hut pizza boxes.\nJawaese and Jawa trade language.\nThe Jawas, also found on Tatooine, speak in a high-pitched, squeaky voice. To speak to others of their species, along with speech, they emit a smell showing their emotions. When trading droids and dealing with non-Jawas, they speak without the smell because many consider the smell \"foul\". A famous exclamation in Jawaese is \"Utinni!\", as screamed by a Jawa to the others in \"A New Hope\", shortly after blasting R2-D2.\nKenari language.\nThe Kenari language spoken in the third episode of \"Andor\" is a blend of Portuguese, Spanish, and Hungarian (Magyar).\nMando'a.\nA written form of the Mandalorian language was developed by Metschan for the display screens of Jango Fett's ship \"Slave I\" in \"Attack of the Clones\", and it was later reused in ' and \"Rebels\". Composer Jesse Harlin, needing lyrics for the choral work he wanted for the 2005 ' video game, invented a spoken form, intending it to be an ancient language. It was named \"Mando'a\" and extensively expanded by Karen Traviss, author of the \"Republic Commando\" novel series.\nMando'a is identified as a primarily spoken, agglutinative language lacking grammatical gender in nouns and pronouns. The language is also identified as lacking a passive voice, primarily speaking in an active voice. It is often vague and described as having three grammatical tenses (present, past, and future). Its speakers typically do not use the tenses other than the present. The language is described as having a mutually intelligible dialect called \"Concordian\" spoken on the planet Concord Dawn, as stated in Traviss's novels \"Order 66\" and \"501st\", and a dialect spoken on Mandalore's moon Concordia is heard in \"The Mandalore Plot\", a season two episode of \"The Clone Wars\".\nSith.\nThe Sith language, intended to be spoken by Sith characters, was created by Ben Grossblatt for the \"Book of Sith\", published in February 2012. Language development and a writing system began in November 2010. Grossblatt sought to create a pronounceable language that was not \"cartoonish\" and \"would conform to the patterns of principles of [human] [\"sic\"] language\". He felt that it needed to \"feel martial and mystical\" and be a \"suitable, aesthetically-pleasing vehicle for communication\". He intended the language's sound as \"tough\u2014but not barbarous\" and as \"convey[ing] a kind of confident, elegant cruelty\". To achieve \"formal, quasi-military\" and \"imposing, undeniable\" qualities, he preferred closed syllables, creating brisk and choppy words. The language is constructed as agglutinative.\nShyriiwook.\nShyriiwook, also known as Wookieespeak, is a language consisting largely of roars and growls spoken by the Wookiee species, notably Chewbacca. Non-Wookiee characters are capable of understanding Shyriiwook, such as Chewbacca's friend Han Solo. Chewbacca's dialogue was created from walrus, camel, bear, and badger recordings from Burtt's personal sound library. One of the most prominent elements was an American black bear living in Happy Hollow Park &amp; Zoo, San Jose, California. The sounds were mixed in different ratios to create different roars.\nTusken Raiders.\nTatooine's Tusken Raiders use a language difficult for non-Tuskens to understand, although the Mandalorian in \"The Mandalorian\" was able to understand and respond in their sign language. According to the \"\" video game, they speak a language of their own. In the game, a droid named HK-47 assists the player in communicating with the Tusken Raiders. They commonly utter roars and battle cries when seen in public.\nThe script for \"The Mandalorian\" episode \"\" stated that the Mandalorian and a Tusken Raider communicate using a sign language, and a hearing member of the crew who knew sign language encouraged the production to look for a deaf person to consult on the sign language and play the Tusken Raider. Troy Kotsur was cast in the role, and he developed the Tusken Sign Language based on the environment and culture of the Tusken Raiders rather than using American Sign Language. The hand shapes used for the language were kept simple. For example, the sign name for the Mandalorian is a flat handshape based on the letter M to outline the gaps in a Mandalorian helmet and the sign name for Grogu is one's hands on either side of the head to indicate big ears. The Tusken Raiders also converse in Tusken Sign Language in \"The Book of Boba Fett\".\nUbese.\nUbese is a language heard in a \"Return of the Jedi\" scene where a disguised Princess Leia bargains with Jabba the Hutt through C-3PO as a translator. Leia repeats the same Ubese phrase three times, translated differently in subtitles and by C-3PO each time. David J. Peterson, a constructed language creator, cited his attempt as a young fan to reconcile this apparent impossibility as an example of how even casual fans may notice errors in fictional constructed languages. He identified Ubese as a \"sketch\" of a language rather than a fully developed language and categorized it as a \"fake language\" intended to \"give the impression of a real language in some context without actually being a real language\". Ultimately, he was critical of Ubese as \"poorly constructed and not worthy of serious consideration\".\nCritical commentary.\nBen Zimmer labeled the method of language construction in \"Star Wars\" \"a far cry\" from that of constructed languages like Klingon, Na'vi, and Dothraki, and he described the use of language as \"never amount[ing] to more than a sonic pastiche\".\nLinguistic anthropologist Jim Wilce summarized analyses of language in \"Star Wars\" conducted through the Society for Linguistic Anthropology's electronic mailing list. David Samuels described the approach to language as instrumental and compared the films to a Summer Institute of Linguistics convention, in which \"there are no untranslatable phrases, and everyone can understand everyone else\", and pointed out that the \"idea that the Force is something that would be understood differently in the context of different grammars is never broached\". Hal Schiffmann made five observations about language in \"Star Wars\": all humans speak English and no other real-world language, there is \"mutual passive bilingualism\" in which characters speaking different languages understand one another, non-human creatures may have their own languages but are translated by C-3PO, certain non-English vocalizations serve to confuse or amuse the audience rather than serve as language, even non-English speaking characters are expected to understand English. Zimmer supported Schiffmann's claim that untranslated alien languages are not representations of real languages by pointing to the film's script, which describes the language of the Jawas as \"a queer, unintelligible language\" and that of the Tusken Raiders as \"a coarse, barbaric language\". Wilce also pointed out discussion on the usage of real non-English to create the \"Otherness\" of characters such as Jabba the Hutt, Greedo, and the Ewoks.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "56167", "revid": "13892963", "url": "https://en.wikipedia.org/wiki?curid=56167", "title": "Orleans County, New York", "text": "County in New York, United States\nOrleans County is a county in the western part of the U.S. state of New York. As of the 2020 census, the population was 40,343. The county seat is Albion. The county received its name at the insistence of Nehemiah Ingersoll though historians are unsure how the name was selected. The two competing theories are that it was named to honor the French Royal House of Orleans or that it was to honor Andrew Jackson's victory in New Orleans. The county is part of the Finger Lakes region of the state.\nLocated on the south shore of Lake Ontario, Orleans County since the late 20th century has been considered part of the Rochester, New York metropolitan area.\nHistory.\nWhen counties were established by the British authorities in the province of New York in 1683, the present Orleans County was part of the territory of Albany County. This was an enormous county, including the northern part of present-day New York State as well as all of the present State of Vermont and, in theory, extending westward to the Pacific Ocean. This county was reduced in size on July 3, 1766, by the creation of Cumberland County, and further on March 16, 1770, by the creation of Gloucester County, both containing territory now in Vermont.\nOn March 12, 1772, the remaining Albany County was split into three parts, one remaining under the name Albany County. Tryon County contained the large western portion (and thus, since no western boundary was specified, theoretically still extended west to the Pacific). The eastern boundary of Tryon County was approximately five miles west of the present city of Schenectady, and the county included the Mohawk River valley, the western part of the Adirondack Mountains and the area west of the West Branch of the Delaware River. The area then designated as Tryon County now includes 37 counties of New York State. The county was named for William Tryon, colonial governor of New York. This western area was occupied largely by the Onondaga, Oneida and other western nations of the Iroquois Confederacy. The westernmost European settlements were in the area of Little Falls and present-day Herkimer.\nDuring the unrest prior to the outbreak of the American Revolutionary War, feelings ran high in the Mohawk Valley, and there were local attacks by rebels against known Loyalists. Most of Tryon County's Loyalists fled to Canada before 1776, where they were later granted land by the Crown to develop what is now Ontario.\nIn 1784, following the peace treaty that ended the American Revolutionary War, Tryon County's name was changed to Montgomery County to honor the general, Richard Montgomery. He had captured several places in Canada and died attempting to capture the city of Quebec. It replaced the name of the now hated colonial British governor. In 1789, Ontario County split off from Montgomery. During this period, thousands of migrants settled in the western part of the state from New England and eastern New York resulting in the creation of more counties.\nIn 1802, Genesee County was created by splitting Ontario County. Genesee County was then divided into Allegany County in 1806, Cattaraugus, Chautauqua, and Niagara Counties in 1808, Ontario, Livingston, and Monroe Counties in 1821, and finally Orleans County in 1824.\nWhen Orleans County was formed in 1824, a dispute arose about naming it after President Andrew Jackson or President John Adams. During and following the Napoleonic era in France, numerous French refugees came to New York, some settling in the upstate areas.\nGeography.\nAccording to the U.S. Census Bureau, the county has a total area of , of which is land and (52%) is water.\nThe high proportion of water is due to the extension of Orleans County north into Lake Ontario to the Canada\u2013US border (a line of latitude running through the middle of the lake). The distance from the Orleans shore north to the international border is greater than the distance from the shore south to the Genesee County line, meaning the area of Orleans under water is greater than that above water.\nOrleans County is in western New York State, northeast of Buffalo and west of Rochester, on the southern shore of Lake Ontario.\nThe Erie Canal passes (east\u2013west) through the middle of the county. When its construction was completed in 1824, it attracted new settlers to the largely rural county. Trade and passenger traffic stimulated the development of local businesses.\nGovernment and politics.\nStarting in 1824, the county government was run by a board of supervisors, consisting of elected supervisors from each township in Orleans County. This geographic representation meant that the residents of more urbanized areas were underrepresented on the board.\nIn 1980, the state and county established a seven-member elected legislature to replace the board of supervisors. Representatives are elected from single-member districts roughly equal in population. It is headed by a chairman.\nOrleans County is heavily Republican. It has voted Republican in every presidential election since the party's founding in 1856, except for one, 1964. It also voted Whig in every presidential election from 1828 until 1852.\nCounty government.\nState and federal government.\nOrleans County is part of:\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2000 census.\nAs of the census of 2010, there were 42,883 people, 16,119 households, and 10,872 families residing in the county. The population density was . There were 17,347 housing units at an average density of . The racial makeup of the county was 89.8% White, 5.9% Black or African American, 0.6% Native American, 0.4% Asian, 0.0% Pacific Islander, 1.3% from other races, and 1.9% from two or more races. 4.1% of the population were Hispanic or Latino of any race. According to Census 2000, 20.3% were of German, 18.3% English, 10.8% Italian, 10.3% Irish, 9.4% American and 7.3% Polish ancestry and 96.0% spoke English and 3.0% Spanish as their first language.\nCensus 2010 showed there were 16,119 households, out of which 31.2% had children under the age of 18 living with them, 49% were married couples living together, 12.4% had a female householder with no husband present, and 32.6% were non-families. 26.2% of all households were made up of individuals, and 11% had someone living alone who was 65 years of age or older. The average household size was 2.5 and the average family size was 2.99.\nIn the county, the population was spread out, with 19.8% under the age of 18, 8.8% from 18 to 24, 24.2% from 25 to 44, 29.8% from 45 to 64, and 17.40% who were 65 years of age or older. The median age was 41 years.\nThe median income for a household in the county was $48,731. Males had a median income of $32,450 versus $22,605 for females. The per capita income for the county was $16,457. About 15.2% of the population were below the poverty line.\nEducation.\nPublic schools\nThe county has five school districts, although the actual district boundaries can extend into neighboring counties, and the same is true for neighboring counties' districts. The five districts, from west to east, are:\nEach of these school districts participates in Orleans/Niagara BOCES or Monroe #2-Orleans BOCES.\nPrivate school\nThere is currently one non-denominational K-12 school in the county.\nCollege\nOne college maintains satellite campuses in Orleans County.\nRecreation.\nThe County of Orleans has created an interactive map of notable places for visitors to see while visiting the county.\nhttps://orleanscountytourism.com/history/\nLakes.\nThere are two major dams on Oak Orchard Creek that have created public boating areas.\nLibraries.\nOrleans County has 4 public libraries serving its population.\nMuseums.\nOrleans County has 6 museums that are open to the public.\nParks.\nThere are two State Parks and many municipal parks spread throughout the county.\nTransportation.\nOrleans County has eight private airstrips and one public-use airport:\nRTS Orleans provides bus service to Orleans County. The county's Department of Public Works is headquartered in Albion and is charged with maintaining roads, including:\nEach town and village within Orleans County maintains its own highway department.\nMajor roadways.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nThe former New York State Route 941M was located in Orleans County.\nCommunities.\nLarger Settlements.\nAll larger settlements are Villages\nTowns.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56168", "revid": "237572", "url": "https://en.wikipedia.org/wiki?curid=56168", "title": "Orange County, New York", "text": "County in New York, United States\nOrange County is a county located in the U.S. state of New York. As of the 2020 United States census, the population was 401,310. The county seat is Goshen. This county was first created in 1683 and reorganized with its present boundaries in 1798. The county is part of the Hudson Valley region of the state.\nOrange County is part of the Kiryas Joel-Poughkeepsie-Newburgh metropolitan statistical area, which belongs to the larger New York\u2013Newark\u2013Bridgeport, NY\u2013NJ\u2013CT\u2013PA Combined Statistical Area.\nAs of the 2020 census the center of population of the state of New York was located in Orange County, in the hamlet of Cuddebackville\nHistory.\nOrange County was officially established on November 1, 1683, when the Province of New York was divided into twelve counties. Each of these was named to honor a member of the British royal family, and Orange County took its name from the Prince of Orange, who subsequently became King William III of England. As originally defined, Orange County included only the southern part of its present-day territory, plus all of present-day Rockland County further south. The northern part of the present-day county, beyond Moodna Creek, was then a part of neighboring Ulster County.\nAt that date, the only European inhabitants of the area were a handful of Dutch colonists in present-day Rockland County, and the area of modern Orange County was entirely occupied by the native Munsee people. Due to its relatively small population, the original Orange County was not fully independent and was administered by New York County.\nThe first European settlers in the area of the present-day county arrived in 1685. They were a party of around twenty-five families from Scotland, led by David Toshach, the Laird of Monzievaird, and his brother-in-law Major Patrick McGregor, a former officer of the French Army. They settled in the Hudson Highlands at the place where the Moodna Creek enters the Hudson River, now known as New Windsor. In 1709, a group of German Palatine refugees settled at Newburgh. They were Protestants from a part of Germany along the Rhine that had suffered during the religious wars. Queen Anne's government arranged for passage from England of nearly 3,000 Palatines in ten ships. Many were settled along the Hudson River in work camps on property belonging to Robert Livingston. In 1712, a 16-year-old indentured servant named Sarah Wells from Manhattan led a small party of three Munsee men and three hired carpenters into the undeveloped interior of the county and created the first settlement in the Town of Goshen on the Otter Kill. She was falsely promised by her master Christopher Denne 100 acres bounty for taking on the dangerous mission to make a land claim for him. He never gave her the land. But, she did fall in love and married Irish immigrant William Bull there in 1718 and they had 12 children and built the Bull Stone House. In 1716, the first known woman of African descent resident was recorded in Orange County. Her name was Mercy. She was enslaved by Christopher Denne at his settlement on the Otter Kill. Additional immigrants came from Ireland; they were of Scots and English descent who had been settled as part of the Scottish and English settlements there.\nDuring the American Revolutionary War the county was divided into Loyalists, Patriots, and those who remained neutral. The local government supported the Revolution, or \"The Cause\". Some residents posed as Loyalists but were part of a secret spy network set up by Gen. George Washington. Capt. William Bull III of the Town of Wallkill (which was then a part of Ulster County) served in the Continental Army with Gen. Washington in Spencer's Additional Continental Regiment. His cousin was revealed after the war to be part of Washington's spy ring. His brother Moses Bull raised 20 men from the Town of Wallkill to service with his brother. Capt. Bull was promoted twice for valor on the battlefield, once in the Battle of Monmouth where he was part of Lord Stirling's men who famously saved the day after Gen. Lee's retreat. Capt. Bull https:// at Valley Forge with several men from Orange County. Capt. Bull retired from the Army in 1781 and returned to the Town of Wallkill where he built Brick Castle. Hundreds of men from Orange County served in the local militia and many of them fought in the Battle of Fort Montgomery and Fort Clinton. However, many residents remained loyal to King George III, include members of Capt. Bull's family. Many in the county were divided within families. Capt. Bull's uncle Thomas Bull was jailed for years in Goshen and then Fishkill for being a Loyalist. Resident Claudius Smith was a Loyalist marauder whose team robbed and terrorized citizens; he was hanged in Goshen in 1779 for allegedly robbing and killing Major Nathaniel Strong; two of his sons were also executed for similar crimes. Capt. Bull's cousin Peter Bull of Hamptonburgh served in the Orange County regiment and was charged with guarding the roads at night from Smith. The Mathews family of Blooming Grove were active Loyalists; Fletcher Mathews was a sympathizer and sometime associate of Smith, and his brother David Mathews was Mayor of New York City during its British occupation for the entirety of the war.\nIn 1798, after the American Revolutionary War, the boundaries of Orange County changed. Its southern corner was used to create the new Rockland County, and in exchange, an area to the north of the Moodna Creek was added, which had previously been in Ulster County. This caused a reorganization of the local administration, as the original county seat had been fixed at Orangetown in 1703, but this was now in Rockland County. Duties were subsequently shared between Goshen, which had been the center of government for the northern part of Orange County, and Newburgh, which played a similar role in the area transferred from Ulster County. The county court was established in 1801. It was not until 1970 that Goshen was named as the sole county seat.\nDue to a boundary dispute between New York and New Jersey, the boundaries of many of the southern towns of the county were not definitively established until the 19th century.\nGeography.\nAccording to the U.S. Census Bureau, the county has a total area of , of which is land and (3.2%) are water.\nOrange County is in southeastern New York State, directly north of the New Jersey-New York border, west of the Hudson River, east of the Delaware River and northwest of New York City. It borders the New York counties of Dutchess, Putnam, Rockland, Sullivan, Ulster, and Westchester, as well as Passaic and Sussex counties in New Jersey and Pike County in Pennsylvania.\nOrange County is the only county which borders both the Hudson and Delaware Rivers, and is also the only county in the state to border both New Jersey (south) and Pennsylvania (west).\nOrange County is where the Great Valley of the Appalachians finally opens up and ends. The western corner is set off by the Shawangunk Ridge. The area along the Rockland County border (within Harriman and Bear Mountain state parks) and south of Newburgh is part of the Hudson Highlands. The land in between is the valley of the Wallkill River. In the southern portion of the county the Wallkill valley expands into a wide glacial lake bed known as the Black Dirt Region for its fertility.\nThe highest point is Schunemunk Mountain, at above sea level. The lowest is sea level along the Hudson.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2018.\nPer the American Community Survey's 2018 estimates, there were 381,951 residents within Orange County. 63.5% of the county was non-Hispanic white, 12.95 Black or African American, 0.8% Native American, 2.9% Asian, 0.1% Pacific Islander, 3.0% from two or more races, and 21.0% Hispanic or Latino of any race. 24.4% of Orange County's residents spoke another language other than English at home.\nThere were 126,776 households in 2018 and an average of 2.90 persons per household. The owner-occupied housing rate was 68.0% and the median gross rent of the county was $1,223. The median homeowner cost with a mortgage was $2,280 and $909 without a mortgage.\nThe median income for a household from 2014 to 2018 was $76,716 and the per capita income was $33,472. 11.5% of the county's inhabitants were below the poverty line in 2018.\n2010 census.\nAt the 2010 United States census, there were 372,813 people living in the county. The population density was . The racial makeup of the county was 77.2% White, 10.2% Black or African American, 0.5% Native American, 2.4% Asian, and 3.1% from two or more races. 18% of the population were Hispanic or Latino of any race. According to the 2000 United States census, 18.3% were of Italian, 18.1% English, 17.4% Irish, 10.2% German, and 5.0% Polish ancestry. According to the 2009\u201313 American Community Survey, 76.57% of people spoke only English at home, 13.39% spoke Spanish, 4.03% spoke Yiddish, and 0.83% spoke Italian.\nDuring the 2000 Census, there were 114,788 households, out of which 39.60% had children under the age of 18 living with them, 57.90% were married couples living together, 11.40% had a female householder with no husband present, and 26.40% were non-families. 21.50% of all households were made up of individuals, and 8.50% had someone living alone who was 65 years of age or older. The average household size was 2.85 and the average family size was 3.35.\nIn the county, the population was spread out, with 29.00% under the age of 18, 8.70% from 18 to 24, 30.00% from 25 to 44, 21.90% from 45 to 64, and 10.30% who were 65 years of age or older. The median age was 35 years. For every 100 females, there were 100.30 males. For every 100 females age 18 and over, there were 97.50 males.\nThe median income for a household in the county was $52,058, and the median income for a family was $60,355. Males had a median income of $42,363 versus $30,821 for females. The per capita income for the county was $21,597. About 7.60% of families and 10.50% of the population were below the poverty line, including 14.80% of those under age 18 and 8.00% of those age 65 or over.\nDespite its rural roots, Orange County has been among the fastest-growing regions within the New York City metropolitan area.\nLaw and government.\nOriginally, like most New York counties, Orange County was governed by a board of supervisors. Its board consisted of the 20 town supervisors, nine city supervisors elected from the nine wards of the City of Newburgh, and four each elected from the wards of the cities of Middletown and Port Jervis. In 1968, the board adopted a county charter and a reapportionment plan that created the county legislature and executive. The first county executive and legislature were elected in November 1969 and took office on January 1, 1970. Today, Orange County is still governed by the same charter; residents elect the county executive and a 21-member county legislature elected from 21 single-member districts. There are also several state constitutional positions that are elected, including a sheriff, county clerk and district attorney. Prior to January 1, 2008, four coroners were also elected; however, on that date, the county switched to a medical examiner system.\nThe current county officers are:\nThe County Legislature and its previous board of supervisors were long dominated by the Republican Party. However, since the late 20th century, the Democrats have closed the gap. During 2008 and 2009 the legislature was evenly split between 10 Republicans, 10 Democrats, and 1 Independence Party member. In 2009, the legislature had its first Democratic chairman elected when one member of the Republican caucus voted alongside the 10 Democratic members to elect Roxanne Donnery (D-Highlands/Woodbury) to the post. At the November 2009 election, several Democratic incumbents were defeated. As of the convening of the legislature on January 1, 2022, there are 14 Republicans, 6 Democrats, and 1 Independence member.\nIn recent years, Orange County has emerged as a swing county, mirroring the preferences of the nation as a whole in presidential elections, voting for the winner in every election from 1996 to 2016. The streak ended in 2020, however, as Orange County narrowly voted to re-elect Donald Trump, even as Democratic nominee Joe Biden of Delaware won the election overall. Bill Clinton won Orange County 48% to 40% in 1996. George W. Bush won 50% of the Orange County vote in 2000, and 55% in 2004. Barack Obama carried the county with a 52% vote share four years later and carried the county again in 2012. However, Donald Trump won the county in 2016, thus making it one of 206 counties across the country to vote for Obama twice and then Trump. In 2020, Trump again won Orange County, this time by just 312 votes out of nearly 170,000 votes cast, a margin of about 0.2 percentage points. Despite this, it was only the fourth-closest county in the state and one of five that Trump won by less than 500 votes.\nPreviously, like most of the Lower Hudson, Orange County had leaned Republican. From 1884 to 1992, a Republican carried Orange County in all but one presidential election. The only time this tradition was broken was in 1964, during Democrat Lyndon Johnson's 44-state landslide. County voters have shown a willingness to sometimes elect Democrats, such as U.S. Rep. John Hall. From 2007 on, when Hall represented the 19th district, which covered most of the county, Orange's representation in Congress was exclusively Democratic, as Maurice Hinchey had represented the towns of Crawford, Montgomery, and Newburgh as well as the city of Newburgh, all of which were in what was then the 22nd district, since 1988.\nIn the 2010 midterms, Hall was defeated by Nan Hayworth. In 2012, after Hinchey's former 22nd district was eliminated in redistricting following his retirement and all of Orange County was included in the current 18th district. Hayworth was defeated by Democrat Sean Patrick Maloney, a former adviser to President Bill Clinton and the first openly gay person to be elected to Congress from New York. Maloney won a rematch against Hayworth in 2014; in 2016 he was again re-elected over Phil Oliva, and in 2018, despite running in the Democratic primary for New York Attorney General, he won re-election again over James O'Donnell. Maloney was re-elected in 2020, defeating the 2018 Republican nominee for US Senate Chele Farley. Due to redistricting, Maloney left the 18th District and the seat was left vacant. The Democrats nominated former Ulster County Executive and incumbent Congressman from the 19th Congressional District Pat Ryan, while the Republicans chose then-Assemblyman Colin Schmitt. While Ryan won the district as a whole, Schmitt won Orange County itself by 9,652 votes, or approximately 7.94%.\nAt the state level, Republicans had held onto both State Senate seats until 2018, when John Bonacic retired after 26 years, the 42nd district was then won by Democrat Jen Metzger, for 1 term. In 2020 it returned to the GOP, via Mike Martucci, who chose not to run for re-election in 2022. The 39th State Senate District was held by Democrat James Skoufis from 2016 through 2022, when statewide redistricting moved Skoufis to the newly drawn 42nd district. Skoufis was re-elected to this new district, consisting of most of the county. Newburgh and Maybrook, meanwhile, remained in the new 39th District, held since 2022 by Republican Robert Rolison.\nDemocrats have also made significant gains in the county's State Assembly seats. The 98th district, which includes the far western part of the county as well as the Town of Warwick, is represented by Karl Brabenec, and the 101st district, which includes the Towns of Crawford and Montgomery, was until 2016 held by Claudia Tenney, both Republicans. After Tenney left her seat to run for Congress that year, Brian Miller, another Republican, was elected to replace her. He held the seat until 2022 when redistricting moved him elsewhere, and he was replaced by fellow Republican Brian Maher. Colin Schmitt represented the 99th district until 2022 when it was redrawn and he left to run for Congress. The district was won by Chris Eachus, a Democrat. The other two districts are also held by Democrats: Aileen Gunther in the 100th district (Middletown) and Jonathan Jacobson in the 104th district (Newburgh).\nSports.\nDelano-Hitch Stadium in Newburgh has played host to various professional and amateur baseball teams from various leagues since opening in 1926. The stadium was home to the North Country Baseball League Newburgh Newts for the 1st and only season, 2015.\nHigh school sports.\nHigh schools in Orange County compete in Section 9 of the New York State Public High School Athletic Association along with schools from Dutchess, Ulster, and Sullivan counties.\nCollege sports.\nThe Army Black Knights of the United States Military Academy in West Point field NCAA Division I teams in 24 different sports. Mount Saint Mary College in Newburgh fields 15 teams in the Eastern College Athletic Conference and the Skyline Conference of NCAA Division III. Orange County Community College Colts in Middletown compete in the National Junior College Athletic Association.\nMotorsports.\nThe Orange County Fair Speedway hosts weekly series racing along with the Super DIRTcar Series along with monster trucks and demolition derbies. They also have a Dirt bike track located outside Turns 3 and 4 of the Speedway. Some notable drivers to race at the track include Stewart Friesen, Brett Hearn and Max McLaughlin.\nCommunities.\nTowns.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nVillages.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCensus-designated places.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nHamlets.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nEducation.\nSchool districts.\nSchool districts include:\nSecondary.\nPrivate secondary educational institutions:\nPoints of interest.\nPoints of interest in Orange County include the United States Military Academy at West Point; OC Gov. Center, a Paul Rudolph Brutalist design in Goshen, NY; Brotherhood Winery in Washingtonville, America's oldest (continuously functioning) winery (as it made legal \"sacramental\" church wines during Prohibition); the birthplace of William H. Seward in Florida; Museum Village in Monroe, an 18th Century Colonial town; the Harness Racing Museum &amp; Hall of Fame in Goshen; Bull Stone House, a NY Historical designated structure, built in 1722 and still used as a private residence (10 generations) by the Bull family, as well as the William Bull III House, built in the 1780s. The Historical, Art Deco style Paramount Theatre (Middletown, New York), built in 1930. Thrall Library/Middletown station (Erie Railroad), built in 1896, closed in 1983, refurbished (&amp; expanded) into a public library in 1995. The multi-acre, Salesian Seminary, in Goshen, which trained NYC novitiates for the priesthood, was sold to the Village c.\u20092005 and a $4.5 million state-of-the-art library built on the grounds in 2018.\nThree state parks: Goosepond Mountain State Park, Harriman State Park and Sterling Forest State Park. Sugarloaf arts community, which features the Lyceum Center theatre. The \"Times Herald-Record\" newspaper, the first cold press offset daily in the country, in Middletown\nCommercial centers of interest include the Galleria at Crystal Run, in Wallkill; Woodbury Common Premium Outlets in Monroe. The Orange County Fair in Wallkill is an annual 2 or 3 week summer event, dating back to 1808, but officially opening in 1841. Newburgh was the location of Orange County Choppers, 61,000 square foot, $12 million, custom motorcycle-shop facility featured on The Discovery Channel's reality television series \"American Chopper\" but it was closed and sold by 2020. The home and birthplace of Velveeta and Liederkranz Cheese is in Monroe (village), while Philadelphia Cream Cheese was invented in Chester.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFilmography.\nOrange County, New York, has hosted 27 films and 16 TV Shows since 2018 including Lake George (2025), which utilized the area's scenic settings, and \"The Whale\" (2022), with significant scenes filmed in Newburgh. \"The Pale Blue Eye\" (2022), a Netflix production starring Christian Bale, also featured locations in New Windsor.\nThe Hallmark movie \"One December Night\" (2021) showcased the towns of Goshen and Newburgh, while Martin Scorsese's \"The Irishman\" (2019) included scenes in Tuxedo and Washingtonville. In television, HBO's \"The White House Plumbers\" (2023) filmed at the Karpeles Manuscript Library in Newburgh.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56169", "revid": "37371155", "url": "https://en.wikipedia.org/wiki?curid=56169", "title": "Oswego County, New York", "text": "County in New York, United States\nOswego County is a county in the U.S. state of New York. As of the 2020 United States census, the population was 117,525. The county seat is Oswego. The county name is from a Mohawk-language word meaning 'the pouring out place', referring to the point at which the Oswego River feeds into Lake Ontario at the northern edge of the county in the city of Oswego. The county is part of the Central New York region of the state.\nOswego County is part of the Syracuse metropolitan area.\nHistory.\nWhen counties were established in the British colony of New York in 1683, the present Oswego County was part of Albany County. This was an enormous county, including the northern part of what is now New York state as well as all of the present state of Vermont and, in theory, extending westward to the Pacific Ocean. This county was reduced in size on July 3, 1766, by the creation of Cumberland County in the British colony, and further on March 16, 1770, by the creation of Gloucester County, both containing territory now in Vermont.\nOn March 12, 1772, what was left of Albany County was split into three parts, one remaining under the name Albany County. One of the other pieces, Tryon County, contained the western portion (and thus, since no western boundary was specified, theoretically still extended west to the Pacific). The eastern boundary of Tryon County was approximately west of the present city of Schenectady, and the county included the western part of the Adirondack Mountains and the area west of the West Branch of the Delaware River. The area then designated as Tryon County now includes 37 counties of New York State. The county was named for William Tryon, colonial governor of New York.\nIn the years prior to 1776, most of the Loyalists in Tryon County fled to Canada. In 1784, following the peace treaty that ended the American Revolutionary War, the name of Tryon County was changed to Montgomery County to honor the general, Richard Montgomery, who had captured several places in Canada and died attempting to capture the city of Quebec, replacing the name of the hated British governor.\nIn 1789, the size of Montgomery County was reduced by the splitting off of Ontario County from Montgomery. The actual area split off from Montgomery County was much larger than the present county, also including the present Allegany, Cattaraugus, Chautauqua, Erie, Genesee, Livingston, Monroe, Niagara, Orleans, Steuben, Wyoming, Yates, and part of Schuyler and Wayne counties.\nOswego County was partly in Macomb's Purchase of 1791.\nIn 1791, Herkimer County was one of three counties split off from Montgomery (the other two being Otsego, and Tioga County). This was much larger than the present county, however, and was reduced by a number of subsequent splits.\nIn 1794, Onondaga County was created from a part of Herkimer County. This county was larger than the current Onondaga County, including the present Cayuga, Cortland, and part of Oswego counties.\nIn 1798, Oneida County was created from a part of Herkimer County. This county was larger than the current Oneida County, including the present Jefferson, Lewis, and part of Oswego counties.\nIn 1805, Oneida County was reduced in size by the splitting off of Jefferson and Lewis counties.\nIn 1816, Oswego County was created as New York State's 48th county from parts of Oneida and Onondaga counties.\nIn 1841, businessmen in Oswego attempted to divide Oswego County into two counties. They failed to persuade the State to do so, however. Occasionally, the topic still resurfaces today by dividing the county into an east part and a west part, with the east portion being renamed \"Salmon County\".\nAt various times, beginning in 1847 and as late as 1975, attempts were made to move the county seat to the Village of Mexico. However, none of these attempts succeeded.\nOn April 20, 2002, at around 6:50 am, many residents of Oswego County were shaken awake by a magnitude 5.2 earthquake centered near Plattsburgh, New York. Minor damage to a Fire Hall in Altmar was the only report of damage. No injuries were sustained.\nDuring February 1\u201312, 2007, a major lake effect snowfall dumped over of snow in many places in Oswego County, resulting in several roof collapses, some communities being cut off, and some people being snowed-in in their homes. A state of emergency was declared for the county, and the National Guard was sent in to help clear the snow.\nGeography.\nAccording to the U.S. Census Bureau, the county has a total area of , of which is land and , comprising 27%, is water.\nOswego County is in northwestern New York State, just north of Syracuse and northwest of Utica, on the eastern shore of Lake Ontario. Part of the Tug Hill Plateau is in the eastern part of the county and, at , is the highest point. The Salmon River Falls, a waterfall, is a popular sightseeing destination in the northeastern portion of the county.\nThere are two harbors in the county: Oswego Harbor at the mouth of the Oswego River and Port Ontario on the Salmon River. The first major port of call on the Great Lakes is the Port of Oswego Authority dock.\nMajor highways.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nOswego County is also home to two colleges: State University of New York at Oswego in the Town of Oswego and the Fulton Branch Campus of Cayuga County Community College in the City of Fulton.\n2000.\nAs of the census of 2000, there were 122,377 people, 45,522 households, and 31,228 families residing in the county. The population density was . There were 52,831 housing units at an average density of . The racial makeup of the county was 97.17% White, 0.59% Black or African American, 0.41% Native American, 0.42% Asian, 0.01% Pacific Islander, 0.48% from other races, and 0.93% from two or more races. Hispanic or Latino of any race were 1.30% of the population. 15.5% were of Irish, 14.0% German, 13.7% Italian, 13.3% English, 9.6% American, 7.9% French and 5.3% Polish ancestry according to Census 2000. 96.2% spoke English and 1.7% Spanish as their first language.\nThere were 45,522 households, out of which 35.00% had children under the age of 18 living with them, 52.80% were married couples living together, 10.80% had a female householder with no husband present, and 31.40% were non-families. 24.30% of all households were made up of individuals, and 9.70% had someone living alone who was 65 years of age or older. The average household size was 2.60 and the average family size was 3.08.\nIn the county, the population was spread out, with 26.80% under the age of 18, 10.90% from 18 to 24, 28.90% from 25 to 44, 22.10% from 45 to 64, and 11.30% who were 65 years of age or older. The median age was 35 years. For every 100 females there were 97.50 males. For every 100 females age 18 and over, there were 94.40 males.\nThe median income for a household in the county was $36,598, and the median income for a family was $43,821. Males had a median income of $34,976 versus $23,938 for females. The per capita income for the county was $16,853. About 9.70% of families and 14.00% of the population were below the poverty line, including 17.10% of those under age 18 and 9.50% of those age 65 or over.\nCommunities.\nOswego County has 22 towns, 2 cities, and 10 villages.\nLarger settlements.\n\u2020 - County seat\n\u2020\u2020 - Former village\n\u2021 - Not wholly in this county\nTowns.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNature.\nThe Lake Ontario National Marine Sanctuary lies in the waters of southeastern Lake Ontario off Oswego County.\nSwimming places in the county include\nEconomy.\nOswego's economy is most prominent as industry; in 2012, manufactured shipments made up $2.1 billion of the local economy. Retail made up the next most prominent sector, totaling $1.2 billion or more than $10,000 per resident. Wholesale merchants also made $368 million sales the same year. Services made up the final total, equal to over $500 million in food service, healthcare, accommodation, and social services.\nMedia.\nSample News Group owns and publishes four periodical newspapers in the county, \"The Palladium-Times\", \"Valley News\", \"Oswego County News\" and \"Oswego Shopper\". These collectively operate the website OswegoCountyNewsNow.com.\nGovernment and politics.\nThe Oswego County Legislature has 25 members, elected from equal population districts, reduced from 36 in 1993. The legislators are split between seven committees that meet monthly and also attend a general meeting once per month. The seven standing committees as of December 2019 were Government, Courts and Consumer Affairs; Public Safety; Infrastructure, Facilities and Technology; Economic Development and Planning; Health; Human Services; and Finance and Personnel.\nIn the 2019 general election, the county GOP won three more seats previously occupied by Democrats, expanding its control of the legislature to 23\u20132. The two Democratic candidates who were elected ran unopposed, and there was only one other Democrat running for any of the 25 seats. Meanwhile, a proposition that sought to expand legislator terms from two years to four years was rejected, with 65.06 percent of 17,701 total votes countywide going against the proposition.\nDistrict representation (2024).\nSource:\nOswego County has two representatives in the state assembly, with Republicans William A. Barclay and Brian Manktelow both serving as assemblymen for portions of the county. There are two state senators who represent Oswego County. Mark Walczyk represents the 49th district and Chris Ryan represents the 50th district in the state senate.\nEducation.\nSchool districts include:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56170", "revid": "49089944", "url": "https://en.wikipedia.org/wiki?curid=56170", "title": "Otsego County, New York", "text": "County in New York, United States\nOtsego County is a county in the U.S. state of New York. As of the 2020 census, the population was 58,524. The county seat is Cooperstown. The county's population center is Oneonta. The name \"Otsego\" is from a Mohawk or Oneida word meaning \"place of the rock.\" The county is part of the Mohawk Valley region of the state.\nHistory.\nIn 1789, Ontario County was split off from Montgomery. The area split off from Montgomery County was much larger than the present county, as it included the present Allegany, Cattaraugus, Chautauqua, Erie, Genesee, Livingston, Monroe, Niagara, Orleans, Steuben, Wyoming, Yates, and part of Schuyler and Wayne counties.\nFormation.\nOtsego County was one of three early counties split off from Montgomery (the other two being Herkimer and Tioga) after the American Revolutionary War. Otsego County was officially established on February 16, 1791, with Cooperstown as its county seat. The original county consisted of three large townships:\nOtsego and Cherry Valley together roughly covered the area of modern Otsego County, while Harpersfield covered the area south of the current county as far as the Delaware River.\nGovernor George Clinton made the original appointments to Otsego County government positions, including:\nNew towns.\nBy 1793, four towns had been added to the county by division of the existing towns:\nIn 1795, a piece of Otsego County was joined with a portion taken from Albany County to create Schoharie County.\nIn 1797, a piece of Otsego County was joined with a portion taken from Ulster County to create Delaware County.\nIn 1843, Otsego County, Michigan was named after the county in New York.\nGeography.\nAccording to the U.S. Census Bureau, the county has a total area of , of which is land and (1.4%) is water.\nOtsego County is in central New York State, to the west of Albany, southeast of Utica, and northeast of Binghamton. The county is part of the Central New York Region and Mohawk Valley Region of New York State. The county is considered by some to belong to the Southern Tier region of New York State, and is the northernmost county of the Appalachian Region.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2000 census.\nAs of the census of 2000, there were 61,676 people, 23,291 households, and 15,115 families residing in the county. The population density was . There were 28,481 housing units at an average density of . The racial makeup of the county was 95.80% White, 1.75% African American, 0.23% Native American, 0.63% Asian, 0.05% Pacific Islander, 0.50% from other races, and 1.05% from two or more races. Hispanic or Latino of any race were 1.90% of the population. 15.0% were of Irish, 14.9% English, 14.9% German, 11.3% Italian and 9.1% American ancestry according to Census 2000. 95.4% spoke English and 2.1% Spanish as their first language.\nThere were 23,291 households, out of which 29.60% had children under the age of 18 living with them, 51.10% were married couples living together, 9.50% had a female householder with no husband present, and 35.10% were non-families. 27.00% of all households were made up of individuals, and 11.60% had someone living alone who was 65 years of age or older. The average household size was 2.43 and the average family size was 2.94.\nIn the county, the population was spread out, with 22.70% under the age of 18, 14.40% from 18 to 24, 24.30% from 25 to 44, 23.60% from 45 to 64, and 15.00% who were 65 years of age or older. The median age was 37 years. For every 100 females there were 93.10 males. For every 100 females age 18 and over, there were 90.00 males.\nThe median income for a household in the county was $33,444, and the median income for a family was $41,110. Males had a median income of $29,988 versus $22,609 for females. The per capita income for the county was $16,806. About 8.80% of families and 14.90% of the population were below the poverty line, including 15.80% of those under age 18 and 8.20% of those age 65 or over.\nGovernment and politics.\nOtsego County is generally a swing and bellwether county, having voted for the winner of the national election in every election from 1980 to 2016. In 2004, Otsego County voted 51\u201348 percent in favor of George W. Bush. In 2008 and 2012, Otsego County voted in favor of Barack Obama. Democrats are prevalent in the City of Oneonta and Village of Cooperstown, whereas the majority of voters in many of the surrounding towns are registered Republicans. In 2020 the county voted for 51%-46% Donald Trump, and lost its bellwether status when Biden won the election.\nOtsego County is the only county in New York that names its legislative body the Board of Representatives. It consists of fourteen members elected from single-member districts. The Board Chair is David Bliss (R). The county also has an elected District Attorney, County Treasurer, County Clerk, and County Sheriff.\nMedia.\nAlong with Herkimer County and the eastern portion of Oneida County, northern Otsego County is considered part of the Utica television market, while the southern half of the county, including the city of Oneonta, is considered to be in the Binghamton television market.\nEconomy.\nThe Village of Cooperstown (home of James Fenimore Cooper, whose father William Cooper founded it) is located at the south end of Otsego Lake. It attracts many tourists to the Baseball Hall of Fame and the New York State Historical Association museums. Cultural attractions also include the Glimmerglass Opera, with a summer season that draws many repeat visitors for stays.\nThe primary contributor to the economy is healthcare: Bassett Medical Center, the headquarters of Bassett Healthcare Network and its more than 3,000 employees, is located here.\nThe City of Oneonta has two institutions of higher education: Hartwick College and the State University of New York at Oneonta; A.O. Fox Memorial Hospital, an affiliate of the Bassett Network; major retail activity; and numerous small businesses. The county as a whole remains relatively rural, with dairy farming a contributing industry that has consolidated employment in recent years, although production has remained steady.\nCommunities.\nTowns.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nVillages.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCensus-designated places.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56172", "revid": "15950401", "url": "https://en.wikipedia.org/wiki?curid=56172", "title": "Sugar Cane", "text": ""}
{"id": "56173", "revid": "26995", "url": "https://en.wikipedia.org/wiki?curid=56173", "title": "Granular matter", "text": ""}
{"id": "56175", "revid": "29615425", "url": "https://en.wikipedia.org/wiki?curid=56175", "title": "Sugar cane", "text": ""}
{"id": "56176", "revid": "1639942", "url": "https://en.wikipedia.org/wiki?curid=56176", "title": "Fatimid Caliphate", "text": "Fourth Islamic caliphate (909\u20131171)\nThe Fatimid Caliphate (; ), also known as the Fatimid Empire, was a caliphate extant from the tenth to the twelfth centuries CE under the rule of the Fatimids, an Isma'ili Shi'a dynasty. Spanning a large area of North Africa and West Asia, it ranged from the western Mediterranean in the west to the Red Sea in the east. The Fatimids traced their ancestry to the Islamic prophet Muhammad's daughter Fatima and her husband Ali, the first Shi'a imam. The Fatimids were acknowledged as the rightful imams by different Isma'ili communities as well as by denominations in many other Muslim lands and adjacent regions. Originating during the Abbasid Caliphate, the Fatimids initially conquered Ifriqiya (roughly present-day Tunisia and north-eastern Algeria). They extended their rule across the Mediterranean coast and ultimately made Egypt the center of the caliphate. At its height, the caliphate included\u2014in addition to Egypt\u2014varying areas of the Maghreb, Sicily, the Levant, and the Hejaz.\nBetween 902 and 909, the foundation of the Fatimid state was realized under the leadership of \"da'i\" (missionary) Abu Abdallah, whose conquest of Aghlabid Ifriqiya with the help of Kutama forces paved the way for the establishment of the Caliphate. After the conquest, Abdallah al-Mahdi Billah was retrieved from Sijilmasa and then accepted as the Imam of the movement, becoming the first Caliph and founder of the dynasty in 909. In 921, the city of al-Mahdiyya was established as the capital. In 948, they shifted their capital to al-Mansuriyya, near Kairouan. In 969, during the reign of al-Mu'izz, they conquered Egypt, and in 973, the caliphate was moved to the newly founded Fatimid capital of Cairo. Egypt became the political, cultural, and religious centre of the empire and it developed a new and \"indigenous Arabic culture\". After its initial conquests, the caliphate often allowed a degree of religious tolerance towards non-Shi'a sects of Islam, as well as to Jews and Christians. However, its leaders made little headway in persuading the Egyptian population to adopt its religious beliefs.\nAfter the reigns of al-'Aziz and al-Hakim, the long reign of al-Mustansir entrenched a regime in which the caliph remained aloof from state affairs and viziers took on greater importance. Political and ethnic factionalism within the army led to a civil war in the 1060s, which threatened the empire's survival. After a period of revival during the tenure of the vizier Badr al-Jamali, the Fatimid caliphate declined rapidly during the late eleventh and twelfth centuries. In addition to internal difficulties, the caliphate was weakened by the encroachment of the Seljuk Turks into Syria in the 1070s and the arrival of the Crusaders in the Levant in 1097. In 1171, Saladin abolished the dynasty's rule and founded the Ayyubid dynasty, which incorporated Egypt back into the nominal sphere of authority of the Abbasid Caliphate.\nName.\nThe Fatimid dynasty claimed descent from Fatimah, the daughter of the Islamic prophet Muhammad. The dynasty legitimized its claim through descent from Muhammad by way of his daughter and her husband Ali, the first Shi'a imam, hence the dynasty's name, \"fa\u1e6dimiyy\" (), the Arabic relative adjective for \"F\u0101\u1e6dima\".\nEmphasizing its Alid descent, the dynasty named itself simply the 'Alid dynasty' (), but many hostile Sunni sources only refer to them as the Ubaydids (), after the diminutive form Ubayd Allah for the name of the first Fatimid caliph.\nHistory.\nOrigins.\nThe Fatimid dynasty came to power as the leaders of Isma'ilism, a revolutionary Shi'a movement \"which was at the same time political and religious, philosophical and social,\" and which originally proclaimed nothing less than the arrival of an Islamic messiah. The origins of that movement, and of the dynasty itself, are obscure prior to the late ninth century.\nThe Fatimid rulers were Arab in origin, starting with its founder, the Isma'ili Shi'a caliph Abdallah al-Mahdi Billah. The caliphate's establishment was accomplished by Kutama Berbers from Little Kabylia, who converted to the Fatimid cause early and made up its original military forces.\nEarly Shi'ism and the roots of Isma'ilism.\nThe Shi'a opposed the Umayyad and Abbasid caliphates, whom they considered usurpers. Instead, they believed in the exclusive right of the descendants of Ali through Muhammad's daughter Fatima, to lead the Muslim community. This manifested itself in a line of imams, descendants of Ali via al-Husayn, whom their followers considered as the true representatives of God on earth. At the same time, there was a widespread messianic tradition in Islam concerning the appearance of a \"mahdi\" (\"the Rightly Guided One\") or \"qa'im\" (\"He Who Arises\"), who would restore true Islamic government and justice and usher in the end times. This figure was widely expected\u00a0\u2013 not just among the Shi'a\u00a0\u2013 to be a descendant of Ali. Among Shi'a, however, this belief became a core tenet of their faith, and was applied to several Shi'a leaders who were killed or died; their followers believed that they had gone into \"occultation\" () and would return (or be resurrected) at the appointed time.\nThese traditions manifested themselves in the succession of the sixth imam, Ja'far al-Sadiq. Al-Sadiq had appointed his son Isma'il ibn Ja'far as his successor, but Isma'il died before his father, and when al-Sadiq himself died in 765, the succession was left open. Most of his followers followed al-Sadiq's son Musa al-Kazim down to a twelfth and final imam who supposedly went into occultation in 874 and would one day return as the . This branch is hence known as the \"Twelvers\". Others followed other sons, or even refused to believe that al-Sadiq had died, and expected his return as the . Another branch believed that Ja'far was followed by a seventh imam, who had gone into occultation and would one day return; hence this party is known as the \"Seveners\". The exact identity of that seventh imam was disputed, but by the late ninth century had commonly been identified with Muhammad, son of Isma'il and grandson of al-Sadiq. From Muhammad's father, Isma'il, the sect, which gave rise to the Fatimids, receives its name of \"Isma'ili\". Due to the harsh Abbasid persecution of the Alids, the Ismaili Imams went into hiding and neither Isma'il's nor Muhammad's lives are well known, and after Muhammad's death during the reign of Harun al-Rashid (r.\u2009786\u00a0\u2013\u00a0809), the history of the early Isma'ili movement becomes obscure.\nThe secret network.\nWhile the awaited \"mahdi\" Muhammad ibn Isma'il remained hidden, however, he would need to be represented by agents, who would gather the faithful, spread the word (\"da'wa\", \"invitation, calling\"), and prepare his return. The head of this secret network was the living proof of the imam's existence, or \"seal\" (\"hujja\"). It is in this role that the ancestors of the Fatimids are first documented. The first known \"hujja\" was a certain Abdallah al-Akbar (\"Abdallah the Elder\"), a wealthy merchant from Khuzestan, who established himself at the small town of Salamiya on the western edge of the Syrian Desert. Salamiya became the centre of the Isma'ili \"da'wa\", with Abdallah al-Akbar being succeeded by his son and grandson as the secret \"grand masters\" of the movement.\nIn the last third of the ninth century, the Isma'ili \"da'wa\" spread widely, profiting from the collapse of Abbasid power in the Anarchy at Samarra and the subsequent Zanj Revolt, as well as from dissatisfaction among Twelver adherents with the political quietism of their leadership and the recent disappearance of the twelfth imam. Missionaries (\"da'i\"s) such as Hamdan Qarmat and Ibn Hawshab spread the network of agents to the area round Kufa in the late 870s, and from there to Yemen (882) and thence India (884), Bahrayn (899), Persia, and the Maghreb (893).\nThe Qarmatian schism and its aftermath.\nIn 899, Abdallah al-Akbar's great-grandson, Abdallah, became the new head of the movement, and introduced a radical change in the doctrine: no longer was he and his forebears merely the stewards for Muhammad ibn Isma'il, but they were declared to be the rightful imams, and Abdallah himself was the awaited \"mahdi\". Various genealogies were later put forth by the Fatimids to justify this claim by proving their descent from Isma'il ibn Ja'far, but even in pro-Isma'ili sources, the succession and names of imams differ, while Sunni and Twelver sources of course reject any Fatimid descent from the Alids altogether and consider them impostors. Abdallah's claim caused a rift in the Isma'ili movement, as Hamdan Qarmat and other leaders denounced this change and held onto the original doctrine, becoming known as the \"Qarmatians\", while other communities remained loyal to Salamiya. Shortly after, in 902\u2013903, pro-Fatimid loyalists began a great uprising in Syria. The large-scale Abbasid reaction it precipitated and the attention it brought on him, forced Abdallah to abandon Salamiya for Palestine, Egypt, and finally for the Maghreb, where the \"da'i\" Abu Abdallah al-Shi'i had made great headway in converting the Kutama Berbers to the Isma'ili cause. Unable to join his \"da'i\" directly, Abdallah instead settled at Sijilmasa sometime between 904 and 905.\nRise to power.\nEstablishment of the Isma'ili State.\nPrior to the Fatimid rise to power, a large part of the Maghreb including Ifriqiya was under the control of the Aghlabids, an Arab dynasty who ruled nominally on behalf the Abbasids but were \"de facto\" independent. In 893 the Abu Abdallah al-Shi'i first settled among the Banu Saktan tribe (part of the larger Kutama tribe) in Ikjan, near the city of Mila (in northeastern Algeria today). However, due to hostility from the local Aghlabid authorities and other Kutuma tribes, he was forced to leave Ikjan and sought the protection of another Kutama tribe, the Banu Ghashman, in Tazrut (two miles southwest of Mila). From there, he began to build support for a new movement. Shortly after, the hostile Kutama tribes and the Arab lords of the nearby cities (Mila, Setif, and Bilizma) allied together to march against him, but he was able to move quickly and muster enough support from friendly Kutama to defeat them one by one before they were able to unite. This first victory brought Abu Abdallah and his Kutama troops valuable loot and attracted more support to the 's cause. Over the next two years Abu Abdallah was able to win over most of the Kutama tribes in the region through either persuasion or coercion. This left much of the countryside under his control, while the major cities remained under Aghlabid control. He established an Isma'ili theocratic state based in Tazrut, operating in a way similar to previous Isma'ili missionary networks in Mesopotamia but adapted to local Kutama tribal structures. He adopted the role of a traditional Islamic ruler at the head of this organization while remaining in frequent contact with Abdallah. He continued to preach to his followers, known as the \"Awliya' Allah\" ('Friends of God'), and to initiate them into Isma'ili doctrine.\nConquest of Aghlabid Ifriqiya.\nIn 902, while the Aghlabid emir Ibrahim II was away on campaign in Sicily, Abu Abdallah struck the first significant blow against Aghlabid authority in North Africa by attacking and capturing the city of Mila for the first time. This news triggered a serious response from the Aghlabids, who sent a punitive expedition of 12,000 men from Tunis in October of the same year. Abu Abdallah's forces were unable to resist this counterattack and after two defeats they evacuated Tazrut (which was largely unfortified) and fled to Ikjan, leaving Mila to be retaken. Ikjan became the new center of the Fatimid movement and the reestablished his network of missionaries and spies.\nIbrahim II died in October 902 while in southern Italy and was succeeded by Abdallah II. In early 903 Abdallah II set out on another expedition to destroy Ikjan and the Kutama rebels, but he ended the expedition prematurely due to troubles at home arising from disputes over his succession. On 27 July 903, he was assassinated and his son Ziyadat Allah III took power in Tunis. These internal Aghlabid troubles gave Abu Abdallah the opportunity to recapture Mila and then go on to capture Setif, another fortified city, by October or November 904. In 905 the Aghlabids sent a third expedition to try and subdue the Kutama. They based themselves in Constantine and in the fall of 905, after receiving further reinforcements, set out to march against Abu Abdallah. However, they were surprised by Kutama forces on the first day of their march, which caused a panic and scattered their army. The Aghlabid general fled and the Kutama captured a large booty. Another Aghlabid military expedition organized the next year (906) failed when the soldiers mutinied. Around the same time or soon after, Abu Abdallah's forces besieged and captured the fortified cities of Tubna and Bilizma. The capture of Tubna was significant as it was the first major commercial center to come under Abu Abdallah's control.\nMeanwhile, Ziyadat Allah III moved his court from Tunis to Raqqada, the palace-city near Kairouan, in response to the growing threat. He fortified Raqqada in 907. In early 907 another Aghlabid army marched westwards again against Abu Abdallah, accompanied by Berber reinforcements from the Aur\u00e8s Mountains. They were again scattered by Kutama cavalry and retreated to Baghaya, the most fortified town on the old southern Roman road between Ifriqiya and the central Maghreb. The fortress, however, fell to the Kutama without a siege when local notables arranged to have the gates opened to them in May or June 907. This opened a hole in the wider defensive system of Ifriqiya and created panic in Raqqada. Ziyadat Allah III stepped up anti-Fatimid propaganda, recruited volunteers, and took measures to defend the weakly fortified city of Kairouan. He spent the winter of 907\u2013908 with his army in al-Aribus (Roman-era Laribus, between present-day El Kef and Maktar), expecting an attack from the north. However, Abu Abdallah's forces had been unable to capture the northerly city of Constantine and therefore they instead attacked along the southern road from Baghaya in early 908 and captured Maydara (present-day Ha\u00efdra). An indecisive battle subsequently occurred between the Aghalabid and Kutama armies near Dar Madyan (probably a site between Sbeitla and Kasserine), with neither side gaining the upper hand. During the winter of 908\u2013909 Abu Abdallah campaigned in the region around Chott el-Jerid, capturing the towns of Tuzur (Tozeur), Nafta, and Qafsa (Gafsa) and taking control of the region. The Aghlabids responded by besieging Baghaya soon afterward in the same winter, but they were quickly repelled.\nOn 25 February 909, Abu Abdallah set out from Ikjan with an army of 200,000 men for a final invasion of Kairouan. The remaining Aghlabid army, led by an Aghlabid prince named Ibrahim Ibn Abi al-Aghlab, met them near al-Aribus on 18 March. The battle lasted until the afternoon, when a contingent of Kutama horsemen managed to outflank the Aghlabid army and finally caused a rout. When news of the defeat reached Raqqada, Ziyadat Allah III packed his valuable treasures and fled towards Egypt. The population of Kairouan looted the abandoned palaces of Raqqada and resisted Ibn Abi al-Aghlab's calls to organise a last-ditch resistance. Upon hearing of the looting, Abu Abdallah sent an advance force of Kutama horsemen who secured Raqqada on 24 March. On 25 March 909 (Saturday, 1 Rajab 296), Abu Abdallah himself entered Raqqada and took up residence here.\nEstablishment of the Caliphate.\nUpon assuming power in Raqqada, Abu Abdallah inherited much of the Aghlabid state's apparatus and allowed its former officials to continue working for the new regime. He established a new, Isma'ili Shi'a regime on behalf of his absent, and for the moment unnamed, master. He then led his army west to Sijilmasa, whence he led Abdallah in triumph to Raqqada, which he entered on 15 January 910. There Abdallah publicly proclaimed himself as caliph with the regnal name of , and presented his son and heir, with the regnal name of al-Qa'im. Al-Mahdi quickly fell out with Abu Abdallah: not only was the over-powerful, but he demanded proof that the new caliph was the true . The elimination of Abu Abdallah al-Shi'i and his brother led to an uprising among the Kutama, led by a child-, which was suppressed. At the same time, al-Mahdi repudiated the millenarian hopes of his followers and curtailed their antinomian tendencies.\nThe new regime regarded its presence in Ifriqiya as only temporary: the real target was Baghdad, the capital of the Fatimids' Abbasid rivals. The ambition to carry the revolution eastward had to be postponed after the failure of two successive invasions of Egypt, led by al-Qa'im, in 914\u2013915 and 919\u2013921. In addition, the Fatimid regime was as yet unstable. The local population were mostly adherents of Maliki Sunnism and various Kharijite sects such as Ibadism, so that the real power base of Fatimids in Ifriqiya was quite narrow, resting on the Kutama soldiery, later extended by the Sanhaja Berber tribes as well. The historian Heinz Halm describes the early Fatimid state as being, in essence, \"a hegemony of the Kutama and Sanhaja Berbers over the eastern and central Maghrib\".\nIn 912, al-Mahdi began looking for the site of a new capital along the Mediterranean shore. Construction of the new fortified palace city, al-Mahdiyya, began in 916. The new city was officially inaugurated on 20 February 921, though construction continued after this. The new capital was removed from the Sunni stronghold of Kairouan, allowing for the establishment of a secure base for the Caliph and his Kutama forces without raising further tensions with the local population.\nThe Fatimids also inherited the Aghlabid province of Sicily, which the Aghlabids had gradually conquered from the Byzantine Empire starting in 827. The conquest was generally completed when the last Christian stronghold, Taormina, was conquered by Ibrahim II in 902. However, some Christian or Byzantine resistance continued in some spots in the northeast of Sicily until 967, and the Byzantines still held territories in southern Italy, where the Aghlabids had also campaigned. This ongoing confrontation with the traditional foe of the Islamic world provided the Fatimids with a prime opportunity for propaganda, in a setting where geography gave them the advantage. Sicily itself proved troublesome, and only after a rebellion under Ibn Qurhub was subdued, was Fatimid authority on the island consolidated.\nConsolidation and western rivalry.\nFor a large part of the tenth century the Fatimids also engaged in a rivalry with the Umayyads of Cordoba, who ruled Al-Andalus and were hostile to the Fatimids' pretensions in an effort to establish domination over the western Maghreb. In 911, Tahert, which had been briefly captured by Abu Abdallah al-Shi'i in 909, had to be retaken by the Fatimid general Masala ibn Habus of the Miknasa tribe. The first Fatimid expeditions to what is now northern Morocco occurred in 917 and 921 and were primarily aimed at the Principality of Nakur, which they subjugated on both occasions. Fez and Sijilmasa were also captured in 921. These two expeditions were led by Masala ibn Habus, who had been made governor of Tahert. Thereafter, the weakened Idrisids and various local Zenata and Sanhaja leaders acted as proxies whose formal allegiances oscillated between the Umayyads or the Fatimids depending on the circumstances. As a result of the political instability in the western Maghreb, effective Fatimid control did not extend much beyond the former territory of the Aghlabids. Masala's successor, Musa ibn Abi'l-Afiya, captured Fez from the Idrisids again, but in 932 defected to the Umayyads, taking the western Maghreb with him. The Umayyads gained the upper hand again in northern Morocco during the 950s, until the Fatimid general Jawhar, on behalf of Caliph Al-Mu'izz li-Din Allah, led another major expedition to Morocco in 958 and spent two years subjugating most of northern Morocco. He was accompanied by Ziri ibn Manad, the leader of the Zirids. Jawhar took Sijilmasa in September or October 958 and then, with the help of Ziri, his forces took Fez in November 959. He was unable, however, to dislodge the Umayyad garrisons in Sala, Sebta (present-day Ceuta) and Tangier, and this marked the only time that the Fatimid army was present at the Strait of Gibraltar. Jawhar and Ziri returned to al-Mansuriyya in 960. The subjugated parts of Morocco, including Fez and Sijilmasa, were left under the control of local vassals while most of the central Maghreb (Algeria), including Tahert, was given to Ziri ibn Manad to govern on the caliph's behalf.\nAll this warfare in the Maghreb and Sicily necessitated the maintenance of a strong army, and a capable fleet as well. Nevertheless, by the time of al-Mahdi's death in 934, the Fatimid Caliphate \"had become a great power in the Mediterranean\". The reign of the second Fatimid imam-caliph, al-Qa'im, was dominated by the Kharijite rebellion of Abu Yazid. Starting in 943/4 among the Zenata Berbers, the uprising spread through Ifriqiya, taking Kairouan and blockading al-Qa'im at al-Mahdiyya, which was besieged in January\u2013September 945. Al-Qa'im died during the siege, but this was kept secret by his son and successor, Isma'il, until he had defeated Abu Yazid; he then announced his father's death and proclaimed himself imam and caliph as al-Mansur. While al-Mansur was campaigning to suppress the last remnants of the revolt, a new palace city was being constructed for him south of Kairouan. Construction began around 946 and it was only fully completed under al-Mansur's son and successor, al-Mu'izz. It was named al-Mansuriyya (also known as Sabra al-Mansuriyya) and became the new seat of the caliphate.\nApogee.\nConquest of Egypt and transfer of the Caliphate to Cairo.\nIn 969, Jawhar launched a carefully prepared and successful invasion of Egypt, which had been under the control of the Ikhshidids, another regional dynasty whose formal allegiance was to the Abbasids. Al-Mu'izz had given Jawhar specific instructions to carry out after the conquest, and one of his first actions was to found a new capital named \"al-Qahira\" (Cairo) in 969. The name \"al-Qahira\", meaning \"the Vanquisher\" or \"the Conqueror\", referenced the planet Mars, \"The Subduer\", rising in the sky at the time when the construction of the city started. The city was located several miles northeast of Fustat, the older regional capital founded by the Arab conquerors in the seventh century.\nControl of Egypt was secured with relative ease and soon afterward, in 970, Jawhar sent a force to invade Syria and remove the remaining Ikhshidids who had fled there from Egypt. This Fatimid force was led by a Kutama general named Ja'far ibn Falah. This invasion was successful at first and many cities, including Damascus, were occupied that same year. Ja'far's next step was to attack the Byzantines, who had captured Antioch and subjugated Aleppo in 969 (around the same time as Jawhar was arriving in Egypt), but he was forced to call off the advance in order to face a new threat from the east. The Qarmatis of Bahrayn, responding to the appeal of the recently defeated leaders of Damascus, had organized a large coalition of Arab tribesmen to attack him. Ja'far chose to confront them in the desert in August 971, but his army was surrounded and defeated and Ja'far himself was killed. A month later the Qarmati imam Hasan al-A'\u1e63am led the army, with new reinforcements from Transjordan, into Egypt, seemingly without opposition. The Qarmatis spent time occupying the Nile Delta region, which gave Jawhar time to organize a defense of Fustat and Cairo. The Qarmati advance was halted just north of the city and eventually routed. A Kalbid relief force arriving by sea secured the expulsion of the Qarmatis from Egypt. Ramla, the capital of Palestine, was retaken by the Fatimids in May 972, but otherwise the progress in Syria had been lost.\nOnce Egypt was sufficiently pacified and the new capital was ready, Jawhar sent for al-Mu'izz in Ifriqiya. The caliph, his court, and his treasury, departed from al-Mansuriyya in fall 972, traveling by land but shadowed by the Fatimid navy sailing along the coast. After making triumphant stops in major cities along the way, the caliph arrived in Cairo on 10 June 973. Like other royal capitals before it, Cairo was constructed as an administrative and palatine city, housing the palaces of the caliph and the official state mosque, Al-Azhar Mosque. In 988, the mosque also became an academic institution that was central in the dissemination of Isma'ili teachings. Until the last years of the Fatimid Caliphate, the economic centre of Egypt remained Fustat, where most of the general population lived and traded.\nUnder the Fatimids, Egypt became the centre of an empire that included at its peak parts of North Africa, Sicily, the Levant (including Transjordan), the Red Sea coast of Africa, Tihamah, Hejaz, Yemen, with its most remote territorial reach being Multan (in modern-day Pakistan). Egypt flourished, and the Fatimids developed an extensive trade network both in the Mediterranean and in the Indian Ocean. Their trade and diplomatic ties, extending all the way to China under the Song Dynasty (r.\u2009960\u00a0\u2013\u00a01279), eventually determined the economic course of Egypt during the High Middle Ages. The Fatimid focus on agriculture further increased their riches and allowed the dynasty and the Egyptians to flourish. The use of cash crops and the propagation of the flax trade allowed Fatimids to import other items from various parts of the world. The Fatimids built upon some of the bureaucratic foundations laid by the Ikhshidids and the old Abbasid imperial order. The office of the \"wazir\" (vizier), which existed under the Ikhshidids, was soon revived under the Fatimids. The first to be appointed to this position was the Jewish convert Ya'qub ibn Killis, who was elevated to this office in 979 by al-Mu'izz's successor al-Aziz. The office of the vizier became progressively more important over the years, as the vizier became the intermediary between the caliph and the large bureaucratic state that he ruled.\nCampaigns in Syria.\nIn 975, the Byzantine emperor John Tzimisces retook most of Palestine and Syria, leaving only Tripoli in Fatimid control. He aimed to capture Jerusalem, but he died in 976 on his way back to Constantinople, thus staving off the Byzantine threat to the Fatimids. Meanwhile, the Turkish \"ghulam\" (plural: \"ghilman\", meaning soldiers recruited as slaves) Aftakin, a Buyid refugee who had fled an unsuccessful rebellion in Baghdad with his own contingent of Turkish soldiers, became the protector of Damascus. He allied with the Qarmatis and with Arab Bedouin tribes in Syria and invaded Palestine in the spring of 977. Jawhar, once again called into action, repelled their invasion and besieged Damascus. However, he suffered a rout during the winter and was forced to hold out in Ascalon against Aftakin. When his Kutama soldiers mutinied in April 978, Caliph al-Aziz himself led an army to relieve him. Instead of returning to Damascus, Aftakin and his Turkish \"ghilman\" joined the Fatimid army and became a useful instrument in the Syrian effort.\nAfter Ibn Killis became vizier in 979, the Fatimids changed tactics. Ibn Killis was able to subjugate most of Palestine and southern Syria (the former Ikhshidid territories) by paying off the Qarmatis with an annual tribute and making alliances with local tribes and dynasties, such as the Jarrahids and the Banu Kilab. Following another failed attempt by a Kutama general, Salman, to take Damascus, the Turkish \"ghulam\" Bultakin finally succeeded in occupying the city for the Fatimids in 983, demonstrating the value of this new force. Another \"ghulam\", Bajkur, was appointed governor of Damascus at this time. That same year he tried and failed to take Aleppo, but he was soon able to conquer Raqqa and Rahba in the Euphrates valley (present-day northeast Syria). Cairo eventually judged him to be a little too popular as governor of Damascus and he was forced to move to Raqqa while Munir, a eunuch in the caliph's household (like Jawhar before him), took direct control in Damascus on behalf of the caliph. Further north, Aleppo remained out of reach and under Hamdanid control.\nThe incorporation of the Turkish troops into the Fatimid army had long-term consequences. On the one hand, they were a necessary addition to the military in order for the Fatimids to compete militarily with other powers in the region. The Fatimids began to recruit \"ghilman\" much as the Abbasids had done before them. They were soon joined by recruited Daylamis (footmen from the Buyid homeland in Iran). Black Africans from the Sudan (upper Nile valley) were also recruited afterward. In the short term the Kutama warriors remained the most important troops of the Caliph, but resentment and rivalry eventually grew between the different ethnic components of the army.\nBajkur, based in Raqqa, made another unsuccessful attempt against Aleppo in 991 which resulted in his capture and execution. That same year, Ibn Killis died and Munir was accused of conducting treasonous correspondence with Baghdad. These difficulties triggered a strong response in Cairo. A major military campaign was prepared to impose Fatimid control over all of Syria. Along the way, Munir was arrested in Damascus and sent back to Cairo. Circumstances were favourable to the Fatimids as the Byzantine emperor Basil II was campaigning far away in the Balkans and the Hamdanid ruler Sa'd al-Dawla died in late 991. Manjutakin, the Turkish Fatimid commander, advanced methodically north along the Orontes valley. He took Homs and Hama in 992 and defeated a combined force from Hamdanid Aleppo and Byzantine-held Antioch. In 993 he took Shayzar and in 994 he began the siege of Aleppo. In May 995, however, Basil II unexpectedly arrived in the region after a forced march with his army through Anatolia, forcing Manjutakin to lift the siege and return to Damascus. Before another Fatimid expedition could be sent, Basil II negotiated a one-year truce with the caliph, which the Fatimids used to recruit and build new ships for their fleet. In 996 many of the ships were destroyed by a fire at al-Maqs, the port on the Nile near Fustat, further delaying the expedition. Finally, in August 996 al-Aziz died and the objective of Aleppo became secondary to other concerns.\nThe Zirids in the Maghreb.\nBefore leaving for Egypt, al-Mu'izz had installed Buluggin ibn Ziri, the son of Ziri bn Manad (who died in 971), as his viceroy in the Maghreb. This established a dynasty of viceroys, with the title of \"amir\", who ruled the region on behalf of the Fatimids. Their authority remained disputed in the western Maghreb, where the rivalry with the Umayyads and with local Zenata leaders continued. After Jawhar's successful western expedition, the Umayyads returned to northern Morocco in 973 to reassert their authority. Buluggin launched one last expedition in 979\u2013980 that reestablished his authority in the region temporarily, until a final decisive Umayyad intervention in 984\u2013985 put an end to further efforts. In 978 the caliph also gave Tripolitania to Buluggin to govern, though Zirid authority there was later replaced by the local Banu Khazrun dynasty in 1001.\nIn 988, Buluggin's son and successor al-Mansur moved the Zirid dynasty's base from Ashir (central Algeria) to the former Fatimid capital al-Mansuriyya, cementing the status of the Zirids as more or less \"de facto\" independent rulers of Ifriqiya, while still officially maintaining their allegiance to the Fatimid caliphs. Caliph al-Aziz accepted this situation for pragmatic reasons to maintain his own formal status as universal ruler. Both dynasties exchanged gifts and the succession of new Zirid rulers to the throne was officially sanctioned by the caliph in Cairo.\nThe reign of al-Hakim.\nAfter al-Aziz's unexpected death, his young son al-Mansur, 11 years old, was installed on the throne as al-Hakim. Hasan ibn Ammar, the leader of the Kalbid clan in Egypt, a military veteran, and one of the last remaining members of al-Mu'izz's old guard, initially became regent, but he was soon forced to flee by Barjawan, the eunuch and tutor of the young al-Hakim, who took power in his stead. Barjawan stabilized the internal affairs of the empire but refrained from pursuing al-Aziz's policy of expansion towards Aleppo. In the year 1000, Barjawan was assassinated by al-Hakim, who now took direct and autocratic control of the state. His reign, which lasted until his mysterious disappearance in 1021, is the most controversial in Fatimid history. Traditional narratives have described him as either eccentric or outright insane, but more recent studies have tried to provide more measured explanations based on the political and social circumstances of the time.\nAmong other things, al-Hakim was known for executing his officials when unsatisfied with them, seemingly without warning, rather than dismissing them from their posts as had been traditional practice. Many of the executions were members of the financial administration, which may mean that this was al-Hakim's way of trying to impose discipline in an institution rife with corruption. He also opened the \"Dar al-'Ilm\" (\"House of Knowledge\"), a library for the study of the sciences, which was in line with al-Aziz's previous policy of cultivating this knowledge. For the general population, he was noted for being more accessible and willing to receive petitions in person, as well as for riding out in person among the people in the streets of Fustat. On the other hand, he was also known for his capricious decrees aimed at curbing what he saw as public improprieties. He also unsettled the plurality of Egyptian society by imposing new restrictions on Christians and Jews, particularly on the way they dressed or behaved in public. He ordered or sanctioned the destruction of a number of churches and monasteries (mostly Coptic or Melkite), which was unprecedented, and in 1009, for reasons that remain unclear, he ordered the demolition of the Church of the Holy Sephulchre in Jerusalem.\nAl-Hakim greatly expanded the recruitment of Black Africans into the army, who subsequently became another powerful faction to balance against the Kutama, Turks, and Daylamis. In 1005, during his early reign, a dangerous uprising led by Abu Rakwa was successfully put down but had come within striking distance of Cairo. In 1012 the leaders of the Arab Tayyi tribe occupied Ramla and proclaimed the sharif of Mecca, al-Hasan ibn Ja'far, as the Sunni anti-caliph, but the latter's death in 1013 led to their surrender. Despite his policies against Christians and his demolition of the church in Jerusalem, al-Hakim maintained a ten-year truce with the Byzantines that began in 1001. For most of his reign, Aleppo remained a buffer state that paid tribute to Constantinople. This lasted until 1017, when the Fatimid Armenian general Fat\u0101k finally occupied Aleppo at the invitation of a local commander who had expelled the Hamdanid \"ghulam\" ruler Mansur ibn Lu'lu'. After a year or two, however, Fatak made himself effectively independent in Aleppo.\nAl-Hakim also alarmed his Isma'ili followers in several ways. In 1013 he announced the designation of two great-great-grandsons of al-Mahdi as two separate heirs: one, Abd al-Rahim ibn Ilyas, would inherit the title of caliphate as the role of political ruler, and the other, Abbas ibn Shu'ayb, would inherit the imamate or religious leadership. This was a serious departure from a central purpose of the Fatimid Imam-Caliphs, which was to combine these two functions in one person. In 1015 he also suddenly halted the Isma'ili doctrinal lectures of the \"majalis al-hikma\" (\"sessions of wisdom\") which had taken place regularly inside the palace. In 1021, while wandering the desert outside Cairo on one of his nightly excursions, he disappeared. He was purportedly murdered, but his body was never found.\nDecline.\nLosses, successes, and civil war.\nAfter al-Hakim's death his two designated heirs were killed, putting an end to his succession scheme, and his sister Sitt al-Mulk arranged to have his 15-year-old son Ali installed on the throne as al-Zahir. She served as his regent until her death in 1023, at which point an alliance of courtiers and officials ruled, with al-Jarjara'i, a former finance official, at their head. Fatimid control in Syria was threatened during the 1020s. In Aleppo, Fatak, who had declared his independence, was killed and replaced in 1022, but this opened the way for a coalition of Bedouin chiefs from the Banu Kilab, Jarrahids, and Banu Kalb led by Salih ibn Mirdas to take the city in 1024 or 1025 and to begin imposing their control on the rest of Syria. Al-Jarjara'i sent Anushtakin al-Dizbari, a Turkish commander, with a force that defeated them in 1029 at the Battle of Uqhuwana near Lake Tiberias. In 1030 the new Byzantine emperor Romanos III broke a truce to invade northern Syria and forced Aleppo to recognize his suzerainty. His death in 1034 changed the situation again and in 1036 peace was restored. In 1038 Aleppo was directly annexed by the Fatimids state for the first time.\nAl-Zahir died in 1036 and was succeeded by his son, al-Mustansir, who had the longest reign in Fatimid history, serving as caliph from 1036 to 1094. However, he remained largely uninvolved in politics and left the government in the hands of others. He was seven years old at his accession and thus al-Jarjara'i continued to serve as vizier and his guardian. When al-Jarjara'i died in 1045 a series of court figures ran the government until al-Yazuri, a jurist of Palestinian origin, took and kept the office of vizier from 1050 to 1058.\nIn the 1040s (possibly in 1041 or 1044), the Zirids declared their independence from the Fatimids and recognized the Sunni Abbasid caliphs of Baghdad, which led the Fatimids to launch the devastating Banu Hilal invasions of North Africa. Fatimid suzerainty over Sicily also faded as the Muslim polity there fragmented and external attacks increased. By 1060, when the Italo-Norman Roger I began his conquest of the island (completed in 1091), the Kalbid dynasty, along with any Fatimid authority, were already gone.\nThere was more success in the east, however. In 1047, the Fatimid \"da'i\" Ali Muhammad al-Sulayhi in Yemen built a fortress and recruited tribes with which he was able to capture San'a in 1048. In 1060, he began a campaign to conquer all of Yemen, capturing Aden and Zabid. In 1062 he marched on Mecca, where Shukr ibn Abi al-Futuh's death in 1061 provided an excuse. Along the way he forced the Zaydi Imam in Sa'da into submission. Upon arriving in Mecca, he installed Abu Hashim Muhammad ibn Ja'far as the new sharif and custodian of the holy sites under the suzerainty of the Fatimids. He returned to San'a where he established his family as rulers on behalf of the Fatimid caliphs. His brother founded the city of Ta'izz, while the city of Aden became an important hub of trade between Egypt and India, which brought Egypt further wealth. His rise to power established the Sulayhid dynasty which continued to rule Yemen as nominal vassals of the Fatimids after this.\nEvents degenerated in Egypt and Syria, however. Starting in 1060, various local leaders began to break away or challenge Fatimid dominion in Syria. While the ethnic-based army was generally successful on the battlefield, it had begun to have negative effects on Fatimid internal politics. Traditionally, the Kutama element of the army had the strongest sway over political affairs, but as the Turkish element grew more powerful it began to challenge this. In 1062, the tentative balance between the different ethnic groups within the Fatimid army collapsed and they quarreled constantly or fought each other in the streets. At the same time, Egypt suffered a seven-year period of drought and famine known as the Mustansirite Hardship. Viziers came and went in a flurry, the bureaucracy broke down, and the caliph was unable or unwilling to assume responsibilities in their absence. Declining resources accelerated the problems among the different ethnic factions and outright civil war began, primarily between the Turks under Nasir al-Dawla ibn Hamdan, a scion of the Hamdanids of Aleppo, and Black African troops, while the Berbers shifted alliance between the two sides. The Turkish faction under Nasir al-Dawla seized partial control of Cairo but their leader was not given any official title. In 1067\u20131068, they plundered the state treasury and then looted any treasures they could find in the palaces. The Turks turned against Nasir al-Dawla in 1069 but he managed to rally Bedouin tribes to his side, took over most of the Nile Delta region, and blocked supplies and food from reaching the capital from this region. Things degenerated further for the general population, especially in the capital, which relied on the countryside for food. Historical sources of this period report extreme hunger and hardship in the city, even to the point of cannibalism. The depredations in the Nile Delta may have also been a turning point that accelerated the long-term decline of the Coptic community in Egypt.\nBadr al-Jamali and the Fatimid revival.\nBy 1072, in a desperate attempt to save Egypt, al-Mustansir recalled general Badr al-Jamali, who was at the time the governor of Acre. Badr led his troops into Egypt, entered Cairo in January 1074, and successfully suppressed the different groups of the rebelling armies. As a result, Badr was made vizier, becoming one of the first military viziers (\"amir al-juyush\" 'commander of the armies') who would dominate late Fatimid politics. In 1078 al-Mustansir formally abdicated responsibility for all state affairs to him. His \"de facto\" rule initiated a temporary and limited revival of the Fatimid state, although it was now faced with serious challenges. Badr reestablished Fatimid authority in the Hejaz (Mecca and Medina) and the Sulayhids were able to hold on in Yemen. Syria, however, saw the advance of the Sunni-aligned Seljuk Turks, who had conquered much of the Middle East and had become the guardians of the Abbasid Caliphs, as well as independent Turkmen groups. Atsiz ibn Uwaq, a Turkmen of the Nawaki tribe, conquered Jerusalem in 1073 and Damascus in 1076 before attempting to invade even Egypt itself. After defeating him at a battle close to Cairo, Badr was able to start a counter-offensive to secure coastal cities, such as Gaza and Ascalon, and later Tyre, Sidon, and Byblos further north in 1089.\nBadr made major reforms to the state, updating and simplifying the administration of Egypt. As he was of Armenian background, his term also saw a large influx of Armenian immigrants, both Christian and Muslim, into Egypt. The Armenian church, patronised by Badr, established itself in the country along with a clerical hierarchy. He commanded a large contingent of Armenian troops, many (if not all) of whom were also Christian. Badr also used his relations and influence with the Coptic Church for political advantage. In particular, he enlisted Cyril II (Coptic Pope from 1078 to 1092) to secure the allegiance of the Christian kingdoms of Nubia (specifically Makuria) and Ethiopia (specifically the Zagwe dynasty) as vassals to the Fatimid state.\nThe Juyushi Mosque ('the Mosque of the Armies'), was commissioned by Badr and completed in 1085 under the patronage of the caliph. The mosque, identified as a \"mashhad\", was also a victory monument commemorating vizier Badr's restoration of order for al-Mustansir. Between 1087 and 1092, the vizier also replaced the mudbrick walls of Cairo with new stone walls and slightly expanded the city. Three of its monumental gates still survive today: Bab Zuweila, Bab al-Futuh, and Bab al-Nasr.\nFinal decline.\nAs the military viziers effectively became heads of state, the Caliph himself was reduced to the role of a figurehead. The reliance on the \"iqta\" system also ate into Fatimid central authority, as more and more the military officers at the further ends of the empire became semi-independent.\nBadr al-Jamali died in 1094, along with Caliph al-Mustansir that same year, and his son Al-Afdal Shahanshah succeeded him in power as vizier. After al-Mustansir, the Caliphate passed on to al-Musta'li; after his death in 1101, it passed to the 5-year-old al-Amir. Another of al-Mustansir's sons, Nizar, attempted to take the throne after his father's death and organized a rebellion in 1095, but he was defeated and executed that same year. This resulted in a schism with Isma'ili missionaries in Iran, led by the \"da'i\" Hasan-i Sabbah, who founded the Nizari sect and went on to form the Order of Assassins. Al-Afdal arranged for his sister to marry al-Musta'li and later for his daughter to marry al-Amir, hoping in this way to merge his family with that of the caliphs. He also attempted to secure the succession of his son to the vizierate as well, but this ultimately failed.\nDuring al-Afdal's tenure (1094\u20131121), the Fatimids faced a new external threat: the First Crusade. Although initially both sides intended to reach an agreement and an alliance against the Seljuk Turks, these negotiations would eventually break down. First contact seems to have been established by the crusaders who sent in May or June 1097, on suggestion of Byzantine Emperor Alexios Komnenos, an embassy to al-Afdal. In return the Fatimids dispatched an embassy to the crusading forces which arrived in February 1098 during their siege of Antioch, witnessing and congratulating the crusaders on their victory against the Seljuk emirs Ridwan of Aleppo and S\u00f6kmen of Jerusalem as well as stressing their friendly attitude towards Christians. The Fatimid embassy stayed for a month with the crusading forces before returning via the harbour of Latakia with gifts as well as Frankish ambassadors. It is uncertain whether an agreement was reached but it seems that the parties expected to reach a conclusion in Cairo. Al-Afdal took then advantage of the crusader victory at Antioch to reconquer Jerusalem in August 1098, possibly to be in a better position in the negotiations with the crusaders. The next time both parties met was at Arqah in April 1099 where an impasse was reached in regard to the question of ownership over Jerusalem. Following this, the crusaders crossed into Fatimid territory and captured Jerusalem in July 1099 while al-Afdal was leading a relief army trying to reach the city. The two forces finally clashed in the Battle of Ascalon in which al-Afdal was defeated. Nevertheless, the initial negotiations were held against the Fatimids and Ibn al-Athir wrote that it was said that the Fatimids had invited the crusaders to invade Syria.\nThis defeat established the Kingdom of Jerusalem as a new regional rival and although many crusaders returned to Europe, having fulfilled their vows, the remaining forces, often aided by the Italian maritime republics, overran much of the coastal Levant, with Tripoli, Beirut, and Sidon falling to them between 1109 and 1110. The Fatimids retained Tyre, Ascalon, and Gaza with the help of their fleet. After 1107, a new rising star rose through the ranks of the regime in the form of Muhammad Ali bin Fatik, better known as al-Ma'mun al-Bata'ihi. He managed to carry out various administrative reforms and infrastructural projects in the later years of al-Afdal's term, including the construction of an astronomical observatory in 1119. Al-Afdal was assassinated in 1121, an act blamed on the Nizaris or Assassins, though the truth of this is unconfirmed.\nAl-Bata'ihi took al-Afdal's place as vizier, but unlike his predecessors he had less support in the army and was ultimately reliant on the caliph for power. In 1124, he lost Tyre to the Crusaders. He was also responsible for constructing a small but notable mosque in Cairo, the Al-Aqmar Mosque, which was completed in 1125 and has largely survived to the present day. That same year, however, Caliph al-Amir had him arrested, probably due to his failure to resist the Crusaders or due to the caliph's resentment of his wealth and power. Three years later he was executed. Al-Amir then ruled the Caliphate personally, briefly interrupting the long period of \"de facto\" rule by the caliph's viziers. Al-Amir himself was assassinated in 1130, probably by the Nizari Assassins.\nAl-Amir did not leave an adult heir but apparently had a son born shortly before his death, known as al-\u1e6cayyib. One of Al-Amir's cousins (a grandson of al-Mustansir), Abd al-Majid, had himself appointed regent. Under pressure from the army, one of al-Afdal's sons, Abu Ali Ahmad (known as Kutayfat), was appointed vizier with titles similar to al-Afdal and Badr al-Jamali. Kutayfat attempted to depose the Fatimid dynasty by imprisoning Abd al-Majid and by declaring himself to be the representative of Muhammad al-Muntazar, the \"hidden\" Imam awaited by Twelver Shi'as. The coup did not last long, as Kutayfat was assassinated in 1131 by al-Amir's followers in the Fatimid establishment. Abd al-Majid was released and resumed his role as regent. In 1132, however, he declared himself to be the new Imam-Caliph, taking the title of al-Hafiz, sidelining the infant al-\u1e6cayyib and breaking with the tradition of the succession passing directly from father to son. Most of the Fatimid lands acknowledged his succession, but the Sulayhids in Yemen did not and broke away from the Caliphate in Cairo, recognizing al-\u1e6cayyib as the true Imam. This caused another schism between the Hafizi and Tayyibi branches of the Musta'li Isma'ilis.\nIn 1135, al-Hafiz was pressured by the Fatimid Armenian troops into appointing Bahram, a Christian Armenian, to the office of vizier. Opposition from Muslim troops forced him to leave in 1137, when Ridwan, a Sunni Muslim, was appointed vizier. When Ridwan began to plot the deposition of al-Hafiz, he was expelled from Cairo and later defeated in battle. He accepted a pardon from the caliph and remained at the palace. Al-Hafiz chose not to appoint another vizier, and instead took direct control of the state until his death in 1149. During this time, the fervor of the Isma'ili religious cause in Egypt had significantly faded, and political challenges to the caliph became more common. Sunni Muslims were also increasingly appointed to high posts. The Fatimid dynasty largely continued to survive due to the established common interests that many factions and elites had in maintaining the current system of government.\nAl-Hafiz was the last Fatimid caliph to rule directly and the last one to ascend to the throne as an adult. The last three caliphs, al-Zafir (r. 1149\u20131154), al-Fa'iz (r. 1154\u20131160), and al-Adid (r. 1160\u20131171), were all children when they came to the throne. Under al-Zafir, an elderly Berber named Ibn Masal was initially vizier, per the instructions left by Al-Hafiz. The army, however, supported a Sunni named Ibn Sallar instead, whose supporters managed to defeat and kill Ibn Masal in battle. After negotiating with the women of the palace, Ibn Sallar was installed as vizier in 1150. In January 1153, the Crusader king Baldwin III of Jerusalem besieged Ascalon, the last remaining Fatimid foothold in the Levant. In April, Ibn Sallar was murdered in a plot organized by Abbas, his stepson, and Abbas's son, Nasr. As no relieving force arrived, Ascalon surrendered in August, on the condition that the inhabitants could leave safely for Egypt. It was on this occasion that the head of Husayn was allegedly brought from Ascalon to Cairo, where it was housed in what is now the al-Hussein Mosque. The next year (1154), Nasr murdered al-Zafir, and Abbas, now vizier, declared his 5-year-old son Isa (al-Fa'iz) the new caliph. The women of the palace intervened, calling on Tala'i ibn Ruzzik, a Muslim Armenian governor in Upper Egypt, to help. Tala'i drove out Abbas and Nasr from Cairo and became vizier that same year. Afterwards he also conducted renewed operations against the Crusaders, but he could do little more than harass them by sea. Al-Fa'iz died in 1160 and Tala'i was assassinated in 1161 by Sitt al-Qusur, a sister of al-Zafir. Tala'i's son, Ruzzik ibn Tala'i, held the office of vizier until 1163, when he was overthrown and killed by Shawar, the governor of Qus.\nAs vizier, Shawar came into conflict with his rival, the Arab general Dirgham. The internal disorder of the Caliphate attracted the attention and meddling of the Sunni Zengid ruler Nur ad-Din, who was now in control of Damascus and a large part of Syria, and of the King of Jerusalem, Amalric I. The Crusaders had already forced Tala'i ibn Ruzzik to pay them a tribute in 1161 and had made an attempt to invade Egypt in 1162. When Shawar was driven out of Cairo by Dirgham in 1163, he sought refuge and help with Nur al-Din. Nur al-Din sent his general, Asad al-Din Shirkuh, to seize Egypt and reinstall Shawar as vizier. He accomplished this task in the summer of 1164, when Dirgham was defeated and killed.\nShawar's remaining years continued in chaos as he made shifting alliances with either the King of Jerusalem or with Nur al-Din, depending on circumstances. In 1167, the Crusaders pursued Shirkuh's forces into Upper Egypt. In 1168, Shawar, worried about the possible Crusader capture of Cairo, infamously set fire to Fustat in an attempt to deny the Crusaders a base from which to besiege the capital. After forcing the Crusaders to leave Egypt again, Shirkuh finally had Shawar murdered in 1169, with the agreement of Caliph al-Adid. Shirkuh himself was appointed as al-Adid's vizier, but he died unexpectedly two months later. The position passed to his nephew, Salah ad-Din Yusuf ibn Ayyub (known in the West as Saladin). Salah ad-Din was openly pro-Sunni and suppressed the Shi'a call to prayer, ended the Isma'ili doctrinal lectures (the \"majalis al-hikma\"), and installed Sunni judges. He finally and officially deposed al-Adid, the last Fatimid caliph, in September 1171. This ended the Fatimid dynasty and began the Ayyubid Sultanate of Egypt and Syria.\nDynasty.\nWhite was the dynastic colour of the Fatimids, in opposition to Abbasid black, while red and yellow banners were associated with the Fatimid caliph's person. Green is also cited as their dynastic colour, based on a tradition that the Islamic prophet Muhammad wore a green cloak.\nBurial place.\nThe Fatimid caliphs were buried in a mausoleum known as \"Turbat az-Za'faraan\" (\"the Saffron Tomb\"), located at the southern end of the eastern Fatimid palace in Cairo on the site now occupied by the Khan el-Khalili market. The remains of the early Fatimid caliphs in Ifriqiya were also transferred here when al-Mu'izz moved his capital to Cairo. However, the mausoleum was completely demolished by the Mamluk amir Jaharkas al-Khalili in 1385 to make way for the construction of a new merchant building (which gave its name to the present-day market). During the demolition, Jaharkas reportedly desecrated the bones of the Fatimid royal family by having them dumped into the rubbish hills east of the city.\nSociety.\nReligious communities.\nFatimid society was highly pluralistic. Isma'ili Shi'ism was the religion of the state and the caliph's court, but most of the population followed different religions or denominations. Most of the Muslim population remained Sunni, and a large part of the population remained Christian. Jews were a smaller minority. As in other Islamic societies of the time, non-Muslims were classified as \"dhimmi\"s, a term which implied both certain restrictions and certain liberties, though the practical circumstances of this status varied from context to context. As elsewhere in the historic Muslim world, they were required to pay the \"jizya\" tax. Scholars generally agree that, on the whole, Fatimid rule was highly tolerant and inclusive towards different religious communities.195\nUnlike western European governments of the era, advancement in Fatimid state offices was more meritocratic than hereditary. Members of other branches of Islam, like the Sunnis, were just as likely to be appointed to government posts as Shiites. Tolerance was extended to non-Muslims, such as Christians and Jews, who occupied high levels in government based on ability, and this policy of tolerance ensured the flow of money from non-Muslims in order to finance the Caliphs' large army of Mamluks brought in from Circassia by Genoese merchants.\nThere were exceptions to this general attitude of tolerance, however, most notably by al-Hakim, though this has been highly debated, with Al-Hakim's reputation among medieval Muslim historians conflated with his role in the Druze faith. Christians in general and Copts in particular were persecuted by Al-Hakim; the persecution of the Christians included closing and demolishing churches and forced conversion to Islam. With the succession of Caliph al-Zahir, the Druze faced a mass persecution, which included large massacres against the Druze in Antioch, Aleppo, and other cities.\nIsma'ilis.\nIt's unclear what number or percentage of the population inside the caliphate were actually Isma'ilis, but they always remained a minority. Historical chronicles report large numbers of enthusiastic converts in Egypt during the reign of al-'Aziz, but this trend dropped significantly around the middle of al-Hakim's reign. The Fatimid state promoted Isma'ili doctrine (the \"da'wa\") through a hierarchical organization. The Imam-Caliph, as successor to the Prophet Muhammad, was both the political and religious leader. Below the Imam-Caliph, the top of this hierarchy was headed by the \"da'i l-du'at\" or \"supreme missionary\". Newcomers to the doctrine were initiated by attending the \"majalis al-hikma\" (\"Sessions of Wisdom\"), lectures and lessons that were delivered in a special hall inside the palaces of Cairo. The doctrine was kept secret from those who were not initiated. Additionally, Isma'ili doctrines were disseminated through the lectures hosted at Al-Azhar Mosque in Cairo, which became an intellectual center hosting teachers and students. Beyond the borders of the Fatimid Caliphate, recruitment to the \"da'wa\" continued to be performed in secret as it had been before the caliphate's establishment, though the many missionaries maintained contact with the leadership in Ifriqiya or Egypt. Some of the \"da'i\"s (missionaries) abroad sometimes came to Cairo and became important figures in the state, as with the example of al-Kirmani during al-Hakim's reign.\nIsma'ili unity was weakened over time by several schisms after the establishment of the caliphate (in addition to the Qarmatian schism before its establishment). The Druze, who believed in the divinity of Caliph al-Hakim, were suppressed in Egypt and elsewhere, but eventually found a home in the region of Mount Lebanon. After the death of Caliph al-Mustansir, a succession crisis resulted in the breakaway of the Nizaris, who supported the claim of his oldest son Nizar, as opposed to the Musta'lis who supported the successful enthronement of al-Musta'li. The Nizaris were also suppressed inside the Caliphate's borders, but continued to be active outside it, mostly in Iran, Iraq, and parts of Syria. After the death of Caliph al-Amir, al-Hafiz, his cousin, successfully claimed the title of Imam-Caliph at the expense of al-Amir's infant son, al-Tayyib. Those who recognized al-Hafiz in Cairo were known as the al-Hafizi branch, but those who opposed this unusual succession and supported the succession of al-Tayyib were known as the al-Tayyibi branch. This particular schism resulted in the loss of Fatimid support in Yemen.\nOther Muslims.\nIn Ifriqiya, the Sunni Muslims of the cities largely followed the Maliki school or \"madhhab\". The Maliki school had become predominant here during the eighth century at the expense of the Hanafi school, which had generally been favoured by the Aghlabids. In Egypt, the majority of Muslims were Sunni and remained so throughout the Fatimid period. Cognizant of this, the Fatimid authorities introduced Shi'a changes to religious rituals only gradually after Jawhar's conquest. It was also in this era that the followers of the Hanafi, Shafi'i, Hanbali, and Maliki schools were beginning to think of themselves collectively, to one extent or another, as Sunni, which undermined the universalism that the Shi'a Isma'ilis promoted. Some Shi'as, including some Hasanid and Husaynid families, were also present in Egypt and welcomed the Fatimids as fellow Shi'as or as blood relatives, but without necessarily converting to Isma'ilism. Many non-Isma'ili Muslims also accepted the Fatimid caliphs as having legitimate rights to lead the Muslim community but did not accept the more absolute Shi'a beliefs in the concept of the Imamate.\nChristians.\nChristians may have still constituted a majority of the population in Egypt during the Fatimid period, although scholarly estimates on this issue are tentative and vary between authors.194 The proportion of Christians would have likely been greater in the rural population than in the main cities. Among Christians, the largest community were Copts, followed by Melkite Christians. A large number of Armenian immigrants also arrived in Egypt during the late 11th and early 12th centuries when Armenian viziers like Badr al-Jamali dominated the state, which led to the Armenian church establishing a foothold in the country as well. In addition to churches in towns and cities, Christian monasteries also dotted the countryside. Some regions, like Wadi al-Natrun, were ancient centres of Coptic monasticism. Italian traders, led by Amalfitans, were also present in Fustat and Alexandria, moving goods between Egypt and the rest of the Mediterranean world.\nWithin the Christian communities, and especially among Copts, there emerged a relatively affluent class of notables who served as scribes or administrators in the Fatimid regime. These laymen used their wealth to patronize, and in turn influence, their churches. The state also had influence on the church, as demonstrated by the transfer of the Coptic Patriarchate from Alexandria to Fustat (specifically what is now Old Cairo) during the patriarchate of Cyril II (1078\u20131092), due to the demands of Badr al-Jamali, who wished for the Coptic pope to stay close to the capital.202 The Church of the Virgin, now known as the Hanging Church, became the new seat of the Patriarchate, along with an alternative church compound built on the upper floor of the St. Mercurius Church. Until the 14th century (when the seat was moved to the Church of the Virgin Mary in Harat Zuwayla), both churches were residences of the Coptic pope and served as venues for the consecrations of new popes and other important religious events.202\nJews.\nJewish communities existed across the territories under Fatimid control and also enjoyed a degree of self-governance. Although a smaller minority compared to Christians and Muslims, their history is relatively well documented thanks to the Genizah documents. The community was divided between Rabbanites and Karaites. Traditionally, up until the late 11th century, the most powerful head of the Jewish community was the \"ga'on\" or leader of the \"yeshiva\" of Jerusalem, who appointed judges and other Jewish community officials across the region. The Fatimids formally charged the \"ga'on\" of Jerusalem with responsibilities as representative of the community. By 1100, however, a new position was established by Egyptian Jews in Fustat, known as the \"Head of the Jews\" or as the \"nagid\". This official in the Egyptian capital became recognized afterward as the head and representative of the Jewish community in its dealings with the Fatimid state. This shift was likely due to the Jerusalem \"ga'on\"'s own loss of influence and to the Jewish community's engagement with the centralizing politics that Badr al-Jamali pursued around this time (which had already resulted in the transfer of the Coptic Patriarchate to Fustat).\nLanguage.\nReligious diversity notwithstanding, the spread of Arabic as the main language of the population had already progressed rapidly before the Fatimid period. In parts of Egypt, Copts and possibly also some Muslim communities were still speaking Coptic when the Fatimids arrived on the scene. It is during the Fatimid period, however, that Coptic religious culture began to be translated into Arabic. By the end of the Fatimid period (12th century), many Coptic Christians could no longer understand the Coptic language, and eventually its usage was reduced to a liturgical language.194\nMilitary system.\nThe Fatimid military was based largely on the Kutama Berber tribesmen brought along on the march to Egypt, and they remained an important part of the military even after Ifriqiya began to break away.\nA fundamental change occurred when the Fatimid Caliphate attempted to push into Syria in the latter half of the tenth century. The Fatimids were faced with the now Turkish-dominated forces of the Abbasid Caliphate and began to realize the limits of their current military. Thus during the reign of al-Aziz Billah and al-Hakim bi-Amr Allah, the Caliph began incorporating armies of Turks and, later, black Africans (even later, other groups such as Armenians were also used). The army units were generally separated along ethnic lines: the Berbers were usually the light cavalry and foot skirmishers, while the Turks were the horse archers or heavy cavalry (known as \"Mamluks\"). The black Africans, Syrians, and Arabs generally acted as the heavy infantry and foot archers. This ethnic-based army system, along with the partial slave status of many of the imported ethnic fighters, would remain fundamentally unchanged in Egypt for many centuries after the fall of the Fatimid Caliphate.\nThe Fatimids focused their military on the defence of the empire as threats presented, which they were able to repel. In the mid-10th century, the Byzantine Empire was ruled by Nikephoros II Phokas, who had destroyed the Muslim Emirate of Crete in 961 and conquered Tartus, al-Masaisah, Ain Zarbah, among other areas, gaining complete control of Iraq and the Syrian borders, and earning the sobriquet \"The Pale Death of the Saracens\". With the Fatimids, however, he proved less successful. After renouncing his payments of tribute to the Fatimid caliphs, he sent an expedition to Sicily, but was forced by defeats on land and sea to evacuate the island completely. In 967, he made peace with the Fatimids and turned to defend himself against their common enemy, Otto\u00a0I, who had proclaimed himself Roman Emperor and had attacked Byzantine possessions in Italy.\nCapital cities.\nAl-Mahdiyya.\nAl-Mahdiyya, the first capital of the Fatimid dynasty, was established by its first caliph, Abdullah al-Mahdi (297\u2013322 AH/909\u2013934 CE) in 300 AH/912\u2013913 CE. The caliph had been residing in nearby Raqqada but chose this new and more strategic location in which to establish his dynasty. The city of al-Mahdiyya is located on a narrow peninsula along the coast of the Mediterranean Sea, east of Kairouan and just south of the Gulf of Hammamet, in modern-day Tunisia. The primary concern in the city's construction and locale was defense. With its peninsular topography and the construction of a wall 8.3 m thick, the city became impenetrable by land. This strategic location, together with a navy that the Fatimids had inherited from the conquered Aghlabids, made the city of al-Mahdiyya a strong military base where Abdullah al-Mahdi consolidated power and planted the seeds of the Fatimid caliphate for two generations. The city included two royal palaces\u2014one for the caliph and one for his son and successor al-Qa'im\u2014as well as a mosque, many administrative buildings, and an arsenal.\nAl-Mansuriyya.\nAl-Mansuriyya (also known as \u1e62abra al-Mansuriyya) was established between 334 and 336 AH (945 and 948 CE) by the third Fatimid caliph al-Mansur (334\u201341 AH/946\u201353 CE) in a settlement known as \u1e62abra, located on the outskirts of Kairouan in modern-day Tunisia. The new capital was established in commemoration of the victory of al-Mansur over the Kharijite rebel Aba Yazid at \u1e62abra. Construction of the city was not quite finished when al-Mansur died in 953, but his son and successor, al-Mu'izz, finished it and completed the city's mosque that same year. Like Baghdad, the plan of the city of Al-Mansuriyya is round, with the caliphal palace at its center. Due to a plentiful water source, the city grew and expanded a great deal under al-Mansur. Archaeological evidence suggests that there were more than 300 hammams built during this period in the city as well as numerous palaces. When al-Mansur's successor, al-Mu'izz, moved the caliphate to Cairo he left his deputy, Buluggin ibn Ziri, as regent of Ifriqiya, marking the beginning of the city's Zirid period. In 1014\u201315 the Zirid ruler Badis ibn al-Mansur ordered merchants and artisans of Kairouan to be transferred to al-Mansuriyya, which may have helped provoke a revolt in 1016 which damaged the city. In 1057, under pressure from the Banu Hilal invasions, the Zirids abandoned al-Mansuriyya for Mahdiyya and the city was devastated. Unlike Kairouan, it remained in ruins afterwards and was never revived. The site was pillaged over time. Modern archeological excavations here began in 1921.\nCairo.\nCairo was established by the fourth Fatimid caliph, al-Mu'izz, in 359 AH/970 CE and remained the capital of the Fatimid caliphate for the duration of the dynasty. The city was officially named \"al-Qahirah al-Mu'izziyya\", which can be translated as the \"Victorious City of al-Mu'izz\", known afterward simply as \"al-Qahira\" and giving us the modern English name \"Cairo\". Cairo can thus be considered the capital of Fatimid cultural production. Though the original Fatimid palace complex, including administrative buildings and royal residents, no longer exists, modern scholars can glean a good idea of the original structure based on the Mamluk-era account of al-Maqrizi. Perhaps the most important of Fatimid monuments outside the palace complex is the mosque of al-Azhar (359\u201361 AH/970\u201372 CE) which still stands today, though the building was significantly expanded and modified in later periods. Likewise, the important Fatimid mosque of al-Hakim, built from 380 to 403 AH/990\u20131012 CE under two Fatimid caliphs, was significantly rebuilt and renovated in the 1980s. Cairo remained the capital for, including al-Mu'izz, eleven generations of caliphs, after which the Fatimid Caliphate finally fell to Ayyubid forces in 567 AH/1171 CE.\nArt and architecture.\nThe Fatimids were known for their exquisite arts. The Fatimid period is important in the history of Islamic art and architecture as it is one of the earliest Islamic dynasties for which enough materials survive for a detailed study of their evolution. The stylistic diversity of Fatimid art was also a reflection of the wider cultural environment of the Mediterranean world at this time. The most notable characteristics of their decorative arts are the use of lively figurative motifs and the use of an angular, floriated Kufic script for Arabic inscriptions. Among the best-known art forms that flourished are a type of ceramic lustreware and the crafting of objects carved in solid rock crystal. The dynasty also sponsored the production of linen textiles and a \"tiraz\" workshop. A vast collection of different luxury objects once existed within the caliph's palaces, but few examples of them have survived to the present day.\nMany traces of Fatimid architecture exist in both Egypt and present-day Tunisia, particularly in the former capitals of Mahdia (al-Mahdiyya) and Cairo (al-Qahira). At Mahdia, the most important surviving monument is Great Mosque. In Cairo, prominent examples include the Al-Azhar Mosque and the Al-Hakim Mosque, as well as the smaller monuments of al-Aqmar Mosque, the Mashhad of Sayyida Ruqayya, and the Mosque of al-Salih Tala'i. Al-Azhar Mosque, which was also a center of learning and teaching known today as al-Azhar University, was named in honour of Fatimah (the daughter of Muhammad from whom the Fatimids claimed descent), who was called \"Az-Zahra\" (the brilliant). There were two main Fatimid palaces in Cairo, covering a huge area around Bayn al-Qasrayn, near Khan el-Khalili. Parts of the city walls constructed by Badr al-Jamali\u2014most notably three of its gates\u2014also survive.\nImportant figures.\nList of important figures:\nLegacy.\nAfter Al-Mustansir Billah, his sons Nizar and Al-Musta'li both claimed the right to rule, leading to a split into the Nizari and Musta'li factions respectively. Nizar's successors eventually came to be known as the \"Aga Khan\", while Musta'li's followers eventually came to be called the \"Dawoodi bohra\".\nThe Fatimid dynasty continued and flourished under Al-Musta'li until Al-Amir bi-Ahkami'l-Lah's death in 1130. Leadership was then contested between At-Tayyib Abu'l-Qasim, Al-Amir's two-year-old son, and Al-Hafiz, Al-Amir's cousin whose supporters (Hafizi) claimed Al-Amir died without an heir. The supporters of At-Tayyib became the Tayyibi Isma'ilis. At-Tayyib's claim to the imamate was endorsed by Arwa al-Sulayhi, Queen of Yemen. In 1084, Al-Mustansir had Arwa designated a \"hujjah\" (a holy, pious lady), the highest rank in the Yemeni Da'wah. Under Arwa, the \"Da'i al-Balagh\" (the imam's local representative) Lamak ibn Malik and then Yahya ibn Lamak worked for the cause of the Fatimids. After At-Tayyib's disappearance, Arwa named Dhu'ayb bin Musa the first \"Da'i al-Mutlaq\" with full authority over Tayyibi religious matters. Tayyibi Isma'ili missionaries (in about 1067 AD (460 AH)) spread their religion to India, leading to the development of various Isma'ili communities, most notably the Alavi, Dawoodi, and Sulaymani Bohras. Syedi Nuruddin went to Dongaon to look after southern India and Syedi Fakhruddin went to East Rajasthan.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56178", "revid": "7098284", "url": "https://en.wikipedia.org/wiki?curid=56178", "title": "Bandana (disambiguation)", "text": "A bandana is a cloth also known as a kerchief.\nBandana or bandanna may also refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "56180", "revid": "86247", "url": "https://en.wikipedia.org/wiki?curid=56180", "title": "Leia Organa", "text": ""}
{"id": "56181", "revid": "86247", "url": "https://en.wikipedia.org/wiki?curid=56181", "title": "Leia Organa-Solo", "text": ""}
{"id": "56182", "revid": "86247", "url": "https://en.wikipedia.org/wiki?curid=56182", "title": "Leia Organa Solo", "text": ""}
{"id": "56183", "revid": "9021902", "url": "https://en.wikipedia.org/wiki?curid=56183", "title": "Battle of Abukir", "text": "Battle of Abukir may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "56186", "revid": "29615425", "url": "https://en.wikipedia.org/wiki?curid=56186", "title": "Barnards Star", "text": ""}
{"id": "56189", "revid": "46866511", "url": "https://en.wikipedia.org/wiki?curid=56189", "title": "Interlaced video", "text": "Technique for doubling the perceived frame rate of a video display\nInterlaced video (also known as interlaced scan) is a technique for doubling the perceived frame rate of a video display without consuming extra bandwidth. The interlaced signal contains two fields of a video frame captured consecutively. This enhances motion perception to the viewer, and reduces flicker by taking advantage of the characteristics of the human visual system.\nThis effectively doubles the time resolution (also called \"temporal resolution\") as compared to non-interlaced footage (for frame rates equal to field rates). Interlaced signals require a display that is natively capable of showing the individual fields in a sequential order. CRT displays and ALiS plasma displays are made for displaying interlaced signals.\nInterlaced scan refers to one of two common methods for \"painting\" a video image on an electronic display screen (the other being progressive scan) by scanning or displaying each line or row of pixels. This technique uses two fields to create a frame. One field contains all odd-numbered lines in the image; the other contains all even-numbered lines.\nSometimes in interlaced video a field is called a frame which can lead to confusion.\nA Phase Alternating Line (PAL)-based television set display, for example, scans 50 \"fields\" every second (25 odd and 25 even). The two sets of 25 fields work together to create a full \"frame\" every 1/25 of a second (or 25 frames per second), but with interlacing create a new half frame every 1/50 of a second (or 50 fields per second). To display interlaced video on progressive scan displays, playback applies deinterlacing to the video signal (which adds input lag).\nThe European Broadcasting Union argued against interlaced video in production and broadcasting. Until the early 2010s, they recommended 720p 50 fps (frames per second) for the current production format\u2014and were working with the industry to introduce 1080p 50 as a future-proof production standard. 1080p 50 offers higher vertical resolution, better quality at lower bitrates, and easier conversion to other formats, such as 720p 50 and 1080i 50. The main argument is that no matter how complex the deinterlacing algorithm may be, the artifacts in the interlaced signal cannot be eliminated because some information is lost between frames.\nDespite arguments against it, television standards organizations continue to support interlacing. It is still included in digital video transmission formats such as DV, DVB, and ATSC. New video compression standards like High Efficiency Video Coding are optimized for progressive scan video, but sometimes do support interlaced video.\nDescription.\nProgressive scan captures, transmits, and displays an image in a path similar to text on a page\u2014line by line, top to bottom.\nThe interlaced scan pattern in a standard definition CRT display also completes such a scan, but in two passes (two fields). The first pass displays the first and all odd numbered lines, from the top left corner to the bottom right corner. The second pass displays the second and all even numbered lines, filling in the gaps in the first scan.\nThis scan of alternate lines is called \"interlacing\". A \"field\" is an image that contains only half of the lines needed to make a complete picture. In the days of CRT displays, the afterglow of the display's phosphor aided this effect.\nInterlacing provides full vertical detail with the same bandwidth that would be required for a full progressive scan, but with twice the perceived frame rate and refresh rate. To prevent flicker, all analog broadcast television systems used interlacing.\nFormat identifiers like 576i50 and 720p50 specify the frame rate for progressive scan formats, but for interlaced formats they typically specify the field rate (which is twice the frame rate). This can lead to confusion, because industry-standard SMPTE timecode formats always deal with frame rate, not field rate. To avoid confusion, SMPTE and EBU always use frame rate to specify interlaced formats, e.g., 480i60 is 480i/30, 576i50 is 576i/25, and 1080i50 is 1080i/25. This convention assumes that one complete frame in an interlaced signal consists of two fields in sequence.\nBenefits of interlacing.\nOne of the most important factors in analog television is signal bandwidth, measured in megahertz. The greater the bandwidth, the more expensive and complex the entire production and broadcasting chain. This includes cameras, storage systems, broadcast systems\u2014and reception systems: terrestrial, cable, satellite, Internet, and end-user displays (TVs and computer monitors).\nFor a fixed bandwidth, interlace provides a video signal with twice the display refresh rate for a given line count (versus progressive scan video at a similar frame rate\u2014for instance 1080i at 60 half-frames per second, vs. 1080p at 30 full frames per second). The higher refresh rate improves the appearance of an object in motion, because it updates its position on the display more often, and when an object is stationary, human vision combines information from multiple similar half-frames to produce the same perceived resolution as that provided by a progressive full frame. This technique is only useful, though, if source material is available in higher refresh rates. Cinema movies are typically recorded at 24fps, and therefore do not benefit from interlacing, a solution which reduces the maximum video bandwidth to 5\u00a0MHz without reducing the effective picture scan rate of 60\u00a0Hz.\nGiven a fixed bandwidth and high refresh rate, interlaced video can also provide a higher spatial resolution than progressive scan. For instance, 1920\u00d71080 pixel resolution interlaced HDTV with a 60\u00a0Hz field rate (known as 1080i60 or 1080i/30) has a similar bandwidth to 1280\u00d7720 pixel progressive scan HDTV with a 60\u00a0Hz frame rate (720p60 or 720p/60), but achieves approximately twice the spatial resolution for low-motion scenes.\nHowever, bandwidth benefits only apply to an analog or \"uncompressed\" digital video signal. With digital video compression, as used in all current digital TV standards, interlacing introduces additional inefficiencies. EBU has performed tests that show that the bandwidth savings of interlaced video over progressive video is minimal, even with twice the frame rate. I.e., 1080p50 signal produces roughly the same bit rate as 1080i50 (aka 1080i/25) signal, and 1080p50 actually requires less bandwidth to be perceived as subjectively better than its 1080i/25 (1080i50) equivalent when encoding a \"sports-type\" scene.\nInterlacing can be exploited to produce 3D TV programming, especially with a CRT display and especially for color filtered glasses by transmitting the color keyed picture for each eye in the alternating fields. This does not require significant alterations to existing equipment. Shutter glasses can be adopted as well, obviously with the requirement of achieving synchronisation. If a progressive scan display is used to view such programming, any attempt to deinterlace the picture will render the effect useless. For color filtered glasses the picture has to be either buffered and shown as if it was progressive with alternating color keyed lines, or each field has to be line-doubled and displayed as discrete frames. The latter procedure is the only way to suit shutter glasses on a progressive display.\nInterlacing problems.\nInterlaced video is designed to be captured, stored, transmitted, and displayed in the same interlaced format. Because each interlaced video frame is two fields captured at different moments in time, interlaced video frames can exhibit motion artifacts known as \"interlacing effects\", or \"combing\", if recorded objects move fast enough to be in different positions when each individual field is captured. These artifacts may be more visible when interlaced video is displayed at a slower speed than it was captured, or in still frames.\nWhile there are simple methods to produce somewhat satisfactory progressive frames from the interlaced image, for example by doubling the lines of one field and omitting the other (halving vertical resolution), or anti-aliasing the image in the vertical axis to hide some of the combing, there are sometimes methods of producing results far superior to these. If there is only sideways (X axis) motion between the two fields and this motion is even throughout the full frame, it is possible to align the scanlines and crop the left and right ends that exceed the frame area to produce a visually satisfactory image. Minor Y\u00a0axis motion can be corrected similarly by aligning the scanlines in a different sequence and cropping the excess at the top and bottom. Often the middle of the picture is the most necessary area to put into check, and whether there is only X or Y\u00a0axis alignment correction, or both are applied, most artifacts will occur towards the edges of the picture. However, even these simple procedures require motion tracking between the fields, and a rotating or tilting object, or one that moves in the Z\u00a0axis (away from or towards the camera) will still produce combing, possibly even looking worse than if the fields were joined in a simpler method. \nSome deinterlacing processes can analyze each frame individually and decide the best method. The best and only perfect conversion in these cases is to treat each frame as a separate image, but that may not always be possible. For framerate conversions and zooming it would mostly be ideal to line-double each field to produce a double rate of progressive frames, resample the frames to the desired resolution and then re-scan the stream at the desired rate, either in progressive or interlaced mode.\nInterline twitter.\nInterlace introduces a potential problem called interline twitter, a form of moir\u00e9. This aliasing effect only shows up under certain circumstances\u2014when the subject contains vertical detail that approaches the horizontal resolution of the video format. For instance, a finely striped jacket on a news anchor may produce a shimmering effect. This is \"twittering\". Television professionals avoid wearing clothing with fine striped patterns for this reason. Professional video cameras or computer-generated imagery systems apply a low-pass filter to the vertical resolution of the signal to prevent interline twitter.\nInterline twitter is the primary reason that interlacing is less suited for computer displays. Each scanline on a high-resolution computer monitor typically displays discrete pixels, each of which does not span the scanline above or below. When the overall interlaced framerate is 60 frames per second, a pixel (or more critically for e.g. windowing systems or underlined text, a horizontal line) that spans only one scanline in height is visible for the 1/60 of a second that would be expected of a 60\u00a0Hz progressive display - but is then followed by 1/60 of a second of darkness (whilst the opposite field is scanned), reducing the per-line/per-pixel refresh rate to 30 frames per second with quite obvious flicker.\nTo avoid this, standard interlaced television sets typically do not display sharp detail. When computer graphics appear on a standard television set, the screen is either treated as if it were half the resolution of what it actually is (or even lower), or rendered at full resolution and then subjected to a low-pass filter in the vertical direction (e.g. a \"motion blur\" type with a 1-pixel distance, which blends each line 50% with the next, maintaining a degree of the full positional resolution and preventing the obvious \"blockiness\" of simple line doubling whilst actually reducing flicker to less than what the simpler approach would achieve). If text is displayed, it is large enough so that any horizontal lines are at least two scanlines high. Most fonts for television programming have wide, fat strokes, and do not include fine-detail serifs that would make the twittering more visible; in addition, modern character generators apply a degree of anti-aliasing that has a similar line-spanning effect to the aforementioned full-frame low-pass filter.\nDeinterlacing.\nALiS plasma panels and CRTs can display interlaced video directly, but modern computer video displays and TV sets are mostly based on LCD technology, which mostly use progressive scanning.\nDisplaying interlaced video on a progressive scan display requires a process called deinterlacing. This is can be an imperfect technique, especially if the frame rate isn't doubled in the deinterlaced output. Providing the best picture quality for interlaced video signals without doubling the frame rate requires expensive and complex devices and algorithms, and can cause various artifacts. For television displays, deinterlacing systems are integrated into progressive scan TV sets that accept interlaced signal, such as broadcast SDTV signal.\nMost modern computer monitors do not support interlaced video, besides some legacy medium-resolution modes (and possibly 1080i as an adjunct to 1080p), and support for standard-definition video (480/576i or 240/288p) is particularly rare given its much lower line-scanning frequency vs typical \"VGA\"-or-higher analog computer video modes. Playing back interlaced video from a DVD, digital file or analog capture card on a computer display instead requires some form of deinterlacing in the player software and/or graphics hardware, which often uses very simple methods to deinterlace. This means that interlaced video often has visible artifacts on computer systems. Computer systems may be used to edit interlaced video, but the disparity between computer video display systems and interlaced television signal formats means that the video content being edited cannot be viewed properly without separate video display hardware.\nCurrent manufacture TV sets employ a system of intelligently extrapolating the extra information that would be present in a progressive signal entirely from an interlaced original. In theory: this should simply be a problem of applying the appropriate algorithms to the interlaced signal, as all information should be present in that signal. In practice, results are currently variable, and depend on the quality of the input signal and amount of processing power applied to the conversion. The biggest impediment, at present, is artifacts in the lower quality interlaced signals (generally broadcast video), as these are not consistent from field to field. On the other hand, high bit rate interlaced signals such as from HD camcorders operating in their highest bit rate mode work well.\nDeinterlacing algorithms temporarily store a few frames of interlaced images and then extrapolate extra frame data to make a smooth flicker-free image. This frame storage and processing results in a slight display lag that is visible in business showrooms with a large number of different models on display. Unlike the old unprocessed NTSC signal, the screens do not all follow motion in perfect synchrony. Some models appear to update slightly faster or slower than others. Similarly, the audio can have an echo effect due to different processing delays.\nHistory.\nWhen motion picture film was developed, the movie screen had to be illuminated at a high rate to prevent visible flicker. The exact rate necessary varies by brightness \u2014 50\u00a0Hz is (barely) acceptable for small, low brightness displays in dimly lit rooms, whilst 80\u00a0Hz or more may be necessary for bright displays that extend into peripheral vision. The film solution was to project each frame of film three times using a three-bladed shutter: a movie shot at 16 frames per second illuminated the screen 48 times per second. Later, when sound film became available, the higher projection speed of 24 frames per second enabled a two-bladed shutter to produce 48 times per second illumination\u2014but only in projectors incapable of projecting at the lower speed.\nThis solution could not be used for television. To store a full video frame and display it twice requires a frame buffer\u2014electronic memory (RAM)\u2014sufficient to store a video frame. This method did not become feasible until the late 1980s and with digital technology. In addition, avoiding on-screen interference patterns caused by studio lighting and the limits of vacuum tube technology required that CRTs for TV be scanned at AC line frequency. (This was 60\u00a0Hz in the US, 50\u00a0Hz Europe.)\nSeveral different interlacing patents have been proposed since 1914 in the context of still or moving image transmission, but few of them were practicable. In 1926, Ulises Armand Sanabria demonstrated television to 200,000 people attending Chicago Radio World's Fair. Sanabria's system was mechanically scanned using a 'triple interlace' Nipkow disc with three offset spirals and was thus a 3:1 scheme rather than the usual 2:1. It worked with 45 line 15 frames per second images being transmitted. With 15 frames per second and a 3:1 interlace the field rate was 45 fields per second yielding (for the time) a very steady image. He did not apply for a patent for his interlaced scanning until May 1931.\nIn 1930, German Telefunken engineer Fritz Schr\u00f6ter first formulated and patented the concept of breaking a single image frame into successive interlaced lines, based on his earlier experiments with phototelegraphy. In the US, RCA engineer Randall C. Ballard patented the same idea in 1932, initially for the purpose of reformatting sound film to television rather than for the transmission of live images. Commercial implementation began in 1934 as cathode-ray tube screens became brighter, increasing the level of flicker caused by progressive (sequential) scanning.\nIn 1936, when the UK was setting analog standards, early thermionic valve based CRT drive electronics could only scan at around 200 lines in 1/50 of a second (i.e. approximately a 10\u00a0kHz repetition rate for the sawtooth horizontal deflection waveform). Using interlace, a pair of 202.5-line fields could be superimposed to become a sharper 405 line frame (with around 377 used for the actual image, and yet fewer visible within the screen bezel; in modern parlance, the standard would be \"377i\"). The vertical scan frequency remained 50\u00a0Hz, but visible detail was noticeably improved. As a result, this system supplanted John Logie Baird's 240 line mechanical progressive scan system that was also being trialled at the time.\nFrom the 1940s onward, improvements in technology allowed the US and the rest of Europe to adopt systems using increasingly higher line-scan frequencies and more radio signal bandwidth to produce higher line counts at the same frame rate, thus achieving better picture quality. However the fundamentals of interlaced scanning were at the heart of all of these systems. The US adopted the 525 line system, later incorporating the composite color standard known as NTSC, Europe adopted the 625 line system, and the UK switched from its idiosyncratic 405 line system to (the much more US-like) 625 to avoid having to develop a (wholly) unique method of color TV. France switched from its similarly unique 819 line monochrome system to the more European standard of 625. Europe in general, including the UK, then adopted the PAL color encoding standard, which was essentially based on NTSC, but inverted the color carrier phase with each line (and frame) in order to cancel out the hue-distorting phase shifts that dogged NTSC broadcasts. France instead adopted its own unique, twin-FM-carrier based SECAM system, which offered improved quality at the cost of greater electronic complexity, and was also used by some other countries, notably Russia and its satellite states. Though the color standards are often used as synonyms for the underlying video standard - NTSC for 525i/60, PAL/SECAM for 625i/50 - there are several cases of inversions or other modifications; e.g. PAL color is used on otherwise \"NTSC\" (that is, 525i/60) broadcasts in Brazil, as well as vice versa elsewhere, along with cases of PAL bandwidth being squeezed to 3.58\u00a0MHz to fit in the broadcast waveband allocation of NTSC, or NTSC being expanded to take up PAL's 4.43\u00a0MHz.\nInterlacing was ubiquitous in displays until the 1970s, when the needs of computer monitors resulted in the reintroduction of progressive scan, including on regular TVs or simple monitors based on the same circuitry; most CRT based displays are entirely capable of displaying both progressive and interlace regardless of their original intended use, so long as the horizontal and vertical frequencies match, as the technical difference is simply that of either starting/ending the vertical sync cycle halfway along a scanline every other frame (interlace), or always synchronising right at the start/end of a line (progressive). Interlace is still used for most standard definition TVs, and the 1080i HDTV broadcast standard, but not for LCD, micromirror (DLP), or most plasma displays; these displays do not use a raster scan to create an image (their panels may still be updated in a left-to-right, top-to-bottom scanning fashion, but always in a progressive fashion, and not necessarily at the same rate as the input signal), and so cannot benefit from interlacing (where older LCDs use a \"dual scan\" system to provide higher resolution with slower-updating technology, the panel is instead divided into two \"adjacent\" halves that are updated \"simultaneously\"): in practice, they have to be driven with a progressive scan signal. The deinterlacing circuitry to get progressive scan from a normal interlaced broadcast television signal can add to the cost of a television set using such displays. Currently, progressive displays dominate the HDTV market.\nInterlace and computers.\nIn the 1970s, computers and home video game systems began using TV sets as display devices. At that point, a 480-line NTSC signal was well beyond the graphics abilities of low cost computers, so these systems used a simplified video signal that made each video field scan directly on top of the previous one, rather than each line between two lines of the previous field, along with relatively low horizontal pixel counts. This marked the return of progressive scanning not seen since the 1920s. Since each field became a complete frame on its own, modern terminology would call this 240p on NTSC sets, and 288p on PAL. While consumer devices were permitted to create such signals, broadcast regulations prohibited TV stations from transmitting video like this. Computer monitor standards such as the TTL-RGB mode available on the CGA and e.g. BBC Micro were further simplifications to NTSC, which improved picture quality by omitting modulation of color, and allowing a more direct connection between the computer's graphics system and the CRT.\nBy the mid-1980s, computers had outgrown these video systems and needed better displays. Most home and basic office computers suffered from the use of the old scanning method, with the highest display resolution being around 640x200 (or sometimes 640x256 in 625-line/50\u00a0Hz regions), resulting in a severely distorted tall narrow pixel shape, making the display of high resolution text alongside realistic proportioned images difficult (logical \"square pixel\" modes were possible but only at low resolutions of 320x200 or less). Solutions from various companies varied widely. Because PC monitor signals did not need to be broadcast, they could consume far more than the 6, 7 and 8\u00a0MHz of bandwidth that NTSC and PAL signals were confined to. IBM's Monochrome Display Adapter and Enhanced Graphics Adapter as well as the Hercules Graphics Card and the original Macintosh computer generated video signals of 342 to 350p, at 50 to 60\u00a0Hz, with approximately 16\u00a0MHz of bandwidth, some enhanced PC clones such as the AT&amp;T 6300 (aka Olivetti M24) as well as computers made for the Japanese home market managed 480p instead at around 24\u00a0MHz, and the Atari ST pushed that to 71\u00a0Hz with 32\u00a0MHz bandwidth - all of which required dedicated high-frequency (and usually single-mode, i.e. not \"video\"-compatible) monitors due to their increased line rates. The Commodore Amiga instead created a true interlaced 480i60/576i50 RGB signal at broadcast video rates (and with a 7 or 14\u00a0MHz bandwidth), suitable for NTSC/PAL encoding (where it was smoothly decimated to 3.5~4.5\u00a0MHz). This ability (plus built-in genlocking) resulted in the Amiga dominating the video production field until the mid-1990s, but the interlaced display mode caused flicker problems for more traditional PC applications where single-pixel detail is required, with \"flicker-fixer\" scan-doubler peripherals plus high-frequency RGB monitors (or Commodore's own specialist scan-conversion A2024 monitor) being popular, if expensive, purchases amongst power users. 1987 saw the introduction of VGA, on which PCs soon standardized, as well as Apple's Macintosh II range which offered displays of similar, then superior resolution and color depth, with rivalry between the two standards (and later PC quasi-standards such as XGA and SVGA) rapidly pushing up the quality of display available to both professional and home users.\nIn the late 1980s and early 1990s, monitor and graphics card manufacturers introduced newer high resolution standards that once again included interlace. These monitors ran at higher scanning frequencies, typically allowing a 75 to 90\u00a0Hz field rate (i.e. 37.5 to 45\u00a0Hz frame rate), and tended to use longer-persistence phosphors in their CRTs, all of which was intended to alleviate flicker and shimmer problems. Such monitors proved generally unpopular, outside of specialist ultra-high-resolution applications such as CAD and DTP which demanded as many pixels as possible, with interlace being a necessary evil and better than trying to use the progressive-scan equivalents. Whilst flicker was often not immediately obvious on these displays, eyestrain and lack of focus nevertheless became a serious problem, and the trade-off for a longer afterglow was reduced brightness and poor response to moving images, leaving visible and often off-colored trails behind. These colored trails were a minor annoyance for monochrome displays, and the generally slower-updating screens used for design or database-query purposes, but much more troublesome for color displays and the faster motions inherent in the increasingly popular window-based operating systems, as well as the full-screen scrolling in WYSIWYG word-processors, spreadsheets, and of course for high-action games. Additionally, the regular, thin horizontal lines common to early GUIs, combined with low color depth that meant window elements were generally high-contrast (indeed, frequently stark black-and-white), made shimmer even more obvious than with otherwise lower fieldrate video applications. As rapid technological advancement made it practical and affordable, barely a decade after the first ultra-high-resolution interlaced upgrades appeared for the IBM PC, to provide sufficiently high pixel clocks and horizontal scan rates for hi-rez progressive-scan modes in first professional and then consumer-grade displays, the practice was soon abandoned. For the rest of the 1990s, monitors and graphics cards instead made great play of their highest stated resolutions being \"non-interlaced\", even where the overall framerate was barely any higher than what it had been for the interlaced modes (e.g. SVGA at 56p versus 43i to 47i), and usually including a top mode technically exceeding the CRT's actual resolution (number of color-phosphor triads) which meant there was no additional image clarity to be gained through interlacing and/or increasing the signal bandwidth still further. This experience is why the PC industry today remains against interlace in HDTV, and lobbied for the 720p standard, and continues to push for the adoption of 1080p (at 60\u00a0Hz for NTSC legacy countries, and 50\u00a0Hz for PAL); however, 1080i remains the most common HD broadcast resolution, if only for reasons of backward compatibility with older HDTV hardware that cannot support 1080p - and sometimes not even 720p - without the addition of an external scaler, similar to how and why most SD-focussed digital broadcasting still relies on the otherwise obsolete MPEG2 standard embedded into e.g. DVB-T.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56190", "revid": "31613059", "url": "https://en.wikipedia.org/wiki?curid=56190", "title": "Fifth Estate (periodical)", "text": "American periodical\nFifth Estate is a U.S. anarchist-libertarian periodical, based in Detroit, Michigan, begun in 1965.\nHistory.\n\"Fifth Estate\" was started by Harvey Ovshinsky, a seventeen-year-old youth from Detroit. He was inspired by a 1965 summer trip to California where he worked on the \"Los Angeles Free Press\", the first underground paper in the United States; Harvey's father, inventor Stan Ovshinsky, knew the editor of the \"Free Press\", Art Kunkin, from their years as comrades in the Socialist Party. The first issue was published on November 19, 1965.\nThe spirit of the paper during the first ten years of its existence was summed up in a Feb. 1, 1969, staff editorial:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We believe that people who are serious in their criticism of this society and their desire to change it must involve themselves in serious revolutionary struggle. We do not believe that music is revolution. We do not believe that dope is revolution. We do not believe that poetry is revolution. We see these as part of a burgeoning revolutionary culture. They cannot replace political struggle as the main means by which the capitalist system will be destroyed. The Man will not allow his social and economic order to be taken from him by Marshall amps and clashing cymbals. Ask the Cubans, the Vietnamese or urban American blacks what lengths the system is willing to go to, to preserve itself.\nBy 1972 the optimism of the sixties had worn off and the tone of the paper became more concerned with struggle than fun. Ovshinsky had left in 1969, leaving a group of young people (teenagers or people in their early twenties) to run the paper. Peter Werbe, a 29-year-old Michigan State University dropout who had been with the paper since March 1966, took over as editor. The staff sent delegations to Vietnam, Cambodia and Cuba. The massive defeat of George McGovern and the election of Richard Nixon for a second term with an increased vote damaged the movement \u2014 many underground papers ceased publication and alternative news agencies such as the Liberation News Service, and the Underground Press Syndicate were beginning to collapse. The \"Fifth Estate\" was mentioned in the national press when one of its reporters, Pat Halley, threw a shaving cream pie at Guru Maharaj Ji in 1973. Though the guru forgave him publicly, two of his followers attacked Halley a week later and fractured his skull.\nIn 2002, the center of the magazine shifted from Detroit, Michigan to Liberty, Tennessee when long-time contributor Andrew Smith (who wrote under the name Andy Sunfrog) took over the main editorial duties of the magazine, although long-time Detroit staffers like Peter Werbe remained involved.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "56191", "revid": "50619322", "url": "https://en.wikipedia.org/wiki?curid=56191", "title": "Memorial Day", "text": "Federal holiday in the United States\nMemorial Day is a federal holiday in the United States for mourning the U.S. military personnel who died while serving in the United States Armed Forces. It is observed on the last Monday of May. \nIt is the unofficial beginning of summer in the United States. \nMemorial Day is a time for visiting cemeteries and memorials to mourn the military personnel who died in the line of duty. Volunteers will place American flags on the graves of those military personnel in national cemeteries. \nThe first national observance of Memorial Day occurred on May 30, 1868. Then known as \"Decoration Day\" and observed on May 30, the holiday was proclaimed by Commander in Chief John A. Logan of the Grand Army of the Republic to honor the Union soldiers who had died in the American Civil War. This national observance followed many local observances which were inaugurated between the end of the Civil War and Logan's declaration. Many cities and people have claimed to be the first to observe it. However, the National Cemetery Administration, a division of the Department of Veterans Affairs, credits Mary Ann Williams of the Ladies Memorial Association of Columbus, Georgia with originating the idea of an annual date to decorate the graves of Civil War veterans with flowers.\nOfficial recognition as a holiday spread among the states, beginning with New York in 1873. By 1890, every Union state had adopted it. The world wars turned it into a day of remembrance for all members of the U.S. military who fought and died in service. In 1968, Congress changed its observance to the last Monday in May, and in 1971 standardized its name as \"Memorial Day.\u201d Two other days celebrate those who have served or are serving in the U.S. military: Armed Forces Day, which is earlier in May, a ceremonial U.S. day of commemoration for honoring those currently serving in the armed forces, and Veterans Day on November 11, a legal holiday which honors all those who have served in the United States Armed Forces.\nOrigins.\nA variety of cities and people have claimed origination of Memorial Day. In some such cases, the claims relate to documented events, occurring before or after the Civil War. Others may stem from general traditions of decorating soldiers' graves with flowers, rather than specific events leading to the national proclamation. Soldiers' graves were decorated in the U.S. before and during the American Civil War. Other claims may be less respectable, appearing to some researchers as taking credit without evidence, while erasing better-evidenced events or connections.\nPrecedents in the South.\nWarrenton, Virginia.\nOn June 3, 1861, Warrenton, Virginia, was the location of the first Civil War soldier's grave to be decorated, according to an article in the \"Richmond Times-Dispatch\" in 1906. This decoration was for the funeral of the first soldier killed during the Civil War, John Quincy Marr, who died on June 1, 1861, during a skirmish at the Battle of Fairfax Courthouse in Virginia.\nJackson, Mississippi.\nOn April 26, 1865, in Jackson, Mississippi, Sue Landon Vaughan decorated the graves of Confederate and Union soldiers according to her account. The first reference to this event however did not appear until many years later. Mention of the observance is inscribed on the southeast panel of the Confederate Monument in Jackson, erected in 1891. Vaughan's account is contradicted by contemporary sources.\nCharleston, South Carolina.\nOn May 1, 1865, in Charleston, South Carolina, the recently freed Black population held a parade of 10,000 people to honor 257 dead Union soldiers. The soldiers had been buried in a mass grave at the Washington Race Course, having died at the Confederate prison camp located there. After the city fell, the freed Black population unearthed and properly buried the soldiers, placing flowers at their graves. The event was reported contemporaneously in the \"Charleston Daily Courier\" and the \"New-York Tribune.\" Historian David Blight has called this commemoration the first Memorial Day. However, no direct link has been established between this event and General John Logan's 1868 proclamation for a national holiday.\nColumbus, Georgia.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n . . . [W]e can keep alive the memory of debt we owe them by dedicating\nat least one day in the year, by embellishing their humble graves with\nflowers, therefore we beg the assistance of the press and the ladies\nthroughout the South to help us in the effort to set apart a certain day\nto be observed, from the Potomac to the Rio Grande and be handed\ndown through time as a religious custom of the country, to wreathe the\ngraves of our martyred dead with flowers. . . Let the soldiers\u2019 graves,\nfor that day at least, be the Southern Mecca, to whose shrine her\nsorrowing women, like pilgrims, may annually bring their grateful\nhearts and floral offerings. . . \n \u2014Mary Ann Williams \n , March 11, 1866\nThe National Cemetery Administration, a division of the Department of Veterans Affairs, and scholars attribute the beginning of a Memorial Day practice in the South to a group of women of Columbus, Georgia. The women were the Ladies Memorial Association of Columbus. They were represented by Mary Ann Williams (Mrs. Charles J. Williams) who as association secretary wrote an open letter to the press on March 11, 1866 asking for assistance in establishing an annual holiday to decorate the graves of soldiers throughout the South. The letter was reprinted in several southern states and the plans were noted in newspapers in the North. The date of April 26 was chosen, which corresponded with the end date of the war with the surrender agreement between Generals Johnston and Sherman in 1865.\nThe holiday was observed in Atlanta, Augusta, Macon, Columbus and elsewhere in Georgia as well as Montgomery, Alabama; Memphis, Tennessee; Louisville, Kentucky; New Orleans, Louisiana; Jackson, Mississippi, and across the South. In some cities, mostly in Virginia, other dates in May and June were observed. General John Logan commented on the observances in a speech to veterans on July 4, 1866, in Salem, Illinois. After General Logan's General Order No. 11 to the Grand Army of the Republic to observe May 30, 1868, the earlier version of the holiday began to be referred to as Confederate Memorial Day.\nColumbus, Mississippi.\nFollowing Mary William's call for assistance, four women of Columbus, Mississippi a day early on April 25, 1866, gathered together at Friendship Cemetery to decorate the graves of the Confederate soldiers. They also felt moved to honor the Union soldiers buried there, and to note the grief of their families, by decorating their graves as well. The story of their gesture of humanity and reconciliation is held by some writers as the inspiration of the original Memorial Day.\nOther Southern precedents.\nAccording to the United States Library of Congress, \"Southern women decorated the graves of soldiers even before the Civil War\u2019s end. Records show that by 1865, Mississippi, Virginia, and South Carolina all had precedents for Memorial Day.\" The earliest Southern Memorial Day celebrations were simple, somber occasions for veterans and their families to honor the dead and tend to local cemeteries. In following years, the Ladies' Memorial Association and other groups increasingly focused rituals on preserving Confederate culture and the Lost Cause of the Confederacy narrative.\nPrecedents in the North.\nGettysburg, Pennsylvania.\nThe 1863 cemetery dedication at Gettysburg, Pennsylvania, included a ceremony of commemoration at the graves of dead soldiers. Some have therefore claimed that President Abraham Lincoln was the founder of Memorial Day. However, Chicago journalist Lloyd Lewis tried to make the case that it was Lincoln's funeral that spurred the soldiers' grave decorating that followed.\nBoalsburg, Pennsylvania.\nOn July 4, 1864, ladies decorated soldiers' graves according to local historians in Boalsburg, Pennsylvania. Boalsburg promotes itself as the birthplace of Memorial Day. However, no published reference to this event has been found earlier than the printing of the History of the 148th Pennsylvania Volunteers in 1904. In a footnote to a story about her brother, Mrs. Sophie (Keller) Hall described how she and Emma Hunter decorated the grave of Emma's father, Reuben Hunter, and then the graves of all soldiers in the cemetery. The original story did not account for Reuben Hunter's death occurring two months later on September 19, 1864. It also did not mention Mrs. Elizabeth Myers as one of the original participants. A bronze statue of all three women gazing upon Reuben Hunter's grave now stands near the entrance to the Boalsburg Cemetery. Although July 4, 1864, was a Monday, the town now claims that the original decoration was on one of the Sundays in October 1864.\nNational Decoration Day.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n ... Let us then gather around their sacred remains and garland the passionless mounds above them with the choicest flowers of Springtime; let us raise above them the dear old flag they saved from dishonor; let us in this solemn presence renew our pledges to aid and assist those whom they have left among us as a sacred charge upon a Nation's gratitude\u2014the soldiers' and sailors' widow and orphan.\n \u2014John A. Logan \n , May 5, 1868\nOn May 5, 1868, General John A. Logan issued a proclamation calling for \"Decoration Day\" to be observed annually and nationwide; he was commander-in-chief of the Grand Army of the Republic (GAR), an organization of and for Union Civil War veterans founded in Decatur, Illinois. With his proclamation, Logan adopted the Memorial Day practice that had begun in the Southern states two years earlier. The northern states quickly adopted the holiday. In 1868, memorial events were held in 183 cemeteries in 27 states, and 336 in 1869. One author claims that the date was chosen because it was not the anniversary of any particular battle. Logan's wife noted that the date was chosen because it was the optimal date for flowers to be in bloom in the North.\nState holiday.\nIn 1873, New York made Decoration Day an official state holiday and by 1890, every northern state had followed suit. There was no standard program for the ceremonies, but they were typically sponsored by the Women's Relief Corps, the women's auxiliary of the Grand Army of the Republic (GAR), which had 100,000 members. By 1870, the remains of nearly 300,000 Union dead had been reinterred in 73 national cemeteries, located near major battlefields and thus mainly in the South. The most famous are Gettysburg National Cemetery in Pennsylvania and Arlington National Cemetery, near Washington, D.C.\nWaterloo proclamation.\nOn May 26, 1966, President Lyndon B. Johnson designated an \"official\" birthplace of the holiday by signing the presidential proclamation naming Waterloo, New York, as the holder of the title. This action followed House Concurrent Resolution 587, in which the 89th Congress had officially recognized that the patriotic tradition of observing Memorial Day had begun one hundred years prior in Waterloo, New York. The legitimacy of this claim has been called into question by several scholars.\nEarly national history.\nIn April 1865, following Lincoln's assassination, commemorations were extensive. The more than 600,000 soldiers of both sides who fought and died in the Civil War meant that burial and memorialization took on new cultural significance. Under the leadership of women during the war, an increasingly formal practice of decorating graves had taken shape. In 1865, the federal government also began creating the United States National Cemetery System for the Union war dead.\nBy the 1880s, ceremonies were becoming more consistent across geography as the GAR provided handbooks that presented specific procedures, poems, and Bible verses for local post commanders to utilize in planning the local event. Historian Stuart McConnell reports:\non the day itself, the post assembled and marched to the local cemetery to decorate the graves of the fallen, an enterprise meticulously organized months in advance to assure that none were missed. Finally came a simple and subdued graveyard service involving prayers, short patriotic speeches, and music ... and at the end perhaps a rifle salute.\nConfederate Memorial Day.\nIn 1868, some Southern public figures began adding the label \"Confederate\" to their commemorations and claimed that Northerners had appropriated the holiday. The first official celebration of Confederate Memorial Day as a public holiday occurred in 1874, following a proclamation by the Georgia legislature. By 1916, ten states celebrated it, on June 3, the birthday of CSA President Jefferson Davis. Other states chose late April dates, or May 10, commemorating Davis' capture.\nThe Ladies' Memorial Association played a key role in using Memorial Day rituals to preserve Confederate culture. Various dates ranging from April 25 to mid-June were adopted in different Southern states. Across the South, associations were founded, many by women, to establish and care for permanent cemeteries for the Confederate dead, organize commemorative ceremonies, and sponsor appropriate monuments as a permanent way of remembering the Confederate dead. The most important of these was the United Daughters of the Confederacy, which grew throughout the South. Changes in the ceremony's hymns and speeches reflect an evolution of the ritual into a symbol of cultural renewal and conservatism in the South. By 1913, David Blight argues, the theme of American nationalism shared equal time with the Confederate.\nRenaming.\nBy the 20th century, various Union memorial traditions, celebrated on different days, merged, and Memorial Day eventually extended to honor all Americans who fought and died while in the U.S. military service. Indiana from the 1860s to the 1920s saw numerous debates on how to expand the celebration. It was a favorite lobbying activity of the Grand Army of the Republic (GAR). An 1884 GAR handbook explained that Memorial Day was \"the day of all days in the G.A.R. Calendar\" in terms of mobilizing public support for pensions. It advised family members to \"exercise great care\" in keeping the veterans sober.\nMemorial Day speeches became an occasion for veterans, politicians, and ministers to commemorate the Civil War and, at first, to rehash the \"atrocities\" of the enemy. They mixed religion and celebratory nationalism, allowing Americans to make sense of their history in terms of sacrifice for a better nation. People of all religious beliefs joined, including German and Irish soldiers\u00a0\u2013 ethnic minorities who at the time faced discrimination\u00a0\u2013 who had become true Americans in the \"baptism of blood\" on the battlefield.\nIn the national capital in 1913 the four-day \"Blue-Gray Reunion\" featured parades, re-enactments, and speeches from a host of dignitaries, including President Woodrow Wilson, the first Southerner elected to the White House since the War. James Heflin of Alabama gave the main address. Heflin was a noted orator; his choice as Memorial Day speaker was criticized, as he was opposed for his support of segregation; however, his speech was moderate in tone and stressed national unity and good will, winning him praise from newspapers.\nThe name \"Memorial Day\", which was first used in 1882, gradually became more common than \"Decoration Day\" after World War II but was not declared the official name by federal law until 1967. On June 28, 1968, Congress passed the Uniform Monday Holiday Act, which moved four holidays, including Memorial Day, from their traditional dates to a specified Monday in order to create a three-day weekend. The change moved Memorial Day from its traditional May 30 date to the last Monday in May. The law took effect at the federal level in 1971.\nIn 1913, an Indiana veteran complained that younger people born since the war had a \"tendency ... to forget the purpose of Memorial Day and make it a day for games, races, and revelry, instead of a day of memory and tears\". In 1911, the scheduling of the Indianapolis Motor Speedway car race, later named the Indianapolis 500, was vehemently opposed by the increasingly elderly GAR. The state legislature in 1923 rejected holding the race on the holiday. However, the new American Legion and local officials wanted the race to continue, so Governor Warren McCray vetoed the bill and the race went on.\nCivil religious holiday.\nMemorial Day endures as a holiday which most businesses observe because it marks the unofficial beginning of summer. (Labor Day is the unofficial end of summer.) The Veterans of Foreign Wars (VFW) and Sons of Union Veterans of the Civil War (SUVCW) advocated returning to the original date. The VFW stated in 2002:\nChanging the date merely to create three-day weekends has undermined the very meaning of the day. No doubt, this has contributed a lot to the general public's nonchalant observance of Memorial Day.\nIn 2000, Congress passed the National Moment of Remembrance Act, asking people to stop and remember at 3:00 pm. On Memorial Day, the flag of the United States is raised briskly to the top of the staff and then solemnly lowered to the half-staff position, where it remains only until noon. It is then raised to full-staff for the remainder of the day. In commemoration ceremonies the Taps are played on the bugle. The National Memorial Day Concert takes place on the west lawn of the United States Capitol. \nScholars, following the lead of sociologist Robert Bellah, often make the argument that the United States has a secular \"civil religion\"\u2014one with no association with any religious denomination or viewpoint\u2014that has incorporated Memorial Day as a sacred event. With the Civil War, a new theme of death, sacrifice, and rebirth enters the civil religion. Memorial Day gave ritual expression to these themes, integrating the local community into a sense of nationalism. The American civil religion, in contrast to that of France, was never anticlerical or militantly secular; in contrast to Britain, it was not tied to a specific denomination, such as the Church of England. The Americans borrowed from different religious traditions so that the average American saw no conflict between the two, and deep levels of personal motivation were aligned with attaining national goals.\nParades.\nSince 1867, Brooklyn, New York, has held an annual Memorial Day parade which it claims to be the nation's oldest. Grafton, West Virginia, and Ironton, Ohio have also had an ongoing parade since 1868. However, the Memorial Day parade in Rochester, Wisconsin, predates both the Doylestown and the Grafton parades by one year (1867).\nPoppies.\nIn 1915, following the Second Battle of Ypres, Lieutenant Colonel John McCrae, a physician with the Canadian Expeditionary Force, wrote the poem \"In Flanders Fields\". Its opening lines refer to the fields of poppies that grew among the soldiers' graves in Flanders. Inspired by the poem, YWCA worker Moina Michael attended a YWCA Overseas War Secretaries' conference three years later wearing a silk poppy pinned to her coat and distributed over two dozen more to others present. The National American Legion adopted the poppy as its official symbol of remembrance in 1920.\nRelated traditions.\nDecoration Days in Southern Appalachia and Liberia are a tradition which arose by the 19th century. Decoration practices are localized and unique to individual families, cemeteries, and communities, but common elements that unify the various Decoration Day practices are thought to represent syncretism of predominantly Christian cultures in 19th century Southern Appalachia with pre-Christian influences from Scotland, Ireland, and African cultures. Appalachian and Liberian cemetery decoration traditions are thought to have more in common with one another than with United States Memorial Day traditions which are focused on honoring the military dead. Appalachian and Liberian cemetery decoration traditions pre-date the United States Memorial Day holiday.\nAccording to scholars Alan and Karen Jabbour, \"the geographic spread ... from the Smokies to northeastern Texas and Liberia, offer strong evidence that the southern Decoration Day originated well back in the nineteenth century. The presence of the same cultural tradition throughout the Upland South argues for the age of the tradition, which was carried westward (and eastward to Africa) by nineteenth-century migration and has survived in essentially the same form till the present.\"\nWhile these customs may have inspired in part rituals to honor military dead like Memorial Day, numerous differences exist between Decoration Day customs and Memorial Day, including that the date is set differently by each family or church for each cemetery to coordinate the maintenance, social, and spiritual aspects of decoration.\nIn film, literature, and music.\nPoetry.\nPoems commemorating Memorial Day include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "56192", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=56192", "title": "Parnall", "text": "British aircraft manufacturer\nParnall was a British aircraft manufacturer that evolved from a wood-working company before the First World War to a significant designer of military and civil aircraft into the 1940s. It was based in the west of England and was originally known as George Parnall &amp; Co. Ltd.\nHistory.\nIn 1916, the Bristol based Parnall &amp; Sons shopfitters started to manufacture aircraft at the Colliseum Works at Park Row in Bristol. During the First World War, the skilled staff were moved to sites around the city and in neighbouring South Gloucestershire producing planes to their own designs and, under contract, those of other companies.\nIn 1919, the aircraft business was split from the parent company Parnall &amp; Sons as George Parnall and Company. In the 1920s, aircraft manufacture was centralised at a factory in Yate close to an airfield used by the Royal Flying Corps. In the 1930s, gun turrets for bomber aircraft were produced. The site was a strategic target for Luftwaffe bombing and during 1941, over fifty people were killed during the raids.\nIn 1935, Parnall Aircraft Limited was formed when George Parnall and Company amalgamated with the Hendy Aircraft Company and Nash and Thompson Limited. After the Second World War as aircraft component manufacture reduced, domestic appliances were built at the site. To reflect this move away from aviation the company changed its name to Parnall (Yate) Limited in 1946. This was acquired by Radiation Ltd. in 1958 and TI Group in 1967.\nAircraft.\nThe Parnall Scout was a prototype single-seat anti-airship wooden biplane fighter aircraft developed in the 1910s. It was too heavy and slow and never went into production.\nThe Parnall Panther was a carrier-based wooden, single-bay biplane spotter and reconnaissance aircraft designed by Harold Bolas, who had joined Parnall and Sons after leaving the Admiralty's Air Department. It had a 230\u00a0hp Bentley BR2 rotary engine. Following contractual disputes production was transferred to the Bristol Aeroplane Company.\nThe Parnall Puffin was an experimental amphibious fighter-reconnaissance biplane.\nThe Parnall Plover single-seat naval fighter aircraft of the 1920s for use off the Royal Navy's aircraft carriers, was ordered into small-scale production, but after extensive evaluation, the Fairey Flycatcher was preferred for large-scale service.\nThe Parnall Possum was an experimental triplane, with a single, central engine driving wing-mounted propellers via shafts and gears. Two of these aircraft were built in the mid-1920s.\nThe Parnall Pixie was a low-powered single-seat monoplane light aircraft originally designed to compete in the Lympne trials for motor-gliders in 1923, where it was flown successfully by Norman Macmillan. It had two sets of wings, one for cross-country flights and the other for speed; it later appeared as a biplane which could be converted into a monoplane. Parnall Pixie IIIa G-EBJG is still in existence with the Midland Air Museum, Coventry, England. The remains are in deep store and are not generally on view to the public without prior arrangement.\nThe Parnall Perch was a single-engined, side-by-side-seat aircraft designed as a general-purpose trainer. No contract on this specification was awarded and only one Perch was built.\nThe Parnall Peto was a small seaplane with folding wings for use as a submarine-carried reconnaissance aircraft.\nThe Parnall Pike was a two/three-seat biplane reconnaissance aircraft, capable of operating off carrier decks or from water, built in 1927. Only one was constructed.\nThe Parnall Pipit was a single-engine, single-seat naval fighter designed to an Air Ministry specification in 1927. Two prototypes were built but both were destroyed by tail flutter.\nThe Parnall Imp was an unusual single-engine, two-seat biplane built in 1927. It had a straight cantilever lower wing which supported the markedly swept upper wing. Only one was built.\nThe Parnall Elf was a two-seat light touring biplane, three being built at Yate between 1928 and 1932. The Elf was the last aircraft designed by Harold Bolas before he left the company to go to the United States.\nThe Parnall Prawn was an experimental flying boat built in 1930. Its single engine was fitted on a tilting mounting in the nose, so that the propeller could be kept clear of the water on takeoff and landing. Only one was built and it is not known whether it was ever flown.\nThe Parnall Parasol was an experimental parasol winged aircraft design to measure the aerodynamic forces on wings in flight. Two were built and flown in the early 1930s.\nThe Parnall G.4/31 was a 1930s general purpose aircraft which could operate as a day and night bomber as well as the reconnaissance, torpedo and dive-bombing roles. It was a large angular biplane powered by a 690\u00a0hp (515\u00a0kW) Bristol Pegasus IM3 with a Townend ring.\nThe Parnall Heck was designed by Basil B. Henderson as a single-engined, conventional low-wing cabin monoplane, built of spruce with a plywood covering, initially a two-seater in tandem layout. The prototype was originally flown as the \"Hendy Heck\" but by the time of its first public demonstration in July 1935, the companies had merged and the aircraft was renamed as the \"Parnall Heck\".\nThe Parnall 382 (also known as the Heck III), was a single-engined wooden monoplane trainer aircraft with two open cockpits. It first flew in 1939.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56193", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=56193", "title": "United States Flag", "text": ""}
{"id": "56195", "revid": "541375021", "url": "https://en.wikipedia.org/wiki?curid=56195", "title": "War of the Worlds", "text": ""}
{"id": "56196", "revid": "35498457", "url": "https://en.wikipedia.org/wiki?curid=56196", "title": "Obi-Wan Kenobi", "text": "Fictional character in the Star Wars franchise\nObi-Wan Kenobi () is a character in the \"Star Wars\" franchise. In the original film trilogy, he is a Jedi Master who trains Luke Skywalker in the ways of the Force. In the prequel trilogy, he mentors Luke's father, Anakin Skywalker. Obi-Wan is portrayed by Alec Guinness in the original trilogy and by Ewan McGregor in the prequel films. McGregor also plays the character in the television series \"Obi-Wan Kenobi\". Guinness's performance in \"Star Wars\" (1977) earned him the Saturn Award for Best Supporting Actor, as well as a nomination for the Academy Award for Best Supporting Actor.\nCreation and development.\nVarious claims have been made about the origins of the character Obi-Wan Kenobi. In his book about the \"Star Wars\" franchise, Chris Taylor asserted that Obi-Wan was inspired by the J.R.R. Tolkien character Gandalf. Ben Sherlock of \"ScreenRant\", meanwhile, claimed that the Jedi Master was based on General Makabe Rokur\u014dta, a character from Akira Kurosawa's 1958 film \"The Hidden Fortress\".\nLucas created Obi-Wan Kenobi as a mentor for Luke, and originally planned for him to continue training Luke in \"The Empire Strikes Back\" (1980), the first sequel to \"Star Wars\". Although Obi-Wan's death was not in the final version of the \"Star Wars\" script, Lucas decided during filming that Obi-Wan should die. Alec Guinness said he begged Lucas to kill off his character because he hated Obi-Wan's dialogue. Lucas, however, claimed he added Obi-Wan's death because the character served no purpose after his duel with Vader. Lucas later reflected: \"It would be much more powerful, satisfying and interesting if Darth Vader were to kill him and he were to go on to a different form.\"\nWhen outlining \"The Empire Strikes Back\", Lucas decided he wanted Obi-Wan to return as a spirit to continue training Luke. Partly due to Guinness's failing health, Lucas realized that he would also need another mentor character. This new mentor would eventually take the form of Yoda.\nLucas described Obi-Wan's character development in \"The Phantom Menace\": \"In the beginning, Obi-Wan is at odds with Qui-Gon, who rebels against the Jedi rules. But by the end of the film, he has \"become\" Qui-Gon by taking on his rebellious personality and his responsibilities.\"\nPortrayal.\nWhen casting \"Star Wars\", Lucas sought an established star for the role of Obi-Wan. He considered Peter Cushing for the part, but decided the actor's lean features would be better employed as the villainous Grand Moff Tarkin. The film's producer, Gary Kurtz, felt a strong character actor was required to convey the \"stability and gravitas\" of Obi-Wan. Before Guinness was cast, the Japanese actor Toshiro Mifune\u2014who plays Makabe Rokur\u014dta in \"The Hidden Fortress\"\u2014was considered for the role. Mifune's daughter, Mika Kitagawa, said her father \"had a lot of samurai pride\" and turned down the roles of both Obi-Wan and Darth Vader because he thought \"Star Wars\" would employ cheap special effects and would therefore \"cheapen the image of samurai\". Once Guinness was selected and production was underway, Lucas credited the English actor with inspiring the cast and crew to work harder, which contributed significantly to the completion of filming. Harrison Ford, who plays Han Solo in the film, said he admired Guinness's preparation, professionalism and kindness towards the other actors.\nEwan McGregor portrays Obi-Wan in the prequel trilogy and in the 2022 miniseries \"Obi-Wan Kenobi.\" His performance in the first prequel film, \"The Phantom Menace\" (1999), earned him a Saturn Award nomination for Best Actor.\nAppearances.\nCanon.\nOriginal trilogy.\nObi-Wan is introduced in \"Star Wars\" (1977) as a mysterious elderly hermit who lives in the Dune Sea of Tatooine. At this time he lives under the alias Ben Kenobi to hide his identity from agents of the Galactic Empire. When Luke and C-3PO travel the desert in search of the runaway droid R2-D2, Obi-Wan rescues them from Tusken Raiders. At Obi-Wan's home, R2-D2 plays a recording of Princess Leia explaining that R2-D2 contains architectural plans for the Empire's planet-destroying battle station, the Death Star. Leia asks Obi-Wan to deliver R2-D2 and the plans to Alderaan to aid the Rebel Alliance. Obi-Wan reveals to Luke that he is a Jedi, a peacekeeper from the days of the Republic. He explains that Luke's father was also a Jedi, and was killed by Darth Vader. Obi-Wan gives Luke his father's lightsaber and invites him to come to Alderaan and begin Jedi training. At first Luke declines, but changes his mind after finding that his aunt and uncle have been killed by Imperial stormtroopers.\nAs Obi-Wan and Luke approach Mos Eisley, Obi-Wan uses a Jedi mind trick to compel Imperial troops to let them through a checkpoint. Obi-Wan and Luke hire the smugglers Han Solo and Chewbacca to take them to Alderaan aboard Han's ship, the \"Millennium Falcon\". During the journey, Obi-Wan instructs Luke in lightsaber combat. Obi-Wan suddenly feels \"a great disturbance in the Force\"; soon after, he and the others find that the Empire has obliterated Alderaan. The \"Falcon\" gets caught in the Death Star's tractor beam, but the group is able to avoid detection and infiltrate the station. Obi-Wan disables the tractor beam, then encounters Vader. They engage in a lightsaber duel as Luke, Leia, Han and Chewbacca escape. Obi-Wan allows Vader to strike him down, then vanishes into the Force. Later, Obi-Wan contacts Luke through the Force and helps him destroy the Death Star.\nIn \"The Empire Strikes Back\" (1980), Obi-Wan appears several times as a Force spirit. On the ice planet Hoth, he instructs Luke to travel to Dagobah to find the exiled Jedi Master Yoda. Yoda is reluctant to mentor Luke, but Obi-Wan convinces him to continue Luke's training. When Luke intends to leave Dagobah to rescue his friends in Cloud City, Obi-Wan beseeches him to stay, but Luke leaves anyway. \nIn \"Return of the Jedi\" (1983), Obi-Wan appears to Luke after Yoda's death on Dagobah. Obi-Wan confirms that Vader is Luke's father, and reveals that Leia is Luke's twin sister. He urges Luke to confront and defeat Vader. After the Rebels destroy the second Death Star and defeat the Empire, Obi-Wan appears at the celebration on Endor alongside the Force spirits of Yoda and Anakin Skywalker.\nPrequel trilogy.\nA younger Obi-Wan appears in \"\" (1999), which is set thirty-two years before \"Star Wars\". He is the apprentice of the Jedi Master Qui-Gon Jinn, and accompanies him to negotiations with the Trade Federation, which is blockading the planet Naboo. Obi-Wan and Qui-Gon rescue Naboo's fourteen-year-old queen Padm\u00e9 Amidala with help from the Gungan Jar Jar Binks, then travel to Coruscant, the capital of the Republic. When they land on Tatooine for repairs, they encounter the nine-year-old slave Anakin Skywalker. Qui-Gon believes the boy is the \"Chosen One\" of Jedi prophecy, destined to bring balance to the Force. After securing his freedom, Anakin joins the group on their journey. While leaving Tatooine, they are attacked by the Sith Lord Darth Maul. Back on Naboo, they meet Maul again, and engage him in lightsaber combat. Maul mortally wounds Qui-Gon, but Obi-Wan defeats Maul. As Qui-Gon dies, he asks his apprentice to train Anakin as a Jedi, with or without the approval of the Jedi Council. Later, Yoda proclaims Obi-Wan a Jedi Knight and reluctantly allows Anakin to become his Padawan.\nThe second film of the trilogy, \"Attack of the Clones\" (2002), takes place ten years later. Anakin has grown powerful but arrogant, and believes that Obi-Wan is holding him back. After they save Padm\u00e9 from an assassination attempt, Obi-Wan traces the assassins to the planet Kamino. He learns of a massive clone army that is being created for the Republic. The clones are derived from the bounty hunter Jango Fett, and Obi-Wan deduces that he was responsible for the attempt on Padm\u00e9's life. Fett escapes to the planet Geonosis with his clone son Boba, unaware that Obi-Wan is pursuing them. On Geonosis, Obi-Wan discovers that a confederacy of star systems is planning to revolt against the Republic. The confederacy is led by the Sith Lord Count Dooku, the former Jedi Master of Qui-Gon. Obi-Wan is captured and sentenced to death by Dooku, but Yoda and Mace Windu arrive with an army and prevent the execution. Obi-Wan and Anakin confront Dooku, but he overpowers them both. Yoda saves their lives, but Dooku escapes.\n\"Revenge of the Sith\" (2005) is set three years later. Obi-Wan is now a Jedi Master, a member of the Jedi Council, and a general. Obi-Wan and Anakin embark on a rescue mission to save the kidnapped Chancellor Palpatine from the cyborg Separatist commander General Grievous. Dooku duels the Jedi once again, knocking Obi-Wan unconscious. Anakin then defeats Dooku and executes him on Palpatine's orders. After locating Grievous on the planet Utapau, Obi-Wan kills him. The Sith Lord Darth Sidious\u2014 who is revealed to be Palpatine\u2014issues Order 66, which compels the clone troopers to betray and kill the Jedi. Obi-Wan and Yoda find that all the Jedi in the Jedi Temple have been slaughtered, including the children. After Obi-Wan warns all surviving Jedi to go into exile, he discovers it was Anakin, now Sidious' apprentice Darth Vader, who led the massacre.\nObi-Wan visits Padm\u00e9 to ascertain Anakin's whereabouts, and realizes that Anakin is her husband and the father of her unborn child. When Padm\u00e9 travels to the volcanic planet Mustafar to confront her husband herself, Obi-Wan stows away aboard her ship. Once on Mustafar, Obi-Wan confronts Vader, who accuses him and Padm\u00e9 of conspiring against him. After Vader uses the Force to strangle Padm\u00e9 into unconsciousness, Obi-Wan engages him in a ferocious lightsaber duel, which ends with Obi-Wan severing several of his limbs. Obi-Wan leaves Vader burning to death, unaware that he will be rescued by Sidious moments later and eventually turned into a cyborg. Obi-Wan takes Padm\u00e9 to the asteroid Polis Massa, where she dies after giving birth to the twins Luke and Leia. He assists in hiding the children from the newly created Empire: Leia is adopted by Senator Bail Organa of Alderaan, while Obi-Wan delivers Luke to Anakin's stepbrother Owen Lars and his wife Beru on Tatooine. Obi-Wan then goes into exile on Tatooine, where he can watch over Luke.\nSequel trilogy.\nIn \"The Force Awakens\" (2015), Rey hears Obi-Wan's voice during a Force vision. During her battle against the resurrected Darth Sidious in \"The Rise of Skywalker\" (2019), she hears the voices of various deceased Jedi, including Obi-Wan. He says, \"These are your final steps, Rey. Rise and take them.\" The voices of both McGregor and Guinness were used in both films.\nTelevision.\n\"The Clone Wars\".\nObi-Wan appears in the animated series \"\" (2008\u20132014, 2020). He is a general during the Clone Wars, and he and Anakin have many adventures fighting the Separatists. During this time Obi-Wan's diplomatic skills earn him the appellation \"The Negotiator\" due to his reputation for preventing and stopping battles without the use of weapons. The series highlights his numerous confrontations with General Grievous, his adversarial relationship with the Dark Jedi Asajj Ventress, his romance with Duchess Satine Kryze, and the return of his old enemy Darth Maul.\n\"Star Wars Rebels\".\nThe animated series \"Star Wars Rebels\" (2014\u20132018) takes place five years before \"Star Wars\". In the season 3 episode \"Visions and Voices\", Ezra Bridger (voiced by Taylor Gray) discovers that Obi-Wan is alive on Tatooine; Obi-Wan's old nemesis Darth Maul finds him as well. In the episode \"Twin Suns\", Obi-Wan finds Ezra while he is lost in the desert while letting him know Maul was intending to use him. At that moment, Maul attacks them, and Obi-Wan ushers Ezra to retreat. Obi-Wan mortally wounds Maul during a final lightsaber duel; with his dying breath, Maul asks Obi-Wan if he is protecting the \"Chosen One\", and Obi-Wan replies that he is. After Maul's death, Obi-Wan is seen watching over Luke Skywalker from a distance.\nIn \"Rebels\", Obi-Wan was voiced by Stephen Stanton, who replaced James Arnold Taylor. \"Rebels\" creator Dave Filoni, who worked with the character during the full duration of \"Star Wars: The Clone Wars\", said he considered asking McGregor to reprise and voice the role. However, a voice recording of the late Alec Guinness as Obi-Wan Kenobi was used in a 2018 episode.\n\"Obi-Wan Kenobi\".\nThe 2022 live-action series \"Obi-Wan Kenobi\" takes place ten years after the events of \"Revenge of the Sith.\" It was originally conceived as a standalone film, but was cancelled during pre-production following the box office disappointment of the 2018 film \"\". At the beginning of the series, Obi-Wan is living in hiding on Tatooine and watching over the ten-year-old Luke. He has lost his connection to the Force, cannot communicate with the spirit of Qui-Gon, and experiences nightmares from his past. Unbeknownst to Obi-Wan, Anakin survived their duel on Mustafar and is now hunting Jedi as Darth Vader. Reva Sevander, one of the Empire's Inquisitors, is obsessed with finding Obi-Wan, who is widely believed to be dead. In an attempt to lure him, she kidnaps Luke's twin sister, Princess Leia. Obi-Wan agrees to rescue Leia after her adoptive father, Bail Organa, visits his home.\nAfter tracking Leia's kidnappers to the planet Daiyu, Obi-Wan encounters the con artist Haja Estree, who directs Obi-Wan to Leia's location. Obi-Wan liberates the young princess, but is unable to flee the planet before the Inquisitors detect his presence. Reva locates him and Leia, and reveals that Anakin is still alive as Vader. When Reva's superior, the Grand Inquisitor, arrives to arrest Obi-Wan, Reva stabs him with her lightsaber. Obi-Wan and Leia then escape to the mining planet Mapuzo, where they are discovered by Imperial troops. They elude their enemies with help from Tala, an Imperial officer who is secretly a member of the Path, an organization that aids those hunted by the Empire. As she escorts them to a hidden passageway, Vader arrives and begins harming innocent bystanders, hoping to bait Obi-Wan into revealing himself. Obi-Wan duels with Vader, who overpowers him. Tala saves Obi-Wan, but Leia is captured again by Reva.\nObi-Wan and Tala rescue Leia from the Inquisitors' stronghold, escaping with the help of Tala's Path allies. Reva leads a siege on the Path facility, and Obi-Wan speaks with her to stall for time. He deduces that she was a Jedi youngling who survived Vader's massacre at the Jedi Temple, and now wants to kill him for revenge. He suggests that she can attack him when he arrives. As the Path members evacuate, Reva tries to assault Vader but is quickly overpowered and left for dead. She manages to survive, however, and finds a message on Obi-Wan's transmitter that reveals Luke's location on Tatooine. Vader pursues the ship carrying the Path members and Obi-Wan, who decides to lure Vader away and confront him on a nearby planet. As they duel, Obi-Wan regains his connection to the Force and realizes Anakin has completely embraced his identity as Vader. Obi-Wan wounds his former apprentice and leaves him incapacitated. On Tatooine, Reva pursues Luke into the desert. Remembering the massacre at the Temple, she is unable to kill the boy, and returns him to his family. Obi-Wan arrives and congratulates her for overcoming her trauma and liberating herself. In the final moments of the series, Obi-Wan finally manages to converse with Qui-Gon.\nNovels and comics.\nObi-Wan appears briefly in the 2015 novel \"\", which is based on unfinished episodes from \"The Clone Wars\". It provides details about the friendship between Obi-Wan and the rogue Jedi Quinlan Vos. In the 2015 \"Star Wars\" comic series, Luke goes to Obi-Wan's abandoned house on Tatooine and finds his diary, in which Obi-Wan has written stories from his past. The 2016 Marvel Comics mini-series \"Obi-Wan and Anakin\" focuses on the two Jedi between \"The Phantom Menace\" and \"Attack of the Clones\". \nObi-Wan appears in the 2019 novel \"Master and Apprentice\", which explores his relationship with Qui-Gon prior to the events of \"The Phantom Menace\". He is also featured in two 2022 novels: \"Brotherhood\", which is set at the beginning of the Clone Wars, and \"Star Wars Padawan\", which recounts his early years as an apprentice.\n\"Legends\".\nFollowing the acquisition of Lucasfilm by The Walt Disney Company in 2012, most of the licensed \"Star Wars\" Expanded Universe material produced between 1977 and 2014 was rebranded as \"Star Wars Legends\" and declared non-canon to the franchise. The \"Legends\" works comprise a separate narrative universe.\nNovels.\nObi-Wan's life prior to \"The Phantom Menace\" is portrayed mostly in Jude Watson's \"Jedi Apprentice\" series, which follows his adventures as Qui-Gon's apprentice. Notable events in the series include his battle with the Dark Jedi Xanatos and his first independent mission. Watson's \"Jedi Quest\" series details his adventures with Anakin in the years leading up to \"Attack of the Clones\". His heroism just before and during the Clone Wars is portrayed in novels such as \"Outbound Flight\", \"The Approaching Storm\", and \"The Cestus Deception\". Obi-Wan's life between \"Revenge of the Sith\" and \"Star Wars\" is depicted in \"The Last of the Jedi\" series. Set roughly a year after the fall of the Republic, the series follows Obi-Wan as he seeks out possible survivors of the Great Jedi Purge, including Anakin's former rival, Ferus Olin. The novels also depict Obi-Wan adjusting to life as a hermit on Tatooine while watching over Luke. He discovers that Vader is still alive after seeing him on the Holonet, the galaxy's official news source.\nObi-Wan appears in the final chapter of \"\", which takes place just after \"Revenge of the Sith\". He learns with alarm that Vader survived their duel on Mustafar, but Qui-Gon assures him that Vader will not set foot on Tatooine for fear of reawakening Anakin Skywalker. Qui-Gon advises him not to reveal to Luke his true parentage until the time is right. In various novels set after \"Return of the Jedi\", Obi-Wan appears as a Force spirit. In \"The Truce at Bakura\", he warns Luke about the Ssi-ruuk; in \"The Lost City of the Jedi\", he guides him to the eponymous city on Yavin 4; in \"Heir to the Empire\", he bids farewell to Luke, explaining that he must abandon his spiritual form and ascend to a higher plane of consciousness. Before parting, Luke says that Obi-Wan was like a father to him, and Obi-Wan replies that he loved Luke like a son. The novel \"Kenobi\" (2013) tells the story of Obi-Wan's first days of exile on Tatooine.\nComics.\nIssue #24 of Marvel's 1977 \"Star Wars\" comic follows Obi-Wan during the Republic era. He is featured in various Dark Horse Comics publications, including several set during the Clone Wars. In ' (1998\u20132006), Obi-Wan fights the Separatists, is tortured by Asajj Ventress before being rescued by Anakin, and apprehends the corrupt Jedi Master Quinlan Vos. Throughout the series, he grows increasingly wary of Palpatine's designs on the Republic and his influence on Anakin. In the ' story \"Old Wounds\" (2005), Obi-Wan confronts Darth Maul on Tatooine during Luke's childhood. Owen Lars shoots and kills Maul, then warns Obi-Wan to stay away from Luke. Through the Force, Obi-Wan reassures Luke that he will be there for him when needed.\n\"Clone Wars\".\nObi-Wan appears in the animated micro-series \"\", which aired on Cartoon Network from 2003 to 2005.\nCultural impact.\nGuinness was nominated for the Academy Award for Best Supporting Actor for his portrayal of Obi-Wan in \"Star Wars\". In 2003, the American Film Institute selected Obi-Wan Kenobi as the 37th-greatest movie hero of all time. He was listed as the third-greatest \"Star Wars\" character by \"IGN\", and was chosen as one of UGO Networks' favorite heroes of all time.\nIn 2004, the Council of the Commune Lubicz in Poland passed a resolution giving the name \"Obi-Wan Kenobi\" to one of the streets in Grabowiec, a small village near Toru\u0144. The street was named in 2005. The name of the street, \"Obi-Wana Kenobiego\", translates from Polish as \"the street of Obi-Wan Kenobi\".\nHis line from the 1977 movie, \"These Aren't The Droids You're Looking For\", has been called catchy, familiar, used in everyday conversations, famous and iconic.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56197", "revid": "44217690", "url": "https://en.wikipedia.org/wiki?curid=56197", "title": "Warp Drive", "text": "Short street in Sterling, Virginia\nWarp Drive is a short street in Sterling, Virginia, United States. Originally named Steeplechase Drive, it is located in an industrial park off Atlantic Boulevard, and primarily serves as the address for Northrop Grumman Innovation Systems, an aerospace company. The street ends at a circle where an off-ramp from Virginia State Highway 28 joins from the opposite direction.\nIn 2011, employees of Orbital Sciences\u2014later acquired by Northrop\u2014asked the Loudoun County Board of Supervisors to rename their street after the warp drive that allows ships in the \"Star Trek\" universe to travel faster than light. The supervisors voted unanimously to make it so (several of them using catchphrases associated with the franchise).\nStreet.\nWarp Drive's eastern terminus is a signalized three-way intersection with Atlantic Boulevard, roughly one half-mile (800\u00a0m) north of its southern terminus at Church Road (Virginia State Route 625) at Sterling. The area is developed in a pattern typical of eastern Loudoun County's edge-city suburban sprawl. On either side of Atlantic at the intersection are office buildings surrounded by parking lots, all facilities of Northrop Grumman Innovation Systems, with some newer residential subdivisions to the southeast and, across the Cabin Branch of Broad Run, the east. The Washington &amp; Old Dominion Trail runs to the immediate southwest.\nTo the northeast is another office building with an artificial pond. The northwest corner of the intersection, and the entire north side of Warp Drive, is a large undeveloped parcel. From the intersection, the street runs 300\u00a0ft (100\u00a0m) west, divided by a grass median strip, to a small traffic circle that gives access to driveways into Orbital's facilities on the north and south. On the west side is the end of a one-way offramp that gives access to Warp from Sully Road (Virginia State Route 28), roughly to the west.\nHistory.\nOrbital Sciences Corporation was founded in 1982 to provide rocket engines and parts to aerospace and defense customers public and private. It has always been headquartered in Northern Virginia, like many other defense contractors. In 1993 it moved into its current complex in Sterling.\nAt that time the short street where Orbital was located was known as Steeplechase Drive. In 2011 the company's executives, who were fans of \"Star Trek\", asked the Loudoun County Board of Supervisors to formally rename the street Warp Drive, after the faster-than-light \"warp drive\" propulsion technology used by the franchise's starships. At the last meeting of the year, the board voted unanimously to grant the request.\nOfficially, the county said the change was made to \"improve the identity and to better integrate the Orbital campus.\" But supervisors were less formal when discussing the issue, which had originally been on a consent agenda. Several cast their votes with catchphrases from . \"To Orbital, live long and prosper,\" said Stevens Miller, who lived in Sterling. Board member Eugene Delgaudio asked, \"Can you give me any speed, Scotty?\", incorrectly using a Scottish accent as he did so.\nOne supervisor, Jim Burton of the Blue Ridge District, tried to be serious. He reminded the board that \"warp\" had other meanings. \"You need to think about it before you vote on it\" he warned. \"Would you prefer 'Beam me up, Scotty?'\", the board's chairman replied. In the end the vote was unanimous. \"What more uplifting motion could there possibly be than something that will literally make law out of a Star Trek joke?\" concluded Miller. \"It's a great idea. I look forward to driving on Warp Drive myself.\" Orbital agreed to reimburse the county for the approximately $500 it would cost to replace the street sign.\nThe online \"Ashburn Patch\" noted how the name change reflected the changes to Loudoun County in the past two decades. While the western portion of the county has stayed largely rural and agricultural, as evoked by the street's original name of Steeplechase Drive, eastern Loudoun has grown tremendously during that same time as many businesses, in particular high-tech defense contractors like Orbital, have located in the area. \"So Orbital's request to change the name of the road along its perimeter from Steeplechase Drive to Warp Drive brings to mind the county's dichotomy,\" it observed. \"Out with the horse-racing theme and in with space.\"\nOn September 18, 2017, Northrop Grumman announced plans to purchase Orbital for $7.8 billion in cash plus assumption of $1.4 billion in debt. Orbital shareholders approved the buyout on November 29, 2017. The FTC approved the acquisition with conditions on June 5, 2018, and one day later, Orbital was absorbed and became Northrop Grumman Innovation Systems.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56199", "revid": "47380772", "url": "https://en.wikipedia.org/wiki?curid=56199", "title": "Pollux", "text": "Pollux may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "56203", "revid": "3206409", "url": "https://en.wikipedia.org/wiki?curid=56203", "title": "Castor", "text": "Castor most commonly refers to:\nCastor or CASTOR may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "56204", "revid": "486141", "url": "https://en.wikipedia.org/wiki?curid=56204", "title": "Cat bus", "text": ""}
{"id": "56205", "revid": "118008", "url": "https://en.wikipedia.org/wiki?curid=56205", "title": "Akhushtal", "text": ""}
{"id": "56206", "revid": "47568590", "url": "https://en.wikipedia.org/wiki?curid=56206", "title": "Crop circle", "text": "Pattern in a crop field\nA crop circle, crop formation, or corn circle is a pattern created by flattening a crop, usually a cereal. The term was first coined in the early 1980s. Crop circles have been described as all falling \"within the range of the sort of thing done in hoaxes\" by Taner Edis, professor of physics at Truman State University. \nAlthough obscure natural causes or alien origins of crop circles are suggested by fringe theorists, there is no scientific evidence for such explanations, and all crop circles are consistent with human causation. In 1991, two hoaxers, Doug Bower and Dave Chorley, took credit for having created over 200 crop circles throughout England in widely-reported interviews. The number of reports of crop circles increased substantially after interviews with them. In the United Kingdom, reported circles are not distributed randomly across the landscape, but appear near roads, areas of medium to dense population, and cultural heritage monuments, such as Stonehenge or Avebury. They usually appear overnight. Nearly half of all crop circles found in the UK in 2003 were located within a radius of the Avebury stone circles.\nIn contrast to crop circles or crop formations, archaeological remains can cause cropmarks in the fields in the shapes of circles and squares, but these do not appear overnight, and are always in the same places every year. \nHistory.\nBefore the 20th century.\nA 1678 news pamphlet \"The Mowing-Devil: or, Strange News Out of Hartfordshire\" describes a crop whose stalks were cut rather than bent. (see folklore section).\nIn 1686, an English naturalist, Robert Plot, reported on rings or arcs of mushrooms (see fairy rings) in \"The Natural History of Stafford-Shire\", proposing air flows from the sky as a cause. In 1991, meteorologist Terence Meaden linked this report with modern crop circles, a claim that has been compared with those made by Erich von D\u00e4niken.\nAn 1880 letter to the editor of \"Nature\" by amateur scientist John Rand Capron describes how several circles of flattened crops in a field were formed under suspicious circumstances and possibly caused by \"cyclonic wind action\", stating \"as viewed from a distance, circular spots ... they all presented much the same character, viz, a few standing stalks as a centre, some prostrate stalks with their heads arranged pretty evenly in a direction forming a circle round the centre, and outside there a circular wall of stalks which had not suffered\".\n20th century.\nIn 1932, archaeologist E. C. Curwen observed four dark rings in a field at Stoughton Down near Chichester, but could examine only one: \"a circle in which the barley was 'lodged' or beaten down, while the interior area was very slightly mounded up.\"\nIn \"Fortean Times,\" David Wood reported that in 1940 he made crop circles near Gloucestershire using ropes. \nIn 1963, Patrick Moore described a crater in a potato field in Wiltshire that he considered was probably caused by an unknown meteoric body. In nearby wheat fields, there were several circular and elliptical areas where the wheat had been flattened. There was evidence of \"spiral flattening\". He thought they could be caused by air currents from the impact, since they led towards the crater. Astronomer Hugh Ernest Butler observed similar craters and said they were likely caused by lightning strikes.\nDuring the 1960s, there were many reports of UFO sightings and circular formations in swamp reeds and sugarcane fields in Tully, Queensland, Australia, and in Canada. For example, on 8 August 1967, three circles were found in a field in Duhamel, Alberta, Canada; Department of National Defence investigators concluded that it was artificial but couldn't say who made them or how. The most famous case is the 1966 Tully \"saucer nest\", when a farmer said he witnessed a saucer-shaped craft rise from a swamp and then fly away. On investigating he found a nearly circular area long by wide where the grass was flattened in clockwise curves to water level within the circle, and the reeds had been uprooted from the mud. The local police officer, the Royal Australian Air Force, and the University of Queensland concluded that it was most probably caused by natural causes, like a down draught, a willy-willy (dust devil), or a waterspout. In 1973, G.J. Odgers, Director of Public Relations, Department of Defence (Air Office), wrote to a journalist that the \"saucer\" was probably debris lifted by a willy-willy.\nAfter the 1960s, there was a surge of UFOlogists in Wiltshire, and there were rumours of \"saucer nests\" appearing in the area, but they were never photographed. There are other pre-1970s reports of circular formations, especially in Australia and Canada, but they were always simple circles, which could have been caused by whirlwinds. \nBritish pranksters Doug Bower and Dave Chorley reported they started creating crop circles in British cornfields in 1978, inspired by the Tully \"saucer nest\" case.\nThe first film to depict a geometric crop circle, in this case created by super-intelligent ants, was the 1974 science-fiction film \"Phase IV\". The film has been cited as a possible inspiration or influence on the pranksters who started this phenomenon.\nThe majority of reports of crop circles have appeared and spread since the late 1970s as many circles began appearing throughout the English countryside. Around this time, researcher Colin Andrews began documenting the phenomenon, and in 1989 he co-authored \"Circular Evidence\" with Pat Delgado, a work that compiled reports and photographs of early formations. This phenomenon became widely known in the late 1980s, after the media started to report crop circles in Hampshire and Wiltshire. After Bower and Chorley gave interviews in 1991 about how they had made crop circles, circles started appearing all over the world. By 2001, approximately 10,000 crop circles have been reported internationally, from locations such as the former Soviet Union, the United Kingdom, Japan, the U.S., and Canada. Researchers have noted a correlation between crop circles, recent media coverage, and the absence of fencing and/or anti-trespassing legislation.\nAlthough farmers expressed concern at the damage caused to their crops, local response to the appearance of crop circles was often enthusiastic, with locals taking advantage of the increase of tourism and visits from scientists, crop circle researchers, and individuals seeking spiritual experiences. The market for crop circle interest consequently generated bus or helicopter tours of circle sites, walking tours, T-shirts, and book sales.\n21st century.\nSince the start of the 21st century, crop formations have increased in size and complexity, with some featuring as many as 2,000 different shapes and some incorporating complex mathematical and scientific characteristics.\nThe researcher Jeremy Northcote found that crop circles in the UK in 2002 were not spread randomly across the landscape. They tended to appear near roads, areas of medium-to-dense population, and cultural heritage monuments such as Stonehenge or Avebury. He found that they always appeared in areas that were easy to access. This suggests strongly that these crop circles were more likely to be caused by intentional human action than by paranormal activity. Another strong indication of that theory was that inhabitants of the zone with the most circles had a historical tendency for making large-scale formations, including stone circles such as Stonehenge, earthen mounds such as Silbury Hill, long barrows such as West Kennet Long Barrow, and .\nBower and Chorley.\nIn 1991, two self-professed pranksters, Doug Bower and Dave Chorley, made headlines by saying they had started the crop circle phenomenon in 1978, using simple tools consisting of a plank of wood, rope, and a baseball cap fitted with a loop of wire to help them walk in straight lines. To prove their case they made a circle in front of journalists; a \"cereologist\" (advocate of paranormal explanations of crop circles), Pat Delgado, examined the circle and declared it authentic before it was revealed that it was a hoax. \nInspired by Australian crop circle accounts from 1966, Bower and Chorley claimed to be responsible for all circles made prior to 1987, and for more than 200 crop circles in 1978\u20131991 (with 1,000 other circles not being made by them). Writing in \"Physics World\", Richard Taylor of the University of Oregon said that \"the pictographs they created inspired a second wave of crop artists. Far from fizzling out, crop circles have evolved into an international phenomenon, with hundreds of sophisticated pictographs now appearing annually around the globe.\"\nArt and business.\nAfter reports of simple circles in the 1970s, increasingly complex geometric designs have been created by anonymous artists, in some cases to attract tourists to an area.\nSince the early 1990s, the UK arts collective Circlemakers, founded by Rod Dickinson and John Lundberg, and subsequently including Wil Russell and Rob Irving, has been creating crop circles in the UK and around the world as part of its art practice and also for commercial clients.\nThe Led Zeppelin Boxed Set that was released on 7 September 1990, along with the remasters of the first boxed set, as well as the second boxed set, all feature an image of a crop circle that appeared in East Field in Alton Barnes, Wiltshire.\nOn the night of 11\u201312 July 1992, a crop-circle-making competition with a prize of \u00a33,000 (funded in part by the Arthur Koestler Foundation) was held in Berkshire. The winning entry was produced by three Westland Helicopters engineers, using rope, PVC pipe, a plank, string, a telescopic device and two stepladders. According to Rupert Sheldrake, the competition was organised by him and John Michell and \"co-sponsored by The Guardian and The Cerealogist\". The prize money came from \"PM\", a German magazine. Sheldrake wrote that \"The experiment was conclusive. Humans could indeed make all the features of state-of-the-art crop formations at that time. Eleven of the twelve teams made more or less impressive formations that followed the set design.\"\nIn 2002, Discovery Channel commissioned five aeronautics and astronautics graduate students from MIT to create crop circles of their own, aiming to duplicate some of the features claimed to distinguish \"real\" crop circles from the known fakes such as those created by Bower and Chorley. The creation of the circle was recorded and used in the Discovery Channel documentary \"Crop Circles: Mysteries in the Fields\".\nIn 2009, \"The Guardian\" reported that crop circle activity had been waning around Wiltshire, in part because makers preferred creating promotional crop circles for companies that paid well for their efforts.\nA video sequence used in connection with the opening of the 2012 Summer Olympics in London showed two crop circles in the shape of the Olympic rings. Another Olympic crop circle was visible to passengers landing at nearby Heathrow Airport before and during the Games.\nA crop circle depicting the emblem of the \"Star Wars\" Rebel Alliance was created in California in December 2017 by a father and his 11-year-old son as a spaceport for X-wing fighters.\nLegal implications.\nIn 1992, G\u00e1bor Tak\u00e1cs and R\u00f3bert Dallos, both then aged 17, were the first people to face legal action after creating a crop circle. Tak\u00e1cs and Dallos, of the St. Stephen Agricultural Technicum, a high school in Hungary specializing in agriculture, created a diameter crop circle in a wheat field near Sz\u00e9kesfeh\u00e9rv\u00e1r, southwest of Budapest, on 8 June 1992. In September, the pair appeared on Hungarian TV and exposed the circle as a hoax, showing photos of the field before and after the circle was made. As a result, Aranykal\u00e1sz Co., the owners of the land, sued the teens for 630,000\u00a0Ft (~$3,000\u00a0USD) in damages. The presiding judge ruled that the students were only responsible for the damage caused in the circle itself, amounting to about 6,000\u00a0Ft (~$30\u00a0USD), and that 99% of the damage to the crops was caused by the thousands of visitors who flocked to Sz\u00e9kesfeh\u00e9rv\u00e1r following the media's promotion of the circle. The fine was eventually paid by the TV show, as were the students' legal fees.\nIn 2000, Matthew Williams became the first man in the UK to be arrested for causing criminal damage after making a crop circle near Devizes. In November 2000, he was fined \u00a3100 plus \u00a340 in costs. As of 2008[ [update]], no one else has been successfully prosecuted in the UK for criminal damage caused by creating crop circles.\nCreation.\nHuman origin.\nThe scientific consensus on crop circles is that they are constructed by human beings as hoaxes, advertising, or art. The most widely known method for a person or group to construct a crop formation is to tie one end of a rope to an anchor point and the other end to a board which is used to crush the plants. It is also possible to bend grass without breaking it, if it has recently rained\u2014a method that was used to create crop circles in Hungary in 1992. Skeptics of the paranormal point out that all characteristics of crop circles are fully compatible with their being made by hoaxers.\nBower and Chorley confessed in 1991 to making the first crop circles in southern England. When some people refused to believe them, they deliberately added straight lines and squares to show that they could not have natural causes. In a copycat effect, increasingly complex circles started appearing in many countries around the world, including fractal figures. Physicists have suggested that the most complex formations might be made with the help of GPS and lasers. In 2009, a circle formation was made over the course of three consecutive nights and was apparently left unfinished, with some half-made circles.\nThe main criticism of alleged non-human creation of crop circles is that while evidence of these origins, besides eyewitness testimonies, is absent, many are definitely known to be the work of human pranksters, and others can be adequately explained as such. There have been cases in which researchers declared crop circles to be \"the real thing\", only to be confronted with the people who created the circle and documented the fraud, such as Bower and Chorley and tabloid \"Today\" hoaxing Pat Delgado, the Wessex Sceptics and Channel 4's \"Equinox\" hoaxing Terence Meaden, or a friend of a Canadian farmer hoaxing a field researcher of the Canadian Crop Circle Research Network. In his 1995 book \"The Demon-Haunted World: Science as a Candle in the Dark\", Carl Sagan concludes that crop circles were created by Bower and Chorley and their copycats, and speculates that UFOlogists willingly ignore the evidence for hoaxing so they can keep believing in an extraterrestrial origin of the circles. Many others have demonstrated how complex crop circles can be created. \"Scientific American\" published an article by Matt Ridley, who started making crop circles in northern England in 1991. He wrote about how easy it is to develop techniques using simple tools that can easily fool later observers. He reported on \"expert\" sources such as \"The Wall Street Journal\" who had been easily fooled, and mused about why people want to believe supernatural explanations for phenomena that are not yet explained. Methods of creating a crop circle are now well documented on the Internet.\nSome crop formations are paid for by companies who use them as advertising. Many crop circles show human symbols, like the heart and arrow symbol of love, and stereotyped alien faces.\nHoaxers have been caught in the process of making new circles, such as in 2004 in the Netherlands.\nNatural origins.\nWeather.\nIt has been suggested that crop circles may be the result of extraordinary meteorological phenomena ranging from freak tornadoes to ball lightning, but there is no evidence of any crop circle being created by any of these causes.\nIn 1880, an amateur scientist, John Rand Capron, wrote a letter to the editor of journal \"Nature\" about some circles in crops and blamed them on a recent storm, saying their shape was \"suggestive of some cyclonic wind action\".\nIn 1980, Terence Meaden, a meteorologist and physicist, proposed that the circles were caused by whirlwinds whose course was affected by southern England hills. As circles became more complex, Terence had to create increasingly complex theories, blaming an electromagneto-hydrodynamic \"plasma vortex\". The meteorological theory became popular, and it was even referenced in 1991 by physicist Stephen Hawking who said that, \"Corn circles are either hoaxes or formed by vortex movement of air\". The weather theory suffered a serious blow in 1991, but Hawking's point about hoaxes was supported when Bower and Chorley stated that they had been responsible for making all those circles. By the end of 1991 Meaden conceded that those circles that had complex designs were made by hoaxers.\nAnimal activity.\nIn 2009, the attorney general for the island state of Tasmania stated that Australian wallabies had been found creating crop circles in fields of opium poppies, which are grown legally for medicinal use, after consuming some of the opiate-laden poppies and running in circles.\nAlternative explanations.\nIn science magazines from the 1980s and 1990s, for example \"Science Illustrated\", one could read reports suggesting that the plants were bent by something that could be microwave radiation, rather than broken by physical impact. The magazines also contained serious reports of the absence of human influence and measurement of unusual radiation. Today, this is considered to be pseudoscience, while at the time it was subject of serious research. At that time, it was also more likely that an unknown factor was behind the incidents, not least seen in light of the fact that GPS was not available to the public.\nParanormal.\nSince becoming the focus of widespread media attention in the 1980s, crop circles have been the subject of speculation by various paranormal, ufological, and anomalistic investigators, ranging from proposals that they were created by bizarre meteorological phenomena to messages from extraterrestrial beings. There has also been speculation that crop circles have a relation to ley lines.\nSome paranormal advocates think that crop circles are caused by ball lightning and that the patterns are so complex that they have to be controlled by some entity. Some proposed entities are: Gaia asking to stop global warming and human pollution; God; supernatural beings (for example Indian devas); the collective minds of humanity through a proposed \"quantum field\"; and extraterrestrial beings.\nResponding to local beliefs that \"extraterrestrial beings\" in UFOs were responsible for crop circles appearing, the Indonesian National Institute of Aeronautics and Space (LAPAN) described crop circles as \"man-made\". Thomas Djamaluddin, research professor of astronomy and astrophysics at LAPAN stated, \"We have come to agree that this 'thing' cannot be scientifically proven.\" Among others, paranormal enthusiasts, ufologists, and anomalistic investigators have offered hypothetical explanations that have been criticised as pseudoscientific by sceptical groups and scientists, including the Committee for Skeptical Inquiry. No credible evidence of extraterrestrial origin has been presented.\nChanges to crops.\nA small number of scientists (physicist Eltjo Haselhoff, the late biophysicist William Levengood) have claimed to observe differences between the crops inside the circles and outside them, citing this as evidence they were not man made. Levengood published papers in journal \"Physiologia Plantarum\" in 1994 and 1999. In his 1994 paper he found that certain deformities in the grain inside the circles were correlated to the position of the grain inside the circle. \nIn 1996, Joe Nickell objected that correlation is not causation, raising several objections to Levengood's methods and assumptions, and said, \"Until his work is independently replicated by qualified scientists doing 'double-blind' studies and otherwise following stringent scientific protocols, there seems no need to take seriously the many dubious claims that Levengood makes, including his similar ones involving plants at alleged 'cattle mutilation' sites.\" Nickell also criticised Levengood for using circular logic, stating: \"There is, in fact, no satisfactory evidence that a single \u201cgenuine\u201d (i.e., vortex-produced) crop-circle exists, so Levengood\u2019s reasoning is circular: Although there are no guaranteed genuine formations on which to conduct research, the research supposedly proves the genuineness of the formations.\"\nAdvocates of non-human causes discount on-site evidence of human involvement as attempts to discredit the phenomena. When Ridley wrote negative articles in newspapers, he was accused of spreading \"government disinformation\" and of working for the UK military intelligence service MI5. Ridley responded by noting that many \"cereologists\" make good livings from selling books and providing high-priced personal tours through crop fields, and he claimed that they have vested interests in rejecting what is by far the most likely explanation for the circles.\nRelated art.\nPatterns similar to crop circles can also be made in snow, by using skis, snow shoes or just walking with ordinary shoes.\nImages can be made in forests by cutting trees, especially in areas with snow. Celebrating the Olympic Games in Lillehammer, Norway in 1994, a tall stylised image of an Olympic torch runner was made in a forest close to one of the arenas.\nFolklore.\nResearchers of crop circles have linked modern crop circles to old folkloric tales to support the claim that they are not artificially produced. Crop circles are culture dependent: they appear mostly in developed and secularised Western countries where people are receptive to New Age beliefs, including Japan, but they do not appear at all in other zones, such as Muslim countries.\nFungi can cause circular areas of crop to die, probably the origin of tales of \"fairie rings\". Tales also mention balls of light many times but never in relation to crop circles.\nA 17th-century English woodcut called the \"Mowing-Devil\" depicts the devil with a scythe mowing (cutting) a circular design in a field of oats. The pamphlet containing the image states that the farmer, disgusted at the wage demanded by his mower for his work, insisted that he would rather have \"the devil himself\" perform the task. Crop circle researcher Jim Schnabel does not consider this to be a historical precedent for crop circles because the stalks were cut down, not bent. The circular form indicated to the farmer that it had been caused by the devil.\nIn the 1948 German story \"Die zw\u00f6lf Schw\u00e4ne\" (\"The Twelve Swans\"), a farmer every morning finds a circular ring of flattened grain in his field. After several attempts, his son sees twelve princesses disguised as swans, who take off their disguises and dance in the field. Crop rings produced by fungi may have inspired such tales, since folklore considers that these rings are created by dancing wolves or fairies.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56207", "revid": "35498457", "url": "https://en.wikipedia.org/wiki?curid=56207", "title": "VT100", "text": "Computer terminal from Digital Equipment Corporation\nThe VT100 is a video terminal, introduced in August 1978 by Digital Equipment Corporation (DEC). It was one of the first terminals to support ANSI escape codes for cursor control and other tasks, and added a number of extended codes for special features like controlling the status lights on the keyboard. This led to rapid uptake of the ANSI standard, which became the de facto standard for hardware video terminals and later terminal emulators.\nThe VT100 series, especially the VT102, was extremely successful in the market, and made DEC the leading terminal vendor at the time. The VT100 series was replaced by the VT200 series starting in 1983, which proved equally successful. Ultimately, over six million terminals in the VT series were sold, based largely on the success of the VT100.\nDescription.\nDEC's first video terminal was the VT05 (1970), succeeded by the VT50 (1974), and soon upgraded to the VT52 (1975). The VT52 featured a text display with 80 columns and 24 rows, bidirectional scrolling, and a custom control protocol that allowed the cursor to be moved about the screen. These \"smart terminals\" were a hit due both to their capabilities and to their ability to be run over inexpensive serial links, rather than custom proprietary connections as in the case of systems like the IBM 3270, which generally required expensive controllers for distributed applications. In contrast, \"dumb terminals\" or \"glass teletypes\" like the ADM-3 (1975) lacked advanced features such as full cursor addressability, and competed mostly on lowest possible hardware cost.\nThe VT100 was introduced in August 1978, replacing the VT50/VT52 family. Like the earlier models, it communicated with its host system over serial lines at a minimum speed of 50 bit/s, but increased the maximum speed to 19,200 bit/s, double that of the VT52.\nThe terminal provided an option for \"smooth scrolling\", whereby displayed lines of text were moved gradually up or down the screen to make room for new lines, instead of advancing in sudden \"jumps\". This made it easier to scan or read the text, although it somewhat slowed down the maximum data rate.\nThe major internal change was the control protocol. Unlike the VT50/52's proprietary cursor control language, the VT100 was based on the newly emerging ANSI X3.64 standard for command codes. At the time, some computer vendors had suggested that the new standard was beyond the state of the art and could not be implemented at a reasonable price. The introduction of low-cost microprocessors and the ever-falling cost of computer memory offered greatly expanded capabilities, and the VT100 used the new Intel 8080 as its internal processor. In addition, the VT100 provided backwards compatibility for VT52-compatible software, by also supporting the older control sequences.\nOther improvements beyond the VT52 included a 132-column mode, and a variety of \"graphic renditions\" including blinking, bolding, reverse video, underlining, and lines of double-sized or double-width characters. The VT100 also introduced an additional box-drawing character set containing various pseudographics that allowed the drawing of on-screen forms.\nAll configuration setup of the VT100 was accomplished using interactive displays presented on the screen; the setup data was stored in non-volatile memory within the terminal. Maintainability was also significantly improved, since a VT100 could be quickly dismantled into replaceable modules.\nThe VT100's internal layout can be split into two boards for functionality, not including the VT100's optional boards you can purchase. There is a board called the video monitor board which is used for things like adjusting the CRT on the terminal itself. This board is responsible for adjusting the CRT in the case that the electron beam is offset. The terminal controller board is what handles the terminal logic, and includes a multitude of chips such as DEC's rebranding of the Intel 8080. \nIn 1983, the VT100 was replaced by the more powerful VT200 series terminals such as the VT220.\nOptions.\nThe VT100 has various third party and first party boards designed to enhance the capabilities of the device. Most notable of these from DEC themselves are the VT1XX-AB (Advanced Video Option) and the VT1XX-AA (20 mA Current Loop Option). The cards' capabilities and existence are described in Chapter 4 of the VT100 User Guide.\nVariants.\nThe VT100 was the first of Digital's terminals to be based on an industry-standard microprocessor, the Intel 8080. Options could be added to the terminal to support an external printer, additional graphic renditions, and more character memory. The last option, known as the \"Advanced Video Option\" or AVO, allowed the terminal to support a full 24 lines of text in 132-column mode, increasing from the 14 lines of the unexpanded model when used in 132-column mode. The VT100 became a platform on which Digital constructed several related hardware products.\nThe VT101 and VT102 were cost-reduced, non-expandable follow-on versions. The VT101 was essentially a base-model VT100, while the VT102 came standard with the AVO and serial printer port options pre-installed. The VT105 contained a simple graphics subsystem known as waveform graphics which was mostly compatible with same system in the earlier VT55. This system allowed two mathematical functions to be drawn to the screen superimposed over the normal text display, allowing text and graphics to be mixed to produce charts and similar output. The VT125 added an implementation of the byte-efficient Remote Graphic Instruction Set (ReGIS), which used custom ANSI codes to send graphics commands to the terminal, rather than requiring the terminal to be set to a separate less-efficient \"graphics mode\" like the VT105.\nThe VT131 added block mode support, allowing a form to be sent to the terminal and filled in locally by the user, and then sending the contents of the fields in the form back to the host when the form is filled in.\nThe VT100 form factor left significant physical space in the case for expansion, and DEC used this to produce several all-in-one stand-alone minicomputer systems. The VT103 included a cardcage and 4\u00d74 (8-slot) Q-Bus backplane, sufficient to configure a small 16-bit LSI-11 microcomputer system within the case, and supported an optional dual TU58 DECtape II block-addressable cartridge tape drive which could be used like a very slow disk drive. The VT180 (codenamed \"Robin\") added a single-board microcomputer using a Zilog Z80 to run the CP/M operating system. The VT278 (DECmate) added a small PDP-8 processor, allowing the terminal to run Digital's WPS-8 word processing software.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56208", "revid": "50863852", "url": "https://en.wikipedia.org/wiki?curid=56208", "title": "Meteor Crater", "text": "Meteorite impact crater in northern Arizona\nMeteor Crater, or Barringer Crater, is an impact crater about east of Flagstaff and west of Winslow in the desert of northern Arizona, United States. The site had several earlier names, and fragments of the meteorite are officially called the Canyon Diablo Meteorite, after the adjacent Canyon Diablo.\nMeteor Crater lies at an elevation of above sea level. It is about in diameter, some deep, and is surrounded by a rim that rises above the surrounding plains. The center of the crater is filled with of rubble lying above crater bedrock. One of the features of the crater is its squared-off outline, believed to be caused by existing regional jointing (cracks) in the strata at the impact site.\nDespite an attempt to make the crater a public landmark, the crater remains privately owned by the Barringer family to the present day through their Barringer Crater Company. The Lunar and Planetary Institute, the American Museum of Natural History, and other science institutes proclaim it to be the \"best-preserved meteorite crater on Earth\". It was designated a National Natural Landmark in November 1967.\nFormation.\nThe crater was created about 50,000 years ago during the Pleistocene epoch, when the local climate on the Colorado Plateau was much cooler and damper. The area was an open grassland dotted with woodlands inhabited by mammoths and giant ground sloths.\nThe object that excavated the crater was a nickel-iron meteorite about across. The speed of the impact has been a subject of some debate. Modeling initially suggested that the meteorite struck at up to , but more recent research suggests the impact was substantially slower, at . About half of the impactor's bulk is believed to have been vaporized during its descent through the atmosphere. Impact energy has been estimated at 10 megatons TNTe. The meteorite was mostly vaporized upon impact, leaving few remains in the crater.\nSince the crater's formation, the rim is thought to have lost of height at the rim crest as a result of natural erosion. Similarly, the basin of the crater is thought to have roughly of additional postimpact sedimentation from lake sediments and alluvium. Very few remaining craters are visible on Earth, since many have been erased by erosive geological processes. The relatively young age of Meteor Crater, paired with the dry Arizona climate, has allowed this crater to remain comparatively unchanged since its formation. The lack of erosion that preserved the crater's shape greatly accelerated its groundbreaking recognition as an impact crater from a natural celestial body.\nDiscovery and investigation.\nMeteor Crater came to the attention of scientists after American settlers encountered it in the 19th century. The crater was given several early names, including \"Coon Mountain\", \"Coon Butte\", \"Crater Mountain\", \"Meteor Mountain,\" and \"Meteor Crater.\" Daniel M. Barringer was one of the first people to suggest that the crater was produced by a meteorite impact, with the Barringer family filing mining claims and purchasing it and its surroundings in the early 20th century. This led to the crater also being known as \"Barringer Crater.\" Meteorites from the area are called Canyon Diablo meteorites, after Canyon Diablo, Arizona, which was the closest community to the crater in the late 19th century. The canyon also crosses the strewn field, where meteorites from the crater-forming event are found. The crater was initially assumed to have been formed by a volcanic steam explosion; evidence of geologically recent volcanic activity occurs across this part of Arizona \u2013 the southeastern edge of the San Francisco volcanic field is only about northwest of Meteor Crater.\nAlbert E. Foote.\nIn 1891, mineralogist Albert E. Foote presented the first scientific paper about the meteorites of Northern Arizona. Several years earlier, Foote had received an iron rock for analysis from a railroad executive. Foote immediately recognized the rock as a meteorite and led an expedition to search and retrieve additional meteorite samples. The team collected samples ranging from small fragments to over . Foote identified several minerals in the meteorites, including microscopic diamonds. His paper to the Association for the Advancement of Science provided the first geological description of Meteor Crater to a scientific community.\nGrove Karl Gilbert.\nIn November 1891, Grove Karl Gilbert, chief geologist for the U.S. Geological Survey, investigated the crater and concluded that it was the result of a volcanic steam explosion. Gilbert assumed that, if it were an impact crater, then the volume of the crater, as well as meteoritic material, should still be present in the crater's rim. Gilbert also assumed a large portion of the meteorite should be buried in the crater and that this should generate a large magnetic anomaly. Gilbert's calculations showed that the volume of the crater and the debris on the rim were roughly equivalent, which meant that the mass of the hypothetical impactor was missing. There were also no detectable magnetic anomalies; he argued that the meteorite fragments found on the rim were coincidental or placed there. Gilbert publicized his conclusions in a series of lectures. In 1892, Gilbert would be among the first scientists to propose that the Moon's craters were caused by impact rather than volcanism.\nDaniel M. Barringer.\nMining engineer and businessman Daniel M. Barringer suspected that the crater had been produced by the impact of a large iron meteorite. The theory that the crater was of meteoric origin had been met with skepticism. At the time, the craters visible on the Moon were thought to be volcanic, and no one had conclusively proved that impact craters existed.\nBarringer had amassed a small fortune as an investor in the successful Commonwealth Mine in Pearce, Cochise County, Arizona. Barringer believed that the bulk of the Meteor Crater impactor could still be found under the crater floor. Impact physics was poorly understood at the time, and Barringer was unaware that most of the meteorite had vaporized on impact. Barringer incorporated a company, the Standard Iron Company, and staked a mining claim on the land, hoping to mine the asteroid that had produced the crater. He estimated from the size of the crater that the meteorite had a mass of 10 million tons.\nThe metal content of the iron meteorites found around the crater was valued at the time at US$125/ton, so Barringer was searching for a lode he believed to be worth more than a billion 1903 dollars. \"By 1928, Barringer had sunk the majority of his fortune into the crater\u00a0\u2013 $500,000, or roughly $\u00a0million in 2024 dollars.\"\nBarringer spent 27 years trying to locate the nonexistent deposit of meteoric iron, and drilled to a depth of , but no significant deposit was ever found.\nBarringer was politically well-connected. He received a land patent signed by Theodore Roosevelt for 640 acres (1 sq mi, 260 ha) around the center of the crater in 1903. In 1906, at his request, President Roosevelt also authorized the establishment of a post office unconventionally named \"Meteor\", located at Sunshine, a stop on the Atchison, Topeka and Santa Fe Railway, north of the crater. The Meteor post office closed on April 15, 1912, due to disuse.\nIn 1929, astronomer F.\u00a0R. Moulton was employed by the Barringer Crater Company to investigate the physics of the impact event. Moulton concluded that the impactor likely weighed as little as 300,000 tonnes, and that the impact of such a body would have generated enough heat to vaporize the impactor instantly. Barringer died just ten days after the publication of Moulton's second report.\nBy this time, \"the great weight of scientific opinion had swung around to the accuracy of the impact hypothesis\u00a0... Apparently an idea, too radical and new for acceptance in 1905, no matter how logical, had gradually grown respectable during the intervening 20 years.\"\nHarvey H. Nininger.\nHarvey Harlow Nininger was an American meteoriticist and educator, and he initiated a widespread interest in the scientific study of meteorites in the 1930s, and assembled the largest personal collection of meteorites up to that time. While based in Denver, Colorado, Nininger published the first edition of a pamphlet titled \"A Comet Strikes the Earth\", which described how Meteor Crater formed when an asteroid impacted the Earth. In 1942, Nininger moved his home and business from Denver to the Meteor Crater Observatory, located near the turn-off for Meteor Crater on Route 66. He christened the building the \"American Meteorite Museum\" and published a number of meteorite and Meteor Crater-related books from the location. He also conducted a wide range of research at the crater, discovering impactite, iron-nickel spherules related to the impact and vaporization of the asteroid, and the presence of many other features, such as half-melted slugs of meteoric iron mixed with melted target rock. Nininger's discoveries were compiled and published in a seminal work, \"Arizona's Meteorite Crater\" (1956). Nininger's extensive sampling and fieldwork in the 1930s and 40s contributed significantly to the scientific community's acceptance of the idea that Meteor Crater formed by the impact of an asteroid. Many of his discoveries were later observed at other relatively fresh impact craters, including Henbury and Monturaqui.\nNininger believed that the crater should be a national monument and, in 1948, he successfully petitioned the American Astronomical Society to pass a motion in support of nationalizing the crater by making \"the unauthorized\u2014and false\u2014claim that the [Barringers] would be receptive to a fair purchase for the crater.\" By this time, mining activity at the crater had ceased, and the Barringers were in the process of planning a tourist attraction on the rim of the crater. Nininger was operating the American Meteorite Museum nearby, on Route 66, at the time. Nininger hoped that a public museum could be built on the crater's rim, and that the project might lead to the founding of a federal institute of meteorite research. Offended by Nininger's attempt to nationalize the crater, the Barringer family promptly terminated his exploration rights and ability to conduct further fieldwork at the crater. A few years later, in 1953, the Standard Iron Company was renamed the \"Barringer Crater Company,\" and a private museum was constructed on the crater rim.\nEugene M. Shoemaker.\nEugene Merle Shoemaker continued investigations at the crater. A key discovery was the presence in the crater of the minerals coesite and stishovite, rare forms of silica found only where quartz-bearing rocks have been severely shocked by an instantaneous overpressure. Shocked quartz cannot be created by volcanic action; the only known mechanisms of creating it are naturally through lightning or an impact event, or artificially, through a nuclear explosion. In 1960, Edward C. T. Chao and Shoemaker identified coesite at Meteor Crater, adding to the growing body of evidence that the crater was formed from an impact generating extremely high temperatures and pressures. He confirmed what F.R. Moulton and H.H. Nininger already proposed: the impact vaporized the vast majority of the impactor. The pieces of Canyon Diablo meteorite found scattered around the site broke away from the main body before and during the impact. Shoemaker published his conclusions in his 1974 book, the \"Guidebook to the geology of Meteor Crater, Arizona.\"\nGeologists used the nuclear detonation that created the Sedan crater, and other such craters from the era of atmospheric nuclear testing, to establish upper and lower limits on the kinetic energy of the meteor impactor.\nGeology.\nThe impact created an inverted stratigraphy, so that the layers immediately exterior to the rim are stacked in the reverse order to which they normally occur; the impact overturned and inverted the layers to a distance of 1\u20132\u00a0km outward from the crater's edge. Specifically, climbing the rim of the crater from outside, one finds:\nSoils around the crater are brown, slightly to moderately alkaline, gravelly or stony loam of the Winona series; on the crater rim and in the crater itself, the Winona is mapped in a complex association with rock outcrop.\nRecent history.\nDuring the 1960s and 1970s, NASA astronauts trained in the crater to prepare for the Apollo missions to the Moon, and ongoing field training for astronauts continues to this day.\nOn August 8, 1964, two commercial pilots in a Cessna 150 flew low over the crater. After crossing the rim, they could not maintain level flight. The pilot attempted to circle in the crater to climb over the rim. During the attempted climb out, the aircraft stalled, crashed, and caught fire. The plane is commonly reported to have run out of fuel, but this is incorrect. Both occupants were severely injured, but survived. A small portion of the wreckage not removed from the crash site remains visible.\nIn 2006, a project called METCRAX (for METeor CRAter eXperiment) investigated \"the diurnal buildup and breakdown of basin temperature inversions or cold-air pools and the associated physical and dynamical processes accounting for their evolving structure and morphology.\"\nTourist attraction.\nMeteor Crater is a popular tourist destination with roughly 270,000 visitors per year. The crater is owned by a family company, the Barringer Crater Company. Meteor Crater is an important educational and research site. It was used to train Apollo astronauts and continues to be an active training site for astronauts. The Meteor Crater Visitor Center sits on the north rim of the crater. It features interactive exhibits and displays about meteorites and asteroids, space, the Solar System, and comets including the American Astronaut Wall of Fame and such artifacts on display as an Apollo boilerplate command module (BP-29), a meteorite found in the area, and meteorite specimens from Meteor Crater that can be touched. Formerly known as the Museum of Astrogeology, the Visitor Center includes a Discovery Center &amp; Space Museum, a movie theater, a gift shop, and observation areas with views inside the rim of the crater. Guided tours of the rim are offered daily, weather permitting.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56210", "revid": "903152616", "url": "https://en.wikipedia.org/wiki?curid=56210", "title": "Social democratic", "text": ""}
{"id": "56211", "revid": "82835", "url": "https://en.wikipedia.org/wiki?curid=56211", "title": "Poverty line in the United States", "text": ""}
{"id": "56212", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=56212", "title": "Linen", "text": "Textile made from spun flax fibre\nLinen () is a textile made from the fibers of the flax plant.\nLinen is very strong and absorbent, and it dries faster than cotton. Because of these properties, linen is comfortable to wear in hot weather and is valued for use in garments. Linen textiles can be made from flax plant fiber, yarn, as well as woven and knitted. Linen also has other distinctive characteristics, such as its tendency to wrinkle. It takes significantly longer to harvest than a material like cotton, although both are natural fibers. It is also more difficult to weave than cotton.\nLinen textiles appear to be some of the oldest in the world; their history goes back many thousands of years. Dyed flax fibers found in a cave in the Caucasus (present-day Georgia) suggest the use of woven linen fabrics from wild flax may date back over 30,000 years. Linen was used in ancient civilizations including Mesopotamia and ancient Egypt, and linen is mentioned in the Bible. In the 18th century and beyond, the linen industry was important in the economies of several countries in Europe as well as the American colonies.\nTextiles in a linen weave texture, even when made of cotton, hemp, or other non-flax fibers, are also loosely referred to as \"linen\".\nEtymology.\nThe word \"linen\" is of West Germanic origin and cognate to the Latin name for the flax plant, , and the earlier Greek ().\nThis word history has given rise to a number of other terms in English, most notably \"line,\" from the use of a linen (flax) thread to determine a straight line. It is also etymologically related to a number of other terms, including \"lining\", because linen was often used to create an inner layer for clothing, and \"lingerie\", from French, which originally denoted underwear made of linen.\nHistory.\nPeople in various parts of the world began weaving linen at least several thousand years ago. It was also recovered from Qumran Cave 1 near the Dead Sea.\nEarly history.\nThe discovery of dyed flax fibers in a cave in Southern Caucasus, West Asia (modern-day country of Georgia) dated to 36,000 years ago suggests that ancient people used wild flax fibers to create linen-like fabrics from an early date.\nFragments of straw, seeds, fibers, yarns, and various types of fabrics, including linen samples, dating to about 8,000 BC have been found in Swiss lake dwellings.\nWoven flax textile fragments have been \"found between infant and child\" in a burial at \u00c7atalh\u00f6y\u00fck, a large settlement dating to around 7,000 BC. To the southeast, in ancient Mesopotamia, flax was domesticated and linen was produced. It was used mainly by the wealthier class of the society, including priests. The Sumerian poem of the courtship of Inanna mentions flax and linen.\nIn ancient Egypt, linen was used for mummification and for burial shrouds. It was also worn as clothing on a daily basis; white linen was worn because of the extreme heat. For example, the Tarkhan dress, considered to be among the oldest woven garments in the world and dated to between 3482 and 3102 BC, is made of linen. Plutarch wrote that the priests of Isis also wore linen because of its purity. Linen was sometimes used as a form of currency in ancient Egypt. Egyptian mummies were wrapped in linen as a symbol of light and purity, and as a display of wealth. Some of these fabrics, woven from hand-spun yarns, were very fine for their day, but are coarse compared with modern linen.\nThe earliest written documentation of a linen industry comes from the Linear B tablets of Pylos, Greece. There are many references to linen throughout the Bible.\nMiddle Ages.\nBy the Middle Ages, there was a thriving trade in German flax and linen. The trade spread throughout Germany by the 9th century and spread to Flanders and Brabant by the 11th century. The Lower Rhine was a center of linen making in the Middle Ages. Flax was cultivated and linen used for clothing in Ireland by the 11th century. Evidence suggests that flax may have been grown and sold in Southern England in the 12th and 13th centuries. Textiles, primarily linen and wool, were produced in decentralized home weaving mills.\nModern history.\nLinen continued to be valued for garments in the 16th century and beyond. Specimens of linen garments worn by historical figures have survived. For example, a linen cap worn by Emperor Charles V was carefully preserved after his death in 1558.\nThere is a long history of the production of linen in Ireland. When the Edict of Nantes was revoked in 1685, many of the Huguenots who fled France settled in the British Isles and elsewhere. They brought improved methods for linen production with them, contributing to the growth of the linen industry in Ireland in particular. Among them was Louis Crommelin, a leader who was appointed overseer of the royal linen manufacture of Ireland. He settled in the town of Lisburn near Belfast, which is itself perhaps the most famous linen producing center throughout history; during the Victorian era the majority of the world's linen was produced in the city, which gained it the name Linenopolis. Although the linen industry was already established in Ulster, Louis Crommelin found scope for improvement in weaving, and his efforts were so successful that he was appointed by the Government to develop the industry over a much wider range than the small confines of Lisburn and its surroundings. The direct result of his good work was the establishment, under statute, of the Board of Trustees of the Linen Manufacturers of Ireland in the year 1711. Several grades were produced including coarse lockram. The Living Linen Project was set up in 1995 as an oral archive of the knowledge of the Irish linen industry, which was at that time still available within a nucleus of people who formerly worked in the industry in Ulster.\nThe linen industry was increasingly critical in the economies of Europe in the 18th and 19th centuries. In England and then in Germany, industrialization and machine production replaced manual work and production moved from the home to new factories.\nLinen was also an important product in the American colonies, where it was brought over with the first settlers and became the most commonly used fabric and a valuable asset for colonial households. The homespun movement encouraged the use of flax to make home spun textiles. Through the 1830s, most farmers in the northern United States continued to grow flax for linen to be used for the family's clothing.\nIn the late 19th and early 20th centuries, linen was very significant to Russia and its economy. At one time it was the country's greatest export item and Russia produced about 80% of the world's fiber flax crop.\nIn December 2006, the General Assembly of the United Nations proclaimed 2009 to be the International Year of Natural Fibres in order to raise people's awareness of linen and other natural fibers.\nUses.\nMany products can be made with linen, such as clothing, bed sheets, aprons, bags, towels (swimming, bath, beach, body and wash towels), napkins, runners, and upholstery. It is used especially in sailcloth and lent cloth, sewing threads, handkerchiefs, table cloth, sheets, collars, cuffs etc..\nToday, linen is usually an expensive textile produced in relatively small quantities. It has a long staple (individual fiber length) relative to cotton and other natural fibers.\nLinen fabric has been used for table coverings, bed coverings and clothing for centuries. The significant cost of linen derives not only from the difficulty of working with the thread but also because the flax plant itself requires a great deal of attention. In addition, flax thread is not elastic, and therefore it is difficult to weave without breaking threads. Thus linen is considerably more expensive to manufacture than cotton.\nThe collective term \"linens\" is still often used generically to describe a class of woven or knitted bed, bath, table and kitchen textiles traditionally made of flax-based linen but today made from a variety of fibers. The term \"linens\" refers to lightweight undergarments such as shirts, chemises, waist-shirts, lingerie (a cognate with \"linen\"), and detachable shirt collars and cuffs, all of which were historically made almost exclusively out of linen. The inner layer of fine composite cloth garments (as for example dress jackets) was traditionally made of linen, hence the word \"lining\".\nOver the past 30 years the end use for linen has changed dramatically. Approximately 70% of linen production in the 1990s was for apparel textiles, whereas in the 1970s only about 5% was used for fashion fabrics.\nLinen uses range across bed and bath fabrics (tablecloths, bath towels, dish towels, bed sheets); home and commercial furnishing items (wallpaper/wall coverings, upholstery, window treatments); apparel items (suits, dresses, skirts, shirts); and industrial products (luggage, canvases, sewing thread). It was once the preferred yarn for hand-sewing the uppers of moccasin-style shoes (loafers), but has been replaced by synthetics.\nA linen handkerchief, pressed and folded to display the corners, was a standard decoration of a well-dressed man's suit during most of the first part of the 20th century.\nNowadays, linen is one of the most preferred materials for bed sheets due to its durability and hypoallergenic properties. Linen can be up to three times stronger than cotton. This is because the cellulose fibers in linen yarn are slightly longer and wrapped tighter than those found in cotton yarn, which gives it great durability and allows linen products to be long-lasting.\nCurrently researchers are working on a cotton/flax blend to create new yarns which will improve the feel of denim during hot and humid weather. Conversely, some brands such as 100% Capri specially treat the linen to look like denim.\nLinen fabric is one of the preferred traditional supports for oil painting. In the United States cotton is popularly used instead, as linen is many times more expensive there, restricting its use to professional painters. In Europe, however, linen is usually the only fabric support available in art shops; in the UK both are freely available with cotton being cheaper. Linen is preferred to cotton for its strength, durability and archival integrity.\nLinen is also used extensively by artisan bakers. Known as a couche, the flax cloth is used to hold the dough into shape while in the final rise, just before baking. The couche is heavily dusted with flour which is rubbed into the pores of the fabric. Then the shaped dough is placed on the couche. The floured couche makes a \"non stick\" surface to hold the dough. Then ridges are formed in the couche to keep the dough from spreading.\nIn the past, linen was also used for books (the only surviving example of which is the Liber Linteus). Due to its strength, in the Middle Ages linen was used for shields, gambesons, and bowstrings; in classical antiquity it was used to make a type of body armour, referred to as a linothorax. Additionally, linen was commonly used to make riggings, sail-cloths, nets, ropes, and canvases because the tensility of the cloth would increase by 20% when wet.\nBecause of its strength when wet, Irish linen is a very popular wrap of pool/billiard cues, due to its absorption of sweat from hands.\nIn 1923, the German city Bielefeld issued banknotes printed on linen. United States currency paper is made from 25% linen and 75% cotton.\nFlax fiber.\nDescription.\nLinen is a bast fiber. Flax fibers vary in length from about 25 to 150\u00a0mm (1 to 6 in) and average 12\u201316 micrometers in diameter. There are two varieties: shorter tow fibers used for coarser fabrics and longer line fibers used for finer fabrics. Flax fibers can usually be identified by their \"nodes\" which add to the flexibility and texture of the fabric.\nThe cross-section of the linen fiber is made up of irregular polygonal shapes which contribute to the coarse texture of the fabric.\nProperties.\nLinen fabric feels cool to touch, a phenomenon which indicates its higher conductivity (the same principle that makes metals feel \"cold\"). It is smooth, making the finished fabric lint-free, and gets softer the more it is washed. However, constant creasing in the same place in sharp folds will tend to break the linen threads. This wear can show up in collars, hems, and any area that is iron creased during laundering. Linen's poor elasticity means that it easily wrinkles.\nMildew, perspiration, and bleach can damage the fabric, but because it is not made from animal fibers (keratin) it is impervious to clothes moths and carpet beetles. Linen is relatively easy to take care of, since it resists dirt and stains, has no lint or pilling tendency, and can be dry-cleaned, machine-washed, or steamed. It can withstand high temperatures, and has only moderate initial shrinkage.\nLinen should not be dried too much by tumble drying, and it is much easier to iron when damp. Linen wrinkles very easily, and thus some more formal garments require ironing often, in order to maintain perfect smoothness. Nevertheless, the tendency to wrinkle is often considered part of linen's particular \"charm\", and many modern linen garments are designed to be air-dried on a good clothes hanger and worn without the necessity of ironing.\nA characteristic often associated with linen yarn is the presence of \"slubs\", or small, soft, irregular lumps, which occur randomly along its length. In the past, slubs were traditionally considered to be defects, and were associated with low-quality linen. However, in the case of many present-day linen fabrics, particularly in the decorative furnishing industry, slubs are considered as part of the aesthetic appeal of an expensive natural product. In addition, slubs do not compromise the integrity of the fabric, and therefore they are not viewed as a defect. However, the very finest linen has very consistent diameter threads, with no slubs at all.\nLinen can degrade in a few weeks when buried in soil. Linen is more biodegradable than cotton, making it an eco friendly fiber.\nMeasure.\nThe standard measure of bulk linen yarn is the \"lea\", which is the number of yards in a pound of linen divided by 300. For example, a yarn having a size of 1\u00a0lea will give 300\u00a0yards per pound. The fine yarns used in handkerchiefs, etc. might be 40\u00a0lea, and give 40x300 = 12,000\u00a0yards per pound. This is a specific length therefore an indirect measurement of the fineness of the linen (i.e. the number of length units per unit mass). The symbol is NeL. The metric unit, Nm, is more commonly used in continental Europe. This is the number of 1,000\u00a0m lengths per kilogram. In China, the English Cotton system unit, NeC, is common. This is the number of 840\u00a0yard lengths in a pound.\nProduction method.\nLinen is laborious to manufacture.\nThe quality of the finished linen product is often dependent upon growing conditions and harvesting techniques. To generate the longest possible fibers, flax is either hand-harvested by pulling up the entire plant or stalks are cut very close to the root. After harvesting, the plants are dried, and then the seeds are removed through a mechanized process called \"rippling\" (threshing) and winnowing.\nThe fibers must then be loosened from the stalk. This is achieved through retting, a process which uses bacteria to decompose the pectin that binds the fibers together. Natural retting methods take place in tanks and pools, or directly in the fields. There are also chemical retting methods; these are faster, but are typically more harmful to the environment and to the fibers themselves.\nAfter retting, the stalks are ready for scutching, which takes place between August and December. Scutching removes the woody portion of the stalks by crushing them between two metal rollers, so that the parts of the stalk can be separated. The fibers are removed and the other parts such as linseed, shives, and tow are set aside for other uses. Next the fibers are heckled: the short fibers are separated with heckling combs by 'combing' them away, to leave behind only the long, soft flax fibers.\nAfter the fibers have been separated and processed, they are typically spun into yarns and woven or knit into linen textiles. These textiles can then be bleached, dyed, printed on, or finished with a number of treatments or coatings.\nAn alternate production method is known as \"cottonizing\" which is quicker and requires less equipment. The flax stalks are processed using traditional cotton machinery; however, the finished fibers often lose the characteristic linen look.\nProducers.\nIn 2018, according to the United Nations' repository of official international trade statistics, China was the top exporter of woven linen fabrics by trade value, with a reported $732.3 million in exports; Italy ($173.0 million), Belgium ($68.9 million) and the United Kingdom ($51.7 million) were also major exporters.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56214", "revid": "42195518", "url": "https://en.wikipedia.org/wiki?curid=56214", "title": "Surcoat", "text": "Outer garment commonly worn in the Middle Ages in Western Europe\nA surcoat or surcote is an outer garment that was commonly worn by soldiers in the Middle Ages. It was worn over armor to show insignia and help identify what side the soldier was on. On the battlefield, the surcoat helped keep the sun off the soldier and their armor, reducing the risk of heat illness. The name derives from French, meaning \"over the coat\", a long, loose, often sleeveless coat reaching down to the feet.\nHistory.\nMen's surcoat.\nStarting around the late 12th century, knights wore long, flowing surcoats. From the early to mid-13th century, these were frequently emblazoned with their personal arms, shown over their armour. These usually extended to about mid-calf, were either sleeved or sleeveless, and had slits in the bottom front and back, allowing the wearer to ride their horses comfortably. Some historians believe that the practice of wearing white surcoats was adopted during the Crusades, their main purpose being to reflect the direct sun, which overheated the armour and the soldier inside \u2013 although it may be argued that here its color would have been of little help, while in poor weather they helped keep rain and the muck of battle away from the easily corroded mail links. The surcoat displayed the device of the knight (origin of the term \"coat of arms\"), thereby identifying him, which in turn, combined with the increased use of the great helm (late 12th century, early 13th century), became an essential means of recognition. Indeed, some historians cite this as one of the reasons behind the spread of heraldry across medieval Europe. In the early fourteenth century, the front of the knight's surcoat was shortened so that it was longer at the back and knee-length at the front, allowing greater freedom of movement and eliminating the danger of a rider getting his spurs caught in the garment. By the mid-fourteenth century, it was replaced with the \"jupon\" (or \"gipon\"), which was a much shorter item and was often padded for supplementary protection.\nIn the 15th century, once suits of plate armour became common, the surcoat was phased out of use. This period in the history of armour development, in which surcoats became increasingly rare, is referred to as the \"surcoatless period\" and lasted from 1420 to 1485.\nWomen's surcoat.\nWomen began wearing surcoats during the 13th century, both with and without sleeves. A particular style, known as the sideless surcoat, developed as a fashion in the 14th century. This was a sleeveless, floor-length garment featuring exaggerated armholes, which at their most extreme were open from shoulder to hip, revealing the gown underneath. The narrow strip covering the torso, known as the plackard, was usually no more than a foot wide. The style drew criticism from some moralists, who thought the garment drew an inappropriate amount of attention to the female body. Despite this, sideless surcoats continued to be worn as ceremonial dress well into the 15th century, long after they had ceased to be fashionable. Some estimates place them being worn as state apparel as late as 1525.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56215", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=56215", "title": "Gramineae", "text": ""}
{"id": "56216", "revid": "48022469", "url": "https://en.wikipedia.org/wiki?curid=56216", "title": "Technical (vehicle)", "text": "Improvised fighting vehicle\nA technical, known as a non-standard tactical vehicle (NSTV) in United States military parlance, is a light improvised fighting vehicle which has been modified to mount small arms and light weapons (SALW) and heavy weaponry. \nThe vehicles most commonly used to make technicals are open-backed civilian pickup trucks and vehicles with four-wheel drive capabilities. Armaments used include machine guns, automatic grenade launchers, anti-aircraft autocannons, rotary cannons, anti-tank weapons, anti-tank guns, anti-tank guided missiles, mortars, multiple rocket launchers, recoilless rifles, and other support weaponry. Technicals perform a similar function to gun trucks and self-propelled guns, but are helpless against more advanced weaponry and superior air power.\nEtymology.\nThe neologism \"technical\" describing such a vehicle is believed to have originated in Somalia during the Somali Civil War in the early 1990s. Barred from bringing in private security, non-governmental organizations hired local gunmen to protect their personnel, using money defined as \"technical assistance grants\". The term broadened to include any vehicle carrying armed men.\nAn alternative account is given by Michael Maren, who says the term was first used in Somalia in the 1980s, after engineers from Soviet arms manufacturer \"Tekniko\" mounted weapons on vehicles for the Somali National Movement during the Somaliland War of Independence. Technicals have also been referred to as \"battlewagons\" and \"gunwagons\".\nIn Russia and Ukraine, technicals are often referred to as \"tachanka\", a reference to horse-drawn machine gun platforms from the First World War and Russian Civil War.\nFeatures.\nAmong irregular militaries, often centered on the perceived strength and charisma of male warlords, the prestige of technicals is strong. According to one article, \"The Technical is the most significant symbol of power in southern Somalia. It is a small truck with large tripod machine guns mounted on the back. A warlord's power is measured by how many of these vehicles he has.\"\nTechnicals are not commonly used by well-funded militaries that are able to procure purpose-built combat vehicles, because the soft-skinned civilian vehicles that technicals are based on do not offer much armor protection to crew and passengers.\nTechnicals fill the niche of traditional light cavalry. Generally costing much less than purpose-built combat vehicles, the major asset of technicals is speed and mobility, as well as their ability to strike from unexpected directions with automatic fire and light troop deployment. The reliability of vehicles such as the Toyota Hilux is useful for forces that lack the repair-related infrastructure of a conventional military on land. In direct engagements they are no match for heavier vehicles, such as tanks or other armored fighting vehicles, and they are mostly helpless against any air support from a proper military. \nHistory.\nPrototypes and early usage.\nLight improvised fighting vehicles date back to the first use of automobiles, and to the horse-drawn \"tachankas\" mounting machine guns in eastern Europe and Russia. At the Bombardment of Papeete in World War I, the French armed several Ford trucks with 37\u00a0mm guns to bolster their defense of the city. During the Spanish Civil War, field guns were fixed to trucks to act as improvised self-propelled guns, and improvised armored cars were constructed by attaching steel plates to trucks.\nIn World War II, various British and Commonwealth units, including the Long Range Desert Group (LRDG), the No. 1 Demolition Squadron or 'PPA' (Popski's Private Army), and the Special Air Service (SAS) were noted for their exploits in the deserts of Egypt, Libya and Chad using unarmored motor vehicles, often fitted with machine guns. Examples of LRDG vehicles include the Chevrolet WB 30 cwt Patrol Truck and the Willys MB Jeep.\nThe SAS' use of heavily armed Land Rovers continued post-war, with their use of Series 1 Land Rovers and later Series 11A 1968 Land Rovers in the Dhofar Rebellion. The SAS painted their Land Rovers pink, as it was found to provide excellent camouflage in the desert and they were nicknamed 'Pink Panthers' or Pinkies. The SAS used a more modern Land Rover Desert Patrol Vehicle (DPV) during the Gulf War.\nWestern Sahara.\nTactics for employing technicals were pioneered by the Sahrawi People's Liberation Army, the armed wing of the Polisario Front, fighting for independence against Mauritania (1975\u201379) and Morocco (1975\u2013present) from headquarters in Tindouf, Algeria. Algeria provided arms and Land Rovers to Sahrawi guerrillas, who successfully used them in long-range desert raids against the less agile conventional armies of their opponents, recalling Sahrawi tribal raids (ghazis) of the pre-colonial period. Polisario later gained access to heavier equipment, but four-wheel drive vehicles remain a staple of their arsenal.\nThe Moroccan army quickly changed their strategy and created mounted units using technicals to challenge Polisario speed and hit and run strategies in the large desert, where the Moroccan units proved their efficiency.\nChadian\u2013Libyan conflict.\nIn 1987, Chadian troops equipped with technicals drove the heavily mechanized Libyan army from the Aozou Strip. The vehicles were instrumental in the victory at the Battle of Fada, and were driven over into Libya to raid military bases. It was discovered that these light vehicles could ride through anti-tank minefields without detonating the mines when driven at speeds over 100\u00a0km/h. The vehicles became so famous that, in 1984, \"Time\" dubbed early stages of the conflict the \"Great Toyota War\".\nThe Toyota War was unusual in that the force equipped with improvised vehicles prevailed over the force equipped with purpose-built fighting vehicles. MILAN anti-tank guided missiles provided by France were key to the Chadian success, while the Libyan forces were poorly deployed and organized.\nThe Troubles in Northern Ireland.\nThroughout the conflict in Northern Ireland (1960s-1998), the Provisional IRA fitted vehicles, especially vans and trucks, with automatic weapons, heavy machine guns, and improvised mortars. Sometimes the vehicles were armored with welded plates and sandbags. The IRA employed tractors and trailers to transport and fire improvised mortars, and heavy equipment to tear down fences and barbed wire and break into fortified security bases. Improvised flamethrowers were usually modified manure spreaders pulled to their targets by tractor.\nSomali Civil War.\nTechnicals played an important role in the 1990s Somali Civil War and the War in Somalia (2006\u20132009). Even prior to the collapse of the Somali Democratic Republic, camouflaged Toyota pickup trucks with mounted M2 Browning machine guns appeared in Somali military parades in the 1980s. After the fall of the Siad Barre regime and the collapse of the Somali National Army (SNA), it was rare for any Somali force to field armored fighting vehicles. However, technicals were very common.\nIn September 1995, Somali faction leader Mohamed Farrah Aidid used 30 technicals and a force of 600 militia to capture Baidoa. It was reported that after his death in 1996, his body was carried to his funeral on a Toyota pickup.\nIn 2006, Proving their susceptibility to heavy weapons and their value as a military prize, the Islamic Courts Union (ICU) captured 30 \"battlewagons\" during the defeat of warlord Abdi Qeybdid's militia in the Second Battle of Mogadishu. That September, an impressive array of 130 technicals was used to take Kismayo from the forces of the Juba Valley Alliance.\nIn November 2006, then President of Puntland, General Adde Musa, personally led fifty technicals to Galkacyo to confront the Islamists. They were used a month later against the army of the Islamic Courts Union at the Battle of Bandiradley alongside Abdi Qeybdiid's reconstituted militia.\nForced into conventional battles in the War in Somalia (2006\u20132009), the unarmored technicals of the ICU proved no match for the T-55 tanks, Mil Mi-24 helicopter gunships and fighter-bombers employed by Ethiopia.\nWar in Afghanistan.\nIn the War in Afghanistan, U.S. special operations forces units such as the Green Berets were known to use technicals for patrol, because of the rugged terrain and the nature of their clandestine operations. The Taliban also use technicals in the bulk of their mobile fighting force.\nIraq War.\nTechnicals were used by Iraqi military forces in the 2003 invasion of Iraq. The Iraqi Republican Guard and Fedayeen emulated tactics of the Somali National Alliance with limited success, but were outmatched by Coalition armor and aviation. In the aftermath of the invasion, technicals were used by Iraqi insurgents for transporting personnel and quick raids against the Iraqi police forces. The insurgent use of technicals increased after the Iraq Spring Fighting of 2004.\nMany military utility vehicles were modified to serve as gun trucks to protect Coalition convoys. The Humvee allows for weapon mounts by design, so it is not considered a technical.\nThe Coalition supplied technicals to the Iraqi police. Private military contractors used technicals and the United States military used modified Toyota Hiluxes, Land Cruisers, and other trucks as well.\nDarfur conflict.\nJanjaweed militias use technicals on their raids against civilian villages in Darfur, Sudan, as do the Sudan Liberation Army (SLA) and Justice and Equality Movement (JEM) rebel troops in defense of their areas of operations. Light vehicles such as technicals are often thought to be more mobile than armored vehicles, but on one occasion an African peace-keeper driving a \"Grizzly\" AVGP whose guns had jammed, succeeded in catching up with, ramming and rolling over a fleeing Sudanese technical.\nLebanon.\nIntroduced by the Palestine Liberation Organization (PLO) guerrilla groups, technicals were extensively employed by all factions involved in the Lebanese Civil War between 1975 and 1990, including the Christian Lebanese Front and the Lebanese National Movement (LNM) irregular militias, the Lebanese Army and the Internal Security Forces (ISF).\nOpposition forces used technicals in the fighting for the Chouf District during the May 2008 clashes in Lebanon.\nLibyan Civil War.\nDuring the First Libyan Civil War, both regime loyalist forces as well as the anti-Gaddafi forces used technicals extensively. The type of warfare in the conflict\u2014wherein highly mobile groups of soldiers and rebels continued to move to and from on the desert terrain, retreating at a time and then suddenly attacking to regain control of small towns and villages in the Eastern rebel held parts of Libya\u2014led to the technical becoming a vehicle of choice for both sides.\nTechnicals were widely used by the rebels while setting up checkpoints. They formed a vast percentage of the rebel inventory, which was limited to light weapons, light body armor and very few tanks. Some medium flatbed trucks carried the Soviet-made ZPU and ZU-23-2 towed anti-aircraft twin or quad barreled guns, and recoilless rifles and S-5 rocket helicopter rocket launcher pods. \nSome rebels improvised with captured heavy weaponry, like BMP-1 turrets and helicopter rocket pods, and lower-tech methods such as using doorbells to ignite rocket-launched ammunition. Rebel technicals frequently employed BM-21 Grad rockets. Rocket tubes were salvaged from damaged regime Ural-375D trucks and mounted on the backs of pickups, with the technicals able to fire anywhere from one to six rockets.\nSyrian Civil War.\nIn the Syrian Civil War, technicals are extensively used as improvised fighting vehicles, especially by former opposition forces such as Jaysh al-Thuwar, who largely lack conventional fighting vehicles. Syrian government forces used technicals, but on a smaller scale. The kind of weapons mounted on technicals varies widely, including machine guns, recoilless rifles, anti-aircraft autocannons (commonly ZPU and ZU-23-2) and even BMP-1 turrets. The Military of ISIL extensively used technicals in Iraq and Syria.\nPeshmerga forces have used technicals to surround and attack ISIS targets.\nRusso-Ukrainian War.\nWar in Donbas.\nDuring the 2014 war in Donbas, both sides were using home-made military vehicles. OSCE monitors recorded 15 Russian armored utility vehicles (UAZ-23632-148 Esaul) in a training area near non-government-controlled Oleksandrivska in April 2021.\nRussian invasion of Ukraine.\nTechnicals were seen being used by Spetsnaz in Gomel, Belarus in February 2022. Ukrainian forces used rocket launchers recovered from downed helicopters, mounted on technicals.\nYemeni Civil War.\nIn the Yemeni Civil War, Houthis and Hadi/Alimi-aligned militias use technicals.\nComposition.\nTechnicals consist of weapons mounted on a civilian vehicle, such as a four-wheel drive pickup truck. Many pickups have been used as technicals including Ford Ranger and Mitsubishi Triton, but the most favoured are the Toyota Hilux and Toyota Land Cruiser. They are typically fitted with heavy machine guns (especially the DShK, Type 77 or M2 Browning), anti-aircraft artillery (usually the ZPU or ZU-23-2), recoilless rifles (usually the SPG-9 or M40 recoilless rifle), anti-tank missiles launchers, multiple rocket launchers such as the Type 63 or the M-63 Plamen and in rare occasions rocket pods salvaged from downed attack helicopters like the S-5 rocket.\nDue to being soft-skinned vehicles, optional add-on hardware include ballistic glass, turret gun shields and improvised vehicle armor made of welded steel plates, as defence against small arms fire to increase survival chances.\nSome technicals have their original tyres changed to off-road tyres, run-flat tyres or specialised tyres with central tyre inflation system. The modified tyres improve technicals' performance on different terrains. Run-flat tyres, or central tyre inflation system equipped tyres give the technicals opportunity to quickly get out of dangerous situations, even when tyres are damaged.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56217", "revid": "48535834", "url": "https://en.wikipedia.org/wiki?curid=56217", "title": "Poaceae", "text": "Family of flowering plants commonly known as grasses\nPoaceae ( ), also called Gramineae ( ), is a large and nearly ubiquitous family of monocotyledonous flowering plants commonly known as true grasses. It includes the cereal grasses, bamboos, the grasses of natural grassland and species cultivated in lawns and pasture. Poaceae is the most well-known family within the informal group known as grass.\nWith around 780 genera and around 12,000 species, the Poaceae is the fifth-largest , following the Asteraceae, Orchidaceae, Fabaceae and Rubiaceae.\nThe Poaceae are the most economically important plant family, including staple foods from domesticated cereal crops such as maize, wheat, rice, oats, barley, and millet for people and as feed for meat-producing animals. They provide, through direct human consumption, a substantial portion of all dietary energy: rice provides 20%, wheat supplies 19%, and maize (corn) 5%. Some members of the Poaceae are used as building materials (bamboo, thatch, and straw); others can provide a source of biofuel, primarily via the conversion of maize to ethanol.\nGrasses have stems that are hollow except at the nodes and narrow alternate leaves borne in two ranks. The lower part of each leaf encloses the stem, forming a leaf-sheath. The leaf grows from the base of the blade, an adaptation allowing it to cope with frequent grazing.\nGrasslands such as savannah and prairie where grasses are dominant are estimated to constitute 40.5% of the land area of the Earth, excluding Greenland and Antarctica. Grasses are also an important part of the vegetation in many other habitats, including wetlands, forests and tundra.\nThough they are commonly called \"grasses\", groups such as the seagrasses, rushes and sedges fall outside this family. The rushes and sedges are related to the Poaceae, being members of the order Poales, but the seagrasses are members of the order Alismatales. However, all of them belong to the monocot group of plants.\nDescription.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nDiagram of a typical lawn grass plant \nGrasses may be annual or perennial herbs, generally with the following characteristics (the image gallery can be used for reference): The stems of grasses, called culms, are usually cylindrical (more rarely flattened, but not 3-angled) and are hollow, plugged at the nodes, where the leaves are attached. Grass leaves are nearly always alternate and distichous (in one plane), and have parallel veins. Each leaf is differentiated into a lower sheath hugging the stem and a blade with entire (i.e., smooth) margins. The leaf blades of many grasses are hardened with silica phytoliths, which discourage grazing animals; some, such as sword grass, are sharp enough to cut human skin. A membranous appendage or fringe of hairs called the ligule lies at the junction between sheath and blade, preventing water or insects from penetrating into the sheath.\nFlowers of Poaceae are characteristically arranged in spikelets, each having one or more florets. The spikelets are further grouped into panicles or spikes. The part of the spikelet that bears the florets is called the rachilla. A spikelet consists of two (or sometimes fewer) bracts at the base, called glumes, followed by one or more florets. A floret consists of the flower surrounded by two bracts, one external\u2014the lemma\u2014and one internal\u2014the palea. The flowers are usually hermaphroditic\u2014maize being an important exception\u2014and mainly anemophilous or wind-pollinated, although insects occasionally play a role. The perianth is reduced to two scales, called \"lodicules\", that expand and contract to spread the lemma and palea; these are generally interpreted to be modified sepals. The fruit of grasses is a caryopsis, in which the seed coat is fused to the fruit wall.\nA tiller is a leafy shoot other than the first shoot produced from the seed.\nGrowth and development.\nGrass blades grow at the base of the blade and not from elongated stem tips. This low growth point evolved in response to grazing animals and allows grasses to be grazed or mown regularly without severe damage to the plant.\nThree general classifications of growth habit present in grasses: bunch-type (also called caespitose), stoloniferous, and rhizomatous.\nThe success of the grasses lies in part in their morphology and growth processes and in part in their physiological diversity. There are both C3 and C4 grasses, referring to the photosynthetic pathway for carbon fixation. The C4 grasses have a photosynthetic pathway, linked to specialized Kranz leaf anatomy, which allows for increased water use efficiency, rendering them better adapted to hot, arid environments.\nThe C3 grasses are referred to as \"cool-season\" grasses, while the C4 plants are considered \"warm-season\" grasses.\nAlthough the C4 species are all in the PACMAD clade (see diagram below), it seems that various forms of C4 have arisen some twenty or more times, in various subfamilies or genera. In the \"Aristida\" genus for example, one species (\"A. longifolia\") is C3 but the approximately 300 other species are C4. As another example, the whole tribe of Andropogoneae, which includes maize, sorghum, sugar cane, \"Job's tears\", and bluestem grasses, is C4. Around 46 percent of grass species are C4 plants.\nTaxonomy.\nThe name Poaceae was given by John Hendley Barnhart in 1895, based on the tribe Poeae described in 1814 by Robert Brown, and the type genus \"Poa\" described in 1753 by Carl Linnaeus. The term is derived from the Ancient Greek .\nEvolutionary history.\nGrasses include some of the most versatile plant life-forms. They became widespread toward the end of the Cretaceous period, and fossilized dinosaur dung (coprolites) belonging to the sauropod titanosaurs (though this provenance has been questioned) have been found containing phytoliths of a variety that include grasses that are related to modern rice and bamboo. Grasses have adapted to conditions in lush rain forests, dry deserts, cold mountains and even intertidal habitats, and are currently the most widespread plant type; grass is a valuable source of food and energy for all sorts of wildlife.\nA cladogram shows subfamilies and approximate species numbers in brackets:\nBefore 2005, fossil findings indicated that grasses evolved around 55 million years ago. Finds of grass-like phytoliths in Cretaceous dinosaur coprolites from the latest Cretaceous (Maastrichtian) aged Lameta Formation of India have pushed this date back to 66 million years ago. Due to high phosphatic content of 12.2-16.2% in Type A coprolites collected from the Lameta, an omnivore is hypothesized to be the source, contradicting the hypothesis of a sauropod origin. In 2011, fossils from the same deposit were found to belong to the modern rice tribe Oryzeae, suggesting substantial diversification of major lineages by this time.\nIn 2018, a study described grass microfossils extracted from the teeth of the hadrosauroid dinosaur \"Equijubus normani\" from northern China, dating to the Albian stage of the Early Cretaceous approximately 113\u2013100 million years ago, which were found to belong to primitive lineages within Poaceae, similar in position to the Anomochlooideae. These are currently the oldest known grass fossils.\nFossils of \"Phragmites\" have been found in the Late Cretaceous of North America, particularly in the Maastrichtian aged Laramie Formation. However slightly older fossils of \n\"Phragmites\" have been found in the Eastern coast of the US dating the Campanian (such as in the Black Creek Formation). \nThe relationships among the three subfamilies Bambusoideae, Oryzoideae and Pooideae in the BOP clade have been resolved: Bambusoideae and Pooideae are more closely related to each other than to Oryzoideae. This separation occurred within the relatively short time span of about 4 million years.\nAccording to Lester Charles King, the spread of grasses in the Late Cenozoic would have changed patterns of hillslope evolution favouring slopes that are convex upslope and concave downslope and lacking a free face were common. King argued that this was the result of more slowly acting surface wash caused by carpets of grass which in turn would have resulted in relatively more soil creep.\nSubdivisions.\nThere are about 12,000 grass species in about 771 genera that are classified into 12 subfamilies. See the full list of Poaceae genera.\nDistribution.\nThe grass family is one of the most widely distributed and abundant groups of plants on Earth. Grasses are found on every continent, including Antarctica. The Antarctic hair grass, \"Deschampsia antarctica\" is one of only two flowering plant species native to the western Antarctic Peninsula.\nEcology.\nGrasses are the dominant vegetation in many habitats, including grassland, salt-marsh, reedswamp and steppes. They also occur as a smaller part of the vegetation in almost every other terrestrial habitat.\nGrass-dominated biomes are called grasslands. If only large, contiguous areas of grasslands are counted, these biomes cover 31% of the planet's land. Grasslands include pampas, steppes, and prairies.\nGrasses provide food to many grazing mammals, as well as to many species of butterflies and moths.\nMany types of animals eat grass as their main source of food, and are called \"graminivores\" \u2013 these include cattle, sheep, horses, rabbits and many invertebrates, such as grasshoppers and the caterpillars of many brown butterflies. Grasses are also eaten by omnivorous or even occasionally by primarily carnivorous animals.\nGrasses dominate certain biomes, especially temperate grasslands, because many species are adapted to grazing and fire.\nGrasses are unusual in that the meristem is near the bottom of the plant; hence, grasses can quickly recover from cropping at the top.\nThe evolution of large grazing animals in the Cenozoic contributed to the spread of grasses. Without large grazers, fire-cleared areas are quickly colonized by grasses, and with enough rain, tree seedlings. Trees eventually outcompete most grasses. Trampling grazers kill seedling trees but not grasses.\nSexual reproduction and meiosis.\nSexual reproduction and meiosis have been studied in rice, maize, wheat and barley. Meiosis research in these crop species is linked to crop improvement, since meiotic recombination is an important component of plant breeding. Unlike in animals, the specification of both male and female plant germlines occurs late in development during flowering. The transition from the sporophyte phase to the gametophyte state is initiated by meiotic entry.\nUses.\nGrasses are, in human terms, perhaps the most economically important plant family. Their economic importance stems from several areas, including food production, industry, and lawns. They have been grown as food for domesticated animals for up to 6,000 years and the grains of grasses such as wheat, rice, maize (corn) and barley have been the most important human food crops. Grasses are also used in the manufacture of thatch, paper, fuel, clothing, insulation, timber for fencing, furniture, scaffolding and construction materials, floor matting, sports turf and baskets.\nFood production.\nOf all crops grown, 70% are grasses. Agricultural grasses grown for their edible seeds are called \"cereals\" or \"grains\" (although the latter term, when used agriculturally, refers to both cereals and similar seeds of other plant species, such as buckwheat and legumes). Three cereals\u2014rice, wheat, and maize (corn)\u2014provide more than half of all calories consumed by humans. Cereals constitute the major source of carbohydrates for humans and perhaps the major source of protein; these include rice (in southern and eastern Asia), maize (in Central and South America), and wheat and barley (in Europe, northern Asia and the Americas).\nSugarcane is the major source of sugar production. Additional food uses of sugarcane include sprouted grain, shoots, and rhizomes, and in drink they include sugarcane juice and plant milk, as well as rum, beer, whisky, and vodka.\nBamboo shoots are used in numerous Asian dishes and broths, and are available in supermarkets in various sliced forms, in both fresh, fermented and canned versions.\nLemongrass is a grass used as a culinary herb for its citrus-like flavor and scent.\nMany species of grass are grown as pasture for foraging or as fodder for prescribed livestock feeds, particularly in the case of cattle, horses, and sheep. Such grasses may be cut and stored for later feeding, especially for the winter, in the form of bales of hay or straw, or in silos as silage. Straw (and sometimes hay) may also be used as bedding for animals.\nAn example of a sod-forming perennial grass used in agriculture is \"Thinopyrum intermedium\".\nIndustry.\nGrasses are used as raw material for a multitude of purposes, including construction and in the composition of building materials such as cob, for insulation, in the manufacture of paper and board such as oriented structural straw board. Grass fiber can be used for making paper, biofuel production, nonwoven fabrics, and as replacement for glass fibers used in reinforced plastics. Bamboo scaffolding is able to withstand typhoon-force winds that would break steel scaffolding. Larger bamboos and \"Arundo donax\" have stout culms that can be used in a manner similar to timber, \"Arundo\" is used to make reeds for woodwind instruments, and bamboo is used for innumerable implements.\n'Phragmites australis' (common reed) is important for thatching and wall construction of homes in Africa. Grasses are used in water treatment systems, in wetland conservation and land reclamation, and used to lessen the erosional impact of urban storm water runoff.\nPalaeoecological reconstructions.\nPollen morphology, particularly in the \"Poaceae\" family, is key to figuring out their evolutionary relationships and how environments have changed over time. Grass pollen grains, however, often look the same, making it hard to use them for detailed climate or environmental reconstructions. Grass pollen has a single pore and can vary a lot in size, from about 20 to over 100 micrometers, and this size difference has been looked into for clues about past habitats, to tell apart domesticated grasses from wild ones, and to indicate various biological features like how they perform photosynthesis, their breeding systems, and genetic complexity. Yet, there's ongoing debate about how effective pollen size is for piecing together historical landscapes and weather patterns, considering other factors such as genetic material amount might also affect pollen size. Despite these challenges, new techniques in Fourier-Transform Infrared Spectroscopy and improved statistical methods are now helping to better identify these similar-looking pollen types.\nLawn and ornamental use.\nGrasses are the primary plants used in lawns, which themselves derive from grazed grasslands in Europe. They also provide an important means of erosion control (e.g. along roadsides), especially on sloping land. Grass lawns are an important covering of playing surfaces in many sports, including football (soccer), American football, tennis, golf, cricket, softball and baseball.\nOrnamental grasses, such as perennial bunch grasses, are used in many styles of garden design for their foliage, inflorescences and seed heads. They are often used in natural landscaping, xeriscaping and slope and beach stabilization in contemporary landscaping, wildlife gardening, and native plant gardening. They are used as screens and hedges.\nSports turf.\nGrass playing fields, courses and pitches are the traditional playing surfaces for many sports, including American football, association football, baseball, cricket, golf, and rugby. Grass surfaces are also sometimes used for horse racing and tennis. Type of maintenance and species of grass used may be important factors for some sports, less critical for others. In some sports facilities, including indoor domes and other places where maintenance of a grass field would be difficult, grass may be replaced with artificial turf, a synthetic grass-like substitute.\nCricket.\nIn cricket, the pitch is the strip of carefully mowed and rolled grass where the bowler bowls. In the days leading up to the match it is repeatedly mowed and rolled to produce a very hard, flat surface for the ball to bounce off.\nGolf.\nGrass on golf courses is kept in three distinct conditions: that of the \"rough\", the \"fairway\", and the \"putting green\". Grass on the fairway is mown short and even, allowing the player to strike the ball cleanly. Playing from the rough is a disadvantage because the long grass may affect the flight of the ball. Grass on the putting green is the shortest and most even, ideally allowing the ball to roll smoothly over the surface. An entire industry revolves around the development and marketing of turf grass varieties.\nTennis.\nIn tennis, grass is grown on very hard-packed soil, and the bounce of a tennis ball may vary depending on the grass's health, how recently it has been mowed, and the wear and tear of recent play. The surface is softer than hard courts and clay (other tennis surfaces), so the ball bounces lower, and players must reach the ball faster resulting in a different style of play which may suit some players more than others. Among the world's most prestigious court for grass tennis is Centre Court at Wimbledon, London, which hosts the final of the annual Wimbledon Championships in England, one of the four Grand Slam tournaments.\nEconomically important grasses.\nA number of grasses are invasive species that damage natural ecosystems, including forms of \"Phragmites australis\" which are native to Eurasia but has spread around the world.\nRole in society.\nGrasses have long had significance in human society. They have been cultivated as feed for people and domesticated animals for thousands of years. The primary ingredient of beer is usually barley or wheat, each of which has been used for this purpose for over 4,000 years.\nIn some places, particularly in suburban areas, the maintenance of a grass lawn is a sign of a homeowner's responsibility to the overall appearance of their neighborhood. One work credits lawn maintenance to:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...the desire for upward mobility and its manifestation in the lawn. As Virginia Jenkins, author of \"The Lawn\", put it quite bluntly, \"Upper middle-class Americans emulated aristocratic society with their own small, semi-rural estates.\" In general, the lawn was one of the primary selling points of these new suburban homes, as it shifted social class designations from the equity and ubiquity of urban homes connected to the streets with the upper-middle class designation of a \"healthy\" green space and the status symbol that is the front lawn.\nIn communities with drought problems, watering of lawns may be restricted to certain times of day or days of the week. Many US municipalities and homeowners' associations have rules that require lawns to be maintained to certain specifications, sanctioning those who allow the grass to grow too long.\nThe smell of freshly cut grass is produced mainly by cis-3-Hexenal.\nSome common aphorisms involve grass. For example:\nA folk myth about grass is that it refuses to grow where any violent death has occurred.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56220", "revid": "44106950", "url": "https://en.wikipedia.org/wiki?curid=56220", "title": "Anti-Semitic", "text": ""}
{"id": "56223", "revid": "44328505", "url": "https://en.wikipedia.org/wiki?curid=56223", "title": "Piltdown Man", "text": "1912 paleoanthropological hoax\nThe Piltdown Man was a paleoanthropological fraud in which bone fragments were presented as the fossilised remains of a previously unknown early human. Although there were doubts about its authenticity virtually from its announcement in 1912, the remains were still broadly accepted for many years, and the falsity of the hoax was only definitively demonstrated in 1953. An extensive scientific review in 2016 established that amateur archaeologist Charles Dawson was responsible for the fraudulent evidence.. Charles Dawson's motivations for his archaeological finds was to gain recognition from other members in the archaeological community.\nIn 1912, Dawson claimed that he had discovered the \"missing link\" between early apes and man. If the Piltdown Man was found to be legit, it would have been a crucial transitional form between the two species. In February 1912, Dawson contacted Arthur Smith Woodward, Keeper of Geology at the Natural History Museum, stating he had found a section of a human-like skull in Pleistocene gravel beds near Piltdown, East Sussex. The find of the Piltdown Man, and the claims that Dawson was making were taken seriously due to Dawson's reputation in the archaeology community and for other local archaeological \"discoveries\". These \"discoveries\" were later found to also be false. That summer, Dawson and Woodward purportedly discovered more bones and artifacts at the site, which they connected to the same individual. These finds included a jawbone, more skull fragments, a set of teeth, and primitive tools. The fragments of the cranium that Dawson had originally found had human like features, where as the lower jawbone that they found had resembled a jawbone of an ape. He also claimed that the stone tools and animal fossils were found in the same layer of Earth that the cranium and jawbone were found. These finds appeared to support a Eurocentric model of human evolution. The Eurocentric model says that early human evolution started in Britain instead of Africa. This model was popular at the time due to the colonial assumptions that the European ancestry was superior to other races. Dawson used specific fossils to make it appear this way. There was a lot of debate around if humans developed their brains first or if they developed as bipedal first. The fossils also fit the hypothesis at the time, that the brain developed first. Then due to the brain growth other aspects of human evolution happened. The belief in Piltdown Man and his large brain caused this hypothesis to perpetuate in the anthropology field for many decades.\nWoodward reconstructed the skull fragments and hypothesised that they belonged to a human ancestor from 500,000 years ago. The discovery was announced at a Geological Society meeting and was given the Latin name \"Eoanthropus dawsoni\" (\"Dawson's dawn-man\"). Fossil evidence at the time was not very complete, and evolutionary theory still was lacking a full coherent fossil record to support human evolution. Although evolutionary theory was being increasingly accepted. The questionable significance of the assemblage remained the subject of considerable controversy until it was conclusively exposed in 1953 as a forgery. It was found to have consisted of the altered mandible and some teeth of an orangutan deliberately combined with the cranium of a fully developed, though small-brained, modern human.\nThe Piltdown hoax is prominent for two reasons: the attention it generated around the subject of human evolution, and the length of time \u2013 41 years \u2013 that elapsed from its alleged initial discovery to its definitive exposure as a composite forgery. The Piltdown Man shows how science can be shaped by cultural expectations, as well as confirmation bias. Piltdown Man affected the public's understanding of human evolution for many generations. It was used as a standard reference for decades and was used as a representation in textbooks, museums, and other forms of media.\nFind.\nAt a meeting of the Geological Society of London on 18 December 1912, Charles Dawson claimed that a workman at the Piltdown gravel pit had given him a fragment of the skull four years earlier. According to Dawson, workmen at the site discovered the skull shortly before his visit and broke it up in the belief that it was a fossilised coconut. Revisiting the site on several occasions, Dawson found further fragments of the skull and took them to Arthur Smith Woodward, keeper of the geological department at the British Museum. Greatly interested by the finds, Woodward accompanied Dawson to the site. Though the two worked together between June and September 1912, Dawson alone recovered more skull fragments and half of the lower jaw. The skull unearthed in 1908 was the only find discovered in situ, with most of the other pieces found in the gravel pit's spoil heaps. French Jesuit paleontologist and geologist Pierre Teilhard de Chardin participated in the uncovering of the Piltdown skull with Woodward.\nAt the same meeting, Woodward announced that a reconstruction of the fragments indicated that the skull was in many ways similar to that of a modern human, except for the occiput (the part of the skull that sits on the spinal column), and brain size, which was about two-thirds that of a modern human. He went on to indicate that, save for two human-like molar teeth, the jaw bone was indistinguishable from that of a modern, young chimpanzee. From the British Museum's reconstruction of the skull, Woodward proposed that Piltdown Man represented an evolutionary missing link between apes and humans, since the combination of a human-like cranium with an ape-like jaw tended to support the notion then prevailing in England that human evolution began with the brain.\n The find was considered legitimate by Otto Schoetensack who had discovered the Heidelberg fossils just a few years earlier; he described it as being the best evidence for an ape-like ancestor of modern humans. Almost from the outset, Woodward's reconstruction of the Piltdown fragments was strongly challenged by some researchers. At the Royal College of Surgeons, copies of the same fragments used by the British Museum in their reconstruction were used to produce an entirely different model, one that in brain size and other features resembled a modern human. This reconstruction, by Arthur Keith, was called \"Homo piltdownensis\" in reflection of its more human appearance. \nWoodward's reconstruction included ape-like canine teeth, which was itself controversial. In August 1913, Woodward, Dawson and Teilhard de Chardin began a systematic search of the spoil heaps specifically to find the missing canines. Teilhard de Chardin soon found a canine that, according to Woodward, fitted the jaw perfectly. A few days later, Teilhard de Chardin moved to France and took no further part in the discoveries. Noting that the tooth \"corresponds exactly with that of an ape\", Woodward expected the find to end any dispute over his reconstruction of the skull. However, Keith attacked the find. Keith pointed out that human molars are the result of side to side movement when chewing. The canine in the Piltdown jaw was impossible as it prevented side to side movement. To explain the wear on the molar teeth, the canine could not have been any higher than the molars. Grafton Elliot Smith, a fellow anthropologist, sided with Woodward, and at the next Royal Society meeting claimed that Keith's opposition was motivated entirely by ambition. Keith later recalled, \"Such was the end of our long friendship.\"\nAs early as 1913, David Waterston of King's College London published in \"Nature\" his conclusion that the sample consisted of an ape mandible and human skull. Likewise, French paleontologist Marcellin Boule concluded the same in 1915. A third opinion from the American zoologist Gerrit Smith Miller Jr. concluded that Piltdown's jaw came from a fossil ape. In 1923, Franz Weidenreich examined the remains and correctly reported that they consisted of a modern human cranium and an orangutan jaw with filed-down teeth.\nSheffield Park find.\nIn 1915, Dawson claimed to have found three fragments of a second skull (Piltdown II) at a new site about away from the original finds. Woodward attempted several times to elicit the location from Dawson, but was unsuccessful. So far as is known, the site was never identified and the finds appear largely undocumented. Woodward did not present the new finds to the Society until five months after Dawson's death in August 1916 and deliberately implied that he knew where they had been found. Found at the new site was a portion of a frontal bone, an occipital fragment, and a lower first molar tooth. They were believed to belong to a different individual of the same species as the original find. In 1921, Henry Fairfield Osborn, President of the American Museum of Natural History, examined the Piltdown and Sheffield Park finds and declared that the jaw and skull belonged together \"without question\" and that the Sheffield Park fragments \"were exactly those which we should have selected to confirm the comparison with the original type.\"\nThe Sheffield Park finds were taken as proof of the authenticity of the Piltdown Man, it was intended to suggest that the original find was not a one off fluke but a real association. But in reality it may have been chance that brought an ape's jaw and a human skull together, but the odds of it happening twice were slim. Even Keith conceded to this new evidence, though he still harboured personal doubts. The Sheffield Park finds changed the narrative from a strange and isolated find to the establishment of a population with multiple individuals. \nMemorial.\nOn 23 July 1938, at Barkham Manor, Piltdown, Sir Arthur Keith unveiled a memorial to mark the site where Piltdown Man was discovered by Charles Dawson. The memorial was put in place to celebrate the important moment in paleoanthropology that Piltdown man was thought to be. Once the fraud was debunked the memorial's symbolic meaning got lost and today there are very few things that point to the town ever being an important archaeological site. Sir Arthur finished his speech saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;So long as man is interested in his long past history, in the vicissitudes which our early forerunners passed through, and the varying fare which overtook them, the name of Charles Dawson is certain of remembrance. We do well to link his name to this picturesque corner of Sussex\u2014the scene of his discovery. I have now the honour of unveiling this monolith dedicated to his memory.\nThe inscription on the memorial stone reads:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Here in the old river gravel Mr Charles Dawson, FSA found the fossil skull of Piltdown Man, 1912\u20131913, The discovery was described by Mr Charles Dawson and Sir Arthur Smith Woodward, \"Quarterly Journal of the Geological Society\", 1913\u201315.\nExposure.\nScientific investigation.\nFrom the outset, some scientists expressed scepticism about the Piltdown find (see above). Gerrit Smith Miller Jr., for example, observed in 1915 that \"deliberate malice could hardly have been more successful than the hazards of deposition in so breaking the fossils as to give free scope to individual judgment in fitting the parts together\". When Dawson first said he discovered the cranium and jawbone there was very little chemical dating techniques. This means that there was a heavy reliance on morphological comparison and expert opinions in order to classify and date artifacts and bones. Discoveries that happened after Piltdown Man like the Australopithecus found in South Africa and the Homo Erectus contradicted many aspects of the Piltdown Man. These early hominid fossils showed small braincases and human jaws, which is the opposite of what Piltdown Man showed. Despite this Piltdown Man was treated as a different lineage for many years. In the decades prior to its exposure as a forgery in 1953, scientists increasingly regarded Piltdown as an enigmatic aberration, inconsistent with the path of hominid evolution as demonstrated by fossils found elsewhere.\nIn the early 1950's scientist at the British Museum, Kenneth Oakly, J.S. Weiner, and W.E. Le Gros Clark created a new technique to date the fossils. This method was called fluorine absorption tests. Fluorine absorption dating opened the possibility of reexamining and dating old finds to get a more precise date of when they were from. This new technique found that there was very little carbon in either the Piltdown skull or the jaw. This test concluded that because of the very little carbon the fossils are geologically recent and not the hundreds of thousands of years old that Dawson was claiming that they were. On top of the fossils not being very old, the skull and jawbone returned two different amounts of carbon, meaning that they are not the same age. After more testing on the bones, they found that there were anatomical differences between the jaw and cranial bone. It was found that the cranial bone and the jaw came from different species. They also found that the dental wear patterns were incompatible with human chewing. \nIn November 1953, \"Time\" magazine published evidence, gathered variously by Kenneth Page Oakley, Sir Wilfrid Edward Le Gros Clark and Joseph Weiner, proving that Piltdown Man was a forgery and demonstrating that the fossil was a composite of three distinct species. It consisted of a human skull of medieval age, the 500-year-old lower jaw of an orangutan and chimpanzee fossil teeth. Someone had created the appearance of age by staining the bones with an iron solution and chromic acid. Microscopic examination revealed file-marks on the teeth, and it was deduced from this that someone had modified the teeth to a shape more suited to a human diet. The article caused the immediate removal of Piltdown Man from all evolutionary charts, as the scientific community reevaluated human evolutionary history. The debunking of the Piltdown Man lead to a full on forgery investigation into the other bones and artifacts that Dawson had claimed to find in the past.\nThe Piltdown Man hoax succeeded so well because, at the time of its discovery, the scientific establishment believed that the large modern brain preceded the modern omnivorous diet, and the forgery provided exactly that evidence. Many scientist were discouraged from giving criticism because of Dawson's prestige and connections within the field. In the 1900's, science was mainly driven by the prestige of the certain scientists that made the discovery. Many scientist were also looking at casts instead of the real bones, this made it more difficult for them to see telltale signs of forgery. Confirmation bias caused scientist to adjust models instead of dismissing discrepancies. Stephen Jay Gould argued that nationalism and cultural prejudice played a role in the ready acceptance of Piltdown Man as genuine, because it satisfied European expectations that the earliest humans would be found in Eurasia, and the British in particular wanted a \"first Briton\" to set against fossil hominids found elsewhere in Europe.. By the late 1940's, after many advances in dating technology and acceptance of African hominid fossils, many paleoanthropologist regarded Piltdown Man as misinterpreted.\nIdentity of the forger.\nThe identity of the Piltdown forger remains unknown, but suspects have included Dawson, Pierre Teilhard de Chardin, Arthur Keith, Martin A. C. Hinton, Horace de Vere Cole and Arthur Conan Doyle.\nThe focus on Dawson as the main forger is supported by the accumulation of evidence regarding other archaeological hoaxes he perpetrated in the decade or two before the Piltdown discovery. The archaeologist Miles Russell of Bournemouth University analysed Dawson's antiquarian collection, and determined that at least 38 of his specimens were fakes. Among these were the teeth of a multituberculate mammal, \"Plagiaulax dawsoni\", \"found\" in 1891 (and whose teeth had been filed down in the same way that the teeth of Piltdown Man were to be some 20 years later); the so-called \"shadow figures\" on the walls of Hastings Castle; a unique hafted stone axe; the Bexhill boat (a hybrid seafaring vessel); the Pevensey bricks (allegedly the latest datable \"finds\" from Roman Britain); the contents of the Lavant Caves (a fraudulent \"flint mine\"); the Beauport Park \"Roman\" statuette (a hybrid iron object); the Bulverhythe Hammer (shaped with an iron knife in the same way as the Piltdown elephant bone implement would later be); a fraudulent \"Chinese\" bronze vase; the Brighton \"Toad in the Hole\" (a toad entombed within a flint nodule); the English Channel sea serpent; the Uckfield Horseshoe (another hybrid iron object) and the Lewes Prick Spur. Of his antiquarian publications, most demonstrate evidence of plagiarism or at least naive referencing. Russell wrote: \"Piltdown was not a 'one-off' hoax, more the culmination of a life's work.\" In addition, Harry Morris, an acquaintance of Dawson, had come into possession of one of the flints obtained by Dawson at the Piltdown gravel pit. He suspected that it had been artificially aged \u2013 \"stained by C. Dawson with intent to defraud\". He remained deeply suspicious of Dawson for many years to come, though he never sought to discredit him publicly, possibly because it would have been an argument against the eolith theory, which Morris strongly supported.\nAdrian Lister of the UK's Natural History Museum has said that \"some people have suggested\" that there may also have been a second 'fraudster' seeking to use outrageous fraud in the hope of anonymously exposing the original frauds. This was a theory first proposed by Miles Russell. He has explained that the piece nicknamed the 'cricket bat' (a fossilised elephant bone) was such a crudely forged 'early tool' that it may have been planted to cast doubt upon the other finds, the 'Earliest Englishman' in effect being recovered with the earliest evidence for the game of cricket. This seems to have been part of a wider attempt, by disaffected members of the Sussex archaeological community, to expose Dawson's activities, other examples being the obviously fraudulent 'Maresfield Map', the 'Ashburnham Dial', and the 'Piltdown Palaeolith'. Nevertheless, the 'cricket bat' was accepted at the time, even though it aroused the suspicions of some and ultimately helped lead to the eventual recognition of the fraud decades later.\nIn 2016, the results of an eight-year review of the forgery were released, identifying Dawson's modus operandi. Multiple specimens demonstrated the same consistent preparation: application of the stain, packing of crevices with local gravel, and fixation of teeth and gravel with dentist's putty. Analysis of shape and trace DNA showed that teeth from both sites belonged to the same orangutan. The consistent method and common source indicated the work of one person on all the specimens, and Dawson was the only one associated with Piltdown II. The authors did not rule out the possibility that someone else provided the false fossils to Dawson but ruled out several other suspects, including Teilhard de Chardin and Doyle, based on the skill and knowledge demonstrated by the forgeries, which closely reflected ideas fashionable in biology at the time. On the other hand, Stephen Jay Gould judged that Pierre Teilhard de Chardin conspired with Dawson in the Piltdown forgery. Teilhard de Chardin had travelled to regions of Africa where one of the anomalous finds originated, and resided in the Wealden area from the date of the earliest finds (although others suggest that he was \"without doubt innocent in this matter\"). Hinton left a trunk in storage at the Natural History Museum in London that in 1970 was found to contain animal bones and teeth carved and stained in a manner similar to the carving and staining on the Piltdown finds. Phillip Tobias implicated Arthur Keith in helping Dawson by detailing the history of the investigation of the hoax, dismissing other theories, and listing inconsistencies in Keith's statements and actions. Other investigations suggest that the hoax involved accomplices rather than a single forger.\nRichard Milner, an American historian of science, argued that Arthur Conan Doyle may have been the perpetrator of the Piltdown Man hoax. Milner noted that Doyle had a plausible motive\u2014namely, revenge on the scientific establishment for debunking one of his favourite psychics\u2014and said that \"The Lost World\" appeared to contain several clues referring cryptically to his having been involved in the hoax. Samuel Rosenberg's 1974 book \"Naked is the Best Disguise\" purports to explain how, throughout his writings, Doyle had provided overt clues to otherwise hidden or suppressed aspects of his way of thinking that seemed to support the idea that Doyle would be involved in such a hoax. More recent research suggests that Doyle was not involved. In 2016, researchers at the Natural History Museum and Liverpool John Moores University analyzed DNA evidence showing that responsibility for the hoax lay with Dawson, who had originally \"found\" the remains. Dawson had initially not been considered the likely perpetrator, because the hoax was seen as being too elaborate for him to have devised; however, the DNA evidence showed that a supposedly ancient tooth Dawson had \"discovered\" in 1915 (at a different site) came from the same jaw as that of the Piltdown Man, suggesting that he had planted them both. That tooth, too, was later proven to have been planted as part of a hoax.\nChris Stringer, an anthropologist from the Natural History Museum, was quoted as saying: \"Conan Doyle was known to play golf at the Piltdown site and had even given Dawson a lift in his car to the area, but he was a public man and very busy[,] and it is very unlikely that he would have had the time [to create the hoax]. So there are some coincidences, but I think they are just coincidences. When you look at the fossil evidence[,] you can only associate Dawson with all the finds, and Dawson was known to be personally ambitious. He wanted professional recognition. He wanted to be a member of the Royal Society and he was after an MBE [sic]. He wanted people to stop seeing him as an amateur\".\nLegacy.\nEarly humans.\nIn 1912, the majority of the scientific community believed the Piltdown Man was the \"missing link\" between apes and humans. The Piltdown man delayed the correct understanding of human evolution for many years. However, over time the Piltdown Man lost its validity, as other discoveries such as the Taung Child and Peking Man were made. R. W. Ehrich and G. M. Henderson note, \"To those who are not completely disillusioned by the work of their predecessors, the disqualification of the Piltdown skull changes little in the broad evolutionary pattern. The validity of the specimen has always been questioned\". Eventually, during the 1940s and 1950s, more advanced dating technologies, such as the fluorine absorption test, proved scientifically that this skull was actually a fraud.\nInfluence.\nThe Piltdown Man fraud significantly affected early research on human evolution. Notably, it led scientists down a blind alley in the belief that the human brain expanded in size before the jaw adapted to new types of food. Discoveries of Australopithecine fossils such as the Taung child found by Raymond Dart during the 1920s in South Africa were ignored because of the support for Piltdown Man as \"the missing link,\" and the reconstruction of human evolution was confused for decades. The examination and debate over Piltdown Man caused a vast expenditure of time and effort on the fossil, with an estimated 250+ papers written on the topic.. The myth of the Piltdown man created a scientific atmosphere that required more rigorous dating and testing in order for claims made by scientist to be believed. There was also an increase in the transparency of research being done, as well as research being peer reviewed. \nThe book \"\" by L. Ron Hubbard features the Piltdown Man as a phase of biological history capable of leaving a person with subconscious memories of traumatic incidents that can only be resolved by use of Scientology technology. Recovered \"memories\" of this phase are prompted by one's obsession with biting, hiding the teeth or mouth, and early familial issues. Nominally, this appears to be related to the large jaw of the Piltdown Man specimen. The book was first published in 1952, shortly before the fraud was confirmed, and has since been republished 5 times (most recently in 2007).\nCreationists often cite the hoax (along with Nebraska Man) as evidence of an alleged dishonesty of paleontologists who study human evolution, although scientists themselves had exposed the Piltdown hoax (and the Nebraska Man incident was not a deliberate fraud). In November 2003, the Natural History Museum in London held an exhibition to mark the 50th anniversary of the exposure of the fraud.\nThe current day influence of Piltdown Man is the lesson it leaves about the dangers of scientific bias and confirmation bias. It showcases the self correcting nature of science and how new technologies and testing will ultimately falsify wrong assumptions. Piltdown Man is still used in many training programs to talk about responsible conduct in research and preventing fraud in archaeology.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56225", "revid": "12331483", "url": "https://en.wikipedia.org/wiki?curid=56225", "title": "Oersted", "text": "Unit of the auxiliary magnetic field H in the CGS system of units\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nThe oersted (, symbol Oe) is the coherent derived unit of the auxiliary magnetic field H in the CGS-EMU and Gaussian systems of units. It is equivalent to 1 dyne per maxwell.\nDifference between Gaussian and SI systems.\nIn the Gaussian system, the unit of the H-field is the oersted and the unit of the B-field is the gauss. In the SI, the unit ampere per metre (A/m), which is equivalent to newton per weber, is used for the H-field and the unit tesla is used for the B-field.\nHistory.\nThe unit was established by the IEC in the 1930s in honour of Danish physicist Hans Christian \u00d8rsted. \u00d8rsted discovered the connection between magnetism and electric current when a magnetic field produced by a current-carrying copper bar deflected a magnetised needle during a lecture demonstration.\nDefinition.\nThe oersted is defined as a dyne per unit pole. The oersted corresponds to (\u2248) amperes per metre, in terms of SI units.\nThe H-field strength inside a long solenoid wound with 79.58 turns per metre of a wire carrying 1\u00a0A is approximately 1\u00a0oersted. The preceding statement is exactly correct if the solenoid considered is infinite in length with the current evenly distributed over its surface.\nThe oersted is closely related to the gauss (G), the CGS unit of magnetic flux density. In vacuum, if the magnetizing field strength is 1\u00a0Oe, then the magnetic field density is 1\u00a0G, whereas in a medium having permeability \"\u03bc\"r (relative to permeability of vacuum), their relation is\n formula_1\nBecause oersteds are used to measure magnetizing field strength, they are also related to the magnetomotive force (mmf) of current in a single-winding wire-loop:\n formula_2\nStored energy.\nThe stored energy in a magnet, called \"magnet performance\" or \"maximum energy product\" (often abbreviated BHmax), is typically measured in units of megagauss-oersteds (MG\u22c5Oe).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56226", "revid": "199747", "url": "https://en.wikipedia.org/wiki?curid=56226", "title": "Electrum", "text": "Alloy of gold and silver\nElectrum is a naturally occurring alloy of gold and silver, with trace amounts of copper and other metals. Its color ranges from pale to bright yellow, depending on the proportions of gold and silver. It has been produced artificially and is also known as \"green gold\".\nElectrum was used as early as the third millennium BC in the Old Kingdom of Egypt, sometimes as an exterior coating to the pyramidia atop ancient Egyptian pyramids and obelisks. It was also used in the making of ancient drinking vessels. The first known metal coins made were of electrum, dating back to the end of the 7th century or the beginning of the 6th century BC.\nEtymology.\nThe name \"electrum\" is the Latinized form of the ancient Greek word \u1f24\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd (\"\u1e17lektron\"), meaning amber or an alloy of gold and silver. Electrum was often referred to as \"white gold\" in ancient times.\nComposition.\nElectrum consists primarily of gold and silver but is sometimes found with traces of platinum, copper and other metals. The name is mostly applied informally to compositions between 20\u201380% gold and 80\u201320% silver, but these are strictly called gold or silver depending on the dominant element. Analysis of the composition of electrum in ancient Greek coinage dating from about 600 BC shows that the gold content was about 55.5% in the coinage issued by Phocaea. In the early classical period the gold content of electrum ranged from 46% in Phocaea to 43% in Mytilene. In later coinage from these areas, dating to 326 BC, the gold content averaged 40% to 41%. In the Hellenistic period electrum coins with a regularly decreasing proportion of gold were issued by the Carthaginians. In the later Eastern Roman Empire controlled from Constantinople, the purity of the gold coinage was reduced.\nHistory.\nElectrum is mentioned in an account of an expedition sent by Pharaoh Sahure of the Fifth Dynasty of Egypt. It is also discussed by Pliny the Elder in his \"Naturalis Historia\". \nEarly coinage.\nThe earliest known electrum coins, Lydian coins and East Greek coins found under the Temple of Artemis at Ephesus, are currently dated to the last quarter of the 7th century BC (625\u2013600 BC). Electrum is believed to have been used in coins c. 600 BC in Lydia during the reign of Alyattes.\nElectrum was much better for coinage than gold, mostly because it was harder and more durable, but also because techniques for refining gold were not widespread at the time. The gold content of naturally occurring electrum in modern western Anatolia ranges from 70% to 90%, in contrast to the 45\u201355% of gold in electrum used in ancient Lydian coinage of the same geographical area. This suggests that the Lydians had already solved the refining technology for silver and were adding refined silver to the local native electrum some decades before introducing pure silver coins.\nIn Lydia, electrum was minted into coins weighing , each valued at &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20443 \"stater\" (meaning \"standard\"). Three of these coins\u2014with a weight of about \u2014totaled one stater, about one month's pay for a soldier. To complement the stater, fractions were made: the \"trite\" (third), the \"hekte\" (sixth), and so forth, including &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204424 of a stater, and even down to &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204448 and &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204496 of a stater. The &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204496 stater was about to . Larger denominations, such as a one stater coin, were minted as well.\nBecause of variation in the composition of electrum, it was difficult to determine the exact worth of each coin. Widespread trading was hampered by this problem, as the intrinsic value of each electrum coin could not be easily determined. This suggests that one reason for the invention of coinage in that area was to increase the profits from seigniorage by issuing currency with a lower gold content than the commonly circulating metal.\nThese difficulties were eliminated circa 570 BC when the Croeseids, coins of pure gold and silver, were introduced. However, electrum currency remained common until approximately 350 BC. The simplest reason for this was that, because of the gold content, one 14.1\u00a0gram stater was worth as much as ten 14.1\u00a0gram silver pieces.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56227", "revid": "50884117", "url": "https://en.wikipedia.org/wiki?curid=56227", "title": "Skin tag", "text": "Small benign skin tumor\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nA skin tag, or acrochordon (pl.: acrochorda), is a small benign tumor that forms primarily in areas where the skin forms creases (or rubs together), such as the neck, armpit and groin. They may also occur on the face, usually on the eyelids. Though tags up to long have been seen, they are typically the size of a grain of rice. The surface of an acrochordon may be smooth or irregular in appearance and is often raised from the surface of the skin on a fleshy stalk called a peduncle. Microscopically, an acrochordon consists of a fibrovascular core, sometimes also with fat cells, covered by an unremarkable epidermis. However, tags may become irritated by shaving, clothing, jewelry, or dermatitis.\nEtiology.\nSkin tags are thought to occur from skin rubbing against skin, since they are often found in skin creases and folds. Studies have shown existence of low-risk human papillomaviruses 6 and 11 in skin tags, hinting at a possible role in their pathogenesis, although a 2012 study found no association between skin tags and either low- or high-risk HPV. Acrochorda have been reported to have a prevalence of 46% in the general population. A causal genetic component is thought to exist. There is no link between acrochorda and gender. They were once thought to be associated with colorectal polyps, but studies have shown no such connection exists. Rarely, they can be associated with Birt\u2013Hogg\u2013Dub\u00e9 syndrome, acromegaly, or polycystic ovary syndrome.\nElevated blood sugar and insulin are linked to an increased incidence of skin tags through an unknown mechanism.\nTreatment.\nRemoval, if desired or warranted, can be done by a dermatologist, a general practitioner, or a similarly trained professional who may use cauterization, cryosurgery, excision, laser, or surgical ligation to remove the acrochorda. Varied home remedies are unsupported by medical evidence.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56228", "revid": "44487672", "url": "https://en.wikipedia.org/wiki?curid=56228", "title": "Dairy", "text": "Place where milk is stored and where butter and cheese are made or sold\nA dairy is a place where milk is stored and where butter, cheese, and other dairy products are made, or a place where those products are sold.325284 It may be a room, a building, or a larger establishment.284 In the United States, the word may also describe a dairy farm or the part of a mixed farm dedicated to milk for human consumption,284 whether from cows, buffaloes, goats, yaks, sheep, horses or camels.\nThe attributive \"dairy\" describes milk-based products, derivatives, and processes, and the animals and workers involved in their production, for example dairyman, dairymaid, dairy cattle or dairy goat. A dairy farm produces milk and a dairy factory processes it into a variety of dairy products. These establishments constitute the global dairy industry, part of the food industry.\nThe word \"dairy\" comes from an Old English word for \"female servant\", as milking was historically done by dairymaids.\nTerminology.\nTerminology differs between countries. In the United States, for example, an entire dairy farm is commonly called a \"dairy\". The building or farm area where milk is harvested from the cow is often called a \"milking parlor\" or \"parlor\", except in the case of smaller dairies, where cows are often put on pasture, and usually milked in \"stanchion barns\". The farm area where milk is stored in bulk tanks is known as the farm's \"milk house\". Milk is then hauled (usually by truck) to a \"dairy plant\", also referred to as a \"dairy\", where raw milk is further processed and prepared for commercial sale of dairy products.\nIn New Zealand, farm areas for milk harvesting are also called \"milking parlours\", and are historically known as \"milking sheds\". As in the United States, sometimes milking sheds are referred to by their type, such as \"herring bone shed\" or \"pit parlour\". Parlour design has evolved from simple barns or sheds to large rotary structures in which the workflow (throughput of cows) is very efficiently handled. In some countries, especially those with small numbers of animals being milked, the farm may perform the functions of a dairy plant, processing their own milk into saleable dairy products, such as butter, cheese, or yogurt. This on-site processing is a traditional method of producing specialist milk products, common in Europe.\nIn the United States a \"dairy\" can also be a place that processes, distributes and sells dairy products, or a room, building or establishment where milk is stored and processed into milk products, such as butter or cheese. In New Zealand English the singular use of the word \"dairy\" almost exclusively refers to a corner shop, or superette. This usage is historical as such shops were a common place for the public to buy milk products.\nHistory.\nMilk producing animals have been domesticated for thousands of years. Initially, they were part of the subsistence farming that nomads engaged in. As the community moved about the country, their animals accompanied them. Protecting and feeding the animals were a major part of the symbiotic relationship between the animals and the herders.\nIn the more recent past, people in agricultural societies owned dairy animals that they milked for domestic and local (village) consumption, a typical example of a cottage industry. The animals might serve multiple purposes (for example, as a draught animal for pulling a plow as a youngster, and at the end of its useful life as meat). In this case, the animals were normally milked by hand and the herd size was quite small, so that all of the animals could be milked in less than an hour\u2014about 10 per milker. These tasks were performed by a \"dairymaid\" (\"dairywoman\") or \"dairyman\". The word \"dairy\" harkens back to Middle English \"dayerie\", \"deyerie\", from \"deye\" (female servant or dairymaid) and further back to Old English \"d\u00e6ge\" (kneader of bread).\nWith industrialisation and urbanisation, the supply of milk became a commercial industry, with specialised breeds of cattle being developed for dairy, as distinct from beef or draught animals. Initially, more people were employed as milkers, but it soon turned to mechanisation with machines designed to do the milking.\nHistorically, the milking and the processing took place close together in space and time: on a dairy farm. People milked the animals by hand; on farms where only small numbers are kept, hand-milking may still be practised. Hand-milking is accomplished by grasping the teats (often pronounced \"tit\" or \"tits\") in the hand and expressing milk either by squeezing the fingers progressively, from the udder end to the tip, or by squeezing the teat between thumb and index finger, then moving the hand downward from udder towards the end of the teat. The action of the hand or fingers is designed to close off the milk duct at the udder (upper) end and, by the movement of the fingers, close the duct progressively to the tip to express the trapped milk. Each half or quarter of the udder is emptied one milk-duct capacity at a time.\nThe \"stripping\" action is repeated, using both hands for speed. Both methods result in the milk that was trapped in the milk duct being squirted out the end into a bucket that is supported between the knees (or rests on the ground) of the milker, who usually sits on a low stool.\nTraditionally the cow, or cows, would stand in the field or paddock while being milked. Young stock, heifers, would have to be trained to remain still to be milked. In many countries, the cows were tethered to a post and milked.\nStructure of the industry.\nWhile most countries produce their own milk products, the structure of the dairy industry varies in different parts of the world. In major milk-producing countries most milk is distributed through whole sale markets. In Ireland and Australia, for example, farmers' co-operatives own many of the large-scale processors, while in the United States many farmers and processors do business through individual contracts. In the United States, the country's 196 farmers' cooperatives sold 86% of milk in the U.S. in 2002, with five cooperatives accounting for half that. This was down from 2,300 cooperatives in the 1940s. In developing countries, the past practice of farmers marketing milk in their own neighbourhoods is changing rapidly. Notable developments include considerable foreign investment in the dairy industry and a growing role for dairy cooperatives. Output of milk is growing rapidly in such countries and presents a major source of income growth for many farmers.\nAs in many other branches of the food industry, dairy processing in the major dairy producing countries has become increasingly concentrated, with fewer but larger and more efficient plants operated by fewer workers. This is notably the case in the United States, Europe, Australia and New Zealand. In 2009, charges of antitrust violations have been made against major dairy industry players in the United States, which critics call \"Big Milk\". Another round of price fixing charges was settled in 2016.\nGovernment intervention in milk markets was common in the 20th century. A limited antitrust exemption was created for U.S. dairy cooperatives by the Capper\u2013Volstead Act of 1922. In the 1930s, some U.S. states adopted price controls, and Federal Milk Marketing Orders started under the Agricultural Marketing Agreement Act of 1937 and continue in the 2000s. The Federal Milk Price Support Program began in 1949. The Northeast Dairy Compact regulated wholesale milk prices in New England from 1997 to 2001.\nPlants producing liquid milk and products with short shelf life, such as yogurts, creams and soft cheeses, tend to be located on the outskirts of urban centres close to consumer markets. Plants manufacturing items with longer shelf life, such as butter, milk powders, cheese and whey powders, tend to be situated in rural areas closer to the milk supply. Most large processing plants tend to specialise in a limited range of products. Exceptionally, however, large plants producing a wide range of products are still common in Eastern Europe, a holdover from the former centralised, supply-driven concept of the market under Communist governments.\nAs processing plants grow fewer and larger, they tend to acquire bigger, more automated and more efficient equipment. While this technological tendency keeps manufacturing costs lower, the need for long-distance transportation often increases the environmental impact.\nMilk production is irregular, depending on cow biology. Producers must adjust the mix of milk which is sold in liquid form vs. processed foods (such as butter and cheese) depending on changing supply and demand.\nMilk supply contracts.\nIn the European Union, milk supply contracts are regulated by Article 148 of Regulation 1308/2013 \u2013 \"Establishing a common organisation of the markets in agricultural products and repealing Council Regulations (EEC) No 922/72, (EEC) No 234/79, (EC) No 1037/2001 and (EC) No 1234/2007\", which permits member states to create a requirement for the supply of milk from a farmer to a raw milk processor to be backed by a written contract, or to ensure that the first purchaser of milk to make a written offer to the farmer, although in this case the farmer may not be required to enter into a contract. Thirteen EU member states including France and Spain have introduced laws on compulsory or mandatory written milk contracts (MWC's) between farmers and processors. \nIn the UK, a voluntary code of best practice on contractual relationships in the dairy sector was agreed by industry during 2012: this set out minimum standards of good practice for contracts between producers and purchasers. The Scottish Government published an analysis of the dairy supply chain and the application of mandatory written contracts across the European Union in 2019, to evaluate the impact of the contracts where they have been adopted. During 2020 the UK government undertook a consultation exercise to determine which contractual measures, if any, would improve the resilience of the dairy industry for the future. Contracts for the delivery of raw milk are now negotiated by groups of farmers, who operate together as recognised Dairy Producer Organisations (DPOs) to agree terms with milk processors on behalf of their members. A recognised DPO must be an independent legal entity (or part of one) and include \"at least 10 dairy producers (all of them must be separate legal entities) or produce 6 million litres a year (2 producers needed), or both\".\nThe Australian government has also introduced a mandatory dairy code of conduct.\nFarming.\nWhen it became necessary to milk larger cows, the cows would be brought to a shed or barn that was set up with stalls (milking stalls) where the cows could be confined their whole life while they were milked. One person could milk more cows this way, as many as 20 for a skilled worker. But having cows standing about in the yard and shed waiting to be milked is not good for the cow, as she needs as much time in the paddock grazing as is possible. It is usual to restrict the twice-daily milking to a maximum of an hour and a half each time. It makes no difference whether one milks 10 or 1000 cows, the milking time should not exceed a total of about three hours each day for any cow as they should be in stalls and laying down as long as possible to increase comfort which will in turn aid in milk production. A cow is physically milked for only about 10 minutes a day depending on her milk letdown time and the number of milkings per day.\nAs herd sizes increased there was more need to have efficient milking machines, sheds, milk-storage facilities (vats), bulk-milk transport and shed cleaning capabilities and the means of getting cows from paddock to shed and back.\nAs herd numbers increased so did the problems of animal health. In New Zealand two approaches to this problem have been used. The first was improved veterinary medicines (and the government regulation of the medicines) that the farmer could use. The other was the creation of \"veterinary clubs\" where groups of farmers would employ a veterinarian (vet) full-time and share those services throughout the year. It was in the vet's interest to keep the animals healthy and reduce the number of calls from farmers, rather than to ensure that the farmer needed to call for service and pay regularly.\nThis daily milking routine goes on for about 300 to 320 days per year that the cow stays in milk. Some small herds are milked once a day for about the last 20 days of the production cycle but this is not usual for large herds. If a cow is left unmilked just once she is likely to reduce milk-production almost immediately and the rest of the season may see her \"dried off\" (giving no milk) and still consuming feed. However, once-a-day milking is now being practised more widely in New Zealand for profit and lifestyle reasons. This is effective because the fall in milk yield is at least partially offset by labour and cost savings from milking once per day. This compares to some intensive farm systems in the United States that milk three or more times per day due to higher milk yields per cow and lower marginal labour costs.\nFarmers who are contracted to supply liquid milk for human consumption (as opposed to milk for processing into butter, cheese, and so on\u2014see milk) often have to manage their herd so that the contracted number of cows are in milk the year round, or the required minimum milk output is maintained. This is done by mating cows outside their natural mating time so that the period when each cow in the herd is giving maximum production is in rotation throughout the year.\nNorthern hemisphere farmers who keep cows in barns almost all the year usually manage their herds to give continuous production of milk so that they get paid all year round. In the southern hemisphere the cooperative dairying systems allow for two months of no productivity because their systems are designed to take advantage of maximum grass and milk production in the spring and because the milk processing plants pay bonuses in the dry (winter) season to carry the farmers through the mid-winter break from milking. It also means that cows have a rest from milk production when they are most heavily pregnant. Some year-round milk farms are penalised financially for overproduction at any time in the year by being unable to sell their overproduction at current prices.\nArtificial insemination (AI) is common in all high-production herds in order to improve the genetics of the female offspring which will be raised for replacements. AI also reduces the need for keeping potentially dangerous bulls on the farm. Male calves are sold to be raised for beef or veal, or slaughtered due to lack of profitability. A cow will calve or freshen about once a year, until she is culled because of declining production, infertility or other health problems. Then the cow will be sold, most often going to slaughter.\nIndustrial processing.\nDairy plants process the raw milk they receive from farmers so as to extend its marketable life. Two main types of processes are employed: heat treatment to ensure the safety of milk for human consumption and to lengthen its shelf-life, and dehydrating dairy products such as butter, hard cheese and milk powders so that they can be stored.\nCream and butter.\nToday, milk is separated by huge machines in bulk into cream and skim milk. The cream is processed to produce various consumer products, depending on its thickness, its suitability for culinary uses and consumer demand, which differs from place to place and country to country.\nSome milk is dried and powdered, some is condensed (by evaporation) mixed with varying amounts of sugar and canned. Most cream from New Zealand and Australian factories is made into butter. This is done by churning the cream until the fat globules coagulate and form a monolithic mass. This butter mass is washed and, sometimes, salted to improve keeping qualities. The residual buttermilk goes on to further processing. The butter is packaged (25 to 50\u00a0kg boxes) and chilled for storage and sale. At a later stage these packages are broken down into home-consumption sized packs.\nSkimmed milk.\nThe product left after the cream is removed is called skim, or skimmed, milk. To make a consumable liquid a portion of cream is returned to the skim milk to make \"low fat milk\" (semi-skimmed) for human consumption. By varying the amount of cream returned, producers can make a variety of low-fat milks to suit their local market. Whole milk is also made by adding cream back to the skim to form a standardised product. Other products, such as calcium, vitamin D, and flavouring, are also added to appeal to consumers.\nCasein.\nCasein is the predominant phosphoprotein found in fresh milk. It has a very wide range of uses from being a filler for human foods, such as in ice cream, to the manufacture of products such as fabric, adhesives, and plastics.\nCheese.\nCheese is another product made from milk. Whole milk is reacted to form curds that can be compressed, processed and stored to form cheese. In countries where milk is legally allowed to be processed without pasteurisation, a wide range of cheeses can be made using the bacteria found naturally in the milk. In most other countries, the range of cheeses is smaller and the use of artificial cheese curing is greater. Whey is also the byproduct of this process. Some people with lactose intolerance are able to eat certain types of cheese. This is because some traditionally made hard cheeses, and soft ripened cheeses may create less reaction than the equivalent amount of milk because of the processes involved. Fermentation and higher fat content contribute to lesser amounts of lactose. Traditionally made Emmental or Cheddar might contain 10% of the lactose found in whole milk. In addition, the ageing methods of traditional cheeses (sometimes over two years) reduce their lactose content to practically nothing. Commercial cheeses, however, are often manufactured by processes that do not have the same lactose-reducing properties. Ageing of some cheeses is governed by regulations; in other cases there is no quantitative indication of degree of ageing and concomitant lactose reduction, and lactose content is not usually indicated on labels.\nWhey.\nIn earlier times, whey or milk serum was considered to be a waste product and it was, mostly, fed to pigs as a convenient means of disposal. Beginning about 1950, and mostly since about 1980, lactose and many other products, mainly food additives, are made from both casein and cheese whey.\nYogurt.\nMaking yogurt is similar to making cheese, only the process is stopped before the curd becomes hard.\nMilk powders.\nMilk is also processed by various drying processes into powders. Whole milk, skim milk, buttermilk, and whey products are dried into a powder form and used for human and animal consumption. The main difference between production of powders for human or for animal consumption is in the protection of the process and the product from contamination. Some people drink milk reconstituted from powdered milk, because milk is roughly 88% water, is often cheaper than fresh milk due to lower transportation costs, and can be stored for several months.\nOther milk products.\nKumis is produced commercially in Central Asia. Although traditionally made from mare's milk, modern industrial variants may use cow's milk.\nIn India, which produces 22% of global milk production (as at 2018), a range of traditional milk-based products are produced commercially.\nMilking.\nOriginally, milking and processing took place on the dairy farm itself. Later, cream was separated from the milk by machine on the farm, and transported to a factory to be made into butter. The skim milk was fed to pigs. This allowed for the high cost of transport (taking the smallest volume high-value product), primitive trucks and the poor quality of roads. Only farms close to factories could afford to take whole milk, which was essential for cheesemaking in industrial quantities, to them.\nOriginally milk was distributed in 'pails', a lidded bucket with a handle. These proved impractical for transport by road or rail, and so the milk churn was introduced, based on the tall conical shape of the butter churn. Later large railway containers, such as the British Railway Milk Tank Wagon were introduced, enabling the transport of larger quantities of milk, and over longer distances.\nThe development of refrigeration and better road transport, in the late 1950s, has meant that most farmers milk their cows and only temporarily store the milk in large refrigerated bulk tanks, from where it is later transported by truck to central processing facilities.\nIn many European countries, particularly the United Kingdom, milk is then delivered direct to customers' homes by a milk float.\nIn the United States, a dairy cow produced about of milk per year in 1950, while the average Holstein cow in 2019 produces more than of milk per year.\nMilking machines.\nMilking machines are used to harvest milk from cows when manual milking becomes inefficient or labour-intensive. One early model was patented in 1907. The milking unit is the portion of a milking machine for removing milk from an udder. It is made up of a claw, four teatcups, (Shells and rubber liners) long milk tube, long pulsation tube, and a pulsator. The claw is an assembly that connects the short pulse tubes and short milk tubes from the teatcups to the long pulse tube and long milk tube. (Cluster assembly) Claws are commonly made of stainless steel or plastic or both. Teatcups are composed of a rigid outer shell (stainless steel or plastic) that holds a soft inner liner or \"inflation\". Transparent sections in the shell may allow viewing of liner collapse and milk flow. The annular space between the shell and liner is called the pulse chamber.\nMilking machines work in a way that is different from hand milking or calf suckling. Continuous vacuum is applied inside the soft liner to massage milk from the teat by creating a pressure difference across the teat canal (or opening at the end of the teat). Vacuum also helps keep the machine attached to the cow. The vacuum applied to the teat causes congestion of teat tissues (accumulation of blood and other fluids). Atmospheric air is admitted into the pulsation chamber about once per second (the pulsation rate) to allow the liner to collapse around the end of teat and relieve congestion in the teat tissue. The ratio of the time that the liner is open (milking phase) and closed (rest phase) is called the pulsation ratio.\nThe four streams of milk from the teatcups are usually combined in the claw and transported to the milkline, or the collection bucket (usually sized to the output of one cow) in a single milk hose. Milk is then transported (manually in buckets) or with a combination of airflow and mechanical pump to a central storage vat or bulk tank. Milk is refrigerated on the farm in most countries either by passing through a heat-exchanger or in the bulk tank, or both.\nThe photo to the right shows a bucket milking system with the stainless steel bucket visible on the far side of the cow. The two rigid stainless steel teatcup shells applied to the front two quarters of the udder are visible. The top of the flexible liner is visible at the top of the shells as are the short milk tubes and short pulsation tubes extending from the bottom of the shells to the claw. The bottom of the claw is transparent to allow observation of milk flow. When milking is completed the vacuum to the milking unit is shut off and the teatcups are removed.\nMilking machines keep the milk enclosed and safe from external contamination. The interior 'milk contact' surfaces of the machine are kept clean by a manual or automated washing procedures implemented after milking is completed. Milk contact surfaces must comply with regulations requiring food-grade materials (typically stainless steel and special plastics and rubber compounds) and are easily cleaned.\nMost milking machines are powered by electricity but, in case of electrical failure, there can be an alternative means of motive power, often an internal combustion engine, for the vacuum and milk pumps.\nMilking shed layouts.\nBail-style sheds.\nThis type of milking facility was the first development, after open-paddock milking, for many farmers. The building was a long, narrow, \"lean-to\" shed that was open along one long side. The cows were held in a yard at the open side and when they were about to be milked, they were positioned in one of the bails (stalls). Usually, the cows were restrained in the bail with a breech chain and a rope to restrain the outer back leg. The cow could not move about excessively and the milker could expect not to be kicked or trampled while sitting on a (three-legged) stool and milking into a bucket. When each cow was finished, she backed out into the yard again. The UK bail, initially developed by Wiltshire dairy farmer Arthur Hosier, was a six standing mobile shed with steps that the cow mounted, so the herdsman did not have to bend so low. The milking equipment was much as today, a vacuum from a pump, pulsators, a claw-piece with pipes leading to the four shells and liners that stimulate and suck the milk from the teat. The milk went into churns, via a cooler.\nAs herd sizes increased a door was set into the front of each bail so that when the milking was done for any cow the milker could, after undoing the leg-rope and with a remote link, open the door and allow her to exit to the pasture. The door was closed, the next cow walked into the bail and was secured. When milking machines were introduced bails were set in pairs so that a cow was being milked in one paired bail while the other could be prepared for milking. When one was finished the machine's cups are swapped to the other cow. This is the same as for \"Swingover Milking Parlours\" as described below except that the cups are loaded on the udder from the side. As herd numbers increased it was easier to double-up the cup-sets and milk both cows simultaneously than to increase the number of bails. About 50 cows an hour can be milked in a shed with 8 bails by one person. Using the same teat cups for successive cows has the danger of transmitting infection, mastitis, from one cow to another. Some farmers have devised their own ways to disinfect the clusters between cows.\nHerringbone milking parlours.\nIn herringbone milking sheds, or parlours, cows enter, in single file, and line up almost perpendicular to the central aisle of the milking parlour on both sides of a central pit in which the milker works (you can visualise a fishbone with the ribs representing the cows and the spine being the milker's working area; the cows face outward). After washing the udder and teats the cups of the milking machine are applied to the cows, from the rear of their hind legs, on both sides of the working area. Large herringbone sheds can milk up to 600 cows efficiently with two people.\nSwingover milking parlours.\nSwingover parlours are the same as herringbone parlours except they have only one set of milking cups to be shared between the two rows of cows, as one side is being milked the cows on the other side are moved out and replaced with unmilked ones. The advantage of this system is that it is less costly to equip, however it operates at slightly better than half-speed and one would not normally try to milk more than about 100 cows with one person.\nRotary milking sheds.\nRotary milking sheds (also known as Rotary milking parlor) consist of a turntable with about 12 to 100 individual stalls for cows around the outer edge. A \"good\" rotary will be operated with 24\u201332 (~48\u201350+) stalls by one (two) milkers. The turntable is turned by an electric-motor drive at a rate that one turn is the time for a cow to be milked completely. As an empty stall passes the entrance a cow steps on, facing the center, and rotates with the turntable. The next cow moves into the next vacant stall and so on. The operator, or milker, cleans the teats, attaches the cups and does any other feeding or whatever husbanding operations that are necessary. Cows are milked as the platform rotates. The milker, or an automatic device, removes the milking machine cups and the cow backs out and leaves at an exit just before the entrance. The rotary system is capable of milking very large herds\u2014over a thousand cows.\nAutomatic milking sheds.\nAutomatic milking or 'robotic milking' sheds can be seen in Australia, New Zealand, the U.S., Canada, and many European countries. Current automatic milking sheds use the voluntary milking (VM) method. These allow the cows to voluntarily present themselves for milking at any time of the day or night, although repeat visits may be limited by the farmer through computer software. A robot arm is used to clean teats and apply milking equipment, while automated gates direct cow traffic, eliminating the need for the farmer to be present during the process. The entire process is computer controlled.\nSupplementary accessories in sheds.\nFarmers soon realised that a milking shed was a good place to feed cows supplementary foods that overcame local dietary deficiencies or added to the cows' wellbeing and production. Each bail might have a box into which such feed is delivered as the cow arrives so that she is eating while being milked. A computer can read the eartag of each animal to ration the correct individual supplement. A close alternative is to use 'out-of-parlour-feeders', stalls that respond to a transponder around the cow's neck that is programmed to provide each cow with a supplementary feed, the quantity dependent on her production, stage in lactation, and the benefits of the main ration\nThe holding yard at the entrance of the shed is important as a means of keeping cows moving into the shed. Most yards have a powered gate that ensures that the cows are kept close to the shed.\nWater is a vital commodity on a dairy farm: cows drink about 20 gallons (80 litres) a day, sheds need water to cool and clean them. Pumps and reservoirs are common at milking facilities. Water can be warmed by heat transfer with milk.\nTemporary milk storage.\nMilk from a cow is transported to a nearby storage vessel by the airflow leaking around the cups on the cow or by a special \"air inlet\" (5\u201310 L/min free air) in the claw. From there it is pumped by a mechanical pump and cooled by a heat exchanger. The milk is then stored in a large vat, or bulk tank, which is usually refrigerated until collection for processing.\nWaste disposal and wastewater management.\nIn countries where cows are grazed outside year-round, waste disposal issues need to be dealt with. The most concentrated waste is at the milking shed, where the animal waste may be liquefied (during the water-washing process) or left in a more solid form, either to be returned to be used on farm ground as organic fertiliser.\nIn the associated milk processing factories, most of the waste is washing water that is treated, usually by composting, and spread on farm fields in either liquid or solid form. This is much different from half a century ago, when the main products were butter, cheese and casein, and the rest of the milk had to be disposed of as waste (sometimes as animal feed).\nIn the dairy industries, there are two main types of wastewater produced: dairy wastewater and cheese whey. Dairy wastewater consists of material losses from the dairy products, effluents from the washing of tanks and equipment, and sanitary wastewater from toilets and sinks. The typical concentrations of BOD and total Kjeldahl nitrogen for dairy wastewater range from 1200 to 5000\u00a0mg/L and 30 to 200\u00a0mg/L, respectively. Cheese whey is the liquid remaining after the formation of curds. It contains important amounts of carbohydrates, proteins, lactic acid, fats, and salts and its BOD value can exceed 40,000\u00a0mg/L. Dairy wastewater management usually includes equalisation, neutralisation and physical separation followed by biological treatment, while cheese whey is treated in anaerobic digesters or passes through membranes for protein recovery.\nIn dairy-intensive areas, various methods have been proposed for disposing of large quantities of milk. Large application rates of milk on the land, or disposing in a hole, is problematic as the residue from the decomposing milk will block the soil pores and thereby reduce the water infiltration rate through the soil profile. As recovery of this effect can take time, any land-based application needs to be well managed and considered. Other waste milk disposal methods commonly employed include solidification and disposal at a solid waste landfill, disposal at a wastewater treatment plant, or discharge into a sanitary sewer.\nAssociated diseases.\nDairy products manufactured under unsanitary or unsuitable conditions have an increased chance of containing bacteria. Proper sanitation practices help to reduce the rate of bacterial contamination, and pasteurisation greatly decreases the amount of contaminated milk that reaches the consumer. Many countries have required government oversight and regulations regarding dairy production, including requirements for pasteurisation.\nAnimal rights.\nA portion of the population, including vegans and many Jains, object to dairy production as unethical, cruel to animals, and environmentally deleterious. They do not consume dairy products given these ethical concerns. They state that cattle suffer under conditions employed by the dairy industry and how they are eventually killed for meat once their milk production declines. \nSome animal rights scholars consider dairy as part of what they call the \"animal\u2013industrial complex\". According to Kathleen Stachowski, the animal\u2013industrial complex \"naturalizes the human as a consumer of other animals,\" whose enormity includes \"its long reach into our lives, and how well it has done its job normalizing brutality toward the animals whose very existence is forgotten\". She states that the corporate dairy industry, the government, and schools forms the animal\u2013industrial complex troika of immense influence, which hides from the public's view the animal rights violations and cruelties happening within the dairy industry. Stachowski also states that the troika \"hijacks\" schoolchildren by promoting milk in the K-12 nutrition education curriculum and making them \"eat the products of industrial animal production\".\nBovine growth hormone.\nIn 1937, it was found that bovine somatotropin (BST or bovine growth hormone) would increase the yield of milk. Several pharmaceutical companies developed commercial rBST products and they have been approved for use in the U.S., Mexico, Brazil, India, Russia, and at least ten others. The World Health Organization, and others have stated that dairy products and meat from BST-treated cows are safe for human consumption. However, based on negative animal welfare effects, rBST has not been allowed in Canada, Australia, New Zealand, Japan, Israel, or the European Union since 2000 \u2013 and in the U.S. has lost popularity due to consumer demands for rBST-free cows, with only about 17% of all cows in America now receiving rBST.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "56229", "revid": "37078343", "url": "https://en.wikipedia.org/wiki?curid=56229", "title": "Cichlidae", "text": ""}
{"id": "56230", "revid": "35508256", "url": "https://en.wikipedia.org/wiki?curid=56230", "title": "Cichlid", "text": "Family of fishes\nCichlids ()\nare a large, diverse, and widespread family of percomorph fish in the family Cichlidae, order Cichliformes. At least 1,760\u00a0species have been scientifically described, making it one of the largest vertebrate families, with only the Cyprinidae being more speciose. New species are discovered annually, and many species remain undescribed. The actual number of species is therefore unknown, with estimates varying between 2,000 and 3,000. They are native to the Neotropics, Africa (including Madagascar), the Middle East, and the Indian subcontinent, although some species have been introduced worldwide.\nMany cichlids, particularly tilapia, are important food fishes, while others, such as the \"Cichla\" species, are valued game fish. The family also includes many popular freshwater aquarium fish kept by hobbyists, including the angelfish, oscars, and discus. Cichlids have the largest number of endangered species among vertebrate families, most in the haplochromine group. Cichlids are particularly well known for having evolved rapidly into many closely related but morphologically diverse species within large lakes, particularly Lakes Tanganyika, Victoria, Malawi, and Edward. Their diversity in the African Great Lakes is important for the study of speciation in evolution. Many cichlids introduced into waters outside of their natural range have become nuisances.\nAll cichlids practice some form of parental care for their eggs and fry, usually in the form of guarding the eggs and fry or mouthbrooding.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nAnatomy and appearance.\nCichlids span a wide range of body sizes, from species as small as in length (e.g., female \"Neolamprologus multifasciatus\") to much larger species approaching in length (\"Boulengerochromis\" and \"Cichla\"). As a group, cichlids exhibit a similar diversity of body shapes, ranging from strongly laterally compressed species (such as \"Altolamprologus\", \"Pterophyllum\", and \"Symphysodon\") to species that are cylindrical and highly elongated (such as \"Julidochromis\", \"Teleogramma\", \"Teleocichla\", \"Crenicichla\", and \"Gobiocichla\"). Generally, however, cichlids tend to be of medium size, ovate in shape, and slightly laterally compressed, and generally similar to the North American sunfishes in morphology, behavior, and ecology.\nCichlids share a single key trait - the fusion of the lower pharyngeal bones into a single tooth-bearing structure. A complex set of muscles allows the upper and lower pharyngeal bones to be used as a second set of jaws for processing food, allowing a division of labor between the \"true jaws\" (mandibles) and the \"pharyngeal jaws\". Cichlids are efficient and often highly specialized feeders that capture and process a very wide variety of food items. This is assumed to be one reason why they are so diverse.\nTaxonomy.\nInternal taxonomy.\nThe following consensus taxonomy is based on the Catalog of Fishes (2025)\nIn the past, cichlid taxonomy has varied depending on the author. Kullander (1998) recognized eight subfamilies of cichlids: the Astronotinae, Cichlasomatinae, Cichlinae, Etroplinae, Geophaginae, Heterochromidinae, Pseudocrenilabrinae, and Retroculinae. A ninth subfamily, the Ptychochrominae, was later recognized by Sparks and Smith. Cichlid taxonomy is still debated, and classification of genera cannot yet be definitively given. A comprehensive system of assigning species to monophyletic genera is still lacking, and there is not complete agreement on what genera should be recognized in this family.\nAs an example of the classification problems, Kullander placed the African genus \"Heterochromis\" phylogenetically within Neotropical cichlids, although later papers concluded otherwise. Other problems center upon the identity of the putative common ancestor for the Lake Victoria superflock (many closely related species sharing a single habitat), and the ancestral lineages of Lake Tanganyikan cichlids.\nPhylogeny derived from morphological characters shows differences at the genus level with phylogeny based on genetic loci. A consensus remains that the Cichlidae as a family are monophyletic.\nIn cichlid taxonomy, dentition was formerly used as a classifying characteristic, but this was complicated because in many cichlids, tooth shapes change with age, due to wear, and cannot be relied upon. Genome sequencing and other technologies transformed cichlid taxonomy.\nAlternatively, all cichlid species native to the New World, can be classified under the subfamily Cichlinae, while Etroplinae can classify all cichlid species native to the Old World.\nExternal taxonomy.\nThe taxonomic placement of cichlids has long been disputed and variable, and has only recently been largely resolved. In the past, based on morphological characteristics, cichlids were classed in a suborder, the Labroidei, along with the wrasses (Labridae), in the order Perciformes. However, studies incorporating molecular phylogenetics have contradicted this grouping. \nMore recent phylogenetic studies support the creation of a distinct order, the Cichliformes, to contain the cichlids and their close relatives, which are no longer thought to be closely related to wrasses. The closest living relative of cichlids has been found to be the marine convict blenny, and both families are classified in the 5th edition of \"Fishes of the World\" as the two families in the Cichliformes, part of the subseries Ovalentaria. The Catalog of Fishes adopts the same placement, although the leaffishes (which have a similar African and South American distribution) are now also placed in the Cichliformes. Although these interrelationships are now generally well-supported, other authors have interpreted these relationships in differing ways, such as instead placing the cichlids, leaffish, and convict blenny as the most basal members of an expanded Blenniiformes.\nEvolution.\nModern cichlids have a disjunct distribution consisting of Africa (including Madagascar), the Neotropics (including Cuba and Hispaniola), the Levant, southern Iran, and the southern Indian subcontinent. This distribution has become the subject of much scientific dispute, with it being debated whether modern cichlid distribution is a consequence of the breakup of Gondwana (which would make cichlids a particularly ancient group dating to the Early Cretaceous), or if it is instead based on more recent oceanic dispersal by the cichlids (despite modern members of the group being largely restricted to freshwater).\nProponents of the Gondwanan theory, which saw more support in the past, have noted that the cichlids display the precise sister relationships predicted by Gondwanan distribution: Africa-South America and India-Madagascar, and that with the exception of the species from Cuba, Hispaniola and Madagascar, cichlids have not reached any oceanic island. The dispersal hypothesis, in contrast, requires cichlids to have negotiated thousands of kilometers of open ocean between India and Madagascar without colonizing any other island, or for that matter, crossing the Mozambique Channel to Africa.\nHowever, more recent studies incorporating phylogenetic evidence have found that the divergences within the cichlids are far too young for cichlids to have even been present for the breakup of Gondwana. Molecular clock estimates have placed the family's origin only to the Late Cretaceous period, and the divergences within the family to have occurred anywhere between the Late Cretaceous to the Eocene (depending on the study). This suggests that only dispersal can support modern cichlid distribution. However, the factors that may have allowed prehistoric cichlids to make migrations over entire oceans remains a mystery. It is known that during the Paleogene, the Atlantic Ocean between South America and Africa was significantly narrower, and it has been suggested that either now-submerged islands or a large plume from the Congo River may have allowed for a shallower or less saline environment that was conducive for cichlids to disperse from Africa to South America. Under the dispersal hypothesis, it is generally accepted that Africa was the ancestral home for cichlids, from which they dispersed to attain their present distribution.\nFossil record.\nThe fossil record of cichlids is comprehensive, although it only starts in the Eocene, well after the family is thought to have undergone significant evolutionary diversification. Fossil cichlids appear in both South America and Africa at roughly the same time in the Eocene, with fossil cichlids known from the Early Eocene (48.6\u00a0mya)-aged Lumbrera Formation of Argentina, as well as the Middle Eocene (46 mya)\u2013aged Mahenge Formation of Tanzania, suggesting that the divergence between Old and New World cichlids must have occurred prior to this point.\nSeveral African fossil sites that contain cichlids (including the Eocene-aged Mahenge Formation of Tanzania and the Miocene-aged Ngorora Formation of Kenya) appear to represent former maars or rift lakes, and the fossil cichlids present in them appear to represent species flocks akin to those in the modern African rift lakes. This suggests that rapid diversification within enclosed ecosystems is a longstanding trait of cichlids.\nFossil remains also suggest that cichlids ranged further north in the geologic past, with the extinct tilapia \"Oreochromis lorenzoi\" being known from the Late Miocene of Italy.\nDistribution and habitat.\nCichlids are one of the largest vertebrate families in the world. They are most diverse in Africa and South America. Africa alone is host to at least an estimated 1,600\u00a0species. Central America and Mexico have about 120\u00a0species, as far north as the Rio Grande in South Texas. Madagascar has its own distinctive species (\"Katria\", \"Oxylapia\", \"Paratilapia\", \"Paretroplus\", \"Ptychochromis\", and \"Ptychochromoides\"), only distantly related to those on the African mainland. Native cichlids are largely absent in Asia, except for 9 species in Israel, Lebanon, and Syria (\"Astatotilapia flaviijosephi\", \"Oreochromis aureus\", \"O.\u00a0niloticus\", \"Sarotherodon galilaeus\", \"Coptodon zillii\", and \"Tristramella\" spp.), two in Iran (\"Iranocichla\"), and three in India and Sri Lanka (\"Etroplus\" and \"Pseudetroplus\"). If disregarding Trinidad and Tobago (where the few native cichlids are members of genera that are widespread in the South American mainland), the three species from the genus \"Nandopsis\" are the only cichlids from the Antilles in the Caribbean, specifically Cuba and Hispaniola. Europe, Australia, Antarctica, and North America north of the Rio Grande drainage have no native cichlids, although in Florida, Hawaii, Japan, northern Australia, and elsewhere, feral populations of cichlids have become established as exotics. Although no longer present in Europe except as introductions, tilapias are known to have ranged as far north as Italy during the Miocene.\nAlthough most cichlids are found at relatively shallow depths, several exceptions do exist. The deepest known occurrences are \"Trematocara\" at more than below the surface in Lake Tanganyika. Others found in relatively deep waters include species such as \"Alticorpus macrocleithrum\" and \"Pallidochromis tokolosh\" down to below the surface in Lake Malawi, and the whitish (nonpigmented) and blind \"Lamprologus lethops\", which is believed to live as deep as below the surface in the Congo River. \nCichlids are less commonly found in brackish and saltwater habitats, though many species tolerate brackish water for extended periods; \"Mayaheros urophthalmus\", for example, is equally at home in freshwater marshes and mangrove swamps, and lives and breeds in saltwater environments such as the mangrove belts around barrier islands. Several species of \"Tilapia\", \"Sarotherodon\", and \"Oreochromis\" are euryhaline and can disperse along brackish coastlines between rivers. Only a few cichlids, however, inhabit primarily brackish or salt water, most notably \"Etroplus maculatus\", \"Etroplus suratensis\", and \"Sarotherodon melanotheron\". The perhaps most extreme habitats for cichlids are the warm hypersaline lakes where the members of the genera \"Alcolapia\" and \"Danakilia\" are found. Lake Abaeded in Eritrea encompasses the entire distribution of \"D.\u00a0dinicolai\", and its temperature ranges from . Although the vast majority of Malagasy cichlids are entirely restricted to fresh water, \"Ptychochromis grandidieri\" and \"Paretroplus polyactis\" are commonly found in coastal brackish water and apparently are salt tolerant, as is also the case for \"Etroplus maculatus\" and \"E.\u00a0suratensis\" from India and Sri Lanka.\nEcology.\nFeeding.\nWithin the cichlid family, carnivores, herbivores, omnivores, planktivores, and detritivores are known, meaning the Cichlidae encompass essentially the full range of food consumption possible in the animal kingdom. Various species have morphological adaptations for specific food sources, but most cichlids consume a wider variety of foods based on availability. \nCarnivorous cichlids can be further divided into piscivorous and molluscivorous, since the morphology and hunting behavior differ greatly between the two categories. Piscivorous cichlids eat other fish, fry, larvae, and eggs. Some species eat the offspring of mouthbrooders by head-ramming, wherein the hunter shoves its head into the mouth of a female to expel her young and eat them. Molluscivorous cichlids have several hunting strategies amongst the varieties within the group. Lake Malawi cichlids consume substrate and filter it out through their gill rakers to eat the mollusks that were in the substrate. Gill rakers are finger-like structures that line the gills of some fish to catch any food that might escape through their gills.\nMany cichlids are primarily herbivores, feeding on algae (e.g. \"Petrochromis\") and plants (e.g. \"Etroplus suratensis\"). Small animals, particularly invertebrates, are only a minor part of their diets.\nOther cichlids are detritivores and eat organic material, called \"Aufwuchs\" (offal); among these species are the tilapiines of the genera \"Oreochromis\", \"Sarotherodon\", and \"Tilapia\".\nOther cichlids are predatory and eat little or no plant matter. These include generalists that catch a variety of small animals, including other fishes and insect larvae (e.g. \"Pterophyllum\"), as well as variety of specialists. \"Trematocranus\" is a specialized snail-eater, while \"Pungu maclareni\" feeds on sponges. A number of cichlids feed on other fish, either entirely or in part. \"Crenicichla\" species are stealth predators that lunge from concealment at passing small fish, while \"Rhamphochromis\" species are open-water pursuit predators that chase down their prey. Paedophagous cichlids such as the \"Caprichromis\" species eat other species' eggs or young, in some cases ramming the heads of mouthbrooding species to force them to disgorge their young. Among the more unusual feeding strategies are those of \"Corematodus\", \"Docimodus evelynae\", \"Plecodus\", \"Perissodus\", and \"Genyochromis\" spp., which feed on scales and fins of other fishes, a behavior known as lepidophagy, along with the death-mimicking behaviour of \"Nimbochromis\" and \"Parachromis\" species, which lay motionless, luring small fish to their side prior to ambush.\nThis variety of feeding styles has helped cichlids to inhabit similarly varied habitats. Its pharyngeal teeth (in the throat) afford cichlids so many \"niche\" feeding strategies, because the jaws pick and hold food, while the pharyngeal teeth crush the prey.\nBehavior.\nAggression.\nAggressive behavior in cichlids is ritualized and consists of multiple displays used to seek confrontation while being involved in evaluation of competitors, coinciding with temporal proximity to mating. Displays of ritualized aggression in cichlids include a remarkably rapid change in coloration, during which a successfully dominant territorial male assumes a more vivid and brighter coloration, while a subordinate or \"nonterritorial\" male assumes a dull-pale coloration. In addition to color displays, cichlids employ their lateral lines to sense movements of water around their opponents to evaluate the competing male for physical traits/fitness. Male cichlids are very territorial due to the pressure of reproduction, and establish their territory and social status by physically driving out challenging males (novel intruders) through lateral displays (parallel orientation, uncovering gills), biting, or mouth fights (head-on collisions of open mouths, measuring jaw sizes, and biting each other's jaws). The cichlid social dichotomy is composed of a single dominant with multiple subordinates, where the physical aggression of males becomes a contest for resources (mates, territory, food). Female cichlids prefer to mate with a successfully alpha male with vivid coloration, whose territory has food readily available.\nMating.\nCichlids mate either monogamously or polygamously. The mating system of a given cichlid species is not consistently associated with its brooding system. For example, although most monogamous cichlids are not mouthbrooders, \"Chromidotilapia\", \"Gymnogeophagus\", \"Spathodus\", and \"Tanganicodus\" all include \u2013 or consist entirely of \u2013 monogamous mouthbrooders. In contrast, numerous open- or cave-spawning cichlids are polygamous; examples include many \"Apistogramma\", \"Lamprologus\", \"Nannacara\", and \"Pelvicachromis\" species.\nMost adult male cichlids, specifically in the cichlid tribe Haplochromini, exhibit a unique pattern of oval-shaped color dots on their anal fins. These phenomena, known as egg spots, aid in the mouthbrooding mechanisms of cichlids. The egg spots consist of carotenoid-based pigment cells, which indicate a high cost to the organism, when considering that fish are not able to synthesize their own carotenoids.\nThe mimicry of egg spots is used by males for the fertilization process. Mouthbrooding females lay eggs and immediately snatch them up with their mouths. Over millions of years, male cichlids have evolved egg spots to initiate the fertilization process more efficiently. When the females are snatching up the eggs into their mouth, the males gyrate their anal fins, which illuminates the egg spots on his tail. Afterwards, the female, believing these are her eggs, places her mouth to the anal fin (specifically the genital papilla) of the male, which is when he discharges sperm into her mouth and fertilizes the eggs.\nThe genuine color of egg spots is a yellow, red, or orange inner circle with a colorless ring surrounding the shape. Through phylogenetic analysis, using the mitochondrial \"ND2\" gene, the true egg spots are thought to have evolved in the common ancestor of the \"Astatoreochromis\" lineage and the modern haplochromine species. This ancestor was most likely riverine in origin, based on the most parsimonious representation of habitat type in the cichlid family. The presence of egg spots in a turbid riverine environment would seem particularly beneficial and necessary for intraspecies communication.\nTwo pigmentation genes are found to be associated with egg-spot patterning and color arrangement. These are \"fhl2-a\" and \"fhl2-b\", which are paralogs. These genes aid in pattern formation and cell-fate determination in early embryonic development. The highest expression of these genes was temporally correlated with egg-spot formation. A short, interspersed, repetitive element was also seen to be associated with egg spots. Specifically, it was evident upstream of the transcriptional start site of \"fhl2\" in only \"Haplochrominis\" species with egg spots\nSelf-fertilization.\nThe cichlid \"Benitochromis nigrodorsalis\" from Western Africa ordinarily undergoes biparental reproduction, but is also able to undergo facultative (optional) selfing (self-fertilization). Facultative selfing may be an adaptive option when a mating partner is unavailable.\nBrood care.\nPit spawning in cichlids.\nPit spawning, also referred to as substrate breeding, is a behavior in cichlid fish in which a fish builds a pit in the sand or ground, where a pair court and consequently spawn. Many different factors go into this behavior of pit spawning, including female choice of the male and pit size, as well as the male defense of the pits once they are dug in the sand.\nCichlids are often divided into two main groups: mouthbrooders and substrate brooders. Different parenting investment levels and behaviors are associated with each type of reproduction. As pit spawning is a reproductive behavior, many different physiological changes occur in the cichlid while this process is occurring that interfere with social interaction. Different kinds of species that pit spawn, and many different morphological changes occur because of this behavioral experience.\nPit spawning is an evolved behavior across the cichlid group. Phylogenetic evidence from cichlids in Lake Tanganyika could be helpful in uncovering the evolution of their reproductive behaviors. Several important behaviors are associated with pit spawning, including parental care, food provisioning, and brood guarding.\nMouth brooding vs. pit spawning.\nOne of the differences studied in African cichlids is reproductive behavior. Some species pit spawn and some are known as mouth brooders. Mouthbrooding is a reproductive technique where the fish scoop up eggs and fry for protection. While this behavior differs from species to species in the details, the general basis of the behavior is the same. Mouthbrooding also affects how they choose their mates and breeding grounds. In a 1995 study, Nelson found that in pit-spawning females choose males for mating based on the size of the pit that they dig, as well as some of the physical characteristics seen in the males. Pit spawning also differs from mouth brooding in the size and postnatal care exhibited. Eggs that have been hatched from pit-spawning cichlids are usually smaller than those of mouthbrooders. Pit-spawners' eggs are usually around 2\u00a0mm, while mouthbrooders are typically around 7\u00a0mm. While different behaviors take place postnatally between mouthbrooders and pit spawners, some similarities exist. Females in both mouthbrooders and pit-spawning cichlids take care of their young after they are hatched. In some cases, both parents exhibit care, but the female always cares for the eggs and newly hatched fry.\nPit spawning process.\nMany species of cichlids use pit spawning, but one of the less commonly studied species that exhibits this behavior is the Neotropical \"Cichlasoma dimerus\". This fish is a substrate breeder that displays biparental care after the fry have hatched from their eggs. One study examined reproductive and social behaviors of this species to see how they accomplished their pit spawning, including different physiological factors such as hormone levels, color changes, and plasma cortisol levels. The entire spawning process could take about 90\u00a0minutes and 400~800\u00a0eggs could be laid. The female deposits about 10\u00a0eggs at a time, attaching them to the spawning surface, which may be a pit constructed on the substrate or another surface. The number of eggs laid was correlated to the space available on the substrate. Once the eggs were attached, the male swam over the eggs and fertilized them. The parents would then dig pits in the sand, wide and deep, where larvae were transferred after hatching. Larvae began swimming 8 days after fertilization and parenting behaviors and some of the physiological factors measured changed.\nColor changes.\nIn the same study, color changes were present before and after the pit spawning occurred. For example, after the larvae were transferred and the pits were beginning to be protected, their fins turned a dark grey color. In another study, of the rainbow cichlid, \"Herotilapia multispinosa\", color changes occurred throughout the spawning process. Before spawning, the rainbow cichlid was an olive color with grey bands. Once spawning behaviors started, the body and fins of the fish became a more golden color. When the eggs were finished being laid, the pelvic fin all the way back to the caudal fin turned to a darker color and blackened in both the males and the females.\nPit sizes.\nFemales prefer a bigger pit size when choosing where to lay eggs. Differences are seen in the sizes of pits that created, as well as a change in the morphology of the pits. Evolutionary differences between species of fish may cause them to either create pits or castles when spawning. The differences were changes in the way that each species fed, their macrohabitats, and the abilities of their sensory systems.\nEvolution.\nCichlids are renowned for their recent, rapid evolutionary radiation, both across the entire clade and within different communities across separate habitats. Within their phylogeny, many parallel instances are seen of lineages evolving to the same trait and multiple cases of reversion to an ancestral trait.\nThe family Cichlidae arose between 80 and 100 million years ago within the order Perciformes (perch-like fishes). Cichlidae can be split into a few groups based on their geographic location: Madagascar, Indian, African, and Neotropical (or South American). The most famous and diverse group, the African cichlids, can be further split either into Eastern and Western varieties, or into groups depending on which lake the species is from: Lake Malawi, Lake Victoria, or Lake Tanganyika. Of these subgroups, the Madagascar and Indian cichlids are the most basal and least diverse.\nOf the African cichlids, the West African or Lake Tanganyika cichlids are the most basal.\nCichlids' common ancestor is believed to have been a spit-spawning species. Both Madagascar and Indian cichlids retain this feature. However, of the African cichlids, all extant substrate brooding species originate solely from Lake Tanganyika. The ancestor of the Lake Malawi and Lake Victoria cichlids were mouthbrooders. Similarly, only around 30% of South American cichlids are thought to retain the ancestral substrate-brooding trait. Mouthbrooding is thought to have evolved individually up to 14 times, and a return to substrate brooding as many as three separate times between both African and Neotropical species.\nAssociated behaviors.\nCichlids have a great variety of behaviors associated with substrate brooding, including courtship and parental care alongside the brooding and nest-building behaviors needed for pit spawning. Cichlids' behavior typically revolves around establishing and defending territories when not courting, brooding, or raising young. Encounters between males and males or females and females are agonistic, while an encounter between a male and female leads to courtship. Courtship in male cichlids follows the establishment of some form of territory, sometimes coupled with building a bower to attract mates. After this, males may attempt to attract female cichlids to their territories by a variety of lekking display strategies or otherwise seek out females of their species. However, cichlids, at the time of spawning, undergo a behavioral change such that they become less receptive to outside interactions. This is often coupled with some physiological change in appearance.\nBrood care.\nCichlids can have maternal, paternal, or biparental care. Maternal care is most common among mouthbrooders, but cichlids' common ancestor is thought to exhibit paternal-only care. Other individuals outside of the parents may also play a role in raising young; in the biparental daffodil cichlid (\"Neolamprologus pulcher\"), closely related satellite males, those males that surround other males' territories and attempt to mate with female cichlids in the area, help rear the primary males' offspring and their own.\nA common form of brood care involves food provisioning. For example, females of lyretail cichlids (\"Neolamprologus modabu\") dig at sandy substrate more to push nutritional detritus and zooplankton into the surrounding water. Adult of \" N. modabu\" perform this strategy to collect food for themselves, but dig more when offspring are present, likely to feed their fry. This substrate-disruption strategy is rather common and can also be seen in convict cichlids (\"Cichlasoma nigrofasciatum\"). Other cichlids have an ectothermal mucus that they grow and feed to their young, while still others chew and distribute caught food to offspring. These strategies, however, are less common in pit-spawning cichlids.\nCichlids have highly organized breeding activities. All species show some form of parental care for both eggs and larvae, often nurturing free-swimming young until they are weeks or months old.\nCommunal parental care, where multiple monogamous pairs care for a mixed school of young have also been observed in multiple cichlid species, including \"Amphilophus citrinellus\", \"Etroplus suratensis\", and \"Tilapia rendalli\". Comparably, the fry of \"Neolamprologus brichardi\", a species that commonly lives in large groups, are protected not only by the adults, but also by older juveniles from previous spawns. Several cichlids, including discus (\"Symphysodon\" spp.), some \"Amphilophus\" species, \"Etroplus\", and \"Uaru\" species, feed their young with a skin secretion from mucous glands.\nThe species \"Neolamprologus pulcher\" uses a cooperative breeding system, in which one breeding pair has many helpers that are subordinate to the dominant breeders.\nParental care falls into one of four categories: substrate or open brooders, secretive cave brooders (also known as guarding speleophils), and at least two types of mouthbrooders, ovophile mouthbrooders and larvophile mouthbrooders.\nOpen brooding.\nOpen- or substrate-brooding cichlids lay their eggs in the open, on rocks, leaves, or logs. Examples of open-brooding cichlids include \"Pterophyllum\" and \"Symphysodon\" species and \"Anomalochromis thomasi\". Male and female parents usually engage in differing brooding roles. Most commonly, the male patrols the pair's territory and repels intruders, while the female fans water over the eggs, removing the infertile ones, and leading the fry while foraging. Both sexes are able to perform the full range of parenting behaviours.\nCave brooding.\nSecretive cave-spawning cichlids lay their eggs in caves, crevices, holes, or discarded mollusc shells, frequently attaching the eggs to the roof of the chamber. Examples include \"Pelvicachromis\" spp., \"Archocentrus\" spp., and \"Apistogramma\" spp. Free-swimming fry and parents communicate in captivity and in the wild. Frequently, this communication is based on body movements, such as shaking and pelvic fin flicking. In addition, open- and cave-brooding parents assist in finding food resources for their fry. Multiple neotropical cichlid species perform leaf-turning and fin-digging behaviors.\nOvophile mouthbrooding.\nOvophile mouthbrooders incubate their eggs in their mouths as soon as they are laid, and frequently mouthbrood free-swimming fry for several weeks. Examples include many East African Rift lakes (Lake Malawi, Lake Tanganyika, and Lake Victoria) endemics, e.g.: \"Maylandia\", \"Pseudotropheus\", \"Tropheus\", and \"Astatotilapia burtoni\", along with some South American cichlids such as \"Geophagus steindachneri\".\nLarvophile mouthbrooding.\nLarvophile mouthbrooders lay eggs in the open or in a cave and take the hatched larvae into the mouth. Examples include some variants of \"Geophagus altifrons\", and some \"Aequidens\", \"Gymnogeophagus\", and \"Satanoperca\", as well as \"Oreochromis mossambicus\" and \"Oreochromis niloticus\". Mouthbrooders, whether of eggs or larvae, are predominantly females. Exceptions that also involve the males include eretmodine cichlids (genera \"Spathodus\", \"Eretmodus\", and \"Tanganicodus\"), some \"Sarotherodon\" species (such as \"Sarotherodon melanotheron\"), \"Chromidotilapia guentheri\", and some \"Aequidens\" species. This method appears to have evolved independently in several groups of African cichlids.\nSpeciation.\nCichlids provide scientists with a unique perspective of speciation, having become extremely diverse in the recent geological past, those of Lake Victoria actually within the last 10,000 to 15,000\u00a0years, a small fraction of the millions taken for Gal\u00e1pagos finch speciation in Darwin's textbook case. Some of the contributing factors to their diversification are believed to be the various forms of prey processing displayed by cichlid pharyngeal jaw apparatuses. These different jaw apparatuses allow for a broad range of feeding strategies, including algae scraping, snail crushing, planktivory, piscivory, and insectivory. Some cichlids can also show phenotypic plasticity in their pharyngeal jaws, which can also help lead to speciation. In response to different diets or food scarcity, members of the same species can display different jaw morphologies that are better suited to different feeding strategies. As species members begin to concentrate around different food sources and continue their lifecycle, they most likely spawn with like individuals. This can reinforce the jaw morphology and given enough time, create new species. Such a process can happen through allopatric speciation, whereby species diverge according to different selection pressures in different geographical areas, or through sympatric speciation, by which new species evolve from a common ancestor while remaining in the same area. In Lake Apoyo in Nicaragua, \"Amphilophus zaliosus\" and its sister species \"Amphilophus citrinellus\" display many of the criteria needed for sympatric speciation. In the African rift lake system, cichlid species in numerous distinct lakes evolved from a shared hybrid swarm.\nPopulation status.\nIn 2010, the International Union for Conservation of Nature classified 184 species as vulnerable, 52 as endangered, and 106 as critically endangered.\nAt present, the IUCN only lists \"Yssichromis\" sp. nov. \"argens\" as extinct in the wild, and six species are listed as entirely extinct, but many more possibly belong in these categories (for example, \"Haplochromis aelocephalus\", \"H.\u00a0apogonoides\", \"H.\u00a0dentex\", \"H.\u00a0dichrourus\", and numerous other members of the genus \"Haplochromis\" have not been seen since the 1980s, but are maintained as critically endangered on the small chance that tiny \u2013but currently unknown\u2013 populations survive).\nLake Victoria.\nBecause of the introduced Nile perch (\"Lates niloticus\"), Nile tilapia (\"Oreochromis niloticus\"), and water hyacinth, deforestation that led to water siltation, and overfishing, many Lake Victoria cichlid species have become extinct or been drastically reduced. By around 1980, lake fisheries yielded only 1% cichlids, a drastic decline from 80% in earlier years.\nBy far the largest Lake Victoria group is the haplochromine cichlids, with more than 500 species, but at least 200 of these (about 40%) have become extinct, and many others are seriously threatened. Initially it was feared that the percentage of extinct species was even higher, but some species have been rediscovered after the Nile perch started to decline in the 1990s. Some species have survived in nearby small satellite lakes, or in refugia among rocks or papyrus sedges (protecting them from the Nile perch), or have adapted to the human-induced changes in the lake itself. The species were often specialists and these were not affected to the same extent. For example, the piscivorous haplochromines were particularly hard hit with a high number of extinctions, while the zooplanktivorous haplochromines reached densities in 2001 that were similar to before the drastic decline, although consisting of fewer species and with some changes in their ecology.\nFood and game fish.\nAlthough cichlids are mostly small- to medium-sized, many are notable as food and game fishes. With few thick rib bones and tasty flesh, artisan fishing is not uncommon in Central America and South America, as well as areas surrounding the African rift lakes.\nTilapia.\nThe most important food cichlids, however, are the tilapiines of North Africa. Fast growing, tolerant of stocking density, and adaptable, tilapiine species have been introduced and farmed extensively in many parts of Asia and are increasingly common aquaculture targets elsewhere.\nFarmed tilapia production is about annually, with an estimated value of US$1.8 billion, about equal to that of salmon and trout.\nUnlike those carnivorous fish, tilapia can feed on algae or any plant-based food. This reduces the cost of tilapia farming, reduces fishing pressure on prey species, avoids concentrating toxins that accumulate at higher levels of the food chain, and makes tilapia the preferred \"aquatic chickens\" of the trade.\nGame fish.\nMany large cichlids are popular game fish. The peacock bass (\"Cichla\" species) of South America is one of the most popular sportfish. It was introduced in many waters around the world. In Florida, this fish generates millions of hours of fishing and sportfishing revenue of more than US$8\u00a0million a year. Other cichlids preferred by anglers include the oscar, Mayan cichlid (\"Cichlasoma urophthalmus\"), and jaguar cichlid (\"Parachromis managuensis\").\nAquarium fish.\nSince 1945, cichlids have become increasingly popular as aquarium fish.\nThe most common species in hobbyist aquaria is \"Pterophyllum scalare\" from the Amazon River basin in tropical South America, known in the trade as the \"angelfish\". Other popular or readily available species include the oscar (\"Astronotus ocellatus\"), convict cichlid (\"Archocentrus nigrofasciatus\") and discus fish (\"Symphysodon\").\nHybrids and selective breeding.\nSome cichlids readily hybridize with related species, both in the wild and under artificial conditions. Other groups of fishes, such as European cyprinids, also hybridize. Unusually, cichlid hybrids have been put to extensive commercial use, in particular for aquaculture and aquaria. The hybrid red strain of tilapia, for example, is often preferred in aquaculture for its rapid growth. Tilapia hybridization can produce all-male populations to control stock density or prevent reproduction in ponds.\nAquarium hybrids.\nThe most common aquarium hybrid is perhaps the blood parrot cichlid, which is a cross of several species, especially from species in the genus \"Amphilophus\". (There are many hypotheses, but the most likely is: \"Amphilophus labiatus\" \u00d7 \"Vieja synspillus\" With a triangular-shaped mouth, an abnormal spine, and an occasionally missing caudal fin (known as the \"love heart\" parrot cichlid), the fish is controversial among aquarists. Some have called blood parrot cichlids \"the Frankenstein monster of the fish world\". Another notable hybrid, the flowerhorn cichlid, was very popular in some parts of Asia from 2001 until late 2003, and is believed to bring good luck to its owner. The popularity of the flowerhorn cichlid declined in 2004. Owners released many specimens into the rivers and canals of Malaysia and Singapore, where they threaten endemic communities.\nNumerous cichlid species have been selectively bred to develop ornamental aquarium strains. The most intensive programs have involved angelfish and discus, and many mutations that affect both coloration and fins are known. Other cichlids have been bred for albino, leucistic, and xanthistic pigment mutations, including oscars, convict cichlid and \"Pelvicachromis pulcher\". Both dominant and recessive pigment mutations have been observed. In convict cichlids, for example, a leucistic coloration is recessively inherited, while in \"Oreochromis niloticus niloticus\", red coloration is caused by a dominant inherited mutation.\nThis selective breeding may have unintended consequences. For example, hybrid strains of \"Mikrogeophagus ramirezi\" have health and fertility problems. Similarly, intentional inbreeding can cause physical abnormalities, such as the notched phenotype in angelfish.\nGenera.\nThe genus list is as per FishBase. Studies are continuing, however, on the members of this family, particularly the haplochromine cichlids of the African rift lakes.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56231", "revid": "19230876", "url": "https://en.wikipedia.org/wiki?curid=56231", "title": "Governor", "text": "Governing official\nA governor is an administrative leader and head of a polity or political region, in some cases, such as governors-general, as the head of a state's official representative. Depending on the type of political region or polity, a \"governor\" may be either appointed or elected, and the governor's powers can vary significantly, depending on the public laws in place locally. The adjective pertaining to a governor is gubernatorial, from the Latin root \"gubernare\". In a federated state, the governor may serve as head of state and head of government for their regional polity, while still operating under the laws of the federation, which has its own head of state for the entire federation.\nAncient empires.\nPre-Roman empires.\nThough the legal and administrative framework of provinces, each administered by a governor, was created by the Romans, the term \"governor\" has been a convenient term for historians to describe similar systems in antiquity. Indeed, many regions of the pre-Roman antiquity were ultimately replaced by Roman 'standardized' provincial governments after their conquest by Rome. Plato used the metaphor of turning the Ship of State with a rudder; the Latin word for rudder is gubernaculum.\nAncient Rome.\nFrom the creation of the earliest Roman subject provinces, a governor was appointed each year to administer each of them. The core function of a Roman governor was as a magistrate or judge, and the management of taxation and the public spending in their area.\nUnder the Republic and the early Empire, however, a governor also commanded military forces in his province. Republican governors were all men who had served in senior magistracies (the consulate or praetorship) in Rome in the previous year, and carried related titles as governor (\"proconsul\" or \"propraetor\"). The first emperor, Octavianus Augustus (who acquired or settled a number of new territories; officially his style was republican: Princeps civitatis), divided the provinces into two categories; the traditionally prestigious governorships remained as before (in what have become known as \"senatorial\" provinces), while in a range of others, he retained the formal governorship himself, delegating the actual task of administration to appointees (usually with the title \"legatus Augusti\"). The \"legatus\" sometimes would appoint a prefect (later procurator), usually a man of equestrian rank, to act as his deputy in a subregion of the larger province: the infamous character of Pontius Pilate in the Christian Gospels was a governor of this sort.\nA special case was Egypt, a rich 'private' domain and vital granary, where the emperor almost inherited the theocratic status of a pharaoh. The emperor was represented there by a governor \"sui generis\" styled \"praefectus augustalis\", a title evoking the religious cult of the emperor.\nEmperors Diocletian (see Tetrarchy) and Constantine in the third and fourth centuries AD carried out a root and branch reorganisation of the administration with two main features:\nThe prestigious governorships of Africa and Asia remained with the title proconsul, and the special right to refer matters directly to the emperor; the \"praefectus augustalis\" in Alexandria and the \"comes Orientis\" in Antioch also retained special titles. Otherwise, the governors of provinces had various titles, some known as \"consularis\", some as \"corrector\", while others as \"praeses\". Apart from Egypt and the East (\"Oriens\" \u2013 \"viz\" greater Syria), each diocese was directed by a governor known as a \"vicarius\". The prefectures were directed by \"praefecti praetorio\" (greatly transformed in their functions from their role in the early Empire).\nByzantium.\nThis system survived with few significant changes until the collapse of the empire in the West, and in the East, the breakdown of order with the Persian and Arab invasions of the seventh century. At that stage, a new kind of governor emerged, the Strategos. It was a role leading the themes which replaced provinces at this point, involving a return to the amalgamation of civil and military office which had been the practice under the Republic and the early Empire.\nLegacy.\nWhile the Roman administration in the West was largely destroyed in the barbarian invasions, its model was remembered; this model became very influential through two particular vehicles: Roman law and the Christian Church.\nTurkish rule.\nIn the Ottoman Empire, all pashas (generals) administered a province of the Great Sultan's vast empire, with specific titles (such as Mutessaryf; Vali or W\u0101li which was often maintained and revived in the oriental successor states; Beilerbei (rendered as \"governor-general\", as he is appointed above several provinces under individual governors) and Dey)\nBritish Empire and Commonwealth realms.\nIn the British Empire, a governor was originally an official appointed by the British monarch (or the cabinet) to oversee a crown colony and was the (sometimes notional) head of the colonial administration. The governors' powers varied from colony to colony, depending on its constitutional setup; while all colonies had a separate court system, the governor only had legislative power in colonies that lacked a Legislative Council or Legislative Assembly. The executive powers vested in the governor varied as well; while many colonies had an Executive Council to help with the colony's administration, these ranged from presidential cabinet-like bodies that only served as consultative forums without collective executive powers or functions of their own while the governor had an independent decision-making capacity, to fully fledged parliamentary ministries whose decisions the governor was required to formally execute.\nToday, crown colonies of the United Kingdom continue to be administered by governors who hold varying degrees of power. Because of the different constitutional histories of the former colonies of the United Kingdom, the term \"governor\" now refers to officials with differing amounts of power.\nAdministrators, commissioners and high commissioners exercise similar powers to governors. (Note: such high commissioners are not to be confused with the high commissioners who are the equivalent of ambassadors between Commonwealth states).\nFrequently the name 'Government House' is given to governors' residences.\nThe term can also be used in a more generic sense, especially for compound titles which include it: governor-general and lieutenant-governor.\nVice-regal governors.\nUnited Kingdom overseas territories.\nIn the United Kingdom's remaining overseas territories, the governor is normally a direct appointee of the British government and plays an active role in governing and lawmaking (though usually with the advice of elected local representatives). The governor's chief responsibility is for the defence and external affairs of the colony.\nIn some minor overseas territories, instead of a governor, there is an administrator or commissioner, or the position is held \"ex officio\" by a High Commissioner.\nAustralia.\nIn Australia, each state has the governor as its formal representative of the sovereign, as head of the state government. It is not a political office but a ceremonial one. Each state governor is appointed by the Australian monarch on the advice of the premier, who is the political chief executive of the state government (until 1986, state governors were appointed by the British monarch on the advice of the British government). State governors have emergency reserve powers but these are rarely used. The territories of Australia other than the ACT have administrators instead of governors, who are appointed formally by the governor-general. The governor-general is the representative of and appointed by the king of Australia sovereign at a federal level on the advice of the prime minister of Australia.\nAs with the governors-general of Australia and other Commonwealth realms, state governors usually exercise their power only on the advice of a government minister.\nCanada.\nIn Canada, there are governors at the federal and provincial levels of government who, within their jurisdictions, act as representatives of the king of Canada, who is Canada's head of state. The federal governor is the governor general of Canada, and the governor of each province is the lieutenant governor. The governor general is appointed by the sovereign on the advice of the prime minister of Canada, whereas the lieutenant governors are appointed by the governor general on the advice of the prime minister. The role of the governor general and of the lieutenant governors in Canada is largely ceremonial, although they do retain the authority to exercise reserve powers in exceptional circumstances.\nEach of the three territories is headed by a commissioner appointed by the federal Cabinet. Unlike provincial lieutenant governors, they are not representatives of the sovereign but rather are representatives of the federal government.\nBritish Hong Kong (1841\u20131997).\nIn the colonial period of Hong Kong, the governor was the representative of the sovereign from 1843, which was the year that the authorities and duties of the post were officially defined by the Hong Kong Letters Patent and the Royal Instructions, until the handover of Hong Kong to the PRC government in 1997. Each governor was appointed by the monarch and possessed significant powers such as the power of appointing lawmakers in the legislative council, the power to grant land, the power of veto over bills and motions, the power of pardon, etc. At the same time, the governor was also the head of the colonial cabinet, the chairman of the Executive Council, the president of the Legislative Council (until 1993), as well as the commander-in-chief of the British Forces in Hong Kong.\nNew Zealand.\nThe governor-general of New Zealand is always the governor of the Ross Dependency, an Antarctic sector which is claimed by the Realm of New Zealand.\nWithin the United Kingdom.\nWithin the United Kingdom itself, there was a position of Governor of Northern Ireland from 1922 until the suspension of the devolved Parliament of Northern Ireland in 1973.\nWithin England.\nFrom the 16th century until 1995, there was a governor of the Isle of Wight, part of England. Since the reign of Henry VIII, the monarch has borne the title of Supreme Governor of the Church of England.\nOther colonial empires.\nEuropean powers other than the United Kingdom, with colonies in Asia, Africa and elsewhere, gave their top representatives in their colonies the title of governor. Those representatives could be from chartered companies that ruled the colonies. In some of these colonies, there are still officials called governors.\nSee:\nRussia and former Soviet Union.\nIn the Russian Empire, the governorate (guberniya) and governorate-general were the main units of territorial and administrative subdivision since the reforms of Peter the Great. These were governed by a governor and governor-general respectively.\nA special case was the Chinese Eastern Railway Zone, which was governed as a concession granted by Imperial China to the Russian 'Chinese Eastern Railway Society' (in Russian \"Obshchestvo Kitayskoy Vostochnoy Zheleznoy Dorogi\"; established on 17 December 1896 in St. Petersburg, later moved to Vladivostok), which built 1,481\u00a0km of tracks (Tarskaya \u2013 Hilar \u2013 Harbin \u2013 Nikolsk-Ussuriski; 3 November 1901 traffic opened) and established on 16 May 1898 the new capital city, Harbin; in August 1898, the defense for Chinese Eastern Railway (CER) across northeast China was assumed by Russia (first under Priamur governor).\nOn July 1, 1903, the Chinese Eastern Railway was opened and given authority of its own CER Administration (Russian: \"Upravleniye KVZhD\"), vested in the Directors of the Chinese Eastern Railway, with the additional quality of Governors of the Chinese Eastern Railway Zone (in Harbin; as such being August 12, 1903 \u2013 July 1, 1905 subordinated to the imperial Viceroyalty of the Far East, see L\u00fcshunkou). The post continued to function despite various political changes until after World War II.\nSome of the administrative subdivisions of Russia are headed by governors, while others are headed by presidents or heads of administration. From 1991 to 2005, they were elected by popular vote and from 2005 to 2012, they were appointed by the federal president and confirmed by the province's legislature. After the debate, conducted by State Duma in April 2012, the direct elections of governors were expected to be restored.\nOther European countries and empires.\nAustria.\nA Landeshauptmann (German for \"state captain\" or \"state governor\", literally 'country headman'; plural \"Landeshauptleute\" or \"Landeshauptm\u00e4nner\" as in Styria till 1861; \"Landeshauptfrau\" is the female form) is an official title in German for certain political offices equivalent to a governor. It has historical uses, both administrative and colonial, and is now used in federal Austria and in South Tyrol, a majority German-speaking province of Italy adjacent to Tyrol.\nFrance.\nDuring the Ancien R\u00e9gime in France, the representative of the king in his provinces and cities was the gouverneur. Royal officers were chosen from the highest nobility, and provincial and city governors (oversight of provinces and cities was frequently combined) were predominantly military positions in charge of defense and policing. Provincial governors\u00a0\u2013 also called \"lieutenant generals\"\u00a0\u2013 also had the ability to convoke provincial parlements, provincial estates and municipal bodies. The title \"gouverneur\" first appeared under Charles VI. The ordinance of Blois of 1579 reduced their number to 12, but an ordinance of 1779 increased their number to 39 (18 first-class governors, 21 second-class governors). Although in principle, they were the king's representatives and their charges could be revoked at the king's will, some governors had installed themselves and their heirs as a provincial dynasty. The governors were at the height of their power from the middle of the 16th to the middle of the 17th century, but their role in provincial unrest during the civil wars led Cardinal Richelieu to create the more tractable positions of intendants of finance, policing and justice, and in the 18th century the role of provincial governors was greatly curtailed.\nGermany.\nUntil 1933, the term \"Landeshauptmann\" (state governor) was used in Prussia for the head of government of a province, In the modern-day states of Germany, the counterpart to \"Landeshauptmann\" is the \"Ministerpr\u00e4sident\" (minister-president). In the present German states of Baden-W\u00fcrttemberg, Bavaria, Hesse, and North Rhine-Westphalia there are \u2013 and earlier in more German states there were \u2013 sub-state administrative regions called in , which is sometimes translated into English as governorate. Thus its respective head, in , is also translated as governor.\nGreece.\nIoannis Kapodistrias was the first (and, with the exception of the short tenure of his younger brother Augustinos Kapodistrias, the only) head of state of Greece to bear the title of governor.\nOther modern Asian countries.\nChina.\nIn the People's Republic of China, the title \"Governor\" () refers to the highest ranking executive of a provincial government. The governor is usually placed second in the provincial power hierarchy, below the secretary of the provincial Chinese Communist Party (CCP) committee (\u7701\u59d4\u4e66\u8bb0), who serves as the highest ranking party official in the province. Governors are elected by the provincial congresses and approved by the provincial party chief. All governors are not locals in the provinces which they govern.\nThe title can be also used while referring to a county governor (\u53bf\u957f).\nIndia.\nIn India, each state has a ceremonial governor appointed by the president of India. These governors are different from the governors who controlled the British-controlled portions of the Indian Empire (as opposed to the princely states) prior to 1947.\nA governor is the head of a state in India. Generally, a governor is appointed for each state, but after the 7th Constitutional Amendment, of 1956, one governor can be appointed for more than one state.\nIndonesia.\nIn Indonesia, the title \"gubernur\" refers to the highest-ranking executive of a provincial government. The governor and the vice governor are elected by a direct vote from the people as a couple candidate, so the governor is responsible to the provincial residents. The governor has a term of five years to work in office and can be re-elected for another single period. In case of death, disability, or resignation, the vice governor would stand in as acting governor for some time before being inaugurated as the permanent governor.\nThe elected governor is inaugurated by the president, or by the Indonesian minister of home affairs on behalf of the president. In addition, the governor is the representative of the central government in the province and is responsible to the president. The governor's authority is regulated within Law () No. 32/2004 and Governmental Ordinance () No. 19/2010.\nPrincipally, the governor has the tasks and the authorities to lead governmental services in the province, based upon the policies that have been made together with the provincial parliament. The governor is not the superordinate of regents or mayors, but only guides supervises, and coordinates the works of city/municipal and regency governments. In other parts, municipal and regency governments have the right to manage each governance affairs based on the autonomy principle and assistantship duties.\nJapan.\nIn Japan, the title refers to the highest ranking executive of a prefectural government. The governor was elected by a direct vote from the people and had a fixed term of four years. There is no restriction on the number of terms a person may serve as governor. The governor holds considerable power within the prefecture, including the ability to veto ordinances that have been passed by the prefecture assembly, as well as control of the prefecture's budget and the power to dissolve the prefecture assembly. The governor can be subjected to a recall referendum. A total of one to four vice governors are appointed by the governor with the approval of the assembly. In the case of the governor's death, disability, or resignation, a vice governor would stand in as governor or acting governor.\nSee List of governors of Japan for a list of the current governors.\nMalaysia.\nIn Malaysia, each of the four non-monarchical states (Penang, Malacca, Sabah and Sarawak) has a ceremonial governor styled \"Yang di-Pertua Negeri\", appointed to a renewable four-year term by the Yang di-Pertuan Agong, the federal King of Malaysia, on the advice of the prime minister after consulting the state governments. Each of these states has a separate head of government called the \"Ketua Menteri\" or chief minister. The four Yang di-Pertua Negeri are members of the Conference of Rulers; however, they cannot participate in the election of the Yang di-Pertuan Agong, discussions related to the privileges of the Malay rulers and matters concerning the observance of Islam.\nPakistan.\nIn Pakistan, each of the four provinces has a governor who is appointed by the president. The governor is the representative of the federal in their province and is the ceremonial head of the province whereas the chief minister is the head of the provincial government. The governor exercises powers similar to the president's, in their respective province.\nPapua New Guinea.\nIn Papua New Guinea, the leaders of the provinces have been known as governors since August 1995. Previously they were called premiers.\nPhilippines.\nIn the Philippines, the title \"Governor\" (\"Gobernador\" or \"Punong Lalawigan\" in Filipino) refers to the highest-ranking executive of a province. The governor is elected by a direct vote from the people and has a fixed term of three years. A governor can serve only up to a maximum of three consecutive terms. He may however be suspended by either the ombudsman or the president, through the secretary of the interior and local government. He may be removed by the president if found guilty of an administrative case or a criminal act during his tenure. He may be subjected to a recall vote, but unlike a referendum, the voters elect the governor of their choice. In case of death, disability, resignation, forced removal, or suspension, the vice governor, elected separately in the same election for governor, succeeds as governor, or acting governor, as the case may be.\nDuring both the Spanish and American colonial periods, as well as during the Japanese occupation of World War II, the chief executive of the Philippines was the governor-general of the Philippines.\nThe highest ranking executive of the Autonomous Region in Muslim Mindanao was called \"regional governor\". The regional governor is elected every three years, separately from a regional vice governor who replaces the regional governor if the latter vacates the position. Bangsamoro, its replacement, has the wa'l\u012b (Arabic for \"governor\") as its head of the region and is elected by parliament for a six-year term.\nSri Lanka.\nThe provincial councils of the nine provinces of Sri Lanka are headed by governors, as representatives of the president. Prior to 1948, in Ceylon (former name for Sri Lanka), the governor of Ceylon was the head of the British colony.\nThailand.\nIn Thailand, the title \"Governor\" (\u0e1c\u0e39\u0e49\u0e27\u0e48\u0e32\u0e23\u0e32\u0e0a\u0e01\u0e32\u0e23 \"Phuwa Ratcha Gaan\" in Thai) refers to the administrator of each Thai province, who is appointed by the Ministry of Internal Affairs. The only exception is the specially governed district of Bangkok, whose governor is elected by its population.\nOther modern countries in North America.\nUnited States.\nIn the United States, the title \"Governor\" refers to the head of each state or insular territory. Governors retain sovereign power over executive and judiciary, are subordinate to the president of the United States and laws provided by the enumerated powers section of the federal constitution, and serve as the political and ceremonial head of the state. Nearly three-fourths of the states (36) hold gubernatorial elections in the same years as midterm elections (two years offset from presidential elections). Eleven states hold them in the same years as presidential elections (Vermont and New Hampshire hold elections every two years in every even-numbered year), while the remaining five hold them in odd-numbered years (two in the year after a presidential election, three in the year before).\nIn colonial North America, governors were chosen in a variety of ways, depending on how the colony was organized. In the crown colonies of Great Britain, France, and Spain, the governor was chosen by the ruling monarch of the colonizing power or his designees; in British colonies, the Board of Trade was often the primary decision maker. Colonies based on a corporate charter, such as the Connecticut Colony and the Massachusetts Bay Colony, elected their own governors based on rules spelt out in the charter or other colonial legislation. In proprietary colonies, such as the Province of Carolina before it became a crown colony (and was divided into North and South), governors were chosen by the Lords Proprietor who controlled the colony. In the early years of the American Revolutionary War, eleven of the Thirteen Colonies evicted (with varying levels of violence) royal and proprietary governors. The other two colonies (Connecticut and Rhode Island) had corporate charters; Connecticut Governor Jonathan Trumbull was governor before and during the war period, while in Rhode Island, Governor Joseph Wanton was removed from office in 1775 for failing to support the rebel war effort.\nBefore achieving statehood, many of the fifty states were territories. Administered by the federal government, they had governors who were appointed by the president and confirmed by the Senate rather than elected by the resident population.\nMexico.\nIn Mexico, \"governor\" refers to the elected leader of each of the nation's thirty-one Free and Sovereign States with the official Spanish title being \"Gobernador\". Mexican governors are directly elected by the citizens of each state for a six-year term and cannot be re-elected.\nOther modern countries in South America.\nMany of the South American republics (such as Chile and Argentina) have provinces or states run by elected governors, with offices similar in nature to U.S. state governors.\nBrazil.\nUntil the 1930 Revolution, the heads of the Brazilian Provinces, now called States, were styled as (provincial/state) presidents (\"presidentes\"). From 1930 to 1945, they were styled either governors (\"governadores\") or, when appointed by the federal government, intervenors (\"interventores\"). From 1945 on, they have only been called governors.\nModern equivalents.\nAs a generic term, \"governor\" is used for various 'equivalent' politician who are the head of a state or province, rendering other official titles such as:\nThis also applies to non-western or antique culture\nOther meanings of the word.\nThe word \"governor\" refers to a member of \"confederation of governors\" of a \"private sector entity\" who is a shareholder and elected by all of the other shareholders of that private sector entity to be a member of \"confederation of governors\" at a private sector entity (\"for profit\" and \"non-profit\").\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56232", "revid": "22604547", "url": "https://en.wikipedia.org/wiki?curid=56232", "title": "Flour", "text": "Cereal, seed, vegetable or root ground into powder\n \nFlour is a powder used to make many different foods, including baked goods, as well as thickening dishes. It is made by grinding grains, beans, nuts, seeds, roots, or vegetables using a mill. \nCereal flour, particularly wheat flour, is the main ingredient of bread, which is a staple food for many cultures. Archaeologists have found evidence of humans making cereal flour over 14,000 years ago. Other cereal flours include corn flour, which has been important in Mesoamerican cuisine since ancient times and remains a staple in the Americas, while rye flour is a constituent of bread in both Central Europe and Northern Europe. Cereal flour consists either of the endosperm, germ, and bran together, known as whole-grain flour, or of the endosperm alone, which is known as refined flour. 'Meal' is technically differentiable from flour as having slightly coarser particle size, known as degree of comminution. However, the word 'meal' is synonymous with 'flour' in some parts of the world. The processing of cereal flour to produce white flour, where the outer layers are removed, means nutrients are lost. Such flour, and the breads made from them, may be fortified by adding nutrients. As of 2016, it is a legal requirement in 86 countries to fortify wheat flour.\nNut flour is made by grinding blanched nuts, except for walnut flour, for which the oil is extracted first. Nut flour is a popular gluten-free alternative, being used within the \"keto\" and \"paleo\" diets. None of the nuts' nutritional benefits are lost during the grinding process. Nut flour has traditionally been used in Mediterranean and Persian cuisine.\nBean flours are made by grinding beans that have been either dried or roasted. Commonly used bean flours include chickpea, also known as gram flour or besan, made from dried chickpeas and traditionally used in Mediterranean, Middle Eastern and Indian cuisine. Soybean flour is made by soaking the beans to dehull them, before they are dried (or roasted to make kinako) and ground down; at least 97% of the product must pass through a 100-mesh standard screen to be called soya flour, which is used in many Asian cuisines.\nSeed flours like teff are traditional to Ethiopia and Eritrea, where they are used to make flatbread and sourdough, while buckwheat has been traditionally used in Russia, Japan and Italy. In Australia, millstones to grind seed have been found that date from the Pleistocene period.\nRoot flours include arrowroot and cassava. Arrowroot flour (also known as arrowroot powder) is used as a thickener in sauces, soups and pies, and has twice the thickening power of wheat flour. Cassava flour is gluten-free and used as an alternative to wheat flour. Cassava flour is traditionally used in African, South and Central American and Caribbean food.\nVegetable flour is made from dehydrating vegetables before they are milled. These can be made from most vegetables, including broccoli, spinach, squash and green peas. They are rich in fibre and are gluten-free. There have been studies to see if vegetable flour can be added to wheat-flour-based bread as an alternative to using other enrichment methods.\nEtymology.\nThe English word \"flour\" is originally a variant of the word \"flower\", and both words derive from the Old French \"fleur\" or \"flour\", which had the literal meaning \"blossom\", and a figurative meaning \"the finest\". The phrase \"fleur de farine\" meant \"the finest part of the flour\", since flour resulted from the elimination of coarse and unwanted matter from the grain during milling.\nHistory.\nMaize or corn flour has been important in Mesoamerican cuisine since ancient times and remains a staple in the Americas. Rye flour is a constituent of bread in central and northern Europe. Archaeological evidence for making wheat flour dates to at least 6000 BC. In Australia, excavations at the site of Madjedbebe found grindstone used to grind seed dating from the Pleistocene period. In 2018, archaeologists reported finding evidence of bread making at Shubayqa 1, a Natufian hunter-gatherer site more than 14,000 years old in northwest Jordan. The Romans were the first to grind cereals on cone mills. In 1786, at the beginning of the Industrial Era, the first steam-powered flour mill, Albion Mills, Southwark, was completed in London. In the 1930s, some flour began to be enriched with iron, niacin, thiamine and riboflavin. In the 1940s, mills started to enrich flour and folic acid was added to the list in the 1990s.\nDegermed and heat-processed flour.\nAn important problem of the Industrial Revolution was the preservation of flour. Transportation distances and a relatively slow distribution system collided with natural shelf life. The reason for the limited shelf life is the fatty acids of the germ, which react from the moment they are exposed to oxygen. This occurs when grain is milled; the fatty acids oxidize and flour starts to become rancid. Depending on climate and grain quality, this process takes six to nine months. In the late 19th century, this process was too short for an industrial production and distribution cycle. As vitamins, micronutrients and amino acids were completely or relatively unknown in the late 19th century, removing the germ was an effective solution. Without the germ, flour cannot become rancid. Degermed flour became standard. Degermation started in densely populated areas and took approximately one generation to reach the countryside.\nHeat-processed flour is flour where the germ is first separated from the endosperm and bran, then processed with steam, dry heat or microwave and blended into flour again.\nProduction.\nMilling of flour is accomplished by grinding grain between stones or steel wheels. Today, \"stone-ground\" usually means that the grain has been ground in a mill in which a revolving stone wheel turns over a stationary stone wheel, vertically or horizontally with the grain in between.\nRoller mills replaced stone grist mills in the 19th century. The production of flour has historically driven technological development, as attempts to make gristmills and flour mills more productive and less labor-intensive led to the watermill and windmill. These terms are now applied more broadly to uses of water and wind power for purposes other than milling. More recently, the Unifine mill, an impact-type mill, was developed in the mid-20th century.\nComposition of cereal flour.\nFlour contains a high proportion of starches, which are a subset of complex carbohydrates also known as polysaccharides. The kinds of flour used in cooking include all-purpose (North America) or plain flour, self-rising (North America) or self-raising flour, and, in North America, cake flour. The higher the protein content, the harder and stronger the flour, and the more it will produce crispy or chewy breads. The lower the protein, the softer the flour, which is better for cakes, cookies, and pie crusts. Cereal flour consists either of the endosperm, germ, and bran together (whole-grain flour) or of the endosperm alone (refined flour).\nBleached flour.\n\"Bleached flour\" is \"refined\" flour with a chemical whitening (bleaching) agent added. \"Refined\" flour has had the germ and bran, containing much of the nutritional fibre and vitamins, removed and is often referred to as \"white flour\".\nBleached flour is artificially aged using a \"bleaching\" agent, a \"maturing\" agent, or both. A bleaching agent affects the carotenoids responsible for the natural colour of the flour; a \"maturing\" agent also affects gluten development. A maturing agent may either strengthen or weaken gluten development.\nThis is still available in North America, but has been banned in Europe, Australia and New Zealand.\nAdditives.\nThe four most common additives used as bleaching or maturing agents in the US are:\nSome other chemicals used as flour treatment agents to modify color and baking properties include:\nCommon preservatives in commercial flour include:\nFrequency of additives.\nAll bleaching and maturing agents (with the possible exception of ascorbic acid) have been banned in the United Kingdom.\nBromination of flour in the US has fallen out of favor, and while it is not yet actually banned anywhere, few retail flours available to the home baker are bromated anymore.\nMany varieties of flour packaged specifically for commercial bakeries are still bromated. Retail bleached flour marketed to the home baker is now treated mostly with either peroxidation or chlorine gas. Current information from Pillsbury is that their varieties of bleached flour are treated both with benzoyl peroxide and chlorine gas. Gold Medal states that their bleached flour is treated either with benzoyl peroxide or chlorine gas, but no way exists to tell which process has been used when buying the flour at the grocery store.\nOld method of bleaching.\nThe old method of procuring white or \"bleached\" flour did not entail the use of chemical agents at all. Rather, the wheat kernels were moistened with water long enough for the outer kernels of the wheat which contained the bran to soften and, eventually, fall off while grinding. In some places, the leaves of Syrian rue (\"Peganum harmala\") were spread in stratified layers between the layers of grain, and left in such a state for several days, until the fumes emitted from the astringent leaves of the plant caused the outer kernels of the wheat to break down and dissolve, leaving a clean and white flour after grinding.\nEnriched flour.\nDuring the process of making flour, specifically as a result of the bleaching process, nutrients are lost. Some of these nutrients may be replaced during refining \u2013 the result is known as \"enriched\" flour. In the UK most flour, and consequently breads made with it, is required to be fortified with added calcium, iron, thiamine (Vitamin B1) and niacin (Vitamin B3); wholemeal flour is exempt as it inherently contains sufficient of these nutrients.\nCake flour.\nCake flour is the lowest in gluten protein content, with 6\u20137% (5\u20138% from second source) protein to produce minimal binding so the cake \"crumbles\" easily.\nPastry flour.\nPastry flour has the second-lowest gluten protein content, with 7.5\u20139.5% (8\u20139% from second source) protein to hold together with a bit more strength than cakes, but still produce flaky crusts rather than hard or crispy ones.\nPlain or all-purpose flour.\nAll-purpose, or \"AP flour\", or plain flour is medium in gluten protein content at 9.5\u201311.5% (10\u201312% from second source) protein content. It has adequate protein content for many bread and pizza bases, though bread flour and special 00 grade Italian flour are often preferred for these purposes, respectively, especially by artisan bakers. Some biscuits are also prepared using this type of flour. \"Plain\" refers not only to AP flour's middling gluten content but also to its lack of any added leavening agent (as in self-rising flour).\nBread flour.\nBread flour is typically made from hard red winter wheat planted in the fall and harvested in the spring. Hard wheat is high in gluten, a protein that makes dough stretchy. Hard wheat is 11.5\u201313.5% (12\u201314% from second source) protein. The increased protein binds to the flour to entrap carbon dioxide released by the yeast fermentation process, resulting in a better rise and chewier texture.\nHard flour.\nHard is a general term for flours with high gluten protein content, commonly refers to extra strong flour, with 13.5\u201316% (or 14\u201315% from some sources) protein (16% is a theoretically possible protein content). This flour may be used where a recipe adds ingredients that require the dough to be extra strong to hold together in their presence, or when strength is needed for constructions of bread (e.g., some centerpiece displays).\nGluten flour.\nGluten flour is refined gluten protein, or a theoretical 100% protein (though practical refining never achieves a full 100%). It is used to strengthen flour as needed. For example, adding approximately one teaspoon per cup of AP flour gives the resulting mix the protein content of bread flour. It is commonly added to whole grain flour recipes to overcome the tendency of greater fiber content to interfere with gluten development, needed to give the bread better rising (gas holding) qualities and chew.\nUnbleached flour.\nUnbleached flour is simply flour that has not undergone bleaching and therefore does not have the color of \"white\" flour. An example is graham flour, whose namesake, Sylvester Graham, was against using bleaching agents, which he considered unhealthy.\nSelf-raising flour.\nIn English-speaking countries, self-raising (or self-rising in North America) flour is commercially available with chemical leavening agents already in the mix. In America, it is also likely to be pre-salted; in Britain this is not the case. The added ingredients are evenly distributed throughout the flour, which aids a consistent rise in baked goods. This flour is generally used for preparing amongst others sponge cakes, scones and muffins. It was invented by Henry Jones and patented in 1845. If a recipe calls for self-raising flour, and this is not available, the following substitution is possible:\nTypes.\nGluten-containing flours.\nWheat flour.\nWheat is the grain most preferred cereal used to make flour. Flours can contain differing levels of the protein gluten. \"Strong flour\" or \"hard flour\" has a higher gluten content than \"weak\" or \"soft\" flour. \"Brown\" and wholemeal flours may be made of hard or soft wheat.\nGluten-free flours.\nWhen flours do not contain gluten, they are suitable for people with gluten-related disorders, such as coeliac disease, non-celiac gluten sensitivity or wheat allergy, among others. Contamination with gluten-containing cereals can occur during grain harvesting, transporting, milling, storing, processing, handling and/or cooking.\nMore types.\nFlour also can be made from soybeans, arrowroot, taro, cattails, manioc, quinoa, and other non-cereal foodstuffs.\nDangers.\nFlammability.\nFlour dust suspended in air is explosive\u2014as is any mixture of a finely powdered flammable substance with air. Some devastating explosions have occurred at flour mills, including the Tradeston Flour Mills, in Glasgow, Scotland, which exploded in 1872 killing eighteen people, and an explosion in 1878 at the Washburn \"A\" Mill in Minneapolis that killed 22 people.\nPathogens.\nIn the US, the Centers for Disease Control and Prevention has cautioned not to eat raw flour doughs or batters. Raw flour could contain harmful bacteria such as \"E. coli\" that were possibly in the ground when the cereal was growing. It is recommended that flour should be cooked like other foods to kill the bacteria. Similar advice has been issued by food standard agencies across the world.\nFraud.\nDuring the industrial revolution, wheat and corn flour fraud became more common as it was mixed with chalk or gypsum dust.\nProducts.\nBread, pasta, crackers, many cakes, and many other foods are made using flour. Wheat or Corn flour is also used to make a roux as a base for thickening gravy and sauces.\nIt can also be used as an ingredient in papier-m\u00e2ch\u00e9 glue.\nCornstarch is a principal ingredient used to thicken many puddings or desserts, and is the main ingredient in packaged custard.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "56233", "revid": "7777", "url": "https://en.wikipedia.org/wiki?curid=56233", "title": "Pilot programming language", "text": ""}
{"id": "56234", "revid": "424237966", "url": "https://en.wikipedia.org/wiki?curid=56234", "title": "Umeaa", "text": ""}
{"id": "56239", "revid": "48780248", "url": "https://en.wikipedia.org/wiki?curid=56239", "title": "Acrylamide", "text": "Organic chemical compound\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nAcrylamide (or acrylic amide) is an organic compound with the chemical formula CH2=CHC(O)NH2. It is a white odorless solid, soluble in water and several organic solvents. From the chemistry perspective, acrylamide is a vinyl-substituted primary amide (CONH2). It is produced industrially mainly as a precursor to polyacrylamides, which find many uses as water-soluble thickeners and flocculation agents.\nAcrylamide forms in burnt areas of food, particularly starchy foods like potatoes, when cooked with high heat, above . Despite health scares following this discovery in 2002, and its classification as a probable carcinogen, there is ongoing debate as to whether acrylamide consumed through diet is likely to cause cancer in humans; Cancer Research UK categorized the idea that eating burnt food causes cancer as a myth.\nProduction.\nAcrylamide can be prepared by the hydration of acrylonitrile, which is catalyzed enzymatically:\nCH2=CHCN + H2O \u2192 CH2=CHC(O)NH2\nThis reaction also is catalyzed by sulfuric acid as well as various metal salts. Treatment of acrylonitrile with sulfuric acid gives acrylamide sulfate, . This salt can be converted to acrylamide with a base or to methyl acrylate with methanol.\nUses.\nThe majority of acrylamide is used to manufacture various polymers, especially polyacrylamide. This water-soluble polymer, which has very low toxicity, is widely used as thickener and flocculating agent. These functions are valuable in the purification of drinking water, corrosion inhibition, mineral extraction, and paper making. Polyacrylamide gels are routinely used in medicine and biochemistry for purification and assays.\nToxicity and carcinogenicity.\nAcrylamide can arise in some cooked foods via a series of steps by the reaction of the amino acid asparagine and glucose. This condensation, one of the Maillard reactions, followed by dehydrogenation produces \"N\"-(-glucos-1-yl)--asparagine, which upon pyrolysis generates some acrylamide.\nThe discovery in 2002 that some cooked foods contain acrylamide attracted significant attention to its possible biological effects. IARC, NTP, and the EPA have classified it as a probable carcinogen, although epidemiological studies (as of 2019) suggest that dietary acrylamide consumption does not significantly increase people's risk of developing cancer.\nEurope.\nAccording to the EFSA, the main toxicity risks of acrylamide are \"Neurotoxicity, adverse effects on male reproduction, developmental toxicity and carcinogenicity\". However, according to their research, there is no concern on non-neoplastic effects. Furthermore, while the relation between consumption of acrylamide and cancer in rats and mice has been shown, it is still unclear whether acrylamide consumption has an effect on the risk of developing cancer in humans, and existing epidemiological studies in humans are very limited and do not show any relation between acrylamide and cancer in humans. Food industry workers exposed to twice the average level of acrylamide do not exhibit higher cancer rates.\nUnited States.\nAcrylamide is classified as an extremely hazardous substance in the United States as defined in Section 302 of the U.S. Emergency Planning and Community Right-to-Know Act (42 U.S.C. 11002), and is subject to strict reporting requirements by facilities which produce, store, or use it in significant quantities.\nAcrylamide is considered a potential occupational carcinogen by U.S. government agencies and classified as a Group 2A carcinogen by the IARC. The Occupational Safety and Health Administration and the National Institute for Occupational Safety and Health have set dermal occupational exposure limits at 0.03\u00a0mg/m3 over an eight-hour workday.\nOpinions of health organizations.\nBaking, grilling or broiling food causes significant concentrations of acrylamide. This discovery in 2002 led to international health concerns. Subsequent research has however found that it is not likely that the acrylamides in burnt or well-cooked food cause cancer in humans; Cancer Research UK categorizes the idea that burnt food causes cancer as a \"myth\".\nThe American Cancer Society says that laboratory studies have shown that acrylamide is likely to be a carcinogen, but that as of 2019[ [update]] evidence from epidemiological studies suggests that dietary acrylamide is unlikely to raise the risk of people developing most common types of cancer.\nHazards.\nRadiolabeled acrylamide is also a skin irritant and may be a tumor initiator in the skin, potentially increasing risk for skin cancer. Symptoms of acrylamide exposure include dermatitis in the exposed area, and peripheral neuropathy.\nLaboratory research has found that some phytochemicals may have the potential to be developed into drugs which could alleviate the toxicity of acrylamide.\nMechanism of action.\nAcrylamide is metabolized to the genotoxic derivative glycidamide. On the other hand, acrylamide and glycidamide can be detoxified via conjugation with glutathione.\nOccurrence in food.\nAcrylamide was discovered in foods, mainly in starchy foods, such as potato chips (UK: \"potato crisps\"), French fries (UK: \"chips\"), and bread that had been heated higher than . Production of acrylamide in the heating process was shown to be temperature-dependent. It was not found in food that had been boiled, or in foods that were not heated.\nAcrylamide has been found in roasted barley tea, called \"mugicha\" in Japanese. The barley is roasted so it is dark brown prior to being steeped in hot water. The roasting process produced 200\u2013600 micrograms/kg of acrylamide in mugicha. This is less than the &gt;1000 micrograms/kg found in potato crisps and other fried whole potato snack foods cited in the same study and it is unclear how much of this enters the drink to be ingested. Rice cracker and sweet potato levels were lower than in potatoes. Potatoes cooked whole were found to have significantly lower acrylamide levels than the others, suggesting a link between food preparation method and acrylamide levels.\nAcrylamide levels appear to rise as food is heated for longer periods of time. Although researchers are still unsure of the precise mechanisms by which acrylamide forms in foods, many believe it is a byproduct of the Maillard reaction. In fried or baked goods, acrylamide may be produced by the reaction between asparagine and reducing sugars (fructose, glucose, etc.) or reactive carbonyls at temperatures above .\nLater studies have found acrylamide in black olives, dried plums, dried pears, coffee, and peanuts.\nThe US FDA has analyzed a variety of U.S. food products for levels of acrylamide since 2002.\nOccurrence in cigarettes.\nCigarette smoking is a major acrylamide source. It has been shown in one study to cause an increase in blood acrylamide levels three-fold greater than any dietary factor.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56241", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=56241", "title": "Premier", "text": "Title of the head of government in some countries\nPremier is a title for the head of government in central governments, state governments and local governments of some countries. A second in command to a premier is designated as a deputy premier.\nA premier will normally be a head of government, but is not the head of state. In presidential systems, the two roles are often combined into one, whereas in parliamentary systems of government the two are usually kept separate.\nRelationship to the term \"prime minister\".\n\"Premier\" is often the title of the heads of government in sub-national entities, such as the provinces and territories of Canada, states of the Commonwealth of Australia, provinces of South Africa, the island of Nevis within the Federation of Saint Kitts and Nevis. In some of these cases, the formal title remains \"Prime Minister\" but \"Premier\" is used to avoid confusion with the national leader. In these cases, care should be taken not to confuse the title of \"premier\" with \"prime minister\". In these countries, terms such as \"Federal Premier\", \"National Premier\" or \"Premier of the Dominion\" were sometimes used to refer to prime ministers, although these are now obsolete.\nEtymology.\nThe word comes from French which means prime minister. \"Premier\" meaning 'first', coming from Latin \"pr\u012bm\u0101rius\". This is why in many nations, \"premier\" is used interchangeably with \"prime minister\".\nExamples by country.\n Australia \u2013 \"premier\" is the official title for the heads of government in Australia's six states. The term \"chief minister\" is the title of the head of government in Australia's two self-governing territories, and is effectively equivalent to a premier.\n Canada \u2013 \"premier\" is used for the heads of government in Canada's 13 Provinces and territories. \" is the French term for both the Prime Minister of the Canadian federal government and a provincial/territorial premier, so context and/or the office holder's name is needed to determine to which level of government one is referring. For example, the \"\n People's Republic of China \u2013 \"premier\" is more common and official, but \"prime minister\" is still used (see Premier of the People's Republic of China).\n Taiwan \u2013 the head of government is officially the President of the Executive Yuan, but it can also be abbreviated to Premier.\n Cayman Islands \u2013 the head of government is referred to as the \u201cPremier\u201d, however, as a British Overseas Territory, the British Monarch is the head of state, and the British government often has the last say on external affairs.\n Bosnia and Herzegovina \u2013 \"Premier\" means the \"Prime Minister\". In the Federation of Bosnia and Herzegovina, a sub-national entity of Bosnia and Herzegovina, as well as in the cantons, the head of government has the formal title of \"premier\", often anglicized as \"prime minister\", while the national prime minister is Chairman of the Council of Ministers of Bosnia and Herzegovina, but \"premier\" is sometimes colloquially used.\n Czechia \u2013 the head of government is colloquially called \u201cPremi\u00e9r\u201d, and the Czech language translates both \u201cPremier\u201d and \u201cPrime Minister\u201d as \u201cPremi\u00e9r\u201d. However, although his post is commonly translated in English as \u201cPrime Minister\u201d, the official title as per articles 67 and 68 of the Constitution is \u201cP\u0159edseda vl\u00e1dy\u201d, literally \u201cPresident of the Government\u201d.\n Croatia \u2013 the head of government is officially called \u201cPresident of the Government\u201d (\"predsjednik vlade\") but \u201cPremier\u201d (\"premijer\") is colloquially used.\n Serbia \u2013 the head of government is officially called \"President of the Government\" (\"predsednik vlade\") but \"Premier\" (\"premijer\") is colloquially used.\n Poland \u2013 the head of government is officially called \"President of the Council of Ministers\" () but \"Premier\" (polish for Prime Minister) is colloquially used.\n Italian Republic \u2013 the President of the Council of Ministers, an office equivalent to prime minister, is informally referred to as the \"Premier\".\n North Macedonia \u2013 the head of the government is named premier (Macedonian \u043f\u0440\u0435\u043c\u0438\u0435\u0440, \"premier\"), usually translated in English as prime minister.\n Soviet Union \u2013 the title of premier was applied to the Chairman of the Council of People's Commissars, named Chairman of the Council of Ministers after 1946, which became the Prime Minister of the Soviet Union in 1991.\n Malaysia \u2013 the head of the Sarawak state government is known as the Premier of Sarawak following a state constitutional amendment in 2022, a move widely seen to reflect the status of Sarawak as an equal partner with Sabah and Malaya in Malaysia as stipulated in the 1963 Malaysia Agreement (MA63).\n Netherlands \u2013 the term premier is colloquially used as a synonym of prime minister. In the Dutch language, the official and also commonly used term is \"minister president\", so this is even a third synonym, but this is normally not translated literally into the English language.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56243", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=56243", "title": "Ixtab", "text": "Yucatec Maya goddess of suicide\nAt the time of the Spanish conquest of Yucat\u00e1n (1527\u20131546), Ix Tab or Ixtab ([i\u0283\u02c8ta\u0253]; \"Rope Woman\", \"Hangwoman\") was the indigenous Maya goddess of suicide by hanging. Playing the role of a psychopomp, she would accompany such suicides to heaven.\nSources.\nThe only description of the goddess occurs in the \"Relaci\u00f3n\" of the 16th-century Spanish inquisitor Diego de Landa:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;They said also and held it as absolutely certain that those who hanged themselves went to this heaven of theirs; and on this account, there were many persons who on slight occasions of sorrows, troubles or sickness, hanged themselves in order to escape these things and to go and rest in their heaven [\"gloria\"], where they said that the goddess of the gallows [\"la diosa de la horca\"], whom they called Ix Tab, would bring them.\nBeyond this description, there is only a very brief and somewhat obscure mention of Ix Tab in the Book of Chilam Balam of Tizimin and in the P\u00e9rez Codex, in a context of chaos, suffering, and hangings: \"They suspended Ix Tab from their hands\", or, alternatively, \"Ix Tab suspended them from her hands\".\nComparisons.\n\"Ix Tab\" is the female form of \"ah tab\", \"hangman\". The function of Ix Tab as a benevolent \"hangwoman\" could derive from a basic association with snares. Landa (Tozzer 1941: 155) mentions the hunting deity [\"Ah\"] \"Tabay\" (\"Ensnarer\" or \"Deceiver\"), possibly a patron of hunting with snares, including such that hoist the prey into the air. Animals hoisted by such snares are found depicted in the Dresden and Madrid codices, the Madrid codex (MC45c) personifying one of these traps by a male hunting deity. Ix Tab could be understood as a specialized, female form of such a deity, luring the human quarry into the hanging rope personified by her. Suicides freely putting their heads into this \"snare\" (prompted, perhaps, by a dream) could then be seen to consecrate themselves to her. On the other hand, the Xtabay of contemporary folklore is a seductive female demon \"ensnaring\" or \"deceiving\" her male human preys so as to madden and destroy them.\nDresden Codex.\nThe Dresden Codex picture (DC53b) of a dead woman with a rope around the neck, suspended from a celestial bar, is often, and without further proof, taken to represent Ix Tab. However, since the picture occurs in a section devoted to eclipses of sun and moon, it may rather have been used to symbolize a lunar eclipse and its dire consequences for women, who were intimately associated with the moon goddess.\nAs possible fabrication.\nIt has been claimed that the Pre-Spanish Maya did not have a suicide goddess, or a significant narrative of suicide by hanging. Originally, Ix Tab may only have been a hunting goddess (see above, Comparisons). Today, the sensationalist idea of a \"cult of Ix Tab\" appears to be invoked by popular Yucatecan media to portray suicide as an indigenous problem, given that Yucat\u00e1n has a suicide rate more than twice that of Mexico at large.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56244", "revid": "43004103", "url": "https://en.wikipedia.org/wiki?curid=56244", "title": "Antonio Gramsci", "text": "Italian Marxist philosopher, writer, and politician (1891\u20131937)\nAntonio Francesco Gramsci ( , ; ; 22 January 1891 \u2013 27 April 1937) was an Italian Marxist philosopher and politician. He was a founding member and one-time leader of the Italian Communist Party. A vocal critic of Benito Mussolini and fascism, he was imprisoned in 1926, and remained in prison until shortly before his death in 1937.\nDuring his imprisonment, Gramsci wrote more than 30 notebooks and 3,000 pages of history and analysis. His \"Prison Notebooks\" are considered a highly original contribution to 20th-century political theory. Gramsci drew insights from varying sources\u2014not only other Marxists but also thinkers such as Niccol\u00f2 Machiavelli, Vilfredo Pareto, Charles Darwin, Sigmund Freud, Friedrich Nietzsche, Pierre Joseph Proudhon, Georges Sorel, and Benedetto Croce. The notebooks cover a wide range of topics, including the history of Italy and Italian nationalism, the French Revolution, fascism, Taylorism and Fordism, civil society, the state, historical materialism, folklore, religion, and high and popular culture.\nGramsci is best known for his theory of cultural hegemony, which describes how the state and ruling capitalist class\u2014the bourgeoisie\u2014use cultural institutions to maintain wealth and power in capitalist societies. In Gramsci's view, the bourgeoisie develops a hegemonic culture using ideology rather than violence, economic force, or coercion. He also attempted to break from the economic determinism of orthodox Marxist thought, and so is sometimes described as a neo-Marxist. He held a humanistic understanding of Marxism, seeing it as a philosophy of praxis and an absolute historicism that transcends traditional materialism and traditional idealism.\nLife.\nEarly life.\nGramsci was born in Ales, in the province of Oristano, on the island of Sardinia, the fourth of seven sons of Francesco Gramsci (1860\u20131937) and Giuseppina Marcias (1861\u20131932). Francesco Gramsci was born in the small town of Gaeta, in the province of Latina, Lazio (today in the central Italian region of Lazio but at the time Gaeta was still part of Terra di Lavoro of Southern Italy), to a well-off family from the southern Italian regions of Campania and Calabria and of Arb\u00ebresh\u00eb (Italo-Albanian) descent. Gramsci himself believed that his father's family had left Albania as recently as 1821. The Albanian origin of his father's family is attested in the surname Gramsci, an Italianised form of \"Gramshi\", which stems from the definite noun of the placename Gramsh, a small town in central-eastern Albania. Gramsci's mother belonged to a Sardinian landowning family from Sorgono, in the province of Nuoro. Francesco Gramsci worked as a low-level official, and his financial difficulties and troubles with the police forced the family to move about through several villages in Sardinia until they finally settled in Ghilarza. During his youth in Sardinia Antonio Gramsci cultivated a deep appreciation for literature and theater\u2014reading works by Italian and European authors.\nIn 1898, Gramsci's father was convicted of embezzlement and imprisoned, reducing his family to destitution. The young Gramsci had to abandon schooling and work at various casual jobs until his father's release in 1904. As a boy, Gramsci suffered from health problems, particularly a malformation of the spine that stunted his growth, as his adult height was less than 5 feet, and left him seriously hunchbacked. For decades, it was reported that his condition had been due to a childhood accident\u2014specifically, having been dropped by a nanny\u2014but more recently it has been suggested that it was due to Pott disease, a form of tuberculosis that can cause deformity of the spine. Gramsci was also plagued by various internal disorders throughout his life.\nGramsci started secondary school in Santu Lussurgiu and completed it in Cagliari, where he lodged with his elder brother Gennaro, a former soldier whose time on the mainland had made him a militant socialist. At the time, Gramsci's sympathies did not yet lie with socialism but rather with Sardinian autonomism, as well as the grievances of impoverished Sardinian peasants and miners, whose mistreatment by the mainlanders would later deeply contribute to his intellectual growth. They perceived their neglect as a result of privileges enjoyed by the rapidly industrialising Northern Italy, and they tended to turn to a growing Sardinian nationalism, brutally repressed by troops from the Italian mainland, as a response.\nTurin.\nIn 1911, Gramsci won a scholarship to study at the University of Turin, sitting the exam at the same time as Palmiro Togliatti. At Turin, he read literature and took a keen interest in linguistics, which he studied under Matteo Bartoli. Gramsci was in Turin while it was going through industrialization, with the Fiat and Lancia factories recruiting workers from poorer regions. Trade unions became established, and the first industrial social conflicts started to emerge. Gramsci frequented socialist circles as well as associating with Sardinian emigrants on the Italian mainland. Both his earlier experiences in Sardinia and his environment on the mainland shaped his worldview. Gramsci joined the Italian Socialist Party (PSI) in late 1913, where he would later occupy a key position and observe from Turin the Russian Revolution.\nAlthough showing a talent for his studies, Gramsci had financial problems and poor health. Together with his growing political commitment, these led to him abandoning his education in early 1915, at age 24. By this time he had acquired an extensive knowledge of history and philosophy. At university, he had come into contact with the thought of Antonio Labriola, Rodolfo Mondolfo, Giovanni Gentile, and most importantly, Benedetto Croce, possibly the most widely respected Italian intellectual of his day. Labriola especially propounded a brand of Hegelian Marxism that he labelled \"philosophy of praxis\". Although Gramsci later used this phrase to escape the prison censors, his relationship with this current of thought was ambiguous throughout his life.\nFrom 1914 onward, Gramsci's writings for socialist newspapers such as \"Il Grido del Popolo\" (The Cry of the People) earned him a reputation as a notable journalist. In 1916 he became co-editor of the Piedmont edition of \"Avanti!\", the Socialist Party official organ. An articulate and prolific writer of political theory, Gramsci proved a formidable commentator, writing on all aspects of Turin's social and political events. Gramsci was at this time also involved in the education and organisation of Turin workers; he spoke in public for the first time in 1916 and gave talks on topics such as Romain Rolland, the French Revolution, the Paris Commune, and the emancipation of women. In the wake of the arrest of Socialist Party leaders that followed the revolutionary riots in August 1917, Gramsci became one of Turin's leading socialists; he was elected to the party's provisional committee and also made editor of \"Il Grido del Popolo\".\nIn April 1919, with Togliatti, Angelo Tasca and Umberto Terracini, Gramsci set up the weekly newspaper \"L'Ordine Nuovo\" (The New Order). In October of the same year, despite being divided into various hostile factions, the PSI moved by a large majority to join the Third International. Vladimir Lenin saw the \"L'Ordine Nuovo\" group as closest in orientation to the Bolsheviks, and it received his backing against the anti-parliamentary programme of a left communist, Amadeo Bordiga.\nIn the course of tactical debates within the party, Gramsci's group mainly stood out due to its advocacy of workers' councils, which had come into existence in Turin spontaneously during the large strikes of 1919 and 1920. For Gramsci, these councils were the proper means of enabling workers to take control of the task of organising production, and saw them as preparing \"the whole class for the aims of conquest and government\". Although he believed his position at this time to be in keeping with Lenin's policy of \"All Power to the Soviets\", his stance that these Italian councils were communist rather than just one organ of political struggle against the bourgeoisie, was attacked by Bordiga for betraying a syndicalist tendency influenced by the thought of Georges Sorel and Daniel De Leon. By the time of the defeat of the Turin workers in spring 1920, Gramsci was almost alone in his defence of the councils.\nCommunist Party of Italy.\nThe failure of the workers' councils to develop into a national movement convinced Gramsci that a Communist party in the Leninist sense was needed. The group around \"L'Ordine Nuovo\" declaimed incessantly against the PSI's centrist leadership and ultimately allied with Bordiga's far larger abstentionist faction. On 21 January 1921, in the town of Livorno (Leghorn), the Communist Party of Italy (, PCd'I) was founded. In opposition to Bordiga, Gramsci supported the \"Arditi del Popolo\", a militant anti-fascist group which struggled against the Blackshirts. Gramsci would be a leader of the party from its inception but was subordinate to Bordiga, whose emphasis on discipline, centralism and purity of principles dominated the party's programme until the latter lost the leadership in 1924. In 1922, Gramsci travelled to Russia as a representative of the new party. Here, he met Julia Schucht (Yulia Apollonovna Schucht, 1896\u20131980), a young Jewish violinist whom he married in 1923 and with whom he had two sons, Delio (1924\u20131982) and Giuliano (1926\u20132007). Gramsci never saw his second son.\nThe Russian mission coincided with the advent of fascism in Italy, and Gramsci returned with instructions to foster, against the wishes of the PCd'I leadership, a united front of leftist parties against fascism. Such a front would ideally have had the PCd'I at its centre, through which Moscow would have controlled all the leftist forces, but others disputed this potential supremacy, as socialists had a significant, while communists seemed relatively young and too radical. Many believed that an eventual coalition led by communists would have functioned too remotely from political debate, and thus would have run the risk of isolation.\nIn late 1922 and early 1923, Benito Mussolini's government embarked on a campaign of repression against the opposition parties, arresting most of the PCd'I leadership, including Bordiga. At the end of 1923, Gramsci travelled from Moscow to Vienna, where he tried to revive a party torn by factional strife. In 1924, Gramsci, now recognised as head of the PCd'I, gained election as a deputy for the Veneto. He started organizing the launch of the official newspaper of the party, called (Unity), living in Rome while his family stayed in Moscow. At its Lyon Congress in January 1926, Gramsci's theses calling for a united front to restore democracy to Italy were adopted by the party.\nIn 1926, Joseph Stalin's manoeuvres inside the Bolshevik party moved Gramsci to write a letter to the Comintern in which he deplored the opposition led by Leon Trotsky but also underlined some presumed faults of the leader. Togliatti, in Moscow as a representative of the party, received the letter, opened it, read it, and decided not to deliver it. This caused a difficult conflict between Gramsci and Togliatti which they never completely resolved.\nImprisonment and death.\nOn 9 November 1926, the Fascist government enacted a new wave of emergency laws, taking as a pretext an alleged attempt on Mussolini's life that had occurred several days earlier. The Fascist police arrested Gramsci, despite his parliamentary immunity, and brought him to the Roman prison \"Regina Coeli\". At his trial, Gramsci's prosecutor stated: \"For twenty years we must stop this brain from functioning.\" He received an immediate sentence of five years in confinement on the island of Ustica, and the following year he received a sentence of 20 years' imprisonment in Turi, Apulia, near Bari.\nOver 11 years in prison, his health deteriorated. Over this period, \"his teeth fell out, his digestive system collapsed so that he could not eat solid food... he had convulsions when he vomited blood and suffered headaches so violent that he beat his head against the walls of his cell.\" An international campaign, organised by Piero Sraffa at Cambridge University and Gramsci's sister-in-law Tatiana, was mounted to demand Gramsci's release. In 1933, he was moved from the prison at Turi to a clinic at Formia; he was still being denied adequate medical attention. Two years later, he was moved to the Quisisana clinic in Rome. He was due for release on 21 April 1937 and planned to retire to Sardinia for convalescence, but a combination of arteriosclerosis, pulmonary tuberculosis, high blood pressure, angina, gout, and acute gastric disorders meant that he was too ill to move.\nGramsci died on 27 April 1937, at the age of 46. His ashes are buried in the Cimitero Acattolico in Rome. By moving Gramsci from prison to hospital when he became very ill, the Mussolini regime was attempting to avoid the accusation that it was his incarceration that caused his death. Nevertheless, his death was linked directly to prison conditions. Gramsci's grandson, Antonio Jr., speculated that Gramsci had been working with the Soviet government to facilitate a move to Moscow, but changed course as the political climate in Russia intensified in 1936.\nPhilosophical work.\nGramsci was one of the most influential Marxist thinkers of the 20th century, and a particularly key thinker in the development of Western Marxism. He wrote more than 30 notebooks and 3,000 pages of history and analysis during his imprisonment. These writings, known as the \"Prison Notebooks\", contain Gramsci's tracing of Italian history and nationalism, as well as some ideas in Marxist theory, critical theory, and educational theory associated with his name, such as:\nHegemony.\nHegemony was a term previously used by Marxists such as Vladimir Lenin to denote the political leadership of the working class in a democratic revolution. Gramsci greatly expanded this concept, developing an acute analysis of how the ruling capitalist class\u2014the bourgeoisie\u2014establishes and maintains its control.\nClassical Marxism had predicted that socialist revolution was inevitable in capitalist societies. By the early 20th century, no such revolution had occurred in the most advanced nations, and those revolutions of 1917\u20131923, such as in Germany or the Biennio Rosso in Italy, had failed. As capitalism seemed more entrenched than ever, Gramsci suggested that it maintained control not just through violence and political and economic coercion but also through ideology. The bourgeoisie developed a hegemonic culture, which propagated its own values and norms so that they became the common sense values of all. People in the working class and other classes identified their own good with the good of the bourgeoisie and helped to maintain the \"status quo\" rather than revolting.\nTo counter the notion that bourgeois values represented natural or normal values for society, the working class needed to develop a culture of its own. While Lenin held that culture was ancillary to political objectives, Gramsci saw it as fundamental to the attainment of power that cultural hegemony be achieved first. In Gramsci's view, a class cannot dominate in modern conditions by merely advancing its own narrow economic interests, and neither can it dominate purely through force and coercion. Rather, it must exert intellectual and moral leadership, and make alliances and compromises with a variety of forces. Gramsci calls this union of social forces a \"historic bloc\", taking a term from Georges Sorel. This bloc forms the basis of consent to a certain social order, which produces and re-produces the hegemony of the dominant class through a nexus of institutions, social relations, and ideas.\nIntellectuals and education.\nGramsci gave much thought to the role of intellectuals in society. He stated that all men are intellectuals, in that all have intellectual and rational faculties, but not all men have the social function of intellectuals. He saw modern intellectuals not as talkers but as practical-minded directors and organisers who produced hegemony through ideological apparatuses such as education and the media. Furthermore, he distinguished between a traditional intelligentsia, which sees itself (in his view, wrongly) as a class apart from society, and the thinking groups that every class produces from its own ranks organically. Such organic intellectuals do not simply describe social life in accordance with scientific rules but instead articulate, through the language of culture, the feelings and experiences which the masses could not express for themselves. To Gramsci, it was the duty of organic intellectuals to speak to the obscured precepts of folk wisdom, or common sense (\"senso comune\"), of their respective political spheres. These intellectuals would represent excluded social groups of a society, or what Gramsci referred to as the subaltern.\nIn line with Gramsci's theories of cultural hegemony, he argued that capitalist power needed to be challenged by building a counter-hegemony. By this, he meant that, as part of the war of position, the organic intellectuals and others within the working-class, need to develop alternative values and an alternative ideology in contrast to bourgeois ideology. He argued that the reason this had not needed to happen in Russia was because the Russian ruling class did not have genuine cultural hegemony. So the Bolsheviks were able to carry out a war of manoeuvre (the Russian Revolution of 1917) relatively easily because ruling-class hegemony had never been fully achieved. He believed that a final war of manoeuvre was only possible, in the developed and advanced capitalist societies, when the war of position had been won by the organic intellectuals and the working class building a counter-hegemony.\nThe need to create a working-class culture and a counter-hegemony relates to Gramsci's call for a kind of education that could develop working-class intellectuals, whose task was not to introduce Marxist ideology into the consciousness of the proletariat as a set of foreign notions but to renovate the existing intellectual activity of the masses and make it natively critical of the status quo. His ideas about an education system for this purpose correspond with the notion of critical pedagogy and popular education as theorized and practised in later decades by Paulo Freire in Brazil, and have much in common with the thought of Frantz Fanon. For this reason, partisans of adult and popular education consider Gramsci's writings and ideas important to this day.\nState and civil society.\nGramsci's theory of hegemony is tied to his conception of the capitalist state. Gramsci does not understand the state in the narrow sense of the government. Instead, he divides it between political society (the police, the army, legal system, etc.)\u2014the arena of political institutions and legal constitutional control\u2014and civil society (the family, the education system, trade unions, etc.)\u2014commonly seen as the private or non-state sphere, which mediates between the state and the economy. He stresses that the division is purely conceptual and that the two often overlap in reality.\nGramsci posits that the capitalist state rules through force plus consent: political society is the realm of force and civil society is the realm of consent. He argues that under modern capitalism the bourgeoisie can maintain its economic control by allowing certain demands made by trade unions and mass political parties within civil society to be met by the political sphere. Thus, the bourgeoisie engages in passive revolution by going beyond its immediate economic interests and allowing the forms of its hegemony to change. Gramsci posits that movements such as reformism and fascism, as well as the scientific management and assembly line methods of Frederick Winslow Taylor and Henry Ford respectively, are examples of this.\nDrawing from Niccol\u00f2 Machiavelli, Gramsci argues that the modern Prince\u2014the revolutionary party\u2014is the force that will allow the working class to develop organic intellectuals and an alternative hegemony within civil society. For Gramsci, the complex nature of modern civil society means that a war of position, carried out by revolutionaries through political agitation, the trade unions, advancement of proletarian culture, and other ways to create an opposing civil society was necessary alongside a war of manoeuvre\u2014a direct revolution\u2014in order to have a successful revolution without danger of a counter-revolution or degeneration.\nDespite his claim that the lines between the two may be blurred, Gramsci rejects the state worship that results from equating political society with civil society, as was done by the Jacobins and fascists. He believes the proletariat's historical task is to create a regulated society, where political society is diminished and civil society is expanded. He defines the withering away of the state as the full development of civil society's ability to regulate itself.\nHistoricism.\nLike the young Marx, Gramsci was an emphatic proponent of historicism. In Gramsci's view, all meaning derives from the relation between human practical activity (or praxis) and the objective historical and social processes of which it is a part. Ideas cannot be understood outside their social and historical context, apart from their function and origin. The concepts by which we organise our knowledge of the world do not derive primarily from our relation to objects, but rather from the social relations between the users of those concepts. As a result, there is no such thing as an unchanging human nature but only historically variable social relationships. Furthermore, philosophy and science do not reflect a reality independent of man. Rather, a theory can be said to be true when, in any given historical situation, it expresses the real developmental trend of that situation.\nFor the majority of Marxists, truth was truth no matter when and where it was known, and scientific knowledge, which included Marxism, accumulated historically as the advance of truth in this everyday sense. In this view, Marxism (or the Marxist theory of history and economics) did not belong to the illusory realm of the superstructure because it is a science. In contrast, Gramsci believed Marxism was true in a socially pragmatic sense: by articulating the class consciousness of the proletariat, Marxism expressed the truth of its times better than any other theory. This anti-scientistic and anti-positivist stance was indebted to the influence of Benedetto Croce. At the same time, it should be underlined that Gramsci's absolute historicism broke with Croce's tendency to secure a metaphysical synthesis of historical destiny. Although Gramsci repudiates the charge, his historical account of truth has been criticised as a form of relativism.\nCritique of economism.\nIn a pre-prison article titled \"The Revolution against \"Das Kapital\"\", Gramsci wrote that the October Revolution in Russia had invalidated the idea that socialist revolution had to await the full development of capitalist forces of production. This reflected his view that Marxism was not a determinist philosophy. The principle of the causal primacy of the forces of production was a misconception of Marxism. Both economic changes and cultural changes are expressions of a basic historical process, and it is difficult to say which sphere has primacy over the other.\nThe belief from the earliest years of the workers' movement that it would inevitably triumph due to historical laws was a product of the historical circumstances of an oppressed class restricted mainly to defensive action. This fatalistic doctrine must be abandoned as a hindrance once the working class becomes able to take the initiative. Because Marxism is a philosophy of praxis, it cannot rely on unseen historical laws as the agents of social change. History is defined by human praxis and therefore includes human will. Nonetheless, willpower cannot achieve anything it likes in any given situation: when the consciousness of the working class reaches the stage of development necessary for action, it will encounter historical circumstances that cannot be arbitrarily altered. It is not predetermined by historical inevitability as to which of several possible developments will take place as a result.\nHis critique of economic determinism extended to that practised by the syndicalists of the Italian trade unions. He believed that many trade unionists had settled for a reformist, gradualist approach in that they had refused to struggle on the political front in addition to the economic front. For Gramsci, much as the ruling class can look beyond its own immediate economic interests to reorganise the forms of its own hegemony, so must the working class present its own interests as congruous with the universal advancement of society. While Gramsci envisioned the trade unions as one organ of a counter-hegemonic force in a capitalist society, the trade union leaders simply saw these organizations as a means to improve conditions within the existing structure. Gramsci referred to the views of these trade unionists as vulgar economism, which he equated to covert reformism and liberalism.\nCritique of materialism.\nBy virtue of his belief that human history and collective praxis determine whether any philosophical question is meaningful or not, Gramsci's views run contrary to the metaphysical materialism and copy theory of perception advanced by Friedrich Engels, and Lenin, although he does not explicitly state this. For Gramsci, Marxism does not deal with a reality that exists in and for itself, independent of humanity. The concept of an objective universe outside of human history and human praxis was analogous to belief in God. Gramsci defined objectivity in terms of a universal intersubjectivity to be established in a future communist society. Natural history was thus only meaningful in relation to human history. In his view philosophical materialism resulted from a lack of critical thought, and could not be said to oppose religious dogma and superstition. Despite this, Gramsci resigned himself to the existence of this arguably cruder form of Marxism. Marxism was a philosophy for the proletariat, a subaltern class, and thus could often only be expressed in the form of popular superstition and common sense. Nonetheless, it was necessary to effectively challenge the ideologies of the educated classes and to do so Marxists must present their philosophy in a more sophisticated guise and attempt to genuinely understand their opponents' views.\nLegacy.\nAccording to the American socialist magazine \"Jacobin\", Gramsci \"is one of the most cited Italian authors\u2014certainly the most cited Italian Marxist ever\u2014and one of the most celebrated Marxist philosophers of the twentieth century.\", adding that the \"Prison Notebooks\" \"allowed his unorthodox Marxism to spread worldwide.\"\nGramsci's thought emanates from the organised political left but has also become an important figure in current academic discussions within cultural studies and critical theory. Political theorists from the political centre and the political right have also found insight into his concepts; for instance, his idea of hegemony has become widely cited. His influence is particularly strong in contemporary political science, such as neo-Gramscianism. His critics charge him with fostering a notion of power struggle through ideas. They find the Gramscian approach to philosophical analysis, reflected in current academic controversies, to conflict with open-ended, liberal inquiry grounded in apolitical readings of the classics of Western culture. Some critics have argued that Gramsci's attempt to reconcile Marxism with intellectualism creates an ideological elitism that can be seen as at odds with individual liberty.\nHis theory of hegemony has drawn criticism from those who believe that the promotion of state intervention in cultural affairs risks undermining the free exchange of ideas, which is essential for a truly open society.\nAs a socialist, Gramsci's legacy has been met with a mixed reception. Togliatti, who led the party (renamed in 1943 as the Italian Communist Party, PCI) after World War II and whose gradualist approach was a forerunner to Eurocommunism, stated that the PCI's practices during this period were congruent with Gramscian thought. It is speculated that he would likely have been expelled from his party if his true views had been known, particularly his growing hostility towards Joseph Stalin.\nOne issue for Gramsci related to his speaking on topics of violence and when it might be justified or not. When the socialist Giacomo Matteotti was murdered, Gramsci did not condemn the murder. Matteotti had already called for the rule of law and had been murdered by the fascists for that stance. The murder produced a crisis for the Italian fascist regime that Gramsci could have exploited. The historian Jean-Yves Fr\u00e9tign\u00e9 argues that Gramsci and the socialists more generally were na\u00efve in their assessment of the fascists and as a result underestimated the brutality of which the regime was capable.\nIn Thailand, Piyabutr Saengkanokkul, an academic, democratic activist, and former Secretary-General of Future Forward Party, cited Gramsci's idea as the main key to establishing a party.\nPersonal life.\nFootball.\nLike fellow Turinese and communist Palmiro Togliatti, Gramsci took an interest in football, which was becoming a sport with massive following and was elected by the fascist regime in Italy as a national sport, and was said to have been a supporter of Juventus, as were other notable communist and left-wing leaders. On 16 December 1988, the PCI's newspaper \"l'Unit\u00e0\" published an article on the front page titled \"Gramsci Was Rooting for Juve\". Signed by Giorgio Fabre, it contained some letters in which Gramsci asked Piero Sraffa for \"news from our Juventus\". Even though those letters later turned out to be false, the article remains part of the Gramscian bibliography and triggered numerous reactions, including from Giampiero Boniperti, who on behalf of the club the following day told at \"La Stampa\": \"We are pleased to know that among our fans there have been personalities who have marked an era from the political, economic, and intellectual point of view. This shows that Juventus truly have something special, a charm that has never lost strength over the years.\" Gramsci's interest in football dates back to a 16 August 1918 article for the PSI's newspaper \"Avanti!\", titled \"Football and Scopone\". Fifteen years later, he pointed at the degeneration of stadium cheering, which emerged with the advent of fascism and the consequent nationalisation of the sport that he said extinguished political and trade union commitment.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCited sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "56249", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=56249", "title": "X-windows", "text": ""}
{"id": "56250", "revid": "31192532", "url": "https://en.wikipedia.org/wiki?curid=56250", "title": "York Rite", "text": "Masonic body and degree system\nIn Anglo-American Freemasonry, York Rite, sometimes referred to as the American Rite, is one of several Rites of Freemasonry. It is named after York, in Yorkshire, where the Rite was supposedly first practiced.\nA Rite is a series of progressive degrees that are conferred by various Masonic organizations or bodies, each of which operates under the control of its own central authority. The York Rite specifically is a collection of separate Masonic Bodies and associated Degrees that would otherwise operate independently. While the corresponding bodies and degrees are present worldwide, the term is primary used by American freemasons. \nThe three primary bodies in the York Rite are the Chapter of Royal Arch Masons, Council of Royal &amp; Select Masters or Council of Cryptic Masons, and the Commandery of Knights Templar, each of which are governed independently but are all considered to be a part of the York Rite. There are also other organizations that are considered to be directly associated with the York Rite, or require York Rite membership to join such as the York Rite Sovereign College but in general the York Rite is considered to be made up of the aforementioned three. The Rite's name is derived from the city of York, where, according to one Masonic legend, the first meetings of Masons in England took place.\nThe York Rite is also one of the concordant bodies of Freemasonry that a Master Mason may join to further his knowledge of Freemasonry. But the York Rite is not found as a single system worldwide, and outside of the United States there are often significant differences in ritual, as well as organization. However, in most cases, provided that the Grand Body in question regards the parent \"Craft\" jurisdiction as regular, each distinct Order has recognized fraternal inter-relations with the respective Grand Body within the York system.\nYork Rite bodies.\nSince the York Rite is actually a grouping of separate organizations joined in order, each body operates with relative autonomy. And though they are referred to as one rite it is common for individuals to be member of some bodies and not others. For example, in many jurisdictions Cryptic Masonry can be skipped allowing the person to be a member of just the Royal Arch and Knights Templar. It is also common for non-Christians to join only the Royal Arch and Council of Royal &amp; Select Masters, as the Knights Templar require members to be willing to defend the Christian faith, if needed. Membership in the Royal Arch is always required and must be kept in order to maintain membership in the other two bodies.\nDetails on the individual bodies are as follows:\nRoyal Arch Masonry.\nRoyal Arch Masonry is the first order a Master Mason joins in the York Rite. The Chapter works the following degrees:\nCryptic Masonry.\nMembership in the \"Council of Royal &amp; Select Masters\" or the \"Council of Cryptic Masons\" is not required for membership in the Knights Templar in some jurisdictions, so it can be skipped. In others it is required. It is called Cryptic Masonry or the Cryptic Rite because a crypt or underground room figures prominently in the legends told in the degrees.\nIn some jurisdictions, a \"Most Excellent Master\" degree is offered between Select Master and Super Excellent Master, while other jurisdictions do not have the \"Super Excellent Master\" degree.\nKnights Templar (Grand Encampment of Knights Templar of the U.S.A.).\nThe Knights Templar is the final order joined in the York Rite. Unlike other Masonic bodies which only require a belief in a Supreme Being regardless of religion, membership in the Knights Templar is open only to Christian Masons who have completed their Royal Arch and in some jurisdictions their Cryptic Degrees. This body is modeled on the historical Knights Templar to carry on the spirit of their organization. Throughout history it has been claimed that Freemasonry itself was founded by the Knights Templar or that the Knights Templar took refuge in Freemasonry after their persecution. The Grand Encampment of the United States acknowledges the existence of these theories but states that there is no proof to justify such claims.\nA local Knights Templar division is called a Commandery and operates under a state level Grand Commandery as well as The Grand Encampment of the United States. This is unique among Masonic bodies as most report to the state level alone. The Knights Templar confer three orders, and one passing order as opposed to the standard degree system found elsewhere in Freemasonry:\nHonorary Bodies.\nIn addition to the Capitular Degrees, Cryptic Degrees, and Chivalric Orders, there are several Honorary Bodies (sometimes called Invitational Bodies) that are associated with the York Rite and for which membership in a Royal Arch Chapter is requisite. Membership is by invitation only and usually only extended to those who have contributed in some significant way to the York Rite. They consist of:\nEquivalent independent bodies.\nRoyal and Select Masters.\nIn England and Wales, the degrees of \"Select Master, Royal Master, Most Excellent Master\" and \"Super-Excellent Master\" are conferred in a separately warranted organization, the Order of Royal and Select Masters.\nRoyal Arch.\nThe Royal Arch is affiliated with various constitutions worldwide, many of which place different emphasis on the order.\nKnights Templar.\nEngland and Wales.\nOfficially known as \"The United Religious, Military and Masonic Orders of the Temple and of St John of Jerusalem, Palestine, Rhodes and Malta, of England and Wales\", this order is colloquially known as the Knights Templar. Local bodies of Knights Templar are known as Preceptories; local bodies of Knights of St Paul are known as Chapters; local bodies of Knights of Malta are known as Priories; all operate under a Grand or Great Priory, often with an intermediate level of Provincial Priories. Although some jurisdictions maintain a separate Great Priory of the Temple and Great Priory of Malta, as, for example, in England, the Grand Master and other officers of both Great Priories hold simultaneous equal office in both bodies. Three degrees are administered in this system:\nMembership is by invitation and candidates are required to be Master Masons, holders of the degree of the Holy Royal Arch and to sign a declaration that they profess the Doctrine of the Holy and Undivided Trinity."}
{"id": "56251", "revid": "50646338", "url": "https://en.wikipedia.org/wiki?curid=56251", "title": "Harald Fairhair", "text": "Legendary first king of Norway\nHarald Fairhair (; c.\u2009850 \u2013 c.\u2009932) was a Norwegian king. According to traditions current in Norway and Iceland in the eleventh and twelfth centuries, he reigned from c.\u00a0872 to 930 and was the first King of Norway. Supposedly, two of his sons, Eric Bloodaxe and Haakon the Good, succeeded Harald to become kings after his death.\nMuch of Harald's biography is uncertain. A couple of praise poems by his court poet \u00deorbj\u00f6rn Hornklofi survive in fragments, but the extant accounts of his life come from sagas set down in writing around three centuries after his lifetime. His life is described in several of the Kings' sagas, none of them older than the twelfth century. Their accounts of Harald and his life differ on many points, but it is clear that in the twelfth and thirteenth centuries Harald was regarded as having unified Norway into one kingdom.\nSince the nineteenth century, when Norway was in a personal union with Sweden, Harald has become a national icon of Norway and a symbol of independence. Though the king's sagas and medieval accounts have been critically scrutinised during the twentieth and early twenty-first centuries, Harald maintains a reputation as the father of the Norwegian nation. At the turn of the 21st century, a few historians have tried to argue that Harald Fairhair did not exist as a historical figure.\nMeaning of epithet.\nOld Norse translates straightforwardly into English as 'hair', but , the adjective of which is a form, is trickier to render, since it means 'fair, fine, beautiful' (but without the moral associations of English \"fair\", as opposed to \"unfair\"). Although it is convenient and conventional to render in English as 'fair-hair(ed)', in English 'fair-haired' means 'blond', whereas the Old Norse fairly clearly means 'beautiful-haired' (in contrast to the epithet which, according to some sources, Haraldr previously bore: , '(thick) matted hair'). Accordingly, some translators prefer to render as 'the fine-haired' or 'fine-hair' (which, however, unhelpfully implies that Haraldr's hairs were thin) or even 'handsome-hair'.\nHistoricity.\nThrough the nineteenth and most of the twentieth centuries, historians broadly accepted the account of Harald Fairhair given by later Icelandic sagas. However, Peter Sawyer began to cast doubt on this in 1976, and the decades around 2000 saw a wave of revisionist research that suggested that Harald Fairhair did not exist, or at least not in a way resembling his appearance in sagas. The key arguments for this are as follows:\nScholarly consensus on Harald's historicity now falls into two camps. One suggests that the medieval Icelandic and Norwegian historiography of Harald Fairhair is part of an origin myth created to explain the settlement of Iceland, perhaps in which a cognomen of Haraldr Sigur\u00f0arson was transferred to a fictitious early king of all Norway. Sverrir Jakobsson has suggested that the idea of Iceland being settled by people fleeing an overbearing Norwegian monarch actually reflects the anxieties of Iceland in the early thirteenth century, when the island was indeed coming under Norwegian dominance. He has also suggested that the legend of Harald Fairhair developed in the twelfth century to enable Norwegian kings, who were then promoting the idea of primogeniture over the older custom of agnatic succession, to claim that their ancestors had had a right to Norway by lineal descent from the country's supposed first king.\nOne possibility advanced is that Harald Fairhair was based on a historical king called Harald, perhaps also known as \"h\u00e1rfagri\", who ruled Vestlandet. The legend of this Harald later grew into the figure of medieval tradition. Historians who accept the early dating of skaldic poetry such as Claus Krag and Hans Jacob Orning tend to accept Harald's existence, while remaining skeptical regarding the saga accounts. In 2015, Hans Jacob Orning, building on then-recent archaeology and Krag's work, argued that Harald was based in Sogn, an area which the medieval Icelandic historian Snorri Sturluson associated with Harald, and which was a centre of power in the ninth century. In the skaldic poetry (which is generally considered authentic ninth-century work by linguists) the estates mentioned match a convenient network of estates with about a day's traveling distance between them, which would be ideal for a king ruling in Vestlandet, but not all of Norway. This reading could be consistent with the \"Historia Norwegi\u00e6\"'s account. While it is possible that Harald could have controlled other areas through jarls and client kings, this is difficult to prove with available archeology. Krag has noted that Snorri's account of Harald's origin in Vestfold might have been propaganda as the area of Viken was disputed between the Norwegian and Danish crown in the thirteenth century. Krag points of that Othere describes Viken as Danish territory and Hrafnsm\u00e1l's description of the battle of Hafrsfjord suggest that Harald was attacked by \"eastern\" enemies that were routed and fled back east. He proposes that the battle was not part of a war of conquest but Harald defending his own territory from invaders. This idea offers a very different reading of the poem where its references to the \"dr\u00f3ttin Nor\u00f0manna\" (\"lord of the northmen\") might have originally meant referred to the leader of the Norwegians in the battle, but later recontextualised as the lord of all Norwegians.\nAttestations.\nHarald is mentioned in several sagas, some which quotes supposedly older skaldic poetry. If the linguistic dating of the poems are correct, they represent the earliest accounts of Harald Fairhair.\n\"Hrafnsm\u00e1l\".\n\"Hrafnsm\u00e1l\", also known as \"Haraldskv\u00e6\u00f0i\", is a fragmentary skaldic poem generally accepted as being written by the 9th-century skald \u00deorbj\u00f6rn Hornklofi. There does not exist a complete copy of the poem, and modern editions of the poem are based on the compilation of the segments. Through dating of the parts as well as the meter is consistent, they may be separate compositions but scholarly consensus is indecisive. Part of the poem is cited by Snorri in Heimskringla as a source for his narrative of the Battle of Hafrsfjord, while another is cited in Fagrskinna as information about Harald. Both credits Hornklofi as the composer.\nHrafnsm\u00e1l largely consists of a conversation between an unnamed valkyrie and a raven; the two discuss the life and martial deeds of Harald Fairhair. The bulk of the poem seems to describe the Battle of Hafrsfjord, were Harald faced off against Kjotve the Rich and Hakl\u00e1ng. The poem includes elements ubiquitous to later tellings of the king: Harald is described as the son of a \"Halfdan\" and an Yngling, but does not use his famous nickname \"h\u00e1rfagri\" (\"fairhair\"), but uses his widely cited previous nickname \"Lufa\". The poem mentions Ragnhild, who in Heimskringla is presented as Harald's queen and mother of Eirik Bloodaxe, as well as the following of ulfhe\u00f0nar warriors that the saga tradition ascribes to Harald.\n\"Glymdr\u00e1pa\".\nLike Hrafnsm\u00e1l, Glymdr\u00e1pa is a praise poem attributed to \u00deorbj\u00f6rn Hornklofi about various battles won by Harald. It is dated to the late 9th century, but an exact dating is difficult and due to its fragmentary presentation it may be a compilation of unrelated stanzas. Unlike Hrafnsm\u00e1l its relation to Harald and the events it supposedly relates to in Heimskringla is ambiguous.\n\"Sendibitr\".\n\"Sendibitr\", the last and shortest poem Snorri quotes is attributed to J\u00f3runn sk\u00e1ldm\u00e6r (Jorunn the skaldmaiden), one of few female poets mentioned in the sagas. It deals with a conflict between Harald and his son Halfdan, identified in Heimskringla as Halfdan the Black (the Younger), Harald's son by \u00c5sa H\u00e5konsdottir. Finnur J\u00f3nsson dates this poem to the late 10th century. If the dating is correct, it is the first instance of Harald having the epithet \"fairhair\" (\"h\u00e1rfagra\" in the text). However, consensus is that the exact dating is uncertain. It has been suggested that the poem refers to past events, which would mean the poet lived in a later time than the events described in the poem. Linguistic dating of the poem has not been successful.\n\"\u00cdslendingab\u00f3k\".\nThe earliest narrative source which mentions Harald, the twelfth-century \"\u00cdslendingab\u00f3k\", notes that Iceland was settled during his lifetime. Harald is thus depicted as the prime cause of the Norse settlement of Iceland and beyond. Iceland was settled by \"malcontents\" from Norway, who resented Harald's claim of rights of taxation over lands, which the possessors appear to have previously held in absolute ownership. It is the earliest non-skaldic account of Harald to use the nickname \"h\u00e1rfagri\".\n\"Skar\u00f0s\u00e1rb\u00f3k\".\nThe \"Skar\u00f0s\u00e1rb\u00f3k\"-version of \"Landn\u00e1mab\u00f3k\" includes a brief narrative of Harald and his background. Harald is here described as the great-grandson of Sigurd Snake-in-the-Eye through his daughter \u00c1slaug, her son Sigurd Hart and his daughter Ragnhild. The text describes Halfdan the Black's death by going through the ice on Randsfjorden, a story also told by Snorri in Heimskringla, and that Harald became king afterwards. He is said to have taken control of Sogn from Atli jarl due to him never paying taxes. This happened before Harald's conquest of Norway.\n\"\u00c1grip af N\u00f3regskonungas\u00f6gum\".\n\"\u00c1grip af N\u00f3regskonungas\u00f6gum\" is dated to about 1190. Here Harald is described as having become the first king of all of Norway at the age of 20. It describes a battle in \"Hafrsv\u00e1gr\" (as opposed of \"Hafrifjord\") against a king called Skeithar-Brandr (\"Skei\u00f0ar-Brandr\"). The text quotes a poem called \"\"Oddmj\u00f3r\" which describes Harald as a Scylding were as other sources calls him an Yngling. He is described to as having waged wars for 10 years before having conquered all of Norway. He is said to have had 20 children, but that only Eirik Bloodaxe &amp; Hakon the Good becoming kings. In this account, Eirik is described as Harald's eldest son and Hakon as the youngest. Only one of Harald's wives/concubines is named, Snj\u00f3fr\u00edthr, daughter of Sv\u00e1si (Norwegian: \"Sv\u00e5se\"), a beautiful sami-woman. She is described as having died three years after their marriage with Harald mourning for her, but the people mourning for him, considering him bewitched. Eirik is said to have succeeded Harald, ruling for five years, with two as a co-ruler with his father. H\u00e1kon eventually supplanted the cruel and oppressive rule of Eirik and his wife Gunnhildr. H\u00e1kon is said to be a Christian, but swayed from Christianity due to his unnamed pagan wife and his will to please his people.\n\"Historia Norwegi\u00e6\".\n\"Historia Norwegi\u00e6\", which is dated to about 1220, mentions that Iceland was discovered in the time of Harald Fairhair by Ing\u00f3lfr Arnarson and Hj\u00f6rleifr Hr\u00f3\u00f0marsson. The work describes the history of the Yngling-dynasty from the legendary king Ingvi as Harald's ancestors and Halfdan the Black was his father. Halfdan is here described as ruling a mountainous region of Norway and having drowned in Rondvatnet. Harald's rule is said to have lasted for 73 years and his nickname derived from his beautiful hair. Notably, Harald is here described as being the first to rule the entire coastal region of Norway, as opposed to all of Norway. The interior is described to as having been ruled by petty kings, however, it is said that Harald as good as ruled this region as well.\nThis account describes Eirik Bloodaxe as the oldest son of Harald, unlike in Heimskringla. H\u00e1kon is not referred to as \"the good\" and is Harald's second son, not his youngest. This account of H\u00e1kon suggest that he did not accept Christianity. Like the later Heimskringla, Ragnvald Rettilbeine is described as killed on Harald's orders. In Heimskringla he is burned alive by Eirik Bloodaxe, while Historia Norwegi\u00e6 describes Ragnvald as being drowned.\n\"Fagrskinna\".\n\"Fagrskinna\" is thought to have been written around 1220 and is a catalogue of the kings of Norway. The first part describes Harald Fairhair's birth ancestry in form of his paternal grandfather Gudr\u00f8d the Hunter and maternal grandfather Sigurd Snake-in-the-Eye, and his parents Halfdan the Black and Ragnhildr. The text also describes Halfdan having another son called Harald by another woman named Ragnhildr, daughter of the king Harald Goldbeard of Sogn. Halfdan's first Harald inherited Sogn after the death of Harald Goldbeard, and then died himself. Halfdan then inherited Sogn from his first son. The story is repeated by Snorri in \"Heimskringla\" and suggests two conflicting stories of Harald's ancestry being combined into one. Harald Fairhair is said to have inherited Halfdan's lands at a young age after the king drowned in the lake R\u01ebnd in Rykinsvik. The text then sites the poem \"Hrafnsm\u00e1l\" at length as an example of Harald's nobility and prowess in battle. Harald appointed Atli the Slender as jarl of Fjaler, but that the two fell out. In this time Harald meet jarl H\u00e5kon Grjotgardsson (called \"H\u00e1kon the Old\" in the text) at a feast in Hladir (\"Lade\") in Trondheim and gave him part of Atli's fief. Atli defended his old area with violence and both of the jarls were killed. Harald proclaimed he would not cut his hair until having become overlord of Norway and earning tribute from every inland valley and outlying headland, earning him the nickname \"Lufa\"\", \"shockhead\". Harald is said to have fought many battles, including a decisive battle in Hafrfjord against Kjotve the Rich and Haklang. After this battle, all of Norway is said to paid tribute to Harald. Ragnvald jarl then cut Harald's hair and gave him the nickname \"Fairhair\".\nThe text then described Harald's various sons, describing Eirik Bloodaxe as his most beloved and one of his oldest. Harald named Eirik his heir and died in Rogaland from old age and was buried in Haugesund.\n\"Heimskringla\".\nIn the \"Saga of Harald Fairhair\" in \"Heimskringla\" (written around 1230), which is the most elaborate although not the oldest or most reliable source to the life of Harald, it is written that Harald succeeded, on the death of his father Halfdan the Black Gudr\u00f6darson in Rondvatnet, to the sovereignty of several small, and somewhat scattered kingdoms in Vestfold, which had come into his father's hands through conquest and inheritance. His protector-regent was his mother's brother duke Guthorm. He is described as the descendant of the Yngling-dynasty, whose history is described earlier in the work.\nThe unification of Norway is something of a love story. It begins with a marriage proposal that resulted in rejection and scorn from Gyda, the daughter of Eirik, king of Hordaland. She said she refused to marry Harald \"before he was king over all of Norway\". Harald was therefore induced to take a vow not to cut nor comb his hair until he was \"\u00fej\u00f3\u00f0konungr\" (\"people-king\") of Norway, and when he was justified in trimming it ten years later, he exchanged the epithet \"Shockhead\" or \"Tanglehair\" (Haraldr l\u00fafa) for the one by which he is usually known.\nIn 866, Harald made the first of a series of conquests over the many petty kingdoms which would compose all of Norway, including V\u00e4rmland in Sweden, which had sworn allegiance to the Swedish saga-king Erik Eymundsson (whose historicity is not confirmed). Marching up through the Uplands and into Trondheim and then south along the coast Harald subdued many petty kings. Snorri credits his success to excellent leadership by him and his uncle Guthorm, as well as military reforms and his hard tax policy. The taxes demanded by Harald were much higher than other kings and a third of the revenues were given to his jarls. This made jarls and rich farmers flock to his cause to enrich themself. One of these was H\u00e5kon Grjotgardsson of Trondheim who allied with Harald and married off his daughter \u00c5sa to him. Harald established the royal estate of Hlade in Trondheim and H\u00e5kon became the first of the Earls of Lade, a family which would be one of the dominating forces in Norway for the next 150 years. Harald's third principal ally was Rognvald Eysteinsson, jarl of M\u00f8re. Snorri describes Rognvald as Harald's closest friend and the one to coin the name \"Fairhair\". Harald is said to have fathered Bj\u00f8rn Farmann and Olav Geirstadalv with Rognvald's sister Svanhild, ancestors of the famous Christian kings Olav Tryggvason (named after his grandfather Olav Geirstadalv) and Olav the Holy.\nIn 872, after a great victory at Hafrsfjord near Stavanger against Kjotve the Rich, Harald found himself king over the whole country, ruling from his Kongsg\u00e5rd seats at Avaldsnes and Alrekstad. His realm was, however, threatened by dangers from without, as large numbers of his opponents had taken refuge, not only in Iceland, then recently discovered; but also in the Orkney Islands, Shetland Islands, Hebrides Islands, Faroe Islands and the northern European mainland. However, his opponents' leaving was not entirely voluntary. Many Norwegian chieftains who were wealthy and respected posed a threat to Harald; therefore, they were subjected to much harassment from Harald, prompting them to vacate the land. At last, Harald was forced to make an expedition to the West, to clear the islands and the Scottish mainland of some Vikings who tried to hide there.\nSnorri describes Harald's marriage to the daughter of Sv\u00e1si, here called Sn\u00e6frithr, but in his account they are described as j\u00f6tnar rather than finns (sami). Gyda is said to have been made a \"fri\u00f0la\" (concubine) of Harald after her father Eirik of Hordaland had been killed in battle by Harald's followers. Harald is said to have divorced \u00c5sa and rejected Gyda and several other concubines to marry a Jutish princess called Ragnhild the Mighty. The couple only had one child, Eirik Bloodaxe, before her premature death. Eirik Bloodaxe was named after Ragnhild's father as was custom in medieval Scandinavia. Likely due to Eirik Bloodaxe royal mother, he was favored above Harald's other sons. Eirik himself had an unquestioning, near psychopathic loyalty to Harald. Unlike other authors, Snorri does not attribute Eirik's cruelty solely to Gunnhild. When Harald and Sn\u00e6frith's son Ragnvald Rettilbeine became known as patron of sorcerers and a practitioner of magic, Harald ordered him to cease such activity. When Ragnvald did not listen Harald sent Eirik Bloodaxe to murder him. Eirik had his half-brother and all of his sorcerers burned in their hall. When Bj\u00f8rn Farmann was killed in a conflict with Eirik, Harald stepped in on Eirik's side against his other sons.\nThere are several accounts of large feasting mead halls constructed for important feasts when Scandinavian royalty was invited. The V\u00e4rmlandish chieftain \u00c1ki (Swedish \"\u00c5ke jarl\") invited both king Harald Fairhair and the Swedish saga-king Erik Eymundsson, but had the Norwegian king stay in the newly constructed and sumptuous one, because he was the youngest one of the kings and the one who had the greatest prospects. The older Swedish king, on the other hand, had to stay in the old feasting hall. The Swedish king was so humiliated that he killed \u00c1ki. Harald drove Erik Eymundsson out of V\u00e4rmland and inserted \u00c1ki's son Ubbi (Swedish: \"Ubbe\") as jarl. Harald is then said to have made a punitive raid into V\u00e4stra G\u00f6taland, to weaken Erik Eymundsson.\nAs Harald's sons came of age their unruly behavior became a source of instability in Norway. Sn\u00e6frith's sons Halfdan Long-Leg and Gudr\u00f8d Ljome burned Rognvald jarl alive in his hall and took his lands in More and Orkney. Halfdan Long-Legs was killed on Orkney by Rognvald's son Torf-Einarr and Gudr\u00f8d was brought to justice by Harald. The estates in M\u00f8re are returned to Rognvald's other son Thorir the Silent who was given Harald's daughter \u00c5lov in marriage as compensation. A variation of this story also appears in \"Orkneyinga saga\". Afterwards, Gudr\u00f8d was kept in Harald's hird, in a position where Harald could prevent him from similar transgressions.\nThe account describes H\u00e1kon the good as Harald's youngest son, through a servant named Thora.\n\"Egil's Saga\".\nThe thirteenth-century \"Egil's Saga\" presents a broadly similar account to that of \"Heimskringla\", though its depiction of Harald and his family is much more negative. It has been suggested that \"Heimskringla\" and \"Egil's Saga\" share Snorri Sturluson as author, or at least share a common source. Given the difference in attitude to the royal family and information regarding Erik Bloodaxe's family, the latter seems more likely. Through the name Harald Fairhair appears, he is mostly irreverently referred to as Haraldr l\u00fafa. Chapter 3 and 4 tells of Harald's conquest of Norway. It repeats Snorri's story of Harald's vow not to cut his hair until he had become king of all of Norway, but no mention is made of Gyda. Harald is said to have first conquered the Uplands and then taken Trondheim and become overlord over the thronds. This accounts differs from \"Heimskringla\" where it is said that Harald made a marriage alliance with H\u00e5kon Grjotgardsson which won him Tr\u00f8ndelag after they together defeated the petty kings there. The saga then relates the story of the brothers Herlaug and Hrollaug, kings of Namdalen. When Herlaug heard Harald was coming he committed suicide by closing himself into a mound with 12 men. Hrollaug renounced his kingship and took the title of jarl instead. Harald accepted Hrollaug's surrender and allowed him to rule Namdalen in his name. This story is also present in \"Heimskringla\". After this, Namdalen and H\u00e5logaland were in his grasp. The saga then related how Harald did battle with the combined forces of kings Audbj\u00f6rn of Fir\u00f0afylki, Solvi Bandy-legs of M\u00f8re og Romsdal and Arnvid of Sunnm\u00f8re. They were all defeated in battle by Harald, with only Solvi escaping with his life to live the rest of his life as a roving Viking. The remaining independent rulers of Norway were then crushed by Harald's allies or opportunists that attacked their neighbors and then submitted to Harald like Hrollaug had done. The saga tells how people of Norway were then put under heavy taxes and oppression by Harald. Anyone suspected of wanting to rise in rebellion were given the option of fleeing the country, submitting himself as a tenant or having hands and feet cut off. According to the saga author, most who were given this option chose to flee. Harald is supposed to have confiscated massive amounts of private property and made many previously free farmers his thralls. Four sons of Harald are mentioned in the saga: Eirikr Bloodaxe (one of the saga's major antagonists), H\u00e1kon A\u00f0alsteinsf\u00f3stri (otherwise called \"the Good\"), Olaf and \"Sigur\u00f0r\" (whose name is otherwise usually rendered as \"Sigr\u00f6\u00f0r\"). The saga renders Harald's title as \"einv\u00e1ldskonungr\" (\"absolute king\").\n\"Grettis saga\".\nNot unlike \"Egil's Saga\", Harald's conquest of Norway sets off the plot of \"Grettis saga\". Gretti's great-grandfather \u00d6nundr Wood-foot is said to be one of many people that fled Norway after fighting for king Kjotvi the Rich and Thorir Haklang in the battle of Hafrsfjord. The saga describes how Harald and his elite \u00dalfh\u00e8\u00f0nar warriors (famously mentioned in Hrafnsm\u00e1l) fought and killed Thorir Haklang when he went berserk. \u00d6nundr got his name after his leg was crushed beneath the knee by the prow of one of the king's ships and he had to walk on a wooden pegleg for the rest of his life.\n\"Saga of Ragnar Lodbrok\".\nThe 13th century \"Ragnars saga lo\u00f0br\u00f3kar ok sona hans\" (\"Saga of Ragnar Lothbrok and his sons\") mentions Harald Fairhair in chapter 18 as the great-great-grandson of Sigurd Hart through his daughter Aslaug, her son Sigurd Snake-in-the-Eye and his daughter Ragnhild.\n\"Ragnarssona \u00fe\u00e1ttr\".\nHarald's maternal ancestry is elaborated upon in the final chapter of the 14th century \"Ragnarssona \u00fe\u00e1ttr\". Harald's mother is said to have been Ragnhild Sigurdsdotter, who according to the saga was the great-granddaughter of Sigurd through her mother Inibjorg and he grandmother Aslaug. This story is the same as in Snorri's earlier \"H\u00e1lfdanar saga svarta\" in \"Heimskringla\", but contradicts \"Fagrskinna\". Both \"H\u00e1lfdanar saga svarta\" and \"Ragnarssona \u00fe\u00e1ttr\" have issues with the traditional dating of the saga events. The marriage of Sigurd Snake-in-the-Eye and Blaeja could not have occurred earlier than 867, which would put the dating Harald's ascension to kingship of Norway in 872 into question. \"Fagrskinna\" makes no mention of Blaeja and states that Ragnhild Sigurdsdotter was Sigurd Snake-in-the-Eye's daughter and not his great-granddaughter, which seems more plausible in regards to the dating of events.\n\"Fl\u00f3amanna saga\".\n\"Fl\u00f3amanna saga\" is traditionally thought of as a 14th-century work and repeats the story of Harald Fairhair's ancestry as told in \"Saga of Ragnar Lodbrok\", and elaborates back to Sigurd Fafnisbani and Odin through Aslaug. In old Norse society, the ancestry of both parents was considered of importance for the status of a person. The saga relates the conflict between Atli the Slender and H\u00e5kon Grjotgardsson and their deaths. H\u00e5kon's son Sigurd Haakonsson advised Harald to kill Atli's son Hallstein which lead to Hallstein's exile in Iceland.\n\"Vatnsd\u00e6la saga\".\nIn \"Vatnsd\u00e6la saga\" Harald's conquest of Norway is described. The saga's initial protagonist Ingimundr recognises that Harald will prevail at Hafrfjord and arranges a meeting with Harald, Ragnvald M\u00f6rejarl and their ulfhednar-warriors. Ingimundr offers his loyalty to Harald which Harald graciously accepts, but Ingimundr is suspicious of the king and he and his friend S\u00e6mundr emigrate to Iceland. Harald wins an extrodinary victory at Hafrfjord and makes Ragnvald a jarl.\n\"Orkneyinga saga\".\nThe \"Orkneyinga saga\" likely dates to in the early thirteenth century and belongs to belongs to the genre of \"Kings' Sagas\" within Icelandic saga literature, a group of histories of the kings of Norway. It describes in more detail the expedition of Harald Fairhair and Rognvald M\u00f8rejarl on an expedition to clear the islands of the Viking refugees of from Harald's conquest of Norway that raided the coast. During the expedition Rognvald's son Ivar was killed so Harald gave governorship of the islands to him. Rognvald wanted to stay in his home in M\u00f8re so he passed the jarlship of the Islands to his brother Sigurd. The saga is informed by the Norwegian politics of the day. Once, historians could write that no-one denied the reality of Harald Fairhair's expeditions to the west (recounted in detail in the \"Heimskringla\"), but this is no longer the case. Thomson (2008) writes that Harald's \"great voyage is so thoroughly ingrained in popular and scholarly history, both ancient and modern, that it comes as a bit of a shock to realise that it might not be true.\" The Norwegian contest with the Kings of Scots over the Hebrides and the Isle of Man in the mid 13th century is the backdrop to the saga writer's intentions and in part at least the sagas aim to legitimise Norwegian claims to both the Northern Isles and the Kingdom of the Isles in the west.\n\"Flateyjarb\u00f3k\".\nThe fourteenth-century \"Flateyjarb\u00f3k\" features a \u00de\u00e1ttr called \"Haralds \u00fe\u00e1ttr h\u00e1rfagra\", literary \"Harald Fairhair's \u00de\u00e1ttr\". The first chapter describes Harald's ascension to the throne at the age of sixteen, in contrast to other accounts which gives the age of ten. He is here given the otherwise unknown nickname \"Dofrafostri\" (\"Dovre-fostered\"). Harald's maternal uncle Guthormr is described as his duke and most important ally. Harald's war with Gandalf Alfgeirsson and his neighboring kings is described as in \"Heimskringla\", through in less detail. Following this Harald's marriage to Gyda is described and his conquest of Norway. Unlike \"Heimskringla\", \"Flateyjarb\u00f3k\" clearly states that the two were married. Harald's further marriages are described as is his rejections of them and his various concubines in favor of Ragnhild the Mighty. The \u00de\u00e1ttr concludes with a description of the fates of Harald's various sons, including Thorgils' and Frodi's career as \"west-vikings\".\nLater life.\nAccording to the saga sources, the latter part of Harald's reign was disturbed by the strife of his many sons. The number of sons he left varies in the different saga accounts, from 11 to 20. Twelve of his sons are named as kings, two of them ruled over the whole of Norway. He gave them all the royal title and assigned lands to them, which they were to govern as his representatives; but this arrangement did not put an end to the discord, which continued into the next reign. When he grew old, Harald handed over the supreme power to his favourite son Eirik Bloodaxe, whom he intended to be his successor. Eirik I ruled side by side with his father when Harald was 80 years old. In the Gray Goose Laws, a person above the age of 80 was not allowed to make financial decisions or decisions about inheritance. This co-rulership likely reflected similar laws and would also been way for Harald to force his intended succession. Harald died three years later due to old age in approximately 933.\nHarald Harfager was commonly stated to have been buried under a mound at Haugar by the Strait of Karmsund near the present-day Haugesund Church in an area that later would be named the town of Haugesund and Haugesund Municipality. The area near Karmsund was the traditional burial site for several early Norwegian rulers. The national monument of Haraldshaugen was raised in 1872, to commemorate the Battle of Hafrsfjord which is traditionally dated to 872.\nIssue.\nWhile the various sagas name anywhere from 11 to 20 sons of Harald in various contexts, the contemporary skaldic poem \"H\u00e1konarm\u00e1l\" says that Harald's son H\u00e5kon would meet only \"eight brothers\" when arriving in Valhalla, a place for slain warriors, kings, and Germanic heroes. Only the following five names of sons can be confirmed from skaldic poems (with saga claims in parentheses), while the full number of sons remains unknown:\nAccording to \"Heimskringla\".\nThe full list of sons (and partial list of daughters) according to Snorri Sturluson's \"Heimskringla\":\nChildren with \u00c5sa, daughter of H\u00e5kon Grjotgardssson, Jarl av Lade:\nChildren with Gyda Eiriksdottir:\nChildren with Svanhild, daughter of \u00d8ystein Jarl:\nChildren with \u00c5shild, daughter of Ring Dagsson:\nChildren with Sn\u00e6frithr Sv\u00e1sadottir, daughter of Sv\u00e5se the Finn:\nOther children:\nIn popular culture.\nIn Norway.\nHarald Fairhair became an important figure in Norwegian nationalism in the nineteenth century, during its struggle for independence from Sweden, when he served as 'a heroic narrative character disseminating a foundation story of Norway becoming an independent nation'. In particular, a national monument to Harald was erected in 1872 on Haraldshaugen, an ancient burial mound at the town of Haugesund then imagined to be Harald Finehair's burial place, despite opposition from left-wing politicians. The German historian Jan R\u00fcdiger concluded that: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; His compelling narrative has survived scholarly scrutiny almost unscathed - or rather, professional historical knowledge based on a century of source criticism coexists with Snorri's unscathed narrative in the sense that in the 21st century both are \"true\" in a completary, non-completive way. As unifier of the kingdom, Harald rests under a 'Viking' memorial site of burial mounds and memorial stones near his royal court at Avaldsnes in Vestland, precisely the region that first caught his attention in Gyda, and whose conquest at the Battle of Hafrsfjord has been regarded as the keystone in the unification of the realm ever since Snorri. Harald Fairhair will always be the first king of Norway.\nThe claim to Harald has become important to the development of the tourism industry of Haugesund and its region:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;today, King Harald Fairhair is associated with several archaeological sites where modern monuments and theme parks (obelisks, towers, sculptures, 'reconstructions' of ancient houses/villages) are constructed and where various commemorative practices (jubilees, rallies, festivals) are being performed. The Viking hero Harald Fairhair has become part of a vital re-enactment culture, which is evident in, among other things, a memorial park in central Haugesund with the erection of a statue of Harald Fairhair ... the performance of a Harald musical ... the building of 'the largest' Viking ship in the world ... the establishment of a theme park based on the Viking concept, and a historic centre where the mythology of King Harald is disseminated ... The main initiators behind these commemorative projects in the Haugesund region today are, as it was in the 1870s, local commercial entrepreneurs who are nourished by local patriotism.\nIn 2013, commercially led archaeological excavations at Avaldsnes began with the explicit intention of developing the local heritage industry in relation to the Harald Fairhair brand, provoking a prominent debate in Norway over the appropriate handling of archaeological heritage.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56252", "revid": "4637213", "url": "https://en.wikipedia.org/wiki?curid=56252", "title": "Lieutenant governor", "text": "General title for high officer of state\nA lieutenant governor, lieutenant-governor, or vice governor is a high officer of state, whose precise role and rank vary by jurisdiction. Often a lieutenant governor is the deputy, or lieutenant, to or ranked under a governor \u2014 a \"second-in-command\", rather like deputy governor. In Canadian provinces and in the Dutch Caribbean, the lieutenant governor is the representative of the Canadian monarch or Dutch monarch in that jurisdiction, and thus outranks the head of government, but for practical purposes has \"virtually\" no power.\nIn India, lieutenant governors are in charge of union territories in that country.\nIn the United States, lieutenant governors are usually second-in-command to a state governor, and the actual power held by the lieutenant governor varies greatly from state to state. The lieutenant governor is often first in line of succession to the governorship, and acts as governor when the governor leaves the state or is unable to serve. Also, the lieutenant governor is often the president of the state senate.\nIn Argentina, lieutenant governors are called \"vice governors\" and are modeled after the U.S. lieutenant governors, since as their U.S. counterpart the vice governors are the second-in-command to a provincial governor, and are the first in the gubernatorial line of succession. Also, the vice governor usually acts as the president of the provincial senate (or the provincial legislature in unicameral provinces).\nLieutenant governors in the Kingdom of the Netherlands.\nThe Netherlands has lieutenant governors () who formerly and currently govern the Netherlands' island territories. Before the dissolution of the Netherlands Antilles in 2010, each island territory of the Netherlands Antilles had a lieutenant governor who served as heads of the governing council of each island territory, which formed a level of decentralized government. Currently, the Netherlands has three lieutenant governors who each oversee one of the three special municipalities in the Caribbean Netherlands: Saba, Bonaire, and Sint Eustatius. These lieutenant governors are referred to locally as Island Governor, and their function is similar to a mayor in the European Netherlands.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56253", "revid": "33092116", "url": "https://en.wikipedia.org/wiki?curid=56253", "title": "Celtic knot", "text": "Decorative knot used extensively in the Celtic style of Insular art\nCeltic knots (, , , ) are a variety of knots and stylized graphical representations of knots used for decoration, used extensively in the Celtic and Northumbrian styles of Insular art. These knots are most known for their adaptation for use in the ornamentation of Christian monuments and manuscripts, such as the 8th-century St. Teilo Gospels, the Book of Kells and the Lindisfarne Gospels. Most are endless knots, and many are varieties of basket weave knots.\nHistory.\nThe use of interlace patterns had its origins in the late Roman Empire. Knot patterns first appeared in the third and fourth centuries AD and can be seen in Roman floor mosaics of that time. Interesting developments in the artistic use of interlaced knot patterns are found in Byzantine architecture and book illumination, Coptic art, Celtic art, Islamic art, Kievan Rus' book illumination, Ethiopian art, and European architecture and book illumination.\nSpirals, step patterns, and key patterns are dominant motifs in Celtic art before the Christian influence on the Celts, which began around 450. These designs found their way into early Christian manuscripts and artwork with the addition of depictions from life, such as animals, plants and even humans. In the beginning, the patterns were intricate interwoven cords, called plaits, which can also be found in other areas of Europe, such as Italy, in the 6th century. A fragment of a Gospel Book, now in the Durham Cathedral library and created in northern Britain in the 7th century, contains the earliest example of true knotted designs in the Celtic manner.\nExamples of plait work (a woven, unbroken cord design) predate knotwork designs in several cultures around the world, but the broken and reconnected plait work that is characteristic of true knotwork began in northern Italy and southern Gaul and spread to Ireland by the 7th century. The style is most commonly associated with the Celtic lands and England (particularly the Kingdom of Northumbria) and was then exported to Europe by Irish and Northumbrian monastic activities on the continent. J. Romilly Allen has identified \"eight elementary knots which form the basis of nearly all the interlaced patterns in Celtic decorative art\".\nThe Celtic knot as a tattoo design became popular in the United States in the 1970s and 1980s.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "56254", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=56254", "title": "Wikipedia feature requests", "text": ""}
{"id": "56255", "revid": "7770027", "url": "https://en.wikipedia.org/wiki?curid=56255", "title": "Paschal candle", "text": "Candle used in liturgies of Western churches during the Easter season\nA Paschal candle is a large candle used in liturgies in Western Christianity (viz., the Roman Catholic Church, the Lutheran Churches, the Anglican Communion, and the Methodist Churches, among others). A new Paschal candle is blessed and lit every year at Easter. It is used throughout the Eastertide and then throughout the year on occasions such as baptisms, funerals and some other special occasions such as the ordination of priests, taking vows or the Consecration of virgins, when the fire from the Paschal candle is carried with a wick to light another liturgical candle, as for example the baptismal candle.\nThe equivalent of the Paschal candle in the Eastern Orthodox Church is the Paschal trikirion, which differs in both style and usage.\nEtymology.\nThe term \"Paschal\" comes from the Latin word \"Pascha\", which came from the Hebrew word \"Pesach (; \u05e4\u05b6\u05bc\u05e1\u05b7\u05d7)\", meaning Passover, and relates to the Paschal mystery of salvation. It is sometimes referred to as the \"Easter candle\" or the \"Christ candle\".\nDescription.\nFor congregations that use a Paschal candle, it is the largest candle in the worship space. In most cases, the candle will display several common symbols:\nIn the (medieval) Church, Paschal candles often reached a stupendous size. The Paschal candle of Salisbury Cathedral was said to have been tall. At present time, in the United States and Southern Europe (e.g., Italy and France) the candle is approximately in diameter and tall; in Northern Europe the candle tends to be shorter in height () and wider in diameter (). The Paschal candle of Manila Cathedral usually reaches and stands at tall.\nThe Paschal candle, like all liturgical candles, must be made at least from the most part of beeswax \"(ex cera apum saltem in maxima parte)\". The Church Fathers saw the bee as a symbol of the Virgin Mary. The beeswax symbolized the pure flesh of Christ, received from his mother.\nUsage.\nEaster Vigil.\nFor churches that celebrate the Easter Vigil on the night of Holy Saturday, the ceremonial preparation, dedication and lighting of the Paschal candle is one of the most solemn moments of the service. The Easter Vigil liturgies of the Roman Catholic, Lutheran, Anglican, Methodist and Presbyterian Churches are nearly identical.\nOn Maundy Thursday of the same week the entire church is darkened by extinguishing all candles and lamps. This and the empty tabernacle symbolise the darkness of a world without Christ.\nAt the opening of the Easter Vigil a fire is lit and blessed. The minister will cuts a cross in the wax with a stylus and trace the symbols on the Paschal candle, saying words similar to: \"Christ, yesterday and today, the Beginning and the End, the Alpha and the Omega. All time belongs to him and all the ages; to him be glory and power through every age for ever. Amen.\" He then inserts five grains of incense (reminiscent of the nails used to fasten Christ on the Cross) on the five points of the cross, saying: \"By his holy and glorious wounds, may Christ our Lord guard us and keep us. Amen.\"\nThe Paschal candle is the first candle to be lit with a flame from this sacred fire, representing the light of Christ coming into the world. This represents the risen Christ, as a symbol of light (life) dispelling darkness (death). Before it is lit, the minister says words similar to: \"May the light of Christ, rising in glory, dispel the darkness of our hearts and minds.\"\nTypically, the worshiping assembly then processes into the church led by the Paschal candle. The candle is raised three times during the procession, accompanied by the chant \"The light of Christ\" to which the assembly responds \"Thanks be to God\".\nIn some communities, it is common for nearby churches of different Christian denominations (e.g. Catholic, Lutheran, Anglican, Methodist and Presbyterian) to make the new Easter Fire together and then after this, each congregation processes back to their own church with their own Paschal Candle for their Easter Vigil celebration; this is considered to be a fostering of ecumenism.\nFollowing the procession the \"Exultet\" is chanted, traditionally by a deacon, but it may be chanted by the priest or \u2013 most parts of it \u2013 by a cantor. The \"Exultet\" concludes with the offering of the candle:\nFrom the Roman Missal:\nOn this, your night of grace, O holy father, accept this candle, a solemn offering, the work of bees and of your servants' hands, an evening sacrifice of praise, this gift from your most holy Church. But now we know the praises of this pillar, which glowing fire ignites for God's honor, a fire into many flames divided, yet never dimmed by sharing of its light, for it is fed by melting wax, drawn out by mother bees to build a torch so precious. O truly blessed night, when things of heaven are wed to those of earth, and divine to the human. Therefore, O Lord, we pray you that this candle, hallowed to the honor of your name, may persevere undimmed, to overcome the darkness of this night. Receive it as a pleasing fragrance, and let it mingle with the lights of heaven. May this flame be found still burning by the Morning Star: the one Morning Star who never sets, Christ your son, who, coming back from death's domain, has shed his peaceful light on humanity, and lives and reigns for ever and ever.\nAfter the Litany of the Saints, the Paschal candle is lowered three times into the Easter water to be blessed while the priest sings a prayer of blessing with the request for the descent of the Holy Spirit. In some Eastern traditions, wax is dripped into the water for an even richer symbolism.\nOther times of the year.\nThe candle remains in the sanctuary close to the altar and is lit at least in all the more solemn worship services until Pentecost (or in some traditions until Ascension Day, when it is extinguished just after the Gospel). In this context the Paschal candle symbolises the presence of the glorified risen Christ.\nAfter Eastertide, the candle should be kept in the baptistry, so that in the celebrations of baptisms the candles of the baptized may be lit from the candle. The Paschal candle is lit during baptisms to signify the Holy Spirit and fire that John the Baptist promised to those who were baptised in Christ.\nBefore 1955, the option existed of blessing the baptismal font on the Vigil of Pentecost, and this was the only time the Paschal candle would be lit at services after Ascension. In the Ordinary form of the Roman Rite, the Paschal candle is lit and should be placed near the coffin during the Mass of the repose of the soul or the Requiem. This is to indicate that the death of a Christian is his or her own passover.\nEastern usage.\nIn the Eastern Orthodox and Byzantine Catholic churches, there is no direct correspondence to the Western Paschal candle. However, throughout Bright Week, the priest carries a cross and paschal trikirion at all of the services, especially when censing, during the Little Entrance or when giving the Paschal greeting. The trikirion consists of three lit candles in a candlestick, which the priest carries in his left hand. In the Slavic tradition, the three candles may be white or different colors: green, red, blue. The deacon also carries a special Paschal candle which is a single large candle whenever he leads an ektenia (litany) or censes.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
