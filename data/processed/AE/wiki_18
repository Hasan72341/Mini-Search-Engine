{"id": "46124", "revid": "14758", "url": "https://en.wikipedia.org/wiki?curid=46124", "title": "ACIS", "text": "Geometric modeling kernel developed by Spatial Corporation\nThe 3D ACIS Modeler (ACIS) is a geometric modeling kernel developed by Spatial Corporation (formerly Spatial Technology), part of Dassault Syst\u00e8mes. ACIS is used by software developers in industries such as computer-aided design, computer-aided manufacturing, computer-aided engineering, architecture, engineering and construction, coordinate-measuring machine, 3D animation, and shipbuilding. ACIS provides software developers and manufacturers the underlying 3D modeling functionality.\nACIS features an object-oriented C++ architecture with 3D modelling capabilities. ACIS is used to construct applications with hybrid modeling features, since it integrates wireframe model, surface, and solid modeling functionality with both manifold and non-manifold topology, and a set of geometric operations.\nHistory.\nAs a geometric kernel, ACIS is a second generation system, coming after the first generation Romulus.\nThere are several versions about what the word ACIS actually stands for, or whether it is an acronym at all. The most popular version is that ACIS stands for \"Alan, Charles, Ian's System\" (Alan Grayer, Charles Lang and Ian Braid as part of Three-Space Ltd.), or \"Alan, Charles, Ian and Spatial\" (as the system was later on sold to Spatial Technology, now Spatial Corp). According to a close source the name actually stands for \"Alan, Charles, Ian, Sowar\", with Sowar coming from Dick Sowar, founder of Spatial Technology. However, when asked, the creators of ACIS would simply suggest that its name was derived from Greek mythology (See also Acis).\nIn 1985 Alan Grayer, Charles Lang and Ian Braid (creators of Romulus and Romulus-D) formed Three-Space Ltd. (Cambridge, England) which had been retained by Dick Sowar's Spatial Technology (which had been founded by Sowar in 1986) to develop the ACIS solid modeling kernel for Spatial Technology's Strata CAM software. The first version of ACIS was released in 1989 and was licensed by HP for integration into its ME CAD software.\nIn late 2000, around the time when Spatial was acquired by Dassault Syst\u00e8mes, the ACIS file format changed slightly and was no longer openly published.\nArchitecture.\nA software component is a functionally specialized unit of software\u2014a collection of software items (functions, classes, etc.) grouped together to serve some distinct purpose. It serves as a constituent part of a whole software system or product. A product is one or more software components that are assembled together and sold as a package. Components can be arranged in different combinations to form different products.\nThe ACIS product line is designed using software component technology, which allows an application to use only the components it requires. In some cases, more than one component is available (either from Spatial or third party vendors) for a given purpose, so application developers can use the component that best meets their needs. For example, several rendering components are available from Spatial, and developers use the one that works best for their platform or application.\nFunctionality.\nACIS Modeler.\nACIS core functionality can be subclassified into three categories, namely:\nFile format.\nSave File Types.\nACIS supports two kinds of save files, Standard ACIS Text (SAT), and Standard ACIS Binary (SAB). The two formats store identical information, so the term SAT file is generally used to refer to either when no distinction is needed.\nSAT files are ASCII text files that may be viewed with a simple text editor. A SAT file contains carriage returns, white space and other formatting that makes it readable to the human eye. A SAT file has a .sat file extension.\nSAB files cannot be viewed with a simple text editor and are meant for compactness and not for human readability. A SAB file has a .sab file extension. A SAB file uses delimiters between elements and binary tags, without additional formatting.\nStructure of the Save File.\nSpecification of SAT format for version 7.0 (circa 2001) has been made publicly available. This allowed external applications, even those not based on ACIS, accessing the data stored in such files. The basic information needed to understand the SAT file format, such as the structure of the save file format, how the data is encapsulated, the types of data written, subtypes and references, is available from this document. However the newer version of ACIS use modified format of SAT files whose specification is not publicly available. Thus reading of modern SAT files requires either using native ACIS library or reverse engineering of the format.\nA save file contains:\nBeginning with ACIS Release 6.3, it is required that the product ID and units be populated for the file header before you can save a SAT file.\nVersion Numbers and ACIS Releases.\nACIS is currently being developed by Spatial. They maintain the concept of a current version (release) number in ACIS, as well as a save version number. The save version allows one to create a SAT save file that can be read by a previous version of ACIS.\nBeginning with ACIS Release 4.0, the SAT save file format did not change with minor releases, only with major releases. This allowed applications that are based upon the same major version of ACIS to exchange data without being concerned about the save version. To provide this interoperability in a simple implementation, ACIS save files have contained a symbol that accurately identified the major version number, but not the minor version. This meant that applications created using the same major version of ACIS would produce compatible save files, regardless of their minor versions. This was accomplished by simply not incrementing the internal minor version number between major versions.\nBeginning with Release 7.0, ACIS started again providing accurate major, minor, and point version numbers. Beginning with Release 2016 1.0 in September, 2015, Spatial updated to Semantic Versioning, and now describes versions by the model year and major, minor and point releases within that model year.\nTo summarize how release numbers and SAT changes are related:\nAdoption.\nIn 2023 Alibre Design, BricsCAD,\nSpaceClaim, TurboCAD, Cimatron, Viacad, SharkCad and Vertex all used ACIS as their geometric kernel/engine.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46125", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=46125", "title": "Cbreak mode", "text": ""}
{"id": "46126", "revid": "31246497", "url": "https://en.wikipedia.org/wiki?curid=46126", "title": "Mustard gas", "text": "Chemical warfare agent\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nMustard gas or sulfur mustard are names commonly used for the organosulfur chemical compound bis(2-chloroethyl) sulfide, which has the chemical structure S(CH2CH2Cl)2, as well as other species. In the wider sense, compounds with the substituents are known as \"sulfur mustards\" or \"nitrogen mustards\", respectively, where X = Cl or Br. Such compounds are potent alkylating agents, making mustard gas acutely and severely toxic. Mustard gas is a carcinogen. There is no preventive agent against mustard gas, with protection depending entirely on skin and airways protection, and no antidote exists for mustard poisoning.\nAlso known as mustard agents, this family of compounds comprises infamous cytotoxins and blister agents with a long history of use as chemical weapons. The name \"mustard gas\" is technically incorrect; the substances, when dispersed, are often not gases but a fine mist of liquid droplets that can be readily absorbed through the skin and by inhalation. The skin can be affected by contact with either the liquid or vapor. The rate of penetration into skin is proportional to dose, temperature and humidity. \nSulfur mustards are viscous liquids at room temperature and have an odor resembling mustard plants, garlic, or horseradish, hence the name. When pure, they are colorless, but when used in impure forms, such as in warfare, they are usually yellow-brown. Mustard gases form blisters on exposed skin and in the lungs, often resulting in prolonged illness ending in death.\nEtymology.\nThe name of mustard gas derived from its yellow color, smell of mustard, and burning sensation on eyes. The term was first used in 1917 during World War I when Germans used the poison in combat.\nHistory as chemical weapons.\nSulfur mustard is a type of chemical warfare agent. As a chemical weapon, mustard gas has been used in several armed conflicts since World War I, including the Iran\u2013Iraq War, resulting in more than 100,000 casualties. Sulfur-based and nitrogen-based mustard agents are regulated under Schedule 1 of the 1993 Chemical Weapons Convention, as substances with few uses other than in chemical warfare. Mustard agents can be deployed by means of artillery shells, aerial bombs, rockets, or by spraying from aircraft.\nAdverse health effects.\nMustard gases have powerful blistering effects on victims. They are also carcinogenic and mutagenic alkylating agents. Their high lipophilicity accelerates their absorption into the body. Because mustard agents often do not elicit immediate symptoms, contaminated areas may appear normal. Within 24 hours of exposure, victims experience intense itching and skin irritation. If this irritation goes untreated, blisters filled with pus can form wherever the agent contacted the skin. As chemical burns, these are severely debilitating. Mustard gas can have the effect of turning a patient's skin different colors due to melanogenesis. \nIf the victim's eyes were exposed, then they become sore, starting with conjunctivitis (also known as pink eye), after which the eyelids swell, resulting in temporary blindness. Extreme ocular exposure to mustard gas vapors may result in corneal ulceration, anterior chamber scarring, and neovascularization. In these severe and infrequent cases, corneal transplantation has been used as a treatment. If inhaled in high concentrations, mustard agents cause bleeding and blistering within the respiratory system, damaging mucous membranes and causing pulmonary edema. Depending on the level of contamination, mustard agent burns can vary between first and second degree burns. They can also be as severe, disfiguring, and dangerous as third degree burns. Some 80% of sulfur mustard in contact with the skin evaporates, while 10% stays in the skin and 10% is absorbed and circulated in the blood.\nThe carcinogenic and mutagenic effects of exposure to mustard gas increase the risk of developing cancer later in life. In a study of patients 25 years after wartime exposure to chemical weaponry, c-DNA microarray profiling indicated that 122 genes were significantly mutated in the lungs and airways of mustard gas victims. Those genes all correspond to functions commonly affected by mustard gas exposure, including apoptosis, inflammation, and stress responses. The long-term ocular complications include burning, tearing, itching, photophobia, presbyopia, pain, and foreign-body sensations.\n Symptoms of exposure have been extensively documented. There is a considerable amount of information about the effects of exposure to sulfur mustard in humans and animals from the last century from wartime exposures and laboratory testing. Substantial information in the original documents is not readily available. There are numerous reviews of the literature that include early data as well as recent information. \nMedical management.\nIn a rinse-wipe-rinse sequence, skin is decontaminated of mustard gas by washing with liquid soap and water, or an absorbent powder. The eyes should be thoroughly rinsed using saline or clean water. A topical analgesic is used to relieve skin pain during decontamination. For skin lesions, topical treatments, such as calamine lotion, steroids, and oral antihistamines are used to relieve itching. Larger blisters are irrigated repeatedly with saline or soapy water, then treated with an antibiotic and petroleum gauze.\nMustard agent burns do not heal quickly and (as with other types of burns) present a risk of sepsis caused by pathogens such as \"Staphylococcus aureus\" and \"Pseudomonas aeruginosa\". The mechanisms behind mustard gas's effect on endothelial cells are still being studied, but recent studies have shown that high levels of exposure can induce high rates of both necrosis and apoptosis. In vitro tests have shown that at low concentrations of mustard gas, where apoptosis is the predominant result of exposure, pretreatment with 50 mM N-acetyl-L-cysteine (NAC) was able to decrease the rate of apoptosis. NAC protects actin filaments from reorganization by mustard gas, demonstrating that actin filaments play a large role in the severe burns observed in victims.\nA British nurse treating soldiers with mustard agent burns during World War I commented:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;They cannot be bandaged or touched. We cover them with a tent of propped-up sheets. Gas burns must be agonizing because usually the other cases do not complain, even with the worst wounds, but gas cases are invariably beyond endurance and they cannot help crying out.\nMechanism of cellular toxicity.\nSulfur mustards readily eliminate chloride ions by intramolecular nucleophilic substitution to form cyclic sulfonium ions. These very reactive intermediates tend to permanently alkylate nucleotides in DNA strands, which can prevent cellular division, leading to programmed cell death. Alternatively, if cell death is not immediate, the damaged DNA can lead to the development of cancer. Oxidative stress is another pathology involved in mustard gas toxicity.\nVarious compounds with the structural subgroup BC2H4X, where X is any leaving group and B is a Lewis base, have a common name of mustard. Such compounds can form cyclic \"onium\" ions (sulfonium, ammonium, etc.) that are good alkylating agents. These compounds include bis(2-haloethyl)ethers (oxygen mustards), the (2-haloethyl)amines (nitrogen mustards), and sesquimustard, which has two \u03b1-chloroethyl thioether groups (ClC2H4S\u2212) connected by an ethylene bridge (\u2212C2H4\u2212). These compounds have a similar ability to alkylate DNA, but their physical properties vary.\nFormulations.\nIn its history, various types and mixtures of mustard gas have been employed. These include:\nHistory.\nDevelopment.\nMustard gases were possibly developed as early as 1822 by C\u00e9sar-Mansu\u00e8te Despretz (1798\u20131863). Despretz described the reaction of sulfur dichloride and ethylene but never made mention of any irritating properties of the reaction product. In 1854, another French chemist, Alfred Riche (1829\u20131908), repeated this procedure, also without describing any adverse physiological properties. In 1860, the British scientist Frederick Guthrie synthesized and characterized the mustard agent compound and noted its irritating properties, especially in tasting. Also in 1860, chemist Albert Niemann, known as a pioneer in cocaine chemistry, repeated the reaction, and recorded blister-forming properties. In 1886, Viktor Meyer published a paper describing a synthesis that produced good yields. He combined 2-chloroethanol with aqueous potassium sulfide, and then treated the resulting thiodiglycol with phosphorus trichloride. The purity of this compound was much higher and consequently the adverse health effects upon exposure were much more severe. These symptoms presented themselves in his assistant, and in order to rule out the possibility that his assistant was suffering from a mental illness (psychosomatic symptoms), Meyer had this compound tested on laboratory rabbits, most of which died. In 1913, the English chemist Hans Thacher Clarke (known for the Eschweiler-Clarke reaction) replaced the phosphorus trichloride with hydrochloric acid in Meyer's formulation while working with Emil Fischer in Berlin. Clarke was hospitalized for two months for burns after one of his flasks broke. According to Meyer, Fischer's report on this accident to the German Chemical Society sent the German Empire on the road to chemical weapons.\nThe German Empire during World War I relied on the Meyer-Clarke method because 2-chloroethanol was readily available from the German dye industry of that time.\nUse.\nMustard gas was first used in World War I by the German army against British and Canadian soldiers near Ypres, Belgium, on July 12, 1917, and later also against the French Second Army. Yperite is \"a name used by the French, because the compound was first used at Ypres.\" The Allies used mustard gas for the first time on November 1917 at Cambrai, France, after the armies had captured a stockpile of German mustard shells. It took the British more than a year to develop their own mustard agent weapon, with production of the chemicals centred on Avonmouth Docks (the only option available to the British was the Despretz\u2013Niemann\u2013Guthrie process). \nMustard gas was originally assigned the name LOST, after the scientists Wilhelm Lommel and Wilhelm Steinkopf, who developed a method of large-scale production for the Imperial German Army in 1916.\nMustard gas was dispersed as an aerosol in a mixture with other chemicals, giving it a yellow-brown color. Mustard agent has also been dispersed in such munitions as aerial bombs, land mines, mortar rounds, artillery shells, and rockets. Exposure to mustard agent was lethal in about 1% of cases. Its effectiveness was as an incapacitating agent. The early countermeasures against mustard agent were relatively ineffective, since a soldier wearing a gas mask was not protected against absorbing it through his skin and being blistered. A common countermeasure was using a urine-soaked mask or facecloth to prevent or reduce injury, a readily available remedy attested by soldiers in documentaries (e.g., \"They Shall Not Grow Old\" in 2018) and others (such as forward aid nurses) interviewed between 1947 and 1981 by the British Broadcasting Corporation for various World War One history programs; however, the effectiveness of this measure is unclear.\nMustard gas can remain in the ground for weeks, and it continues to cause ill effects. If mustard agent contaminates one's clothing and equipment while cold, then other people with whom they share an enclosed space could become poisoned as contaminated items warm up enough material to become an airborne toxic agent. An example of this was depicted in a British and Canadian documentary about life in the trenches, particularly once the \"sousterrain\" (subways and berthing areas underground) were completed in Belgium and France. Towards the end of World War I, mustard agent was used in high concentrations as an area-denial weapon that forced troops to abandon heavily contaminated areas.\nSince World War I, mustard gas has been used in several wars and other conflicts, usually against people who cannot retaliate in kind:\nThe use of toxic gases or other chemicals, including mustard gas, during warfare is known as chemical warfare, and this kind of warfare was prohibited by the Geneva Protocol of 1925, and also by the later Chemical Weapons Convention of 1993. The latter agreement also prohibits the development, production, stockpiling, and sale of such weapons.\nIn September 2012, a US official stated that the rebel militant group ISIS was manufacturing and using mustard gas in Syria and Iraq, which was allegedly confirmed by the group's head of chemical weapons development, Sleiman Daoud al-Afari, who has since been captured.\nDevelopment of the first chemotherapy drug.\nAs early as 1919 it was known that mustard agent was a suppressor of hematopoiesis. In addition, autopsies performed on 75 soldiers who had died of mustard agent during World War I were done by researchers from the University of Pennsylvania who reported decreased counts of white blood cells. This led the American Office of Scientific Research and Development (OSRD) to finance the biology and chemistry departments at Yale University to conduct research on the use of chemical warfare during World War II.\nAs a part of this effort, the group investigated nitrogen mustard as a therapy for Hodgkin's lymphoma and other types of lymphoma and leukemia, and this compound was tried out on its first human patient in December 1942. The results of this study were not published until 1946, when they were declassified. In a parallel track, after the air raid on Bari in December 1943, the doctors of the U.S. Army noted that white blood cell counts were reduced in their patients. Some years after World War II was over, the incident in Bari and the work of the Yale University group with nitrogen mustard converged, and this prompted a search for other similar chemical compounds. Due to its use in previous studies, the nitrogen mustard called \"HN2\" became the first cancer chemotherapy drug, chlormethine (also known as mechlorethamine, mustine) to be used. Chlormethine and other mustard gas molecules are still used to this day as an chemotherapy agent albeit they have largely been replaced with more safe chemotherapy drugs like cisplatin and carboplatin.\nDisposal.\nIn the United States, storage and incineration of mustard gas and other chemical weapons were carried out by the U.S. Army Chemical Materials Agency. Disposal projects at the two remaining American chemical weapons sites were carried out near Richmond, Kentucky, and Pueblo, Colorado. The last of the declared mustard weapons stockpile of the United States was destroyed on June 22, 2023 in Pueblo with other remaining chemical weapons being destroyed later in 2023.\nNew detection techniques are being developed in order to detect the presence of mustard gas and its metabolites. The technology is portable and detects small quantities of the hazardous waste and its oxidized products, which are notorious for harming unsuspecting civilians. The immunochromatographic assay would eliminate the need for expensive, time-consuming lab tests and enable easy-to-read tests to protect civilians from sulfur-mustard dumping sites.\nIn 1946, 10,000 drums of mustard gas (2,800 tonnes) stored at the production facility of Stormont Chemicals in Cornwall, Ontario, Canada, were loaded onto 187 boxcars for the journey to be buried at sea on board a long barge south of Sable Island, southeast of Halifax, at a depth of . The dump location is 42 degrees, 50 minutes north by 60 degrees, 12 minutes west.\nA large British stockpile of old mustard agent that had been made and stored since World War I at M. S. Factory, Valley near Rhydymwyn in Flintshire, Wales, was destroyed in 1958.\nMost of the mustard gas found in Germany after World War II was dumped into the Baltic Sea. Between 1966 and 2002, fishermen have found about 700 chemical weapons in the region of Bornholm, most of which contain mustard gas. One of the more frequently dumped weapons was \"Spr\u00fchb\u00fcchse 37\" (Spr\u00fcB\u00fc37, Spray Can 37, 1937 being the year of its fielding with the German Army). These weapons contain mustard gas mixed with a thickener, which gives it a tar-like viscosity. When the content of the Spr\u00fcB\u00fc37 comes in contact with water, only the mustard gas in the outer layers of the lumps of viscous mustard hydrolyzes, leaving behind amber-colored residues that still contain most of the active mustard gas. On mechanically breaking these lumps (e.g., with the drag board of a fishing net or by the human hand) the enclosed mustard gas is still as active as it had been at the time the weapon was dumped. These lumps, when washed ashore, can be mistaken for amber, which can lead to severe health problems. Artillery shells containing mustard gas and other toxic ammunition from World War I (as well as conventional explosives) can still be found in France and Belgium. These were formerly disposed of by explosion undersea, but since the current environmental regulations prohibit this, the French government is building an automated factory to dispose of the accumulation of chemical shells.\nIn 1972, the U.S. Congress banned the practice of disposing of chemical weapons into the ocean by the United States. 29,000 tons of nerve and mustard agents had already been dumped into the ocean off the United States by the U.S. Army. According to a report created in 1998 by William Brankowitz, a deputy project manager in the U.S. Army Chemical Materials Agency, the army created at least 26 chemical weapons dumping sites in the ocean offshore from at least 11 states on both the East Coast and the West Coast (in Operation CHASE, Operation Geranium, etc.). In addition, due to poor recordkeeping, about one-half of the sites have only their rough locations known.\nIn June 1997, India declared its stock of chemical weapons of of mustard gas. By the end of 2006, India had destroyed more than 75 percent of its chemical weapons/material stockpile and was granted extension for destroying the remaining stocks by April 2009 and was expected to achieve 100 percent destruction within that time frame. India informed the United Nations in May 2009 that it had destroyed its stockpile of chemical weapons in compliance with the international Chemical Weapons Convention. With this India has become the third country after South Korea and Albania to do so. This was cross-checked by inspectors of the United Nations.\nProducing or stockpiling mustard gas is prohibited by the Chemical Weapons Convention. When the convention entered force in 1997, the parties declared worldwide stockpiles of 17,440 tonnes of mustard gas. As of December 2015, 86% of these stockpiles had been destroyed.\nA significant portion of the United States' mustard agent stockpile was stored at the Edgewood Area of Aberdeen Proving Ground in Maryland. Approximately 1,621 tons of mustard agents were stored in one-ton containers on the base under heavy guard. A chemical neutralization plant was built on the proving ground and neutralized the last of this stockpile in February 2005. This stockpile had priority because of the potential for quick reduction of risk to the community. The nearest schools were fitted with overpressurization machinery to protect the students and faculty in the event of a catastrophic explosion and fire at the site. These projects, as well as planning, equipment, and training assistance, were provided to the surrounding community as a part of the Chemical Stockpile Emergency Preparedness Program (CSEPP), a joint program of the Army and the Federal Emergency Management Agency (FEMA). Unexploded shells containing mustard gases and other chemical agents are still present in several test ranges in proximity to schools in the Edgewood area, but the smaller amounts of poison gas () present considerably lower risks. These remnants are being detected and excavated systematically for disposal. The U.S. Army Chemical Materials Agency oversaw disposal of several other chemical weapons stockpiles located across the United States in compliance with international chemical weapons treaties. These include the complete incineration of the chemical weapons stockpiled in Alabama, Arkansas, Indiana, and Oregon. Earlier, this agency had also completed destruction of the chemical weapons stockpile located on Johnston Atoll located south of Hawaii in the Pacific Ocean. The largest mustard agent stockpile, at approximately 6,200 short tons, was stored at the Deseret Chemical Depot in northern Utah. The incineration of this stockpile began in 2006. In May 2011, the last of the mustard agents in the stockpile were incinerated at the Deseret Chemical Depot, and the last artillery shells containing mustard gas were incinerated in January 2012.\nIn 2008, many empty aerial bombs that contained mustard gas were found in an excavation at the Marrangaroo Army Base just west of Sydney, Australia. In 2009, a mining survey near Chinchilla, Queensland, uncovered 144 105-millimeter howitzer shells, some containing \"Mustard H\", that had been buried by the U.S. Army during World War II.\nIn 2014, a collection of 200 bombs was found near the Flemish villages of Passendale and Moorslede. The majority of the bombs were filled with mustard agents. The bombs were left over from the German army and were meant to be used in the Battle of Passchendaele in World War I. It was the largest collection of chemical weapons ever found in Belgium.\nA large amount of chemical weapons, including mustard gas, was found in a neighborhood of Washington, D.C. The cleanup was completed in 2021.\nPost-war accidental exposure.\nIn 2002, an archaeologist at the Presidio Trust archaeology lab in San Francisco was exposed to mustard gas, which had been dug up at the Presidio of San Francisco, a former military base.\nIn 2010, a clamming boat pulled up some old artillery shells of World War I from the Atlantic Ocean south of Long Island, New York. Multiple fishermen suffered from blistering and respiratory irritation severe enough to require hospitalization.\nWWII-era tests on men.\nFrom 1943 to 1944, mustard agent experiments were performed on Australian service volunteers in tropical Queensland, Australia, by Royal Australian Engineers, British Army and American experimenters, resulting in some severe injuries. One test site, the Brook Islands National Park, was chosen to simulate Pacific islands held by the Imperial Japanese Army. These experiments were the subject of the documentary film \"Keen as Mustard\".\nThe United States tested sulfur mustards and other chemical agents including nitrogen mustards and lewisite on up to 60,000 servicemen during and after WWII. The experiments were classified secret and as with Agent Orange, claims for medical care and compensation were routinely denied, even after the WWII-era tests were declassified in 1993. The Department of Veterans Affairs stated that it would contact 4,000 surviving test subjects but failed to do so, eventually only contacting 600. Skin cancer, severe eczema, leukemia, and chronic breathing problems plagued the test subjects, some of whom were as young as 19 at the time of the tests, until their deaths, but even those who had previously filed claims with the VA went without compensation.\nAfrican American servicemen were tested alongside white men in separate trials to determine whether their skin color would afford them a degree of immunity to the agents, and Nisei servicemen, some of whom had joined after their release from Japanese American Internment Camps were tested to determine susceptibility of Japanese military personnel to these agents. These tests also included Puerto Rican subjects.\nDetection in biological fluids.\nConcentrations of thiodiglycol in urine have been used to confirm a diagnosis of chemical poisoning in hospitalized victims. The presence in urine of 1,1'-sulfonylbismethylthioethane (SBMTE), a conjugation product with glutathione, is considered a more specific marker, since this metabolite is not found in specimens from unexposed persons. In one case, intact mustard gas was detected in postmortem fluids and tissues of a man who died one week post-exposure.\nReferences.\nNotes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "46127", "revid": "567924", "url": "https://en.wikipedia.org/wiki?curid=46127", "title": "Robert Tarjan", "text": "American computer scientist and mathematician\nRobert Endre Tarjan (born April 30, 1948) is an American computer scientist and mathematician. He is the discoverer of several graph theory algorithms, including his strongly connected components algorithm, and co-inventor of both splay trees and Fibonacci heaps. Tarjan is currently the James S. McDonnell Distinguished University Professor of Computer Science at Princeton University.\nPersonal life and education.\nHe was born in Pomona, California. His father, George Tarjan (1912\u20131991), raised in Hungary, was a child psychiatrist, specializing in mental retardation, and ran a state hospital. Robert Tarjan's younger brother James became a chess grandmaster. As a child, Robert Tarjan read a lot of science fiction, and wanted to be an astronomer. He became interested in mathematics after reading Martin Gardner's mathematical games column in Scientific American. He became seriously interested in math in the eighth grade, thanks to a \"very stimulating\" teacher.\nWhile he was in high school, Tarjan got a job, where he worked with IBM punch card collators. He first worked with real computers while studying astronomy at the Summer Science Program in 1964.\nTarjan obtained a Bachelor's degree in mathematics from the California Institute of Technology in 1969. At Stanford University, he received his master's degree in computer science in 1971 and a Ph.D. in computer science (with a minor in mathematics) in 1972. At Stanford, he was supervised by Robert Floyd and Donald Knuth, both highly prominent computer scientists, and his Ph.D. dissertation was \"An Efficient Planarity Algorithm\". Tarjan selected computer science as his area of interest because he believed that computer science was a way of doing mathematics that could have a practical impact.\nTarjan now lives in Princeton, NJ, and Silicon Valley. He is married to Nayla Rizk.\nHe has three daughters: Alice Tarjan, Sophie Zawacki, and Maxine Tarjan.\nComputer science career.\nTarjan has been teaching at Princeton University since 1985. He has also held academic positions at Cornell University (1972\u201373), University of California, Berkeley (1973\u20131975), Stanford University (1974\u20131980), and New York University (1981\u20131985). He has also been a fellow of the NEC Research Institute (1989\u20131997). In April 2013 he joined Microsoft Research Silicon Valley in addition to the position at Princeton. In October 2014 he rejoined Intertrust Technologies as chief scientist.\nTarjan has worked at AT&amp;T Bell Labs (1980\u20131989), Intertrust Technologies (1997\u20132001, 2014\u2013present), Compaq (2002) and Hewlett Packard (2006\u20132013).\nAlgorithms and data structures.\nTarjan is known for his pioneering work on graph theory algorithms and data structures. Some of his well-known algorithms include Tarjan's off-line least common ancestors algorithm, Tarjan's strongly connected components algorithm, and Tarjan's bridge-finding algorithm, and he was one of five co-authors of the median of medians linear-time selection algorithm. The Hopcroft\u2013Tarjan planarity testing algorithm was the first linear-time algorithm for planarity testing.\nTarjan has also developed important data structures such as the Fibonacci heap (a heap data structure consisting of a forest of trees), and the splay tree (a self-adjusting binary search tree; co-invented by Tarjan and Daniel Sleator). Another significant contribution was the analysis of the disjoint-set data structure; he was the first to prove the optimal runtime involving the inverse Ackermann function.\nAwards.\nTarjan received the Turing Award jointly with John Hopcroft in 1986. The citation for the award states that it was:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For fundamental achievements in the design and analysis of algorithms and data structures.\nTarjan was also elected an ACM Fellow in 1994. The citation for this award states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For seminal advances in the design and analysis of data structures and algorithms.\nSome of the other awards for Tarjan include:\nSelected publications.\nTarjan's papers have been collectively cited over 94,000 times. Among the most cited are:\nPatents.\nTarjan holds at least 18 U.S. patents. These include:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46128", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=46128", "title": "Invasion of Normandy", "text": ""}
{"id": "46129", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=46129", "title": "ITV Digital", "text": "Former British subscription-based digital terrestrial TV service\nITV Digital was a British digital terrestrial television broadcaster which launched a pay-TV service on the world's first digital terrestrial television network. Its main shareholders were Carlton Communications plc and Granada plc, owners of multiple licences of the ITV network. Starting as ONdigital in 1998, the service was rebranded as ITV Digital in July 2001.\nLow audience figures, piracy issues and an ultimately unaffordable multi-million pound deal with the Football League led to the broadcaster suffering large losses, and it entered administration in March 2002. Pay television services ceased permanently on 1 May of that year, but carriage of the remaining free-to-air channels such as BBC One and Channel 4 continued. In October, ITV Digital\u2019s former terrestrial multiplexes were taken over by Crown Castle and the BBC to create the Freeview free-to-air service.\nHistory.\nOn 31 January 1997, Carlton Television, Granada Television and satellite company British Sky Broadcasting (BSkyB) together created British Digital Broadcasting (BDB) as a joint venture, and applied to operate three digital terrestrial television (DTT) licences. They faced competition from a rival, Digital Television Network (DTN), a company created by cable operator CableTel (later known as NTL). On 25 June 1997, BDB won the auction and the Independent Television Commission (ITC) awarded the sole broadcast licence for DTT to the consortium. Then on 20 December 1997, the ITC awarded three pay-TV digital multiplex licences to BDB.\nThat same year, however, the ITC forced BSkyB out of the consortium on competition grounds; this effectively placed Sky in direct competition with the new service as Sky would also launch its digital satellite service in 1998, although Sky was still required to provide key channels such as Sky Movies and Sky Sports to BDB. With Sky as part of the consortium, British Digital Broadcasting would have paid discounted rates to carry Sky's television channels. Instead, with its positioning as a competitor, Sky charged the full market rates for the channels, at an extra cost of around \u00a360million a year to BDB. On 28 July 1998, BDB announced the service would be called ONdigital, and claimed it would be the biggest television brand launch in history. The company would be based in Marco Polo House (since demolished) in Battersea, south London, which was previously the home of BSkyB's earlier rival, British Satellite Broadcasting (BSB).\nSix multiplexes were set up, with three of them allocated to the existing analogue broadcasters. The other three multiplexes were auctioned off. ONdigital was given one year from the award of the licence to launch the first DTT service. In addition to launching audio and video services, it also led the specification of an industry-wide advanced interactive engine, based on MHEG-5. This was an open standard that was used by all broadcasters on DTT.\nThe launch.\nONdigital was officially launched on 15 November 1998 amid a large public ceremony featuring celebrity Ulrika Jonsson and fireworks around the Crystal Palace transmitting station. Its competitor Sky Digital had already debuted on 1 October. The service launched with 12 primary channels, which included the new BBC Choice and ITV2 channels; a subscription package featuring channels such as Sky One, Cartoon Network, E4, UKTV channels and many developed in-house by Carlton and Granada such as Carlton World; premium channels including Sky Sports 1 and 3 (later including 2), Sky Premier and Sky MovieMax; and the newly launched FilmFour.\nFrom the beginning, however, the company was quickly losing money. Supply problems with set-top boxes meant that the company missed Christmas sales and retailers had to wait several months for the customers to receive their boxes. Meanwhile, aggressive marketing by BSkyB for Sky Digital made the ONdigital offer look unattractive. The new digital satellite service provided a dish, digibox, installation and around 200 channels for \u00a3159, a lower price than ONdigital at \u00a3199. Sky had also launched earlier, meaning they had a head start over the ONdigital service. ONdigital's subscription pricing had been set to compare with the older Sky analogue service of 20 channels. In 1999, digital cable services were launched by NTL, Telewest and Cable &amp; Wireless.\nIn February 1999, ITV secured the rights for UEFA Champions League football matches for four years, which would partly be broadcast through ONdigital. Two sports channels were added to the platform, Champions ON 28 and Champions ON 99 (later renamed ONsport 1 and ONsport 2 when it secured the rights to ATP tennis games), the latter of which timeshared with Carlton Cinema. Throughout 1999, channels including MTV and British Eurosport launched on the platform. The exclusive Carlton Kids and Carlton World channels closed in 2000 to make way for two Discovery channels.\nONdigital reported in April 1999 that it had 110,000 subscribers, while Sky Digital had over 350,000 by that time. By March 2000, there were 673,000 ONdigital customers.\nThe first interactive digital service was launched in mid-1999, called ONgames. On 7 March 2000, ONmail was launched which provided an interactive e-mail service. A deal with multiplex operator SDN led to the launch of pay-per-view service ONrequest on 1 May 2000. In June 2000, ONoffer was launched. On 18 September 2000, the internet TV service ONnet was launched.\nOn 17 June 2000, ONdigital agreed to a \u00a3315 million three-year deal with the Football League to broadcast 88 live Nationwide League and Worthington Cup matches from the 2001\u201302 season.\nSetbacks.\nIn 1999, Sky started to give away their digiboxes for free whilst the customer subscribed. This was a problem for ONdigital, as they had no choice but to sell prepaid set top boxes to win customers back from rival services. Even when they decided to sell prepaid set top boxes (under the ONprepaid brand), they could not easily compete with Sky.\nONdigital's growth slowed throughout 2000, and by the start of 2001 the number of subscribers was no longer increasing; meanwhile, its competitor Sky Digital oversaw a dramatic increase in subscribers, spearheaded by the launch of interactive services, such as Open... and Sky Gamestar, and the launch of rival cable digital services from the likes of NTL and Telewest ate into ONdigital's subscriber numbers. The ONdigital management team responded with a series of free set-top box promotions, initially at retailers such as Currys and Dixons, when ONdigital receiving equipment was purchased at the same time as a television set or similarly priced piece of equipment. These offers eventually became permanent, with the set-top box loaned to the customer at no charge for as long as they continued to subscribe to ONdigital, an offer that was matched by Sky. ONdigital's churn rate, a measure of the number of subscribers leaving the service, reached 28% during 2001.\nAdditional problems for ONdigital were the choice of 64QAM broadcast mode, which when coupled with far weaker than expected broadcast power, meant that the signal was weak in many areas; a complex pricing structure with many options; a poor-quality subscriber management system (adapted from Canal+); a paper magazine TV guide whereas BSkyB had an electronic programme guide (EPG); insufficient technical customer services; and much signal piracy. While there was a limited return path provided via an in-built 2400 baud modem, there was no requirement, as there was with BSkyB, to connect the set-top box's modem to a phone line.\nWith this combination of factors contributing to the service's lack of popularity, in 2001, executives at ONdigital management wrote a letter to the government, asking for emergency funding to finance the service in order to keep it alive due to a lack of customers and paying members.\nLoaned equipment.\nONdigital began to sell prepaid set-top boxes (under the name ONprepaid) from November 1999 in order to win customers, especially at the launch of other digital services from the likes of NTL and Telewest. This bundle sold in high street shops and supermarkets at a price that included the set-top box (which was technically on loan) and the first year's subscription package. These prepaid boxes amounted to 50% of sales in December 1999. Thousands of these packages were also sold at well below retail price on auction sites such as the then-popular QXL. As the call to activate the viewing card did not require any bank details, many ONdigital boxes which were supposed to be on loan were at unverifiable addresses. This was later changed so a customer could not buy a box without ONdigital verifying their address. Many customers did not activate the viewing card at all, although where the viewer's address was known, ONdigital would write informing them that they must activate before a certain deadline.\nPiracy.\nThe ONdigital pay-per-view channels were encrypted using a system \u2013 SECA MediaGuard \u2013 which had subsequently been cracked by hackers working for NDS Group, the makers of the VideoGuard system that Sky Digital used. ONdigital did not update this system, therefore it was possible to produce and sell counterfeit subscription cards which would give access to all the channels. About 100,000 pirate cards were in circulation by 2002, and these played a role in the demise of the broadcaster that year.\nRebranding.\nIn April 2001 it was said that ONdigital would be 'relaunched' to bring it closer to the ITV network and to better compete with Sky. On 11 July 2001 Carlton and Granada rebranded ONdigital as ITV Digital.\nOther services were also rebranded, such as ONnet to ITV Active. A rebranding campaign was launched, with customers being sent ITV Digital stickers to place over the ONdigital logos on their remote controls and set top boxes. The software running on the receivers was not changed, however, and continued to display 'ON' on nearly every screen. However, iDTVs made after the rebrand removed the 'ON' prefix from their software. Option 7 on the main menu on iDTVs was also renamed from \"ONdigital Updates\" to \"Subscription Information\".\nThe rebrand was not without controversy, as SMG plc (owner of Scottish Television and Grampian Television), UTV and Channel Television pointed out that the ITV brand did not belong solely to Carlton and Granada. SMG and UTV initially refused to carry the advertising campaign for ITV Digital and did not allow the ITV Sport Channel space on their multiplex, thus it was not available at launch in most of Scotland and Northern Ireland. The case was resolved in Scotland and the Channel Islands and later still in Northern Ireland, allowing ITV Sport to launch in the non-Carlton and Granada regions, although it was never made available in the Channel Islands, where there was no DTT or cable, and it never appeared on Sky Digital.\nLater in 2001, ITV Sport Channel was announced. This would be a premium sport channel, and would broadcast English football games as per the company's deal with the Football League in 2000, as well as ATP tennis games and Champions League games previously covered by ONsport 1 and ONsport 2. The channel launched on 11 August of that year, and was also carried on cable by NTL.\nDownfall.\nThe service reached 1 million subscribers by January 2001, whereas Sky Digital had 5.7 million. Granada reported \u00a369 million in losses in the first six months of 2001, leading some investors to urge it to close or sell ONdigital/ITV Digital. ITV Digital was unable to make a deal to put the ITV Sport Channel on Sky, which could have given the channel access to millions of Sky customers and generated income; the channel was only licensed to cable company NTL. Subscriptions for ONnet/ITV Active, its internet service, peaked at around 100,000 customers. ITV Digital had a 12% share of digital subscribers as of December 2001. ITV Digital and Granada cut jobs that month. By 2002, the company was thought to be losing up to \u00a31 million per day.\nIn February 2002, Carlton and Granada said that ITV Digital needed an urgent \"fundamental restructuring\". The biggest cost the company faced was its three-year deal with the Football League, which had been deemed too expensive by critics when agreed, as it was inferior to the top-flight Premiership coverage from Sky Sports. It was reported on 21 March 2002 that ITV Digital had proposed paying only \u00a350 million for the remaining two years of the Football League deal, a reduction of \u00a3129m. Chiefs from the League said that any reduction in the payment could threaten the existence of many football clubs, which had budgeted for large incomes from the television contract.\nAdministration.\nOn 27 March 2002, ITV Digital was placed in administration as it was unable to pay the full amount due to the Football League. Later, as chances of its survival remained bleak, the Football League sued Carlton and Granada, claiming that the firms had breached their contract in failing to deliver the guaranteed income. On 1 August the league lost the case, with the judge ruling that it had \"failed to extract sufficient written guarantees\". The league then filed a negligence claim against its own lawyers for failing to press for a written guarantee at the time of the deal with ITV Digital. From this, in June 2006, it was awarded a paltry \u00a34 in damages of the \u00a3150m it was seeking. The collapse put in doubt the government's ambition to switch off analogue terrestrial TV signals by 2010.\nDespite several interested parties, the administrators were unable to find a buyer for the company and effectively put it into liquidation on 26 April 2002. Most subscription channels stopped broadcasting on ITV Digital on 1 May 2002 at 7 am, with only free-to-air services continuing. The next day, ITV chief executive Stuart Prebble quit. In all, 1,500 jobs were lost by ITV Digital's collapse. ITV Digital was eventually placed into liquidation on 18 October, with debts of \u00a31.25 billion.\nPost-collapse.\nBy 30 April 2002, the Independent Television Commission (ITC) had revoked ITV Digital's broadcasting licence and started looking for a buyer. A consortium made up of the BBC and Crown Castle submitted an application on 13 June, later joined by BSkyB, and were awarded the licence on 4 July. They launched the Freeview service on 30 October 2002, offering 30 free-to-air TV channels and 20 free-to-air radio channels including several interactive channels such as BBC Red Button and Teletext, but no subscription or premium services. Those followed on 31 March 2004 when Top Up TV began broadcasting 11 pay TV channels in timeshared broadcast slots.\nFrom 10 December 2002, ITV Digital's liquidators started to ask customers to return their set top boxes or pay a \u00a339.99 fee. Had this been successful, it could have threatened to undermine the fledgling Freeview service, since at the time most digital terrestrial receivers in households were ONdigital and ITV Digital legacy hardware. In January 2003, Carlton and Granada stepped in and paid \u00a32.8m to the liquidators to allow the boxes to stay with their customers, because at the time the ITV companies received a discount on their broadcasting licence payments based on the number of homes they had converted to digital television. It was also likely done to avoid further negativity towards the two companies.\nDuring the time under administration, Carlton and Granada were in talks regarding a merger, which was eventually cleared in 2004.\nEffect on football clubs.\nFollowing the proposed Football League merger, with the lucrative finances it proposed, ITV Digital's collapse had a large effect on many football clubs. Bradford City F.C. was one of the affected, and its debt forced it into administration in May 2002, followed by Leicester City in October.\nBarnsley F.C. also entered administration in October 2002, despite the club making a profit for the twelve years prior to the collapse of ITV Digital. Barnsley had budgeted on the basis that the money from the ITV Digital deal would be received, leaving a \u00a32.5 million shortfall in their accounts when the broadcaster collapsed.\nClubs were forced to slash staff, and some players were forced to be sold as they were unable to pay them. Some clubs increased ticket prices for fans to offset the losses.\nThe rights to show Football League matches were resold to Sky Sports for \u00a395 million for the next four years compared to \u00a3315 million over three years from ITV Digital, leading to a reduction from \u00a32 million per season to \u00a3700,000 in broadcasting revenue for First Division clubs.\nIn total, fourteen Football League clubs were placed in administration within four years of the collapse of ITV Digital, compared to four in the four years before.\nNews Corporation hacking allegations.\nOn 31 March 2002, French cable company Canal+ accused Rupert Murdoch's News Corporation in the United States of extracting the UserROM code from its MediaGuard encryption cards and leaking it onto the internet.\nCanal+ brought a lawsuit against News Corporation alleging that it, through its subsidiary NDS (which provides encryption technology for Sky and other TV services from Murdoch), had been working on breaking the MediaGuard smartcards used by Canal+, ITV Digital and other non-Murdoch-owned TV companies throughout Europe. The action was later partially dropped after News Corporation agreed to buy Canal+'s struggling Italian operation Telepiu, a direct rival to a Murdoch-owned company in that country. \nOther legal action by EchoStar/NagraStar was being pursued as late as August 2005, accusing NDS of the same wrongdoing. In 2008, NDS was found to have broken piracy laws by hacking EchoStar Communications' smart card system, however only $1,500 in statutory damages was awarded.\nOn 26 March 2012, an investigation from BBC's \"Panorama\" found evidence that one of News Corporation's subsidiaries sabotaged ITV Digital. It found that NDS hacked ONdigital/ITV Digital smartcard data and leaked them through a pirate website under Murdoch's control \u2013 actions which enabled pirated cards to flood the market. The accusations arose from emails obtained by the BBC, and an interview with Lee Gibling, the operator of a hacking website, who claimed he was paid up to \u00a360,000 per year by Ray Adams, NDS's head of security. This would mean that Murdoch used computer hacking to directly undermine rival ITV Digital. Lawyers for News Corporation claimed that these accusations of illegal activities against a rival business are \"false and libellous\". In June 2013 the Metropolitan Police decided to look into these allegations following a request by Labour MP Tom Watson.\nMarketing.\nITV Digital ran an advertising campaign involving the comedian Johnny Vegas as Al and a knitted monkey simply called Monkey, voiced by Ben Miller. A knitted replica of Monkey could be obtained by signing up to ITV Digital. Because the monkey could not be obtained without signing up to the service, a market for second-hand monkeys developed. At one time, original ITV Digital Monkeys were fetching several hundred pounds on eBay, and knitting patterns delivered by email were sold for several pounds. The campaign was created by the advertising agency Mother. In August 2002, following ITV Digital's collapse, Vegas claimed that he was owed money for the advertisements. In early 2007, Monkey and Al reappeared in an advert for PG Tips tea, which at first included a reference to ITV Digital's downfall.\nSet top boxes.\nThe set-top boxes used for ITV Digital and ONdigital were:\nCarlton/Granada digital television channels.\nCarlton and Granada (later ITV Digital Channels Ltd) created a selection of channels which formed some of the core content available via the service. These were:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46131", "revid": "750223", "url": "https://en.wikipedia.org/wiki?curid=46131", "title": "Solaris (Tarkovsky's movie)", "text": ""}
{"id": "46132", "revid": "50255754", "url": "https://en.wikipedia.org/wiki?curid=46132", "title": "Rennes", "text": "Prefecture and commune in Brittany, France\nRennes (; ; Gallo: \"Resnn\"; ) is a city in the east of Brittany in Northwestern France at the confluence of the rivers Ille and Vilaine. Rennes is the prefecture of the Brittany region and Ille-et-Vilaine department. In 2021, its urban area had a population of 371,464 inhabitants, while the larger metropolitan area had a population of 771,320. The inhabitants of Rennes are called \"Rennais\" (masculine) and \"Rennaises\" (feminine) in French.\nRennes's history goes back more than 2,000 years to a time when it was a small Gallic village named Condate. Together with Vannes and Nantes, it was one of the major cities of the ancient Duchy of Brittany. From the early sixteenth century until the French Revolution, Rennes was a parliamentary, administrative and garrison city of the historic province of Brittany in the Kingdom of France, as evidenced by its 17th-century Parliament's Palace. Rennes played an important role in the Stamped Paper Revolt (Revolt of the papier timbr\u00e9) in 1675. After the destructive fire of 1720, the medieval wooden center of the city was partially rebuilt in stone. Remaining mostly rural until the Second World War, Rennes underwent significant development in the twentieth century.\nSince the 1950s, Rennes has grown in importance through rural flight and modern industrial development, partly in the automotive sector. The city developed extensive building plans to accommodate upwards of 200,000 inhabitants. During the 1980s, Rennes became one of the main centres in telecommunications and high-tech industry. It is now a significant digital innovation centre in France. In 2002, Rennes became the smallest city in the world to have a Metro line.\nLabeled a city of art and history, it has preserved an important medieval and classical heritage within its historic center, with over 90 buildings protected as historic monuments. Home to more than 66,000 students in 2016, it is also the eighth-largest university campus of France. In 2018, named Rennes as \"the most liveable city in France\".\nAdministration.\nSince 2015, Rennes is divided into 6 cantons (populations as of 2019):\nRennes is divided into 12 quarters:\nMayors.\nThe current mayor of Rennes is Nathalie App\u00e9r\u00e9. A member of the Socialist Party, she replaced retiring Socialist incumbent Daniel Delaveau, in office from 2008 to 2014.\nAmong previous well-known mayors are:\nThe \"\" (\"city hall\") is right in the centre of Rennes.\nNational representation.\nThe French Prison Service operates the \"Centre p\u00e9nitentiaire de Rennes\", the largest women's prison in France.\nGeography.\nThe ancient centre of the town is built on a hill, with the north side being more elevated than the south side. It is at the confluence of two rivers: the Ille and the Vilaine.\nRennes is located on the European atlantic arc, 50\u00a0km from the English Channel (near Saint-Malo, Dinard, and Mont Saint-Michel).\nRennes has the distinction of having a significant Green Belt around its ring road. This Green Belt is a protected area between the city proper (rather dense) and the rest of its urban area (rather rural).\nClimate.\nRennes features an oceanic climate. Precipitation in Rennes is considerably less abundant than in the western parts of Brittany, reaching only half of the levels of, e.g., the city of Quimper, which makes rainfall in Rennes comparable to the levels of large parts of western Germany. Sunshine hours range between 1,700 and 1,850 annually, which is about the amount of sunshine received by the city of Lausanne.\nDemographics.\nIn 2018, the inner population of the city was 221,272. The Rennes intercommunal structure connecting Rennes with 42 nearby suburbs (named Rennes M\u00e9tropole) had 450,593 inhabitants and the metropolitan area had a population of nearly 750,000.\nRennes has the second fastest-growing metropolitan area in France after Toulouse and ahead of Montpellier, Bordeaux and Nantes.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nSights.\nHistoric centre.\nThe historic centre is located on the former plan of the ramparts. There is a difference between the northern city centre and the southern city centre due to the 1720 fire, which destroyed most of the timber-framed houses in the northern part of the city. The rebuilding was done in stone, on a grid plan. The poorer southern part was not rebuilt.\nDue to the presence of the \"parlement de Bretagne\", many \"h\u00f4tels particuliers\" were built in the northern part, the richer half of Rennes in the 18th century. Most of the city's \"monuments historiques\" can be found there.\nColourful traditional half-timbered houses are situated primarily along the roads of Saint-Sauveur, Saint-Georges, de Saint-Malo, Saint-Guillaume, des Dames, du Chapitre, Vasselot, Saint-Michel, de la Psallette and around the plazas of Champ-Jacquet, des Lices, Saint-Anne and Rallier-du-Baty.\nThe Parlement de Bretagne and city hall area.\nThe \"Parlement de Bretagne\" (Administrative and judicial centre of Brittany, ) is the most famous 17th century building in Rennes. It was rebuilt after a terrible fire in 1994 that may have been caused by a flare fired by a protester during a demonstration. It houses the Rennes Court of Appeal. The surrounding plaza is built in the classical style.\nIn the west, the Place de la Mairie (City Hall Plaza, Plasenn Ti K\u00ear):\nIn the east, at the end of the \"Rue Saint-Georges\" with traditional half-timbered houses: \nIn the south-east:\nThe Place des Lices and cathedral area.\nThe Place des Lices is lined by h\u00f4tels particuliers. Along with the Place Rallier-du-Baty, it is the location of the weekly big market, the march\u00e9 des Lices.\nNear the Rennes Cathedral (cath\u00e9drale Saint-Pierre de Rennes) is the Rue du Chapitre:\nAlso in this area are the former St. Yves chapel, which is now the tourist office and a local historical museum, and the Basilica Saint-Sauveur.\nRemains of the ramparts.\nBuilt from the 3rd to the 12th centuries, the ramparts were largely destroyed between the beginning of the 16th century and the 1860s.\nPlace Saint-Anne area.\nIn the south-west of the area, \"La Rue Saint-Michel\" nicknamed \"Rue de La Soif\" (\"Road of Thirst\"), is known for its many bars. Meanwhile, in the south-east, the Place du Champ-Jacquet features Renaissance buildings and a statue of mayor Jean Leperdit ripping up a conscription list.\nEast: Thabor park area.\nArea of Saint-Melaine square\nNotre-Dame-en-Saint-Melaine basilica,\nJardin botanique du Thabor (formal French garden, orangerie, rose garden, aviary) a botanical garden on 10 hectares of land, built between 1860 and 1867.\n17th century promenade \"la Motte \u00e0 Madame\", and a monumental stairway overlooking the Rue de Paris entrance to the Thabor.\nSouth city centre.\nThe south city centre is a mix of old buildings and 19th and 20th century constructions.\nSouth of the Vilaine.\nThe Fine Arts Museum is situated on Quai \u00c9mile Zola, by the Vilaine River.\nLes Champs Libres is a building on Esplanade Charles de Gaulle, and was designed by the architect Christian de Portzamparc. It houses the Brittany Museum (Mus\u00e9e de Bretagne), the regional library Biblioth\u00e8que de Rennes M\u00e9tropole with six floors, and the Espace des Sciences science centre with a planetarium.\nAt Place Honor\u00e9 Commeurec is Les Halles Centrales, a covered market from 1922, with one part converted into contemporary art gallery.\nThe Mercure Hotel is located in a restored building on Rue du Pr\u00e9-Bott\u00e9, which is the former office of Ouest-\u00c9clair, and then of \"Ouest-France\", France's leading daily regional newspaper.\nThere are large mills at Rue Duhamel, constructed on each side of the south branch of the Vilaine in 1895 and 1902.\nOther sights.\nTo the northwest of Rennes, near Rue de Saint-Malo, are the locks of the Canal d'Ille-et-Rance, opened in 1843.\nTwo locations for Oberth\u00fcr Printing Works were built by Marthenot between 1870 and 1895 on Rue de Paris in the eastern part of the city. Oberth\u00fcr Park is the second biggest garden in the city.\nThe 17th century manor of Haute-Chalais, a granite ch\u00e2teau, is situated to the south of the city in Blosne Quarter (Br\u00e9quigny).\nParks and gardens.\nParc du Thabor contains a compact but significant botanical garden, the Jardin botanique du Thabor. The University of Rennes, with a campus in the city's eastern section, also contains a botanical garden and collections (the Jardin botanique de l'Universit\u00e9 de Rennes).\nEconomy.\nThe local economy is based on car manufacturing, telecommunications, the digital sector and agrifood.\nThe telecommunications firm Orange (ex-France Telecom) is the largest private employer in the metropolitan area of Rennes with a workforce of 4,800 people. PSA Peugeot Citro\u00ebn is the second largest private employer, with 3,000 employees. PSA opened a manufacturing plant at La Janais in Chartres-de-Bretagne in 1961. Technicolor, one of the biggest TV and cinema broadcasting firms in the world, employs over 500 people.\nRennes has the second largest concentration of digital and ICT firms in France after Paris (with well-known companies and startups like Atos, Google, Neosoft, Orange S.A., Thales, Ericsson, Harmonic France, STmicroelectronics, Technicolor R&amp;D, Ubisoft, Regionsjob, Capgemini, OVH, Dassault Syst\u00e8mes, Delta Dore, Canon, Artefacto, Enensys Technologies, Exfo, Mitsubishi Electric R&amp;D Europe, Digitaleo, Kelbillet, Klaxoon, Sopra Group, Niji, and Airbus Cybersecurity). Rennes was one of the first French cities to receive French Tech accreditation, in November 2014. Moreover, Rennes has the third highest public research potential in the digital and ICT sectors in France, after Paris and Grenoble, with 3,000 people working in 10 laboratories, including the well-known IRISA, IETR, IRMAR, DGA-MI (cyberdefense), and SATIE. It also has the third highest innovation potential in the French agrifood industry, with many firms in this field (Lactalis, Triballat Sojasun, Coralis, Panavi, Bridor, Groupe Avril, Lo\u00efc Raison, Groupe Roullier, Sanders, etc.), an agro campus (Agrocampus Ouest) and a large international and professional expo, SPACE (held every September).\nOther large firms located in Rennes include the restaurant conglomerate Groupe Le Duff (owners of Brioche Dor\u00e9e, Bruegger's, La Madeleine, Mimi's Cafe, Timothy's World Coffee), Ouest-France, the most-read French-language newspaper in the world (with a circulation of 800,000 daily copies), and Samsic Service (cleanliness, industrial safety, job search, etc.).\nCulture.\nRennes is known as one of the most festive cities in France. It invests heavily in arts and culture and a number of its festivals such as the music festival \"Les Transmusicales\", \"Les Tomb\u00e9es de la Nuit\", \"Mythos\", Stunfest (fighting game competition) and \"Travelling\" (a film festival) are well known throughout the country. During the 1980s, Rennes was often cited as a hub of rock and new wave music in France.\nLes Champs Libres is the largest cultural institution in Brittany. They welcome more than a million visitors each year. Organized in a six-story pyramid with views over the city, the library offers 120,000 documents for loan, and there we can find as well the Museum of Brittany, Espace des Sciences and Planetarium.\nConcert halls.\nRennes is well-equipped with musical facilities:\nMuseums and exhibition places.\nThere are also five museums in Rennes:\nIn addition, there are art facilities such as \"40mcube\" exhibition space or the centre for contemporary art \"La Cri\u00e9e\".\nThere are also miscellaneous cultural venues, including the dance-dedicated \"Triange\" and two \"Art et Essai\" (arthouse) cinemas, \"l'Arvor\" and \"Cine TNB\". Surrounding cities house many other cultural sites.\nMedia.\nRennes was one of the first cities in France to have its own local television channel, 'TV Rennes', created in 1987.\nRennes has also local radio stations (Hit West, Radio Campus, Canal B, Radio Caroline, Radio Rennes, Radio Laser) and local newspapers and magazines (Ouest-France, Le Mensuel de Rennes, Place Publique, 20 Minutes Rennes).\nLocal culture.\nLocal languages.\nIn Brittany, two regional languages are spoken: Breton and Gallo. In Rennes, as part of Upper Brittany, Gallo was predominantly spoken as the local language, although Breton has always been spoken by migrants from the west of the region (Lower Brittany).\nNowadays, the Breton language is taught in two Diwan schools, some bilingual public and Catholic schools, in evening courses, and in university.\nThe municipality launched a linguistic plan through \"Ya d'ar brezhoneg\" on 24 January 2008.\nIn 2008, 2.87% of primary school children were enrolled in bilingual primary schools, and the number of pupils enrolled in these schools is steadily growing.\nLocal food.\nSpecialties from Rennes include:\nMany other Breton specialties (seafood, milk, vegetables, cheese, meat) are seen at the March\u00e9 des Lices, a weekly market held every Saturday morning (one of the largest markets in France).\nEducation.\nThe Rennes agglomeration has a large student population (around 63,000).\nThe city has two main universities; \"Universit\u00e9 de Rennes\", which offers courses in science, technology, medicine, philosophy, law, management, and economics, and \"Universit\u00e9 Rennes 2\", which has courses in the arts, literature, languages, communication, human and social sciences, and sport. The official website of Universit\u00e9 Rennes 2 identifies the facility as \"the largest research and higher learning institution in Arts, Literature, Languages, Social Sciences and Humanities in the West of France.\"\nThere are a few \"\u00c9cole Sup\u00e9rieures\" in Rennes, such as the \"\u00c9cole Normale Sup\u00e9rieure de Rennes\" on the Ker Lann campus just outside Rennes, the \"Institut d'\u00e9tudes politiques de Rennes\", and the ESC Rennes School of Business.\nThere are also branches of the \"\u00c9cole Sup\u00e9rieure d'\u00c9lectricit\u00e9\" \u2013 Sup\u00e9lec and Telecom Bretagne in the east of the city (Cesson-S\u00e9vign\u00e9), a campus of the \"\u00c9cole pour l'informatique et les nouvelles technologies\", a campus of the \"\u00c9cole pour l'informatique et les techniques avanc\u00e9es\", and the \"Institut National des Sciences Appliqu\u00e9es\", a \"grande \u00e9cole\" which is next to the \"\u00c9cole nationale sup\u00e9rieure de chimie de Rennes\".\nThe computer science and applied mathematics research institute, IRISA, is located on the campus of the Universit\u00e9 des Sciences, near Cesson-S\u00e9vign\u00e9. The \"D\u00e9l\u00e9gation G\u00e9n\u00e9rale pour l'Armement\" (defence procurement agency) operates the CELAR research centre, dedicated to electronics and computing, in the neighbouring town of Bruz.\nThe Catholic University of Rennes (\"Institut Catholique de Rennes\") is a Catholic university founded in 1989.\nThe city is also home to an American study abroad program for high school students, School Year Abroad, in which students are immersed in French culture through five classes in the language and a nine-month home stay.\nThe \"\u00c9cole Complem\u00e9ntaire Japonaise de Rennes\" (\u30ec\u30f3\u30cc\u88dc\u7fd2\u6388\u696d\u6821 \"Rennu Hosh\u016b Jugy\u014d K\u014d\"), a part-time Japanese supplementary school, is based in the \"Coll\u00e8ge Anne de Bretagne\" in Rennes.\nTransport.\nRennes has well-developed national road, rail and air links.\nPublic transport.\nLocal transport is based primarily on an extensive bus network (65 lines) and a light metro line that was inaugurated in March 2002 and cost \u20ac500\u00a0million to build. The driverless Rennes Metro (VAL) is in length and has 15 stations, including one designed by architect Norman Foster (La Poterie station). A second light metro line known as Line B was opened on 20 September 2022, after 8 years of construction.\nCycling.\nRennes provides another mode of local transport: a bike sharing system with 900 bicycles (named STAR, le v\u00e9lo). Rennes created the first system of modern French bike sharing in 1998.\nRoads.\nThe city is an important hub of Brittany's motorway network and is surrounded by a ring road, the Rocade (national road 136). The construction of the bypass was started in 1968 and completed in 1999. It is long, has 2 lanes each way (sometimes 3 lanes) and is toll-free. Many other expressways are connected to the Rennes ring road for local and regional service. By road, Saint-Malo can be reached in 45 minutes, Nantes in 1 hour, Brest in 2 hours and 30 minutes, Paris in 4 hours, Bordeaux in 5 hours, and Brussels in 6 hours and 30 minutes.\nRailway.\nRennes has a major French railway station, the Gare de Rennes, opened in 1857. Since 2 July 2017, it is now one hour and twenty-seven minutes by TGV high-speed train from Paris (after the extension of the High Speed Rail Line). Train services are available to other major cities in France such as Lyon, Marseille, Lille, and Strasbourg.\nRennes is also an important railway station for regional transport in Brittany. The TER Bretagne provides links to Saint-Malo, Nantes, Redon, Vitr\u00e9, Saint-Brieuc, Vannes, Laval, Brest and many other regional cities. It is served by Gares station on the VAL Rennes Metro.\nAirport.\nRennes is served by Rennes Brittany Airport (Saint-Jacques), located from the centre to the south-west in the commune Saint-Jacques-de-la-Lande.\nIt notably operates regular or seasonal flights to Paris-Charles de Gaulle, Lyon, Marseille, Nice, Toulouse, Barcelona, Palma de Mallorca, Rome-Fiumicino, Southampton, Dublin, Exeter, Manchester, Amsterdam Schiphol, Madrid Barajas, Birmingham, London-City, London-Gatwick and daily flights to London Southend Airport with Flybe.\nInternational relations.\nTwin towns \u2013 sister cities.\nRennes is twinned with:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nOther forms of cooperation.\nFriendly towns within France\nPacts of cooperation\nSponsorship\nRennes also has the only Institut Franco-Am\u00e9ricain in France.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46133", "revid": "50920239", "url": "https://en.wikipedia.org/wiki?curid=46133", "title": "Cardiomyopathy", "text": "Disease of the heart muscle\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nCardiomyopathy is a group of primary diseases of the heart muscle. Early on there may be few or no symptoms. As the disease worsens, shortness of breath, feeling tired, and swelling of the legs may occur, due to the onset of heart failure. An irregular heart beat and fainting may occur. Those affected are at an increased risk of sudden cardiac death.\nAs of 2013, cardiomyopathies are defined as \"disorders characterized by morphologically and functionally abnormal myocardium in the absence of any other disease that is sufficient, by itself, to cause the observed phenotype.\" Types of cardiomyopathy include hypertrophic cardiomyopathy, dilated cardiomyopathy, restrictive cardiomyopathy, arrhythmogenic right ventricular dysplasia, and Takotsubo cardiomyopathy (broken heart syndrome). In hypertrophic cardiomyopathy the heart muscle enlarges and thickens. In dilated cardiomyopathy the ventricles enlarge and weaken. In restrictive cardiomyopathy the ventricle stiffens.\nIn many cases, the cause cannot be determined. Hypertrophic cardiomyopathy is usually inherited, whereas dilated cardiomyopathy is inherited in about one third of cases. Dilated cardiomyopathy may also result from alcohol, heavy metals, coronary artery disease, cocaine use, and viral infections. Restrictive cardiomyopathy may be caused by amyloidosis, hemochromatosis, and some cancer treatments. Broken heart syndrome is caused by extreme emotional or physical stress.\nTreatment depends on the type of cardiomyopathy and the severity of symptoms. Treatments may include lifestyle changes, medications, or surgery. Surgery may include a ventricular assist device or heart transplant. In 2015 cardiomyopathy and myocarditis affected 2.5 million people. Hypertrophic cardiomyopathy affects about 1 in 500 people while dilated cardiomyopathy affects 1 in 2,500. They resulted in 354,000 deaths up from 294,000 in 1990. Arrhythmogenic right ventricular dysplasia is more common in young people.\nSigns and symptoms.\nThe presentation of cardiomyopathy is:\nCauses.\nCardiomyopathies can be of genetic (familial) or non-genetic (acquired) origin. Genetic cardiomyopathies usually are caused by sarcomere or cytoskeletal diseases, neuromuscular disorders, inborn errors of metabolism, malformation syndromes and sometimes are unidentified. Non-genetic cardiomyopathies can have definitive causes such as viral infections, myocarditis and others.\nCardiomyopathies are either confined to the heart or are part of a generalized systemic disorder, both often leading to cardiovascular death or progressive heart failure-related disability. Other diseases that cause heart muscle dysfunction are excluded, such as coronary artery disease, hypertension, or abnormalities of the heart valves. Often, the underlying cause remains unknown, but in many cases the cause may be identifiable. Alcoholism, for example, has been identified as a cause of dilated cardiomyopathy, as has drug toxicity, and certain infections (including Hepatitis C). Untreated celiac disease can cause cardiomyopathies, which can completely reverse with a timely diagnosis. In addition to acquired causes, molecular biology and genetics have given rise to the recognition of various genetic causes.\nA more clinical categorization of cardiomyopathy as 'hypertrophied', 'dilated', or 'restrictive', has become difficult to maintain because some of the conditions could fulfill more than one of those three categories at any particular stage of their development.\nThe current American Heart Association (AHA) definition divides cardiomyopathies into primary, which affect the heart alone, and secondary, which are the result of illness affecting other parts of the body. These categories are further broken down into subgroups which incorporate new genetic and molecular biology knowledge.\nMechanism.\nThe pathophysiology of cardiomyopathies is better understood at the cellular level with advances in molecular techniques. Mutant proteins can disturb cardiac function in the contractile apparatus (or mechanosensitive complexes). Cardiomyocyte alterations and their persistent responses at the cellular level cause changes that are correlated with sudden cardiac death and other cardiac problems.\nCardiomyopathies are generally varied individually. Different factors can cause cardiomyopathies in adults as well as children. For example, dilated cardiomyopathy in adults is associated with ischemic cardiomyopathy, hypertension, valvular diseases, and genetics. In children, neuromuscular diseases such as Becker muscular dystrophy or X-linked genetic disorder, are directly linked with cardiomyopathies.\nDiagnosis.\nAmong the diagnostic procedures done to determine a cardiomyopathy are:\nClassification.\nCardiomyopathies can be classified using different criteria:\nTreatment.\nTreatment may include suggestion of lifestyle changes to better manage the condition. Treatment depends on the type of cardiomyopathy and condition of disease, but may include medication (conservative treatment) or iatrogenic/implanted pacemakers for slow heart rates, defibrillators for those prone to fatal heart rhythms, ventricular assist devices (VADs) for severe heart failure, or catheter ablation for recurring dysrhythmias that cannot be eliminated by medication or mechanical cardioversion. The goal of treatment is often symptom relief, and some patients may eventually require a heart transplant.\nAcoramidis (Attruby) was approved for medical use in the United States in November 2024, to treat adults with cardiomyopathy of wild-type or variant (hereditary) transthyretin-mediated amyloidosis (ATTR-CM) to reduce death and hospitalization related to heart problems.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46134", "revid": "45925219", "url": "https://en.wikipedia.org/wiki?curid=46134", "title": "Robert Bylot", "text": "English explorer\nRobert Bylot (fl.\u20091610\u20131616) was an English explorer who made four voyages to the Arctic. He was uneducated and from a working-class background, but was able to rise to rank of master in the English Royal Navy.\nVoyages.\nRobert Bylot.\nFirst voyage, 1610\u20131611.\nBylot was first mate on the during Henry Hudson's 1610\u20131611 expedition into what is now known as Hudson Bay. In the spring of 1611, Hudson wanted to continue the expedition, but the crew wanted to return home. There was discontent between the captain and members of the crew, and was stripped of his rank.\nLater there was a mutiny in which Hudson, his son and several sailors were set adrift in an open boat in James Bay. It was due to Bylot's navigational skills that \"Discovery\" was able to return from the Arctic safely; Hudson and his party were never seen again. Upon return to England, Bylot was tried as a mutineer but was pardoned.\nSecond voyage, 1612\u20131613.\nBylot returned to Hudson Bay in 1612 with Sir Thomas Button. They wintered over at the mouth of the Nelson River, and in the spring of 1613, continued north. They were able to reach 65th parallel north, then returned to England.\nNorthwest Passage.\nFirst voyage, 1615.\nIn 1615, the Muscovy Company hired Bylot to find the Northwest Passage as captain of \"Discovery\". William Baffin was the pilot. They sailed west from Hudson Strait and were blocked by ice at Frozen Strait.\nSecond voyage, 1616.\nThe following year, the Muscovy Company again hired Bylot and Baffin to continue to search for the Northwest Passage. The voyage resulted in several notable achievements. First was the circumnavigation and mapping of what is now called Baffin Bay. Second was the discovery of Smith Sound, by which the North Pole would eventually be reached. Third was the discovery of Lancaster Sound, through which the Northwest Passage would eventually be found three centuries later.\nLegacy.\nBylot and Baffin's work in Baffin Bay was doubted by cartographers back in England. As late as 1812, some charts of the area only showed a dotted bulge with the words: \"Baffin's Bay according to the relation of W. Baffin in 1616, but not now believed.\"\nWhen the bay was \"rediscovered\" by Sir John Ross in 1818, the records of the Bylot\u2013Baffin voyage proved extremely accurate. In England, almost total credit for the discovery was given to Baffin, and Bylot was virtually ignored. Historian Farley Mowat speculated two possible reasons for this: Bylot's lack of education and lower position relative to Baffin in English society, and his involvement in the mutiny during Hudson's expedition.\nBylot Island, off the northern end of Baffin Island and one of the more dramatic of the Canadian Arctic islands, was named after him.\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "46135", "revid": "1071745", "url": "https://en.wikipedia.org/wiki?curid=46135", "title": "George Lakoff", "text": "American linguist (born 1941)\nGeorge Philip Lakoff ( ; born May 24, 1941) is an American cognitive linguist and philosopher, best known for his thesis that people's lives are significantly influenced by the conceptual metaphors they use to explain complex phenomena. Lakoff served as professor of linguistics at the University of California, Berkeley, from 1972 until his retirement in 2016.\nThe conceptual metaphor thesis, introduced in his and Mark Johnson's 1980 book \"Metaphors We Live By\" has found applications in a number of academic disciplines. Applying it to politics, literature, philosophy and mathematics has led Lakoff into territory normally considered basic to political science. In his 1996 book \"Moral Politics\", Lakoff described conservative voters as being influenced by the \"strict father model\" as a central metaphor for such a complex phenomenon as the state, and liberal/progressive voters as being influenced by the \"nurturant parent model\" as the folk psychological metaphor for this complex phenomenon. According to him, an individual's experience and attitude towards sociopolitical issues is influenced by being framed in linguistic constructions. In \"Metaphor and War: The Metaphor System Used to Justify War in the Persian Gulf\" (1991), he argues that the American involvement in the Persian Gulf War was obscured or \"spun\" by the metaphors which were used by the first Bush administration to justify it. Between 2003 and 2008, Lakoff was involved with a progressive think tank, the now defunct Rockridge Institute.\nLakoff is a member of the scientific committee of the Fundaci\u00f3n IDEAS (IDEAS Foundation), Spain's Socialist Party's think tank. The more general theory that elaborated his thesis is known as embodied mind. His first marriage was to linguist Robin Lakoff.\nWork.\nReappraisal of metaphor.\nAlthough some of Lakoff's research involves questions traditionally pursued by linguists \u2013 such as the conditions under which a certain linguistic construction is grammatically viable \u2013, he has become best known for his reappraisal of the role that metaphors play in the socio-political activity of humans. The Western scientific tradition has seen metaphor as a purely linguistic construction. The essential thrust of Lakoff's work has been to argue that metaphors are a primarily conceptual construction and are in fact central to the development of thought.\nIn his words: \"Our ordinary conceptual system, in terms of which we both think and act, is fundamentally metaphorical in nature.\" According to Lakoff, non-metaphorical thought is possible only when we talk about purely physical reality; the greater the level of abstraction, the more layers of metaphor are required to express that abstraction. People do not notice these metaphors for various reasons, including that some metaphors become \"dead\" in the sense that we no longer recognize their origin. Another reason is that we just do not \"see\" what is \"going on\". For instance, according to Lakoff, the notion that \"argument is war\" serves as the underlying metaphor in intellectual debate \u2013 a formulation he later revised to \"argument is struggle\":\nAccording to Lakoff, the development of thought has been the process of developing better metaphors. He also points out that the application of one domain of knowledge to another offers new perceptions and understandings.\nLinguistics wars.\nLakoff began his career as a student and later as a teacher of the theory of transformational grammar developed by Massachusetts Institute of Technology professor Noam Chomsky. In the late 1960s, however, he joined with others to promote generative semantics as an alternative to Chomsky's generative syntax. In an interview he stated:\nDuring that period, I was attempting to unify Chomsky's transformational grammar with formal logic. I had helped work out a lot of the early details of Chomsky's theory of grammar. Noam claimed then \u2014 and still does, so far as I can tell \u2014 that syntax is independent of meaning, context, background knowledge, memory, cognitive processing, communicative intent, and every aspect of the body...In working through the details of his early theory, I found quite a few cases where semantics, context, and other such factors entered into rules governing the syntactic occurrences of phrases and morphemes. I came up with the beginnings of an alternative theory in 1963 and, along with wonderful collaborators like \"Haj\" Ross and Jim McCawley, developed it through the sixties.\nLakoff's claim that Chomsky asserts independence between syntax and semantics has been rejected by Chomsky, who expressed the following view in 1965: A decision as to the boundary separating syntax and semantics (if there is one) is not a prerequisite for theoretical and descriptive study of syntactic and semantic rules. On the contrary, the problem of delimitation will clearly remain open until these fields are much better understood than they are today. Exactly the same can be said about the boundary separating semantic systems from systems of knowledge and belief. That these seem to interpenetrate in obscure ways has long been noted\u2026.\nIn response to Lakoff's making the above claim about Chomsky's view, Chomsky claimed that Lakoff has \"virtually no comprehension of the work he is discussing\". This rift between Generative Grammar and Generative Semantics led to fierce, acrimonious debates among linguists that have come to be known as the \"linguistics wars\".\nEmbodied mind.\nWhen Lakoff claims the mind is \"embodied\", he is arguing that almost all of human cognition, up through the most abstract reasoning, depends on and makes use of such concrete and \"low-level\" facilities as the sensorimotor system and the emotions. Therefore, embodiment is a rejection not only of dualism vis-a-vis mind and matter, but also of claims that human reason can be basically understood without reference to the underlying \"implementation details\". Lakoff offers three complementary but distinct arguments in favor of embodiment:\nLakoff envisages consciousness as neurally embodied, however he explicitly states that the mechanism is not just neural computation alone. Using the concept of disembodiment, Lakoff supports the physicalist approach to the afterlife. If the soul can not have any of the properties of the body, then Lakoff claims it can not feel, perceive, think, be conscious, or have a personality. If this is true, then Lakoff asks what would be the point of the afterlife? Many scientists share the belief that there are problems with falsifiability and foundation ontologies purporting to describe \"what exists\", to a sufficient degree of rigor to establish a reasonable method of empirical validation. But Lakoff takes this further to explain why hypotheses built with complex metaphors cannot be directly falsified. Instead, they can only be rejected based on interpretations of empirical observations guided by other complex metaphors. This is what he means when he says that falsifiability itself can never be established by any reasonable method that would not rely ultimately on a shared human bias. The bias he's referring to is the set of conceptual metaphors governing how people interpret observations.\nLakoff is, with coauthors Mark Johnson and Rafael E. N\u00fa\u00f1ez, one of the primary proponents of the embodied mind thesis. Lakoff discussed these themes in his 2001 Gifford Lectures at the University of Glasgow, published as \"The Nature and Limits of Human Understanding\". Others who have written about the embodied mind include philosopher Andy Clark (See his \"Being There\"), philosophers and neurobiologists Humberto Maturana and Francisco Varela and Varela's student Evan Thompson, roboticists such as Rodney Brooks, Rolf Pfeifer and Tom Ziemke, the physicist David Bohm (see his \"Thought As A System\"), Ray Gibbs (see his \"Embodiment and Cognitive Science\"), John Grinder and Richard Bandler in their neuro-linguistic programming, and Julian Jaynes. The work of these writers can be traced back to earlier philosophical writings, most notably in the phenomenological tradition, such as Maurice Merleau-Ponty (1908\u20131961) and Heidegger (1889\u20131976). The basic thesis of \"embodied mind\" is also traceable to the American contextualist or pragmatist tradition, notably to John Dewey in such works as \"Art as Experience\" (1934).\nMathematics.\nAccording to Lakoff, even mathematics is subjective to the human species and its cultures: thus \"any question of math's being inherent in physical reality is moot, since there is no way to know whether or not it is\". By this, he is saying that there is nothing outside of the thought structures we derive from our embodied minds that we can use to \"prove\" that mathematics is somehow beyond biology. Lakoff and Rafael E. N\u00fa\u00f1ez (2000) argue at length that mathematical and philosophical ideas are best understood in light of the embodied mind.\nThe philosophy of mathematics ought therefore to look to the current scientific understanding of the human body as a foundation ontology, and should abandon self-referential attempts to ground the operational components of mathematics in anything other than \"meat\".\nMathematical reviewers have generally been critical of Lakoff and N\u00fa\u00f1ez, pointing to mathematical errors. Lakoff claims that these errors have been corrected in subsequent printings. Although Lakoff and N\u00fa\u00f1ez's book attempts a refutation of some of the most widely accepted viewpoints in the philosophy of mathematics and advice for how the field might proceed, its authors have yet to elicit much of a reaction from philosophers of mathematics themselves. The small community specializing in the psychology of mathematical learning, to which N\u00fa\u00f1ez belongs, is paying attention.\nLakoff has also claimed that we should remain agnostic about whether mathematics is somehow wrapped up with the very nature of the universe. Early in 2001 Lakoff told the American Association for the Advancement of Science (AAAS): \"Mathematics may or may not be out there in the world, but there's no way that we scientifically could possibly tell.\" This is because the structures of scientific knowledge are not \"out there\" but rather in our brains, based on the details of our anatomy. Therefore, we cannot \"tell\" that mathematics is \"out there\" without relying on conceptual metaphors rooted in our biology. This claim bothers those who believe that there really is a way we could \"tell\". The falsifiability of this claim is perhaps the central problem in the cognitive science of mathematics, a field that attempts to establish a foundation ontology based on the human cognitive and scientific process.\nPolitical significance and involvement.\nLakoff has publicly expressed some of his political views and his ideas about the conceptual structures that he views as central to understanding the political process. He almost always discusses the former in terms of the latter. \"Moral Politics\" (1996, revisited in 2002) gives book-length consideration to the conceptual metaphors that Lakoff sees as present in the minds of American \"liberals\" and \"conservatives\". The book is a blend of cognitive science and political analysis. Lakoff makes an attempt to keep his personal views confined to the last third of the book, where he explicitly argues for the superiority of the liberal vision.\nLakoff argues that the differences in opinions between liberals and conservatives follow from the fact that they subscribe with different strength to two different central metaphors about the relationship of the state to its citizens. Both, he claims, see governance through metaphors of the family. Conservatives would subscribe more strongly and more often to a model that he calls the \"strict father model\" and has a family structured around a strong, dominant \"father\" (government), and assumes that the \"children\" (citizens) need to be disciplined to be made into responsible \"adults\" (morality, self-financing). Once the \"children\" are \"adults\", though, the \"father\" should not interfere with their lives: the government should stay out of the business of those in society who have proved their responsibility. In contrast, Lakoff argues that liberals place more support in a model of the family, which he calls the \"nurturant parent model\", based on \"nurturant values\", where both \"mothers\" and \"fathers\" work to keep the essentially good \"children\" away from \"corrupting influences\" (pollution, social injustice, poverty, etc.). Lakoff says that most people have a blend of both metaphors applied at different times, and that political speech works primarily by invoking these metaphors and urging the subscription of one over the other.\nLakoff further argues that one of the reasons liberals have had difficulty since the 1980s is that they have not been as aware of their own guiding metaphors, and have too often accepted conservative terminology framed in a way to promote the strict father metaphor. Lakoff insists that liberals must cease using terms like \"partial birth abortion\" and \"tax relief\" because they are manufactured specifically to allow the possibilities of only certain types of opinions. \"Tax relief\" for example, implies explicitly that taxes are an affliction, something someone would want \"relief\" from. To use the terms of another metaphoric worldview, Lakoff insists, is to unconsciously support it. Liberals must support linguistic think tanks in the same way that conservatives do if they are going to succeed in appealing to those in the country who share their metaphors.\nLakoff offers advice about how to counteract politicians' lies. He maintains that the act of stating that a lie is false reinforces the lie because it repeats the way the lie is framed. Instead, he recommends what he calls a \"truth sandwich\":\n\"1. Start with the truth. The first frame gets the advantage.\n2. Indicate the lie. Avoid amplifying the specific language if possible.\n3. Return to the truth. Always repeat truths more than lies.\"\nLakoff calls this a \"truth sandwich\" even though the baloney is in the middle. The position of the lie avoids both primacy and recency effects.\nBetween 2003 and 2008, Lakoff was involved with a progressive think tank, the Rockridge Institute, an involvement that follows in part from his recommendations in \"Moral Politics\". Among his activities with the institute, which concentrates in part on helping liberal candidates and politicians with re-framing political metaphors, Lakoff has given numerous public lectures and written accounts of his message from \"Moral Politics.\" In 2008, Lakoff joined Fenton Communications, the nation's largest public interest communications firm, as a Senior Consultant. One of his political works, \"Don't Think of an Elephant! Know Your Values and Frame the Debate\", self-labeled as \"the Essential Guide for Progressives\", was published in September 2004 and features a foreword by former Democratic presidential candidate Howard Dean.\nDisagreement with Steven Pinker.\nIn 2006 Steven Pinker wrote an unfavorable review of Lakoff's book \"Whose Freedom?\" in \"The New Republic\". Pinker argued that Lakoff's propositions are unsupported, and his prescriptions are a recipe for electoral failure. He wrote that Lakoff was condescending and deplored Lakoff's \"shameless caricaturing of beliefs\" and his \"faith in the power of euphemism.\" Pinker portrayed Lakoff's arguments as \"cognitive relativism, in which mathematics, science, and philosophy are beauty contests between rival frames rather than attempts to characterize the nature of reality.\" Lakoff wrote a rebuttal to the review, stating that his position on many matters is the exact reverse of what Pinker attributes to him. Lakoff states that he explicitly rejects cognitive relativism, arguing that he is \"a realist, both about how the mind works and how the world works. Given that the mind works by frames and metaphors, the challenge is to use such a mind to accurately characterize how the world works.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46136", "revid": "173996", "url": "https://en.wikipedia.org/wiki?curid=46136", "title": "The Football Association", "text": "Governing body of association football in England \nThe Football Association (the FA) is the governing body of association football in England and the Crown Dependencies of Jersey, Guernsey and the Isle of Man. Formed in 1863, it is the oldest football association in the world and is responsible for overseeing all aspects of the amateur and professional game in its territory.\nThe FA facilitates all competitive football matches within its remit at national level, and indirectly at local level through the county football associations. It runs numerous competitions, the most famous of which is the FA Cup. It is also responsible for appointing the management of the men's, women's, and youth national football teams.\nThe FA is a member of both UEFA and FIFA and holds a permanent seat on the International Football Association Board (IFAB) which is responsible for the Laws of the Game. As the first football association, it does not use the national name \"English\" in its title. The FA is based at Wembley Stadium in London. The FA is a member of the British Olympic Association, meaning that the FA has control over the men's and women's Great Britain Olympic football team.\nAll of England's professional football teams are members of the Football Association. Although it does not run the day-to-day operations of the Premier League, it has veto power over the appointment of the league chairman and chief executive and over any changes to league rules. The English Football League, made up of the three fully professional divisions below the Premier League, is self-governing, subject to the FA's sanctions.\nHistory.\nIt was in England where the first official Association with clear rules was formed. For centuries before the first meeting of the Football Association in the Freemasons' Tavern on Great Queen Street, London on 26 October 1863, there were no universally accepted rules for playing football. In 1862, Ebenezer Cobb Morley, as captain of Barnes, wrote to \"Bell's Life\" newspaper proposing a governing body for the sport \"with the object of establishing a definite code of rules for the regulation of the game\"; the letter led to the first meeting at The Freemasons' Tavern that created the FA in 1863. Morley was a founding member. Six meetings near London's Covent Garden, at 81\u201382 Long Acre, ended in a split between the Association football and Rugby football. Both of them had their own uniforms, rituals, gestures and highly formalised rules.\nIn public school games, the rules were formalised according to local conditions; but when the schoolboys reached university, chaos ensued when the players used different rules, so members of the University of Cambridge devised and published a set of Cambridge Rules in 1848 which was widely adopted. Another set of rules, the Sheffield Rules, was used by a number of clubs in the North of England from the 1850s.\nEleven London football clubs and schools' representatives met on 26 October 1863 to agree on common rules. The founding clubs present at the first meeting were:\nCharterhouse sent their captain, B.F. Hartshorne, but declined the offer to join. Many of these clubs are now defunct or still play rugby. Civil Service FC, who now plays in the Southern Amateur League, is the only one of the original eleven football clubs still in existence, with an unbroken history, and playing association football, although Forest School has been a member since the fifth meeting in December 1863. Both Barnes and Wanderers have been re-established as football clubs in the modern era.\nEbenezer Cobb Morley was the FA's first secretary (1863\u201366) and its second president (1867\u201374) and drafted the Laws of the Game generally called the \"London Rules\" at his home in Barnes, London. He played in the first-ever match in 1863.\nThe first version of the rules for the modern game was drawn up over a series of six meetings held in The Freemasons' Tavern from October till December. Of the clubs at the first meeting, Crusaders, Surbiton and Charterhouse did not attend the subsequent meetings, replaced instead by the Royal Navy School, Wimbledon School and Forest School. \nSplit from rugby.\nAt the final meeting, F. M. Campbell, the first FA treasurer and the Blackheath representative, withdrew his club from the FA over the removal of two draft rules at the previous meeting, the first which allowed for the running with the ball in hand and the second, obstructing such a run by hacking (kicking an opponent in the shins), tripping and holding. Other English rugby clubs followed this lead and did not join the FA but instead in 1871 formed the Rugby Football Union. The term \"soccer\" dates back to this split to refer to football played under the \"association\" rules. After six clubs had withdrawn as they supported the opposing Rugby Rules, the Football Association had just nine members in January 1864: Barnes, Kilburn, Crystal Palace, War Office (Civil Service), Forest Club, Forest School, Sheffield, Uppingham and Royal Engineers (Chatham).\nAn inaugural game using the new FA rules was initially scheduled for Battersea Park on 2 January 1864, but enthusiastic members of the FA could not wait for the new year: the first game under F. A. rules was played at Mortlake on 19 December 1863 between Morley's Barnes team and their neighbours Richmond (who were not members of the FA), ending in a goalless draw. The Richmond side were obviously unimpressed by the new rules in practice because they subsequently helped form the Rugby Football Union in 1871. The Battersea Park game was the first exhibition game using FA rules, and was played there on Saturday 9 January 1864. The members of the opposing teams for this game were chosen by the President of the FA (A. Pember) and the Secretary (E. C. Morley) and included many well-known footballers of the day. After the first match according to the new FA rules a toast was given \"Success to football, irrespective of class or creed\".\nAnother notable match was London v Sheffield, in which a representative team from the FA played Sheffield FC under Association rules in March 1866; Charles Alcock described this game as \"first [match] of any importance under the auspices of the Football Association\". Alcock (of Harrow School) of the Wanderers was elected to the committee of the FA in 1866, becoming its first full-time secretary and treasurer in 1870. He masterminded the creation of the Football Association Cup\u2014the longest-running association football competition in the world\u2014in 1871. Fifteen participating clubs subscribed to purchase a trophy. The first Cup Final was held at The Oval on 16 March 1872, fought between the Wanderers and the Royal Engineers (RE), watched by 2,000 spectators. In 1874 Francis Marindin became the third president of the Football Association.\nAs football grew in popularity, it also began to take root in youth communities. In 1875, a Hanover Institute team (founded by Quintin Hogg, supported by fellow Old Etonian Arthur Kinnaird) was involved in an early attempt to incorporate football into the regular activities of a youth club, organising a match with boys from St Andrew's Home in Soho.\nSingle set of laws.\nAfter many years of wrangling between the London-based Football Association and the Sheffield Football Association, the FA Cup brought the acceptance that one undisputed set of laws was required. The two associations had played 16 inter-association matches under differing rules; the Sheffield Rules, the London Rules and Mixed Rules. In April 1877, those laws were set with a number of Sheffield Rules being incorporated. In 1890, Kinnaird replaced Major Francis Marindin, becoming the fourth president of the Football Association. Kinnaird had at that time been a FA committeeman since the age of 21, in 1868. Kinnaird remained president for the next 33 years, until his death in 1923.\nThe FA Cup was initially contested by mostly southern, amateur teams, but more professionally organised northern clubs began to dominate the competition during the early 1880s; \"The turning point, north replacing south, working class defeating upper and professionals impinging upon the amateurs' territory, came in 1883.\" Hitherto, public school sides had played a dribbling game punctuated by violent tackles, but a new passing style developed in Scotland was successfully adopted by some Lancashire teams, along with a more organised approach to training. Blackburn Olympic reached the final in March 1883 and defeated Old Etonians. Near-neighbours Blackburn Rovers started to pay players, and the following season won the first of three consecutive FA Cups. The FA initially tried to outlaw professionalism but, in the face of a threatened breakaway body (the British Football Association), by 1885 was forced to permit payments to players. Three years later, in 1888, the first Football League was established, formed by six professional clubs from northwest England and six from the midlands.\nIn 1992, the Football Association took control of the newly created Premier League which consisted of 22 clubs who had broken away from the First Division of the Football League. The Premier League reduced to 20 clubs in 1995 and is one of the richest football leagues in the world.\nThe Football Association has updated their logo several times. They celebrated their 150th year with a special 2013\u20132014 season logo. The shield design (taken from the coat of arms of the Football Association) is the same, but the three lions, rosettes and border are in gold instead of black and red, with the usual white background. The title strip above reads \"The FA\" in white on gold, and there is a scroll below reading \"150 years\" in white on gold, between \"1863\" and \"2013\".\nWomen's football.\nBy 1921 women's football had become increasingly popular through the charitable games played by women's teams during and after the First World War. In a move that was widely seen as caused by jealousy of the crowds' interest in women's games which frequently exceeded that of the top men's teams, in 1921 the Football Association banned all women's teams from playing on grounds affiliated to the FA because they thought football damaged women's bodies. For several decades, this meant that women's football virtually ceased to exist.\nThe decision to exclude women was only reversed from 1969 when, after the increased interest in football caused by England's 1966 World Cup triumph, the Women's Football Association was founded, although it would take a further two years \u2013 and an order from UEFA \u2013 to force the (men's) Football Association to remove its restrictions on the playing rights of women's teams. It was not until 1983 that the WFA was able to affiliate to the FA as a \"County Association\" and only in 1993 did the FA found the \"Women's Football Committee\" to run women's football in England. The \"Women's Football Conference\", as it is now known, has representation on the FA Council equivalent to a County Football Association.\nHonours.\nFA 2017 reform.\nIn December 2016, five former FA executives \u2013 David Bernstein, David Davies, Greg Dyke, Alex Horne and David Triesman \u2013 called on Parliament's Culture, Media and Sport Committee to propose legislation to reform the FA, saying it was outdated, held back by \"elderly white men\", and unable to counter the power of the Premier League or \"to reform and modernise in a fast-changing world\".\nIn April 2017, it was announced that some reforms, including reducing the size of the FA's board and increasing the number of women, would be submitted for approval to the FA's annual general meeting on 18 May. However, the proposed changes were criticised by some for not going far enough, particularly to improve minority representation. The proposals were approved at the AGM and include:\nHowever, pressure for FA reform continued fuelled by allegations of racism and bullying in relation to the Mark Sampson and Eniola Aluko cases, and the historical sexual abuse scandal. In October 2017, FA chairman Greg Clarke announced a \"fundamental\" review of the FA after admitting it had \"lost the trust of the public\" following the Sampson controversy. In the same month, Clarke was criticised by sexual abuse victim Andy Woodward and the Professional Footballers' Association's chief executive Gordon Taylor for remarks Clarke made to a Digital, Culture, Media and Sport Committee (DCMS) hearing.\nIn November 2020, Clarke resigned as FA chairman over his use of the term \"coloured\" when referring to black players in comments to the DCMS committee via video link. The FA subsequently announced they would seek a new chairman, with hopes there would be an announcement as to the successor by March 2021.\nUK football sexual abuse scandal (2016\u20132021).\nIn mid-November 2016, allegations of widespread historical sexual abuse at football clubs dating back to the 1970s began to emerge. On 21 November, the Football Association said it would set up a helpline; this was established with the NSPCC and opened on 24 November, reportedly receiving over 50 calls within the first two hours, over 100 by 27 November, and 860 (\"more than three times as many referrals as in the first three days of the Jimmy Savile scandal\") by 1 December with 350 individuals alleging abuse. The FA and NSPCC also collaborated to produce a film about how to keep children safe in the sport, featuring the captains of England's men's, women's and cerebral palsy football teams (Wayne Rooney, Steph Houghton and Jack Rutter).\nOn 27 November, the FA announced it was to set up an internal review, led by independent counsel Kate Gallafent, into what Crewe and Manchester City knew about convicted child sex offender Barry Bennell and allegations of child sexual abuse in football, and investigate what information it was aware of at the time of the alleged offences.\nThe FA was criticised by Conservative MP Damian Collins, chairman of the House of Commons' Culture, Media and Sport Committee, for being too slow in reacting and not instigating a wider review. Former sport minister Gerry Sutcliffe talked of previous concern about how the FA dealt with governance of the sport and with youth development (in the 1990s, the FA was said to have reacted \"dismissively\" to worries about sexual abuse in the game, and too slow to implement criminal record checks; in 2003, the FA had scrapped a project meant to ensure children were being protected from sexual abuse; and FA officials had been uncooperative with the review project, with ten of 14 FA staff not replying to interview requests and a report by the researchers of others being \"prevented/bullied\" from talking). Sutcliffe said an independent body, such as the Department for Culture, Media and Sport should look at the issue rather than the FA investigating itself: \"What I've seen in football over the years is that they're very narrow, very insular, and may not do a proper job even though with the right intentions.\"\nOn 6 December 2016, the FA announced that, due to \"the increased scope of the review since it was announced\" and Gallafent's other professional commitments, the review would be conducted by Clive Sheldon QC. On 11 January 2017, the Sheldon review had made its first call for evidence, writing to all football clubs in England and Wales, amateur and professional, asking for information by 15 March about allegations of child sexual abuse between 1970 and 2005. In March 2018, it was reported that the scale of evidence provided, plus the \"chaotic nature of the archiving\", had delayed the inquiry team's sift through the FA's legal files; around 500,000 pages of material from 6,000 files were uploaded to a digital platform, and 353 documents were identified as highly relevant. Sheldon expected to start writing his final report in August 2018.\nIn July 2018, it was reported that the FA's independent inquiry had found no evidence of an institutional cover-up or of a paedophile ring operating within football. Sheldon's report, likely to be highly critical of several clubs, was initially expected to be delivered to the FA in September 2018, but its publication was delayed, potentially by up to a year, pending the retrial of Bob Higgins and possible further charges against Barry Bennell.\nThe 700-page report was eventually published on 17 March 2021. It identified failures to act adequately on complaints or rumours of sexual abuse at eight professional clubs: Aston Villa, Chelsea, Crewe Alexandra, Manchester City, Newcastle United, Peterborough, Southampton and Stoke City. The report also made 13 recommendations for further improvements, including clubs employing qualified safeguarding officers, an FA board member to be the designated \"children's safeguarding champion\", spot checks of amateur clubs, a \"national day of safeguarding in football\" and an annual safeguarding report. However, the measures were criticised for being too late and lacking ambition. The FA issued a \"heartfelt apology\" to survivors and said it would be implementing all of Sheldon's recommendations.\nCrown Dependencies.\nThe football associations within the Crown Dependencies of Jersey (Jersey Football Association), Guernsey (Guernsey Football Association) and the Isle of Man (Isle of Man Football Association) are affiliated to the FA despite having a separate identity from that of the United Kingdom and by extension England. They are considered county football associations by the FA. Matt Le Tissier and Graeme Le Saux have represented the FA's full national representative team and were born in Guernsey and Jersey respectively.\nThe Guernsey Football Association, Isle of Man Football Association and Jersey Football Association have been affiliated with the FA since 1903, 1908 and 1905 respectively.\nA loophole was closed in May 2008 by FIFA which allowed players born in the Channel Islands to choose which home nation within the United Kingdom they will represent at international level. During the 1990s, Trevor Wood (Jersey) and Chris Tardif (Guernsey) represented Northern Ireland.\nOverseas Territories.\nThe British overseas territory of Gibraltar's Gibraltar Football Association was affiliated to the FA from 1911 until it opted to become a fully recognised member of UEFA, a feat achieved after a 14-year legal battle. Joseph Nunez, the Gibraltar FA President claimed they were \"unilaterally thrown out\" of the FA following an intervention from Geoff Thompson.\nOn the other hand, the Hong Kong Football Association (HKFA), established in 1914, is one of the oldest football associations in Asia. They joined FIFA in 1954, and were also one of twelve founding members of the Asian Football Confederation (AFC). HK played an important role in the early development of Asian football and hosted the first Asian Cup competition in 1956. The dependent territory was relinquished by the UK in 1997 and handed over to the People's Republic of China.\nSome of the other British overseas territories have local football associations or leagues (including the Anguilla Football Association, the Ascension Island Football League, the Bermuda Football Association, the British Virgin Islands Football Association, the Cayman Islands Football Association, the Falkland Islands Football League, the Montserrat Football Association, the Turks and Caicos Islands Football Association) and saint Helena, but these are not considered subsidiary to the Football Association.\nAlthough the British overseas territories are too small to support professional teams, they have produced players such as Clyde Best who have gone on to play professionally in the Football Association, and referees such as Carlyle Crockwell, who have refereed FIFA matches.\nRelationship with FIFA.\nThe Football Association first joined FIFA in 1905. The \"British Associations\" (England, Ireland, Scotland and Wales) opted to leave FIFA after World War I when FIFA chose not to exclude those who were part of the Central Powers from the organisation. The British Associations' stance had changed by 1922 and in 1924 they had rejoined FIFA.\nThe British Olympic Association had fought against 'broken time' \u2013 monetary compensation for athletes' earnings when competing in the Olympic games. At the 1925 Olympic Congress in Prague, the British had made an amendment that concluded governing federations should define amateur status for their sports but only in accordance with the definition of amateurism accepted by the Olympic Congress. In 1928, Switzerland proposed to FIFA that in certain circumstances, 'broken time' payments should be allowed and FIFA accepted. The FA resigned from FIFA in protest against the proposal. As a result of the FA's resignation, England did not participate in the 1930, 1934 or 1938 FIFA World Cup.\nAt the 1930 Olympic Congress in Berlin, Belgian delegates proposed that for each sport the definition of amateur status be left to its international federation. The BOA argued for a common definition of amateurism and argued that 'broken time' payments were against the Olympic ideal.\nThe FA rejoined FIFA in 1946 and participated in their first World Cup in 1950. One of the first actions of the Football Association was to request the expulsion of the German and Japanese national football associations for their countries' role in World War II. Germany and Japan were prevented from qualifying for the 1950 FIFA World Cup as a consequence. They were re-acquainted with FIFA in 1950 following a second request from Switzerland who had had a previous request rejected in 1948.\nCompetitions.\nThe FA runs several competitions:\nFinance and governance.\nFinances.\nThe FA's main commercial asset is its ownership of the rights to England internationals and the FA Cup. Broadcasting income remains the FA's largest revenue stream with both domestic and international broadcasting rights for England fixtures and the FA Cup tied up until at least 2021.\nFor the four seasons from 2008 to 2012, the FA secured \u00a3425\u00a0million from ITV and Setanta for England and FA Cup games domestic television rights, a 42% increase over the previous contract, and \u00a3145\u00a0million for overseas television rights, up 272% on the \u00a339\u00a0million received for the previous four-year period. However, during 2008\u201309 Setanta UK went into administration, which weakened the FA's cashflow position.\nTurnover for the year ending 31 July 2016 was \u00a3370\u00a0million on which it made a profit after tax of \u00a37\u00a0million. It has also made an investment of \u00a3125\u00a0million back into every level of Football in 2016. In July 2015 the FA announced plans to carry out a significant organisational restructure, in order to deliver considerable cost savings to invest in elite England teams, facilities and grassroots coaching.\nThe FA's income does not include the turnover of English football clubs, which are independent businesses. As well as running its own operations the FA chooses five charities each year to which it gives financial support.\nIn three years up to 2014, the FA received \u00a3350,000 in fines from players over comments made on Twitter. The highest fine imposed was a \u00a390,000 fine to Ashley Cole in 2012 after calling the FA \"a bunch of twats.\" The FA became stricter on comments made by players on Twitter, disciplining 121 players in three years.\nPrincipals.\nThe FA has a figurehead President, who since 1939 has always been a member of the British royal family. The Chairman of the FA has overall responsibility for policy. Traditionally this person rose through the ranks of the FA's committee structure (e.g. by holding posts such as the chairmanship of a county football association). In 2008 politician David Triesman was appointed as the FA's first \"independent chairman\", the first from outside the football hierarchy. The day-to-day head of the FA was known as the Secretary until 1989, when the job title was changed to Chief Executive.\nBoard of directors.\nTaken from The FA's website on 9 January 2022\nNational game representatives:\nProfessional game representatives: \nIndependent non-executive directors:\nBoard observers:\nNotes and references.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46137", "revid": "1951353", "url": "https://en.wikipedia.org/wiki?curid=46137", "title": "Rafael E. N\u00fa\u00f1ez", "text": "American mathematician\nRafael E. N\u00fa\u00f1ez is a professor of cognitive science at the University of California, San Diego and a proponent of embodied cognition. He co-authored \"Where Mathematics Comes From\" with George Lakoff."}
{"id": "46138", "revid": "23646674", "url": "https://en.wikipedia.org/wiki?curid=46138", "title": "Sicherheitsdienst", "text": "Intelligence agency of the SS and the Nazi Party in Nazi Germany\n (, \"Security Service\"), full title (\"Security Service of the \"Reichsf\u00fchrer-SS\"\"), or SD, was the intelligence agency of the SS and the Nazi Party in Nazi Germany. Established in 1931, the SD was the first Nazi intelligence organization and the Gestapo (formed in 1933) was considered its sister organization through the integration of SS members and operational procedures. The SD was administered as an independent SS office between 1933 and 1939. That year, the SD was transferred over to the Reich Security Main Office (\"Reichssicherheitshauptamt\"; RSHA), as one of its seven departments. Its first director, Reinhard Heydrich, intended for the SD to bring every single individual within the Third Reich's reach under \"continuous supervision\".\nFollowing Germany's defeat in World War II, the tribunal at the Nuremberg trials officially declared that the SD was a criminal organisation, along with the rest of Heydrich's RSHA (including the Gestapo) both individually and as branches of the SS in the collective. Heydrich was assassinated in 1942; his successor, Ernst Kaltenbrunner, was convicted of war crimes and crimes against humanity at the Nuremberg trials, sentenced to death and hanged in 1946.\nHistory.\nOrigins.\nThe SD, one of the oldest security organizations of the SS, was first formed in 1931 as the \"Ic-Dienst\" (Intelligence Service) operating out of a single apartment and reporting directly to Heinrich Himmler. Himmler appointed a former junior naval officer, Reinhard Heydrich, to organise the small agency. The office was renamed \"Sicherheitsdienst\" (SD) in the summer of 1932. The SD became more powerful after the Nazi Party took control of Germany in 1933 and the SS started infiltrating all leading positions of the security apparatus of the Reich. Even before Hitler became Chancellor in January 1933, the SD was a veritable \"watchdog\" over the SS and over members of the Nazi Party and played a critical role in consolidating political-police powers into the hands of Himmler and Heydrich.\nGrowth of SD and SS power.\nOnce Hitler was appointed Chancellor by German President Paul von Hindenburg, he quickly made efforts to manipulate the aging president. On 28 February 1933, Hitler convinced Hindenburg to declare a state of emergency which suspended all civil liberties throughout Germany, due at least in part to the Reichstag fire on the previous night. Hitler assured Hindenburg throughout that he was attempting to stabilize the tumultuous political scene in Germany by taking a \"defensive measure against Communist acts of violence endangering the state\". Wasting no time, Himmler set the SD in motion as they began creating an extensive card-index of the Nazi regime's political opponents, arresting labor organizers, socialists, Jewish leaders, journalists, and communists in the process, sending them to the newly established prison facility near Munich, Dachau. Himmler's SS and SD made their presence felt at once by helping rid the regime of its known political enemies and its perceived ones, as well. As far as Heydrich and Himmler were concerned, the SD left their mission somewhat vaguely defined so as to \"remain an instrument for all eventualities\". One such eventuality would soon arise.\nFor a while, the SS competed with the \"Sturmabteilung\" (SA) for influence within Germany. Himmler distrusted the SA and came to deplore the \"rabble-rousing\" brownshirts (despite once having been a member) and what he saw as indecent sexual deviants amid its leadership. At least one pretext to secure additional influence for Himmler's SS and Heydrich's SD in \"protecting\" Hitler and securing his absolute trust in their intelligence collection abilities, involved thwarting a plot from Ernst R\u00f6hm's SA using subversive means.\nOn 20 April 1934 Hermann G\u00f6ring handed over control of the \"Geheime Staatspolizei\" (Gestapo) to Himmler. Heydrich, named chief of the Gestapo by Himmler on 22 April 1934, also continued as head of the SD. These events further extended Himmler's control of the security mechanism of the Reich, which by proxy also strengthened the surveillance power of Heydrich's SD, as both entities methodically infiltrated every police agency in Germany. Subsequently, the SD was made the sole \"party information service\" on 9 June 1934.\nUnder pressure from the \"Reichswehr\" (German armed forces) leadership (whose members viewed the enormous armed forces of the SA as an existential threat) and with the collusion of G\u00f6ring, Joseph Goebbels, the Gestapo and SD, Hitler was led to believe that R\u00f6hm's SA posed a serious conspiratorial threat requiring a drastic and immediate solution. For its part, the SD provided fictitious information that there was an assassination plot on Hitler's life and that an SA putsch to assume power was imminent since the SA were allegedly amassing weapons. Additionally, reports were coming into the SD and Gestapo that the vulgarity of the SA's behavior was damaging the party and was even making antisemitism less palatable. On 30 June 1934 the SS and Gestapo acted in coordinated mass arrests that continued for two days. The SS took one of its most decisive steps in eliminating its competition for command of security within Germany and established itself firmly in the Nazi hierarchy, making the SS and its intelligence organ, the SD, responsible only to the F\u00fchrer. The purge became known as the Night of the Long Knives, with up to 200 people killed in the action. Moreover, the brutal crushing of the SA and its leadership sent a clear message to everyone that opposition to Hitler's regime could be fatal. It struck fear across the Nazi leadership as to the tangible concern of the reach and influence of Himmler's intelligence collection and policing powers.\nSD and Austria.\nDuring the autumn of 1937, Hitler secured Mussolini's support to annex Austria (Mussolini was originally apprehensive of the Nazi takeover of Austria) and informed his generals of his intentions to invade both Austria and Czechoslovakia. Getting Mussolini to approve political intrigue against Austria was a major accomplishment, as the Italian \"Duce\" had expressed great concern previously in the wake of an Austrian SS unit's attempt to stage a coup not more than three weeks after the R\u00f6hm affair, an episode that embarrassed the SS, enraged Hitler, and ended in the assassination of Austrian Chancellor Engelbert Dollfuss on 25 July 1934. Nonetheless, to facilitate the incorporation of Austria into the greater Reich, the SD and Gestapo went to work arresting people immediately, using lists compiled by Heydrich. Heydrich's SD and Austrian SS members received financing from Berlin to harass Austrian Chancellor von Schuschnigg's government all throughout 1937. One section of the SD that was nothing more than a front for subversive activities against Austria ironically promoted \"German-Austrian peace\".\nThroughout the events leading to the \"Anschlu\u00df\" and even after the Nazis marched into Austria on 12 March 1938, Heydrich \u2013 convinced that only his SD could pull off a peaceful union between the two German-speaking nations \u2013 organized demonstrations, conducted clandestine operations, ordered terror attacks, distributed propaganda materials, encouraged the intimidation of opponents, and had his SS and SD personnel round up prominent anti-Nazis, most of whom ended up in Mauthausen concentration camp The coordinated efforts of the SiPo and Heydrich's SD during the first days of the \"Anschlu\u00df\" effectively eliminated all forms of possible political, military and economic resistance within Austria. Once the annexation became official, the Austrian police were immediately subordinated to Heydrich's SD, the SS and Gestapo. Machinations by the SD, the Gestapo, and the SS helped to bring Austria fully into Hitler's grasp and on 13 March 1938, he signed into law the union with Austria as tears streamed down his face.\n\"Case Green\" and the Sudetenland.\nConcomitant to its machinations against Austria, the SD also became involved in subversive activities throughout Czechoslovakia. Focusing on the Sudetenland with its 3 million ethnic Germans and the disharmony there which the Czech government could not seem to remedy, Hitler set Heydrich's SD in motion in what came to be known as \"Case Green\". Passed off as a mission to liberate Sudeten Germans from alleged Czech persecution, Case Green was in fact a contingency plan to outright invade and destroy the country, as Hitler intended to \"wipe Czechoslovakia off the map.\"\nThis operation was akin to earlier SD efforts in Austria; however, unlike Austria, the Czechs fielded their own Secret Service, against which Heydrich had to contend. Once \"Case Green\" began, Heydrich's SD spies began covertly gathering intelligence, even going so far as having SD agents use their spouses and children in the cover scheme. The operation covered every conceivable type of intelligence data, using a myriad of cameras and photographic equipment, focusing efforts on important strategic locations like government buildings, police stations, postal services, public utilities, logistical routes, and above all, airfields.\nHitler worked out a sophisticated plan to acquire the Sudetenland, including manipulating Slovak nationalists to vie for independence and the suppression of this movement by the Czech government. Under directions from Heydrich, SD operative Alfred Naujocks was re-activated to engage in sabotage activities designed to incite a response from the Slovaks and the Czechs, a mission that ultimately failed. In June 1938 a directive from the SD head office indicated that Hitler issued an order at Jueterbog to his generals to prepare for the invasion of Czechoslovakia. To hasten a presumed heavy response from the French, British, and Czechs, Hitler then upped the stakes and claimed that the Czechs were slaughtering Sudeten Germans. He demanded the unconditional and prompt cession of the Sudetenland to Germany in order to secure the safety of endangered ethnic Germans. Around this time, early plots by select members of the German General Staff emerged, plans which included ridding themselves of Hitler.\nEventually a diplomatic showdown pitting Hitler against the governments of Czechoslovakia, Great Britain, and France, whose tepid reaction to the Austrian Anschluss had precipitated this crisis to some degree, ensued. The Sudetenland Crisis came to an end when Neville Chamberlain and Hitler signed the Munich Agreement on 29 September 1938, effectively ceding the Sudetenland to Nazi Germany. Involvement in international affairs by the SD certainly did not end there and the agency remained active in foreign operations to such a degree that the head of the Reich Foreign Ministry office, Joachim von Ribbentrop, complained of their meddling, since Hitler would apparently make decisions based on SD reports without consulting him. According to historian Richard Breitman, there was animosity between the SS leadership and Ribbentrop's Foreign Office atop their \"jurisdictional disputes\".\nIntrigue against Poland.\nAside from its participation in diminishing the power of the SA and its scheme to kill R\u00f6hm, the SD took part in international intrigue, first by activities in Austria, again in Czechoslovakia, and then by helping provoke the \"reactive\" war against Poland. Code-named \"Operation Himmler\" and part of Hitler's plan to justify an attack upon Poland, the SD's clandestine activity for this mission included faking a Polish attack against \"innocent Germans\" at a German radio station in Gleiwitz. The SD took concentration-camp inmates condemned to die, and fitted them with Polish Army uniforms which Heinz Jost had acquired from Admiral Wilhelm Canaris' \"Abwehr\" (military intelligence). Leading this mission and personally selected by Heydrich was SS veteran Alfred Naujocks, who later reported during a War Criminal proceeding that he brought a Polish-speaking German along so he could broadcast a message in Polish from the German radio station \"under siege\" to the effect that it was time for an all out confrontation between Germans and Poles. To add documented proof of this attack, the SD operatives placed the fictitious Polish troops (killed by lethal injection, then shot for appearance) around the \"attacked\" radio station with the intention of taking members of the press to the site of the incident. Immediately in the wake of the staged incidents on 1 September 1939, Hitler proclaimed from the Reichstag in a famous radio address that German soldiers had been \"returning\" fire since 5:45 in the morning, setting the Second World War in Europe into motion.\nTasks and general structure.\nThe SD was tasked with the detection of actual or potential enemies of the Nazi leadership and the neutralization of such opposition, whether internal or external. To fulfill this task, the SD developed an organization of agents and informants throughout the Reich and later throughout the occupied territories, all part of the development of an extensive SS state and a totalitarian regime without parallel. The organization consisted of a few hundred full-time agents and several thousand informants. Historian George C. Browder writes that SD regiments were comparable to SS regiments, in that:\nSD districts (\"Bezirke\") emerged covering several Party circuits (\"Kreis\") or an entire district (\"Gau\"). Below this level, SD sub-districts (\"Unterbezirke\") slowly developed. They were originally to cover a single \"Kreis\", and, in turn, to be composed of wards (\"Revier\"), but such an ambitious network never emerged. Eventually, the SD-sub-districts acquired the simple designation of 'outposts' (\"Aussenstellen\") as the lowest level-office in the field structure.\nThe SD was mainly an information-gathering agency, while the Gestapo\u2014and to a degree the Criminal Police (\"Kriminalpolizei\" or Kripo)\u2014was the executive agency of the political-police system. The SD and Gestapo did have integration through SS members holding dual positions in each branch. Nevertheless, there was some jurisdictional overlap and operational conflict between the SD and Gestapo. In addition, the Criminal Police kept a level of independence since its structure had been longer-established.\nAs part and parcel of its intelligence operations, the SD carefully tracked foreign opinion and criticism of Nazi policies, censoring when necessary and likewise publishing hostile political cartoons in the SS weekly magazine, \"Das Schwarze Korps\". An additional task assigned to the SD and the Gestapo involved keeping tabs on the morale of the German population at large, which meant they were charged to \"carefully supervise the political health of the German ethnic body\" and once any symptoms of \"disease and germs\" appeared, it was their job to \"remove them by every appropriate means\". Regular reports\u2014including opinion polls, press dispatches, and information bulletins were established. These were monitored and reviewed by the head of the Inland-SD, Otto Ohlendorf (responsible for intelligence and security within Germany) and by the former Heidelberg professor and SD member Reinhard H\u00f6hn. This activity aimed to control and assess the \"life domain\" or \"Lebensgebiet\" of the German population. Gathered information was then distributed by the SD through secret internal political reports entitled \"Meldungen aus dem Reich\" (reports from the Reich) to the upper echelons of the Nazi Party, enabling Hitler's r\u00e9gime to evaluate the general morale and attitude of the German people so they could be manipulated by the Nazi propaganda machine in timely fashion. When the Nuremberg Laws were passed in 1935, the SD reported that the measures against the Jews were well received by the German populace.\nIn 1936, the police were divided into the \"Ordnungspolizei\" (Orpo or Order Police) and the \"Sicherheitspolizei\" (SiPo or Security Police). The Orpo consisted mainly of the \"Schutzpolizei\" (urban police), the \"Gendarmerie\" (rural police) and the \"Gemeindepolizei\" (municipal police). The SiPo was composed of the Kripo and the Gestapo. Heydrich became Chief of the SiPo and continued as Chief of the SD.\nContinued escalation of antisemitic policies in the spring of 1937 from the SD's Department of Jewish Affairs () \u2013 staffed by members like Adolf Eichmann, Herbert Hagen, and Theodor Dannecker \u2013 led to the eventual removal (\"Entfernung\") of Jews from Germany; regardless of concerns about where they were headed. Adolf Eichmann's original task (in his capacity as deputy for the Jewish Affairs department within the SD) was at first to remove any semblance of \"Jewish influence from all spheres of public life\", which included the encouragement of wholesale Jewish emigration. Official bureaucratization increased apace with numerous specialized offices formed, aiding towards the overall persecution of the Jews.\nBecause the Gestapo and the SD had parallel duties, Heydrich tried to reduce any confusion or related territorial disputes through a decree on 1 July 1937, clearly defining the SD's areas of responsibility as those dealing with \"learning (\"Wissenschaft\"), art, party and state, constitution and administration, foreign lands, Freemasonry and associations\" whereas the \"Gestapo's jurisdiction was Marxism, treason, and emigrants\". Additionally, the SD was responsible for matters related to \"churches and sects, pacifism, the Jews, right-wing movements\", as well as \"the economy, and the Press\", but the SD was instructed to \"avoid all matters which touched the 'state police executive powers' (\"staatspolizeiliche Vollzugsma\u00dfnahmen\") since these belonged to the Gestapo, as did all individual cases.\"\nIn 1938, the SD was made the intelligence organization for the State as well as for the Nazi Party, supporting the Gestapo and working with the General and Interior Administration. As such, the SD came into immediate, fierce competition with German military intelligence, the \"Abwehr,\" which was headed by Admiral Canaris. The competition stemmed from Heydrich and Himmler's intention to absorb the \"Abwehr\" and Admiral Canaris' view of the SD as an amateur upstart. Canaris refused to give up the autonomy that his military intelligence organ possessed. Additional problems also existed, like the racial exemption for members of the \"Abwehr\" from the Nazi Aryan-screening process, and then there was competition for resources which occurred throughout Nazi Germany's existence.\nOn 27 September 1939, the SiPo became a part of the Reich Security Main Office (RSHA) under Heydrich:\nFrom February 1944 forward, the sections of the \"Abwehr\" were incorporated into \"Amt\" VI.\nThe SD's relationship with the \"Einsatzgruppen\".\nThe SD was the overarching agency under which the \"Einsatzgruppen der Sicherheitspolizei und des SD\", also known as the \"Einsatzgruppen\", was subordinated; this was one of the principal reasons for the later war-crimes indictment against the organization by the Allies. The \"Einsatzgruppen's\" part in the Holocaust has been well documented. Its mobile killing units were active in the implementation of the Final Solution (the plan for genocide) in the territories overrun by the Nazi war machine. This SD subsidiary worked closely with the Wehrmacht in persecuting Jews, communists, partisans, and other groups, as well. Starting with the invasion of Poland throughout the campaign in the East, the \"Einsatzgruppen\" ruthlessly killed anyone suspected of being an opponent of the regime, either real or imagined. The men of the \"Einsatzgruppen\" were recruited from the SD, Gestapo, Kripo, Orpo, and Waffen-SS.\nOn 31 July 1941, G\u00f6ring gave written authorisation to SD Chief Heydrich to ensure a government-wide cooperative effort in the implementation of the so-called Final Solution to the Jewish question in territories under German control. An SD headquarter's memorandum indicated that the SD was tasked to accompany military invasions and assist in pacification efforts. The memo explicitly stated:\nThe SD will, where possible, follow up immediately behind the troops as they move in and, as in the Reich, will assume responsibility for the security of political life. Within the Reich, security measures are the responsibility of the Gestapo with SD cooperation. In occupied territory, measures will be under the direction of a senior SD commander; Gestapo officials will be allotted to individual \"Einsatzst\u00e4be\". It will be necessary to make available for special deployment a unit of \"Verf\u00fcgungstruppe\" or \"Totenkopf\" [Death Head] formations.\nCorrespondingly, SD affiliated units, including the \"Einsatzgruppen\" followed German troops into Austria, the Sudetenland, Bohemia, Moravia, Poland, Lithuania, as well as Russia. Since their task included cooperating with military leadership and vice versa, suppression of opposition in the occupied territories was a joint venture. There were territorial disputes and disagreement about how some of these policies were to be implemented. Nonetheless, by June 1941, the SS and the SD task forces were systematically shooting Jewish men of military age, which soon turned to \"gunning down\" old people, women, and children in the occupied areas.\nOn 20 January 1942, Heydrich chaired a meeting, now called the Wannsee Conference, to discuss the implementation of the plan. Facilities such as Chelmno, Majdanek, Sobibor, Treblinka, and Auschwitz have their origins in the planning actions undertaken by Heydrich. Heydrich remained chief of the Security Police (SiPo) and the SD (through the RSHA) until his assassination in 1942, after which Ernst Kaltenbrunner was named chief by Himmler on 30 January 1943, and remained there until the end of the war. The SD was declared a criminal organization after the war and its members were tried as war criminals at Nuremberg. Whatever their original purpose, the SD and SS were ultimately created to identify and eradicate internal enemies of the State, as well as to pacify, subjugate, and exploit conquered territories and peoples.\nOrganization.\nThe SS Security Service, known as the SS \"SD-Amt\", became the official security organization of the Nazi Party in 1934. Consisting at first of paid agents and a few hundred unpaid informants scattered across Germany, the SD was quickly professionalized under Heydrich, who commissioned National Socialist academics and lawyers to ensure that the SS and its Security Service in particular, operated \"within the framework of National Socialist ideology.\" Heydrich was given the power to select men for the SS Security Service from among any SS subdivisions since Himmler considered the organization of the SD as important. In September 1939, the SD was divided into two departments, the interior department (\"Inland-SD\") and the foreign department (\"Ausland-SD\"), and placed under the authority of the Reich Security Main Office (RSHA).\nInland-SD.\nThe Interior Security Service (\"Inland-SD\"), responsible for intelligence and security within Germany, was known earlier as Department II and later, when placed under the Reich Security Main Office, as its Department III. It was originally headed by Hermann Behrends and from September 1939 by Otto Ohlendorf. It was within this organization that Adolf Eichmann began working out the details for the Final Solution to the Jewish Question. Department III was divided into the following sections:\nAusland-SD.\nThe Foreign Security Service (\"Ausland-SD\"), responsible for intelligence activities beyond the boundaries of Germany, was known earlier as Department III and later, after September 1939, as Department VI of the Reich Security Main Office. It was nominally commanded by Heydrich, but run by his chief of staff Heinz Jost. In March 1942 Jost was fired and replaced by Walter Schellenberg, a deputy of Heydrich. After the 20 July plot in 1944, Department VI took over the functions of the Military Intelligence Service (\"Abwehr\"). Department VI was divided into the following sections:\nSecurity forces.\nThe SD and the SiPo were the main sources of officers for the security forces in occupied territories. SD-SiPo led battalions were typically placed under the command of the SS and Police Leaders, reporting directly to the RSHA in Berlin. The SD also maintained a presence at all concentration camps and supplied personnel, on an as-needed basis, to such special action troops as the \"Einsatzgruppen\". In fact, all members of the \"Einsatzgruppen\" wore the SD sleeve diamond on their uniforms.\nThe SD-SiPo was the primary agency, in conjunction with the \"Ordnungspolizei\", assigned to maintain order and security in the Nazi ghettos established by the Germans throughout occupied Eastern Europe. On 7 December 1941, the same day as the Japanese attack on Pearl Harbor, the first extermination camp was opened at Chelmno near Lodz by Ernst Damzog, the SD and SiPo commander in occupied Pozna\u0144 (Posen). Damzog had personally selected the staff for the killing centre and later supervised the daily operation of the camp, which was under the command of Herbert Lange. Over a span of approximately 15 months, 150,000 people were killed there.\nInfiltration.\nAccording to the book \"Piercing the Reich\", the SD was infiltrated in 1944 by a former Russian national who was working for the Americans. The agent's parents had fled the Russian Revolution, and he had been raised in Berlin, and then moved to Paris. He was recruited by Albert Jolis of the Office of Strategic Services (OSS) Seventh Army detachment. The mission was codenamed RUPPERT.\nHow extensive the SD's knowledge was about the early plots to kill Hitler by key members of the military remains a contested subject and a veritable unknown. According to British historian John Wheeler-Bennett, \"in view of the wholesale destruction of Gestapo archives it is improbable that this knowledge will ever be forthcoming. That the authorities were aware of serious 'defeatism' is certain, but it is doubtful whether they suspected anyone of outright treason.\"\nPersonnel.\nGiven the nature of the intelligence operations assigned to the SD, there were clear delineations between what constituted a full member (\"Mitglied\") of the SD and those who were considered \"associates\" (\"Mitarbeiter\") with a further subset for clerical support personnel (typists, file clerks, etc.) who were connoted as V-persons (\"Vertrauensleute\"). All SD personnel, whether simply associates or full members were required to swear an oath of secrecy, had to meet all the requirements for SS membership, were assigned SD code numbers (\"Chiffre Nummer\") and if they were \"above the level of V-person\" they had to carry \"an SD identification card.\" The vast majority of early SD members were relatively young, but the officers were typically older by comparison; nevertheless, the average age of an SD member was approximately 2 years older than the average Nazi Party member. Much like the Nazi revolution in general, membership in the SS and the SD appealed more to the impressionable youth. Most SD members were Protestant by faith, had served in the military, and generally had a significant amount of education, representing \"an educated elite\" in the general sense \u2013 with about 14 percent of them earning doctorate degrees. Heydrich viewed the SD as spiritual-elite leaders within the SS and the \"cream of the cream of the NSDAP.\"\nAccording to historian George C. Browder, \"SD men represented no pathological or psychically susceptible group. Few were wild or extreme Nazi fanatics. In those respects they were 'ordinary men'. Yet in most other respects, they were an extraordinary mix of men, drawn together by a unique mix of missions.\" Along with members of the Gestapo, SD personnel were \"regarded with a mixture of fear and foreboding,\" and people wanted as little to do with them as possible. Belonging to the security apparatus of Nazi Germany obviously had its advantages but it was also fraught with occupationally related social disadvantages as well, and if post-war descriptions of the SD by historians are any indication, membership therein implied being a part of a \"ubiquitous secret society\" which was \"sinister\" and a \"messenger of terror\" not just for the German population, but within the \"ranks of the Nazi Party itself.\"\nUniforms and insignia.\nThe SD used SS-ranks. When in uniform they wore the grey Waffen-SS uniform with army and \"Ordnungspolizei\" rank insignia on the shoulder straps, and SS rank insignia on the left collar patch. The right collar patch was black without the runes. The branch color of the SD was green. The SD sleeve diamond (SD \"Raute\") insignia was worn on the lower left sleeve.\nReferences.\nInformational notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "46140", "revid": "561624", "url": "https://en.wikipedia.org/wiki?curid=46140", "title": "Satellite Navigation System", "text": ""}
{"id": "46143", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=46143", "title": "Planner (programming language)", "text": "Programming language\nPlanner (often seen in publications as \"PLANNER\" although it is not an acronym) is a programming language designed by Carl Hewitt at MIT, and first published in 1969. First, subsets such as Micro-Planner and Pico-Planner were implemented, and then essentially the whole language was implemented as \"Popler\" by Julian Davies at the University of Edinburgh in the POP-2 programming language. Derivations such as QA4, Conniver, QLISP and Ether (see scientific community metaphor) were important tools in artificial intelligence research in the 1970s, which influenced commercial developments such as Knowledge Engineering Environment (KEE) and Automated Reasoning Tool (ART).\nProcedural approach versus logical approach.\nThe two major paradigms for constructing semantic software systems were procedural and logical. The procedural paradigm was epitomized by \nLisp which featured recursive procedures that operated on list structures.\nThe logical paradigm was epitomized by uniform proof procedure resolution-based derivation (proof) finders. According to the logical paradigm it was \u201ccheating\u201d to incorporate procedural knowledge.\nProcedural embedding of knowledge.\nPlanner was invented for the purposes of the procedural embedding of knowledge and was a rejection of the resolution uniform proof procedure paradigm, which\nPlanner was a kind of hybrid between the procedural and logical paradigms because it combined programmability with logical reasoning. Planner featured a procedural interpretation of logical sentences where an implication of the form (P implies Q) can be procedurally interpreted in the following ways using pattern-directed invocation:\nIn this respect, the development of Planner was influenced by natural deductive logical systems (especially the one by Frederic Fitch [1952]).\nMicro-planner implementation.\nA subset called Micro-Planner was implemented by Gerry Sussman, Eugene Charniak and Terry Winograd and was used in Winograd's natural-language understanding program SHRDLU, Eugene Charniak's story understanding work, Thorne McCarty's work on legal reasoning, and some other projects. This generated a great deal of excitement in the field of AI. It also generated controversy because it proposed an alternative to the logic approach that had been one of the mainstay paradigms for AI.\nAt SRI International, Jeff Rulifson, Jan Derksen, and Richard Waldinger developed QA4 which built on the constructs in Planner and introduced a context mechanism to provide modularity for expressions in the database. Earl Sacerdoti and Rene Reboh developed QLISP, an extension of QA4 embedded in INTERLISP, providing Planner-like reasoning embedded in a procedural language and developed in its rich programming environment. QLISP was used by Richard Waldinger and Karl Levitt for program verification, by Earl Sacerdoti for planning and execution monitoring, by Jean-Claude Latombe for computer-aided design, by Nachum Dershowitz for program synthesis, by Richard Fikes for deductive retrieval, and by Steven Coles for an early expert system that guided use of an econometric model.\nComputers were expensive. They had only a single slow processor and their memories were very small by comparison with today. So Planner adopted some efficiency expedients including the following:\nThe genesis of Prolog.\nGerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971, spreading the news about Micro-Planner and SHRDLU and casting doubt on the resolution uniform proof procedure approach that had been the mainstay of the Edinburgh Logicists. At the University of Edinburgh, Bruce Anderson implemented a subset of Micro-Planner called PICO-PLANNER, and Julian Davies (1973) implemented essentially all of Planner.\nAccording to Donald MacKenzie, Pat Hayes recalled the impact of a visit from Papert to Edinburgh, which had become the \"heart of artificial intelligence's Logicland,\" according to Papert's MIT colleague, Carl Hewitt. Papert eloquently voiced his critique of the resolution approach dominant at Edinburgh \"\u2026and at least one person upped sticks and left because of Papert.\"\nThe above developments generated tension among the Logicists at Edinburgh. These tensions were exacerbated when the UK Science Research Council commissioned Sir James Lighthill to write a report on the AI research situation in the UK. The resulting report [Lighthill 1973; McCarthy 1973] was highly critical although SHRDLU was favorably mentioned.\nPat Hayes visited Stanford where he learned about Planner. When he returned to Edinburgh, he tried to influence his friend Bob Kowalski to take Planner into account in their joint work on automated theorem proving. \"Resolution theorem-proving was demoted from a hot topic to a relic of the misguided past. Bob Kowalski doggedly stuck to his faith in the potential of resolution theorem proving. He carefully studied Planner.\u201d. Kowalski [1988] states \"I can recall trying to convince Hewitt that Planner was similar to SL-resolution.\" But Planner was invented for the purposes of the procedural embedding of knowledge and was a rejection of the resolution uniform proof procedure paradigm. Colmerauer and Roussel recalled their reaction to learning about Planner in the following way:\n\"While attending an IJCAI convention in September \u201871 with Jean Trudel, we met Robert Kowalski again and heard a lecture by Terry Winograd on natural language processing. The fact that he did not use a unified formalism left us puzzled. It was at this time that we learned of the existence of Carl Hewitt\u2019s programming language, Planner. The lack of formalization of this language, our ignorance of Lisp and, above all, the fact that we were absolutely devoted to logic meant that this work had little influence on our later research.\"\nIn the fall of 1972, Philippe Roussel implemented a language called Prolog (an abbreviation for PROgrammation en LOGique \u2013 French for \"programming in logic\"). Prolog programs are generically of the following form (which is a special case of the backward-chaining in Planner):\n\"When goal\" Q, \"goal\" P1 \"and\" ... \"and goal\" Pn\nProlog duplicated the following aspects of Micro-Planner:\nProlog also duplicated the following capabilities of Micro-Planner which were pragmatically useful for the computers of the era because they saved space and time:\nUse of the Unique Name Assumption and Negation as Failure became more questionable when attention turned to Open Systems.\nThe following capabilities of Micro-Planner were omitted from Prolog:\nProlog did not include negation in part because it raises implementation issues. Consider for example if negation were included in the following Prolog program:\n\"not\" Q.\nQ :- P.\nThe above program would be unable to prove \"not\" P even though it follows by the rules of mathematical logic. This is an illustration of the fact that Prolog (like Planner) is intended to be a programming language and so does not (by itself) prove many of the logical consequences that follow from a declarative reading of its programs.\nThe work on Prolog was valuable in that it was much simpler than Planner. However, as the need arose for greater expressive power in the language, Prolog began to include many of the capabilities of Planner that were left out of the original version of Prolog.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "46145", "revid": "1126265", "url": "https://en.wikipedia.org/wiki?curid=46145", "title": "Oracle Solaris", "text": "Unix operating system originally developed by Sun Microsystems\nOracle Solaris is a proprietary Unix operating system offered by Oracle for SPARC and x86-64 based workstations and servers. Originally developed by Sun Microsystems as Solaris, it superseded the company's earlier SunOS in 1993 and became known for its scalability, especially on SPARC systems, and for originating many innovative features such as DTrace, ZFS and Time Slider. After the Sun acquisition by Oracle in 2010, it was renamed Oracle Solaris.\nSolaris was registered as compliant with the Single UNIX Specification until April 29, 2019. Historically, Solaris was developed as proprietary software. In June 2005, Sun Microsystems released most of the codebase under the CDDL license, and founded the OpenSolaris open-source project. Sun aimed to build a developer and user community with OpenSolaris; after the Oracle acquisition in 2010, the OpenSolaris distribution was discontinued and later Oracle discontinued providing public updates to the source code of the Solaris kernel, effectively turning Solaris version 11 back into a closed-source proprietary operating system. Following that, OpenSolaris was forked as Illumos and is alive through several Illumos distributions. In September 2017, Oracle laid off most of the Solaris teams.\nHistory.\nIn 1987, AT&amp;T Corporation and Sun announced that they were collaborating on a project to merge the most popular Unix variants on the market at that time: Berkeley Software Distribution (BSD), UNIX System V, and Xenix. This became Unix System V Release 4 (SVR4). About 40 AT&amp;T and Sun programmers would work together in the San Francisco Bay area, the two companies said, with the goal of SunOS compliance with SVR4 in 1988 and addition of BSD 4.2 features in 1989.\nOn September 4, 1991, Sun announced that it would replace SunOS 4, with one based on SVR4. This was identified internally as \"SunOS 5\", but a new marketing name was introduced at the same time: \"Solaris 2\". The justification for this new overbrand was that it encompassed not only SunOS, but also the OpenWindows graphical user interface and Open Network Computing (ONC) functionality.\nAlthough SunOS 4.1.\"x\" micro releases were retroactively named \"Solaris 1\" by Sun, the Solaris name is used almost exclusively to refer only to the releases based on SVR4-derived SunOS 5.0 and later.For releases based on SunOS 5, the SunOS minor version is included in the Solaris release number. For example, Solaris 2.4 incorporates SunOS 5.4. After Solaris 2.6, the \"2.\" was dropped from the release name, so Solaris 7 incorporates SunOS 5.7, and the latest release SunOS 5.11 forms the core of Solaris 11.4.Although SunSoft stated in its initial Solaris 2 press release their intent to eventually support both SPARC and x86 systems, the first two Solaris 2 releases, 2.0 and 2.1, were SPARC-only. An x86 version of Solaris 2.1 was released in June 1993, about 6 months after the SPARC version, as a desktop and uniprocessor workgroup server operating system. It included the Wabi emulator to support Windows applications. At the time, Sun also offered the Interactive Unix system that it had acquired from Interactive Systems Corporation. In 1994, Sun released Solaris 2.4, supporting both SPARC and x86 systems from a unified source code base.\nIn 2011, the Solaris 11 kernel source code leaked.\nOn September 2, 2017, Simon Phipps, a former Sun Microsystems employee not hired by Oracle in the acquisition, reported on Twitter that Oracle had laid off the Solaris core development staff, which many interpreted as sign that Oracle no longer intended to support future development of the platform. While Oracle did have a large layoff of Solaris development engineering staff, development continued and Solaris 11.4 was released in 2018.\nSupported architectures.\nSolaris uses a common code base for the platforms it supports: 64-bit SPARC and x86-64.\nSolaris has a reputation for being well-suited to symmetric multiprocessing, supporting a large number of CPUs. It has historically been tightly integrated with Sun's SPARC hardware (including support for 64-bit SPARC applications since Solaris 7), with which it is marketed as a combined package. This has led to more reliable systems, but at a cost premium compared to commodity PC hardware. However, it has supported x86 systems since Solaris 2.1 and 64-bit x86 applications since Solaris 10, allowing Sun to capitalize on the availability of commodity 64-bit CPUs based on the x86-64 architecture. Sun heavily marketed Solaris for use with both its own x86-64-based Sun Java Workstation and the x86-64 models of the Sun Ultra series workstations, and servers based on AMD Opteron and Intel Xeon processors, as well as x86 systems manufactured by companies such as Dell, Hewlett-Packard, and IBM. As of 2009[ [update]], the following vendors support Solaris for their x86 server systems:\nOther platforms.\nSolaris 2.5.1 included support for the PowerPC platform (PowerPC Reference Platform), but the port was canceled before the Solaris 2.6 release. In January 2006, a community of developers at Blastwave began work on a PowerPC port which they named \"Polaris\". In October 2006, an OpenSolaris community project based on the Blastwave efforts and Sun Labs' \"Project Pulsar\", which re-integrated the relevant parts from Solaris 2.5.1 into OpenSolaris, announced its first official source code release.\nA port of Solaris to the Intel Itanium architecture was announced in 1997 but never brought to market.\nOn November 28, 2007, IBM, Sun, and Sine Nomine Associates demonstrated a preview of OpenSolaris for System z running on an IBM System z mainframe under z/VM, called \"Sirius\" (in analogy to the Polaris project, and also due to the primary developer's Australian nationality: HMS \"Sirius\" of 1786 was a ship of the First Fleet to Australia). On October 17, 2008, a prototype release of Sirius was made available and on November 19 the same year, IBM authorized the use of Sirius on System z Integrated Facility for Linux (IFL) processors.\nSolaris also supports the Linux platform application binary interface (ABI), allowing Solaris to run native Linux binaries on x86 systems. This feature is called \"Solaris Containers for Linux Applications\" (SCLA), based on the branded zones functionality introduced in Solaris 10 8/07.\nInstallation and usage options.\nSolaris can be installed from various pre-packaged software groups, ranging from a minimalistic \"Reduced Network Support\" to a complete \"Entire Plus OEM\". Installation of Solaris is not necessary for an individual to use the system. The DVD ISO image can be used to load Solaris, running in-memory, rather than initiating the installation.\nAdditional software, like Apache, MySQL, etc. can be installed as well in a packaged form from \"sunfreeware\" and OpenCSW. Solaris can be installed from physical media or a network for use on a desktop or server, or be run in a live mode without installation on a desktop or server.\nUpdates.\nThere are several types of updates within each major release, including the Software Packages, and the Oracle Solaris Image. \nAdditional minor updates called Support Repository Updates (SRUs) and Critical Patch Update Packages (CPUs), require a support credential, thus are not freely available to the public.\nDesktop environments.\nEarly releases of Solaris used OpenWindows as the standard desktop environment. In Solaris 2.0 to 2.2, OpenWindows supported both NeWS and X applications, and provided backward compatibility for SunView applications from Sun's older desktop environment. NeWS allowed applications to be built in an object-oriented way using PostScript, a common printing language released in 1982. The X Window System originated from MIT's Project Athena in 1984 and allowed for the display of an application to be disconnected from the machine where the application was running, separated by a network connection. Sun's original bundled SunView application suite was ported to X.\nSun later dropped support for legacy SunView applications and NeWS with OpenWindows 3.3, which shipped with Solaris 2.3, and switched to X11R5 with Display Postscript support. The graphical look and feel remained based upon OPEN LOOK. OpenWindows 3.6.2 was the last release under Solaris 8. The OPEN LOOK Window Manager (olwm) and other OPEN LOOK-specific applications were dropped in Solaris 9, but support libraries were still bundled, providing long term binary backwards compatibility with existing applications. The OPEN LOOK Virtual Window Manager (olvwm) can still be downloaded for Solaris from sunfreeware and works on releases as recent as Solaris 10.\nSun and other Unix vendors formed an industry alliance to standardize Unix desktop environments. As a member of the Common Open Software Environment (COSE) initiative, Sun helped co-develop the Common Desktop Environment (CDE). This was an initiative to create a standard Unix desktop environment. Each vendor contributed different components: Hewlett-Packard contributed the window manager, IBM provided the file manager, and Sun provided the e-mail and calendar facilities as well as drag-and-drop support (ToolTalk). This new desktop environment was based upon the Motif look and feel and the old OPEN LOOK desktop environment was considered legacy. CDE unified Unix desktops across multiple open system vendors. CDE was available as an unbundled add-on for Solaris 2.4 and 2.5, and was included in Solaris 2.6 through 10.\nIn 2001, Sun issued a preview release of the open-source desktop environment GNOME 1.4, based on the GTK+ toolkit, for Solaris 8. Solaris 9 8/03 introduced GNOME 2.0 as an alternative to CDE. Solaris 10 includes Sun's Java Desktop System (JDS), which is based on GNOME and comes with a large set of applications, including StarOffice, Sun's office suite. Sun describes JDS as a \"major component\" of Solaris 10. The Java Desktop System is not included in Solaris 11 which instead ships with a stock version of GNOME. Likewise, CDE applications are no longer included in Solaris 11, but many libraries remain for binary backwards compatibility.\nThe open source desktop environments KDE and Xfce, along with numerous other window managers, also compile and run on recent versions of Solaris.\nSun was investing in a new desktop environment called Project Looking Glass since 2003. The project has been inactive since late 2006.\nLicense.\nTraditional operating system license (1992 to 2004).\nFor versions up to 2005 (Solaris 9), Solaris was licensed under a license that permitted a customer to buy licenses in bulk, and install the software on any machine up to a maximum number. The key license grant was:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;License to Use. Customer is granted a non-exclusive and non-transferable license (\"License\") for the use of the accompanying binary software in machine-readable form, together with accompanying documentation (\"Software\"), by the number of users and the class of computer hardware for which the corresponding fee has been paid.\nIn addition, the license provided a \"License to Develop\" granting rights to create derivative works, restricted copying to only a single archival copy, disclaimer of warranties, and the like. The license varied only little through 2004.\nOpen source (2005 until March 2010).\nFrom 2005 to 2010, Sun began to release the source code for development builds of Solaris under the Common Development and Distribution License (CDDL) via the OpenSolaris project. This code was based on the work being done for the post-Solaris 10 release (code-named \"Nevada\"; eventually released as Oracle Solaris 11). As the project progressed, it grew to encompass most of the necessary code to compile an entire release, with a few exceptions.\nPost-Sun closed source (March 2010 to present).\nWhen Sun was acquired by Oracle in 2010, the OpenSolaris project was discontinued after the board became unhappy with Oracle's stance on the project. In March 2010, the previously freely available Solaris 10 was placed under a restrictive license that limited the use, modification and redistribution of the operating system. The license allowed the user to download the operating system free of charge, through the Oracle Technology Network, and use it for a 90-day trial period. After that trial period had expired the user would then have to purchase a support contract from Oracle to continue using the operating system.\nWith the release of Solaris 11 in 2011, the license terms changed again. The new license allows Solaris 10 and Solaris 11 to be downloaded free of charge from the Oracle Technology Network and used without a support contract indefinitely; however, the license only expressly permits the user to use Solaris as a development platform and expressly forbids commercial and \"production\" use. Educational use is permitted in some circumstances. From the OTN license:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If You are an educational institution vested with the power to confer official high school, associate, bachelor, master and/or doctorate degrees, or local equivalent, (\"Degree(s)\"), You may also use the Programs as part of Your educational curriculum for students enrolled in Your Degree program(s) solely as required for the conferral of such Degree (collectively \"Educational Use\").\nWhen Solaris is used without a support contract, it can be upgraded to each new 'point release\u2019; however, a support contract is required for access to patches and updates that are released monthly.\nVersion history.\nNotable features of Solaris include DTrace, Doors, Service Management Facility, Solaris Containers, Solaris Multiplexed I/O, Solaris Volume Manager, ZFS, and Solaris Trusted Extensions.\nUpdates to Solaris versions are periodically issued. In the past, these were named after the month and year of their release, such as \"Solaris 10 1/13\"; as of Solaris 11, sequential update numbers are appended to the release name with a period, such as \"Oracle Solaris 11.4\".\nIn ascending order, the following versions of Solaris have been released:\nLegend:UnsupportedSupportedLatest versionPreview versionFuture version&lt;templatestyles src=\"Version/styles.css\" /&gt;\n \nA more comprehensive summary of some Solaris versions is also available. Solaris releases are also described in the Solaris 2 FAQ.\nDevelopment release.\nThe underlying Solaris codebase has been under continuous development since work began in the late 1980s on what was eventually released as Solaris 2.0. Each version such as Solaris 10 is based on a snapshot of this development codebase, taken near the time of its release, which is then maintained as a derived project. Updates to that project are built and delivered several times a year until the next official release comes out.\nThe Solaris version under development by Sun since the release of Solaris 10 in 2005, was codenamed \"Nevada\", and is derived from what is now the OpenSolaris codebase.\nIn 2003, an addition to the Solaris development process was initiated. Under the program name \"Software Express for Solaris\" (or just \"Solaris Express\"), a binary release based on the current development basis was made available for download on a monthly basis, allowing anyone to try out new features and test the quality and stability of the OS as it progressed to the release of the next official Solaris version. A later change to this program introduced a quarterly release model with support available, renamed \"Solaris Express Developer Edition\" (SXDE).\nIn 2007, Sun announced \"Project Indiana\" with several goals, including providing an open source binary distribution of the OpenSolaris project, replacing SXDE. The first release of this distribution was \"OpenSolaris 2008.05\".\nThe \"Solaris Express Community Edition\" (SXCE) was intended specifically for OpenSolaris developers. It was updated every two weeks until it was discontinued in January 2010, with a recommendation that users migrate to the OpenSolaris distribution. Although the download license seen when downloading the image files indicates its use is limited to personal, educational and evaluation purposes, the license acceptance form displayed when the user actually installs from these images lists additional uses including commercial and production environments.\nSXCE releases terminated with build 130 and OpenSolaris releases terminated with build 134 a few weeks later. The next release of OpenSolaris based on build 134 was due in March 2010, but it was never fully released, though the packages were made available on the package repository. Instead, Oracle renamed the binary distribution Solaris 11 Express, changed the license terms and released build 151a as 2010.11 in November 2010.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46146", "revid": "486612", "url": "https://en.wikipedia.org/wiki?curid=46146", "title": "Navigation satellite", "text": ""}
{"id": "46148", "revid": "18024", "url": "https://en.wikipedia.org/wiki?curid=46148", "title": "Intelligence service", "text": ""}
{"id": "46149", "revid": "41935478", "url": "https://en.wikipedia.org/wiki?curid=46149", "title": "GLONASS", "text": "Russian global navigation satellite system\nThe Global Navigation Satellite System (), universally recognized by its acronym GLONASS (, ), is a Russian satellite navigation system operating as part of a radionavigation-satellite service. It provides an alternative to Global Positioning System (GPS) and is the second navigational system in operation with global coverage and of comparable precision.\nSatellite navigation devices supporting both GPS and GLONASS have more satellites available, meaning positions can be fixed more quickly and accurately, especially in built-up areas where buildings may obscure the view to some satellites. Owing to its higher orbital inclination, GLONASS supplementation of GPS systems also improves positioning in high latitudes (near the poles).\nDevelopment of GLONASS began in the Soviet Union in 1976. Beginning on 12 October 1982, numerous rocket launches added satellites to the system until the completion of the constellation in 1995. In 2001, after a decline in capacity during the late 1990s, the restoration of the system was made a government priority, and funding increased substantially. GLONASS is the most expensive program of Roscosmos, consuming a third of its budget in 2010.\nBy 2010, GLONASS had achieved full coverage of Russia's territory. In October 2011, the full orbital constellation of 24 satellites was restored, enabling full global coverage. The GLONASS satellites' designs have undergone several upgrades, with the latest version, GLONASS-K2, launched in 2023.\nSystem description.\nGLONASS is a global navigation satellite system, providing real time position and velocity determination for military and civilian users. The satellites are located in middle circular orbit at altitude with a 64.8\u00b0 inclination and an orbital period of 11 hours and 16 minutes (every 17 revolutions, done in 8 sidereal days, a satellite passes over the same location). GLONASS's orbit makes it especially suited for usage in high latitudes (north or south), where getting a GPS signal can be problematic.\nThe constellation operates in three orbital planes, with eight evenly spaced satellites on each. A fully operational constellation with global coverage consists of 24 satellites, while 18 satellites are necessary for covering the territory of Russia. To get a position fix the receiver must be in the range of at least four satellites.\nSignal.\nFDMA.\nGLONASS satellites transmit two types of signals: open standard-precision signal L1OF/L2OF, and obfuscated high-precision signal L1SF/L2SF.\nThe signals use similar DSSS encoding and binary phase-shift keying (BPSK) modulation as in GPS signals. All GLONASS satellites transmit the same code as their standard-precision signal; however each transmits on a different frequency using a 15-channel frequency-division multiple access (FDMA) technique spanning either side from 1602.0 MHz, known as the L1 band. The center frequency is 1602\u00a0MHz + \"n\" \u00d7 0.5625\u00a0MHz, where \"n\" is a satellite's frequency channel number (\"n\"=\u22126...,0...,6, previously \"n\"=0...,13). Signals are transmitted in a 38\u00b0 cone, using right-hand circular polarization, at an EIRP between 25 and 27 dBW (316 to 500 watts). Note that the 24-satellite constellation is accommodated with only 15 channels by using identical frequency channels to support antipodal (opposite side of planet in orbit) satellite pairs, as these satellites are never both in view of an Earth-based user at the same time.\nThe L2 band signals use the same FDMA as the L1 band signals, but transmit straddling 1246\u00a0MHz with the center frequency 1246\u00a0MHz + \"n\" \u00d7 0.4375\u00a0MHz, where \"n\" spans the same range as for L1. In the original GLONASS design, only obfuscated high-precision signal was broadcast in the L2 band, but starting with GLONASS-M, an additional civil reference signal L2OF is broadcast with an identical standard-precision code to the L1OF signal.\nThe open standard-precision signal is generated with modulo-2 addition (XOR) of 511\u00a0kbit/s pseudo-random ranging code, 50 bit/s navigation message, and an auxiliary 100\u00a0Hz meander sequence (Manchester code), all generated using a single time/frequency oscillator. The pseudo-random code is generated with a 9-stage shift register operating with a period of 1 milliseconds.\nThe navigational message is modulated at 50 bits per second. The superframe of the open signal is 7500 bits long and consists of 5 frames of 30 seconds, taking 150 seconds (2.5 minutes) to transmit the continuous message. Each frame is 1500 bits long and consists of 15 strings of 100 bits (2 seconds for each string), with 85 bits (1.7 seconds) for data and check-sum bits, and 15 bits (0.3 seconds) for time mark. Strings 1-4 provide immediate data for the transmitting satellite, and are repeated every frame; the data include ephemeris, clock and frequency offsets, and satellite status. Strings 5-15 provide non-immediate data (i.e. almanac) for each satellite in the constellation, with frames I-IV each describing five satellites, and frame V describing remaining four satellites.\nThe ephemerides are updated every 30 minutes using data from the Ground Control segment; they use Earth Centred Earth Fixed (ECEF) Cartesian coordinates in position and velocity, and include lunisolar acceleration parameters. The almanac uses modified orbital elements (Keplerian elements) and is updated daily.\nThe more accurate high-precision signal is available for authorized users, such as the Russian military, yet unlike the United States P(Y) code, which is modulated by an encrypting W code, the GLONASS restricted-use codes are broadcast in the clear using only \"security through obscurity\". The details of the high-precision signal have not been disclosed. The modulation (and therefore the tracking strategy) of the data bits on the L2SF code has recently changed from unmodulated to 250 bit/s burst at random intervals. The L1SF code is modulated by the navigation data at 50 bit/s without a Manchester meander code.\nThe high-precision signal is broadcast in phase quadrature with the standard-precision signal, effectively sharing the same carrier wave, but with a ten-times-higher bandwidth than the open signal. The message format of the high-precision signal remains unpublished, although attempts at reverse-engineering indicate that the superframe is composed of 72 frames, each containing 5 strings of 100 bits and taking 10 seconds to transmit, with total length of 36 000 bits or 720 seconds (12 minutes) for the whole navigational message. The additional data are seemingly allocated to critical Lunisolar acceleration parameters and clock correction terms.\nAccuracy.\nAt peak efficiency, the standard-precision signal offers horizontal positioning accuracy within 5\u201310 metres, vertical positioning within , a velocity vector measuring within , and timing within 200 nanoseconds, all based on measurements from four first-generation satellites simultaneously; newer satellites such as GLONASS-M improve on this.\nGLONASS uses a coordinate datum named \"PZ-90\" (Earth Parameters 1990 \u2013 Parametry Zemli 1990), in which the precise location of the North Pole is given as an average of its position from 1990 to 1995. This is in contrast to the GPS's coordinate datum, WGS 84, which uses the location of the North Pole in 1984. As of 17 September 2007, the PZ-90 datum has been updated to version PZ-90.02 which differ from WGS 84 by less than in any given direction. Since 31 December 2013, version PZ-90.11 is being broadcast, which is aligned to the International Terrestrial Reference System and Frame 2008 at epoch 2011.0 at the centimetre level, but ideally a conversion to ITRF2008 should be done.\nCDMA.\nSince 2008, new CDMA signals are being researched for use with GLONASS.\nThe interface control documents for GLONASS CDMA signals was published in August 2016.\nAccording to GLONASS developers, there will be three open and two restricted CDMA signals. The open signal L3OC is centered at 1202.025\u00a0MHz and uses BPSK(10) modulation for both data and pilot channels; the ranging code transmits at 10.23 million chips per second, modulated onto the carrier frequency using QPSK with in-phase data and quadrature pilot. The data is error-coded with 5-bit Barker code and the pilot with 10-bit Neuman-Hoffman code.\nOpen L1OC and restricted L1SC signals are centered at 1600.995\u00a0MHz, and open L2OC and restricted L2SC signals are centered at 1248.06\u00a0MHz, overlapping with GLONASS FDMA signals. Open signals L1OC and L2OC use time-division multiplexing to transmit pilot and data signals, with BPSK(1) modulation for data and BOC(1,1) modulation for pilot; wide-band restricted signals L1SC and L2SC use BOC (5, 2.5) modulation for both data and pilot, transmitted in quadrature phase to the open signals; this places peak signal strength away from the center frequency of narrow-band open signals.\nBinary phase-shift keying (BPSK) is used by standard GPS and GLONASS signals. Binary offset carrier (BOC) is the modulation used by Galileo, modernized GPS, and BeiDou-2.\nThe navigational message of CDMA signals is transmitted as a sequence of text strings. The message has variable size - each pseudo-frame usually includes six strings and contains ephemerides for the current satellite (string types 10, 11, and 12 in a sequence) and part of the almanac for three satellites (three strings of type 20). To transmit the full almanac for all current 24 satellites, a superframe of 8 pseudo-frames is required. In the future, the superframe will be expanded to 10 pseudo-frames of data to cover full 30 satellites.\nThe message can also contain Earth's rotation parameters, ionosphere models, long-term orbit parameters for GLONASS satellites, and COSPAS-SARSAT messages. The system time marker is transmitted with each string; UTC leap second correction is achieved by shortening or lengthening (zero-padding) the final string of the day by one second, with abnormal strings being discarded by the receiver.\nThe strings have a version tag to facilitate forward compatibility: future upgrades to the message format will not break older equipment, which will continue to work by ignoring new data (as long as the constellation still transmits old string types), but up-to-date equipment will be able to use additional information from newer satellites.\nThe navigational message of the L3OC signal is transmitted at 100 bit/s, with each string of symbols taking 3 seconds (300 bits). A pseudo-frame of 6 strings takes 18 seconds (1800 bits) to transmit. A superframe of 8 pseudo-frames is 14,400 bits long and takes 144 seconds (2 minutes 24 seconds) to transmit the full almanac.\nThe navigational message of the L1OC signal is transmitted at 100 bit/s. The string is 250 bits long and takes 2.5 seconds to transmit. A pseudo-frame is 1500 bits (15 seconds) long, and a superframe is 12,000 bits or 120 seconds (2 minutes).\nL2OC signal does not transmit any navigational message, only the pseudo-range codes:\nGlonass-K1 test satellite launched in 2011 introduced L3OC signal. Glonass-M satellites produced since 2014 (s/n 755+) will also transmit L3OC signal for testing purposes.\nEnhanced Glonass-K1 and Glonass-K2 satellites, to be launched from 2023, will feature a full suite of modernized CDMA signals in the existing L1 and L2 bands, which includes L1SC, L1OC, L2SC, and L2OC, as well as the L3OC signal. Glonass-K2 series should gradually replace existing satellites starting from 2023, when Glonass-M launches will cease.\nGlonass-KM satellites will be launched by 2025. Additional open signals are being studied for these satellites, based on frequencies and formats used by existing GPS, Galileo, and Beidou/COMPASS signals:\nSuch an arrangement will allow easier and cheaper implementation of multi-standard GNSS receivers.\nWith the introduction of CDMA signals, the constellation will be expanded to 30 active satellites by 2025; this may require eventual deprecation of FDMA signals. The new satellites will be deployed into three additional planes, bringing the total to six planes from the current three\u2014aided by System for Differential Correction and Monitoring (SDCM), which is a GNSS augmentation system based on a network of ground-based control stations and communication satellites Luch 5A and Luch 5B. GLONASS-KM satellites will also use new L3SVI open signal to broadcast Precise Point Positioning (PPP) to deliver GLONASS High Accuracy Services.\nSix additional Glonass-V satellites, using Tundra orbit in three orbital planes, will be launched starting in 2025; this regional high-orbit segment will offer increased regional availability and 25% improvement in precision over Eastern Hemisphere, similar to Japanese QZSS system and Beidou-1. The new satellites will form two ground traces with inclination of 64.8\u00b0, eccentricity of 0.072, period of 23.9 hours, and ascending node longitude of 60\u00b0 and 120\u00b0. Glonass-V vehicles are based on Glonass-K platform and will broadcast new CDMA signals only. Previously Molniya orbit, geosynchronous orbit, or inclined orbit were also under consideration for the regional segment.\nRoscosmos also plans to launch up to 240 small size satellites on the low Earth orbit (LEO) to improve signal availability and interfecence; LEO satellites will have a limited lifespan of 5 years to allow a faster pace of replenishment.\nNavigational message.\nCommon properties of open CDMA signals.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSatellites.\nThe main contractor of the GLONASS program is Joint Stock Company Information Satellite Systems Reshetnev (ISS Reshetnev, formerly called NPO-PM). The company, located in Zheleznogorsk, is the designer of all GLONASS satellites, in cooperation with the Institute for Space Device Engineering () and the Russian Institute of Radio Navigation and Time. Serial production of the satellites is accomplished by the company Production Corporation Polyot in Omsk.\nOver the three decades of development, the satellite designs have gone through numerous improvements, and can be divided into three generations: the original GLONASS (since 1982), GLONASS-M (since 2003) and GLONASS-K (since 2011). Each GLONASS satellite has a GRAU designation 11F654, and each of them also has the military \"Cosmos-NNNN\" designation.\nFirst generation.\nThe true first generation of GLONASS (also called Uragan) satellites were all three-axis stabilized vehicles, generally weighing and were equipped with a modest propulsion system to permit relocation within the constellation. Over time they were upgraded to Block IIa, IIb, and IIv vehicles, with each block containing evolutionary improvements.\nSix Block IIa satellites were launched in 1985\u20131986 with improved time and frequency standards over the prototypes, and increased frequency stability. These spacecraft also demonstrated a 16-month average operational lifetime. Block IIb spacecraft, with a two-year design lifetimes, appeared in 1987, of which a total of 12 were launched, but half were lost in launch vehicle accidents. The six spacecraft that made it to orbit worked well, operating for an average of nearly 22 months.\nBlock IIv was the most prolific of the first generation. Used exclusively from 1988 to 2000, and continued to be included in launches through 2005, a total of 56 satellites were launched. The design life was three years, however numerous spacecraft exceeded this, with one late model lasting 68 months, nearly double.\nBlock II satellites were typically launched three at a time from the Baikonur Cosmodrome using Proton-K Blok-DM2 or Proton-K Briz-M boosters. The only exception was when, on two launches, an Etalon geodetic reflector satellite was substituted for a GLONASS satellite.\nSecond generation.\nThe second generation of satellites, known as Glonass-M, were developed beginning in 1990 and first launched in 2003. These satellites possess a substantially increased lifetime of seven years and weigh slightly more at . They are approximately in diameter and high, with a solar array span of for an electrical power generation capability of 1600 watts at launch. The aft payload structure houses 12 primary antennas for L-band transmissions. Laser corner-cube reflectors are also carried to aid in precise orbit determination and geodetic research. On-board cesium clocks provide the local clock source. 52 Glonass-M have been produced and launched.\nA total of 41 second generation satellites were launched through the end of 2013. As with the previous generation, the second generation spacecraft were launched three at a time using Proton-K Blok-DM2 or Proton-K Briz-M boosters. Some were launched alone with Soyuz-2-1b/Fregat.\nIn July 2015, ISS Reshetnev announced that it had completed the last GLONASS-M (No. 61) spacecraft and it was putting it in storage waiting for launch, along with eight previously built satellites.\nAs on 22 September 2017, GLONASS-M No.52 satellite went into operation and the orbital grouping has again increased to 24 space vehicles.\nThird generation.\nGLONASS-K is a substantial improvement of the previous generation: it is the first unpressurised GLONASS satellite with a much reduced mass of versus the of GLONASS-M. It has an operational lifetime of 10 years, compared to the 7-year lifetime of the second generation GLONASS-M. It will transmit more navigation signals to improve the system's accuracy \u2014 including new CDMA signals in the L3 and L5 bands, which will use modulation similar to modernized GPS, Galileo, and BeiDou. Glonass-K consist of 26 satellites having satellite index 65-98 and widely used in Russian Military space.\nThe new satellite's advanced equipment\u2014made solely from Russian components \u2014 will allow the doubling of GLONASS' accuracy. As with the previous satellites, these are 3-axis stabilized, nadir pointing with dual solar arrays. The first GLONASS-K satellite was successfully launched on 26 February 2011.\nDue to their weight reduction, GLONASS-K spacecraft can be launched in pairs from the Plesetsk Cosmodrome launch site using the substantially lower cost Soyuz-2.1b boosters or in six-at-once from the Baikonur Cosmodrome using Proton-K Briz-M launch vehicles.\nGround control.\nThe ground control segment of GLONASS is almost entirely located within former Soviet Union territory, except for several in Brazil and one in Nicaragua.\nThe GLONASS ground segment consists of:\nReceivers.\nCompanies producing GNSS receivers making use of GLONASS:\nNPO Progress describes a receiver called \"GALS-A1\", which combines GPS and GLONASS reception.\nSkyWave Mobile Communications manufactures an Inmarsat-based satellite communications terminal that uses both GLONASS and GPS.\nAs of 2011[ [update]], some of the latest receivers in the Garmin eTrex line also support GLONASS (along with GPS). Garmin also produce a standalone Bluetooth receiver, the GLO for Aviation, which combines GPS, WAAS and GLONASS.\nVarious smartphones from 2011 onwards have integrated GLONASS capability in addition to their pre-existing GPS receivers, with the intention of reducing signal acquisition periods by allowing the device to pick up more satellites than with a single-network receiver, including devices from:\nStatus.\nAvailability.\nAs of 2024[ [update]], the GLONASS constellation status is:\nThe system requires 18 satellites for continuous navigation services covering all of Russia, and 24 satellites to provide services worldwide. The GLONASS system covers 100% of worldwide territory.\nOn 2 April 2014, the system experienced a technical failure that resulted in practical unavailability of the navigation signal for around 12 hours.\nOn 14\u201315 April 2014, nine GLONASS satellites experienced a technical failure due to software problems.\nOn 19 February 2016, three GLONASS satellites experienced a technical failure: the batteries of GLONASS-738 exploded, the batteries of GLONASS-737 were depleted, and GLONASS-736 experienced a stationkeeping failure due to human error during maneuvering. GLONASS-737 and GLONASS-736 were expected to be operational again after maintenance, and one new satellite (GLONASS-751) to replace GLONASS-738 was expected to complete commissioning in early March 2016. The full capacity of the satellite group was expected to be restored in the middle of March 2016.\nAfter the launching of two new satellites and maintenance of two others, the full capacity of the satellite group was restored.\nAccuracy.\nAccording to Russian System of Differentional Correction and Monitoring's data, as of 2010[ [update]], precision of GLONASS navigation definitions (for p=0.95) for latitude and longitude were with mean number of navigation space vehicles (NSV) equals 7\u20148 (depending on station). In comparison, the same time precision of GPS navigation definitions were with mean number of NSV equals 6\u201411 (depending on station).\nSome modern receivers are able to use both GLONASS and GPS satellites together, providing greatly improved coverage in urban canyons and giving a very fast time to fix due to over 50 satellites being available. In indoor, urban canyon or mountainous areas, accuracy can be greatly improved over using GPS alone. For using both navigation systems simultaneously, precision of GLONASS/GPS navigation definitions were with mean number of NSV equals 14\u201419 (depends on station).\nIn May 2009, Anatoly Perminov, then director of the Roscosmos, stated that actions were undertaken to expand GLONASS's constellation and to improve the ground segment to increase the navigation definition of GLONASS to an accuracy of by 2011. In particular, the latest satellite design, GLONASS-K has the ability to double the system's accuracy once introduced. The system's ground segment is also to undergo improvements. As of early 2012, sixteen positioning ground stations are under construction in Russia and in the Antarctic at the Bellingshausen and Novolazarevskaya bases. New stations will be built around the southern hemisphere from Brazil to Indonesia. Together, these improvements are expected to bring GLONASS' accuracy to 0.6 m or better by 2020. The setup of a GLONASS receiving station in the Philippines is also now under negotiation.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46150", "revid": "50845910", "url": "https://en.wikipedia.org/wiki?curid=46150", "title": "Lua", "text": "Lightweight programming language\nLua ( ; from meaning \"moon\") is a lightweight, high-level, multi-paradigm programming language designed mainly for embedded use in applications. Lua is cross-platform software, since the interpreter of compiled bytecode is written in ANSI C, and Lua has a relatively simple C application programming interface (API) to embed it into applications.\nLua originated in 1993 as a language for extending software applications to meet the increasing demand for customization at the time. It provided the basic facilities of most procedural programming languages, but more complicated or domain-specific features were not included; rather, it included mechanisms for extending the language, allowing programmers to implement such features. As Lua was intended to be a general embeddable extension language, the designers of Lua focused on improving its speed, portability, extensibility and ease-of-use in development.\nHistory.\nLua was created in 1993 by Roberto Ierusalimschy, Luiz Henrique de Figueiredo, and Waldemar Celes, members of the Computer Graphics Technology Group (Tecgraf) at the Pontifical Catholic University of Rio de Janeiro, in Brazil.\nFrom 1977 until 1992, Brazil had a policy of strong trade barriers (called a market reserve) for computer hardware and software, believing that Brazil could and should produce its own hardware and software. In that climate, Tecgraf's clients could not afford, either politically or financially, to buy customized software from abroad; under the market reserve, clients would have to go through a complex bureaucratic process to prove their needs couldn't be met by Brazilian companies. Those reasons led Tecgraf to implement the basic tools it needed from scratch.\nLua's predecessors were the data-description and configuration languages Simple Object Language (SOL) and Data-Entry Language (DEL). They had been independently developed at Tecgraf in 1992\u20131993 to add some flexibility into two different projects (both were interactive graphical programs for engineering applications at Petrobras company). There was a lack of any flow-control structures in SOL and DEL, and Petrobras felt a growing need to add full programming power to them.\nIn \"The Evolution of Lua\", the language's authors wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In 1993, the only real contender was Tcl, which had been explicitly designed to be embedded into applications. However, Tcl had unfamiliar syntax, did not offer good support for data description, and ran only on Unix platforms. We did not consider LISP or Scheme because of their unfriendly syntax. Python was still in its infancy. In the free, do-it-yourself atmosphere that then reigned in Tecgraf, it was quite natural that we should try to develop our own scripting language\u00a0... Because many potential users of the language were not professional programmers, the language should avoid cryptic syntax and semantics. The implementation of the new language should be highly portable, because Tecgraf's clients had a very diverse collection of computer platforms. Finally, since we expected that other Tecgraf products would also need to embed a scripting language, the new language should follow the example of SOL and be provided as a library with a C API.\nLua 1.0 was designed in such a way that its object constructors, being then slightly different from the current light and flexible style, incorporated the data-description syntax of SOL (hence the name Lua: \"Sol\" meaning \"Sun\" in Portuguese, and \"Lua\" meaning \"Moon\"). Lua syntax for control structures was mostly borrowed from Modula (codice_1, codice_2, codice_3/codice_4), but also had taken influence from CLU (multiple assignments and multiple returns from function calls, as a simpler alternative to reference parameters or explicit pointers), C++ (\"neat idea of allowing a local variable to be declared only where we need it\"), SNOBOL and AWK (associative arrays). In an article published in \"Dr. Dobb's Journal\", Lua's creators also state that LISP and Scheme with their single, ubiquitous data-structure mechanism (the list) were a major influence on their decision to develop the table as the primary data structure of Lua.\nLua semantics have been increasingly influenced by Scheme over time, especially with the introduction of anonymous functions and full lexical scoping. Several features were added in new Lua versions.\nVersions of Lua prior to version 5.0 were released under a license similar to the BSD license. From version 5.0 onwards, Lua has been licensed under the MIT License. Both are permissive free software licences and are almost identical.\nFeatures.\nLua is commonly described as a \"multi-paradigm\" language, providing a small set of general features that can be extended to fit different problem types. Lua does not contain explicit support for inheritance, but allows it to be implemented with metatables. Similarly, Lua allows programmers to implement namespaces, classes and other related features using its single table implementation; first-class functions allow the employment of many techniques from functional programming and full lexical scoping allows fine-grained information hiding to enforce the principle of least privilege.\nIn general, Lua strives to provide simple, flexible meta-features that can be extended as needed, rather than supply a feature-set specific to one programming paradigm. As a result, the base language is light; the full reference interpreter is only about 247\u00a0kB compiled and easily adaptable to a broad range of applications.\nAs a dynamically typed language intended for use as an extension language or scripting language, Lua is compact enough to fit on a variety of host platforms. It supports only a small number of atomic data structures such as Boolean values, numbers (double-precision floating point and 64-bit integers by default) and strings. Typical data structures such as arrays, sets, lists and records can be represented using Lua's single native data structure, the table, which is essentially a heterogeneous associative array.\nLua implements a small set of advanced features such as first-class functions, garbage collection, closures, proper tail calls, coercion (automatic conversion between string and number values at run time), coroutines (cooperative multitasking) and dynamic module loading.\nSyntax.\nThe classic \"Hello, World!\" program can be written as follows, with or without parentheses:\nprint(\"Hello, World!\")\nprint \"Hello, World!\"\nThe declaration of a variable, without a value.\nlocal variable\nThe declaration of a variable with a value of 10.\nlocal students = 10\nA comment in Lua starts with a double-hyphen and runs to the end of the line, similar to Ada, Eiffel, Haskell, SQL and VHDL. Multi-line strings and comments are marked with double square brackets.\n-- Single line comment\nMulti-line comment\nThe factorial function is implemented in this example:\nfunction factorial(n)\n local x = 1\n for i = 2, n do\n x = x * i\n end\n return x\nend\nControl flow.\nLua has one type of conditional test: codice_5 with optional codice_6 and codice_7 execution control constructs.\nThe generic codice_5 statement requires all three keywords:\nif condition then\n --statement body\nend\nAn example of an codice_1 statement\nif x ~= 10 then\n print(x)\nend\nThe codice_6 keyword may be added with an accompanying statement block to control execution when the codice_1 condition evaluates to codice_12:\nif condition then\n --statement body\nelse\n --statement body\nend\nAn example of an codice_13 statement\nif x == 10 then\n print(10)\nelse\n print(x)\nend\nExecution may also be controlled according to multiple conditions using the codice_7 keywords:\nif condition then\n --statement body\nelseif condition then\n --statement body\nelse -- optional\n --optional default statement body\nend\nAn example of an codice_15 statement\nif x == y then\n print(\"x = y\")\nelseif x == z then\n print(\"x = z\")\nelse -- optional\n print(\"x does not equal any other variable\")\nend\nLua has four types of conditional loops: the codice_2 loop, the codice_3 loop (similar to a codice_18 loop), the numeric codice_19 loop and the generic codice_19 loop.\n--condition = true\nwhile condition do\n --statements\nend\nrepeat\n --statements\nuntil condition\nfor i = first, last, delta do --delta may be negative, allowing the for loop to count down or up\n --statements\n --example: print(i)\nend\nThis generic codice_19 loop would iterate over the table codice_22 using the standard iterator function codice_23, until it returns codice_24:\nfor key, value in pairs(_G) do\n print(key, value)\nend\nLoops can also be nested (put inside of another loop).\nlocal grid = {\n { 11, 12, 13 },\n { 21, 22, 23 },\nfor y, row in pairs(grid) do\n for x, value in pairs(row) do\n print(x, y, value)\n end\nend\nFunctions.\nLua's treatment of functions as first-class values is shown in the following example, where the print function's behavior is modified:\ndo\n local oldprint = print\n -- Store current print function as oldprint\n function print(s)\n -- Redefine print function. The usual print function can still be used\n through oldprint. The new one has only one argument.\n oldprint(s == \"foo\" and \"bar\" or s)\n end\nend\nAny future calls to codice_25 will now be routed through the new function, and because of Lua's lexical scoping, the old print function will only be accessible by the new, modified print.\nLua also supports closures, as demonstrated below:\nfunction addto(x)\n -- Return a new function that adds x to the argument\n return function(y)\n -- When we refer to the variable x, which is outside the current\n scope and whose lifetime would be shorter than that of this anonymous\n function, Lua creates a closure.\n return x + y\n end\nend\nfourplus = addto(4)\nprint(fourplus(3)) -- Prints 7\n--This can also be achieved by calling the function in the following way:\nprint(addto(4)(3))\n-- This is because we are calling the returned function from 'addto(4)' with the argument '3' directly.\n This also helps to reduce data cost and up performance if being called iteratively.\nA new closure for the variable codice_26 is created every time codice_27 is called, so that each new anonymous function returned will always access its own codice_26 parameter. The closure is managed by Lua's garbage collector, just like any other object.\nTables.\nTables are the most important data structures (and, by design, the only built-in composite data type) in Lua and are the foundation of all user-created types. They are associative arrays with addition of automatic numeric key and special syntax.\nA table is a set of key and data pairs, where the data is referenced by key; in other words, it is a hashed heterogeneous associative array.\nTables are created using the codice_29 constructor syntax.\na_table = {} -- Creates a new, empty table\nTables are always passed by reference (see Call by sharing).\nA key (index) can be any value except codice_24 and NaN, including functions.\na_table = {x = 10} -- Creates a new table, with one entry mapping \"x\" to the number 10.\nprint(a_table[\"x\"]) -- Prints the value associated with the string key, in this case 10.\nb_table = a_table\nb_table[\"x\"] = 20 -- The value in the table has been changed to 20.\nprint(b_table[\"x\"]) -- Prints 20.\nprint(a_table[\"x\"]) -- Also prints 20, because a_table and b_table both refer to the same table.\nA table is often used as structure (or record) by using strings as keys. Because such use is very common, Lua features a special syntax for accessing such fields.\npoint = { x = 10, y = 20 } -- Create new table\nprint(point[\"x\"]) -- Prints 10\nprint(point.x) -- Has exactly the same meaning as line above. The easier-to-read dot notation is just syntactic sugar.\nBy using a table to store related functions, it can act as a namespace.\nPoint.new = function(x, y)\nend\nPoint.set_x = function(point, x)\n point.x = x -- point[\"x\"] = x;\nend\nTables are automatically assigned a numerical key, enabling them to be used as an array data type. The first automatic index is 1 rather than 0 as it is for many other programming languages (though an explicit index of 0 is allowed).\nA numeric key codice_31 is distinct from a string key codice_32.\narray = { \"a\", \"b\", \"c\", \"d\" } -- Indices are assigned automatically.\nprint(array[2]) -- Prints \"b\". Automatic indexing in Lua starts at 1.\nprint(#array) -- Prints 4. # is the length operator for tables and strings.\narray[0] = \"z\" -- Zero is a legal index.\nprint(#array) -- Still prints 4, as Lua arrays are 1-based.\nThe length of a table codice_33 is defined to be any integer index codice_34 such that codice_35 is not codice_24 and codice_37 is codice_24; moreover, if codice_39 is codice_24, codice_34 can be zero. For a regular array, with non-nil values from 1 to a given codice_34, its length is exactly that codice_34, the index of its last value. If the array has \"holes\" (that is, nil values between other non-nil values), then codice_44 can be any of the indices that directly precedes a codice_24 value (that is, it may consider any such nil value as the end of the array).\nExampleTable =\n {1, 2, 3, 4},\nprint(ExampleTable[1][3]) -- Prints \"3\"\nprint(ExampleTable[2][4]) -- Prints \"8\"\nA table can be an array of objects.\nfunction Point(x, y) -- \"Point\" object constructor\n return { x = x, y = y } -- Creates and returns a new object (table)\nend\narray = { Point(10, 20), Point(30, 40), Point(50, 60) } -- Creates array of points\n -- array = { { x = 10, y = 20 }, { x = 30, y = 40 }, { x = 50, y = 60 } };\nprint(array[2].y) -- Prints 40\nUsing a hash map to emulate an array is normally slower than using an actual array; however, Lua tables are optimized for use as arrays to help avoid this issue.\nMetatables.\nExtensible semantics is a key feature of Lua, and the metatable allows powerful customization of tables. The following example demonstrates an \"infinite\" table. For any codice_34, codice_47 will give the codice_34-th Fibonacci number using dynamic programming and memoization.\nfibs = { 1, 1 } -- Initial values for fibs[1] and fibs[2].\nsetmetatable(fibs, {\n __index = function(values, n) --__index is a function predefined by Lua, \n it is called if key \"n\" does not exist.\n values[n] = values[n - 1] + values[n - 2] -- Calculate and memoize fibs[n].\n return values[n]\n end\nObject-oriented programming.\nAlthough Lua does not have a built-in concept of classes, object-oriented programming can be emulated using functions and tables. An object is formed by putting methods and fields in a table. Inheritance (both single and multiple) can be implemented with metatables, delegating nonexistent methods and fields to a parent object.\nThere is no such concept as \"class\" with these techniques; rather, prototypes are used, similar to Self or JavaScript. New objects are created either with a factory method (that constructs new objects from scratch) or by cloning an existing object.\nCreating a basic vector object:\nfunction Vector.new(x, y, z) -- The constructor\n return setmetatable({x = x, y = y, z = z}, VectorMeta)\nend\nfunction Vector.magnitude(self) -- Another method\n return math.sqrt(self.x^2 + self.y^2 + self.z^2)\nend\nlocal vec = Vector.new(0, 1, 0) -- Create a vector\nprint(vec.magnitude(vec)) -- Call a method (output: 1)\nprint(vec.x) -- Access a member variable (output: 0)\nHere, tells Lua to look for an element in the table if it is not present in the table. , which is equivalent to , first looks in the table for the element. The table does not have a element, but its metatable delegates to the table for the element when it's not found in the table.\nLua provides some syntactic sugar to facilitate object orientation. To declare member functions inside a prototype table, one can use , which is equivalent to . Calling class methods also makes use of the colon: is equivalent to .\nThat in mind, here is a corresponding class with syntactic sugar:\nVector.__index = Vector\nfunction Vector:new(x, y, z) -- The constructor\n -- Since the function definition uses a colon, \n -- its first argument is \"self\" which refers\n -- to \"Vector\"\n return setmetatable({x = x, y = y, z = z}, self)\nend\nfunction Vector:magnitude() -- Another method\n -- Reference the implicit object using self\n return math.sqrt(self.x^2 + self.y^2 + self.z^2)\nend\nlocal vec = Vector:new(0, 1, 0) -- Create a vector\nprint(vec:magnitude()) -- Call a method (output: 1)\nprint(vec.x) -- Access a member variable (output: 0)\nInheritance.\nIt is possible to use metatables to mimic the behavior of class inheritance in Lua. In this example, we allow vectors to have their values multiplied by a constant in a derived class.\nVector.__index = Vector\nfunction Vector:new(x, y, z) -- The constructor\n -- Here, self refers to whatever class's \"new\"\n -- method we call. In a derived class, self will\n -- be the derived class; in the Vector class, self\n -- will be Vector\n return setmetatable({x = x, y = y, z = z}, self)\nend\nfunction Vector:magnitude() -- Another method\n -- Reference the implicit object using self\n return math.sqrt(self.x^2 + self.y^2 + self.z^2)\nend\n-- Example of pseudo class inheritance\nVectorMult.__index = VectorMult\nsetmetatable(VectorMult, Vector) -- Make VectorMult a child of Vector\nfunction VectorMult:multiply(value) \n self.x = self.x * value\n self.y = self.y * value\n self.z = self.z * value\n return self\nend\nlocal vec = VectorMult:new(0, 1, 0) -- Create a vector\nprint(vec:magnitude()) -- Call a method (output: 1)\nprint(vec.y) -- Access a member variable (output: 1)\nvec:multiply(2) -- Multiply all components of vector by 2\nprint(vec.y) -- Access member again (output: 2)\nIt is also possible to implement multiple inheritance; can either be a function or a table. Operator overloading can also be done; Lua metatables can have elements such as , and so on.\nImplementation.\nLua programs are not interpreted directly from the textual Lua file, but are compiled into bytecode, which is then run on the Lua virtual machine (VM). The compiling process is typically invisible to the user and is performed during run-time, especially when a just-in-time compilation (JIT) compiler is used, but it can be done offline to increase loading performance or reduce the memory footprint of the host environment by leaving out the compiler. Lua bytecode can also be produced and executed from within Lua, using the codice_49 function from the string library and the codice_50 functions. Lua version 5.3.4 is implemented in approximately 24,000 lines of C code.\nLike most CPUs, and unlike most virtual machines (which are stack-based), the Lua VM is register-based, and therefore more closely resembles most hardware design. The register architecture both avoids excessive copying of values, and reduces the total number of instructions per function. The virtual machine of Lua 5 is one of the first register-based pure VMs to have a wide use. Parrot and Android's Dalvik are two other well-known register-based VMs. PCScheme's VM was also register-based.\nThis example is the bytecode listing of the factorial function defined above (as shown by the codice_51 5.1 compiler):\n function &lt;factorial.lua:1,7&gt; (9 instructions, 36 bytes at 0x8063c60)\n 1 param, 6 slots, 0 upvalues, 6 locals, 2 constants, 0 functions\n 1 [2] LOADK 1 -1 ; 1\n 2 [3] LOADK 2 -2 ; 2\n 3 [3] MOVE 3 0\n 4 [3] LOADK 4 -1 ; 1\n 5 [3] FORPREP 2 1 ; to 7\n 6 [4] MUL 1 1 5\n 7 [3] FORLOOP 2 -2 ; to 6\n 8 [6] RETURN 1 2\n 9 [7] RETURN 0 1\nC API.\nLua is intended to be embedded into other applications, and provides a C API for this purpose. The API is divided into two parts: the Lua core and the Lua auxiliary library. The Lua API's design eliminates the need for manual reference counting (management) in C code, unlike Python's API. The API, like the language, is minimalist. Advanced functions are provided by the auxiliary library, which consists largely of preprocessor macros which assist with complex table operations.\nThe Lua C API is stack based. Lua provides functions to push and pop most simple C data types (integers, floats, etc.) to and from the stack, and functions to manipulate tables through the stack. The Lua stack is somewhat different from a traditional stack; the stack can be indexed directly, for example. Negative indices indicate offsets from the top of the stack. For example, \u22121 is the top (most recently pushed value), while positive indices indicate offsets from the bottom (oldest value). Marshalling data between C and Lua functions is also done using the stack. To call a Lua function, arguments are pushed onto the stack, and then the codice_52 is used to call the actual function. When writing a C function to be directly called from Lua, the arguments are read from the stack.\nHere is an example of calling a Lua function from C:\nint main(void)\n // create a Lua state\n lua_State *L = luaL_newstate();\n // load and execute a string\n if (luaL_dostring(L, \"function foo (x,y) return x+y end\")) {\n lua_close(L);\n return -1;\n // push value of global \"foo\" (the function defined above)\n // to the stack, followed by integers 5 and 3\n lua_getglobal(L, \"foo\");\n lua_pushinteger(L, 5);\n lua_pushinteger(L, 3);\n lua_call(L, 2, 1); // call a function with two arguments and one return value\n printf(\"Result: %d\\n\", lua_tointeger(L, -1)); // print integer value of item at stack top\n lua_pop(L, 1); // return stack to original state\n lua_close(L); // close Lua state\n return 0;\nRunning this example gives:\n$ cc -o example example.c -llua\n$ ./example\nResult: 8\nThe C API also provides some special tables, located at various \"pseudo-indices\" in the Lua stack. At codice_53 prior to Lua 5.2 is the globals table, codice_22 from within Lua, which is the main namespace. There is also a registry located at codice_55 where C programs can store Lua values for later retrieval.\nModules.\nBesides standard library (core) modules it is possible to write extensions using the Lua API. Extension modules are shared objects which can be used to extend the functions of the interpreter by providing native facilities to Lua scripts. Lua scripts may load extension modules using codice_56, just like modules written in Lua itself, or with codice_57. When a C library is loaded via Lua will look for the function codice_58 and call it, which acts as any C function callable from Lua and generally returns a table filled with methods. A growing set of modules termed \"rocks\" are available through a package management system named LuaRocks, in the spirit of CPAN, RubyGems and Python eggs. Prewritten Lua bindings exist for most popular programming languages, including other scripting languages. For C++, there are a number of template-based approaches and some automatic binding generators.\nApplications.\nIn video game development, Lua is widely used as a scripting language, mainly due to its perceived ease of embedding, fast execution, and short learning curve. Notable games which use Lua include \"Roblox\", \"Garry's Mod\", \" World of Warcraft\", \"Payday 2\", \"Phantasy Star Online 2\", \"Dota 2\", \"Crysis\", and many others. Some games that do not natively support Lua programming or scripting have this function added by mods, as ComputerCraft does for \"Minecraft\". Similarly, Lua API libraries, like Discordia, are used for platforms that do not natively support Lua. Lua is used in an open-source 2-dimensional game engine called LOVE2D. Also, Lua is used in non-video game software, such as Adobe Lightroom, Moho, iClone, Aerospike, and some system software in FreeBSD and NetBSD, and used as a template scripting language on MediaWiki using the Scribunto extension.\nIn 2003, a poll conducted by GameDev.net showed that Lua was the most popular scripting language for game programming. On 12 January 2012, Lua was announced as a winner of the Front Line Award 2011 from the magazine \"Game Developer\" in the category Programming Tools.\nMany non-game applications also use Lua for extensibility, such as LuaTeX, an implementation of the TeX type-setting language; Redis, a key-value database; ScyllaDB, a wide-column store, Neovim, a text editor; Nginx, a web server; Wireshark, a network packet analyzer; Discordia, a Discord API library; and Pure Data, a visual audio programming language (through the pdlua extension).\nDerived languages.\nDialects.\nIn addition, the Lua users community provides some \"power patches\" on top of the reference C implementation.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46151", "revid": "11487766", "url": "https://en.wikipedia.org/wiki?curid=46151", "title": "1480s BC", "text": "Decade\nThe 1480s BC was a decade lasting from January 1, 1489 BC to December 31, 1480 BC.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46154", "revid": "1306352", "url": "https://en.wikipedia.org/wiki?curid=46154", "title": "Glue language", "text": ""}
{"id": "46155", "revid": "48911350", "url": "https://en.wikipedia.org/wiki?curid=46155", "title": "DGPS", "text": ""}
{"id": "46157", "revid": "37005538", "url": "https://en.wikipedia.org/wiki?curid=46157", "title": "Garrett County, Maryland", "text": "County in Maryland, United States\nGarrett County () is the westernmost county of the U.S. state of Maryland, completely within the Appalachian Mountains. As of the 2020 United States census, the population was 28,806, making it the third-least populous county in Maryland. Its county seat is Oakland. The county was named for John Work Garrett (1820\u20131884), president of the Baltimore and Ohio Railroad. Created from Allegany County in 1872, it was the last county to be formed in the state. The county is part of the Western Maryland region of the state. Garrett County is bordered by four West Virginia counties and to the north the Maryland\u2013Pennsylvania boundary known as the Mason\u2013Dixon line. The eastern border with Allegany County was defined by the Bauer Report, submitted to Governor Lloyd Lowndes, Jr. on November 9, 1898. The Potomac River and State of West Virginia lie to the south and west.\nGarrett County lies in the Allegheny Mountains, which here form the western flank of the Appalachian Mountain Range. Hoye-Crest, a summit along Backbone Mountain, is the highest point in Maryland at an elevation of .\nThe Eastern Continental Divide runs along portions of Backbone Mountain. The western part of the county, drained by the Youghiogheny River, is the only part of Maryland within the Mississippi River drainage basin. All other parts of the county are in the Chesapeake Bay basin.\nThe National Register of Historic Places listings in Garrett County, Maryland has 20 National Register of Historic Places properties and districts, including Casselman Bridge, National Road a National Historic Landmark. Garrett County is part of Maryland's 6th congressional district. The extreme south of the county lies within the United States National Radio Quiet Zone.\nHistory.\nIn the early 20th century, the railroad and tourism started to decline. Coal mining and timber production continued at a much slower pace. Today, tourism has made a dramatic rebound in the county with logging and farming making up the greatest part of the economic base. Due to a cool climate and lack of any large city, Garrett County has remained a sparsely populated rural area.\nGeography.\nAccording to the U.S. Census Bureau, the county has a total area of , of which is land and (1.3%) is water. It is the second-largest county in Maryland by land area.\nGarrett County is located entirely within the highland zone of the Appalachian Mountains known variously as the Allegheny Mountains, the Allegheny Plateau, and the Appalachian Plateau. The county's highest elevations are located along four flat-topped ridges and range to a height of at Hoye-Crest along Backbone Mountain, the highest point in the state of Maryland. As is typical in the Allegheny region, broad flats generally lie below the ridge crests at elevations of approximately . River valleys are generally narrow and deep, with ravines typically 1,000 to below surrounding peaks.\nThe county contains over of parks, lakes, and publicly accessible forestland. It is drained by two river systems, the Potomac and the Youghiogheny. The Savage River, a tributary of the Potomac, drains about a third of the county. The Casselman River, a tributary of the Youghiogheny, flows north from the county's central section into Pennsylvania. The Youghiogheny itself drains the westernmost area of the county and flows north into Pennsylvania, where it empties into the Monongahela River at McKeesport, just south of Pittsburgh.\nGeologic points of interest.\nThe Glades.\nThe Glades' is of great scientific interest because it is an ombrotrophic system (fed solely by rainwater) with peat layers up to thick, and is one of the oldest examples of mountain peatland in the Appalachians.\nOn the western edge of the Savage River State Forest along Maryland Route 495 lies Bittinger, Maryland, which is named after Henry Bittinger, who first settled in the area and who was joined by other German settlers moving in and taking up the fertile farmland. On the eastern edge of Bittinger is one of the largest glades area of Garrett County. Geographically, this is an area that seems to have been affected by the last great ice sheet of North America. Two miles southeast of Bittinger, there is a large deposit of peat moss.\nLoess Dunes.\nIn the Casselman River valley, south of Grantsville, Maryland and beside Maryland Route 495, one can see remains of geological evidence about the last great ice sheet over North America. A series of low mounds can be seen in the fields on the west side of Maryland Route 495 that are \"loess\" (wind-blown) material. Apparently, these are the only ones still visible in the northern part of Garrett County.\nThe mounds were formed when a glacier lake existed in the Casselman valley, and the ice around the edges of the frozen lake melted. Wind blew fine grains of earth into the water around the edges where it sank to the bottom, and the mounds were the result of the deposit of this wind-blown material.\nForests, rivers, caves.\nSee these articles for information on the forests, rivers, and caves of Garrett County:\nParks and recreation.\nGarrett County contains over of parks, lakes, and publicly accessible forestland. Popular activities in the county include camping, hiking, backpacking, rock climbing, alpine and cross-country skiing, snowmobiling, hunting, ice fishing, fly fishing, whitewater canoeing, kayaking, rafting, boating, swimming, sailing, horseback riding, and water skiing.\nState parks.\nThere are seven state parks in Garrett County. All offer picnic and fishing areas; all but Casselman River State Park have hiking paths. Mountain bike paths, swimming areas, and boat launches and rentals are available at Deep Creek, Herrington Manor, and New Germany state parks. Rental cabins are available at Herrington Manor and New Germany state parks. Big Run, Deep Creek, Herrington Manor, and New Germany state parks all offer canoeing, while campsites may be found at Big Run, Deep Creek, New Germany, and Swallow Falls state parks.\nCounty parks.\nGarrett County owns four park sites and fifteen recreation facilities. The parks are maintained in cooperation with local associations and civic groups. The recreation areas are attached to public schools and colleges and maintained by the Garrett County Board of Education.\nMunicipal parks.\nThe municipal parks of Garrett County provide sport facilities, hiking, bike and walk paths, playgrounds, picnic areas, boat ramps, and fishing.\nLibraries and museums.\nThe Ruth Enlow Library was founded in 1915 as the Oakland Free Public Library. Since then, an additional four branches have been added to the library system in Accident, Friendsville, Grantsville, and Kitzmiller. The present director of the library is Thomas Vose.\nThe Garrett County Historical Society and Museums include a Historical Museum, a Transportation Museum, the Grantsville Museum and the Leo Beachley Photographic Archives.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2010 census.\nAs of the 2010 United States census, there were 30,097\u00a0people, 12,057\u00a0households, and 8,437\u00a0families residing in the county. The population density was . There were 18,854 housing units at an average density of . The racial makeup of the county was 97.8% white, 1.0% black or African American, 0.3% Asian, 0.1% American Indian, 0.1% from other races, and 0.7% from two or more races. Those of Hispanic or Latino origin made up 0.7% of the population. In terms of ancestry, 35.4% were German, 13.6% identified as American, 11.3% were Irish, and 11.3% were English.\nOf the 12,057\u00a0households, 30.0% had children under the age of 18 living with them, 56.4% were married couples living together, 9.3% had a female householder with no husband present, 30.0% were non-families, and 25.5% of all households were made up of individuals. The average household size was 2.45 and the average family size was 2.92. The median age was 42.7 years.\nThe median income for a household in the county was $45,760 and the median income for a family was $56,545. Males had a median income of $40,035 versus $27,325 for females. The per capita income for the county was $23,888. About 8.9% of families and 12.5% of the population were below the poverty line, including 19.2% of those under age 18 and 12.1% of those aged 65 or over.\n2000 census.\nAs of the census of 2000, there were 29,846 people, 11,476 households, and 8,354 families residing in the county. The population density was 18/km2 (46/sq\u00a0mi). There were 16,761 housing units at an average density of 10/km2 (26/sq\u00a0mi). The racial makeup of the county was 98.83% White, 0.43% Black or African American, 0.07% Native American, 0.19% Asian, 0.02% Pacific Islander, 0.09% from other races, and 0.37% from two or more races. 0.44% of the population were Hispanic or Latino of any race. 36.1% were of German, 22.9% identified as American, 9.6% English and 8.8% Irish ancestry.\nThere were 11,476 households, out of which 32.60% had children under the age of 18 living with them, 60.70% were married couples living together, 8.40% had a female householder with no husband present, and 27.20% were non-families. 23.50% of all households were made up of individuals, and 10.60% had someone living alone who was 65 years of age or older. The average household size was 2.55 and the average family size was 3.00.\nIn the county, the population was spread out, with 25.10% under the age of 18, 7.80% from 18 to 24, 27.60% from 25 to 44, 24.60% from 45 to 64, and 14.90% who were 65 years of age or older. The median age was 38 years. For every 100 females, there were 97.20 males. For every 100 females age 18 and over, there were 93.80 males.\nThe median income for a household in the county was $32,238, and the median income for a family was $37,811. Males had a median income of $29,469 versus $20,673 for females. The per capita income for the county was $16,219. 13.30% of the population and 9.80% of families were below the poverty line. Out of the total people living in poverty, 16.60% are under the age of 18 and 13.90% are 65 or older.\nGarrett County is home to an Amish community in the Oakland area that consists of a church district of about 70 homes. The Amish community dates back to 1850 and became associated with the New Order Amish, with electricity permitted inside of homes.\nPolitics and government.\nGovernment.\nThe county is governed by an elected three-member Board of County Commissioners, whose members serve four-year terms and must live in the district they represent. The Board is the traditional form of county government in Maryland. It may exercise only those powers conferred by the General Assembly of Maryland, and even those powers are narrowly construed.\nGarrett County is administered under a line organizational method, with the County Administrator responsible for the general administration of County Government. The administration of the county is centralized with the County Administrator responsible for overseeing the financial planning, annual budget process, personnel management, and direction and management of operations within the organization.\nCounty seal.\nOn December 15, 1977, the seal of Garrett County went into effect by virtue of Resolution #7. The seal is elliptical, with the name \"Garrett County\" inscribed above the upper fourth of the ellipse, and \"Maryland 1872\" inscribed below the lower fourth of the ellipse. The date \"1872\" depicts the year of the formation of Garrett County. The seal illustrates a large snowflake to depict winter; water to represent sailing; and oaks and conifer to represent the county's mountains. The colors are peacock blue for the sky and water. The blue and white background is divided by kelly green.\nCounty flag.\nThe official flag for Garrett County is elliptical. The flag illustrates a large snowflake to depict winter; water to represent sailing; and oaks and conifer to represent the county's mountains. The colors are peacock blue for the sky and water. The blue and white background is divided by kelly green.\nPolitics.\nAlthough since the Civil War Maryland has been a Democratic-leaning state, Garrett County, owing to its history of German settlement from north of the Mason\u2013Dixon line, plus strong pre-war Unionism resulting from virtual absence of slaves, has always been strongly Republican. Since it was created in 1872, Garrett is one of 15 counties across the nation (chiefly Unionist strongholds in antebellum slave states) to have never voted for a Democratic presidential candidate.\nCompared with neighbouring and closely allied Grant County, West Virginia, Garrett has not shown quite the same levels of Republican support \u2013 Lyndon Johnson did get within 109 votes of Barry Goldwater in 1964 \u2013 but as with Grant County, the only occasion Garrett County has not been carried by the official Republican nominee occurred in 1912 when a major split in the Republican Party allowed \"Bull Moose Party\" nominee and former President Theodore Roosevelt to claim the county. Since 1996, no Democratic presidential nominee has won even 30% of the county's vote, and not since 2010 has Garrett County voted Democratic in any statewide election.\nGarrett County has been the most conservative county in Maryland in the 21st century. Owing to its strong Republican lean, Garrett County sometimes votes against ballot measures that the rest of the state approves by large margins. In 2022, Garrett County was the only county in the state to vote against legalizing recreational cannabis via 2022 Maryland Question 4. In 2024, Garrett County was the only county in the state to vote against enshrining a right to abortion in the state constitution via 2024 Maryland Question 1. Garrett County is part of Maryland's 6th congressional district, which is represented by April McClain Delaney.\nLaw enforcement.\nThe county is policed by the Garrett County Sheriff's Office and the Maryland State Police.\nThe state parks are policed by the Department of Natural Resources Police.\nThe county established an Office of the Fire Marshal in 2022, working in collaboration with the Maryland State Office established in 1894.\nEconomy.\nGarrett County produces natural gas, the only county in the state to do so. Much of the economic activity in the area centers around tourism. In the winter, the Wisp ski resort in Oakland and New Germany State Park's cross-country skiing trail are frequent destinations, and Deep Creek Lake sees much activity in the summer. The state parks in the county are frequented year-round. During the COVID-19 pandemic, tourism boomed as many people from Washington, DC, Baltimore, and Pittsburgh wanted to get away from the city.\nTransportation.\nMajor highways.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAirport.\nGarrett County Airport (2G4) is a general aviation airport surrounded by the mountains of Western Maryland. The airport enhances the region's tourist industry and provides emergency air service evacuation and landing facilities for general aviation.\nMedia.\nGarrett County is part of the Pittsburgh, Pennsylvania television market. KDKA-TV and WTAE-TV in Pittsburgh, Pennsylvania, and WJAC-TV in Johnstown, Pennsylvania serves Oakland, the county seat. Oakland also has an educational television station (by way of PBS member station WGPT, part of state-wide Maryland Public Television; it is also served by Pittsburgh-based member station WQED).\nIt has a weekly newspaper, the \"Garrett County Republican\", which was purchased by NCWV Media in 2017.\nEvents.\nAnnual events include the Autumn Glory Festival, the Scottish Highland Festival, and the Garrett County Agricultural Fair.\nCommunities.\nTowns.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCensus-designated places.\nThe United States Census Bureau recognizes seven census-designated places (CDPs) in Garrett County.\nUnincorporated communities.\nThe following communities are classified as populated places or locales by the Geographic Names Information System.\nEducation.\nGarrett College is a public community college in McHenry, Maryland. The college had three outreach centers in Accident, Grantsville, and Oakland.\nGarrett County Public Schools operates public schools. There are two public high schools in the county, Southern Garrett High School and Northern Garrett High School, two public middle schools, Southern Garrett Middle School and Northern Garrett Middle School, and seven public elementary schools, Accident Elementary School, Broad Ford Elementary School, Crellin Elementary School, Friendsville Elementary School, Grantsville Elementary School, Route 40 Elementary School, and Yough Glades Elementary School. There is also one K-8 public school in the county, which is Swan Meadow School.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46159", "revid": "46469420", "url": "https://en.wikipedia.org/wiki?curid=46159", "title": "Omaha, Nebraska", "text": "Largest city in Nebraska, US\nOmaha is the most populous city in the U.S. state of Nebraska. It is located in the Midwestern United States along the Missouri River, about north of the mouth of the Platte River. Omaha had a population of 486,051 at the 2020 census, making it the 41st-most populous U.S. city. The eight-county Omaha\u2013Council Bluffs metropolitan area extending into Iowa has approximately 1 million residents, the 55th-largest metropolitan area in the U.S. Omaha is the county seat of Douglas County.\nOmaha's pioneer period began in 1854, when the city was founded along the Missouri River by speculators from neighboring Council Bluffs, Iowa. It originally comprised a crossing called Lone Tree Ferry earning the city its nickname, the \"Gateway to the West\". Omaha introduced this new West to the world in 1898, when it played host to the World's Fair, dubbed the Trans-Mississippi Exposition. During the 19th century, Omaha's central location in the United States spurred the city to become an important national transportation hub. Throughout the rest of the 19th century, the transportation and jobbing sectors were important in the city, along with its railroads and breweries. In the 20th century, the Omaha Stockyards, once the world's largest, and its meatpacking plants gained international prominence.\nOmaha is the home to the headquarters of four \"Fortune\" 500 companies: Berkshire Hathaway, Kiewit Corporation, Mutual of Omaha, and Union Pacific Corporation. Other companies headquartered in the city include First National Bank of Omaha, Gallup, Inc., Green Plains, Intrado, Valmont Industries, Werner Enterprises, WoodmenLife, and three of the nation's ten largest architecture and engineering firms (DLR Group, HDR, Inc., and Leo A Daly). Notable cultural institutions include the Henry Doorly Zoo and Aquarium, Old Market, Durham Museum, Lauritzen Gardens, and annual College World Series. Modern Omaha inventions include the Reuben sandwich; cake mix, developed by Duncan Hines; center-pivot irrigation; Raisin Bran; the first ski lift in the U.S.; the Top 40 radio format as first used in the U.S. at Omaha's KOWH Radio; and the TV dinner.\nHistory.\nVarious Native American tribes had lived in the land that became Omaha since the 17th century, including the Omaha and Ponca, Dhegihan-Siouan language people who had originated in the lower Ohio River valley and migrated west by the early 17th century; Pawnee, Otoe, Missouria, and Iowa. The word \"Omaha\" ( or ) in the Omaha language means 'Upstream People' or 'Against the Current'.\nIn 1804 the Lewis and Clark Expedition passed the riverbanks where the city of Omaha would be built. Between July 30 and August 3, 1804, members of the expedition, including Meriwether Lewis and William Clark, met with Oto and Missouria tribal leaders at the Council Bluff at a point about north of present-day Omaha. Immediately south of that area, Americans built several fur trading outposts in succeeding years, including Fort Lisa in 1812; Fort Atkinson in 1819; Cabann\u00e9's Trading Post, built in 1822, and Fontenelle's Post in 1823, in what became Bellevue. There was fierce competition among fur traders until John Jacob Astor created the monopoly of the American Fur Company. The Mormons built a town called Cutler's Park in the area in 1846. While it was temporary, the settlement provided the basis for further development.\nThrough 26 separate treaties with the United States federal government, Native American tribes in Nebraska gradually ceded the lands that now make up the state. The treaty and cession involving the Omaha area occurred in 1854 when the Omaha Tribe ceded most of east-central Nebraska. Logan Fontenelle, an interpreter for the Omaha and signatory to the 1854 treaty, played an essential role in those proceedings.\nPioneer Omaha.\nBefore it was legal to claim land in Indian Country, William D. Brown operated the Lone Tree Ferry that brought settlers from Council Bluffs, Iowa to the area that became Omaha. Brown is generally credited as having the first vision for a city where Omaha now sits. The passage of the Kansas\u2013Nebraska Act in 1854 was presaged by the staking out of claims around the area to become Omaha by residents from neighboring Council Bluffs. On July 4, 1854, the city was informally established at a picnic on Capital Hill, current site of Omaha Central High School. Soon after, the Omaha Claim Club was formed to provide vigilante justice for claim jumpers and others who infringed on the land of many of the city's founding fathers. Some of this land, which now wraps around Downtown Omaha, was later used to entice Nebraska Territorial legislators to an area called Scriptown. The Territorial capitol was in Omaha, but when Nebraska became a state in 1867, the capital was relocated to Lincoln, southwest of Omaha. The U.S. Supreme Court later ruled against numerous landowners whose violent actions were condemned in \"Baker v. Morton\".\nMany of Omaha's founding figures stayed at the Douglas House or the Cozzens House Hotel. Dodge Street was important early in the city's early commercial history; North 24th Street and South 24th Street also developed independently as business districts. Early pioneers were buried in Prospect Hill Cemetery and Cedar Hill Cemetery. Cedar Hill closed in the 1860s and its graves were moved to Prospect Hill, where pioneers were later joined by soldiers from Fort Omaha, African Americans and early European immigrants. There are several other historical cemeteries in Omaha, historical Jewish synagogues and historical Christian churches dating from the pioneer era, as well. Two sculpture parks, Pioneer Courage and Spirit of Nebraska's Wilderness and The Transcontinental Railroad, celebrate the city's pioneering history.\n19th century.\nThe economy of Omaha boomed and busted through its early years. In 1858, the \"Omaha Daily Republican\" was founded by the \"Omaha Printing Company (rebranded Aradius Group, 2016)\", it was Nebraska's first regional newspaper\u2013founded before Nebraska claimed statehood. Omaha was a stopping point for settlers and prospectors heading west, either overland or by the Missouri River. The steamboat \"Bertrand\" sank north of Omaha on its way to the goldfields in 1865. Its massive collection of artifacts is on display at the nearby Desoto National Wildlife Refuge. The jobbing and wholesaling district brought new jobs, followed by the railroads and the stockyards. Groundbreaking for the First transcontinental railroad in 1863, provided an essential developmental boom for the city. In 1862, the U.S. Congress allowed the Union Pacific Railroad to begin building westward railways; in January 1866 it commenced construction out of Omaha.\nThe Union Stockyards, another important part of the city's development, were founded in South Omaha in 1883. Within 20 years, Omaha had four of the five major meatpacking companies in the United States. By the 1950s, half the city's workforce was employed in meatpacking and processing. Meatpacking, jobbing and railroads were responsible for most of the growth in the city from the late 19th century through the early decades of the 20th century.\nImmigrants soon created ethnic enclaves throughout the city, including Irish in Sheelytown in South Omaha; Germans in the Near North Side, joined by the European Jews and black migrants from the South; and Little Italy and Little Bohemia in South Omaha. Beginning in the late 19th century, Omaha's upper class lived in posh enclaves throughout the city, including the south and north Gold Coast neighborhoods, Bemis Park, Kountze Place, Field Club and throughout Midtown Omaha. They traveled the city's sprawling park system on boulevards designed by renowned landscape architect Horace Cleveland. The Omaha Horse Railway first carried passengers throughout the city, as did the later Omaha Cable Tramway Company and several similar companies. In 1888, the Omaha and Council Bluffs Railway and Bridge Company built the Douglas Street Bridge, the first pedestrian and wagon bridge between Omaha and Council Bluffs.\nGambling, drinking and prostitution were widespread in the 19th century, first rampant in the city's Burnt District and later in the Sporting District. Controlled by Omaha's political boss Tom Dennison by 1890, criminal elements enjoyed support from Omaha's \"perpetual\" mayor, \"Cowboy Jim\" Dahlman, nicknamed for his eight terms as mayor.\nCalamities such as the Great Flood of 1881 did not slow down the city's violence. In 1882, the Camp Dump Strike pitted state militia against unionized strikers, drawing national attention to Omaha's labor troubles. The Governor of Nebraska had to call in U.S. Army troops from nearby Fort Omaha to protect strikebreakers for the Burlington Railroad, bringing along Gatling guns and a cannon for defense. When the event ended, one man was dead and several were wounded. In 1891, a mob hanged Joe Coe, an African-American porter after he was accused of raping a white girl. There were also several other riots and civil unrest events in Omaha during this period.\nIn 1898, Omaha's leaders, under the guidance of Gurdon Wattles, held the Trans-Mississippi and International Exposition, touted as a celebration of agricultural and industrial growth throughout the Midwest. The Indian Congress, which drew more than 500 American Indians from across the country, was held simultaneously. More than 2 million visitors attended these events at Kountze Park and the Omaha Driving Park in the Kountze Place neighborhood.\n20th century.\nWith dramatically increasing population in the 20th century, competition and fierce labor struggles led to major civil unrest. In 1900, Omaha was the center of a national uproar over the kidnapping of Edward Cudahy, Jr., the son of a local meatpacking magnate.\nThe city's labor and management clashed in bitter strikes, racial tension escalated as blacks were hired as strikebreakers, and ethnic strife broke out. A major riot by earlier immigrants in South Omaha destroyed the city's Greek Town in 1909, completely driving out the Greek population.\nThe civil rights movement in Omaha has roots that extend back to 1912, when the first chapter of the National Association for the Advancement of Colored People west of the Mississippi River was founded in the city.\nThe Omaha Easter Sunday Tornado of 1913 destroyed much of the city's African-American community, in addition to much of Midtown Omaha.\nIt was during that same year that future United States President Gerald R. Ford was born in Omaha. Today, there is a museum dedicated to his birthplace.\nSix years later, in 1919, the city was caught up in the Red Summer riots when thousands of whites marched from South Omaha to the courthouse to lynch a black worker, Willy Brown, a suspect in an alleged rape of a white woman. The mob burned the Douglas County Courthouse to get the prisoner, causing more than $1 million damage. They hanged and shot Will Brown, then burned his body. Troops were called in from Fort Omaha to quell the riot, prevent more crowds gathering in South Omaha, and to protect the black community in North Omaha.\nThe culture of North Omaha thrived throughout the 1920s through 1950s, with several creative figures, including Tillie Olsen, Wallace Thurman, Lloyd Hunter, and Anna Mae Winburn emerging from the vibrant Near North Side.\nMusicians created their own world in Omaha, and also joined national bands and groups that toured and appeared in the city.\nAfter the tumultuous Great Depression of the 1930s, Omaha rebounded with the development of Offutt Air Force Base just south of the city. The Glenn L. Martin Company operated a factory there in the 1940s that produced 521 B-29 \"Superfortresses\", including the \"Enola Gay\" and \"Bockscar\" used in the atomic bombing of Japan in World War II.\nThe construction of Interstates 80, 480 and 680, along with the North Omaha Freeway, spurred development. There was also controversy, particularly in North Omaha, where new routes bisected several neighborhoods. Creighton University hosted the DePorres Club, an early civil rights group whose use of sit-in strategies for integration of public facilities predated the national movement.\nFollowing the development of the Glenn L. Martin Company bomber manufacturing plant in Bellevue at the beginning of World War II, the relocation of the Strategic Air Command to the Omaha suburb in 1948 provided a major economic boost to the area.\nFrom the 1950s through the 1960s, more than 40 insurance companies were headquartered in Omaha, including Woodmen of the World and Mutual of Omaha. By the late 1960s, the city rivaled, but never surpassed, the United States insurance centers of Hartford, Connecticut, New York City and Boston.\nAfter surpassing Chicago in meat processing by the late 1950s, Omaha suffered the loss of 10,000 jobs as both the railroad and meatpacking industries restructured. The city struggled for decades to shift its economy as workers suffered. Poverty became more entrenched among families who remained in North Omaha.\nIn the 1960s, three major race riots along North 24th Street destroyed the Near North Side's economic base, with recovery slow for decades. In 1969, Woodmen Tower was completed and became Omaha's tallest building and first major skyscraper at , a sign of renewal.\nSince the 1970s, Omaha has continued expanding and growing, mostly to available land to the west. West Omaha has become home to the majority of the city's population. North and South Omaha's populations continue to be centers of new immigrants, with economic and racial diversity. In 1975 a major tornado, along with a major blizzard, caused more than $100 million in damages in 1975 dollars.\nDowntown Omaha has since been rejuvenated in numerous ways, starting with the development of Gene Leahy Mall and W. Dale Clark Library in the late 1970s. In the 1980s, Omaha's fruit warehouses were converted into a shopping area called the Old Market.\nThe demolition of Jobber's Canyon in 1989 led to the creation of the ConAgra Foods campus. Several nearby buildings, including the Nash Block, have been converted into condominiums. The stockyards were taken down; the only surviving building is the Livestock Exchange Building, which was converted to multi-use and listed on the National Register of Historic Places.\nA historic preservation movement in Omaha has led to a number of historic structures and districts being designated Omaha Landmarks or listed on the National Register of Historic Places. Much of the push toward preservation came after Omaha gained the notorious designation of having, in 1989, demolished the largest-ever National Register historic district in the United States, a record that still stands as of 2013. The Jobbers Canyon Historic District, along the Missouri River, was felled for a new headquarters campus for ConAgra Foods, a company which threatened to relocate if Omaha did not allow them to raze the city's historic district. The Jobber's Canyon warehouses had before then been allowed to deteriorate and were the scene of several fires set by the homeless population that had come to live in the abandoned buildings. At the time, there were no plans in place for revitalizing the buildings.\nIn the 1980s and 1990s, Omaha also saw major company headquarters leave the city, including Enron, founded in the city in 1930 and taken to Houston in 1987 by the now-notorious Kenneth Lay. First Data Corporation, a large credit-card processor, also was founded in Omaha in 1969; as of 2009, its headquarters are in Atlanta.\nInacom, founded in Omaha in 1991, was a technology company that customized computer systems for large businesses, and was on the Fortune 500 list from 1997 until 2000, when it filed for bankruptcy. Northwestern Bell, the Bell System affiliate for Northwestern states, had its headquarters in Omaha from its founding in 1896 until it moved to Denver in 1991 as US West. Level 3 Communications, a large Tier 1 network provider, was founded in Omaha in 1985 as Kiewit Diversified Group, a division of Kiewit Corporation, a Fortune 500 construction and mining company still headquartered in Omaha; Level 3 moved to Denver in 1998. World Com was founded by a merger with Omaha's MFS Communications, started as Metropolitan Fiber Systems in 1993. MFS, backed by Kiewit Corporation CEO Walter Scott Jr. and Warren Buffett, purchased UUNET, one of the largest Internet backbones in the world, for $2 billion in 1996. The now-infamous Bernie Ebbers purchased the much larger MFS for $14.3 billion in 1997 under his World Com. He moved headquarters of the merged company from Omaha to Mississippi.\n21st century.\nAround the start of the 21st century, several downtown skyscrapers and cultural institutions were built.\nThe First National Bank Tower on Dodge Street was completed in 2002 and is the tallest building in Omaha and the state, surpassing the Woodmen Tower as the tallest in both at . The creation of the city's new North Downtown included the construction of the CenturyLink Center and the Slowdown/Film Streams development at North 14th and Webster Streets. Construction of the new TD Ameritrade Park, also in the North Downtown area, began in 2009 and was completed in 2011. TD Ameritrade Park is now the home of the College World Series, an event tourists flock to each year. The Union Pacific Center and the Holland Performing Arts Center opened in 2004 and 2005, respectively.\nImportant retail and office developments occurred in West Omaha, such as the Village Pointe shopping center and several business parks. The site of the former Ak-Sar-Ben arena was redeveloped into a mixed-use development Aksarben Village. In January 2009, Blue Cross Blue Shield of Nebraska announced plans to build a 10 story, $98 million headquarters in the Aksarben Village which it completed in Spring 2011. Another major mixed-use development to come to Omaha was Midtown Crossing at Turner Park. Developed by Mutual of Omaha, the development includes several condominium towers and retail businesses built around Omaha's Turner Park.\nThere have also been several developments along the Missouri River waterfront near downtown. The Bob Kerrey Pedestrian Bridge was opened to foot and bicycle traffic on September 28, 2008. Started in 2003, RiverFront Place Condos first phase was completed in 2006 and the second phase was opened in 2011. The development along Omaha's riverfront is attributed with prompting the City of Council Bluffs to move their own riverfront development time line forward.\nIn the summers of 2008, 2012, 2016, and 2021 the United States Olympic Team swimming trials were held in Omaha, at the Qwest/Century Link Center. These events were highlights in the city's sports community, as well as a showcase for redevelopment in the downtown area.\nIn the 2020s, a number of large projects have been either completed or planned in an attempt to revitalize downtown Omaha. These include the redevelopment of the Gene Leahy Mall, a large park near Omaha's Riverfront, and the Omaha Streetcar, a nearly $500 million system of public transit. A new skyscraper, the Mutual of Omaha Headquarters Tower, at , will be the new tallest building in Omaha and the state upon its completion in 2026.\nDouglas County treasurer John Ewing was elected mayor in 2025, ending Stothert's 12-year long administration. He is the first black mayor of Omaha.\nGeography.\nAccording to the United States Census Bureau, the city has a total area of , of which is land and is water. Situated in the Midwestern United States on the bank of the Missouri River in eastern Nebraska, much of Omaha is built in the Missouri River Valley. Other significant bodies of water in the Omaha-Council Bluffs metropolitan area include Lake Manawa, Papillion Creek, Carter Lake, Platte River and the Glenn Cunningham Lake. The city's land has been altered considerably with substantial land grading throughout Downtown Omaha and scattered across the city. East Omaha sits on a flood plain west of the Missouri River. The area is the location of Carter Lake, an oxbow lake. The lake was once the site of East Omaha Island and Florence Lake, which dried up in the 1920s.\nMetropolitan area.\nThe Omaha-Council Bluffs metropolitan area consists of eight counties; five in Nebraska and three in Iowa. The metropolitan area now includes Harrison, Pottawattamie, and Mills Counties in Iowa and Washington, Douglas, Sarpy, Cass, and Saunders Counties in Nebraska. This area was formerly referred to only as the Omaha Metropolitan Statistical Area and consisted of only five counties: Pottawattamie in Iowa, and Washington, Douglas, Cass, and Sarpy in Nebraska. The Omaha-Council Bluffs combined statistical area comprises the Omaha-Council Bluffs metropolitan statistical area and the Fremont Micropolitan statistical area; the CSA has a population of 858,720 (2005 Census Bureau estimate). Omaha ranks as the 41st-most populous city in the United States, and is the core city of its 60th-largest metropolitan area. There are no consolidated city-counties in the area; the City of Omaha studied the possibility extensively through 2003 and concluded, \"The City of Omaha and Douglas County should merge into a municipal county, work to commence immediately, and that functional consolidations begin immediately in as many departments as possible, including but not limited to parks, fleet management, facilities management, local planning, purchasing and personnel.\"\nGeographically, Omaha is considered as being in the \"Heartland\" of the United States. Important environmental impacts on the natural habitat in the area include the spread of invasive plant species, restoring prairies and bur oak savanna habitats, and managing the whitetail deer population.\nOmaha is home to several hospitals, mostly along Dodge Street (US6). Being the county seat, it is also the location of the county courthouse.\nNeighborhoods.\nOmaha is generally divided into six geographic areas: Downtown, Midtown, North Omaha, South Omaha, West Omaha, and East Omaha. West Omaha includes the Miracle Hills, Boys Town, Regency, and Gateway areas. The city has a wide range of historical and new neighborhoods and suburbs that reflect its socioeconomic diversity. Early neighborhood development happened in ethnic enclaves, including Little Italy, Little Bohemia, Little Mexico and Greek Town. According to U.S. Census data, five European ethnic enclaves existed in Omaha in 1880, expanding to nine in 1900.\nAround the start of the 20th century. the City of Omaha annexed several surrounding communities, including Florence, Dundee and Benson. At the same time, the city annexed all of South Omaha, including the Dahlman and Burlington Road neighborhoods. From its first annexation in 1857 (of East Omaha) to its controversial annexation of Elkhorn in 2007, Omaha has continually had an eye towards growth.\nStarting in the 1950s, development of highways and new housing led to the movement of the middle class to suburbs in West Omaha. Some of the movement was designated as white flight from racial unrest in the 1960s. Newer and poorer migrants lived in older housing close to downtown; those residents who were more established moved west into newer housing. Some suburbs are gated communities or have become edge cities. Recently, Omahans have made strides to revitalize the downtown and Midtown areas with the redevelopment of the Old Market, Turner Park, Gifford Park, and the designation of the Omaha Rail and Commerce Historic District.\nClimate.\nOmaha, due to its latitude of 41.26\u02da N and location far from moderating bodies of water or mountain ranges, displays a hot-summer humid continental climate (K\u00f6ppen: \"Dfa\"). July averages , with average relative humidity around 70% which then leads to relatively frequent thunderstorms. Temperatures reach on 29 days and on 1.7 days annually. The January daily average is , with lows reaching on 11 days annually. The lowest temperature recorded in the city was on January 5, 1884, and the highest on July 25, 1936. Average yearly precipitation is , falling mostly in the warmer months. Snow is the most common precipitation in winter, with average seasonal snowfall being .\nBased on 30-year averages obtained from NOAA's National Climatic Data Center for the months of December, January and February, Weather Channel ranked Omaha the 5th coldest major U.S. city as of 2014.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n&lt;includeonly&gt;&lt;templatestyles src=\"Chart/styles.css\"/&gt;&lt;/includeonly&gt;\n2020 census.\nThe 2020 United States census counted 486,051 people, 189,922 households, and 113,245 families in Omaha. The population density was 3,406.8 per square mile (1,315.4/km2). There were 203,215 housing units, at an average density of 1,424.4 per square mile (550.0/km2). The racial makeup (including Hispanics in the racial counts) was 65.47% (318,218) white, 12.4% (60,280) black or African-American, 1.12% (5,426) Native American, 4.6% (22,377) Asian, 0.09% (461) Pacific Islander, 7.25% (35,233) from other races, and 9.06% (44,056) from two or more races. Hispanic or Latino of any race was 14.0% (67,715) of the population.\nOf the 189,922 households, 28.3% had children under the age of 18; 43.0% were married couples living together; 29.2% had a female householder with no husband present. 33.2% of households consisted of individuals and 10.7% had someone living alone who was 65 years of age or older. The average household size was 2.5 and the average family size was 3.2.\n24.5% of the population was under the age of 18, 9.6% from 18 to 24, 28.2% from 25 to 44, 23.2% from 45 to 64, and 13.1% who were 65 years of age or older. The median age was 34.9 years. For every 100 females, the population had 97.1 males. For every 100 females ages 18 and older, there were 95.0 males.\nThe 2016\u20132020 5-year American Community Survey estimates show that the median household income was $62,213 (with a margin of error of +/- $969) and the median family income $80,956 (+/- $1,380). Males had a median income of $41,528 (+/- $592) versus $31,295 (+/- $490) for females. The median income for those above 16 years old was $36,290 (+/- $532). Approximately, 8.0% of families and 12.0% of the population were below the poverty line, including 15.6% of those under the age of 18 and 7.8% of those ages 65 or over.\n2010 census.\nAs of the census of 2010, there were 408,958 people, 162,627 households, and 96,477 families residing in the city. The population density was . There were 177,518 housing units, at an average density of . The city's racial makeup was 73.1% White, 13.7% African American, 0.8% Native American, 2.4% Asian, 0.1% Pacific Islander, 6.9% from other races, and 3.0% from two or more races. Hispanic or Latino people of any race were 13.1% of the population. Non-Hispanic Whites were 68.0% of the population.\nThere were 162,627 households, of which 31.3% had children under the age of 18 living with them, 40.6% were married couples living together, 13.7% had a female householder with no husband present, 4.9% had a male householder with no wife present, and 40.7% were non-families. 32.3% of all households were made up of individuals, and 9.3% had someone living alone who was at least 65 years old. The average household size was 2.45 and the average family size was 3.14.\nThe median age in the city was 33.5 years. 25.1% of residents were under the age of 18; 11.4% were between the ages of 18 and 24; 27.9% were from 25 to 44; 24.4% were from 45 to 64; and 11.4% were 65 years of age or older. The city's gender makeup was 49.2% male and 50.8% female.\nThe median household income (in 2017 dollars) from 2013 to 2017 was $53,789.\nCrime.\nAs a major industrial city into the mid-20th century, Omaha shared in social tensions that came with rapid growth and the arrival of large numbers of immigrants and migrants. Persistent poverty resulting from racial discrimination and job losses generated different crimes in the late 20th century, with the drug trade and drug abuse becoming associated with violent crime rates, which climbed after 1986 as Los Angeles gangs made affiliates in the city.\nGambling in Omaha has been an important part of the city's history. From its founding in the 1850s through the 1930s, the city was known as a \"wide-open\" town where gambling of all sorts was openly accepted. By the 1950s, at the same time large-scale restructuring of the railroads, the meatpacking industry and other sectors caused widespread job losses and unemployment, Omaha reportedly had more illicit gambling than any other city in the nation. From the 1930s through the 1970s, a Mafia-based criminal element controlled gambling in the city.\nAs most forms of gambling are currently restricted in Nebraska, gambling in Omaha is limited to keno, lotteries, and parimutuel betting. This leaves Omahans to drive across the Missouri River to Council Bluffs, Iowa, where casinos are legal and many businesses operate. Recently, the National Indian Gaming Commission approved a controversial proposal made by the Ponca tribe of Nebraska. It will allow the tribe to build a casino in Carter Lake, Iowa, which sits on the west side of the Missouri River, adjacent to Omaha, where casinos are illegal.\nPeople.\nNative Americans were the first residents of the Omaha area. The city of Omaha was established by white settlers from neighboring Council Bluffs who arrived from the Mid-Atlantic states a few years earlier. While much of the early population was of Upland Southern stock, over the next 100 years numerous ethnic groups moved to the city. In 1910, the Census Bureau reported Omaha's population as 96.4% White and 3.6% Black. Irish immigrants in Omaha originally moved to an area in present-day North Omaha called Gophertown, as they lived in dug-out sod houses. That population was followed by Polish immigrants in the Sheelytown neighborhood, and many immigrants were recruited for jobs in South Omaha's stockyards and meatpacking industry. The German community in Omaha was largely responsible for founding its once-thriving beer industry, including the Metz, Krug, Falstaff and Storz breweries.\nSince its founding, ethnic groups in the city have clustered in enclaves in north, south and downtown Omaha. In its early days, the sometimes lawless nature of a new frontier city included crime, such as illicit gambling and riots.\nIn the early 20th century, Jewish immigrants set up many businesses along the North 24th Street commercial area. It suffered with the loss of industrial jobs in the 1960s and, later, the shifting of population west of the city. The commercial area is now the center of the African-American community, concentrated in North Omaha. The African American community has maintained its social and religious base, while it is experiencing an economic revitalization.\nThe Little Italy neighborhood grew south of downtown, as many Italian immigrants came to the city to work in the Union Pacific shops. Scandinavians first came to Omaha as Mormon settlers in the Florence neighborhood. Czechs had a strong political and cultural voice in Omaha, and were involved in a variety of trades and businesses, including banks, wholesale houses, and funeral homes. The Notre Dame Academy and Convent and Czechoslovak Museum are legacies of their residence. Today the legacy of the city's early European immigrant populations is evident in many social and cultural institutions in Downtown and South Omaha.\nMexicans originally immigrated to Omaha to work in the rail yards. Today they account for most of South Omaha's Hispanic population and many have taken jobs in meat processing. Other large early ethnic populations in Omaha included Danes, Poles, and Swedes.\nA growing number of African immigrants have made their homes in Omaha in the last twenty years. There are approximately 8,500 Sudanese living in Omaha, including the largest population of Sudanese refugees in the United States. Most have immigrated since 1995 because of warfare in Sudan. They represent ten ethnic groups, including the Nuer, Dinka, Equatorians, Maubans and Nubians. Most Sudanese people in Omaha speak the Nuer language. Other Africans have immigrated to Omaha as well, with one-third from Nigeria, and large populations from Kenya, Togo, Cameroon and Ghana.\nWith the expansion of railroad and industrial jobs in meatpacking, Omaha attracted many immigrants and migrants. As the major city in Nebraska, it has historically been more racially and ethnically diverse than the rest of the state. At times rapid population change, overcrowded housing and job competition have aroused racial and ethnic tensions. Around the start of the 20th century, violence towards new immigrants in Omaha often erupted out of suspicion and fear.\nIn 1909, anti-Greek sentiment flared after increased Greek immigration, and worsened their tendency to become strikebreakers. The killing of a policeman of Irish descent enraged the Irish community; an angry mob violently stormed the Greek neighborhood in Omaha in what would become known as the Greek Town Riot. That mob violence forced the Greek immigrant population to flee from the city. By 1910, 53.7% of Omaha's residents and 64.2% of South Omaha's residents were foreign born or had at least one parent born outside of America.\nSix years after the Greek Town Riot, in 1915, a mob killed Juan Gonzalez, a Mexican immigrant, near Scribner, a town in the Greater Omaha metropolitan area. The event occurred after an Omaha Police Department officer investigated a criminal operation that sold goods stolen from the nearby railroad yards. Racial profiling targeted Gonzalez as the culprit. After escaping the city, he was trapped along the Elkhorn River, where the mob, including several policemen from Omaha, shot him more than twenty times. It was discovered Gonzalez was unarmed, and he had a reliable alibi for the time of the murder. No one was ever indicted for his killing.\nIn the fall of 1919, following Red Summer, postwar social and economic tensions, the earlier hiring of African Americans as strikebreakers, and job uncertainty contributed to a mob from South Omaha lynching Willy Brown and the ensuing Omaha Race Riot. Trying to defend Brown, the city's mayor, Edward Parsons Smith, was lynched also, surviving only after a quick rescue.\nLike other industrial cities in the U.S., Omaha suffered severe job losses in the 1950s, more than 10,000 in all, as the railroad and meatpacking industries restructured. Stockyards and packing plants were located closer to ranches, and union achievements were lost as wages declined in surviving jobs. Many workers left the area if they could get to other jobs. Poverty deepened in areas of the city whose residents depended on those jobs, specifically North and South Omaha. At the same time, with reduced revenues, the city had less financial ability to respond to longstanding problems.\nDespair after the April 1968 assassination of Martin Luther King Jr. contributed to riots in North Omaha, including one at the Logan Fontenelle Housing Project. For some, the civil rights movement in Omaha, Nebraska evolved towards black nationalism, as the Black Panther Party was involved in tensions in the late 1960s. Organizations such as the Black Association for Nationalism Through Unity became popular among the city's African-American youth. This tension culminated in the \"cause c\u00e9l\u00e8bre\" trial of the Rice/Poindexter Case, in which an Omaha Police Department officer was killed by a bomb while answering an emergency call.\nWhites in Omaha have followed the white flight pattern, suburbanizing to West Omaha. In the late 1990s and early 2000s, gang violence and incidents between the Omaha Police and Black residents undermined relations between groups in North and South Omaha.\nEconomy.\nWith diversification in several industries, including banking, insurance, telecommunications, architecture/construction, and transportation, Omaha's economy has grown since the early 1990s, and six national fiber optic networks converge in Omaha.\nOmaha's most prominent businessman is Warren Buffett, nicknamed the \"Oracle of Omaha\", who for decades has ranked as one of the richest people in the world. Four Omaha-based companies: Berkshire Hathaway, Union Pacific Railroad, Mutual of Omaha, and Kiewit Corporation, are among the \"Fortune\" 500.\nOmaha is the headquarters of several other major corporations, including the Gallup Organization, Werner Enterprises, First National Bank of Omaha, WoodmenLife, Gavilon, Scoular and First Comp Insurance. Many other large national firms have major operations or operational headquarters in Omaha, including Bank of the West, First Data, Sojern, PayPal, LinkedIn, Pacific Life, MetLife and Conagra Brands. The city is also home to three of the 30 largest architecture firms in the United States, including HDR, Inc., DLR Group, Inc., and Leo A Daly.\nTop employers.\nAccording to the Greater Omaha Chamber of Commerce, the largest regional employers are:\nTourism.\nTourist attractions in Omaha include history, sports, outdoors and cultural experiences. Its principal tourist attractions are the Henry Doorly Zoo and the College World Series. The Old Market in Downtown Omaha is another major attraction and is important to the city's retail economy. The city has been a tourist destination for many years. Famous early visitors included British author Rudyard Kipling and General George Crook. In 1883 Omaha hosted the first official performance of the Buffalo Bill's Wild West Show for 8,000 attendees. In 1898 the city hosted more than 1 million visitors from across the United States at the Trans-Mississippi and International Exposition, a world's fair that lasted for more than half the year.\nResearch on leisure and hospitality situates Omaha in the same tier for tourists as the neighboring cities of Des Moines, Iowa; Topeka, Kansas; Kansas City, Missouri; Oklahoma City, Oklahoma; Denver, Colorado; and Sioux Falls, South Dakota. A recent study found investment of $1 million in cultural tourism generated approximately $83,000 in state and local taxes, and provided support for hundreds of jobs for the metropolitan area, which in turn led to additional tax revenue for government.\nArts and culture.\nSeveral national newspapers, including the \"Boston Globe\" and The \"New York Times\" have lauded Omaha's historical and cultural attractions.\nThe city is home to the Omaha Community Playhouse, the largest community theater in the United States. The Omaha Symphony Orchestra and its modern Holland Performing Arts Center, the Opera Omaha at the Orpheum theater, the Blue Barn Theatre, American Midwest Ballet, and The Rose Theater form the backbone of Omaha's performing arts community. Opened in 1931, the Joslyn Art Museum has large art collections. Since its inception in 1976, Omaha Children's Museum has been a place where children can challenge themselves, discover how the world works and learn through play. The Bemis Center for Contemporary Arts, one of the nation's premier urban artist colonies, was founded in Omaha in 1981, and the Durham Museum is accredited with the Smithsonian Institution for traveling exhibits. The city is also home to the largest singly funded mural in the nation, \"Fertile Ground\", by Meg Saligman. The annual Omaha Blues, Jazz, &amp; Gospel Festival celebrates local music along with the Omaha Black Music Hall of Fame.\nIn 1955, Omaha's Union Stockyards overtook Chicago's stockyards as the United States' meat packing center. This legacy is reflected in the cuisine of Omaha, with renowned steakhouses such as Gorat's and the recently closed Mister C's, as well as the retail chain Omaha Steaks.\nHenry Doorly Zoo.\nThe Henry Doorly Zoo is widely considered a premier zoo. The zoo is home to the world's largest nocturnal exhibit and indoor swamp; the world's largest indoor rainforest, the world's largest indoor desert, and the largest geodesic dome in the world (13 stories tall). The zoo is Nebraska's number-one paid attendance attraction and has welcomed more than 25 million visitors over the past 40 years.\nOld Market.\nThe Old Market is a major historic district in Downtown Omaha listed on the National Register of Historical Places. Today, its warehouses and other buildings house shops, restaurants, bars, coffee shops, and art galleries. Downtown is also the location of the Omaha Rail and Commerce Historic District, which has several art galleries and restaurants. Lauritzen Gardens features with a variety of landscaping, and the new Kenefick Park recognizes Union Pacific Railroad's long history in Omaha. North Omaha has several historical cultural attractions including the Dreamland Historical Project, Love's Jazz and Art Center, and the John Beasley Theater. The annual River City Roundup is celebrated at Fort Omaha, and the neighborhood of Florence celebrates its history during \"Florence Days\". Native Omaha Days is a biennial event celebrating Near North Side heritage.\nReligion.\nReligious institutions reflect the city's heritage. The city's Christian community has several historical churches dating from the founding of the city. There are also all sizes of congregations, including small, medium and megachurches. Omaha hosts the only Church of Jesus Christ of Latter-day Saints temple in Nebraska along with a large Jewish community. There are 152 parishes in the Roman Catholic Archdiocese of Omaha, and several Eastern Orthodox congregations throughout the city.\nLauritzen Gardens.\nLauritzen Gardens is a botanical garden located near South Omaha. The garden contains several large greenhouses, and outdoor plant exhibits. Covering over 100 acres of land, Lauritzen Gardens welcomes over 200,000 guests annually, making it one of the most popular attractions in Omaha.\nMusic.\nOmaha's rich history in rhythm and blues, and jazz gave rise to a number of influential bands, including Anna Mae Winburn's Cotton Club Boys and Lloyd Hunter's Seranaders. Rock and roll pioneer Wynonie Harris, jazz great Preston Love, drummer Buddy Miles, and Luigi Waites are among the city's homegrown talent. Doug Ingle from the late 1960s band Iron Butterfly was born in Omaha, as was indie folk singer-songwriter Elliott Smith, though both were raised elsewhere. Musical theater star Andrew Rannells was also born in Omaha and is known amongst his fans for mentioning it in most of his interviews.\nToday, the diverse culture of Omaha includes a variety of performance venues, museums, and musical heritage, including the historically significant jazz scene in North Omaha and the modern and influential \"Omaha Sound\".\nContemporary music groups either in or originally from Omaha include Mannheim Steamroller, Bright Eyes, The Faint, Cursive, Azure Ray, Tilly and the Wall, and 311. During the late 1990s, Omaha became nationally known as the birthplace of Saddle Creek Records, and the subsequent \"Omaha Sound\" was born from their bands' collective style.\nOmaha also has a fledgling hip hop scene. Long-time bastion Houston Alexander, a one-time graffiti artist and professional Mixed Martial Arts competitor, is a local hip-hop radio show host. Cerone Thompson, known as \"Scrybe\", has had a number one single on college radio stations across the United States. He has also had several number one hits on the local hip hop station respectively titled, \"Lose Control\" and \"Do What U Do\". Other notable artists include Stylo of Mastered Trax Latino who holds a strong following in South Omaha and Mexico / Latin America.\nMany ethnic and cultural bands have come from Omaha. The Omaha Black Music Hall of Fame celebrates the city's long history of African-American music and the Strathdon Caledonia Pipe Band carries on a Scottish legacy. Internationally renowned composer Anton\u00edn Dvo\u0159\u00e1k wrote his Ninth (\"New World\") Symphony in 1893 based on his impressions of the region after visiting Omaha's robust Czech community. In the period surrounding World War I Valentin J. Peter encouraged Germans in Omaha to celebrate their rich musical heritage, too. Frederick Metz, Gottlieb Storz and Frederick Krug were influential brewers whose beer gardens kept many German bands active.\nLandmark preservation.\nOmaha is home to dozens of nationally, regionally and locally significant landmarks. The city has more than a dozen historic districts, including Fort Omaha Historic District, Gold Coast Historic District, Omaha Quartermaster Depot Historic District, Field Club Historic District, Bemis Park Historic District, and the South Omaha Main Street Historic District. Omaha is notorious for its 1989 demolition of 24 buildings in the Jobbers Canyon Historic District, which represents to date the largest loss of buildings on the National Register. The only original building surviving of that complex is the Nash Block.\nOmaha has almost one hundred individual properties listed on the National Register of Historic Places, including the Bank of Florence, Holy Family Church, the Christian Specht Building and the Joslyn Castle. There are also three properties designated as National Historic Landmarks.\nLocally designated landmarks, including residential, commercial, religious, educational, agricultural and socially significant locations across the city, honor Omaha's cultural legacy and important history. The City of Omaha Landmarks Heritage Preservation Commission is the government body that works with the mayor of Omaha and the Omaha City Council to protect historic places. Important history organizations in the community include the Douglas County Historical Society.\nBuilt in 1962, Omaha's Cinerama was called Indian Hills Theater. Its demolition in 2001 by the Nebraska Methodist Health System was unpopular, with objections from local historical and cultural groups and luminaries from around the world. The Dundee Theatre is the lone surviving single-screen movie theater in Omaha and still shows films. A recent development to the Omaha film scene was the addition of Film Streams's Ruth Sokolof Theater in North Downtown. The two-screen theater is part of the Slowdown facility. It features American independents, foreign films, documentaries, classics, themed series, and director retrospectives. In addition to the five Douglas Theatres venues in Omaha, two more are opening, including Midtown Crossing Theatres, on 32nd and Farnam Streets near the Mutual of Omaha Building. Westroads Mall has a modern multiplex movie theater with 14 screens, operated by Rave Cinemas.\nSports.\nSports have been important in Omaha for more than a century, and the city plays host to three minor-league professional sports teams.\nOmaha has hosted the annual June NCAA College World Series men's baseball tournament since 1950. It has been played at the downtown Charles Schwab Field since 2011.\nThe Omaha Sports Commission is a quasi-governmental nonprofit organization that coordinates much of the professional and amateur athletic activity in the city, including the 2008, 2012 and 2016 US Olympic Swimming Team Trials and the building of a new stadium in North Downtown. The University of Nebraska\u2013Lincoln and the Commission co-hosted the 2008 National Collegiate Athletic Association (NCAA) Division One Women's Volleyball Championship in December of that year. The 2016 Big 10 Baseball Championship was also played at the College World Series Stadium. Another quasi-governmental board, the Metropolitan Entertainment and Convention Authority (MECA), was created by city voters in 2000, and is responsible for maintaining the CHI Health Center Omaha (formerly CenturyLink Center Omaha).\nThe Omaha Storm Chasers play at Werner Park. They won seven championships (in 1969, 1970, 1978, 1990, 2011, 2013, and 2014).\nOmaha is also home to the Omaha Diamond Spirit, a collegiate summer baseball team that plays in the MINK league.\nThe Omaha Supernovas are a professional indoor volleyball team based in Omaha, Nebraska. The team competes in the Pro Volleyball Federation (PVF). The Supernovas began play in the league's inaugural 2024 season. The team plays their home games at CHI Health Center Omaha. The Supernovas won the inaugural championship in May 2024. During its championship run in the inaugural PVF season, Omaha and the Supernovas became the league's shining star, hosting 134,969 fans across the 15 matches held at the CHI Health Center. That includes a whopping 9,656 average mark for the 12 Supernovas\u2019 home matches, plus the 19,094 spectators who attended the PVF Semifinals and Championship.\nThe Supernovas erased any doubt that professional volleyball could happen in the United States with their 9,656 match average the No. 1 mark amongst professional volleyball teams in the world.\nOmaha broke many of its own attendance records across its historic season, starting with 11,624 fans attending the first-ever PVF match on Jan. 24 between Omaha and the Atlanta Vibe. That mark was broken a few weeks later on Sunday, Feb. 18 as 11,918 fans showed up to watch the Supernovas take on the Orlando Valkyries. The newest and most current attendance record was set on Saturday, March 16 with 12,090 spectators packing into the CHI Health Center to see the Supernovas beat the Valkyries in four sets.\nUnion Omaha, a professional minor league soccer team, is a member of USL League One and began play in the 2020 season. Their home games are played at Werner Park, which it shares with the Storm Chasers. The team, nicknamed the Owls, won the league championship in 2021. Union then made a deep run to the quarterfinals of the 2022 U.S. Open Cup, defeating two Major League Soccer teams in the process. The team announced plans in 2024 to build a 7,000-seat soccer-specific stadium near Downtown Omaha.\nThe Creighton University Bluejays compete in a number of NCAA Division I sports as members of the Big East Conference. The Bluejays play baseball at Charles Schwab Field, soccer at Morrison Stadium, and basketball at the 18,000 seat CHI Health Center Omaha. The Jays annually rank in the top 15 in attendance each year, averaging more than 16,000 people per game. \nThe Omaha Mavericks, representing the University of Nebraska Omaha (UNO), also play basketball, baseball and soccer in NCAA Division I as members of The Summit League. The UNO men's ice hockey team plays in the National Collegiate Hockey Conference.\nIce hockey is a popular spectator sport in Omaha. The Omaha Lancers, a United States Hockey League team, play at the Ralston Arena. The Omaha Mavericks play in the on-campus Baxter Arena.\nOmaha was home to an expansion team, the Nighthawks, in the United Football League from 2010 to 2011. The Omaha Beef indoor football team played at the Omaha Civic Auditorium until 2012 when they moved to the new Ralston Arena.\nOmaha was a notable cadence term of Pro Football Hall of Fame quarterback Peyton Manning during his 18-year playing career used to indicate a change of playcall. In 2021, he launched Omaha Productions.\nThe Kansas City-Omaha Kings, an NBA franchise, played in both cities from 1972 to 1978, before decamping solely to Kansas City until 1985, when the team moved to its current home of Sacramento.\nThe Cox Classic golf tournament was part of the Web.com Tour from 1996 to 2013. The circuit returned to Omaha in 2017 with the Pinnacle Bank Championship.\nParks and recreation.\nOmaha has a thriving running community and many miles of paved running and biking trails throughout the city and surrounding communities. The Omaha Marathon involves a half-marathon and a race that takes place annually in September. Omaha also has a history of curling, including multiple junior national champions.\nThe city's historic boulevards were originally designed by Horace Cleveland in 1889 to work with the parks to create a seamless flow of trees, grass and flowers throughout the city. Florence Boulevard and Fontenelle Boulevard are among the remnants of this system. Omaha boasts more than of trails for pedestrians, bicyclists and hikers. They include the American Discovery Trail, which traverses the entire United States, and the Lewis and Clark National Historic Trail passes through Omaha as it travels westward from Illinois to Oregon. Trails throughout the area are included in comprehensive plans for the city of Omaha, the Omaha metropolitan area, Douglas County, and long-distance coordinated plans between the municipalities of southeast Nebraska. The city also has a park dedicated to pollinating bees and insects called 'Pacific Preserve'\nGovernment.\nOmaha has a strong mayor form of government, along with a city council elected from seven districts across the city. The mayor is John Ewing Jr., who was elected in May 2025. The longest-serving mayor in Omaha's history was \"Cowboy\" Jim Dahlman, who served 20 years over eight terms. He was regarded as the \"wettest mayor in America\" because of the flourishing number of bars in Omaha during his tenure. Dahlman was a close associate of political boss Tom Dennison. During Dahlman's tenure, the city switched from its original strong-mayor form of government to a city commission government. In 1956, the city switched back.\nThe city clerk is Elizabeth Butler. The City of Omaha administers twelve departments, including finance, police, human rights, libraries and planning. The Omaha City Council is the legislative branch and has seven members elected from districts across the city. The council enacts local ordinances and approves the city budget. Government priorities and activities are established in a budget ordinance approved annually. The council takes official action through the passage of ordinances and resolutions. Nebraska's constitution grants the option of home rule to cities with more than 5,000 residents, meaning they may operate under their own charters. Omaha is one of only three cities in Nebraska to use this option, out of 17 eligible. The City of Omaha is considering consolidating with Douglas County government.\nAlthough registered Republicans outnumbered Democrats in the 2nd congressional district, which includes Omaha, Democratic presidential candidate Barack Obama opened three campaign offices in the city with 15 staff members to cover the state in fall 2008. Mike Fahey, the Democratic mayor of Omaha, said he would do whatever it took to deliver the district's electoral vote to Obama; and the Obama campaign considered the district \"in play\". Former Nebraska U.S. Senator Bob Kerrey and then-U.S. Senator Ben Nelson campaigned in the city for Obama, and in November 2008 Obama won the district's electoral vote. This was an historical win, as Obama became the first Democratic presidential candidate to win an electoral vote in Nebraska since 1964, only made possible by Nebraska's split electoral vote system.\nIn 2011, Nebraska lawmakers moved Offutt Air Force Base and the town of Bellevue\u2014an area with a large minority population\u2014out of the Omaha-based 2nd district and shifted in the Republican-heavy Omaha suburbs in Sarpy County. The move is expected to dilute the city's urban Democratic vote.\nThe 2nd district sent its single electoral vote for Joe Biden in the 2020 election. Biden's victory, by more than 20,000 votes, shows Omaha's and the 2nd district's continuing trend toward Democratic politics in recent years.\nEducation.\nPrimary and secondary education.\nOmaha has many public and private educational institutions, including Omaha Public Schools, the largest public school district in Nebraska, which serves more than 47,750 students in more than 75 schools. After a contentious period of uncertainty, in 2007 the Nebraska Legislature approved a plan to create a learning community for Omaha-area school districts with a central administrative board.\nThe Westside Community Schools, also known as District 66, is a district in the heart of Omaha. It serves students in pre-kindergarten through the 12th grade and recorded a district enrollment of 6,123 students K-12 for the 2015\u201316 school year.\nThrough annexations Omaha also has the Millard Public Schools and Elkhorn Public Schools. Omaha is also home to Brownell-Talbot School, Nebraska's only preschool through grade 12, independent college preparatory school.\nThe Roman Catholic Archdiocese of Omaha operates numerous private Catholic schools with 21,500 students in 32 elementary schools and nine high schools. They include https:// in Midtown Omaha, Holy Cross in Morton Meadows, St. Robert Bellarmine School at 120th and Pacific Street, St. Stephen the Martyr School in Millard, and Creighton Preparatory School, all of which have received the U.S. Department of Education Blue Ribbon School award.\nHigher education.\nThere are eleven colleges and universities among Omaha's higher education institutions. The largest public school is University of Nebraska Omaha, which was founded in 1908 and is currently an NCAA Division I school with over 15,000 students. The University of Nebraska Medical Center in midtown Omaha is home to the Eppley Cancer Center, one of 66 designated Cancer Centers by the National Cancer Institute in the United States. The University of Nebraska College of Medicine is also on the UNMC campus.\nOmaha's largest private university is Creighton University. It is a Jesuit institution that is ranked the top non-doctoral regional university in the Midwestern United States. Its campus is just outside Downtown Omaha in the new North Downtown district. The university has a combined 6,700 students in its undergraduate, graduate, medical, and law schools.\nOmaha is also home to a number of smaller colleges and universities. Clarkson College is a small private college focusing on health sciences and affiliated with the Episcopal Church. Nebraska Methodist College is a small private school focusing on health careers and education. The College of Saint Mary is a Catholic woman's school known for its healthcare offerings. Bellevue University is a mid-size private university. Doane University is the oldest private university in Nebraska, with campuses in Crete and Lincoln. Its residential campus is in Crete with a smaller campus in Omaha.\nMedia.\nThe city is the focus of the Omaha designated market area, and is the 76th largest in the United States.\nMagazines.\n\"Omaha Magazine\"\nNewspapers.\nThe major daily newspaper in Nebraska is the \"Omaha World-Herald\", formerly the largest employee-owned newspaper in the United States. Weeklies in the city include the Midlands Business Journal (weekly business publication); \"American Classifieds\" (formerly \"Thrifty Nickel\"), a weekly classified newspaper; \"The Reader\", as well as \"The Omaha Star\". Founded in 1938 in North Omaha, the \"Star\" is Nebraska's only African-American newspaper.\nTelevision stations and cable TV.\nOmaha's three television news stations include: KETV 7 (ABC- branded NewsWatch 7), KMTV-TV 3 (CBS- branded 3 News Now), and WOWT 6 (NBC Omaha). KPTM 42 (FOX 42/CW 15) and KXVO 15 (TBD) do not air local news content. Cox Communications provides cable television services throughout the metropolitan area. Prism TV, offered through CenturyLink, is a broadband TV option also available throughout the Omaha area. Satellite providers such as DirecTV and Dish Network and the local programming they offer are also available throughout the metropolitan area.\nInfrastructure.\nOmaha's growth has required the constant development of new urban infrastructure that influence, allow and encourage the constant expansion of the city.\nUtilities.\nRetail natural gas and water public utilities in Omaha are provided by the Metropolitan Utilities District. Nebraska is the only public power state in the nation. All electric utilities are non-profit and customer-owned. Electricity in the city is provided by the Omaha Public Power District. Public housing is governed by the Omaha Housing Authority. Metro Area Transit provides public transportation. CenturyLink and Cox provide local telephone and internet services. The City of Omaha maintains two modern sewage treatment plants.\nPortions of the Enron corporation began as Northern Natural Gas Company in Omaha. Northern provides three natural gas lines to Omaha. Enron formerly owned UtiliCorp United, Inc., which became Aquila, Inc. Peoples Natural Gas, a division of Aquila, Inc., serves several surrounding communities around the Omaha metropolitan area, including Plattsmouth.\nHealth care.\nThere are several hospitals in Omaha. Research hospitals include the Boys Town National Research Hospital, the University of Nebraska Medical Center and the Creighton University Medical Center. The Boys Town facility is well known for hearing-related research and treatment. The University of Nebraska Medical Center hosts the Eppley Institute for Research in Cancer and Allied Diseases, a world-renowned cancer treatment facility named in honor of Omahan Eugene Eppley.\nTransportation.\nOmaha's central role in the history of transportation across America earned it the nickname \"Gate City of the West\". Despite President Lincoln's decree that Council Bluffs, Iowa, be the starting point for the Union Pacific Railroad, construction began from Omaha on the eastern portion of the first transcontinental railroad. By the middle of the 20th century, nearly every major railroad served Omaha.\nToday, the Omaha Rail and Commerce Historic District celebrates this connection, along with the listing of the Burlington Train Station and the Union Station on the National Register of Historic Places. First housed in the former Herndon House, the Union Pacific Railroad's corporate headquarters have been in Omaha since the company began. Their new headquarters, the Union Pacific Center, opened in Downtown Omaha in 2004.\nAmtrak, the national passenger rail system, provides service through Omaha, with the California Zephyr serving Omaha station once daily in each direction. The intercity bus terminal is at 1601 Jackson St. in downtown Omaha. The terminal also service to Jefferson Lines, Burlington Trailways, and Express Arrow. Metro Transit, previously known as Metro Area Transit, is the local bus system.\nOmaha's position as a transportation center was finalized with the 1872 opening of the Union Pacific Missouri River Bridge that linked the transcontinental railroad to the railroads terminating in Council Bluffs. In 1888, the first road bridge, the Douglas Street Bridge, opened. In the 1890s, the Illinois Central drawbridge opened as the largest bridge of its type in the world. Omaha's Missouri River road bridges are now entering their second generation, including the Works Progress Administration-financed South Omaha Bridge, now called Veteran's Memorial Bridge, which was added to the National Register of Historic Places. In 2006, Omaha and Council Bluffs announced joint plans to build the Missouri River Pedestrian Bridge, which opened in 2008.\nThe primary mode of transportation in Omaha is by automobile, with I-80, I-480, I-680, I-29, and U.S. Route 75 (JFK Freeway and North Freeway) providing freeway service across the metropolitan area. The expressway along West Dodge Road (U.S. Route 6 and Nebraska Link 28B) and U.S. Route 275 has been upgraded to freeway standards from I-680 to Fremont. City-owned Metro Transit, formerly MAT Metro Area Transit, provides public bus service to hundreds of locations throughout the Metro.\nA 2017 study by Walk Score ranked Omaha 26th most walkable of fifty largest U.S. cities. Of the top 50 most walkable cities only one, Omaha, Nebraska, saw its Walk Score decline, and it only decreased 0.3 points from last year. There is an extensive trail system throughout the city for walkers, runners, bicyclists, and other pedestrian modes of transportation.\nOmaha is laid out on a grid plan, with 12 blocks to the mile with a north-to-south house numbering system. Omaha is the location of a historic boulevard system designed by H.W.S. Cleveland who sought to combine the beauty of parks with the pleasure of driving cars. The historic Florence and Fontenelle Boulevards, as well as the modern Sorenson Parkway, are important elements in this system. The City of Omaha has proposed the Omaha Streetcar through the city's urban core, with proposed extensions to Council Bluffs, Iowa, Eppley Airfield, North Omaha, West Omaha, and Bellevue, Nebraska.\nEppley Airfield, Omaha's airport, serves the region with over 5 million passengers in 2018. United Airlines, Southwest Airlines, Delta Air Lines, American Airlines, Alaska Airlines, Allegiant Air, Frontier Airlines, and Sun Country Airlines serve the airport with direct and connecting service. As of 2018, the airport has non-stop service to 34 destinations. General aviation airports that serve the area include the Millard Municipal Airport, North Omaha Airport and the Council Bluffs Airport. Offutt Air Force Base continues to serve as a military airbase; it is at the southern edge of Bellevue, which in turn lies immediately south of Omaha.\nSister cities.\nOmaha has eight sister cities:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46160", "revid": "1317565466", "url": "https://en.wikipedia.org/wiki?curid=46160", "title": "Accuracy in Media", "text": "Conservative American news website\nAccuracy in Media (AIM) is an American non-profit conservative news media watchdog founded in 1969 by economist Reed Irvine.\nAIM supported the Vietnam War and blamed media bias for the U.S. loss in the war. During the Reagan administration, AIM criticized reporting about the El Mozote massacre in El Salvador. During the Clinton administration, AIM pushed Vince Foster conspiracy theories. During the George W. Bush administration, AIM accused the media of bias against the Iraq War, defended the Bush administration's use of torture, and campaigned to stop the United States from signing the United Nations Convention on the Law of the Sea (UNCLOS). It described 2008 presidential candidate Barack Obama as \"the most radical candidate ever to stand at the precipice of acquiring his party's presidential nomination. It is apparent that he is a member of an international socialist movement.\" It also criticized the media's response to the COVID-19 pandemic.\nAIM, which opposes the scientific consensus on climate change, has criticized media reporting on climate change. The organization gives out the Reed Irvine Accuracy in Media Award. Past recipients include Marc Morano (who runs the climate change denial website ClimateDepot), Tucker Carlson, and Jim Hoft (founder of \"The Gateway Pundit\").\nHistory.\nAccuracy in Media (AIM) was founded in 1969 by Reed Irvine, an economist at the Federal Reserve Bank. In order to reduce what they perceive as bias in media reporting, AIM works to \"investigate complaints, take proven cases to top media officials, seek corrections and mobilize public pressure to bring about remedial action.\"\nReed Irvine and then-executive secretary Abraham Kalish sent letters to the editors of many newspapers and magazines they identified as skewed, calling out slanted news stories. If the newspaper rejected the letter, AIM bought space and printed the letter in that newspaper. Beginning in 1975, Accuracy in Media began purchasing participating interests in major media companies, allowing Irvine to attend annual shareholder meetings. He used these opportunities to express the AIM's concerns to the various companies' owners. Reed's son, Don, chairs the organization. Don Irvine referred to his father as a \"die-hard anti-communist.\" In 1990, Irvine was mentioned by Walter Goodman of \"The New York Times\" for \"his efforts to put pressure on networks and advertisers to crack down on reporters to whom he takes exception do not mark him as an enthusiast of unfettered expression.\" Following Irvine's death in 2004, an editorial in the \"Columbia Journalism Review\" said that \"[Irvine] was stone blind to his own prejudices, and he could be scurrilous and unfair in his attacks, but he knew something about our major media\" and credited Irvine in part for the rise of the popular conservative view that the American media is imbued with a liberal bias.\nAccording to \"The Washington Post\", while Irvine worked at the Federal Reserve, co-workers he would eat lunch with often \"complained that conservative points of view were not adequately reported in the media.\" In his way of changing this, Irvine formed AIM.\nIt is also said that Reed Irvine was urged to start the organization after the 1968 Democratic National Convention because he thought the mainstream media networks were overly sympathetic to antiwar protestors.\nMembership to AIM grew significantly when Reagan was president, topping 40,000 members with a budget of $1.5 million. As the organization grew, Reed Irvine was also a shareholder in media companies. During a shareholder meeting for TBS in 1989, Irvine said at the meeting that conservative leaning organizations had a difficult time getting their views presented on TBS and this was not the case for more liberal leaning groups.\nAs of April 2020,[ [update]] the current president of AIM is Adam Guillette.\nFunding.\nAIM's income in 1971 was $5,000. By the early 1980s, it was $1.5\u00a0million. In 2009, AIM received $500,000 in contributions.\nAt least eight separate oil companies are known to have been contributors in the early 80s. Only three donors are given by name: the Allied Educational Foundation (founded and chaired by George Barasch), Shelby Cullom Davis, and billionaire Richard Mellon Scaife. Scaife gave $2.2\u00a0million to Accuracy in Media between 1977 and 1998. AIM has been funded by Exxon.\nActivism.\nWar coverage.\nAIM was critical of media reports about the harmful effects of Agent Orange, a military herbicide with adverse health effects for humans, in the Vietnam War. AIM blamed the U.S. media for the loss in the Vietnam War. AIM criticized the 1983 PBS documentary series \"Vietnam: A Television History\" as being pro-communist. According to \"The New York Times\", one of AIM's greatest accomplishments was the documentary, \"Television's Vietnam: The Real Story\" in response to the PBS series.\nAIM charged the alliance conducting the NATO Kosovo intervention in 1999 with distorting the situation in Kosovo and lying about the number of civilian deaths in order to justify U.S. involvement in the conflict under the Clinton administration.\nAIM supported the Iraq War and accused the media of bias against the Iraq War in 2007, and alleged bias in mainstream media's coverage of the 2012 Benghazi attack. In 2008, AIM asserted \"Waterboarding Is Not Torture\" in a sub-heading. The article said that Guantanamo Bay detainees \"are enjoying hotel living conditions\" and that torture is what \"left-wingers associate with anything that makes an accused terrorist uncomfortable\".\nHuman rights.\nIn 1982, \"The New York Times\" reporter Raymond Bonner broke the story of the El Mozote massacre in El Salvador. The report was strongly criticized by AIM and the Reagan administration, and Bonner was pressured into business reporting, later deciding to resign.\nAIM was critical of journalist Helen Marmor, who in 1983 produced a documentary for NBC concerning the Russian Orthodox Church. AIM contended that \"it ignored the repressive religious policies of the Soviet state.\"\nVince Foster conspiracy theory.\nAIM received a substantial amount of funding from Richard Mellon Scaife who paid Christopher W. Ruddy to investigate allegations that President Bill Clinton was connected to the suicide of Vince Foster. AIM contended that \"Foster was murdered\", which is contrary to three independent reports including one by Kenneth Starr. AIM faulted the media for not picking up on the conspiracy, and applied itself for Freedom of Information Act (FOIA) disclosure of Foster's death-scene photographs. Its suit to compel disclosure was denied by the District Court of Columbia in a summary judgment, unanimously affirmed by the Court of Appeals for the District of Columbia.\nAIM credited much of its reporting on the Foster case to Ruddy. Yet, his work was called a \"hoax\" and \"discredited\" by conservatives such as Ann Coulter, it was also disputed by the \"American Spectator\", which caused Scaife to end his funding of the Arkansas Project with the publisher. As CNN explained on February 28, 1997, \"The [Starr] report refutes claims by conservative political organizations that Foster was the victim of a murder plot and coverup\", but \"despite those findings, right-wing political groups have continued to allege that there was more to the death and that the president and First Lady tried to cover it up.\"\nUnited Nations.\nAIM has been critical of the United Nations and its coverage by the media. In February 2005, AIM alleged that United Nations correspondents, including Ian Williams, a correspondent for \"The Nation\" had accepted money from the UN while covering it for their publications. AIM also asserted that the United Nations Correspondents Association may have violated immigration laws by employing the Williams' wife. Williams and \"The Nation\" denied wrongdoing.\nAIM has campaigned against the United States signing the United Nations Convention on the Law of the Sea (UNCLOS). AIM writes, \"UNCLOS is a foot in the door for a wide-ranging international agenda... America's survival as a sovereign nation hangs in the balance.\" AIM argued that signing up to UNCLOS could lead to the prohibition of spanking children.\nClimate change.\nAIM rejects the scientific consensus on climate change. In 2008, AIM wrote, \"the theory of man-made global warming is designed to increase government control over our economy and our lives through higher taxes and energy rationing.\"\nIn November 2005, AIM columnist Cliff Kincaid criticized Fox News for broadcasting a program \"The Heat is On\", which reported that global warming represents a serious problem (the program was broadcast with a disclaimer). Kincaid argued the piece was one-sided and stated that this \"scandal\" amounted to a \"hostile takeover of Fox News.\" In 2006, Kincaid criticized Fox for \"tilting to the left\" on the issue of climate change.\nAIM criticized the media for not covering a 1995 study on climate change, which it argued cast doubt on climate change. One of the authors of the study responded to AIM, \"The paper... focused on a discrepancy between observations and theoretical climate model predictions\u2014the sort of thing that climate change deniers love to take out of context and hype. The conservative organization Accuracy in Media took note of the study, citing lack of media coverage of it as some sort of evidence of media bias in coverage of climate change\u2014something that I, to this day, find puzzling as the paper actually dealt with a relatively obscure technical detail of climate models and hardly challenged the mainstream view that human activity was leading to the warming of the globe.\"\nBarack Obama.\nIn 2008, AIM described Barack Obama, who was at the time a candidate in the 2008 presidential election, as \"the most radical candidate ever to stand at the precipice of acquiring his party's presidential nomination. It is apparent that he is a member of an international socialist movement.\" AIM titled one of its reports, \"Is Barack Obama a Marxist Mole?\" In the lead-up to the 2008 election, AIM wrote, \"there is a pattern of people who hate America showing up at critical junctures in Obama's life and career to influence and advise him.\"\nCOVID-19 pandemic.\nIn March 2020, the president of AIM, Adam Guillette, took a stance on the COVID-19 pandemic outbreak, asserting that the media is exaggerating the pandemic.\nAccuracy in Media Award.\nThe organization gives out the Reed Irvine Accuracy in Media Award, which has attracted controversy for some of its recipients.\nIn 2010, AIM gave the Reed Irvine Accuracy in Media Award to political activist Marc Morano, who is known for running the website ClimateDepot, which rejects the scientific consensus on climate change.\nIn 2011, AIM gave the award to Tucker Carlson.\nIn 2013, AIM gave the Reed Irvine Accuracy in Media Award to Jim Hoft, who runs \"The Gateway Pundit\", a website renowned for publishing falsehoods and hoaxes.\nHitler truck.\nIn 2022, AIM sponsored an ad campaign against antisemitism that used a truck with a digital image of Hitler giving the Nazi salute. The image included the text: \"All in favor of banning Jews, raise your right hand.\" Several rocks were thrown at the truck. The use of the imagery was criticized by the Anti-Defamation League and the UC Berkeley chapter of Hillel International.\nAntisemitism trucks.\nIn October 2023, following the October 7 attacks, AIM initiated a controversial campaign in which they displayed the names and images of college students who had expressed support for Palestine on trucks. This event sparked significant debate and controversy around issues of free speech, privacy, and online harassment.\nOn Nov. 16, 2023, such a \"doxxing truck\" sponsored by AIM, with a three-sided digital billboard, drove through Yale's campus displaying photos and names of at least 6 Yale students, 5 of which are graduate students of color, under a banner reading \"Yale's Leading Antisemites.\" A website address printed on the side of the truck directed to a page with AIM's logo, which requested people petition Connecticut government officials and Yale to take action against those students. In late January 2024, AIM had a doxxing truck at CU Boulder in Colorado; one professor moved class online as a consequence.\nOn June 13, 2025, such a truck was parked outside Highland Hospital, in Oakland, California, displaying the name and face of a staff member, and claiming that she is a \"violent antisemite\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46163", "revid": "42935", "url": "https://en.wikipedia.org/wiki?curid=46163", "title": "Condorcet's Method", "text": ""}
{"id": "46164", "revid": "52483122", "url": "https://en.wikipedia.org/wiki?curid=46164", "title": "Classful routing", "text": ""}
{"id": "46165", "revid": "50635648", "url": "https://en.wikipedia.org/wiki?curid=46165", "title": "Charlton Heston", "text": "American actor (1923\u20132008)\nCharlton Heston (born John Charles Carter; October 4, 1923 \u2013 April 5, 2008) was an American actor. He gained stardom for his leading man roles in numerous Hollywood films including biblical epics, science-fiction films, and action films. He won an Academy Award in addition to earning nominations for three Golden Globe Awards and three Primetime Emmy Awards. He won numerous honorary accolades including the Jean Hersholt Humanitarian Award in 1978, the Golden Globe Cecil B. DeMille Award in 1967, the Screen Actors Guild Life Achievement Award in 1971, the Kennedy Center Honors in 1997, and the Presidential Medal of Freedom in 2003.\nHeston gained stardom for his leading roles as Moses in \"The Ten Commandments\" (1956) and as the title role of \"Ben-Hur\" (1959), the latter of which earned him the Academy Award for Best Actor. His other notable credits include \"The Greatest Show on Earth\" (1952), \"Secret of the Incas\" (1954), \"Touch of Evil\" (1958), \"The Big Country\" (1958), \"El Cid\" (1961), \"The Greatest Story Ever Told\" (1965), \"Khartoum\" (1966), \"Planet of the Apes\" (1968), \"Julius Caesar\" (1970), \"The Omega Man\" (1971), \"Antony and Cleopatra\" (1972), \"Soylent Green\" (1973), \"The Three Musketeers\" (1974), \"Airport 1975\" (1974), \"Earthquake\" (1974), and \"Crossed Swords\" (1978). He later acted in \"Mother Lode\" (1982), \"Tombstone\" (1993), \"True Lies\" (1994), \"Alaska\" (1996), and \"Hamlet\" (1996).\nIn the 1950s and early 1960s, he was one of a handful of Hollywood actors who openly denounced racism and he was also an active supporter of the civil rights movement. In 1987, Heston left the Democratic Party and became a Republican, founding a conservative political action committee and supporting Ronald Reagan. Heston was a five-term president of the National Rifle Association (NRA), from 1998 to 2003. After announcing that he had Alzheimer's disease in 2002, he retired from acting and the NRA presidency.\nEarly life.\nFamily.\nJohn Charles Carter was born on October 4, 1923, in Cook County, Illinois, to Lilla (n\u00e9e\u00a0Baines; 1899\u20131994) and Russell Whitford Carter (1897\u20131966), a sawmill operator. His autobiography states that he was born in Wilmette, Illinois, while most sources indicate that he was born in adjacent Evanston, Illinois. His birth certificate, registered when he was 11 days old, lists his name as Charlton Carter and records his birthplace as Evanston.\nHeston said in a 1995 interview that he was not very good at remembering addresses or his early childhood. Heston was partially of Scottish descent, including from the Clan Fraser, but the majority of his ancestry was English. His earliest colonial ancestors arrived in America from England in the 1600s. His maternal great-grandparents and namesakes were Englishman William Charlton from Sunderland and Scotswoman Mary Drysdale Charlton. They emigrated to Canada, where his grandmother, Marian Emily Charlton, was born in 1872. In his autobiography Heston refers to his father participating in his family's construction business. When Heston was an infant, his father's work moved the family to St. Helen, Michigan. It was a rural, heavily forested part of the state, and Heston lived an isolated yet idyllic existence, spending much time hunting and fishing in the backwoods of the area.\nWhen Heston was ten years old, his parents divorced after having three children. Shortly thereafter, his mother remarried and Charlton, with his younger sister Lilla and younger brother Alan, next moved to Wilmette. Heston and his two siblings took the surname of his mother's new husband. The three children attended New Trier High School, which would become the high school attended by Rock Hudson and Ann-Margret. He recalled living there, \"All kids play pretend games, but I did it more than most. Even when we moved to Chicago, I was more or less a loner. We lived in a North Shore suburb, where I was a skinny hick from the woods, and all the other kids seemed to be rich and know about girls\". Contradictions on paper and in an interview surround when \"Charlton\" became Heston's first name. His birth certificate lists his name as Charlton Carter, and the 1930 United States census record for Richfield, Michigan, in Roscommon County, shows his name as being Charlton J. Carter at age six. Later accounts and movie studio biographies say he was born John Charles Carter. When Russell Carter died in 1966, Charlton's brother and sister changed their surname from Carter to Heston the following year; Charlton did not.\nCharlton was his maternal grandmother Marian's maiden name, not his mother Lilla's. This is contrary to how 20th-century references read and what Heston said. When Heston's maternal grandmother and his biological maternal grandfather Charles Baines separated or divorced in the early 1900s, Marian (\"n\u00e9e\" Charlton) Baines married William Henry Lawton in 1907. Charlton Heston's mother, Lilla, and her sister May were adopted by their maternal grandfather and changed their last name to Charlton in order to distance themselves from their biological father, Mr. Baines, who was an undesirable father figure. The Carters divorced in 1933 and Lilla Carter married Chester Heston. The newly married Mrs. Heston preferred her children use the same last name as hers. It was thus as Charlton Heston that he appeared in his first film with younger brother Alan Carter (small role), an adaptation of Henrik Ibsen's \"Peer Gynt\" (1941). His nickname was always Chuck.\nEducation.\nHeston frequently recounted that while growing up in northern Michigan in a sparsely populated area, he often wandered in the forest, \"acting\" out characters from books he had read. Later, in high school, he enrolled in New Trier's drama program, playing the lead role in the amateur silent 16 mm film adaptation of \"Peer Gynt\", from the Ibsen play, by future film activist David Bradley released in 1941. From the Winnetka Community Theatre (or the Winnetka Dramatist's Guild, as it was then known) in which he was active, he earned a drama scholarship to Northwestern University. He attended college from 1941 to 1943 and among his acting teachers was Alvina Krause. Several years later, Heston teamed up with Bradley to produce the first sound version of William Shakespeare's \"Julius Caesar\", in which Heston played Mark Antony.\nWorld War II service.\nIn March 1944 Heston married Northwestern University student Lydia Marie Clarke at Grace Methodist Church in downtown Greensboro, North Carolina. That same year, he joined the military. Heston enlisted in the United States Army Air Forces and served for two years as a radio operator and aerial gunner aboard a B-25 Mitchell medium bomber stationed in the Alaskan Aleutian Islands with the 77th Bombardment Squadron of the Eleventh Air Force. He reached the rank of staff sergeant.\nAfter his rise to fame, Heston narrated for highly classified U.S. Armed Forces and Department of Energy instructional films, particularly relating to nuclear weapons, and \"for six years Heston [held] the nation's highest security clearance\" or Q clearance. The Q clearance is similar to a DoD or DIA clearance of top secret.\nCareer.\n1947\u20131955: Early theatre and film roles.\nAfter the war, the Hestons lived in Hell's Kitchen, New York City, where they worked as artists' models. Seeking a way to make it in theatre, they decided to manage a playhouse in Asheville, North Carolina, in 1947, making $100 a week (roughly ). In 1948, they returned to New York, where Heston was offered a supporting role in a Broadway revival of Shakespeare's \"Antony and Cleopatra\", starring Katharine Cornell. In television, Heston played a number of roles in CBS's \"Studio One\", one of the most popular anthology dramas of the 1950s. In 1949 Heston played Mark Antony in an independent film adaptation of \"Julius Caesar\" (1950). Film producer Hal B. Wallis spotted Heston in a 1950 television production of \"Wuthering Heights\" and offered him a contract. When his wife reminded Heston they had decided to pursue theater and television, he replied, \"Well, maybe just for one film to see what it's like.\"\nHeston's first professional movie appearance was the leading role at age 26 in \"Dark City\", a 1950 film noir produced by Hal Wallis. His breakthrough came when Cecil B. DeMille cast him as a circus manager in \"The Greatest Show on Earth\", which was named by the Motion Picture Academy as the Best Picture of 1952. It was also the most popular movie of that year. King Vidor used Heston in a melodrama with Jennifer Jones, \"Ruby Gentry\" (1952). He followed it with a Western at Paramount, \"The Savage\" (1952), playing a white man raised by Indians. 20th Century Fox used him to play Andrew Jackson in \"The President's Lady\" (1953) opposite Susan Hayward. Back at Paramount he was Buffalo Bill in \"Pony Express\" (1953). He followed this with another Western, \"Arrowhead\" (1953).\nIn 1953, Heston was Billy Wilder's first choice to play Sefton in \"Stalag 17\". However, the role was given to William Holden, who won an Oscar for it. Hal Wallis reunited Heston with Lizabeth Scott in a melodrama \"Bad for Each Other\" (1953). In 1954, he made two adventure films for Paramount Pictures. \"The Naked Jungle\" had him battle a plague of killer ants. He played the lead in \"Secret of the Incas\", which was shot on location at the archeological site Machu Picchu and has numerous similarities to \"Raiders of the Lost Ark\", which appeared a quarter of a century later. Heston played William Clark, the explorer, in \"The Far Horizons\" (1955) alongside Fred MacMurray as Meriwether Lewis. He tried a comedy \"The Private War of Major Benson\" (1955) at Universal, then supported Jane Wyman in a drama \"Lucy Gallant\" (1955).\nHeston became an icon for playing Moses in the hugely successful biblical epic \"The Ten Commandments\" (1956), selected by director Cecil B. DeMille, who thought Heston bore an uncanny resemblance to Michelangelo's statue of Moses. DeMille cast Heston's three-month-old son, Fraser Clarke Heston, as the infant Moses. \"The Ten Commandments\" became one of the greatest box office successes of all time and is the eighth-highest-grossing film adjusted for inflation. His portrayal of the Hebrew prophet and deliverer was praised by film critics. \"The Hollywood Reporter\" described him as \"splendid, handsome and princely (and human) in the scenes dealing with him as a young man, and majestic and terrible as his role demands it\". The \"New York Daily News\" wrote that he \"is remarkably effective as both the young, princely Moses and as the Patriarchal savior of his people\". His performance as Moses earned him his first nomination for the Golden Globe Award for Best Actor \u2013 Motion Picture Drama and Spain's Fotogramas de Plata Award for Best Foreign Performer. When the Egyptian Theater reopened in December 1998, it screened Cecil B. DeMille's 1923 original \"The Ten Commandments\", which had premiered there 75 years earlier. Charlton and Lydia Heston were honored guests at this opening showing and were seated with their longtime friends, brothers Charles Elias Disney and Daniel H. Disney.\nHeston went back to Westerns with \"Three Violent People\" (1957). Universal tried to interest him in a thriller starring Orson Welles, \"Touch of Evil\"; Heston agreed to be in it if Welles directed. The film has come to be regarded as a classic masterpiece. He also played a rare supporting role in William Wyler's \"The Big Country\" opposite Gregory Peck and Burl Ives. Heston got another chance to play Andrew Jackson in \"The Buccaneer\" (1958), produced by De Mille and starring Yul Brynner.\n1956\u20131967: Film stardom.\nAfter Marlon Brando, Burt Lancaster, and Rock Hudson turned down the title role in \"Ben-Hur\" (1959), Heston accepted the role, winning the Academy Award for Best Actor, one of the unprecedented 11 Oscars the film earned. After Moses and \"Ben-Hur\", Heston became more identified with Biblical epics than any other actor. He later voiced Ben-Hur in an animated television production of the Lew Wallace in 2003. Heston followed it with \"The Wreck of the Mary Deare\" (1959) co-starring Gary Cooper, which was a box office disappointment.\nHeston turned down the lead opposite Marilyn Monroe in \"Let's Make Love\" to appear in Benn W. Levy's play \"The Tumbler\", directed by Laurence Olivier. Called a \"harrowingly pretentious verse drama\" by \"Time\", the production went through a troubled out-of-town tryout period in Boston and closed after five performances on Broadway in February 1960. Heston, a great admirer of Olivier the actor, took on the play to work with him as a director. After the play flopped, Heston told columnist Joe Hyams, \"I feel I am the only one who came out with a profit.\u00a0... I got out of it precisely what I went in for\u2014a chance to work with Olivier. I learned from him in six weeks things I never would have learned otherwise. I think I've ended up a better actor.\"\nHeston enjoyed acting on stage, believing it revivified him as an actor. He never returned to Broadway but acted in regional theatres. His most frequent stage roles included the title role in \"Macbeth\", and Mark Antony in both \"Julius Caesar\" and \"Antony and Cleopatra\". Heston considered himself to be a Shakespearean actor and collected significant works by and about William Shakespeare. He played Sir Thomas More in \"A Man for All Seasons\" in several regional productions in the 1960s, 1970s and 1980s, eventually playing it in London's West End. The play was a success and the West End production was taken to Aberdeen, Scotland, for a week, where it was staged at His Majesty's Theatre. Samuel Bronston pursued Heston to play the title role in an epic shot in Spain, \"El Cid\" (1961), which was a big success. He was in a war film for Paramount, \"The Pigeon That Took Rome\" (1962), and a melodrama shot in Hawaii, \"Diamond Head\" (1963). Bronston wanted him for another epic and the result was \"55 Days at Peking\" (1963), which was a box office disappointment.\nHeston focused on epics: he was John the Baptist in \"The Greatest Story Ever Told\" (1965); Michelangelo in \"The Agony and the Ecstasy\" (1965) opposite Rex Harrison; the title role in \"Major Dundee\" (1965), directed by Sam Peckinpah. \"The War Lord\" (1965), directed by Franklin J. Schaffner, was on a smaller scale and critically acclaimed, though commercially it fared poorly. In \"Khartoum\" (1966) Heston played General Charles Gordon. From 1965 until 1971, Heston served as president of the Screen Actors Guild. The Guild had been created in 1933 for the benefit of actors, who had different interests from the producers and directors who controlled the Academy of Motion Picture Arts and Sciences. He was more conservative than most actors and publicly clashed with outspoken liberal actors such as Ed Asner. \"Counterpoint\" (1968) was a war film that was not particularly successful at the box office. Neither was the Western \"Will Penny\" (1968), directed by Tom Gries; however, Heston received excellent reviews and it was one of his favorite films.\n1968\u20131976: Established star.\nHeston had not been in a big hit for a number of years but in 1968 he starred in \"Planet of the Apes\", directed by Schaffner, which was hugely popular. Less so was a football drama, \"Number One\" (1969) directed by Gries. Heston had a smaller supporting role in \"Beneath the Planet of the Apes\" (1970), which was popular. However, \"The Hawaiians\" (1970), directed by Gries, was not. In 1970, he portrayed Mark Antony again in another film version of Shakespeare's \"Julius Caesar\". His co-stars included Jason Robards as Brutus, Richard Chamberlain as Octavius, Robert Vaughn as Casca, and English actors Richard Johnson as Cassius, John Gielgud as Caesar, and Diana Rigg as Portia.\nIn 1971, he starred in the post-apocalyptic science-fiction film \"The Omega Man\", which has received mixed critical reviews, but was popular, and has become a cult film in the years since release. It was also during this time he became a gun rights advocate. In 1972, Heston made his directorial debut and starred as Mark Antony in an adaptation of the William Shakespeare play he had performed earlier in his theater career, \"Antony and Cleopatra\". Hildegarde Neil was Cleopatra and English actor Eric Porter was Ahenobarbus. After receiving scathing reviews, the film was never released to theaters and is rarely seen on television.\nHis next film, \"Skyjacked\" (1972) was a hit. However \"The Call of the Wild\" (1972) was a flop, one of Heston's least favorite films. He quickly recovered with a string of box office hits: \"Soylent Green\" (1973), another dystopian science fiction film that has since achieved cult status; \"The Three Musketeers\" (1973), playing Cardinal Richelieu as part an all-star cast ensemble; two back-to-back disaster films, the hugely successful \"Earthquake\" (1974), and \"Airport 1975\" (1974), also a success; and \"Midway\" (1976) a war film, also a box office hit.\n1977\u20132000: Later film roles.\nHeston's long run as a box office draw effectively ended with \"Two-Minute Warning\" (1976), a suspense film, and \"The Last Hard Men\" (1976), a Western. He played King Henry VIII for \"The Prince and the Pauper\" (1977) from the \"Musketeers\" team, then starred in a disaster-suspense film \"Gray Lady Down\" (1978). Heston was in a Western written by his son, \"The Mountain Men\" (1980), and a horror film, \"The Awakening\" (1980). He made his second film as a director, \"Mother Lode\" (1982), also written by his son, and it was a commercial disappointment.\nFrom 1985 until 1987, he starred in his only prime time stint on a television series in the soap \"The Colbys\". With his son Fraser, he produced and starred in several TV movies, including remakes of \"Treasure Island\" and \"A Man for All Seasons\". In 1992, Heston appeared on the A&amp;E cable network in a short series of videos, \"Charlton Heston Presents the Bible\", reading passages from the King James version. \nIn 1993, Heston teamed with John Anthony West and Robert M. Schoch in an Emmy Award-winning NBC special, \"The Mystery of the Sphinx\". West and Schoch had proposed a much earlier date for the construction of the Great Sphinx than the one which is generally accepted. They had suggested that the main type of weathering evident on the Great Sphinx and surrounding enclosure walls could only have been caused by prolonged and extensive rainfall and that the whole structure was carved out of limestone bedrock by an ancient advanced culture (such as the Heavy Neolithic Qaraoun culture). Never taking himself too seriously, Heston also made several appearances as \"Chuck\" in Dame Edna Everage's shows, both on stage and on television. Heston appeared in 1993 in a cameo role in \"Wayne's World 2\" in a scene where Wayne Campbell (Mike Myers) requests casting a better actor for a small role. After the scene is reshot with Heston, Campbell weeps in awe. That same year, Heston hosted \"Saturday Night Live\". He had cameos in the films \"Hamlet\", \"Tombstone\", and \"True Lies\".\nHeston starred in many theatrical productions at the Los Angeles Music Center, where he appeared in \"Detective Story\", \"The Caine Mutiny Court-Martial\", and as Sherlock Holmes in \"The Crucifer of Blood\" opposite Richard Johnson as Dr. Watson. In 2001, he made a cameo appearance as an elderly dying chimpanzee in Tim Burton's remake of \"Planet of the Apes\". His last film role was as Josef Mengele in \"\", which had limited release (mainly to festivals) in 2003. Heston's distinctive voice landed him roles as a film narrator, including the opening scenes of \"Armageddon\" and Disney's \"Hercules\". He played the title role in \"Mister Roberts\" three times and cited it as one of his favorite roles. In the early 1990s, he tried unsuccessfully to revive and direct the show with Tom Selleck in the title role. In 1998, Heston had a cameo role playing himself in the American television series \"Friends\" in the episode \"The One with Joey's Dirty Day\". In 2000, he played Chief Justice Haden Wainwright in \"The Outer Limits\" episode \"Final Appeal\".\nActing credits and accolades.\nRichard Corliss wrote in \"Time\" magazine, \"From start to finish, Heston was a grand, ornery anachronism, the sinewy symbol of a time when Hollywood took itself seriously, when heroes came from history books, not comic books. Epics like \"Ben-Hur\" or \"El Cid\" simply couldn't be made today, in part because popular culture has changed as much as political fashion. But mainly because there's no one remotely like Charlton Heston to infuse the form with his stature, fire, and guts.\" In his obituary for the actor, film critic Roger Ebert noted, \"Heston made at least three movies that almost everybody eventually sees: \"Ben-Hur\", \"The Ten Commandments\" and \"Planet of the Apes\".\" Heston's cinematic legacy was the subject of \"Cinematic Atlas: The Triumphs of Charlton Heston\", an 11-film retrospective by the Film Society of the Lincoln Center that was shown at the Walter Reade Theatre from August 29 to September 4, 2008.\nOn April 17, 2010, Heston was inducted into the National Cowboy and Western Heritage Museum's Hall of Great Western Performers. In his childhood hometown of St. Helen, Michigan, a charter (independent) school, Charlton Heston Academy, opened on September 4, 2012. It is housed in the former St. Helen Elementary School. Enrollment on the first day was 220 students in grades kindergarten through eighth.\nCharlton Heston was commemorated on a United States postage stamp issued on April 11, 2014. Charlton Heston was inducted as a Laureate of the Lincoln Academy of Illinois and awarded the Order of Lincoln (the State's highest honor) by Illinois Governor James R. Thompson in 1977 in the area of Performing Arts.\nPolitical views.\nHeston's political activism had four stages. In the first stage, 1955\u20131961, he endorsed liberal Democratic candidates for president and signed on to petitions for liberal political causes. From 1961 until 1972, the second stage, he continued to endorse Democratic candidates for president. Moving beyond Hollywood, he became nationally visible in 1963 in support of the Civil Rights Act of 1964. From 1965 until 1971, he served as the elected President of the Screen Actors Guild and clashed with his liberal rival Ed Asner. In 1968, he helped publicize gun control measures when he joined fellow Hollywood stars in support of the Gun Control Act of 1968.\nThe third stage began in 1972. Heston rejected the liberalism of George McGovern and supported Republican Richard Nixon in 1972 for president. In the 1980s, he gave strong support to Ronald Reagan during his conservative presidency. In 1995, Heston entered his fourth stage by establishing his own political action fund-raising committee and jumped into the internal politics of the National Rifle Association. He gave numerous culture wars speeches and interviews upholding the conservative position, blaming media and academia for imposing affirmative action, which he saw as unfair reverse discrimination.\nCivil rights advocate.\nHeston campaigned for presidential candidate Adlai Stevenson in 1956, although he was unable to campaign for John F. Kennedy in 1960 because he was filming \"El Cid\" in Spain. Reportedly, when a segregated Oklahoma movie theater was showing his movie \"El Cid\" for the first time in 1961, he joined a picket line outside the movie theater. Heston made no reference to this incident in his autobiography but he described traveling to Oklahoma City to picket segregated restaurants, to the chagrin of the producers of \"El Cid\", Allied Artists. During the March on Washington for Jobs and Freedom held in Washington, D.C., in 1963, he accompanied Martin Luther King Jr. In later speeches, he said he helped the civil rights cause \"long before Hollywood found it fashionable\".\nIn the 1964 election, he endorsed Lyndon B. Johnson, who had masterminded the passage of the Civil Rights Act of 1964 through Congress over the vociferous opposition of southern Democrats. That year, Heston publicly opposed California Proposition 14 that rolled back the state's fair housing law, the Rumford Fair Housing Act.86\nConservative beliefs.\nIn his 1995 autobiography, \"In the Arena\", written after he became a conservative Republican, Heston wrote that while driving back from the set of \"The War Lord\", he saw a \"Barry Goldwater for President\" billboard with his campaign slogan \"In Your Heart You Know He's Right\" and thought to himself, \"Son of a bitch, he is right.\" Heston later said that his support for Goldwater was the event that helped turn him against gun control laws. Following the assassination of Senator Robert F. Kennedy in 1968, Heston, Gregory Peck, Kirk Douglas, and James Stewart issued a statement in support of President Johnson's Gun Control Act of 1968. The Johnson White House had solicited Heston's support. He endorsed Hubert Humphrey in the 1968 presidential election.\nVietnam war.\nHeston opposed the Vietnam War during its course (though he changed his opinion in the years following the war) and in 1969 was approached by the Democratic Party to run for the U.S. Senate against incumbent George Murphy. He agonized over the decision but ultimately determined he could never give up acting. He supported Richard Nixon in 1972, though Nixon is not mentioned in his autobiography.\nGun rights.\nBy the 1980s, Heston supported gun rights and changed his political affiliation from Democratic to Republican. When asked why he changed political alliances, Heston replied \"I didn't change. The Democratic Party changed.\" In 1987, he first registered as a Republican. He campaigned for Republicans and Republican presidents Ronald Reagan, George H. W. Bush, and George W. Bush.\nCulture war.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n \"the God-fearing, law-abiding, Caucasian, middle-class Protestant\u2014or even worse, evangelical Christian, Midwestern or Southern\u2014or even worse, rural, apparently straight\u2014or even worse, admitted heterosexuals, gun-owning\u2014or even worse, NRA card-carrying, average working stiff\u2014or even worse, male working stiff\u2014because, not only don't you count, you are a down-right obstacle to social progress. Your voice deserves a lower decibel level, your opinion is less enlightened, your media access is insignificant; and frankly, mister, you need to wake up, wise up, and learn a little something from your new America; and until you do, would you mind shutting up?\"\n\u2014Heston, \"Fighting the Culture War in America\" speech (1997) \nHeston resigned in protest from Actors Equity, saying the union's refusal to allow a white actor to play a Eurasian role in \"Miss Saigon\" was \"obscenely racist\". Heston charged that CNN's telecasts from Baghdad were \"sowing doubts\" about the allied effort in the 1990\u20131991 Gulf War. At a Time Warner stockholders' meeting, Heston castigated the company for releasing an Ice-T album which included a song \"Cop Killer\" about killing police officers. While filming \"The Savage\", Heston was initiated by blood into the Miniconjou Lakota Nation, saying that he had no natural American Indian heritage, but elected to be \"Native American\" to salvage the term from exclusively referring to American Indians.\nIn Heston's 1997 speech, called \"Fighting the Culture War in America\", Heston rhetorically deplored a culture war he said was being conducted by a generation of media people, educators, entertainers, and politicians. He stated, \"The Constitution was handed down to guide us by a bunch of wise old dead white guys who invented our country! Now some flinch when I say that. Why! It's true\u00a0... they were white guys! So were most of the guys that died in Lincoln's name opposing slavery in the 1860s. So why should I be ashamed of white guys? Why is \"Hispanic Pride\" or \"Black Pride\" a good thing, while \"White Pride\" conjures shaven heads and white hoods? Why was the Million Man March on Washington celebrated by many as progress, while the Promise Keepers March on Washington was greeted with suspicion and ridicule? I'll tell you why: Cultural warfare!\" In an address to students at Harvard Law School entitled \"Winning the Cultural War\", Heston said, \"If Americans believed in political correctness, we'd still be King George's boys\u2014subjects bound to the British crown.\"\n He said to the students: \"You are the best and the brightest. You, here in this fertile cradle of American academia, here in the castle of learning on the Charles River. You are the cream. But I submit that you and your counterparts across the land are the most socially conformed and politically silenced generation since Concord Bridge. And as long as you validate that and abide it, you are, by your grandfathers' standards, cowards\". During a speech at Brandeis University, he stated, \"Political correctness is tyranny with manners\". In a speech to the National Press Club in 1997, Heston said, \"Now, I doubt any of you would prefer a rolled up newspaper as a weapon against a dictator or a criminal intruder.\"\nNRA president.\nHeston was the ceremonial president and spokesman of the NRA from 1998 until his resignation in 2003. At the 2000 NRA convention, he raised a rifle over his head and declared that he would not allow a potential Al Gore administration to take away his Second Amendment rights except \"from my cold, dead hands\". In announcing his resignation from the presidency in 2003, he again raised a rifle over his head, repeating the words of his 2000 speech.\nIn the 2002 film \"Bowling for Columbine\", Michael Moore interviewed Heston at Heston's home, asking him about an April 1999 meeting the NRA held in Denver, Colorado, shortly after the Columbine High School massacre. Moore criticized Heston for the perceived thoughtlessness in the timing and location of the meeting. When Moore asked Heston for his thoughts on why gun-related homicide is so much higher in the United States than in other countries, Heston said it was because, \"we have probably more mixed ethnicity\" and that \"we have a history of violence, perhaps more than most countries\". Heston subsequently excused himself on-camera and walked away, and Moore was later criticized by some for having conducted the interview as an ambush. The interview was conducted early in 2001 before Heston publicly announced his Alzheimer's diagnosis, but the film was released afterward, causing some to say that Moore should have cut the interview from the final film.\nIraq war.\nIn April 2003, he sent a message of support to the American forces in the Iraq War, attacking opponents of the war as \"pretend patriots\".\nAbortion views.\nHeston opposed abortion and introduced Bernard Nathanson's 1987 anti-abortion documentary, \"Eclipse of Reason\", which focuses on late-term abortions. Heston served on the advisory board of Accuracy in Media, a conservative media watchdog group founded by Reed Irvine.\nPersonal life.\nIn March 1944, Heston married Northwestern University student Lydia Marie Clarke at Grace Methodist Church in downtown Greensboro, North Carolina.\nHeston was an Episcopalian, and he has been described as \"a spiritual man\" with an \"earthy flair\", who \"respected religious traditions\" and \"particularly enjoyed the historical aspects of the Christian faith\".\nIllness and death.\nIn 1996, Heston received a hip replacement. He was diagnosed with prostate cancer in 1998. Following a course of radiation treatment, the cancer went into remission. In 2000, he publicly disclosed that he had been treated for alcoholism at a Utah clinic in May\u2013June of that year.\nOn August 9, 2002, he publicly announced (via a taped message) that he had been diagnosed with symptoms which are consistent with Alzheimer's disease. In July 2003, in his final public appearance, Heston received the Presidential Medal of Freedom at the White House from President George W. Bush. In March 2005, various newspapers reported that family and friends were shocked by the progression of his illness and that he was sometimes unable to get out of bed.\nHeston died on the morning of April 5, 2008, at his home in Beverly Hills, California, with Lydia, his wife of 64 years, by his side. He was 84 years old. Heston was also survived by their son, Fraser Clarke Heston, and their daughter, Holly Ann Heston. The cause of Heston's death was not disclosed by his family. A month later, media outlets reported his death was due to pneumonia.\nEarly tributes came in from leading figures; President George W. Bush called Heston \"a man of character and integrity, with a big heart\u00a0... He served his country during World War II, marched in the civil rights movement, led a labor union and vigorously defended Americans' Second Amendment rights.\" Former First Lady Nancy Reagan said that she was \"heartbroken\" over Heston's death and released a statement, reading, \"I will never forget Chuck as a hero on the big screen in the roles he played, but more importantly I considered him a hero in life for the many times that he stepped up to support Ronnie in whatever he was doing.\"\nHeston's funeral was held a week later on April 12, 2008, in a ceremony which was attended by 250 people including Nancy Reagan and Hollywood stars such as California Governor Arnold Schwarzenegger, Olivia de Havilland, Keith Carradine, Pat Boone, Tom Selleck, Oliver Stone (who had cast Heston in his 1999 movie \"Any Given Sunday\"), Rob Reiner, and Christian Bale.\nThe funeral was held at Episcopal Parish of St. Matthew's Church in Pacific Palisades, the church where Heston had regularly worshipped and attended Sunday services since the early 1980s. He was cremated and his ashes were given to his family.\nBibliography.\nBy Heston:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46166", "revid": "18024", "url": "https://en.wikipedia.org/wiki?curid=46166", "title": "Classless routing", "text": ""}
{"id": "46168", "revid": "14383484", "url": "https://en.wikipedia.org/wiki?curid=46168", "title": "Indian Space Research Organisation", "text": ""}
{"id": "46169", "revid": "50982237", "url": "https://en.wikipedia.org/wiki?curid=46169", "title": "Lucca", "text": "City and comune in Tuscany, Italy\nLucca ( , ) is a city and \"comune\" in Tuscany, Central Italy, on the Serchio River, in a fertile plain near the Ligurian Sea. The city has a population of about 89,000, while its province has a population of 383,957.\nLucca is known as an Italian \"Citt\u00e0 d'arte\" (City of Art) from its intact Renaissance-era city walls and its very well preserved historic center, where, among other buildings and monuments, are located the Piazza dell'Anfiteatro, which has its origins in the second half of the 1st century A.D., the Guinigi Tower, a tower that dates from the 14th century and the Cathedral of San Martino.\nThe city is the birthplace of numerous world-class composers, including Giacomo Puccini, Alfredo Catalani, and Luigi Boccherini.\nToponymy.\nTo the Ancient Romans, Lucca was known as \"Luca\". From more recent and concrete toponymic studies, the name Lucca has references that lead to \"sacred grove\" (Latin: \"lucus\"), \"to cut\" (Latin: \"lucare\") and \"luminous space\" (\"leuk\", a term used by the first European populations). The origin apparently refers to a wooded area deforested to make room for light or to a clearing located on a river island of Serchio debris, in the middle of wooded areas.\nHistory.\nAntiquity.\nThe territory of present-day Lucca was certainly settled by the Etruscans, and it also has traces of a probable earlier Ligurian presence (called \"Luk\" meaning \"marsh\", which was previously speculated as a possible origin of the city's name), dating from the 3rd century BC. However, it was only with the arrival of the Romans that the area took on the appearance of a real town. It obtained the status of a Roman colony in 180 BC and of a municipality (municipium) in 89 BC.\nThe rectangular grid of its historical centre preserves the Roman street plan, and the Piazza San Michele occupies the site of the ancient forum. The outline of the Roman amphitheatre is still seen in the Piazza dell'Anfiteatro, and the outline of a Roman theater is visible in Piazza Sant'Agostino. Fragments of the Roman-era walls are incorporated into the church of Santa Maria della Rosa.\nAt the Lucca Conference, in 56 BC, Julius Caesar, Pompey, and Crassus reaffirmed their political alliance known as the First Triumvirate.\nMiddle Ages.\nFrediano, an Irish monk, was bishop of Lucca in the early sixth century. At one point, Lucca was plundered by Odoacer, the first Germanic king of Italy. Lucca was an important city and fortress even in the sixth century, when Narses besieged it for several months in 553. From 576 to 797, under the Lombards, it was the capital of a duchy, known as Duchy of Tuscia, which included a large part of today's Tuscany and the province of Viterbo; during this time the city also minted its own coins. The Holy Face of Lucca (or Volto Santo), a major relic supposedly carved by Nicodemus, arrived in 742.\nAmong the population that inhabited Lucca in the medieval era, there was also a significant presence of Jews. The first mention of their presence in the city is from a document from the year 859. The Jewish community was led by the Kalonymos family (which later became a major component of proto-Ashkenazic Jewry).\nThanks above all to the Holy Face and to the relics of important saints, such as and Saint Fridianus, the city was one of the main destinations of the Via Francigena, the major pilgrimage route to Rome from the north.\nLucca cloth was a silk fabric that was woven with gold or silver threads. It was a popular type of textile in Lucca throughout the mediaeval period.\nLucca became prosperous through the silk trade that began in the eleventh century, and came to rival the silks of Byzantium. During the tenth\u2013eleventh centuries Lucca was the capital of the feudal margraviate of Tuscany, more or less independent but owing nominal allegiance to the Holy Roman emperor.\nIn 1057, Anselm of Baggio (later Pope Alexander II) was appointed bishop of Lucca, a position he held also during the papacy. As bishop of Lucca he managed to rebuild the patrimony of the Church of Lucca, recovering alienated assets and obtaining numerous donations thanks to his prestige, and had the Cathedral of the city rebuilt. From 1073 to 1086, the bishop of Lucca was his nephew Anselm II, a prominent figure in the Investiture Controversy.\nDuring the High Middle Ages, one of the most illustrious dynasties of Lucca was the noble Allucingoli family, which managed to forge strong ties with the Church. Among the family members were Ubaldo Allucingoli, who was elected to the Papacy as Pope Lucius III in 1181, and the Cardinals Gerardo Allucingoli and Uberto Allucingoli.\nRepublican period (12th to 19th century).\nAfter the death of Matilda of Tuscany, the city began to constitute itself an independent commune with a charter in 1160. For almost 500 years, Lucca remained an independent republic. There were many minor provinces in the region between southern Liguria and northern Tuscany dominated by the Malaspina; Tuscany in this time was a part of feudal Europe. Dante's \"Divine Comedy\" includes many references to the great feudal families who had huge jurisdictions with administrative and judicial rights. Dante spent some of his exile in Lucca.\nIn 1273 and again in 1277, Lucca was ruled by a Guelph \"capitano del popolo\" (captain of the people) named Luchetto Gattilusio. In 1314, internal discord allowed Uguccione della Faggiuola of Pisa to make himself lord of Lucca. The Lucchesi expelled him two years later, and handed over the city to another \"condottiero\", Castruccio Castracani, under whose rule it became a leading state in central Italy. Lucca rivalled Florence until Castracani's death in 1328. On 22 and 23 September 1325, in the battle of Altopascio, Castracani defeated Florence's Guelphs. For this he was nominated by Louis IV the Bavarian to become duke of Lucca. Castracani's tomb is in the church of San Francesco. His biography is Machiavelli's third famous book on political rule.\nOccupied by the troops of Louis of Bavaria, the city was sold to a rich Genoese, Gherardino Spinola, then seized by John, king of Bohemia. Pawned to the Rossi of Parma, by them it was ceded to Mastino II della Scala of Verona, sold to the Florentines, surrendered to the Pisans, and then nominally liberated by the emperor Charles IV and governed by his vicar.\nIn 1408, Lucca hosted a convocation organized by Pope Gregory XII with his cardinals intended to end the schism in the papacy.\nLucca managed, at first as a democracy, and after 1628 as an oligarchy, to maintain its independence alongside of Venice and Genoa, and painted the word \"Libertas\" on its banner until the French Revolution in 1789.\nEarly modern period.\nLucca had been the second largest Italian city state (after Venice) with a republican constitution (\"comune\") to remain independent over the centuries.\nBetween 1799 and 1800, it was contested by the French and Austrian armies. Finally the French prevailed and granted a democratic constitution in the 1801. However, already in 1805 the Republic of Lucca was converted into a monarchy by Napoleon, who installed his sister Elisa Bonaparte Baciocchi as \"Princess of Lucca\".\nFrom 1815 to 1847, it was a Bourbon-Parma duchy. The only reigning dukes of Lucca were Maria Luisa of Spain, and her son Charles II, Duke of Parma, who succeeded her in 1824. Meanwhile, the Duchy of Parma had been assigned for life to Marie Louise, Duchess of Parma, the second wife of Napoleon. In accordance with the Treaty of Vienna (1815), upon the death of Marie Louise, Duchess of Parma in 1847, Parma reverted to Charles II, Duke of Parma, while Lucca lost independence and was annexed to the Grand Duchy of Tuscany. As part of Tuscany, it became part of the Kingdom of Sardinia in 1860 and finally part of the Italian State in 1861.\nWorld War II internment camp.\nIn 1942, during World War II, a prisoner-of-war camp was established at the village of Colle di Compito, in the municipality of Capannori, about from Lucca. Its official number was P.G. (\"prigionieri di guerra\") 60, and it was usually referred to as PG 60 Lucca. Although it never had permanent structures and accommodation consisted of tents in an area prone to flooding, it housed more than 3,000 British and Commonwealth prisoners of war during the period of its existence. It was handed over to the Germans on 10 September 1943, not long after the signing of the Italian armistice. During the Italian Social Republic, as a puppet state of the Germans, political prisoners, foreigners, common law prisoners and Jews were interned there, and it functioned as a concentration camp. In June 1944, the prisoners were moved to Bagni di Lucca.\nPopulation.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nCulture.\nLucca is the birthplace of composers Giacomo Puccini (\"La Boh\u00e8me\" and \"Madama Butterfly\"), Nicolao Dorati, Francesco Geminiani, Gioseffo Guami, Luigi Boccherini, and Alfredo Catalani. It is also the birthplace of artist Benedetto Brandimarte. Since 2004, Lucca is home to IMT Lucca, a public research institution and a selective graduate school and part of the Superior Graduate Schools in Italy (\"Grandes \u00e9coles\").\nEvents.\nLucca hosts the annual Lucca Summer Festival. The 2006 edition featured live performances by Eric Clapton, Placebo, Massive Attack, Roger Waters, Tracy Chapman, and Santana at the Piazza Napoleone. For the 2025 edition, Riccardo Cocciante is scheduled to perform, while the 2026 lineup features Jamiroquai on 4 July, Alabama Shakes with special guest Matt Berninger on 7 July, Katy Perry on 19 July, and Marcus Miller with the tribute show \u201cWe Want Miles!\u201d on 21 July.\nLucca hosts the annual Lucca Comics and Games festival, Europe's largest festival for comics, movies, games and related subjects.\nOther events include:\nMoreover, Lucca hosts Lucca Biennale Cartasia, an international biennial contemporary art exhibition focusing solely on Paper Art.\nFilm and television.\nMauro Bolognini's 1958 film \"Giovani mariti\", with Sylva Koscina, is set and was filmed in Lucca.\nSergio Martino's 1993 miniseries \"Private Crimes\", starring Edwige Fenech, is set and was filmed in Lucca.\n\"Top Gear\" filmed a segment of the second episode of its 17th series here.\nArchitecture.\nLucca is also known for its marble deposits. After a fire in the early 1900s, the West Wing of the Legislative Assembly of Ontario was rebuilt with marble sourced in Lucca. The floor mosaic in the West Wing was hand-laid and is constructed entirely of Italian, Lucca marble.\nMain sights.\nWalls, streets, and squares.\nThe walls encircling the old town remain intact, even though the city has expanded and been modernised, which is unusual for cities in this region. These walls were built initially as a defensive rampart which, after losing their military importance, became a pedestrian promenade (the Passeggiata delle Mure Urbane) atop the walls which not only links the Bastions of Santa Croce, San Frediano, San Martino, San Pietro/Battisti, San Salvatore, La Libert\u00e0/Cairoli, San Regolo, San Colombano, Santa Maria, San Paolino/Catalani and San Donato but also passes over the gates (Porte) of San Donato, Santa Maria, San Jacopo, Elisa, San Pietro, and Sant'Anna. Each of the four principal sides of the structure is lined with a tree species different from the others.\nThe walled city is encircled by Piazzale Boccherini, Viale Lazzaro Papi, Viale Carlo Del Prete, Piazzale Martiri della Libert\u00e0, Via Batoni, Viale Agostino Marti, Viale G. Marconi (\"vide\" Guglielmo Marconi), Piazza Don A. Mei, Viale Pacini, Viale Giusti, Piazza Curtatone, Piazzale Ricasoli, Viale Ricasoli, Piazza Risorgimento (\"vide\" Risorgimento), and Viale Giosu\u00e8 Carducci.\nThe town includes a number of public squares, most notably the Piazza dell'Anfiteatro, (site of the ancient Roman amphitheater), the Piazzale Verdi, the Piazza Napoleone, and the Piazza San Michele.\nChurches.\nThere are many medieval, some as old as the 8th century, basilica-form churches in Lucca, characterized by richly arcaded fa\u00e7ades and campaniles.\nEducation.\nSince 2005, Lucca hosts IMT School for Advanced Studies Lucca, a selective graduate and doctoral school which is part of the Italian superior graduate school system. Its main educational facilities are located at the San Francesco Convent Complex and Campus, and the former Renaissance-style Roman Catholic church of San Ponziano now hosts the university library.\nSports.\nAssociation football arrived in Lucca in 1905 and has its roots in Brazil, thanks to a number of fans that helped found the club who had learned the game in Brazil. The Lucchese 1905, or simply Lucchese, plays in Serie C, the third tier of Italian football, having last been in top tier Serie A in 1952. The club plays its home games at Stadio Porta Elisa, just outside the northeast wall of the city.\nTransportation.\nBuses.\nConsorzio Lucchese Autotrasporti Pubblici, also known as CLAP, was established in 1969, as the main company in the Province of Lucca to manage the local public transport. In 2005, following the decision of the Region to assign the local public transport to a single operator for each of the 14 lots constituted, CLAP merged with the companies Lazzi and C.LU.B. Scpa to form the consortium VaiBus which was absorbed by the newly formed company CTT Nord in 2012. VaiBus was part of ONE Scarl the consortium holder of the two-year (2018-2019) contract for the management of the TPL throughout the Region.\nSince 1 November 2021 the public local transport is managed by Autolinee Toscane.\nNotable people.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSister cities.\nLucca is twinned with:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46171", "revid": "49653432", "url": "https://en.wikipedia.org/wiki?curid=46171", "title": "Crisps", "text": ""}
{"id": "46172", "revid": "1287211425", "url": "https://en.wikipedia.org/wiki?curid=46172", "title": "Siderno", "text": "Siderno ( or ; ) is a town and \"comune\" in the Metropolitan City of Reggio Calabria, Calabria, southern Italy, about 3 kilometres from Locri. \nSiderno Marina is the newer town located on the Ionian coast. It is a destination for both Italian and foreign tourists and has a bathing beach.\nSiderno Superiore is the old town, higher up on the flank of the coastal mountain range. It has historic palaces, old buildings and very narrow streets. Its population has largely relocated to the Marina which offers more job opportunities and services.\nHistory.\nThe early history of the town is unknown. The old town in the hilly inland was probably founded in the 10th century by some people from Locri, who had fled to the area to defend themselves from Saracen incursions; in the following century it became a hamlet of the county of Grotteria and was home to various feudal lords. Siderno Marina was built along the coast after the 1783 earthquake.\nClimate.\nEmigration.\nLarge-scale emigration abroad as well as to Northern Italy, which began to diminish only in the 1970s, has had a lasting effect on the demographic situation in the region. Emigrants from Siderno immigrated to the United States, Canada and Australia since the end of the 19th century to find employment.\nMany moved to Canada settled in Schreiber, Ontario due to then-ongoing construction of the Canadian Pacific Railway. Half of Schreiber's 2,000 residents trace their roots to Siderno.\nEconomy.\nSiderno is a tourist resort on the Ionian coast of the province of Reggio Calabria, with wide, sandy beaches, and a clear sea .\nThe Siderno area is a center of production of bergamot orange, a citrus fruit that is used as an essence and fundamental ingredient in cosmetics, for its wound healing properties in the pharmaceutical industry, and for flavouring in the food industry.\nCrime.\nThe town is home to the 'Ndrangheta, a Mafia-type criminal organization based in Calabria. Several powerful criminal clans originate from the town. Siderno was the fiefdom of Antonio Macr\u00ec, the undisputed local boss until his demise in January 1975. Several of the criminal clans are sometimes involved in bloody feuds. The town is home to one of the 'Ndrangheta's biggest and most important clans, the Commisso 'ndrina, heavily involved in the global cocaine business and money laundering.\nSeveral clans moved to Canada, in particular the Greater Toronto Area, home to what Canadian law enforcement call the Siderno Group, which has been here since at least the 1950s. \"The criminal minds of Siderno are in Canada\", according to the Siderno police force. One of them, Antonio Commisso, was arrested in June 2005. Individuals related to the so-called Siderno Group were still active in Southern Ontario in 2018.\nFrazioni.\nDonisi (), Vennerello, Mirto (), Campo, Lucis, Zammariti, Pellegrina, Arona, San Filippo, Leone, Grappidaro, Gonia (), Pergola, Lamia.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46173", "revid": "62026", "url": "https://en.wikipedia.org/wiki?curid=46173", "title": "Fish and chips", "text": "British fried fish and fried potato dish\nFish and chips is a hot dish consisting of battered and fried fish, served with chips. Often considered the national dish of the United Kingdom, fish and chips originated in England in the 19th century. Today, the dish is a common takeaway food in numerous other countries, particularly English-speaking and Commonwealth nations.\nFish and chip shops first appeared in the UK in the 1860s, and by 1910 there were over 25,000 of them across the UK. This increased to over 35,000 by the 1930s, but eventually decreased to approximately 10,000 by 2009. The British government safeguarded the supply of fish and chips during the First World War and again in the Second World War. It was one of the few foods in the UK not subject to rationing during the wars, which further contributed to its popularity.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nThe British tradition of eating fish battered and fried in oil was introduced to the country by the Chuts and Spanish and Portuguese Jews who lived in the Netherlands before settling in the UK. These immigrants arrived as early as the 16th century, the main immigration to London being during the 1850s. They prepared fried fish in a manner similar to \"pescado frito\", which is coated in flour then fried in oil. Fish fried for Shabbat for dinner on Friday evenings could be eaten cold the following afternoon for shalosh seudot, palatable this way as liquid vegetable oil was used rather than a hard fat, such as butter. Charles Dickens mentions \"fried fish warehouses\" in \"Oliver Twist\" (1838), and in 1845 Alexis Soyer in his first edition of \"A Shilling Cookery for the People\", gives a recipe for \"fried fish, Jewish fashion\", which is dipped in a batter mix of flour and water before frying. However, \"fish the Jews' way\" in most English cookery books usually refer not to plain fried fish, but to escabeche, fish fried, then pickled in vinegar.\nThe location of the first fish and chip shop is unclear. The earliest known shops were opened in London during the 1860s by Eastern European Jewish immigrant Joseph Malin, and by John Lees in Mossley, Lancashire. Fried fish and chips had existed separately for at least 50 years prior to this, so the possibility that they had been combined at an earlier time cannot be ruled out. Fish and chips became a stock meal among the working class in England as a consequence of the rapid development of trawl fishing in the North Sea, and the development of railways which connected the ports to major industrial cities during the second half of the 19th century, so that fresh fish could be rapidly transported to the cities.\nDeep-fried chips (slices or pieces of potato) as a dish may have first appeared in England in about the same period: the \"Oxford English Dictionary\" notes as its earliest usage of \"chips\" in this sense the mention in Charles Dickens' \"A Tale of Two Cities\" (1859): \"husky chips of potato, fried with some reluctant drops of oil\".\nThe modern fish-and-chip shop (\"chippy\" in modern British slang) originated in the UK, although outlets selling fried food occurred commonly throughout Europe. Early fish-and-chip shops had only very basic facilities. Usually these consisted principally of a large cauldron of cooking fat, heated by a coal fire. The fish-and-chip shop later evolved into a fairly standard format, with the food served, in paper wrappings, to queuing customers, over a counter in front of the fryers. According to Professor John Walton, author of \"Fish and Chips and the British Working Class\", the British government made safeguarding supplies of fish and chips during the First World War a priority: \"The cabinet knew it was vital to keep families on the home front in good heart, unlike the German regime that failed to keep its people well fed\".\nIn 1928, Harry Ramsden opened his first fish and chip shop in Guiseley, West Yorkshire. On a single day in 1952, the shop served 10,000 portions of fish and chips, earning a place in the \"Guinness Book of Records\". In George Orwell's \"The Road to Wigan Pier\" (1937), which documents his experience of working-class life in the North of England, the author considered fish and chips chief among the 'home comforts' which acted as a panacea to the working classes.\nDuring the Second World War, fish and chips\u2014a staple of the working class\u2014remained one of the few foods in the United Kingdom not subject to rationing. Prime Minister Winston Churchill referred to the combination of fish and chips as \"the good companions\".\nBritish fish and chips were originally served in a wrapping of old newspapers but this practice has now largely ceased, with plain paper, cardboard, or plastic being used instead. In the UK, the Fish Labelling Regulations 2003, and in the Republic of Ireland the European Communities (Labelling of Fishery and Aquaculture Products) Regulations 2003, respectively enact directive 2065/2001/EC, and generally mean that \"fish\" must be sold with the particular commercial name or species named; so, for example, \"cod and chips\" now appears on menus rather than the more vague \"fish and chips\". In the UK the Food Standards Agency guidance excludes caterers from this; but several local Trading Standards authorities and others do say it cannot be sold merely as \"fish and chips\".\nWhen Malin's in Bow went out of business in the early 1970s, they sold the exclusive rights for the fish recipe and custom designed frying equipment, unchanged since the 1860s, to the American fast food chain Arthur Treacher's Fish &amp; Chips. The chain marketed it as \"the original\". Only a handful of Arthur Treacher's are still in business, most located in northern Ohio, the last place in the world the historic Malin's fish and chips recipe is still made with the same equipment design, frying techniques and recipe that would be familiar to someone from the 1860s.\nUnited Kingdom.\nA prominent meal in British culture, fish and chips became popular in wider circles in London and South East England in the middle of the 19th century: Charles Dickens mentions a \"fried fish warehouse\" in \"Oliver Twist\", first published in 1838, while in the north of England a trade in deep-fried chipped potatoes developed. It remains unclear exactly when and where these two trades combined to become the modern fish and chip shop industry. A Jewish immigrant, Joseph Malin, opened the first recorded combined fish-and-chip shop in Bow, East London, circa 1860; a Mr Lees pioneered the concept in the North of England, in Mossley, in 1863. A century later, the National Federation of Fish Friers, which made Malin's its first member, presented a plaque to Malin's as being the world's first fish and chip shop. A blue plaque is located at the other main contender for the first fish and chip shop, the present site of Oldham's Tommyfield Market. Located in Covent Garden, The Rock &amp; Sole Plaice, dating from 1871, is London's oldest fish and chip shop still in operation. \nThe concept of a sit-down fish restaurant\u2014as opposed to takeaway\u2014was introduced by Samuel Isaacs, an entrepreneur from Whitechapel, East London who ran a thriving wholesale and retail fish business. Dubbed the 'Fish Restaurant King', Isaacs' first restaurant opened in Lambeth, South London in 1896 serving fish and chips, bread and butter, and tea for nine pence. It became instantly popular and led to a chain which comprised 22 restaurants. Isaacs' trademark was the phrase \"This is the Plaice\", combined with a picture of the punned-upon fish in question, which appeared in all of his restaurants. Isaacs' restaurants were carpeted, had table service, tablecloths, flowers, china and cutlery, and made the trappings of upmarket dining affordable to the working classes. They were located in the Strand and other London locations, as well as Brighton, Ramsgate, Margate and other seaside resorts in southern England. Menus were expanded in the early 20th century to include meat dishes and other variations. A glimpse of the old Brighton restaurant at No.1 Marine Parade can be seen in the background of Norman Wisdom's 1955 film \"One Good Turn\" just as Pitkin runs onto the seafront; this is now the site of a Harry Ramsden's fish and chips restaurant. \nFrom their first appearance on the British High Street in the early 1860s, fish and chip shops spread rapidly in order to satisfy the needs of the growing industrial population. By 1910, there were over 25,000 fish and chip shops across the UK, a figure that grew to over 35,000 shops by the 1930s. Since then the trend has reversed, and in 2009 there were approximately 10,000 shops.\nScotland.\nDundee City Council claims that chips were first sold by a Belgian immigrant, Edward De Gernier, in the city's Greenmarket in the 1870s. In Edinburgh and the surrounding area, a combination of Gold Star brown sauce and water or malt vinegar, known as \"sauce\", or more specifically as \"chippy sauce\", has great popularity; salt and vinegar is preferred elsewhere in Scotland.\nFish &amp; Chips Awards.\nThe annual National Fish &amp; Chips Awards were set up in the UK in 1988. The 30th Annual Fish &amp; Chips Awards ceremony was attended by Norwegian ambassador to the UK Mona Juul.\nAustralia.\nThe first recorded owner of an Australian fish and chip shop is Greek migrant Athanasias Comino, who opened his shop in 1879 on Sydney's Oxford Street, though Comino's shop was inspired by an unknown Welshman's pre-existing fish and chip shop.\nIn Australia today, there are an estimated 4,000 fish and chip shops, as well as fish and chips being an essential menu offering in many Australian pubs and restaurants.\nCanada.\nFish and chips is a very popular takeaway and pub dish across Canada, known as in French-speaking provinces. The dish is particularly prevalent in the Atlantic provinces, Ontario, and along the West Coast. A variety of fish species are featured, depending on regional availability, including Atlantic cod, haddock, pickerel, and local lake-caught fish such as perch or walleye. While chips are traditionally served, they are often substituted for the iconic Canadian dish . In the province of Newfoundland and Labrador, fish and chips made with Atlantic cod are a staple food and the most common takeout meal.\nIreland.\nIn Ireland, the first fish and chips were sold by an Italian immigrant, Giuseppe Cervi, who mistakenly stepped off a North America-bound ship at Queenstown (now Cobh) in County Cork in the 1880s and walked all the way to Dublin. He started by selling fish and chips outside Dublin pubs from a handcart. He then found a permanent spot in Great Brunswick Street (now Pearse Street). His wife Palma would ask customers \"\" This phrase (meaning 'one of this, one of that') entered the vernacular in Dublin as \"one and one\", which is still a way of referring to fish and chips in the city.\nNew Zealand.\nFish and chips is the most popular takeaway food in New Zealand. Food historians have not been able to pinpoint exactly when the meal became an established part of New Zealand cuisine, but all recognise that the first fish and chips shops were introduced by British settlers before World War I. During the 20th century, nearly every small town and suburb in New Zealand had at least one fish-and-chip shop. As in Britain, Friday night has been the traditional night to eat fish.\nTraditionally, fish and chips were served in wrappings of greaseproof paper and then newspaper as insulation. With the decline of the newspaper industry, this has become less common although plain, unprinted paper is still popular.\nIn 1980, four up-and-coming New Zealand Labour Party politicians, including David Lange, were nicknamed the \"Fish and Chip Brigade\" due to a picture published at the time with the group eating fish and chips.\nUnited States.\nIn the United States, the dish is most commonly sold as \"fish and chips\", except in Upstate New York and Wisconsin and other parts of the Northeast and Upper Midwest, where this dish would be called a \"fish fry\". While in the United States \"chips\" refers to potato chips (\"crisps\" in British English), the dish retains its native name. In the Southern United States, a common form of cuisine is fried catfish with French fries, accompanied by coleslaw, pickles, raw onion slices and lemon slices.\nOther countries.\nThe western Norwegian town of Kristiansund has had a tradition with fish and chips as street food since the 1940s. It is known locally as .\nComposition.\nChoice of fish.\nIn Britain and Ireland, cod and haddock appear most commonly as the fish used for fish and chips, but vendors also sell many other kinds of fish, especially other white fish, such as lemon sole, pollock, hake or coley, plaice, skate, ray, and huss or rock salmon (a term covering several species of dogfish and similar fish). In traditional fish and chip shops several varieties of fish are offered by name (\"haddock and chips\"), but in some restaurants and stalls \"fish and chips\", unspecified, is offered; it is increasingly likely to be the much cheaper pollock. In Northern Ireland, cod, plaice or whiting appear most commonly in 'fish suppers'\u2014'supper' being Scottish and Northern Irish terminology for a food item accompanied by chips. Suppliers in Devon and Cornwall often offer pollock and coley as cheap alternatives to haddock.\nIn Canada, cod, haddock and Atlantic Salmon are favoured in Atlantic Region and Pacific cod, Alaska pollock, flounder, halibut, trout and Chinook salmon are favoured in British Columbia. Because of influences of Japanese Canadians, fish and chips in British Columbia is influenced by the tempura techniques used in Japanese cuisine.\nIn Australia, reef cod and rock cod (a variety different from that used in the United Kingdom), barramundi or flathead (more expensive options), flake (a type of shark meat), King George whiting (little more expensive than other fish, but cheaper than barramundi or flathead) or snapper (cheaper options), are commonly used. From the early 21st century, farmed basa imported from Vietnam and hoki have become common in Australian fish and chip shops. Other types of fish are also used based on regional availability.\nIn New Zealand, snapper or gurnard was originally the preferred species for battered fillets in the North Island. As catches of this fish declined, it was replaced by hoki, shark (particularly rig) \u2013 marketed as lemon fish \u2013 and tarakihi. Bluefin gurnard and blue cod predominate in South Island fish and chips.\nIn the United States, the type of fish used depends on availability in a given region. or, in New England, Atlantic cod or haddock.\nIn India, the dish is usually based on beckti or pomfret and uses chilli paste, and more pepper than would be used in Britain.\nIn South Africa, hake and snoek are common choices.\nCooking.\nTraditional frying uses beef dripping or lard; however, vegetable oils, such as palm oil, rapeseed or peanut oil (used because of its relatively high smoke point) now[ [update]] predominate, in part because it makes fried chips suitable for vegetarians and for adherents of certain faiths.\nThere is a longstanding debate among vendors in the UK on whether beef dripping or vegetable oil is the best way to fry fish and chips. The traditional method of dripping or lard are used in some living industrial history museums, such as the Black Country and Beamish Living Museums in England. \nThe fish part of the dish is filleted, and no bones should be found in the fish.\nBatter.\nIn Britain and Ireland, fish and chip shops traditionally use a simple water and flour batter, adding a little sodium bicarbonate (baking soda) and a little vinegar to create lightness, as they react to create bubbles in the batter. Other recipes may use beer or milk batter, where these liquids are often substitutes for water. The carbon dioxide in the beer lends a lighter texture to the batter. Beer also results in an orange-brown colour. A simple beer batter might consist of a 2:3 ratio of flour to beer by volume. The type of beer alters the taste of the batter; some prefer lager whereas others use stout or bitter.\nChips.\nBritish chips are usually considerably thicker than American-style French fries. Some US restaurants and some people in their home cooking may use a thick type of chip, similar to the British variant, sometimes referred to as \"steak fries\".\nAccompaniments.\nIn chip shops in most parts of Britain and Ireland, salt and vinegar are traditionally sprinkled over fish and chips at the time it is served. Suppliers use malt vinegar, onion vinegar (used for pickling onions), or the cheaper non-brewed condiment. In a few places, notably Edinburgh, 'sauce' (as in 'salt and sauce') is more traditional than vinegar\u2014with 'sauce' meaning a brown sauce. In England, curry sauce, gravy, mushy peas, beans and tartar sauce are popular side dishes, as are a range of pickles that typically include gherkins, onions and eggs. In table-service restaurants and pubs, the dish is usually served with a slice of lemon for squeezing over the fish and without any sauces or condiments, with salt, vinegar and sauces available at the customer's leisure. Ketchup is also a popular addition (a 2020 YouGov poll in the UK saw ketchup, curry sauce and mushy peas as the top three toppings after salt and vinegar).\nIn Ireland, Wales and England, many takeaways serve warm side portions of sauces such as curry sauce or gravy, if requested and normally for a small extra fee (curry sauce topped the poll in Wales with one in three using it as a topping). The sauces are usually poured over the chips. In the Midlands especially, chips with mushy peas or baked beans are known as a \"pea mix\" or a \"bean mix\". \nOther fried products include 'scraps' (also known as 'bits' in Southern England and \"scrumps\" in South Wales), originally a by-product of fish frying. Still popular in Northern England, they were given as treats to the children of customers. Portions prepared and sold today consist of loose blobs of batter, deep-fried to a crunchy golden crisp in the cooking fat. The potato scallop or potato cake consists of slices of potato dipped in fish batter and deep-fried until golden brown. These are often accompanied for dipping by the warm sauces listed above.\nIn Sheffield, Yorkshire fishcakes are made by sandwiching a piece of fish between two slices of potato and deep frying it in batter. This is commonly sold in a bread bun and known as a Fishcake Butty.\nNutrition information.\nAn average serving of fish and chips consisting of of fried fish with of fried chips has approximately calories and contains approximately of fat. The use of tartar sauce as a condiment adds more calories and fat to the dish.\nVendors.\nIn the United Kingdom, Ireland, Australia, Canada, New Zealand and South Africa, fish and chips are usually sold by independent restaurants and take-aways known as fish and chip shops. Outlets range from small affairs to chain restaurants. Locally owned seafood restaurants are also popular in many places, as are mobile \"chip vans\". In Canada, the outlets may be referred to as \"chip wagons\". \nIn Ireland, the majority of traditional vendors are migrants or the descendants of migrants from southern Italy. A trade organisation exists to represent this tradition. In New Zealand and Australia, fish-and-chip vendors are a popular business and source of income among the Asian community, particularly Chinese migrants. In Indonesia, fish and chips are commonly found in western and seafood restaurants in large cities, as well as chain restaurants like The Manhattan Fish Market, Fish &amp; Chips, etc.\nMany British establishments have humorous or pun-based names, such as, \"A Salt and Battery\", \"The Codfather\", \"The Frying Scotsman\", \"Oh My Cod\", \"Frying Nemo\", \"Rock and Sole\" and \"Jack the Chipper\". The numerous competitions and awards for \"best fish-and-chip shop\" testify to the recognised status of this type of outlet in popular culture.\nFish and chips is a popular lunch meal eaten by families travelling to seaside resorts for day trips who do not bring their own picnic meals.\nFish-and-chip outlets sell roughly 25% of all the white fish consumed in the United Kingdom, and 10% of all potatoes.\nFish-and-chip shops traditionally wrapped their product in newspaper, or with an inner layer of white paper (for hygiene) and an outer layer of newspaper or blank newsprint (for insulation and to absorb grease), though the use of newspaper for wrapping has almost ceased on grounds of hygiene. Nowadays[ [update]], establishments usually use food-quality wrapping paper, or recyclable cardboard boxes.\nThe British National Federation of Fish Friers was founded in 1913. It promotes fish and chips and offers training courses. It has about 8,500 members from around the UK.\nA previous world record for the \"largest serving of fish and chips\" was held by Gadaleto's Seafood Market in New Paltz, New York. This 2004 record was broken by Yorkshire pub Wensleydale Heifer in July 2011. An attempt to break this record was made by Doncaster fish and chip shop Scawsby Fisheries in August 2012, which served of battered cod alongside of chips. Current record is held by Resorts World Birmingham which served a fish and chips weighing from a raw filet of halibut on 9 February 2018.\nCultural impact.\nThe long-standing Roman Catholic tradition of not eating meat on Fridays, especially during Lent, and of substituting fish for meat on that day continues to influence habits even in predominantly Protestant, semi-secular and secular societies. Friday night remains a traditional occasion for eating fish and chips; many cafeterias and similar establishments, while varying their menus on other days of the week, habitually offer fish and chips every Friday.\nIn 1967, inspired by the use of salt and vinegar as condiments for fish and chips in the UK, the Smiths Potato Crisps Company created Salt &amp; Vinegar flavour crisps.\nIn Australia and New Zealand, the words \"fish and chips\" are often used as a shibboleth to highlight the difference in each country's short-i vowel sound . Australian English has a higher forward sound , close to the \"ee\" in \"see\" (but shorter), while New Zealand English has a lower backward sound akin to the \"a\" in \"Rosa's\" (but not in \"Rosa\", which is typically lower ). Thus, New Zealanders hear Australians say \"feesh and cheeps,\" while Australians hear New Zealanders say \"fush and chups.\"\nEnvironment.\nIn the UK, waste oil from fish and chip shops has become a useful source of biodiesel. The German biodiesel company Petrotec has outlined plans to produce biodiesel in the UK using waste oil from the British fish-and-chip industry.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "46174", "revid": "29058361", "url": "https://en.wikipedia.org/wiki?curid=46174", "title": "National Institutes of Health", "text": "US government medical research agency\nThe National Institutes of Health (NIH) is the primary agency of the United States federal government responsible for biomedical and public health research. It was founded in 1887 and is part of the United States Department of Health and Human Services (HHS). Many NIH facilities are located in Bethesda, Maryland, and other nearby suburbs of the Washington metropolitan area, with other primary facilities in Research Triangle Park in North Carolina and smaller satellite facilities located around the United States.\nThe NIH conducts its scientific research through the NIH Intramural Research Program (IRP) and provides significant biomedical research funding to non-NIH research facilities through its Extramural Research Program. As of 2013[ [update]], the IRP had 1,200 principal investigators and more than 4,000 postdoctoral fellows in basic, translational, and clinical research, being the largest biomedical research institution in the world, while, as of 2003, the extramural arm provided 28% of biomedical research funding spent annually in the U.S., or about US$26.4 billion. Basic research by the NIH contributed to every new drug approved by the Federal Drug Administration over the period 2010\u20132016.\nThe NIH is responsible for many scientific accomplishments, including the discovery of fluoride to prevent tooth decay, the use of lithium to manage bipolar disorder, and the creation of vaccines against hepatitis, \"Haemophilus influenzae\" (HIB), and human papillomavirus (HPV). In 2012, the NIH comprised 27 separate institutes and centers of different biomedical disciplines.\nIn 2019, the NIH was ranked number two in the world, behind Harvard University, for biomedical sciences in the Nature Index, which measured the largest contributors to papers published in a subset of leading journals from 2015 to 2018.\nHistory.\nOrigins.\nIn 1887, a laboratory for the study of bacteria, the Hygienic Laboratory, was established within the Marine Hospital Service, which at the time was expanding its functions beyond the system of Marine Hospitals into quarantine and research programs. It was initially located at the New York Marine Hospital on Staten Island. In 1891, it moved to the top floor of the Butler Building in Washington, D.C. In 1904, it moved again to a new campus at the Old Naval Observatory, which grew to include five major buildings.\nIn 1901, the Division of Scientific Research was formed, which included the Hygienic Laboratory as well as other research offices of the Marine Hospital Service. In 1912, the Marine Hospital Service became the Public Health Service (PHS). In 1922, PHS established a Special Cancer Investigations laboratory at Harvard Medical School. This development marked the beginning of partnerships with universities.\nIn 1930, the Hygienic Laboratory was re-designated as the National Institute of Health by the Ransdell Act, and was given $750,000 to construct two NIH buildings at the Old Naval Observatory campus. In 1937, the NIH absorbed the rest of the Division of Scientific Research, of which it was formerly part.\nIn 1938, the NIH moved to its current campus in Bethesda, Maryland. Over the next few decades, Congress would markedly increase funding of the NIH. Various institutes and centers within the NIH were created for specific research programs. In 1944, the Public Health Service Act was approved and the National Cancer Institute became a division of the NIH. In 1948, the name changed from National Institute of Health to National Institutes of Health.\nLater history.\nIn the 1960s, virologist and cancer researcher Chester M. Southam injected HeLa cancer cells into patients at the Jewish Chronic Disease Hospital. When three doctors resigned after refusing to inject patients without their consent, the experiment gained considerable media attention. The NIH was a major source of funding for Southam's research and required all research involving human subjects to obtain their consent before any experimentation. Upon investigating all of their grantee institutions, the NIH discovered that the majority of them did not protect the rights of human subjects. From then on, the NIH has required all grantee institutions to approve any research proposals involving human experimentation with review boards.\nIn 1967, the Division of Regional Medical Programs was created to administer grants for research for heart disease, cancer, and strokes. That same year, the NIH director lobbied the White House for increased federal funding to increase research and the speed with which health benefits could be brought to the people. An advisory committee was formed to oversee the further development of the NIH and its research programs. By 1971, cancer research was in full force, and President Nixon signed the National Cancer Act, initiating a National Cancer Program, President's Cancer Panel, National Cancer Advisory Board, and 15 new research, training, and demonstration centers.\nFunding for the NIH has often been a source of contention in the US Congress, serving as a proxy for the political currents of the time. In 1992, the NIH encompassed nearly one percent of the federal government's operating budget and controlled more than 50 percent of all funding for health research, and 85 percent of all funding for health studies in universities. While government funding for research in other disciplines has been increasing at a rate similar to inflation since the 1970s, research funding for the NIH nearly tripled through the 1990s and early 2000s, but has remained relatively stagnant since then.\nBy the 1990s, the NIH committee focus had shifted to DNA research and launched the Human Genome Project.\nOn January 22, 2025, the Trump administration imposed an immediate freeze on meetings \u2013 such as grant review panels \u2013 as well as travel, communications, and hiring at the NIH, affecting $47.4 billion worth of activities.\nLeadership.\nThe NIH Office of the Director is the central office responsible for setting policy for the NIH, and for planning, managing, and coordinating the programs and activities of all NIH components. The NIH Director plays an active role in shaping the agency's activities and outlook. The Director is responsible for providing leadership to the Institutes and Centers by identifying needs and opportunities, especially in efforts involving multiple Institutes. Within the Director's Office is the Division of Program Coordination, Planning and Strategic Initiatives with 12 divisions including:\nThe Agency Intramural Research Integrity Officer \"is directly responsible for overseeing the resolution of all research misconduct allegations involving intramural research, and for promoting research integrity within the NIH Office of Intramural Research (OIR).\" There is a Division of Extramural Activities, which has its own Director. The Office of Ethics has its own Director, as does the Office of Global Research.\nLocations and campuses.\nIntramural research is primarily conducted at the main campus in Bethesda, Maryland, and Rockville, Maryland, and the surrounding communities.\nThe Bayview Campus in Baltimore, Maryland houses the research programs of the National Institute on Aging, National Institute on Drug Abuse, and National Human Genome Research Institute with nearly 1,000 scientists and support staff. The Frederick National Laboratory in Frederick, MD and the nearby Riverside Research Park, houses many components of the National Cancer Institute, including the Center for Cancer Research, Office of Scientific Operations, Management Operations Support Branch, the division of Cancer Epidemiology and Genetics and the division of Cancer Treatment and Diagnosis.\nThe National Institute of Environmental Health Sciences is located in the Research Triangle region of North Carolina.\nOther ICs have satellite locations in addition to operations at the main campus. The National Institute of Allergy and Infectious Diseases maintains its Rocky Mountain Labs in Hamilton, Montana, with an emphasis on BSL3 and BSL4 laboratory work. NIDDK operates the Phoenix Epidemiology and Clinical Research Branch in Phoenix, Arizona.\nResearch.\nAs of 2017, 153 scientists receiving financial support from the NIH have been awarded a Nobel Prize and 195 have been awarded a Lasker Award.\nIntramural and extramural research.\nIn 2019, the NIH devoted 10% of its funding to research within its own facilities (intramural research), and gave &gt;80% of its funding in research grants to extramural (outside) researchers. Of this extramural funding, a certain percentage (2.8% in 2014) must be granted to small businesses under the SBIR/STTR program. As of 2011[ [update]], the extramural funding consisted of about 50,000 grants to more than 325,000 researchers at more than 3000 institutions. By 2018[ [update]], this rate of granting remained reasonably steady, at 47,000 grants to 2,700 organizations. In FY 2010[ [update]], the NIH spent US$ (not including temporary funding from the American Recovery and Reinvestment Act of 2009) on clinical research, US$ on genetics-related research, US$ on prevention research, US$ on cancer, and US$ on biotechnology.\nPublic Access Policy.\nIn 2008 a Congressional mandate called for investigators funded by the NIH to submit an electronic version of their final manuscripts to the National Library of Medicine's research repository, PubMed Central (PMC), no later than 12 months after the official date of publication. The NIH Public Access Policy was the first public access mandate for a U.S. public funding agency.\nEconomic return.\nIn 2000, the Joint Economic Committee of Congress reported NIH research, which was funded at $16 billion a year in 2000, that some econometric studies had given a rate of return of 25 to 40 percent per year by reducing the economic cost of illness in the US. It found that of the 21 drugs with the highest therapeutic impact on society introduced between 1965 and 1992, public funding was \"instrumental\" for 15. As of 2011, NIH-supported research helped to discover 153 new FDA-approved drugs, vaccines, and new indications for drugs in the 40 years prior. One study found NIH funding aided either directly or indirectly in developing the drugs or drug targets for all of the 210 FDA-approved drugs from 2010 to 2016. In 2015, Pierre Azoulay et al. estimated $10 million invested in research generated two to three new patents.\nNotable discoveries and developments.\nSince its inception, the NIH intramural research program has been a source of many pivotal scientific and medical discoveries. Some of these include:\nNIH Toolbox.\nIn September 2006, the NIH Blueprint for Neuroscience Research started a contract for the NIH Toolbox for the Assessment of Neurological and Behavioral Function to develop a set of state-of-the-art measurement tools to enhance collection of data in large cohort studies. Scientists from more than 100 institutions nationwide contributed. In September 2012, the NIH Toolbox was rolled out to the research community. NIH Toolbox assessments are based, where possible, on Item Response Theory and adapted for testing by computer.\nDatabase of Genotypes and Phenotypes.\nNIH sponsors the Database of Genotypes and Phenotypes (dbGaP), a repository of information produced by studies investigating the interaction of genotype and phenotype. The information includes phenotypes, molecular assay data, analyses and documents. Summary-level data is available to the general public whereas the individual-level data is accessible to researchers. According to the City Journal NIH denies access to such attributes as intelligence, education and health on the grounds that studying their genetic basis would be stigmatizing.\nCoronavirus vaccine.\nThe NIH partnered with Moderna in 2020 during the COVID-19 pandemic to develop a vaccine. The final phase of testing began on July 27 with up to 30,000 volunteers assigned to one of two groups\u2014one receiving the mRNA-1273 vaccine and the other receiving salt water injections\u2014and continued until there had been approximately 100 cases of COVID-19 among the participants. In 2021, the NIH contributed $4,395,399 towards the Accelerating COVID-19 Therapeutic Interventions and Vaccines (ACTIV) program.\nGrant to EcoHealth Alliance and Wuhan Institute for studying bat coronaviruses.\nFollowing the outbreak of the COVID-19 pandemic, the NIH-funded EcoHealth Alliance has been the subject of controversy and increased scrutiny due to its ties to the Wuhan Institute of Virology (WIV)\u2014which has been at the center of speculation since early 2020 that SARS-CoV-2 may have escaped in a lab incident. Between 2014 and 2019, NIH awarded approximately $3.7 million in grant funding to EcoHealth Alliance, a nonprofit organization focused on global health and infectious disease research. A portion of this funding, around $600,000, was subcontracted to WIV in China as part of a project titled \"Understanding the Risk of Bat Coronavirus Emergence.\" The project aimed to study bat coronaviruses and assess their potential to infect humans. The research at WIV included the creation of chimeric viruses, which combined genetic material from different bat coronaviruses to evaluate their ability to infect human cells. In documents released in 2021, including NIH correspondence with Congress, it was disclosed that one of these modified viruses resulted in an \"unexpected outcome,\" where the virus became more infectious in humanized mice. The NIH maintained that this outcome was not the intended goal of the research and did not violate the terms of the grant, though critics raised concerns about potential gain-of-function research. Under political pressure, the NIH withdrew funding to EcoHealth Alliance in July 2020. In 2023, HHS barred WIV from receiving U.S. government funding for a decade, citing non-compliance with safety and reporting standards.\nNIH Interagency Pain Research Coordinating Committee.\nOn February 13, 2012, the National Institutes of Health (NIH) announced a new group of individuals assigned to research pain. This committee is composed of researchers from different organizations and will focus to \"coordinate pain research activities across the federal government with the goals of stimulating pain research collaboration\u2026 and providing an important avenue for public involvement\" (\"Members of new\", 2012). With a committee such as this research will not be conducted by each individual organization or person but instead a collaborating group which will increase the information available. With this hopefully more pain management will be available including techniques for those with arthritis. In 2020 Beth Darnall, American scientist and pain psychologist, was appointed as scientific member of the group.\nFunding.\nBudget and politics.\nTo allocate funds, the NIH must first obtain its budget from Congress. This process begins with institute and center (IC) leaders collaborating with scientists to determine the most important and promising research areas within their fields. IC leaders discuss research areas with NIH management who then develops a budget request for continuing projects, new research proposals, and new initiatives from the Director. The NIH submits its budget request to the Department of Health and Human Services (HHS), and the HHS considers this request as a portion of its budget. Many adjustments and appeals occur between the NIH and HHS before the agency submits NIH's budget request to the Office of Management and Budget (OMB). OMB determines what amounts and research areas are approved for incorporation into the President's final budget. The President then sends the NIH's budget request to Congress in February for the next fiscal year's allocations. The House and Senate Appropriations Subcommittees deliberate and by fall, Congress usually appropriates funding. This process takes approximately 18 months before the NIH can allocate any actual funds.\nWhen a government shutdown occurs, the NIH continues to treat people who are already enrolled in clinical trials, but does not start any new clinical trials and does not admit new patients who are not already enrolled in a clinical trial, except for the most critically ill, as determined by the NIH Director.\nHistorical funding.\nOver the last century, the responsibility to allocate funding has shifted from the OD and Advisory Committee to the individual ICs and Congress increasingly set apart funding for particular causes. In the 1970s, Congress began to earmark funds specifically for cancer research, and in the 1980s there was a significant amount allocated for AIDS/HIV research.\nFunding for the NIH has often been a source of contention in Congress, serving as a proxy for the political currents of the time. During the 1980s, President Reagan repeatedly tried to cut funding for research, only to see Congress partly restore funding. The political contention over NIH funding slowed the nation's response to the AIDS epidemic; while AIDS was reported in newspaper articles from 1981, no funding was provided for research on the disease. In 1984 National Cancer Institute scientists found implications that \"variants of a human cancer virus called HTLV-III are the primary cause of acquired immunodeficiency syndrome (AIDS),\" a new epidemic that gripped the nation.\nIn 1992, the NIH encompassed nearly 1 percent of the federal government's operating budget and controlled more than 50 percent of all funding for health research and 85 percent of all funding for health studies in universities. From 1993 to 2001 the NIH budget doubled. For a time, funding essentially remained flat, and for seven years after the 2008 financial crisis, the NIH budget struggled to keep up with inflation.\nIn 1999 Congress increased the NIH's budget by $2.3 billion to $17.2 billion in 2000. In 2009 Congress again increased the NIH budget to $31 billion in 2010. In 2017 and 2018, Congress passed laws with bipartisan support that substantially increasing appropriations for the NIH, which was 37.3 billion dollars annually in FY2018.\nFunding freezes.\nFrom the outset of 2025, NIH funding operations have faced interruptions on an unprecedented scale under the direction of the current executive branch of the U.S. government; disruptions as of March 2025 include the following:\n\u2022 impeding grants for dementia and ALS research;\n\u2022 hindering procurement of necessary resources, such as those for transporting patient blood samples;\n\u2022 preventing a research scientist from consulting with physicians treating children with a devastating rare condition;\n\u2022 interrupting the supply of mice for genetic studies, with years of research being imperiled as a result;\n\u2022 cutting research grants for training doctoral and postdoctoral students.\nThis has led to protests such as the Bethesda Declaration, an open letter from former and current NIH staffers.\nExtramural research.\nResearchers at universities or other institutions outside of the NIH can apply for research project grants (RPGs) from the NIH. There are numerous funding mechanisms for different project types (e.g., basic research, clinical research, etc.) and career stages (e.g., early career, postdoc fellowships, etc.). The NIH regularly issues \"requests for applications\" (RFAs), e.g., on specific programmatic priorities or timely medical problems (such as Zika virus research in early 2016). In addition, researchers can apply for \"investigator-initiated grants\" whose subject is determined by the scientist.\nThe total number of applicants has increased substantially, from about 60,000 investigators who had applied during the period from 1999 to 2003 to slightly less than 90,000 in who had applied during the period from 2011 to 2015. Due to this, the \"cumulative investigator rate\", that is, the likelihood that unique investigators are funded over a 5-year window, has declined from 43% to 31%.\nR01 grants are the most common funding mechanism and include investigator-initiated projects. The roughly 27,000 to 29,000 R01 applications had a funding success of 17-19% during 2012 though 2014. Similarly, the 13,000 to 14,000 R21 applications had a funding success of 13-14% during the same period. In FY 2016, the total number of grant applications received by the NIH was 54,220, with approximately 19% being awarded funding. Institutes have varying funding rates. The National Cancer Institute awarded funding to 12% of applicants, while the National Institute for General Medical Science awarded funding to 30% of applicants.\nFunding criteria.\nThe NIH employs five broad decision criteria in its funding policy. First, ensure the highest quality of scientific research by employing an arduous peer review process. Second, seize opportunities that have the greatest potential to yield new knowledge and that will lead to better prevention and treatment of disease. Third, maintain a diverse research portfolio to capitalize on major discoveries in a variety of fields such as cell biology, genetics, physics, engineering, and computer science. Fourth, address public health needs according to the disease burden (e.g., prevalence and mortality). And fifth, construct and support the scientific infrastructure (e.g., well-equipped laboratories and safe research facilities) necessary to conduct research.\nAdvisory committee members advise the institute on policy and procedures affecting the external research programs and provide a second level of review for all grant and cooperative agreement applications considered by the Institute for funding.\nGender and sex bias.\nIn 2014, it was announced that the NIH is directing scientists to perform their experiments with both female and male animals, or cells derived from females as well as males if they are studying cell cultures, and that the NIH would take the balance of each study design into consideration when awarding grants. The announcement also stated that this rule would probably not apply when studying sex-specific diseases (for example, ovarian or testicular cancer).\nStakeholders.\nGeneral public.\nOne of the goals of the NIH is to \"expand the base in medical and associated sciences in order to ensure a continued high return on the public investment in research.\" Taxpayer dollars funding the NIH are from the taxpayers, making them the primary beneficiaries of advances in research. Thus, the general public is a key stakeholder in the decisions resulting from the NIH funding policy. However, some in the general public do not feel their interests are being represented, and individuals have formed patient advocacy groups to represent their own interests.\nExtramural researchers and scientists.\nImportant stakeholders of the NIH funding policy include researchers and scientists. Extramural researchers differ from intramural researchers in that they are not employed by the NIH but may apply for funding. Throughout the history of the NIH, the amount of funding received has increased, but the proportion to each IC remains relatively constant. The individual ICs then decide who will receive the grant money and how much will be allotted.\nPolicy changes on who receives funding significantly affect researchers. For example, the NIH has recently attempted to approve more first-time NIH R01 applicants or the research grant applications of young scientists. To encourage the participation of young scientists, the application process has been shortened and made easier. In addition, first-time applicants are being offered more funding for their research grants than those who have received grants in the past.\nCommercial partnerships.\nIn 2011 and 2012, the Department of Health and Human Services Office of Inspector General published a series of audit reports revealing that throughout the fiscal years 2000\u20132010, institutes under the aegis of the NIH did not comply with the time and amount requirements specified in appropriations statutes, in awarding federal contracts to commercial partners, committing the federal government to tens of millions of dollars of expenditure ahead of appropriation of funds from Congress.\nInstitutes and centers.\nThe NIH is composed of 27 separate institutes and centers that conduct and coordinate biomedical research. These are:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nIn addition, the National Center for Research Resources operated from April 13, 1962, to December 23, 2011.\nARPA-H.\nThe Advanced Research Projects Agency for Health (ARPA-H) is an entity formerly within the Office of the United States Secretary of Health and Human Services, which was created by Congress in the Consolidated Appropriations Act, 2022. Modeled after DARPA, HSARPA, IARPA, and ARPA-E, it is intended to pursue unconventional research projects through methods not typically used by federal agencies or private sector companies. Secretary Xavier Becerra delegated ARPA-H to the NIH on May 24, 2022. It received $1 billion in appropriations in 2022, and $1.5 billion in 2023, and as of \u00a02023[ [update]] it is requesting $2.5 billion for 2024.\nConsensus Development Program.\nThe Consensus Development Program is an initiative focused on gathering expert opinions to establish standards and guidelines in various fields, especially in health and medicine. Developed as a collaborative effort by organizations such as the NIH, the program assembles panels of specialists who assess available evidence on critical topics and form recommendations to guide clinical practice and policy. This method helps ensure that healthcare decisions are informed by the latest scientific research and expert consensus.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46177", "revid": "1319267997", "url": "https://en.wikipedia.org/wiki?curid=46177", "title": "Epidemic typhus", "text": "Bacterial infection spread by body lice\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nEpidemic typhus, also known as louse-borne typhus, is a form of typhus so named because the disease often causes epidemics following wars and natural disasters where civil life is disrupted. Epidemic typhus is spread to people through contact with infected body lice, in contrast to endemic typhus which is usually transmitted by fleas.\nThough typhus has been responsible for millions of deaths throughout history, it is still considered a rare disease that occurs mainly in populations that suffer unhygienic extreme overcrowding. Typhus is most rare in industrialized countries. It occurs primarily in the colder, mountainous regions of central and east Africa, as well as Central and South America. The causative organism is \"Rickettsia prowazekii\", transmitted by the human body louse (\"Pediculus humanus corporis\"). Untreated typhus cases have a fatality rate of approximately 40%.\nEpidemic typhus should not be confused with murine typhus, which is more endemic to the United States, particularly Southern California and Texas. This form of typhus has similar symptoms but is caused by \"Rickettsia typhi\", is less deadly, and has different vectors for transmission.\nSigns and symptoms.\nSymptoms of this disease typically begin within 2 weeks of contact with the causative organism. Signs/symptoms may include:\nAfter 5\u20136 days, a macular skin eruption develops: first on the upper trunk and spreading to the rest of the body (though the face, palms, and soles of the feet are rarely affected).\nBrill\u2013Zinsser disease, first described by Nathan Brill in 1913 at Mount Sinai Hospital in New York City, is a mild form of epidemic typhus that recurs in someone after a long period of latency (similar to the relationship between chickenpox and shingles). This recurrence often arises in times of relative immunosuppression, which is often in the context of a person suffering malnutrition or other illnesses. In combination with poor sanitation and hygiene in times of social chaos and upheaval, which enable a greater density of lice, this reactivation is why typhus generates epidemics in such conditions.\nComplications.\nComplications are as follows:\nTransmission.\nFeeding on a human who carries the bacterium infects the louse. \"R. prowazekii\" grows in the louse's gut and is excreted in its feces. The louse transmits the disease by biting an uninfected human, who scratches the louse bite (which itches) and rubs the feces into the wound. The incubation period is one to two weeks. \"R. prowazekii\" can remain viable and virulent in the dried louse feces for many days. Typhus will eventually kill the louse, though the disease will remain viable for many weeks in the dead louse.\nEpidemic typhus has historically occurred during times of war and deprivation. For example, typhus killed millions of prisoners in German Nazi concentration camps during World War II. The unhygenic conditions in camps such as Auschwitz, Theresienstadt, and Bergen-Belsen allowed diseases such as typhus to flourish. Situations in the twenty-first century with potential for a typhus epidemic would include refugee camps during a major famine or natural disaster. In the periods between outbreaks, when human to human transmission occurs less often, the flying squirrel serves as a zoonotic reservoir for the \"Rickettsia prowazekii\" bacterium.\nIn 1916, Henrique da Rocha Lima proved that the bacterium \"Rickettsia prowazekii\" was the agent responsible for typhus. He named it after his colleague Stanislaus von Prowazek, who had along with himself become infected with typhus while investigating an outbreak, subsequently dying, and H. T. Ricketts, another zoologist who had died from typhus while investigating it. Once these crucial facts were recognized, Rudolf Weigl in 1930 was able to fashion a practical and effective vaccine production method. He ground up the insides of infected lice that had been drinking blood. It was, however, very dangerous to produce, and carried a high likelihood of infection to those who were working on it.\nA safer mass-production-ready method using egg yolks was developed by Herald R. Cox in 1938. This vaccine was widely available and used extensively by 1943.\nDiagnosis.\nIFA, ELISA or PCR positive after 10 days.\nTreatment.\nThe infection is treated with antibiotics. Intravenous fluids and oxygen may be needed to stabilize the patient. There is a significant disparity between the untreated mortality and treated mortality rates: 10-60% untreated versus close to 0% treated with antibiotics within 8 days of initial infection. Tetracycline, chloramphenicol, and doxycycline are commonly used.\nSome of the simplest methods of prevention and treatment focus on preventing infestation of body lice. Completely changing the clothing, washing the infested clothing in hot water, and in some cases also treating recently used bedsheets all help to prevent typhus by removing potentially infected lice. Clothes left unworn and unwashed for 7 days also result in the death of both lice and their eggs, as they have no access to a human host. Another form of lice prevention requires dusting infested clothing with a powder consisting of 10% DDT, 1% malathion, or 1% permethrin, which kill lice and their eggs.\nOther preventive measures for individuals are to avoid unhygienic, extremely overcrowded areas where the causative organisms can jump from person to person. In addition, they are warned to keep a distance from larger rodents that carry lice, such as rats, squirrels, or opossums.\nHistory.\nHistory of outbreaks.\nBefore 19th century.\nDuring the second year of the Peloponnesian War (430 BC), the city-state of Athens in ancient Greece had an epidemic, known as the Plague of Athens, which killed, among others, Pericles and his two elder sons. The plague returned twice more, in 429 BC and in the winter of 427/6 BC. Epidemic typhus is proposed as a strong candidate for the cause of this disease outbreak, supported by both medical and scholarly opinions.\nThe first description of typhus was probably given in 1083 at La Cava abbey near Salerno, Italy. In 1546, Girolamo Fracastoro, a Florentine physician, described typhus in his famous treatise on viruses and contagion, \"De Contagione et Contagiosis Morbis\".\nTyphus was carried to mainland Europe by soldiers who had been fighting on Cyprus. The first reliable description of the disease appears during the siege of the Emirate of Granada by the Catholic Monarchs in 1489 during the Granada War. These accounts include descriptions of fever and red spots over arms, back and chest, progressing to delirium, gangrenous sores, and the stench of rotting flesh. During the siege, the Catholics lost 3,000 men to enemy action, but an additional 17,000 died of typhus.\nTyphus was also common in prisons (and in crowded conditions where lice spread easily), where it was known as \"Gaol fever\" or \"Jail fever\". Gaol fever often occurs when prisoners are frequently huddled together in dark, filthy rooms. Imprisonment until the next term of court was often equivalent to a death sentence. Typhus was so infectious that prisoners brought before the court sometimes infected the court itself. Following the Black Assize of Oxford 1577, over 510 died from epidemic typhus, including Speaker Robert Bell, Lord Chief Baron of the Exchequer. The outbreak that followed, between 1577 and 1579, killed about 10% of the English population. \nDuring the Lent assize held at Taunton (1730), typhus caused the death of the Lord Chief Baron of the Exchequer, the High Sheriff of Somerset, the sergeant, and hundreds of other persons. During a time when there were 241 capital offences, more prisoners died from 'gaol fever' than were put to death by all the public executioners in the realm. In 1759 an English authority estimated that each year a quarter of the prisoners had died from gaol fever. In London, typhus frequently broke out among the ill-kept prisoners of Newgate Gaol and moved into the general city population.\n19th century.\nEpidemics occurred in the British Isles and throughout Europe, for instance, during the English Civil War, the Thirty Years' War, and the Napoleonic Wars. Many historians believe that the typhus outbreak among Napoleon's troops is the real reason why he stalled his military campaign into Russia, rather than starvation or the cold. A major epidemic occurred in Ireland between 1816 and 1819, and again in the late 1830s. Another major typhus epidemic occurred during the Great Irish Famine between 1846 and 1849. The Irish typhus spread to England, where it was sometimes called \"Irish fever\" and was noted for its virulence. It killed people of all social classes since lice were endemic and inescapable, but it hit particularly hard in the lower or \"unwashed\" social strata. It was carried to North America by the many Irish refugees who fled the famine. In Canada, the 1847 North American typhus epidemic killed more than 20,000 people, mainly Irish immigrants in fever sheds and other forms of quarantine, who had contracted the disease aboard coffin ships. As many as 900,000 deaths have been attributed to the typhus fever during the Crimean War in 1853\u20131856, and 270,000 to the 1866 Finnish typhus epidemic.\nIn the United States, a typhus epidemic struck Philadelphia in 1837. The son of Franklin Pierce died in 1843 of a typhus epidemic in Concord, New Hampshire. Several epidemics occurred in Baltimore, Memphis, and Washington, D.C. between 1865 and 1873. Typhus fever was also a significant killer during the American Civil War, although typhoid fever was the more prevalent cause of US Civil War \"camp fever.\" Typhoid is a completely different disease from typhus. Typically more men died on both sides of disease than wounds.\nRudolph Carl Virchow, a physician, anthropologist, and historian attempted to control an outbreak of typhus in Upper Silesia and wrote a 190-page report about it. He concluded that the solution to the outbreak did not lie in individual treatment or by providing small changes in housing, food or clothing, but rather in widespread structural changes to directly address the issue of poverty. Virchow's experience in Upper Silesia led to his observation that \"Medicine is a social science\". His report led to changes in German public health policy.\n20th century.\nTyphus was endemic in Poland and several neighboring countries prior to World War I (1914\u20131918). During and shortly after the war, epidemic typhus caused up to three million deaths in Russia, and several million citizens also died in Poland and Romania. Since 1914, many troops, prisoners and even doctors were infected, and at least 150,000 died from typhus in Serbia, 50,000 of whom were prisoners. Delousing stations were established for troops on the Western Front, but the disease ravaged the armies of the Eastern Front. Fatalities were generally between 10 and 40 percent of those infected, and the disease was a major cause of death for those nursing the sick. During World War I and the Russian Civil War between the White and Red, the typhus epidemic caused 2\u20133 million deaths out of 20\u201330 million cases in Russia between 1918 and 1922.\nTyphus caused hundreds of thousands of deaths during World War II. It struck the German Army during Operation Barbarossa, the invasion of Russia, in 1941. In 1942 and 1943 typhus hit French North Africa, Egypt and Iran particularly hard. Typhus epidemics killed inmates in the Nazi concentration camps and death camps such as Auschwitz, Dachau, Theresienstadt, and Bergen-Belsen. Footage shot at Bergen-Belsen concentration camp shows the mass graves for typhus victims. Anne Frank, at age 15, and her sister Margot both died of typhus in the camps. Even larger epidemics in the post-war chaos of Europe were averted only by the widespread use of the newly discovered DDT to kill lice on the millions of refugees and displaced persons.\nFollowing the development of a vaccine during World War II, Western Europe and North America have been able to prevent epidemics. These have usually occurred in Eastern Europe, the Middle East, and parts of Africa, particularly Ethiopia. Naval Medical Research Unit Five worked there with the government on research to attempt to eradicate the disease.\nIn one of its first major outbreaks since World War II, epidemic typhus reemerged in 1995 in a jail in N'Gozi, Burundi. This outbreak followed the start of the Burundian Civil War in 1993, which caused the displacement of 760,000 people. Refugee camps were crowded and unsanitary, and often far from towns and medical services.\n21st century.\nA 2005 study found seroprevalence of \"R. prowazekii\" antibodies in homeless populations in two shelters in Marseille, France. The study noted the \"hallmarks of epidemic typhus and relapsing fever\".\nHistory of vaccines.\nMajor developments for typhus vaccines started during World War I, as typhus caused high mortality, and threatened the health and readiness for soldiers on the battlefield. Vaccines for typhus, like other vaccines of the time, were classified as either living or killed vaccines. Live vaccines were typically an injection of live agent, and killed vaccines are live cultures of an agent that are chemically inactivated prior to use.\nAttempts to create a living vaccine of classical, louse-borne, typhus were attempted by French researchers but these proved unsuccessful. Researchers turned to murine typhus to develop a live vaccine. At the time, murine vaccine was viewed as a less severe alternative to classical typhus. Four versions of a live vaccine cultivated from murine typhus were tested, on a large scale, in 1934.\nWhile the French were making advancements with live vaccines, other European countries were working to develop killed vaccines. During World War II, there were three kinds of potentially useful killed vaccines. All three killed vaccines relied on the cultivation of \"Rickettsia prowazekii\", the organism responsible for typhus. The first attempt at a killed vaccine was developed by Germany, using the \"Rickettsia prowazekii\" found in louse feces. The vaccine was tested extensively in Poland between the two world wars and used by the Germans for their troops during their attacks on the Soviet Union.\nA second method of growing \"Rickettsia prowazekii\" was discovered using the yolk sac of chick embryos. Germans tried several times to use this technique of growing \"Rickettsia prowazekii\" but no effort was pushed very far.\nThe last technique was an extended development of the previously known method of growing murine typhus in rodents. It was discovered that rabbits could be infected, by a similar process, and contract classical typhus instead of murine typhus. Again, while proven to produce suitable \"Rickettsia prowazekii\" for vaccine development, this method was not used to produce wartime vaccines.\nDuring WWII, the two major vaccines available were the killed vaccine grown in lice and the live vaccine from France. Neither was used much during the war. The killed, louse-grown vaccine was difficult to manufacture in large enough quantities, and the French vaccine was not believed to be safe enough for use.\nThe Germans worked to develop their own live vaccine from the urine of typhus victims. While developing a live vaccine, Germany used live \"Rickettsia prowazekii\" to test multiple possible vaccines' capabilities. They gave live \"Rickettsia prowazekii\" to concentration camp prisoners, using them as a control group for the vaccine tests.\nThe use of DDT as an effective means of killing lice, the main carrier of typhus, was discovered in Naples.\nSociety and culture.\nBiological weapon.\nTyphus was one of more than a dozen agents that the United States researched as potential biological weapons before President Richard Nixon suspended all non-defensive aspects of the U.S. biological weapons program in 1969.\nPoverty and displacement.\nThe CDC lists the following areas as active foci of human epidemic typhus: Andean regions of South America, some parts of Africa; on the other hand, the CDC only recognizes an active enzootic cycle in the United States involving flying squirrels (CDC). Though epidemic typhus is commonly thought to be restricted to areas of the developing world, serological examination of homeless persons in Houston found evidence for exposure to the bacterial pathogens that cause epidemic typhus and murine typhus. A study involving 930 homeless people in Marseille, France, found high rates of seroprevalence to \"R. prowazekii\" and a high prevalence of louse-borne infections in the homeless.\nTyphus has been increasingly discovered in homeless populations in developed nations. Typhus among homeless populations is especially prevalent as these populations tend to migrate across states and countries, spreading the risk of infection with their movement. The same risk applies to refugees, who travel across country lines, often living in close proximity and unable to maintain necessary hygienic standards to avoid being at risk for catching lice possibly infected with typhus.\nBecause the typhus-infected lice live in clothing, the prevalence of typhus is also affected by weather, humidity, poverty and lack of hygiene. Lice, and therefore typhus, are more prevalent during colder months, especially winter and early spring. In these seasons, people tend to wear multiple layers of clothing, giving lice more places to go unnoticed by their hosts. This is particularly a problem for poverty-stricken populations as they often do not have multiple sets of clothing, preventing them from practicing good hygiene habits that could prevent louse infestation.\nDue to fear of an outbreak of epidemic typhus, the US Government put a typhus quarantine in place in 1917 across the entirety of the US-Mexican border. Sanitation plants were constructed that required immigrants to be thoroughly inspected and bathed before crossing the border. Those who routinely crossed back and forth across the border for work were required to go through the sanitation process weekly, updating their quarantine card with the date of the next week's sanitation. These sanitation border stations remained active over the next two decades, regardless of the disappearance of the typhus threat. This fear of typhus and resulting quarantine and sanitation protocols dramatically hardened the border between the US and Mexico, fostering scientific and popular prejudices against Mexicans. This ultimately intensified racial tensions and fueled efforts to ban immigrants to the US from the Southern Hemisphere because the immigrants were associated with the disease.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n55. \u2191 Alice S. Chapman (2006). \"Cluster of Sylvatic Epidemic Typhus Cases Associated with Flying Squirrels, 2004 - 2006\" MedscapeCME https://"}
{"id": "46178", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=46178", "title": "SQUID", "text": "Type of magnetometer\nA SQUID (superconducting quantum interference device) is a very sensitive magnetometer used to measure extremely weak magnetic fields, based on superconducting loops containing Josephson junctions.\nSQUIDs are sensitive enough to measure fields as low as 5\u00d710\u221218 T with a few days of averaged measurements. Their noise levels are as low as 3 fT\u00b7Hz\u2212&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442. For comparison, a typical refrigerator magnet produces 0.01 tesla (10\u22122 T), and some processes in animals produce very small magnetic fields between 10\u22129 T and 10\u22126 T. SERF atomic magnetometers, invented in the early 2000s are potentially more sensitive and do not require cryogenic refrigeration but are orders of magnitude larger in size (~1\u00a0cm3) and must be operated in a near-zero magnetic field.\nHistory and design.\nThere are two main types of SQUID: direct current (DC) and radio frequency (RF). RF SQUIDs can work with only one Josephson junction (superconducting tunnel junction), which might make them cheaper to produce, but are less sensitive.\nDC SQUID.\nThe DC SQUID was invented in 1964 by Robert Jaklevic, John J. Lambe, James Mercereau, and Arnold Silver of Ford Research Labs after Brian Josephson postulated the Josephson effect in 1962, and the first Josephson junction was made by John Rowell and Philip Anderson at Bell Labs in 1963. It has two Josephson junctions in parallel in a superconducting loop. It is based on the DC Josephson effect. In the absence of any external magnetic field, the input current formula_1 splits into the two branches equally. If a small external magnetic field is applied to the superconducting loop, a screening current, formula_2, begins to circulate the loop that generates the magnetic field canceling the applied external flux, and creates an additional Josephson phase which is proportional to this external magnetic flux. The induced current is in the same direction as formula_1 in one of the branches of the superconducting loop, and is opposite to formula_1 in the other branch; the total current becomes formula_5 in one branch and formula_6 in the other. As soon as the current in either branch exceeds the critical current, formula_7, of the Josephson junction, a voltage appears across the junction.\nNow suppose the external flux is further increased until it exceeds formula_8, half the magnetic flux quantum. Since the flux enclosed by the superconducting loop must be an integer number of flux quanta, instead of screening the flux the SQUID now energetically prefers to increase it to formula_9. The current now flows in the opposite direction, opposing the difference between the admitted flux formula_9 and the external field of just over formula_8. The current decreases as the external field is increased, is zero when the flux is exactly formula_9, and again reverses direction as the external field is further increased. Thus, the current changes direction periodically, every time the flux increases by additional half-integer multiple of formula_9, with a change at maximum amperage every half-plus-integer multiple of formula_9 and at zero amps every integer multiple.\nIf the input current is more than formula_7, then the SQUID always operates in the resistive mode. The voltage, in this case, is thus a function of the applied magnetic field and the period equal to formula_9. Since the current-voltage characteristic of the DC SQUID is hysteretic, a shunt resistance, formula_17 is connected across the junction to eliminate the hysteresis (in the case of copper oxide based high-temperature superconductors the junction's own intrinsic resistance is usually sufficient). The screening current is the applied flux divided by the self-inductance of the ring. Thus formula_18 can be estimated as the function of formula_19 (flux to voltage converter) as follows:\nformula_20\nformula_21, where formula_22 is the self inductance of the superconducting ring\nformula_23\nThe discussion in this section assumed perfect flux quantization in the loop. However, this is only true for big loops with a large self-inductance. According to the relations, given above, this implies also small current and voltage variations. In practice the self-inductance formula_22 of the loop is not so large. The general case can be evaluated by introducing a parameter\nformula_25\nwhere formula_26 is the critical current of the SQUID. Usually formula_27 is of order one.\nRF SQUID.\nThe RF SQUID was invented in 1967 by Robert Jaklevic, John J. Lambe, Arnold Silver, and James Edward Zimmerman at Ford. It is based on the AC Josephson effect and uses only one Josephson junction. It is less sensitive compared to DC SQUID but is cheaper and easier to manufacture in smaller quantities. Most fundamental measurements in biomagnetism, even of extremely small signals, have been made using RF SQUIDS.\nThe RF SQUID is inductively coupled to a resonant tank circuit. Depending on the external magnetic field, as the SQUID operates in the resistive mode, the effective inductance of the tank circuit changes, thus changing the resonant frequency of the tank circuit. These frequency measurements can be easily taken, and thus the losses which appear as the voltage across the load resistor in the circuit are a periodic function of the applied magnetic flux with a period of formula_9. For a precise mathematical description refer to the original paper by Ern\u00e9 et al.\nMaterials used.\nThe traditional superconducting materials for SQUIDs are pure niobium or a lead alloy with 10% gold or indium, as pure lead is unstable when its temperature is repeatedly changed. To maintain superconductivity, the entire device needs to operate within a few degrees of absolute zero, cooled with liquid helium.\nHigh-temperature SQUID sensors were developed in the late 1980s. They are made of high-temperature superconductors, particularly YBCO, and are cooled by liquid nitrogen which is cheaper and more easily handled than liquid helium. They are less sensitive than conventional low temperature SQUIDs but good enough for many applications.\nIn 2006, A proof of concept was shown for CNT-SQUID sensors built with an aluminium loop and a single walled carbon nanotube Josephson junction. The sensors are a few 100\u00a0nm in size and operate at 1K or below. Such sensors allow to count spins.\nIn 2022 a SQUID was constructed on magic angle twisted bilayer graphene (MATBG)\nUses.\nThe extreme sensitivity of SQUIDs makes them ideal for studies in biology. Magnetoencephalography (MEG), for example, uses measurements from an array of SQUIDs to make inferences about neural activity inside brains. Because SQUIDs can operate at acquisition rates much higher than the highest temporal frequency of interest in the signals emitted by the brain (kHz), MEG achieves good temporal resolution. Another area where SQUIDs are used is magnetogastrography, which is concerned with recording the weak magnetic fields of the stomach. A novel application of SQUIDs is the magnetic marker monitoring method, which is used to trace the path of orally applied drugs. In the clinical environment SQUIDs are used in cardiology for magnetic field imaging (MFI), which detects the magnetic field of the heart for diagnosis and risk stratification.\nProbably the most common commercial use of SQUIDs is in magnetic property measurement systems (MPMS). These are turn-key systems, made by several manufacturers, that measure the magnetic properties of a material sample which typically has a temperature between 300 mK and 400 K. With the decreasing size of SQUID sensors since the last decade, such sensor can equip the tip of an AFM probe. Such device allows simultaneous measurement of roughness of the surface of a sample and the local magnetic flux.\nFor example, SQUIDs are being used as detectors to perform magnetic resonance imaging (MRI). While high-field MRI uses precession fields of one to several teslas, SQUID-detected MRI uses measurement fields that lie in the microtesla range. In a conventional MRI system, the signal scales as the square of the measurement frequency (and hence precession field): one power of frequency comes from the thermal polarization of the spins at ambient temperature, while the second power of frequency comes from the fact that the induced voltage in the pickup coil is proportional to the frequency of the precessing magnetization. In the case of untuned SQUID detection of prepolarized spins, however, the NMR signal strength is independent of precession field, allowing MRI signal detection in extremely weak fields, on the order of Earth's magnetic field. SQUID-detected MRI has advantages over high-field MRI systems, such as the low cost required to build such a system, and its compactness. The principle has been demonstrated by imaging human extremities, and its future application may include tumor screening.\nAnother application is the scanning SQUID microscope, which uses a SQUID immersed in liquid helium as the probe. The use of SQUIDs in oil prospecting, mineral exploration, earthquake prediction and geothermal energy surveying is becoming more widespread as superconductor technology develops; they are also used as precision movement sensors in a variety of scientific applications, such as the detection of gravitational waves.\nA SQUID is the sensor in each of the four gyroscopes employed on Gravity Probe B in order to test the limits of the theory of general relativity.\nA modified RF SQUID was used to observe the dynamical Casimir effect for the first time.\nSQUIDs constructed from super-cooled niobium wire loops are used as the basis for D-Wave Systems 2000Q quantum computer.\nTransition-edge sensors.\nOne of the largest uses of SQUIDs is to read out superconducting Transition-edge sensors. Hundreds of thousands of multiplexed SQUIDs coupled to transition-edge sensors are presently being deployed to study the Cosmic microwave background, for X-ray astronomy, to search for dark matter made up of Weakly interacting massive particles, and for spectroscopy at Synchrotron light sources.\nCold dark matter.\nAdvanced SQUIDS called near quantum-limited SQUID amplifiers form the basis of the Axion Dark Matter Experiment (ADMX) at the University of Washington. Axions are a prime candidate for cold dark matter.\nProposed uses.\nA potential military application exists for use in anti-submarine warfare as a magnetic anomaly detector (MAD) fitted to maritime patrol aircraft.\nSQUIDs are used in superparamagnetic relaxometry (SPMR), a technology that utilizes the high magnetic field sensitivity of SQUID sensors and the superparamagnetic properties of magnetite nanoparticles. These nanoparticles are paramagnetic; they have no magnetic moment until exposed to an external field where they become ferromagnetic. After removal of the magnetizing field, the nanoparticles decay from a ferromagnetic state to a paramagnetic state, with a time constant that depends upon the particle size and whether they are bound to an external surface. Measurement of the decaying magnetic field by SQUID sensors is used to detect and localize the nanoparticles. Applications for SPMR may include cancer detection.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46182", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=46182", "title": "White noise", "text": "Type of signal in signal processing\nIn signal processing, white noise is a random signal having equal intensity at different frequencies, giving it a constant power spectral density. The term is used with this or similar meanings in many scientific and technical disciplines, including physics, acoustical engineering, telecommunications, and statistical forecasting. White noise refers to a statistical model for signals and signal sources, not to any specific signal. White noise draws its name from white light, although light that appears white generally does not have a flat power spectral density over the visible band.\nIn discrete time, white noise is a discrete signal whose samples are regarded as a sequence of serially uncorrelated random variables with a mean of zero and a finite variance; a single realization of white noise is a random shock. In some contexts, it is also required that the samples be independent and have identical probability distribution (in other words independent and identically distributed random variables are the simplest representation of white noise). In particular, if each sample has a normal distribution with zero mean, the signal is said to be additive white Gaussian noise.\nThe samples of a white noise signal may be sequential in time, or arranged along one or more spatial dimensions. In digital image processing, the pixels of a white noise image are typically arranged in a rectangular grid, and are assumed to be independent random variables with uniform probability distribution over some interval. The concept can be defined also for signals spread over more complicated domains, such as a sphere or a torus.\nAn &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;infinite-bandwidth white noise signal is a purely theoretical construction. The bandwidth of white noise is limited in practice by the mechanism of noise generation, by the transmission medium and by finite observation capabilities. Thus, random signals are considered white noise if they are observed to have a flat spectrum over the range of frequencies that are relevant to the context. For an audio signal, the relevant range is the band of audible sound frequencies (between 20 and 20,000 Hz). Such a signal is heard by the human ear as a hissing sound, resembling the /h/ sound in a sustained aspiration. On the other hand, the \"sh\" sound in \"ash\" is a colored noise because it has a formant structure. In music and acoustics, the term \"white noise\" may be used for any signal that has a similar hissing sound.\nIn the context of phylogenetically based statistical methods, the term \"white noise\" can refer to a lack of phylogenetic pattern in comparative data. In nontechnical contexts, it is sometimes used to mean \"random talk without meaningful contents\".\nStatistical properties.\nAny distribution of values is possible (although it must have zero DC component). Even a binary signal which can only take on the values 1 or -1 will be white if the sequence is statistically uncorrelated. Noise having a continuous distribution, such as a normal distribution, can of course be white.\nIt is often incorrectly assumed that Gaussian noise (i.e., noise with a Gaussian amplitude distribution\u00a0\u2013 see normal distribution) necessarily refers to white noise, yet neither property implies the other. Gaussianity refers to the probability distribution with respect to the value, in this context the probability of the signal falling within any particular range of amplitudes, while the term 'white' refers to the way the signal power is distributed (i.e., independently) over time or among frequencies.\nOne form of white noise is the generalized mean-square derivative of the Wiener process or Brownian motion.\nA generalization to random elements on infinite dimensional spaces, such as random fields, is the white noise measure.\nPractical applications.\nMusic.\nWhite noise is commonly used in the production of electronic music, usually either directly or as an input for a filter to create other types of noise signal. It is used extensively in audio synthesis, typically to recreate percussive instruments such as cymbals or snare drums which have high noise content in their frequency domain. A simple example of white noise is a nonexistent radio station (static).\nElectronics engineering.\nWhite noise is also used to obtain the impulse response of an electrical circuit, in particular of amplifiers and other audio equipment. It is not used for testing loudspeakers as its spectrum contains too great an amount of high-frequency content. Pink noise, which differs from white noise in that it has equal energy in each octave, is used for testing transducers such as loudspeakers and microphones.\nComputing.\nWhite noise is used as the basis of some random number generators. For example, Random.org uses a system of atmospheric antennas to generate random digit patterns from sources that can be well-modeled by white noise.\nTinnitus treatment.\nWhite noise is a common synthetic noise source used for sound masking by a tinnitus masker. White noise machines and other white noise sources are sold as privacy enhancers and sleep aids (see music and sleep) and to mask tinnitus. The Marpac Sleep-Mate was the first domestic use white noise machine built in 1962 by traveling salesman Jim Buckwalter. Alternatively, the use of an AM radio tuned to unused frequencies (\"static\") is a simpler and more cost-effective source of white noise. However, white noise generated from a common commercial radio receiver tuned to an unused frequency is extremely vulnerable to being contaminated with spurious signals, such as adjacent radio stations, harmonics from non-adjacent radio stations, electrical equipment in the vicinity of the receiving antenna causing interference, or even atmospheric events such as solar flares and especially lightning.\nWork environment.\nThe effects of white noise upon cognitive function are mixed. A small study published in 2007 found that white noise background stimulation improves cognitive functioning among secondary students with attention deficit hyperactivity disorder (ADHD), while decreasing performance of non-ADHD students. Other work indicates it is effective in improving the mood and performance of workers by masking background office noise, but decreases cognitive performance in complex card sorting tasks.\nSimilarly, an experiment was carried out on sixty-six healthy participants to observe the benefits of using white noise in a learning environment. The experiment involved the participants identifying different images whilst having different sounds in the background. Overall the experiment showed that white noise does in fact have benefits in relation to learning. The experiments showed that white noise improved the participants' learning abilities and their recognition memory slightly.\nMathematical definitions.\nWhite noise vector.\nA random vector (that is, a random variable with values in \"Rn\") is said to be a white noise vector or white random vector if its components each have a probability distribution with zero mean and finite variance, and are statistically independent: that is, their joint probability distribution must be the product of the distributions of the individual components.\nA necessary (but, in general, not sufficient) condition for statistical independence of two variables is that they be statistically uncorrelated; that is, their covariance is zero. Therefore, the covariance matrix \"R\" of the components of a white noise vector \"w\" with \"n\" elements must be an \"n\" by \"n\" diagonal matrix, where each diagonal element \"Rii\" is the variance of component \"wi\"; and the correlation matrix must be the \"n\" by \"n\" identity matrix.\nIf, in addition to being independent, every variable in \"w\" also has a normal distribution with zero mean and the same variance formula_1, \"w\" is said to be a Gaussian white noise vector. In that case, the joint distribution of \"w\" is a multivariate normal distribution; the independence between the variables then implies that the distribution has spherical symmetry in \"n\"-dimensional space. Therefore, any orthogonal transformation of the vector will result in a Gaussian white random vector. In particular, under most types of discrete Fourier transform, such as FFT and Hartley, the transform \"W\" of \"w\" will be a Gaussian white noise vector, too; that is, the \"n\" Fourier coefficients of \"w\" will be independent Gaussian variables with zero mean and the same variance formula_1.\nThe power spectrum \"P\" of a random vector \"w\" can be defined as the expected value of the squared modulus of each coefficient of its Fourier transform \"W\", that is, \"Pi\" = E(|\"Wi\"|2). Under that definition, a Gaussian white noise vector will have a perfectly flat power spectrum, with \"Pi\"\u00a0=\u00a0\"\u03c3\"2 for all\u00a0\"i\".\nIf \"w\" is a white random vector, but not a Gaussian one, its Fourier coefficients \"Wi\" will not be completely independent of each other; although for large \"n\" and common probability distributions the dependencies are very subtle, and their pairwise correlations can be assumed to be zero.\nOften the weaker condition statistically uncorrelated is used in the definition of white noise, instead of statistically independent. However, some of the commonly expected properties of white noise (such as flat power spectrum) may not hold for this weaker version. Under this assumption, the stricter version can be referred to explicitly as independent white noise vector. Other authors use strongly white and weakly white instead.\nAn example of a random vector that is Gaussian white noise in the weak but not in the strong sense is formula_3 where formula_4 is a normal random variable with zero mean, and formula_5 is equal to formula_6 or to formula_7, with equal probability. These two variables are uncorrelated and individually normally distributed, but they are not jointly normally distributed and are not independent. If formula_8 is rotated by 45 degrees, its two components will still be uncorrelated, but their distribution will no longer be normal.\nIn some situations, one may relax the definition by allowing each component of a white random vector formula_9 to have non-zero expected value formula_10. In image processing especially, where samples are typically restricted to positive values, one often takes formula_10 to be one half of the maximum sample value. In that case, the Fourier coefficient formula_12 corresponding to the zero-frequency component (essentially, the average of the formula_13) will also have a non-zero expected value formula_14; and the power spectrum formula_15 will be flat only over the non-zero frequencies.\nDiscrete-time white noise.\nA discrete-time stochastic process formula_16 is a generalization of a random vector with a finite number of components to infinitely many components. A discrete-time stochastic process formula_16 is called white noise if its mean is equal to zero for all formula_18 , i.e. formula_19 and if the autocorrelation function formula_20 has a nonzero value only for formula_21, i.e. formula_22.\nContinuous-time white noise.\nIn order to define the notion of white noise in the theory of continuous-time signals, one must replace the concept of a random vector by a continuous-time random signal; that is, a random process that generates a function formula_9 of a real-valued parameter formula_24.\nSuch a process is said to be white noise in the strongest sense if the value formula_25 for any time formula_24 is a random variable that is statistically independent of its entire history before formula_24. A weaker definition requires independence only between the values formula_28 and formula_29 at every pair of distinct times formula_30 and formula_31. An even weaker definition requires only that such pairs formula_28 and formula_29 be uncorrelated. As in the discrete case, some authors adopt the weaker definition for white noise, and use the qualifier independent to refer to either of the stronger definitions. Others use weakly white and strongly white to distinguish between them.\nHowever, a precise definition of these concepts is not trivial, because some quantities that are finite sums in the finite discrete case must be replaced by integrals that may not converge. Indeed, the set of all possible instances of a signal formula_9 is no longer a finite-dimensional space formula_35, but an infinite-dimensional function space. Moreover, by any definition a white noise signal formula_9 would have to be essentially discontinuous at every point; therefore even the simplest operations on formula_9, like integration over a finite interval, require advanced mathematical machinery.\nSome authors require each value formula_25 to be a real-valued random variable with expectation formula_10 and some finite variance formula_1. Then the covariance formula_41 between the values at two times formula_30 and formula_31 is well-defined: it is zero if the times are distinct, and formula_1 if they are equal. However, by this definition, the integral\n formula_45\nover any interval with positive width formula_46 would be simply the width times the expectation: formula_47. This property renders the concept inadequate as a model of white noise signals either in a physical or mathematical sense.\nTherefore, most authors define the signal formula_9 indirectly by specifying random values for the integrals of formula_25 and formula_50 over each interval formula_51. In this approach, however, the value of formula_25 at an isolated time cannot be defined as a real-valued random variable. Also the covariance formula_41 becomes infinite when formula_54; and the autocorrelation function formula_55 must be defined as formula_56, where formula_57 is some real constant and formula_58 is the Dirac delta function.\nIn this approach, one usually specifies that the integral formula_59 of formula_25 over an interval formula_61 is a real random variable with normal distribution, zero mean, and variance formula_62; and also that the covariance formula_63 of the integrals formula_59, formula_65 is formula_66, where formula_46 is the width of the intersection formula_68 of the two intervals formula_69. This model is called a Gaussian white noise signal (or process).\nIn the mathematical field known as white noise analysis, a Gaussian white noise formula_9 is defined as a stochastic tempered distribution, i.e. a random variable with values in the space formula_71 of tempered distributions. Analogous to the case for finite-dimensional random vectors, a probability law on the infinite-dimensional space formula_71 can be defined via its characteristic function (existence and uniqueness are guaranteed by an extension of the Bochner\u2013Minlos theorem, which goes under the name Bochner\u2013Minlos\u2013Sazanov theorem); analogously to the case of the multivariate normal distribution formula_73, which has characteristic function\n formula_74\nthe white noise formula_75 must satisfy\n formula_76\nwhere formula_77 is the natural pairing of the tempered distribution formula_78 with the Schwartz function formula_79 (i.e. we consider formula_79 as a fixed linear function on formula_71 analogous to formula_82 above) and formula_83.\nMathematical applications.\nTime series analysis and regression.\nIn statistics and econometrics one often assumes that an observed series of data values is the sum of the values generated by a deterministic linear process, depending on certain independent (explanatory) variables, and on a series of random noise values. Then regression analysis is used to infer the parameters of the model process from the observed data, e.g. by ordinary least squares, and to test the null hypothesis that each of the parameters is zero against the alternative hypothesis that it is non-zero. Hypothesis testing typically assumes that the noise values are mutually uncorrelated with zero mean and have the same Gaussian probability distribution\u00a0\u2013 in other words, that the noise is Gaussian white (not just white). If there is non-zero correlation between the noise values underlying different observations then the estimated model parameters are still unbiased, but estimates of their uncertainties (such as confidence intervals) will be biased (not accurate on average). This is also true if the noise is heteroskedastic\u00a0\u2013 that is, if it has different variances for different data points.\nAlternatively, in the subset of regression analysis known as time series analysis there are often no explanatory variables other than the past values of the variable being modeled (the dependent variable). In this case the noise process is often modeled as a moving average process, in which the current value of the dependent variable depends on current and past values of a sequential white noise process.\nRandom vector transformations.\nThese two ideas are crucial in applications such as channel estimation and channel equalization in communications and audio. These concepts are also used in data compression.\nIn particular, by a suitable linear transformation (a coloring transformation), a white random vector can be used to produce a non-white random vector (that is, a list of random variables) whose elements have a prescribed covariance matrix. Conversely, a random vector with known covariance matrix can be transformed into a white random vector by a suitable whitening transformation.\nGeneration.\nWhite noise may be generated digitally with a digital signal processor, microprocessor, or microcontroller. Generating white noise typically entails feeding an appropriate stream of random numbers to a digital-to-analog converter. The quality of the white noise will depend on the quality of the algorithm used.\nInformal use.\nThe term is sometimes used as a colloquialism to describe a backdrop of ambient sound, creating an indistinct or seamless commotion. Following are some examples:\nThe term can also be used metaphorically, as in the novel \"White Noise\" (1985) by Don DeLillo which explores the symptoms of modern culture that came together so as to make it difficult for an individual to actualize their ideas and personality.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46183", "revid": "2663551", "url": "https://en.wikipedia.org/wiki?curid=46183", "title": "Butter", "text": "Dairy product\nButter is a dairy product made from the fat and protein components of churned cream. It is a semi-solid emulsion at room temperature, consisting of approximately 81% butterfat. It is used at room temperature as a spread, melted as a condiment, and used as a fat in baking, sauce-making, pan frying, and other cooking procedures.\nMost frequently made from cow's milk, butter can also be manufactured from the milk of other mammals, including sheep, goats, buffalo, and yaks. It is made by churning milk or cream to separate the fat globules from the buttermilk. Salt has been added to butter since antiquity to help preserve it, particularly when being transported; salt may still play a preservation role but is less important today as the entire supply chain is usually refrigerated. In modern times, salt may be added for taste and food coloring added for color. Rendering butter, removing the water and milk solids, produces clarified butter (including \"ghee\"), which is almost entirely butterfat.\nButter is a gel. \nButter remains a firm solid when refrigerated but softens to a spreadable consistency at room temperature and melts to a thin liquid consistency at . The density of butter is . It generally has a pale yellow color but varies from deep yellow to nearly white. Its natural, unmodified color is dependent on the source animal's feed and genetics, but the commercial manufacturing process sometimes alters this with food colorings like annatto or carotene.\nIn 2022, world production of butter made from cow milk was 6 million tonnes, led by the United States with 13% of the total.\nEtymology.\nThe word \"butter\" derives (via Germanic languages) from the Latin \"butyrum\", which is the latinisation of the Greek \u03b2\u03bf\u03cd\u03c4\u03c5\u03c1\u03bf\u03bd (\"bouturon\") and \u03b2\u03bf\u03cd\u03c4\u03c5\u03c1\u03bf\u03c2. This may be a compound of \u03b2\u03bf\u1fe6\u03c2 (\"bous\"), \"ox, cow\" + \u03c4\u03c5\u03c1\u03cc\u03c2 (\"turos\"), \"cheese\", that is \"cow-cheese\". The word \"turos\" (\"cheese\") is attested in Mycenaean Greek. The Latinized form is found in the name butyric acid, a compound found in rancid butter and other dairy products.\nProduction.\nUnhomogenized milk and cream contain butterfat in microscopic globules. These globules are surrounded by membranes made of phospholipids (fatty acid emulsifiers) and proteins, which prevent the fat in milk from pooling together into a single mass. Butter is produced by agitating cream, which damages these membranes and allows the milk fats to conjoin, separating from the other parts of the cream. Variations in the production method will create butters with different consistencies, mostly due to the butterfat composition in the finished product. Butter contains fat in three separate forms: free butterfat, butterfat crystals, and undamaged fat globules. In the finished product, different proportions of these forms result in different consistencies within the butter; butters with many crystals are harder than butters dominated by free fats.\nChurning produces small butter grains floating in the water-based portion of the cream. This watery liquid is called buttermilk, although the buttermilk most commonly sold today is instead directly fermented skimmed milk. The buttermilk is drained off; sometimes more buttermilk is removed by rinsing the grains with water. Then the grains are \"worked\": pressed and kneaded together. When prepared manually, this is done using wooden boards called scotch hands. This consolidates the butter into a solid mass and breaks up embedded pockets of buttermilk or water into tiny droplets.\nCommercial butter is about 80% butterfat and 15% water; traditionally-made butter may have as little as 65% fat and 30% water. Butterfat is a mixture of triglyceride, a triester derived from glycerol, and three of any of several fatty acid groups. Annatto is sometimes added by U.S. butter manufacturers without declaring it on the label because the U.S. allows butter to have an undisclosed flavorless and natural coloring agent (whereas all other foods in the U.S. must label coloring agents). The preservative lactic acid is sometimes added instead of salt (and as a flavor enhancer), and sometimes additional diacetyl is added to boost the buttery flavor (in the U.S., both ingredients can be listed simply as \"natural flavors\"). When used together in the NIZO manufacturing method, these two flavorings produce the flavor of cultured butter without actually fully fermenting.\nTypes.\nBefore modern factory butter making, cream was usually collected from several milkings and was therefore several days old and somewhat fermented by the time it was made into butter. Butter made in this traditional way (from a fermented cream) is known as cultured butter. During fermentation, the cream naturally sours as bacteria convert milk sugars into lactic acid. The fermentation process produces additional aroma compounds, including diacetyl, which makes for a fuller-flavored and more \"buttery\" tasting product.35\nButter made from fresh cream is called sweet cream butter. Production of sweet cream butter first became common in the 19th century, when the development of refrigeration and the mechanical milk separator33 made sweet cream butter faster and cheaper to produce at scale (sweet cream butter can be made in 6 hours, whereas cultured butter can take up to 72 hours to make).\nCultured butter is preferred throughout continental Europe, while sweet cream butter dominates in the United States and the United Kingdom. Chef Jansen Chan, the director of pastry operations at the International Culinary Center in Manhattan, says, \"It's no secret that dairy in France and most of Europe is higher quality than most of the U.S.\" The combination of butter culturing, the 82% butterfat minimum (as opposed to the 80% minimum in the U.S.), and the fact that French butter is grass-fed, accounts for why French pastry (and French food in general) has a reputation for being richer-tasting and flakier. Cultured butter is sometimes labeled \"European-style\" butter in the United States, although cultured butter is made and sold by some, especially Amish, dairies.\nMilk that is to be made into butter is usually pasteurized during production to kill pathogenic bacteria and other microbes. Butter made from unpasteurized raw milk is very rare and can be dangerous. Commercial raw milk products are not legal to sell through interstate commerce in the United States and are very rare in Europe.34 Raw cream butter is not usually available for purchase.\nClarified butter.\nClarified butter has almost all of its water and milk solids removed, leaving almost-pure butterfat. Clarified butter is made by heating butter to its melting point and then allowing it to cool; after settling, the remaining components separate by density. At the top, whey proteins form a skin, which is removed. The resulting butterfat is then poured off from the mixture of water and casein proteins that settle to the bottom.37\nGhee is clarified butter that has been heated to around 120\u00a0\u00b0C (250\u00a0\u00b0F) after the water evaporated, turning the milk solids brown. This process flavors the ghee, and also produces antioxidants that help protect it from rancidity. Because of this, ghee can be kept for six to eight months under normal conditions.37\nWhey butter.\nCream may be separated (usually by a centrifuge or a sedimentation) from whey instead of milk, as a byproduct of cheese-making. Whey butter may be made from whey cream. Whey cream and butter have a lower fat content and taste more salty, tangy and \"cheesy\". They are also cheaper to make than \"sweet\" cream and butter. The fat content of whey is low, so of whey will typically give only of butter.\nProtected origin butters.\nSeveral butters have protected geographical indications; these include:\nHistory.\nElaine Khosrova traces the invention of butter back to the Neolithic era;. it is known to have existed in the Near East following the development of herding. A later Sumerian tablet, dating to approximately 2,500 B.C., describes the butter making process, from the milking of cattle, while contemporary Sumerian tablets identify butter as a ritual offering.\nIn the Mediterranean climate, unclarified butter spoils quickly, unlike cheese, so it is not a practical method of preserving the nutrients of milk. The ancient Greeks and Romans seemed to use the butter only as unguent and medicine and considered it as a food of the barbarians. \nA play by the Greek comic poet Anaxandrides refers to Thracians as \"boutyrophagoi\", \"butter-eaters\". In his \"Natural History\", Pliny the Elder calls butter \"the most delicate of food among barbarous nations\" and goes on to describe its medicinal properties. Later, the physician Galen also described butter as a medicinal agent only.\nMiddle Ages.\nIn the cooler climates of northern Europe, butter could be stored longer before it spoiled. Scandinavia has the oldest tradition in Europe of butter export, dating at least to the 12th century. After the fall of Rome and through much of the Middle Ages, butter was a common food across most of Europe, but had a low reputation, and so was consumed principally by peasants. Butter slowly became more accepted by the upper class, notably when the Roman Catholic Church allowed its consumption during Lent from the early 16th century. Bread and butter became common fare among the middle class and the English, in particular, gained a reputation for their liberal use of melted butter as a sauce with meat and vegetables.33\nIn antiquity, butter was used for fuel in lamps, as a substitute for oil. The \"Butter Tower\" of Rouen Cathedral was erected in the early 16th century when Archbishop Georges d'Amboise authorized the burning of butter during Lent, instead of oil, which was scarce at the time.\nAcross northern Europe, butter was sometimes packed into barrels (firkins) and buried in peat bogs, perhaps for years. Such \"bog butter\" would develop a strong flavor as it aged, but remain edible, in large part because of the cool, airless, antiseptic and acidic environment of a peat bog. Firkins of such buried butter are a common archaeological find in Ireland; the National Museum of Ireland \u2013 Archaeology has some containing \"a grayish cheese-like substance, partially hardened, not much like butter, and quite free from putrefaction.\" The practice was most common in Ireland in the 11th to 14th centuries; it had ended entirely before the 19th century.\nIndustrialization.\nUntil the 19th century, the vast majority of butter was made by hand, on farms, for farm family use or to sell. They used wood presses with carved decoration identifying the producer to press butter into pucks or small bricks to sell at nearby markets or general stores. This practice continued until production was mechanized and butter was produced in less decorative stick form.\nLike Ireland, France became well known for its butter, particularly in Normandy and Brittany. Butter consumption in London in the mid-1840s was estimated at 15,357 tons annually.\nThe first butter factories appeared in the United States in the early 1860s, after the successful introduction of cheese factories a decade earlier. In the late 1870s, the centrifugal cream separator was introduced, marketed most successfully by Swedish engineer Carl Gustaf Patrik de Laval.\nIn 1920, Otto Hunziker wrote \"The Butter Industry, Prepared for Factory, School and Laboratory\"; three editions were printed, in 1920, 1927, and 1940. As part of the efforts of the American Dairy Science Association, Hunziker and others published articles regarding: causes of tallowiness (an odor defect, distinct from rancidity, a taste defect); mottles (an aesthetic issue related to uneven color); introduced salts; the impact of creamery metals and liquids; and acidity measurement. These and other ADSA publications helped standardize practices internationally.\nButter consumption declined in most western nations during the 20th century, mainly because of the rising popularity of margarine, which is less expensive and, until recent years, was perceived as being healthier. In the United States, margarine consumption overtook butter during the 1950s, and it is still the case today that more margarine than butter is eaten in the U.S. and the EU.\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nProduction.\nIn 2022, world production of butter made from cow milk was 6 million tonnes, led by the United States with 13% of the total (table).\nStorage.\nNormal butter softens to a spreadable consistency around 15\u00a0\u00b0C (60\u00a0\u00b0F), well above refrigerator temperatures. The \"butter compartment\" found in many refrigerators may be one of the warmer sections inside, but it still leaves butter quite hard. Until recently, many refrigerators sold in New Zealand featured a \"butter conditioner\", a compartment kept warmer than the rest of the refrigerator\u2014but still cooler than room temperature\u2014with a small heater. Keeping butter tightly wrapped delays rancidity, which is hastened by exposure to light or air, and also helps prevent it from picking up other odors. Wrapped butter has a shelf life of several months at refrigerator temperatures. Butter can also be frozen to extend its storage life.\nPackaging.\nIn most countries butter is sold in packets by weight, often in and packages.\nBulk packaging.\nSince the 1940s, but more commonly the 1960s, butter pats have been individually wrapped and packed in cardboard boxes. Prior to use of cardboard, butter was bulk packed in wood. The earliest discoveries used firkins. From about 1882 wooden boxes were used, as the introduction of refrigeration on ships allowed longer transit times. Butter boxes were generally made with woods whose resin would not taint the butter, such as sycamore, kahikatea, hoop pine, maple, or spruce. They commonly weighed a firkin ().\nUnited States.\nIn the United States, butter has traditionally been made into small, rectangular blocks by means of a pair of wooden butter paddles. It is usually produced in sticks that are individually wrapped in waxed or foiled paper, and sold as a package of 4 sticks. This practice is believed to have originated in 1907, when Swift and Company began packaging butter in this manner for mass distribution.\nDue to historical differences in butter printers (machines that cut and package butter), 4-ounce sticks are commonly produced in two different shapes:\nIn cooking and gastronomy.\nButter has been considered indispensable in French cuisine since the 17th century. Chefs and cooks have extolled its importance: Fernand Point said \"Donnez-moi du beurre, encore du beurre, toujours du beurre!\" ('Give me butter, more butter, still more butter!'). Julia Child said, \"With enough butter, anything is good.\"\nMelted butter plays an important role in the preparation of sauces, notably in French cuisine. \"Beurre noisette\" (hazelnut butter) and \"Beurre noir\" (black butter) are sauces of melted butter cooked until the milk solids and sugars have turned golden or dark brown; they are often finished with an addition of vinegar or lemon juice.36 Hollandaise and b\u00e9arnaise sauces are emulsions of egg yolk and melted butter. Hollandaise and b\u00e9arnaise sauces are stabilized with the powerful emulsifiers in the egg yolks, but butter itself contains enough emulsifiers\u2014mostly remnants of the fat globule membranes\u2014to form a stable emulsion on its own.635\u2013636\n\"Beurre blanc\" (white butter) is made by whisking butter into reduced vinegar or wine, forming an emulsion with the texture of thick cream. \"Beurre mont\u00e9\" (prepared butter) is melted but still emulsified butter; it lends its name to the practice of \"mounting\" a sauce with butter: whisking cold butter into any water-based sauce at the end of cooking, giving the sauce a thicker body and a glossy shine\u2014as well as a buttery taste.632\nButter is used for saut\u00e9ing and frying, although its milk solids brown and burn above 150\u00a0\u00b0C (250\u00a0\u00b0F)\u2014a rather low temperature for most applications. The smoke point of butterfat is around 200\u00a0\u00b0C (400\u00a0\u00b0F), so clarified butter or ghee is better suited to frying.37 \nButter fills several roles in baking, including making possible a range of textures, making chemical leavenings work better, tenderizing proteins, and enhancing the tastes of other ingredients. It is used in a similar manner to other solid fats like lard, suet, or shortening, but has a flavor that may better complement sweet baked goods.\nCompound butters are mixtures of butter and other ingredients used to flavor various dishes.\nNutrition.\nButter (salted during manufacturing) is 16% water, 81% fat, and 1% protein, with negligible carbohydrates. Of the of total fat, saturated fat is 51 g, monounsaturated fat is 21 g, polyunsaturated fat is 3 g, trans fat is 3 g, and trans fat designated as \"18:1 t\" is 3 g, for a total of 81 g (source for table).\nIn a reference amount of , salted butter supplies 717 calories and 76% of the Daily Value (DV) for vitamin A, 15% DV for vitamin E, and 28% DV for sodium, with no other micronutrients in significant content (table). In 100 grams, salted butter contains 215 mg of cholesterol (table).\nAs butter is essentially just the milk fat, it contains only traces of lactose, indicating that moderate consumption of butter is unlikely to cause symptoms for lactose intolerant people. People with milk allergies may still need to avoid butter, which contains enough of the allergy-causing proteins to cause reactions.\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nHealth concerns.\nA 2015 study concluded that \"hypercholesterolemic people should keep their consumption of butter to a minimum, whereas moderate butter intake may be considered part of the diet in the normocholesterolemic population.\"\nA meta-analysis and systematic review published in 2016 found relatively small or insignificant overall associations of a dose of 14g/day of butter with mortality and cardiovascular disease, and consumption was insignificantly inversely associated with incidence of diabetes. The study states that \"findings do not support a need for major emphasis in dietary guidelines on either increasing or decreasing butter consumption.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "46184", "revid": "49087436", "url": "https://en.wikipedia.org/wiki?curid=46184", "title": "The Star Beast (novel)", "text": "1954 SF novel by Robert A. Heinlein\nThe Star Beast is a 1954 science fiction novel by Robert A. Heinlein about a high school senior who discovers that his extraterrestrial pet is more than it appears to be. The novel was originally serialized, somewhat abridged, in \"The Magazine of Fantasy &amp; Science Fiction\" (May, June, July 1954) as \"Star Lummox\" and then published in hardcover as part of Scribner's series of Heinlein juveniles.\nPlot summary.\nIn the future, Earth has had interstellar spaceflight for centuries and has made contact with numerous intelligent alien species. Teenager John Thomas Stuart XI lives in a small Rocky Mountain town, Westville, and cares for Lummox, an extraterrestrial beast his great-grandfather had brought home. Lummox has learned how to speak, and has gradually grown from the size of a collie pup to a ridable behemoth\u2014especially after consuming a used car. The childlike Lummox is perceived as a neighborhood nuisance and, upon leaving the Stuart property one day, causes substantial property damage across the city. John's widowed mother wants him to get rid of it, and brings an action in the local court to have it destroyed.\nEventually, the court orders Lummox destroyed. City officials try several methods to kill Lummox but fail, as its alien physiology appears to be virtually invulnerable to ordinary weapons or poisons, and Lummox does not even realize they are attempting to execute him. Desperate to save his pet, John Thomas considers selling Lummox to a zoo. He quickly changes his mind and runs away from home, riding into the nearby wilderness on Lummox's back. His girlfriend, Betty Sorenson, joins him and suggests bringing the beast back into town and hiding it in a neighbor's greenhouse. However, it is not easy to conceal such a large creature. \nMeanwhile, at the Earth government Department of Spacial Affairs, Mr. Kiku, the Permanent Undersecretary and an expert diplomat, is dealing with the Hroshii, a previously unknown, advanced, and powerful alien race. They demand the return of their lost child, or they will destroy Earth. A friendly alien diplomat of a third species intimates that the threat is not an empty one. Initially, no one associates Lummox with the newcomers, partly due to the size difference (Lummox grew very large from overfeeding). Lummox is finally identified as important Hroshii royalty, and is approximately female (the Hroshii have six sexes). It turns out that the friendship between John Thomas and Lummox may be the only thing saving Earth from destruction. From her viewpoint, during her centuries on Earth, the young, extremely long-lived Lummox has been pursuing a hobby: the raising of John Thomases. She makes it clear to the other Hroshii that she intends to continue doing so. This gives Mr. Kiku the leverage he needs to establish diplomatic relations. At the insistence of Lummox, the newly married John and Betty accompany her back to the Hroshii homeworld as part of Earth's diplomatic mission.\nReception.\nDamon Knight wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This is a novel that won't go bad on you. Many of science fiction's triumphs, even from as little as ten years ago, are unreadable today; they were shoddily put together, not meant for re-use. But Heinlein is durable. I've read this story twice, so far \u2013 once in the \"Fantasy and Science Fiction\" serialized version, once in hard covers \u2013 and expect to read it again, sooner or later, for pleasure. I don't know any higher praise.\nGroff Conklin described the novel as \"one of Heinlein's most enchanting tales\". P. Schuyler Miller found \"The Star Beast\" \"one of the best of 1954\".\nIllustrations.\nThe F&amp;SF serialization has a series of illustrations by Fred Kirberger (two covers plus black-and-white interior art). Although the secondary protagonist, Mr. Kiku, is clearly described in the text as a black Kenyan, he is illustrated as a white man. Lummox and the other Hroshii are only depicted as vague shapes or textures at the edges of some scenes.\nThe original Scribner's hardcover edition has cover art and a frontispiece by Clifford Geary that depicts Lummox.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46185", "revid": "305540", "url": "https://en.wikipedia.org/wiki?curid=46185", "title": "Mineral matter in plants", "text": ""}
{"id": "46187", "revid": "50654738", "url": "https://en.wikipedia.org/wiki?curid=46187", "title": "Lobotomy", "text": "Neurosurgical operation\nA lobotomy (from el \" \"\u03bb\u03bf\u03b2\u03cc\u03c2\" (lobos)\"\u00a0'lobe' and \" \"\u03c4\u03bf\u03bc\u03ae\" (tom\u0113)\"\u00a0'cut, slice') or leucotomy is a discredited form of neurosurgical treatment for psychiatric disorder or neurological disorder (e.g. epilepsy, depression) that involves severing connections in the brain's prefrontal cortex. The surgery severs most of the connections to and from the prefrontal cortex, and the anterior part of the frontal lobes of the brain.\nIn the past, this treatment was used for handling psychiatric disorders as a mainstream procedure in some countries. A preoccupation with the ability to work and personal responsibility over patient well-being were contributing factors to the success of lobotomies in the US.\nThe originator of the procedure, Portuguese neurologist Ant\u00f3nio Egas Moniz, shared the Nobel Prize for Physiology or Medicine of 1949 for the \"discovery of the therapeutic value of leucotomy in certain psychoses\", although the awarding of the prize has been subject to controversy.\nThe procedure was modified and championed by Walter Freeman, who performed the first lobotomy at a mental hospital in the United States in 1936. Its use increased dramatically from the early 1940s and into the 1950s; by 1951, almost 20,000 lobotomies had been performed in the US and proportionally more in the United Kingdom. More lobotomies were performed on women than on men: a 1951 study found that nearly 60% of American lobotomy patients were women, and limited data shows that 74% of lobotomies in Ontario from 1948 to 1952 were performed on female patients. From the 1950s onward, lobotomy began to be abandoned, first in the Soviet Union, where the procedure immediately garnered extensive criticism and was not widely employed, before being banned in December 1950, and then Europe. However, derivatives of it such as stereotactic tractotomy and bilateral cingulotomy are still used.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nOutline.\nHistorically, patients of frontal lobotomy were, immediately following surgery, often stuporous and incontinent. Some developed an enormous appetite and gained considerable weight. Seizures were another common complication of surgery. Emphasis was put on the training of patients in the weeks and months following surgery.\nThe purpose of the operation was to reduce the symptoms of mental disorders, and it was recognized that this was accomplished at the expense of a person's personality and intellect. British psychiatrist Maurice Partridge, who conducted a follow-up study of 300 patients, said the treatment achieved its effects by \"reducing the complexity of psychic life\". Following the operation, spontaneity, responsiveness, self-awareness, and self-control were reduced. Activity was replaced by inertia, and people were mostly left emotionally blunted and restricted in their intellectual range.\nThe consequences of the operation have been described as \"mixed\". However, many lobotomy patients suffered devastating postoperative complications, including intracranial hemorrhage, epilepsy, alterations in affect and personality, brain abscess, dementia, and death. Ominous portrayals of lobotomized patients in novels, plays, and films further diminished public opinion, and the development of antipsychotic medications led to a rapid decline in lobotomy's popularity and Walter Freeman's reputation. Others could leave the hospital or become more manageable within the hospital. \nA precarious number of people managed to return to responsible work, while at the other extreme, people were left with severe and disabling impairments. Most people fell into an intermediate group, left with some improvement of their symptoms but also with emotional and intellectual deficits to which they made a better or worse adjustment. On average, there was a mortality rate of approximately 5% during the 1940s. A survey of British lobotomy patients lobotomised between 1942 and 1954 found that 13% of patients were deemed to have made a full recovery and a further 28% were deemed to have made a significant recovery; for 25% lobotomy was deemed to have made no change and 4% died as a result of the surgery.\nThe frontal lobotomy procedure could have severe negative effects on a patient's personality and ability to function independently. Lobotomy patients often show a marked reduction in initiative and inhibition. They may also exhibit difficulty imagining themselves in the position of others because of decreased cognition and detachment from society.\nWalter Freeman coined the term \"surgically induced childhood\" and used it constantly to refer to the results of lobotomy. The operation left people with an \"infantile personality\"; a period of maturation would then, according to Freeman, lead to recovery. In an unpublished memoir, he described how the \"personality of the patient was changed in some way in the hope of rendering him more amenable to the social pressures under which he is supposed to exist.\" He described one 29-year-old woman as being, following lobotomy, a \"smiling, lazy and satisfactory patient with the personality of an oyster\" who could not remember Freeman's name and endlessly poured coffee from an empty pot. When her parents had difficulty dealing with her behavior, Freeman advised a system of rewards (ice cream) and punishment (smacks).\nHistory.\nIn the early 20th century, the number of patients residing in mental hospitals increased significantly while little in the way of effective medical treatment was available. Lobotomy was one of a series of radical and invasive physical therapies developed in Europe at this time that signaled a break with the psychiatric culture of therapeutic nihilism which had prevailed since the mid-nineteenth-century. The new \"heroic\" physical therapies devised during this experimental era, including malarial therapy for general paresis of the insane (1917), deep sleep therapy (1920), insulin shock therapy (1933), cardiazol shock therapy (1934), and electroconvulsive therapy (1938), served to galvanize a profession which had been both therapeutically moribund and systemically demoralized. Unlike other medical disciplines (e.g., cardiology, dermatology, orthopedics, etc.) which applied surgical and pharmacological treatments that were both apparent and measurable regarding their efficacy, psychiatry had often struggled with quantification. These novel remedial methodologies, however, meant that (at the time) modern psychiatric treatments were no longer relegated to the metaphysical or abstract, and this increased the popularity of the field among clinicians and prospective patients alike. Suddenly, conditions like insanity, psychosis, and others felt less like incurable afflictions and more like surmountable diagnoses, emboldening psychiatrists to attempt new procedures. Additionally, the relative (and quantitative) success of the shock therapies, despite the considerable risks they posed to patients, also helped to inspire doctors in the field to pioneer ever more drastic forms of medical interventions, including lobotomies.\nThe clinician-historian Joel Braslow argues that from malarial therapy onward to lobotomy, physical psychiatric therapies \"spiral closer and closer to the interior of the brain\", with this organ increasingly taking \"center stage as a source of disease and site of cure\". For medical historian Roy Porter, the often violent and invasive psychiatric interventions developed during the 1930s and 1940s are indicative of both the well-intentioned desire of psychiatrists to find some medical means of alleviating the suffering of the vast number of patients then in psychiatric hospitals and also the relative lack of social power of those same patients to resist the increasingly radical and even reckless interventions of asylum doctors. Many doctors, patients, and family members of the period believed that despite potentially catastrophic consequences, the results of lobotomy were seemingly positive in many instances or were at least deemed as such when measured next to the apparent alternative of long-term institutionalisation. Lobotomy has always been controversial, but for a period of the medical mainstream, it was regarded as a legitimate last-resort remedy for categories of patients who were otherwise regarded as hopeless. Today, lobotomy has become a disparaged procedure, a byword for medical barbarism and an exemplary instance of the medical trampling of patients' rights.\nEarly psychosurgery.\nBefore the 1930s, individual doctors had infrequently experimented with novel surgical operations on those deemed insane. Most notably in 1888, Swiss psychiatrist Gottlieb Burckhardt initiated what is commonly considered the first systematic attempt at modern human psychosurgery. He operated on six chronic patients under his care at the Swiss Pr\u00e9fargier Asylum, removing sections of their cerebral cortex. Burckhardt's decision to operate was informed by three pervasive views on the nature of mental illness and its relationship to the brain. First, the belief that mental illness was organic in nature, and reflected an underlying brain pathology; next, that the nervous system was organized according to an associationist model comprising an input or afferent system (a sensory center), a connecting system where information processing took place (an association center), and an output or efferent system (a motor center); and, finally, a modular conception of the brain whereby discrete mental faculties were connected to specific regions of the brain. Burckhardt's hypothesis was that by deliberately creating lesions in regions of the brain identified as association centers, a transformation in behaviour might ensue. According to his model, those mentally ill might experience \"excitations abnormal in quality, quantity and intensity\" in the sensory regions of the brain and this abnormal stimulation would then be transmitted to the motor regions giving rise to mental pathology. He reasoned, however, that removing material from either of the sensory or motor zones could give rise to \"grave functional disturbance\". Instead, by targeting the association centers and creating a \"ditch\" around the motor region of the temporal lobe, he hoped to break their lines of communication and thus alleviate both mental symptoms and the experience of mental distress.\nIntending to ameliorate symptoms in those with violent and intractable conditions rather than effect a cure, Burckhardt began operating on patients in December 1888, but both his surgical methods and instruments were crude and the results of the procedure were mixed at best. He operated on six patients in total and, according to his own assessment, two experienced no change, two patients became quieter, one patient experienced epileptic convulsions and died a few days after the operation, and one patient improved. Complications included motor weakness, epilepsy, sensory aphasia and \"word deafness\". Claiming a success rate of 50 percent, he presented the results at the Berlin Medical Congress and published a report, but the response from his medical peers was hostile and he did no further operations.\nIn 1912, two physicians based in Saint Petersburg, the leading Russian neurologist Vladimir Bekhterev and his younger Estonian colleague, the neurosurgeon Ludvig Puusepp, published a paper reviewing a range of surgical interventions that had been performed on the mentally ill. While generally treating these endeavours favorably, in their consideration of psychosurgery they reserved unremitting scorn for Burckhardt's surgical experiments of 1888 and opined that it was extraordinary that a trained medical doctor could undertake such an unsound procedure.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We have quoted this data to show not only how groundless but also how dangerous these operations were. We are unable to explain how their author, holder of a degree in medicine, could bring himself to carry them out\u00a0...\nThe authors neglected to mention, however, that in 1910 Puusepp himself had performed surgery on the brains of three mentally ill patients, sectioning the cortex between the frontal and parietal lobes. He had abandoned these attempts because of unsatisfactory results and this experience probably inspired the invective that was directed at Burckhardt in the 1912 article. By 1937, Puusepp, despite his earlier criticism of Burckhardt, was increasingly persuaded that psychosurgery could be a valid medical intervention for the mentally disturbed. In the late 1930s, he worked closely with the neurosurgical team of the Racconigi Hospital near Turin to establish it as an early and influential centre for the adoption of leucotomy in Italy.\nDevelopment.\nLeucotomy was first undertaken in 1935 under the direction of the Portuguese neurologist (and inventor of the term \"psychosurgery\") Ant\u00f3nio Egas Moniz. First developing an interest in psychiatric conditions and their somatic treatment in the early 1930s, Moniz conceived a new opportunity for recognition in the development of a surgical intervention on the brain as a treatment for mental illness.\nFrontal lobes.\nThe source of inspiration for Moniz's decision to hazard psychosurgery has been clouded by contradictory statements made on the subject by Moniz and others both contemporaneously and retrospectively. The traditional narrative addresses the question of why Moniz targeted the frontal lobes by way of reference to the work of the Yale neuroscientist John Fulton and, most dramatically, to a presentation Fulton made with his junior colleague Carlyle Jacobsen at the Second International Congress of Neurology held in London in 1935. Fulton's primary area of research was on the cortical function of primates and he had established America's first primate neurophysiology laboratory at Yale in the early 1930s. At the 1935 Congress, with Moniz in attendance, Fulton and Jacobsen presented two chimpanzees named Becky and Lucy who had had frontal lobectomies and subsequent changes in behaviour and intellectual function. According to Fulton's account of the congress, they explained that before surgery, both animals, and especially Becky, the more emotional of the two, exhibited \"frustrational behaviour\"\u00a0\u2013 that is, tantrums that could include rolling on the floor and defecating\u00a0\u2013 if, because of their poor performance in a set of experimental tasks, they were not rewarded. Following the surgical removal of their frontal lobes, the behaviour of both primates changed markedly and Becky was pacified to such a degree that Jacobsen apparently stated it was as if she had joined a \"happiness cult\". During the question and answer section of the paper, Moniz, it is alleged, \"startled\" Fulton by inquiring if this procedure might be extended to human subjects suffering from mental illness. Fulton stated that he replied that while possible in theory it was surely \"too formidable\" an intervention for use on humans.\nMoniz began his experiments with leucotomy just three months after the congress had reinforced the apparent cause-and-effect relationship between the Fulton and Jacobsen presentation and the Portuguese neurologist's resolve to operate on the frontal lobes. As the author of this account Fulton, who has sometimes been claimed as the father of lobotomy, was later able to record that the technique had its true origination in his laboratory. Endorsing this version of events, in 1949, the Harvard neurologist Stanley Cobb remarked during his presidential address to the American Neurological Association that \"seldom in the history of medicine has a laboratory observation been so quickly and dramatically translated into a therapeutic procedure\". Fulton's report, penned ten years after the events described, is, however, without corroboration in the historical record and bears little resemblance to an earlier unpublished account he wrote of the congress. In this previous narrative, he mentioned an incidental, private exchange with Moniz, but it is likely that the official version of their public conversation he promulgated is without foundation. In fact, Moniz stated that he had conceived of the operation sometime before his journey to London in 1935, having told in confidence his junior colleague, the young neurosurgeon Pedro Almeida Lima, as early as 1933 of his psychosurgical idea. The traditional account exaggerates the importance of Fulton and Jacobsen to Moniz's decision to initiate frontal lobe surgery, and omits the fact that a detailed body of neurological research that emerged at this time suggested to Moniz and other neurologists and neurosurgeons that surgery on this part of the brain might yield significant personality changes in the mentally ill.\nThe frontal lobes have been the object of scientific inquiry and speculation since the late 19th century. Fulton's contribution, while it may have functioned as a source of intellectual support, is in itself unnecessary and inadequate as an explanation of Moniz's resolution to operate on this section of the brain. Under an evolutionary and hierarchical model of brain development it had been hypothesized that those regions associated with the more recent development, such as the mammalian brain and, most especially, the frontal lobes, were responsible for more complex cognitive functions. However, this theoretical formulation found little laboratory support, as 19th-century experimentation found no significant change in animal behaviour following surgical removal or electrical stimulation of the frontal lobes. This picture of the so-called \"silent lobe\" changed in the period after World War I with the production of clinical reports of ex-servicemen with brain trauma. The refinement of neurosurgical techniques also facilitated increasing attempts to remove brain tumours, and treat focal epilepsy in humans and led to more precise experimental neurosurgery in animal studies. Cases were reported where mental symptoms were alleviated following the surgical removal of diseased or damaged brain tissue. The accumulation of medical case studies on behavioural changes following damage to the frontal lobes led to the formulation of the concept of \"Witzelsucht\", which designated a neurological condition characterised by a certain hilarity and childishness in those with the condition. The picture of frontal lobe function that emerged from these studies was complicated by the observation that neurological deficits attendant on damage to a single lobe might be compensated for if the opposite lobe remained intact. In 1922, the Italian neurologist Leonardo Bianchi published a detailed report on the results of bilateral lobectomies in animals that supported the contention that the frontal lobes were both integral to intellectual function and that their removal led to the disintegration of the subject's personality. This work, while influential, was not without its critics due to deficiencies in experimental design.\nThe first bilateral lobectomy of a human subject was performed by the American neurosurgeon Walter Dandy in 1930. The neurologist Richard Brickner reported on this case in 1932, relating that the recipient, known as \"Patient A\", while experiencing a blunting of affect, had no apparent decrease in intellectual function and seemed, at least to the casual observer, perfectly normal. Brickner concluded from this evidence that \"the frontal lobes are not 'centers' for the intellect\". These clinical results were replicated in a similar operation undertaken in 1934 by the neurosurgeon Roy Glenwood Spurling and reported on by the neuropsychiatrist Spafford Ackerly. By the mid-1930s, interest in the function of the frontal lobes reached a high-water mark. This was reflected in the 1935 neurological congress in London, which hosted as part of its deliberations, \"a remarkable symposium\u00a0... on the functions of the frontal lobes\". The panel was chaired by Henri Claude, a French neuropsychiatrist, who commenced the session by reviewing the state of research on the frontal lobes, and concluded that \"altering the frontal lobes profoundly modifies the personality of subjects\". This parallel symposium contained numerous papers by neurologists, neurosurgeons and psychologists; amongst these was one by Brickner, which impressed Moniz greatly, that again detailed the case of \"Patient A\". Fulton and Jacobsen's paper, presented in another session of the conference on experimental physiology, was notable in linking animal and human studies on the function of the frontal lobes. Thus, at the time of the 1935 Congress, Moniz had available to him an increasing body of research on the role of the frontal lobes that extended well beyond the observations of Fulton and Jacobsen.\nNor was Moniz the only medical practitioner in the 1930s to have contemplated procedures directly targeting the frontal lobes. Although ultimately discounting brain surgery as carrying too much risk, physicians and neurologists such as William Mayo, Thierry de Martel, Richard Brickner, and Leo Davidoff had, before 1935, entertained the proposition. Inspired by Julius Wagner-Jauregg's development of malarial therapy for the treatment of general paresis of the insane, the French physician Maurice Ducost\u00e9 reported in 1932 that he had injected 5\u00a0ml of malarial blood directly into the frontal lobes of over 100 paretic patients through holes drilled into the skull. He claimed that the injected paretics showed signs of \"uncontestable mental and physical amelioration\" and that the results for psychotic patients undergoing the procedure were also \"encouraging\". The experimental injection of fever-inducing malarial blood into the frontal lobes was also replicated during the 1930s in the work of Ettore Mariotti and M. Sciutti in Italy and Ferdi\u00e8re Coulloudon in France. In Switzerland, almost simultaneously with the commencement of Moniz's leucotomy programme, the neurosurgeon Fran\u00e7ois Ody had removed the entire right frontal lobe of a catatonic schizophrenic patient. In Romania, Ody's procedure was adopted by Dimitri Bagdasar and Constantinesco working out of the Central Hospital in Bucharest. Ody, who delayed publishing his own results for several years, later rebuked Moniz for claiming to have cured patients through leucotomy without waiting to determine if there had been a \"lasting remission\".\nNeurological model.\nThe theoretical underpinnings of Moniz's psychosurgery were largely commensurate with the nineteenth-century ones that had informed Burckhardt's decision to excise matter from the brains of his patients. Although in his later writings, Moniz referenced both the neuron theory of Ram\u00f3n y Cajal and the conditioned reflex of Ivan Pavlov, in essence he simply interpreted this new neurological research in terms of the old psychological theory of associationism. He differed significantly from Burckhardt, however in that he did not think there was any organic pathology in the brains of the mentally ill, but rather that their neural pathways were caught in fixed and destructive circuits leading to \"predominant, obsessive ideas\". As Moniz wrote in 1936:\n[The] mental troubles must have\u00a0... a relation with the formation of cellulo-connective groupings, which become more or less fixed. The cellular bodies may remain altogether normal, their cylinders will not have any anatomical alterations; but their multiple liaisons, very variable in normal people, may have arrangements more or less fixed, which will have a relation with persistent ideas and deliria in certain morbid psychic states.\nFor Moniz, \"to cure these patients\", it was necessary to \"destroy the more or less fixed arrangements of cellular connections that exist in the brain, and particularly those which are related to the frontal lobes\", thus removing their fixed pathological brain circuits. Moniz believed the brain would functionally adapt to such injury. Unlike the position adopted by Burckhardt, it was unfalsifiable according to the knowledge and technology of the time as the absence of a known correlation between physical brain pathology and mental illness could not disprove his thesis.\nFirst leucotomies.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe hypotheses underlying the procedure might be called into question; the surgical intervention might be considered very audacious; but such arguments occupy a secondary position because it can be affirmed now that these operations are not prejudicial to either physical or psychic life of the patient, and also that recovery or improvement may be obtained frequently in this way.\n\u2014Egas Moniz (1937)\nOn 12 November 1935 at the Hospital de Santa Marta in Lisbon, Moniz initiated the first of a series of operations on the brains of people with mental illnesses. The initial patients selected for the operation were provided by the medical director of Lisbon's Miguel Bombarda Mental Hospital, Jos\u00e9 de Matos Sobral Cid. As Moniz lacked training in neurosurgery and his hands were impaired by gout, the procedure was performed under general anaesthetic by Pedro Almeida Lima, who had previously assisted Moniz with his research on cerebral angiography. The intention was to remove some of the long fibres that connected the frontal lobes to other major brain centres. To this end, it was decided that Lima would trephine into the side of the skull and then inject ethanol into the \"subcortical white matter of the prefrontal area\" so as to destroy the connecting fibres, or association tracts, and create what Moniz termed a \"frontal barrier\". After the first operation was complete, Moniz considered it a success and, observing that the patient's depression had been relieved, he declared her \"cured\" although she was never, in fact, discharged from the mental hospital. Moniz and Lima persisted with this method of injecting alcohol into the frontal lobes for the next seven patients but, after having to inject some patients on numerous occasions to elicit what they considered a favourable result, they modified the means by which they would section the frontal lobes. For the ninth patient they introduced a surgical instrument called a leucotome; this was a cannula that was in length and in diameter. It had a retractable wire loop at one end that, when rotated, produced a diameter circular lesion in the white matter of the frontal lobe. Typically, six lesions were cut into each lobe, but, if they were dissatisfied by the results, Lima might perform several procedures, each producing multiple lesions in the left and right frontal lobes.\nBy the conclusion of this first run of leucotomies in February 1936, Moniz and Lima had operated on twenty patients with an average period of one week between each procedure; Moniz published his findings with great haste in March of the same year. The patients were aged between 27 and 62 years of age; twelve were female and eight were male. Nine of the patients were diagnosed with depression, six with schizophrenia, two with panic disorder, and one each with mania, catatonia and manic-depression. Their most prominent symptoms were anxiety and agitation. The duration of their illness before the procedure varied from as little as four weeks to as much as 22 years, although all but four had been ill for at least one year. Patients were normally operated on the day they arrived at Moniz's clinic and returned within ten days to the Miguel Bombarda Mental Hospital. A perfunctory post-operative follow-up assessment took place anywhere from one to ten weeks following surgery. Complications were observed in each of the leucotomy patients and included: \"increased temperature, vomiting, bladder and bowel incontinence, diarrhea, and ocular affections such as ptosis and nystagmus, as well as psychological effects such as apathy, akinesia, lethargy, timing, and local disorientation, kleptomania, and abnormal sensations of hunger\". Moniz asserted that these effects were transitory and, according to his published assessment, the outcome for these first twenty patients was that 35%, or seven cases, improved significantly, another 35% were somewhat improved and the remaining 30% (six cases) were unchanged. There were no deaths and he did not consider that any patients had deteriorated following leucotomy.\nReception.\nMoniz rapidly disseminated his results through articles in the medical press and a monograph in 1936. Initially, however, the medical community appeared hostile to the new procedure. On 26 July 1936, one of his assistants, Diogo Furtado, gave a presentation at the Parisian meeting of the Soci\u00e9t\u00e9 M\u00e9dico-Psychologique on the results of the second cohort of patients leucotomised by Lima. Sobral Cid, who had supplied Moniz with the first set of patients for leucotomy from his own hospital in Lisbon, attended the meeting and denounced the technique, declaring that the patients who had been returned to his care post-operatively were \"diminished\" and had experienced a \"degradation of personality\". He also claimed that the changes Moniz observed in patients were more properly attributed to shock and brain trauma, and he derided the theoretical architecture that Moniz had constructed to support the new procedure as \"cerebral mythology.\" At the same meeting the Parisian psychiatrist, Paul Courbon, stated he could not endorse a surgical technique that was solely supported by theoretical considerations rather than clinical observations. He also opined that the mutilation of an organ could not improve its function and that such cerebral wounds as were occasioned by leucotomy risked the later development of meningitis, epilepsy and brain abscesses. Nonetheless, Moniz's reported successful surgical treatment of 14 out of 20 patients led to the rapid adoption of the procedure on an experimental basis by individual clinicians in countries such as Brazil, Cuba, Italy, Romania and the United States during the 1930s.\nItalian leucotomy.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nIn the present state of affairs if some are critical about lack of caution in therapy, it is, on the other hand, deplorable and inexcusable to remain apathetic, with folded hands, content with learned lucubrations upon symptomatologic minutiae or upon psychopathic curiosities, or even worse, not even doing that.\n\u2014Amarro Fiamberti\nThroughout the remainder of the 1930s, the number of leucotomies performed in most countries where the technique was adopted remained quite low. In Britain, which was later a major centre for leucotomy, only six operations had been undertaken before 1942. Generally, medical practitioners who attempted the procedure adopted a cautious approach and few patients were leucotomised before the 1940s. Italian neuropsychiatrists, who were typically early and enthusiastic adopters of leucotomy, were exceptional in eschewing such a gradualist course.\nLeucotomy was first reported in the Italian medical press in 1936 and Moniz published an article in Italian on the technique in the following year. In 1937, he was invited to Italy to demonstrate the procedure and for two weeks in June of that year, he visited medical centres in Trieste, Ferrara, and one close to Turin\u00a0\u2013 the Racconigi Hospital\u00a0\u2013 where he instructed his Italian neuropsychiatric colleagues on leucotomy and also oversaw several operations. Leucotomy was featured at two Italian psychiatric conferences in 1937 and over the next two years a score of medical articles on Moniz's psychosurgery was published by Italian clinicians based in medical institutions located in Racconigi, Trieste, Naples, Genoa, Milan, Pisa, Catania and Rovigo. The major centre for leucotomy in Italy was the Racconigi Hospital, where the experienced neurosurgeon Ludvig Puusepp provided a guiding hand. Under the medical directorship of Emilio Rizzatti, the medical personnel at this hospital had completed at least 200 leucotomies by 1939. Reports from clinicians based at other Italian institutions detailed significantly fewer leucotomy operations.\nExperimental modifications of Moniz's operation were introduced with little delay by Italian medical practitioners. Most notably, in 1937 Amarro Fiamberti, the medical director of a psychiatric institution in Varese, first devised the transorbital procedure whereby the frontal lobes were accessed through the eye sockets. Fiamberti's method was to puncture the thin layer of orbital bone at the top of the socket and then inject alcohol or formalin into the white matter of the frontal lobes through this aperture. Using this method, while sometimes substituting a leucotome for a hypodermic needle, it is estimated that he leucotomised about 100 patients in the period up to the outbreak of World War II. Fiamberti's innovation of Moniz's method would later prove inspirational for Walter Freeman's development of transorbital lobotomy.\nAmerican leucotomy.\nThe first prefrontal leucotomy in the United States was performed at the George Washington University Hospital, on 14 September 1936, by the neurologist Walter Freeman, and his friend and colleague, the neurosurgeon James W. Watts. Freeman had first encountered Moniz at the London-hosted Second International Congress of Neurology in 1935, where he had presented a poster exhibit of the Portuguese neurologist's work on cerebral angiography. Fortuitously occupying a booth next to Moniz, Freeman, delighted by their chance meeting, formed a highly favourable impression of Moniz, later remarking upon his \"sheer genius\". According to Freeman, if they had not met in person, it is highly unlikely that he would have ventured into the domain of frontal lobe psychosurgery. Freeman's interest in psychiatry was the natural outgrowth of his appointment in 1924 as the medical director of the Research Laboratories of the Government Hospital for the Insane in Washington, known colloquially as St Elizabeth's. Freeman, who favoured an organic model of mental illness causation, spent the next several years exhaustively, yet ultimately fruitlessly, investigating a neuropathological basis for insanity. Chancing upon a preliminary communication by Moniz on leucotomy in the spring of 1936, Freeman initiated a correspondence in May of that year. Writing that he had been considering psychiatric brain surgery previously, he informed Moniz that, \"having your authority I expect to go ahead\". Moniz, in return, promised to send him a copy of his forthcoming monograph on leucotomy and urged him to purchase a leucotome from a French supplier.\nUpon receipt of Moniz's monograph, Freeman reviewed it anonymously for the \"Archives of Neurology and Psychiatry\". Praising the text as one whose \"importance can scarcely be overestimated\", he summarised Moniz's rationale for the procedure as based on the fact that while no physical abnormality of cerebral cell bodies was observable in the mentally ill, their cellular interconnections may harbour a \"fixation of certain patterns of relationship among various groups of cells\" and that this resulted in obsessions, delusions and mental morbidity. While recognising that Moniz's thesis was inadequate, for Freeman it had the advantage of circumventing the search for diseased brain tissue in the mentally ill by instead suggesting that the problem was a functional one of the brain's internal wiring where relief might be obtained by severing problematic mental circuits.\nIn 1937 Freeman and Watts adapted Lima and Moniz's surgical procedure, and created the \"Freeman-Watts technique\", also known as the \"Freeman-Watts standard prefrontal lobotomy,\" which they styled the \"precision method\".\nTransorbital lobotomy.\nThe Freeman\u2013Watts prefrontal lobotomy still required drilling holes in the skull, so surgery had to be performed in an operating room by trained neurosurgeons. Walter Freeman believed this surgery would be unavailable to those he saw as needing it most: patients in state mental hospitals that had no operating rooms, surgeons, or anesthesia and limited budgets. Freeman wanted to simplify the procedure so that it could be carried out by psychiatrists in psychiatric hospitals.\nInspired by the work of Italian psychiatrist Amarro Fiamberti, Freeman at some point conceived of approaching the frontal lobes through the eye sockets instead of through drilled holes in the skull. In 1945 he took an ice pick from his own kitchen and began testing the idea on grapefruit and cadavers.\nThe use of lobotomy in the United States was resisted and criticized heavily by American neurosurgeons. However, because Freeman managed to promote the success of the surgery through the media, lobotomy became touted as a miracle procedure, capturing the attention of the public and leading to an overwhelming demand for the operation. In 1945 Freeman streamlined the procedure, replacing it with transorbital lobotomy, in which a picklike instrument was forced through the back of the eye sockets to pierce the thin bone that separates the eye sockets from the frontal lobes. The pick's point was then inserted into the frontal lobe and used to sever connections in the brain (presumably between the prefrontal cortex and thalamus). In 1946 Freeman performed this procedure for the first time on a patient, who was subdued prior to the operation with electroshock treatment.\nThe transorbital lobotomy procedure, which Freeman performed very quickly, sometimes in less than 10 minutes, was used on many patients with relatively minor mental disorders that Freeman believed did not warrant traditional lobotomy surgery, in which the skull itself was opened. A large proportion of such lobotomized patients exhibited reduced tension or agitation, but many also showed other effects, such as apathy, passivity, lack of initiative, poor ability to concentrate, and a generally decreased depth and intensity of their emotional response to life. Some died as a result of the procedure. However, those effects were not widely reported in the 1940s, and at that time the long-term effects were largely unknown. Because the procedure met with seemingly widespread success, Moniz was awarded the 1949 Nobel Prize for Physiology or Medicine (along with Swiss physiologist Walter Rudolf Hess).\nLobotomies were performed on a wide scale during the 1940s; Freeman himself performed or supervised more than 3,500 lobotomies by the late 1960s. Freeman performed his first transorbital lobotomy on Ellen Ionesco, a woman who suffered from bouts of manic depression and suicidal ideation. Freeman utilized media coverage and penned editorials for numerous interviews promoting the procedure and achieving accolades for his work in psychiatric care.\nWatts did not favor the transorbital method, and this difference of opinion contributed to the end of their partnership. Watts resisted the technique itself, Freeman's lack of sterile technique when performing it, and the idea of performing the procedure in an outpatient setting. Watts recalled that the hospital reprimanded Freeman, stating that he was \"not a surgeon and if he wants to operate he'll have to apply for surgical privileges.\"\nFreeman performed the first transorbital lobotomy on a live patient in 1946. Its simplicity suggested the possibility of carrying it out in mental hospitals lacking the surgical facilities required for the earlier, more complex procedure. (Freeman suggested that, where conventional anesthesia was unavailable, electroconvulsive therapy be used to render the patient unconscious.) In 1947, the Freeman and Watts partnership ended, as the latter was disgusted by Freeman's barbarism and neglectful modifications of the lobotomy from a surgical operation into a simple \"office\" procedure. Between 1940 and 1944, 684 lobotomies were performed in the United States. However, because of the fervent promotion of the technique by Freeman and Watts, those numbers increased sharply toward the end of the decade. In 1949, the peak year for lobotomies in the US, 5,074 procedures were undertaken, and by 1951 over 18,608 individuals had been lobotomized in the US.\nPrevalence.\nIn the United States, approximately 40,000 people were lobotomized, and in England, 17,000 lobotomies were performed. According to one estimate, in the three Nordic countries of Denmark, Norway, and Sweden, a combined figure of approximately 9,300 lobotomies were performed. Scandinavian hospitals lobotomized 2.5 times as many people per capita as hospitals in the US. According to another estimate, Sweden lobotomized at least 4,500 people between 1944 and 1966, mainly women. This figure includes young children. And in Norway, there were 2,005 known lobotomies. In Denmark, there were 4,500 known lobotomies. In Japan, the majority of lobotomies were performed on children with behaviour problems. The Soviet Union banned the practice in 1950 on moral grounds. In Germany, it was performed only a few times. By the late 1970s, the practice of lobotomy had generally ceased, although it continued as late as the 1980s in France. As of 2019, legality of the procedure in the United States varies according to state law, with some states restricting it heavily, while others effectively leave its regulation to laws of general applicability.\nCriticism.\nEarly skepticism toward lobotomy emerged in Soviet psychiatry. As reports on leucotomy and lobotomy surfaced in Soviet medical journals between 1936 and 1937, followed by more extensive reviews of Freeman and Watts's initial studies in 1939, Soviet reviewers expressed alarm at the procedure's severe complications and a reported 5 percent mortality rate, while also questioning its efficacy, observing that symptoms like fear, depression, and agitation often resolved spontaneously without necessitating such a dramatic procedure. These reviews suggested lobotomy should not be performed in the USSR.\nLater, by 1944, an author in the \"Journal of Nervous and Mental Disease\" remarked: \"The history of prefrontal lobotomy has been brief and stormy. Its course has been dotted with both violent opposition and with slavish, unquestioning acceptance.\" Beginning in 1947 Swedish psychiatrist Snorre Wohlfahrt evaluated early trials, reporting that it is \"distinctly hazardous to leucotomize schizophrenics\" and that lobotomy was \"still too imperfect to enable us, with its aid, to venture on a general offensive against chronic cases of mental disorder\", stating further that \"Psychosurgery has as yet failed to discover its precise indications and contraindications and the methods must unfortunately still be regarded as rather crude and hazardous in many respects.\" In 1948 Norbert Wiener, the author of \"\", said: \"Prefrontal lobotomy... has recently been having a certain vogue, probably not unconnected with the fact that it makes the custodial care of many patients easier. Let me remark in passing that killing them makes their custodial care still easier.\"\nConcerns about lobotomy steadily grew. Soviet psychiatrist Vasily Gilyarovsky criticized lobotomy and the mechanistic brain localization assumption used to carry out lobotomy:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It is assumed that the transection of white substance of the frontal lobes impairs their connection with the thalamus and eliminates the possibility to receive from it stimuli which lead to irritation and on the whole derange mental functions. This explanation is mechanistic and goes back to the narrow localizationism characteristic of psychiatrists of America, from where leucotomy was imported to us.\nThe Soviet Union officially banned the procedure in 1950 on the initiative of Gilyarovsky. Doctors in the Soviet Union concluded that the procedure was \"contrary to the principles of humanity\" and \"'through lobotomy' an insane person is changed into an idiot\". By the 1970s, numerous countries had banned the procedure, as had several US states.\nIn 1977, the US Congress, during the presidency of Jimmy Carter, created the National Committee for the Protection of Human Subjects of Biomedical and Behavioral Research to investigate allegations that psychosurgery\u00a0\u2013 including lobotomy techniques\u00a0\u2013 was used to control minorities and restrain individual rights. The committee concluded that some extremely limited and properly performed psychosurgery could have positive effects.\nTorsten Wiesel has called the award of the Nobel Prize to Moniz an \"astounding [error] of judgment... a terrible mistake\", and there have been calls for the Nobel Foundation to rescind the award.\nLiterary and cinematic portrayals.\nLobotomies have been featured in several literary and cinematic presentations that both reflected society's attitude toward the procedure and, at times, changed it. Writers and filmmakers have played a pivotal role in turning public sentiment against the procedure.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nPrint Sources\nOnline sources"}
{"id": "46191", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=46191", "title": "Tillage", "text": "Preparation of soil by mechanical agitation\nTillage is the agricultural preparation of soil by mechanical agitation of various types, such as digging, stirring, and overturning. Examples of human-powered tilling methods using hand tools include shoveling, picking, mattock work, hoeing, and raking. Examples of draft-animal-powered or mechanized work include ploughing (overturning with moldboards or chiseling with chisel shanks), rototilling, rolling with cultipackers or other rollers, harrowing, and cultivating with cultivator shanks (teeth).\nTillage that is deeper and more thorough is classified as primary, and tillage that is shallower and sometimes more selective of location is secondary. Primary tillage such as ploughing tends to produce a rough surface finish, whereas secondary tillage tends to produce a smoother surface finish, such as that required to make a good seedbed for many crops. Harrowing and rototilling often combine primary and secondary tillage into one operation.\n\"Tillage\" can also mean the land that is tilled. The word \"cultivation\" has several senses that overlap substantially with those of \"tillage\". In a general context, both can refer to agriculture. Within agriculture, both can refer to any kind of soil agitation. Additionally, \"cultivation\" or \"cultivating\" may refer to an even narrower sense of shallow, selective secondary tillage of row crop fields that kills weeds while sparing the crop plants.\nDefinitions.\n\"Primary tillage\" loosens the soil and mixes in fertilizer or plant material, resulting in soil with a rough texture.\n\"Secondary tillage\" produces finer soil and sometimes shapes the rows, preparing the seed bed. It also provides weed control throughout the growing season during the maturation of the crop plants, unless such weed control is instead achieved with low-till or no-till methods involving herbicides.\nHistory.\nTilling was first performed via human labor, sometimes involving slaves. Hoofed animals could also be used to till soil by trampling, in addition to pigs, whose natural instincts are to root the ground regularly if allowed to. The wooden plow was then invented. (\"It is difficult to pinpoint the exact date of its invention\". \"However, the earliest evidence of plow usage dates back to around 4000 BCE in Mesopotamia\" (\"modern-day Iraq\") . It could be pulled with human labor, or by mule, ox, elephant, water buffalo, or a similar sturdy animal. Horses are generally unsuitable, though breeds such as the Clydesdale were bred as draft animals.\nTilling could at times be very labor-intensive. This aspect is discussed in the 16th-century French agronomic text written by Charles Estienne:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe popularity of tillage as an agricultural technique in early modern times had to do with theories about plant biology proposed by European thinkers. In 1731, English writer Jethro Tull published the book \"Horse-Hoeing Husbandry: An Essay on the Principles of Vegetation and Tillage,\" which argued that soil needed to be pulverized into fine powder for plants to make use of it. Tull believed that, since water, air, and heat were clearly not the primary substance of a plant, plants were made of earth, and thus had to consume very small pieces of earth as food. Tull wrote that each subsequent tillage of the soil would increase its fertility, and that it was impossible to till the soil too much. However, scientific observation has shown that the opposite is true; tillage causes soil to lose structural qualities that allow plant roots, water, and nutrients to penetrate it, accelerates soil loss by erosion, and results in soil compaction.\nThe steel plow allowed farming in the American Midwest, where tough prairie grasses and rocks caused trouble. Soon after 1900, the farm tractor was introduced, which made modern large-scale agriculture possible. However, the destruction of the prairie grasses and tillage of the fertile topsoil of the American Midwest caused the Dust Bowl, in which the soil was blown away and stirred up into dust storms that blackened the sky. This prompted re-consideration of tillage techniques, but in the United States as of 2019, 3 trillion pounds of soil were estimated to be lost due to erosion while adoption of improved techniques for controlling erosion are still not widespread. In the mid-1930s Frank and Herbert Petty of Doncaster, Victoria, Australia developed the Petty Plough. This steerable plough could be pulled by either two horses or a tractor and the disc wheels could be steered in unison, or separately allowing the operator to plough the center of rows as well as between and around orchard trees.\nTypes.\nPrimary and secondary tillage.\nPrimary tillage is usually conducted after the last harvest, when the soil is wet enough to allow plowing but also allows good traction. Some soil types can be plowed dry. The objective of primary tillage is to attain a reasonable depth of soft soil, incorporate crop residues, kill weeds, and to aerate the soil. Secondary tillage is any subsequent tillage, to incorporate fertilizers, reduce the soil to a finer tilth, level the surface, or control weeds.\nReduced tillage.\nReduced tillage leaves between 15 and 30% crop residue cover on the soil or 500 to 1000 pounds per acre (560 to 1100\u00a0kg/ha) of small grain residue during the critical erosion period. This may involve the use of a chisel plow, field cultivators, or other implements. See the general comments below to see how they can affect the amount of residue.\nIntensive tillage.\nIntensive tillage leaves less than 15% crop residue cover or less than 500 pounds per acre (560\u00a0kg/ha) of small grain residue. This type of tillage is often referred to as conventional tillage, but as conservational tillage is now more widely used than intensive tillage (in the United States), it is often not appropriate to refer to this type of tillage as conventional. Intensive tillage often involves multiple operations with implements such as a mold board, disk, or chisel plow. After this, a finisher with a harrow, rolling basket, and cutter can be used to prepare the seed bed. There are many variations.\nConservation tillage.\nConservation tillage leaves at least 30% of crop residue on the soil surface, or at least 1,000\u00a0lb/ac (1,100\u00a0kg/ha) of small grain residue on the surface during the critical soil erosion period. This slows water movement, which reduces the amount of soil erosion. Additionally, conservation tillage has been found to benefit predatory arthropods that can enhance pest control. Conservation tillage also benefits farmers by reducing fuel consumption and soil compaction. By reducing the number of times the farmer travels over the field, significant savings in fuel and labor are made.\nConservation tillage is used on over 370 million acres, mostly in South America, Oceania and North America. In most years since 1997, conservation tillage was used in US cropland more than intensive or reduced tillage.\nHowever, conservation tillage delays warming of the soil due to the reduction of dark earth exposure to the warmth of the spring sun, thus delaying the planting of the next year's spring crop of corn.\nZone tillage.\nZone or strip tillage is a form of modified deep tillage in which only narrow strips are tilled, leaving soil in between the rows untilled. This type of tillage agitates the soil to help reduce soil compaction problems and to improve internal soil drainage. It is designed to only disrupt the soil in a narrow strip directly below the crop row. In comparison to no-till, which relies on the previous year's plant residue to protect the soil and aids in postponement of the warming of the soil and crop growth in Northern climates, zone tillage produces a strip approximately five inches wide that simultaneously breaks up plow pans, assists in warming the soil and helps to prepare a seedbed. When combined with cover crops, zone tillage helps replace lost organic matter, slows the deterioration of the soil, improves soil drainage, increases soil water and nutrient holding capacity, and allows necessary soil organisms to survive.\nIt has been successfully used on farms in the Midwest and West of the US for over 40 years, and is currently used on more than 36% of the U.S. farmland. Some specific states where zone tillage is currently in practice are Pennsylvania, Connecticut, Minnesota, Indiana, Wisconsin, and Illinois.\nIts use in the USA's Northern Corn Belt states lacks consistent yield results; however, there is still interest in deep tillage within agriculture. In areas that are not well-drained, deep tillage may be used as an alternative to installing more expensive tile drainage.\nEffects.\nPositive.\nPlowing:\nArchaeology.\nTilling can damage ancient structures such as long barrows. In the UK, half of the long barrows in Gloucestershire and almost all the burial mounds in Essex have been damaged. According to English Heritage in 2003, ploughing with modern powerful tractors had done as much damage in the last six decades as traditional farming did in the previous six centuries.\nAlternatives.\nModern agricultural science has greatly reduced the use of tillage. Crops can be grown for several years without any tillage through the use of herbicides to control weeds, crop varieties that tolerate packed soil, and equipment that can plant seeds or fumigate the soil without really digging it up. This practice, called no-till farming, reduces costs and environmental change by reducing soil erosion and diesel fuel usage.\nSite preparation of forest land.\nSite preparation is any of the various treatments applied to a site to ready it for seeding or planting. The purpose is to facilitate the regeneration of that site by the chosen method. Site preparation may be designed to achieve, singly or in any combination, improved access by reducing or rearranging slash and ameliorating adverse forest floor, soil, vegetation, or other biotic factors. Site preparation is undertaken to ameliorate one or more constraints that would otherwise be likely to thwart management objectives. A valuable bibliography on the effects of soil temperature and site preparation on subalpine and boreal tree species has been prepared by McKinnon et al. (2002).\nSite preparation is the work that is done before a forest area is regenerated. Some types of site preparation are burning.\nBurning.\nBroadcast burning is commonly used to prepare clearcut sites for planting, e.g., in central British Columbia, and in the temperate region of North America generally.\nPrescribed burning is carried out primarily for slash hazard reduction and to improve site conditions for regeneration; all or some of the following benefits may accrue:\na) Reduction of logging slash, plant competition, and humus prior to direct seeding, planting, scarifying or in anticipation of natural seeding in partially cut stands or in connection with seed-tree systems.\nb) Reduction or elimination of unwanted forest cover prior to planting or seeding, or prior to preliminary scarification thereto.\nc) Reduction of humus on cold, moist sites to favour regeneration.\nd) Reduction or elimination of slash, grass, or brush fuels from strategic areas around forested land to reduce the chances of damage by wildfire.\nPrescribed burning for preparing sites for direct seeding was tried on a few occasions in Ontario, but none of the burns was hot enough to produce a seedbed that was adequate without supplementary mechanical site preparation.\nChanges in soil chemical properties associated with burning include significantly increased pH, which Macadam (1987) in the Sub-boreal Spruce Zone of central British Columbia found persisting more than a year after the burn. Average fuel consumption was 20 to 24 t/ha and the forest floor depth was reduced by 28% to 36%. The increases correlated well with the amounts of slash (both total and \u22657\u00a0cm diameter) consumed. The change in pH depends on the severity of the burn and the amount consumed; the increase can be as much as 2 units, a 100-fold change. Deficiencies of copper and iron in the foliage of white spruce on burned clearcuts in central British Columbia might be attributable to elevated pH levels.\nEven a broadcast slash fire in a clearcut does not give a uniform burn over the whole area. Tarrant (1954), for instance, found only 4% of a 140-ha slash burn had burned severely, 47% had burned lightly, and 49% was unburned. Burning after windrowing obviously accentuates the subsequent heterogeneity.\nMarked increases in exchangeable calcium also correlated with the amount of slash at least 7\u00a0cm in diameter consumed. Phosphorus availability also increased, both in the forest floor and in the 0\u00a0cm to 15\u00a0cm mineral soil layer, and the increase was still evident, albeit somewhat diminished, 21 months after burning. However, in another study in the same Sub-boreal Spruce Zone found that although it increased immediately after the burn, phosphorus availability had dropped to below pre-burn levels within 9 months.\nNitrogen will be lost from the site by burning, though concentrations in remaining forest floor were found by Macadam (1987) to have increased in two out of six plots, the others showing decreases. Nutrient losses may be outweighed, at least in the short term, by improved soil microclimate through the reduced thickness of forest floor where low soil temperatures are a limiting factor.\nThe \"Picea/Abies\" forests of the Alberta foothills are often characterized by deep accumulations of organic matter on the soil surface and cold soil temperatures, both of which make reforestation difficult and result in a general deterioration in site productivity; Endean and Johnstone (1974) describe experiments to test prescribed burning as a means of seedbed preparation and site amelioration on representative clear-felled \"Picea/Abies\" areas. Results showed that, in general, prescribed burning did not reduce organic layers satisfactorily, nor did it increase soil temperature, on the sites tested. Increases in seedling establishment, survival, and growth on the burned sites were probably the result of slight reductions in the depth of the organic layer, minor increases in soil temperature, and marked improvements in the efficiency of the planting crews. Results also suggested that the process of site deterioration has not been reversed by the burning treatments applied.\nAmeliorative intervention.\nSlash weight (the oven-dry weight of the entire crown and that portion of the stem less than four inches in diameter) and size distribution are major factors influencing the forest fire hazard on harvested sites. Forest managers interested in the application of prescribed burning for hazard reduction and silviculture, were shown a method for quantifying the slash load by Kiil (1968). In west-central Alberta, he felled, measured, and weighed 60 white spruce, graphed (a) slash weight per merchantable unit volume against diameter at breast height (dbh), and (b) weight of fine slash (&lt;1.27\u00a0cm) also against dbh, and produced a table of slash weight and size distribution on one acre of a hypothetical stand of white spruce. When the diameter distribution of a stand is unknown, an estimate of slash weight and size distribution can be obtained from average stand diameter, number of trees per unit area, and merchantable cubic foot volume. The sample trees in Kiil's study had full symmetrical crowns. Densely growing trees with short and often irregular crowns would probably be overestimated; open-grown trees with long crowns would probably be underestimated.\nThe need to provide shade for young outplants of Engelmann spruce in the high Rocky Mountains is emphasized by the U.S. Forest Service. Acceptable planting spots are defined as microsites on the north and east sides of down logs, stumps, or slash, and lying in the shadow cast by such material. Where the objectives of management specify more uniform spacing, or higher densities, than obtainable from an existing distribution of shade-providing material, redistribution or importing of such material has been undertaken.\nAccess.\nSite preparation on some sites might be done simply to facilitate access by planters, or to improve access and increase the number or distribution of microsites suitable for planting or seeding.\nWang et al. (2000) determined field performance of white and black spruces 8 and 9 years after outplanting on boreal mixedwood sites following site preparation (Donaren disc trenching versus no trenching) in 2 plantation types (open versus sheltered) in southeastern Manitoba. Donaren trenching slightly reduced the mortality of black spruce but significantly increased the mortality of white spruce. Significant difference in height was found between open and sheltered plantations for black spruce but not for white spruce, and root collar diameter in sheltered plantations was significantly larger than in open plantations for black spruce but not for white spruce. Black spruce open plantation had significantly smaller volume (97\u00a0cm3) compared with black spruce sheltered (210\u00a0cm3), as well as white spruce open (175\u00a0cm3) and sheltered (229\u00a0cm3) plantations. White spruce open plantations also had smaller volume than white spruce sheltered plantations. For transplant stock, strip plantations had a significantly higher volume (329\u00a0cm3) than open plantations (204\u00a0cm3). Wang et al. (2000) recommended that sheltered plantation site preparation should be used.\nMechanical.\nUp to 1970, no \"sophisticated\" site preparation equipment had become operational in Ontario, but the need for more efficacious and versatile equipment was increasingly recognized. By this time, improvements were being made to equipment originally developed by field staff, and field testing of equipment from other sources was increasing.\nAccording to J. Hall (1970), in Ontario at least, the most widely used site preparation technique was post-harvest mechanical scarification by equipment front-mounted on a bulldozer (blade, rake, V-plow, or teeth), or dragged behind a tractor (Imsett or S.F.I. scarifier, or rolling chopper). Drag type units designed and constructed by Ontario's Department of Lands and Forests used anchor chain or tractor pads separately or in combination, or were finned steel drums or barrels of various sizes and used in sets alone or combined with tractor pad or anchor chain units.\nJ. Hall's (1970) report on the state of site preparation in Ontario noted that blades and rakes were found to be well suited to post-cut scarification in tolerant hardwood stands for natural regeneration of yellow birch. Plows were most effective for treating dense brush prior to planting, often in conjunction with a planting machine. Scarifying teeth, e.g., Young's teeth, were sometimes used to prepare sites for planting, but their most effective use was found to be preparing sites for seeding, particularly in backlog areas carrying light brush and dense herbaceous growth. Rolling choppers found application in treating heavy brush but could be used only on stone-free soils. Finned drums were commonly used on jack pine\u2013spruce cutovers on fresh brushy sites with a deep duff layer and heavy slash, and they needed to be teamed with a tractor pad unit to secure good distribution of the slash. The S.F.I. scarifier, after strengthening, had been \"quite successful\" for 2 years, promising trials were under way with the cone scarifier and barrel ring scarifier, and development had begun on a new flail scarifier for use on sites with shallow, rocky soils. Recognition of the need to become more effective and efficient in site preparation led the Ontario Department of Lands and Forests to adopt the policy of seeking and obtaining for field testing new equipment from Scandinavia and elsewhere that seemed to hold promise for Ontario conditions, primarily in the north. Thus, testing was begun of the Brackekultivator from Sweden and the Vako-Visko rotary furrower from Finland.\nMounding.\nSite preparation treatments that create raised planting spots have commonly improved outplant performance on sites subject to low soil temperature and excess soil moisture. Mounding can certainly have a big influence on soil temperature. Draper et al. (1985), for instance, documented this as well as the effect it had on root growth of outplants (Table 30).\nThe mounds warmed up quickest, and at soil depths of 0.5\u00a0cm and 10\u00a0cm averaged 10 and 7\u00a0\u00b0C higher, respectively, than in the control. On sunny days, daytime surface temperature maxima on the mound and organic mat reached 25\u00a0\u00b0C to 60\u00a0\u00b0C, depending on soil wetness and shading. Mounds reached mean soil temperatures of 10\u00a0\u00b0C at 10\u00a0cm depth 5 days after planting, but the control did not reach that temperature until 58 days after planting. During the first growing season, mounds had 3 times as many days with a mean soil temperature greater than 10\u00a0\u00b0C than did the control microsites.\nDraper et al.'s (1985) mounds received 5 times the amount of photosynthetically active radiation (PAR) summed over all sampled microsites throughout the first growing season; the control treatment consistently received about 14% of daily background PAR, while mounds received over 70%. By November, fall frosts had reduced shading, eliminating the differential. Quite apart from its effect on temperature, incident radiation is also important photosynthetically. The average control microsite was exposed to levels of light above the compensation point for only 3 hours, i.e., one-quarter of the daily light period, whereas mounds received light above the compensation point for 11 hours, i.e., 86% of the same daily period. Assuming that incident light in the 100\u2013600 \u03bcE/m2/s intensity range is the most important for photosynthesis, the mounds received over 4 times the total daily light energy that reached the control microsites.\nOrientation of linear site preparation.\nWith linear site preparation, orientation is sometimes dictated by topography or other considerations, but the orientation can often be chosen. It can make a difference. A disk-trenching experiment in the Sub-boreal Spruce Zone in interior British Columbia investigated the effect on growth of young outplants (lodgepole pine) in 13 microsite planting positions: berm, hinge, and trench in each of north, south, east, and west aspects, as well as in untreated locations between the furrows. Tenth-year stem volumes of trees on south-, east-, and west-facing microsites were significantly greater than those of trees on north-facing and untreated microsites. However, planting spot selection was seen to be more important overall than trench orientation.\nIn a Minnesota study, the N\u2013S strips accumulated more snow but snow melted faster than on E\u2013W strips in the first year after felling. Snow-melt was faster on strips near the centre of the strip-felled area than on border strips adjoining the intact stand. The strips, 50 feet (15.24 m) wide, alternating with uncut strips 16 feet (4.88 m) wide, were felled in a \"Pinus resinosa\" stand, aged 90 to 100 years.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46193", "revid": "9065236", "url": "https://en.wikipedia.org/wiki?curid=46193", "title": "Threshing machine", "text": "Agricultural machine\nA threshing machine or a thresher is a piece of farm equipment that separates grain seed from the stalks and husks. It does so by beating the plant to make the seeds fall out. Before such machines were developed, threshing was done by hand with flails: such hand threshing was very laborious and time-consuming, taking about one-quarter of agricultural labour by the 18th century. Mechanization of this process removed a substantial amount of drudgery from farm labour. The first threshing machine was invented circa 1786 by the Scottish engineer Andrew Meikle, and the subsequent adoption of such machines was one of the earlier examples of the mechanization of agriculture. During the 19th century, threshers and mechanical reapers and reaper-binders gradually became widespread and made grain production much less laborious.\nSeparate reaper-binders and threshers have largely been replaced by machines that combine all of their functions, that is combine harvesters or combines. However, the simpler machines remain important as appropriate technology in low-capital farming contexts, both in developing countries and in developed countries on small farms that strive for especially high levels of self-sufficiency. For example, pedal-powered threshers are a low-cost option, and some Amish sects use horse-drawn binders and old-style threshers.\nAs the verb \"thresh\" is cognate with the verb \"thrash\" (and synonymous in the grain-beating sense), the names thrashing machine and thrasher are (less common) alternate forms.\nEarly social impacts.\nThe Swing Riots in the UK were partly a result of the threshing machine. Following years of war, high taxes and low wages, farm labourers finally revolted in 1830. They had faced unemployment for years, due to the widespread introduction of the threshing machine and the policy of enclosing fields. With the reduction in jobs and lower wages, the threshing machine caused anger among many labourers, resulting in the Swing Riots. The Swing Rioters smashed threshing machines and threatened farmers who had them. The riots were dealt with very harshly; nine of the rioters were hanged and a further 450 transported to Australia.\nLater adoption.\nEarly threshing machines were hand-fed and horse-powered. Some were housed in a specially constructed building, a gin gang, which would be attached to a threshing barn. They were small by today's standards and were about the size of an upright piano. Later machines were steam-powered, driven by a portable engine or traction engine. Isaiah Jennings, a skilled inventor, created a small thresher that does not harm the straw in the process. In 1834, John Avery and Hiram Abial Pitts devised significant improvements to a machine that automatically threshes and separates grain from the chaff, freeing farmers from a slow and laborious process. Avery and Pitts were granted United States patent #542 on December 29, 1837.\nJohn Ridley, an Australian inventor, also developed a threshing machine in South Australia in 1843.\nThe 1881 \"Household Cyclopedia\" said of Meikle's machine:\n\"Since the invention of this machine, Mr. Meikle and others have progressively introduced a variety of improvements, all tending to simplify the labour, and to augment the quantity of the work performed. When first erected, though the grain was equally well separated from the straw, yet as the whole of the straw, chaff, and grain, was indiscriminately thrown into a confused heap, the work could only with propriety be considered as half executed. By the addition of rakes, or shakers, and two pairs of fanners, all driven by the same machinery, the different processes of thrashing, shaking, and winnowing are now all at once performed, and the grain immediately prepared for the public market. When it is added, that the quantity of grain gained from the superior powers of the machine is fully equal to a twentieth part of the crop, and that, in some cases, the expense of thrashing and cleaning the grain is considerably less than what was formerly paid for cleaning it alone, the immense saving arising from the invention will at once be seen.\"\n\"The expense of horse labour, from the increased value of the animal and the charge of his keeping, being an object of great importance, it is recommended that, upon all sizable farms, that is to say, where two hundred acres [800,000 m\u00b2], or upwards, of grain are sown, the machine should be worked by wind, unless where local circumstances afford the conveniency of water. Where coals are plenty and cheap, steam may be advantageously used for working the machine.\"\nSteam-powered machines used belts connected to a traction engine; often both engine and thresher belonged to a contractor who toured the farms of a district. Steam remained a viable commercial option until the early post-WWII years.\nModern developments.\nIn Europe and Americas.\nModern-day combines harvesters (or simply combines) operate on the same principles and use the same components as the original threshing machines built in the 19th century. Combines also perform the reaping operation at the same time. The name \"combine\" is derived from the fact that the two steps are combined in a single machine. Also, most modern combines are self-powered (usually by a diesel engine) and self-propelled, although tractor-powered, pull-type combines models were offered by John Deere and Case International into the 1990s.\nToday, as in the 19th century, threshing begins with a cylinder and concave. The cylinder has sharp serrated bars, and rotates at high speed (about 500 RPM) so that the bars beat against the entire plant as it is mechanically fed from the reaping equipment at the front of the combine to the gap between the concave and the rotating beater/cylinder. The concave is curved to match the curve of the cylinder, and the grain, now separated from the plant stalks falls immediately through grated openings in the concave as it is beaten. The motion of the rotating cylinder thrusts the remaining straw and chaff toward the rear of the machine.\nWhilst the majority of the grain falls through the concave, the straw is carried by a set of \"walkers\" to the rear of the machine, allowing any grain and chaff still in the straw to fall below. Below the straw walkers, a fan blows a stream of air across the grain, removing dust and small bits of crushed plant material out of the back of the combine. The residues fall to the ground and occasionally are collected for other purposes, such as fodder.\nThe grain, either coming through the concave or the walkers, meets a set of sieves mounted on an assembly called a shoe, which is shaken mechanically. The top sieve has larger openings and serves to remove large pieces of chaff from the grain. The lower sieve separates clean grain, which falls through, from incompletely threshed pieces. The incompletely threshed grain is returned to the cylinder by means of a system of conveyors, where the process repeats.\nSome threshing machines were equipped with a bagger, which invariably held two bags, one being filled, and the other being replaced with an empty. A worker called a \"sewer\" removed and replaced the bags, and sewed full bags shut with a needle and thread. Other threshing machines would discharge grain from a conveyor, for bagging by hand. Combines are equipped with a grain tank, which accumulates grain for deposit in a truck or wagon.\nA large amount of chaff and straw would accumulate around a threshing machine, and several innovations, such as the air chaffer, were developed to deal with this. Combines generally chop and disperse straw as they move through the field, though the chopping is disabled when the straw is to be baled, and chaff collectors are sometimes used to prevent the dispersal of weed seed throughout a field.\nThe corn sheller was almost identical in design, with slight modifications to deal with the larger kernel size and presence of cobs. Modern-day combines can be adjusted to work with any grain crop and many unusual seed crops.\nBoth the older and modern machines require a good deal of effort to operate. The concave clearance, cylinder speed, fan velocity, sieve sizes, and feeding rate must be adjusted for crop conditions.\nAnother development in Asia.\nFrom the early 20th century, petrol or diesel-powered threshing machines, designed especially to thresh rice, the most important crop in Asia, have been developed along different lines to the modern combine.\nEven after the combine was invented and became popular, a new compact-size thresher called a \"harvester\", with wheels, still remains in use and at present it is available from a Japanese agricultural manufacturer. The compact-size machine is very convenient to handle in small terrace fields in mountain areas where a large machine, such as a combine, is not usable.\nPeople there use this harvester with a modern compact binder.\nPreservation.\nA number of older threshing machines have survived into preservation. They are often to be seen in operation at live steam festivals and traction engine rallies such as the Great Dorset Steam Fair in England, and the Western Minnesota Steam Threshers Reunion in northwest Minnesota.\nMusical references.\nIrish songwriter John Duggan immortalised the threshing machine in the song \"The Old Thrashing Mill\". The song has been recorded by Foster and Allen and Brendan Shine.\nOn the Alan Lomax collection \"Songs of Seduction\" (Rounder Select, 2000), there is a bawdy Irish folk song called \"The Thrashing Machine\" sung by tinker Annie O'Neil, as recorded in the early 20th century.\nIn his film score for \"Of Mice and Men\" (1939) and consequently in his collection \"Music for the Movies\" (1942), American composer Aaron Copland titled a section of the score \"Threshing Machines,\" to suit a scene in the Lewis Milestone film where Curley is threatening Slim over giving May a puppy, when many of the itinerant worker men are standing around or working on threshers.\nIn the song \"Thrasher\" from the album \"Rust Never Sleeps\", Neil Young compares the modern threshing machine's technique of separating wheat from wheat stalks to the natural forces of time that separate close friends from one another.\nThreshing machines appear in Twenty One Pilots' music video for the song \"House of Gold\".\nThe song The \"Thrashing Machine\" By Chad Morgan Depicts Chadwick trying to impress a girl by showing her his threshing machine.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46195", "revid": "1313038465", "url": "https://en.wikipedia.org/wiki?curid=46195", "title": "Moss, Norway", "text": "Moss is a coastal town and a municipality in \u00d8stfold county, Norway. The administrative centre of the municipality is the town of Moss. The city of Moss was established as a municipality on 1 January 1838 (see formannskapsdistrikt) and City in 1720. The rural municipality of Jel\u00f8y was merged with the city on 1 July 1943. The former municipality of Rygge was merged into it on 1 January 2020.\nIts administrative district covers areas east of the town, such as the island of Dilling\u00f8y in the lake Vansj\u00f8. Parts of the town are located on the peninsula of Jel\u00f8y. The city of Moss has 30,723 inhabitants (2012).\nName.\nThe Old Norse form of the name was . It may be derived from an old root \"mer-\" which means to \"divide\" or \"split\".\nThe adjacent topography shares similar etymology:\nHistory.\nArcheological finds suggest that there were settlements in the area more than 7,000 years ago and continuously through the Iron Age, Viking Age, through to modern times. During the Viking era, the place was known as \"Varna\" (from the Old Norse , or protection) and was the site of a cooperative for battleships held by local warlords on behalf of the king.\nThe first literary reference to the name \"Mo(u)\u017fs(\u00df)\" is from Bishop Eystein Aslaksson's Red book (NRA AM fol. 328) from 1396, and by then the town had become a commercial center with craftsmen and mills. By the 16th century, the town's port was significant enough to warrant its own customs official. Liquor distilleries became one of the dominant industries, and it was not until 1607, after the Reformation, that the town got its own church.\nBy 1700, Moss had become a hub for both ship and land traffic between Copenhagen and Christiania, and in 1704 Moss Jernverk (Moss Ironworks) was established just north of the city center. By 1720 it received its charter as a merchant town, with its own official. This may have had background in an important battle in 1716 that was fought in the town square in Moss in which Norwegian troops commanded by Vincent Budde prevailed over invading Swedish forces, sent by Charles XII to capture Akershus Fortress. In 1767 a local resident built a \"pleasure pavilion\" near the town, which survives as the Hotel Refsnes Gods.\nIn 1814, Moss became the site for the signing of the Convention of Moss, which effectively put an end to the Dano-Norwegian kingdom. This set the stage for economic development that has persisted to this day.\nOn the morning of 14 July 2006, a bolide exploded above the nearby town of Rygge - moments later, several stony meteorites fell over Moss. A number of meteorites were recovered by local residents and visiting meteorite hunters, which after analysis and classification, were found to be a rare type of carbonaceous chondrite.\nSeal and coat-of-arms.\nMoss became a separate city in 1786 and received its first seal the same year. The seal showed a church under some clouds, placed within a circle. Above the circle were fasces, the late 19th century symbol of freedom. A later seal, dating from around 1829, shows the same composition, but with six birds flying around the church.\nIn the 1930s the city wanted to adopt a coat-of-arms and the birds were chosen as a possible symbol. The original birds were likely doves, a symbol of peace. In 1934, the idea of the crow was launched. The residents of Moss have long been referred to as crows. An old tale tells of a number of birds, thought to have been crows, swarming around the church spire due to a fire that started when lightning struck a birds' nest in the spire. The fire was quickly put out; birds became a motif in the city seal (and later coat-of-arms) for that reason.\nThe coat-of-arms was granted on 2 April 1954 and shows a yellow crow on a red background. It was designed by Christian Stenersen.\nNorwegian lady statues.\nMoss and Virginia Beach, Virginia in the United States are sister cities. On Good Friday, 27 March 1891, the Norwegian bark \"Dictator\", whose home port was Moss, was lost in the treacherous waters of the Graveyard of the Atlantic. The ship had been en route to England from Pensacola, Florida with a cargo of Georgia Pine lumber. After being caught and disabled in a storm, she was headed for port at Hampton Roads, Virginia to make repairs when she encountered another storm just off Virginia Beach.\nWorking in the high winds and seas, lifesaving crews from shore were able to save some of the 17 persons aboard. However, Captain J. M. Jorgensen's pregnant wife, Johanne, and their 4-year-old son Carl were among the 7 persons who drowned.\nThe ship's wooden female figurehead had washed ashore. It was placed in a vertical position facing the ocean near the boardwalk as a memorial to those who died in the shipwreck. It was a landmark there for more than 60 years, but gradually became weathered and eroded.\nIn 1962, Norwegian sculptor \u00d8rnulf Bast was commissioned to create two nine-foot bronze replicas of the original figurehead by the City of Moss. The Norwegian Lady Statues were unveiled on 22 September 1962. One was presented as a gift to Virginia Beach, and an exact duplicate was erected in Moss to unite the two sister cities. Each statue gives the appearance of facing the other across the Atlantic Ocean.\nOn 13 October 1995, Queen Sonja of Norway visited the Norwegian Lady statue in Virginia Beach, and placed memorial flowers.\nGeography.\nMoss is located on the eastern shore of Oslofjord, 60\u00a0km south of Oslo. The municipality also includes some islands, like Jel\u00f8ya. The Raet goes through the municipality. The area is forested lowland, the highest point is 140 m asl. 84% of the population is located in the town Moss.\nClimate.\nMoss has a humid continental climate (Dfb), or a temperate oceanic climate (Cfb) if the original threshold in the K\u00f6ppen climate classification is used.\nThe weather station at Moss Airport Rygge (40 m) started recording temperature in 1955. The all-time high was recorded August 1982, and the all-time low in February 1985. 10 of the record lows are from before 1990, and only the December record low is from after 2000. Rygge airport is located more inland and will have colder lows in winter and autumn than the town. The average date for first overnight freeze (below ) in autumn is 7 October (1981-2010 average) at Rygge.\nIndustry.\nThe town is known for paper mills, as well as metalworks and other factories. Dilling\u00f8y is known as a place for alternative non-military civil service. Moss is mentioned since the Renaissance and was the site of the signing of the Convention of Moss in 1814, which solidified the union with Sweden. The headquarters of textile producer Helly Hansen were located in Moss until 2009. The maker of international hotel keycards, Trio Ving, also has their headquarters here. AquaFence, a manufacturer of reusable temporary flood and hurricane barriers, is headquartered here.\nTransport.\nThe railway \u00d8stfold Line runs through Moss, stopping at Moss Station, which is the southern terminus of one service of the Oslo Commuter Rail and an intermediate stop for regional trains. Moss connects across the Oslofjord to Horten via the Moss\u2013Horten Ferry. There are also bus-lines to Oslo Airport, Gardermoen, Gothenburg, Copenhagen, Oslo in addition to local bus lines. Moss port is one of the top 3 busiest container ports in Norway (measured in TEUs).\nHealth care.\nTogether with \u00d8stfold Kalnes Hospital, \u00d8stfold Moss Hospital covers general health care services for the municipality. The hospital is a modern unit for planned operations. There is a large outpatient and inpatient activity in a number of disciplines, in the field of somatics and mental health care as well as an operation department for both inpatient and day surgery. There is an eye department, imaging services, blood sampling and blood bank and more. The municipality also has three health stations - City center, Bredsand and Kambo health stations.\nSport.\nMoss FK are the town's football club. They play in the First Division, and have played in the Norwegian Premier League as recently as 2002.\nInternational relations.\nTwin towns \u2014 Sister cities.\nThe following cities are twinned with Moss:\nUse of preposition with \"Moss\".\n\"In Moss\" is translated \"i Moss\". In the 1800s one said [on Moss] \"p\u00e5 Moss\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "46196", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=46196", "title": "Marl", "text": "Lime-rich mud or mudstone which contains variable amounts of clays and silt\nMarl is an earthy material rich in carbonate minerals, clays, and silt. When hardened into rock, this becomes marlstone. It is formed in marine or freshwater environments, often through the activities of algae.\nMarl makes up the lower part of the cliffs of Dover, and the Channel Tunnel follows these marl layers between France and the United Kingdom. Marl is also a common sediment in post-glacial lakes, such as the marl ponds of the northeastern United States and marl lakes of the Canadian Rockies.\nMarl has been used as a soil conditioner and neutralizing agent for acid soil and in the manufacture of cement.\nDescription.\nMarl or marlstone is a carbonate-rich mud or mudstone which contains variable amounts of clays and silt. The term was originally loosely applied to a variety of materials, most of which occur as loose, earthy deposits consisting chiefly of an intimate mixture of clay and calcium carbonate, formed under freshwater conditions. These typically contain 35\u201365% clay and 65\u201335% carbonate. The term is today often used to describe indurated marine deposits and lacustrine (lake) sediments which are more accurately named 'marlstone'.\nMarlstone is an indurated (resists crumbling or powdering) rock of about the same composition as marl. This is more correctly described as an earthy or impure argillaceous limestone. It has a blocky subconchoidal fracture, and is less fissile than shale. The dominant carbonate mineral in most marls is calcite, but other carbonate minerals such as aragonite or dolomite may be present.\n\"Glauconitic marl\" is marl containing pellets of glauconite, a clay mineral that gives the marl a green color. Glauconite is characteristic of sediments deposited in marine conditions.\nOccurrences.\nThe lower stratigraphic units of the chalk cliffs of Dover consist of a sequence of glauconitic marls followed by rhythmically banded limestone and marl layers. Such alternating cycles of chalk and marl are common in Cretaceous beds of northwestern Europe. The Channel Tunnel follows these marl layers between France and the United Kingdom. Upper Cretaceous cyclic sequences in Germany and marl\u2013opal-rich Tortonian-Messinian strata in the Sorbas Basin related to multiple sea drawdown have been correlated with Milankovitch orbital forcing.\nMarl as lacustrine sediment is common in post-glacial lake-bed sediments. \"Chara\", a macroalga also known as stonewort, thrives in shallow lakes with high pH and alkalinity, where its stems and fruiting bodies become calcified. After the alga dies, the calcified stems and fruiting bodies break down into fine carbonate particles that mingle with silt and clay to produce marl. Marl ponds of the northeastern United States are often kettle ponds in areas of limestone bedrock that become poor in nutrients (oligotrophic) due to precipitation of essential phosphate. Normal pond life is unable to survive, and skeletons of freshwater molluscs such as \"Sphaerium\" and \"Planorbis\" accumulate as part of the bottom marl.\nIn Hungary, Buda Marl is found that was formed in the Upper Eocene era. It lies between layers of rock and soil and may be defined it as both \"weak rock and strong soil.\"\nMarl is the dominant rock type in the Vaca Muerta Formation in Argentina.\nEconomic geology.\nMarl has been used as a soil conditioner and neutralizing agent for acid soil and in the manufacture of Portland cement. Because some marls have a very low permeability, they have been exploited for construction of the Channel Tunnel between England and France and are being investigated for the storage of nuclear waste.\nHistorical use in agriculture.\nMarl is one of the oldest soil amendments used in agriculture. In addition to increasing available calcium, marl is valuable for improving soil structure and decreasing soil acidity and thereby making other nutrients more available. It was used sporadically in Britain beginning in prehistoric times and its use was mentioned by Pliny the Elder in the 1st century. Its more widespread use from the 16th century on contributed to the early modern agricultural revolution. However, the lack of a high-energy economy hindered its large-scale use until the Industrial Revolution.\nMarl was used extensively in Britain, particularly in Lancashire, during the 18th century. The marl was normally extracted close to its point of use, so that almost every field had a marl pit, but some marl was transported greater distances by railroad. However, marl was gradually replaced by lime and imported mineral fertilizers early in the 19th century. A similar historical pattern was seen in Scotland.\nMarl was one of a few soil amendments available in limited quantities in the southern United States, where soils were generally poor in nutrients, prior to about 1840. By the late 19th century, marl was being mined on an industrial scale in New Jersey and was increasingly being used on a more scientific basis, with marl being classified by grade and the state geological survey publishing detailed chemical analyses.\nModern agricultural and aquacultural uses.\nMarl continues to be used for agriculture into the 21st century, though less frequently. The rate of application must be adjusted for the reduced content of calcium carbonate versus straight lime, expressed as the calcium carbonate equivalent. Because the carbonate in marl is predominantly calcium carbonate, magnesium deficiency may be seen in crops treated with marl if they are not also supplemented with magnesium.\nMarl has been used in Pamlico Sound to provide a suitable artificial substrate for oysters in a reef-like environment.\nPortland cement.\nMarl has been used in the manufacture of Portland cement. It is abundant and yields better physical and mechanical properties than metakaolin as a supplementary cementitious material and can be calcined at a considerably lower temperature.\nCivil engineering.\nThe Channel Tunnel was constructed in the West Melbury Marly Chalk, a geological formation containing marl beds. This formation was chosen because of its very low permeability, absence of chert, and lack of fissures found in overlying formations. The underlying Glauconitic Marl is easily recognizable in core samples and helped establish the right level for excavating the tunnel.\nMarl soil has poor engineering properties, particularly when alternately wetted and dried. The soils can be stabilized by adding pozzolan (volcanic ash) to the soil.\nNuclear waste storage.\nSome marl beds have a very low permeability and are under consideration for use in the storage of nuclear waste. One such proposed storage site is the Wellenberg in central Switzerland.\nMarl lakes.\nA marl lake is a lake whose bottom sediments include large deposits of marl. They are most often found in areas of recent glaciation and are characterized by alkaline water, rich in dissolved calcium carbonate, from which carbonate minerals are deposited.\nMarl lakes have frequently been dredged or mined for marl, often used for manufacturing Portland cement. However, they are regarded as ecologically important, and are vulnerable to damage by silting, nutrient pollution, drainage, and invasive species. In Britain, only the marl lakes of the more remote parts of northern Scotland are likely to remain pristine into the near future.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "46202", "revid": "19814917", "url": "https://en.wikipedia.org/wiki?curid=46202", "title": "Pink noise", "text": "Signal with equal energy per octave\nPink noise, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u2044\"f\" noise, fractional noise or fractal noise is a signal or process with a frequency spectrum such that the power spectral density (power per frequency interval) is inversely proportional to the frequency of the signal. In pink noise, each octave interval (halving or doubling in frequency) carries an equal amount of noise energy.\nPink noise sounds like a waterfall. It is often used to tune loudspeaker systems in professional audio. Pink noise is one of the most commonly observed signals in biological systems.\nThe name arises from the pink appearance of visible light with this power spectrum. This is in contrast with white noise which has equal intensity per frequency interval.\nDefinition.\nWithin the scientific literature, the term \"1/f noise\" is sometimes used loosely to refer to any noise with a power spectral density of the form\nformula_1\nwhere f is frequency, and 0 &lt; \"\u03b1\" &lt; 2, with exponent \u03b1 usually close to 1. One-dimensional signals with \"\u03b1\" = 1 are usually called pink noise.\nThe following function describes a length N one-dimensional pink noise signal (i.e. a Gaussian white noise signal with zero mean and standard deviation \u03c3, which has been suitably filtered), as a sum of sine waves with different frequencies, whose amplitudes fall off inversely with the square root of frequency u (so that power, which is the square of amplitude, falls off inversely with frequency), and phases are random:\nformula_2\n\u03c7u are independently and identically (iid) chi-distributed variables, and \u03d5u are uniform random.\nIn a two-dimensional pink noise signal, the amplitude at any orientation falls off inversely with frequency. A pink noise square of length N can be written as:\nformula_3\nGeneral 1/\"f\u03b1\"-like noises occur widely in nature and are a source of considerable interest in many fields. Noises with \u03b1 near 1 generally come from condensed-matter systems in quasi-equilibrium, as discussed below. Noises with a broad range of \u03b1 generally correspond to a wide range of non-equilibrium driven dynamical systems.\nPink noise sources include \"flicker noise\" in electronic devices. In their study of fractional Brownian motion, Mandelbrot and Van Ness proposed the name \"fractional noise\" (sometimes since called \"fractal noise\") to describe 1/\"f\u03b1\" noises for which the exponent \u03b1 is not an even integer, or that are fractional derivatives of Brownian (1/\"f\"2) noise.\nDescription.\nIn pink noise, there is equal energy per octave of frequency. The energy of pink noise at each frequency level, however, falls off at roughly 3\u00a0dB per octave. This is in contrast to white noise which has equal energy at all frequency levels.\nThe human auditory system, which processes frequencies in a roughly logarithmic fashion approximated by the Bark scale, does not perceive different frequencies with equal sensitivity; signals around 1\u20134\u00a0kHz sound loudest for a given intensity. However, humans still differentiate between white noise and pink noise with ease.\nGraphic equalizers also divide signals into bands logarithmically and report power by octaves; audio engineers put pink noise through a system to test whether it has a flat frequency response in the spectrum of interest. Systems that do not have a flat response can be equalized by creating an inverse filter using a graphic equalizer. Because pink noise tends to occur in natural physical systems, it is often useful in audio production. Pink noise can be processed, filtered, and/or effects can be added to produce desired sounds. Pink-noise generators are commercially available.\nOne parameter of noise, the peak versus average energy contents, or crest factor, is important for testing purposes, such as for audio power amplifier and loudspeaker capabilities because the signal power is a direct function of the crest factor. Various crest factors of pink noise can be used in simulations of various levels of dynamic range compression in music signals. On some digital pink-noise generators the crest factor can be specified.\nGeneration.\nPink noise can be computer-generated by first generating a white noise signal, Fourier-transforming it, then dividing the amplitudes of the different frequency components by the square root of the frequency (in one dimension), or by the frequency (in two dimensions) etc. This is equivalent to spatially filtering (convolving) the white noise signal with a white-to-pink-filter. For a length formula_4 signal in one dimension, the filter has the following form:\nformula_5\nMatlab programs are available to generate pink and other power-law coloured noise in http:// or https:// of dimensions.\nOne efficient algorithm for generation is the Voss\u2013McCartney algorithm, an efficient method to generate discrete-time pink noise (1/f noise). It sums multiple independent random sequences (white noise sources), each updated at different rates, to approximate the 1/f power spectral density. Lower-frequency components are updated less frequently than higher-frequency components.\nA simple pseudocode implementation is:\nn_streams = number of random streams\nstreams = [random() for _ in range(n_streams)]\noutput = []\nfor i in range(total_samples):\n for j in range(n_streams):\n if i % (2**j) == 0:\n streams[j] = random()\n output.append(sum(streams))\nEach stream is updated at intervals that are powers of two, ensuring that slower-changing streams contribute low-frequency content and faster-changing streams contribute high-frequency content.\nProperties.\nPower-law spectra of amplitude and power.\nIn a pink noise signal in any number of dimensions, the total power formula_6 at each frequency, summed across all orientations, falls off inversely with frequency: formula_7. Each octave carries an equal amount of total noise power. The total power at each frequency is the power summed over a spherical shell in the Fourier domain, so it is the average power formula_8 along any orientation formula_9, multiplied by the surface area of the shell: formula_10. This tells us that the average power at any orientation falls off as formula_11 in one dimension, as formula_12 in two dimensions (e.g. pink noise images), and as formula_13 in general formula_14 dimensions. The average amplitude at any orientation is the square root of the average power: formula_15, so it falls as formula_16 in 1D, formula_17 in 2D, and as formula_18 in general formula_14 dimensions.\nThe following table lists these power-law frequency-dependencies for pink noise signal in different dimensions formula_14, and also for general power-law colored noise with power formula_21 (pink noise has formula_22 and Brown noise has formula_23):\nDistribution of point values.\nConsider pink noise of any dimension that is produced by generating a Gaussian white noise signal with mean formula_24 and sd formula_25, then multiplying its spectrum with a filter (equivalent to spatially filtering it with a filter formula_26). Then the point values of the pink noise signal will also be normally distributed, with mean formula_24 and sd formula_28.\nAutocorrelation.\nUnlike white noise, which has no correlations across the signal, a pink noise signal is correlated with itself, as follows.\n1D signal.\nThe Pearson's correlation coefficient of a one-dimensional pink noise signal (comprising discrete frequencies formula_29) with itself across a distance formula_14 in the configuration (space or time) domain is:\nformula_31\nIf instead of discrete frequencies, the pink noise comprises a superposition of continuous frequencies from formula_32 to formula_33, the autocorrelation coefficient is:\nformula_34\nwhere formula_35 is the cosine integral function.\n2D signal.\nThe Pearson's autocorrelation coefficient of a two-dimensional pink noise signal comprising discrete frequencies is theoretically approximated as:\nformula_36\nwhere formula_37 is the Bessel function of the first kind.\nOccurrence.\nPink noise has been discovered in the statistical fluctuations of an extraordinarily diverse number of physical and biological systems (Press, 1978; see articles in Handel &amp; Chung, 1993, and references therein). Examples of its occurrence include fluctuations in tide and river heights, quasar light emissions, heart beat, firings of single neurons, resistivity in solid-state electronics and single-molecule conductance signals resulting in flicker noise. Pink noise describes the statistical structure of many natural images. \nGeneral 1/\"f\"\u00a0\u03b1 noises occur in many physical, biological and economic systems, and some researchers describe them as being ubiquitous. In physical systems, they are present in some meteorological data series, the electromagnetic radiation output of some astronomical bodies. In biological systems, they are present in, for example, heart beat rhythms, neural activity, and the statistics of DNA sequences, as a generalized pattern.\nAn accessible introduction to the significance of pink noise is one given by Martin Gardner (1978) in his \"Scientific American\" column \"Mathematical Games\". In this column, Gardner asked for the sense in which music imitates nature. Sounds in nature are not musical in that they tend to be either too repetitive (bird song, insect noises) or too chaotic (ocean surf, wind in trees, and so forth). The answer to this question was given in a statistical sense by Voss and Clarke (1975, 1978), who showed that pitch and loudness fluctuations in speech and music are pink noises. So music is like tides not in terms of how tides sound, but in how tide heights vary.\nPrecision timekeeping.\nThe ubiquitous 1/f noise poses a \"noise floor\" to precision timekeeping. The derivation is based on.\nSuppose that we have a timekeeping device (it could be anything from quartz oscillators, atomic clocks, and hourglasses). Let its readout be a real number formula_38 that changes with the actual time formula_39. For concreteness, let us consider a quartz oscillator. In a quartz oscillator, formula_38 is the number of oscillations, and formula_41 is the rate of oscillation. The rate of oscillation has a constant component formula_42and a fluctuating component formula_43, so formula_44. By selecting the right units for formula_45, we can have formula_46, meaning that on average, one second of clock-time passes for every second of real-time.\nThe stability of the clock is measured by how many \"ticks\" it makes over a fixed interval. The more stable the number of ticks, the better the stability of the clock. So, define the average clock frequency over the interval formula_47 asformula_48Note that formula_49 is unitless: it is the numerical ratio between ticks of the physical clock and ticks of an ideal clock.\nThe Allan variance of the clock frequency is half the mean square of change in average clock frequency:formula_50where formula_51 is an integer large enough for the averaging to converge to a definite value.\nFor example, a 2013 atomic clock achieved formula_52, meaning that if the clock is used to repeatedly measure intervals of 7 hours, the standard deviation of the actually measured time would be around 40 femtoseconds.\nNow we haveformula_53where formula_54 is one packet of a square wave with height formula_55 and wavelength formula_56. Let formula_57 be a packet of a square wave with height 1 and wavelength 2, then formula_58, and its Fourier transform satisfies formula_59.\nThe Allan variance is then formula_60, and the discrete averaging can be approximated by a continuous averaging: formula_61, which is the total power of the signal formula_62, or the integral of its power spectrum:\nformula_63In words, the Allan variance is approximately the power of the fluctuation after bandpass filtering at formula_64 with bandwidth formula_65.\nFor formula_66 fluctuation, we have formula_67 for some constant formula_68, so formula_69. In particular, when the fluctuating component formula_43 is a 1/f noise, then formula_71 is independent of the averaging time formula_72, meaning that the clock frequency does not become more stable by simply averaging for longer. This contrasts with a white noise fluctuation, in which case formula_73, meaning that doubling the averaging time would improve the stability of frequency by formula_74.\nThe cause of the noise floor is often traced to particular electronic components (such as transistors, resistors, and capacitors) within the oscillator feedback.\nHumans.\nIn brains, pink noise has been widely observed across many temporal and physical scales from ion channel gating to EEG and MEG and LFP recordings in humans. In clinical EEG, deviations from this 1/f pink noise can be used to identify epilepsy, even in the absence of a seizure, or during the interictal state. Classic models of EEG generators suggested that dendritic inputs in gray matter were principally responsible for generating the 1/f power spectrum observed in EEG/MEG signals. However, recent computational models using cable theory have shown that action potential transduction along white matter tracts in the brain also generates a 1/f spectral density. Therefore, white matter signal transduction may also contribute to pink noise measured in scalp EEG recordings,\nparticularly if the effects of ephaptic coupling are taken into consideration. \nIt has also been successfully applied to the modeling of mental states in psychology, and used to explain stylistic variations in music from different cultures and historic periods. Richard F. Voss and J. Clarke claim that almost all musical melodies, when each successive note is plotted on a scale of pitches, will tend towards a pink noise spectrum. Similarly, a generally pink distribution pattern has been observed in film shot length by researcher James E. Cutting of Cornell University, in the study of 150 popular movies released from 1935 to 2005.\nPink noise has also been found to be endemic in human response. Gilden et al. (1995) found extremely pure examples of this noise in the time series formed upon iterated production of temporal and spatial intervals. Later, Gilden (1997) and Gilden (2001) found that time series formed from reaction time measurement and from iterated two-alternative forced choice also produced pink noises.\nElectronic devices.\nThe principal sources of pink noise in electronic devices are almost invariably the slow fluctuations of properties of the condensed-matter materials of the devices. In many cases the specific sources of the fluctuations are known. These include fluctuating configurations of defects in metals, fluctuating occupancies of traps in semiconductors, and fluctuating domain structures in magnetic materials. The explanation for the approximately pink spectral form turns out to be relatively trivial, usually coming from a distribution of kinetic activation energies of the fluctuating processes. Since the frequency range of the typical noise experiment (e.g., 1\u00a0Hz \u2013 1\u00a0kHz) is low compared with typical microscopic \"attempt frequencies\" (e.g., 1014\u00a0Hz), the exponential factors in the Arrhenius equation for the rates are large. Relatively small spreads in the activation energies appearing in these exponents then result in large spreads of characteristic rates. In the simplest toy case, a flat distribution of activation energies gives exactly a pink spectrum, because formula_75\nThere is no known lower bound to background pink noise in electronics. Measurements made down to 10\u22126\u00a0Hz (taking several weeks) have not shown a ceasing of pink-noise behaviour. (Kleinpenning, de Kuijper, 1988) measured the resistance in a noisy carbon-sheet resistor, and found 1/f noise behavior over the range of formula_76, a range of 9.5 decades.\nA pioneering researcher in this field was Aldert van der Ziel.\nFlicker noise is commonly used for the reliability characterization of electronic devices. It is also used for gas detection in chemoresistive sensors by dedicated measurement setups.\nIn gravitational wave astronomy.\n1/\"f\"\u00a0\u03b1 noises with \u03b1 near 1 are a factor in gravitational-wave astronomy. The noise curve at very low frequencies affects pulsar timing arrays, the European Pulsar Timing Array (EPTA) and the future International Pulsar Timing Array (IPTA); at low frequencies are space-borne detectors, the formerly proposed Laser Interferometer Space Antenna (LISA) and the currently proposed evolved Laser Interferometer Space Antenna (eLISA), and at high frequencies are ground-based detectors, the initial Laser Interferometer Gravitational-Wave Observatory (LIGO) and its advanced configuration (aLIGO). The characteristic strain of potential astrophysical sources are also shown. To be detectable the characteristic strain of a signal must be above the noise curve.\nClimate dynamics.\nPink noise on timescales of decades has been found in climate proxy data, which may indicate amplification and coupling of processes in the climate system.\nDiffusion processes.\nMany time-dependent stochastic processes are known to exhibit 1/\"f\"\u00a0\u03b1 noises with \u03b1 between 0 and 2. In particular Brownian motion has a power spectral density that equals 4\"D\"/\"f\"\u00a02, where \"D\" is the diffusion coefficient. This type of spectrum is sometimes referred to as Brownian noise. The analysis of individual Brownian motion trajectories also show 1/\"f\"\u00a02 spectrum, albeit with random amplitudes. Fractional Brownian motion with Hurst exponent \"H\" also show 1/\"f\"\u00a0\u03b1 power spectral density with \u03b1=2\"H\"+1 for subdiffusive processes (\"H\"&lt;0.5) and \u03b1=2 for superdiffusive processes (0.5&lt;\"H\"&lt;1).\nOrigin.\nThere are many theories about the origin of pink noise. Some theories attempt to be universal, while others apply to only a certain type of material, such as semiconductors. Universal theories of pink noise remain a matter of current research interest.\nA hypothesis (referred to as the Tweedie hypothesis) has been proposed to explain the genesis of pink noise on the basis of a mathematical convergence theorem related to the central limit theorem of statistics. The Tweedie convergence theorem describes the convergence of certain statistical processes towards a family of statistical models known as the Tweedie distributions. These distributions are characterized by a variance to mean power law, that have been variously identified in the ecological literature as Taylor's law and in the physics literature as \"fluctuation scaling\". When this variance to mean power law is demonstrated by the method of expanding enumerative bins this implies the presence of pink noise, and vice versa. Both of these effects can be shown to be the consequence of mathematical convergence such as how certain kinds of data will converge towards the normal distribution under the central limit theorem. This hypothesis also provides for an alternative paradigm to explain power law manifestations that have been attributed to self-organized criticality.\nThere are various mathematical models to create pink noise. The superposition of exponentially decaying pulses is able to generate a signal with the formula_77-spectrum at moderate frequencies, transitioning to a constant at low frequencies and formula_78 at high frequencies. In contrast, the sandpile model of self-organized criticality, which exhibits quasi-cycles of gradual stress accumulation between fast rare stress-releases, reproduces the flicker noise that corresponds to the intra-cycle dynamics. The statistical signature of self-organization is justified in It can be generated on computer, for example, by filtering white noise, inverse Fourier transform, or by multirate variants on standard white noise generation.\nIn supersymmetric theory of stochastics, an approximation-free theory of stochastic differential equations, 1/\"f\" noise is one of the manifestations of the spontaneous breakdown of topological supersymmetry. This supersymmetry is an intrinsic property of all stochastic differential equations and its meaning is the preservation of the continuity of the phase space by continuous time dynamics. Spontaneous breakdown of this supersymmetry is the stochastic generalization of the concept of deterministic chaos, whereas the associated emergence of the long-term dynamical memory or order, i.e., 1/\"f\" and crackling noises, the Butterfly effect etc., is the consequence of the Goldstone theorem in the application to the spontaneously broken topological supersymmetry.\nAudio testing.\nPink noise is commonly used to test the loudspeakers in sound reinforcement systems, with the resulting sound measured with a test microphone in the listening space connected to a spectrum analyzer or a computer running a real-time fast Fourier transform (FFT) analyzer program such as Smaart. The sound system plays pink noise while the audio engineer makes adjustments on an audio equalizer to obtain the desired results. Pink noise is predictable and repeatable, but it is annoying for a concert audience to hear. Since the late 1990s, FFT-based analysis enabled the engineer to make adjustments using pre-recorded music as the test signal, or even the music coming from the performers in real time. Pink noise is still used by audio system contractors and by computerized sound systems which incorporate an automatic equalization feature.\nIn manufacturing, pink noise is often used as a burn-in signal for audio amplifiers and other components, to determine whether the component will maintain performance integrity during sustained use. The process of end-users burning in their headphones with pink noise to attain higher fidelity has been called an audiophile \"myth\".\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46203", "revid": "1313303178", "url": "https://en.wikipedia.org/wiki?curid=46203", "title": "35 mm movie film", "text": "Standard theatrical motion picture film gauge\n35\u00a0mm film is a film gauge used in filmmaking, and the film standard. In motion pictures that record on film, 35\u00a0mm is the most commonly used gauge. The name of the gauge is not a direct measurement, and refers to the nominal width of the 35 mm format photographic film, which consists of strips wide. The standard image exposure length on 35\u00a0mm for movies (\"single-frame\" format) is four perforations per frame along both edges, which results in 16 frames per foot of film.\nA variety of largely proprietary gauges were devised for the numerous camera and projection systems being developed independently in the late 19th and early 20th centuries, along with various film feeding systems. This resulted in cameras, projectors, and other equipment having to be calibrated to each gauge. The 35\u00a0mm width, originally specified as &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1+3\u20448 inches, was introduced around 1890 by William Kennedy Dickson and Thomas Edison, using film stock supplied by George Eastman. Film 35\u00a0mm wide with four perforations per frame became accepted as the international standard gauge in 1909, and remained by far the dominant film gauge for image origination and projection until the advent of digital photography and cinematography.\nThe gauge has been versatile in application. It has been modified to include sound, redesigned to create a safer film base, formulated to capture color, has accommodated a bevy of widescreen formats, and has incorporated digital sound data into nearly all of its non-frame areas. Eastman Kodak, Fujifilm and Agfa-Gevaert are some companies that offered 35\u00a0mm films. As of 2015, Kodak is the last remaining manufacturer of motion picture film.\nThe ubiquity of 35\u00a0mm movie projectors in commercial movie theaters made 35\u00a0mm the only motion picture format that could be played in almost any cinema in the world, until digital projection largely superseded it.\nHistory and development.\nEarly history.\nIn 1880, George Eastman began to manufacture gelatin dry photographic plates in Rochester, New York. Along with W. H. Walker, Eastman invented a holder for a roll of picture-carrying gelatin layer-coated paper. Hannibal Goodwin then invented a nitrocellulose film base in 1887, the first transparent, flexible film. Eastman also produced these components, and his was the first major company to mass-produce such film when, in 1889, Eastman realized that the dry-gelatino-bromide emulsion could be coated onto this clear base, eliminating the paper.\nWith the advent of flexible film, Thomas Edison quickly set out on his invention, the Kinetoscope, which was first shown at the Brooklyn Institute of Arts and Sciences on May 9, 1893. The Kinetoscope was a film loop system intended for one-person viewing. Edison, along with assistant William Kennedy Dickson, followed that up with the Kinetophone, which combined the Kinetoscope with Edison's cylinder phonograph. Beginning in March 1892, Eastman and then, from April 1893 into 1896, New York's https:// supplied Edison with film stock. Dickson is credited as the inventor of 35\u00a0mm movie film in 1889,652 when the Edison company was using Eastman film.653\u2013654 The company still received film from Blair after this; at first Blair would supply only film stock that would be trimmed and perforated at the Edison lab to create gauge filmstrips, then at some point in 1894 or 1895, Blair began sending stock to Edison that was cut exactly to specification. Edison's aperture defined a single frame of film at four perforations high.\nAround 1896, a 35\u00a0mm projector known as a \"photo-rotoscope\" was made by W. C. Hughes in London, which advanced the film by means of a \"dog\" motion.\nFor a time, it had been generally assumed that Dickson was following cinematography formats established by Eastman in producing the film, but Eastman had produced film in sheets that were then cut to order.652\u2013653 Dickson used the film supplied for Eastman Kodak cameras in 1889, a transparent 70\u00a0mm celluloid film, in his development of a more suitable film stock, and \"simply slit this film in half\";653\u2013654 it was initially developed for the Kinetoscope, a one-person viewer, not to be projected.658 The image was still of high quality, even when magnified, and was more economical than 70\u00a0mm film (and more economical than any other gauge, as cutting the 70\u00a0mm to size would have created waste).654 35\u00a0mm was immediately accepted as standard by the Lumi\u00e8re brothers, and became the main film used in the UK because it was the stock sold to these filmmakers by the Blair company.653\nEdison claimed exclusive patent rights to the design of 35\u00a0mm motion picture film, with four sprocket holes (perforations) per frame, forcing his only major filmmaking competitor, American Mutoscope &amp; Biograph, to use a 68\u00a0mm film that used friction feed, not sprocket holes, to move the film through the camera. A court judgment in March 1902 invalidated Edison's claim, allowing any producer or distributor to use the Edison 35\u00a0mm film design without license. Filmmakers were already doing so in Britain and Europe, where Edison did not file patents. At the time, film stock was usually supplied unperforated and punched by the filmmaker to their standards with perforation equipment. A variation developed by the Lumi\u00e8re brothers used a single circular perforation on each side of the frame towards the middle of the horizontal axis.\nBecoming the standard.\nWhen films began to be projected, several projection devices were unsuccessful and fell into obscurity because of technical failure, lack of business acumen on the part of their promoters, or both. The Vitascope, the first projection device to use 35\u00a0mm, was technologically superior and compatible with the many motion pictures produced on 35\u00a0mm film. Edison bought the device in 1895\u201396; the Lumiere's 35\u00a0mm projection Cinematograph also premiered in 1895, and they established 35\u00a0mm as the standard for exhibition.658\nStandardization in recording came from monopolization of the business by Eastman and Edison, and because of Edison's typical business model involving the patent system: Eastman and Edison managed their film patents well656 \u2013 Edison filed the 35\u00a0mm patent in 1896, the year after Dickson left his employ657 \u2013 and so controlled the use and development of film.656 Dickson left the Edison company in 1895, going on to help competitors produce cameras and other film gauges that would not infringe on Edison's patents. However, by 1900, filmmakers found it too expensive to develop and use other gauges, and went back to using the cheap and widely-available 35\u00a0mm.657\nDickson said in 1933:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nUntil 1953, the 35\u00a0mm film was seen as \"basic technology\" in the film industry, rather than optional, despite other gauges being available.652\nIn 1908, Edison formed \"a cartel of production companies\", a trust called the Motion Picture Patents Company (MPPC), pooling patents for collective use in the industry and positioning Edison's own technology as the standard to be licensed out.656 35\u00a0mm became the \"official\" standard of the newly formed MPPC, which agreed in 1909 to what would become the standard: 35\u00a0mm gauge, with Edison perforations and a 1.33:1 (4:3) aspect ratio (also developed by Dickson).652 Scholar Paul C. Spehr describes the importance of these developments:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nWhen the MPPC adopted the 35\u00a0mm format, Bell &amp; Howell produced cameras, projectors, and perforators for the medium of an \"exceptionally high quality\", further cementing it as the standard.659 Edison and Eastman's form of business manipulation was ruled unlawful in 1914, but by this time the technology had become the established standard.657 In 1917, the new Society of Motion Picture Engineers (SMPE) \"acknowledged the de facto status of 35\u00a0mm as the industry's dominant film gauge, adopting it as an engineering standard\".659\nInnovations in sound.\nWhen film editing was done by physically cutting the film, editing the picture could only have been done on the frame line. However, the sound was stored for the whole frame between each of the four sprocket holes, and so the sound editors could cut on any arbitrary set of holes, and thus get &lt;templatestyles src=\"Fraction/styles.css\" /&gt;+1\u20444-frame edit resolution. With this technique, an audio edit could be accurate to within 10.41\u00a0ms.\"1\u20132 A limitation of analog optical recording was the audio frequency would cut off, in a well-maintained theater, at around 12kHz.4 Studios would often record audio on the transparent film strips, but with magnetic tape on one edge; recording audio on full 35\u00a0mm magnetic tape was more expensive.5\nThree different digital soundtrack systems for 35\u00a0mm cinema release prints were introduced during the 1990s. They are: Dolby Digital, which is stored between the perforations on the sound side; SDDS, stored in two redundant strips along the outside edges (beyond the perforations); and DTS, in which sound data is stored on separate compact discs synchronized by a timecode track on the film just to the right of the analog soundtrack and left of the frame. Because these soundtrack systems appear on different parts of the film, one movie can contain all of them, allowing broad distribution without regard for the sound system installed at individual theatres.\nThe analogue optical track technology has also changed: in the early years of the 21st century, distributors changed to using cyan dye optical soundtracks instead of applicated tracks, which use environmentally unfriendly chemicals to retain a silver (black-and-white) soundtrack. Because traditional incandescent exciter lamps produce copious amounts of infrared light, and cyan tracks do not absorb infrared light, this change has required theaters to replace the incandescent exciter lamp with a complementary colored red LED or laser. These LED or laser exciters are backwards-compatible with older tracks. The film \"Anything Else\" (2003) was the first to be released with only cyan tracks.\nTo facilitate this changeover, intermediate prints known as \"high magenta\" prints were distributed. These prints used a silver plus dye soundtrack that were printed into the magenta dye layer. The advantage gained was an optical soundtrack, with low levels of sibilant (cross-modulation) distortion, on both types of sound heads.\nModern 3D systems.\nThe success of digitally projected 3D movies in the first two decades of the 21st century led to a demand from some theater owners to be able to show these movies in 3D without incurring the high capital cost of installing digital projection equipment. To satisfy that demand, a number of systems had been proposed for 3D systems based on 35\u00a0mm film by Technicolor, Panavision and others. These systems are improved versions of the \"over-under\" stereo 3D prints first introduced in the 1960s.\nTo be attractive to exhibitors, these schemes offered 3D films that can be projected by a standard 35\u00a0mm cinema projector with minimal modification, and so they are based on the use of \"over-under\" film prints. In these prints a left-right pair of 2.39:1 non-anamorphic images are substituted for the one 2.39:1 anamorphic image of a 2D \"scope\" print. The frame dimensions are based on those of the Techniscope 2-perf camera format used in the 1960s and 1970s. However, when used for 3D the left and right frames are pulled down together, thus the standard 4-perf pulldown is retained, minimising the need for modifications to the projector or to long-play systems. The linear speed of film through the projector and sound playback both remain exactly the same as in normal 2D operation.\nThe Technicolor system uses the polarisation of light to separate the left and right eye images and for this they rent to exhibitors a combination splitter-polarizer-lens assembly which can be fitted to a lens turret in the same manner as an anamorphic lens. In contrast, the Panavision system uses a spectral comb filter system, but their combination splitter-filter-lens is physically similar to the Technicolor assembly and can be used in the same way. No other modifications are required to the projector for either system, though for the Technicolor system a silver screen is necessary, as it would be with polarised-light digital 3D. Thus a programme can readily include both 2D and 3D segments with only the lens needing to be changed between them.\nIn June 2012, Panavision 3D systems for both 35\u00a0mm film and digital projection were withdrawn from the market by DVPO theatrical (who marketed these system on behalf of Panavision) citing \"challenging global economic and 3D market conditions\".\nDecline and resurgence.\nIn the transition period centered around 2010\u20132015, the rapid conversion of the cinema exhibition industry to digital projection saw 35\u00a0mm film projectors removed from most of the projection rooms as they were replaced by digital projectors. By the mid-2010s, most of the theaters across the world had been converted to digital projection, although a small percentage (under 10% overall) continued running 35\u00a0mm projectors, mostly indie theaters or those in more economically challenged regions. However, it continued as a niche market for enthusiasts and format lovers.\nIn the 2020s, 35\u00a0mm has seen some resurgence in usage. The resurgence comes from those who find 35\u00a0mm to be more visually pleasing and evoke nostalgic feelings, as well as a desire from young Millennials and Generation Z filmmakers and photographers to preserve the art. Several films such as \"Oppenheimer\" and \"Anora\" have been produced using 35\u00a0mm film. In an effort to rebuild business lost during the COVID-19 pandemic, some theaters have used special event screenings of films with 35\u00a0mm film projectors to attract customers. Most of these screenings occur in large metropolitan areas.\nAttributes.\nColor.\nOriginally, film was a strip of cellulose nitrate coated with black-and-white photographic emulsion. Early film pioneers, like D. W. Griffith, color tinted or toned portions of their movies for dramatic impact, and by 1920, 80 to 90 percent of all films were tinted. The first successful natural color process was Britain's Kinemacolor (1909\u20131915), a two-color additive process that used a rotating disk with red and green filters in front of the camera lens and the projector lens. But any process that photographed and projected the colors sequentially was subject to color \"fringing\" around moving objects, and a general color flickering.\nIn 1916, William Van Doren Kelley began developing Prizma, the first commercially viable American color process using 35\u00a0mm film. Initially, like Kinemacolor, it photographed the color elements one after the other and projected the results by additive synthesis. Ultimately, Prizma was refined to bipack photography, with two strips of film, one treated to be sensitive to red and the other not, running through the camera face to face. Each negative was printed on one surface of the same duplitized print stock and each resulting series of black-and-white images was chemically toned to transform the silver into a monochrome color, either orange-red or blue-green, resulting in a two-sided, two-colored print that could be shown with any ordinary projector. This system of two-color bipack photography and two-sided prints was the basis for many later color processes, such as Multicolor, Brewster Color and Cinecolor.\nAlthough it had been available previously, color in Hollywood feature films first became truly practical from the studios' commercial perspective with the advent of Technicolor, whose main advantage was quality prints in less time than its competitors. In its earliest incarnations, Technicolor was another two-color system that could reproduce a range of reds, muted bluish greens, pinks, browns, tans and grays, but not real blues or yellows. \"The Toll of the Sea\", released in 1922, was the first film printed in their subtractive color system. Technicolor's camera photographed each pair of color-filtered frames simultaneously on one strip of black-and-white film by means of a beam splitter prism behind the camera lens. Two prints on half-thickness stock were made from the negative, one from only the red-filtered frames, the other from the green-filtered frames. After development, the silver images on the prints were chemically toned to convert them into images of the approximately complementary colors. The two strips were then cemented together back to back, forming a single strip similar to duplitized film.\nIn 1928, Technicolor started making their prints by the imbibition process, which was mechanical rather than photographic and allowed the color components to be combined on the same side of the film. Using two matrix films bearing hardened gelatin relief images, thicker where the image was darker, aniline color dyes were transferred into the gelatin coating on a third, blank strip of film.\nTechnicolor re-emerged as a three-color process for cartoons in 1932 and live action in 1934. Using a different arrangement of a beam-splitter cube and color filters behind the lens, the camera simultaneously exposed three individual strips of black-and-white film, each one recording one-third of the spectrum, which allowed virtually the entire spectrum of colors to be reproduced. A printing matrix with a hardened gelatin relief image was made from each negative, and the three matrices transferred color dyes into a blank film to create the print.\nTwo-color processes, however, were far from extinct. In 1934, William T. Crispinel and Alan M. Gundelfinger revived the Multicolor process under the company name Cinecolor. Cinecolor saw considerable use in animation and low-budget pictures, mainly because it cost much less than three-color Technicolor. If color design was carefully managed, the lack of colors such as true green could pass unnoticed. Although Cinecolor used the same duplitized stock as Prizma and Multicolor, it had the advantage that its printing and processing methods yielded larger quantities of finished film in less time.\nIn 1950, Kodak announced the first Eastman color 35\u00a0mm negative film (along with a complementary positive film) that could record all three primary colors on the same strip of film. An improved version in 1952 was quickly adopted by Hollywood, making the use of three-strip Technicolor cameras and bipack cameras (used in two-color systems such as Cinecolor) obsolete in color cinematography. This \"monopack\" structure is made up of three separate emulsion layers, one sensitive to red light, one to green and one to blue.\nSafety film.\nAlthough Eastman Kodak had first introduced acetate-based film, it was far too brittle and prone to shrinkage, so the dangerously flammable nitrate-based cellulose films were generally used for motion picture camera and print films. In 1949 Kodak began replacing all nitrocellulose (nitrate-based) films with the safer, more robust cellulose triacetate-based \"Safety\" films. In 1950 the Academy of Motion Picture Arts and Sciences awarded Kodak with a Scientific and Technical Academy Award (Oscar) for the safer triacetate stock. By 1952, all camera and projector films were triacetate-based. Most if not all film prints today are made from synthetic polyester safety base (which started replacing Triacetate film for prints in the early 1990s). The downside of polyester film is that it is extremely strong, and, in case of a fault, will stretch and not break\u2013potentially causing damage to the projector and ruining a fairly large stretch of film: 2\u20133\u00a0ft or approximately 2\u00a0seconds. Also, polyester film will melt if exposed to the projector lamp for too long. Original camera negative is still made on a triacetate base, and some intermediate films (certainly including internegatives or \"dupe\" negatives, but not necessarily including interpositives or \"master\" positives) are also made on a triacetate base as such films must be spliced during the \"negative assembly\" process, and the extant negative assembly process is solvent-based. Polyester films are not compatible with solvent-based assembly processes.\nOther types.\nBesides black &amp; white and color negative films, there are black &amp; white and color reversal films, which when developed create a positive (\"natural\") image that is projectable. There are also films sensitive to non-visible wavelengths of light, such as infrared.\nCommon formats.\nAcademy format.\nIn the conventional motion picture format, frames are four perforations tall, with an aspect ratio of 1.375:1, . This is a derivation of the aspect ratio and frame size designated by Thomas Edison () at the dawn of motion pictures, which was an aspect ratio of 1.33:1. The first sound features were released in 1926\u201327, and while Warner Bros. was using synchronized phonograph discs (sound-on-disc), Fox placed the soundtrack in an optical record directly on the film (sound-on-film) on a strip between the sprocket holes and the image frame. \"Sound-on-film\" was soon adopted by the other Hollywood studios, resulting in an almost square image ratio of 0.860\u00a0in by 0.820\u00a0in.\nBy 1929, most movie studios had revamped this format using their own house aperture plate size to try to recreate the older screen ratio of 1.33:1. Furthermore, every theater chain had their own house aperture plate size in which the picture was projected. These sizes often did not match up even between theaters and studios owned by the same company, and therefore, uneven projection practices occurred.\nIn November 1929, the Society of Motion Picture Engineers set a standard aperture ratio of 0.800\u00a0in by 0.600\u00a0in. Known as the \"1930 standard\", studios which followed the suggested practice of marking their camera viewfinders for this ratio were: Paramount-Famous-Lasky, Metro-Goldwyn Mayer, United Artists, Pathe, Universal, RKO, Tiffany-Stahl, Mack Sennett, Darmour, and Educational. The Fox Studio markings were the same width but allowed .04\u00a0in more height.\nIn 1932, in refining this ratio, the Academy of Motion Picture Arts and Sciences expanded upon this 1930 standard. The camera aperture became , and the projected image would use an aperture plate size of , yielding an aspect ratio of 1.375:1. This became known as the \"Academy\" ratio. Since the 1950s the aspect ratio of some theatrically released motion picture films has been 1.85:1 (1.66:1 in Europe) or 2.35:1 (2.40:1 after 1970). The image area for \"TV transmission\" is slightly smaller than the full \"Academy\" ratio at , an aspect ratio of 1.33:1. Hence when the \"Academy\" ratio is referred to as having an aspect ratio of 1.33:1, it is done so mistakenly.\nWidescreen.\nThe commonly used anamorphic format uses a similar four-perf frame, but an anamorphic lens is used on the camera and projector to produce a wider image, today with an aspect ratio of about 2.39:1 (more commonly referred to as 2.40:1). The ratio was formerly 2.35:1\u2014and is still often mistakenly referred to as such\u2014until an SMPTE revision of projection standards in 1970. The image, as recorded on the negative and print, is horizontally compressed (squeezed) by a factor of 2.\nThe unexpected success of the Cinerama widescreen process in 1952 led to a boom in film format innovations to compete with the growing audiences of television and the dwindling audiences in movie theaters. These processes could give theatergoers an experience that television could not at that time\u2014color, stereophonic sound and panoramic vision. Before the end of the year, 20th Century Fox had narrowly \"won\" a race to obtain an anamorphic optical system invented by Henri Chr\u00e9tien, and soon began promoting the Cinemascope technology as early as the production phase.\nLooking for a similar alternative, other major studios hit upon a simpler, less expensive solution by April 1953: the camera and projector used conventional spherical lenses (rather than much more expensive anamorphic lenses), but by using a removable aperture plate in the film projector gate, the top and bottom of the frame could be cropped to create a wider aspect ratio. Paramount Pictures began this trend with their aspect ratio of 1.66:1, first used in \"Shane\", which was originally shot for Academy ratio. It was Universal Studios, however, with their May release of \"Thunder Bay\" that introduced the now standard 1.85:1 format to American audiences and brought attention to the industry the capability and low cost of equipping theaters for this transition.\nOther studios followed suit with aspect ratios of 1.75:1 up to 2:1. For a time, these various ratios were used by different studios in different productions, but by 1956, the aspect ratio of 1.85:1 became the \"standard\" US format. These \"flat\" films are photographed with the full Academy frame, but are matted (most often with a mask in the theater projector, not in the camera) to obtain the \"wide\" aspect ratio. The standard, in some European countries, became 1.66:1 instead of 1.85:1, although some productions with pre-determined American distributors composed for the latter to appeal to US markets.\nIn September 1953, 20th Century Fox debuted CinemaScope with their production of \"The Robe\" to great success. CinemaScope became the first marketable usage of an anamorphic widescreen process and became the basis for a host of \"formats\", usually suffixed with \"-scope,\" that were otherwise identical in specification, although sometimes inferior in optical quality. (Some developments, such as SuperScope and Techniscope, however, were truly entirely different formats.) By the early 1960s, however, Panavision would eventually solve many of the CinemaScope lenses' technical limitations with their own lenses, and by 1967, CinemaScope was replaced by Panavision and other third-party manufacturers.\nThe 1950s and 1960s saw many other novel processes using 35\u00a0mm, such as VistaVision, SuperScope, and Technirama, most of which ultimately became obsolete. VistaVision, however, would be revived decades later by Lucasfilm and other studios for special effects work, while a SuperScope variant became the predecessor to the modern Super 35 format that is popular today.\nSuper 35.\nThe concept behind Super 35 originated with the Tushinsky Brothers' SuperScope format, particularly the SuperScope 235 specification from 1956. In 1982, Joe Dunton revived the format for \"Dance Craze\", and Technicolor soon marketed it under the name \"Super Techniscope\" before the industry settled on the name Super 35. The central driving idea behind the process is to return to shooting in the original silent \"Edison\" 1.33:1 full 4-perf negative area (), and then crop the frame either from the bottom or the center (like 1.85:1) to create a 2.40:1 aspect ratio (matching that of anamorphic lenses) with an area of . Although this cropping may seem extreme, by expanding the negative area out perf-to-perf, Super 35 creates a 2.40:1 aspect ratio with an overall negative area of , only less than the 1.85:1 crop of the Academy frame (). The cropped frame is then converted at the intermediate stage to a 4-perf anamorphically squeezed print compatible with the anamorphic projection standard. This allows an \"anamorphic\" frame to be captured with non-anamorphic lenses, which are much more common. \nUntil the year 2000, once the film was photographed in Super 35, an optical printer was used to anamorphose (squeeze) the image. This optical step reduced the overall quality of the image and made Super 35 a controversial subject among cinematographers, many who preferred the higher image quality and frame negative area of anamorphic photography (especially with regard to granularity). With the advent of digital intermediates (DI) at the beginning of the 21st century, however, Super 35 photography has become even more popular, since everything could be done digitally, scanning the original 4-perf 1.33:1 (or 3-perf 1.78:1) picture and cropping it to the 2.39:1 frame already in-computer, without anamorphosing stages, and also without creating an additional optical generation with increased grain. This process of creating the aspect ratio in the computer allows the studios to perform all post-production and editing of the movie in its original aspect (1.33:1 or 1.78:1) and to then release the cropped version, while still having the original when necessary (for Pan &amp; Scan, HDTV transmission, etc.).\n3-perf.\nThe non-anamorphic widescreen ratios (most commonly 1.85:1) used in modern feature films makes inefficient use of the available image area on 35\u00a0mm film using the standard 4-perf pulldown; the height of a 1.85:1 frame occupying only 65% of the distance between the frames. It is clear, therefore, that a change to a 3-perf pulldown would allow for a 25% reduction in film consumption whilst still accommodating the full 1.85:1 frame. Ever since the introduction of these widescreen formats in the 1950s various film directors and cinematographers have argued in favour of the industry making such a change. The Canadian cinematographer Miklos Lente invented and patented a three-perforation pull down system which he called \"Trilent 35\" in 1975 though he was unable to persuade the industry to adopt it.\nThe idea was later taken up by the Swedish film-maker Rune Ericson who was a strong advocate for the 3-perf system. Ericson shot his 51st feature \"Pirates of the Lake\" in 1986 using two Panaflex cameras modified to 3-perf pulldown and suggested that the industry could change over completely over the course of ten-years. However, the movie industry did not make the change mainly because it would have required the modification of the thousands of existing 35\u00a0mm projectors in movie theaters all over the world. Whilst it would have been possible to shoot in 3-perf and then convert to standard 4-perf for release prints the extra complications this would cause and the additional optical printing stage required made this an unattractive option at the time for most film makers.\nHowever, in television production, where compatibility with an installed base of 35\u00a0mm film projectors is unnecessary, the 3-perf format is sometimes used, giving\u2014if used with Super 35\u2014the 16:9 ratio used by HDTV and reducing film usage by 25 percent. Because of 3-perf's incompatibility with standard 4-perf equipment, it can utilize the whole negative area between the perforations (Super 35) without worrying about compatibility with existing equipment; the Super 35 image area includes what would be the soundtrack area in a standard print. All 3-perf negatives require optical or digital conversion to standard 4-perf if a film print is desired, though 3-perf can easily be transferred to video with little to no difficulty by modern telecine or film scanners. With digital intermediate now a standard process for feature film post-production, 3-perf is becoming increasingly popular for feature film productions which would otherwise be averse to an optical conversion stage.\nVistaVision.\nThe VistaVision motion picture format was created in 1954 by Paramount Pictures to create a finer-grained negative and print for flat widescreen films. Similar to still photography, the format uses a camera running 35\u00a0mm film horizontally instead of vertically through the camera, with frames that are eight perforations long, resulting in a wider aspect ratio of 1.5:1 and greater detail, as more of the negative area is used per frame. This format is unprojectable in standard theaters and requires an optical step to reduce the image into the standard 4-perf vertical 35\u00a0mm frame.\nWhile the format was dormant by the early 1960s, the camera system was revived for visual effects by John Dykstra at Industrial Light and Magic, starting with \"Star Wars\", as a way of reducing granularity in the optical printer by having increased original camera negative area at the point of image origination. Its usage has again declined since the dominance of computer-based visual effects, although it still sees limited utilization.\nPerforations.\nBH perforations.\nFilm perforations were originally round holes cut into the side of the film, but as these perforations were subject to wear and deformation, the shape was changed to what is now called the Bell &amp; Howell (BH) perforation, which has straight top and bottom edges and outward curving sides. The BH perforation's dimensions are from the middle of the side curve to opposite top corner by in height. The BH1866 perforation, or BH perforation with a pitch of , is the modern standard for negative and internegative films.\nKS perforations.\nBecause BH has sharp corners, the repeated use of the film through intermittent movement projectors creates strain that can easily tear the perforations. Furthermore, they tended to shrink as the print slowly decayed. Therefore, larger perforations with a rectangular base and rounded corners were introduced by Kodak in 1924 to improve steadiness, registration, durability, and longevity. Known as \"Kodak Standard\" (KS), they are high by wide. Their durability makes KS perfs the ideal choice for some (but not all) intermediate and all release prints, and original camera negatives which require special use, such as high-speed filming, but not for bluescreen, front projection, rear projection, or matte work as these specific applications demand the more accurate registration which is only possible with BH or DH perforations. The increased height also means that the image registration was considerably less accurate than BH perfs, which remains the standard for negatives. The KS1870 perforation, or KS perforation with a pitch of , is the modern standard for release prints.\nThese two perforations have remained by far the most commonly used ones. BH perforations are also known as \"N\" (negative) and KS as \"P\" (positive). The Bell &amp; Howell perf remains the standard for camera negative films because of its perforation dimensions in comparison to most printers, thus it can keep a steady image compared to other perforations.\nDH perforations.\nThe Dubray\u2013Howell (DH) perforation was first proposed in 1932 to replace the two perfs with a single hybrid. The proposed standard was, like KS, rectangular with rounded corners and a width of , and, like BH, was tall. This gave it longer projection life but also improved registration. One of its primary applications was usage in Technicolor's dye imbibition printing (dye transfer). The DH perf never had broad uptake, and Kodak's introduction of monopack Eastmancolor film in the 1950s reduced the demand for dye transfer, although the DH perforation persists in special application intermediate films.\nCS perforations.\nIn 1953, the introduction of CinemaScope by Fox Studios required the creation of a different shape of perforation which was nearly square and smaller to provide space for four magnetic sound stripes for stereophonic and surround sound. These perforations are commonly referred to as CinemaScope (CS) or \"Fox hole\" perfs. Their dimensions are in width by in height. Due to the size difference, CS perfed film cannot be run through a projector with standard KS sprocket teeth, but KS prints \"can\" be run on sprockets with CS teeth. Shrunken film with KS prints that would normally be damaged in a projector with KS sprockets may sometimes be run far more gently through a projector with CS sprockets because of the smaller size of the teeth. Magnetic striped 35\u00a0mm film became obsolete in the 1980s after the advent of Dolby Stereo, as a result film with CS perfs is no longer manufactured.\nDuring continuous contact printing, the raw stock and the negative are placed next to one another around the sprocket wheel of the printer. The negative, which is the closer of the two to the sprocket wheel (thus creating a slightly shorter path), must have a marginally shorter pitch between perforations (0.1866\u00a0in pitch); the raw stock has a long pitch (0.1870\u00a0in). While cellulose nitrate and cellulose diacetate stocks used to shrink during processing slightly enough to have this difference naturally occur, modern safety stocks do not shrink at the same rate, and therefore negative (and some intermediate) stocks are perforated at a pitch of 0.2% shorter than print stock.\nTechnical specifications.\nTechnical specifications for 35\u00a0mm film are standardized by SMPTE.\n35\u00a0mm spherical\nSuper 35\u00a0mm film\n35\u00a0mm anamorphic\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46204", "revid": "33438184", "url": "https://en.wikipedia.org/wiki?curid=46204", "title": "Prince of Wales", "text": "British royal title (formerly a native Welsh title)\nPrince of Wales is a title traditionally given to the male heir apparent to the English, and later, the British throne. The title originated with the Welsh rulers of Gwynedd who, from the late 12th century, used it (albeit inconsistently) to assert their supremacy over the other Welsh rulers. However, to mark the finalisation of his conquest of Wales, in 1301, Edward I of England invested his son Edward of Caernarfon with the title, thereby beginning the tradition of giving the title to the heir apparent when he was the monarch's son or grandson. The title was later claimed by the leader of a Welsh rebellion, Owain Glynd\u0175r, from 1400 until 1415.\nKing Charles III created his son, William, Prince of Wales on 9 September 2022, the day after his accession to the throne, with formal letters patent issued on 13 February 2023. The title has become a point of controversy in Wales. \nWelsh princes of Wales.\nOrigins to 1283.\nThe first known use of the title \"Prince of Wales\" was in the 1160s by Owain Gwynedd, ruler of Kingdom of Gwynedd, in a letter to Louis VII of France. In the 12th century, Wales was a patchwork of Anglo-Norman Lordships and native Welsh kingdoms \u2013 notably Deheubarth, Powys and Gwynedd \u2013 competing among themselves for hegemony. As he was already the King of Gwynedd, Owain's aim in using the title in his letter to Louis was probably to claim pre-eminence over the other native Welsh rulers. \nAt the time, the word \"prince\", deriving as it did from the Latin , meant \"first person, chief leader; ruler, sovereign.\" It was not until the 14th century that it came to mean \"heir to the throne\".\nFollowing Owain's death in 1170 no other ruler, with the exception of Rhys ap Gruffydd of Deheubarth, is known to have adopted the title until 1245. Rhys used several titles, sometimes concurrently, and in two charters from the 1180s he is referred to as \"Prince of Wales\" or \"Prince of the Welsh\".\nThe title was revived in 1245 when Dafydd ap Llywelyn, ruler of Gwynedd, began using it in the final months of his reign. In the intervening years, Owen Gwynedd's successors in Gwynedd, including Dafydd, had, instead, adopted the titles \"Prince of North Wales\" or \"Prince of Aberffraw and Lord of Snowdon\".\nHowever, it is in the reign of Llywelyn ap Gruffudd, Dafydd's nephew and successor in Gwynedd, that the title is consistently used over an extended period. From 1262 to his death in 1282, Llywelyn used no other style except 'Prince of Wales and Lord of Snowdon'. This was accompanied by Llywelyn making the Principality of Wales (encompassing Gwynedd, Deheubarth, Powys and parts of the Marches) a political reality. He had achieved this by significantly expanding his directly ruled territories into Mid- and South Wales and inducing all the other remaining native Welsh rulers to do him homage and acknowledge him as overlord by 1263. Additionally, Llywelyn developed governance structures which made his authority effective across the entire Principality of Wales, including in the territories of the Welsh rulers that owed him allegiance. The significance of these developments was marked by Henry III of England recognising Llywelyn's title and authority in the Treaty of Montgomery of 1267. As J. Beverley Smith has noted, his title \"at once, acknowledged and proclaimed a status unique in Welsh political history\".\nLlywelyn's principality was destroyed as a result of the conquest of Wales by Edward I between 1277 and 1283, during which Llywelyn was killed in 1282. After his death, his brother, Dafydd, adopted Llywelyn's title and continued resistance for a few months. However, Dafydd was defeated and executed in 1283 and the principality was permanently annexed by Edward I.\nPost-conquest claimants.\nIn the fourteenth century, two pretenders to the title of 'Prince of Wales' attempted to make good their claims: Owain Lawgoch, a descendant of the Princes of Gwynedd, and Owain Glynd\u0175r, whose ancestors included the former rulers of Powys and Deheubarth. Owain Lawgoch's abortive attempt at invading Wales in 1372 was followed by Glynd\u0175r's much more serious revolt beginning in 1400.\nGlynd\u0175r's rebellion commenced with his supporters proclaiming him Prince of Wales. However, it is unclear how important this was in his initial objectives, given that his immediate motivation appears to have been a personal grievance with a neighbouring English Lord. By 1401, he had effectively dropped his claim to the title. But, with the rebellion's military successes of 1402\u20131403 and the growth in his support in Wales, he became more ambitious. In 1404, he had himself crowned as Prince of Wales, and he launched plans to create the state institutions of a new principality. This phase of the revolt was short-lived, however. By 1406, the rebellion began to fail militarily, and, from 1409, Glynd\u0175r had to exchange the trappings of a ruling prince for those of a hunted outlaw. He died in obscurity, probably around 1415.\nHeirs apparent to the English or British thrones.\nTitles and roles.\nThe title is neither automatic nor heritable; it merges with the Crown when its holder eventually accedes to the throne, or reverts to the Crown if its holder predeceases the current monarch, leaving the sovereign free to grant it to the new heir apparent (such as the late prince's son or brother).\nThe Prince of Wales usually has other titles and honours, if the eldest son of the monarch:\nNo formal public role or responsibility has been legislated by Parliament or otherwise delegated to the prince of Wales by law or custom. In that role, Charles often assisted Elizabeth II in the performance of her duties. He represented her when welcoming dignitaries to London and during state visits. He also represented the Queen and the United Kingdom overseas at state and ceremonial occasions such as funerals. The Prince of Wales has also been granted the authority to issue royal warrants.\nIn 2011, along with the other Commonwealth realms, the United Kingdom committed to the Perth Agreement, which proposed changes to the laws governing succession, including altering the male-preference primogeniture to absolute primogeniture. The Succession to the Crown Act 2013 was introduced to the British parliament on 12 December 2012, published the next day, and received royal assent on 25 April 2013. It was brought into force on 26 March 2015, at the same time as the other realms implemented the Perth Agreement in their own laws.\nInsignia.\nThe Prince of Wales's feathers are the badge of the Prince of Wales by virtue of being the heir apparent. The ostrich feathers are generally traced back to Edward of Woodstock ('The Black Prince'). He bore (as an alternative to his differenced royal arms) a shield of \"Sable, three ostrich feathers argent\", described as his \"shield for peace\", probably meaning the shield he used for jousting. These arms appear several times on his chest tomb in Canterbury Cathedral, alternating with his paternal royal arms (the royal arms of King Edward III differenced by \"a label of three points argent\"). The Black Prince also used heraldic badges of one or more ostrich feathers in various other contexts.\nSelected events and anomalies.\nFirst English Prince of Wales.\nIn order to finalise his conquest of Wales, Edward I began the custom of granting the title of Prince of Wales to the heir apparent to the English throne. Consequently, in 1301, Edward invested his Welsh-born eldest son, Edward of Caernarfon, as the first Plantagenet Prince of Wales.\nWriting in \"Britannia\", William Camden describes the killing of Llywelyn and Edward's use of the title \"Prince of Wales\" for his son:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;As concerning the Princes of Wales of British bloud in ancient times, you may reade in the Historie of Wales published in print. For my part I thinke it requisite and pertinent to my intended purpose to set downe summarily those of latter daies, descended from the roiall line of England. King Edward the First, unto whom his father King Henrie the Third had granted the Principalitie of Wales, when hee had obtained the Crowne and Lhewellin Ap Gryffith, the last Prince of the British race, was slain, and therby the sinewes as it were of the principalitie were cut, in the twelft yeere of his reigne united the same unto the Kingdome of England. And the whole province sware fealty and alleageance unto Edward of Caernarvon his sonne, whom hee made Prince of Wales. But King Edward the Second conferred not upon his sonne Edward the title of Prince of Wales, but onely the name of Earle of Chester and of Flint, so farre as ever I could learne out of the Records, and by that title summoned him to Parliament, being then nine yeres old. King Edward the Third first created his eldest sonne Edward surnamed the Blacke Prince, the Mirour of Chivalrie (being then Duke of Cornwall and Earle of Chester), Prince of Wales by solemne investure, with a cap of estate and Coronet set on his head, a gold ring put upon his finger, and a silver vierge delivered into his hand, with the assent of Parliament.\u2014\u200a\nBrothers.\nIn 1504, Henry Tudor (the future Henry VIII) was given the title after the death of his older brother Arthur (in 1502), who predeceased his father, King Henry VII.\nThe same occurred in 1616, when Henry Frederick Stuart predeceased (in 1612) his father James I; Henry's brother Charles Stuart, later Charles I, was given the title.\n1911 investiture of Prince Edward.\nEdward (then the heir apparent; later King Edward VIII) was invested as Prince of Wales at Caernarfon Castle in July 1911. This was the first such public investiture for centuries. He had been created Prince of Wales in June 1910.\nOn arrival, Edward addressed the crowd briefly in Welsh: \"\" (\"All Wales is a sea of song\"). The king presented Edward with the insignia of his office. After the ceremony the royal party rejoined the royal yacht. It was said that the ceremonial was partly \"invented tradition\".\n1969 investiture of Prince Charles.\nAlthough the investiture of Charles as Prince of Wales in 1969 took place during a period of social change and a growing Welsh nationalist movement, it was largely welcomed by people in Wales. The investiture was also attended, by invitation, by 3,500 people who lived and worked in Wales. In the UK, the press focused on the pomp and regalia, with newspaper headlines such as \"Welsh go wild for Their Royal Prince\" and \"Proud Wales takes Prince to her heart.\" It was also supported by the Secretary of State for Wales at the time, George Thomas, although he remained a controversial figure in Wales. Thomas later said to Prime Minister Harold Wilson that Charles's speech had \"boosted Welsh nationalism.\"\nThe 1960s movement surrounding the investiture has historically been described as the \"anti-investiture movement\" and \"anti-investiture sentiment\". The investiture occurred during a period of revival of the Welsh national consciousness, with an outspoken section considering him as an English Prince being imposed upon Wales. The investiture also led to significant protests in Wales. The group \"Cofia 1282\" (\"Remember 1282\") also held protests against the investiture.\nWilliam as Prince of Wales.\nOn 9 September 2022 (the day after his accession to the throne), during his first address as king, Charles III said of his son William, \"Today I am proud to create him Prince of Wales, Tywysog Cymru. The country whose title I've been so greatly privileged to bear during so much of my life of duty.\" Buckingham Palace stated that \"The Prince and Princess [of Wales] look forward to celebrating Wales's proud history and traditions as well as a future that is full of promise\". The First Minister of Wales, Mark Drakeford, noted that \"William will be absolutely aware of the sensitivities that surround the title...\"\nThough the title started to be used immediately afterward, it was only documented formally by letters patent on 13 February 2023.\nContemporary debate.\nTitle.\nCharles III proclaimed William as Prince of Wales on 9 September 2022, the day after the death of Elizabeth II, surprising Mark Drakeford, First Minister of Wales, who said he had not been given notice of the announcement. The creation of a new Prince of Wales was the catalyst for a renewed debate on the title, and already, on 8 September, a petition had been started calling for the title to be ended. The petition had garnered 25,000 signatures in its first few days.\nFormer Welsh Assembly presiding officer Lord Elis-Thomas had also questioned the need for the title to continue, and recalled previous discussion with the then Prince Charles, who expressed his desire never again to have an investiture in Caernarfon Castle. According to Elis-Thomas, Charles laughed and said, \"Do you think I want to put William through what I went through?\"\nThe decision to grant William the title of Prince of Wales was criticised by the Welsh nationalist party Plaid Cymru Senedd member Cefin Campbell called the decision \"divisive\" and party leader Adam Price called for a public debate on the issue.\nThe question raised by critics was one of respect for Wales as a country in its own right, and the continued symbol of the historical invasion and oppression of Wales. William pledged that he would serve Wales with humility and great respect for its people, and spoke of the honour he felt to do so. He signalled a desire to reform the role.\nThe contemporary debate does not focus wholly on abolition, but explores how, if the title is to continue, it may be adapted to reflect the realities of the changing constitutional relationship with Wales. This includes the question of whether the Welsh Government should play a greater role in the appointment process, or whether there should be a Senedd ceremonial process to reflect the nation's governance over its own affairs.\nOpinion polls.\nA BBC Wales poll in 1999 showed that 73% of Welsh speakers believed the title should continue after Charles. A BBC poll in 2009, 40 years following the investiture, revealed 58% of Welsh people support the title \"Prince of Wales\"; 26% opposed the title. However, only 16% responded that Wales had benefited from having a prince.\nIn July 2018, an ITV poll found that 57% of Welsh people supported the title passing to William, with 22% for abolition or vacating the title. Support for another investiture was lower, with 31% supporting a ceremony similar to the 1969 one, 18% supporting a ceremony different to 1969, and 27% opposing an investiture.\nIn 2019, a BBC Wales poll showed that 50% supported the continuation of the title and 22% opposed. On the investiture, 41% supported a similar ceremony to 1969, 20% a different-style investiture ceremony, and 30% opposed any future investiture. A 2021 poll by Beaufort Research for Western Mail showed 61% of respondents in Wales supported another investiture, including 60% of Welsh-speakers polled.\nIn June 2022, an ITV/YouGov poll showed that 46% of adults in Wales wanted the Prince of Wales title to continue, and 31% said it should be abolished. In September 2022, a YouGov poll showed 66% support for Prince William to be given the title compared to 22% opposed, with 19% supporting a 1969-style investiture, 30% a different style of investiture and 34% opposing any investiture of Prince William as Prince of Wales.\nList of princes of Wales (English or British heirs apparent).\nThe current sovereign Charles III was the longest serving Prince of Wales for 64 years and 44 days between 1958 and 2022, and the oldest person to hold the position. He was also heir apparent for longer than any other in British history. Upon the death of his mother on 8 September 2022, Charles became king and the title merged with the Crown. The following day, King Charles III bestowed the title upon his elder son, Prince William, Duke of Cornwall and Cambridge. Prince William is the oldest person to be created Prince of Wales.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46205", "revid": "6518807", "url": "https://en.wikipedia.org/wiki?curid=46205", "title": "Whitefish (fisheries term)", "text": "Several species of demersal fish with fins\nWhitefish or white fish is a fisheries term for several species of demersal fish with fins, particularly Atlantic cod (\"Gadus morhua\"), whiting (\"Merluccius bilinearis\"), haddock (\"Melanogrammus aeglefinus\"), hake (\"Urophycis\"), and pollock (\"Pollachius\"), among others.\nWhitefish live on or near the seafloor, and can be contrasted with the oily or blue fish (also known as fatty fish), including pelagic fish, which live away from the seafloor. Whitefish do not have much oil in their tissue, and have flakier white or light-coloured flesh. Most of the oil found in their bodies is concentrated in the organs, e.g. cod liver oil.\nWhitefish can be divided into benthopelagic fish (round fish that live \"near\" the sea bed, such as cod and coley) and benthic fish (which live \"on\" the sea bed, such as flatfish like plaice).\nWhitefish is sometimes eaten straight but is often used reconstituted for fishsticks, gefilte fish, lutefisk, surimi (imitation crab meat), etc. Because of their lower oil and fat content, whitefish are particularly suitable for preservation by salting and drying. For centuries it was preserved by drying as stockfish and clipfish and traded as a world commodity. It is commonly used as the fish in the classic British dish of fish and chips.\nGrowth.\nThe growth amidst whitefish species can be altered due to intraspecific competition. Fish populations such as Vendace and Roach share zooplankton for food which is crucial for young populations of whitefish. As this competition occurs, growth rate can be affected within multiple age groups or at an older age.\nNutritional information.\nOne fillet of whitefish, mixed species (198g) contains the following nutritional information according to the United States Department of Agriculture:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46206", "revid": "10854501", "url": "https://en.wikipedia.org/wiki?curid=46206", "title": "Clairvaux Abbey", "text": "Former Cistercian monastery in Aube, France\nClairvaux Abbey (, \"l\u2019abbaye de Clairvaux\"; ) was a Cistercian monastery in Ville-sous-la-Fert\u00e9, from Bar-sur-Aube. The abbey was founded in 1115 by Bernard of Clairvaux. As a primary abbey, it was one of the most significant monasteries in the order. Dissolved during the French Revolution, it was used from 1808 to 2023 as Clairvaux Prison, a high-security correctional facility. As of 2024, the site was being converted to a tourist destination.\nIts layout was significantly altered by construction in the 18th and 19th centuries. Before it was a prison, Clairvaux Abbey served as an archetype for Cistercian monasteries; significant portions of the ancient abbey remain standing.\nHistory.\nFounding to dissolution.\nAccording to legend, on 25 June 1115 the Cistercian monk Bernard was sent from C\u00eeteaux Abbey with a group of twelve other monks to found a new monastery at Vall\u00e9e d'Absinthe. Hughes I, Count of Troyes and a relative of Bernard, donated this valley to the Cistercians. The monastery was dedicated to the Virgin Mary on October 13, 1115, which became the feast day of Our Lady of Clairvaux. Bernard was installed as first abbot by William of Champeaux, Bishop of Ch\u00e2lons-sur-Marne.\nThe abbey developed rapidly, eventually reaching its peak in numbers at 700 members belonging to Clairvaux alone, thus the largest Cistercian abbey in France. Many daughter monasteries followed. In 1118 Trois-Fontaines Abbey was founded from Clairvaux on land donated by Hugh de Vitry. Many nobles were buried there. Later, Clairvaux founded Foigny Abbey (1121), and Cherlieu Abbey was founded in 1131. During Bernard's lifetime over sixty monasteries were founded from Clairvaux all over Europe and reaching into Scandinavia. Many (\"over a third of them\") were pre-existing communities of monks, canons, or hermits who had decided to join the Cistercian movement.\nConstruction of the abbey in its roughly current form (named \"Clairvaux II\" by historians) began in 1135, and the abbey church was dedicated in 1174. However, the only building surviving from this time is a large 12th-century lay brother's building, eventually converted into a barn. By the end of the middle ages, it had founded 530 abbeys across Europe. As the mother of so many, Clairvaux occupied a central place in the Cistercian world. \nClairvaux continued to attract promising monks; one of them became a pope (Eugene III), twelve became cardinals, and over thirty were elevated to the episcopacy. The manuscripts copied and written at Clairvaux were of great importance. Research about the monks' literary and theological studies have led to a research project that seeks to reconstruct the abbey's medieval library. In the 13th century, Clairvaux Abbot Stephen Lexington founded the Cistercian college at the University of Paris and it remained under the abbey's responsibility for generations.\nIn the early modern period, Clairvaux was the nucleus of the movement toward stricter observance, particularly under Abbot Denis Largentier in the 16th and 17th centuries. Starting in 1708, comprehensive reconstruction of the abbey's buildings in the classical style began, dubbed \"Clairvaux III\" by historians. The works were wide-ranging, and records indicate that construction was not complete upon the arrival of the revolution.\nClairvaux's library was of particular note, it expanded continuously through the middle ages and early modern period. At the time of its dissolution, it housed 40,000 volumes. Its collection of medieval manuscripts inventoried by Abbot Pierre de Virey, of which 1,115 of 1,790 survive, constitutes the largest of its kind, and is exceptionally well-preserved. This collection is today housed in the Troyes-Champagne \"M\u00e9diath\u00e8que,\" the Biblioth\u00e8que nationale de France, and the University of Montpelier's Faculty of Medicine. \nRevolution to present day.\nAt the time of the French Revolution in 1789, Clairvaux had only 26 professed religious, counting the abbot, Louis-Marie Rocourt, ten lay brothers, and ten affiliated pensioners of the house; 19 of the religious and all the lay brothers were secularized. The relics of Bernard of Clairvaux were moved from the abbey church to Troyes Cathedral.\nHaving become state property according to the decree of 2 November 1789, the abbey was purchased in 1792 and converted into a glassworks, which was repossessed by the state upon its bankruptcy in 1804 and turned into a prison. This fate was not uncommon for former monasteries following the penal reforms of Napoleon, it also befell others like Fontevraud and Mont-Saint-Michel. Because the abbey church was sold off as a quarry in 1812, a small new chapel was built inside the former refectory in 1828. During the 19th century, the abbey held 2,700 prisoners, including 500 women and 550 children. Deplorable conditions at the abbey inspired Victor Hugo to write his short story \"Claude Gueux\", based on a real prisoner at Clairvaux, in 1834. Following a reform in 1875 that required individual cells for prisoners, \"chicken cages\", cells measuring 1.5 x 2-meter (5 x 6.5\u00a0ft), were installed, they remained in use until 1971. The abbey was in 1926 as a historical monument by the French Ministry of Culture, but only one of the buildings, the one for the lay brothers, is medieval in origin yet erected after Bernard had died.\nStarting in the 2000s, the prison was gradually dismantled. Comprehensive restorations began in 2013, and the prison was finally shut down in 2023. Renovation has been underway since.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n\u00a0This article incorporates text from a publication now in the public domain:\u00a0"}
{"id": "46208", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=46208", "title": "Dudley Moore", "text": "English actor, comedian and musician (1935\u20132002)\nDudley Stuart John Moore (19 April 1935\u00a0\u2013 27 March 2002) was an English actor, comedian, musician and composer. He first came to prominence in the UK as a leading figure in the British satire boom of the 1960s. He was one of the four writer-performers in the groundbreaking satirical comedy revue \"Beyond the Fringe\" from 1960 to 1964. With another member of that team, Peter Cook, Moore collaborated on the BBC television series \"Not Only... But Also\" from 1965 to 1970. In their popular double act, Moore's buffoonery contrasted with Cook's deadpan monologues. They jointly received the 1966 British Academy Television Award for Best Entertainment Performance and worked together on other projects, such as the hit film \"Bedazzled\" (1967) and the Derek and Clive series of comedy albums. Moore and Cook ceased working together regularly after 1978, by which time Moore had settled in Los Angeles, California to concentrate on his film career.\nFollowing \"Bedazzled\", Moore's work as a comedy film actor was marked by further hit films, particularly \"Foul Play\" (1978), \"10\" (1979) and \"Arthur\" (1981). For \"Arthur\", Moore was nominated for the Academy Award for Best Actor and won a Golden Globe Award. He received a second Golden Globe for his performance in \"Micki &amp; Maude\" (1984). Moore was awarded a star on the Hollywood Walk of Fame in 1987 and was made a CBE by Queen Elizabeth II at Buckingham Palace on 16 November 2001 in what was his last public appearance.\nEarly life and education.\nMoore was born at the original Charing Cross Hospital in central London, the son of Ada Francis (n\u00e9e Hughes), a secretary, and John Moore, a railway electrician from Glasgow.\nHe had an older sister, Barbara. Moore was brought up on the Becontree estate in Dagenham, Essex. He was short at and had club feet that required extensive hospital treatment. This made him the butt of jokes from other children. His right foot responded well to corrective treatment by the time he was six, but his left foot was permanently twisted and his left leg below the knee was withered. He remained self-conscious about this throughout his life.\nMoore became a chorister at the age of six. When he was 11 years old, he earned a scholarship to the Guildhall School of Music, where he took up harpsichord, organ, violin, musical theory and composition. He rapidly developed into a highly talented pianist and organist and was playing the organ at local church weddings by the age of 14. He attended Dagenham County High School, where he received dedicated musical tuition from Peter Cork (1926\u20132012), who helped him towards his Oxford music scholarship. (Norma Winstone was another student of Cork's at Dagenham). Cork was also a composer. Moore kept in touch until the mid-1990s and his letters to Cork were published in 2006.\nIn 1955 Moore won an organ scholarship to Magdalen College, Oxford, where he was tutored by the composer Bernard Rose and from where he graduated in 1958. While studying music and composition there, he also performed with Alan Bennett in The Oxford Revue. During his university years, Moore developed a love of jazz music and became an accomplished jazz pianist and composer. He began working with musicians such as John Dankworth and Cleo Laine. In 1960, Moore left Dankworth's band to work on \"Beyond the Fringe\".\nCareer.\nJazz pianist.\nOn leaving Oxford University in 1958 he joined Sir John Dankworth's big band on piano. Subsequently he made a number of recordings leading his own trio including Pete McGurk (later replaced by Jeff Clyne) on bass and Chris Karan on drums.\n\"Beyond the Fringe\".\nJohn Bassett, a graduate of Wadham College, Oxford recommended Moore, his jazz bandmate and a rising cabaret talent, to producer Robert Ponsonby, who was putting together a comedy revue entitled \"Beyond the Fringe\". Bassett also chose Jonathan Miller. Moore then recommended Alan Bennett, who in turn suggested Peter Cook.\n\"Beyond the Fringe\" was at the forefront of the 1960s UK satire boom, although the show's original runs in Edinburgh and the provinces in 1960 had had a lukewarm response. When the revue transferred to the Fortune Theatre in London, in a revised production by Donald Albery and William Donaldson, it became a sensation, thanks in some part to a favourable review by Kenneth Tynan. There were also a number of musical items in the show, using Dudley Moore's music, most famously an arrangement of the Colonel Bogey March in the style of Beethoven, which Moore appears unable to bring to an end.\nIn 1962 the show transferred to the John Golden Theatre in New York, with its original cast. President John F. Kennedy attended a performance on 10 February 1963. The show continued in New York until 1964.\nPartnership with Peter Cook.\nSir John Dankworth's trumpeter, Ron Simmonds, remembered the duo playing in the intervals of the band's saturday night residency at the Marquee Club in 1961. \nWhen Moore returned to the UK he was offered his own series on the BBC, \"Not Only... But Also\" (1965, 1966, 1970). It was commissioned specifically as a vehicle for Moore, but when he invited Peter Cook on as a guest, their comedy partnership was so notable that it became a permanent fixture of the series. Cook and Moore are most remembered for their sketches as two working-class men, Pete and Dud, in macs and cloth caps, commenting on politics and the arts, but they also fashioned a series of one-off characters, usually with Moore in the role of interviewer to one of Cook's upper-class eccentrics.\nThe pair developed an unorthodox method for scripting the material, using a tape recorder to tape an ad-libbed routine that they would then have transcribed and edited. This would not leave enough time to fully rehearse the script, so they often had a set of cue cards. Moore was famous for \"corpsing\" so, as the programmes often went out live, Cook would deliberately make him laugh to get an even bigger reaction from the studio audience. The BBC wiped much of the series, though some of the soundtracks (which were issued on LP record) have survived. In 1968 Cook and Moore briefly switched to ATV for four one-hour programmes entitled \"Goodbye Again\"; however, they were not as critically well-received as the BBC shows.\nOn film, Moore and Cook appeared in the 1966 British comedy film \"The Wrong Box\", before co-writing and co-starring in \"Bedazzled\" (1967) with Eleanor Bron. Set in Swinging London of the 1960s, \"Bedazzled\" was directed by Stanley Donen. The pair closed the decade with appearances in the ensemble caper film \"Monte Carlo or Bust\" and Richard Lester's \"The Bed Sitting Room\", based on the play by Spike Milligan and John Antrobus. In 1968 and 1969 Moore embarked on two solo comedy ventures, firstly in the film \"30 is a Dangerous Age, Cynthia\" and secondly, on stage, for an Anglicised adaptation of Woody Allen's \"Play It Again, Sam\" at the Globe Theatre in London's West End.\nIn the 1970s, the relationship between Moore and Cook became increasingly strained as the latter's alcoholism began affecting his work. In 1971, however, Cook and Moore took sketches from \"Not Only...But Also\" and \"Goodbye Again\", together with new material, to create the stage revue \"Behind the Fridge\". This show toured Australia and New Zealand in 1971 and ran in London's west end between 1972 and 1973 before transferring to New York City in 1973, re-titled \"Good Evening\". Cook frequently appeared inebriated, on and off stage. Nonetheless, the show proved very popular and it won Tony and Grammy Awards.\nWhen the Broadway run of \"Good Evening\" ended, Moore stayed on in the U.S. to pursue his film acting ambitions in Hollywood, but the pair reunited to host \"Saturday Night Live\" on 24 January 1976 during SNL's first season. They performed a number of their classic stage routines, including \"One Leg Too Few\" and \"Frog and Peach\", among others, in addition to participating in some skits with the show's ensemble.\nIt was during the Broadway run of \"Good Evening\" that Cook persuaded Moore to take the humour of Pete and Dud further on long-playing records as Derek and Clive. Chris Blackwell circulated bootleg copies to friends in the music business and the popularity of the recording convinced Cook to release it commercially as \"Derek and Clive (Live)\" (1976). Two further \"Derek and Clive\" albums, \"Derek and Clive Come Again\" (1977) and \"Derek and Clive Ad Nauseam\" (1978), were later released. The latter was also filmed for a documentary, \"Derek and Clive Get the Horn\". In the film it is clear tensions between the two men were at a breaking point, with Moore at one point walking out of the recording room singing, 'Breaking up is so easy to do.' In 2009, it came to light that, at the time, there were attempts to have them prosecuted under obscenity laws for their \"Derek and Clive\" comedy recordings.\nThe last significant appearance for the partnership was in 1978's \"The Hound of the Baskervilles\", where Moore played Dr. Watson to Cook's Sherlock Holmes, as well as three other roles: in drag; as a one-legged man; and at the start and end of the film as a flamboyant and mischievous pianist. He also wrote the film's score. Co-star Terry-Thomas described it as \"the most outrageous film I ever appeared in\u00a0... there was no magic\u00a0... it was bad!\". The film was not a success, either critically or financially.\nMoore and Cook eventually reunited for the annual American benefit for the homeless, \"Comic Relief\", in 1987, and again in 1989 for a British audience at the Amnesty International benefit \"The Secret Policeman's Biggest Ball\".\nMoore was deeply affected by the death of Cook in 1995, and for weeks would regularly telephone Cook's home in London, just to hear his friend's voice on the telephone answering machine. Moore attended Cook's memorial service in London and, at the time, many people who knew him noted that Moore was behaving strangely and attributed it to grief or drinking. In November 1995, Moore teamed up with friend and humorist Martin Lewis in organising a two-day salute to Cook in Los Angeles that Moore co-hosted with Lewis.\nIn December 2004 the Channel 4 television station in the United Kingdom broadcast \"Not Only But Always\", a TV film dramatising the relationship between Moore and Cook, although most of the attention of the production was directed towards Cook. Around the same time, the relationship between the two was also the subject of a stage play called \"\" by Chris Bartlett and Nick Awde. For this production Moore is the main subject. Set in a chat-show studio in the 1980s, it concerns Moore's comic and personal relationship with Cook and the directions their careers took after the split of the partnership.\nMusic.\nDuring the 1960s Moore formed the Dudley Moore Trio, with drummer Chris Karan and bassist Pete McGurk. Following McGurk's suicide in June 1968, Peter Morgan joined the group as his replacement.\nMoore's admitted principal musical influences were Oscar Peterson and Erroll Garner. In an interview he recalled the day he finally mastered Garner's unique left-hand strum and was so excited that he walked around for several days with his left hand constantly playing that cadence. His early recordings included \"My Blue Heaven\", \"Lysie Does It\", \"Poova Nova\", \"Take Your Time\", \"Indiana\", \"Sooz Blooz\", \"Baubles, Bangles &amp; Beads\", \"Sad One for George\" and \"Autumn Leaves\". The trio performed regularly on British television, made numerous recordings and had a long-running residency at Peter Cook's London nightclub, the Establishment. Among other albums, they recorded \"The Dudley Moore Trio\", \"Dudley Moore plays The Theme from Beyond the Fringe and All That Jazz\", \"The World of Dudley Moore\", \"The Other Side Of Dudley Moore\" and \"Genuine Dud\".\nMoore was a close friend of record producer Chris Gunning and played piano (uncredited) on the 1969 single \"Broken Hearted Pirates\" which Gunning produced for Simon Dupree and the Big Sound. In 1976 he played piano on Larry Norman's album \"In Another Land\", in particular on the song \"The Sun Began to Rain\". In 1981 he recorded \"Smilin' Through\" with Cleo Laine.\nHe composed the soundtracks for the films \"Bedazzled\" (1967), \"30 is a Dangerous Age, Cynthia\" (1968), \"Inadmissible Evidence\" (1968), \"Staircase\" (1969), \"The Hound of the Baskervilles\" (1978) and \"Six Weeks\" (1982), among others.\nLater career in film, television and music.\nIn the late 1970s Moore moved to Hollywood, where he had a supporting role in the hit film \"Foul Play\" (1978) with Goldie Hawn and Chevy Chase. The following year saw his break-out role in Blake Edwards's \"10\", which became one of the biggest box-office hits of 1979 and gave him an unprecedented status as a romantic leading man. Moore followed up with the comedy film \"Wholly Moses!\", which was not a major success.\nIn 1981 Moore appeared in the title role of the comedy \"Arthur\", an even bigger hit than \"10\". Co-starring Liza Minnelli and Sir John Gielgud, it was both commercially and critically successful, Moore receiving an Oscar nomination for Best Actor, while Gielgud won the Best Supporting Actor Oscar for his role as Arthur's stern but compassionate manservant. Moore lost to Henry Fonda (for \"On Golden Pond\"). He did, however, win a Golden Globe award for Best Actor in a Musical/Comedy. In the same year, on British television, Moore was the featured guest subject on \"An Audience With...\".\nHis subsequent films, \"Six Weeks\" (1982), \"Lovesick\" (1983), \"Romantic Comedy\" (1983) and \"Unfaithfully Yours\" (1984) were only moderate successes. He won another Golden Globe for Best Actor in a Musical/Comedy in 1984, starring in the Blake Edwards directed \"Micki &amp; Maude\", co-starring Amy Irving.\nLater films, including \"Best Defense\" (1984), ' (1985), \"Like Father Like Son\" (1987), ' (1988), a sequel to the original, \"Crazy People\" (1990), \"Blame It on the Bellboy\" (1992) and an animated adaptation of \"King Kong\", were inconsistent in terms of both critical and commercial reception. Moore eventually disowned the \"Arthur\" sequel, but, in later years, Cook would tease him by claiming he preferred \"Arthur 2: On the Rocks\" to \"Arthur\".\nIn 1986 he once again hosted \"Saturday Night Live\", albeit without Peter Cook this time.\nMoore was the subject of the British \"This Is Your Life\", for a second time, in March 1987 when he was surprised by Eamonn Andrews at his Venice Beach restaurant; he had previously been honoured by the programme in December 1972.\nIn addition to acting, Moore continued to work as a composer and pianist, writing scores for a number of films and giving piano concerts, among the highlights of which were his popular parodies of classical favourites. He appeared as Ko-Ko in Jonathan Miller's production of \"The Mikado\" in Los Angeles in March 1988. He appeared on Kenny G's music video \"Against Doctor's Orders\" from the album \"Silhouette\".\nIn 1991 he released the album \"Songs Without Words\" and in 1992 \"Live From an Aircraft Hangar\", recorded at London's Royal Albert Hall.\nHe collaborated with the conductor Sir Georg Solti in 1991 to create a Channel 4 television series, \"Orchestra!\", which was designed to introduce audiences to the symphony orchestra. He later worked with the American conductor Michael Tilson Thomas on a similar television series, \"Concerto!\" (1993), likewise designed to introduce audiences to classical music concertos.\nMoore appeared in two series for CBS, \"Dudley\" (1993) and \"Daddy's Girls\" (1994); however, both were cancelled before the end of their run.\nMoore had been interviewed for the \"New York Times\" in 1987 by the music critic Rena Fruchter, herself an accomplished pianist, and the two became close friends. By 1995 Moore's film career was on the wane and he was having trouble remembering his lines, a problem he had never previously encountered. It was for this reason he was sacked from Barbra Streisand's film \"The Mirror Has Two Faces\". However, his difficulties were, in fact, due to the onset of the medical condition that eventually led to his death. Opting to concentrate on the piano, he enlisted Fruchter as an artistic partner. They performed as a duo in the US and Australia. However, his disease soon started to make itself apparent there as well, as his fingers would not always do what he wanted them to do. Further symptoms such as slurred speech and loss of balance were misinterpreted by the public and the media as a sign of drunkenness. Moore himself was at a loss to explain this. He moved into Fruchter's family home in New Jersey and stayed there for five years; however, this placed a great strain both on her marriage and her friendship with Moore, and she later set him up in the house next door.\nRestaurant.\nTony Bill and Dudley Moore founded a restaurant in 1983 (closed in November 2000), 72 Market Street Oyster Bar and Grill, in Venice, California.\nPersonal life.\nMoore was married and divorced four times: to actresses Suzy Kendall (15 June 1968 \u2013 15 September 1972); Tuesday Weld (20 September 1975 \u2013 18 July 1980), with whom he had a son, Patrick, on 26 February 1976; Brogan Lane (21 February 1988 \u2013 1991); and Nicole Rothschild (16 April 1994 \u2013 1998), with whom he had a son, Nicholas, on 28 June 1995.\nIn 1994, Moore was arrested and charged with domestic assault after allegedly assaulting his then-girlfriend and soon-to-be wife, Nicole Rothschild.\nHe maintained good relationships with Kendall, Weld, and Lane. He expressly forbade Rothschild from attending his funeral, however, since at the time his illness became apparent, he was going through a difficult divorce with her, while still sharing a Los Angeles house with her and her previous husband.\nIllness and death.\nIn April 1997, after spending five days in a New York hospital, Moore was informed that he had calcium deposits in the basal ganglia of his brain and irreversible frontal lobe damage. He underwent quadruple coronary artery bypass surgery in London and also suffered four strokes.\nOn 30 September 1999, Moore announced that he was suffering from the terminal degenerative brain disorder progressive supranuclear palsy (PSP), a Parkinson-plus syndrome.\nAs some of its early symptoms are very similar to intoxication, he had been reported as being drunk. However, the illness had been diagnosed earlier that year. In November 1999, Moore made his first public appearance since disclosing his illness, reading poetry, alongside Julie Andrews, at a benefit concert in Philadelphia for the charity \"Music for All Seasons\". At first Moore struggled, but soon he settled in and began to joke and ad-lib. He then received a standing ovation, for what was to be his last performance. His disease would quickly progress, eventually requiring him to use a wheelchair.\nMoore died on the morning of 27 March 2002 as a result of pneumonia, secondary to immobility caused by his PSP, in Plainfield, New Jersey, at the age of 66. Rena Fruchter was holding his hand when he died; she reported his final words were \"I can hear the music all around me.\" Moore was buried at Hillside Cemetery in Scotch Plains, New Jersey. Fruchter later wrote a memoir of their relationship titled \"Dudley Moore\" (Ebury Press, 2004).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46209", "revid": "4321602", "url": "https://en.wikipedia.org/wiki?curid=46209", "title": "Louis II of Hungary", "text": "King of Hungary and Croatia from 1516 to 1526\nLouis II (; ; ; ; 1 July 1506 \u2013 29 August 1526) was King of Hungary, Croatia and Bohemia from 1516 to 1526. He died during the Battle of Moh\u00e1cs fighting the Ottomans, whose victory led to the Ottoman annexation of large parts of Hungary.\nEarly life.\nAt his premature birth in Buda on 1 July 1506, the court doctors kept him alive by slaying animals and wrapping him in their warm carcasses as a primitive incubator. He was the only son of Vladislaus II Jagiellon and his third wife, Anne of Foix-Candale.\nCoronation.\nVladislaus II took steps to ensure a smooth succession by arranging for the boy to be crowned in his own lifetime; the coronation of Louis as king of Hungary took place on 4 June 1508 in Sz\u00e9kesfeh\u00e9rv\u00e1r Basilica, and his coronation as king of Bohemia was held on 11 March 1509 in St. Vitus Cathedral in Prague.\nKing of Hungary and Croatia.\nIn 1515 Louis II was married to Mary of Austria, granddaughter of Emperor Maximilian I, as stipulated by the First Congress of Vienna in 1515. His sister Anne was married to Mary's brother Ferdinand, then a governor on behalf of his brother Charles V, and later Emperor Ferdinand I.\nDuring the greater part of his reign he was the puppet of the magnates and kept in such penury that he was often obliged to pawn his jewels to get enough food and clothing. His guardians, Cardinal Tam\u00e1s Bak\u00f3cz and Count George Brandenburg-Ansbach, shamefully neglected him, squandered the royal revenues and distracted the whole kingdom with their endless dissensions. Matters grew even worse on the death of Cardinal Bak\u00f3cz, when the magnates Istv\u00e1n B\u00e1thory, John Z\u00e1polya and Istv\u00e1n Werb\u0151czy fought each other furiously, and used the diets as their tools.\nKing of Bohemia.\nAs king of Bohemia, Louis became known as \"Ludovicus the Child\". The first thaler coins were minted during his reign in Bohemia, later giving the name to the dollars used in different countries. These correctly style him as \"LVDOVICVS\u2022PRIM\u2022D:GRACIA\u2022REX\u2022BO*\" (Louis the First, by the grace of God King of Bohemia).\nWar with the Ottomans.\nAfter his father's death in 1516, the minor Louis II ascended to the throne of Hungary and Croatia. Louis was adopted by the Holy Roman Emperor Maximilian I in 1515. When Maximilian I died in 1519, Louis's cousin George, Margrave of Brandenburg-Ansbach, became his legal guardian.\nFollowing the accession to the Ottoman throne of Suleiman I, the sultan sent Behram \u00c7avu\u015f as an ambassador to Louis II to collect the annual tribute that Hungary had been subjected to, and Louis refused to pay. According to some accounts, he also had the Ottoman ambassador executed and sent the head to the Sultan, but there is no evidence for this. Rather, \u00c7avu\u015f was kept waiting years, virtually imprisoned in Buda, by way of revenge for Suleiman's father, Selim I, who from 1513 to 1519 had forced the Hungarian envoy Barnab\u00e1s B\u00e9layban, Ban of Serim, to travel with him on his campaigns into Persia and Egypt, and to find time to ask for financial help from western countries against the Ottomans. Louis believed that the Papal States and other Christian States including Charles V, Holy Roman Emperor, would help him. This hastened the fall of Hungary.\nHungary was in a state of near anarchy in 1520 under the rule of the magnates. The king's finances were a shambles; he borrowed to meet his household expenses despite the fact that they totaled about one-third of the national income. The country's defenses weakened as border guards went unpaid, fortresses fell into disrepair, and initiatives to increase taxes to reinforce defenses were stifled. By 1521 Sultan Suleiman the Magnificent was well aware of Hungary's weakness.\nThe Ottoman Empire declared war on the Kingdom of Hungary, Suleiman postponed his plan to besiege Rhodes and made an expedition to Belgrade. Louis and his wife Mary requested military aid from other European countries. His uncle, King Sigismund of Poland, and his brother-in-law, Archduke Ferdinand, were willing to help. Ferdinand dispatched 3,000 infantry troops and some artillery while preparing to mobilize the Austrian estates, while Sigismund promised to send footmen. However, the coordination process totally failed. Mary, although a determined leader, caused distrust by relying on non-Hungarian advisors while Louis lacked vigour, which his nobles realized. The Austrian military aid, although seemingly strengthening the border, even had the undesired effect of dissolving the unified leadership that the \"ban\" had held until that time. \nBelgrade and many strategic castles in Serbia were captured by the Ottomans. This was disastrous for Louis' kingdom; without the strategically important cities of Belgrade and \u0160abac, Hungary, including Buda, was open to further Turkish conquests.\nAfter the siege of Rhodes, in 1526 Suleiman made a second expedition to subdue all of Hungary. \nAround the middle of July, the young King departed from Buda, determined to \"either fight back the invaders or be crushed once and for all\". Louis made a tactical error when he tried to stop the Ottoman army in an open field battle with a medieval army, insufficient firearms, and obsolete tactics. On 29 August 1526, Louis led his forces against Suleiman in the disastrous Battle of Moh\u00e1cs. The Hungarian army was surrounded by Ottoman cavalry in a pincer movement, and in the center the Hungarian heavy knights and infantry were repulsed and suffered heavy casualties, especially from the well-positioned Ottoman cannons and well-armed and trained Janissary musketeers.\nNearly the entire Hungarian Royal army was destroyed in nearly 2 hours on the battlefield. During the retreat, the twenty-year-old king died when he fell backwards off his horse while trying to ride up a steep ravine of the Csele stream. He fell into the stream and, due to the weight of his armor, he was unable to stand up and drowned. Suleiman the Magnificent expressed regret at the death of his young adversary. Upon encountering the lifeless body of King Louis, the Sultan is said to have lamented: \"I came indeed in arms against him; but it was not my wish that he should be thus cut off before he scarcely tasted the sweets of life and royalty.\"\nAfter the death of Louis, Ferdinand (as husband to Louis' sister Anna), contested for the crown of Bohemia and Hungary. His bid for Hungary split the opinion of the magnates, with the majority electing John Z\u00e1polya. This split would later cause the majority of Hungary to be ruled under the Ottomans.\nJagiellon bloodline.\nAlthough Louis II's marriage remained childless, he probably had an illegitimate child with his mother's former lady-in-waiting, Angelitha Wass. This son was called John (J\u00e1nos in Hungarian). This name appears in sources in Vienna as either J\u00e1nos Wass or J\u00e1nos Lanthos. The former surname is his mother's maiden name. The latter surname may refer to his occupation. \"Lanthos\" means \"lutenist\", or \"bard\". He received incomes from the Royal Treasury regularly. He had further offspring.\nLegacy.\nNorth of the town of Mohacs, there is a 5 meter high monument to the memory of Louis II. It is located near the site of Louis' death at the Csele Stream. On the monument there is a bronze plaque which depicts Louis falling off his horse. On the top of the monument there is a figure of a sleeping lion. Soma Turcs\u00e1nyi, a \nHussar lieutenant, at his own expense, constructed the original commemorative column in 1864. It was reconstructed in 1897. The monument was restored by the local government in 1986.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "46210", "revid": "50661308", "url": "https://en.wikipedia.org/wiki?curid=46210", "title": "VistaVision", "text": "Motion picture camera film format\nVistaVision is a higher resolution, widescreen variant of the 35mm motion picture film format that was created and designed by engineers at Paramount Pictures in 1954.\nParamount did not use anamorphic processes such as CinemaScope but refined the quality of its flat widescreen system by orienting the 35\u00a0mm negative horizontally in the camera gate and shooting onto a larger area, which yielded a finer-grained projection print.\nAs finer-grained film stocks appeared on the market, VistaVision became obsolete. Paramount dropped the format after only seven years, although for another 40 years the format was used by some European and Japanese producers for feature films and by American films such as the first three \"Star Wars\" films for high-resolution visual effects sequences. The format made a comeback in feature films in the 2020s after its use on \"The Brutalist\" in 2024.\nIn many ways, VistaVision was a testing ground for cinematography ideas that evolved into 70\u00a0mm IMAX and OMNIMAX film formats in the 1970s. Both IMAX and OMNIMAX are oriented sideways, as is VistaVision.\nHistory.\nAs a response to an industry recession caused largely by the popularity of television, the Hollywood studios turned to large-format films in order to regain audience attendance. In 1952, the widescreen format Cinerama debuted in September, and consisted of three strips of 35\u00a0mm film projected side-by-side onto a giant, curved screen, augmented by seven channels of stereophonic sound. In 1953, Twentieth Century-Fox announced the introduction of a simpler version of Cinerama using anamorphic lenses instead of multiple film strips, a widescreen process later known as CinemaScope. \nBy January 1953, Paramount Pictures decided to convert \"Sangaree\" (1953) into a 3-D production, which had originally been filmed \"flat\" for the prior two weeks. When the film was screened for Paramount president Barney Balaban, he had a lengthy conversation with Spyros Skouras, president of Twentieth Century-Fox, in which Balaban stated he had preferred the CinemaScope process. By the next month, Paramount Pictures devised its own system to augment its 3-D process, known as Paravision. This process utilized a screen size that yielded an aspect ratio of five units wide by three units high. The first film released by Paramount to use the Paravision process was \"Red Garters\" (1954). \nThis \"flat\" widescreen process was adopted by other studios, and by the end of 1953, more than half of the theaters in the U.S. had installed widescreens. However, because a smaller portion of the image was used and magnification was increased, excessive grain and soft images plagued early widescreen presentations. Some studios sought to compensate for these effects by shooting color films with a full aperture gate (rather than the Academy aperture) and then reducing the image in Technicolor's optical printer. This process is a predecessor of today's Super 35 format, which also uses a 1.85:1 ratio but one-third more frame area than does a standard 1.85:1 matted into a 4:3 ratio.\nThe idea behind VistaVision originated with John R. Bishop, the head of Paramount's camera department. He had been impressed with the Cinerama process, although he took exception to the blow-up process. He told \"Popular Science Magazine\": \"The negative is the bad boy. We simply can't store enough detail in its small size. Sit close to the screen, and your eyes tire. Too fuzzy, too grainy.\" He became interested in projecting the widescreen image in sharp detail. He installed a Leica lens in a Mitchell Camera after remembering an abandoned two-frame color system developed by the William P. Stein Company that exposed both negatives to form a single projection image. Bishop turned the camera on its side and shot a film test which proved successful. In shooting in the VistaVision process, the film was run horizontally rather than vertically, and instead of exposing two simultaneous four-perforation frames, the entire eight perforations were used for one image. The negative frame area was approximated to be 1.472 x 0.997 inches. \nDuring its technical development, Paramount's camera technicians dubbed this process the \"Lazy 8\" system, by which the term \"lazy\" stood for the horizontal film path, and \"8\" for the eight-sprocket image width. Paramount trade-named the process \"VistaVision\" early in 1954, and the first production to utilize the camera process was \"White Christmas\" (1954). The process afforded a wider aspect ratio of 1.5:1 versus the conventional 1.37:1 Academy ratio, and a much larger image area. In order to satisfy theaters with various screen sizes, VistaVision films were shot so that they could be shown in one of three recommended aspect ratios: 1.66:1, 1.85:1, and 2.00:1.\nIn its lead-up to \"White Christmas\", Paramount Pictures' publicity department stressed the CinemaScope process was \"uncomfortably wide\", in which their \"VistaVision\" process would emphasize that \"height is as important as width.\" By then, several theaters had been equipped with horizontal screen projectors for VistaVision's eight-sprocket image frame. For theater exhibitors that were not equipped, an alternate 35 mm film print was used with a compatible sound system known as the \"Perspecta Stereo\", encoded in the optical track. The VistaVision fanfare, heard in most of the films produced in this ratio, was composed by Nathan Van Cleave.\n\"White Christmas\" held its West Coast premiere at the Warner Beverly Hills Theatre on October 27, 1954. The \"Los Angeles Times\" detailed the VistaVision process was \"a simple innovation, but not easy to grasp\" by which they noted the \"enlargement and compression process gives the picture a depth of focus which enhances its clarity.\" Before its release, in March 1954, Paramount chief engineer Loren L. Ryder believed that VistaVision would become the forerunner of widescreen projection for the following reasons:\nFollowing the film's release, Paramount reiterated its policy to have their standard film prints \"available to play in any theatre anywhere in the world with no requirement that the exhibitor alter [their] equipment in order to play a VistaVision picture.\" Subsequent Paramount films including \"Strategic Air Command\" (1955), \"To Catch a Thief\" (1955), \"The Man Who Knew Too Much\" (1956), \"The Ten Commandments\" (1956), \"Funny Face\" (1957), and \"Vertigo\" (1958) were filmed in VistaVision. Though it was not as prevalent as CinemaScope, rival studios adopted the VistaVision process, including MGM's \"High Society\" (1956), Warner Bros.' \"The Searchers\" (1956), and United Artists' \"The Vikings\" (1958). \nBy the late 1950s, VistaVision became obsolete with the industry preference for Panavision and more refinements in Eastmancolor film stock. Paramount produced their final Vistavision film, \"One-Eyed Jacks\" in 1961. By the 1960s, they adopted Technirama as its primary widescreen projection system. \nSince the release of \"One-Eyed Jacks\" which began shooting in 1958 but was not released until 1961, the format would not be used as a primary imaging system for a feature film until 2024. However, VistaVision's high resolution made it attractive for some visual effects work within some later feature films.\nVisual effects usage.\nIn 1975, a small group of artists and technicians (including Richard Edlund, who was to win two Academy Awards for his work) revived the long-dormant format to create the visual effects shots for George Lucas' space epic \"Star Wars\". A retooled VistaVision camera dubbed the Dykstraflex (named for visual effects master John Dykstra) was used by the group (later called Industrial Light &amp; Magic (ILM)) in complex process shots. For more than two decades after this, VistaVision was often used as an originating and intermediate format for shooting visual effects because a larger negative area compensates against the increased grain created when shots are optically composited. By the early 21st century, computer-generated imagery, advanced film scanning, digital intermediate methods and film stocks with higher resolutions optimized for visual effects work had together rendered VistaVision mostly obsolete even for visual effects work. Nevertheless, in 2008, ILM was still using the format in some production steps, such as for \"Indiana Jones and the Kingdom of the Crystal Skull\", and a VistaVision camera was used in the semi-trailer flip scene in \"The Dark Knight\" because there were not enough IMAX cameras to cover all of the angles needed for the shot. In 2010, certain key sequences of the film \"Inception\" were shot in VistaVision, and in the film \"Scott Pilgrim vs. the World\", shots that needed to be optically enlarged were shot in VistaVision.\nFilms shot in VistaVision.\n1954's \"White Christmas\" was the first Paramount film to utilize the VistaVision method, but perhaps the most well-known film to be filmed completely in VistaVision format is Alfred Hitchcock's 1958 film \"Vertigo\". The use of VistaVision faded by the beginning of the 1960s, with \"One-Eyed Jacks\" in 1961 being the final American film of the 20th Century to be shot entirely using the VistaVision process. \nBy the 21st century, however, the format saw a revival with \"The Brutalist\" in 2024. That same year, it was reported that Paul Thomas Anderson filmed his 2025 film \"One Battle After Another\" in VistaVision, as well as Yorgos Lanthimos's \"Bugonia\" (2025), Alejandro Gonz\u00e1lez I\u00f1\u00e1rritu's untitled 2026 film starring Tom Cruise, M. Night Shyamalan's \"Remain\" (2026), and Greta Gerwig's \"\" (2026). Additionally, the entire third season of \"Euphoria\" (2026) was shot in the format.\nLegacy.\nThe camera numbered VistaVision #1 that was used on Cecil B. DeMille's \"The Ten Commandments\" and several Alfred Hitchcock films was offered at auction on September 30, 2015 by Profiles in History with an estimated value of US$30,000 to $50,000, with a winning bid of US$65,000. Also offered at the same auction was VistaVision High Speed #1 (VVHS1), which was used to film the parting of the Red Sea in \"The Ten Commandments\" and special effects for \"Star Wars\" (winning bid: US$60,000.)\nIn \"\", VistaVision process was used and modified known as \"Anime Vision\", which allowed for a brighter and sharper picture for projection in theaters compared to a TV production.\nThe RED Monstro &amp; V-Raptor 8K VV cameras are modern incarnations of the VistaVision film format. Cameras that utilize the Monstro sensor include the Red Ranger Monstro, DSMC2 Monstro and the Panavision Millennium DXL &amp; DXL2. Cameras that utilize the V-Raptor 8K VV camera include the Red V-Raptor and the Red V-Raptor XL.\nThere was a renewed interest in VistaVision starting in 2024. The films The Brutalist and One Battle After Another both employed the format to critical acclaim.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46211", "revid": "41299752", "url": "https://en.wikipedia.org/wiki?curid=46211", "title": "Tuna", "text": "Tribe of fish\nA tuna (pl.: tunas or tuna) is a saltwater fish that belongs to the tribe Thunnini, a subgrouping of the Scombridae (mackerel) family. The Thunnini comprise 15 species across five genera, the sizes of which vary greatly, ranging from the bullet tuna (max length: , weight: ) up to the Atlantic bluefin tuna (max length: , weight: ), which averages and is believed to live up to 50 years.\nTuna, opah, and mackerel sharks are the only species of fish that can maintain a body temperature higher than that of the surrounding water. An active and agile predator, the tuna has a sleek, streamlined body, and is among the fastest-swimming pelagic fish\u2014the yellowfin tuna, for example, is capable of speeds of up to .\nFound in warm seas, the tuna is commercially fished extensively as a food fish, and is popular as a bluewater game fish. As a result of overfishing, some tuna species, such as the southern bluefin tuna, are threatened with extinction.\nEtymology.\nThe term \"tuna\" comes from Spanish \"at\u00fan\" &lt; Andalusian Arabic \"at-t\u016bn\", assimilated from \"al-t\u016bn\" [Modern Arabic ] : 'tuna fish' &lt; Middle Latin \"thunnus\". \"\" is derived from used for the Atlantic bluefin tuna, that name in turn is ultimately derived from \"th\u00fdn\u014d\", meaning \"to rush, dart along\".\nA dated alternative term is \"tunny\".\nIn English, tuna has been referred to as Chicken of the Sea. This name persists today in Japan, where tuna as a food can be called , literally \"sea chicken\".\nTaxonomy.\nThe Thunnini tribe is a monophyletic clade comprising 15 species in five genera:\n* family Scombridae\n** tribe Thunnini: tunas\n*** genus \"Allothunnus:\" slender tunas\n*** genus \"Auxis:\" frigate tunas\n*** genus \"Euthynnus:\" little tunas\n*** genus \"Katsuwonus:\" skipjack tunas\n*** genus \"Thunnus:\" albacores and true tunas\n**** subgenus \"Thunnus (Thunnus)\": bluefin group\n**** subgenus \"Thunnus (Neothunnus)\": yellowfin group\nThe cladogram is a tool for visualizing and comparing the evolutionary relationships between taxa, and is read left-to-right as if on a timeline. The following cladogram illustrates the relationship between the tunas and other tribes of the family Scombridae. For example, the cladogram illustrates that the skipjack tunas are more closely related to the true tunas than are the slender tunas (the most primitive of the tunas), and that the next nearest relatives of the tunas are the bonitos of the tribe Sardini.\nTrue species.\nThe \"true\" tunas are those that belong to the genus \"Thunnus\". Until recently, it was thought that there were seven \"Thunnus\" species, and that Atlantic bluefin tuna and Pacific bluefin tuna were subspecies of a single species. In 1999, Collette established that based on both molecular and morphological considerations, they are in fact distinct species.\nThe genus \"Thunnus\" is further classified into two subgenera: \"Thunnus (Thunnus)\" (the bluefin group), and \"Thunnus (Neothunnus)\" (the yellowfin group).\nOther species.\nThe Thunnini tribe also includes seven additional species of tuna across four genera. They are:\nBiology.\nDescription.\nThe tuna is a sleek, elongated and streamlined fish, adapted for speed. It has two closely spaced but separated dorsal fins on its back; The first fin is \"depressible\"\u00a0\u2013 it can be laid down, flush, in a groove that runs along its back; it is supported by spines. Seven to ten yellow finlets run from the dorsal fins to the tail, which is lunate\u00a0\u2013 curved like a crescent moon\u00a0\u2013 and tapered to pointy tips. A tuna's pelvic fins are located below the base of the pectoral fins. Both dorsal and pelvic fins retract when the fish is swimming fast.\nThe tuna's body is countershaded to camouflage itself in deeper water when seen from above, its dorsal side is generally a metallic dark blue while the ventral or under side is silvery, often with an iridescent shine. The caudal peduncle, to which the tail is attached, is quite thin, with three stabilizing horizontal keels on each side.\nPhysiology.\n\"Thunnus\" are widely but sparsely distributed throughout the oceans of the world, generally in tropical and temperate waters at latitudes ranging between about 45\u00b0 north and south of the equator. All tunas are able to maintain the temperature of certain parts of their body above the temperature of ambient seawater. For example, bluefin can maintain a core body temperature of , in water as cold as . Unlike other endothermic creatures such as mammals and birds, tuna do not maintain temperature within a relatively narrow range.\nTunas achieve endothermy by conserving the heat generated through normal metabolism. In all tunas, the heart operates at ambient temperature, as it receives cooled blood, and coronary circulation is directly from the gills. The \"rete mirabile\" (\"wonderful net\"), the intertwining of veins and arteries in the body's periphery, allows nearly all of the metabolic heat from venous blood to be \"re-claimed\" and transferred to the arterial blood via a counter-current exchange system, thus mitigating the effects of surface cooling. This allows the tuna to elevate the temperatures of the highly-aerobic tissues of the skeletal muscles, eyes and brain, which supports faster swimming speeds and reduced energy expenditure, and which enables them to survive in cooler waters over a wider range of ocean environments than those of other fish.\nAlso unlike most fish, which have white flesh, the muscle tissue of tuna ranges from pink to dark red. The red myotomal muscles derive their color from myoglobin, an oxygen-binding molecule, which tuna express in quantities far higher than most other fish. The oxygen-rich blood further enables energy delivery to their muscles.\nFor powerful swimming animals like dolphins and tuna, cavitation may be detrimental, because it limits their maximum swimming speed. Even if they have the power to swim faster, dolphins may have to restrict their speed, because collapsing cavitation bubbles on their tail are too painful. Cavitation also slows tuna, but for a different reason. Unlike dolphins, these fish do not feel the bubbles, because they have bony fins without nerve endings. Nevertheless, they cannot swim faster because the cavitation bubbles create a vapor film around their fins that limits their speed. Lesions have been found on tuna that are consistent with cavitation damage.\nFishing.\nCommerce.\nTuna is an important commercial fish. The International Seafood Sustainability Foundation (ISSF) compiled a detailed scientific report on the state of global tuna stocks in 2009, which includes regular updates. According to the ISSF, the most important species for commercial and recreational tuna fisheries are yellowfin (\"Thunnus albacares\"), bigeye (\"T. obesus\"), bluefin (\"T. thynnus\", \"T. orientalis\", and \"T. macoyii\"), albacore (\"T. alalunga\"), and skipjack (\"Katsuwonus pelamis\").\nBased on catches from 2007, the report states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe Australian government alleged in 2006 that Japan had illegally overfished southern bluefin by taking 12,000 to 20,000 tonnes per year instead of the agreed upon 6,000 tonnes; the value of such overfishing would be as much as US$2\u00a0billion. Such overfishing has severely damaged bluefin stocks. According to the WWF, \"Japan's huge appetite for tuna will take the most sought-after stocks to the brink of commercial extinction unless fisheries agree on more rigid quotas\". Japan's Fisheries Research Agency counters that Australian and New Zealand tuna fishing companies under-report their total catches of southern bluefin tuna and ignore internationally mandated total allowable catch totals.\nIn recent years, opening day fish auctions at Tokyo's Tsukiji fish market and Toyosu Market have seen record-setting prices for bluefin tuna, reflecting market demand. In each of 2010, 2011, 2012, 2013 and 2019, new record prices have been set for a single fish\u00a0\u2013 the current record is 333.6\u00a0million japanese yen (US$3.1\u00a0million) for a bluefin, or a unit price of JP\u00a5\u00a01,200,000/kg (US$5,057/lb). The opening auction price for 2014 plummeted to less than 5% of the previous year's price, which had drawn complaints for climbing \"way out of line\". A summary of record-setting auctions are shown in the following table (highlighted values indicate new world records):\nIn November 2011, a different record was set when a fisherman in Massachusetts caught an tuna. It was captured inadvertently using a dragnet. Due to the laws and restrictions on tuna fishing in the United States, federal authorities impounded the fish because it was not caught with a rod and reel. Because of the tuna's deteriorated condition as a result of the trawl net, the fish sold for just under $5,000.\nMethods.\nBesides for edible purposes, many tuna species are caught frequently as game, often for recreation or for contests in which money is awarded based on weight. Larger specimens are notorious for putting up a fight while hooked, and have been known to injure people who try to catch them, as well as damage their equipment.\nAssociation with whaling.\nIn 2005, Nauru, defending its vote from Australian criticism at that year's meeting of the International Whaling Commission, argued that some whale species have the potential to devastate Nauru's tuna stocks, and that Nauru's food security and economy relies heavily on fishing. Despite this, Nauru does not permit whaling in its own waters and does not allow other fishing vessels to take or intentionally interact with marine mammals in its Exclusive Economic Zone. In 2010 and 2011, Nauru supported Australian proposals for a western Pacific-wide ban on tuna purse-seining in the vicinity of marine mammals\u00a0\u2013 a measure which was agreed by the Western and Central Pacific Fisheries Commission at its eighth meeting in March 2012.\nAssociation with dolphins.\nDolphins swim beside several tuna species. These include yellowfin tuna in the eastern Pacific Ocean, but not albacore. Tuna schools are believed to associate themselves with dolphins for protection against sharks, which are tuna predators.\nCommercial fishing vessels used to exploit this association by searching for dolphin pods. Vessels would encircle the pod with nets to catch the tuna beneath. The nets were prone to entangling dolphins, injuring or killing them. Public outcry and new government regulations, which are now monitored by NOAA have led to more dolphin-friendly methods, now generally involving lines rather than nets. There are neither universal independent inspection programs nor verification of dolphin safety, so these protections are not absolute. According to Consumers Union, the resulting lack of accountability means claims of tuna that is \"dolphin safe\" should be given little credence.\nFishery practices have changed to be dolphin friendly, which has caused greater bycatch including sharks, turtles and other oceanic fish. Fishermen no longer follow dolphins, but concentrate their fisheries around floating objects such as fish aggregation devices, also known as FADs, which attract large populations of other organisms. Measures taken thus far to satisfy the public demand to protect dolphins can be potentially damaging to other species as well.\nAquaculture.\nIncreasing quantities of high-grade tuna caught at sea are reared in net pens and fed bait fish. In Australia, former fishermen raise southern bluefin tuna (\"Thunnus maccoyii\") and another bluefin species. Farming its close relative, the Atlantic bluefin tuna, \"Thunnus thynnus\", is beginning in the Mediterranean, North America and Japan. Hawai\u02bbi approved permits for the first U.S. offshore farming of bigeye tuna in water deep in 2009.\nJapan is the biggest tuna consuming nation and is also the leader in tuna farming research. Japan first successfully farm-hatched and raised bluefin tuna in 1979. In 2002, it succeeded in completing the reproduction cycle and in 2007, completed a third generation. The farm breed is known as Kindai tuna. Kindai is the contraction of Kinki University in Japanese (Kinki daigaku). In 2009, Clean Seas, an Australian company which has been receiving assistance from Kinki University managed to breed southern bluefin tuna in captivity and was awarded the second place in World's Best Invention of 2009 by \"Time\" magazine.\nFood.\nFresh and frozen.\nThe fresh or frozen flesh of tuna is widely regarded as a delicacy in most areas where it is shipped, being prepared in a variety of ways. When served as a steak, the meat of most species is known for its thickness and firm texture. In the U.K., supermarkets began flying in fresh tuna steaks in the late 1990s, which helped to increase the popularity of using fresh tuna in cooking; by 2009, celebrity chefs regularly featured fresh tuna in salads, wraps, and char-grilled dishes.\nServed raw.\nVarious species of tuna are often served raw in Japanese cuisine as sushi or sashimi.\nCommercial sashimi tuna may have their coloration fixated by pumping carbon monoxide (CO) into bags containing the tuna, and holding it at 4\u00b0C. For a 2-inch tuna steak, this requires 24 hours. The fish is then vacuum sealed and frozen. In Japan, color fixation using CO is prohibited.\nCanned.\nTuna is canned in edible oils, in brine, in water, and in various sauces. Tuna may be processed and labeled as \"solid\", \"chunked\" (\"chunk\") or \"flaked\". When tuna is canned and packaged for sale, the product is sometimes called tuna fish (U.S.), a calque (loan translation) from the German \"Thunfisch\". Canned tuna is sometimes used as food for pets, especially cats.\nCanned tuna was first produced in Australia in 1903 and quickly became popular.\nIn the early 1980s canned tuna in Australia was most likely southern bluefin, as of 2003[ [update]] it was usually yellowfin, skipjack, or tongol (labelled \"northern bluefin\" or \"longtail\").\nAustralian standards once required cans of tuna to contain at least 51% tuna, but those regulations were dropped in 2003. The remaining weight is usually oil or water.\nThe product became more plentiful in the United States in the late 1940s. In 1950, 8,500,000 pounds of canned tuna were produced, and the U.S. Department of Agriculture classified it as a \"plentiful food\".\nIn the United States, 52% of canned tuna is used for sandwiches; 22% for tuna salads; and 15% for tuna casseroles and dried, prepackaged meal kits, such as General Mills's Tuna Helper line. Other canned tuna dishes include tuna melts (a type of sandwich where the tuna is mixed with mayonnaise and served on bread with cheese melted on top); salade ni\u00e7oise (a salad made of tuna, olives, green beans, potatoes, hard-boiled eggs and anchovy dressing); and tuna burgers (served on buns).\nIn the United States, the Food and Drug Administration (FDA) regulates canned tuna (see part \"c\").\nAs tunas are often caught far from where they are processed, poor interim conservation can lead to spoilage. Tuna is typically gutted by hand, and later precooked for prescribed times of 45 minutes to three hours. The fish are then cleaned and filleted, canned (and sealed), with the dark lateral blood meat often separately canned for pet food (cat or dog). The sealed can is then heated under pressure (called \"retort cooking\") for 2\u20134 hours. This process kills any bacteria, but retains the histamine that may have been produced by those bacteria, and so may still taste spoiled. The international standard sets the maximum histamine level at 200 milligrams per kilogram. An Australian study of 53 varieties of unflavored canned tuna found none to exceed the safe histamine level, although some had \"off\" flavors.\nIn some markets, depending upon the color of the flesh of the tuna species, the can is marked as \"light\" or \"white\" meat, with \"light\" meaning a greyish pink color and \"white\" meaning a light pink color. In the United States, only albacore can legally be sold in canned form as \"white meat tuna\"; in other countries, yellowfin is also acceptable.\nVentresca tuna (from \"ventre\", the Italian word for belly), is a luxury canned tuna, from the fatty bluefin tuna belly, also used in sushi as toro.\nNutrition.\nCanned light tuna in oil is 29% protein, 8% fat, 60% water, and contains no carbohydrates, while providing 200 calories in a 100 gram reference amount (table). It is a rich source (20% or more of the Daily Value, DV) of phosphorus (44% DV) and vitamin D (45% DV), and a moderate source of iron (11% DV).\nMercury and health.\nMercury content in tuna can vary widely. Among those calling for improved warnings about mercury in tuna is the American Medical Association, which adopted a policy that physicians should help make their patients more aware of the potential risks. A study published in 2008 found that mercury distribution in the meat of farmed tuna is inversely related to the lipid content, suggesting that higher lipid concentration within edible tissues of tuna raised in captivity might, other factors remaining equal, have a diluting effect on mercury content. Mackerel tuna is one species of tuna that is lower in mercury concentration than skipjack or yellowfin, but this species is known as \"black meat\" or \"dark meat\" tuna, which is a lower grade for canning because of the color, unfavorable flavor, and poor yield.\nIn March 2004, the United States FDA issued guidelines recommending that pregnant women, nursing mothers, and children limit their intake of tuna and other predatory fish. The Environmental Protection Agency provides guidelines on how much canned tuna is safe to eat. Roughly speaking, the guidelines recommend one can of light tuna per week for individuals weighing less than , and two cans per week for those who weigh more. In 2007, it was reported that some canned light tuna such as yellowfin tuna is significantly higher in mercury than skipjack, and caused Consumers Union and other activist groups to advise pregnant women to refrain from consuming canned tuna. In 2009, a California appeals court upheld a ruling that canned tuna does not need warning labels as the methylmercury is naturally occurring.\nA January 2008 report revealed potentially dangerous levels of mercury in certain varieties of sushi tuna, reporting levels \"so high that the Food and Drug Administration could take legal action to remove the fish from the market.\"\nManagement and conservation.\nThe main tuna fishery management bodies are the Western and Central Pacific Fisheries Commission, the Inter-American Tropical Tuna Commission, the Indian Ocean Tuna Commission, the International Commission for the Conservation of Atlantic Tunas, and the Commission for the Conservation of Southern Bluefin Tuna. The five gathered for the first time in Kobe, Japan in January 2007. Environmental organizations made submissions on risks to fisheries and species. The meeting concluded with an action plan drafted by some 60 countries or areas. Concrete steps include issuing certificates of origin to prevent illegal fishing and greater transparency in the setting of regional fishing quotas. The delegates were scheduled to meet at another joint meeting in January or February 2009 in Europe.\nIn 2010, Greenpeace International added the albacore, bigeye tuna, Pacific bluefin tuna, Atlantic bluefin tuna, southern bluefin tuna, and yellowfin tuna to its seafood red list, which are fish \"commonly sold in supermarkets around the world, and which have a very high risk of being sourced from unsustainable fisheries.\"\nBluefin tuna have been widely accepted as being severely overfished, with some stocks at risk of collapse. According to the International Seafood Sustainability Foundation (a global, nonprofit partnership between the tuna industry, scientists, and the World Wide Fund for Nature), Indian Ocean yellowfin tuna, Pacific Ocean (eastern and western) bigeye tuna, and North Atlantic albacore tuna are all overfished. In April 2009, no stock of skipjack tuna (which makes up roughly 60% of all tuna fished worldwide) was considered to be overfished.\nThe BBC documentary \"South Pacific\", which first aired in May 2009, stated that, should fishing in the Pacific continue at its current rate, populations of all tuna species could collapse within five years. It highlighted huge Japanese and European tuna fishing vessels, sent to the South Pacific international waters after overfishing their own fish stocks to the point of collapse.\nA 2010 tuna fishery assessment report, released in January 2012 by the Secretariat of the Pacific Community, supported this finding, recommending that all tuna fishing should be reduced or limited to current levels and that limits on skipjack fishing be considered.\nResearch indicates that increasing ocean temperatures are taking a toll on the tuna in the Indian Ocean, where rapid warming of the ocean has resulted in a reduction of marine phytoplankton. The bigeye tuna catch rates have also declined abruptly during the past half century, mostly due to increased industrial fisheries, with the ocean warming adding further stress to the fish species.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46213", "revid": "48736052", "url": "https://en.wikipedia.org/wiki?curid=46213", "title": "Glenn Hughes (musician)", "text": "British bassist and singer (born 1951)\nGlenn Hughes (born 21 August 1951) is an English musician, best known for playing bass and performing vocals in the hard rock band Trapeze and in the Mk. III and IV line-ups of Deep Purple, as well as briefly fronting Black Sabbath in the mid-1980s.\nIn addition to being an active session musician, Hughes maintains a notable solo career. He fronts the supergroup Black Country Communion, and fronted California Breed from 2013 to 2015 and The Dead Daisies from 2019 to 2023. In 2016, Hughes was inducted into the Rock and Roll Hall of Fame as a member of Deep Purple.\nEarly life.\nHughes was born in Cannock, Staffordshire, England, on 21 August 1951. He fronted Finders Keepers in the 1960s as bassist/vocalist.\nCareer.\nTrapeze, Deep Purple, Hughes and Thrall (1973\u20131982).\nHughes fronted the British funk rock band Trapeze. Hughes was bassist and lead vocalist for the first three Trapeze albums, released between 1970 and 1972. He also credited with contributing guitar, piano and trombone to these albums.\nHughes was recruited to replace Roger Glover as bassist in Deep Purple in 1973, though he considered himself more a vocalist than a bassist. He was reportedly uninterested in the Deep Purple job until some of the other members proposed that Paul Rodgers of Free be brought in as co-lead vocalist.\nAlthough the recruitment of Rodgers fell through, Hughes had now become interested in the \"two-lead-singer thing\", and David Coverdale was later hired as Deep Purple's lead vocalist. The two would ultimately share lead vocal duties in the band for the next three albums, until the break-up of Deep Purple in 1976. Battling a severe cocaine addiction, Hughes then embarked on a solo career, releasing his first solo album in 1977, titled \"Play Me Out\". In 2016, Hughes was inducted into the Rock and Roll Hall of Fame as a member of Deep Purple.\nIn 1982, he joined with ex-Pat Travers guitarist Pat Thrall to form Hughes/Thrall, and they released one self-titled album which went virtually unnoticed at the time. Part of the reason for the album's obscurity was the inability to support it with a proper tour, due to both parties suffering from drug addiction. As Hughes stated in a 2007 interview, \"The Hughes-Thrall album was a brilliant, brilliant album, but we only did 17 shows because we were too loaded.\"\nGary Moore, Black Sabbath and health problems (1983\u20131990).\nIn the mid-1980s, Hughes recorded several different albums with bands and artists including Phenomena (\"Phenomena\", \"Phenomena II: Dream Runner\"), Gary Moore (\"Run for Cover\"), and Black Sabbath (\"Seventh Star\"; originally a solo album by Sabbath guitarist Tony Iommi that was released as a Sabbath album due to record label pressure).\nHughes' health problems due to overeating, drugs and alcohol began to seriously affect his musical projects and this contributed to very short stints with Gary Moore and Tony Iommi, as Hughes was unable to tour with them properly due to his poor health. In 1985 Black Sabbath reunited with original vocalist Ozzy Osbourne for their one-off Live Aid performance. While waiting for a break in Osbourne's career, Iommi decided to record a solo album and Hughes was brought in to provide the vocals. Due to the aforementioned contractual obligations with the record company, the album was credited to \"Black Sabbath featuring Tony Iommi\" and released in 1986 to generally positive critical reviews. While touring to promote the new album, Hughes was replaced by vocalist Ray Gillen after just six shows; this was due both to injury from a confrontation with Black Sabbath's production manager John Downing, which contributed to a degradation in his voice, and his not being in good enough physical shape to complete the tour.\nHughes's first bass guitar was a salmon pink, pre-CBS Fender Jazz Bass. During his tenure in Trapeze, he played a Fender Jazz Bass as well as a Rickenbacker 4001 on the Deep Purple albums \"Burn\", \"Stormbringer\", and \"Come Taste the Band\". This Rickenbacker was eventually given to Black Sabbath bassist Geezer Butler, who subsequently used it on the Never Say Die! tour in 1978.\nHealth recovery and career rejuvenation (1991\u20132008).\nAt the end of the decade, Hughes realised his ongoing drug problem was derailing him; a clean, sober and fully rejuvenated Hughes returned by 1991 with the vocal for the hit \"America: What Time Is Love?\" with The KLF. He also recorded all the vocals for former Europe guitarist John Norum's solo album \"Face the Truth\". He then re-embarked on a solo career that has been his primary focus to date. In 1999, Hughes did a short tribute tour to Tommy Bolin in Texas, with Tommy's brother Johnnie (of Black Oak Arkansas) on drums.\nIn 2003, Hughes made a guest appearance in the metal opera project \"AINA\", alongside other guest vocalists like Michael Kiske, Tobias Sammet, Andre Matos, and Simone Simons on the debut album \"Days of Rising Doom\".\nIn 2005 Hughes released \"Soul Mover\" supporting it with a European tour. He also collaborated with Tony Iommi on the 2005 album \"Fused\". Hughes then released \"Music for the Divine\" in 2006, which featured Red Hot Chili Peppers members Chad Smith and John Frusciante. Hughes toured in support of the album throughout Europe in autumn 2006. In 2006 Hughes made a guest appearance on Quiet Riot's eleventh studio album \"Rehab,\" doing bass work and songwriting work with the band.\n\"Live in Australia\", an acoustic CD and companion DVD of a performance at Sydney's famous \"Basement\" club was released via Edel Records on 17 November 2007. The album \"First Underground Nuclear Kitchen\" was released on 9 May 2008 in Europe and on 12 May in the rest of the world.\nAutobiography and other projects (2009\u20132016).\nIn 2009, Hughes formed Black Country Communion with Jason Bonham (drums), Joe Bonamassa (guitar) and Derek Sherinian (keyboards). The band released three albums through 2012 and disbanded in March 2013 following the departure of Bonamassa. Black Country Communion reunited in 2016 and released a fourth album in 2017.\nIn July 2010, Hughes appeared as a guest vocalist (together with singer J\u00f8rn Lande) fronting Heaven &amp; Hell at the High Voltage Rock Festival in London as a tribute to the late Ronnie James Dio.\nHughes' autobiography was published in May 2011 by British specialist limited edition publishers Foruli. The book, titled \"Deep Purple and Beyond: Scenes from the Life of a Rock Star\", was co-written with author Joel McIver and featured contributions by Tony Iommi, David Coverdale, Ozzy Osbourne, and Tom Morello, as well as a foreword by Lars Ulrich of Metallica. An extended paperback edition, retitled \"Glenn Hughes: The Autobiography\", was published in late 2011 by Jawbone Press.\nOn 13 September 2012, Hughes and Derek Sherinian met Bako Sahakyan, the president of the breakaway Nagorno-Karabakh Republic and organised a concert in Stepanakert.\nIn 2013, Hughes made a special guest appearance on the debut, self-titled album from Device. He is featured on the song \"Through It All\" accompanying David Draiman on vocals.\nHughes has been touring as a member of Kings of Chaos, performing lead vocals, backing vocals and acoustic guitars, since early 2013. In late 2013, he formed a new band called California Breed with drummer Jason Bonham and guitarist Andrew Watt. The group released one self-titled album in 2014. California Breed announced in 2015 that they had broken up.\nDuring 2015, Hughes undertook a solo world tour, featuring guitarist Doug Aldrich and drummer Pontus Engborg. The next year, he released his most recent studio album, \"Resonate\".\nThe Dead Daisies (2019\u2013present).\nIn September 2019, supergroup the Dead Daisies debuted a new track, \"Righteous Days\", on Planet Rock Radio in the UK. It was also announced that Hughes would be joining the collective as lead singer and bassist. The then current incarnation of the Dead Daisies featured Hughes, guitarist Doug Aldrich, drummer Deen Castronovo, and rhythm guitarist David Lowy.\nIn November, the band headed to the south of France to begin writing and recording the next album, which would be the first with Hughes. They spent two weeks in November then a further two weeks in December at La Fabrique Studios in Saint-R\u00e9my de Provence (south of France) working with producer Ben Grosse. The new album was to be released in 2020.\nAt the beginning of 2020, finishing touches and final mixing of the next album was completed with Grosse. In February, a European tour starting at the end of May 2020 and stretching until well into July was announced but later postponed due to the COVID-19 pandemic. In June it was announced that the band would be playing a few shows with Foreigner in Germany and Poland starting in Hamburg on 6 June 2021. In addition, it was announced that the band would also do a number of dates in Europe in summer 2021 with Judas Priest.\nOn 17 April, \"Unspoken\", the first single from the forthcoming album, was released. On 15 May US dance duo Dance With The Dead released a remix version of \"Unspoken\". On 17 July 2020 \"The Lockdown Sessions\" EP was released by the band on digital platforms. The band later announced that the release of \"Holy Ground\", as well as a supporting tour, had been pushed back to 22 January 2021. The next single to be released by the band was \"Bustle and Flow\" on 25 September. The song reached 15 on the Billboard Mainstream Rock Chart. On 4 December the next single, \"Holy Ground\", which is also the title track of the forthcoming album, was released and was added to the Planet Rock 'A' playlist.\n2021 saw the release of the fifth studio album \"Holy Ground\". The album came out on 22 January featuring 11 songs including three singles. The next day drummer Deen Castronovo announced that he had left the band, due to a future back surgery. In his place for future live shows he will be replaced by Tommy Clufetos, formerly in the band as a session musician.\nIn September 30, 2022 the band released \"Radiance\", their newest studio LP. Featuring a return of Hughes on bass and vocals and Brian Tichy on drums replacing Tommy Clufetos. The album featured the singles \"Face Your Fear\" and \"Radiance\"."}
{"id": "46214", "revid": "49338125", "url": "https://en.wikipedia.org/wiki?curid=46214", "title": "Bilateral cingulotomy", "text": "Neurosurgical procedure for treating depression, OCD, and chronic pain\nBilateral cingulotomy is a form of psychosurgery, introduced in 1948 as an alternative to lobotomy. Today, it is mainly used in the treatment of depression and obsessive-compulsive disorder. In the early years of the twenty-first century, it was used in Russia to treat addiction. It is also used in the treatment of chronic pain. The objective of this procedure is the severing of the supracallosal fibres of the cingulum bundle, which pass through the anterior cingulate gyrus.\nHistory.\nCingulotomy was introduced in the 1940s as an alternative to standard pre-frontal leucotomy/lobotomy in the hope of alleviating symptoms of mental illness whilst reducing the undesirable effects of the standard operation (personality changes, etc.). It was suggested by American physiologist John Farquhar Fulton who, at a meeting of the Society of British Neurosurgeons in 1947, said \"were it feasible, cingulotomy in man would seem an appropriate place for limited leucotomy\". This was derived from the hypothesis of James Papez who thought that the cingulum was a major component of an anatomic circuit believed to play a significant role in emotion. The first reports of the use of cingulotomy on psychiatric patients came from J le Beau in Paris, Hugh Cairns in Oxford, and Kenneth Livingston in Oregon.\nTarget.\nBilateral cingulotomy targets the anterior cingulate cortex, which is a part of the limbic system. This system is responsible for the integration of feelings and emotion in the human cortex. It consists of the cingulate gyrus, parahippocampal gyrus, amygdala, and the hippocampal formation.\nStudies in patients who were subject to bilateral cingulotomy, involving fMRI analyses, showed that the anterior cingulate cortex has a key role in cognitive control and is highly likely to be involved in the control of attentional response, whereas the dorsal part of that region of the brain was not identified to be involved in such a process, although this is still under dispute. The function of the dorsal part of the cingulate cortex was connected to the sorting out and processing of conflicting information signals. In addition, neuroimaging studies also indicated that the anterior cingulate cortex participates in the modulation of cortical regions that are of higher order, as well as sensory processing areas.\nThese findings have also been confirmed by stereotactic microelectrode analysis of single cortical neurons in a study, which involved nine patients undergoing bilateral cingulotomy. The study investigated the effect of performing attention demanding tasks on the activity of 36 neurons located in the anterior cingulate cortex. Upon analyzing the results of the study, it was concluded that the anterior cingulate cortex is indeed involved in the modification of cognitive tasks that require attention, based on the fact that there was a change in the basal firing rate of neurons in that region during simulation of such tasks.\nNeuroimaging also uncovered different sub-regions in the anterior cingulate cortex itself, based on their function. These studies showed that the caudal part of the anterior cingulate cortex plays a more important function in cognitive activities that involve attention, salience, interference and response competition. These results, combined with electrophysiological investigation of the function of neurons in the anterior cingulate cortex, have provided insights that can be used in the improvement of cingulotomy performed on patients treated for obsessive\u2013compulsive disorder (OCD). The basis behind this idea is the fact that a variation of certain tasks, emotional Stroop tasks (ES), which have been particularly identified as exerting effects in OCD patients, activate neurons in the more rostral part of the anterior cingulate cortex. Thus, theoretically, if bilateral cingulotomy is performed in such a patient in the rostral anterior cingulate cortex, better results should be obtained.\nMoreover, OCD has been associated with a malformation of the basal ganglia. The function of this part of the human brain has been mapped to be composed of fiber tracks associated with numerous parallel cortico-striato-thalamocortical circuits (CSTC), which are involved in sensorimotor, motor, oculomotor as well as the cognitive processes that are manifested by the limbic system. This pathway involves GABAergic inhibitory projections that serve as one of the means of communication between the different structures involved. It has been hypothesized that some forms of OCD are a result of disinhibition of one or several of the circuits that operate in the CSTC. This is also indicated by a finding that showed a significant decrease in intracortical inhibition in OCD patients. Thus, lesions in the anterior cingulate cortex might contribute to the lessening of the disinhibition effect. This hypothesis has been confirmed by another study, which assessed the cortical inhibitory and excitatory mechanisms in OCD. The study measured the excitability of the motor cortex, as well as intracortical inhibition in OCD patients and a control group of healthy individuals. The results showed a significant decrease in intracortical inhibition, which resulted in a slowdown of interstimulus intervals by 3\u00a0ms. In addition to its proximity to and association with the limbic system and the amygdala in particular, which plays a key role in emotional experience, the anterior cingulate cortex shares afferent and efferent pathways with a number of thalamic nuclei as well as the posterior cingulate and part of some parietal, frontal and supplementary motor cortex. All these underline the high likelihood that the anterior cingulate cortex must have some involvement in OCD.\nFunctional MRI analyses of the anterior cingulate cortex have also led to the introduction of bilateral cingulotomy for the treatment of chronic pain. Such application was introduced since the anterior cingulate cortex has been found to be related to the processing of nociceptive information input. In particular, the role of the anterior cingulate cortex is in the interpretation of how a stimulus affects a person rather than its actual physical intensity.\nProcedure.\nA book published in 1992 described how the operation was carried out at that time. In most cases the procedure started with the medical team taking a number of CT scan X-ray images of the brain of the patient. This step ensured that the exact target, the cingulate cortex, was mapped out, so that the surgeon could identify it. Burr holes were then created in the patient's skull using a drill. Lesions at the targeted tissue were made with the help of fine electrodes inserted at the right angle into the subject's brain based on plotting charts and making sure important arteries and blood vessels were intact. The electrode was placed in a probe, or a holder, with only its tip projecting. Upon the correct insertion of the holder into the brain tissue, air was injected and more scan images were taken. Then, after the medical team had made sure they were on the right track, the tip of the electrode was advanced to the plane of the cingulate where it was heated to 75\u201390\u00a0\u00b0C. Once the first lesion was created it served as a center around which several other lesions were created. In order to confirm whether lesions are made at the right place, scan images were taken postoperatively and analyzed.\nRecent technological advances, however, have made bilateral cingulotomy a more precise operation. For example, nowadays a neurosurgical team that performs the procedure can use an MRI to identify the location of the anterior and posterior commissures. This approach allows neurosurgeons to obtain a number of coronal images, which are then used to calculate the stereotactic coordinates of the target in the anterior cingulate cortex, where lesions need to be made. Moreover, the MRI enables more precise differentiation of the cell composition, and thus easily permits the identification of the grey matter in that region. This can then be further confirmed with the help of microelectrode recordings.\nSide effects.\nPatients usually recover from this operation over a period of four days. However, there are cases of subjects being released from hospital after as few as 48 hours after the operation. The mild shorter postoperative complications that are most commonly related to bilateral cingulotomy are typical of head interventions and include but are not limited to nausea, vomiting, and headaches. However, in some cases, patients exhibit seizures that sometimes appear up to two months after the surgical intervention. It has been questioned whether this is relevant and can be attributed to cingulotomy because such seizures were observed in patients who already had a history of this condition.\nCase studies.\nA 2002 study conducted at the Massachusetts General Hospital analyzed the outcome of bilateral cingulotomy in 44 patients for the treatment of OCD in the period between 1965 and 1986. Patients were followed up over a long term and evaluated based on several criteria: 1) how many of them were responders after a period of six months, 2) how many cingulotomies a patient had undergone before the examination of the effectiveness of the procedure, 3) whether the patient showed any significant change after the most recent procedure, and 4) what the side effects related to the procedure were.\nThe follow-up of the patients produced contradictory results, which indicated that bilateral cingulotomy is not the optimal treatment for OCD. Of the 44 patients, only 32% both fit the \"responder\" criteria and showed significant improvement compared to the other subjects. Another 14% exhibited some signs of improvement. Multiple cingulotomies correlated with a higher likelihood of continuing to respond to follow-up inquiries (6% more often fit the full \"responder\" criteria, 11% more often fit the partial \"responder\" criteria). However, the side effects associated with the procedure were numerous. Among the complaints that patients had after the surgery were apathy and deficits in memory, although these were rarely reported. In addition, some subjects complained of some form of urinary disturbance, ranging from urinary retention to incontinence. Hydrocephalus (2%) and seizures (2%) were also observed.\nBilateral cingulotomy has also been used in the treatment of chronic refractory pain. A systematic review of 11 studies encompassing 224 patients found that anterior cingulotomy led to significant pain relief in greater than 60% of patients post-operatively as well as at one year following the procedure. Of the included studies, one clinical study investigated the effect of bilateral cingulotomy for the treatment of refractory chronic pain. In this case, 23 patients who were subject to 28 cingulotomies in total were followed up. The analyses aimed at determining how much the pain of each individual was affected after the procedure with the help of a questionnaire. In addition, the examiners tried to evaluate the impacts on social and family relations of the participants in the study. Based on the data obtained, cingulotomy for treatment of chronic pain showed promising results. 72% reported improvement in the level of pain experienced, and 50% indicated that they no longer required painkillers after cingulotomy. More than half of the patients also claimed that the surgical procedure was beneficial and contributed to the improvement of their social interactions.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46215", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=46215", "title": "70 mm film", "text": "Wide high-resolution film gauge\n70\u00a0mm film (or 65\u00a0mm film) is a wide high-resolution film gauge for motion picture photography, with a negative area nearly 3.5 times as large as the standard 35\u00a0mm motion picture film format. As used in cameras, the film is wide. For projection, the original 65\u00a0mm film is printed on film. The additional 5\u00a0mm contains the four magnetic stripes, holding six tracks of stereophonic sound. Although later 70\u00a0mm prints use digital sound encoding (specifically the DTS format), the vast majority of existing and surviving 70\u00a0mm prints pre-date this technology.\nEach frame is five perforations tall (i.e., 23.8125\u00a0mm or 15/16 inches tall), with an image aspect ratio of 2.2:1. The use of anamorphic Ultra Panavision 70 lenses squeezes an ultra-wide 2.76:1 aspect ratio horizontally into that 2.2:1 imaging area. To this day, Ultra Panavision 70 produces the second widest picture size; surpassed only by Polyvision, which was only used for 1927's \"Napol\u00e9on\".\nWith regard to exhibition, 70\u00a0mm film was always considered a specialty format reserved for epics and spectacle films shot on 65\u00a0mm and blockbuster films that were released both in 35\u00a0mm and as 70\u00a0mm blow-ups. While few venues were equipped to screen this special format, at the height of its popularity most major markets and cities had a theater that could screen it. Some venues continue to screen 70\u00a0mm to this day or have even had 70\u00a0mm projectors permanently or temporarily installed for more recent 70\u00a0mm releases.\nHistory.\nFilms formatted with a width of 70\u00a0mm have existed since the early days of the motion picture industry. The first 70\u00a0mm format film was most likely footage of the Henley Regatta, which was projected in 1896 and 1897, but may have been filmed as early as 1894. It required a specially built projector built by Herman Casler in Canastota, New York and had a ratio similar to full frame, with an aperture of by . There were also several film formats of various sizes from 50 to 68\u00a0mm which were developed from 1884 onwards, including Cin\u00e9orama (not to be confused with the entirely distinct \"Cinerama\" format), started in 1900 by Raoul Grimoin-Sanson. In 1914 the Italian Filoteo Alberini invented a panoramic film system utilising a 70\u00a0mm wide film called Panoramica.\nFox Grandeur.\nIn 1928, William Fox of the Fox Film Corporation, in personal collaboration with Theodore Case as the Fox-Case Corporation, began working on a wide film format using 70\u00a0mm film which they named Grandeur. Cameras were ordered by Fox-Case from Mitchell Camera Corp, with the first 70\u00a0mm production cameras, designated as the Mitchell Model FC camera, delivered to Fox-Case in May 1929. This was one of a number of wide-film processes developed by some of the major film studios at about that time. However, due to the financial strains of the Great Depression, along with strong resistance from movie theater owners, who were in the process of equipping their theaters for sound, none of these systems became commercially successful. Fox dropped Grandeur in 1930.\nTodd-AO.\nProducer Mike Todd had been one of the founders of Cinerama, a wide-screen movie process that was launched in 1952. Cinerama employed three 35\u00a0mm film projectors running in synchronism to project a wide (2.6:1) image onto a deeply curved screen. Although the results were impressive, the system was expensive, cumbersome and had some serious shortcomings due to the need to match up three separate projected images. Todd left the company to develop a system of his own which, he hoped, would be as impressive as Cinerama, yet be simpler and cheaper and avoid the problems associated with three-strip projection; in his own words, he wanted \"Cinerama out of one hole\".\nIn collaboration with the American Optical Company, Todd developed a system which was to be called \"Todd-AO\". This uses a single 70\u00a0mm wide film and was introduced with the film \"Oklahoma!\" in October 1955. The 70\u00a0mm film is perforated at the same pitch (0.187 inch, 4.75\u00a0mm) as standard 35\u00a0mm film. With a five-perforation pull-down, the Todd-AO system provides a frame dimension of 1.912 inch (48.56\u00a0mm) by 0.87 inch (22.09\u00a0mm) giving an aspect ratio of 2.2:1.\nThe original version of Todd-AO used a frame rate of 30 per second, 25% faster than the 24 frames per second that was (and is) the standard; this was changed after the second film \u2013 \"Around the World in 80 Days\" - because of the need to produce (24 frame/sec) 35\u00a0mm reduction prints from the Todd-AO 65\u00a0mm negative. The Todd-AO format was originally intended to use a deeply curved Cinerama-type screen but this failed to survive beyond the first few films. However, in the 1960s and 70s, such films as \"The Sound of Music\" (which had been filmed in Todd-AO) and \"Patton\" (which had been filmed in a copycat process known as Dimension 150) were shown in some Cinerama theaters, which allowed for deeply curved screens.\nTodd-AO adopted a similar multi-channel magnetic sound system to the one developed for Cinemascope two years earlier, recorded on \"stripes\" of magnetic oxide deposited on the film. However, Todd-AO has six channels instead of the four of Cinemascope and due to the wider stripes and faster film speed provides superior audio quality. Five of these six channels are fed to five speakers spaced behind the screen, and the sixth is fed to surround speakers around the walls of the auditorium.\nPanavision and the 65/70 mm format.\nPanavision developed their own 65/70\u00a0mm system that was technically compatible and virtually identical to Todd-AO. Monikered as Super Panavision 70, it used spherical lenses and the same 2.2:1 aspect ratio at 24 frames per second. Panavision also had another 65\u00a0mm system, Ultra Panavision 70, which sprang from the MGM Camera 65 system they helped develop for MGM that was used to film \"Raintree County\" and \"Ben-Hur\". Both Ultra Panavision 70 and MGM Camera 65 employed an anamorphic lens with a 1.25\u00d7 squeeze on a 65\u00a0mm negative (as opposed to 35\u00a0mm CinemaScope which used a 2\u00d7 compression, or 8-perf, horizontally filmed 35\u00a0mm Technirama which used a 1.5\u00d7 compression). When projected on a 70\u00a0mm print, a 1.25\u00d7 anamorphic projection lens was used to decompress the image to an aspect ratio of 2.76:1, one of the widest ever used in commercial cinema.\nDecline and resurgence.\nDue to the high cost of 70\u00a0mm film and the expensive projection system and screen required to use the stock, distribution for films using the stock was limited, although this did not always hurt profits. Most 70\u00a0mm films were also released on 35\u00a0mm film for a wider distribution after the initial debut of the film. \"South Pacific\" (1958), \"Lawrence of Arabia\" (1962), \"My Fair Lady\" (1964), and \"The Sound of Music\" (1965) are well-known films widely shown in 70\u00a0mm format with a general release in 35\u00a0mm format. 70\u00a0mm film received a brief resurgence in the 1980s when it became popular to make \"blow-up\" prints of 35\u00a0mm titles. It had another resurgence in the mid-2010s with the release of \"The Master\" (2012), \"The Hateful Eight\" (2015) and \"Dunkirk\" (2017), with a small number of venues getting temporary or permanent 70\u00a0mm film projectors in order to be able to screen these titles. Quentin Tarantino, in particular, led a successful campaign to have the equipment required to show \"The Hateful Eight\" in Ultra Panavision installed in 100 cinemas worldwide.\nBlow-ups.\nThe 35\u00a0mm to 70\u00a0mm \"blow-up\" process produces 70\u00a0mm release prints from 35\u00a0mm negatives, so that films shot on the smaller format could benefit from 70\u00a0mm image and sound quality. This process began in the 1960s with titles like \"The Cardinal\" (1963) and continues up until the present day, with the height of its popularity being in the 1980s. These enlargements often provided richer colors, and a brighter, steadier and sharper (though often grainier) image, but the main benefit was the ability to provide 6-channel stereophonic sound as most theaters before the mid-70s (before the advent of Dolby A) were screening 35\u00a0mm prints with single channel monaural sound. However these \"blow-ups\" rarely used the full six channels of the Todd-AO system and instead used the four-track mixes made for 35\u00a0mm prints, the additional half-left and half-right speakers of the Todd-AO layout being fed with a simple mix of the signals intended for the adjacent speakers (known as a \"spread\") or simply left blank. If a 70\u00a0mm film was shown in a Cinerama theatre, the Cinerama sound system was used. From 1976 onwards, many 70\u00a0mm prints used Dolby noise reduction on the magnetic tracks but Dolby disliked of the \"spread\" and instead re-allocated the 6 available tracks to provide for left, center and right screen channels, left and right surround channels plus a \"low-frequency enhancement\" channel to give more body to low-frequency bass. This layout came to be known as \"5.1\" (the \"point one\" is the low-frequency enhancement channel) and was subsequently adopted for digital sound systems used with 35\u00a0mm.\nIn the 1980s the use of these \"blow-ups\" increased with large numbers of 70\u00a0mm prints being made of some blockbusters of the period such as the 125 70\u00a0mm prints made of \"The Empire Strikes Back\" (1980). However the early 1990s saw the advent of digital sound systems (Dolby Digital, DTS and SDDS) for 35\u00a0mm prints which meant that 35\u00a0mm could finally match 70\u00a0mm for sound quality but at a far lower cost. Coupled with the rise of the multiplex cinema, which meant that audiences were increasingly seeing films on relatively small screens rather than the giant screens of the old \"Picture Palaces\", this meant that the expensive 70\u00a0mm format went out of favour again. The DTS digital sound-on-disc system was adapted for use with 70\u00a0mm film, thus saving the significant costs of magnetic striping, but this has not been enough to stop the decline, and 70\u00a0mm prints were rarely made.\nAmong some of the more recent 70\u00a0mm blow-up titles are Paul Thomas Anderson's \"Inherent Vice\" (2014), \"Phantom Thread\" (2017) and \"Licorice Pizza\" (2021), Patty Jenkins's \"Wonder Woman\" (2017), Steven Spielberg's \"Ready Player One\" (2018) and Brady Corbet's \"The Brutalist\" (2024).\nCurrent use.\nFrom 1970, the usage of 65\u00a0mm negative film drastically reduced, although the Soviet Union (who used 70\u00a0mm stock) continued to use it frequently until the end of the 1980s. This was in part due to the high cost of 65\u00a0mm raw stock and processing. Some of the few films since 1990 shot entirely on 65\u00a0mm stock are Kenneth Branagh's \"Hamlet\" (1996), Ron Fricke's \"Baraka\" (1992) and its sequel, \"Samsara\" (2011) and Quentin Tarantino's \"The Hateful Eight\" (2015). Some titles used a mixture of 5-perf and 15-perf (IMAX) 65\u00a0mm stock, including Christopher Nolan's films \"Dunkirk\" (2017), \"Tenet\" (2020) and \"Oppenheimer\" (2023), and Ryan Coogler's \"Sinners\" (2025).\nOther titles with a significant amount of 65\u00a0mm footage (both 5-perf and 15-perf) include Ron Howard's \"Far and Away\" (1992), Kenneth Branagh's \"Murder on the Orient Express\" (2017) and \"Death on the Nile\" (2022), Paul Thomas Anderson's \"The Master\" (2012), and Christopher Nolan's \"The Dark Knight\" (2008), \"Inception\" (2010), \"The Dark Knight Rises\" (2012) and \"Interstellar\" (2014).\nSince the 2010s, most movie theaters have converted to digital projection systems, resulting in the removal of both 35\u00a0mm (the previous industry standard) projectors and 70\u00a0mm projectors. However some venues and organizations remain committed to screening 70\u00a0mm film, seeing the special format as something that can set them apart and be an audience draw in an industry where most movies are screened digitally.\n70\u00a0mm film festivals continue to take place regularly at venues such as The Somerville Theatre in Somerville, Massachusetts, The Music Box Theatre in Chicago, the Hollywood Theatre in Portland, Oregon, the American Cinematheque's Aero and Egyptian Theaters in Los Angeles, the Museum of the Moving Image in New York City, the TIFF Bell Lightbox in Toronto, the Worcester Polytechnic Institute in Worcester, Massachusetts, and the AFI Silver Theatre in Silver Spring, Maryland, among others.\nUses of 70\u00a0mm.\nUltra Panavision.\nAn anamorphic squeeze combined with 65\u00a0mm film allowed for extremely wide aspect ratios to be used while still preserving quality. This was used in the 1957 film \"Raintree County\" and to incredible success in the 1959 film \"Ben-Hur\" and the 2015 film \"The Hateful Eight\", both of which were filmed with the Ultra Panavision 70/MGM Camera 65 process at an aspect ratio of 2.76:1. It required the use of a 1.25\u00d7 anamorphic lens to compress the image horizontally, and a corresponding lens on the projector to uncompress it.\nVisual effects.\nLimited use of 65\u00a0mm film was revived in the late 1970s for some of the visual effects sequences in films like \"Close Encounters of the Third Kind\", mainly because the larger negative did a better job than 35\u00a0mm negative of minimizing visible film grain during optical compositing. 65\u00a0mm was the primary film format used at VFX pioneer Douglas Trumbull's facility EEG (Entertainment Effects Group), which later became Boss Film Studios, run by ex-Industrial Light &amp; Magic (ILM) supervisor Richard Edlund. Since the 1990s, a handful of films (such as \"Spider-Man 2\") have used 65mm for this purpose, but the usage of digital intermediate for compositing has largely negated these issues. Digital intermediate offers other benefits such as lower cost and a greater range of available lenses and accessories to ensure a consistent look to the footage.\nIMAX.\nA horizontal variant of 70\u00a0mm, with an even bigger picture area, is used for the high-performance IMAX format which uses a frame that is 15 perforations wide on 70\u00a0mm film. The Dynavision and Astrovision systems each use slightly less film per frame and vertical pulldown to save print costs while being able to project onto an IMAX screen. Both were rare, with Astrovision largely used in Japanese planetariums. IMAX introduced a digital projection system in the late 2000s and most IMAX venues have migrated to a digital setup.\n70\u00a0mm 3D early use.\nThe first commercial introduction of 70\u00a0mm single projector 3D was the 1967 release of \"Con la muerte a la espalda\", a Spanish/French/Italian co-production which used a process called Hi-Fi Stereo 70, itself based on a simplified, earlier developed Soviet process called Stereo-70. This process captured two anamorphic images, one for each eye, side by side on 65\u00a0mm film. A special lens on a 70\u00a0mm projector added polarization and merged the two images on the screen. The 1971 re-release of Warner Bros.' \"House of Wax\" used the side-by-side StereoVision format and was distributed in both anamorphically squeezed 35\u00a0mm and deluxe non-anamorphic 70\u00a0mm form. The system was developed by Allan Silliphant and Chris Condon of StereoVision International Inc., which handled all technical and marketing aspects on a five-year special-royalty basis with Warner Bros. The big screen 3D image was both bright and clear, with all the former sync and brightness problems of traditional dual 35\u00a0mm 3D eliminated. Still, it took many years more before IMAX began to test the water for big-screen 3D, and sold the concept to Hollywood executives.\nIMAX 3D.\nHollywood has released films shot on 35\u00a0mm as IMAX blow-up versions. Many 3D films were shown in the 70\u00a0mm IMAX format. \"The Polar Express\" in IMAX 3D 70\u00a0mm earned 14 times as much, per screen, as the simultaneous 2D 35\u00a0mm release of that film in the fall of 2004.\nTechnical specifications.\nUltra Panavision 70 (MGM Camera 65).\n\"Same as Standard 65 mm except\"\nShowscan.\n\"Same as Standard 65\u00a0mm except\"\nIMAX Dome / OMNIMAX.\n\"Same as IMAX except\"\nOmnivision Cinema 180.\n\"same as standard 65/70 except:\"\nOmnivision started in Sarasota, Florida. Theatres were designed to compete with Omnimax but with much lower startup and operating costs. Most theatres were built in fabric domed structures designed by Seaman Corporation. The last known OmniVision theatres to exist in USA are The Alaska Experience Theatre in Anchorage, Alaska, built in 1981 (closed in 2007, reopened in 2008), and the Hawaii Experience Theatre in Lahaina, Hawaii (closed in 2004). Rainbow's End (theme park) in NZ had the only remaining permanent Cinema 180 attraction until May 2015 when it was demolished.\nOne of the few producers of 70\u00a0mm films for Cinema 180 was the German company Cinevision (today AKPservices GmbH, Paderborn).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46216", "revid": "21112944", "url": "https://en.wikipedia.org/wiki?curid=46216", "title": "Israeli\u2013Palestinian conflict", "text": "Ongoing military and political conflict in the Levant\nThe Israeli\u2013Palestinian conflict is an ongoing military and political conflict about land and self-determination within the territory of the former Mandatory Palestine. Key aspects of the conflict include the Israeli occupation of the West Bank and Gaza Strip, the status of Jerusalem, Israeli settlements, borders, security, water rights, the permit regime in the West Bank and in the Gaza Strip, Palestinian freedom of movement, and the Palestinian right of return.\nThe conflict has its origins in the rise of Zionism in the late 19th century in Europe, a movement which aimed to establish a Jewish state through the colonization of Palestine, synchronously with the first arrival of Jewish settlers to Ottoman Palestine in 1882. The Zionist movement garnered the support of an imperial power in the 1917 Balfour Declaration issued by Britain, which promised to support the creation of a \"Jewish homeland\" in Palestine. Following British occupation of the formerly Ottoman region during World War I, Mandatory Palestine was established as a British mandate. Increasing Jewish immigration led to tensions between Jews and Arabs, which grew into intercommunal conflict. In 1936, an Arab revolt erupted, demanding independence and an end to British support for Zionism, which was suppressed by the British. Eventually, tensions led to the United Nations adopting a partition plan in 1947, triggering a civil war.\nDuring the ensuing 1948 Palestine war, more than half of the mandate's predominantly Palestinian Arab population fled or were expelled by Israeli forces. By the end of the war, Israel was established on most of the former mandate's territory, and the Gaza Strip and the West Bank were controlled by Egypt and Jordan respectively. Since the 1967 Six-Day War, Israel has been occupying the West Bank and the Gaza Strip, known collectively as the Palestinian territories. Two Palestinian uprisings against Israel and its occupation erupted in 1987 and 2000, the first and second intifadas respectively. Israel's occupation resulted in Israel constructing illegal settlements there, creating a system of institutionalized discrimination against Palestinians under its occupation called Israeli apartheid. This discrimination includes Israel's denial of Palestinian refugees from their right of return and right to their lost properties. Israel has also drawn international condemnation for violating the human rights of the Palestinians.\nThe international community, with the exception of the United States and Israel, has been in consensus since the 1980s regarding a settlement of the conflict on the basis of a two-state solution along the 1967 borders and a just resolution for Palestinian refugees. The United States and Israel have instead preferred bilateral negotiations, rather than a resolution of the conflict on the basis of international law. In recent years, public support for a two-state solution has decreased, with Israeli policy reflecting an interest in maintaining the occupation, rather than seeking a permanent resolution to the conflict. In 2007, Israel tightened its blockade of the Gaza Strip and made official its policy of isolating it from the West Bank. Since then, Israel has framed its relationship with Gaza in terms of the laws of war, rather than in terms of its status as an occupying power. In a July 2024 advisory opinion, the International Court of Justice (ICJ) determined that Israel continues to illegally occupy the West Bank and Gaza Strip. The ICJ also determined that Israeli policies violate the International Convention on the Elimination of All Forms of Racial Discrimination. \nSince 2006, Hamas and Israel have fought several wars. Attacks by Hamas-led armed groups in October 2023 in Israel, which resulted in nearly 1,200 deaths, were followed by another war, which has caused widespread destruction, loss of life, mass population displacement, a humanitarian crisis, and an ongoing famine in the Gaza Strip. Israel's actions in Gaza during this war have been described by international law experts, genocide scholars and human rights organizations as a genocide.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nThe Israeli\u2013Palestinian conflict began in the late 19th and early 20th centuries, with the development of political Zionism and the arrival of Zionist settlers to Palestine. During the early 20th century, Arab nationalism also grew within the Ottoman Empire. To gain support from the Arab nationalists in the war against the Ottoman Empire, Great Britain promised support for the formation of an independent Arab state in Palestine in the McMahon\u2013Hussein correspondence. The British Empire supplied a large amount of weapons to the Arab revolt 1916-1918. With support from the Arab revolt the British Empire defeated the Ottoman's forces and took control of Palestine, Jordan and Syria. It later transpired that the British and French governments had secretly made the Sykes-Picot Agreement in 1916 not to allow the formation of an independent Arab state. In July 1920, the short-lived Arab Kingdom of Syria, with Emir Faisal (one of the leaders of the Arab Revolt) as king and tolerated by Britain, was crushed by French armed forces, equipped with modern artillery. \nWhile Jewish colonization began during this period, it was not until the arrival of more ideologically Zionist immigrants in the decade preceding the First World War that the landscape of Ottoman Palestine would start to significantly change. Land purchases, the eviction of tenant Arab peasants and armed confrontation with Jewish para-military units would all contribute to the Palestinian population's growing fear of territorial displacement and dispossession. From early on, the leadership of the Zionist movement had the idea of \"transferring\" (a euphemism for ethnic cleansing) the Arab Palestinian population out of the land for the purpose of establishing a Jewish demographic majority. According to the Israeli historian Benny Morris the idea of transfer was \"inevitable and inbuilt into Zionism\". The Arab population felt the threat of transfer as early as the 1880s with the arrival of the first aliyah. Chaim Weizmann's efforts to build British support for the Zionist movement would eventually secure the Balfour Declaration, a public statement issued by the British government in 1917 during the First World War announcing support for the establishment of a \"national home for the Jewish people\" in Palestine.\n1920s.\nWith the creation of the British Mandate in Palestine after the end of the first world war, large-scale Jewish immigration began accompanied by the development of a separate Jewish-controlled sector of the economy supported by foreign capital. The more ardent Zionist ideologues of the Second Aliyah would become the leaders of the Yishuv starting in the 1920s and believed in the separation of Jewish and Arab societies.\nAmin al-Husseini, appointed as Grand Mufti of Jerusalem by the British High Commissioner Herbert Samuel, immediately marked Jewish national movement and Jewish immigration to Palestine as the sole enemy to his cause, initiating large-scale riots against the Jews as early as 1920 in Jerusalem and in 1921 in Jaffa. Among the results of the violence was the establishment of the Jewish paramilitary force Haganah. In 1929, a series of violent riots resulted in the deaths of 133 Jews and 116 Arabs, with significant Jewish casualties in Hebron and Safed, and the evacuation of Jews from Hebron and Gaza.\nAlongside political unrest, rural Palestine in the Mandate era experienced demographic and agricultural expansion. Large villages such as Lajjun and Hamama grew in size, reclaimed marginal lands, and integrated into regional markets, reflecting the resilience and transformation of the Palestinian countryside during this period.\n1936\u20131939 Arab revolt.\nIn the early 1930s, the Arab national struggle in Palestine had drawn many Arab nationalist militants from across the Middle East, such as Sheikh Izz ad-Din al-Qassam from Syria, who established the Black Hand militant group and had prepared the grounds for the 1936\u20131939 Arab revolt in Palestine. Following the death of al-Qassam at the hands of the British in late 1935, tensions erupted in 1936 into the Arab general strike and general boycott. The strike soon deteriorated into violence, and the Arab revolt was bloodily repressed by the British assisted by the British armed forces of the Jewish Settlement Police, the Jewish Supernumerary Police, and Special Night Squads. The suppression of the revolt would leave at least 10% of the adult male population killed, wounded, imprisoned or exiled. Between the expulsion of much of the Arab leadership and the weakening of the economy, the Palestinians would struggle to confront the growing Zionist movement.\nThe cost and risks associated with the revolt and the ongoing inter-communal conflict led to a shift in British policies in the region and the appointment of the Peel Commission which recommended creation of a small Jewish country, which the two main Zionist leaders, Chaim Weizmann and David Ben-Gurion, accepted on the basis that it would allow for later expansion. The subsequent White Paper of 1939, which rejected a Jewish state and sought to limit Jewish immigration to the region, was the breaking point in relations between British authorities and the Zionist movement.\n1940\u20131947.\nThe renewed violence, which continued sporadically until the beginning of World War II, ended with around 5,000 casualties on the Arab side and 700 combined on the British and Jewish side total. With the eruption of World War II, the situation in Mandatory Palestine calmed down. It allowed a shift towards a more moderate stance among Palestinian Arabs under the leadership of the Nashashibi clan and even the establishment of the Jewish\u2013Arab Palestine Regiment under British command, fighting Germans in North Africa. The more radical exiled faction of al-Husseini, however, tended to cooperate with Nazi Germany, and participated in the establishment of a pro-Nazi propaganda machine throughout the Arab world. The defeat of Arab nationalists in Iraq and subsequent relocation of al-Husseini to Nazi-occupied Europe tied his hands regarding field operations in Palestine, though he regularly demanded that the Italians and the Germans bomb Tel Aviv. The Jewish Agency for Palestine and Palestinian National Defense Party called on Palestine's Jewish and Arab youth to volunteer for the British Army. 30,000 Palestinian Jews and 12,000 Palestinian Arabs enlisted in the British armed forces during the war, while a Jewish Brigade was created in 1944.\nBy the end of World War II, a crisis over the fate of Holocaust survivors from Europe led to renewed tensions between the Yishuv and Mandate authorities. By 1944, Jewish groups began to conduct military-style operations against the British, with the aim of persuading Great Britain to accept the formation of a Jewish state. This culminated in the Jewish insurgency in Mandatory Palestine. This sustained Zionist paramilitary campaign of resistance against British authorities, along with the increased illegal immigration of Jewish refugees and 1947 United Nations partition, led to eventual withdrawal of the British from Palestine.\n1947 United Nations partition plan.\nOn 29 November 1947, the General Assembly of the United Nations adopted Resolution 181(II) recommending the adoption and implementation of a plan to partition Palestine into an Arab state, a Jewish state and the City of Jerusalem. Palestinian Arabs were opposed to the partition. Zionists accepted the partition but planned to expand Israel's borders beyond what was allocated to it by the UN. On the next day, Palestine was swept by violence, igniting the first phase of the Palestine War. For four months, under continuous Arab provocation and attack, the Yishuv was usually on the defensive while occasionally retaliating. The Arab League supported the Arab struggle by forming the volunteer-based Arab Liberation Army, supporting the Palestinian Arab Army of the Holy War, under the leadership of Abd al-Qadir al-Husayni and Hasan Salama. On the Jewish side, the civil war was managed by the major underground militias \u2013 the Haganah, Irgun and Lehi \u2013 strengthened by numerous Jewish veterans of World War II and foreign volunteers. By spring 1948, it was already clear that the Arab forces were nearing a total collapse, while Yishuv forces gained more and more territory, creating a large scale refugee problem of Palestinian Arabs.\n1948 Arab\u2013Israeli War.\nFollowing the Declaration of the Establishment of the State of Israel on 14 May 1948, the Arab League decided to intervene on behalf of Palestinian Arabs, marching their forces into former British Palestine, beginning the main phase of the 1948 Arab\u2013Israeli War. The overall fighting, leading to around 15,000 casualties, resulted in cease-fire and armistice agreements of 1949, with Israel holding much of the former Mandate territory, Jordan occupying and later annexing the West Bank and Egypt taking over the Gaza Strip, where the All-Palestine Government was declared by the Arab League on 22 September 1948. The 1947\u20131948 civil war in Mandatory Palestine and 1948 Arab-Israeli War resulted in the ethnic cleansing of 750,000 Palestinian Arabs. In 1950, Israel passed the Law of Return, which allowed Jews and their spouses to become citizens with voting rights, even if they had never lived there before.\n1956 Suez Crisis.\nThrough the 1950s, Jordan and Egypt supported the Palestinian Fedayeen militants' cross-border attacks into Israel, while Israel carried out its own reprisal operations in the host countries. The 1956 Suez Crisis resulted in a short-term Israeli occupation of the Gaza Strip and exile of the All-Palestine Government, which was later restored with Israeli withdrawal. The All-Palestine Government was completely abandoned by Egypt in 1959 and was officially merged into the United Arab Republic, to the detriment of the Palestinian national movement. Gaza Strip then was put under the authority of the Egyptian military administrator, making it a de facto military occupation. In 1964, however, a new organization, the Palestine Liberation Organization (PLO), was established by Yasser Arafat. It immediately won the support of most Arab League governments and was granted a seat in the Arab League.\n1967 Six-Day War.\nIn the 1967 Arab-Israel War, Israel occupied the Palestinian West Bank, East Jerusalem, Gaza Strip, Egyptian Sinai, Syrian Golan Heights, and two islands in the Gulf of Aqaba.\nThe war exerted a significant effect upon Palestinian nationalism, as the PLO was unable to establish any control on the ground and ultimately established its headquarters in Jordan, from where it supported the Jordanian army during the War of Attrition. However, the Palestinian base in Jordan collapsed with the Jordanian\u2013Palestinian civil war in 1970, after which the PLO was forced to relocate to South Lebanon.\nIn the mid-1970s, the international community converged on a framework to resolve the conflict through the establishment of an independent Palestinian state in the West Bank and Gaza. This \"land for peace\" proposal was endorsed by the ICJ and UN.\n1973 Yom Kippur War.\nOn 6 October 1973, a coalition of Arab forces consisting of mainly Egypt and Syria launched a surprise attack against Israel on the Jewish holy day of Yom Kippur. Despite this, the war concluded with an Israeli victory, with both sides suffering tremendous casualties.\nFollowing the end of the war, the UN Security Council passed Resolution 338 confirming the land-for-peace principle established in Resolution 242, initiating the Middle East peace process. The Arab defeat would play an important role in the PLO's willingness to pursue a negotiated settlement to the conflict, while many Israelis began to believe that the area under Israeli occupation could not be held indefinitely by force.\nThe Camp David Accords, agreed upon by Israel and Egypt in 1978, primarily aimed to establish a peace treaty between the two countries. The accords also proposed the creation of a \"Self-Governing Authority\" for the Arab population in the West Bank and Gaza Strip, excluding Jerusalem, under Israeli control. A peace treaty based on these accords was signed in 1979, leading to Israel's withdrawal from the occupied Egyptian Sinai Peninsula by 1982.\n1982 Lebanon War.\nDuring the Lebanese Civil War, Palestinian militants continued to launch attacks against Israel while also battling opponents within Lebanon. In 1978, the Coastal Road massacre led to the Israeli full-scale invasion known as Operation Litani. This operation sought to dislodge the PLO from Lebanon while expanding the area under the control of the Israeli allied Christian militias in southern Lebanon. The operation succeeded in leaving a large portion of the south in control of the Israeli proxy which would eventually form the South Lebanon Army. Under United States pressure, Israeli forces would eventually withdraw from Lebanon.\nIn 1982, Israel, having secured its southern border with Egypt, sought to resolve the Palestinian issue by attempting to dismantle the military and political power of the PLO in Lebanon. The goal was to establish a friendly regime in Lebanon and continue its policy of settlement and annexation in occupied Palestine. The PLO had observed the latest ceasefire with Israel and shown a preference for negotiations over military operations. As a result, Israel sought to remove the PLO as a potential negotiating partner. Most Palestinian militants were defeated within several weeks, Beirut was captured, and the PLO headquarters were evacuated to Tunisia in June by Yasser Arafat's decision.\nFirst Intifada (1987\u20131993).\nThe first Palestinian uprising began in 1987 as a response to Israel's military occupation, escalating attacks on Palestinians, and policies of settlement building and collective punishment. The uprising largely consisted of nonviolent acts of civil disobedience and protest, and was largely led by grassroots popular, youth, and women's committees. By the early 1990s, the conflict, termed the First Intifada, was the focus of international settlement efforts, in part motivated by the success of the Egyptian\u2013Israeli peace treaty of 1982. Eventually the Israeli\u2013Palestinian peace process led to the Oslo Accords of 1993, allowing the PLO to relocate from Tunisia and take ground in the West Bank and Gaza Strip, establishing the Palestinian National Authority. The peace process also had significant opposition among elements of Palestinian society, such as Hamas and Palestinian Islamic Jihad, who immediately initiated a campaign of attacks targeting Israelis. Following hundreds of casualties and a wave of anti-government propaganda, Israeli Prime Minister Rabin was assassinated by an Israeli far-right extremist who objected to the peace initiative. This struck a serious blow to the peace process, which in 1996 led to the newly elected government of Israel backing off from the process, to some degree.\nSecond Intifada (2000\u20132005).\nFollowing several years of unsuccessful negotiations, the conflict re-erupted as the Second Intifada in September 2000. The violence, escalating into an open conflict between the Palestinian National Security Forces and the Israel Defense Forces, lasted until 2004/2005 and led to thousands of fatalities. In 2005, Israeli Prime Minister Sharon ordered the removal of Israeli settlers and soldiers from Gaza. Israel and its Supreme Court formally declared an end to occupation, saying it \"had no effective control over what occurred\" in Gaza. However, the United Nations, Human Rights Watch and many other international bodies and NGOs continue to consider Israel to be the occupying power of the Gaza Strip as Israel controls Gaza Strip's airspace, territorial waters and controls the movement of people or goods in or out of Gaza by air or sea.\nFatah\u2013Hamas split (2006\u20132007).\nIn 2006, Hamas won a plurality of 44% in the Palestinian parliamentary election. Israel responded it would begin economic sanctions unless Hamas agreed to accept prior Israeli\u2013Palestinian agreements, forswear violence, and recognize Israel's right to exist, all of which Hamas rejected. After internal Palestinian political struggle between Fatah and Hamas erupted into the 2007 Battle of Gaza, Hamas took full control of the area. In 2007, Israel imposed a naval blockade on the Gaza Strip, and cooperation with Egypt allowed a ground blockade of the Egyptian border.\nThe tensions between Israel and Hamas escalated until late 2008, when Israel launched operation Cast Lead upon Gaza, resulting in thousands of civilian casualties and billions of dollars in damage. By February 2009, a ceasefire was signed with international mediation between the parties, though the occupation and small and sporadic eruptions of violence continued.\nIn 2011, a Palestinian Authority attempt to gain UN membership as a fully sovereign state failed. In Hamas-controlled Gaza, sporadic rocket attacks on Israel and Israeli air raids continued to occur. In November 2012, Palestinian representation in the UN was upgraded to a non-member observer state, and its mission title was changed from \"Palestine (represented by PLO)\" to \"State of Palestine\". In 2014, another war broke out between Israel and Gaza, resulting in over 70 Israeli and over 2,000 Palestinian casualties.\n2023\u2013present Gaza war.\nAfter the 2014 war and 2021 crisis, Hamas began planning an attack on Israel. In 2022, Netanyahu returned to power while headlining a hardline far-right government, which led to greater political strife in Israel and clashes in the Palestinian territories. This culminated in a surprise attack launched by Hamas-led militant groups on southern Israel from the Gaza Strip on 7 October 2023, in which more than 1,195 Israeli civilians, military personnel, and other foreign nationals were killed, and 251 were taken hostage into Gaza. The Israeli military responded by declaring war on Hamas and conducting an extensive aerial bombardment campaign on Gaza, followed by a large-scale ground invasion with the stated goal of destroying Hamas, freeing hostages, and controlling security in Gaza afterwards. South Africa accused Israel of genocide at the International Court of Justice and called for an immediate ceasefire. The court issued an order requiring Israel to take all measures to prevent any acts contrary to the 1948 Genocide Convention, but did not order Israel to suspend its military campaign.\nThe war spilled over the Middle East, with Israel engaging in clashes with local militias in the West Bank, Hezbollah in Lebanon and northern Israel, and other Iranian-backed militias in Syria, as well as Iran itself. Iranian-backed militias also engaged in clashes with the United States, while the Houthis blockaded the Red Sea in protest, to which the United States responded with airstrikes in Yemen, Iraq, and Syria. Taking advantage of the weakening position of Iranian-backed militias, Syrian opposition groups initiated an offensive in November 2024 that reignited the Syrian civil war, culminating in the fall of the Assad regime and the establishment of a transitional government in the place of the former Ba'athist government; Israel invaded the area around the its demarcated boundaries with Syria shortly afterwards.\nThe war has caused widespread destruction, a humanitarian crisis, and an ongoing famine in the Gaza Strip, while most of the population was forcibly displaced. Many human rights organizations and scholars of genocide studies and international law say that Israel is committing genocide in Gaza, though some dispute this. Over 60,000 Palestinians in Gaza have been killed, almost half of them women and children, and more than 148,000 have been injured. A study in \"The Lancet\" estimated 64,260 deaths in Gaza from traumatic injuries by June 2024, while noting a potentially larger death toll when \"indirect\" deaths are included. As of May 2025, a comparable figure for traumatic injury deaths would be 93,000.\nSeptember 2025 developments.\nOn 9 September 2025, Israeli airstrikes targeted senior Hamas leaders in Doha. Reports differed: some sources stated that senior leaders survived, while others reported deaths of lower-level operatives and at least one Qatari officer. On 12 September, the United Nations General Assembly adopted the \"New York Declaration\" by a vote of 142 in favour, 10 opposed and 12 abstentions. The declaration endorses concrete steps toward a two-state solution and calls for measures to establish a Palestinian government free of Hamas's control as part of a broader political process.\nAttempts to reach a peaceful settlement.\nThe PLO's participation in diplomatic negotiations was dependent on its complete disavowal of terrorism and recognition of Israel's \"right to exist.\" This stipulation required the PLO to abandon its objective of reclaiming all of historic Palestine and instead focus on the 22 percent which came under Israeli military control in 1967. By the late 1970s, Palestinian leadership in the occupied territories and most Arab states supported a two-state settlement. In 1981, Saudi Arabia put forward a plan based on a two-state settlement to the conflict with support from the Arab League. Israeli analyst Avner Yaniv describes Arafat as ready to make a historic compromise at this time, while the Israeli cabinet continued to oppose the existence of a Palestinian state. Yaniv described Arafat's willingness to compromise as a \"peace offensive\" which Israel responded to by planning to remove the PLO as a potential negotiating partner in order to evade international diplomatic pressure. Israel would invade Lebanon the following year in an attempt to undermine the PLO as a political organization, weakening Palestinian nationalism and facilitating the annexation of the West Bank into Greater Israel.\nWhile the PLO had adopted a program of pursuing a Palestinian state alongside Israel since the mid-1970s, the 1988 Palestinian Declaration of Independence formally consecrated this objective. This declaration, which was based on resolutions from the Palestine National Council sessions in the late 1970s and 1980s, advocated for the creation of a Palestinian state comprising the West Bank, Gaza Strip, and East Jerusalem, within the borders set by the 1949 armistice lines prior to 5 June 1967. Following the declaration, Arafat explicitly denounced all forms of terrorism and affirmed the PLO's acceptance of UN Resolutions 242 and 338, as well as the recognition of Israel's right to exist. All the conditions defined by Henry Kissinger for US negotiations with the PLO had now been met.\nThen-Israeli prime minister Yitzhak Shamir stood behind the stance that the PLO was a terrorist organization. He maintained a strict stance against any concessions, including withdrawal from occupied Palestinian territories, recognition of or negotiations with the PLO, and especially the establishment of a Palestinian state. Shamir viewed the U.S. decision to engage in dialogue with the PLO as a mistake that threatened the existing territorial status quo. He argued that negotiating with the PLO meant accepting the existence of a Palestinian state and hence was unacceptable.\nThe peace process.\nThe term \"peace process\" refers to the step-by-step approach to resolving the conflict. Having originally entered into usage to describe the US mediated negotiations between Israel and surrounding Arab countries, notably Egypt, the term \"peace-process\" has grown to be associated with an emphasis on the negotiation process rather than on presenting a comprehensive solution to the conflict. As part of this process, fundamental issues of the Israeli\u2013Palestinian conflict such as borders, access to resources, and the Palestinian right of return, have been left to \"final status\" talks. Such \"final status\" negotiations along the lines discussed in Madrid in 1991 have never taken place.\nThe Oslo Accords of 1993 and 1995 built on the incremental framework put in place by the 1978 Camp David negotiations and the 1991 Madrid and Washington talks. The motivation behind the incremental approach towards a settlement was that it would \"build confidence\", but the eventual outcome was instead a dramatic decline in mutual confidence. At each incremental stage, Israel further entrenched its occupation of the Palestinian territories, despite the PA upholding its obligation to curbing violent attacks from extremist groups, in part by cooperating with Israeli forces.\nMeron Benvenisti, former deputy mayor of Jerusalem, observed that life became harsher for Palestinians during this period as state violence increased and Palestinian land continued to be expropriated as settlements expanded. Israeli foreign minister Shlomo Ben-Ami described the Oslo Accords as legitimizing \"the transformation of the West Bank into what has been called a 'cartographic cheeseboard'.\"\nCreation of the Palestinian Authority and security cooperation.\nCore to the Oslo Accords was the creation of the Palestinian Authority and the security cooperation it would enter into with the Israeli military authorities in what has been described as the \"outsourcing\" of the occupation to the PA. Just before signing the Oslo accord, Rabin described the expectation that the \"Palestinians will be better at establishing internal security than we were, because they will allow no appeals to the Supreme Court and will prevent [human rights groups] from criticizing the conditions there.\" Along these lines, Ben-Ami, who participated in the Camp David 2000 talks, described this process: \"One of the meanings of Oslo was that the PLO was eventually Israel's collaborator in the task of stifling the Intifada and cutting short what was clearly an authentically democratic struggle for Palestinian independence.\"\nThe Wye River Memorandum agreed on by the PA and Israel introduced a \"zero tolerance\" policy for \"terror and violence.\" This policy was uniformly criticized by human rights organizations for its \"encouragement\" of human rights abuses. Dennis Ross describes the Wye as having successfully reduced both violent and non-violent protests, both of which he considers to be \"inconsistent with the spirit of Wye.\" Watson claims that the PA frequently violated its obligations to curb incitement and its record on curbing terrorism and other security obligations under the Wye River Memorandum was, at best, mixed.\nOslo Accords (1993, 1995).\nIn 1993, Israeli officials led by Yitzhak Rabin and Palestinian leaders from the Palestine Liberation Organization led by Yasser Arafat strove to find a peaceful solution through what became known as the Oslo peace process. A crucial milestone in this process was Arafat's letter of recognition of Israel's right to exist. Emblematic of the asymmetry in the Oslo process, Israel was not required to, and did not, recognize the right of a Palestinian state to exist. In 1993, the Declaration of Principles (or Oslo I) was signed and set forward a framework for future Israeli\u2013Palestinian negotiations, in which key issues would be left to \"final status\" talks. The stipulations of the Oslo agreements ran contrary to the international consensus for resolving the conflict; the agreements did not uphold Palestinian self-determination or statehood and repealed the internationally accepted interpretation of UN Resolution 242 that land cannot be acquired by war. With respect to access to land and resources, Noam Chomsky described the Oslo agreements as allowing \"Israel to do virtually what it likes.\" The Oslo process was delicate and progressed in fits and starts.\nThe process took a turning point at the assassination of Yitzhak Rabin in November 1995 and the election of Netanyahu in 1996, finally unraveling when Arafat and Ehud Barak failed to reach an agreement at Camp David in July 2000 and later at Taba in 2001. The interim period specified by Oslo had not built confidence between the two parties; Barak had failed to implement additional stages of the interim agreements and settlements expanded by 10% during his short term. The disagreement between the two parties at Camp David was primarily on the acceptance (or rejection) of international consensus. For Palestinian negotiators, the international consensus, as represented by the yearly vote in the UN General Assembly which passes almost unanimously, was the starting point for negotiations. The Israeli negotiators, supported by the American participants, did not accept the international consensus as the basis for a settlement. Both sides eventually accepted the Clinton parameters \"with reservations\" but the talks at Taba were \"called to a halt\" by Barak, and the peace process itself came to a stand-still. Ben-Ami, who participated in the talks at Camp David as Israel's foreign minister, would later describe the proposal on the table: \"The Clinton parameters... are the best proof that Arafat was right to turn down the summit's offers\".\nCamp David Summit (2000).\nIn July 2000, US President Bill Clinton convened a peace summit between Palestinian President Yasser Arafat and Israeli Prime Minister Ehud Barak. Barak reportedly put forward the following as \"bases for negotiation\", via the US to the Palestinian President: a non-militarized Palestinian state split into 3\u20134 parts containing 87\u201392% of the West Bank after having already given up 78% of historic Palestine. Thus, an Israeli offer of 91 percent of the West Bank (5,538km2 of the West Bank translates into only 86 percent from the Palestinian perspective), including Arab parts of East Jerusalem and the entire Gaza Strip, as well as a stipulation that 69 Jewish settlements (which comprise 85% of the West Bank's Jewish settlers) would be ceded to Israel, no right of return to Israel, no sovereignty over the Temple Mount or any core East Jerusalem neighborhoods, and continued Israel control over the Jordan Valley.\nArafat rejected this offer, which Palestinian negotiators, Israeli analysts and Israeli Foreign Minister Shlomo Ben-Ami described as \"unacceptable\". According to the Palestinian negotiators the offer did not remove many of the elements of the Israeli occupation regarding land, security, settlements, and Jerusalem.\nAfter the Camp David summit, a narrative emerged, supported by Israeli Prime Minister Ehud Barak and his foreign minister Shlomo Ben-Ami, as well as US officials including Dennis Ross and Madeleine Albright, that Yasser Arafat had rejected a generous peace offer from Israel and instead incited a violent uprising. This narrative suggested that Arafat was not interested in a two-state solution, but rather aimed to destroy Israel and take over all of Palestine. This view was widely accepted in US and Israeli public opinion. Nearly all scholars and most Israeli and US officials involved in the negotiations have rejected this narrative. These individuals include prominent Israeli negotiators, the IDF chief of staff, the head of the IDF's intelligence bureau, the head of the Shin Bet as well as their advisors.\nNo tenable solution was crafted which would satisfy both Israeli and Palestinian demands, even under intense US pressure. Clinton has long blamed Arafat for the collapse of the summit. In the months following the summit, Clinton appointed former US Senator George J. Mitchell to lead a fact-finding committee aiming to identify strategies for restoring the peace process. The committee's findings were published in 2001 with the dismantlement of existing Israeli settlements and Palestinian crackdown on militant activity being one strategy.\nDevelopments following Camp David.\nFollowing the failed summit Palestinian and Israeli negotiators continued to meet in small groups through August and September 2000 to try to bridge the gaps between their respective positions. The United States prepared its own plan to resolve the outstanding issues. Clinton's presentation of the US proposals was delayed by the advent of the Second Intifada at the end of September.\nClinton's plan, eventually presented on 23 December 2000, proposed the establishment of a sovereign Palestinian state in the Gaza Strip and 94\u201396 percent of the West Bank plus the equivalent of 1\u20133 percent of the West Bank in land swaps from pre-1967 Israel. On Jerusalem, the plan stated that \"the general principle is that Arab areas are Palestinian and that Jewish areas are Israeli.\" The holy sites were to be split on the basis that Palestinians would have sovereignty over the Temple Mount/Noble sanctuary, while the Israelis would have sovereignty over the Western Wall. On refugees, the plan suggested a number of proposals including financial compensation, the right of return to the Palestinian state, and Israeli acknowledgment of suffering caused to the Palestinians in 1948. Security proposals referred to a \"non-militarized\" Palestinian state, and an international force for border security. Both sides accepted Clinton's plan and it became the basis for the negotiations at the Taba Peace summit the following January.\nTaba Summit (2001).\nThe Israeli negotiation team presented a new map at the Taba Summit in Taba, Egypt, in January 2001. The proposition removed the \"temporarily Israeli controlled\" areas, and the Palestinian side accepted this as a basis for further negotiation. With Israeli elections looming the talks ended without an agreement but the two sides issued a joint statement attesting to the progress they had made: \"The sides declare that they have never been closer to reaching an agreement and it is thus our shared belief that the remaining gaps could be bridged with the resumption of negotiations following the Israeli elections.\" The following month the Likud party candidate Ariel Sharon defeated Ehud Barak in the Israeli elections and was elected as Israeli prime minister on 7 February 2001. Sharon's new government chose not to resume the high-level talks.\nRoad map for peace (2002\u20132003).\nOne peace proposal, presented by the Quartet of the European Union, Russia, the United Nations and the United States on 17 September 2002, was the Road Map for Peace. This plan did not attempt to resolve difficult questions such as the fate of Jerusalem or Israeli settlements, but left that to be negotiated in later phases of the process. The proposal never made it beyond the first phase, whose goals called for a halt to both Israeli settlement construction and Israeli\u2013Palestinian violence. Neither goal has been achieved as of November 2015.\nThe Annapolis Conference was a Middle East peace conference held on 27 November 2007, at the United States Naval Academy in Annapolis, Maryland, United States. The conference aimed to revive the Israeli\u2013Palestinian peace process and implement the \"Roadmap for peace\". The conference ended with the issuing of a joint statement from all parties. After the Annapolis Conference, the negotiations were continued. Both Mahmoud Abbas and Ehud Olmert presented each other with competing peace proposals. Ultimately no agreement was reached.\nArab Peace Initiative (2002, 2007, 2017).\nThe Arab Peace Initiative ( \"Mub\u0101dirat as-Sal\u0101m al-\u02bfArab\u012byyah\"), also known as the Saudi Initiative, was first proposed by Crown Prince Abdullah of Saudi Arabia at the 2002 Beirut summit. The initiative is a proposed solution to the Arab\u2013Israeli conflict as a whole, and the Israeli\u2013Palestinian conflict in particular. The initiative was initially published on 28 March 2002, at the Beirut summit, and agreed upon again at the 2007 Riyadh summit. Unlike the Road Map for Peace, it spelled out \"final solution\" borders based on the UN borders established before the 1967 Six-Day War. It offered full normalization of relations with Israel, in exchange for the withdrawal of its forces from all the occupied territories, including the Golan Heights, to recognize \"an independent Palestinian state with East Jerusalem as its capital\" in the West Bank and Gaza Strip, as well as a \"just solution\" for the Palestinian refugees.\nThe Palestinian Authority led by Yasser Arafat immediately embraced the initiative. His successor Mahmoud Abbas also supported the plan and officially asked U.S. President Barack Obama to adopt it as part of his Middle East policy. Islamist political party Hamas, the elected government of the Gaza Strip, was deeply divided, with most factions rejecting the plan. Palestinians have criticized the Israel\u2013United Arab Emirates normalization agreement and another with Bahrain signed in September 2020, fearing the moves weaken the Arab Peace Initiative, regarding the UAE's move as \"a betrayal.\"\nThe Israeli government under Ariel Sharon rejected the initiative as a \"non-starter\" because it required Israel to withdraw to pre-June 1967 borders. After the renewed Arab League endorsement in 2007, then-Prime Minister Ehud Olmert gave a cautious welcome to the plan. In 2015, Israeli Prime Minister Benjamin Netanyahu expressed tentative support for the Initiative, but in 2018, he rejected it as a basis for future negotiations with the Palestinians.\nCurrent status.\nApartheid.\nIn July 2024, the International Court of Justice determined that Israeli policies violate the International Convention on the Elimination of All Forms of Racial Discrimination. As of 2022, all the major Israeli and international human rights organizations were in agreement that Israeli actions constituted the crime of apartheid. In April 2021, Human Rights Watch released its report \"A Threshold Crossed\", describing the policies of Israel towards Palestinians living in Israel, the West Bank and Gaza constituted the crime of apartheid. A further report titled \"Israel's Apartheid Against Palestinians: Cruel System of Domination and Crime Against Humanity\" was released by Amnesty International on 1 February 2022.\nIn 2018, the Knesset passed the which the Israeli legal group Adalah nicknamed the \"Apartheid law.\" Adalah described the Nation-State law as \"constitutionally enshrining Jewish supremacy and the identity of the State of Israel as the nation-state of the Jewish people.\" The Nation-State law is a Basic Law, meaning that it has \"quasi-constitutional status,\" and states that the right to exercise national self-determination in Israel is \"unique to the Jewish people\".\nOccupied Palestinian territory.\nIsrael has occupied the Palestinian territories, which comprise the West Bank (including East Jerusalem) and the Gaza Strip, since the 1967 Six-Day War, making it the longest military occupation in modern history. In 2024, the International Court of Justice determined that the Palestinian territories constitute one political unit and that Israel's occupation since 1967, and the subsequent creation of Israeli settlements and exploitation of natural resources, are illegal under international law. The court also ruled that Israel should pay full reparations to the Palestinian people for the damage the occupation has caused.\nSome Palestinians say they are entitled to all of the West Bank, Gaza Strip, and East Jerusalem. Israel says it is justified in not ceding all this land, because of security concerns, and also because the lack of any valid diplomatic agreement at the time means that ownership and boundaries of this land is open for discussion. Palestinians believe any reduction of their territorial claims is a severe deprivation of their rights. In negotiations, the Palestinian stance is that any moves to reduce the boundaries of this land is a hostile move against their key interests. Israel considers this land to be in dispute and feels the purpose of negotiations is to define what the final borders will be. In 2017 Hamas announced that it was ready to support a Palestinian state on the 1967 borders \"without recognising Israel or ceding any rights\".\nIsraeli settlements.\nThe international community considers Israeli settlements to be illegal under international law, but Israel disputes this. Those who justify the legality of the settlements use arguments based upon Articles 2 and 49 of the Fourth Geneva Convention, as well as UN Security Council Resolution 242. The expansion of settlements often involves the confiscation of Palestinian land and resources, leading to displacement of Palestinian communities and creating a source of tension and conflict. Settlements are often protected by the Israeli military and are frequently flashpoints for violence against Palestinians. Furthermore, the presence of settlements and Jewish-only bypass roads creates a fragmented Palestinian territory, seriously hindering economic development and freedom of movement for Palestinians. Amnesty International reports that Israeli settlements divert resources needed by Palestinian towns, such as arable land, water, and other resources; and that settlements reduce Palestinians' ability to travel freely via local roads, owing to security considerations.\nAs of 2023, there were about 500,000 Israeli settlers living in the West Bank, with another 200,000 living in East Jerusalem. In February 2023, Israel's Finance Minister Bezalel Smotrich took charge of most of the Civil Administration, obtaining broad authority over civilian issues in the West Bank. In the first six months of 2023, 13,000 housing units were built in settlements, which is almost three times more than in the whole of 2022.\nIsraeli military police.\nIn a report published in February 2014 covering incidents over the three-year period of 2011\u20132013, Amnesty International stated that Israeli forces employed reckless violence in the West Bank, and in some instances appeared to engage in wilful killings which would be tantamount to war crimes. Besides the numerous fatalities, Amnesty said at least 261 Palestinians, including 67 children, had been gravely injured by Israeli use of live ammunition. In this same period, 45 Palestinians, including 6 children had been killed. Amnesty's review of 25 civilian deaths concluded that in no case was there evidence of the Palestinians posing an imminent threat. At the same time, over 8,000 Palestinians suffered serious injuries from other means, including rubber-coated metal bullets. Only one IDF soldier was convicted, killing a Palestinian attempting to enter Israel illegally. The soldier was demoted and given a 1-year sentence with a five-month suspension. The IDF answered the charges stating that its army held itself \"to the highest of professional standards\", adding that when there was suspicion of wrongdoing, it investigated and took action \"where appropriate\".\nSeparation of the Gaza Strip.\nSince 2006, Israel has enforced an official and explicit policy of enforcing \"separation\" between the West Bank and Gaza Strip. This separation policy has involved strict restrictions on imports, exports and travel to and from the Gaza Strip. This policy began to develop as early as the 1950s, but was further formalized with the implementation of an Israeli closure regime in 1991, where Israel began requiring Gazans to obtain permits to exit the Gaza Strip and to enter the West Bank (cancelling the \"general exit permit\"). By treating the Gaza Strip as a separate entity, Israel has aimed to increase its control over the West Bank while avoiding a political resolution to the conflict. The lack of territorial contiguity between Gaza and the West Bank and the absence of any \"safe passage\" explain the success of Israel's policy of separation. Harvard political economist Sara Roy describes the separation policy as motivated by Israeli rejection of territorial compromise, fundamentally undermining Palestinian political and economic cohesion and weakening national unity among Palestinians.\nThe severing of Gaza from the West Bank hinterland reflects a paradigm shift in the framing of the conflict. After Hamas assumed power in 2007, Israel declared Gaza a \"hostile territory,\" preferring to frame its obligations towards Gaza in terms of the law of armed conflict, over what it presented as a border dispute, as opposed to those of military occupation (this framing was rebuffed by the ICJ in 2024 when the court stated that Israel continued to occupy the Gaza Strip even after the 2005 disengagement). Indeed, the intensified blockade policy was presented by Israeli officials as \"economic warfare\" intended to \"keep the Gazan economy on the brink of collapse\" at the \"lowest possible level.\" Roy cites an Israeli Supreme Court's decision approving fuel cuts to Gaza as emblematic of the disabling of Gaza; the court deemed the fuel cuts permissible on the basis that they would not harm the population's \"essential humanitarian needs.\"\nThe executive director of the Israeli human rights organization Gisha described Israeli policy towards Gaza between 2007 and 2010 as \"explicitly punitive,\" controlling the entry of food based on calculated calorie needs to limit economic activity and enforce \"economic warfare.\" These restrictions included allowing only small packets of margarine to prevent local food production. Gaza's GDP dramatically declined during this period as a result of these measures. Indeed, by April 2010 Israel restricted the entry of commercial items to Gaza to a list of 73 products, compared with 4,000 products which had previously been approved. The result was the virtual collapse of Gaza's private sector, which Roy describes as largely completed after the 2008 Israeli Operation Cast Lead in Gaza. According to Gisha, travel restrictions from the Gaza Strip are not based on individual security concerns, rather, the general rule is that travel to Israel or the West Bank from Gaza is not permitted other than in \"exceptional\" cases. Israeli imposed travel restrictions aim in particular to prevent Gazans from living in the West Bank. Indeed, Israeli policy treats the Gaza Strip as a \"terminus\" station, with family reunification between the West Bank and Gaza Strip only possible if the family agrees to permanently relocate to the Gaza Strip. The Israeli officials described the blockade as serving limited security value, instead referring to these restrictions as motivated by \"political-security.\"\nBlockade of the Gaza Strip.\nAlthough closure has a long history in Gaza dating back to 1991 when it was first imposed, it was made more acute after 2000 with the start of the second intifada. Closure was tightened further after the 2005 disengagement and then again in 2006, after Hamas's electoral victory. Heightened restrictions were imposed on imports and exports as well as on the movement of people, including Gaza's labor force. The total siege of Gaza that was imposed following the Hamas led attack on Israel during 7 October 2023, was part of that same policy of separation and closure, characterized by the destruction of Gaza's infrastructure (especially housing) and the denial of food, water, electricity, and fuel to its population. On 9 October 2023, Israel declared war on Hamas and tightened its blockade of the Gaza Strip. Israeli Defense Minister Yoav Gallant declared, \"There will be no electricity, no food, no fuel, everything is closed. We are fighting human animals and we are acting accordingly.\"\nSince its initiation, blockade has had a detrimental impact on the private sector in Gaza, the primary driver of economic growth in Gaza. Prior to the blockade, Gaza imported 95% of its inputs for manufacturing and exported 85% of the finished products (primarily to Israel and the West Bank). Employment in this sector dropped to 4% by 2010, with an overall unemployment rate of 40% at this time and 80% of the population living on less than 2 dollars a day. Fewer than 40 commercial items were allowed in to the Gaza Strip by 2009, compared to a list of 4,000 items before the start of the blockade. Fuel imports were restricted such that 95% of Gaza's industrial operations were forced to close, with the rest operating far below capacity. In aggregate, 100,000 out of the 120,000 employed in the private sector lost their jobs as a result of the blockade. Most critically for the economy has been the near complete ban on exports from the Gaza Strip. The number of truckloads carrying exports fell to 2% their pre-blockade numbers. Only exports to the European market were allowed, a far less profitable market for Gazans than Israel and the West Bank. The products approved for export were primarily flowers and strawberries. The first export to the West Bank or Israel did not happen until 2012 and only in very limited quantities: up to four truckloads of furniture manufactured in Gaza were allowed through Israel for an exhibition in Amman.\nEven in the early years of Israeli imposed closure, the associated increased cost of doing business had a detrimental impact on trade. Goods transferred between the West Bank, Gaza, and Israel were required to be loaded onto Palestinian trucks initially and then off loaded onto Israeli trucks at the border even for distances of 50\u2013100 miles. These increased costs include the costs for security checks, clearance, storage, and spoilage, as well as increased transportation costs.\nThe Military Advocate General of Israel said that Israel is justified under international law to impose a blockade on an enemy for security reasons as Hamas \"turned the territory under its de facto control into a launching pad of mortar and rocket attacks against Israeli towns and villages in southern Israel.\" Media headlines have described a United Nations commission as ruling that Israel's blockade is \"both legal and appropriate.\" However, Amnesty International has stated that this is \"completely false,\" and that the cited UN report made no such claim. The Israeli Government's continued land, sea and air blockage is tantamount to collective punishment of the population, according to the United Nations Office for the Coordination of Humanitarian Affairs.\nIn January 2008, the Israeli government calculated how many calories per person were needed to prevent a humanitarian crisis in the Gaza Strip, and then subtracted eight percent to adjust for the \"culture and experience\" of the Gazans. Details of the calculations were released following Israeli human rights organization Gisha's application to the high court. Israel's Coordinator of Government Activities in the Territories, who drafted the plan, stated that the scheme was never formally adopted, this was not accepted by Gisha.\nOn 20 June 2010, in response to the Gaza flotilla raid, Israel's Security Cabinet approved a new system governing the blockade that would allow practically all non-military or dual-use items to enter the Gaza Strip. According to a cabinet statement, Israel would \"expand the transfer of construction materials designated for projects that have been approved by the Palestinian Authority, including schools, health institutions, water, sanitation and more\u2014as well as (projects) that are under international supervision.\" Despite the easing of the land blockade, Israel will continue to inspect all goods bound for Gaza by sea at the port of Ashdod. Despite these announcements, the economic situation did not substantially change and the virtual complete ban on exports remained in place. Only some consumer products and material for donor-sponsored projects was allowed in.\nUnited Nations and recognition of Palestinian statehood.\nThe PLO has campaigned for full member status for the state of Palestine at the UN and for recognition on the 1967 borders. This campaign has received widespread support. The UN General Assembly votes every year almost unanimously in favor of a resolution calling for the establishment of a Palestinian state on the 1967 borders. The US and Israel instead prefer to pursue bilateral negotiation rather than resolving the conflict on the basis of international law. Netanyahu has criticized the Palestinians of purportedly trying to bypass direct talks, whereas Abbas has argued that the continued construction of Israeli-Jewish settlements is \"undermining the realistic potential\" for the two-state solution. Although Palestine has been denied full member status by the UN Security Council, in late 2012 the UN General Assembly overwhelmingly approved the \"de facto\" recognition of sovereign Palestine by granting non-member state status.\nIncitements to violence.\nFollowing the Oslo Accords, which was to set up regulative bodies to rein in frictions, Palestinian incitement against Israel, Jews, and Zionism continued, parallel with Israel's pursuance of settlements in the Palestinian territories, though under Abu Mazen it has reportedly dwindled significantly. Charges of incitement have been reciprocal, both sides interpreting media statements in the Palestinian and Israeli press as constituting incitement. Schoolbooks published for both Israeli and Palestinian schools have been found to have encouraged a one-sided narrative and at times hatred of the other side.\nPerpetrators of murderous attacks, whether against Israelis or Palestinians, often find strong vocal support from sections of their communities despite varying levels of condemnation from politicians.\nBoth parties to the conflict have been criticized by third-parties for teaching incitement to their children by downplaying the other side's historical ties to the area, teaching propagandist maps, or indoctrinating their children to one day join the armed forces.\nIssues in dispute.\nThe core issues of the conflict are the status of Jerusalem, the right of return for Palestinian refugees, security concerns, Israeli settlements in the West Bank, and borders. With the PLO's recognition of Israel's \"right to exist\" in 1982, the international community, with the main exception of the United States and Israel, has been in consensus on a framework for resolving the conflict on the basis of international law. Various UN bodies and the ICJ have supported this position; every year, the UN General Assembly votes almost unanimously in favor of a resolution titled \"Peaceful Settlement of the Question of Palestine.\" This resolution consistently affirms the illegality of the Israeli settlements, the annexation of East Jerusalem, and the principle of the inadmissibility of the acquisition of territory by war. It also emphasizes the need for an Israeli withdrawal from the Palestinian territory occupied since 1967 and the need for a just resolution to the refugee question on the basis of UN resolution 194.\nUnilateral strategies and the rhetoric of hardline political factions, coupled with violence, have fostered mutual embitterment and hostility and a loss of faith in the possibility of reaching a peaceful settlement. Since the break down of negotiations, security has played a less important role in Israeli concerns, trailing behind employment, corruption, housing and other pressing issues. Israeli policy had reoriented to focus on managing the conflict and the associated occupation of Palestinian territory, rather than reaching a negotiated solution. The expansion of Israeli settlements in the West Bank has led the majority of Palestinians to believe that Israel is not committed to reaching an agreement, but rather to a pursuit of establishing permanent control over this territory in order to provide that security.\nStatus of Jerusalem.\nIn 1967, Israel unilaterally annexed East Jerusalem, in violation of international law. Israel seized a significant area further east of the city, eventually creating a barrier of Israeli settlements around the city, isolating Jerusalem's Palestinian population from the West Bank. Israel's policy of constructing sprawling Jewish neighborhoods surrounding the Palestinian sections of the city were aimed at making a repartition of the city almost impossible. In a further effort to change the demography of Jerusalem in favor of a Jewish majority, Israel discouraged Palestinian presence in the city while encouraging Jewish presence, as a matter of policy. Specifically, Israel introduced policies restricting the space available for the construction of Palestinian neighborhoods, delaying or denying building permits and raising housing demolition orders. Tensions in Jerusalem are primarily driven by provocations by Israeli authorities and Jewish extremists against Arabs in the city.\nThe Israeli government, including the Knesset and Supreme Court, is seated in the \"new city\" of West Jerusalem and has been since Israel's founding in 1948. After Israel annexed East Jerusalem in 1967, it assumed complete administrative control of East Jerusalem. Since then, various UN bodies have consistently denounced Israel's control over East Jerusalem as invalid. In 1980, Israel passed the Jerusalem Law declaring \"Jerusalem, complete and united, is the capital of Israel.\"\nMany countries do not recognize Jerusalem as Israel's capital, with exceptions being the United States and Russia. The majority of UN member states and most international organizations do not recognize Israel's claims to East Jerusalem, which occurred after the 1967 Six-Day War, nor its 1980 Jerusalem Law proclamation. The International Court of Justice in its 2004 Advisory opinion on the \"Legal Consequences of the Construction of a Wall in the Occupied Palestinian Territory\" described East Jerusalem as \"occupied Palestinian territory\".\nThe three largest Abrahamic religions\u2014Judaism, Islam, and Christianity\u2014hold Jerusalem as an important setting for their religious and historical narratives. Jerusalem is the holiest city in Judaism, being the former location of the Jewish temples on the Temple Mount and the capital of the ancient Israelite kingdom. For Muslims, Jerusalem is the third holiest site, being the location of the Isra' and Mi'raj event, and the Al-Aqsa Mosque. For Christians, Jerusalem is the site of Jesus' crucifixion and the Church of the Holy Sepulchre.\nHoly sites and the Temple Mount.\nSince the early 20th century, the issue of holy places and particularly the sacred places in Jerusalem has been employed by nationalist politicians.\nIsraelis did not have access to the holy places in East Jerusalem during the period of Jordanian rule. Since 1975, Israel has banned Muslims from worshiping at Joseph's Tomb, a shrine considered sacred by both Jews and Muslims. Settlers established a yeshiva, installed a Torah scroll and covered the mihrab. During the Second Intifada Palestinian protesters looted and burned the site. Israeli security agencies routinely monitor and arrest Jewish extremists that plan attacks, though many serious incidents have still occurred. Israel has allowed almost complete autonomy to the Muslim trust (Waqf) over the Temple Mount.\nPalestinians have voiced concerns regarding the welfare of Christian and Muslim holy places under Israeli control. Additionally, some Palestinian advocates have made statements alleging that the Western Wall Tunnel was re-opened with the intent of causing the mosque's collapse.\nPalestinian refugees.\nPalestinian refugees are people who lost both their homes and means of livelihood as a result of the 1948 Arab\u2013Israeli conflict and the 1967 Six-Day War. The number of Palestinians who were expelled or fled from Israel was estimated at 711,000 in 1949. The descendants of all refugees (not just Palestinian refugees) are considered by the UN to also be refugees. As of 2010 there are 4.7 million Palestinian refugees. Between 350,000 and 400,000 Palestinians were displaced during the 1967 Arab\u2013Israeli war. A third of the refugees live in recognized refugee camps in Jordan, Lebanon, Syria, the West Bank and the Gaza Strip. The remainder live in and around the cities and towns of these host countries. Most Palestinian refugees were born outside Israel and are not allowed to live in any part of historic Palestine.\nIsrael has since 1948 prevented the return of Palestinian refugees and refused any settlement permitting their return except in limited cases. On the basis of the Universal Declaration of Human Rights and UN General Assembly Resolution 194, Palestinians claim the right of refugees to return to the lands, homes and villages where they lived before being driven into exile in 1948 and 1967. Arafat himself repeatedly assured his American and Israeli interlocutors at Camp David that he primarily sought the principle of the right of return to be accepted, rather than the full right of return, in practice.\nPalestinian and international authors have justified the right of return of the Palestinian refugees on several grounds:\nSeveral scholars included in the broader New Historians argue that the Palestinian refugees fled or were chased out or expelled by the actions of the Haganah, Lehi and Irgun, Zionist paramilitary groups. A number have also characterized this as an ethnic cleansing. The New Historians cite indications of Arab leaders' desire for the Palestinian Arab population to stay put.\nThe Israeli Law of Return that grants citizenship to people of Jewish descent has been described as discriminatory against other ethnic groups, especially Palestinians that cannot apply for such citizenship under the law of return, to the territory which they were expelled from or fled during the course of the 1948 war.\nAccording to the UN Resolution 194, adopted in 1948, \"the refugees wishing to return to their homes and live at peace with their neighbours should be permitted to do so at the earliest practicable date, and that compensation should be paid for the property of those choosing not to return and for loss of or damage to property which, under principles of international law or in equity, should be made good by the Governments or authorities responsible.\" UN Resolution 3236 \"reaffirms also the inalienable right of the Palestinians to return to their homes and property from which they have been displaced and uprooted, and calls for their return\". Resolution 242 from the UN affirms the necessity for \"achieving a just settlement of the refugee problem\"; however, Resolution 242 does not specify that the \"just settlement\" must or should be in the form of a literal Palestinian right of return.\nHistorically, there has been debate over the relative impact of the causes of the 1948 Palestinian exodus, although there is a wide consensus that violent expulsions by Zionist and Israeli forces were the main factor. Other factors include psychological warfare and Arab sense of vulnerability. Notably, historian Benny Morris states that most of Palestine's 700,000 refugees fled because of the \"flail of war\" and expected to return home shortly after a successful Arab invasion. He documents instances in which Arab leaders advised the evacuation of entire communities as happened in Haifa although recognizes that these were isolated events. In his later work, Morris considers the displacement the result of a national conflict initiated by the Arabs themselves. In a 2004 interview with Haaretz, he described the exodus as largely resulting from an atmosphere of transfer that was promoted by Ben-Gurion and understood by the military leadership. He also claimed that there \"are circumstances in history that justify ethnic cleansing\". Morris has been criticized by political scientist Norman Finkelstein for having seemingly changed his views for political, rather than historical, reasons.\nAlthough Israel accepts the right of the Palestinian Diaspora to return into a new Palestinian state, Israel insists that the return of this population into the current state of Israel would threaten the stability of the Jewish state; an influx of Palestinian refugees would lead to the end of the state of Israel as a Jewish state since a demographic majority of Jews would not be maintained.\nIsraeli security concerns.\nThroughout the conflict, Palestinian violence has been a concern for Israelis. Security concerns have historically been a key driver in Israeli political decision making, often expanding in scope and taking precedence over other considerations such as international law and Palestinian human rights. The occupation of the West Bank, Gaza, East Jerusalem and the continued expansion of settlements in those areas have been justified on security grounds.\nIsrael, along with the United States and the European Union, refer to any use of force by Palestinian groups as terroristic and criminal. The United Nations General Assembly resolution A/RES/45/130 reflects an international consensus (113 out of 159 voting nations voted in favor, 13 voted against) affirming Palestinians' legitimacy, as a people under foreign occupation, to use armed struggle to resist said occupation.\nIn Israel, Palestinian suicide bombers have targeted civilian buses, restaurants, shopping malls, hotels and marketplaces. From 1993 to 2003, 303 Palestinian suicide bombers attacked Israel. In 1994, Hamas initiated their first lethal suicide attack in response to the cave of the Patriarchs massacre where American-Israeli physician Baruch Goldstein opened fire in a mosque, killing 29 people and injuring 125.\nThe Israeli government initiated the construction of a security barrier following scores of suicide bombings and terrorist attacks in July 2003. Israel's coalition government approved the security barrier in the northern part of the green line between Israel and the West Bank. According to the IDF, since the erection of the fence, terrorist acts have declined by approximately 90%. The decline in attacks can also be attributed to the permanent presence of Israeli troops inside and around Palestinian cities and increasing security cooperation between the IDF and the Palestinian Authority during this period. The barrier followed a route that ran almost entirely through land occupied by Israel in June 1967, unilaterally seizing more than 10% of the West Bank, including whole neighborhoods and settlement blocs, while splitting Palestinian villages in half with immediate effects on Palestinians' freedom of movement. The barrier, in some areas, isolated farmers from their fields and children from their schools, while also restricting Palestinians from moving within the West Bank or pursuing employment in Israel.\nIn 2004 the International Court of Justice ruled that the construction of the barrier violated the Palestinian right to self-determination, contravened the Fourth Geneva Convention, and could not be justified as a measure of Israeli self-defense. The ICJ further expressed that the construction of the wall by Israel could become a permanent fixture, altering the status quo. Israel's High Court, however, disagreed with the ICJ's conclusions, stating that they lacked a factual basis. Several human rights organizations, including B'Tselem, Human Rights Watch, and Amnesty International, echoed the ICJ's concerns. The groups suggested that the wall's route was designed to perpetuate the existence of settlements and facilitate their future annexation into Israel, and that the wall was a means for Israel to consolidate control over land used for illegal settlements. The sophisticated structure of the wall also indicated its likely permanence.\nSince 2001, the threat of Qassam rockets fired from Palestinian territories into Israel continues to be of great concern for Israeli defense officials. In 2006\u2014the year following Israel's disengagement from the Gaza Strip\u2014the Israeli government claimed to have recorded 1,726 such launches, more than four times the total rockets fired in 2005. As of January 2009, over 8,600 rockets have been launched, causing widespread psychological trauma and disruption of daily life. As a result of these attacks, Israelis living in southern Israel have had to spend long periods in bomb shelters. The relatively small payload carried on these rockets, Israel's advanced early warning system, American-supplied anti-missile capabilities, and network of shelters made the rockets rarely lethal. In 2014, out of 4,000 rockets fired from the Gaza Strip, only six Israeli civilians were killed. For comparison, the payload carried on these rockets is smaller than Israeli tank shells, of which 49,000 were fired in Gaza in 2014.\nThere is significant debate within Israel about how to deal with the country's security concerns. Options have included military action (including targeted killings and house demolitions of terrorist operatives), diplomacy, unilateral gestures toward peace, and increased security measures such as checkpoints, roadblocks and security barriers. The legality and the wisdom of all of the above tactics have been called into question by various commentators.\nSince mid-June 2007, Israel's primary means of dealing with security concerns in the West Bank has been to cooperate with and permit United States-sponsored training, equipping, and funding of the Palestinian Authority's security forces, which with Israeli help have largely succeeded in quelling West Bank supporters of Hamas.\nWater resources.\nIn the Middle East, water resources are of great political concern. Israel receives approximately half of its water from desalination plants. Much of the remainder comes from two large underground aquifers which continue under the Green Line, the use of this water has been contentious in the Israeli\u2013Palestinian conflict. Israel withdraws most water from these areas, but it also supplies the West Bank with approximately 40million cubic metres annually, contributing to 77% of Palestinians' water supply in the West Bank, which is to be shared for a population of about 2.6 million.\nWhile Israel's consumption of this water has decreased since it began its occupation of the West Bank, it still consumes the majority of it: in the 1950s, Israel consumed 95% of the water output of the Western Aquifer, and 82% of that produced by the Northeastern Aquifer. Although this water was drawn entirely on Israel's own side of the pre-1967 border, the sources of the water are nevertheless from the shared groundwater basins located under both West Bank and Israel.\nIn the Oslo II Accord, both sides agreed to maintain \"existing quantities of utilization from the resources.\" In so doing, the Palestinian Authority established the legality of Israeli water production in the West Bank, subject to a Joint Water Committee (JWC). Moreover, Israel obligated itself in this agreement to provide water to supplement Palestinian production, and further agreed to allow additional Palestinian drilling in the Eastern Aquifer, also subject to the Joint Water Committee. The water that Israel receives comes mainly from the Jordan River system, the Sea of Galilee and two underground sources. According to a 2003 BBC article the Palestinians lack access to the Jordan River system.\nAccording to a report of 2008 by the Food and Agriculture Organization of the United Nations, water resources were confiscated for the benefit of the Israeli settlements in the Ghor. Palestinian irrigation pumps on the Jordan River were destroyed or confiscated after the 1967 war and Palestinians were not allowed to use water from the Jordan River system. Furthermore, the authorities did not allow any new irrigation wells to be drilled by Palestinian farmers, while it provided fresh water and allowed drilling wells for irrigation purposes at the Jewish settlements in the West Bank and Gaza Strip.\nA report was released by the UN in August 2012 and Max Gaylard, the UN Resident and Humanitarian Coordinator in the occupied Palestinian territory, explained at the launch of the publication: \"Gaza will have half a million more people by 2020 while its economy will grow only slowly. In consequence, the people of Gaza will have an even harder time getting enough drinking water and electricity, or sending their children to school\". Gaylard present alongside Jean Gough, of the UN Children's Fund (UNICEF), and Robert Turner, of the UN Relief and Works Agency for Palestinian Refugees in the Near East (UNRWA). The report projects that Gaza's population will increase from 1.6 million people to 2.1 million people in 2020, leading to a density of more than 5,800 people per square kilometre.\nWater infrastructure financing.\nNumerous foreign nations and international organizations have established bilateral agreements with the Palestinian and Israeli water authorities. It was estimated that a future investment of about US$1.1bn for the West Bank and $0.8bn for the Gaza Strip Southern Governorates was needed for the planning period from 2003 to 2015.\nIn late 2012, a donation of $21.6 million was announced by the Government of the Netherlands\u2014the Dutch government stated that the funds would be provided to the UN Relief and Works Agency for Palestinian Refugees in the Near East (UNRWA), for the specific benefit of Palestinian children. An article, published by the UN News website, stated that: \"Of the $21.6 million, $5.7 will be allocated to UNRWA's 2012 Emergency Appeal for the occupied Palestinian territory, which will support programmes in the West Bank and Gaza aiming to mitigate the effects on refugees of the deteriorating situation they face.\"\nAgricultural rights.\nThe conflict has been about land since its inception. When Israel became a state after the war in 1948, 77% of Palestine's land was used for the creation on the state. The majority of those living in Palestine at the time became refugees in other countries and this first land crisis became the root of the Israeli\u2013Palestinian conflict. Because the root of the conflict is with land, the disputes between Israel and Palestine are well-manifested in the agriculture of Palestine.\nIn Palestine, agriculture is a mainstay in the economy. The production of agricultural goods supports the population's sustenance needs and fuels Palestine's export economy. According to the Council for European Palestinian Relations, the agricultural sector formally employs 13.4% of the population and informally employs 90% of the population. Over the past 10 years, unemployment rates in Palestine have increased and the agricultural sector became the most impoverished sector in Palestine. Unemployment rates peaked in 2008 when they reached 41% in Gaza.\nPalestinian agriculture suffers from numerous problems including Israeli military and civilian attacks on farms and farmers, blockades to exportation of produce and importation of necessary inputs, widespread confiscation of land for nature reserves as well as military and settler use, confiscation and destruction of wells, and physical barriers within the West Bank.\nIsrael's West Bank barrier.\nWith the construction of the separation barrier, the Israeli state promised free movement across regions. However, border closures, curfews, and checkpoints has significantly restricted Palestinian movement. In 2012, there were 99 fixed check points and 310 flying checkpoints. The border restrictions impacted the imports and exports in Palestine and weakened the industrial and agricultural sectors because of the constant Israeli control in the West Bank and Gaza. In order for the Palestinian economy to be prosperous, the restrictions on Palestinian land must be removed. According to \"The Guardian\" and a report for World Bank, the Palestinian economy lost $3.4bn (%35 of the annual GDP) to Israeli restrictions in the West Bank alone.\nPalestinian violence outside of Israel.\nSome Palestinians have committed violent acts over the globe on the pretext of a struggle against Israel.\nDuring the late 1960s, groups affiliated with the PLO became increasingly infamous for its use of international terror. In 1969 alone, these groups were responsible for hijacking 82 planes. El Al Airlines became a regular hijacking target. The hijacking of Air France Flight 139 by the Popular Front for the Liberation of Palestine culminated during a hostage-rescue mission, where Israeli special forces successfully rescued the majority of the hostages.\nOne of the most well-known and notorious terrorist acts was the capture and eventual murder of 11 Israeli athletes by the Black September Organization during the 1972 Summer Olympics.\nPalestinian-on-Palestinian violence.\nFighting among rival Palestinian and Arab movements has played a crucial role in shaping Israel's security policy towards Palestinian militants, as well as in the Palestinian leadership's own policies. As early as the 1930s revolts in Palestine, Arab forces fought each other while also skirmishing with Zionist and British forces, and internal conflicts continue to the present day.\nIn the First Intifada, more than a thousand Palestinians were killed in a campaign initiated by the Palestine Liberation Organization to crack down on suspected Israeli security service informers and collaborators. The Palestinian Authority was strongly criticized for its treatment of alleged collaborators, rights groups complaining that those labeled collaborators were denied fair trials. According to a report released by the Palestinian Human Rights Monitoring Group, less than 45 percent of those killed were actually guilty of informing for Israel.\nOverriding authority and international status.\nAs far as Israel is concerned, the jurisdiction of the Palestinian Authority is derived from the Oslo Accords, signed with the PLO, under which it acquired control over cities in the Palestinian territories (Area A) while the surrounding countryside came either under Israeli security and Palestinian civil administration (Area B) or complete Israeli civil administration (Area C). Israel has built additional highways to allow Israelis to traverse the area without entering Palestinian cities in Area A. The initial areas under Palestinian Authority control are diverse and non-contiguous. The areas have changed over time by subsequent negotiations, including Oslo II, Wye River and Sharm el-Sheik. According to Palestinians, the separated areas make it impossible to create a viable nation and fails to address Palestinian security needs; Israel has expressed no agreement to withdrawal from some Areas B, resulting in no reduction in the division of the Palestinian areas, and the institution of a safe pass system, without Israeli checkpoints, between these parts.\nUnder the Oslo Accords, as a security measure, Israel has insisted on its control over all land, sea and air border crossings into the Palestinian territories, and the right to set import and export controls. This is to enable Israel to control the entry into the territories of materials of military significance and of potentially dangerous persons.\nThe PLO's objective for international recognition of the State of Palestine is considered by Israel as a provocative \"unilateral\" act that is inconsistent with the Oslo Accords.\nEconomic disputes and boycotts.\nIn Gaza, the agricultural market suffers from economic boycotts and border closures and restrictions placed by Israel. \nAfter Hamas' victory in the 2006 Palestinian legislative election, Israel imposed economic sanctions against the Palestinian Authority. The sanctions were a result of Hamas refusing to recognize Israel, disavow violent actions, and accept previous agreements between Israel and the PA, including the Oslo Accords. The PA's Minister of Agriculture estimates that around US$1.2 billion were lost in September 2006 because of these security measures. As a result, as of 2007[ [update]], the PA's 160,000 employees had not received their salaries in over one year.\nFatalities.\nStudies provide aggregated casualty data for the Israeli\u2013Palestinian conflict. According to the Stockholm International Peace Research Institute, 13,000 Israelis and Palestinians were killed in the conflict between 1948 and 1997. Other estimates give 14,500 killed between 1948 and 2009. During the 1982 Lebanon War, Israel killed an estimated 20,000 Palestinians and Lebanese, not including the 800\u20133,500 Palestinians killed in the Sabra-Shatila Massacre.\nAccording to B'tselem, during the first intifada from 1987 until 2000, 1,551 Palestinians and 421 Israelis lost their lives. According to the database of the UNOffice for the Coordination of Humanitarian Affairs \u2013 occupied Palestinian territory (OCHAoPt), 6,407 Palestinians and 308 Israelis were killed in the conflict from 2008 to September 2023, before the Gaza war.\nFigures include both Israeli civilians and security forces casualties in West Bank, Gaza and Israel. All numbers refer to casualties of direct conflict between Israelis and Palestinians including in IDF military operations, artillery shelling, search and arrest campaigns, barrier demonstrations, targeted killings, settler violence etc. The figures do not include events indirectly related to the conflict such as casualties from unexploded ordnance, etc., or events when the circumstances remain unclear or are in dispute. The figures include all reported casualties of all ages and both genders.\nAs reported by the Israeli human rights group B'Tselem, from 29 September 2000 to the year 2010, a total of 7,454 Palestinian and Israeli individuals were killed due to the conflict. According to the report, 1,317 of the 6,371 Palestinians were minors, and at least 2,996 did not participate in fighting at the time of death. Palestinians killed 1,083 Israelis, including 741 civilians, of whom 124 were minors.\nOn 7 October 2023, Hamas-led militant groups launched a surprise attack on Israel, in which 1,195 Israelis and foreign nationals, including 815 civilians, were killed, and 251 taken hostage. Since the start of Gaza war, over 52,000 Palestinians in Gaza have been reported as killed, over half of them women and children, and more than 110,000 Palestinians have been injured. A study in \"the Lancet\" estimated 64,260 deaths due to traumatic injuries by June 2024, while noting a larger potential death toll when \"indirect\" deaths are included. Israel's tightened blockade of Gaza cut off basic necessities, causing a severe hunger crisis with a high risk of famine persisting as of \u00a02025[ [update]].\nCriticism of casualty statistics.\nThe Israeli-based International Policy Institute for Counter-Terrorism (ICT) claimed that Israeli and Palestinian human rights groups overestimated the percentage of civilians killed since the IDF suspected many of those killed to be possible militants.\nDuring Operation Cast Lead, Israeli figures reported the number of Palestinians killed at 1,166 Palestinian, 60 percent were classified as \"terrorists\" by Israeli officials. This discrepancy is partially due to Israel's classification of Gazan police, who did not take part in hostilities, as combatants. The broad consensus among human rights organizations is that these police were primarily civilians, as they did not actively participate in hostilities nor were they part of armed groups. The accuracy of Israeli casualty figures was further questioned based on the number of children killed. Israel reported 89 Palestinian minors killed, whereas the human rights organization B'Tselem reported 252, substantiating their figures with birth and death certificates and other documents in almost all cases. The Israeli figures also stand out against the figures published by the US Department of State, which reported the number killed \"at close to 1,400 Palestinians, including more than 1,000 civilians.\"\nLandmines and unexploded ordnance.\nA comprehensive collection mechanism to gather land mine and explosive remnants of war (ERW) casualty data does not exist for the Palestinian territories. In 2009, the United Nations Mine Action Centre reported that more than 2,500 mine and explosive remnants of war casualties occurred between 1967 and 1998, at least 794 casualties (127 killed, 654 injured and 13 unknown) occurred between 1999 and 2008 and that 12 people had been killed and 27 injured since the Gaza War. The UN Mine Action Centre identified the main risks as coming from \"ERW left behind by Israeli aerial and artillery weapon systems, or from militant caches targeted by the Israeli forces.\" There are at least 15 confirmed minefields in the West Bank on the border with Jordan. The Palestinian National Security Forces do not have maps or records of the minefields.\nPublic opinion.\nDomestic.\nIn a Pew Research Center poll in June 2025, Israelis have been found to be more skeptical of peaceful coexistence with Palestinians than before, with a decrease from 50% in 2013 to just 21% in 2025.\nIn 2021, Jerusalem Media and Communications Centre conducted two polls among Palestinians, one before the 2021 Israel\u2013Palestine crisis in April and the other after it in October. The polls showed support for two-state solution decreased from 39% in April to 29% in October.\nThe trend of decline in support for the two-state solution have been shown to be similar among both Jewish Israelis and Palestinians, with support dropping from 53% and 51% respectively in 2016 to just 34% and 33% in 2022. There are differences within each population though, with secular respondents from both sides, supporters of Fatah or third parties among Palestinians, and supporters of moderate left among Israelis more likely than others to support a two-state solution. Additionally, Arab Israelis have also been shown to generally be much more supportive of a two-state solution compared to Jewish Israelis or Palestinians.\nInternational.\nIn a Pew Research Center poll in 2022, a majority of Americans view positively both the Israeli people (67%) and the Palestinian people (52%). However, views of respective governments are lower for both the government of Israel (48%) and government of Palestine (28%). Regarding the resolution of conflict, 35% support a two-state solution, 27% support some form of one-state solution, and 37% are unsure.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\nUnited Nations\nAcademic, news, and similar sites (excluding Israeli or Palestinian sources)\nConflict resolution groups\nHuman rights groups\nJewish and Israeli academic, news, and similar sites\nJewish and Israeli \"peace movement\" news and advocacy sites\nOther sites"}
{"id": "46223", "revid": "1313965535", "url": "https://en.wikipedia.org/wiki?curid=46223", "title": "Sowing", "text": "Planting of seeds or other propagules in the ground for germination\nSowing is the process of planting seeds. An area that has had seeds planted in it will be described as a sowed or sown area.\nPlants which are usually sown.\nAmong the major field crops, oats, wheat, and rye are sown, grasses and legumes are seeded and maize and soybeans are planted. In planting, wider rows (generally 75 cm (30 in) or more) are used, and the intent is to have precise; even spacing between individual seeds in the row, various mechanisms have been devised to count out individual seeds at exact intervals.\nDepth of sowing.\nIn sowing, little if any soil is placed over the seeds, as seeds can be generally sown into the soil by maintaining a planting depth of about 2-3 times the size of the seed.\nSowing types and patterns.\nFor hand sowing, several sowing types exist; these include:\nSeveral patterns for sowing may be used together with these types; these include:\nTypes of sowing.\nHand sowing.\nHand sowing or (planting) is the process of casting handfuls of seed over prepared ground: broadcasting, that is, broadcast seeding (from which the technological term is derived). Usually, a drag or harrow is employed to incorporate the seed into the soil. Though labor-intensive for any but small areas, this method is still used in some situations. Practice is required to sow evenly and at the desired rate. A hand seeder can be used for sowing, though it is less of a help than it is for the smaller seeds of grasses and legumes.\nHand sowing may be combined with pre-sowing in seed trays. This allows the plants to come to strength indoors during cold periods (e.g. spring in temperate countries).\nSeed drill.\nIn agriculture, most seed is now sown using a seed drill, which offers the best precision; seed is sown evenly and at the desired rate. The drill also places the seed at a measured distance below the soil, so that less seed is required. The standard design uses a fluted feed metering system, which is volumetric in nature; individual seeds are not counted. Rows are typically about 10\u201330\u00a0cm apart, depending on the crop species and growing conditions. Several row opener types are used depending on soil type and local tradition. Grain drills are most often drawn by tractors, but can also be pulled by horses. Pickup trucks are sometimes used, since little draft is required.\nA seed rate of about 100\u00a0kg of seed per hectare (2 bushels per acre) is typical, though rates vary considerably depending on crop species, soil conditions, and farmer's preference. Excessive rates can cause the crop to lodge, while too thin a rate will result in poor utilisation of the land, competition with weeds and a reduction in the yield.\nOpen field.\nOpen-field planting refers to the form of sowing used historically in the agricultural context whereby fields are prepared generically and left open, as the name suggests, before being sown directly with seed. The seed is frequently left uncovered at the surface of the soil before germinating and therefore exposed to the prevailing climate and conditions like storms etc. This is in contrast to the seedbed method used more commonly in domestic gardening or more specific (modern) agricultural scenarios where the seed is applied beneath the soil surface and monitored and manually tended frequently to ensure more successful growth rates and better yields.\nPre-treatment of seed and soil before sowing.\nBefore sowing, certain seeds first require a treatment prior to the sowing process.\nThis treatment may be seed scarification, stratification, seed soaking or seed cleaning with cold (or medium hot) water.\nSeed soaking is generally done by placing seeds in medium hot water for at least 24 to up to 48 hours\nSeed cleaning is done especially with fruit, as the flesh of the fruit around the seed can quickly become prone to attack from insects or plagues. Seed washing is generally done by submerging cleansed seeds 20 minutes in 50 degree Celsius water. This (rather hot than moderately hot) water kills any organisms that may have survived on the skin of a seed. Especially with easily infected tropical fruit such as lychees and rambutans, seed washing with high-temperature water is vital.\nIn addition to the mentioned seed pretreatments, seed germination is also assisted when a disease-free soil is used. Especially when trying to germinate difficult seed (e.g. certain tropical fruit), prior treatment of the soil (along with the usage of the most suitable soil; e.g. potting soil, prepared soil or other substrates) is vital. The two most used soil treatments are pasteurisation and sterilisation. Depending on the necessity, pasteurisation is to be preferred as this does not kill all organisms. Sterilisation can be done when trying to grow truly difficult crops. To pasteurise the soil, the soil is heated for 15 minutes in an oven of 120\u00a0\u00b0C.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46224", "revid": "50759295", "url": "https://en.wikipedia.org/wiki?curid=46224", "title": "16 mm film", "text": "Historically popular gauge of film\n16\u00a0mm film is a historically popular and economical gauge of film. 16\u00a0mm refers to the width of the film (about &lt;templatestyles src=\"Fraction/styles.css\" /&gt;2\u20443 inch); other common film gauges include 8 mm and 35\u00a0mm. It is generally used for non-theatrical (e.g., industrial, educational, television) film-making, or for low-budget motion pictures. It also existed as a popular amateur or home movie-making format for several decades, alongside 8\u00a0mm film and later Super 8 film. Eastman Kodak released the first 16\u00a0mm \"outfit\" in 1923, consisting of a Cin\u00e9-Kodak camera, Kodascope projector, tripod, screen and splicer, for US$335 (). RCA-Victor introduced a 16\u00a0mm sound movie projector in 1932, and developed an optical sound-on-film 16\u00a0mm camera, released in 1935.\nHistory.\nEastman Kodak introduced 16\u00a0mm film in 1923, as a less expensive alternative to 35\u00a0mm film for amateurs. The same year the Victor Animatograph Corporation started producing their own 16\u00a0mm cameras and projectors. During the 1920s, the format was often referred to by the professional industry as 'sub-standard'.\nKodak hired Willard Beech Cook from his 28 mm Pathescope of America company to create the new 16\u00a0mm 'Kodascope Library'. In addition to making home movies, people could buy or rent films from the library, a key selling aspect of the format.\nIntended for amateur use, 16\u00a0mm film was one of the first formats to use acetate safety film as a film base. Kodak never used nitrate film for the format, owing to the high flammability of the nitrate base. Kodak discontinued all nitrate base use in 1952.\nProduction evolution.\nThe silent 16\u00a0mm format was initially aimed at the home enthusiast, but by the 1930s it had begun to make inroads into the educational market. The addition of optical sound tracks and, most notably, Kodachrome in 1935, gave an enormous boost to its popularity. The format was used extensively during World War II, and there was a huge expansion of 16\u00a0mm professional filmmaking in the post-war years. Films for government, business, medical and industrial clients created a large network of 16\u00a0mm professional filmmakers and related service industries in the 1950s and 1960s. The advent of television production also enhanced the use of 16\u00a0mm film, initially for its advantage of cost and portability over 35\u00a0mm. At first used as a news-gathering format, the 16\u00a0mm format was also used to create television programming shot outside the confines of the more rigid television studio production sets. The home movie market gradually switched to the even less expensive 8 mm and Super 8 mm film formats.\n16\u00a0mm, using light cameras, was extensively used for television production in many countries before portable video cameras appeared. In Britain, the BBC's Ealing-based film department made significant use of 16mm film and, during its peak, employed over 50 film crews. Throughout much of the 1960s\u20131990s period, these crews made use of cameras such as the Arriflex ST and Eclair NPR in combination with quarter-inch sound recorders, such as the Nagra III. Using these professional tools, film department crews would work on some of the most significant programmes produced by the BBC, including \"Man Alive\", \"Panorama\" and \"Chronicle\". Usually made up of five people, these small crews were able to work incredibly efficiently and, even in hostile environments, were able to film an entire programme with a shooting ratio of less than 5:1.\nBeginning in the 1950s, news organizations and documentarians in the United States frequently shot on portable Auricon and, later, CP-16 cameras that were self-blimped and had the ability to record sound directly on film. The introduction of magnetic striped film further improved sound fidelity.\nReplacing analog video devices, digital video has made significant inroads in television production use. Nevertheless, 16\u00a0mm is still in use in its Super 16 ratio (see below) for productions seeking its specific look.\nFormat standards.\nPerforations.\nTwo perforation pitches are available for 16\u00a0mm film. One specification, known as \"long pitch\", has a spacing of and is used primarily for print and reversal film stocks. Negative and intermediate film stocks have perforations spaced , known as \"short pitch\". These differences allow for the sharpest and smoothest possible image when making prints using a contact printer.\nFilm stocks are available in either 'single-perf' or 'double-perf', meaning the film is perforated on either one or both edges. A perforation for 16\u00a0mm film is with a radius curve on all four corners of . Tolerances are \u00b1.\nStandard 16 mm.\nThe picture-taking area of standard 16\u00a0mm is , an aspect ratio of , the standard pre-widescreen Academy ratio for 35\u00a0mm. The \"nominal\" picture projection area (per SMPTE RP 20-2003) is 0.380 in by 0.284 in, and the maximum picture projection area (per SMPTE ST 233-2003) is 0.384 in by 0.286 in, each implying an aspect ratio of 1.34:1. Double-perf 16\u00a0mm film, the original format, has a perforation at both sides of every frame line. Single-perf is perforated at one side only, making room for an optical or magnetic soundtrack along the other side.\nSuper 16 mm.\nThe variant called Super 16\u00a0mm, Super 16, or 16\u00a0mm Type W is an adaptation of the 1.66 (1.66:1 or 15:9) aspect ratio of the \"Paramount format\" to 16\u00a0mm film. It was developed by Swedish cinematographer Rune Ericson in 1969, using single-sprocket film and taking advantage of the extra room for an expanded picture area of , giving an aspect ratio of .\nSuper 16 cameras are usually 16\u00a0mm cameras that have had the film gate and ground glass in the viewfinder modified for the wider frame, and, since this process widens the frame by affecting only one side of the film, the various cameras' front mounting plate or turret areas must also be re-machined to shift and re-center the mounts for any lenses used. Because the resulting, new, Super 16 aspect ratio takes up the space originally reserved for the 16mm soundtrack, films shot in this format must be enlarged by optical printing to 35 mm for sound-projection, and, in order to preserve the proper 1.66:1, or (slightly cropped) 1.85:1 theatrical aspect ratios which this format was designed to provide. And, with the recent development of digital intermediate workflows, it is now possible to digitally enlarge to a 35\u00a0mm sound print with virtually no quality loss (given a high quality digital scan), or alternatively to use high-quality video equipment for the original image capture.\nIn 2009, German lens manufacturer Vantage introduced a series of anamorphic lenses under its HAWK brand. These provided a 1.30x squeeze factor (as opposed to the standard 2\u00d7) specifically for the Super 16 format, allowing nearly all of the Super 16 frame to be used for 2.39:1 widescreen photography.\nUltra 16 mm.\nThe DIY-crafted Ultra 16 is a variation of Super 16. Cinematographer Frank G. DeMarco is credited with inventing Ultra 16 in 1996 while shooting tests for Darren Aronofsky's \"Pi\". Ultra 16 is created by widening the left and right sides of the gate of a standard 16\u00a0mm camera by 0.7\u00a0mm to expose part of the horizontal area between the perforations. Perforation placement on standard 16\u00a0mm film at the divisions between frames accommodates use of these normally unexposed areas.\nThe Ultra 16 format, with frame dimensions of , provides a frame size between standard 16\u00a0mm and Super 16\u2014while avoiding the expense of converting a 16\u00a0mm camera to Super 16, the larger lens-element requirements for proper aperture field coverage on Super 16 camera conversions, and, the potential image vignetting caused by trying to use some \"conventional\" 16\u00a0mm lenses on those Super 16 converted cameras. Thus, almost all standard 16\u00a0mm optics can now achieve the wider image in Ultra 16, but without the above pitfalls and optical \"shortcomings\" encountered when attempting their use for Super 16.\nThe frame has an aspect ratio of , which readily converts to NTSC/PAL (1.33 ratio), HDTV (1.78 ratio) and to 35\u00a0mm film (1.66 [European] and 1.85 wide screen ratios), using either the full vertical frame, or the full width (intersprocket) frame, and at times, portions of both, depending upon the required application.\nModern usage.\nThe only suppliers of 16\u00a0mm color reversal/negative film in 2022 are Kodak and Orwo. Agfa and Fuji closed their film manufacturing facilities in the 2010s. B&amp;W films are still produced by Kodak, Foma and ORWO/Filmotec, with ORWO/Filmotec having begun sales of a new color negative film in May of 2022.\n16\u00a0mm film is used in television, such as for the \"Hallmark Hall of Fame\" anthology (it has since been produced in 16:9 high definition) and \"Friday Night Lights\" and \"The O.C.\" as well as \"The Walking Dead\" in the US. In the UK, the format is exceedingly popular for television series such as \"Doc Martin\", dramas and commercials.\nThe British Broadcasting Corporation (BBC) played a large part in the development of the format. It worked extensively with Kodak during the 1950s and 1960s to bring 16\u00a0mm to a professional level, since the BBC needed cheaper, more portable production solutions while maintaining a higher quality than was offered at the time, when the format was mostly for home display of theatrical shorts, newsreels, and cartoons, documentary capture and display for various purposes (including education), and limited \"high end\" amateur use.\nAs of 2016[ [update]], the format was frequently used for student films, while its use in documentaries had almost disappeared. With the advent of HDTV, Super 16 film is still used for some productions destined for HD. Some low-budget theatrical features are shot on 16\u00a0mm and super 16\u00a0mm such as Kevin Smith's 16\u00a0mm 1994 independent hit \"Clerks,\" or \"Man Bites Dog\", \"Mid90s\" and \"Closer to Home\".\nThanks to advances in film stock and digital technology\u2014specifically digital intermediate (DI)\u2014the format has dramatically improved in picture quality since the 1970s, and is now a revitalized option. \"Vera Drake\", for example, was shot on Super 16\u00a0mm film, digitally scanned at a high resolution, edited and color graded, and then printed out onto 35\u00a0mm film via a laser film recorder. Because of the digital process, the final 35\u00a0mm print quality is good enough to fool some professionals into thinking it was shot on 35\u00a0mm.\nIn Britain, most exterior television footage was shot on 16\u00a0mm from the 1960s until the 1990s, when the development of more portable television cameras and videotape machines led to video replacing 16\u00a0mm in many instances. Many drama shows and documentaries were made entirely on 16\u00a0mm, notably \"Brideshead Revisited\", \"The Jewel in the Crown\", \"The Ascent of Man\", \"Life on Earth\", and the early seasons of \"Poirot\". More recently, the advent of widescreen television has led to the use of \"Super\" 16. For example, the 2008 BBC fantasy drama series \"Merlin\" was shot in Super 16.\nAs recently as 2010, \"Scrubs\" was shot on Super16 and aired either as 4:3 SD (first 7 seasons) or as 16:9 HD (seasons 8 and 9). John Inwood, the cinematographer of the series, believed that footage from his Aaton XTR Prod camera was not only sufficient to air in high definition, it \"looked terrific\".\nThe Academy Award winning \"Leaving Las Vegas\" (1995) was shot on 16\u00a0mm.\nThe first two seasons of \"Buffy the Vampire Slayer\" were shot on 16\u00a0mm and switched to 35\u00a0mm for its later seasons.\nThe first season of \"Sex and the City\" was shot on 16\u00a0mm. Later seasons were shot on 35\u00a0mm. All three seasons of \"Veronica Mars\" were shot on 16\u00a0mm and aired in HD. \"This Is Spinal Tap\", and Christopher Guest's subsequent mockumentary films, are shot in Super 16\u00a0mm.\nThe first three seasons of \"Stargate SG-1\" (bar the season 3 finale and the effects shots) were shot in 16\u00a0mm, before switching to 35\u00a0mm for later seasons.\nPeter Jackson's 1992 zombie comedy \"Braindead\" was shot on Super 16mm, so that more of its $3 million budget could be spent on its extensive gore effects.\nCatherine Hardwicke's 2003 teen drama \"Thirteen (2003 film)\" was shot on Super 16mm, due to low budget of $2 million. \nThe 2009 Academy Award winner for Best Picture, \"The Hurt Locker\", was shot using Aaton Super 16\u00a0mm cameras and Fujifilm 16\u00a0mm film stocks. The cost savings over 35\u00a0mm allowed the production to utilize multiple cameras for many shots, exposing over one million feet of film.\nBritish Napoleonic-era TV drama \"Sharpe\" was shot on Super 16\u00a0mm right through to the film \"Sharpe's Challenge\" (2006). For the last film in the series, \"Sharpe's Peril\" (2008), the producers switched to 35\u00a0mm.\n\"Moonrise Kingdom\" was shot using super 16\u00a0mm.\nDarren Aronofsky shot \"mother!\" on 16\u00a0mm.\nLinus Sandgren shot most of the 2018 biographical drama \"First Man\" on Super 16.\nSpike Lee shot the Netflix film \"Da 5 Bloods\"' flashback scenes on 16\u00a0mm film, which was part of the reason cinematographer Newton Thomas Sigel was considered for an Oscar nomination. \"The Insider\" reports that Netflix was \"initially concerned about having the movie's flashback scenes shot on grainy 16\u00a0mm film ... There was pushback because it opened up a lot of challenges.\" According to Sigel, the film stock Lee wanted to use was expensive because it is rarely used. It would be even more expensive to shoot on 16mm film while on location in Vietnam and then ship the film back to the United States to be processed at a film lab. Lee was \"pretty adamant\" about using 16mm for the flashbacks; Sigel said \"I would never have been able to do it without such fervent support from him.\" Sigel had pitched to Lee the idea to shoot the Vietnam sequences using the kind of camera and film stock that would have been available during the Vietnam era.\nCornish filmmaker Mark Jenkin is notable for using 16\u00a0mm film and a hand-cranked 1978 Bolex camera, most notably in his films \"Bait\" (2019) and \"Enys Men\" (2022).\n16mm film was also used to produce early Full-Motion Video arcade games, such as Nintendo's \"Wild Gunman\" (1974) and Kasco's \"The Driver\" (1979). These games would consist of one or more 16mm projectors that the game hardware would alternate between to display different outcomes depending on the player's actions; In single-projector systems, such as the one used in Nintendo's \"Sky Hawk\" (1976), both outcomes would appear simultaneously on the same film in split-screen, with the game instead adjusting the film's framing so that only one outcome could be seen at a time.\nDigital 16 mm.\nA number of digital cameras approximate the look of the 16\u00a0mm format by using 16\u00a0mm-sized sensors and taking 16\u00a0mm lenses. These cameras include the Ikonoskop A-Cam DII (2008) and the Digital Bolex (2012). The Blackmagic Pocket Cinema Camera (2013) and the Blackmagic Micro Cinema Camera (2015) has a Super\u00a016-sized sensor. The Z CAM E2G (2019) even offers Digital 16\u00a0mm in 4K and with a global shutter.\nCameras.\nProfessional cameras.\nThe professional industry tends to use 16\u00a0mm cameras from Aaton and Arri, most notably the Aaton Xtera, Aaton XTRprod, Arriflex 16SR3, and Arriflex 416. Aaton also released the A-Minima, which is about the size of a video camcorder and is used for specialized filming requiring smaller, more versatile cameras. Photo Sonics have special extremely high speed cameras for 16\u00a0mm that film at up to 1,000 frames per second. Panavision has produced the Panaflex 16, nicknamed \"Elaine\".\nAmateur cameras.\nFor amateur, hobbyist, and student use, it is more economical to use older models from Arri, Aaton, Auricon, Beaulieu, Bell and Howell, Bolex, Canon, Cinema Products, Eclair, Keystone, Krasnogorsk, Mitchell, and others.\nFilm reproduction methods.\nMost original movie production companies that use film shoot on 35\u00a0mm. The 35\u00a0mm size must be converted or reduced to 16\u00a0mm for 16\u00a0mm systems. There are multiple ways of obtaining a 16\u00a0mm print from 35\u00a0mm. The preferred method is to strike a 16\u00a0mm negative from the original 35\u00a0mm negative and then make a print from the new 16\u00a0mm negative. A 16\u00a0mm negative struck from the original 35\u00a0mm negative is called an \"original\". A new 16\u00a0mm print made from a print with no negative is called a \"reversal\".\n16\u00a0mm prints can be made from many combinations of size and format, each with a distinct, descriptive name:\nFilm traders often refer to 16\u00a0mm prints by the print's production method, i.e., an \"original\", \"reversal\", \"dupe down\", \"double dupe\", or \"double dupe down\".\nColor fading of old film and color recovery.\nOver time, the cyan, magenta and yellow dyes that form the image in color 16\u00a0mm film inevitably fade. The rate of deterioration depends on storage conditions and the film type. In the case of Kodachrome amateur and documentary films and Technicolor IB (imbibition process) color prints, the dyes are so stable and the deterioration so slow that even prints now over 70 years old typically show no obvious problems.\nDyes in the far more common Eastmancolor print film and similar products from other manufacturers are notoriously unstable. Prior to the introduction of a longer-lasting \"low fade\" type in 1979, Eastmancolor prints routinely suffered from easily seen color shift and fading within ten years. The dyes degrade at different rates, with magenta being the longest-lasting, eventually resulting in a pale reddish image with little if any other color discernible.\nIn the process of digitizing old color films, even badly faded source material can sometimes be restored to full color through digital techniques that amplify the faded dye colors. A digital intermediate scanned from the original negative (if it was processed and stored correctly) can often fully restore colors.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46225", "revid": "48417338", "url": "https://en.wikipedia.org/wiki?curid=46225", "title": "8 mm film", "text": "Film format historically common in amateur filmmaking\n8\u00a0mm film is a motion picture film format in which the film strip is wide. It exists in two main versions\u00a0\u2013 the original standard 8\u00a0mm film, also known as regular 8\u00a0mm, and Super 8. Although both standard 8\u00a0mm and Super 8 are 8\u00a0mm wide, Super 8 has a larger image area because of its smaller and more widely spaced perforations.\nThere are also two other varieties of Super 8 \u2013 Single 8\u00a0mm and Straight-8\u00a0\u2013 that require different cameras but produce a final film with the same dimensions.\nStandard 8.\nThe standard 8\u00a0mm (also known as regular 8 or double 8) film format was developed by the Eastman Kodak company during the Great Depression and released to the market in 1932 to create a home movie format that was less expensive than 16\u00a0mm.\nDouble 8 spools actually contain a 16 mm film with twice as many perforations along each edge as normal 16\u00a0mm film; on its first pass through the camera, the film is exposed only along half of its width. When the first pass is complete, the operator opens the camera and flips and swaps the spools (the design of the spool hole ensures that the operator does this properly) and the same film is subsequently exposed along its other edge, the edge left unexposed on the first pass. After the film is developed, the processor splits it down the middle, resulting in two lengths of 8\u00a0mm film, each with a single row of perforations along one edge. Each frame is half the width and half the height of a 16\u00a0mm frame, so there are four times the number of frames in a given film area, which is what makes it cost less. Because of the two passes of the film, the format was sometimes called \"Double 8\". The frame size of regular 8\u00a0mm is 4.8\u00a0mm \u00d7 3.5\u00a0mm, and 1 meter of film contains 264 pictures. Normally, Double 8 is filmed at 16 or 18 frames per second.\nCommon length film spools allowed filming of about 3 to &lt;templatestyles src=\"Fraction/styles.css\" /&gt;4+1\u20442 minutes at 12, 15, 16, and 18 frames per second.\nKodak ceased sales of standard 8\u00a0mm film under its own brand in the early 1990s but continued to manufacture the film, which was sold via independent film stores. Black-and-white 8\u00a0mm film is still manufactured in the Czech Republic, and several companies buy bulk quantities of 16\u00a0mm film to make regular 8\u00a0mm by re-perforating the stock, cutting it into 25 foot (7.6 m) lengths, and collecting it into special standard 8\u00a0mm spools, which they then sell. Re-perforation requires special equipment. Some specialists also produce Super 8\u00a0mm film from existing 16\u00a0mm or even 35\u00a0mm film stock.\nSound.\nWhen Eastman Kodak first conceived the 8\u00a0mm format, no provision was made for the addition of a sound track. Nevertheless, in the 1960s, projectors appeared on the market that were capable of recording and replaying sound from a magnetic stripe applied to the film after it had been processed. The only part of the film wide enough to accept such a magnetic stripe was the area between the edge and the perforations. A much narrower stripe was sometimes added to the opposite edge so that the film piled up evenly on the spool, but was never used for sound. The sound to picture separation was the same dimensionally as 16\u00a0mm film, and as that format is 28 frames, that meant that the Double-8 system was 56 frames. The proximity of the sound stripe to the perforations caused some problems in keeping the film in close contact with the sound head. There was never an optical system.\nA few sound prints appeared for use in Double 8 projectors.\nSuper 8.\nIn 1965, Super-8 film was released and was quickly adopted by many amateur film-makers. It featured a better quality image and was easier to use mainly due to a cartridge-loading system that did not require reloading and rethreading halfway through.\nTo easily differentiate Super 8 film from Standard 8, projector spools for the former had larger spindle holes. Therefore, it was not possible to mount a Super 8 spool on a Standard 8 projector, and vice versa.\nSound.\nThe Super 8 format was designed from the start to accommodate a sound track (one of the few film formats to do so). This track would occupy the area between the edge of the film and the image area. As in the double 8 system, a second stripe was sometimes added between the edge and the perforations. The image to sound distance was much shorter for the Super 8 system at just 18 frames.\nAt first, the magnetic stripe had to be applied after the film was processed and recorded on a suitable projector. In the 1970s, cameras appeared which were able to record live sound directly onto pre-striped film. This film was loaded into oversize cartridges that provided access for the camera's sound recording head. The camera would also accept non sound cartridges, but silent cameras could not accept sound cartridges. One major advantage of the Super 8 system was that as the camera pressure plate was a part of the cartridge, it could be moulded to the profile of the stripe(s) on the film.\nProjectors also appeared on the market which took advantage of the balance stripe next to the perforations by recording and replaying stereo sound.\nProjectors appeared in the late 1970s that featured the ability to play films with an optical soundtrack. The image-sound separation for the optical format was 22 frames. These were never popular in the English speaking world and are consequently very rare in those countries, but they did enjoy some popularity in the Far East and Europe mainly because optical prints were cheaper.\nSound prints in Super 8 were plentiful and considering that they were very expensive by modern-day standards, sold in appreciable quantities. A two-reel print (running approximately 17 minutes) cost around $50 with feature films costing at least $150-plus. A few prints were also released with stereo sound. In Europe, optical prints were also popular and were appreciated for their often superior sound quality. In theory, magnetic prints should have been superior, but Super 8 magnetic prints were often poorly recorded after the picture was processed, due to high-speed, mass production techniques. An optical track, on the other hand, could be printed at the same time as the image and in equivalent quality.\nSingle 8.\nAnother version of Super 8 film, Single-8, was produced by Fuji in Japan. Introduced in 1965 as an alternative to the Kodak Super 8 format, it had the same final film dimensions but with a different cassette. Unlike the co-axial design of Super 8, the Single 8 cartridge featured one spool above the other.\nSound.\nSingle 8's film format being identical to Super 8 means that everything written above regarding projectors for Super 8 applies equally to Single 8.\nCameras also appeared for the Single 8 system that were capable of directly recording to pre-striped film which was presented in an oversize Single-8 cartridge which provided access for the camera's sound recording head in a similar manner to Super 8. The only difference was that film manufacturers initially had to manufacture the film with a rebated area for the sound stripe. This was because the pressure plate ensuring good film registration was part of the camera and not the cartridge. The sound film had to be the same overall thickness as silent film which the camera could also accept. Although the rebated stock was more expensive to manufacture, a balance stripe on the opposite side of the film was rendered unnecessary and offset the cost. Fuji later developed a thinner film that did not require rebating, but the balance stripe was required because the thickness of the sound stripe was almost the same as the film base.\nStraight Eight.\nA number of camera companies offered single-width 8\u00a0mm film in magazines or spools, but the format faded when Kodak introduced Kodachrome, as this was only available in the Double 8\u00a0mm format. The first single-run 8\u00a0mm film was offered in 1935 with a Bell &amp; Howell movie camera Filmo 127-A called Straight Eight. Single-width 8\u00a0mm film revived in the United States by Bolsey-8 in 1956 and continued for some time outside the United States, with Germany Agfa Movex 8 between 1937 and 1950s and Soviet Union KOMZ Ekran movie cameras and Svema offering reversal film in 1960s.\nUltraPan 8.\nIntroduced in 2011 by Nicholas Kovats and implemented by Jean-Louis Seguin, this format uses Standard 8 film in a modified Bolex (H16 or H8) camera. Similar to the Techniscope cameras of the 1960s, UltraPan 8 achieves wider aspect ratios generally reserved for camera systems with anamorphic lenses through manipulating film negative exposure instead of light capture. The area of film exposed per frame is 10.52\u00a0mm \u00d7 3.75\u00a0mm, having an aspect ratio of 2.8:1. There are effectively two UP8 frames for every one 16\u00a0mm frame. The design means there is no waste of film emulsion for the targeted aspect ratio. Earlier versions of this general idea date from the 1950s and exactly the same design occurs in implementations of the 1960s and 1970s. The current implementation of the idea gains impetus from the relative ease with which digital delivery systems can handle what would otherwise have required, in the past, either a dedicated mechanical projector or the transfer to another film format for which projectors were already available.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46226", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=46226", "title": "Anthony Zinni", "text": "American Marine Corps general\nAnthony Charles Zinni (born September 17, 1943) is a retired United States Marine Corps general and a former Commander in Chief of the United States Central Command (CENTCOM). From 2001 to 2003, he served as a special envoy for the United States to Israel and the Palestinian Authority. From 2017 to 2019, he served as a special envoy to help resolve the Qatar diplomatic crisis.\nWhile serving as a special envoy, Zinni was also an instructor in the Department of International Studies at the Virginia Military Institute. He later served as an instructor at the Sanford School of Public Policy at Duke University, a public speaker, and an author of best-selling books on his military career and foreign affairs, including \"Battle for Peace\". As of 2005[ [update]], he was involved in the corporate world, joining M.I.C. Industries as its president for International Operations in 2005.\nZinni also serves or has served on the advisory boards of a number of companies, including the security testing firm, Mu Dynamics, based in Sunnyvale, California. He joined Duke University's Terry Sanford Institute of Public Policy in spring 2008 as the Sanford Distinguished Lecturer in Residence and taught a new course in the Hart Leadership Program. Zinni also serves on the board of directors for Caliburn International, a military contracting conglomerate that includes operations for Homestead Temporary Shelter for Unaccompanied Children.\nHe has been credited for foresight in predicting the dangers of terrorism coming out of Afghanistan before the September 11 attacks of 2001, and for supporting the Iraq War troop surge of 2007. In October 2009, he came out firmly in support of General Stanley A. McChrystal's request for up to 40,000 additional troops in Afghanistan.\nEarly life and education.\nZinni was born in Bryn Mawr, Pennsylvania and raised in Conshohocken, Pennsylvania, the son of Lilla (\"n\u00e9e\" Disabatino), a seamstress and homemaker, and Antonio Zinni, a chauffeur. His parents were of Italian descent. His father was drafted into the U.S. Army shortly after immigrating and served in World War I, being promoted to corporal and later receiving citizenship. Zinni's brother served in the Korean War.\nIn 1965, Zinni graduated from Villanova University with a B.S. degree in economics and was commissioned a second lieutenant in the United States Marine Corps. He later earned an M.A. degree in management and supervision from Central Michigan University in 1984 and a second M.A. degree in international relations from Salve Regina College in 1987. Zinni graduated from the Marine Corps Command and Staff College in 1978 and the National War College in 1984. He attended the John F. Kennedy Special Warfare Center and School in 1967 and the Amphibious Warfare School in 1970. In 2023, Zinni was awarded an honorary degree from Salve Regina University.\nCareer.\nU.S. Marine Corps.\nAfter completion of the Basic School in 1965, Zinni was assigned to the 2nd Marine Division, where he served as a platoon commander, company executive officer, and company commander in the 1st Battalion, 6th Marines. He also served as a company commander in the 1st Infantry Training Regiment during this tour. In 1967, Zinni was assigned as an infantry battalion advisor to the Vietnamese Marine Corps. Following his service in the Vietnam War, he was ordered to the Basic School where he served as a tactics instructor, platoon commander, and company executive officer. In 1970, he returned to Vietnam as a company commander in 1st Battalion, 5th Marines where he was wounded, evacuated, and subsequently assigned to the 3rd Force Service Support Group on Okinawa. There he served as a company commander and guard officer. In 1971, Zinni returned to the 2nd Marine Division, where he served as a company commander in the 1st Battalion, 8th Marines, Aide de Camp to the Commanding General, and Officer in Charge of the Infantry Training Center. In 1974, he was assigned to Headquarters Marine Corps, where he was assigned as the Retention and Release Officer and Plans Officer in the Officer Assignment Branch of the Manpower Department.\nZinni again served in the 2nd Marine Division in 1978, as the Operations Officer of the 3rd Battalion, 2nd Marines, Executive Officer of the 1st Battalion, 8th Marines, Executive Officer of the 8th Marine Regiment and Commanding Officer of the 2nd Battalion, 8th Marines. In 1981, he was assigned as an operations and tactics instructor at the Marine Corps Command and Staff College at Quantico, Virginia. He was next assigned to the Operations Division at Headquarters, U.S. Marine Corps where he served as the Head of the Special Operations and Terrorism Counteraction Section and as the Head, Marine Air-Ground Task Force Concepts and Capabilities Branch. In 1984, he earned his master's degree from Central Michigan University. In 1986, he was selected as a fellow on the Chief of Naval Operations Strategic Studies Group. From 1987 to 1989, Zinni served on Okinawa as the regimental commander of the 9th Marine Regiment and the Commanding Officer of the 35th Marine Expeditionary Unit, which was twice deployed to the Philippines to conduct emergency security operations and disaster relief operations. Upon his return to the U.S., he was assigned as the Chief of Staff of the Marine Air-Ground Training and Education Center at Marine Corps Base Quantico.\nHis initial general officer assignment was as the Deputy Director of Operations at the U.S. European Command. In 1991, he served as the Chief of Staff and Deputy Commanding General of Combined Task Force Operation Provide Comfort during the Kurdish relief effort in Turkey and Iraq. He also served as the Military Coordinator for Operation Provide Hope, the relief effort for the former Soviet Union. In 1992\u201393, he served as the Director for Operations for the Unified Task Force in Somalia for Operation Restore Hope. Also in 1993, he served as the Assistant to the U.S. Special Envoy to Somalia during Operation Continue Hope/UNOSOM II. Zinni was assigned as the Deputy Commanding General, U.S. Marine Corps Combat Development Command, Quantico, Virginia, from 1992 to 1994.\nFrom 1994 to 1996, he served as the Commanding General, 1st Marine Expeditionary Force. During early 1995, Zinni served as Commander of the Combined Task Force for Operation United Shield, protecting the withdrawal of U.N. forces from Somalia.\nFrom September 1996 until August 1997, Zinni served as the Deputy Commander in Chief, United States Central Command. His final tour was from August 1997 to September 2000 as the Commander in Chief, United States Central Command, MacDill Air Force Base, Florida. He organized Operation Desert Fox, a series of airstrikes against Iraq during December 1998, with the stated purpose of degrading Iraq's weapons of mass destruction program. As CinCCENT, he and General Wesley Clark, CINCEUR, held a mini-summit between their commands to determine policies over Africa. Clark was reluctant to support Zinni's activist attempts to engage more in Africa. Following his command of CENTCOM, he retired in autumn 2000.\nTestimony before Congress.\nOn March 15, 2000, Zinni testified before Congress:\nIraq remains the most significant near-term threat to U.S. interests in the Persian Gulf region. This is primarily due to its large conventional military force, the pursuit of WMD, oppressive treatment of Iraqi citizens, refusal to comply with United Nations Security Council resolutions (UNSCR), persistent threats to the enforcement of the no-fly zones (NFZ), and continued efforts to violate UN Security Council sanctions through oil smuggling.\nWhile Iraq's WMD capabilities were degraded under UN supervision and set back by Coalition strikes, some capabilities remain and others could quickly be regenerated. Despite claims that WMD efforts have ceased, Iraq probably is continuing clandestine nuclear research, retains stocks of chemical and biological munitions, and is concealing extended-range SCUD missiles, possibly equipped with CBW payloads. Even if Baghdad reversed its course and surrendered all WMD capabilities, it retains the scientific, technical, and industrial infrastructure to replace agents and munitions within weeks or months. A special concern is the absence of a UN inspection and monitoring presence, which until December 1998 had been paramount to preventing a large-scale resumption of prohibited weapons programs. A new disarmament regime must be reintroduced into Iraq as soon as possible and allowed to carry out the mandates dictated by the post-Gulf War UN resolutions.\nZinni also warned about terrorism:\nExtremists like Osama bin Laden and his World Islamic Front network benefit from the global nature of communications that permits recruitment, fundraising, and direct connections to sub-elements worldwide ... Terrorists are seeking more lethal weaponry to include: chemical, biological, radiological, and even nuclear components with which to perpetrate more sensational attacks ... Three [Iraq, Iran, &amp; Sudan ] of the seven recognized state-sponsors of terrorism are within this potentially volatile area, and the Taliban regime in Afghanistan has been sanctioned by the UN Security Council for its harboring of Osama bin Laden. Nearly one-half of the 28 recognized terrorist organizations have operational sites within the region. Afghanistan has emerged as a catalyst for regional instability offering sanctuary, support, and training facilities to a growing number of extremist elements.\nSpecial envoy.\nFrom 2001 to 2003, Zinni served as a special envoy for the U.S. to Israel and the Palestinian Authority.\nIn August 2017, he traveled to the Persian Gulf at the request of United States Secretary of State Rex Tillerson to help mediate the Qatar diplomatic crisis. Zinni resigned from his position as an envoy in January 2019, for he thought he could not resolve the dispute.\nCNA Military Advisory Board.\nGen. Zinni served on the CNA Military Advisory Board,[8] the first group of retired generals and admirals to examine the national security implications of climate change. Founded in 2006 by Sherri Goodman, the CNA Military Advisory board brought together military leaders from the United States Army, Navy, Air Force, and Marine Corps. The landmark report of the CNA Military Advisory Board, National Security and the Threat of Climate Change, established the concept of climate change as a \u201cthreat multiplier.\u201d\nIn the 2007 report, General Zinni referenced the inevitability of climate change and the need to take action now. General Zinni was one of the first leaders to appreciate the link between climate change, migration, terrorism, and instability. He wanted to \u201clook at how climate change effects could drive populations to migrate. . . . What kinds of conflicts might result from their migration? You may also have a population that is traumatized by an event or change in condition triggered by climate change... It\u2019s not hard to make the connection between climate change and instability and climate change and terrorism.\u201d \nPersonal life.\nZinni's son, Anthony Zinni, serves in the Marine Corps and was promoted to the rank of major effective September 1, 2010.\nZinni holds positions on several boards of directors of major U.S. corporations. In addition, he has held academic positions that include the Stanley Chair in Ethics at the Virginia Military Institute, the Nimitz Chair at the University of California, Berkeley, the Hofheimer Chair at the Joint Forces Staff College, and the Harriman Professorship of Government and membership on the board of the Reves Center for International Studies at the College of William and Mary. He has worked as Chairman of the Board of the Middle East Institute, with the University of California's Institute on Global Conflict and Cooperation and the Henry Dunant Centre for humanitarian dialogue in Geneva. He is also a Distinguished Advisor at the Center for Strategic and International Studies and a member of the Council on Foreign Relations. He was the Executive Vice President for Dyncorp International from July 18, 2007, to the end of 2008. He served on the Board of Directors of DynCorp International prior to that position.\nHe serves or has served on the board of trustees of the National Constitution Center in Philadelphia, which is a museum dedicated to the U.S. Constitution.\nAs of 2014[ [update]], he serves as chairman of the board of governors of the Middle East Institute. He has been named honorary chairman of that institution. Zinni also serves as an honorary board member of the non-profit Wine Country Marines \u2013 a 501(c)3 dedicated to helping wounded service members, and aiding the welfare of currently serving service members, as well as addressing veterans employment and transition and healthcare.\nIn April 2004, Zinni gave a lecture entitled \"From the Battlefield to the Negotiating Table: Preventing Deadly Conflict\" at the University of San Diego's Joan B. Kroc Institute for Peace &amp; Justice Distinguished Lecture Series.\nIn 2004, Zinni was named in an investigative report by Diana B. Henriques of \"The New York Times\" as being among the \"retired or former military people\" recruited to the corporate boards and sales forces of investment firms engaged in deceptive marketing of financial instruments aimed at military veterans in order to lend them credibility. The investment firm that had recruited Zinni, First Command Financial Planning, Inc., responded in written comments to a subsequent United States House of Representatives investigation that \"It would be unfortunate if anyone inferred that these honorable individuals would take any action or support any organization that did not act in the best interests of service members.\" The U.S. Securities and Exchange Commission (SEC) and National Association of Securities Dealers (NASD) subsequently concluded that First Command \"willfully violated the Securities Act of 1933 Section 17(a)(2) dealing with inter-state fraud.\" In particular, the SEC concluded that First Command had sold mutual fund investments to veterans termed \"systematic plans\" which had very high sales charges termed \"front-end sales loads\", \"by, in part, making misleading statements and omissions concerning, among other things: (a) comparisons between the systematic plan and other mutual fund investments; (b) the availability of the Thrift Savings Plan (\"TSP\"), which offers military investors many of the features of a systematic plan at lower costs; and (c) the efficacy of the front-end sales load in ensuring that investors remain committed to the systematic plan.\" In December 2004, First Command entered into a $12 million settlement with the SEC and NASD without admitting guilt.\nIn 2006, Zinni argued that more troops were needed in Iraq in the context of preventing the then-budding civil war.\nIn 2007, he worked on a report entitled \"National Security and the Threat of Climate Change\" with 11 other retired military commanders. The report stated that global warming would act as a threat multiplier to global conflict.\nGeneral Zinni is also a \"Distinguished Military Fellow\" for the Center for Defense Information, a part of the World Security Institute.\nIn 2009, Zinni reported that he had been offered and accepted the post of United States Ambassador to Iraq for the Barack Obama administration, but that the appointment had been subsequently withdrawn without explanation. The administration's final choice for the ambassadorship was Christopher R. Hill.\nOn June 26, 2009, General Anthony (Tony) Zinni (USMC ret.), then a member of the BAE Systems, Inc. Board, has been appointed Chairman of the BAE Systems, Inc. Board and, pending appointment of a permanent successor to Walt Havenstein, Acting President and CEO of BAE Systems, Inc. Tony will also join the BAE Systems Executive Committee in his capacity as Acting President and CEO of BAE Systems, Inc.\nGeneral Zinni also serves or has served on the board of Kaseman which has teamed up with Blackwater to pursue security work for the State Department.\nSince 2011, Anthony Zinni is a member of the board of the Peace Research Endowment.\nPolitical involvement.\nEfforts to get him to run for the U.S. Senate have gone nowhere. Zinni has said he would never run for office. He says his decision to endorse President George W. Bush in 2000 was a mistake, and in 2003, indicated that he plans to avoid politics in the future. However, on March 3, 2006, Zinni joined fellow former United States Marines General Joseph P. Hoar, Lt. General Greg Newbold, Lt. General Frank Petersen, and Congressman Jack Murtha in endorsing fellow former U.S. Marine and Secretary of the Navy Jim Webb for U.S. Senate in Virginia. Zinni had been floated as a possible vice presidential running mate of Barack Obama, in 2008.\nAwards and decorations.\nZinni's decorations include the following:\nIn addition to his U.S. military decorations, Zinni holds decorations from France, Italy, Bahrain, Egypt, Yemen, Vietnam, and Kuwait.\nHis civilian awards include the Papal Gold Cross of Honor, the Union League's Abraham Lincoln Award, the Italic Studies Institute's Global Peace Award, the Distinguished Sea Service Award from the Naval Order of the United States, the Eisenhower Distinguished Service Award from the Veterans of Foreign Wars, The Chapman Award from the Marine Corps University Foundation, the Penn Club Award, the St. Thomas of Villanova Alumni Medal, the George P. Shultz Award for Public Service from the U.S. Department of State, and UNICO National's Grand Patriot Award.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46227", "revid": "2149194", "url": "https://en.wikipedia.org/wiki?curid=46227", "title": "Focus on the Family", "text": "US fundamentalist Protestant Christian organization\nFocus on the Family (FOTF or FotF) is an American Evangelical Protestant organization founded in 1977 in Southern California by James Dobson, based in Colorado Springs, Colorado. The group is one of a number of evangelical parachurch organizations that rose to prominence in the 1980s. As of the 2017 tax filing year, Focus on the Family declared itself to be a church, \"primarily to protect the confidentiality of our donors\". Traditionally, churches are entities that have regular worship services and congregants.\nIt prominently lobbies against LGBT rights \u2014 including those related to marriage, adoption, and parenting \u2014 labeling it a \"particularly evil lie of Satan\". The organization also seeks to change public policy in the areas of sex education, creationism, abortion, state-sponsored school prayer, gambling, drugs, and enforcement of their interpretation of proper gender roles.\nThe core promotional activities of the organization include the flagship daily radio broadcast hosted by its president Jim Daly together with co-host Focus VP John Fuller. Focus also provides free resources in line with the group's views, and publishes books, magazines, videos, and audio recordings.\nThe organization also produces programs for targeted audiences, such as \"Adventures in Odyssey\", \"McGee and Me!\", \"The Last Chance Detectives\", and \"Ribbits!\" for children, and dramas for other audiences.\nHistory.\nOrigins and Dobson era.\nFrom 1977 to 2003, James Dobson served as the sole leader of the organization, which was originally based in Arcadia, California. Dobson and his organization generated significant controversy by taking a different approach to ministry than many other evangelical parachurch organizations, opting to combine its parenting programs with conservative political activism. By 1993, Focus on the Family was receiving approximately 10,000 personal letters and 3,000 phone calls per day by individuals seeking personal assistance from the organization. \nThe organization, and especially James Dobson, wielded significant national influence within the U.S., and particularly among politically conservative Christians and women working within the home. During the 1990s, Dobson and Focus on the Family were accused by an early member of the organization of moving away from their original mission of helping families and instead becoming \"too political\". The organization's cornerstone items included their radio broadcasts, as well as other ventures such as their film publishing arm \"Focus on the Family Films\".\nIn 2003, Donald P. Hodel became president and chief executive officer, tasked with the day-to-day operations. Dobson remained chairman of the board of directors, with chiefly creative and speaking duties. In March 2005, Hodel retired and Jim Daly, formerly the vice president in charge of Focus on the Family's International Division, assumed the role of president and chief executive officer.\nBy 2007, the executive leadership of the organization reportedly worked to sustain the group's cultural influence by investing more heavily into family programs targeted at younger generations as opposed to only bolstering its political programs favored by James Dobson. As a result of targeting a younger demographic more frequently in digital spaces, the organization reported a decrease in donations, dropping from 755,000 donors in 2004 to 564,000 donors by September 2007.\nIn the first decade the 2000s, Focus lead abstinence programs both domestically in the U.S. and worldwide. The program, often titled \"No Apologies\", had some success in Muslim-majority countries such as Egypt and Malaysia where the teachings of abstinence aligned with messages of Islam. The program was brought to China with the permission of the Chinese Communist Party, who desired to bring down birth rates at the time.\nIn November 2008, the organization eliminated 202 jobs, representing 18 percent of its workforce. The organization also cut its budget from $160\u00a0million in fiscal 2008 to $138\u00a0million for fiscal 2009.\nIn February 2009, Dobson resigned his chairmanship. He left Focus on the Family in early 2010, and subsequently founded Family Talk as a non-profit organization and launched a new broadcast that began airing nationally on May 3, 2010. He died in August 2025.\nPost-Dobson.\nIn a break from the previous status quo, president Jim Daly purportedly tried to steer the organization away from the same level of political activism that the organization was known for in its initial decades of existence. Daly made connections with figures and organizations that founder Dobson disdained and cut off, such as Democratic United States President Barack Obama, liberal activist Ted Trimpa, and the newspaper The Independent.\nOn June 23, 2017, Vice President Mike Pence attended the organization's 40th anniversary celebration; at the event, he praised founder James Dobson, stated that then-President Donald Trump was an ally of the organization, and added that the Trump administration supported Focus on the Family's goals (including the abolition of Planned Parenthood). Pence's attendance at the event, along with Focus on the Family's stances on LGBT rights, was criticized by the Human Rights Campaign.\nIn its IRS Form 990 for Tax Year 2015, dated October 26, 2017, Focus on the Family for the first time declared itself a \"church, convention of churches or association of churches\", claiming that it was no longer required to file the IRS disclosure form and that the sources and disposition of its $89 million budget were \"Not for public inspection\". Tax attorney Gail Harmon, who advises nonprofit organizations on tax law, said she found the declaration \"shocking\", noting that \"There's nothing about them that meets the traditional definition of what a church is. They don't have a congregation, they don't have the rites of various parts of a person's life.\" A spokesperson for the organization stated that it changed its status \"primarily to protect the confidentiality of our donors\". By 2023, the organization had offices in 14 countries and partnerships in 60 countries, for an international presence in 98 countries.\nPrograms.\nWait No More.\nFocus on the Family's Wait No More ministry works with adoption agencies, church leaders and ministry partners to recruit families to adopt children from foster care. In Colorado, the number of children waiting for adoption dropped from approximately 800 to 350 people, due in part to the efforts of Wait No More. Focus on the Family's efforts to encourage adoption among Christian families is part of a larger effort by Evangelicals to, in their perception, live out what they see as the \"biblical mandate\" to help children.\nOption Ultrasound Program.\nFocus on the Family's Option Ultrasound Program (OUP) provides grants to crisis pregnancy centers to pay the cost of ultrasound machines or sonography training. Focus on the Family began OUP in 2004 with the goal of convincing women not to have abortions. FOTF officials said that ultrasound services help a woman better understand her pregnancy and baby's development, creating an important \"bonding opportunity\" between \"mother and unborn child\".\nIn 2011, FOTF announced that they would like to talk with pro-choice groups like Planned Parenthood to work towards the shared goal of making abortion less common. Rep. Michele Bachmann (R-Minn.) introduced a sonogram bill in 2011 and, citing Focus on the Family, told Congress that \"78 percent of women who see and hear the fetal heartbeat choose life.\" She was later corrected by Focus on the Family, which released a statement saying they did not release such data.1 A study released in February 2012 showed that ultrasounds do not have a direct impact on an abortion decision.\nBoundless.org.\nBoundless.org is Focus on the Family's website for young adults ages 18\u201334 featuring articles, a blog, a podcast, and a conference. The site has been classified as a webzine, and originally included a moderated forum for young adults to exchange thoughts and ideas about topics relevant to them without being dictated what they should believe by an \"authoritarian tone\". The website covers topics such as singleness, dating, relationships, popular culture, career, and sex.\nPlugged In.\nPlugged In is a Focus on the Family publication and associated website created for families that reviews magazines, newspaper comics, films, books, music, and TV and radio shows. As of 2007 it was one of their most popular products, and reviews were offered to members through both their website and through text messages.\nDay of Dialogue.\nThe Day of Dialogue was a student event which took place April 16. Since 2018, the event is no longer marked on a single date, or organized nationally. Founders described the goal of the event, created in opposition to the anti-bullying and anti-homophobic Day of Silence, as \"encouraging honest and respectful conversation among students about God's design for sexuality\". It was previously known as the \"Day of Truth\" and was founded by the Alliance Defense Fund in 2005. In 2007, Exodus International began supporting the Day of Truth, an event created by Alliance Defending Freedom (ADF) in 2005 that challenges homosexuality. \nIn 2009, the ADF announced they had passed on their leadership role for the event to Exodus. In October 2010, Exodus announced they would no longer support the event. President Alan Chambers stated they realized they needed to \"equip kids to live out biblical tolerance and grace while treating their neighbors as they'd like to be treated, whether they agree with them or not\", adding that the Day of Truth was becoming too divisive. Chambers said that Exodus had not changed its position on homosexuality, rather they were reevaluating how to best communicate their message. Focus on the Family subsequently claimed leadership of the event, and renamed it the Day of Dialogue.\nNational Day of Prayer.\nThe National Day of Prayer Task Force is an American evangelical conservative Christian non-profit organization which organizes, coordinates, and presides over Evangelical Christian religious observances each year on the National Day of Prayer. The website of the NDP Task Force states that \"its business affairs are separate\" from those of Focus on the Family, but also that \"between 1990 and 1993, Focus on the Family did provide grants in support of the NDP Task Force\" and that \"Focus on the Family is compensated for services rendered.\" Shirley Dobson, wife of James Dobson, was chairwoman of the NDP Task Force from 1991 until 2016, when Anne Graham Lotz, daughter of evangelist Billy Graham, assumed the post.\nRadio Theatre.\nRadio Theatre is a program run by Focus on the Family that makes both original and adapted radio dramas. Much of the staff involved with Adventures in Odyssey is also involved with Radio Theatre such as Paul McCusker.\nThey have adapted novels including \"Les Miserables\" and \"Anne of Green Gables\" as well as the complete Chronicles of Narnia. Performers on their adaptations have included Andy Serkis.\nFormer ministries.\nFamily Life Seminars.\nOne of Focus on the Family's earliest ministries, Family Life Seminars were speaking events hosted by James Dobson in the 1970s. To reduce the time that the events were taking Dobson away from his own family, the seminars were eventually recorded and released as a seven-part film series. The film series then in turn inspired a television program based on the films.\nLove Won Out.\nFocus on the Family formed Love Won Out, an ex-gay ministry in 1998. In 2009, it was sold to Exodus International.\nPolitical positions and activities.\nFocus on the Family's 501(c)(3) status prevents them from advocating any individual political candidate, though it has permitted them to spend up to a certain amount on other political activities such as lobbying and voter education. Focus on the Family has an affiliated group, Family Policy Alliance, though the two groups are legally separate. As a 501(c)(4) social welfare group, Family Policy Alliance has fewer political lobbying restrictions. FOTF's revenue in 2012 was US$90.5\u00a0million, and that of Family Policy Alliance (formerly CitizenLink) was US$8\u00a0million. By 2023, Family Policy Alliance and its network of local state councils were generating over $40\u00a0million of revenue.\nFocus on the Family maintains a strong stand against abortion, and provides grant funding and medical training to assist crisis pregnancy centers (CPCs; also known as pregnancy resource centers) in obtaining ultrasound machines. According to the organization, this funding, which has allowed CPCs to provide pregnant women with live sonogram images of the developing fetus, has led directly to the birth of over 1500 babies who would have otherwise been aborted. The organization has been staunchly opposed to public funding for elective abortions.\nFocus on the Family has been a prominent supporter of the pseudoscience of intelligent design, publishing pro-intelligent design articles in its \"Citizen\" magazine and selling intelligent design videos on its website. Focus on the Family co-published the intelligent design videotape \"Unlocking the Mystery of Life\" with the Discovery Institute, hub of the intelligent design movement.\nIn New Zealand, Focus on the Family supported a Citizens Initiated Referendum on the repeal of section 59 of the Crimes Act 1961, which placed limits on the physical disciplining of children.\nFocus on the Family Singapore came under criticism in October 2014 over allegations of sexism and promoting gender stereotypes during their workshops on managing relationships for junior college students. The workshop received a complaint from both a Hwa Chong Junior College student, as well as negative feedback from the college management as being 'ineffective' and stopped before the end of the year.\nFollowing the 2022 U.S. Supreme Court decision to overturn \"Roe v. Wade\", Focus on the Family published an article on its \"Daily Citizen\" site urging conservative Christians to engage in a \"cultural civil war\" against \"radical abortion laws\" implemented in left-leaning states. This added to speculation that political violence similar to the January 6th attacks could be accepted or encouraged on the grounds of opposing abortion rights.\n2008 presidential campaign.\nIn the 2008 United States presidential election, Focus on the Family shifted from supporting Mike Huckabee, to not supporting any candidate, to accepting the Republican ticket once Sarah Palin was added. Prior to the election, a television and letter campaign was launched predicting terrorist attacks in four U.S. cities and equating the U.S. with Nazi Germany. This publicity was condemned by the Anti-Defamation League. Within a month before the general election, Focus on the Family began distributing a 16-page letter titled \"Letter from 2012 in Obama's America\", which describes an imagined American future in which \"many of our freedoms have been taken away by a liberal Supreme Court of the United States and a majority of Democrats in both the House of Representatives and the Senate\". According to \"USA Today\", the letter was \"part of an escalation in rhetoric from Christian right activists\" trying to paint Democratic Party presidential nominee Senator Barack Obama in a negative light.\nFocus on the Family Action supported Senator Saxby Chambliss (R-Ga.) in his successful December 2, 2008, runoff election win. The organization, according to the \"Colorado Independent\", donated $35,310 in radio ads to the Chambliss runoff campaign effort. As the \"Independent\" reports, the Focus-sponsored ads were aired in about a dozen Georgia markets. The commercials were produced in the weeks after Focus laid off 202 employees, some 20 percent of its workforce, because of the national economic crisis.\nOpposition to LGBTQ rights.\nOne of Focus on the Family's notable political stances is its strong opposition to same-sex marriage, civil unions, and domestic partnerships. Focus on the Family, through its partnership with Family Policy Alliance, also strongly advocates for legislation against transgender rights, including crafted policies which oppose the consensus of medical experts who work with the transgender community. The organization has referred to the LGBT rights movement as a \"particularly evil lie of Satan\".\nFocus on the Family founder James Dobson drew criticism for using the group to oppose homosexual members in the United States Military. Similarly, Dobson and the organization supported a 1992 amendment to the Colorado constitution which stopped laws that allowed for protections from LGBTQ discrimination.\nDobson spoke at the 2004 rally against gay marriage called Mayday for Marriage. The event marked the first time that Dobson publicly endorsed a presidential candidate, George W. Bush. During the event he denounced the Supreme Court rulings in favor of gay rights, and he urged rally participants to vote so that the battle against gay rights could be won in the Senate.\nIn an interview with \"Christianity Today\", Dobson also explained that he was not in favor of civil unions. He stated that generally agreed civil unions were merely same-sex marriage under a different name. He claimed his main priority in opposing the same-sex marriage movement was first and foremost to define marriage on the federal level as being exclusive between a man and a woman, and that afterward he wished to combat the passage of civil unions on a state-by-state basis.\nCivil rights advocacy groups identify Focus on the Family as a major opponent of LGBT rights. The Southern Poverty Law Center, a civil rights and hate group monitoring organization, described Focus on the Family as one of a \"dozen major groups [which] help drive the religious right's anti-gay crusade\". While the Southern Poverty Law Center previously did not classify Focus on the Family as a hate group, for it opposed homosexuality \"on strictly Biblical grounds\", the organization officially classified Focus on the Family as one in May 2025.\nFocus on the Family was a member of ProtectMarriage.com, a coalition formed to sponsor California Proposition 8, a ballot initiative to restrict marriage to opposite-sex couples, which passed in 2008, but was subsequently struck down as being unconstitutional by a federal court in \"Perry v. Schwarzenegger\".\nMisrepresentation of research.\nSocial scientists have criticized Focus on the Family for misrepresenting their research in order to bolster its own perspective. Researcher Judith Stacey, whose work was used by Focus on the Family to claim that gays and lesbians do not make good parents, said that the claim was \"a direct misrepresentation of the research\". She elaborated, \"Whenever you hear Focus on the Family, legislators or lawyers say, 'Studies prove that children do better in families with a mother and a father,' they are referring to studies which compare two-parent heterosexual households to single-parent households. The studies they are talking about do not cite research on families headed by gay and lesbian couples.\" FOTF claimed that Stacey's allegation was without merit and that their position is that the best interests of children are served when there is a father and a mother. \"We haven't said anything about sexual orientation\", said Glenn Stanton.\nJames Dobson cited the research of Kyle Pruett and Carol Gilligan in a \"Time\" magazine guest article in the service of a claim that two women cannot raise a child; upon finding out that her work had been used in this way, Gilligan wrote a letter to Dobson asking him to apologize and to cease and desist from citing her work, describing herself as \"mortified to learn that you had distorted my work\u00a0... Not only did you take my research out of context, you did so without my knowledge to support discriminatory goals that I do not agree with\u00a0... there is nothing in my research that would lead you to draw the stated conclusions you did in the \"Time\" article.\" Pruett wrote a similar letter, in which he said that Dobson \"cherry-picked a phrase to shore up highly (in my view) discriminatory purposes. This practice is condemned in real science, common though it may be in pseudo-science circles. There is nothing in my longitudinal research or any of my writings to support such conclusions\", and asked that FOTF not cite him again without permission.\nAfter Elizabeth Saewyc's research on teen suicide was used by Focus on the Family to promote conversion therapy she said that \"the research has been hijacked for somebody's political purposes or ideological purposes and that's worrisome\", and that research in fact linked the suicide rate among LGBT teens to harassment, discrimination, and closeting. Other scientists who have criticized Focus on the Family for misrepresenting their findings include Robert Spitzer, Gary Remafedi, and Angela Phillips.\nFootball advertisements.\nIn 2010, Focus on the Family bought ad time during Super Bowl XLIV to air a commercial featuring Heisman Trophy winning Florida Gators quarterback Tim Tebow and his mother, Pam. In the ad, Pam described Tim as a \"miracle baby\" who \"almost didn't make it into this world\", and further elaborated that \"with all our family's been through, we have to be tough\" (after which Pam was promptly tackled by Tim). The ad directed viewers to the organization's website.\nWomen's rights groups asked CBS not to air the then-unseen ad, arguing that it was divisive. Planned Parenthood released a video response of its own featuring fellow NFL player Sean James. The claim that Tebow's family chose not to perform an abortion was also widely criticized; critics felt that the claim was implausible because it would be unlikely for doctors to recommend the procedure because abortion is illegal in the Philippines, where Tebow was born. CBS's decision to run the ad was also criticized for deviating from its past policy to reject advocacy-type ads during the Super Bowl, including ads by left-leaning groups such as PETA, MoveOn.org and the United Church of Christ (which wanted to run an ad that was pro-same-sex marriage). However, CBS stated that \"we have for some time moderated our approach to advocacy submissions after it became apparent that our stance did not reflect public sentiment or industry norms on the issue.\"\nFocus on the Family produced another commercial which ran during the second quarter of the January 14, 2012 Denver Broncos-New England Patriots AFC Divisional Playoff broadcast on CBS, featuring children reciting the Bible verse John 3:16. The ad did not generate nearly the amount of controversy that surrounded the Super Bowl commercial. It did gain some national media attention, and president Jim Daly stated in a press release that its purpose was to \"help everyone understand some numbers are more important than the ones on the scoreboard.\"\nRecognition and awards.\nIn 2008, Dobson's \"Focus on the Family\" program was nominated for induction into the National Radio Hall of Fame. Nominations were made by the 157 members of the Hall of Fame and voting on inductees was handed over to the public using online voting. The nomination drew the ire of gay rights activists, who launched efforts to have the program removed from the nominee list and to vote for other nominees to prevent \"Focus\" from winning. However, on July 18, 2008, it was announced that the program had won and would be inducted into the Radio Hall of Fame in a ceremony on November 8, 2008. Truth Wins Out, a gay rights group, protested against the ceremony with over 300 protesters.\nHeadquarters and size.\nThe Focus on the Family headquarters is a four building, complex located off of Interstate 25 in northern Colorado Springs, Colorado, with its own ZIP Code (80995). The buildings consist of the Administration building, International building, Welcome Center and Operations building, and totals 526,070 square feet.\nFocus on the Family's original headquarters were in Arcadia, California for the initial fourteen years following the time that James Dobson incorporated the company. The organization began with 500 square feet of office space and employed a single part-time secretary, according to the prior director of corporate affairs, Dan Wright. By 1984 Focus of the Family's Arcadia properties occupied 55,000 square feet across three buildings (though prior to a consolidation of their campus, they owned as many as seven individual buildings around the city) and employed 320 personnel. \nIn 1991, Focus moved their headquarters to their current location in Colorado Springs with 1,200 employees. In 2002, the number of employees peaked at 1,400. By September 2011, after years of layoffs, they had 650 employees remaining. Christopher Ott of \"Salon\" said in 1998 that the FOTF campus has \"handsome new brick buildings, professional landscaping and even its own traffic signs\" and that \"The buildings and grounds are well-maintained and comfortable. If there is any ostentatious or corrupt influence here, it is nowhere in sight.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46228", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=46228", "title": "Henry Fonda", "text": "American actor (1905\u20131982)\nHenry Jaynes Fonda (May 16, 1905 \u2013 August 12, 1982) was an American actor whose career spanned five decades on Broadway and in Hollywood. Known for his work on screen and stage, he often portrayed characters who embodied an everyman image.\nBorn and raised in Nebraska, Fonda made his mark early as a Broadway actor and made his Hollywood film debut in 1935. He rose to film stardom with performances in films like \"Jezebel\" (1938), \"Jesse James\" (1939) and \"Young Mr. Lincoln\" (1939). He received a nomination for the Academy Award for Best Actor for his role as Tom Joad in \"The Grapes of Wrath\" (1940).\nIn 1941, Fonda starred opposite Barbara Stanwyck in the screwball comedy classic \"The Lady Eve\". After his service in World War II, he starred in two highly regarded Westerns: \"The Ox-Bow Incident\" (1943) and \"My Darling Clementine\" (1946), the latter directed by John Ford. He also starred in Ford's Western \"Fort Apache\" (1948). During a seven-year break from films, Fonda focused on stage productions, returning to star in the war-boat ensemble movie \"Mister Roberts\" in 1955, a role he championed on Broadway. In 1956, at the age of 51, Fonda played the title role of 38-year-old Manny Balestrero in Alfred Hitchcock's thriller \"The Wrong Man\". In 1957, Fonda starred as Juror 8, the hold-out juror, in \"12 Angry Men\", a film he co-produced and that earned him a BAFTA award for Best Foreign Actor.\nLater in his career, Fonda played a range of characters, including a villain in the epic \"Once Upon a Time in the West\" (1968) and the lead in the romantic comedy \"Yours, Mine and Ours\" with Lucille Ball. He also portrayed military figures, such as a colonel in \"Battle of the Bulge\" (1965) and Admiral Nimitz in \"Midway\" (1976).\nFonda won the Academy Award for Best Actor at the 54th Academy Awards for his final film role in \"On Golden Pond\" (1981), which co-starred Katharine Hepburn and his daughter Jane Fonda. He was too ill to attend the ceremony and died from heart disease five months later.\nFonda was the patriarch of a family of actors, including daughter Jane Fonda, son Peter Fonda, granddaughter Bridget Fonda and grandson Troy Garity. In 1999, he was named the sixth-Greatest Male Screen Legend of the Classic Hollywood Era (stars with a film debut by 1950) by the American Film Institute.\nAncestry and early life.\nBorn in Grand Island, Nebraska, on May 16, 1905, Henry Jaynes Fonda was the son of printer William Brace Fonda, and his wife, Herberta (Jaynes). The family moved to Omaha, Nebraska, in 1906.\nFonda's patriline originates with an ancestor from Genoa, Italy, who migrated to the Netherlands in the 15th century. In 1642, a branch of the Fonda family immigrated to the Dutch colony of New Netherland on the East Coast of North America. They were among the first Dutch population to settle in what is now upstate New York, establishing the town of Fonda, New York. By 1888, many of their descendants had relocated to Nebraska.\nFonda was brought up as a Christian Scientist. The family was close and highly supportive, especially in health matters, as they avoided doctors due to their religion. Despite having a religious background, he later became an agnostic. Fonda was a bashful, short boy who tended to avoid girls, except his sisters, and was a good skater, swimmer, and runner. He worked part-time in his father's print plant and imagined a possible career as a journalist. Later, he worked after school for the phone company. He also enjoyed drawing. Fonda was active in the Boy Scouts of America; Howard Teichmann's biography of Fonda, as well as his son Peter Fonda, stated that he reached the rank of Eagle Scout. However, other sources contradict that claim, some stating that he was instead a ScoutMaster. When he was 14, he and his father witnessed the brutal lynching of Will Brown from a nearby building during the Omaha race riot of 1919. This enraged the young Fonda and he kept a keen awareness of prejudice for the rest of his life. Remarking on the incident in a 1975 BBC interview, he said: \"It was the most horrendous sight I'd ever seen. My hands were wet, there were tears in my eyes. All I could think of was that young black man dangling at the end of a rope.\" By his senior year in high school, Fonda had grown to more than tall, but remained shy. He attended the University of Minnesota, where he majored in journalism, but did not graduate. While at Minnesota he was a member of Chi Delta Xi, a local fraternity, which later became Chi Phi's Gamma Delta chapter on that campus. He took a job with the Retail Credit Company.\nCareer.\nEarly stage work.\nAt age 20, Fonda started his acting career at the Omaha Community Playhouse when his mother's friend Dodie Brando (mother of Marlon Brando) recommended that he try out for a juvenile part in \"You and I\", in which he was cast as Ricky. He was fascinated by the stage, learning everything from set construction to stage production, and embarrassed by his acting ability. When he received the lead in \"Merton of the Movies\", he realized the beauty of acting as a profession, as it allowed him to deflect attention from his own tongue-tied personality and create stage characters relying on someone else's scripted words. Fonda decided to quit his job and go east in 1928 to seek his fortune.\nHe arrived on Cape Cod and played a minor role at the Cape Playhouse in Dennis, Massachusetts. A friend took him to Falmouth, MA where he joined and quickly became a valued member of the University Players, an intercollegiate summer stock company. There, he worked with Margaret Sullavan, his future wife. James Stewart joined the Players a few months after Fonda left, though they were soon to become lifelong friends. Fonda left the Players at the end of their 1931\u20131932 season after appearing in his first professional role in \"The Jest\", by Sem Benelli. Joshua Logan, a young sophomore at Princeton who had been double-cast in the show, gave Fonda the part of Tornaquinci, \"an elderly Italian man with a long white beard and even longer hair.\" Also in the cast of \"The Jest\" with Fonda and Logan were Bretaigne Windust, Kent Smith, and Eleanor Phelps.\nSoon after, Fonda headed for New York City to be with his then wife, Margaret Sullavan. The marriage was brief, but when James Stewart came to New York his luck changed. Getting contact information from Joshua Logan, \"Jimmy\" and \"Hank\" found they had a lot in common, as long as they didn't discuss politics. The two men became roommates and honed their skills on Broadway. Fonda appeared in theatrical productions from 1926 to 1934. They fared no better than many Americans in and out of work during the early part of the Great Depression, sometimes lacking enough money to take the subway.\nEntering Hollywood.\nFonda got his first break in films when he was hired in 1935 as Janet Gaynor's leading man in 20th Century Fox's screen adaptation of \"The Farmer Takes a Wife\"; he reprised his role from the Broadway production of the same name, which had gained him recognition. Suddenly, Fonda was making $3,000 a week () and dining with Hollywood stars such as Carole Lombard. Stewart soon followed him to Hollywood, and they roomed together again, in lodgings next door to Greta Garbo. In 1935 Fonda starred in the RKO film \"I Dream Too Much\" with the opera star Lily Pons. \"The New York Times\" announced him as \"Henry Fonda, the most likable of the new crop of romantic juveniles.\"\nFonda's film career blossomed as he costarred with Sylvia Sidney and Fred MacMurray in \"The Trail of the Lonesome Pine\" (1936), the first Technicolor movie filmed outdoors.\nFonda starred with ex-wife Margaret Sullavan in \"The Moon's Our Home\", and a short rekindling of their relationship led to a brief but temporary consideration of remarriage. Fonda got the nod for the lead role in \"You Only Live Once\" (1937), also costarring Sidney, and directed by Fritz Lang. He starred opposite Bette Davis, who had chosen him, in the film \"Jezebel\" (1938). This was followed by the title role in \"Young Mr. Lincoln\" (1939), his first collaboration with director John Ford, and that year he played Frank James in \"Jesse James\" (1939) starring Tyrone Power and Nancy Kelly. Another 1939 film was \"Drums Along the Mohawk\", also directed by Ford.\nFonda's successes led Ford to recruit him to play Tom Joad in the film version of John Steinbeck's novel \"The Grapes of Wrath\" (1940). A reluctant Darryl Zanuck, who preferred Tyrone Power, insisted on Fonda's signing a seven-year contract with his studio, Twentieth Century-Fox. Fonda agreed and was ultimately nominated for an Academy Award for his work in the film, which many consider to be his finest role. Fonda starred in Fritz Lang's \"The Return of Frank James\" (1940) with Gene Tierney. He then played opposite Barbara Stanwyck in Preston Sturges's \"The Lady Eve\" (1941), and again teamed with Tierney in the successful screwball comedy \"Rings on Her Fingers\" (1942). Stanwyck was one of Fonda's favorite co-stars, and they appeared in three films together. He was acclaimed for his role in \"The Ox-Bow Incident\" (1943).\nFonda enlisted in the United States Navy to fight in World War II, saying, \"I don't want to be in a fake war in a studio.\" Previously, Jimmy Stewart and Fonda had helped raise funds for the defense of Britain. Fonda served for three years, initially as a quartermaster 3rd class on the destroyer . He was later commissioned as a lieutenant junior grade in Air Combat Intelligence in the Central Pacific and was awarded the Bronze Star Medal and Navy Presidential Unit Citation. Although he had been promoted to full lieutenant, Fonda was discharged from active duty due to being \"overage in rank\", and transferred to the Naval Reserve, serving three years (1945-1948).\nPostwar career.\nAfter the war, Fonda took a break from movies and attended Hollywood parties and enjoyed civilian life. Stewart and Fonda would listen to records and invite Johnny Mercer, Hoagy Carmichael, Dinah Shore, and Nat King Cole over for music, with the latter giving the family piano lessons. Fonda played Wyatt Earp in \"My Darling Clementine\" (1946), which was directed by John Ford. Fonda did seven postwar films until his contract with Fox expired, the last being Otto Preminger's \"Daisy Kenyon\" (1947), opposite Joan Crawford. He starred in \"The Fugitive\" (1947), which was the first film of Ford's new production company, Argosy Pictures. In 1948 he appeared in a subsequent Argosy/Ford production, \"Fort Apache\", as a rigid Army colonel, along with John Wayne and Shirley Temple in her first adult role.\nRefusing another long-term studio contract, Fonda returned to Broadway, wearing his own officer's cap to originate the title role in \"Mister Roberts\", a comedy about the U.S. Navy, during World War II in the South Pacific Ocean where Fonda, a junior officer, Lt. Douglas A. Roberts wages a private war against a tyrannical captain. He won a 1948 Tony Award for the part. Fonda followed that by reprising his performance in the national tour and with successful stage runs in \"Point of No Return\" and \"The Caine Mutiny Court-Martial\". After an eight-year absence from films, he starred in the same role in the 1955 film version of \"Mister Roberts\" with James Cagney, William Powell, and Jack Lemmon, continuing a pattern of bringing his acclaimed stage roles to life on the big screen. On the set of \"Mister Roberts\", Fonda came to blows with director John Ford, who punched him during filming, and Fonda vowed never to work for the director again. While he kept that vow for years, Fonda spoke glowingly of Ford in Peter Bogdanovich's documentary \"Directed by John Ford\" and in a documentary on Ford's career alongside Ford and James Stewart. Fonda refused to participate until he learned that Ford had insisted on casting Fonda as the lead in the film version of \"Mr. Roberts\", reviving Fonda's film career after concentrating on the stage for years.\nAfter \"Mr. Roberts\", Fonda was next in Paramount Pictures's production of Leo Tolstoy's epic novel \"War and Peace\" (1956) about French Emperor Napoleon's invasion of Russia in 1812, in which he played Pierre Bezukhov opposite Audrey Hepburn; it took two years to shoot. Fonda worked with Alfred Hitchcock in 1956, playing a man falsely accused of robbery in \"The Wrong Man\"; the unusual semidocumentary work of Hitchcock was based on an actual incident and partly filmed on location.\nIn 1957, Fonda made his first foray into producing with \"12 Angry Men\", in which he also starred. The film was based on a teleplay and a script by Reginald Rose, and directed by Sidney Lumet. The low-budget production was completed in 17 days of filming, mostly in one claustrophobic jury room. It had a strong cast, including also Jack Klugman, Lee J. Cobb, Martin Balsam, and E. G. Marshall. The intense story about twelve jurors deciding the fate of a young man accused of murder was well received by critics worldwide. Fonda shared the Academy Award and Golden Globe nominations with co-producer Reginald Rose, and won the 1958 BAFTA Award for Best Actor for his performance as Juror 8. Early on, the film drew poorly, but after gaining recognition and awards, it proved a success. In spite of the outcome, Fonda vowed that he would never produce a movie again, fearing that failing as a producer might derail his acting career. After acting in the Western movies \"The Tin Star\" (1957) and \"Warlock\" (1959), Fonda returned to the production seat for the NBC Western television series \"The Deputy\" (1959\u20131961), in which he starred as Marshal Simon Fry. His co-stars were Allen Case and Read Morgan.\nDuring the 1960s, Fonda performed in a number of war and Western epics, including 1962's \"The Longest Day\" and the Cinerama production \"How the West Was Won\", 1965's \"In Harm's Way\", and \"Battle of the Bulge\". In the Cold War suspense film \"Fail-Safe\" (1964), Fonda played the President of the United States who tries to avert a nuclear holocaust through tense negotiations with the Soviets after American bombers are mistakenly ordered to attack the USSR. He also returned to more light-hearted cinema in \"Spencer's Mountain\" (1963), which was the inspiration for the 1970s TV series, \"The Waltons\", based on the Great Depression of the 1930s memories of Earl Hamner Jr.\nFonda appeared against type as the villain 'Frank' in 1968's \"Once Upon a Time in the West\". After initially turning down the role, he was convinced to accept it by actor Eli Wallach and director Sergio Leone (who had previously tried to hire him to portray the Man with No Name in his Dollars Trilogy, a role that was later taken on by Clint Eastwood), who flew from Italy to the United States to persuade him to take the part. Fonda had planned on wearing a pair of brown-colored contact lenses, but Leone preferred the paradox of contrasting close-up shots of Fonda's innocent-looking blue eyes with the vicious personality of the character Fonda portrayed.\nFonda's relationship with Jimmy Stewart survived their disagreements over politics \u2013 Fonda was a liberal Democrat, and Stewart a conservative Republican. After a heated argument, they avoided talking politics with each other. The two men teamed up for 1968's \"Firecreek\", where Fonda again played the heavy. In 1970, Fonda and Stewart co-starred in the Western \"The Cheyenne Social Club\", in which they humorously argued politics. They had first appeared together on film in \"On Our Merry Way\" (1948), an episodic comedy which also starred William Demarest and Fred MacMurray and featured a grown-up Carl \"Alfalfa\" Switzer, who had acted as a child in the \"Our Gang\" movie serials of the 1930s.\nLater career.\nDespite approaching his seventies, Fonda continued to work in theater, television and film through the 1970s. In 1970, Fonda appeared in three films; the most successful was \"The Cheyenne Social Club\". The other two films were \"Too Late the Hero\", in which Fonda played a secondary role, and \"There Was a Crooked Man\", about Paris Pitman Jr. (played by Kirk Douglas) trying to escape from an Arizona prison.\nFonda returned to both foreign and television productions, which provided career sustenance through a decade in which many aging screen actors suffered waning careers. He starred in the ABC television series \"The Smith Family\" between 1971 and 1972. A television film adaptation of John Steinbeck's novel, 1973's \"The Red Pony\", earned Fonda an Emmy nomination. After the unsuccessful Hollywood melodrama, \"Ash Wednesday\", he filmed three Italian productions released in 1973 and 1974. The most successful of these, \"My Name Is Nobody\", presented Fonda in a rare comedic performance as an old gunslinger whose plans to retire are dampened by a \"fan\" of sorts.\nFonda continued stage acting throughout his last years, including several demanding roles in Broadway plays. He returned to Broadway in 1974 for the biographical drama, \"Clarence Darrow\", for which he was nominated for a Tony Award. Fonda's health had been deteriorating for years, but his first outward symptoms occurred after a performance of the play in April 1974, when he collapsed from exhaustion. After the appearance of a cardiac arrhythmia brought on by prostate cancer, he had a pacemaker installed following cancer surgery. Fonda returned to the play in 1975. After the run of a 1978 play, \"First Monday of October\", he took the advice of his doctors and quit plays, though he continued to star in films and television.\nFonda appeared in a revival of \"The Time of Your Life\" that opened on March 17, 1972, at the Huntington Hartford Theater in Los Angeles, where Fonda, Richard Dreyfuss, Gloria Grahame, Ron Thompson, Strother Martin, Jane Alexander, Lewis J. Stadlen, Richard X. Slattery, and Pepper Martin were among the cast with Edwin Sherin directing.\nIn 1976, Fonda appeared in several notable television productions, the first being ', the story of the volatile relationship between President Harry Truman (E. G. Marshall) and General MacArthur (Fonda), produced by ABC. After an appearance in the acclaimed Showtime broadcast of \"Almos' a Man\", based on a story by Richard Wright, he starred in the epic NBC miniseries Captains and the Kings, based on Taylor Caldwell's novel. Three years later, he appeared in ABC's ', but the miniseries was overshadowed by its predecessor, \"Roots\". Also in 1976, Fonda starred in the World War II blockbuster \"Midway\".\nFonda finished the 1970s in a number of disaster films. The first of these was the 1977 Italian killer octopus thriller \"Tentacles\" and \"Rollercoaster\", in which Fonda appeared with George Segal, Richard Widmark and a young Helen Hunt. He performed again with Widmark, Olivia de Havilland, Fred MacMurray, and Jos\u00e9 Ferrer in the killer bee action film \"The Swarm\". He also acted in the global disaster film \"Meteor\" (his second role as a sitting President of the United States after \"Fail-Safe\"), with Sean Connery, Natalie Wood, and Karl Malden, and the Canadian production \"City on Fire\", which also featured Shelley Winters and Ava Gardner. Fonda had a small role with his son, Peter, in \"Wanda Nevada\" (1979), with Brooke Shields.\nAs Fonda's health declined and he took longer breaks between filming, critics began to acknowledge the value of his extensive body of work. In 1979, he received the Golden Plate Award of the American Academy of Achievement. His Golden Plate was presented by Awards Council member Jimmy Stewart. In 1979, he was inducted into the American Theater Hall of Fame for his achievements on Broadway and received the Kennedy Center Honor. Lifetime Achievement awards from the Golden Globes and Academy Awards followed in 1980 and 1981, respectively.\nFonda continued to act into the early 1980s, though all but one of the productions in which he was featured before his death were for television. The television works included the live performance of Preston Jones's \"The Oldest Living Graduate\" and the Emmy-nominated \"Gideon's Trumpet\" (co-starring Fay Wray in her last performance) about Clarence Gideon's fight to have the right to publicly funded legal counsel for the indigent.\n\"On Golden Pond\" in 1981, the film adaptation of Ernest Thompson's play, marked one final professional and personal triumph for Fonda. Directed by Mark Rydell, the movie presented a powerful collaboration between Fonda, Katharine Hepburn, and his daughter, Jane Fonda. The elder Fonda played an emotionally brittle and distant father who becomes more accessible at the end of his life. Jane Fonda has said that elements of the story mirrored their real-life relationship and helped them resolve certain issues. She bought the film rights in the hope that her father would play the role and later described it as \"a gift to my father that was so unbelievably successful.\"\nPremiered in December 1981, the film was well received by critics and, after a limited release on December 4, \"On Golden Pond\" developed enough of an audience to be widely released on January 22. With 10 Academy Award nominations, the film earned nearly $120\u00a0million at the box office, becoming an unexpected blockbuster. In addition to wins for Hepburn (Best Actress), and Thompson (Screenplay), \"On Golden Pond\" brought Fonda his only Oscar\u00a0\u2013 for Best Actor (he was the oldest recipient of the award; it also earned him a Golden Globe Best Actor award). Fonda was by that point too ill to attend the ceremony, and his daughter Jane accepted on his behalf. She said when accepting the award that her dad would probably quip, \"Well, ain't I lucky.\" Years later, Fonda's performance would be remembered as a \"brutally honest portrayal of frightened old age.\"\nFonda's final performance was in the 1981 television drama \"Summer Solstice\" with Myrna Loy. It was filmed after \"On Golden Pond\" had wrapped and Fonda was in rapidly declining health.\nPersonal life.\nMarriages and children.\nFonda was married five times and had three children, one of them adopted. His marriage to Margaret Sullavan in 1931 soon ended in separation, which was finalized in a 1933 divorce. Throughout most of 1935, Fonda dated actress/singer Shirley Ross; by year's end, it had been widely reported\u2014by, among others, then-syndicated columnist Ed Sullivan\u2014that the couple was engaged, with wedding plans afoot. Reports notwithstanding, both parties evidently reconsidered and in January 1936 it was reported that Fonda was now seeing actress Virginia Bruce.\nLater that year Fonda married Frances Ford Seymour Brokaw, widow of a wealthy industrialist, George Tuttle Brokaw. The Brokaws had a daughter who had been born soon after the Brokaws marriage in 1931.\nFonda had met Frances at Denham Studios in England on the set of \"Wings of the Morning\", the first picture in Europe to be filmed in three-strip Technicolor. They had two children, Jane (b. 1937) and Peter (1940\u20132019), both of whom became successful actors. Jane has won two Best Actress Academy Awards, and Peter was nominated for two Oscars, one for Best Actor.\nIn August 1949, Fonda announced to Frances that he wanted a divorce so he could remarry; their 13 years of marriage had not been happy ones for him. Devastated by Fonda's confession and plagued by emotional problems for many years, Frances went into the Craig House Sanitarium in January 1950 for treatment. She committed suicide there on April 14. Before her death, she had written six notes to various individuals, but left no final message for her husband. Fonda quickly arranged a private funeral with only himself and his mother-in-law, Sophie Seymour, in attendance. Years later, Dr. Margaret Gibson, the psychiatrist who had treated Frances at Austen Riggs, described Henry Fonda as \"a cold, self-absorbed person, a complete narcissist.\"\nLater in 1950, Fonda married Susan Blanchard, his mistress. She was 21 years old, the daughter of Australian-born interior designer Dorothy Hammerstein, and the step-daughter of Oscar Hammerstein II. Together, they adopted a daughter, Amy Fishman (b. 1953). They divorced three years later. Blanchard was in awe of Fonda, and she described her role in the marriage as \"a geisha\", doing everything she could to please him, dealing with and solving problems he would not acknowledge.\nIn 1957 Fonda married the Italian baroness Afdera Franchetti. They divorced in 1961. Soon after, in 1965, Fonda married Shirlee Mae Adams (born in 1932) and remained with her until his death in 1982.\nFonda's relationship with his children has been described as \"emotionally distant\". Fonda loathed displays of feeling in himself or others, and this was a consistent part of his character. Whenever he felt that his emotional wall was being breached, he had outbursts of anger, exhibiting a furious temper that terrified his family. In Peter Fonda's 1998 autobiography \"Don't Tell Dad\" (1998), he described how he was never sure how his father felt about him. He never volunteered to his father that he loved him until he was elderly, and Peter finally heard, \"I love you, son.\" His daughter Jane rejected her father's friendships with Republican actors such as John Wayne and James Stewart. Their relationship became extremely strained as Jane Fonda became a left-wing activist.\nJane Fonda reported feeling detached from her father, especially during her early acting days. In 1958 she met Lee Strasberg while visiting her father in Malibu. The Fonda and Strasberg families were neighbors, and she had developed a friendship with Strasberg's daughter, Susan. Jane Fonda began studying acting with Strasberg, learning the techniques of \"The Method\" of which Strasberg was a renowned proponent. This proved to be a pivotal point in her career. As Jane Fonda developed her skill as an actress, she became frustrated with her father's talent that, to her, appeared a demonstration of effortless ability.\nPolitical views.\nFonda was a supporter of the Democratic Party and \"an admirer\" of U.S. President Franklin D. Roosevelt. In 1960 Fonda appeared in a campaign commercial for presidential candidate John F. Kennedy. The ad focused on Kennedy's naval service during World War II, specifically the famous PT-109 incident. He supported \nLyndon B. Johnson in the 1964 United States presidential election, and Ted Kennedy in the 1980 Democratic Party primaries. He was initially a registered Republican, but switched parties.\nOn acting.\nThe writer Al Aronowitz, while working on a profile of Jane Fonda for \"The Saturday Evening Post\" in the 1960s, asked Henry Fonda about method acting: \"I can't articulate about the Method\", he told me, \"because I never studied it. I don't mean to suggest that I have any feelings one way or the other about it...I don't know what the Method is and I don't care what the Method is. Everybody's got a method. Everybody can't articulate about their method, and I can't, if I have a method\u2014and Jane sometimes says that I use the Method, that is, the capital letter Method, without being aware of it. Maybe I do; it doesn't matter.\"\nAronowitz reported Jane saying, \"My father can't articulate the way he works. He just can't do it. He's not even conscious of what he does, and it made him nervous for me to try to articulate what I was trying to do. And I sensed that immediately, so we did very little talking about it...he said, 'Shut up, I don't want to hear about it.' He didn't want me to tell him about it, you know. He wanted to make fun of it.\"\nDeath.\nFonda died at his Los Angeles home on August 12, 1982, from heart disease. Fonda's wife, Shirlee, his daughter Jane, and his son Peter were at his side that day. He suffered from prostate cancer, but this did not directly cause his death and was noted only as a concurrent ailment on his death certificate.\nFonda requested that no funeral be held, and his body was cremated. President Ronald Reagan, a former actor himself, hailed Fonda as \"a true professional dedicated to excellence in his craft. He graced the screen with a sincerity and accuracy which made him a legend.\"\nThe home where Fonda was born in 1905 is preserved at The Stuhr Museum of the Prairie Pioneer in Grand Island, Nebraska.\nLegacy.\nFonda is widely recognized as one of the Hollywood greats of the classic era. On the centenary of his birth, May 16, 2005, Turner Classic Movies (TCM) honored Fonda with a marathon of his films. Also in May 2005, the United States Post Office released a 37-cent postage stamp with an artist's drawing of Fonda as part of their \"Hollywood legends\" series. The Fonda Theatre in Hollywood, originally known as the Carter DeHaven Music Box, was named for the actor in 1985 by the Nederlander Organization.\nIn popular culture.\nIn Joseph Heller's satirical novel \"Catch-22,\" there is a running joke that fictional character Major Major Major Major resembles Henry Fonda. Philip D. Beidler comments that \"one of the novel's great absurd jokes is the character's bewildering resemblance to Henry Fonda\".\nFilmography.\nFrom the beginning of his career in 1935 through his last projects in 1981, Fonda appeared in 106 films, television programs, and shorts. Through the course of his career, he appeared in many films, including classics such as \"12 Angry Men\" and \"The Ox-Bow Incident\". He was nominated for an Academy Award for Best Actor for his role in 1940's \"The Grapes of Wrath\" and won for his part in 1981's \"On Golden Pond\". Fonda made his mark in Westerns (which included his most villainous role as Frank in \"Once Upon a Time in the West\") and war films, and made frequent appearances in both television and foreign productions late in his career.\nTheatre.\nBroadway stage performances\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "46229", "revid": "16713407", "url": "https://en.wikipedia.org/wiki?curid=46229", "title": "Beyond the Fringe", "text": "1960s British comedy revue/play\nBeyond the Fringe was a British comedy stage revue written and performed by Alan Bennett, Peter Cook, Jonathan Miller, and Dudley Moore. It debuted at the 1960 Edinburgh Festival and went on to play in London's West End and then in America, both on tour and on New York's Broadway in the early 1960s. Hugely successful, it is widely regarded as seminal to the \"satire boom\", the rise of satirical comedy in 1960s Britain.\nThe show.\nThe idea for \"Beyond the Fringe\" came from Robert Ponsonby, who was the director of the Edinburgh International Festival from 1956 to 1960. Ponsonby's idea was to bring together the best parts of the revues staged by the Cambridge Footlights and The Oxford Revue at the Edinburgh Fringe in previous years. He said that the Festival should put on a late-night revue \"to beat The Fringe at its own game.\" By 1960, the Festival was so firmly established that \"it required for its health some good-humoured self-mockery.\" \nPonsonby's assistant, John \"Johnny\" Bassett, recommended Dudley Moore, who had played with Bassett in a jazz band while at university in Oxford. Moore in turn recommended Alan Bennett, who had had a hit at the Fringe a few years earlier. Bassett also chose Jonathan Miller, who had been a Footlights star in 1957. Miller recommended Cook.\nBennett and Miller were already pursuing careers in academia and medicine respectively, but Cook had an agent, having written a West End revue for Kenneth Williams. Cook's agent negotiated a higher weekly fee for him, but by the time the agent's fee was deducted Cook actually earned less than the others from the initial run.\nThe majority of the sketches were by Cook and were largely based on material written for other revues. Among the entirely new material were \"The End of the World\", \"TVPM\" and \"The Great Train Robbery\". Cook and Moore revived some of the sketches on their later television and stage shows, most famously the two-hander \"One Leg Too Few\". Miller told the press in March 1960 that the show would \"be anti-establishment, anti-capital punishment, anti-colour bar and anti-1960. But it will be all very serious stuff, sharp, bitter and to the point.\"\nThe show's run in Edinburgh was immensely successful. Before beginning its run in the West End, the show had great success at the Cambridge Arts Theatre, but a brief run in Brighton garnered a lukewarm response. When the revue transferred to the Fortune Theatre in London, opening in early May 1961, in a revised production by Donald Albery and William Donaldson and directed by Eleanor Fazan, it became a true sensation. This was helped in large part by a favourable review by Kenneth Tynan.\nIn 1962, the show transferred to the John Golden Theatre in New York, with its original cast. President John F. Kennedy attended a performance on 10 February 1963. The show continued in New York, with most of the original cast, until 1964, when Paxton Whitehead replaced Miller, while the London version continued with a different cast until 1966.\nControversy.\nThe revue is widely considered to be ahead of its time, both in its unapologetic willingness to debunk figures of authority, and by virtue of its inherently surrealistic comedic vein. Humiliation of authority was something only previously delved into in \"The Goon Show\" and, arguably, \"Hancock's Half Hour\", with such parliamentarians as Sir Winston Churchill and Harold Macmillan coming under special scrutiny\u2014although the BBC were predisposed to frown upon it. Macmillan\u2014according to Cook\u2014was not particularly fond of the slurred caricature and charade of senile forgetfulness (marked by a failure to pronounce 'Conservative Party' coherently) handed down on him in Cook's impersonation. Since \"Beyond the Fringe\" was not owned by the BBC, however, the quartet enjoyed relative carte blanche. The only protocol they were obliged to adhere to was that, by law, their scripts for theatrical performances had to be sent to the Lord Chamberlain for approval prior to performance, a requirement abolished by the Theatres Act in 1968.\nMost specifically, its lampooning of the British war effort in a sketch titled \"The Aftermyth of War\" was scorned by some war veterans for its supposed insensitivity. One British visitor to the Broadway performance was said to have stood up and shouted 'rotters!' at a sketch he found distasteful, before apparently sitting down again and enjoying the remainder of the show, while another, at the first performance in Edinburgh, allegedly stood up and declared that the 'young bounders don't know the first thing about it!' and promptly left the auditorium. In response to these negative audience reactions, the \"Beyond the Fringe\" team said that they were not ridiculing the efforts of those involved in the war, but were challenging the subsequent media portrayal of them.\nInfluence.\n\"Beyond the Fringe\" was a forerunner to British television programmes \"That Was the Week That Was\", \"At Last the 1948 Show\", and \"Monty Python's Flying Circus\".\nAs with the established comedy revue, it was a series of satirical sketches and musical pieces using a minimal set, looking at events of the day and, with Shakespeare, the past. It effectively represented the views and disappointments of the first generation of British people to grow up after World War II, and gave voice to a sense of the loss of national purpose with the end of the British Empire. Although all of the cast contributed material, the most often quoted pieces were those by Cook, many of which had appeared before in his Cambridge Footlights revues. The show broke new ground with Peter Cook's impression of then Prime Minister Harold Macmillan; on one occasion, this was performed with Macmillan in the audience, and Cook added an \"ad lib\" ridiculing Macmillan for turning up to watch.\nThe show is credited with giving many other performers the courage to be satirical and more improvisational in their manner, and broke the conventions of not lampooning the Royal Family or the government of the day. Shakespearean drama was another target of their comedy. There were also a number of musical items in the show, using Dudley Moore's music, most famously an arrangement of the Colonel Bogey March which resists Moore's repeated attempts to bring it to an end.\nThe show prefigured the Satire Boom of the 1960s. Without it, there might not have been either \"That Was the Week That Was\" or \"Private Eye\", the satirical magazine which originated at the same time, that partially survived due to financial support from Peter Cook, and that served as the model for the later American \"Spy\" magazine. Cook and Moore formed a comedy duo and appeared in the popular television show \"Not Only... But Also\", and the 1967 film \"Bedazzled\". Cook also launched his club, The Establishment, around this time. Many of the members of Monty Python recall being inspired by \"Beyond the Fringe\".\nThe retrospective show \"Before the Fringe\", broadcast during the early years of BBC 2, took its title from this production. It consisted of performances of material that was popular in theatrical revue before the advent of \"Beyond the Fringe\".\nAll four members appeared in the Amnesty International charity stage show Pleasure at Her Majesty's, reprising most of the material.\nInternational success.\nThe show's success was not limited to the UK. In 1962, it also opened in South Africa. Next it arrived in the US. First the Broadway Company opened on 27 October 1962, then it was performed by the National Company in 1963. Subsequently, opening on 8 October 1964, the National Touring Company took it on a nationwide tour for six months as \"Beyond the Fringe '65\" under the auspices of Alexander H. Cohen, with the cast consisting of Bob Cessna, Donald Cullen, Joel Fabiani, and James Valentine. Slight changes were made to adapt the show for American audiences, for instance the opening number (discussing America) was retitled \"Home Thoughts from Abroad\".\nThe show was revived in slightly altered form in Los Angeles in 2000 and 2001 by Joseph Dunn's ReEstablishment Theater to critical acclaim.\nLegacy.\nThe four original members of \"Beyond the Fringe\" feature prominently as characters in the play \"\", by Chris Bartlett and Nick Awde. Appropriately, that comedy-drama had a sellout run at the 2005 Edinburgh Festival Fringe before transferring to London's West End at The Venue, in 2006, in a version starring Kevin Bishop as Moore, Tom Goodman-Hill as Cook, Fergus Craig as Alan Bennett and Colin Hoult as Jonathan Miller. It subsequently embarked on a nationwide tour.\nThe creation, performance and aftermath of the show are covered in the 2004 film \"Not Only But Always\".\n\"Good Evening\", Roy Smiles' play about the Beyond The Fringe team, was broadcast on BBC Radio 4 in 2008, with Benedict Cumberbatch as Dudley Moore.\nIn 2017, \"Beyond the Fringe\" was recreated for an episode of the Netflix TV series \"The Crown\" in which Prime Minister Macmillan is in attendance and singled out for abuse by Peter Cook (performed by Patrick Warner.)"}
{"id": "46230", "revid": "33780426", "url": "https://en.wikipedia.org/wiki?curid=46230", "title": "James Dobson", "text": "American evangelical Christian psychologist and author (1936\u20132025)\nJames Clayton Dobson Jr. (April 21, 1936 \u2013 August 21, 2025) was an American evangelical Christian author, psychologist and founder of Focus on the Family (FotF), which he led from 1977 until 2010. In the 1980s, he was ranked as one of the most influential spokesmen for conservative social positions in American public life. Although never an ordained minister, he was called \"the nation's most influential evangelical leader\" by \"The New York Times\" while \"Slate\" portrayed him as being a successor to evangelical leaders Jerry Falwell and Pat Robertson.\nAs part of his former role in the organization he produced the daily radio program \"Focus on the Family\", which the organization has said was broadcast in more than a dozen languages and on over 7,000 stations worldwide, and reportedly heard daily by more than 220 million people in 164 countries. \"Focus on the Family\" was also carried by about 60 U.S. television stations daily. In 2010, he launched the radio broadcast \"Family Talk with Dr. James Dobson\".\nDobson advocated for \"family values\"\u2014the instruction of children in heterosexuality and traditional gender roles, which he believed are mandated by the Bible. The goal of this was to promote heterosexual marriage, which he viewed as a cornerstone of civilization that was to be protected from his perceived dangers of feminism and the LGBTQ rights movement. Dobson sought to equip his audience to fight in the American culture war, which he called the \"Civil War of Values\".\nHis writing career began as an assistant to Paul Popenoe. After Dobson's rise to prominence through promoting corporal punishment of disobedient children in the 1970s, he became a founder of purity culture in the 1990s. He promoted his ideas via his various Focus on the Family affiliated organizations, the Family Research Council which he founded in 1981, Family Policy Alliance which he founded in 2004, the Dr. James Dobson Family Institute which he founded in 2010, and a network of US state-based lobbying organizations called Family Policy Councils.\nEarly life and education.\nJames Clayton Dobson Jr. was born to Myrtle Georgia (n\u00e9e Dillingham) and James C. Dobson Sr. on April 21, 1936, in Shreveport, Louisiana. From his earliest childhood, religion played a central part in his life. He once told a reporter that he learned to pray before he learned to talk, and says he gave his life to Jesus at the age of three, in response to an altar call by his father. He was the son, grandson, and great-grandson of Church of the Nazarene ministers.\nHis parents were traveling evangelists; as a child, Dobson often stayed with family members while his parents were out traveling. Like most Nazarenes, they forbade dancing and going to movies. Young Jimmie Lee, as he was called, concentrated on his studies. As a teenager, he was rebellious, though he eventually found a close relationship with his father.\nDobson's mother was intolerant of \"sassiness\" and would strike her child with whatever object came to hand, including a shoe or belt; she once gave Dobson a \"massive blow\" with a girdle outfitted with straps and buckles. Dobson studied academic psychology and came to believe that he was being called to become a Christian counselor or perhaps a Christian psychologist. He attended Pasadena College (now Point Loma Nazarene University) as an undergraduate, where he met his wife, Shirley, and served as captain of the school's tennis team. Dobson graduated in 1958, served in the National Guard for six months, and began working at Children's Hospital Los Angeles. In 1967, Dobson received his doctorate in psychology from the University of Southern California in Los Angeles.\nCareer.\nEarly career.\nIn 1967, he became an Associate Clinical Professor of Pediatrics at the University of Southern California School of Medicine for 14 years. At USC he was exposed to troubled youth and the counterculture of the 1960s. He found it \"a distressing time to be so young\" because society offered him no moral absolutes he felt he could rely upon. Opposition to United States involvement in the Vietnam War was blossoming into a widespread rejection of authority, which Dobson viewed as \"a sudden disintegration of moral and ethical principles\" among Americans his age and the younger people he saw in clinical practice. This convinced him that \"the institution of the family was disintegrating.\"\nBased on these experiences, in 1970 Dobson published \"Dare to Discipline\". The book encouraged parents to assert their authority over their children, particularly by corporal punishment. Dobson saw children as rebellious and inherently sinful and believed a rejection of authority to be the source of societal problems. He wrote that \"Respect for leadership is the glue that holds social organization together. Without it there is chaos, violence, and insecurity for everyone.\"\nHe spent 17 years on the staff of the Children's Hospital of Los Angeles in the Division of Child Development and Medical Genetics. For a time, Dobson worked as an assistant to Paul Popenoe and counselor at Popenoe's Institute of Family Relations, a marriage-counseling center, in Los Angeles. Popenoe counseled couples on the importance of same-race marriage and adherence to gender norms for the purpose of eugenics. Under Popenoe, Dobson published about male-female differences and the dangers of feminism. When the American Psychological Association de-pathologized homosexuality by removing it from their list of mental disorders in 1973, Dobson resigned from the organization in protest. In 1976, he took a sabbatical from USC and Children's Hospital; he never returned.\nWith funding from a Christian publisher, he began to broadcast his ideas on the radio and in public lectures. Saying that he feared to repeat the mistakes of his own absentee father by being away on the lecture circuit, Dobson video recorded and distributed his lectures. He sent a representative around the country to solicit funding from evangelical businessmen and distribute the videos. A video about absent fathers titled \"Where's Dad?\" had 100 million views by the early 1980s.\nFocus on the Family.\nIn 1977, he founded Focus on the Family. He grew the organization into a multimedia empire by the mid-1990s, including 10 radio programs, 11 magazines, numerous videos, and basketball camps, and program of faxing suggested sermon topics and bulletin fillers to thousands of churches every week. In 1995, the organization's budget was more than $100 million annually.\nBefore becoming famous for the radio ministry, he created the \"Focus on the Family Film Series\" released in 1978 based on his Family Life seminars.\nJimmy Carter organized a White House Conference on Families in 1979\u20131980 that explicitly included a \"diversity of families\" with various structures. Dobson objected to this, believing that only his preferred notion of the traditional family\u2014one headed by a male breadwinner married to a female caregiver\u2014should be endorsed by the conference. He also objected to the fact that he was not invited to the planning for the event. At Dobson's urging, his listeners wrote 80,000 letters to the White House asking for Dobson to be invited, which he eventually was. This demonstrated to Dobson his power to rally his followers for political ends.\nBeginning in 1980, Dobson built networks of political activists and founded lobbying organizations that advocated against LGBTQ rights and opposed legal abortion, among other socially conservative policy goals. He nurtured relationships with conservative politicians, such as Ronald Reagan. He was among the founders of Family Research Council in 1981, a federal lobbying organization classified as a hate group, and Family Policy Councils that lobby at the level of state government. When Focus on the Family moved to Colorado Springs in 1991, the city started to be called \"the Vatican of the Religious Right\" with Dobson imagined as an evangelical pope.\nFocus on the Family established an ex-gay program called Love Won Out in 1998. The program promoted conversion therapy, the pseudoscientific practice of attempting to make gay people straight. Dobson increased his promotion of Love Won Out in 2000 upon discovering that opposition to gay marriage was helping the Christian Right gain members and voters. State-level affiliates of FotF drafted gay marriage bans in several states, starting with Nebraska Initiative 416 in 2000. Dobson broadcast that gay marriage was turning children from faithful Christian homes against God. His arguments caused large evangelical turnouts in support of the gay marriage prohibitions, resulting in defense of marriage amendments to thirty U.S. state constitutions.\nDobson stepped down as president and CEO of Focus on the Family in 2003, and resigned from the position of chairman of the board in February 2009. Dobson explained his departure as twofold: firstly, to allow a smooth transfer of leadership to the next generation, and in this case, to Jim Daly whom he directly appointed as his replacement. And secondly, because he and Daly had divergent views on policy, \"especially when it comes to confronting those who would weaken the family and undermine our faith.\" After he stepped down, Focus on the Family hired an orthodoxy expert to maintain Dobson's message. Free to become more explicitly political without imperiling Focus on the Family's tax exemptions, Dobson rededicated himself primarily to lobbying instead of advice to families. While Daly attempted to appeal to a new generation of evangelicals with softened messages on abortion and homosexuality, Dobson remained hard-line. Focus on the Family removed archives of Dobson's writing from their headquarters and website.\nTed Bundy interview.\nDobson interviewed serial killer Ted Bundy on-camera the day before Bundy's execution on January 24, 1989. The interview became controversial because Bundy was given an opportunity to attempt to explain his actions (the rape and murder of 30 young women). Bundy claimed in the interview (in a reversal of his previous stance) that violent pornography played a significant role in molding and crystallizing his fantasies. In May 1989, during an interview with John Tanner, a Republican Florida prosecutor, Dobson called for Bundy to be forgiven. The Bundy tapes gave Focus on the Family revenues of over $1 million, $600,000 of which it donated to anti-pornography groups and to anti-abortion groups.\nShift to political activity.\nIn 2004, Dobson founded Family Policy Alliance, a lobbying arm of his media empire. With a more permissive tax status than Focus on the Family, it was allowed to directly fundraise for political campaigns. The Alliance also coordinates the action of Dobson's network of state-based Family Policy Councils. Together, these organizations seek to encode traditional gender roles into public policy and law. They consider LGBTQ rights to be a threatening \"agenda\".\nThroughout its existence, Dobson has attacked the President's Emergency Plan for AIDS Relief (PEPFAR), a US government program to fight AIDS worldwide. In 2006, he said that \"80 percent of this money is going toward terrible programs that are immoral as well as ineffective. For example, to promote condom distribution, people associated with these government programs have dressed up like condoms and created ceramic sculptures of male genitalia.\" He renewed his attack in 2023, falsely claiming that PEPFAR funds abortions. Focus on the Family received a grant of $49,505 through PEPFAR in 2017 to operate an abstinence-only purity pledge program.\nDr. James Dobson Family Institute.\nIn 2010, Dobson founded the Dr. James Dobson Family Institute, a non-profit organization that produces his radio program, \"Dr. James Dobson's Family Talk\". He stepped away from leadership of the Dr. James Dobson Family Institute in 2022, naming Joe Waresak the new president. He continued to broadcast his radio show.\nDobson frequently appeared as a guest on the Fox News Channel.\nPersonal life and death.\nDobson and Shirley Deere were married on August 26, 1960. The couple had two children. Dobson turned control of some of Focus on the Family's youth-oriented magazine titles over to his son Ryan Dobson in 2009. He gave his daughter a golden key necklace as a gift when she voiced her commitment to sexual purity at age ten. He encouraged other parents to give similar gifts.\nDobson died at his home in Colorado Springs, Colorado, on August 21, 2025, at the age of 89.\nAwards.\nAt the invitation of Presidents and Attorneys General, Dobson has also served on government advisory panels and testified at several government hearings. He was given the \"Layman of the Year\" award by the National Association of Evangelicals in 1982, \"The Children's Friend\" honor by Childhelp USA (an advocate agency against child abuse) in 1987, and the Humanitarian Award by the California Psychological Association in 1988. In 2005, Dobson received an honorary doctorate from Indiana Wesleyan University and was inducted into IWU's \"Society of World Changers\", while speaking at the university's Academic Convocation.\nIn 2008, Dobson's \"Focus on the Family\" program was inducted into the National Radio Hall of Fame to controversy from secular listeners opposed to Dobson's views, along with those supporting LGBTQ rights.\nSocial views.\nViews on marriage.\nJames Dobson was a strong proponent of marriage defined as \"one where husband and wife are lawfully married, are committed to each other for life\", and have a homemaker mother and breadwinner father. According to his view, women are not deemed inferior to men because both are created in God's image, but each gender has biblically mandated roles. He recommended that married women with children under the age of 18 focus on mothering, rather than work outside the home.\nDobson could be said to have viewed marriage as a transaction in which women exchange sex for protection:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The natural sex appeal of girls serves as their primary source of bargaining power in the game of life. In exchange for feminine affection and love, a man accepts a girl as his lifetime responsibility\u2014supplying her needs and caring for her welfare. This sexual aspect of the marital agreement can hardly be denied.\u2014\u200a\nHe advised wives to use their social and sexual skills to coerce their husbands into becoming good partners. By doing this, according to Dobson, women would transform male lust into love, and male destructive impulses into useful accomplishments. He regarded heterosexual marriage as the cornerstone of civilization, as women fulfilled their role of civilizing their husbands.\nIn his 2004 book \"Marriage Under Fire\", Dobson suggested that heterosexual marriage rates in Denmark, Norway, and Sweden was falling due to the recognition of same-sex relationships by those countries during the 1990s. He remarked that the \"institution of marriage in those countries is rapidly dying\" as a result, with most young people cohabiting or choosing to remain single (living alone) and illegitimacy rates rising in some Norwegian counties up to 80%.\nDobson wrote that \"every civilization in the world\" had been built upon marriage. He also believed that homosexuality was neither a choice nor genetic, but was caused by external factors during early childhood. He anecdotally cited as evidence the life of actress Anne Heche, who was previously in a relationship with Ellen DeGeneres. Criticizing \"the realities of judicial tyranny\", Dobson wrote that \"[t]here is no issue today that is more significant to our culture than the defense of the family. Not even the war on terror eclipses it.\"\nViews on schooling.\nFocus on the Family supports private school vouchers and tax credits for religious schools. According to the Focus on the Family website, Dobson believed that parents were ultimately responsible for their children's education, and encourages parents to visit their children's schools to ask questions and to join the PTA so that they may voice their opinions. Dobson opposed sex education curricula that are not abstinence-only.\nAccording to People for the American Way, Focus on the Family material has been used to challenge a book or curriculum taught in public schools. Critics, such as People for the American Way, allege that Focus on the Family encourages Christian teachers to establish prayer groups in public schools. Dobson supported student-led prayer in public schools, and believed that allowing student-led Christian prayer in schools did not violate the First Amendment to the United States Constitution.\nViews on discipline of children.\nIn his book \"Dare to Discipline\", Dobson advocated the spanking of children as young as fifteen months and up to eight years old when they misbehave, using switches or belts kept on the child's dresser as a reminder of authority. In Dobson's opinion, parents must uphold their authority and do so consistently. Dobson said corporal punishment should end with the child asking for forgiveness and receiving a hug. After the spanking, he believed in having a \"heart to heart\" talk with a child, which provided an opportunity to re-bond and express love to the child. Though \"Dare to Discipline\" was not overtly political, Dobson considered his parenting techniques to be the solution to the social unrest of the 1960s. The book was a rebuttal to Benjamin Spock, whose parenting ideas were more permissive. By returning to the authoritarian parenting style popular in prior eras, Dobson hoped to preserve order, obedience, and social hierarchy. The book quickly sold over two million copies, establishing Dobson as a trusted authority among parents bewildered by the rapid changes of the era.\nIn \"The Strong-Willed Child\", Dobson drew an analogy between the defiance of a family pet and that of a small child, and concludes that \"just as surely as a dog will occasionally challenge the authority of his leaders, so will a little child\u2014only more so.\" \"The Strong-Willed Child\" says that if authority is portrayed correctly to a child, the child will understand how to interact with other authority figures:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;By learning to yield to the loving authority... of his parents, a child learns to submit to other forms of authority which will confront him later in his life\u2014his teachers, school principal, police, neighbors and employers.\nIf allowed to challenge parental authority, Dobson says, children would challenge God's authority when they grew older. Hence, rebellion must be punished to protect the child's salvation. Believing that \"pain is a marvelous purifier\", Dobson recommended corporal punishment as the most effective way to keep the child subordinate to adults. He believed the parent should model both divine mercy and wrath to prepare the inherently sinful child for a relationship with God. Dobson warned of the dire consequences of failing to discipline one's children: \"Eli, the priest, permitted his sons to desecrate the temple. All three were put to death.\"\nHe warned against \"harsh spanking\", as he found it unnecessary to beat a child into submission. In a 1997 book, he warns that \"discipline must not be harsh and destructive to the child's spirit.\" Dobson considers disciplining children to be a necessary but unpleasant part of raising children which should only be carried out by qualified parents:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Anyone who has ever abused a child\u2014or has ever felt himself losing control during a spanking\u2014should not expose the child to that tragedy. Anyone who has a violent temper that at times becomes unmanageable should not use that approach. Anyone who secretly 'enjoys' the administration of corporal punishment should not be the one to implement it.\nWhen asked \"How long do you think a child should be allowed to cry after being punished? Is there a limit?\" Dobson responded:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Yes, I believe there should be a limit. As long as the tears represent a genuine release of emotion, they should be permitted to fall. But crying quickly changes from inner sobbing to an expression of protest... Real crying usually lasts two minutes or less but may continue for five. After that point, the child is merely complaining, and the change can be recognized in the tone and intensity of his voice. I would require him to stop the protest crying, usually by offering him a little more of whatever caused the original tears. In younger children, crying can easily be stopped by getting them interested in something else.\nSociologists John Bartkowski and Christopher Ellison have stated that Dobson's views \"diverge sharply from those recommended by contemporary mainstream experts\" and are not based on any sort of empirical testing, but rather are nothing more than expressions of his religious doctrines of \"biblical literalism and 'authority-mindedness.'\" In the 1980s, Penelope Leach wrote that Dobson's approach was ineffective because, rather than establishing parental authority, spanking only communicates parental frustration and weakness.\nAlthough childrearing experts have discredited corporal punishment, Dobson did not change his views. In 2015, he wrote that, when spanking fails to make a child obey, the problem may be that the parent is not hitting hard enough or frequently enough.\nViews on tolerance and diversity.\nIn the winter of 2004\u20132005, the We Are Family Foundation sent American elementary schools approximately 60,000 copies of a free DVD using popular cartoon characters (especially SpongeBob SquarePants) to \"promote tolerance and diversity\". Dobson contended that \"tolerance\" and \"diversity\" were \"buzzwords\" that the We Are Family Foundation misused as part of a \"hidden agenda\" to promote homosexuality. Kate Zernik pointed out Dobson asserting: \"tolerance and its first cousin, diversity, 'are almost always buzzwords for homosexual advocacy.'\" He said on the Focus on the Family website that \"childhood symbols are apparently being hijacked to promote an agenda that involves teaching homosexual propaganda to children.\" He offered as evidence the association of many leading LGBTQ rights organizations, including GLAAD, GLSEN, HRC, and PFLAG, with the We Are Family Foundation as shown by links which he claims once existed on their website.\nThe We Are Family Foundation countered that Dobson had mistaken their organization with \"an unrelated Web site belonging to another group called 'We Are Family', which supports gay youth.\" Dobson countered:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIn September 2005, Tolerance.org published a follow-up message advertising the DVD's continued availability, including We Are Family Foundation president Nancy Hunt's speculation that many of the DVDs may be \"still sitting in boxes, unused, because of Dobson's vitriolic attack\".\nViews on homosexuality.\nIn Dobson's view, homosexuality results from influences in a child's environment rather than an inborn trait. He said that homosexual behavior, specifically \"unwanted same-sex attraction\", has been and can be \"overcome\" through understanding developmental models for homosexuality and choosing to heal the complex developmental issues which led to same-sex attraction.\nFocus on the Family ministry sponsored the monthly conference Love Won Out, where participants hear \"powerful stories of ex-gay men and women\". Parents, Families and Friends of Lesbians and Gays (P-FLAG) protested against the conference in Orlando, questioning both its methodology and supposed success. In regards to the conference, Dobson stated that\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Gay activists come with preconceived notions about who we are and what we believe and about the hate that boils from within, which is simply not true. Regardless of what the media might say, Focus on the Family has no interest in promoting hatred toward homosexuals or anyone else. We also don't wish to deprive them of their basic constitutional rights. The Constitution applies to all of us. Dobson strongly opposed the movement to legitimize same-sex marriages. In his book \"Bringing Up Boys\", Dobson stated, &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[T]he disorder is not typically 'chosen.' Homosexuals deeply resent being told that they selected this same-sex inclination in pursuit of sexual excitement or some other motive. It is unfair, and I don't blame them for being irritated by that assumption. Who among us would knowingly choose a path that would result in alienation from family, rejection by friends, disdain from the heterosexual world, exposure to sexually transmitted diseases such as AIDS and tuberculosis, and even a shorter lifespan?\nCritics have stated that Dobson's views on homosexuality do not represent the mainstream views of the mental health community, with Dan Gilgoff referring to the positions of the American Psychiatric Association and the American Psychological Association on homosexuality. Sociologist Judith Stacey criticized Dobson for claiming that sociological studies show that gay couples do not make good parents. She stated that Dobson's claim \"is a direct misrepresentation of my research\".\nDobson objected to a bill expanding the prohibition of sexual orientation-based discrimination in the areas of \"public accommodation, housing practices, family planning services and twenty other areas\". He said that, were such a bill passed, public businesses could no longer separate locker rooms and bathrooms by gender, which he claimed would lead to a situation where \"every woman and little girl will have to fear that a predator, bisexual, cross-dresser or even a homosexual or heterosexual male might walk in and relieve himself in their presence\".\nIn 2017, Dobson was among the first to sign the Nashville Statement, written by the Council on Biblical Manhood and Womanhood. The statement specifies conservative evangelical views on gender roles and sexuality, condemning LGBTQ-affirming Christians: \"We affirm that it is sinful to approve of homosexual immorality or transgenderism and that such approval constitutes an essential departure from Christian faithfulness and witness.\"\nViews on mass shootings.\nIn 2012, in a broadcast titled \"A Nation Shaken by the Sandy Hook Tragedy\", Dobson said that the mass shooting was a judgment by God because of American acceptance of gay marriage and legal abortion. Similarly, Dobson said the 2019 El Paso shooting and mass shootings in general happen because \"the LGBTQ movement is closing in on the God-inspired and established institution of the family.\"\nViews on abortion.\nEarly in his career, Dobson appeared to accept abortion. He wrote a forward for a 1973 book, \"Sex is a Parent Affair\", that takes a nonjudgmental stance toward abortion because \"the Bible is silent on the subject\" except for some interpretations of which \"may indicate a developing embryo or fetus was not regarded as a full human being\". In general, the evangelical movement did not speak much about abortion until the 1980s.\nStarting in the 1980s, Dobson became a major force in the anti-abortion movement. His message centered upon biblically moral mothers who sacrificed for their children; he chastised unmarried mothers or \"rebellious\", believing pregnancy to be a sacred duty. He broadcast interviews with women who kept pregnancies because their trust in God overcame their own emotions and desires. Dobson contended that abortion invites women to reject God, diverts women from their natural role as mothers, and prevents more Christians from coming into the world. Ending abortion, in his view, would redeem society by binding women to their divine role. Focus on the Family and its allied lobbying organizations are among the US's most powerful advocates for restrictions on abortion access.\nViews on gender.\nDobson viewed the gender binary as fundamental to humanity; he believed God created men and women to differ \"in every cell of their bodies\". The complementary differences make them well-suited to traditional gender roles. \"Males and females differ biochemically, anatomically, and emotionally\", according to Dobson. Men like to \"hunt and fish and hike in the wilderness\" while women prefer to \"stay at home and wait for them\". Because men have a fragile ego and women are emotionally vulnerable, \"men derive self-esteem by being respected; women feel worthy when they are loved.\" Men and women are obligated to adhere to the \"time-honored roles of protector and protected\". The effects of hormonal differences, he argues, make women more suited for the home.\nDobson argued that confused gender relationships in a household result in homosexuality if a child displaces their sexual feelings onto the same-sex parent. Hence, parents should model a romance-like relationship with their opposite-sex child, according to Dobson, with the ultimate goal of steering the child toward heterosexual marriage as an adult.\nDobson encouraged \"daddy\u2013daughter dating\" in which fathers and daughters set aside time for special activities together. Because he believed heterosexuality must be cultivated, Dobson intended these romanticized attachments to model proper heterosexual partnership to girls age six or younger. An employee of Dobson's created the first purity ball\u2014a father-daughter dance event promoting female chastity\u2014in 1998. Dobson promoted the purity balls on his radio show. Along with other fundamentalist figures such as Billy Graham, Dobson is considered a founder of purity culture, a Christian subculture in which sexual immorality by women or LGBTQ people is considered a national threat.\nDobson considered transgender people a threat, writing in 2016 that \"a married man with any gumption\" would defend his wife's privacy in the bathroom from \"a strange-looking man, dressed like a woman\". He also considered feminists a threat because they question the natural leadership of men. In his 1975 book \"What Wives Wish Their Husbands Knew About Women\" he denounces the \"feminist propaganda\" of strong female characters in movies, complaining when men are shown as inferior to a \"confident superchick\".\nGendered language in the Bible.\nIn response to a 1997 article in \"World\" magazine claiming that the \"New International Version\" of the Bible was going to be printed with gender-neutral language, Dobson called a meeting at Focus on the Family headquarters of influential men in the religious publishing business. The group drafted the Colorado Springs Guidelines, which require Bible translations to use male-default language such as the word \"man\" to designate the human race. As a result, plans for the gender-neutral Bible version were halted. When Dobson discovered his own \"Odyssey Bible\" used gender-neutral language, he discontinued it and offered refunds. According to \"World\", Dobson's 1997 meeting eventually led to the publication of the \"English Standard Version\" in 2001, which avoids gender-neutral language. Along with over a hundred other evangelical figures, in 2002 Dobson opposed publication of \"Today's New International Version\" because of the \"political correctness\" of the translation and the publisher's rejection of the Colorado Springs Guidelines.\nPolitical and social influence.\nDobson's social and political opinions were widely read among many evangelical church congregations in the United States, and he accrued substantial influence in the Republican Party. Among other conservative causes, his lobbying significantly contributed to numerous state-level bans on same-sex marriage.\nSocial influence.\nDobson's books on corporal punishment helped to legitimize the practice, providing it with theological grounding for Christian readers. When opposition to physical discipline became widespread in the 1980s and 1990s in American society, conservative Protestants emerged as perhaps the most ardent remaining supporters of corporal punishment. This support was bolstered by \"authority-centered\" parenting techniques advised in Dobson's books.\nDobson frequently cautioned parents to use corporal punishment in a limited way. Theologian Donald Eric Capps and psychologist Adah Maurer argued in the 1990s that, in practice, parents frequently use indiscriminate violence against children. They argue Dobson's work provides parents with self-serving theological rationalizations for their violent outbursts. Capps and Maurer conclude that the popularity of corporal punishment in this era damaged children in ways that may last into adulthood.\nThroughout his career at Focus on the Family, Dobson argued for gender role instruction. He believed that gender and sexuality were not fixed from birth, but required careful cultivation. He sought to provide boys with outlets for their natural aggression, and to teach girls how to develop romantic partnerships, which they use to channel and refine male destructive impulses into civilized behavior. Thus the feminist and LGBTQ rights movements, because they seek to disturb gender roles, are a threat not only to family harmony but to national strength. To preserve pious gender roles, Dobson distributed Christian-targeted psychological advice. His daily radio program \"Focus on the Family\" was (according to his organization) broadcast in more than a dozen languages and on over 7,000 stations worldwide, and reportedly heard daily by more than 220 million people in 164 countries.\nDuring the 1960s and 1970s effort to legalize abortion, journalism often reported the plight of women in need of abortion, such as Sherri Finkbine. Dobson, together with Francis Schaeffer and others, shifted the public conversation away from the suffering of women, toward the suffering of the fetus and the selfishness of women who seek abortion.\nThrough his books and broadcasts, Dobson sought to prepare parents to fight in the American culture wars, a conflict in which Dobson described that \"parents of faith are at war with culture\" and which he labeled a \"Civil War of Values\". Dobson wielded significant influence over parents and politically conservative Christians, and, in the 1990s, a reportedly significant segment of this dedicated following were women who worked inside the home.\nAround two thousand radio stations aired Dobson's program to an audience of six to ten million by the early 2000s. With over two million addresses on his mailing list, his organization launched a publishing house. Richard Land called him \"the most influential evangelical leader in America\" at that time, saying his influence was comparable to Billy Graham in the 1960s and 1970s.\nHe was a founder of purity culture, a nationwide chastity movement through which he significantly shaped American attitudes about sex and gender, and Alliance Defending Freedom. Dobson was a member of the Council on Biblical Manhood and Womanhood. He supported the evangelical men's parachurch organization Promise Keepers and contributed to their 1994 book \"The Seven Promises of a Promise Keeper\".\nPolitical influence.\nDobson chose to exercise political influence behind the scenes, as a \"political fixer\". It may have helped him maintain his credibility with his audience. He never ran for office or acted as the public head of a primarily political organization.\nStarting in 1980, Dobson built a network of conservative activists. In 1981, he founded the Family Research Council as a political arm through which \"social conservative causes\" could achieve greater political influence. Dobson was appointed by U.S. President Ronald Reagan to the National Advisory Committee on Juvenile Justice and Delinquency Prevention in 1982, where he served for two years. Through the 1980s, he coordinated the creation of Family Policy Councils in most US states, lobbying organizations that act on the level of state politics.\nBy the 1990s, Dobson had amassed a sizable network of conservative politicians, many of whom he met with regularly. Beginning in the same decade, Dobson and his vast activist organization helped pass state-level bans on gay marriage across the US. His top legislative goal was prohibiting gay marriage at the federal level, with a constitutional amendment. In 2005, he told his biographer \"my greatest concern is for the relentless attack by homosexual activists who are determined to destroy the institution of marriage.\"\nDobson was an ally of Judge Roy Moore starting in the early 1990s. He rallied his audience in support of the judge in 1997 and again in 2003 because of the Moore's refusal to remove a Ten Commandments display from the Alabama Judicial Building. Viewing Moore as \"a man of proven character and integrity\" Dobson endorsed Moore's political campaigns until 2017, when allegations came to light of Moore's sexual misconduct toward teen girls.\nIn late 2004, Dobson led a campaign to block the appointment of Arlen Specter to head of the Senate Judiciary Committee because of Specter's pro-abortion rights stance. Responding to a question by Fox News personality Alan Colmes on whether he wanted the Republican Party to be known as a \"big-tent party\", he replied, \"I don't want to be in the big tent ... I think the party ought to stand for something.\" In 2006, Focus on the Family spent more than a half million dollars to promote a constitutional amendment to ban same-sex marriage in its home state of Colorado.\nDobson founded a fundraising and lobbying arm of FotF called Focus on the Family Action, now called Family Policy Alliance. As a 501(c)(4) organization, it faces fewer IRS restrictions on political activity than FotF. In the organization's first six months of existence, it raised nearly nine million dollars in support of six Republican candidates for competitive US Senate seats. All six won their races. A May 2005 article by Chris Hedges in \"Harper's Magazine\" described Dobson as \"perhaps the most powerful figure in the Dominionist movement\" and \"a crucial player in getting out the Christian vote for George W. Bush\".\nIn November 2004, Dobson was described by the online magazine \"Slate\" as \"America's most influential evangelical leader\". The article stated \"Forget Jerry Falwell and Pat Robertson, who in their dotage have marginalized themselves with gaffes ... Dobson is now America's most influential evangelical leader, with a following reportedly greater than that of either Falwell or Robertson at his peak ... Dobson may have delivered Bush his victories in Ohio and Florida.\" Further, \"He's already leveraging his new power. When a thank-you call came from the White House, Dobson issued the staffer a blunt warning that Bush \"needs to be more aggressive\" about pressing the religious right's anti-abortion, anti-gay rights agenda, or it would \"pay a price in four years\". Dobson sometimes complained that the Republican Party may take the votes of social conservatives for granted, and has suggested that evangelicals may withhold support from the GOP if the party does not more strongly support conservative family issues.\nHowever, in 2006, Dobson said that, while \"there is disillusionment out there with Republicans\" and \"that worries me greatly\", he nonetheless suggested voters turn out and vote Republican in 2006. \"My first inclination was to sit this one out\", but according to \"The New York Times\", Dobson then added that \"he had changed his mind when he looked at who would become the leaders of Congressional committees if the Democrats took over.\"\nDobson garnered national media attention once again in February 2008 after releasing a statement in the wake of Senator John McCain's expected success in the so-called \"Super Tuesday\" Republican primary elections. In his statement, Dobson said: \"I cannot, and will not, vote for Senator John McCain, as a matter of conscience\", and indicated that he would refrain from voting altogether if McCain were to become the Republican candidate, echoing other conservative commentators' concerns about the Senator's conservatism. He endorsed Mike Huckabee for president. After McCain selected an anti-abortion candidate, Sarah Palin, as his running mate, Dobson said that he was more enthusiastic in his support for the Republican ticket. When Palin's 17-year-old daughter's pregnancy was revealed, Dobson issued a press release commending Palin's stance, saying,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We have always encouraged the parents to love and support their children and always advised the girls to see their pregnancies through, even though there will of course be challenges along the way. That is what the Palins are doing, and they should be commended once again for not just talking about their pro-life and pro-family values, but living them out even in the midst of trying circumstances.\nOn June 24, 2008, Dobson criticized statements made by U.S. presidential candidate Barack Obama in Obama's 2006 \"Call to Renewal\" address. Dobson said that Obama was \"distorting the traditional understanding of the Bible to fit his own world view\". On October 23, 2008, Dobson published a \"Letter from 2012 in Obama's America\" that proposed that an Obama presidency could lead to: mandated homosexual teachings across all schools; the banning of firearms in entire states; the end of the Boy Scouts, home schooling, Christian school groups, Christian adoption agencies, and talk radio; pornography on prime-time and daytime television; mandatory bonuses for gay soldiers; terrorist attacks across America; the nuclear bombing of Tel Aviv; the conquering of most of Eastern Europe by Russia; the end of health care for Americans over 80; out-of-control gasoline prices; and complete economic disaster in the United States, among other catastrophes. In the days after the 2008 presidential election, Dobson stated on his radio program that he was mourning the Obama election, claiming that Obama supported infanticide, would be responsible for the deaths of millions of unborn children, and was \"going to appoint the most liberal justices to the Supreme Court, perhaps, that we've ever had\".\nDobson supported intelligent design and spoke at conferences on the subject frequently criticizing evolution. In 2007, he was one of 25 evangelicals who called for the ouster of Richard Cizik from his position at the National Association of Evangelicals because Cizik had taken a stance urging evangelicals to take global warming seriously.\nOn June 13, 2007, the National Right to Life Committee ousted Colorado Right to Life after the latter ran a full-page ad criticizing Dobson. On May 30, 2010, Dobson delivered the pre-race invocation at the NASCAR Coca-Cola 600 automobile race, raising criticism about his association with a sport associated with sponsors and activities which would not meet his definition of family-friendly.\nAt a National Day of Prayer event in the U.S. Capitol, Dobson called Barack Obama \"the abortion president\". He said, \"President Obama, before he was elected, made it very clear that he wanted to be the abortion president. He didn't make any bones about it. This is something that he really was going to promote and support, and he has done that, and in a sense he is the abortion president.\" Among others, Rep. Janice Hahn complained because Dobson used the National Day of Prayer for partisan purposes. She said, \"Dobson just blew a hole into this idea of being a nonpartisan National Day of Prayer. It was very disturbing to me ... and really a shame. James Dobson hijacked the National Day of Prayer\u2014this nonpartisan, nonpolitical National Day of Prayer\u2014to promote his own distorted political agenda.\"\nDobson endorsed Ted Cruz in the 2016 Republican primaries as well as Trump in the general election against Hillary Clinton. In 2016, Dobson was one of the Trump Administration's evangelical faith advisors. In 2020, Dobson worked alongside other conservative evangelicals and evangelical organizations, including Jim Daly and Focus on the Family, to support the reelection of President Donald Trump. He echoed his support of Trump throughout the impeachment proceedings earlier that year.\nDobson praised the 2022 U.S. Supreme Court case \"Dobbs v. Jackson Women's Health Organization\", which overruled \"Roe v. Wade\" and \"Planned Parenthood v. Casey\", saying, \"Praise God! We have just received the news for which we have been praying and working!\"\nEcumenical relations.\nDobson and Charles Colson participated in a 2000 conference at the Vatican on the global economy's impact on families. During the conference, the two Protestants met with Pope John Paul II. Dobson later told the Catholic News Service that although he had theological differences with Roman Catholicism, \"when it comes to the family, there is far more agreement than disagreement, and with regard to moral issues from abortion to premarital sex, safe-sex ideology and homosexuality, I find more in common with Catholics than with some of my evangelical brothers and sisters.\"\nIn November 2009, Dobson signed an ecumenical statement known as the \"\" calling on evangelicals, Catholics and Eastern Orthodox Christians not to comply with rules and laws permitting abortion, same-sex marriage and other matters that go against their religious consciences.\nCriticism.\nU.S. Surgeon General C. Everett Koop, a fellow evangelical Christian who wanted Dobson as an ally in his battle to stem the AIDS crisis, was deeply disappointed when Dobson embraced pseudoscientific and homophobic claims about AIDS. \"The Christian activity in reference to AIDS of both D. James Kennedy and Jim Dobson is reprehensible\", Koop said in 1989. He viewed the AIDS crisis as \"an opportunity for Christian service\" which Dobson was squandering.\nIn her 2020 book \"Jesus and John Wayne\", Kristin Kobes Du Mez, a professor at Calvin University in Grand Rapids, Michigan criticizes the ideal of Christian masculinity created by Dobson, Mark Driscoll and others: \"It was a vision that promised protection for women but left women without defense, one that worshiped power and turned a blind eye to justice, and one that transformed the Jesus of the Gospels into an image of their own making.\"\nGil Alexander-Moegerle, a former Focus on the Family executive and radio show co-host, wrote the highly critical book \"James Dobson's War on America\" in 1997. In it, he says that Dobson's loving, caring public persona is a sham; the real Dobson is racist, sexist, homophobic, materialistic, power-hungry, and shameless. He says that the Nazarene religious concept of entire sanctification is key to understanding Dobson's views: \"James Dobson believes that he has been entirely sanctified, morally perfected, that he does not and cannot sin. Now you know why he and moralists like him make a life of condemning what he believes to be the sins of others. He is perfect.\"\nSome fundamentalist Christians consider Dobson a heretic for presenting secular concepts from psychology and self-help literature as though they are justified by the Bible.\nTheologian Donald Eric Capps contends that Dobson's corporal punishment techniques exploit children by turning their natural need to be loved against them. Dobson's advice to \"break the will\" of the child is a recipe for child abuse, according to Capps, and is antithetical to loving one's child. Capps also argues that corporal punishment may sexualize children. For evidence of this, he points to Dobson's vivid childhood recollection of being beaten with his mother's girdle. Capps believed that using physical pain to heighten a child's relationship to God is \"perverted\".\nDobson has been criticized for recommending conversion therapy advocate Joseph Nicolosi's methods of preventing homosexuality in children, including quoting Nicolosi's suggestion that \"[a] boy's father ... to mirror and affirm his son's maleness ... can even take his son with him into the shower, where the boy cannot help but notice that Dad has a penis, just like his, only bigger.\"\nPublications.\nDobson authored or co-authored 36 books including:\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
