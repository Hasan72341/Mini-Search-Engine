{"id": "41663", "revid": "12331483", "url": "https://en.wikipedia.org/wiki?curid=41663", "title": "Responsivity", "text": "Input-output gain of a detector system\nResponsivity is a measure of the input\u2013output gain of a detector system. In the specific case of a photodetector, it measures the electrical output per optical input. \nA photodetector's responsivity is usually expressed in units of amperes or volts per watt of incident radiant power. For a system that responds linearly to its input, there is a unique responsivity. For nonlinear systems, the responsivity is the local slope. Many common photodetectors respond linearly as a function of the incident power. \nResponsivity is a function of the wavelength of the incident radiation and of the sensor's properties, such as the bandgap of the material of which the photodetector is made. One simple expression for the responsivity \"R\" of a photodetector in which an optical signal is converted into an electric current (known as a photocurrent) is \n formula_1\nwhere formula_2 is the quantum efficiency (the conversion efficiency of photons to electrons) of the detector for a given wavelength, formula_3 is the electron charge, formula_4 is the frequency of the optical signal, and formula_5 is the Planck constant. This expression is also given in terms of formula_6, the wavelength of the optical signal, and has the unit of amperes per watt (A/W).\nThe term responsivity is also used to summarize input\u2013output relationship in non-electrical systems. For example, a neuroscientist may measure how neurons in the visual pathway respond to light. In this case, responsivity summarizes the change in the neural response per unit signal strength. The responsivity in these applications can have a variety of units. The signal strength typically is controlled by varying either intensity (intensity-response function) or contrast (contrast-response function). The neural response measure depends on the part of the nervous system under study. For example, at the level of the retinal cones, the response might be in photocurrent. In the central nervous system the response is usually spikes per second. In functional neuroimaging, the response measure is usually BOLD contrast. The responsivity units reflect the relevant stimulus and physiological units. \nWhen describing an amplifier, the more common term is gain. \n\"Deprecated synonym\" sensitivity. A system's sensitivity is the inverse of the stimulus level required to produce a threshold response, with the threshold typically chosen just above the noise level.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41664", "revid": "4413097", "url": "https://en.wikipedia.org/wiki?curid=41664", "title": "Restoration", "text": "Restoration is the act of restoring something to its original state. This may refer to:\nRestoration may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41665", "revid": "1778754", "url": "https://en.wikipedia.org/wiki?curid=41665", "title": "Return loss", "text": "Measure of power reflected by a discontinuity in a line or fiber\nIn telecommunications, return loss is a measure in relative terms of the power of the signal reflected by a discontinuity in a transmission line or optical fiber. This discontinuity can be caused by a mismatch between the termination or load connected to the line and the characteristic impedance of the line. It is usually expressed as a ratio in decibels (dB):\nformula_1\nwhere RL(dB) is the return loss in dB, \"P\"i is the incident power, and \"P\"r is the reflected power.\nReturn loss is related to both standing wave ratio (SWR) and reflection coefficient (\u0393). Increasing return loss corresponds to lower SWR. Return loss is a measure of how well devices or lines are matched. A match is good if the return loss is high. A high return loss is desirable and results in a lower insertion loss.\nFrom a certain perspective \"return loss\" is a misnomer. The usual function of a transmission line is to convey power from a source to a load with minimal loss. If a transmission line is correctly matched to a load, the reflected power will be zero, no power will be lost due to reflection, and \"return loss\" will be infinite. Conversely if the line is terminated in an open circuit, the reflected power will be equal to the incident power; all of the incident power will be lost in the sense that none of it will be transferred to a load, and RL will be zero. Thus the numerical values of RL tend in the opposite sense to that expected of a \"loss\".\nSign.\nAs defined above, RL will always be positive, since \"P\"r can never exceed \"P\"i. However, return loss has historically been expressed as a negative number, and this convention is still widely found in the literature. Strictly speaking, if a negative sign is ascribed to RL, the ratio of \"reflected\" to \"incident\" power is implied:\n formula_2\nwhere RL\u2032(dB) is the negative of RL(dB). \nIn practice, the sign ascribed to RL is largely immaterial. If a transmission line includes several discontinuities along its length, the total return loss will be the sum of the RLs caused by each discontinuity, and provided all RLs are given the same sign, no error or ambiguity will result. Whichever convention is used, it will always be understood that \"P\"r can never exceed \"P\"i.\nElectrical.\nIn metallic conductor systems, reflections of a signal traveling down a conductor can occur at a discontinuity or impedance mismatch. The ratio\n formula_3\nof the amplitude of the reflected wave \"V\"r to the amplitude of the incident wave \"V\"i is known as the reflection coefficient.\nReturn loss is the negative of the magnitude of the reflection coefficient in dB. Since power is proportional to the square of the voltage, return loss is given by\n formula_4\nwhere the vertical bars indicate magnitude. Thus, a large positive return loss indicates that the reflected power is small relative to the incident power, which indicates good impedance match between transmission line and load.\nIf the incident power and the reflected power are expressed in \"absolute\" decibel units, (e.g., dBm), then the return loss in dB can be calculated as the difference between the incident power \"P\"i (in absolute dBm units) and the reflected power \"P\"r (also in absolute dBm units):\n formula_5\nOptical.\nIn optics (particularly in fiber optics) a loss that takes place at discontinuities of refractive index, especially at an air\u2013glass interface such as a fiber endface. At those interfaces, a fraction of the optical signal is reflected back toward the source. This reflection phenomenon is also called \"Fresnel reflection loss\", or simply \"Fresnel loss\".\nFiber optic transmission systems use lasers to transmit signals over optical fiber, and a low optical return loss\n formula_6\n(where formula_7 is the reflected power, and formula_8 is the incident, or input, power) can cause the laser to stop transmitting correctly. The measurement of ORL is becoming more important in the characterization of optical networks as the use of wavelength-division multiplexing increases. These systems use lasers that have a lower tolerance for ORL and introduce elements into the network that are located in close proximity to the laser.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "41666", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41666", "title": "RF power margin", "text": "In telecommunications, the term RF power margin has the following meanings: "}
{"id": "41667", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41667", "title": "Ringaround", "text": "In telecommunications, the term ringaround has the following meanings:"}
{"id": "41668", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=41668", "title": "Ringback signal", "text": ""}
{"id": "41669", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41669", "title": "Ringdown", "text": "In telephony, ringdown is a method of signaling an operator in which telephone ringing current is sent over the line to operate a lamp or cause the operation of a self-locking relay known as a \"drop\".\nRingdown is used in manual operation, and is distinguished from automatic signaling by dialing a number. The signal consists of a continuous or pulsed alternating current (AC) signal transmitted over the line. It may be used with or without a telephone switchboard. The term originated in magneto telephone signaling in which cranking the magneto generator, either integrated into the telephone set or housed in a connected ringer box, would not only \"ring\" its bell but also cause a drop to fall \"down\" at the telephone exchange switchboard, marked with the number of the line to which the magneto telephone instrument was connected. At the end of the conversation, one participant would crank to \"ring off\", signaling the operator to take down the connection. In modern British English, \"ring off\" still means ending a telephone conversation, though it is of course done by other means. Ring off is also used figuratively to indicate no longer communicating with a person.\nThe last ringdown telephone exchange in the United States was located at Bryant Pond, Maine, had 400+ subscribers, and converted to dial service in October 1983.\nRingdown operator.\nIn telephone systems where calls from distant automated exchanges arrive for manual subscribers or non-dialable points, there often would be a ringdown operator (reachable from the distant operator console by dialling NPA+181) who would manually ring the desired subscriber on a party line or toll station. On some systems, this function was carried out by the inward operator (NPA+121). In both cases, this is a telephone operator at the destination who provides assistance solely to other operators on inbound toll calls; the ringdown operator nominally cannot be dialed directly by the subscriber.\nNon-operator use.\nIn an application \"not\" involving a telephone operator, a two-point automatic ringdown circuit, or ringdown, has a telephone at each end. When the telephone at one end goes off-hook, the phone at the other end instantly rings. No dialing is involved and therefore telephone sets without dials are sometimes used.\nMany ringdown circuits work in both directions. In some cases a circuit is designed to work in one direction only. That is, going off-hook at one end (end A) rings the other (end B). Going off-hook at end B has no effect at end A.\nRingdown features are often part of a key telephone system. In the wire spring relay key service units of the Bell System 1A2, a model 216 automatic ringdown was used to operate the circuit. In the 400-series units, a number of different KTUs operate (supervise) a ringdown, including the model 415. In other situations, the ringdown is powered and operated by equipment inside the telephone exchange.\nIn the case of enterprises with a private branch exchange (PBX) switch, the ringdown can be operated by the PBX key. The switch is programmed to ring a specific extension (the called phone) when a defined extension (the calling phone) goes off-hook. The PBX does not offer dial tone to the calling extension: it only detects on-hook or off-hook status.\nVoice over IP adapters can be networked and configured to provide automatic ringdown by selecting a dial plan which replaces the empty string with a predefined number or SIP address, dialed immediately. (Some Cisco VoIP phones and analog adapters treat a dial plan of (S0 &lt;:1234567890&gt;) as a hotline configuration which dials 1-234-567890 zero seconds after the telephone is taken off-hook, for instance).\nThese circuits are used:\n\"Example: an information desk and the information desk staff supervisor's desk.\"\n\"Example: a phone used to summon a taxicab to an airport or hotel.\"\n\"Example: a \"house phone\" in a hotel lobby to the live operator at the hotel's switchboard\"\n\"Example: the after-hours phone to reach the watchman from the front door at a warehouse.\"\n\"Example: an airport control tower to the airport's fire station or fire dispatch center.\"\n\"Example: Independent System Operator (ISO) communication to a power plant.\"\n\"Example: a hospital emergency department and an ambulance dispatch center.\"\nIn some cases, automatic ringdown circuits have one-to-many configurations. When one phone goes off-hook, a group of phones is made to ring simultaneously.\nIn cases where one or both ends of the circuit terminate in a key telephone system, a well designed system will have no hold feature on the ringdown circuit unless supervision provides a Calling Party Control (CPC) signal.\nPLAR.\nPrivate line automatic ringdown (PLAR) is a type of analog signaling often used in telephone-based systems. When a device is taken off-hook, ringing voltage is automatically applied to a circuit to alert other stations on the line. When answered on another station, a call is maintained over the circuit. The telephone company switch is not involved in the process, making this a private line.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41670", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=41670", "title": "Ringer equivalence number", "text": "Indication of the electrical load on a telephone line\nThe ringer equivalence number (REN) is a telecommunications measure that represents the electrical loading effect of a telephone ringer on a telephone line. In the United States, ringer equivalence was first defined by U.S. Code of Federal Regulations, Title 47, Part 68, based on the load that a standard Bell System model 500 telephone represented, and was later determined in accordance with specification \"ANSI/TIA-968-B\" (August 2009). Measurement systems analogous to the REN exist internationally.\nDefinition.\nThe ringer equivalence of 1 represents the loading effect of a single traditional telephone ringing circuit, such as that within the Western Electric model 500 telephone. The ringer equivalence of modern telephone equipment may be significantly lower than 1. For example, externally powered electronic ringing telephones may have a value as low as 0.1, while modern line-powered telephones, in which the ringer is powered from the telephone line, typically have a REN of approximately 0.8.\nIn the United States, the FCC Part 68 specification defined REN 1 as equivalent to a 6930 \u03a9 resistor in series with an (microfarad) capacitor. The modern ANSI/TIA-968-B specification (August 2009) defines it as an impedance of at (type A ringer), or from to (type B ringer).\nMaximum ringer equivalence.\nThe total ringer load on a subscriber line is the sum of the ringer equivalences of all devices (phone, fax, a separate answerphone, etc.) connected to the line. This represents the overall loading effect of the subscriber equipment on the central office ringing current source. Subscriber telephone lines are usually limited to support a ringer equivalence of 5, per the federal specifications.\nIf the total allowable ringer load is exceeded, the phone circuit may fail to ring or otherwise malfunction. For example, call waiting, caller ID, and ADSL services are often affected by high ringer load.\nSome analog telephone adapters for Internet telephony require analog telephones with low REN, for example, the AT&amp;T 210 is a basic phone which does not require an external electrical connection and has a REN of 0.9B.\nInternational specifications.\nIn the United Kingdom a maximum of 4 is allowed on any British Telecom (BT) line.\nIn Australia a maximum of 3 is allowed on any Telstra or Optus Line.\nIn Canada it is called a \"load number\" (LN); which must not exceed 100. The LN of each device represents the percentage of total load allowed.\nIn Europe 1 REN used to be equivalent to an 1800 \u03a9 resistor in series with a 1 \u03bcF capacitor. The latest ETSI specification (2003\u201309) calls for 1 REN to be greater than 16 k\u03a9 at 25\u00a0Hz and 50\u00a0Hz.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41671", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41671", "title": "Ring latency", "text": "In a ring network, such as Token Ring, ring latency is the time required for a signal to propagate once around the ring. Ring latency may be measured in seconds or in bits at the data transmission rate. Ring latency includes signal propagation delays in the ring medium, the drop cables, and the data stations connected to the ring network. "}
{"id": "41672", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41672", "title": "Round-trip delay", "text": "Time required to receive a response to a query across a communication system\nIn telecommunications, round-trip delay (RTD) or round-trip time (RTT) is the amount of time it takes for a signal to be sent \"plus\" the amount of time it takes for acknowledgement of that signal having been received. This time delay includes propagation times for the paths between the two communication endpoints. In the context of computer networks, the signal is typically a data packet. RTT is commonly used interchangeably with ping time, which can be determined with the ping command. However, ping time may differ from experienced RTT with other protocols since the payload and priority associated with ICMP messages used by ping may differ from that of other traffic.\nEnd-to-end delay is the length of time it takes for a signal to travel in one direction and is often approximated as half the RTT.\nProtocol design.\nRTT is a measure of the amount of time taken for an entire message to be sent to a destination and for a reply to be sent back to the sender. The time to send the message to the destination in its entirety is known as the network latency, and thus RTT is twice the latency in the network plus a processing delay at the destination. The other sources of delay in a network that make up the network latency are processing delay in transmission, propagation time, transmission time and queueing time. Propagation time is dependent on distance. Transmission time for a message is proportional to the message size divided by the bandwidth. Thus higher bandwidth networks will have lower transmission time, but the propagation time will remain unchanged, and so RTT does fall with increased bandwidth, but the delay increasingly represents propagation time.\nNetworks with both high bandwidth and a high RTT (and thus high bandwidth-delay product) can have large amounts of data in transit at any given time. Such \"long fat networks\" require a special protocol design. One example is the TCP window scale option.\nThe RTT was originally estimated in TCP by:\nformula_1\nwhere formula_2 is constant weighting factor (formula_3). Choosing a value for formula_2 close to 1 makes the weighted average immune to changes that last a short time (e.g., a single segment that encounters long delay). Choosing a value for formula_2 close to 0 makes the weighted average respond to changes in delay very quickly. This was improved by the Jacobson/Karels algorithm, which takes standard deviation into account as well. Once a new RTT is calculated, it is entered into the equation above to obtain an average RTT for that connection, and the procedure continues for every new calculation.\nWi-Fi.\nAccurate round-trip time measurements over Wi-Fi using IEEE 802.11mc are the basis for the Wi-Fi positioning system.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41673", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41673", "title": "Routing indicator", "text": "In telecommunications, the term routing indicator (RI) has the following meanings:\nA Routing Indicator is a group of letters assigned to identify a station within a tape relay network to facilitate routing of traffic. It indicates the status of the station and may indicate its geographical area. The following factors are reflected in routing indicator assignment:\nRouting indicators consist of not less than four, and not more than seven\nletters, including suffixes. The intent of allocated letters and of letter position is as follows:"}
{"id": "41674", "revid": "1763779", "url": "https://en.wikipedia.org/wiki?curid=41674", "title": "Rubidium standard", "text": "Frequency standard\nA rubidium standard or rubidium atomic clock is a frequency standard in which a specified hyperfine transition of electrons in rubidium-87 atoms is used to control the output frequency.\nSynopsis.\nThe Rb standard is the most inexpensive, compact, and widely produced atomic clock, used to control the frequency of television stations, cell phone base stations, in test equipment, and global navigation satellite systems like GPS. Commercial rubidium clocks are less accurate than caesium atomic clocks, which serve as primary frequency standards, so a rubidium clock is usually used as a secondary frequency standard. \nCommercial rubidium frequency standards operate by disciplining a crystal oscillator to the rubidium hyperfine transition of 6.8 GHz (). The intensity of light from a rubidium discharge lamp that reaches a photodetector through a resonance cell will drop by about 0.1% when the rubidium vapor in the resonance cell is exposed to microwave power near the transition frequency. The crystal oscillator is stabilized to the rubidium transition by detecting the light dip while sweeping an RF synthesizer (referenced to the crystal) through the transition frequency.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41675", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=41675", "title": "Rural radio service", "text": "Rural radiotelephone service (RRTS) provides basic, analog communications service between locations deemed so remote that traditional wireline service or service by other means is not feasible. RRTS uses channelized radio to provide radiotelephone services such as Basic Exchange Telephone Radio Service between a fixed subscriber location and a remote central office, private line service between a two fixed locations or interconnection between two or more central offices. RRTS does not enable mobile communications.\nLicensing.\nIn the United States, the Federal Communications Commission issues initial rural radiotelephone service licenses on a site-by-site basis. Once a license is issued, the licensee can sell or lease the license to another party.\nThe FCC service rules for rural radiotelephone are filed in 47 C.F.R. part 22 subpart F.\nTechnical information.\nIn the United States, the ULS radio service code and description for rural radiotelephone licenses is CR \u2013 Rural Radiotelephone. The licensed spectrum is divided in 44 channels of 20 kHz each.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41676", "revid": "8570870", "url": "https://en.wikipedia.org/wiki?curid=41676", "title": "Saturation", "text": "Saturation, saturated, unsaturation or unsaturated may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41677", "revid": "45203278", "url": "https://en.wikipedia.org/wiki?curid=41677", "title": "Scan", "text": "Scan, SCAN or Scanning may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41678", "revid": "45789152", "url": "https://en.wikipedia.org/wiki?curid=41678", "title": "Scanning", "text": ""}
{"id": "41679", "revid": "1312419563", "url": "https://en.wikipedia.org/wiki?curid=41679", "title": "Schematic", "text": "Representation of a system using abstract graphic symbols\nA schematic, or schematic diagram, is a designed representation of the elements of a system using abstract, graphic symbols rather than realistic pictures. A schematic usually omits all details that are not relevant to the key information the schematic is intended to convey, and may include oversimplified elements in order to make this essential meaning easier to grasp, as well as additional organization of the information.\nFor example, a subway map intended for passengers may represent a subway station with a dot. The dot is not intended to resemble the actual station at all but aims to give the viewer information without unnecessary visual clutter. A schematic diagram of a chemical process uses symbols in place of detailed representations of the vessels, piping, valves, pumps, and other equipment that compose the system, thus emphasizing the functions of the individual elements and the interconnections among them and suppresses their physical details. In an electronic circuit diagram, the layout of the symbols may not look anything like the circuit as it appears in the physical world: instead of representing the way the circuit \"looks\", the schematic aims to capture, on a more general level, the way it \"works\". This may be contrasted with a wiring diagram, which preserves the spatial relationships between each of its components.\nTypes.\nSchematics and other types of diagrams, e.g.,\nA semi-schematic diagram combines some of the abstraction of a purely schematic diagram with other elements displayed as realistically as possible, for various reasons. It is a compromise between a purely abstract diagram (e.g. the schematic of the Washington Metro) and an exclusively realistic representation (e.g. the corresponding aerial view of Washington).\nElectrical and electronic industry.\nIn electrical and electronic industry, a schematic diagram is often used to describe the design of equipment. Schematic diagrams are often used for the maintenance and repair of electronic and electromechanical systems. While schematics were traditionally drawn by hand, using standardized templates or pre-printed adhesive symbols, today electronic design automation software (EDA or \"electrical CAD\") is often used.\nIn electronic design automation, until the 1980s schematics were virtually the only formal representation for circuits. More recently, with the progress of computer technology, other representations were introduced and specialized computer languages were developed, since with the explosive growth of the complexity of electronic circuits, traditional schematics are becoming less practical. For example, hardware description languages are indispensable for modern digital circuit design.\nSchematics for electronic circuits are prepared by designers using EDA (electronic design automation) tools called schematic capture tools or schematic entry tools. These tools go beyond simple drawing of devices and connections. Usually they are integrated into the whole design flow and linked to other EDA tools for verification and simulation of the circuit under design.\nProgrammable logic controllers (PLC) can be programmed using ladder diagrams.\nIn electric power systems design, a schematic drawing called a \"one-line\" \"diagram\" is frequently used to represent substations, distribution systems or even whole electrical power grids. These diagrams simplify and compress the details that would be repeated on each phase of a three-phase system, showing only one element instead of three. Electrical diagrams for switchgear often have common device functions designate by standard function numbers. Another type of diagram used for power systems is a \"three-line diagram\".\nFor analysis purposes of a power system, from the one-line diagram, if the system is balanced, an \"equivalent per-phase\" (or \"single-phase\") \"schematic diagram\" can be obtained. If all of the parameters are represented as impedances and voltage sources, the equivalent per-phase schematic diagram is called an \"impedance diagram\". If all of the parameters are represented as admittances and current sources, the equivalent per-phase schematic diagram is called an \"admittance diagram\".\nIf the power system is unbalanced, but it is linear (or can be approximated by a linear system), then Fortescue's theorem (symmetrical components) can be applied. In this way, from the one-line diagram, three different per-phase schematic diagrams are obtained, known as \"sequence diagrams\": \"positive sequence diagram\", \"negative sequence diagram\", and \"zero sequence diagram\". Each of these diagrams can be represented as an impedance diagram or as an admittance diagram.\nSchematics in repair manuals.\nSchematic diagrams are used extensively in repair manuals to help users understand the interconnections of parts, and to provide graphical instruction to assist in dismantling and rebuilding mechanical assemblies. Many automotive and motorcycle repair manuals devote a significant number of pages to schematic diagrams.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41680", "revid": "49561808", "url": "https://en.wikipedia.org/wiki?curid=41680", "title": "Scrambler", "text": "Telecommunication device that obscures signals\nIn telecommunications, a scrambler is a device that transposes or inverts signals or otherwise encodes a message at the sender's side to make the message unintelligible at a receiver not equipped with an appropriately set descrambling device. Whereas encryption usually refers to operations carried out in the digital domain, scrambling usually refers to operations carried out in the analog domain. Scrambling is accomplished by the addition of components to the original signal or the changing of some important component of the original signal in order to make extraction of the original signal difficult. Examples of the latter might include removing or changing vertical or horizontal sync pulses in television signals; televisions will not be able to display a picture from such a signal. Some modern scramblers are actually encryption devices, the name remaining due to the similarities in use, as opposed to internal operation.\nIn telecommunications and recording, a \"scrambler\" (also referred to as a \"randomizer\") is a device that manipulates a data stream before transmitting. The manipulations are reversed by a \"descrambler\" at the receiving side. Scrambling is widely used in satellite, radio relay communications and PSTN modems. A scrambler can be placed just before a FEC coder, or it can be placed after the FEC, just before the modulation or line code. A scrambler in this context has nothing to do with encrypting, as the intent is not to render the message unintelligible, but to give the transmitted data useful engineering properties.\nA scrambler replaces sequences (referred to as \"whitening sequences\") with other sequences without removing undesirable sequences, and as a result it changes the probability of occurrence of vexatious sequences. Clearly it is not foolproof as there are input sequences that yield all-zeros, all-ones, or other undesirable periodic output sequences. A scrambler is therefore not a good substitute for a line code, which, through a coding step, removes unwanted sequences.\nPurposes of scrambling.\nA scrambler (or randomizer) can be either:\nThere are two main reasons why scrambling is used:\nScramblers are essential components of physical layer system standards besides interleaved coding and modulation. They are usually defined based on linear-feedback shift registers (LFSRs) due to their good statistical properties and ease of implementation in hardware.\nIt is common for physical layer standards bodies to refer to lower-layer (physical layer and link layer) encryption as scrambling as well. This may well be because (traditional) mechanisms employed are based on feedback shift registers as well.\nSome standards for digital television, such as DVB-CA and MPE, refer to encryption at the link layer as scrambling.\nTypes of scramblers.\nAdditive (synchronous) scramblers.\n\"Additive scramblers\" (they are also referred to as \"synchronous\") transform the input data stream by applying a pseudo-random binary sequence (PRBS) (by modulo-two addition). Sometimes a pre-calculated PRBS stored in the read-only memory is used, but more often it is generated by a linear-feedback shift register (LFSR).\nIn order to assure a synchronous operation of the transmitting and receiving LFSR (that is, \"scrambler\" and \"descrambler\"), a \"sync-word\" must be used.\nA sync-word is a pattern that is placed in the data stream through equal intervals (that is, in each frame). A receiver searches for a few sync-words in adjacent frames and hence determines the place when its LFSR must be reloaded with a pre-defined \"initial state\".\nThe \"additive descrambler\" is just the same device as the additive scrambler.\nAdditive scrambler/descrambler is defined by the polynomial of its LFSR (for the scrambler on the picture above, it is formula_1) and its \"initial state\".\nMultiplicative (self-synchronizing) scramblers.\n\"Multiplicative scramblers\" (also known as \"feed-through\") are called so because they perform a \"multiplication\" of the input signal by the scrambler's transfer function in Z-space. They are discrete linear time-invariant systems.\nA multiplicative scrambler is recursive, and a multiplicative descrambler is non-recursive. Unlike additive scramblers, multiplicative scramblers do not need the frame synchronization, that is why they are also called \"self-synchronizing\". Multiplicative scrambler/descrambler is defined similarly by a polynomial (for the scrambler on the picture it is formula_2), which is also a \"transfer function\" of the descrambler.\nComparison of scramblers.\nScramblers have certain drawbacks: \nNoise.\nThe first voice scramblers were invented at Bell Labs in the period just before World War II. These sets consisted of electronics that could mix two signals or alternatively \"subtract\" one signal back out again. The two signals were provided by a telephone and a record player. A matching pair of records was produced, each containing the same recording of noise. The recording was played into the telephone, and the mixed signal was sent over the wire. The noise was then subtracted out at the far end using the matching record, leaving the original voice signal intact. Eavesdroppers would hear only the noisy signal, unable to understand the voice.\nOne of those, used (among other duties) for telephone conversations between Winston Churchill and Franklin D. Roosevelt was intercepted and unscrambled by the Germans. At least one German engineer had worked at Bell Labs before the war and came up with a way to break them. Later versions were sufficiently different that the German team was unable to unscramble them. Early versions were known as \"A-3\" (from AT&amp;T Corporation). An unrelated device called SIGSALY was used for higher-level voice communications.\nThe noise was provided on large shellac phonograph records made in pairs, shipped as needed, and destroyed after use. This worked, but was enormously awkward. Just achieving synchronization of the two records proved difficult. Post-war electronics made such systems much easier to work with by creating pseudo-random noise based on a short input tone. In use, the caller would play a tone into the phone, and both scrambler units would then listen to the signal and synchronize to it. This provided limited security, however, as any listener with a basic knowledge of the electronic circuitry could often produce a machine of similar-enough settings to break into the communications.\nCryptographic.\nIt was the need to synchronize the scramblers that suggested to James H. Ellis the idea for non-secret encryption, which ultimately led to the invention of both the RSA encryption algorithm and Diffie\u2013Hellman key exchange well before either was reinvented publicly by Rivest, Shamir, and Adleman, or by Diffie and Hellman.\nThe latest scramblers are not scramblers in the truest sense of the word, but rather digitizers combined with encryption machines. In these systems the original signal is first converted into digital form, and then the digital data is encrypted and sent. Using modern public-key systems, these \"scramblers\" are much more secure than their earlier analog counterparts. Only these types of systems are considered secure enough for sensitive data.\nVoice inversion scrambling can be as simple as inverting the frequency bands around a static point to various complex methods of changing the inversion point randomly and in real time and using multiple bands. Voice inversion with a fixed frequency offers no security at all and software is available to restore the original voice, which is why it is no longer used to protect conversations today. However, voice inversion is still found in low-end Chinese walkie talkies.\nThe \"scramblers\" used in cable television are designed to prevent casual signal theft, not to provide any real security. Early versions of these devices simply \"inverted\" one important component of the TV signal, re-inverting it at the client end for display. Later devices were only slightly more complex, filtering out that component entirely and then adding it by examining other portions of the signal. In both cases the circuitry could be easily built by any reasonably knowledgeable hobbyist. (see Television encryption.)\nElectronic kits for scrambling and descrambling are available from hobbyist suppliers. Scanner enthusiasts often use them to listen in to scrambled communications at car races and some public-service transmissions. It is also common in FRS radios. This is an easy way to learn about scrambling.\nThe term \"scrambling\" is sometimes incorrectly used when jamming is meant.\nDescramble.\nDescramble in cable television context is the act of taking a scrambled or encrypted video signal that has been provided by a cable television company for premium television services, processed by a scrambler and then supplied over a coaxial cable and delivered to the household where a set-top box reprocesses the signal, thus descrambling it and making it available for viewing on the television set. A descrambler is a device that restores the picture and sound of a scrambled channel. A descrambler must be used with a cable converter box to be able to unencrypt all of the premium &amp; pay-per-view channels of a Cable Television System.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41681", "revid": "45266726", "url": "https://en.wikipedia.org/wiki?curid=41681", "title": "Screen", "text": "Screen or Screens may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41682", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41682", "title": "Secondary frequency standard", "text": "Standards in electronics and telecommunications\nIn telecommunications, a secondary frequency standard is a frequency standard that does not have inherent accuracy, and therefore must be calibrated against a primary frequency standard. \nSecondary standards include crystal oscillators and rubidium standards. A crystal oscillator depends for its frequency on its physical dimensions, which vary with fabrication and environmental conditions. A rubidium standard is a secondary standard even though it uses atomic transitions, because it takes the form of a gas cell through which an optical signal is passed. The gas cell has inherent inaccuracies because of gas pressure variations, including those induced by temperature variations. There are also variations in the concentrations of the required buffer gases, which variations cause frequency deviations."}
{"id": "41684", "revid": "1320167173", "url": "https://en.wikipedia.org/wiki?curid=41684", "title": "Security", "text": "Degree of resistance to, or protection from, harm\nSecurity is protection from, or resilience against, potential harm (or other unwanted coercion). Beneficiaries (technically referents) of security may be persons and social groups, objects and institutions, ecosystems, or any other entity or phenomenon vulnerable to unwanted change. \nSecurity mostly refers to protection from hostile forces, but it has a wide range of other senses: for example, as the absence of harm (e.g., freedom from want); as the presence of an essential good (e.g., food security); as resilience against potential damage or harm (e.g. secure foundations); as secrecy (e.g., a secure telephone line); as containment (e.g., a secure room or cell); and as a state of mind (e.g., emotional security).\nSecurity is both a feeling and a state of reality. One might feel secure when one is not actually so; or might feel insecure despite being safe. This distinction is usually not very clear to express in the English language.\nThe term is also used to refer to acts and systems whose purpose may be to provide security (security company, security police, security forces, security service, security agency, security guard, cyber security systems, security cameras, remote guarding). Security can be physical and virtual.\nEtymology.\nThe word 'secure' entered the English language in the 16th century. It is derived from Latin \"securus\", meaning freedom from anxiety: \"se\" (without) + \"cura\" (care, anxiety).\nOverview.\nReferent.\nA security referent is the focus of a security policy or discourse; for example, a referent may be a potential beneficiary (or victim) of a security policy or system.\nSecurity referents may be persons or social groups, objects, institutions, ecosystems, or any other phenomenon vulnerable to unwanted change by the forces of its environment. The referent in question may combine many referents in the same way that, for example, a nation-state is composed of many individual citizens.\nContext.\nThe security context is the relationships between a security referent and its environment. From this perspective, security and insecurity depend first on whether the environment is beneficial or hostile to the referent and also on how capable the referent is of responding to their environment in order to survive and thrive.\nCapabilities.\nThe means by which a referent provides for security (or is provided for) vary widely. They include, for example:\nEffects.\nAny action intended to provide security may have multiple effects. An action may have a wide benefit, enhancing security for several or all security referents in the context; alternatively, the action may be effective only temporarily, benefit one referent at the expense of another, or be entirely ineffective or counterproductive.\nContested approaches.\nApproaches to security are contested and the subject of debate. For example, in debate about national security strategies, some argue that security depends principally on developing protective and coercive capabilities in order to protect the security referent in a hostile environment (and potentially to project that power into its environment, and dominate it to the point of strategic supremacy). Others argue that security depends principally on building the conditions in which equitable relationships can develop, partly by reducing antagonism between actors, ensuring that fundamental needs can be met, and also ensuring that differences of interest can be negotiated effectively.\nSecurity contexts (examples).\nThe table shows some of the main domains where security concerns are prominent.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nThe range of security contexts is illustrated by the following examples (in alphabetical order):\nComputer security.\nComputer security, also known as cybersecurity or IT security, refers to the security of computing devices such as computers and smartphones, as well as computer networks such as private and public networks, and the Internet. The field has growing importance due to the increasing reliance on computer systems in most societies. It concerns the protection of hardware, software, data, people, and also the procedures by which systems are accessed. The means of computer security include the physical security of systems and the security of information held on them.\nCorporate security.\nCorporate security refers to the resilience of corporations against espionage, theft, damage, and other threats. The security of corporations has become more complex as reliance on IT systems has increased, and their physical presence has become more highly distributed across several countries, including environments that are, or may rapidly become, hostile to them.\nEnvironmental security.\nEnvironmental security, also known as ecological security, refers to the integrity of ecosystems and the biosphere, particularly in relation to their capacity to sustain a diversity of life-forms (including human life). The security of ecosystems has attracted greater attention as the impact of ecological damage by humans has grown.\nHome security.\nHome security normally refers to the security systems used on a property used as a dwelling (commonly including doors, locks, alarm systems, lighting, fencing); and personal security practices (such as ensuring doors are locked, alarms are activated, windows are closed etc.)\nHuman security.\nHuman security is an emerging paradigm that, in response to traditional emphasis on the right of nation-states to protect themselves, has focused on the primacy of the security of people (individuals and communities). The concept is supported by the United Nations General Assembly, which has stressed \"the right of people to live in freedom and dignity\" and recognized \"that all individuals, in particular vulnerable people, are entitled to freedom from fear and freedom from want\".\nInformation security.\nInformation security refers to the security of information in any form. Spoken, written, digital, networked, technological, and procedural forms of information are all examples that may be covered in an information security management scheme. Computer security, IT security, ICT security, and network security are thus all subdomains of information security.\nNational security.\nNational security refers to the security of a nation-state, including its people, economy, and institutions. In practice, state governments rely on a wide range of means, including diplomacy, economic power, and military capabilities.\nResource security.\n\"Resource security\" refers to the political and commercial objective of ensuring that supplies of materials needed for the production of goods and the satisfaction of human needs can be reliably sustained into the future. It involves protecting the supply of such resources as water, energy, food and industrial raw materials from risks of global depletion and risks to national supply incurred by trade restrictions, government or terrorist interference or market failures. While critical raw materials such as rare earth minerals are an important focus of resource security planning, resource security covers a broader range of resources. Food security, ensuring that a reliable supply of, and access to, safe and nutritious food, and energy security are important aspects of resource security. Food security is gaining in importance as the world's population has grown and productive land has diminished through overuse and climate change.\nThe UK government published a \"Resource Security Action Plan\" for England in March 2012, subtitled \"Making the most of valuable resources\", responding to concerns raised by businesses and business leaders such as the Confederation of British Industry (CBI) and the Engineering Employers' Federation (EEF), and work in this field undertaken by the House of Commons Science and Technology Committee. The action plan was an interdepartmental initiative for which the Department for Environment, Food and Rural Affairs (DEFRA) took the lead role as first point of contact for business enquiries. \nGovernment and business concerns related to \"a range of renewable and non-renewable resources\", concentrating on those not already covered by energy security and food security measures, and especially sought to protect the supply of certain specific metals and materials under supply pressure. A generalised fear of resource insufficiency was felt to be inappropriate: thus Vince Cable, then Secretary of State for Business Innovation and Skills, spoke in December 2011 about a public policy approach to resource management:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; Similarly the \"Action Plan\" notes that in general the issue of \"resource security\" is not concerned with \"scarcity\" of resources but with availability, supply constraints and the potential financial and environmental costs of opening up new sources of supply.\nEEF, the UK's manufacturers' representation organisation (now Make UK) issued a report in 2014 entitled \"Materials for Manufacturing: Safeguarding Supply\", along with an appeal to the government seeking action to protect the country's supply of essential materials. The report highlighted \"over-reliance on China for strategic supplies\" as a key issue. The EEF and other partners argued that an \"Office of Resource Management\" within government \"could strategically co-ordinate action across Whitehall\". The office would form part of the Department for Business, Innovation and Skills and maintain an overview of the risks to resource security.\nPerceptions of security.\nSince it is not possible to know with precision the extent to which something is 'secure' (and a measure of vulnerability is unavoidable), perceptions of security vary, often greatly. For example, a fear of death by earthquake is common in the US, but slipping on the bathroom floor kills more people; and in France, the UK, and the US, there are far fewer deaths caused by terrorism than there are women killed by their partners in the home.\nAnother problem of perception is the common assumption that the mere presence of a security system (such as armed forces or antivirus software) implies security. For example, two computer security programs installed on the same device can prevent each other from working properly, while the user assumes that he or she benefits from twice the protection that only one program would afford.\nSecurity theater is a critical term for measures that change perceptions of security without necessarily affecting security itself. For example, visual signs of security protections, such as a home that advertises its alarm system, may deter an intruder, whether or not the system functions properly. Similarly, the increased presence of military personnel on the streets of a city after a terrorist attack may help to reassure the public, whether or not it diminishes the risk of further attacks.\nRecurring concepts.\nCertain concepts recur throughout different fields of security:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41685", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41685", "title": "Security kernel", "text": "Telecommunication term\nIn telecommunications, the term security kernel has the following meanings: "}
{"id": "41686", "revid": "23939382", "url": "https://en.wikipedia.org/wiki?curid=41686", "title": "Security management", "text": "Computer security procedure\nSecurity management is the identification of an organization's assets i.e. including people, buildings, machines, systems and information assets, followed by the development, documentation, and implementation of policies and procedures for protecting assets.\nAn organization uses such security management procedures for information classification, threat assessment, risk assessment, and risk analysis to identify threats, categorize assets, and rate system vulnerabilities.\nLoss prevention.\nLoss prevention focuses on what one's critical assets are and how they are going to protect them. A key component to loss prevention is assessing the potential threats to the successful achievement of the goal. This must include the potential opportunities that further the object (why take the risk unless there's an upside?) Balance probability and impact determine and implement measures to minimize or eliminate those threats.\nSecurity management includes the theories, concepts, ideas, methods, procedures, and practices that are used to manage and control organizational resources in order to accomplish security goals. Policies, procedures, administration, operations, training, awareness campaigns, financial management, contracting, resource allocation, and dealing with problems like security degradation are all included in this vast sector.\nSecurity risk management.\nThe management of security risks applies the principles of risk management to the management of security threats. It consists of identifying threats (or risk causes), assessing the effectiveness of existing controls to face those threats, determining the risks' consequence(s), prioritizing the risks by rating the likelihood and impact, classifying the type of risk, and selecting an appropriate risk option or risk response. In 2016, a universal standard for managing risks was developed in The Netherlands. In 2017, it was updated and named: Universal Security Management Systems Standard 2017.\nTypes of risks.\nInternal.\nRisk options\nRisk avoidance.\nThe first choice to be considered is the possibility of eliminating the existence of criminal opportunity or avoiding the creation of such an opportunity. When additional considerations or factors are not created as a result of this action that would create a greater risk. For example, removing all the cash flow from a retail outlet would eliminate the opportunity for stealing the money, but it would also eliminate the ability to conduct business.\nRisk reduction.\nWhen avoiding or eliminating the criminal opportunity conflicts with the ability to conduct business, the next step is reducing the opportunity of potential loss to the lowest level consistent with the function of the business. In the example above, the application of risk reduction might result in the business keeping only enough cash on hand for one day's operation.\nRisk spreading.\nAssets that remain exposed after the application of reduction and avoidance are the subjects of risk spreading. This is the concept that limits loss or potential losses by exposing the perpetrator to the probability of detection and apprehension prior to the consummation of the crime through the application of perimeter lighting, barred windows, and intrusion detection systems. The idea is to reduce the time available for thieves to steal assets and escape without apprehension.\nRisk transfer.\nThe two primary methods of accomplishing risk transfer is to insure the assets or raise prices to cover the loss in the event of a criminal act. Generally speaking, when the first three steps have been properly applied, the cost of transferring risks is much lower.\nRisk acceptance.\nAll of the remaining risks must simply be assumed by the business as a part of doing business. Included with these accepted losses are deductibles, which have been made as part of the insurance coverage.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41687", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41687", "title": "Self-synchronizing code", "text": "Type of code in coding theory\nIn coding theory, especially in telecommunications, a self-synchronizing code is a uniquely decodable code in which the symbol stream formed by a portion of one code word, or by the overlapped portion of any two adjacent code words, is not a valid code word. Put another way, a set of strings (called \"code words\") over an alphabet is called a self-synchronizing code if for each string obtained by concatenating two code words, the substring starting at the second symbol and ending at the second-last symbol does not contain any code word as substring. Every self-synchronizing code is a prefix code, but not all prefix codes are self-synchronizing.\nOther terms for self-synchronizing code are synchronized code or, ambiguously, comma-free code. A self-synchronizing code permits the proper framing of transmitted code words provided that no uncorrected errors occur in the symbol stream; external synchronization is not required. Self-synchronizing codes also allow recovery from uncorrected errors in the stream; with most prefix codes, an uncorrected error in a single bit may propagate errors further in the stream and make the subsequent data corrupted.\nImportance of self-synchronizing codes is not limited to data transmission. Self-synchronization also facilitates some cases of data recovery, for example of a digitally encoded text.\nExamples.\nCounterexamples:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41688", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41688", "title": "Semiautomatic switching system", "text": "Telecommunication switching system\nIn telecommunications, the term semiautomatic switching system has the following meanings: "}
{"id": "41689", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=41689", "title": "Sensitive information", "text": ""}
{"id": "41690", "revid": "1302184", "url": "https://en.wikipedia.org/wiki?curid=41690", "title": "Sensitivity", "text": "Sensitivity may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41691", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41691", "title": "Separate-channel signaling", "text": "Separate-channel signaling is a form of signaling in which the whole or a part of one or more channels in a multichannel system is used to provide for supervisory and control signals for the message traffic channels. \nThe same channels, such as frequency bands or time slots, that are used for signaling are not used for message traffic. This is used for E-carrier telecommunications.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41692", "revid": "252195", "url": "https://en.wikipedia.org/wiki?curid=41692", "title": "Serial access", "text": ""}
{"id": "41693", "revid": "139104", "url": "https://en.wikipedia.org/wiki?curid=41693", "title": "Serial transmission", "text": ""}
{"id": "41694", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41694", "title": "Service termination point", "text": "In telecommunications, the service termination point is the last point of service rendered by a commercial carrier under applicable tariffs.\nUsually, the service termination point is on the customer premises and corresponds to the demarcation point. The customer is responsible for equipment and operation from the service termination point to user end instruments."}
{"id": "41695", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41695", "title": "Shadow loss", "text": "In telecommunications, the term shadow loss has the following meanings: "}
{"id": "41696", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=41696", "title": "Shannon's law", "text": "Shannon's law may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41697", "revid": "50968713", "url": "https://en.wikipedia.org/wiki?curid=41697", "title": "Sheath", "text": "Sheath, pronounced , may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41698", "revid": "202276", "url": "https://en.wikipedia.org/wiki?curid=41698", "title": "Shield", "text": "Item of armour carried to intercept attacks or projectiles\nA shield is a piece of personal armour held in the hand, which may or may not be strapped to the wrist or forearm. Shields are used to intercept specific attacks, whether from close-ranged weaponry like spears or long ranged projectiles such as arrows. They function as means of active blocks, as well as to provide passive protection by closing one or more lines of engagement during combat.\nShields vary greatly in size and shape, ranging from large panels that protect the user's whole body to small models (such as the buckler) that were intended for hand-to-hand-combat use. Shields also vary a great deal in thickness; whereas some shields were made of relatively deep, absorbent, wooden planking to protect soldiers from the impact of spears and crossbow bolts, others were thinner and lighter and designed mainly for deflecting blade strikes (like the roromaraugi or qauata). Finally, shields vary greatly in shape, ranging in roundness to angularity, proportional length and width, symmetry and edge pattern; different shapes provide more optimal protection for infantry or cavalry, enhance portability, provide secondary uses such as ship protection or as a weapon and so on.\nIn prehistory and during the era of the earliest civilisations, shields were made of wood, animal hide, woven reeds or wicker. In classical antiquity, the Barbarian Invasions and the Middle Ages, they were normally constructed of poplar tree, lime or another split-resistant timber, covered in some instances with a material such as leather or rawhide and often reinforced with a metal boss, rim or banding. They were carried by foot soldiers, knights and cavalry.\nDepending on time and place, shields could be round, oval, square, rectangular, triangular, bilabial or scalloped. Sometimes they took on the form of kites or flatirons, or had rounded tops on a rectangular base with perhaps an eye-hole, to look through when used with combat. The shield was held by a central grip or by straps with some going over or around the user's arm and one or more being held by the hand.\nOften shields were decorated with a painted pattern or an animal representation to show their army or clan. It was common for Aristocratic officials such and knights, barons, dukes, and kings to have their shields painted with customary designs known as a coat of arms. These designs developed into systematized heraldic devices during the High Middle Ages for purposes of battlefield identification. Even after the introduction of gunpowder and firearms to the battlefield, shields continued to be used by certain groups. In the 18th century, for example, Scottish Highland fighters liked to wield small shields known as targes, and as late as the 19th century, some non-industrialized peoples (such as Zulu warriors) employed them when waging wars.\nIn the 20th and 21st century, shields have been used by military and police units that specialize in anti-terrorist actions, hostage rescue, riot control and siege-breaking.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nPrehistory.\nThe first prototype of the shield was believed to be created in the Late Neolithic Age. However the oldest surviving shields date to sometime in the Bronze Age. The oldest form of shield was a protection device designed to block attacks by hand weapons, such as swords, axes and maces, or ranged weapons like sling-stones and arrows. Shields have varied greatly in construction over time and place. Sometimes shields were made of metal, but wood or animal hide construction was much more common; wicker and even turtle shells have been used. Many surviving examples of metal shields are generally felt to be ceremonial rather than practical, for example the Yetholm-type shields of the Bronze Age, or the Iron Age Battersea shield.\nHistory.\nAncient.\nSize and weight varied greatly. Lightly armored warriors relying on speed and surprise would generally carry light shields (\"pelte\") that were either small or thin. Heavy troops might be equipped with robust shields that could cover most of the body. Many had a strap called a guige that allowed them to be slung over the user's back when not in use or on horseback. During the 14th\u201313th century\u00a0BC, the Sards or Shardana, working as mercenaries for the Egyptian pharaoh Ramses II, utilized either large or small round shields against the Hittites. The Mycenaean Greeks used two types of shields: the \"figure-of-eight\" shield and a rectangular \"tower\" shield. These shields were made primarily from a wicker frame and then reinforced with leather. Covering the body from head to foot, the figure-of-eight and tower shield offered most of the warrior's body a good deal of protection in hand-to-hand combat. The Ancient Greek hoplites used a round, bowl-shaped wooden shield that was reinforced with bronze and called an \"aspis\". The aspis was used by the Spartans to create the Greek phalanx formation. Their shields offered protection not only for themselves but for their comrades to their left. \nExamples of Germanic wooden shields circa 350\u00a0BC\u00a0\u2013 500\u00a0AD survive from weapons sacrifices in Danish bogs.\nThe heavily armored Roman legionaries carried large shields (\"scuta\"). The \"scutum\" had an oval shape during the early republican era, but gradually developed into the familiar rectangular shape most commonly seen in the early Imperial legions. The Romans used their shields to create a tortoise-like formation called a \"testudo\" in which large groups of soldiers would be enclosed in an armoured box to provide protection against missiles and to allow for approaches under heavy fire.\nPost-classical.\nTypical in the early European Middle Ages were round shields with light, non-splitting wood like linden, fir, alder, or poplar, usually reinforced with leather cover on one or both sides and occasionally metal rims, encircling a metal shield boss. These light shields suited a fighting style where each incoming blow is intercepted with the boss in order to deflect it. The bosses could also be used as a secondary weapon by punching with the shield. These shields were often used in formation forming a wall of shields. The Normans later introduced the kite shield around the 10th century, which was rounded at the top and tapered at the bottom. This gave some protection to the user's legs, and was especially suited for horsemen, whose legs would otherwise be vulnerable. The kite shield predominantly features enarmes, leather straps used to grip the shield tight to the arm. Used by foot and mounted troops alike, it gradually came to replace the round shield as the common choice until the end of the 12th century, when more efficient limb armour allowed the shields to grow shorter, and be entirely replaced by the 14th century.\nAs body armour improved, knight's shields became smaller, leading to the familiar heater shield style. Both kite and heater style shields were made of several layers of laminated wood, with a gentle curve in cross section. The heater style inspired the shape of the symbolic heraldic shield that is still used today. Eventually, specialised shapes were developed such as the \"bouche\", which had a lance rest cut into the upper corner of the lance side, to help guide it in combat or tournament. Free standing shields called pavises, which were propped up on stands, were used by medieval crossbowmen who needed protection while reloading.\nIn time, some armoured foot knights gave up shields entirely in favour of mobility and two-handed weapons. Other knights and common soldiers adopted the buckler, giving rise to the term \"swashbuckler\". The buckler is a small round shield, typically between 8 and 16\u00a0inches (20\u201340\u00a0cm) in diameter. The buckler was one of very few types of shield that were usually made of metal. Small and light, the buckler was easily carried by being hung from a belt; it gave little protection from missiles and was reserved for hand-to-hand combat where it served both for protection and offence. The buckler's use began in the Middle Ages and continued well into the 16th century.\nIn Italy, the targa, parma, and rotella were used by common people, fencers and even knights. The development of plate armour made shields less and less common as it eliminated the need for a shield. Lightly armoured troops continued to use shields after men-at-arms and knights ceased to use them. Shields continued in use even after gunpowder powered weapons made them essentially obsolete on the battlefield. In the 18th century, the Scottish clans used a small, round targe that was partially effective against the firearms of the time, although it was arguably more often used against British infantry bayonets and cavalry swords in close-in fighting.\nDuring the 19th century, non-industrial cultures with little access to guns were still using war shields. Zulu warriors carried large lightweight shields called Ishlangu made from a single ox hide supported by a wooden spine. This was used in combination with a short spear (iklwa) and/or club. Other African shields include Glagwa from Cameroon or Nguba from Congo.\nModern.\nLaw enforcement shields.\nShields for protection from armed attack are still used by many police forces around the world. These modern shields are usually intended for two broadly distinct purposes. The first type, riot shields, are used for riot control and can be made from metal or polymers such as polycarbonate Lexan or Makrolon or boPET Mylar. These typically offer protection from relatively large and low velocity projectiles, such as rocks and bottles, as well as blows from fists or clubs. Synthetic riot shields are normally transparent, allowing full use of the shield without obstructing vision. Similarly, metal riot shields often have a small window at eye level for this purpose. These riot shields are most commonly used to block and push back crowds when the users stand in a \"wall\" to block protesters, and to protect against shrapnel, projectiles like stones and bricks, molotov cocktails, and during hand-to-hand combat.\nThe second type of modern police shield is the bullet-resistant ballistic shield, also called tactical shield. These shields are typically manufactured from advanced synthetics such as Kevlar and are designed to be bulletproof, or at least bullet resistant. Two types of shields are available:\nTactical shields often have a firing port so that the officer holding the shield can fire a weapon while being protected by the shield, and they often have a bulletproof glass viewing port. They are typically employed by specialist police, such as SWAT teams in high risk entry and siege scenarios, such as hostage rescue and breaching gang compounds, as well as in antiterrorism operations.\nLaw enforcement shields often have a large signs stating \"POLICE\" (or the name of a force, such as \"US MARSHALS\") to indicate that the user is a law enforcement officer.\nTypes of shields.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41699", "revid": "1296195204", "url": "https://en.wikipedia.org/wiki?curid=41699", "title": "Shift register", "text": "Computer memory unit using cascaded flip-flops\nA shift register is a type of digital circuit using a cascade of flip-flops where the output of one flip-flop is connected to the input of the next. They share a single clock signal, which causes the data stored in the system to shift from one location to the next. By connecting the last flip-flop back to the first, the data can cycle within the shifters for extended periods, and in this configuration they were used as computer memory, displacing delay-line memory systems in the late 1960s and early 1970s.\nIn most cases, several parallel shift registers would be used to build a larger memory pool known as a \"bit array\". Data was stored into the array and read back out in parallel, often as a computer word, while each bit was stored serially in the shift registers. There is an inherent trade-off in the design of bit arrays; putting more flip-flops in a row allows a single shifter to store more bits, but requires more clock cycles to push the data through all of the shifters before the data can be read back out again.\nShift registers can have both parallel and serial inputs and outputs. These are often configured as \"serial-in, parallel-out\" (SIPO) or as \"parallel-in, serial-out\" (PISO). There are also types that have both serial and parallel input and types with serial and parallel output. There are also \"bidirectional\" shift registers, which allow shifting in both directions: L\u00a0\u2192\u00a0R or R\u00a0\u2192\u00a0L. The serial input and serial output of a shift register are connected to create a circular shift register. A PIPO register (parallel in, parallel out) is simply a D-type register and is \"not\" a shift register, but is very fast \u2013 an output is given within a single clock pulse. A \"universal\" shift register provides bidirectional serial-in and serial-out, as well as parallel-in and parallel-out.\nSerial-in serial-out (SISO).\nDestructive readout.\nThese are the simplest kind of shift registers. The data string is presented at \"data in\" and is shifted right one stage each time \"data advance\" is brought high. At each advance, the bit on the far left (i.e. \"data in\") is shifted into the first flip-flop's output. The bit on the far right (i.e. \"data out\") is shifted out and lost.\nThe data is stored after each on the \"Q\" output, so there are four storage \"slots\" available in this arrangement, hence it is a 4-bit register. To give an idea of the shifting pattern, imagine that the register holds 0000 (so all storage slots are empty). As \"data in\" presents 1,0,1,1,0,0,0,0 (in that order, with a pulse at \"data advance\" each time\u2014this is called clocking or strobing) to the register, this is the result. The right hand column corresponds to the right-most flip-flop's output pin, and so on.\nSo the serial output of the entire value is 00010110. It can be seen that if data were to be continued to input, it would get exactly what was put in (10110000), but offset by four \"data advance\" cycles. This arrangement is the hardware equivalent of a queue. Also, at any time, the whole register can be set to zero by bringing the reset (R) pins high.\nThis arrangement performs \"destructive readout\"\u00a0\u2013 each datum is lost once it has been shifted out of the right-most bit.\nSerial-in parallel-out (SIPO).\nThis configuration allows conversion from serial to parallel format. Data input is serial, as described in the SISO section above. Once the data has been clocked in, it may be either read off at each output simultaneously, or it can be shifted out.\nIn this configuration, each flip-flop is edge triggered. All flip-flops operate at the given clock frequency. Each input bit makes its way down to the Nth output after N clock cycles, leading to parallel output.\nIn cases where the parallel outputs should not change during the serial loading process, it's desirable to use a latched or buffered output. In a latched shift register (such as the 74595) the serial data is first loaded into an internal buffer register, then upon receipt of a load signal the state of the buffer register is copied into a set of output registers. In general, the practical application of the serial-in/parallel-out shift register is to convert data from serial format on a single wire to parallel format on multiple wires.\nParallel-in serial-out (PISO).\nThis configuration has the data input on lines D1 through D4 in parallel format, D1 being the most significant bit. To write the data to the register, the Write/Shift control line must be held LOW. To shift the data, the W/S control line is brought HIGH and the registers are clocked. The arrangement now acts as a PISO shift register, with D1 as the Data Input. However, as long as the number of clock cycles is not more than the length of the data-string, the Data Output, Q, will be the parallel data read off in order. The animation below shows the write/shift sequence, including the internal state of the shift register. \nUses.\nSerial and parallel conversion.\nOne of the most common uses of a shift register is to convert between serial and parallel interfaces.\nDelay.\nSerial-in serial-out shift registers can be used as simple delay circuits.\nStack.\nSeveral bidirectional shift registers can also be connected in parallel for a hardware implementation of a stack.\nMore I/O pins.\nShift registers are commonly attached to microcontrollers when more general-purpose input/output pins are required than are available, sometimes over a Serial Peripheral Interface in daisy chain configuration, which allows any number of binary devices to be accessed using only two to four pins, though more slowly than parallel I/O.\nFor more outputs, SIPO shift registers are used. The parallel outputs of the shift register and the desired state for all those devices can be sent out of the microcontroller using a single serial connection.\nFor more inputs, PISO shift registers are used. Each binary input (such as a button or more complicated circuitry) is attached to a parallel input of the shift register, then the data is sent back serially to the microcontroller.\nPulse extenders.\nShift registers can also be used as pulse extenders. Compared to monostable multivibrators, the timing does not depend on component values, but it requires an external clock, and the timing accuracy is limited by the granularity of this clock. An example of such a pulse extender is the Ronja Twister, wherein five 74164 shift registers create the core of the timing logic this way (http://).\nData processing.\nIn early computers, shift registers were used to handle data processing: two numbers to be added were stored in two shift registers and clocked out into an arithmetic and logic unit (ALU) with the result being fed back to the input of one of the shift registers (the accumulator), which was one bit longer, since binary addition can only result in an answer that has the same size or is one bit longer.\nBitshift operations.\nMany computer languages include bitwise operations to \"shift right\" and \"shift left\" the data in a register, effectively dividing by two or multiplying by two for each place shifted.\nShift register memory.\nVery large serial-in serial-out shift registers (thousands of bits in size) were used in a similar manner to the earlier delay-line memory in some devices built in the early 1970s. Shift registers don't need many pins or address decoding logic, so was much cheaper than random-access memory back then. Such \"shift register memory\" was sometimes called \"circulating memory\".\nDatapoint\u00a03300, for example, stored its terminal display of 25\u00a0rows of 72\u00a0columns of 6-bit upper-case characters using 54 200-bit shift registers (arranged in 6 tracks of 9 packs), providing storage for 1800 characters. The shift register design meant that scrolling the terminal display could be accomplished by simply pausing the display output to skip one line of characters. A similar design was used for the Apple I's terminal.\nHistory.\nOne of the first known examples of a shift register was in the Mark 2 Colossus, a code-breaking machine built in 1944. It was a six-stage device built of vacuum tubes and thyratrons. A shift register was also used in the IAS machine, built by John von Neumann and others at the Institute for Advanced Study in the late 1940s. Shift registers made their way into integrated circuits in the 1960s as evidenced by early patents from Frank Wanlass and Kent Smith working at General Instrument.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41700", "revid": "50446187", "url": "https://en.wikipedia.org/wiki?curid=41700", "title": "Shot noise", "text": "Type of electronic noise\nShot noise or Poisson noise is a type of noise which can be modeled by a Poisson process. \nIn electronics shot noise originates from the discrete nature of electric charge. Shot noise also occurs in photon counting in optical devices, where shot noise is associated with the particle nature of light.\nOrigin.\nIn a statistical experiment such as tossing a fair coin and counting the occurrences of heads and tails, the numbers of heads and tails after many throws will differ by only a tiny percentage, while after only a few throws outcomes with a significant excess of heads over tails or vice versa are common; if an experiment with a few throws is repeated over and over, the outcomes will fluctuate a lot. From the law of large numbers, one can show that the relative fluctuations reduce as the reciprocal square root of the number of throws, a result valid for all statistical fluctuations, including shot noise.\nShot noise exists because phenomena such as light and electric current consist of the movement of discrete (also called \"quantized\") 'packets'. Consider light\u2014a stream of discrete photons\u2014coming out of a laser pointer and hitting a wall to create a visible spot. The fundamental physical processes that govern light emission are such that these photons are emitted from the laser at random times; but the many billions of photons needed to create a spot are so many that the brightness, the number of photons per unit of time, varies only infinitesimally with time. However, if the laser brightness is reduced until only a handful of photons hit the wall every second, the relative fluctuations in number of photons, i.e., brightness, will be significant, just as when tossing a coin a few times. These fluctuations are shot noise.\nThe concept of shot noise was first introduced in 1918 by Walter Schottky who studied fluctuations of current in vacuum tubes.\nShot noise may be dominant when the finite number of particles that carry energy (such as electrons in an electronic circuit or photons in an optical device) is sufficiently small so that uncertainties due to the Poisson distribution, which describes the occurrence of independent random events, are significant. It is important in electronics, telecommunications, optical detection, and fundamental physics.\nThe term can also be used to describe any noise source, even if solely mathematical, of similar origin. For instance, particle simulations may produce a certain amount of \"noise\", where because of the small number of particles simulated, the simulation exhibits undue statistical fluctuations which don't reflect the real-world system. The magnitude of shot noise increases according to the square root of the expected number of events, such as the electric current or intensity of light. But since the strength of the signal itself increases more rapidly, the \"relative\" proportion of shot noise decreases and the signal-to-noise ratio (considering only shot noise) increases anyway. Thus shot noise is most frequently observed with small currents or low light intensities that have been amplified.\nSignal-to-Noise.\nFor large numbers, the Poisson distribution approaches a normal distribution about its mean, and the elementary events (photons, electrons, etc.) are no longer individually observed, typically making shot noise in actual observations indistinguishable from true Gaussian noise. Since the standard deviation of shot noise is equal to the square root of the average number of events \"N\", the signal-to-noise ratio (SNR) is given by:\nformula_1\nThus when \"N\" is very large, the signal-to-noise ratio is very large as well, and any \"relative\" fluctuations in \"N\" due to other sources are more likely to dominate over shot noise. However, when the other noise source is at a fixed level, such as thermal noise, or grows slower than formula_2, increasing \"N\" (the DC current or light level, etc.) can lead to dominance of shot noise.\nProperties.\nElectronic devices.\nShot noise in electronic circuits consists of random fluctuations of direct current (DC), which is due to electric current being the flow of discrete charges (electrons). Because the electron has such a tiny charge, however, shot noise is of relative insignificance in many (but not all) cases of electrical conduction. For instance 1 ampere of current consists of about electrons per second; even though this number will randomly vary by several billion in any given second, such a fluctuation is minuscule compared to the current itself. In addition, shot noise is often less significant as compared with two other noise sources in electronic circuits, flicker noise and Johnson\u2013Nyquist noise. However, shot noise is temperature and frequency independent, in contrast to Johnson\u2013Nyquist noise, which is proportional to temperature, and flicker noise, with the spectral density decreasing with increasing frequency. Therefore, at high frequencies and low temperatures shot noise may become the dominant source of noise.\nWith very small currents and considering shorter time scales (thus wider bandwidths) shot noise can be significant. For instance, a microwave circuit operates on time scales of less than a nanosecond and if we were to have a current of 16 nanoamperes that would amount to only 100 electrons passing every nanosecond. According to Poisson statistics the \"actual\" number of electrons in any nanosecond would vary by 10 electrons rms, so that one sixth of the time fewer than 90 electrons would pass a point and one sixth of the time more than 110 electrons would be counted in a nanosecond. Now with this small current viewed on this time scale, the shot noise amounts to 1/10 of the direct current itself.\nThe result by Schottky, based on the assumption that the statistics of electrons passage is Poissonian, reads for the spectral noise density at the frequency formula_3,\nformula_4\nwhere formula_5 is the electron charge, and formula_6 is the average current of the electron stream. The noise spectral power is frequency independent, which means the noise is white. This can be combined with the Landauer formula, which relates the average current with the transmission eigenvalues formula_7 of the contact through which the current is measured (formula_8 labels transport channels). In the simplest case, these transmission eigenvalues can be taken to be energy independent and so the Landauer formula is \nformula_9\nwhere formula_10 is the applied voltage. This provides for \nformula_11\ncommonly referred to as the Poisson value of shot noise, formula_12. This is a classical result in the sense that it does not take into account that electrons obey Fermi\u2013Dirac statistics. The correct result takes into account the quantum statistics of electrons and reads (at zero temperature)\nformula_13\nIt was obtained in the 1990s by Viktor Khlus, Gordey Lesovik (independently the single-channel case), and Markus B\u00fcttiker (multi-channel case). This noise is white and is always suppressed with respect to the Poisson value. The degree of suppression, formula_14, is known as the Fano factor. Noises produced by different transport channels are independent. Fully open (formula_15) and fully closed (formula_16) channels produce no noise, since there are no irregularities in the electron stream.\nAt finite temperature, a closed expression for noise can be written as well. It interpolates between shot noise (zero temperature) and Nyquist-Johnson noise (high temperature).\nEffects of interactions.\nWhile this is the result when the electrons contributing to the current occur completely randomly, unaffected by each other, there are important cases in which these natural fluctuations are largely suppressed due to a charge build up. Take the previous example in which an average of 100 electrons go from point A to point B every nanosecond. During the first half of a nanosecond we would expect 50 electrons to arrive at point B on the average, but in a particular half nanosecond there might well be 60 electrons which arrive there. This will create a more negative electric charge at point B than average, and that extra charge will tend to \"repel\" the further flow of electrons from leaving point A during the remaining half nanosecond. Thus the net current integrated over a nanosecond will tend more to stay near its average value of 100 electrons rather than exhibiting the expected fluctuations (10 electrons rms) we calculated. This is the case in ordinary metallic wires and in metal film resistors, where shot noise is almost completely cancelled due to this anti-correlation between the motion of individual electrons, acting on each other through the coulomb force.\nHowever this reduction in shot noise does not apply when the current results from random events at a potential barrier which all the electrons must overcome due to a random excitation, such as by thermal activation. This is the situation in p-n junctions, for instance. A semiconductor diode is thus commonly used as a noise source by passing a particular direct current through it.\nIn other situations interactions can lead to an enhancement of shot noise, which is the result of a super-poissonian statistics. For example, in a resonant tunneling diode the interplay of electrostatic interaction and of the density of states in the quantum well leads to a strong enhancement of shot noise when the device is biased in the negative differential resistance region of the current-voltage characteristics.\nShot noise is distinct from voltage and current fluctuations expected in thermal equilibrium; this occurs without any applied DC voltage or current flowing. These fluctuations are known as Johnson\u2013Nyquist noise or thermal noise and increase in proportion to the Kelvin temperature of any resistive component. However both are instances of white noise and thus cannot be distinguished simply by observing them even though their origins are quite dissimilar.\nSince shot noise is a Poisson process due to the finite charge of an electron, one can compute the root mean square current fluctuations as being of a magnitude\nformula_17\nwhere \"q\" is the elementary charge of an electron, \u0394\"f\" is the single-sided bandwidth in hertz over which the noise is considered, and \"I\" is the DC flowing.\nFor a current of 100 mA, measuring the current noise over a bandwidth of 1\u00a0Hz, we obtain\nformula_18\nIf this noise current is fed through a resistor a noise voltage of\nformula_19\nwould be generated. Coupling this noise through a capacitor, one could supply a noise power of\nformula_20\nto a matched load.\nPhotodetectors.\nThe mean number of incident photons in time interval formula_21 on a photodetector is\nformula_22\nwhere \"c\" is the speed of light, \"h\" is the Planck constant, \"P\" is the average power, and formula_23 is the photon wavelength. Following Poisson statistics, the standard deviation of photon number is\nformula_24\nThe spectral density (formula_25) of shot noise limited light is \nformula_26\nThe SNR for a CCD camera can be calculated from the following equation:\nformula_27\nwhere:\nOptics.\nIn optics, shot noise describes the fluctuations of the number of photons detected (or simply counted in the abstract) because they occur independently of each other. This is therefore another consequence of discretization, in this case of the energy in the electromagnetic field in terms of photons. In the case of photon \"detection\", the relevant process is the random conversion of photons into photo-electrons for instance, thus leading to a larger effective shot noise level when using a detector with a quantum efficiency below unity. Only in an exotic squeezed coherent state can the number of photons measured per unit time have fluctuations smaller than the square root of the expected number of photons counted in that period of time. Of course there are other mechanisms of noise in optical signals which often dwarf the contribution of shot noise. When these are absent, however, optical detection is said to be \"photon noise limited\" as only the shot noise (also known as \"quantum noise\" or \"photon noise\" in this context) remains.\nShot noise is easily observable in the case of photomultipliers and avalanche photodiodes used in the Geiger mode, where individual photon detections are observed. However the same noise source is present with higher light intensities measured by any photo detector, and is directly measurable when it dominates the noise of the subsequent electronic amplifier. Just as with other forms of shot noise, the fluctuations in a photo-current due to shot noise scale as the square-root of the average intensity:\nformula_28\nThe shot noise of a coherent optical beam (having no other noise sources) is a fundamental physical phenomenon, reflecting quantum fluctuations in the electromagnetic field. In optical homodyne detection, the shot noise in the photodetector can be attributed to either the zero point fluctuations of the quantised electromagnetic field, or to the discrete nature of the photon absorption process. However, shot noise itself is not a distinctive feature of quantised field and can also be explained through semiclassical theory. What the semiclassical theory does not predict, however, is the squeezing of shot noise. Shot noise also sets a lower bound on the noise introduced by quantum amplifiers which preserve the phase of an optical signal.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41701", "revid": "6490875", "url": "https://en.wikipedia.org/wiki?curid=41701", "title": "Sideband", "text": "Radio communications concept\nIn radio communications, a sideband is a band of frequencies higher than or lower than the carrier frequency, that are the result of the modulation process. The sidebands carry the information transmitted by the radio signal. The sidebands comprise all the spectral components of the modulated signal except the carrier. The signal components above the carrier frequency constitute the upper sideband (USB), and those below the carrier frequency constitute the lower sideband (LSB). All forms of modulation produce sidebands.\nSideband creation.\nWe can illustrate the creation of sidebands with one trigonometric identity:\nformula_1\nAdding formula_2 to both sides:\nformula_3\nSubstituting (for instance) \u00a0formula_4\u00a0 and \u00a0formula_5\u00a0 where formula_6 represents time:\nformula_7\nAdding more complexity and time-variation to the amplitude modulation also adds it to the sidebands, causing them to widen in bandwidth and change with time. In effect, the sidebands \"carry\" the information content of the signal.\nSideband Characterization.\nIn the example above, a cross-correlation of the modulated signal with a pure sinusoid, formula_8 is zero at all values of formula_9 except 1100, 1000, and 900. And the non-zero values reflect the relative strengths of the three components. A graph of that concept, called a Fourier transform (or \"spectrum\"), is the customary way of visualizing sidebands and defining their parameters.\nAmplitude modulation.\nAmplitude modulation of a carrier signal normally results in two mirror-image sidebands. The signal components above the carrier frequency constitute the upper sideband (USB), and those below the carrier frequency constitute the lower sideband (LSB). For example, if a 900kHz carrier is amplitude modulated by a 1kHz audio signal, there will be components at 899kHz and 901kHz as well as 900kHz in the generated radio frequency spectrum; so an audio bandwidth of (say) 7kHz will require a radio spectrum bandwidth of 14kHz. In conventional AM transmission, as used by \"broadcast band\" AM stations, the original audio signal can be recovered (\"detected\") by either synchronous detector circuits or by simple envelope detectors because the carrier and both sidebands are present. This is sometimes called double sideband amplitude modulation (DSB-AM), but not all variants of DSB are compatible with envelope detectors.\nIn some forms of AM, the carrier may be reduced, to save power. The term \"DSB reduced-carrier\" normally implies enough carrier remains in the transmission to enable a receiver circuit to regenerate a strong carrier or at least synchronise a phase-locked loop but there are forms where the carrier is removed completely, producing double sideband with \"suppressed\" carrier (DSB-SC). Suppressed carrier systems require more sophisticated circuits in the receiver and some other method of deducing the original carrier frequency. An example is the stereophonic difference (L-R) information transmitted in stereo FM broadcasting on a 38\u00a0kHz subcarrier where a low-power signal at half the 38-kHz carrier frequency is inserted between the monaural signal frequencies (up to 15kHz) and the bottom of the stereo information sub-carrier (down to 38\u201315kHz, i.e. 23kHz). The receiver locally regenerates the subcarrier by doubling a special 19\u00a0kHz pilot tone. In another example, the quadrature modulation used historically for chroma information in PAL television broadcasts, the synchronising signal is a short burst of a few cycles of carrier during the \"back porch\" part of each scan line when no image is transmitted. But in other DSB-SC systems, the carrier may be regenerated directly from the sidebands by a Costas loop or squaring loop. This is common in digital transmission systems such as BPSK where the signal is continually present.\nIf part of one sideband and all of the other remain, it is called vestigial sideband, used mostly with television broadcasting, which would otherwise take up an unacceptable amount of bandwidth. Transmission in which only one sideband is transmitted is called single-sideband modulation or SSB. SSB is the predominant voice mode on shortwave radio other than shortwave broadcasting. Since the sidebands are mirror images, which sideband is used is a matter of convention.\nIn SSB, the carrier is suppressed, significantly reducing the electrical power (by up to 12dB) without affecting the information in the sideband. This makes for more efficient use of transmitter power and RF bandwidth, but a beat frequency oscillator must be used at the receiver to reconstitute the carrier. If the reconstituted carrier frequency is wrong then the output of the receiver will have the wrong frequencies, but for speech small frequency errors are no problem for intelligibility. Another way to look at an SSB receiver is as an RF-to-audio frequency transposer: in USB mode, the dial frequency is subtracted from each radio frequency component to produce a corresponding audio component, while in LSB mode each incoming radio frequency component is subtracted from the dial frequency.\nFrequency modulation.\nFrequency modulation also generates sidebands, the bandwidth consumed depending on the modulation index - often requiring significantly more bandwidth than DSB. Bessel functions can be used to calculate the bandwidth requirements of FM transmissions. Carson's rule is a useful approximation of bandwidth in several applications.\nEffects.\nSidebands can interfere with adjacent channels. The part of the sideband that would overlap the neighboring channel must be suppressed by filters, before or after modulation (often both). In broadcast band frequency modulation (FM), subcarriers above 75kHz are limited to a small percentage of modulation and are prohibited above 99\u00a0kHz altogether to protect the \u00b175\u00a0kHz normal deviation and \u00b1100\u00a0kHz channel boundaries. Amateur radio and public service FM transmitters generally utilize \u00b15\u00a0kHz deviation.\nTo accurately reproduce the modulating waveform, the entire signal processing path of the system of transmitter, propagation path, and receiver must have enough bandwidth so that enough of the sidebands can be used to recreate the modulated signal to the desired degree of accuracy.\nIn a non-linear system such as an amplifier, sidebands of the original signal frequency components may be generated due to distortion. This is generally minimized but may be intentionally done for the fuzzbox musical effect.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "41702", "revid": "3727527", "url": "https://en.wikipedia.org/wiki?curid=41702", "title": "Signal compression", "text": "Signal compression is the use of various techniques to increase the quality or quantity of signal parameters transmitted through a given telecommunications channel.\nTypes of signal compression include:\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\nIndex of articles associated with the same name\nThis includes a list of related items that share the same name (or similar names). &lt;br&gt; If an [ internal link] incorrectly led you here, you may wish to change the link to point directly to the intended article."}
{"id": "41703", "revid": "10547048", "url": "https://en.wikipedia.org/wiki?curid=41703", "title": "Signaling (telecommunications)", "text": "Exchange of information required to set up a telecommunications connection\nIn telecommunications, signaling is the use of signals for controlling communications. This may constitute an information exchange concerning the establishment and control of a telecommunication circuit and the management of the network.\nClassification.\nSignaling systems may be classified based on several principal characteristics.\nIn-band and out-of-band signaling.\nIn the public switched telephone network (PSTN), in-band signaling is the exchange of call control information within the same physical channel, or within the same frequency band, that the message (the callers' voice) is using. An example is dual-tone multi-frequency signaling (DTMF), which is used on most telephone lines to customer premises.\nOut-of-band signaling is telecommunication signaling on a dedicated channel separate from that used for the message. Out-of-band signaling has been used since Signaling System No. 6 (SS6) was introduced in the 1970s, and also in Signalling System No. 7 (SS7) in 1980 which became the standard for signaling among exchanges internationally.\nIn the mid-20th century, supervision signals on long-distance trunks in North America were primarily in-band, for example at 2600 Hz, necessitating a notch filter to prevent interference. Late in the century, all supervisory signals had been moved out of band. With the advent of digital trunks, supervision signals are carried by robbed bits or other bits in the E1-carrier dedicated to signaling.\nLine versus register signaling.\nLine signaling is concerned with conveying information on the state of the line or channel, such as on-hook, off-hook (answer supervision and disconnect supervision, together referred to as \"supervision\"), ringing, and hook flash. \nRegister signaling is concerned with conveying addressing information, such as the calling and/or called telephone number. In the early days of telephony, with operator handling calls, the addressing formation is by voice as \"Operator, connect me to Mr. Smith please\". In the first half of the 20th century, addressing formation is done by using a rotary dial, which rapidly breaks the line current into pulses, with the number of pulses conveying the address. Finally, starting in the second half of the century, address signaling is by DTMF.\nChannel-associated versus common-channel signaling.\nChannel-associated signaling (CAS) employs a signaling channel that is dedicated to a specific bearer channel.\nCommon-channel signaling (CCS) employs a signaling channel which conveys signaling information relating to multiple bearer channels. These bearer channels, therefore, have their signaling channel in common.\nCompelled signaling.\nCompelled signaling refers to signaling where the receipt of each signal from an originating register needs to be explicitly acknowledged before the next signal can be sent.\nMost forms of R2 register signaling are compelled, while R1 multi-frequency signaling is not.\nThe term is only relevant in the case of signaling systems that use discrete signals (e.g. a combination of tones to denote one digit), as opposed to signaling systems which are message-oriented (such as SS7 and ISDN Q.931) where each message is able to convey multiple items of formation (e.g. multiple digits of the called telephone number).\nSubscriber versus trunk signaling.\nSubscriber signaling refers to the signaling between the telephone and the telephone exchange. Trunk signaling is the signaling between exchanges.\nExamples.\nEvery signaling system can be characterized along each of the above axes of classification. A few examples:\nWhereas common-channel signaling systems are out-of-band by definition, and in-band signaling systems are also necessarily channel-associated, the above metering pulse example demonstrates that there exist channel-associated signaling systems which are out-of-band.\nProtocols.\nA signaling protocol is a type of communications protocol for encapsulating the signaling between communication endpoints and switching systems to establish or terminate a connection and to identify the state of connection.\nThe following is a list of signaling protocols:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41704", "revid": "668752", "url": "https://en.wikipedia.org/wiki?curid=41704", "title": "Signal processing gain", "text": ""}
{"id": "41705", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41705", "title": "Signal-to-crosstalk ratio", "text": "The signal-to-crosstalk ratio at a specified point in a circuit is the ratio of the power of the wanted signal to the power of the unwanted signal from another channel. \nThe signals are adjusted in each channel so that they are of equal power at the zero transmission level point in their respective channels. \nThe signal-to-crosstalk ratio is usually expressed in dB. "}
{"id": "41706", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41706", "title": "Signal-to-noise ratio", "text": "Ratio of the desired signal to the background noise\nSignal-to-noise ratio (SNR or S/N) is a measure used in science and engineering that compares the level of a desired signal to the level of background noise. SNR is defined as the ratio of signal power to noise power, often expressed in decibels. A ratio higher than 1:1 (greater than 0\u00a0dB) indicates more signal than noise.\nSNR is an important parameter that affects the performance and quality of systems that process or transmit signals, such as communication systems, audio equipment, radar systems, imaging systems, and data acquisition systems. A high SNR means that the signal is clear and easy to detect or interpret, while a low SNR means that the signal is corrupted or obscured by noise and may be difficult to distinguish or recover. SNR can be improved by various methods, such as increasing the signal strength, reducing the noise level, filtering out unwanted noise, or using error correction techniques.\nSNR also determines the maximum possible amount of data that can be transmitted reliably over a given channel, which depends on its bandwidth and SNR. This relationship is described by the Shannon\u2013Hartley theorem, which is a fundamental law of information theory.\nSNR can be calculated using different formulas depending on how the signal and noise are measured and defined. The most common way to express SNR is in decibels, which is a logarithmic scale that makes it easier to compare large or small values. Other definitions of SNR may use different factors or bases for the logarithm, depending on the context and application.\nDefinition.\nOne definition of signal-to-noise ratio is the ratio of the power of a signal (meaningful input) to the power of background noise (meaningless or unwanted input):\nformula_1\nwhere P is average power. Both signal and noise power must be measured at the same or equivalent points in a system, and within the same system bandwidth.\nThe signal-to-noise ratio of a random variable (S) to random noise N is:\nformula_2\nwhere E refers to the expected value, which in this case is the mean square of N.\nIf the signal is simply a constant value of \"s\", this equation simplifies to:\nformula_3\nIf the noise has expected value of zero, as is common, the denominator is its variance, the square of its standard deviation \"\u03c3\"N.\nThe signal and the noise must be measured the same way, for example as voltages across the same impedance. Their root mean squares can alternatively be used according to:\nformula_4\nwhere A is root mean square (RMS) amplitude (for example, RMS voltage).\nDecibels.\nBecause many signals have a very wide dynamic range, signals are often expressed using the logarithmic decibel scale. Based upon the definition of decibel, signal and noise may be expressed in decibels (dB) as\nformula_5\nand\nformula_6\nIn a similar manner, SNR may be expressed in decibels as\nformula_7\nUsing the definition of SNR\nformula_8\nUsing the quotient rule for logarithms\nformula_9\nSubstituting the definitions of SNR, signal, and noise in decibels into the above equation results in an important formula for calculating the signal to noise ratio in decibels, when the signal and noise are also in decibels:\nformula_10\nIn the above formula, P is measured in units of power, such as watts (W) or milliwatts (mW), and the signal-to-noise ratio is a pure number.\nHowever, when the signal and noise are measured in volts (V) or amperes (A), which are measures of amplitude, they must first be squared to obtain a quantity proportional to power, as shown below:\nformula_11\nDynamic range.\nThe concepts of signal-to-noise ratio and dynamic range are closely related. Dynamic range measures the ratio between the strongest un-distorted signal on a channel and the minimum discernible signal, which for most purposes is the noise level. SNR measures the ratio between an arbitrary signal level (not necessarily the most powerful signal possible) and noise. Measuring signal-to-noise ratios requires the selection of a representative or \"reference\" signal. In audio engineering, the reference signal is usually a sine wave at a standardized nominal or alignment level, such as 1\u00a0kHz at +4 dBu (1.228 VRMS).\nSNR is usually taken to indicate an \"average\" signal-to-noise ratio, as it is possible that instantaneous signal-to-noise ratios will be considerably different. The concept can be understood as normalizing the noise level to 1 (0\u00a0dB) and measuring how far the signal 'stands out'.\nDifference from conventional power.\nIn physics, the average power of an AC signal is defined as the average value of voltage times current; for resistive (non-reactive) circuits, where voltage and current are in phase, this is equivalent to the product of the rms voltage and current:\nformula_12\nformula_13\nBut in signal processing and communication, one usually assumes that formula_14 so that factor is usually not included while measuring power or energy of a signal. This may cause some confusion among readers, but the resistance factor is not significant for typical operations performed in signal processing, or for computing power ratios. For most cases, the power of a signal would be considered to be simply\nformula_15\nAlternative definition.\nAn alternative definition of SNR is as the reciprocal of the coefficient of variation, i.e., the ratio of mean to standard deviation of a signal or measurement:\nformula_16\nwhere formula_17 is the signal mean or expected value and formula_18 is the standard deviation of the noise, or an estimate thereof. Notice that such an alternative definition is only useful for variables that are always non-negative (such as photon counts and luminance), and it is only an approximation since formula_19. It is commonly used in image processing, where the SNR of an image is usually calculated as the ratio of the mean pixel value to the standard deviation of the pixel values over a given neighborhood.\nSometimes SNR is defined as the square of the alternative definition above, in which case it is equivalent to the more common definition:\nformula_20\nThis definition is closely related to the sensitivity index or \"d'\", when assuming that the signal has two states separated by signal amplitude formula_17, and the noise standard deviation formula_18 does not change between the two states.\nThe \"Rose criterion\" (named after Albert Rose) states that an SNR of at least 5 is needed to be able to distinguish image features with certainty. An SNR less than 5 means less than 100% certainty in identifying image details.\nYet another alternative, very specific, and distinct definition of SNR is employed to characterize sensitivity of imaging systems; see Signal-to-noise ratio (imaging).\nRelated measures are the \"contrast ratio\" and the \"contrast-to-noise ratio\".\nModulation system measurements.\nAmplitude modulation.\nChannel signal-to-noise ratio is given by\nformula_23\nwhere W is the bandwidth and formula_24 is modulation index\nOutput signal-to-noise ratio (of AM receiver) is given by\nformula_25\nFrequency modulation.\nChannel signal-to-noise ratio is given by\nformula_26\nOutput signal-to-noise ratio is given by\nformula_27\nNoise reduction.\nAll real measurements are disturbed by noise. This includes electronic noise, but can also include external events that affect the measured phenomenon \u2014 wind, vibrations, the gravitational attraction of the moon, variations of temperature, variations of humidity, etc., depending on what is measured and of the sensitivity of the device. It is often possible to reduce the noise by controlling the environment.\nInternal electronic noise of measurement systems can be reduced through the use of low-noise amplifiers.\nWhen the characteristics of the noise are known and are different from the signal, it is possible to use a filter to reduce the noise. For example, a lock-in amplifier can extract a narrow bandwidth signal from broadband noise a million times stronger.\nWhen the signal is constant or periodic and the noise is random, it is possible to enhance the SNR by averaging the measurements. In this case the noise goes down as the square root of the number of averaged samples.\nDigital signals.\nWhen a measurement is digitized, the number of bits used to represent the measurement determines the maximum possible signal-to-noise ratio. This is because the minimum possible noise level is the error caused by the quantization of the signal, sometimes called quantization noise. This noise level is non-linear and signal-dependent; different calculations exist for different signal models. Quantization noise is modeled as an analog error signal summed with the signal before quantization (\"additive noise\").\nThis theoretical maximum SNR assumes a perfect input signal. If the input signal is already noisy (as is usually the case), the signal's noise may be larger than the quantization noise. Real analog-to-digital converters also have other sources of noise that further decrease the SNR compared to the theoretical maximum from the idealized quantization noise, including the intentional addition of dither.\nAlthough noise levels in a digital system can be expressed using SNR, it is more common to use Eb/No, the energy per bit per noise power spectral density.\nThe modulation error ratio (MER) is a measure of the SNR in a digitally modulated signal.\nFixed point.\nFor \"n\"-bit integers with equal distance between quantization levels (uniform quantization) the dynamic range (DR) is also determined.\nAssuming a uniform distribution of input signal values, the quantization noise is a uniformly distributed random signal with a peak-to-peak amplitude of one quantization level, making the amplitude ratio 2\"n\"/1. The formula is then:\nformula_28\nThis relationship is the origin of statements like \"16-bit audio has a dynamic range of 96\u00a0dB\". Each extra quantization bit increases the dynamic range by roughly 6\u00a0dB.\nAssuming a full-scale sine wave signal (that is, the quantizer is designed such that it has the same minimum and maximum values as the input signal), the quantization noise approximates a sawtooth wave with peak-to-peak amplitude of one quantization level and uniform distribution. In this case, the SNR is approximately\nformula_29\nFloating point.\nFloating-point numbers provide a way to trade off signal-to-noise ratio for an increase in dynamic range. For n-bit floating-point numbers, with n-m bits in the mantissa and m bits in the exponent:\nformula_30\nformula_31\nThe dynamic range is much larger than fixed-point but at a cost of a worse signal-to-noise ratio. This makes floating-point preferable in situations where the dynamic range is large or unpredictable. Fixed-point's simpler implementations can be used with no signal quality disadvantage in systems where dynamic range is less than 6.02m. The very large dynamic range of floating-point can be a disadvantage, since it requires more forethought in designing algorithms.\nOptical signals.\nOptical signals have a carrier frequency (about and more) that is much higher than the modulation frequency. This way the noise covers a bandwidth that is much wider than the signal itself. The resulting signal influence relies mainly on the filtering of the noise. To describe the signal quality without taking the receiver into account, the optical SNR (OSNR) is used. The OSNR is the ratio between the signal power and the noise power in a given bandwidth. Most commonly a reference bandwidth of 0.1\u00a0nm is used. This bandwidth is independent of the modulation format, the frequency and the receiver. For instance an OSNR of 20\u00a0dB/0.1\u00a0nm could be given, even the signal of 40 GBit DPSK would not fit in this bandwidth. OSNR is measured with an optical spectrum analyzer.\nTypes and abbreviations.\nSignal to noise ratio may be abbreviated as SNR and less commonly as S/N. PSNR stands for peak signal-to-noise ratio. GSNR stands for geometric signal-to-noise ratio. SINR is the signal-to-interference-plus-noise ratio.\nOther uses.\nWhile SNR is commonly quoted for electrical signals, it can be applied to any form of signal, for example isotope levels in an ice core, biochemical signaling between cells, or financial trading signals. \nThe term is sometimes used metaphorically to refer to the ratio of useful information to false or irrelevant data in a conversation or exchange. For example, in online discussion forums and other online communities, off-topic posts and spam are regarded as noise that interferes with the signal of appropriate discussion.\nSNR can also be applied in marketing and how business professionals manage information overload. Managing a healthy signal to noise ratio can help business executives improve their KPIs (Key Performance Indicators).\nSimilar concepts.\nThe signal-to-noise ratio is similar to Cohen's d given by the difference of estimated means divided by the standard deviation of the data formula_32 and is related to the test statistic formula_33 in the t-test.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41707", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41707", "title": "Signal transition", "text": "Signal transition, when referring to the modulation of a carrier signal, is a change from one significant condition to another. \nExamples of signal transitions are a change from one electric current, voltage, or power level to another; a change from one optical power level to another; a phase shift; or a change from one frequency or wavelength to another. \nSignal transitions are used to create signals that represent information, such as \"0\" and \"1\" or \"mark\" and \"space\".\nReferences.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41708", "revid": "4081", "url": "https://en.wikipedia.org/wiki?curid=41708", "title": "Significant condition", "text": ""}
{"id": "41709", "revid": "466162", "url": "https://en.wikipedia.org/wiki?curid=41709", "title": "Silicon photodiode", "text": ""}
{"id": "41710", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41710", "title": "Simple Network Management Protocol", "text": "Computer network management and monitoring protocol\nSimple Network Management Protocol (SNMP) is an Internet Standard protocol for collecting and organizing information about managed devices on IP networks and for modifying that information to change device behavior. Devices that typically support SNMP include cable modems, routers, network switches, servers, workstations, printers, and more.\nSNMP is widely used in network management for network monitoring. SNMP exposes management data in the form of variables on the managed systems organized in a management information base (MIB), which describes the system status and configuration. These variables can then be remotely queried (and, in some circumstances, manipulated) by managing applications.\nThree significant versions of SNMP have been developed and deployed. SNMPv1 is the original version of the protocol. More recent versions, SNMPv2c and SNMPv3, feature improvements in performance, flexibility and security.\nSNMP is a component of the Internet Protocol Suite as defined by the Internet Engineering Task Force (IETF). It consists of a set of standards for network management, including an application layer protocol, a database schema, and a set of data objects.\nOverview and basic concepts.\nIn typical uses of SNMP, one or more administrative computers called \"managers\" have the task of monitoring or managing a group of hosts or devices on a computer network. Each managed system executes a software component called an \"agent\" that reports information via SNMP to the manager.\nAn SNMP-managed network consists of three key components:\nA \"managed device\" is a network node that implements an SNMP interface that allows unidirectional (read-only) or bidirectional (read and write) access to node-specific information. Managed devices exchange node-specific information with the NMSs. Sometimes called network elements, the managed devices can be any type of device, including, but not limited to, routers, access servers, switches, cable modems, bridges, hubs, IP telephones, IP video cameras, computer hosts, and printers.\nAn \"agent\" is a network-management software module that resides on a managed device. An agent has local knowledge of management information and translates that information to or from an SNMP-specific form.\nA \"network management station\" executes applications that monitor and control managed devices. NMSs provide the bulk of the processing and memory resources required for network management. One or more NMSs may exist on any managed network.\nManagement information base.\nSNMP agents expose management data on the managed systems as variables. The protocol also permits active management tasks, such as configuration changes, through remote modification of these variables. The variables accessible via SNMP are organized in hierarchies. SNMP itself does not define which variables a managed system should offer. Rather, SNMP uses an extensible design that allows applications to define their own hierarchies. These hierarchies are described as a management information base (MIB). MIBs describe the structure of the management data of a device subsystem; they use a hierarchical namespace containing object identifiers (OID). Each OID identifies a variable that can be read or set via SNMP. MIBs use the notation defined by Structure of Management Information Version 2.0 (SMIv2, ), a subset of ASN.1.\nProtocol details.\nSNMP operates in the application layer of the Internet protocol suite. All SNMP messages are transported via User Datagram Protocol (UDP). The SNMP agent receives requests on UDP port 161. The manager may send requests from any available source port to port 161 in the agent. The agent response is sent back to the source port on the manager. The manager receives notifications (\"Traps\" and \"InformRequests\") on port 162. The agent may generate notifications from any available port. When used with Transport Layer Security or Datagram Transport Layer Security, requests are received on port 10161 and notifications are sent to port 10162.\nSNMPv1 specifies five core protocol data units (PDUs). Two other PDUs, \"GetBulkRequest\" and \"InformRequest\" were added in SNMPv2 and the \"Report\" PDU was added in SNMPv3. All SNMP PDUs are constructed as follows:\nThe seven SNMP PDU types, as identified by the \"PDU-type\" field, are as follows:\n specifies that an SNMP implementation must accept a message of at least 484 bytes in length. In practice, SNMP implementations accept longer messages. If implemented correctly, an SNMP message is discarded if the decoding of the message fails and thus malformed SNMP requests are ignored. A successfully decoded SNMP request is then authenticated using the community string. If the authentication fails, a trap is generated indicating an authentication failure and the message is dropped.\nSNMPv1 and SNMPv2c use \"communities\" to establish trust between managers and agents. Most agents support three community names, one each for read-only, read-write and trap. These three \"community strings\" control different types of activities. The read-only community applies to \"get\" requests. The read-write community string applies to \"set\" requests. The trap community string applies to receipt of \"traps\". SNMPv3 also uses community strings, but allows for secure authentication and communication between SNMP manager and agent.\nProtocol versions.\nIn practice, SNMP implementations often support multiple versions: typically SNMPv1, SNMPv2c, and SNMPv3.\nVersion 1.\nSNMP version 1 (SNMPv1) is the initial implementation of the SNMP protocol. The design of SNMPv1 was done in the 1980s by a group of collaborators who viewed the officially sponsored OSI/IETF/NSF (National Science Foundation) effort (HEMS/CMIS/CMIP) as both unimplementable in the computing platforms of the time as well as potentially unworkable. SNMP was approved based on a belief that it was an interim protocol needed for taking steps towards large-scale deployment of the Internet and its commercialization.\nThe first Request for Comments (RFCs) for SNMP, now known as SNMPv1, appeared in 1988:\nIn 1990, these documents were superseded by:\nIn 1991, (MIB-1) was replaced by the more often used:\nSNMPv1 is widely used and is the de facto network management protocol in the Internet community.\nSNMPv1 may be carried by transport layer protocols such as User Datagram Protocol (UDP), OSI Connectionless-mode Network Service (CLNS), AppleTalk Datagram Delivery Protocol (DDP), and Novell Internetwork Packet Exchange (IPX).\nVersion 1 has been criticized for its poor security. The specification does, in fact, allow room for custom authentication to be used, but widely used implementations \"support only a trivial authentication service that identifies all SNMP messages as authentic SNMP messages.\" The security of the messages, therefore, becomes dependent on the security of the channels over which the messages are sent. For example, an organization may consider their internal network to be sufficiently secure that no encryption is necessary for its SNMP messages. In such cases, the \"community name\", which is transmitted in cleartext, tends to be viewed as a de facto password, in spite of the original specification.\nVersion 2.\nSNMPv2, defined by and , revises version 1 and includes improvements in the areas of performance, security and manager-to-manager communications. It introduced \"GetBulkRequest\", an alternative to iterative GetNextRequests for retrieving large amounts of management data in a single request. The new party-based security system introduced in SNMPv2, viewed by many as overly complex, was not widely adopted. This version of SNMP reached the Proposed Standard level of maturity, but was deemed obsolete by later versions.\n\"Community-Based Simple Network Management Protocol version 2\", or \"SNMPv2c\", is defined in \u2013. SNMPv2c comprises SNMPv2 \"without\" the controversial new SNMP v2 security model, using instead the simple community-based security scheme of SNMPv1. This version is one of relatively few standards to meet the IETF's Draft Standard maturity level, and was widely considered the \"de facto\" SNMPv2 standard. It was later restated as part of SNMPv3.\n\"User-Based Simple Network Management Protocol version 2\", or \"SNMPv2u\", is defined in \u2013. This is a compromise that attempts to offer greater security than SNMPv1, but without incurring the high complexity of SNMPv2. A variant of this was commercialized as \"SNMP v2*\", and the mechanism was eventually adopted as one of two security frameworks in SNMP v3.\n64-bit counters.\nSNMP version 2 introduces the option for 64-bit data counters. Version 1 was designed only with 32-bit counters, which can store integer values from zero to 4.29 billion (precisely ). A 32-bit version 1 counter cannot store the maximum speed of a 10-gigabit or larger interface, expressed in bits per second. Similarly, a 32-bit counter tracking statistics for a 10-gigabit or larger interface can roll over back to zero again in less than one minute, which may be a shorter time interval than a counter is polled to read its current state. This would result in lost or invalid data due to the undetected value rollover and corruption of trend-tracking data.\nThe 64-bit version 2 counter can store values from zero to 18.4 quintillion (precisely 18,446,744,073,709,551,615) and so is currently unlikely to experience a counter rollover between polling events. For example, 1.6 terabit Ethernet is predicted to become available by 2025. A 64-bit counter incrementing at a rate of 1.6 trillion bits per second would be able to retain information for such an interface without rolling over for 133 days.\nSNMPv1 and SNMPv2c interoperability.\nSNMPv2c is incompatible with SNMPv1 in two key areas: message formats and protocol operations. SNMPv2c messages use a different header and different protocol data unit (PDU) formats than SNMPv1 messages. SNMPv2c also uses two protocol operations that are not specified in SNMPv1. To overcome incompatibility, defines two SNMPv1/v2c coexistence strategies: proxy agents and bilingual network-management systems.\nProxy agents.\nAn SNMPv2 agent can act as a proxy agent on behalf of SNMPv1-managed devices. When an SNMPv2 NMS issues a command intended for an SNMPv1 agent, it sends it to the SNMPv2 proxy agent instead. The proxy agent forwards codice_1, codice_2, and codice_3 messages to the SNMPv1 agent unchanged. GetBulk messages are converted by the proxy agent to codice_2 messages and then are forwarded to the SNMPv1 agent. Additionally, the proxy agent receives and maps SNMPv1 trap messages to SNMPv2 trap messages and then forwards them to the NMS.\nBilingual network-management system.\nBilingual SNMPv2 network-management systems support both SNMPv1 and SNMPv2. To support this dual-management environment, a management application examines information stored in a local database to determine whether the agent supports SNMPv1 or SNMPv2. Based on the information in the database, the NMS communicates with the agent using the appropriate version of SNMP.\nVersion 3.\nAlthough SNMPv3 makes no changes to the protocol aside from the addition of cryptographic security, it looks very different due to new textual conventions, concepts, and terminology. The most visible change was to define a secure version of SNMP, by adding security and remote configuration enhancements to SNMP. The security aspect is addressed by offering both strong authentication and data encryption for privacy. For the administration aspect, SNMPv3 focuses on two parts, namely notification originators and proxy forwarders. The changes also facilitate remote configuration and administration of the SNMP entities, as well as addressing issues related to the large-scale deployment, accounting, and fault management.\nFeatures and enhancements included:\nSecurity was one of the biggest weaknesses of SNMP until v3. Authentication in SNMP Versions 1 and 2 amounts to nothing more than a password (community string) sent in clear text between a manager and agent. Each SNMPv3 message contains security parameters that are encoded as an octet string. The meaning of these security parameters depends on the security model being used. The security approach in v3 targets:\nv3 also defines the USM and VACM, which were later followed by a transport security model (TSM) that provided support for SNMPv3 over SSH and SNMPv3 over TLS and DTLS.\nAs of 2004[ [update]] the IETF recognizes \"Simple Network Management Protocol version 3\" as defined by \u2013 (also known as STD0062) as the current standard version of SNMP. The IETF has designated SNMPv3 a full Internet standard, the highest maturity level for an RFC. It considers earlier versions to be obsolete (designating them variously \"Historic\" or \"Obsolete\").\nImplementation issues.\nSNMP's powerful write capabilities, which would allow the configuration of network devices, are not being fully utilized by many vendors, partly because of a lack of security in SNMP versions before SNMPv3, and partly because many devices simply are not capable of being configured via individual MIB object changes.\nSome SNMP values (especially tabular values) require specific knowledge of table indexing schemes, and these index values are not necessarily consistent across platforms. This can cause correlation issues when fetching information from multiple devices that may not employ the same table indexing scheme (for example, fetching disk utilization metrics, where a specific disk identifier is different across platforms.)\nSome major equipment vendors tend to over-extend their proprietary command line interface (CLI) centric configuration and control systems.\nIn February 2002 the Carnegie Mellon Software Engineering Institute (CM-SEI) Computer Emergency Response Team Coordination Center (CERT-CC) issued an Advisory on SNMPv1, after the Oulu University Secure Programming Group conducted a thorough analysis of SNMP message handling. Most SNMP implementations, regardless of which version of the protocol they support, use the same program code for decoding protocol data units (PDU) and problems were identified in this code. Other problems were found with decoding SNMP trap messages received by the SNMP management station or requests received by the SNMP agent on the network device. Many vendors had to issue patches for their SNMP implementations.\nSecurity implications.\nUsing SNMP to attack a network.\nBecause SNMP is designed to allow administrators to monitor and configure network devices remotely, it can also be used to penetrate a network. A significant number of software tools can scan the entire network using SNMP; therefore, mistakes in the configuration of the read-write mode can make a network susceptible to attacks.\nIn 2001, Cisco released information that indicated that, even in read-only mode, the SNMP implementation of Cisco IOS is vulnerable to certain denial of service attacks. These security issues can be fixed through an IOS upgrade.\nIf SNMP is not used in a network, it should be disabled in network devices. When configuring SNMP read-only mode, close attention should be paid to the configuration of the access control and from which IP addresses SNMP messages are accepted. If the SNMP servers are identified by their IP addresses, SNMP is only allowed to respond to these IPs and SNMP messages from other IP addresses would be denied. However, IP address spoofing remains a security concern.\nAuthentication.\nSNMP is available in different versions, and each version has its own security issues. SNMP v1 sends passwords in plaintext over the network. Therefore, passwords can be read with packet sniffing. SNMP v2 allows password hashing with MD5, but this has to be configured. Virtually all network management software support SNMP v1, but not necessarily SNMP v2 or v3. SNMP v2 was specifically developed to provide data security, that is authentication, privacy and authorization, but only SNMP version 2c gained the endorsement of the Internet Engineering Task Force (IETF), while versions 2u and 2* failed to gain IETF approval due to security issues. SNMP v3 uses MD5, Secure Hash Algorithm (SHA) and keyed algorithms to offer protection against unauthorized data modification and spoofing attacks. If a higher level of security is needed the Data Encryption Standard (DES) can be optionally used in the cipher block chaining mode. SNMP v3 is implemented on Cisco IOS since release 12.0(3)T.\nSNMPv3 may be subject to brute force and dictionary attacks for guessing the authentication keys, or encryption keys, if these keys are generated from short (weak) passwords or passwords that can be found in a dictionary. SNMPv3 allows both providing random uniformly distributed cryptographic keys and generating cryptographic keys from a password supplied by the user. The risk of guessing authentication strings from hash values transmitted over the network depends on the cryptographic hash function used and the length of the hash value. SNMPv3 uses the HMAC-SHA-2 authentication protocol for the User-based Security Model (USM). SNMP does not use a more secure challenge-handshake authentication protocol. SNMPv3 (like other SNMP protocol versions) is a stateless protocol, and it has been designed with a minimal amount of interactions between the agent and the manager. Thus introducing a challenge-response handshake for each command would impose a burden on the agent (and possibly on the network itself) that the protocol designers deemed excessive and unacceptable.\nThe security deficiencies of all SNMP versions can be mitigated by IPsec authentication and confidentiality mechanisms. SNMP also may be carried securely over Datagram Transport Layer Security (DTLS).\nMany SNMP implementations include a type of automatic discovery where a new network component, such as a switch or router, is discovered and polled automatically. In SNMPv1 and SNMPv2c, this is done through a \"community string\" that is transmitted in clear-text to other devices. Clear-text passwords are a significant security risk. Once the community string is known outside the organization, it could become the target for an attack. To alert administrators of other attempts to glean community strings, SNMP can be configured to pass community-name authentication failure traps. If SNMPv2 is used, the issue can be avoided by enabling password encryption on the SNMP agents of network devices.\nThe common default configuration for community strings are \"public\" for read-only access and \"private\" for read-write. Because of the well-known defaults, SNMP topped the list of the SANS Institute's Common Default Configuration Issues and was number ten on the SANS Top 10 Most Critical Internet Security Threats for the year 2000. System and network administrators frequently do not change these configurations.\nWhether it runs over TCP or UDP, SNMPv1 and v2 are vulnerable to IP spoofing attacks. With spoofing, attackers may bypass device access lists in agents that are implemented to restrict SNMP access. SNMPv3 security mechanisms, such as USM or TSM, can prevent spoofing attacks.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41711", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=41711", "title": "Simplex circuit", "text": ""}
{"id": "41712", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41712", "title": "Simplex signaling", "text": "Simplex signaling (SX) is signaling in which two conductors are used for a single telecommunication circuit, and a center-tapped coil, or its equivalent, is used to split the signaling current equally between the two conductors. The return path for the current is through ground. \nIt is distinct from a phantom circuit in which the return current path for power or signaling is provided through different signal conductors.\nSX signaling may be one-way, for intra-central-office use, or the simplex legs may be connected to form full-duplex signaling circuits that function like composite (CX) signaling circuits with E&amp;M lead control.\nSimplex is also used to describe a powering method where one or more signal conductors carries direct current to power a remote device, which sends its output signal back on the same conductor. Phantom powering as used in audio is a form of simplex powering, as the return current flows through the ground or shield conductor."}
{"id": "41713", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=41713", "title": "Simulate", "text": ""}
{"id": "41714", "revid": "48911350", "url": "https://en.wikipedia.org/wiki?curid=41714", "title": "SINAD", "text": ""}
{"id": "41715", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41715", "title": "Single-frequency signaling", "text": "Telephony signaling technique\nIn telephony, single-frequency signaling (SF or SF tone) is line signaling in which dial pulses or supervisory signals are conveyed by a single-frequency tone in each direction in the voice-band. SF and similar systems were used in 20th-century carrier systems.\nAn SF signaling unit converts DC signaling (usually, at least in long-distance circuits, E&amp;M signaling) to a format (characterized by the presence or absence of a single voice-frequency tone), which is suitable for transmission over an AC path, \"e.g.\", a carrier system. The SF tone is present in the on-hook or idle state and absent during the seized state. In the seized state, dial pulses are conveyed by bursts of SF tone, corresponding to the interruptions in dc continuity created by a rotary dial or other DC dialing mechanism. \nThe SF tone may occupy a small portion of the user data channel spectrum, \"e.g.,\" 1600\u00a0Hz or 2600 Hz (SF \"in-band signaling)\". There may be a notch filter at the precise SF frequency, either filtering the circuit at all times or only when the circuit is off-hook, to prevent the user from inadvertently disconnecting a call if the users voice has a sufficiently strong spectral content at the SF frequency, a falsing condition known as \"talk-off\". Notoriously, this property was exploited by blue boxers and other toll fraudsters. The SF tone may also be just outside the user voice band, \"e.g.,\" 3600\u00a0Hz. \nThe Defense Data Network (DDN) transmitted DC line signaling pulses or supervisory signals, or both, over carrier channels or cable pairs on a four-wire circuit basis using a 2600\u00a0Hz signal tone. The conversion into tones, or vice versa, is done by SF signal units.\nSF was developed in the early 20th century and standardized in middle century. It declined in the 1970s due to the adoption of T-carrier, and was largely abandoned late in the century in favor of common-channel signaling.\nSF tones can transmit data that only consists of everyday telephone numbers, numbers which only have 0-9 in them. How many pulses are transmitted in one time is part of the number that is dialed. One pulse is 1, two pulses are 2, three pulses are 3 and so on, with 10 pulses being 0.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "41716", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41716", "title": "Single-mode optical fiber", "text": "Optical fiber designed to carry only a single mode of light, the transverse mode\nIn fiber-optic communication, a single-mode optical fiber, also known as fundamental- or mono-mode, is an optical fiber designed to carry only a single mode of light - the transverse mode. Modes are the possible solutions of the Helmholtz equation for waves, which is obtained by combining Maxwell's equations and the boundary conditions. These modes define the way the wave travels through space, i.e. how the wave is distributed in space. Waves can have the same mode but have different frequencies. This is the case in single-mode fibers, where we can have waves with different frequencies, but of the same mode, which means that they are distributed in space in the same way, and that gives us a single ray of light. Although the ray travels parallel to the length of the fiber, it is often called transverse mode since its electromagnetic oscillations occur perpendicular (transverse) to the length of the fiber. The 2009 Nobel Prize in Physics was awarded to Charles K. Kao for his theoretical work on the single-mode optical fiber. The standards G.652 and G.657 define the most widely used forms of single-mode optical fiber.\nHistory.\nIn 1961, Elias Snitzer while working at American Optical published a comprehensive theoretical description of single mode fibers in the Journal of the Optical Society of America.\nAt the Corning Glass Works (now Corning Inc.), Robert Maurer, Donald Keck and Peter Schultz started with fused silica, a material that can be made extremely pure, but has a high melting point and a low refractive index. They made cylindrical preforms by depositing purified materials from the vapor phase, adding carefully controlled levels of dopants to make the refractive index of the core slightly higher than that of the cladding, without raising attenuation dramatically. In September 1970, they announced they had made single-mode fibers with attenuation at the 633-nanometer helium-neon line below 20\u00a0dB/km.\nCharacteristics.\nUnlike multi-mode optical fiber, single-mode fiber does not exhibit modal dispersion. This is due to the fiber having such a small cross section that only the first mode is transported. Single-mode fibers are therefore better at retaining the fidelity of each light pulse over longer distances than multi-mode fibers. For these reasons, single-mode fibers can have a higher bandwidth than multi-mode fibers. Equipment for single-mode fiber is more expensive than equipment for multi-mode optical fiber, but the single-mode fiber itself is usually cheaper in bulk. \nA typical single-mode optical fiber has a core diameter between 8 and 10.5\u00a0\u03bcm and a cladding diameter of 125\u00a0\u03bcm. There are a number of special types of single-mode optical fiber which have been chemically or physically altered to give special properties, such as dispersion-shifted fiber and nonzero dispersion-shifted fiber. Data rates are limited by polarization mode dispersion and chromatic dispersion. , data rates of up to 10 gigabits per second were possible at distances of over with commercially available transceivers (Xenpak). By using optical amplifiers and dispersion-compensating devices, state-of-the-art DWDM optical systems can span thousands of kilometers at 10 Gbit/s, and several hundred kilometers at 40 Gbit/s.\nThe lowest-order bounds mode is ascertained for the wavelength of interest by solving Maxwell's equations for the boundary conditions imposed by the fiber, which are determined by the core diameter and the refractive indices of the core and cladding. The solution of Maxwell's equations for the lowest order bound mode will permit a pair of orthogonally polarized fields in the fiber, and this is the usual case in a communication fiber.\nIn step-index guides, single-mode operation occurs when the normalized frequency, \"V\", is less than or equal to 2.405. For power-law profiles, single-mode operation occurs for a normalized frequency, \"V\", less than approximately \nformula_1, \nwhere \"g\" is the profile parameter.\nIn practice, the orthogonal polarizations may not be associated with degenerate modes.\nOS1 and OS2 are standard 9/125\u00a0\u03bcm single-mode optical fiber. Both are used with wavelengths 1310\u00a0nm and 1550\u00a0nm. OS1 has a maximum attenuation of 1\u00a0dB/km and OS2 is a maximum of 0.4\u00a0dB/km. OS1 is defined in ISO/IEC 11801, and OS2 is defined in ISO/IEC 24702.\nConnectors.\nOptical fiber connectors are used to join optical fibers where a connect/disconnect capability is required. The basic connector unit is a connector assembly. A connector assembly consists of an adapter and two connector plugs. \nDue to the sophisticated polishing and tuning procedures that may be incorporated into optical connector manufacturing, connectors are generally assembled onto optical fiber in a supplier's manufacturing facility. However, the assembly and\npolishing operations involved can be performed in the field, for example to make cross-connect jumpers to size.\nOptical fiber connectors are used in telephone company central offices, at installations on customer premises, and in outside plant applications. Their uses include:\nOutside plant applications may involve locating connectors underground in subsurface enclosures that may be subject to flooding, on outdoor walls, or on utility poles. The closures that enclose them may be hermetic, or may be \"free-breathing\". Hermetic closures will prevent the connectors within being subjected to temperature swings unless they are breached. Free-breathing enclosures will subject them to temperature and humidity swings, and possibly to condensation and biological action from airborne bacteria, insects, etc. Connectors in the underground plant may be subjected to groundwater immersion if the closures containing them are breached or improperly assembled.\nThe latest industry requirements for optical fiber connectors are in Telcordia http://, \"Generic Requirements for Single-Mode Optical Connectors and Jumper Assemblies\".\nA \"multi-fiber\" optical connector is designed to simultaneously join multiple optical fibers together, with each optical fiber being joined to only one other optical fiber.\nThe last part of the definition is included so as not to confuse multi-fiber connectors with a branching component, such as a coupler. The latter joins one optical fiber to two or more other optical fibers.\nMulti-fiber optical connectors are designed to be used wherever quick and/or repetitive connects and disconnects of a group of fibers are needed. Applications include telecommunications companies' central offices (COs), installations on customer premises, and outside plant (OSP) applications.\nThe multi-fiber optical connector can be used in the creation of a low-cost switch for use in fiber optical testing. Another application is in cables delivered to a user with pre-terminated multi-fiber jumpers. This would reduce the need for field splicing, which could greatly reduce the number of hours necessary for placing an optical fiber cable in a telecommunications network. This, in turn, would result in savings for the installer of such cable.\nIndustry requirements for multi-fiber optical connectors are covered in http://, \"Generic Requirements for Multi-Fiber Optical Connectors\".\nFiber optic switches.\nAn optical switch is a component with two or more ports that selectively transmits, redirects, or blocks an optical signal in a transmission medium. According to Telcordia http://, an optical switch must be actuated to select or change between states. The actuating signal (also referred to as the control signal) is usually electrical, but in principle, could be optical or mechanical. (The control signal format may be Boolean and may be an independent signal; or, in the case of optical actuation, the control signal may be encoded in the input data signal. Switch performance is generally intended to be independent of wavelength within the component passband.)\nQuadruply clad fiber.\nIn fiber optics, a quadruply clad fiber is a single-mode optical fiber that has four claddings. Each cladding has a refractive index lower than that of the core. With respect to one another, their relative refractive indices are, in order of distance from the core: lowest, highest, lower, higher. \nA quadruply clad fiber has the advantage of very low macrobending losses. It also has two zero-dispersion points, and moderately low dispersion over a wider wavelength range than a singly clad fiber or a doubly clad fiber.\nAdvantages.\nLow Attenuation.\nSingle-mode optical fibers exhibit very low signal attenuation, typically around 0.2\u00a0dB/km at 1550\u00a0nm. This allows for signal transmission over distances exceeding 100 kilometers without the need for electrical repeaters, making them suitable for wide-area and submarine networks. \nHigh Bandwidth and Data Rate Capacity.\nThanks to single-path light propagation, single-mode fiber avoids modal dispersion entirely. This allows support for extremely high data rates and advanced technologies like dense wavelength-division multiplexing (DWDM), enabling efficient use of fiber infrastructure.\nLow Dispersion and High Signal Integrity.\nWith a core diameter of approximately 8\u201310\u00a0\u03bcm, light travels in a single mode, minimizing modal distortion. Although chromatic dispersion still occurs, it can be compensated using specialized fiber types or signal processing. The result is a high-fidelity signal over long distances.\nScalability for Future Networks.\nSingle-mode fibers support high transmission frequencies and are compatible with future optical technologies, making them ideal for long-term infrastructure investment. They are standard in backbone, metro, and data center interconnect networks.\nImmunity to Interference and Crosstalk.\nThe confined propagation of light within a single mode improves signal-to-noise ratio and reduces vulnerability to external interference and crosstalk, particularly in dense network environments.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41717", "revid": "42371145", "url": "https://en.wikipedia.org/wiki?curid=41717", "title": "S interface", "text": "Interface reference point\nThe S interface or S reference point, also known as S0, is a user\u2013network interface reference point in an ISDN BRI environment, characterized by a four-wire circuit using 144kbit/s (2 bearer and 1 signaling channel; 2B+D) user rate.\nThe S interface is the connection between ISDN terminal equipment (TE) or terminal adapters (TAs) and an NT1 (network terminator, type 1.) Not all TE or TAs connect externally to an S interface, but instead integrate an NT1 so they can connect directly to a U interface (local loop from central office.)\nContrast to the T interface, which connects between an NT2 (PBX or other local switching device) and NT1. However, the S interface is electrically equivalent to the T interface, and the two are jointly referred to as the S/T interface.\nThe S interface operates at 4000 48-bit frames per second; i.e., 192kbit/s, with a user portion of 36bits per frame; i.e., 144kbit/s.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41718", "revid": "13127810", "url": "https://en.wikipedia.org/wiki?curid=41718", "title": "Skew", "text": "Skew may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41719", "revid": "49070267", "url": "https://en.wikipedia.org/wiki?curid=41719", "title": "Skip zone", "text": "Area where radio transmissions can not be received\nA skip zone, also called a silent zone or zone of silence, is a region where a radio transmission can not be received. The zone is located between regions both closer and farther from the transmitter where reception is possible.\nCause.\nWhen using medium to high-frequency radio telecommunication, there are radio waves which travel both parallel to the ground, and towards the ionosphere, referred to as a ground wave and sky wave, respectively. A skip zone is an annular region between the farthest points at which the ground wave can be received and the nearest point at which the refracted sky waves can be received. Within this region, no signal can be received because, due to the conditions of the local ionosphere, the relevant sky waves are not reflected but penetrate the ionosphere.\nThe skip zone is a natural phenomenon that cannot be influenced by technical means. Its width depends on the height and shape of the ionosphere and, particularly, on the local ionospheric maximum electron density characterized by critical frequency foF2. It varies mainly with this parameter, being larger for low foF2. With a fixed working frequency it is large by night and may even disappear by day. Transmitting at night is most effective for long-distance communication but the skip zone becomes significantly larger. \nVery high frequency waves and higher normally travel through the ionosphere wherefore communication via skywave is exceptional. A highly ionized Es-Layer that occasionally may appear in summer may produce such Sporadic E propagation.\nAvoidance.\nA method of decreasing the skip zone is by decreasing the frequency of the radio waves. Decreasing the frequency is akin to increasing the ionospheric width. A point is eventually reached when decreasing the frequency results in a zero distance skip zone. In other words, a frequency exists for which vertically incident radio waves will always be refracted back to the Earth. This frequency is equivalent to the ionospheric plasma frequency and is also known as the ionospheric critical frequency, or foF2.\nOther.\nSkip zone is the subject of a film 'SKIPZONE' made in 1992 by UK artist, Peter Lee-Jones. It refers to areas in Scottish Highlands where it is difficult to obtain radio and TV reception.\nIn the episode \"Short Wave\" of \"Father Knows Best\", the family hears a distress call from a small boat at sea. Jim explains that the reason they, and not the Coast Guard, can hear the transmission is because of a \"skip\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41720", "revid": "50192435", "url": "https://en.wikipedia.org/wiki?curid=41720", "title": "Slant range", "text": "Distance measure in radar and radio electronics\nIn radio electronics, especially radar terminology, slant range or slant distance is the distance along the relative direction between two points. If the two points are at the same level (relative to a specific datum), the slant distance equals the horizontal distance. \nAn example of slant range is the distance to an aircraft flying at high altitude with respect to that of the radar antenna. The slant range (1) is the hypotenuse of the triangle represented by the altitude of the aircraft and the distance between the radar antenna and the aircraft's ground track (point (3) on the earth directly below the aircraft). In the absence of altitude information, for example from a height finder, the aircraft location would be plotted further (2) from the antenna than its actual ground track."}
{"id": "41721", "revid": "47136065", "url": "https://en.wikipedia.org/wiki?curid=41721", "title": "Slave clock", "text": "Clock that is depent on another clock for its accuracy\nIn telecommunication and horology, a slave clock is a clock that depends on another clock, the master clock. Modern clocks are synchronized through the Internet or by radio time signals, to Coordinated Universal Time. UTC is based on a network of atomic clocks in many countries. For scientific purposes, precision clocks can be synchronized to within nanoseconds by dedicated satellite channels. Slave clock synchronization is usually achieved by phase-locking the slave clock signal to a signal received from the master clock. To adjust for the transit time of the signal from the master clock to the slave clock, the phase of the slave clocks are adjusted so that both clocks are in phase. Thus, the time markers of both clocks, at the output of the clocks, occur simultaneously.\nThe predecessors of atomic clocks, computer clocks, and digital clocks, these electric clocks (or pneumatic clocks) were synchronized by an electrical pulse, wired to their master clock in the same facility. (In the case of pneumatic clocks, pneumatic tubing was used instead of electrical wiring.) Thus the terms \"master\" and \"slave.\" From the late 19th to the mid 20th centuries, electrical master/slave clock systems were installed, all clocks in a building or facility synchronized through electric wires to a central master clock. Slave clocks either kept time by themselves, and were periodically corrected by the master clock, or required impulses from the master clock. Many slave clocks of these types were in operation, most commonly in schools, offices, military bases, hospitals, railway networks, telephone exchanges and factories the world over. School bells of elementary schools, high schools, and others were able to be synchronized across an entire campus, connected to the system. In schools, the master clock was in the principal's office, with slave units in classrooms which were in other buildings on campus. In factories, a system with a bell or horn could signal the end of a shift, lunchtime or break time. Very few relics of this electrical, analogue system operate in the 21st century. Most 21st century systems of the type are digital.\nPictures.\nMechanical slave clocks from the 1950s and 1960s era.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41722", "revid": "10951369", "url": "https://en.wikipedia.org/wiki?curid=41722", "title": "Slave station", "text": "Slave station may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41723", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=41723", "title": "Sliding window", "text": ""}
{"id": "41724", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=41724", "title": "Slip", "text": "Slip or The Slip may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41725", "revid": "1305584561", "url": "https://en.wikipedia.org/wiki?curid=41725", "title": "Spatial application", "text": "A spatial application is a technological application (such as video) requiring high spatial resolution, possibly at the expense of reduced temporal positioning accuracy, such as increased jerkiness. \nExamples of spatial applications include the requirement to display small characters and to resolve fine detail in still video, or in motion video that contains very limited motion."}
{"id": "41727", "revid": "1302642738", "url": "https://en.wikipedia.org/wiki?curid=41727", "title": "Specific detectivity", "text": "Parameter characterizing photodetector performance\nSpecific detectivity, or D*, for a photodetector is a figure of merit used to characterize performance, equal to the reciprocal of noise-equivalent power (NEP), normalized per square root of the sensor's area and frequency bandwidth (reciprocal of twice the integration time).\nSpecific detectivity is given by formula_1, where formula_2 is the area of the photosensitive region of the detector, formula_3 is the bandwidth, and NEP the noise equivalent power [unit: formula_4]. It is commonly expressed in \"Jones\" units (formula_5) in honor of Robert Clark Jones who originally defined it.\nGiven that noise-equivalent power can be expressed as a function of the responsivity formula_6 (in units of formula_7 or formula_8) and the noise spectral density formula_9 (in units of formula_10 or formula_11) as formula_12, it is common to see the specific detectivity expressed as formula_13.\nIt is often useful to express the specific detectivity in terms of relative noise levels present in the device. A common expression is given below.\n formula_14\nWith \"q\" as the electronic charge, formula_15 is the wavelength of interest, \"h\" is the Planck constant, \"c\" is the speed of light, \"k\" is the Boltzmann constant, \"T\" is the temperature of the detector, formula_16 is the zero-bias dynamic resistance area product (often measured experimentally, but also expressible in noise level assumptions), formula_17 is the quantum efficiency of the device, and formula_18 is the total flux of the source (often a blackbody) in photons/sec/cm2.\nDetectivity measurement.\nDetectivity can be measured from a suitable optical setup using known parameters.\nYou will need a known light source with known irradiance at a given standoff distance. The incoming light source will be chopped at a certain frequency, and then each wavelength will be integrated over a given time constant over a given number of frames.\nIn detail, we compute the bandwidth formula_3 directly from the integration time constant formula_20.\n formula_21\nNext, an average signal and rms noise needs to be measured from a set of formula_22 frames. This is done either directly by the instrument, or done as post-processing.\n formula_23\n formula_24\nNow, the computation of the radiance formula_25 in W/sr/cm2 must be computed where cm2 is the emitting area. Next, emitting area must be converted into a projected area and the solid angle; this product is often called the etendue. This step can be obviated by the use of a calibrated source, where the exact number of photons/s/cm2 is known at the detector. If this is unknown, it can be estimated using the black-body radiation equation, detector active area formula_26 and the etendue. This ultimately converts the outgoing radiance of the black body in W/sr/cm2 of emitting area into one of W observed on the detector.\nThe broad-band responsivity, is then just the signal weighted by this wattage.\n formula_27\nwhere\nFrom this metric noise-equivalent power can be computed by taking the noise level over the responsivity.\n formula_33\nSimilarly, noise-equivalent irradiance can be computed using the responsivity in units of photons/s/W instead of in units of the signal.\nNow, the detectivity is simply the noise-equivalent power normalized to the bandwidth and detector area.\n formula_34\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41728", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=41728", "title": "Speckle pattern", "text": ""}
{"id": "41729", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41729", "title": "Spectral width", "text": "Measurement in communication theory\nIn telecommunications, spectral width is the width of a spectral band, i.e., the range of wavelengths or frequencies over which the magnitude of all spectral components is significant, i.e., equal to or greater than a specified fraction of the largest magnitude.\nIn fiber-optic communication applications, the usual method of specifying spectral width is the \"full width at half maximum\" (FWHM). This is the same convention used in bandwidth, defined as the frequency range where power drops by less than half (at most \u22123 dB).\nThe FWHM method may be difficult to apply when the spectrum has a complex shape. Another method of specifying spectral width is a special case of root-mean-square deviation where the independent variable is wavelength, \u03bb, and \"f\" (\u03bb) is a suitable radiometric quantity.\nThe \"relative spectral width\", \u0394\u03bb/\u03bb, is frequently used where \u0394\u03bb is obtained according to note 1, and \u03bb is the center wavelength."}
{"id": "41730", "revid": "31541467", "url": "https://en.wikipedia.org/wiki?curid=41730", "title": "Speed of service", "text": "In telecommunication, speed of service is the time for a message to be received. For example:"}
{"id": "41732", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41732", "title": "Spill-forward feature", "text": "In telecommunications, a spill-forward feature is a service feature, in the operation of an intermediate office, that, acting on incoming trunk service treatment indications, assumes routing control of the call from the originating office. This increases the chances of completion by offering the call to more trunk groups than are available in the originating office.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41733", "revid": "173504", "url": "https://en.wikipedia.org/wiki?curid=41733", "title": "Sporadic E", "text": ""}
{"id": "41734", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41734", "title": "Spread spectrum", "text": "Spreading the frequency domain of a signal\nIn telecommunications, especially radio communication, spread spectrum are techniques by which a signal (e.g., an electrical, electromagnetic, or acoustic) generated with a particular bandwidth is deliberately spread in the frequency domain over a wider frequency band. Spread-spectrum techniques are used for the establishment of secure communications, increasing resistance to natural interference, noise, and jamming, to prevent detection, to limit power flux density (e.g., in satellite downlinks), and to enable multiple-access communications.\nTelecommunications.\nSpread spectrum generally makes use of a sequential noise-like signal structure to spread the normally narrowband information signal over a relatively wideband (radio) band of frequencies. The receiver correlates the received signals to retrieve the original information signal. Originally there were two motivations: either to resist enemy efforts to jam the communications (anti-jam, or AJ), or to hide the fact that communication was even taking place, sometimes called low probability of intercept (LPI).\nFrequency-hopping spread spectrum (FHSS), direct-sequence spread spectrum (DSSS), time-hopping spread spectrum (THSS), chirp spread spectrum (CSS), and combinations of these techniques are forms of spread spectrum. The first two of these techniques employ pseudorandom number sequences\u2014created using pseudorandom number generators\u2014to determine and control the spreading pattern of the signal across the allocated bandwidth. Wireless standard IEEE 802.11 uses either FHSS or DSSS in its radio interface.\nInvention of frequency hopping.\nThe idea of trying to protect and avoid interference in radio transmissions dates back to the beginning of radio wave signaling. In 1899, Guglielmo Marconi experimented with frequency-selective reception in an attempt to minimize interference. The concept of Frequency-hopping was adopted by the German radio company Telefunken and also described in part of a 1903 US patent by Nikola Tesla. Radio pioneer Jonathan Zenneck's 1908 German book \"Wireless Telegraphy\" describes the process and notes that Telefunken was using it previously. It saw limited use by the German military in World War I, was put forward by Polish engineer Leonard Danilewicz in 1929, showed up in a patent in the 1930s by Willem Broertjes (https:// issued Aug. 2, 1932), and in the top-secret US Army Signal Corps World War II communications system named SIGSALY.\nDuring World War II, Golden Age of Hollywood actress Hedy Lamarr and avant-garde composer George Antheil developed an intended jamming-resistant radio guidance system for use in Allied torpedoes, patenting the device under https:// \"Secret Communications System\" on August 11, 1942. Their approach was unique in that frequency coordination was done with paper player piano rolls, a novel approach which was never put into practice.\nClock signal generation.\nSpread-spectrum clock generation (SSCG) is used in some synchronous digital systems, especially those containing microprocessors, to reduce the spectral density of the electromagnetic interference (EMI) that these systems generate. A synchronous digital system is one that is driven by a clock signal and, because of its periodic nature, has an unavoidably narrow frequency spectrum. In fact, a perfect clock signal would have all its energy concentrated at a single frequency (the desired clock frequency) and its harmonics.\nBackground.\nPractical synchronous digital systems radiate electromagnetic energy on a number of narrow bands spread on the clock frequency and its harmonics, resulting in a frequency spectrum that, at certain frequencies, can exceed the regulatory limits for electromagnetic interference (e.g. those of the FCC in the United States, JEITA in Japan and the IEC in Europe).\nSpread-spectrum clocking avoids this problem by reducing the peak radiated energy and, therefore, its electromagnetic emissions and so comply with electromagnetic compatibility (EMC) regulations. It has become a popular technique to gain regulatory approval because it requires only simple equipment modification. It is even more popular in portable electronics devices because of faster clock speeds and increasing integration of high-resolution LCD displays into ever smaller devices. As these devices are designed to be lightweight and inexpensive, traditional passive, electronic measures to reduce EMI, such as capacitors or metal shielding, are not viable. Active EMI reduction techniques such as spread-spectrum clocking are needed in these cases.\nMethod.\nIn PCIe, USB 3.0, and SATA systems, the most common technique is downspreading, via frequency modulation with a lower-frequency source. Spread-spectrum clocking, like other kinds of dynamic frequency change, can also create challenges for designers. Principal among these is clock/data misalignment, or clock skew. A phase-locked loop on the receiving side needs a high enough bandwidth to correctly track a spread-spectrum clock.\nEven though SSC compatibility is mandatory on SATA receivers, it is not uncommon to find expander chips having problems dealing with such a clock. Consequently, an ability to disable spread-spectrum clocking in computer systems is considered useful.\nEffect.\nNote that this method does not reduce total radiated energy, and therefore systems are not necessarily less likely to cause interference. Spreading energy over a larger bandwidth effectively reduces electrical and magnetic readings within narrow bandwidths. Typical measuring receivers used by EMC testing laboratories divide the electromagnetic spectrum into frequency bands approximately 120\u00a0kHz wide. If the system under test were to radiate all its energy in a narrow bandwidth, it would register a large peak. Distributing this same energy into a larger bandwidth prevents systems from putting enough energy into any one narrowband to exceed the statutory limits. The usefulness of this method as a means to reduce real-life interference problems is often debated, as it is perceived that spread-spectrum clocking hides rather than resolves higher radiated energy issues by simple exploitation of loopholes in EMC legislation or certification procedures. This situation results in electronic equipment sensitive to narrow bandwidth(s) experiencing much less interference, while those with broadband sensitivity, or even operated at other higher frequencies (such as a radio receiver tuned to a different station), will experience more interference.\nFCC certification testing is often completed with the spread-spectrum function enabled in order to reduce the measured emissions to within acceptable legal limits. However, the spread-spectrum functionality may be disabled by the user in some cases. As an example, in the area of personal computers, some BIOS writers include the ability to disable spread-spectrum clock generation as a user setting, thereby defeating the object of the EMI regulations. This might be considered a loophole, but is generally overlooked as long as spread-spectrum is enabled by default.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41735", "revid": "46866511", "url": "https://en.wikipedia.org/wiki?curid=41735", "title": "Squelch", "text": "Type of noise gate\nIn telecommunications, squelch is a circuit function that acts to suppress the audio (or video) output of a receiver in the absence of a strong input signal. Essentially, squelch is a specialized type of noise gate designed to suppress weak signals. Squelch is used in two-way radios and VHF/UHF radio scanners to eliminate the sound of noise when the radio is not receiving a desired transmission.\nSquelch.\nIn some designs, the squelch threshold is preset. For example, television squelch settings are usually preset. Receivers in base stations, or repeaters at remote mountain top sites, are usually not adjustable remotely from the control point.\nIn two-way radios (also known as radiotelephones), the received signal level required to unsquelch (un-mute) the receiver may be fixed or adjustable with a knob or a sequence of button presses. Typically the operator will adjust the control until noise is heard, and then adjust in the opposite direction until the noise is squelched. At this point, a weak signal will unsquelch the receiver and be heard by the operator. Further adjustment will increase the level of signal required to unsquelch the receiver. Some applications have the receiver tied to other equipment that uses the audio muting control voltage, as a \"signal present\" indication; for example, in a repeater the act of the receiver unmuting will switch on the transmitter. Squelch can be \"opened\" (turned off), which allows all signals to be heard, including radio frequency noise on the receiving frequency. This can be useful when trying to hear distant or otherwise weak signals, for example in DXing.\nCarrier squelch is the most simple variant of all. It functions strictly on the signal strength, such as when a television mutes the audio or blanks the video on \"empty\" channels, or when a walkie-talkie mutes the audio when no signal is present. Carrier squelch uses receiver Automatic gain control (AGC) to determine the squelch threshold. Single-sideband modulation (SSB) typically uses carrier squelch.\nNoise squelch is more reliable than carrier squelch. A noise squelch circuit is noise-operated and can be used in AM or FM receivers, and relies on the receiver quieting in the presence of an AM or FM carrier. To minimize the effects of voice audio on squelch operation, the audio from the receiver's detector is passed through a high-pass filter, typically passing 4,000\u00a0Hz (4kHz) and above, leaving only high frequency noise. The squelch control adjusts the gain of an amplifier which varies the level of the noise coming out of the filter. \nThis noise is rectified, producing a DC voltage when noise is present. The presence of continuous noise on an idle channel creates a DC voltage which turns the receiver audio off. When a signal with little or no noise is received, the noise-derived voltage is reduced and the receiver audio is unmuted.\nNoise squelch can be defeated by intermodulation present in the high-pass band. For this reason, many receivers with noise squelch will also use a carrier squelch set at a higher threshold than the noise squelch.\nTone squelch and selective calling.\nTone squelch, or another form of selective calling, is sometimes used to solve interference problems. Where more than one user is on the same channel (\"co-channel\" users), selective calling addresses a subset of all receivers. Instead of turning on the receiver audio for any signal, the audio turns on only in the presence of the correct selective calling code. This is akin to the use of a lock on a door. A carrier squelch is unlocked and will let any signal in. Selective calling locks out all signals except ones with the correct key to the lock (the correct code).\nIn non-critical uses, selective calling can also be used to hide the presence of interfering signals such as receiver-produced intermodulation. Receivers with poor specifications\u2014such as inexpensive police scanners or low-cost mobile radios\u2014cannot reject the strong signals present in urban environments. The interference will still be present, and will still degrade system performance, but by using selective calling the user will not have to hear the noises produced by receiving the interference.\nFour different techniques are commonly used. Selective calling can be regarded as a form of in-band signaling.\nCTCSS.\nCTCSS (Continuous Tone-Coded Squelch System) continuously superimposes any one of about 50 low-pitch audio tones on the transmitted signal, ranging from 67 to 254 Hz. The original tone set was 10, then 32 tones, and has been expanded even further over the years. CTCSS is often called \"PL tone\" (for \"Private Line\", a trademark of Motorola), or simply \"tone squelch\". General Electric's implementation of CTCSS is called \"Channel Guard\" (or \"CG\"). RCA Corporation used the name \"Quiet Channel\", or \"QC\". There are many other company-specific names used by radio vendors to describe compatible options. Any CTCSS system that has compatible tones is interchangeable. Old and new radios with CTCSS and radios across manufacturers are compatible. For those PMR446 radios with 38 codes, the codes 0 to 38 are CTCSS Tones:\nSelCall.\nSelcall (Selective Calling) transmits a burst of up to five in-band audio tones at the beginning of each transmission. This feature (sometimes called \"tone burst\") is common in European systems. Early systems used one tone (commonly called \"Tone Burst\"). Several tones were used, the most common being 1,750\u00a0Hz, which is still used in European amateur radio repeater systems. The addressing scheme provided by one tone was not enough, so a two-tone system was devised\u2014one tone followed by a second tone (sometimes called a \"1+1\" system). Motorola later marketed a system called \"Quik-Call\" that used two simultaneous tones followed by two more simultaneous tones (sometimes called a \"2+2\" system) that was heavily used by fire department dispatch systems in the US. Later selective call systems used paging system technology that made use of a burst of five sequential tones.\nDCS.\nDCS (Digital-Coded Squelch), generically known as \"CDCSS\" (Continuous Digital-Coded Squelch System), was designed as the digital replacement for CTCSS. In the same way that a single CTCSS tone would be used on an entire group of radios, the same DCS code is used in a group of radios. DCS is also referred to as \"Digital Private Line\" (or \"DPL\"), another trademark of Motorola, and likewise, General Electric's implementation of DCS is referred to as \"Digital Channel Guard\" (or \"DCG\"). Despite the fact that it is not a tone, DCS is also called \"DTCS\" (Digital Tone Code Squelch) by Icom, and other names by other manufacturers. Radios with DCS options are generally compatible, provided the radio's encoder-decoder will use the same code as radios in the existing system.\nDCS adds a 134.4\u00a0bit/s (sub-audible) bitstream to the transmitted audio. The code word is a 23-bit Golay (23,12) code which has the ability to detect and correct errors of 3 or fewer bits. The word consists of 12 data bits followed by 11 check bits. The last 3 data bits are a fixed '001', this leaves 9 code bits (512 possibilities) which are conventionally represented as a 3-digit octal number. Note that the first bit transmitted is the LSB, so the code is \"backwards\" from the transmitted bit order. Only 83 of the 512 possible codes are available, to prevent falsing due to alignment collisions.\nDCS codes are standardized by the Telecommunications Industry Association with the following 83 codes being found in their most recent standard, however, some systems use non-standard codes. For those PMR446 radios with 121 codes, the codes 39 to 121 are DCS codes:\nXTCSS.\nXTCSS is the newest signalling technique, and provides 99 codes with the added advantage of \"silent operation\". XTCSS-fitted radios are purposed to enjoy more privacy and flexibility of operation. XTCSS is implemented as a combination of CTCSS and in-band signalling.\nUses.\nSquelch was invented first and is still in wide use in two-way radio. Squelch of any kind is used to indicate loss of signal, which is used to keep commercial and amateur radio repeaters from continually transmitting. Since a carrier squelch receiver cannot tell a valid carrier from a spurious signal (noise, etc.), CTCSS is often used as well, as it avoids false keyups. Use of CTCSS is especially helpful on congested frequencies or on frequency bands prone to skip and during band openings.\nProfessional wireless microphones use squelch to avoid reproducing noise when the receiver does not receive enough signal from the microphone. Most professional models have adjustable squelch, usually set with a screwdriver adjustment or front-panel control on the receiver.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41737", "revid": "31335090", "url": "https://en.wikipedia.org/wiki?curid=41737", "title": "Standard test signal", "text": "Single-frequency signal used for telecommunications testing\nIn telecommunications, a standard test signal is a single-frequency signal with standardized level used for testing the peak power transmission capability and for measuring the total harmonic distortion of circuits or parts of an electric circuit. \nStandardized test signal levels and frequencies are listed in MIL-STD-188-100 and in the Code of Federal Regulations Title 47, part 68."}
{"id": "41738", "revid": "101696", "url": "https://en.wikipedia.org/wiki?curid=41738", "title": "Standard test tone", "text": ""}
{"id": "41739", "revid": "689223", "url": "https://en.wikipedia.org/wiki?curid=41739", "title": "Standard time and frequency signal", "text": ""}
{"id": "41740", "revid": "684386", "url": "https://en.wikipedia.org/wiki?curid=41740", "title": "Standby", "text": "Standby may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41741", "revid": "50498524", "url": "https://en.wikipedia.org/wiki?curid=41741", "title": "Standing wave", "text": "Wave that remains in a constant position\nIn physics, a standing wave, also known as a stationary wave, is a wave that oscillates in time but whose peak amplitude profile does not move in space. The peak amplitude of the wave oscillations at any point in space is constant with respect to time, and the oscillations at different points throughout the wave are in phase. The locations at which the absolute value of the amplitude is minimum are called nodes, and the locations where the absolute value of the amplitude is maximum are called antinodes.\nStanding waves were first described scientifically by Michael Faraday in 1831. Faraday observed standing waves on the surface of a liquid in a vibrating container. Franz Melde coined the term \"standing wave\" (German: \"stehende Welle\" or \"Stehwelle\") around 1860 and demonstrated the phenomenon in his classic experiment with vibrating strings.\nThis phenomenon can occur because the medium is moving in the direction opposite to the movement of the wave, or it can arise in a stationary medium as a result of interference between two waves traveling in opposite directions. The most common cause of standing waves is the phenomenon of resonance, in which standing waves occur inside a resonator due to interference between waves reflected back and forth at the resonator's resonant frequency.\nFor waves of equal amplitude traveling in opposing directions, there is on average no net propagation of energy.\nMoving medium.\nAs an example of the first type, under certain meteorological conditions standing waves form in the atmosphere in the lee of mountain ranges. Such waves are often exploited by glider pilots.\nStanding waves and hydraulic jumps also form on fast flowing river rapids and tidal currents such as the Saltstraumen maelstrom. A requirement for this in river currents is a flowing water with shallow depth in which the inertia of the water overcomes its gravity due to the supercritical flow speed (Froude number: 1.7 \u2013 4.5, surpassing 4.5 results in direct standing wave) and is therefore neither significantly slowed down by the obstacle nor pushed to the side. Many standing river waves are popular river surfing breaks.\nOpposing waves.\nAs an example of the second type, a \"standing wave\" in a transmission line is a wave in which the distribution of current, voltage, or field strength is formed by the superposition of two waves of the same frequency propagating in opposite directions. The effect is a series of nodes (zero displacement) and anti-nodes (maximum displacement) at fixed points along the transmission line. Such a standing wave may be formed when a wave is transmitted into one end of a transmission line and is reflected from the other end by an impedance mismatch, \"i.e.\", discontinuity, such as an open circuit or a short. The failure of the line to transfer power at the standing wave frequency will usually result in attenuation distortion.\nIn practice, losses in the transmission line and other components mean that a perfect reflection and a pure standing wave are never achieved. The result is a \"partial standing wave\", which is a superposition of a standing wave and a traveling wave. The degree to which the wave resembles either a pure standing wave or a pure traveling wave is measured by the standing wave ratio (SWR).\nAnother example is standing waves in the open ocean formed by waves with the same wave period moving in opposite directions. These may form near storm centres, or from reflection of a swell at the shore, and are the source of microbaroms and microseisms.\nMathematical description.\nThis section considers representative one- and two-dimensional cases of standing waves. First, an example of an infinite length string shows how identical waves traveling in opposite directions interfere to produce standing waves. Next, two finite length string examples with different boundary conditions demonstrate how the boundary conditions restrict the frequencies that can form standing waves. Next, the example of sound waves in a pipe demonstrates how the same principles can be applied to longitudinal waves with analogous boundary conditions.\nStanding waves can also occur in two- or three-dimensional resonators. With standing waves on two-dimensional membranes such as drumheads, illustrated in the animations above, the nodes become nodal lines, lines on the surface at which there is no movement, that separate regions vibrating with opposite phase. These nodal line patterns are called Chladni figures. In three-dimensional resonators, such as musical instrument sound boxes and microwave cavity resonators, there are nodal surfaces. This section includes a two-dimensional standing wave example with a rectangular boundary to illustrate how to extend the concept to higher dimensions.\nStanding wave on an infinite length string.\nTo begin, consider a string of infinite length along the \"x\"-axis that is free to be stretched transversely in the \"y\" direction.\nFor a harmonic wave traveling to the right along the string, the string's displacement in the \"y\" direction as a function of position \"x\" and time \"t\" is\nformula_1\nThe displacement in the \"y\"-direction for an identical harmonic wave traveling to the left is\nformula_2\nwhere\nFor identical right- and left-traveling waves on the same string, the total displacement of the string is the sum of \"y\"R and \"y\"L,\nformula_3\nUsing the trigonometric sum-to-product identity formula_4,\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nEquation (1) does not describe a traveling wave. At any position \"x\", \"y\"(\"x\",\"t\") simply oscillates in time with an amplitude that varies in the \"x\"-direction as formula_5. The animation at the beginning of this article depicts what is happening. As the left-traveling blue wave and right-traveling green wave interfere, they form the standing red wave that does not travel and instead oscillates in place.\nBecause the string is of infinite length, it has no boundary condition for its displacement at any point along the \"x\"-axis. As a result, a standing wave can form at any frequency.\nAt locations on the \"x\"-axis that are \"even\" multiples of a quarter wavelength,\nformula_6\nthe amplitude is always zero. These locations are called nodes. At locations on the \"x\"-axis that are \"odd\" multiples of a quarter wavelength\nformula_7\nthe amplitude is maximal, with a value of twice the amplitude of the right- and left-traveling waves that interfere to produce this standing wave pattern. These locations are called anti-nodes. The distance between two consecutive nodes or anti-nodes is half the wavelength, \"\u03bb\"/2.\nStanding wave on a string with two fixed ends.\nNext, consider a string with fixed ends at \"x\" \n 0 and \"x\" \n \"L\". The string will have some damping as it is stretched by traveling waves, but assume the damping is very small. Suppose that at the \"x\" \n 0 fixed end a sinusoidal force is applied that drives the string up and down in the y-direction with a small amplitude at some frequency \"f\". In this situation, the driving force produces a right-traveling wave. That wave reflects off the right fixed end and travels back to the left, reflects again off the left fixed end and travels back to the right, and so on. Eventually, a steady state is reached where the string has identical right- and left-traveling waves as in the infinite-length case and the power dissipated by damping in the string equals the power supplied by the driving force so the waves have constant amplitude.\nEquation (1) still describes the standing wave pattern that can form on this string, but now Equation (1) is subject to boundary conditions where \"y\" \n 0 at \"x\" \n 0 and \"x\" \n \"L\" because the string is fixed at \"x\" \n \"L\" and because we assume the driving force at the fixed \"x\" \n 0 end has small amplitude. Checking the values of \"y\" at the two ends,\nformula_8\nformula_9\nThis boundary condition is in the form of the Sturm\u2013Liouville formulation. The latter boundary condition is satisfied when formula_10. \"L\" is given, so the boundary condition restricts the wavelength of the standing waves to\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nformula_11\nWaves can only form standing waves on this string if they have a wavelength that satisfies this relationship with \"L\". If waves travel with speed \"v\" along the string, then equivalently the frequency of the standing waves is restricted to\nformula_12\nThe standing wave with \"n\" \n 1 oscillates at the fundamental frequency and has a wavelength that is twice the length of the string. Higher integer values of \"n\" correspond to modes of oscillation called harmonics or overtones. Any standing wave on the string will have \"n\" + 1 nodes including the fixed ends and \"n\" anti-nodes.\nTo compare this example's nodes to the description of nodes for standing waves in the infinite length string, Equation (2) can be rewritten as\nformula_13\nformula_14\nIn this variation of the expression for the wavelength, \"n\" must be even. Cross multiplying we see that because \"L\" is a node, it is an \"even\" multiple of a quarter wavelength,\nformula_15\nformula_14\nThis example demonstrates a type of resonance and the frequencies that produce standing waves can be referred to as \"resonant frequencies\".\nStanding wave on a string with one fixed end.\nNext, consider the same string of length \"L\", but this time it is only fixed at \"x\" \n 0. At \"x\" \n \"L\", the string is free to move in the \"y\" direction. For example, the string might be tied at \"x\" \n \"L\" to a ring that can slide freely up and down a pole. The string again has small damping and is driven by a small driving force at \"x\" \n 0.\nIn this case, Equation (1) still describes the standing wave pattern that can form on the string, and the string has the same boundary condition of \"y\" \n 0 at \"x\" \n 0. However, at \"x\" \n \"L\" where the string can move freely there should be an anti-node with maximal amplitude of \"y\". Equivalently, this boundary condition of the \"free end\" can be stated as \"\u2202y/\u2202x\" \n 0 at \"x\" \n \"L\", which is in the form of the Sturm\u2013Liouville formulation. The intuition for this boundary condition \"\u2202y/\u2202x\" \n 0 at \"x\" \n \"L\" is that the motion of the \"free end\" will follow that of the point to its left.\nReviewing Equation (1), for \"x\" \n \"L\" the largest amplitude of \"y\" occurs when \"\u2202y/\u2202x\" \n 0, or\nformula_17\nThis leads to a different set of wavelengths than in the two-fixed-ends example. Here, the wavelength of the standing waves is restricted to\nformula_13\nformula_19\nEquivalently, the frequency is restricted to\nformula_20\nIn this example \"n\" only takes odd values. Because \"L\" is an anti-node, it is an \"odd\" multiple of a quarter wavelength. Thus the fundamental mode in this example only has one quarter of a complete sine cycle\u2013zero at \"x\" \n 0 and the first peak at \"x\" \n \"L\"\u2013the first harmonic has three quarters of a complete sine cycle, and so on.\nThis example also demonstrates a type of resonance and the frequencies that produce standing waves are called \"resonant frequencies\".\nStanding wave in a pipe.\nConsider a standing wave in a pipe of length \"L\". The air inside the pipe serves as the medium for longitudinal sound waves traveling to the right or left through the pipe. While the transverse waves on the string from the previous examples vary in their displacement perpendicular to the direction of wave motion, the waves traveling through the air in the pipe vary in terms of their pressure and longitudinal displacement along the direction of wave motion. The wave propagates by alternately compressing and expanding air in segments of the pipe, which displaces the air slightly from its rest position and transfers energy to neighboring segments through the forces exerted by the alternating high and low air pressures. Equations resembling those for the wave on a string can be written for the change in pressure \u0394\"p\" due to a right- or left-traveling wave in the pipe.\nformula_21\nformula_22\nwhere\nIf identical right- and left-traveling waves travel through the pipe, the resulting superposition is described by the sum\nformula_23\nThis formula for the pressure is of the same form as Equation (1), so a stationary pressure wave forms that is fixed in space and oscillates in time.\nIf the end of a pipe is closed, the pressure is maximal since the closed end of the pipe exerts a force that restricts the movement of air. This corresponds to a pressure anti-node (which is a node for molecular motions, because the molecules near the closed end cannot move). If the end of the pipe is open, the pressure variations are very small, corresponding to a pressure node (which is an anti-node for molecular motions, because the molecules near the open end can move freely). The exact location of the pressure node at an open end is actually slightly beyond the open end of the pipe, so the effective length of the pipe for the purpose of determining resonant frequencies is slightly longer than its physical length. This difference in length is ignored in this example. In terms of reflections, open ends partially reflect waves back into the pipe, allowing some energy to be released into the outside air. Ideally, closed ends reflect the entire wave back in the other direction.\nFirst consider a pipe that is open at both ends, for example an open organ pipe or a recorder. Given that the pressure must be zero at both open ends, the boundary conditions are analogous to the string with two fixed ends,\nformula_24\nformula_25\nwhich only occurs when the wavelength of standing waves is\nformula_26\nformula_27\nor equivalently when the frequency is\nformula_28\nwhere \"v\" is the speed of sound.\nNext, consider a pipe that is open at \"x\" \n 0 (and therefore has a pressure node) and closed at \"x\" \n \"L\" (and therefore has a pressure anti-node). The closed \"free end\" boundary condition for the pressure at \"x\" \n \"L\" can be stated as \"\u2202(\u0394p)/\u2202x\" \n 0, which is in the form of the Sturm\u2013Liouville formulation. The intuition for this boundary condition \"\u2202(\u0394p)/\u2202x\" \n 0 at \"x\" \n \"L\" is that the pressure of the closed end will follow that of the point to its left. Examples of this setup include a bottle and a clarinet. This pipe has boundary conditions analogous to the string with only one fixed end. Its standing waves have wavelengths restricted to\nformula_13\nformula_30\nor equivalently the frequency of standing waves is restricted to\nformula_31\nFor the case where one end is closed, \"n\" only takes odd values just like in the case of the string fixed at only one end.\nSo far, the wave has been written in terms of its pressure as a function of position \"x\" and time. Alternatively, the wave can be written in terms of its longitudinal displacement of air, where air in a segment of the pipe moves back and forth slightly in the \"x\"-direction as the pressure varies and waves travel in either or both directions. The change in pressure \u0394\"p\" and longitudinal displacement \"s\" are related as\nformula_32\nwhere \"\u03c1\" is the density of the air. In terms of longitudinal displacement, closed ends of pipes correspond to nodes since air movement is restricted and open ends correspond to anti-nodes since the air is free to move. A similar, easier to visualize phenomenon occurs in longitudinal waves propagating along a spring.\nWe can also consider a pipe that is closed at both ends. In this case, both ends will be pressure anti-nodes or equivalently both ends will be displacement nodes. This example is analogous to the case where both ends are open, except the standing wave pattern has a &lt;templatestyles src=\"Fraction/styles.css\" /&gt;\u03c0\u20442 phase shift along the \"x\"-direction to shift the location of the nodes and anti-nodes. For example, the longest wavelength that resonates\u2013the fundamental mode\u2013is again twice the length of the pipe, except that the ends of the pipe have pressure anti-nodes instead of pressure nodes. Between the ends there is one pressure node. In the case of two closed ends, the wavelength is again restricted to\nformula_26\nformula_27\nand the frequency is again restricted to\nformula_35\nA Rubens tube provides a way to visualize the pressure variations of the standing waves in a tube with two closed ends.\n2D standing wave with a rectangular boundary.\nNext, consider transverse waves that can move along a two dimensional surface within a rectangular boundary of length \"Lx\" in the \"x\"-direction and length \"Ly\" in the \"y\"-direction. Examples of this type of wave are water waves in a pool or waves on a rectangular sheet that has been pulled taut. The waves displace the surface in the \"z\"-direction, with \"z\" \n 0 defined as the height of the surface when it is still.\nIn two dimensions and Cartesian coordinates, the wave equation is\nformula_36\nwhere\nTo solve this differential equation, let's first solve for its Fourier transform, with\nformula_37\nTaking the Fourier transform of the wave equation,\nformula_38\nThis is an eigenvalue problem where the frequencies correspond to eigenvalues that then correspond to frequency-specific modes or eigenfunctions. Specifically, this is a form of the Helmholtz equation and it can be solved using separation of variables. Assume\nformula_39\nDividing the Helmholtz equation by \"Z\",\nformula_40\nThis leads to two coupled ordinary differential equations. The \"x\" term equals a constant with respect to \"x\" that we can define as\nformula_41\nSolving for \"X\"(\"x\"),\nformula_42\nThis \"x\"-dependence is sinusoidal\u2013recalling Euler's formula\u2013with constants \"A\"\"k\"\"x\" and \"B\"\"k\"\"x\" determined by the boundary conditions. Likewise, the \"y\" term equals a constant with respect to \"y\" that we can define as\nformula_43\nand the dispersion relation for this wave is therefore\nformula_44\nSolving the differential equation for the \"y\" term,\nformula_45\nMultiplying these functions together and applying the inverse Fourier transform, \"z\"(\"x\",\"y\",\"t\") is a superposition of modes where each mode is the product of sinusoidal functions for \"x\", \"y\", and \"t\",\nformula_46\nThe constants that determine the exact sinusoidal functions depend on the boundary conditions and initial conditions. To see how the boundary conditions apply, consider an example like the sheet that has been pulled taut where \"z\"(\"x\",\"y\",\"t\") must be zero all around the rectangular boundary. For the \"x\" dependence, \"z\"(\"x\",\"y\",\"t\") must vary in a way that it can be zero at both \"x\" \n 0 and \"x\" \n \"L\"\"x\" for all values of \"y\" and \"t\". As in the one dimensional example of the string fixed at both ends, the sinusoidal function that satisfies this boundary condition is\nformula_47\nwith \"k\"\"x\" restricted to\nformula_48\nLikewise, the \"y\" dependence of \"z\"(\"x\",\"y\",\"t\") must be zero at both \"y\" \n 0 and \"y\" \n \"L\"\"y\", which is satisfied by\nformula_49\nRestricting the wave numbers to these values also restricts the frequencies that resonate to\nformula_50\nIf the initial conditions for \"z\"(\"x\",\"y\",0) and its time derivative \"\u017c\"(\"x\",\"y\",0) are chosen so the \"t\"-dependence is a cosine function, then standing waves for this system take the form\nformula_51\nformula_52\nSo, standing waves inside this fixed rectangular boundary oscillate in time at certain resonant frequencies parameterized by the integers \"n\" and \"m\". As they oscillate in time, they do not travel and their spatial variation is sinusoidal in both the \"x\"- and \"y\"-directions such that they satisfy the boundary conditions. The fundamental mode, \"n\" \n 1 and \"m\" \n 1, has a single antinode in the middle of the rectangle. Varying \"n\" and \"m\" gives complicated but predictable two-dimensional patterns of nodes and antinodes inside the rectangle.\nFrom the dispersion relation, in certain situations different modes\u2013meaning different combinations of \"n\" and \"m\"\u2013may resonate at the same frequency even though they have different shapes for their \"x\"- and \"y\"-dependence. For example, if the boundary is square, \"L\"\"x\" \n \"L\"\"y\", the modes \"n\" \n 1 and \"m\" \n 7, \"n\" \n 7 and \"m\" \n 1, and \"n\" \n 5 and \"m\" \n 5 all resonate at\nformula_53\nRecalling that \"\u03c9\" determines the eigenvalue in the Helmholtz equation above, the number of modes corresponding to each frequency relates to the frequency's multiplicity as an eigenvalue.\nStanding wave ratio, phase, and energy transfer.\nIf the two oppositely moving traveling waves are not of the same amplitude, they will not cancel completely at the nodes, the points where the waves are 180\u00b0 out of phase, so the amplitude of the standing wave will not be zero at the nodes, but merely a minimum. Standing wave ratio (SWR) is the ratio of the amplitude at the antinode (maximum) to the amplitude at the node (minimum). A pure standing wave will have an infinite SWR. It will also have a constant phase at any point in space (but it may undergo a 180\u00b0 inversion every half cycle). A finite, non-zero SWR indicates a wave that is partially stationary and partially travelling. Such waves can be decomposed into a superposition of two waves: a travelling wave component and a stationary wave component. An SWR of one indicates that the wave does not have a stationary component \u2013 it is purely a travelling wave, since the ratio of amplitudes is equal to 1.\nA pure standing wave does not transfer energy from the source to the destination. However, the wave is still subject to losses in the medium. Such losses will manifest as a finite SWR, indicating a travelling wave component leaving the source to supply the losses. Even though the SWR is now finite, it may still be the case that no energy reaches the destination because the travelling component is purely supplying the losses. However, in a lossless medium, a finite SWR implies a definite transfer of energy to the destination.\nExamples.\nOne easy example to understand standing waves is two people shaking either end of a jump rope. If they shake in sync the rope can form a regular pattern of waves oscillating up and down, with stationary points along the rope where the rope is almost still (nodes) and points where the arc of the rope is maximum (antinodes).\nAcoustic resonance.\nStanding waves are also observed in physical media such as strings and columns of air. Any waves traveling along the medium will reflect back when they reach the end. This effect is most noticeable in musical instruments where, at various multiples of a vibrating string or air column's natural frequency, a standing wave is created, allowing harmonics to be identified. Nodes occur at fixed ends and anti-nodes at open ends. If fixed at only one end, only odd-numbered harmonics are available. At the open end of a pipe the anti-node will not be exactly at the end as it is altered by its contact with the air and so end correction is used to place it exactly. The density of a string will affect the frequency at which harmonics will be produced; the greater the density the lower the frequency needs to be to produce a standing wave of the same harmonic.\nVisible light.\nStanding waves are also observed in optical media such as optical waveguides and optical cavities. Lasers use optical cavities in the form of a pair of facing mirrors, which constitute a Fabry\u2013P\u00e9rot interferometer. The gain medium in the cavity (such as a crystal) emits light coherently, exciting standing waves of light in the cavity. The wavelength of light is very short (in the range of nanometers, 10\u22129 m) so the standing waves are microscopic in size. One use for standing light waves is to measure small distances, using optical flats.\nX-rays.\nInterference between X-ray beams can form an X-ray standing wave (XSW) field. Because of the short wavelength of X-rays (less than 1 nanometer), this phenomenon can be exploited for measuring atomic-scale events at material surfaces. The XSW is generated in the region where an X-ray beam interferes with a diffracted beam from a nearly perfect single crystal surface or a reflection from an X-ray mirror. By tuning the crystal geometry or X-ray wavelength, the XSW can be translated in space, causing a shift in the X-ray fluorescence or photoelectron yield from the atoms near the surface. This shift can be analyzed to pinpoint the location of a particular atomic species relative to the underlying crystal structure or mirror surface. The XSW method has been used to clarify the atomic-scale details of dopants in semiconductors, atomic and molecular adsorption on surfaces, and chemical transformations involved in catalysis.\nMechanical waves.\nStanding waves can be mechanically induced into a solid medium using resonance. One easy to understand example is two people shaking either end of a jump rope. If they shake in sync, the rope will form a regular pattern with nodes and antinodes and appear to be stationary, hence the name standing wave. Similarly a cantilever beam can have a standing wave imposed on it by applying a base excitation. In this case the free end moves the greatest distance laterally compared to any location along the beam. Such a device can be used as a sensor to track changes in frequency or phase of the resonance of the fiber. One application is as a measurement device for dimensional metrology.\nSeismic waves.\nStanding surface waves on the Earth are observed as free oscillations of the Earth.\nFaraday waves.\nThe Faraday wave is a non-linear standing wave at the air-liquid interface induced by hydrodynamic instability. It can be used as a liquid-based template to assemble microscale materials.\nSeiches.\nA seiche is an example of a standing wave in an enclosed body of water. It is characterised by the oscillatory behaviour of the water level at either end of the body and typically has a nodal point near the middle of the body where very little change in water level is observed. It should be distinguished from a simple storm surge where no oscillation is present. In sizeable lakes, the period of such oscillations may be between minutes and hours, for example Lake Geneva's longitudinal period is 73 minutes and its transversal seiche has a period of around 10 minutes, while Lake Huron can be seen to have resonances with periods between 1 and 2 hours. See Lake seiches.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41742", "revid": "49473295", "url": "https://en.wikipedia.org/wiki?curid=41742", "title": "Standing wave ratio", "text": "Measure used in radio engineering and telecommunications\nIn radio engineering and telecommunications, standing wave ratio (SWR) is a measure of impedance matching of loads to the characteristic impedance of a transmission line or waveguide. Impedance mismatches result in standing waves along the transmission line, and SWR is defined as the ratio of the partial standing wave's amplitude at an antinode (maximum) to the amplitude at a node (minimum) along the line.\nVoltage standing wave ratio (VSWR) (pronounced \"vizwar\") is the ratio of maximum to minimum voltage on a transmission line . For example, a VSWR of 1.2 means a peak voltage 1.2 times the minimum voltage along that line, if the line is at least one half wavelength long.\nA SWR can be also defined as the ratio of the maximum amplitude to minimum amplitude of the transmission line's currents, electric field strength, or the magnetic field strength. Neglecting transmission line loss, these ratios are identical.\nThe power standing wave ratio (PSWR) is defined as the square of the VSWR, however, this deprecated term has no direct physical relation to power actually involved in transmission.\nSWR is usually measured using a dedicated instrument called an SWR meter. Since SWR is a measure of the load impedance relative to the characteristic impedance of the transmission line in use (which together determine the reflection coefficient as described below), a given SWR meter can interpret the impedance it sees in terms of SWR only if it has been designed for the same particular characteristic impedance as the line. In practice most transmission lines used in these applications are coaxial cables with an impedance of either 50 or 75\u00a0ohms, so most SWR meters correspond to one of these.\nChecking the SWR is a standard procedure in a radio station. Although the same information could be obtained by measuring the load's impedance with an impedance analyzer (or \"impedance bridge\"), the SWR meter is simpler and more robust for this purpose. By measuring the magnitude of the impedance mismatch at the transmitter output it reveals problems due to either the antenna or the transmission line.\nImpedance matching.\nSWR is used as a measure of impedance matching of a load to the characteristic impedance of a transmission line carrying radio frequency (RF) signals. This especially applies to transmission lines connecting radio transmitters and receivers with their antennas, as well as similar uses of RF cables such as cable television connections to TV receivers and distribution amplifiers. Impedance matching is achieved when the source impedance is the complex conjugate of the load impedance. The easiest way of achieving this, and the way that minimizes losses along the transmission line, is for the imaginary part of the complex impedance of both the source and load to be zero, that is, pure resistances, equal to the characteristic impedance of the transmission line. When there is a mismatch between the load impedance and the transmission line, part of the forward wave sent toward the load is reflected back along the transmission line towards the source. The source then sees a different impedance than it expects which can lead to lesser (or in some cases, more) power being supplied by it, the result being very sensitive to the electrical length of the transmission line.\nSuch a mismatch is usually undesired and results in standing waves along the transmission line which magnifies transmission line losses (significant at higher frequencies and for longer cables). The SWR is a measure of the depth of those standing waves and is, therefore, a measure of the matching of the load to the transmission line. A matched load would result in an SWR of 1:1 implying no reflected wave. An infinite SWR represents complete reflection by a load unable to absorb electrical power, with all the incident power reflected back towards the source.\nIt should be understood that the match of a load to the transmission line is different from the match of a \"source\" to the transmission line or the match of a source to the load \"seen through\" the transmission line. For instance, if there is a perfect match between the load impedance Zload and the source impedance that perfect match will remain if the source and load are connected through a transmission line with an electrical length of one half wavelength (or a multiple of one half wavelengths) using a transmission line of \"any\" characteristic impedance Z0. However the SWR will generally not be 1:1, depending only on Zload and Z0. With a different length of transmission line, the source will see a different impedance than Zload which may or may not be a good match to the source. Sometimes this is deliberate, as when a quarter-wave matching section is used to improve the match between an otherwise mismatched source and load.\nHowever typical RF sources such as transmitters and signal generators are designed to look into a purely resistive load impedance such as 50\u03a9 or 75\u03a9, corresponding to common transmission lines' characteristic impedances. In those cases, matching the load to the transmission line, Zload \n Z0, \"always\" ensures that the source will see the same load impedance as if the transmission line weren't there. This is identical to a 1:1 SWR. This condition (Zload \n Z0) also means that the load seen by the source is independent of the transmission line's electrical length. Since the electrical length of a physical segment of transmission line depends on the signal frequency, violation of this condition means that the impedance seen by the source through the transmission line becomes a function of frequency (especially if the line is long), even if Zload is frequency-independent. So in practice, a good SWR (near 1:1) implies a transmitter's output seeing the exact impedance it expects for optimum and safe operation.\nRelationship to the reflection coefficient.\nThe voltage component of a standing wave in a uniform transmission line consists of the forward wave (with complex amplitude formula_1) superimposed on the reflected wave (with complex amplitude formula_2).\nA wave is partly reflected when a transmission line is terminated with an impedance unequal to its characteristic impedance. The reflection coefficient formula_3 can be defined as:\nformula_4\nor\nformula_5\nformula_3 is a complex number that describes both the magnitude and the phase shift of the reflection. The simplest cases with formula_3 \"measured at the load\" are:\nThe SWR directly corresponds to the magnitude of formula_3.\nAt some points along the line the forward and reflected waves interfere constructively, exactly in phase, with the resulting amplitude formula_12 given by the sum of those waves' amplitudes:\nformula_13\nAt other points, the waves interfere 180\u00b0 out of phase with the amplitudes partially cancelling:\nformula_14\nThe voltage standing wave ratio is then\nformula_15\nSince the magnitude of formula_3 always falls in the range [0,1], the SWR is always greater than or equal to unity. Note that the \"phase\" of \"V\"f and \"V\"r vary along the transmission line in opposite directions to each other. Therefore, the complex-valued reflection coefficient formula_3 varies as well, but only in phase. With the SWR dependent \"only\" on the complex magnitude of formula_3, it can be seen that the SWR measured at \"any\" point along the transmission line (neglecting transmission line losses) obtains an identical reading.\nSince the power of the forward and reflected waves are proportional to the square of the voltage components due to each wave, SWR can be expressed in terms of forward and reflected power:\nformula_19\nBy sampling the complex voltage and current at the point of insertion, an SWR meter is able to compute the effective forward and reflected voltages on the transmission line for the characteristic impedance for which the SWR meter has been designed. Since the forward and reflected power is related to the square of the forward and reflected voltages, some SWR meters also display the forward and reflected power.\nIn the special case of a load RL, which is purely resistive but unequal to the characteristic impedance of the transmission line Z0, the SWR is given simply by their ratio:\nformula_20\nwith the ratio or its reciprocal is chosen to obtain a value greater than unity.\nThe standing wave pattern.\nUsing complex notation for the voltage amplitudes, for a signal at frequency f, the actual (real) voltages Vactual as a function of time t are understood to relate to the complex voltages according to:\nformula_21 \nThus taking the real part of the complex quantity inside the parenthesis, the actual voltage consists of a sine wave at frequency f with a peak amplitude equal to the complex magnitude of V, and with a phase given by the phase of the complex V. Then with the position along a transmission line given by x, with the line ending in a load located at xo, the complex amplitudes of the forward and reverse waves would be written as:\nformula_22\nfor some complex amplitude A (corresponding to the forward wave at xo that some treatments use phasors where the time dependence is according to formula_23 and spatial dependence (for a wave in the +x direction) of formula_24 Either convention obtains the same result for Vactual.\nAccording to the superposition principle the net voltage present at any point x on the transmission line is equal to the sum of the voltages due to the forward and reflected waves:\nformula_25\nSince we are interested in the variations of the \"magnitude\" of Vnet along the line (as a function of x), we shall solve instead for the squared magnitude of that quantity, which simplifies the mathematics. To obtain the squared magnitude we multiply the above quantity by its complex conjugate:\nformula_26\nDepending on the phase of the third term, the maximum and minimum values of Vnet (the square root of the quantity in the equations) are formula_27 and formula_28 respectively, for a standing wave ratio of:\nformula_29\nformula_30\nas earlier asserted. Along the line, the above expression for formula_31 is seen to oscillate sinusoidally between formula_32 and formula_33 with a period of \u00a0. This is \"half\" of the guided wavelength for the frequency f\u00a0. That can be seen as due to interference between two waves of that frequency which are travelling in \"opposite\" directions.\nFor example, at a frequency (free space wavelength of 15\u00a0m) in a transmission line whose velocity factor is 0.67\u00a0, the guided wavelength (distance between voltage peaks of the forward wave alone) would be At instances when the forward wave at is at zero phase (peak voltage) then at it would also be at zero phase, but at it would be at 180\u00b0 phase (peak \"negative\" voltage). On the other hand, the magnitude of the voltage due to a standing wave produced by its addition to a reflected wave, would have a wavelength between peaks of only Depending on the location of the load and phase of reflection, there might be a peak in the magnitude of Vnet at Then there would be another peak found where at whereas it would find minima of the standing wave at 8.8\u00a0m, etc.\nPractical implications of SWR.\nThe most common case for measuring and examining SWR is when installing and tuning transmitting antennas. When a transmitter is connected to an antenna by a feed line, the driving point impedance of the antenna must match the characteristic impedance of the feed line in order for the transmitter to see the impedance it was designed for (the impedance of the feed line, usually 50 or 75 ohms).\nThe impedance of a particular antenna design can vary due to a number of factors that cannot always be clearly identified. This includes the transmitter frequency (as compared to the antenna's design or resonant frequency), the antenna's height above and quality of the ground, proximity to large metal structures, and variations in the exact size of the conductors used to construct the antenna.(p20.2)\nWhen an antenna and feed line do not have matching impedances, the transmitter sees an unexpected impedance, where it might not be able to produce its full power, and can even damage the transmitter in some cases.\nThe reflected power in the transmission line increases the average current and therefore losses in the transmission line compared to power actually delivered to the load.\nIt is the interaction of these reflected waves with forward waves which causes standing wave patterns, with the negative repercussions we have noted.(p19.13)\nMatching the impedance of the antenna to the impedance of the feed line can sometimes be accomplished through adjusting the antenna itself, but otherwise is possible using an antenna tuner, an impedance matching device. Installing the tuner between the feed line and the antenna allows for the feed line to see a load close to its characteristic impedance, while sending most of the transmitter's power (a small amount may be dissipated within the tuner) to be radiated by the antenna despite its otherwise unacceptable feed point impedance. Installing a tuner in between the transmitter and the feed line can also transform the impedance seen at the transmitter end of the feed line to one preferred by the transmitter. However, in the latter case, the feed line still has a high SWR present, with the resulting increased feed line losses unmitigated.\nThe magnitude of those losses are dependent on the type of transmission line, and its length. They always increase with frequency. For example, a certain antenna used well away from its resonant frequency may have an SWR of 6:1. For a frequency of 3.5\u00a0MHz, with that antenna fed through 75 meters of RG-8A coax, the loss due to standing waves would be 2.2\u00a0dB. However the same 6:1 mismatch through 75 meters of RG-8A coax would incur 10.8\u00a0dB of loss at 146\u00a0MHz. Thus, a better match of the antenna to the feed line, that is, a lower SWR, becomes increasingly important with increasing frequency, even if the transmitter is able to accommodate the impedance seen (or an antenna tuner is used between the transmitter and feed line).\nCertain types of transmissions can suffer other negative effects from reflected waves on a transmission line. Analog TV can experience \"ghosts\" from delayed signals bouncing back and forth on a long line. FM stereo can also be affected and digital signals can experience delayed pulses leading to bit errors. Whenever the delay times for a signal going back down and then again up the line are comparable to the modulation time constants, effects occur. For this reason, these types of transmissions require a low SWR on the feedline, even if SWR induced loss might be acceptable and matching is done at the transmitter.\nMethods of measuring standing wave ratio.\nMany different methods can be used to measure standing wave ratio. The most intuitive method uses a slotted line which is a section of transmission line with an open slot which allows a probe to detect the actual voltage at various points along the line.\nThus the maximum and minimum values can be compared directly. This method is used at VHF and higher frequencies. At lower frequencies, such lines are impractically long.\nDirectional couplers can be used at HF through microwave frequencies. Some are a quarter wave or more long, which restricts their use to the higher frequencies. Other types of directional couplers sample the current and voltage at a single point in the transmission path and mathematically combine them in such a way as to represent the power flowing in one direction.\nThe common type of SWR / power meter used in amateur operation may contain a dual directional coupler. Other types use a single coupler which can be rotated 180 degrees to sample power flowing in either direction. Unidirectional couplers of this type are available for many frequency ranges and power levels and with appropriate coupling values for the analog meter used.\nThe forward and reflected power measured by directional couplers can be used to calculate SWR. The computations can be done mathematically in analog or digital form or by using graphical methods built into the meter as an additional scale or by reading from the crossing point between two needles on the same meter. \nThe above measuring instruments can be used \"in line\" that is, the full power of the transmitter can pass through the measuring device so as to allow continuous monitoring of SWR. Other instruments, such as network analyzers, low power directional couplers and antenna bridges use low power for the measurement and must be connected in place of the transmitter. Bridge circuits can be used to directly measure the real and imaginary parts of a load impedance and to use those values to derive SWR. These methods can provide more information than just SWR or forward and reflected power.\nStand alone antenna analyzers use various measuring methods and can display SWR and other parameters plotted against frequency. By using directional couplers and a bridge in combination, it is possible to make an in line instrument that reads directly in complex impedance or in SWR.\nStand alone antenna analyzers also are available that measure multiple parameters.\nPower standing wave ratio.\nThe term \"power standing wave ratio\" (PSWR) is sometimes referred to, and defined as, the square of the voltage standing wave ratio. The term is widely cited as \"misleading\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The expression \"power standing-wave ratio\", which may sometimes be encountered, is even more misleading, for the power distribution along a loss-free line is constant.\u00a0...\nHowever it does correspond to one type of measurement of SWR using what was formerly a standard measuring instrument at microwave frequencies, the slotted line. The slotted line is a waveguide (or air-filled coaxial line) in which a small sensing antenna which is part of a \"crystal detector\" or \"detector\" is placed in the electric field in the line. The voltage induced in the antenna is rectified by either a point contact diode (crystal rectifier) or a Schottky barrier diode that is incorporated in the detector. These detectors have a square law output for low levels of input. Readings therefore corresponded to the square of the electric field along the slot, \"E\"2(\"x\"), with maximum and minimum readings of \"E\"2max and \"E\"2min found as the probe is moved along the slot. The ratio of these yields the \"square\" of the SWR, the so-called PSWR.\nThis technique of rationalization of terms is fraught with problems. The square law behavior of the detector diode is exhibited only when the voltage across the diode is below the knee of the diode. Once the detected voltage exceeds the knee, the response of the diode becomes nearly linear. In this mode the diode and its associated filtering capacitor produce a voltage that is proportional to the peak of the sampled voltage. The operator of such a detector would not have a ready indication as to the mode in which the detector diode is operating and therefore differentiating the results between SWR or so called PSWR is not practical. Perhaps even worse, is the common case where the minimum detected voltage is below the knee and the maximum voltage is above the knee. In this case, the computed results are largely meaningless. Thus the terms PSWR and Power Standing Wave Ratio are deprecated and should be considered only from a legacy measurement perspective.\nImplications of SWR on medical applications.\nSWR can also have a detrimental impact upon the performance of microwave-based medical applications. In microwave electrosurgery an antenna that is placed directly into tissue may not always have an optimal match with the feedline resulting in standing waves, the presence of which can affect monitoring components used to measure power levels, making such measurements less reliable.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;* Antenna tuner (\"transmatch\")\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41743", "revid": "16057", "url": "https://en.wikipedia.org/wiki?curid=41743", "title": "Star coupler", "text": "A star coupler is a device that takes in an input signal and splits it into several output signals.\nIn fiber optics, and especially in telecommunications, a star coupler is a passive optical device, used in network applications. An optical signal introduced into any input port is distributed to all output ports. Because of the way a passive star coupler is constructed, the number of ports is usually a power of 2; i.e., two input ports and two output ports (a \"two-port\" coupler, customarily called a \"directional coupler,\" or \"splitter\"); four input ports and four output ports (a \"four-port\" coupler); eight input ports and eight output ports (an \"eight-port\" coupler), etc.\nDigital Equipment Corporation (now part of Hewlett-Packard) of Maynard, Massachusetts sold a star coupler that interconnected links to computers via coaxial cable rather than optical fibres, but the function was essentially the same. The signal that was distributed was 70 Mbit/s computer interconnect (CI) data and the star coupler provided two redundant paths of either 8 or 16 ports each. Digital's star coupler was developed for use with the VAX- and later Alpha-based computers running Digital's OpenVMS operating system, to provide a passive, highly reliable interconnect for Digital's cluster technology."}
{"id": "41744", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41744", "title": "Start signal", "text": "Signal\nIn telecommunications, a start signal is a signal that prepares a device to receive data or to perform a function. \nIn asynchronous serial communication, start signals are used at the beginning of a character that prepares the receiving device for the reception of the code elements. \nA start signal is limited to one signal element usually having the duration of a unit interval. "}
{"id": "41745", "revid": "2378565", "url": "https://en.wikipedia.org/wiki?curid=41745", "title": "Start-stop transmission", "text": ""}
{"id": "41746", "revid": "125972", "url": "https://en.wikipedia.org/wiki?curid=41746", "title": "Statement", "text": "Statement or statements may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41747", "revid": "252195", "url": "https://en.wikipedia.org/wiki?curid=41747", "title": "Steady-state condition", "text": ""}
{"id": "41748", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=41748", "title": "Step-index profile", "text": "Refractive index profile in optical fibre\nFor an optical fiber, a step-index profile is a refractive index profile characterized by a uniform refractive index within the core and a sharp decrease in refractive index at the core-cladding interface so that the cladding is of a lower refractive index. The step-index profile corresponds to a power-law index profile with the profile parameter approaching infinity. The step-index profile is used in most single-mode fibers and some multimode fibers.\nA step-index fiber is characterized by the core and cladding refractive indices \"n1\" and \"n2\" and the core and cladding radii a and b. Examples of standard core and cladding diameters 2a/2b are 8/125, 50/125, 62.5/125, 85/125, or 100/140 (units of \u03bcm). The fractional refractive-index change formula_1. The value of n1 is typically between 1.44 and 1.46, and formula_2 is typically between 0.001 and 0.02.\nStep-index optical fiber is generally made by doping high-purity fused silica glass (SiO2) with different concentrations of materials like titanium, germanium, or boron.\nModal dispersion in a step index optical fiber is given by\nformula_3\nwhere\nformula_4 is the fractional index of refraction\nformula_5 is the refractive index of core\nformula_6 is the length of the optical fiber under observation\nformula_7 is the speed of light.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41749", "revid": "196446", "url": "https://en.wikipedia.org/wiki?curid=41749", "title": "Stopband", "text": "A stopband is a band of frequencies, between specified limits, through which a circuit, such as a filter or telephone circuit, does not allow signals to pass, or the attenuation is above the required stopband attenuation level. Depending on application, the required attenuation within the stopband may typically be a value between 20 and 120 dB higher than the nominal passband attenuation, which often is 0\u00a0dB.\nThe lower and upper \"limiting frequencies\", also denoted lower and upper stopband corner frequencies, are the frequencies where the stopband and the transition bands meet in a filter specification. The stopband of a low-pass filter is the frequencies from the stopband corner frequency (which is slightly higher than the passband 3\u00a0dB cut-off frequency) up to the infinite frequency. The stopband of a high-pass filter consists of the frequencies from 0 hertz to a stopband corner frequency (slightly lower than the passband cut-off frequency).\nA band-stop filter has one stopband, specified by two non-zero and non-infinite corner frequencies. The difference between the limits in the band-stop filter is the stopband bandwidth, which usually is expressed in hertz.\nA bandpass filter typically has two stopbands. The shape factor of a bandpass filter is the relationship between the 3\u00a0dB bandwidth, and the difference between the stopband limits.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n2.&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41750", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41750", "title": "Stop signal", "text": "Signal\nIn telecommunications, a stop signal is a signal that marks the end of part of a transmission, for example:\nReferences.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41751", "revid": "38198", "url": "https://en.wikipedia.org/wiki?curid=41751", "title": "Store-and-forward switching center", "text": ""}
{"id": "41752", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41752", "title": "Stressed environment", "text": "Environment causing disruption of radio waves\nIn radio communications, a stressed environment is an environment that is under the influence of extrinsic factors that degrade communications integrity, such as when (a) the beginning communications medium is disturbed by natural or man-made events (such as an intentional nuclear burst), (b) the received signal is degraded by natural or man-made interference (such as jamming signals or co-channel interference), (c) an interfering signal can reconfigure the network, and/or (d) an adversary threatens successful communications, in which case radio signals may be encrypted in order to deny the adversary an intelligible message, traffic flow information, network information, or automatic link establishment (ALE) control information.\nReferences.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41753", "revid": "9056972", "url": "https://en.wikipedia.org/wiki?curid=41753", "title": "Stroke speed", "text": ""}
{"id": "41755", "revid": "13889901", "url": "https://en.wikipedia.org/wiki?curid=41755", "title": "Subnet address", "text": ""}
{"id": "41756", "revid": "210259", "url": "https://en.wikipedia.org/wiki?curid=41756", "title": "Subscriber", "text": ""}
{"id": "41757", "revid": "8978739", "url": "https://en.wikipedia.org/wiki?curid=41757", "title": "Substitution method (optical fiber)", "text": "In optical fiber technology, the substitution method is a method of measuring the transmission loss of a fiber. It consists of:\nThe substitution method has certain shortcomings with regard to its accuracy, but its simplicity makes it a popular field test method. It is conservative, in that if it were used to measure the individual losses of several long fibers, and the long fibers were concatenated, the total loss obtained (excluding splice losses) would be expected to be lower than the sum of the individual fiber losses. \nSome modern optical power meters have the capability to set to zero the reference level measured at the output of the reference fiber, so that the transmission loss of the fiber under test may be read out directly."}
{"id": "41758", "revid": "252195", "url": "https://en.wikipedia.org/wiki?curid=41758", "title": "Successful block transfer", "text": ""}
{"id": "41760", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41760", "title": "Summation check", "text": "Telecommunication term\nIn telecommunications, the term summation check (sum check) has the following meanings: "}
{"id": "41761", "revid": "4141788", "url": "https://en.wikipedia.org/wiki?curid=41761", "title": "Supervisory program", "text": "Computer program\nA supervisory program or supervisor is a computer program that is usually referred as an operating system. It controls the execution of other routines such as regulating work schedules, input/output operations, and error actions.\nHistorically, this term was essentially associated with IBM's line of mainframe operating systems starting with OS/360. In other operating systems, the supervisor is generally called the kernel."}
{"id": "41762", "revid": "16416757", "url": "https://en.wikipedia.org/wiki?curid=41762", "title": "Reduced-carrier transmission", "text": "AM signal with a low-power or suppressed carrier\nReduced-carrier transmission is an amplitude modulation (AM) transmission in which the carrier signal level is reduced to reduce wasted electrical power. Suppressed-carrier transmission is a special case in which the carrier level is reduced below that required for demodulation by a normal receiver.\nReduction of the carrier level permits higher power levels in the sidebands than would be possible with conventional AM transmission. Carrier power must be restored by the receiving station to permit demodulation, usually by means of a beat frequency oscillator (BFO). Failure of the BFO to match the original carrier frequency when receiving such a signal will cause a heterodyne.\nSuppressed carriers are often used for single sideband (SSB) transmissions, such as for amateur radio on shortwave. That system is referred to in full as SSB suppressed carrier (SSBSC) or (SSB-SC). International broadcasters agreed in 1985 to also use SSBSC entirely by 2015, though IBOC and IBAC digital radio (namely Digital Radio Mondiale) seems likely to make this irrelevant.\nFM stereo transmissions use a double-sideband suppressed carrier (DSBSC) signal from a stereo generator, together with a pilot tone of exactly half the original carrier frequency. This allows reconstitution of the original stereo carrier, and hence the stereo signal."}
{"id": "41763", "revid": "16364713", "url": "https://en.wikipedia.org/wiki?curid=41763", "title": "Surface wave", "text": "Physical phenomenon\nIn physics, a surface wave is a mechanical wave that propagates along the interface between differing media. A common example is gravity waves along the surface of liquids, such as ocean waves. Gravity waves can also occur within liquids, at the interface between two fluids with different densities. Elastic surface waves can travel along the surface of solids, such as \"Rayleigh\" or \"Love\" waves. Electromagnetic waves can also propagate as \"surface waves\" in that they can be guided along with a refractive index gradient or along an interface between two media having different dielectric constants. In radio transmission, a \"ground wave\" is a guided wave that propagates close to the surface of the Earth.\nMechanical waves.\nIn seismology, several types of surface waves are encountered. Surface waves, in this mechanical sense, are commonly known as either \"Love waves\" (L waves) or \"Rayleigh waves\". A seismic wave is a wave that \"travels through the Earth, often as the result of an earthquake or explosion.\" Love waves have transverse motion (movement is perpendicular to the direction of travel, like light waves), whereas Rayleigh waves have both longitudinal (movement parallel to the direction of travel, like sound waves) and transverse motion. Seismic waves are studied by seismologists and measured by a seismograph or seismometer. Surface waves span a wide frequency range, and the period of waves that are most damaging is usually 10 seconds or longer. Surface waves can travel around the globe many times from the largest earthquakes. Surface waves are caused when P waves and S waves come to the surface.\nExamples are the waves at the surface of water and air (ocean surface waves). Another example is internal waves, which can be transmitted along the interface of two water masses of different densities.\nIn theory of hearing physiology, the traveling wave (TW) of Von Bekesy, resulted from an acoustic surface wave of the basilar membrane into the cochlear duct. His theory purported to explain every feature of the auditory sensation owing to these passive mechanical phenomena. Jozef Zwislocki, and later David Kemp, showed that that is unrealistic and that active feedback is necessary.\nElectromagnetic waves.\n\"Ground waves\" are radio waves propagating parallel to and adjacent to the surface of the Earth, following the curvature of the Earth. This radiative ground wave is known as Norton surface wave, or more properly Norton ground wave, because ground waves in radio propagation are not confined to the surface.\nAnother type of surface wave is the non-radiative, bound-mode \"Zenneck surface wave\" or \"Zenneck\u2013Sommerfeld surface wave\". The earth has one refractive index and the atmosphere has another, thus constituting an interface that supports the guided Zenneck wave's transmission. Other types of surface wave are the trapped surface wave, the gliding wave and Dyakonov surface waves (DSW) propagating at the interface of transparent materials with different symmetry. Apart from these, various types of surface waves have been studied for optical wavelengths.\nMicrowave field theory.\nWithin microwave field theory, the interface of a dielectric and conductor supports \"surface wave transmission\". Surface waves have been studied as part of transmission lines and some may be considered as single-wire transmission lines.\nCharacteristics and utilizations of the electrical surface wave phenomenon include:\nSurface plasmon polariton.\nThe surface plasmon polariton (SPP) is an electromagnetic surface wave that can travel along an interface between two media with different dielectric constants. It exists under the condition that the permittivity of one of the materials forming the interface is negative, while the other one is positive, as is the case for the interface between air and a lossy conducting medium below the plasma frequency. The wave propagates parallel to the interface and decays exponentially vertical to it, a property called evanescence. Since the wave is on the boundary of a lossy conductor and a second medium, these oscillations can be sensitive to changes to the boundary, such as the adsorption of molecules by the conducting surface.\nSommerfeld\u2013Zenneck surface wave.\nThe Sommerfeld\u2013Zenneck wave or Zenneck wave is a non-radiative guided electromagnetic wave that is supported by a planar or spherical interface between two homogeneous media having different dielectric constants. This surface wave propagates parallel to the interface and decays exponentially vertical to it, a property known as evanescence. It exists under the condition that the permittivity of one of the materials forming the interface is negative, while the other one is positive, as for example the interface between air and a lossy conducting medium such as the terrestrial transmission line, below the plasma frequency. Its electric field strength falls off at a rate of e-\u03b1d/\u221ad in the direction of propagation along the interface due to two-dimensional geometrical field spreading at a rate of 1/\u221ad, in combination with a frequency-dependent exponential attenuation (\u03b1), which is the terrestrial transmission line dissipation, where \u03b1 depends on the medium's conductivity. Arising from original analysis by Arnold Sommerfeld and Jonathan Zenneck of the problem of wave propagation over a lossy earth, it exists as an exact solution to Maxwell's equations. The Zenneck surface wave, which is a non-radiating guided-wave mode, can be derived by employing the Hankel transform of a radial ground current associated with a realistic terrestrial Zenneck surface wave source. Sommerfeld-Zenneck surface waves predict that the energy decays as R\u22121 because the energy distributes over the circumference of a circle and not the surface of a sphere. Evidence does not show that in radio space wave propagation, Sommerfeld-Zenneck surfaces waves are a mode of propagation as the path-loss exponent is generally between 20\u00a0dB/dec and 40\u00a0dB/dec.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41764", "revid": "8524693", "url": "https://en.wikipedia.org/wiki?curid=41764", "title": "Survivability", "text": "Ability to remain alive or continue to exist\nSurvivability is the ability to remain alive or continue to exist. The term has more specific meaning in certain contexts.\nEcological.\nFollowing disruptive forces such as flood, fire, disease, war, or climate change some species of flora, fauna, and local life forms are likely to survive more successfully than others because of consequent changes to their surrounding biophysical conditions.\nEngineering.\nIn engineering, survivability is the quantified ability of a system, subsystem, equipment, process, or procedure to continue to function during and after a natural or man-made disturbance; for example, a nuclear electromagnetic pulse from the detonation of a nuclear weapon.\nFor a given application, survivability must be qualified by specifying the range of conditions over which the entity will survive, the minimum acceptable level or post-disturbance functionality, and the maximum acceptable downtime.\nMilitary.\nIn the military environment, survivability can be defined as the ability to remain mission capable after a single engagement. Engineers working in survivability are often responsible for improving four main system elements:\nThe European Survivability Workshop introduced the concept of \"Mission Survivability\" whilst retaining the three core areas above, either pertaining to the \"survivability\" of a platform through a complete mission, or the \"survivability\" of the mission itself (i.e. probability of mission success). Recent studies have also introduced the concept of \"Force Survivability\" which relates to the ability of a force rather than an individual platform to remain \"mission capable\".\nThere is no clear prioritisation of the three elements; this will depend on the characteristics and role of the platform. Some platform types, such as submarines and airplanes, minimise their susceptibility and may, to some extent, compromise in the other areas. Main Battle Tanks minimise vulnerability through the use of heavy armours. Present day surface warship designs tend to aim for a balanced combination of all three areas.\nA popular term is the \"survivability onion\"; described as 5-8 layers: \nDon't be there. If you are there, don\u2019t be seen. If you are seen, don\u2019t be targeted/acquired. If you are targeted/acquired, don\u2019t be hit. If you are hit, don\u2019t be penetrated. If you are penetrated, don\u2019t be killed.\nNaval.\nSurvivability denotes the ability of a ship and its on-board systems to remain functional and continue designated mission in a man-made hostile environment. The naval vessels are designed to operate in a man-made hostile environment, and therefore the survivability is a vital feature required from them. The naval vessel's survivability is a complicated subject affecting the whole life cycle of the vessel, and should be considered from the initial design phase of every war ship.\nThe classical definition of naval survivability includes three main aspects, which are susceptibility, vulnerability, and recoverability; although, recoverability is often subsumed within vulnerability.\nSusceptibility consists of all the factors that expose the ship to the weapons effects in a combat environment. These factors in general are the operating conditions, the threat, and the features of the ship itself. The operating conditions, such as sea state, weather and atmospheric conditions, vary considerably, and their influence is difficult to address (hence they are often not accounted for in survivability assessment). The threat is dependent on the weapons directed against the ship and weapon's performance, such as the range. The features of the ship in this sense include platform signatures (radar, infrared, acoustic, magnetic), the defensive systems on board, such as surface-to-air missiles, EW and decoys, and also the tactics employed by the platform in countering the attack (aspects such as speed, maneuverability, chosen aspect presented to the threat).\nVulnerability refers to the ability of the vessel to withstand the short-term effects of the threat weapon. Vulnerability is an attribute typical to the vessel and therefore heavily\naffected by the vessel's basic characteristics such as size, subdivision, armouring, and other hardening features, and also the design of the ship's systems, in particular the location of equipment, degrees of redundancy and separation, and the presence within a system of single point failures. Recoverability refers to vessel's ability to restore and maintain its functionality after sustaining damage. Thus, recoverability is dependent on the actions aimed to neutralize the effects of the damage. These actions include firefighting, limiting the extent of flooding, and dewatering. Besides the equipment, the crew also has a vital role in recoverability.\nCombat vehicle crew.\nThe crews of military combat vehicles face numerous lethal hazards which are both diverse and constantly evolving. Improvised Explosive Devices (IEDs), mines, and enemy fire are examples of such persistent and variable threats. Historically, measures taken to mitigate these hazards were concerned with protecting the vehicle itself, but due to this achieving only limited protection, the focus has now shifted to safeguarding the crew within from an ever-broadening range of threats, including Radio Controlled IEDs (RCIEDs), blast, fragmentation, heat stress, and dehydration.\nThe expressed goal of \"crew survivability\" is to ensure vehicle occupants are best protected. It goes beyond simply ensuring crew have the appropriate protective equipment and has expanded to include measuring the overpressure and blunt impact forces experienced by a vehicle from real blast incidents in order to develop medical treatment and improve overall crew survivability. Sustainable crew survivability is dependent on the effective integration of knowledge, training, and equipment.\nPrevention and training.\nThreat intelligence identifying trends, emerging technologies, and attack tactics used by enemy forces enables crews to implement procedures that will reduce their exposure to unnecessary risks. Such intelligence also allows for more effective pre-deployment training programs where personnel can be taught the most up-to-date developments in IED concealment, for example, or undertake tailored training that will enable them to identify the likely attack strategy of enemy forces. In addition, with expert, current threat intelligence, the most effective equipment can be procured or rapidly developed in support of operations.\nNetwork.\nDefinitions of network survivability.\n\"The capability of a system to fulfill its mission, in a timely manner, in the presence of such as attacks or large-scale natural disasters. Survivability is a subset of resilience.\"\n\u201cThe capability of a system to fulfill its mission, in a timely manner, in the presence of attacks, failures, or accidents.\u201d\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41765", "revid": "37442177", "url": "https://en.wikipedia.org/wiki?curid=41765", "title": "Switched loop", "text": "Circuit configuration\nIn telephony, a Switched loop is a circuit that automatically releases a connection from an attendant console or switchboard, once the connection has been made to the appropriate terminal. \nLoop buttons or jacks are used to answer incoming listed directory number calls, dial \"0\" internal calls, transfer requests, and intercepted calls. The attendant can handle only one telephone call at a time. \"Synonym\": released loop."}
{"id": "41767", "revid": "8524693", "url": "https://en.wikipedia.org/wiki?curid=41767", "title": "Synchronism", "text": "Synchronism may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41768", "revid": "47614224", "url": "https://en.wikipedia.org/wiki?curid=41768", "title": "Synchronizing", "text": ""}
{"id": "41769", "revid": "252195", "url": "https://en.wikipedia.org/wiki?curid=41769", "title": "Synchronous network", "text": ""}
{"id": "41770", "revid": "46867800", "url": "https://en.wikipedia.org/wiki?curid=41770", "title": "Synchronous orbit", "text": "Orbit of an astronomical body equal to that body's average rotational period\nA synchronous orbit is an orbit in which an orbiting body (usually a satellite) has a period equal to the average rotational period of the body being orbited (usually a planet), and in the same direction of rotation as that body.\nSimplified meaning.\nA synchronous orbit is an orbit in which the orbiting object (for example, an artificial satellite or a moon) takes the same amount of time to complete an orbit as it takes the object it is orbiting to rotate once.\nProperties.\nA satellite in a synchronous orbit that is both equatorial and circular will appear to be suspended motionless above a point on the orbited planet's equator. For synchronous satellites orbiting Earth, this is also known as a geostationary orbit. However, a synchronous orbit need not be equatorial; nor circular. A body in a non-equatorial synchronous orbit will appear to oscillate north and south above a point on the planet's equator, whereas a body in an elliptical orbit will appear to oscillate eastward and westward. As seen from the orbited body the combination of these two motions produces a figure-8 pattern called an analemma.\nNomenclature.\nThere are many specialized terms for synchronous orbits depending on the body orbited. The following are some of the more common ones. A synchronous orbit around Earth that is circular and lies in the equatorial plane is called a geostationary orbit. The more general case, when the orbit is inclined to Earth's equator or is non-circular is called a geosynchronous orbit. The corresponding terms for synchronous orbits around Mars are areostationary and areosynchronous orbits. \nFormula.\nFor a stationary synchronous orbit:\n formula_1\n G = Gravitational constant\n m2 = Mass of the celestial body\n T = Sidereal rotational period of the body\nformula_2 = Radius of orbit\nBy this formula, one can find the synchronous orbital radius of a body, given its mass and sidereal rotational period. \nOrbital speed (how fast a satellite is moving through space) is calculated by multiplying the angular speed of the satellite by the orbital radius.\nDue to obscure quirks of orbital mechanics, no tidally locked body in a 1:1 spin-orbit resonance (i.e. a moon locked to a planet or a planet locked to a star) can have a stable satellite in a synchronous orbit, as the synchronous orbital radius lies outside the body's Hill sphere. This is universal and irrespective of the masses and distances involved. \nExamples.\nAn astronomical example is Pluto's largest moon Charon.\nMuch more commonly, synchronous orbits are employed by artificial satellites used for communication, such as geostationary satellites.\nFor natural satellites, which can attain a synchronous orbit only by tidally locking their parent body, it always goes in hand with synchronous rotation of the satellite. This is because the smaller body becomes tidally locked faster, and by the time a synchronous orbit is achieved, it has had a locked synchronous rotation for a long time already.\nThe following table lists select Solar System bodies' masses, sidereal rotational periods, and the semi-major axises and altitudes of their synchronous orbital radii (calculated by the formula in the above section): \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41771", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41771", "title": "System integrity", "text": "In telecommunications, the term system integrity has the following meanings: "}
{"id": "41772", "revid": "33373980", "url": "https://en.wikipedia.org/wiki?curid=41772", "title": "System lifecycle", "text": ""}
{"id": "41773", "revid": "37593029", "url": "https://en.wikipedia.org/wiki?curid=41773", "title": "Systems control", "text": "Systems control, in a communications system, is the control and implementation of a set of functions that:"}
{"id": "41774", "revid": "21436738", "url": "https://en.wikipedia.org/wiki?curid=41774", "title": "Systems design", "text": "Organizing components structures and behaviors for any simple to complex system\nThe basic study of system design is the understanding of component parts and their subsequent interaction with one another.\nSystems design has appeared in a variety of fields, including aeronautics, sustainability, computer/software architecture, and sociology.\nProduct development.\nIf the broader topic of product development \"blends the perspective of marketing, design, and manufacturing into a single approach to product development,\" then design is the act of taking the marketing information and creating the design of the product to be manufactured. \nThus in product development, systems design involves the process of defining and developing systems, such as interfaces and data, for an electronic control system to satisfy specified requirements. Systems design could be seen as the application of systems theory to product development. There is some overlap with the disciplines of systems analysis, systems architecture and systems engineering.\nPhysical design.\nThe physical design relates to the actual input and output processes of the system. This is explained in terms of how data is input into a system, how it is verified/authenticated, how it is processed, and how it is displayed.\nIn physical design, the following requirements about the system are decided.\nPut another way, the physical portion of system design can generally be broken down into three sub-tasks:\nArchitecture design.\nDesigning the overall structure of a system focuses on creating a scalable, reliable, and efficient system. For example, services like Google, Twitter, Facebook, Amazon, and Netflix exemplify large-scale distributed systems. Here are key considerations:\nMachine learning systems design.\nMachine learning systems design focuses on building scalable, reliable, and efficient systems that integrate machine learning (ML) models to solve real-world problems. ML systems require careful consideration of data pipelines, model training, and deployment infrastructure. ML systems are often used in applications such as recommendation engines, fraud detection, and natural language processing.\nKey components to consider when designing ML systems include:\nDesigning an ML system involves balancing trade-offs between accuracy, latency, cost, and maintainability, while ensuring system scalability and reliability. The discipline overlaps with MLOps, a set of practices that unifies machine learning development and operations to ensure smooth deployment and lifecycle management of ML systems.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41775", "revid": "27801057", "url": "https://en.wikipedia.org/wiki?curid=41775", "title": "Tactical communications", "text": "Orders and reports within a battlefield\nTactical communications are military communications in which information of any kind, especially orders and military intelligence, are conveyed from one command, person, or place to another upon a battlefield, particularly during the conduct of combat. It includes any kind of delivery of information, whether verbal, written, visual or auditory, and can be sent in a variety of ways. In modern times, this is usually done by electronic means. Tactical communications do not include communications provided to tactical forces by the Defense Communications System to non-tactical military commands, to tactical forces by civil organizations, nor does it include strategic communication.\nEarly means.\nThe earliest way of communicating with others in a battle was by the commander's voice or by human messenger. A runner would carry reports or orders from one officer to another. Once the horse was domesticated messages could travel much faster. A very fast way to send information was to use either drums, trumpets or flags. Each sound or banner would have a pre-determined significance for the soldier who would respond accordingly. Auditory signals were only as effective, though, as the receiver's ability to hear them. The din of battle or long distances could make using noise less effective. They were also limited in the amount of information they could convey; the information must be simple, such as \"attack\" or \"retreat\".\nVisual cues, such as flags or smoke signals required the receiver to have a clear line of sight to the signal, and know when and where to look for them. Intricate warning systems have though always been used such as scouting towers with fires to signal incoming threats - this could occur at the tactical as well as the strategic level. The armies of the 19th century used two flags in combinations that replicated the alphabet. This allowed commanders the ability to send any order they wanted as they needed to, but still relied on line-of-sight. During the Siege of Paris (1870\u201371) the defending French effectively used carrier pigeons to relay information between tactical units.\nThe wireless revolution.\nAlthough visual communication flew at the speed of light, it relied on a direct line of sight between the sender and the receiver. Telegraphs helped theater commanders to move large armies about, but one certainly could not count on using immobile telegraph lines on a changing battlefield. \nAt the end of the 19th century the disparate units across any field were instantaneously joined to their commanders by the invention and mass production of the radio. At first the radio could only broadcast tones, so messages were sent via Morse code. The first field radios used by the United States Army saw action in the Spanish\u2013American War (1898) and the Philippine Insurrection (1899\u20131902). At the same time as radios were deployed the field telephone was developed and made commercially viable. This caused a new signal occupation specialty to be developed: lineman.\nDuring the Interwar period the German army invented Blitzkrieg in which air, armor, and infantry forces acted swiftly and precisely, with constant radio communication. They triumphed until their enemies equipped themselves to communicate and coordinate similarly.\nThe digital battlefield.\nSecurity was a problem. If you broadcast your plans over radio waves, anyone with a similar radio listening to the same frequency could hear your plans. Trench codes became the tactical part of World War I cryptography. Advances in electronics, particularly after World War II, allowed for electronic scrambling of voice radio. Operational and strategic messages during the war were by text were encrypted with ciphers too complex for humans to crack without the assistance of a similar, high-tech machine, such as the German Enigma machine. Once computer science advanced, tactical voice radio could be encrypted, and large amounts of data could be sent over the airwaves in quick bursts of signals with more complex encryption. \nCommunication between armies were of course much more difficult before the electronic age and could only be achieved with messengers on horseback or by foot and with time delays according to the distance the messenger needed to travel. Advances in long-range communications aided the commander on the battlefield, for then they could receive news of any outside force or factor that could impact the conduct of a battle.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "41776", "revid": "47070250", "url": "https://en.wikipedia.org/wiki?curid=41776", "title": "Tactical communications system", "text": ""}
{"id": "41777", "revid": "17698045", "url": "https://en.wikipedia.org/wiki?curid=41777", "title": "Tactical data information link\u2013A", "text": ""}
{"id": "41778", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41778", "title": "Tape relay", "text": "A tape relay is a method of retransmitting teletypewriter traffic from one communication channel to another, in which messages arriving on an incoming channel are recorded in the form of perforated tape, this punched tape then being either fed directly and automatically into an outgoing channel, or manually transferred to an automatic transmitter for transmission on an outgoing channel. Tape relay, sometimes informally called \"torn tape operation\", was commonplace during much of the 20th century. "}
{"id": "41779", "revid": "49901947", "url": "https://en.wikipedia.org/wiki?curid=41779", "title": "T-carrier", "text": "Carrier system for digital transmission of multiplexed telephone calls\nThe T-carrier system is a member of the series of data-multiplexing carrier systems developed by AT&amp;T Bell Laboratories for digital transmission of multiplexed telephone calls.\nThe first version, the Transmission System 1 (T1), was introduced in 1962 in the Bell System, and could transmit up to 24 telephone calls simultaneously over a single transmission line of copper wire. Subsequent specifications carried multiples of the basic T1 (1.544\u00a0Mbit/s) data rates, such as T2 (6.312\u00a0Mbit/s) with 96 channels, T3 (44.736\u00a0Mbit/s) with 672 channels, and others.\nAlthough a \"T2\" was defined as part of AT&amp;T's T-carrier system, which defined five levels, T1 through T5, only the T1 and T3 were commonly in use.\nTransmission System 1.\nThe T-carrier is a hardware specification for carrying multiple time-division multiplexed (TDM) telecommunications channels over a single four-wire transmission circuit. It was developed by AT&amp;T at Bell Laboratories ca. 1957 and first employed by 1962 for long-haul pulse-code modulation (PCM) digital voice transmission with the D1 channel bank.\nThe T-carriers are commonly used for trunking between switching centers in a telephone network, including to private branch exchange (PBX) interconnect points. It uses the same twisted pair copper wire that analog trunks used, employing one pair for transmitting, and another pair for receiving. Signal repeaters may be used for extended distance requirements.\nBefore the digital T-carrier system, carrier wave systems such as 12-channel carrier systems worked by frequency-division multiplexing; each call was an analog signal. A T1 trunk could transmit 24 telephone calls at a time, because it used a digital carrier signal called Digital Signal 1 (DS-1). DS-1 is a communications protocol for multiplexing the bitstreams of up to 24 telephone calls, along with one special bit: a \"framing bit\" (for frame synchronization). T1's maximum data transmission rate is 1.544 megabits per second. (24 Channels X 8 bits) + 1 framing bit @ 8000 samples per second = 1,544,000 bit/s.\nOutside of the United States, Canada, Japan, and South Korea, the E-carrier system is used. E-carrier is similar transmission system with higher capacity that is not directly compatible with the T-carrier.\nLegacy.\nExisting frequency-division multiplexing carrier systems worked well for connections between distant cities, but required expensive modulators, demodulators and filters for every voice channel. In the late 1950s, Bell Labs sought cheaper terminal equipment for connections within metropolitan areas. Pulse-code modulation allowed sharing a coder and decoder among several voice trunks, so this method was chosen for the T1 system introduced into local use in 1961. In later decades, the cost of digital electronics declined to the point that an individual codec per voice channel became commonplace, but by then the other advantages of digital transmission had become entrenched.\nThe T1 format carried 24 pulse-code modulated, time-division multiplexed speech signals each encoded in 64\u00a0kbit/s streams, leaving 8\u00a0kbit/s of framing information which facilitates the synchronization and demultiplexing at the receiver. The T2 and T3 circuit channels carry multiple T1 channels multiplexed, resulting in transmission rates of 6.312 and 44.736\u00a0Mbit/s, respectively. A T3 line comprises 28 T1 lines, each operating at total signaling rate of 1.544\u00a0Mbit/s. It is possible to get a fractional T3 line, meaning a T3 line with some of the 28 lines turned off, resulting in a slower transfer rate but typically at reduced cost.\nSupposedly, the 1.544 Mbit/s rate was chosen because tests by AT&amp;T Long Lines in Chicago were conducted underground. The test site was typical of Bell System outside plant of the time in that, to accommodate loading coils, cable vault manholes were physically apart, which determined the repeater spacing. The optimum bit rate was chosen empirically\u2014the capacity was increased until the failure rate was unacceptable, then reduced to leave a margin. Companding allowed acceptable audio performance with only seven bits per PCM sample in this original T1/D1 system. The later D3 and D4 channel banks had an extended frame format, allowing eight bits per sample, reduced to seven every sixth sample or frame when one bit was \"robbed\" for signaling the state of the channel. The standard does not allow an all zero sample which would produce a long string of binary zeros and cause the repeaters to lose bit sync (on D4/AMI and earlier systems). However, when carrying data (Switched 56) there could be long strings of zeros, so one bit per sample is set to \"1\" (jam bit 7) leaving 7 bits \u00d7 8,000 frames per second for data. On Extended Superframe B8ZS systems, long strings of zeros are replaced by a special code. This allows equipment to maintain sync, while also allowing 64kbps of data to be carried by each time slot.\nA more detailed understanding of the development of the 1.544\u00a0Mbit/s rate and its division into channels is as follows. Given that the telephone system nominal voiceband (including guardband) is 4,000\u00a0Hz, the required digital sampling rate is 8,000\u00a0Hz (see Nyquist rate). Since each T1 frame contains 1 byte of voice data for each of the 24 channels, that system needs then 8,000 frames per second to maintain those 24 simultaneous voice channels. Because each frame of a T1 is 193 bits in length (24 channels \u00d7 8 bits per channel + 1 framing bit = 193 bits), 8,000 frames per second is multiplied by 193 bits to yield a transfer rate of 1.544\u00a0Mbit/s (8,000 \u00d7 193 = 1,544,000).\nInitially, T1 used Alternate Mark Inversion (AMI) to reduce frequency bandwidth and eliminate the DC component of the signal. Later B8ZS became common practice. For AMI, each mark pulse had the opposite polarity of the previous one and each space was at a level of zero, resulting in a three level signal which carried only binary data. Similar 1970s British 23 channel systems at 1.536 megabaud were equipped with ternary signal repeaters, in anticipation of using a 3B2T or 4B3T code to increase the number of voice channels in the future. But in the 1980s, the systems were merely replaced with European standard ones. American T-carriers could only work in AMI or B8ZS mode.\nThe AMI or B8ZS signal allowed a simple error rate measurement. The D bank in the central office could detect a bit with the wrong polarity, or \"bipolarity violation\" and sound an alarm. Later systems could count the number of violations and reframes and otherwise measure signal quality and allow a more sophisticated alarm indication signal system.\nThe decision to use a 193-bit frame was made in 1958. To allow for the identification of information bits within a frame, two alternatives were considered. Assign (a) just one extra bit, or (b) additional eight bits per frame. The 8-bit choice is cleaner, resulting in a 200-bit frame, twenty-five 8-bit channels, of which 24 are traffic and one 8-bit channel available for operations, administration, and maintenance (OA&amp;M). AT&amp;T chose the single bit per frame not to reduce the required bit rate (1.544 vs 1.6\u00a0Mbit/s), but because AT&amp;T Marketing worried that \"if 8 bits were chosen for OA&amp;M function, someone would then try to sell this as a voice channel and you wind up with nothing.\"\nSoon after commercial success of T1 in 1962, the T1 engineering team realized the mistake of having only one bit to serve the increasing demand for housekeeping functions. They petitioned AT&amp;T management to change to 8-bit framing. This was flatly turned down because it would make installed systems obsolete.\nHaving this hindsight, some ten years later, CEPT chose eight bits for framing the European E1, although, as feared, the extra channel is sometimes appropriated for voice or data.\nHigher bandwidth carriers.\nIn the 1970s, Bell Labs developed higher rate systems. T1C with a more sophisticated modulation scheme carried 3\u00a0Mbit/s, on those balanced pair cables that could support it. T-2 carried 6.312\u00a0Mbit/s, requiring a special low-capacitance cable with foam insulation. This was standard for Picturephone. T-4 and T-5 used coaxial cables, similar to the old L-carriers used by AT&amp;T Long Lines. TD microwave radio relay systems were also fitted with high rate modems to allow them to carry a DS1 signal in a portion of their FM spectrum that had too poor quality for voice service. Later they carried DS3 and DS4 signals. During the 1980s companies such as RLH Industries, Inc. developed T1 over optical fiber. The industry soon developed and evolved with multiplexed T1 transmission schemes.\nDigital signal cross-connect.\nDS1 signals are interconnected typically at Central Office locations at a common metallic cross-connect point known as a DSX-1. When a DS1 is transported over metallic outside plant cable, the signal travels over conditioned cable pairs known as a T1 span. A T1 span can have up to +-130 Volts of DC power superimposed on the associated four wire cable pairs to supply power to line or \"Span\" signal repeaters, and T1 NIU's (T1 Smartjacks). T1 span repeaters are typically engineered up to apart, depending on cable gauge, and at no more than 36\u00a0dB of loss before requiring a repeated span. There can be no cable bridge taps or Load Coils across any pairs.\nT1 copper spans are being replaced by optical transport systems, but if a copper (Metallic) span is used, the T1 is typically carried over an HDSL encoded copper line. Four wire HDSL does not require as many repeaters as conventional T1 spans. Newer two wire HDSL (HDSL-2) equipment transports a full 1.544\u00a0Mbit/s T1 over a single copper wire pair up to approximately twelve thousand (12,000) feet (3.5\u00a0km), if all 24 gauge cable is used. HDSL-2 does not employ multiple repeaters as does conventional four wire HDSL, or newer HDSL-4 systems.\nOne advantage of HDSL is its ability to operate with a limited number of bridge taps, with no tap being closer than from any HDSL transceiver. Both two or four wire HDSL equipment transmits and receives over the same cable wire pair, as compared to conventional T1 service that utilizes individual cable pairs for transmit or receive.\nDS3 signals are rare except within buildings, where they are used for interconnections and as an intermediate step before being multiplexed onto a SONET circuit. This is because a T3 circuit can only go about between repeaters. A customer who orders a DS3 usually receives a SONET circuit run into the building and a multiplexer mounted in a utility box. The DS3 is delivered in its familiar form, two coax cables (1 for send and 1 for receive) with BNC connectors on the ends.\nBit robbing.\nTwelve DS1 frames make up a single T1 Superframe (T1 SF). Each T1 Superframe is composed of two signaling frames. All T1 DS0 channels that employ in-band signaling will have its eighth bit over written, or \"robbed\" from the full 64\u00a0kbit/s DS0 payload, by either a logical ZERO or ONE bit to signify a circuit signaling state or condition. Hence robbed bit signaling will restrict a DS0 channel to a rate of only 56\u00a0kbit/s during two of the twelve DS1 frames that make up a T1 SF framed circuit. T1 SF framed circuits yield two independent signaling channels (A and B) T1 ESF framed circuits four signaling frames in a twenty four frame extended frame format that yield four independent signaling channels (A, B, C, and D).\nFifty-six kbit/s DS0 channels are associated with digital data service (DDS) services typically do not utilize the eighth bit of the DS0 as voice circuits that employ A&amp;B out of band signaling. One exception is Switched 56\u00a0kbit/s DDS. In DDS, bit eight is used to identify DTE request to send (RTS) condition. With Switched 56 DDS, bit eight is pulsed (alternately set to logical ZERO and ONE) to transmit two state dial pulse signaling information between a SW56 DDS CSU/DSU, and a digital end office switch.\nThe use of robbed-bit signaling in America has decreased significantly as a result of Signaling System No 7 (SS7) on inter-office dial trunks. With SS7, the full 64\u00a0kbit/s DS0 channel is available for use on a connection, and allows 64\u00a0kbit/s, and 128\u00a0kbit/s ISDN data calls to exist over a switched trunk network connection if the supporting T1 carrier entity is optioned B8ZS (Clear Channel Capable).\nCarrier pricing.\nCarriers price DS1 lines in many different ways. However, most boil down to two simple components: local loop (the cost the local incumbent charges to transport the signal from the end user's central office, otherwise known as a CO, to the point of presence, otherwise known as a POP, of the carrier) and the port (the cost to access the telephone network or the Internet through the carrier's network). Typically, the port price is based upon access speed and yearly commitment level while the loop is based on geography. The farther the CO and POP, the more the loop costs.\nThe loop price has several components built into it, including the mileage calculation (performed in V/H coordinates, not standard GPS coordinates) and the telco piece. Each local Bell operating company\u2014namely Verizon, AT&amp;T Inc., and Qwest\u2014charge T-carriers different price per mile rates. Therefore, the price calculation has two distance steps: geomapping and the determination of local price arrangements.\nWhile most carriers utilize a geographic pricing model as described above, some Competitive Local Exchange Carriers (CLECs), such as TelePacific, Integra Telecom, tw telecom, Windstream, Level 3 Communications, and XO Communications offer national pricing.\nUnder this DS1 pricing model, a provider charges the same price in every geography it services. National pricing is an outgrowth of increased competition in the T-carrier market space and the commoditization of T-carrier products. Providers that have adopted a national pricing strategy may experience widely varying margins as their suppliers, the Bell operating companies (e.g., Verizon, AT&amp;T Inc., and Qwest), maintain geographic pricing models, albeit at wholesale prices.\nFor voice DS1 lines, the calculation is mostly the same, except that the port (required for Internet access) is replaced by LDU (otherwise known as Long Distance Usage). Once the price of the loop is determined, only voice-related charges are added to the total. In short, the total price = loop + LDU x minutes used.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "41780", "revid": "11952314", "url": "https://en.wikipedia.org/wiki?curid=41780", "title": "TCP/IP Suite", "text": ""}
{"id": "41781", "revid": "1951353", "url": "https://en.wikipedia.org/wiki?curid=41781", "title": "Technical control facility", "text": "In telecommunications, a technical control facility (TCF) is defined by US Federal Standard 1037C as a telecommunications facility, or a designated and specially configured part thereof, that:"}
{"id": "41782", "revid": "11677590", "url": "https://en.wikipedia.org/wiki?curid=41782", "title": "Telecommunications service", "text": ""}
{"id": "41783", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=41783", "title": "Teleconference", "text": "Live exchange of information among several persons remote from one another\nA teleconference or telecon is a live exchange of information among several people remote from one another but linked by a communications system. Terms such as audio conferencing, telephone conferencing, and phone conferencing are also sometimes used to refer to teleconferencing.\nThe communications system may support the teleconference by providing one or more of the following: audio, video, and/or data services by one or more means, such as telephone, computer, telegraph, teletypewriter, radio, and television.\nInternet teleconferencing.\nInternet teleconferencing includes internet telephone conferencing, videotelephony, web conferencing, virtual workplace, and augmented reality conferencing.\nInternet telephony involves conducting a teleconference over the Internet or a wide area network. One key technology in this area is Voice over Internet Protocol (VOIP).\nA working example of an augmented reality conferencing was demonstrated at the Salone di Mobile in Milano by AR+RFID Lab.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41784", "revid": "47070250", "url": "https://en.wikipedia.org/wiki?curid=41784", "title": "Teletraining", "text": ""}
{"id": "41785", "revid": "48438651", "url": "https://en.wikipedia.org/wiki?curid=41785", "title": "Terminal adapter", "text": "A terminal adapter or TA is a device that connects a terminal device \u2013 a computer, a mobile communications device, or other \u2013 to a communications network.\nISDN.\nIn ISDN terminology, the \"terminal adapter\" connects a \"terminal\" (computer) to the ISDN network. The TA therefore fulfills a similar function to the ones a modem has on the POTS network, and is therefore sometimes called an ISDN modem. The latter term, however, is partially misleading as there is no modulation or demodulation performed.\nThere are devices on the market that combine the functions of an ISDN TA with those of a classical modem (with an ISDN line interface). These combined TA/modems permit connections from both ISDN and analog-line/modem counterparts. In addition, a TA may contain an interface and codec for one or more analog telephone lines (aka \"a/b line\"), allowing an existing POTS installation to be upgraded to ISDN without changing phones.\nTerminal adapters typically connect to a basic rate interface (S0, sometimes also U0). On the \"terminal\" side, the most popular interfaces are RS-232 serial and USB; others like V.35 or RS-449 are only of historical interest.\nDevices connecting ISDN to a network (e.g. Ethernet) commonly include routing functionality; while they technically include a TA function, they are referred to as (ISDN) routers.\nMobile networks.\nIn mobile networks, the \"terminal adapter\" is used by the terminal equipment to access the mobile termination, using AT commands (see Hayes command set).\nIn 2G (such as GSM or CDMA), the terminal adapter is a theoretically optional while in 3G (such as W-CDMA), the terminal adapter is mandatory and is part of the mobile termination.\nAutomation industry.\nIn the automation industry, a \"terminal adapter\" is a \"passive\" device that converts a connector like the 8P8C (RJ-45) modular connector or 9 pin D-Sub into a terminal block to facilitate wiring. It is often used when daisy chain wiring is necessary on a multi-node serial communication network like RS-485 or RS-422."}
{"id": "41786", "revid": "42773290", "url": "https://en.wikipedia.org/wiki?curid=41786", "title": "Terminal equipment", "text": "Term used in telecommunication\nIn telecommunications, the term terminal equipment has the following meanings:\nReferences.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41787", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41787", "title": "Ternary signal", "text": "In telecommunications, a ternary signal is a signal that can assume, at any given instant, one of three states or significant conditions, such as power level, phase position, pulse duration, or frequency.\nExamples of ternary signals are (a) a pulse that can have a positive, zero, or negative voltage value at any given instant (PAM-3), (b) a sine wave that can assume phases of 0\u00b0, 120\u00b0, or 240\u00b0 relative to a clock pulse (3-PSK), and (c) a carrier signal that can assume any one of three different frequencies depending on three different modulation signal significant conditions (3-FM).\nSome examples of PAM-3 line codes that use ternary signals are:\n3-PSK can be seen as falling between \"binary phase-shift keying\" (BPSK), which uses two phases, and \"quadrature phase-shift keying\" (QPSK), which uses four phases.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41788", "revid": "190816", "url": "https://en.wikipedia.org/wiki?curid=41788", "title": "Thermal noise", "text": ""}
{"id": "41789", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=41789", "title": "Thermodynamic temperature", "text": "Measure of temperature relative to absolute zero\nThermodynamic temperature, also known as absolute temperature, is a physical quantity that measures temperature starting from absolute zero, the point at which particles have minimal thermal motion.\nThermodynamic temperature is typically expressed using the Kelvin scale, on which the unit of measurement is the \"kelvin\" (unit symbol: K). This unit is the same interval as the degree Celsius, used on the Celsius scale but the scales are offset so that 0\u00a0K on the Kelvin scale corresponds to absolute zero. For comparison, a temperature of 295\u00a0K corresponds to 21.85\u00a0\u00b0C and 71.33\u00a0\u00b0F. Another absolute scale of temperature is the Rankine scale, which is based on the Fahrenheit degree interval.\nHistorically, thermodynamic temperature was defined by Lord Kelvin in terms of a relation between the macroscopic quantities thermodynamic work and heat transfer as defined in thermodynamics, but the kelvin was redefined by international agreement in 2019 in terms of phenomena that are now understood as manifestations of the kinetic energy of free motion of particles such as atoms, molecules, and electrons.\nOverview.\nThermodynamic temperature can be defined in purely thermodynamic terms using the Carnot cycle. Thermodynamic temperature was rigorously defined historically long before particles such as atoms, molecules, and electrons were fully understood.\nThe International System of Units (SI) specifies the absolute scale for measuring temperature, and the unit of measure \"kelvin\" (symbol: K) for specific values along the scale. A temperature interval of one degree Celsius is the same as one kelvin. Since the 2019 revision of the SI, the kelvin has been defined in relation to the \"physical property\" underlying thermodynamic temperature: the kinetic energy of atomic free particle motion. The revision fixed the Boltzmann constant at exactly .\nThe property that imbues material substances with a temperature can be readily understood by examining the ideal gas law, which relates, through the Boltzmann constant, how heat energy causes precisely defined changes in the pressure and temperature of certain gases. This is because monatomic gases like helium and argon behave kinetically like freely moving perfectly elastic and spherical billiard balls that move only in a specific subset of the possible motions that can occur in matter: that comprising the three \"translational\" degrees of freedom. The translational degrees of freedom are the familiar billiard ball-like movements along the \"x\"-, \"y\"-, and \"z\"-axes of 3D space (see \"Fig.\u00a01\", below). This is why the noble gases all have the same heat capacity per atom and why that value is lowest of all the gases.\nMolecules (two or more chemically bound atoms), however, have \"internal structure\" and therefore have additional \"internal\" degrees of freedom (see \"Fig. 3\", below), which has the effect that molecules absorb more heat energy for any given rise in temperature than do the monatomic gases. Heat energy is born in all available degrees of freedom; this is in accordance with the equipartition theorem, so all available internal degrees of freedom have the same average energy as do their three external degrees of freedom. However, the property that gives all gases their pressure, which is the net force per unit area on a container arising from gas particles recoiling off it, is a function of the kinetic energy borne in the freely moving atoms' and molecules' three translational degrees of freedom.\nFixing the Boltzmann constant at a specific value had the effect of precisely establishing the magnitude of the kelvin in terms of the average kinetic behavior of the noble gases. Moreover, the \"starting point\" of the thermodynamic temperature scale, absolute zero, was reaffirmed as the point at which \"zero average kinetic energy\" remains in a sample; the only remaining particle motion being that comprising random vibrations due to zero-point energy.\nAbsolute zero of temperature.\nTemperature scales are numerical. The numerical zero of a temperature scale is not bound to the absolute zero of temperature. Nevertheless, some temperature scales have their numerical zero coincident with the absolute zero of temperature. Examples are the Kelvin temperature scale and the Rankine temperature scale. Other temperature scales have their numerical zero far from the absolute zero of temperature. Examples are the Celsius scale and the Fahrenheit scale.\nAt the zero point of thermodynamic temperature, absolute zero, the particle constituents of matter have minimal motion and can become no colder. Absolute zero, which is a temperature of zero kelvins (0\u00a0K), precisely corresponds to \u2212273.15\u00a0\u00b0C and \u2212459.67\u00a0\u00b0F. Matter at absolute zero has no remaining transferable average kinetic energy and the only remaining particle motion is due to an ever-pervasive quantum mechanical phenomenon called ZPE (zero-point energy). Though the atoms in, for instance, a container of liquid helium that was \"precisely\" at absolute zero would still jostle slightly due to zero-point energy, a theoretically perfect heat engine with such helium as one of its working fluids could never transfer any net kinetic energy (heat energy) to the other working fluid and no thermodynamic work could occur.\nTemperature is generally expressed in absolute terms when scientifically examining temperature's interrelationships with certain other physical properties of matter such as its volume or pressure (see Gay-Lussac's law), or the wavelength of its emitted black-body radiation. Absolute temperature is also useful when calculating chemical reaction rates (see Arrhenius equation). Furthermore, absolute temperature is typically used in cryogenics and related phenomena like superconductivity, as per the following example usage:\n\"Conveniently, tantalum's transition temperature (\"T\"c) of 4.4924 kelvins is slightly above the 4.2221\u00a0K boiling point of helium.\"\nRankine scale.\nThough there have been many other temperature scales throughout history, there have been only two scales for measuring thermodynamic temperature which have absolute zero as their null point (0): The Kelvin scale and the Rankine scale.\nThroughout the scientific world where modern measurements are nearly always made using the International System of Units, thermodynamic temperature is measured using the Kelvin scale. The Rankine scale is part of English engineering units and finds use in certain engineering fields, particularly in legacy reference works. The Rankine scale uses the \"degree Rankine\" (symbol: \u00b0R) as its unit, which is the same magnitude as the degree Fahrenheit (symbol: \u00b0F).\nA unit increment of one kelvin is exactly 1.8 times one degree Rankine; thus, to convert a specific temperature on the Kelvin scale to the Rankine scale, \"x\" K = 1.8 \"x\" \u00b0R, and to convert from a temperature on the Rankine scale to the Kelvin scale, \"x\" \u00b0R = \"x\"/1.8 K. Consequently, absolute zero is \"0\" for both scales, but the melting point of water ice (0\u00a0\u00b0C and 273.15\u00a0K) is 491.67\u00a0\u00b0R.\nTo convert temperature \"intervals\" (a span or difference between two temperatures), the formulas from the preceding paragraph are applicable; for instance, an interval of 5 kelvins is precisely equal to an interval of 9 degrees Rankine.\nModern redefinition of the kelvin.\nFor 65 years, between 1954 and the 2019 revision of the SI, a temperature interval of one kelvin was defined as of the temperature difference between the triple point of water and absolute zero. The 1954 resolution by the International Bureau of Weights and Measures (BIPM), plus later resolutions and publications, defined the triple point of water as precisely 273.16\u00a0K and acknowledged that it was \"common practice\" to accept that due to previous conventions (namely, that 0\u00a0\u00b0C had long been defined as the melting point of water and that the triple point of water had long been experimentally determined to be indistinguishably close to 0.01\u00a0\u00b0C), the difference between the Celsius scale and Kelvin scale is accepted as 273.15\u00a0K; which is to say, 0\u00a0\u00b0C corresponds to 273.15\u00a0K. The net effect of this as well as later resolutions was twofold: 1) they defined absolute zero as precisely 0\u00a0K, and 2) they defined that the triple point of special isotopically controlled water called Vienna Standard Mean Ocean Water occurred at precisely 273.16\u00a0K and 0.01\u00a0\u00b0C. One effect of the aforementioned resolutions was that the melting point of water, while \"very\" close to 273.15\u00a0K and 0\u00a0\u00b0C, was not a defining value and was subject to refinement with more precise measurements.\nThe 1954 BIPM standard did a good job of establishing\u2014within the uncertainties due to isotopic variations between water samples\u2014temperatures around the freezing and triple points of water, but required that \"intermediate values\" between the triple point and absolute zero, as well as extrapolated values from room temperature and beyond, to be experimentally determined via apparatus and procedures in individual labs. This shortcoming was addressed by the International Temperature Scale of 1990, or ITS\u201190, which defined 13 additional points, from 13.8033\u00a0K, to 1,357.77\u00a0K. While definitional, ITS\u201190 had\u2014and still has\u2014some challenges, partly because eight of its extrapolated values depend upon the melting or freezing points of metal samples, which must remain exceedingly pure lest their melting or freezing points be affected\u2014usually depressed.\nThe 2019 revision of the SI was primarily for the purpose of decoupling much of the SI system's definitional underpinnings from the kilogram, which was the last physical artifact defining an SI base unit (a platinum/iridium cylinder stored under three nested bell jars in a safe located in France) and which had highly questionable stability. The solution required that four physical constants, including the Boltzmann constant, be definitionally fixed.\nAssigning the Boltzmann constant a precisely defined value had no practical effect on modern thermometry except for the most exquisitely precise measurements. Before the revision, the triple point of water was exactly 273.16\u00a0K and 0.01\u00a0\u00b0C and the Boltzmann constant was experimentally determined to be , where the \"(51)\" denotes the uncertainty in the two least significant digits (the 03) and equals a relative standard uncertainty of 0.37\u00a0ppm. Afterwards, by defining the Boltzmann constant as exactly , the 0.37\u00a0ppm uncertainty was transferred to the triple point of water, which became an experimentally determined value of (). That the triple point of water ended up being exceedingly close to 273.16\u00a0K after the SI revision was no accident; the final value of the Boltzmann constant was determined, in part, through clever experiments with argon and helium that used the triple point of water for their key reference temperature.\nNotwithstanding the 2019 revision, water triple-point cells continue to serve in modern thermometry as exceedingly precise calibration references at 273.16\u00a0K and 0.01\u00a0\u00b0C. Moreover, the triple point of water remains one of the 14 calibration points comprising ITS\u201190, which spans from the triple point of hydrogen (13.8033\u00a0K) to the freezing point of copper (1,357.77\u00a0K), which is a nearly hundredfold range of thermodynamic temperature.\nRelationship of temperature, motions, conduction, and thermal energy.\nNature of kinetic energy, translational motion, and temperature.\nThe thermodynamic temperature of any \"bulk quantity\" of a substance (a statistically significant quantity of particles) is directly proportional to the mean average kinetic energy of a specific kind of particle motion known as \"translational motion\". These simple movements in the three \"x\"-, \"y\"-, and \"z\"-axes dimensions of space means the particles move in the three spatial \"degrees of freedom\". This particular form of kinetic energy is sometimes referred to as \"kinetic temperature\". Translational motion is but one form of heat energy and is what gives gases not only their temperature, but also their pressure and the vast majority of their volume. This relationship between the temperature, pressure, and volume of gases is established by the ideal gas law's formula \"pV\" = \"nRT\" and is embodied in the gas laws.\nThough the kinetic energy borne exclusively in the three translational degrees of freedom comprise the thermodynamic temperature of a substance, molecules, as can be seen in \"Fig.\u00a03\", can have other degrees of freedom, all of which fall under three categories: bond length, bond angle, and rotational. All three additional categories are not necessarily available to all molecules, and even for molecules that \"can\" experience all three, some can be \"frozen out\" below a certain temperature. Nonetheless, all those degrees of freedom that are available to the molecules under a particular set of conditions contribute to the specific heat capacity of a substance; which is to say, they increase the amount of heat (kinetic energy) required to raise a given amount of the substance by one kelvin or one degree Celsius.\nThe relationship of kinetic energy, mass, and velocity is given by the formula \"E\"k\u00a0=\u00a0\"mv\"2. Accordingly, particles with one unit of mass moving at one unit of velocity have precisely the same kinetic energy, and precisely the same temperature, as those with four times the mass but half the velocity.\nThe Boltzmann constant relates the thermodynamic temperature of a gas to the mean kinetic energy of a particle's translational motion:\nformula_1\nwhere:\nWhile the Boltzmann constant is useful for finding the mean kinetic energy in a sample of particles, it is important to note that even when a substance is isolated and in thermodynamic equilibrium (all parts are at a uniform temperature and no heat is going into or out of it), the translational motions of individual atoms and molecules occurs across a wide range of speeds (see animation in \"Fig.\u00a01\" above). At any one instant, the proportion of particles moving at a given speed within this range is determined by probability as described by the Maxwell\u2013Boltzmann distribution. The graph shown here in \"Fig.\u00a02\" shows the speed distribution of 5500\u00a0K helium atoms. They have a \"most probable\" speed of 4.780\u00a0km/s (0.2092\u00a0s/km). However, a certain proportion of atoms at any given instant are moving faster while others are moving relatively slowly; some are momentarily at a virtual standstill (off the \"x\"-axis to the right). This graph uses \"inverse speed\" for its \"x\"-axis so the shape of the curve can easily be compared to the curves in \"\" below. In both graphs, zero on the \"x\"-axis represents infinite temperature. Additionally, the \"x\"- and \"y\"-axes on both graphs are scaled proportionally.\nHigh speeds of translational motion.\nAlthough very specialized laboratory equipment is required to directly detect translational motions, the resultant collisions by atoms or molecules with small particles suspended in a fluid produces Brownian motion that can be seen with an ordinary microscope. The translational motions of elementary particles are \"very\" fast and temperatures close to absolute zero are required to directly observe them. For instance, when scientists at the NIST achieved a record-setting low temperature of 700\u00a0nK (billionths of a kelvin) in 1994, they used optical lattice laser equipment to adiabatically cool cesium atoms. They then turned off the entrapment lasers and directly measured atom velocities of 7\u00a0mm per second in order to calculate their temperature. Formulas for calculating the velocity and speed of translational motion are given in the following footnote.\nIt is neither difficult to imagine atomic motions due to kinetic temperature, nor distinguish between such motions and those due to zero-point energy. Consider the following hypothetical thought experiment, as illustrated in \"Fig.\u00a02.5\" at left, with an atom that is exceedingly close to absolute zero. Imagine peering through a common optical microscope set to 400 power, which is about the maximum practical magnification for optical microscopes. Such microscopes generally provide fields of view a bit over 0.4\u00a0mm in diameter. At the center of the field of view is a single levitated argon atom (argon comprises about 0.93% of air) that is illuminated and glowing against a dark backdrop. If this argon atom was at a beyond-record-setting \"one-trillionth\" of a kelvin above absolute zero, and was moving perpendicular to the field of view towards the right, it would require 13.9 seconds to move from the center of the image to the 200\u00a0\u03bcm tick mark; this travel distance is about the same as the width of the period at the end of this sentence on modern computer monitors. As the argon atom slowly moved, the positional jitter due to zero-point energy would be much less than the 200\u00a0nm (0.0002\u00a0mm) resolution of an optical microscope. Importantly, the atom's translational velocity of 14.43\u00a0\u03bcm/s constitutes all its retained kinetic energy due to not being precisely at absolute zero. Were the atom \"precisely\" at absolute zero, imperceptible jostling due to zero-point energy would cause it to very slightly wander, but the atom would perpetually be located, on average, at the same spot within the field of view. This is analogous to a boat that has had its motor turned off and is now bobbing slightly in relatively calm and windless ocean waters; even though the boat randomly drifts to and fro, it stays in the same spot in the long term and makes no headway through the water. Accordingly, an atom that was precisely at absolute zero would not be \"motionless\", and yet, a statistically significant collection of such atoms would have zero net kinetic energy available to transfer to any other collection of atoms. This is because regardless of the kinetic temperature of the second collection of atoms, they too experience the effects of zero-point energy. Such are the consequences of statistical mechanics and the nature of thermodynamics.\nInternal motions of molecules and internal energy.\nAs mentioned above, there are other ways molecules can jiggle besides the three translational degrees of freedom that imbue substances with their kinetic temperature. As can be seen in the animation at right, molecules are complex objects; they are a population of atoms and thermal agitation can strain their internal chemical bonds in three different ways: via rotation, bond length, and bond angle movements; these are all types of \"internal degrees of freedom\". This makes molecules distinct from \"monatomic\" substances (consisting of individual atoms) like the noble gases helium and argon, which have only the three translational degrees of freedom (the \"x\"-, \"y\"-, and \"z\"-axes). Kinetic energy is stored in molecules' internal degrees of freedom, which gives them an \"internal temperature\". Even though these motions are called \"internal\", the external portions of molecules still move\u2014rather like the jiggling of a stationary water balloon. This permits the two-way exchange of kinetic energy between internal motions and translational motions with each molecular collision. Accordingly, as internal energy is removed from molecules, both their kinetic temperature (the kinetic energy of translational motion) and their internal temperature simultaneously diminish in equal proportions. This phenomenon is described by the equipartition theorem, which states that for any bulk quantity of a substance in equilibrium, the kinetic energy of particle motion is evenly distributed among all the active degrees of freedom available to the particles. Since the internal temperature of molecules are usually equal to their kinetic temperature, the distinction is usually of interest only in the detailed study of non-local thermodynamic equilibrium (LTE) phenomena such as combustion, the sublimation of solids, and the diffusion of hot gases in a partial vacuum.\nThe kinetic energy stored internally in molecules causes substances to contain more heat energy at any given temperature and to absorb additional internal energy for a given temperature increase. This is because any kinetic energy that is, at a given instant, bound in internal motions, is not contributing to the molecules' translational motions at that same instant. This extra kinetic energy simply increases the amount of internal energy that substance absorbs for a given temperature rise. This property is known as a substance's specific heat capacity.\nDifferent molecules absorb different amounts of internal energy for each incremental increase in temperature; that is, they have different specific heat capacities. High specific heat capacity arises, in part, because certain substances' molecules possess more internal degrees of freedom than others do. For instance, room-temperature nitrogen, which is a diatomic molecule, has \"five\" active degrees of freedom: the three comprising translational motion plus two rotational degrees of freedom internally. Not surprisingly, in accordance with the equipartition theorem, nitrogen has five-thirds the specific heat capacity per mole (a specific number of molecules) as do the monatomic gases. Another example is gasoline (see table showing its specific heat capacity). Gasoline can absorb a large amount of heat energy per mole with only a modest temperature change because each molecule comprises an average of 21 atoms and therefore has many internal degrees of freedom. Even larger, more complex molecules can have dozens of internal degrees of freedom.\nDiffusion of thermal energy: entropy, phonons, and mobile conduction electrons.\n\"Heat conduction\" is the diffusion of thermal energy from hot parts of a system to cold parts. A system can be either a single bulk entity or a plurality of discrete bulk entities. The term \"bulk\" in this context means a statistically significant quantity of particles (which can be a microscopic amount). Whenever thermal energy diffuses within an isolated system, temperature differences within the system decrease (and entropy increases).\nOne particular heat conduction mechanism occurs when translational motion, the particle motion underlying temperature, transfers momentum from particle to particle in collisions. In gases, these translational motions are of the nature shown above in \"Fig.\u00a01\". As can be seen in that animation, not only does momentum (heat) diffuse throughout the volume of the gas through serial collisions, but entire molecules or atoms can move forward into new territory, bringing their kinetic energy with them. Consequently, temperature differences equalize throughout gases very quickly\u2014especially for light atoms or molecules; convection speeds this process even more.\nTranslational motion in \"solids\", however, takes the form of \"phonons\" (see \"Fig.\u00a04\" at right). Phonons are constrained, quantized wave packets that travel at the speed of sound of a given substance. The manner in which phonons interact within a solid determines a variety of its properties, including its thermal conductivity. In electrically insulating solids, phonon-based heat conduction is \"usually\" inefficient and such solids are considered \"thermal insulators\" (such as glass, plastic, rubber, ceramic, and rock). This is because in solids, atoms and molecules are locked into place relative to their neighbors and are not free to roam.\nMetals however, are not restricted to only phonon-based heat conduction. Thermal energy conducts through metals extraordinarily quickly because instead of direct molecule-to-molecule collisions, the vast majority of thermal energy is mediated via very light, mobile \"conduction electrons\". This is why there is a near-perfect correlation between metals' thermal conductivity and their electrical conductivity. Conduction electrons imbue metals with their extraordinary conductivity because they are \"delocalized\" (i.e., not tied to a specific atom) and behave rather like a sort of quantum gas due to the effects of \"zero-point energy\" (for more on ZPE, see \"Note 1\" below). Furthermore, electrons are relatively light with a rest mass only &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20441836 that of a proton. As Isaac Newton wrote with his third law of motion,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Law #3: All forces occur in pairs, and these two forces are equal in magnitude and opposite in direction.\nHowever, a bullet accelerates faster than a rifle given an equal force. Since kinetic energy increases as the square of velocity, nearly all the kinetic energy goes into the bullet, not the rifle, even though both experience the same force from the expanding propellant gases. In the same manner, because they are much less massive, thermal energy is readily borne by mobile conduction electrons. Additionally, because they are delocalized and \"very\" fast, kinetic thermal energy conducts extremely quickly through metals with abundant conduction electrons.\nDiffusion of thermal energy: black-body radiation.\nThermal radiation is a byproduct of the collisions arising from various vibrational motions of atoms. These collisions cause the electrons of the atoms to emit thermal photons (known as black-body radiation). Photons are emitted anytime an electric charge is accelerated (as happens when electron clouds of two atoms collide). Even \"individual molecules\" with internal temperatures greater than absolute zero also emit black-body radiation from their atoms. In any bulk quantity of a substance at equilibrium, black-body photons are emitted across a range of wavelengths in a spectrum that has a bell curve-like shape called a Planck curve (see graph in \"Fig.\u00a05\" at right). The top of a Planck curve (the peak emittance wavelength) is located in a particular part of the electromagnetic spectrum depending on the temperature of the black-body. Substances at extreme cryogenic temperatures emit at long radio wavelengths whereas extremely hot temperatures produce short gamma rays (see ).\nBlack-body radiation diffuses thermal energy throughout a substance as the photons are absorbed by neighboring atoms, transferring momentum in the process. Black-body photons also easily escape from a substance and can be absorbed by the ambient environment; kinetic energy is lost in the process.\nAs established by the Stefan\u2013Boltzmann law, the intensity of black-body radiation increases as the fourth power of absolute temperature. Thus, a black-body at 824\u00a0K (just short of glowing dull red) emits 60 times the radiant power as it does at 296\u00a0K (room temperature). This is why one can so easily feel the radiant heat from hot objects at a distance. At higher temperatures, such as those found in an incandescent lamp, black-body radiation can be the principal mechanism by which thermal energy escapes a system.\nTable of thermodynamic temperatures.\nThe table below shows various points on the thermodynamic scale, in order of increasing temperature.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nHeat of phase changes.\nThe kinetic energy of particle motion is just one contributor to the total thermal energy in a substance; another is \"phase transitions\", which are the potential energy of molecular bonds that can form in a substance as it cools (such as during condensing and freezing). The thermal energy required for a phase transition is called \"latent heat\". This phenomenon may more easily be grasped by considering it in the reverse direction: latent heat is the energy required to \"break\" chemical bonds (such as during evaporation and melting). Almost everyone is familiar with the effects of phase transitions; for instance, steam at 100\u00a0\u00b0C can cause severe burns much faster than the 100\u00a0\u00b0C air from a hair dryer. This occurs because a large amount of latent heat is liberated as steam condenses into liquid water on the skin.\nEven though thermal energy is liberated or absorbed during phase transitions, pure chemical elements, compounds, and eutectic alloys exhibit no temperature change whatsoever while they undergo them (see \"Fig.\u00a07\", below right). Consider one particular type of phase transition: melting. When a solid is melting, crystal lattice chemical bonds are being broken apart; the substance is transitioning from what is known as a \"more ordered state\" to a \"less ordered state\". In \"Fig.\u00a07\", the melting of ice is shown within the lower left box heading from blue to green.\nAt one specific thermodynamic point, the melting point (which is 0\u00a0\u00b0C across a wide pressure range in the case of water), all the atoms or molecules are, on average, at the maximum energy threshold their chemical bonds can withstand without breaking away from the lattice. Chemical bonds are all-or-nothing forces: they either hold fast, or break; there is no in-between state. Consequently, when a substance is at its melting point, every joule of added thermal energy only breaks the bonds of a specific quantity of its atoms or molecules, converting them into a liquid of precisely the same temperature; no kinetic energy is added to translational motion (which is what gives substances their temperature). The effect is rather like popcorn: at a certain temperature, additional thermal energy cannot make the kernels any hotter until the transition (popping) is complete. If the process is reversed (as in the freezing of a liquid), thermal energy must be removed from a substance.\nAs stated above, the thermal energy required for a phase transition is called \"latent heat\". In the specific cases of melting and freezing, it is called \"enthalpy of fusion\" or \"heat of fusion\". If the molecular bonds in a crystal lattice are strong, the heat of fusion can be relatively great, typically in the range of 6 to 30\u00a0kJ per mole for water and most of the metallic elements. If the substance is one of the monatomic gases (which have little tendency to form molecular bonds) the heat of fusion is more modest, ranging from 0.021 to 2.3\u00a0kJ per mole. Relatively speaking, phase transitions can be truly energetic events. To completely melt ice at 0\u00a0\u00b0C into water at 0\u00a0\u00b0C, one must add roughly 80 times the thermal energy as is required to increase the temperature of the same mass of liquid water by one degree Celsius. The metals' ratios are even greater, typically in the range of 400 to 1200 times. The phase transition of boiling is much more energetic than freezing. For instance, the energy required to completely boil or vaporize water (what is known as \"enthalpy of vaporization\") is roughly 540 times that required for a one-degree increase.\nWater's sizable enthalpy of vaporization is why one's skin can be burned so quickly as steam condenses on it (heading from red to green in \"Fig.\u00a07\"\u00a0above); water vapors (gas phase) are liquefied on the skin with releasing a large amount of energy (enthalpy) to the environment including the skin, resulting in skin damage. In the opposite direction, this is why one's skin feels cool as liquid water on it evaporates (a process that occurs at a sub-ambient wet-bulb temperature that is dependent on relative humidity); the water evaporation on the skin takes a large amount of energy from the environment including the skin, reducing the skin temperature. Water's highly energetic enthalpy of vaporization is also an important factor underlying why \"solar pool covers\" (floating, insulated blankets that cover swimming pools when the pools are not in use) are so effective at reducing heating costs: they prevent evaporation. (In other words, taking energy from water when it is evaporated is limited.) For instance, the evaporation of just 20\u00a0mm of water from a 1.29\u00a0m-deep pool chills its water .\nInternal energy.\nThe total energy of all translational and internal particle motions, including that of conduction electrons, plus the potential energy of phase changes, plus zero-point energy of a substance comprise the \"internal energy\" of it.\nInternal energy at absolute zero.\nAs a substance cools, different forms of internal energy and their related effects simultaneously decrease in magnitude: the latent heat of available phase transitions is liberated as a substance changes from a less ordered state to a more ordered state; the translational motions of atoms and molecules diminish (their kinetic energy or temperature decreases); the internal motions of molecules diminish (their internal energy or temperature decreases); conduction electrons (if the substance is an electrical conductor) travel \"somewhat\" slower; and black-body radiation's peak emittance wavelength increases (the photons' energy decreases). When particles of a substance are as close as possible to complete rest and retain only ZPE (zero-point energy)-induced quantum mechanical motion, the substance is at the temperature of absolute zero (T\u00a0=\u00a00).\nWhereas absolute zero is the point of zero thermodynamic temperature and is also the point at which the particle constituents of matter have minimal motion, absolute zero is not necessarily the point at which a substance contains zero internal energy; one must be very precise with what one means by \"internal energy\". Often, all the phase changes that \"can\" occur in a substance, \"will\" have occurred by the time it reaches absolute zero. However, this is not always the case. Notably, T\u00a0=\u00a00 helium remains liquid at room pressure (\"Fig.\u00a09\" at right) and must be under a pressure of at least to crystallize. This is because helium's heat of fusion (the energy required to melt helium ice) is so low (only 21\u00a0joules\u00a0per\u00a0mole) that the motion-inducing effect of zero-point energy is sufficient to prevent it from freezing at lower pressures.\nA further complication is that many solids change their crystal structure to more compact arrangements at extremely high pressures (up to millions of bars, or hundreds of gigapascals). These are known as \"solid\u2013solid phase transitions\" wherein latent heat is liberated as a crystal lattice changes to a more thermodynamically favorable, compact one.\nThe above complexities make for rather cumbersome blanket statements regarding the internal energy in T\u00a0=\u00a00 substances. Regardless of pressure though, what \"can\" be said is that at absolute zero, all solids with a lowest-energy crystal lattice such those with a \"closest-packed arrangement\" (see \"Fig.\u00a08\", above left) contain minimal internal energy, retaining only that due to the ever-present background of zero-point energy. One can also say that for a given substance at constant pressure, absolute zero is the point of lowest \"enthalpy\" (a measure of work potential that takes internal energy, pressure, and volume into consideration). Lastly, all T\u00a0=\u00a00 substances contain zero kinetic thermal energy.\nPractical applications for thermodynamic temperature.\nThermodynamic temperature is useful not only for scientists, it can also be useful for lay-people in many disciplines involving gases. By expressing variables in absolute terms and applying Gay-Lussac's law of temperature/pressure proportionality, solutions to everyday problems are straightforward; for instance, calculating how a temperature change affects the pressure inside an automobile tire. If the tire has a cold gage pressure of 200\u00a0kPa, then its absolute pressure is 300\u00a0kPa. Room temperature (\"cold\" in tire terms) is 296\u00a0K. If the tire temperature is 20\u00a0\u00b0C hotter (20\u00a0kelvins), the solution is calculated as \u00a0= 6.8% greater thermodynamic temperature \"and\" absolute pressure; that is, an absolute pressure of 320\u00a0kPa, which is a gage pressure of 220\u00a0kPa.\nRelationship to ideal gas law.\nThe thermodynamic temperature is closely linked to the ideal gas law and its consequences. It can be linked also to the second law of thermodynamics. The thermodynamic temperature can be shown to have special properties, and in particular can be seen to be uniquely defined (up to some constant multiplicative factor) by considering the efficiency of idealized heat engines. Thus the ratio \"T\"2/\"T\"1 of two temperatures \"T\"1 and \"T\"2 is the same in all absolute scales.\nStrictly speaking, the temperature of a system is well-defined only if it is at thermal equilibrium. From a microscopic viewpoint, a material is at thermal equilibrium if the quantity of heat between its individual particles cancel out. There are many possible scales of temperature, derived from a variety of observations of physical phenomena.\nLoosely stated, temperature differences dictate the direction of heat between two systems such that their combined energy is maximally distributed among their lowest possible states. We call this distribution \"entropy\". To better understand the relationship between temperature and entropy, consider the relationship between heat, work and temperature illustrated in the Carnot heat engine. The engine converts heat into work by directing a temperature gradient between a higher temperature heat source, \"T\"H, and a lower temperature heat sink, \"T\"C, through a gas filled piston. The work done per cycle is equal in magnitude to net heat taken up, which is sum of the heat \"q\"H taken up by the engine from the high-temperature source, plus the waste heat given off by the engine, \"q\"C &lt; 0. The \"efficiency\" of the engine is the work divided by the heat put into the system or\nformula_3\nwhere formula_4 is the work done per cycle. Thus the efficiency depends only on .\nCarnot's theorem states that all reversible engines operating between the same heat reservoirs are equally efficient. Thus, any reversible heat engine operating between temperatures \"T\"1 and \"T\"2 must have the same efficiency, that is to say, the efficiency is the function of only temperatures\nformula_5\nIn addition, a reversible heat engine operating between a pair of thermal reservoirs at temperatures \"T\"1 and \"T\"3 must have the same efficiency as one consisting of two cycles, one between \"T\"1 and another (intermediate) temperature \"T\"2, and the second between \"T\"2 and \"T\"3. If this were not the case, then energy (in the form of q) will be wasted or gained, resulting in different overall efficiencies every time a cycle is split into component cycles; clearly a cycle can be composed of any number of smaller cycles as an engine design choice, and any reversible engine between the same reservoir at \"T\"1 and \"T\"3 must be equally efficient regardless of the engine design.\nIf we choose engines such that work done by the one cycle engine and the two cycle engine are same, then the efficiency of each heat engine is written as below.\nformula_6\nHere, the engine 1 is the one cycle engine, and the engines 2 and 3 make the two cycle engine where there is the intermediate reservoir at \"T\"2. We also have used the fact that the heat formula_7 passes through the intermediate thermal reservoir at formula_8 without losing its energy. (I.e., formula_7 is not lost during its passage through the reservoir at formula_8.) This fact can be proved by the following.\nformula_11\nIn order to have the consistency in the last equation, the heat formula_7 flown from the engine 2 to the intermediate reservoir must be equal to the heat formula_13 flown out from the reservoir to the engine 3.\nWith this understanding of \"q\"1, \"q\"2 and \"q\"3, mathematically,\nformula_14\nBut since the first function is \"not\" a function of \"T\"2, the product of the final two functions \"must\" result in the removal of \"T\"2 as a variable. The only way is therefore to define the function f as follows:\nformula_15\nand\nformula_16\nso that\nformula_17\nI.e. the ratio of heat exchanged is a function of the respective temperatures at which they occur. We can choose any monotonic function for our formula_18; it is a matter of convenience and convention that we choose formula_19. Choosing then \"one\" fixed reference temperature (i.e. triple point of water), we establish the thermodynamic temperature scale.\nSuch a definition coincides with that of the ideal gas derivation; also it is this \"definition\" of the thermodynamic temperature that enables us to represent the Carnot efficiency in terms of \"T\"H and \"T\"C, and hence derive that the (complete) Carnot cycle is isentropic:\nformula_20\nSubstituting this back into our first formula for efficiency yields a relationship in terms of temperature:\nformula_21\nNote that for \"T\"C = 0 the efficiency is 100% and that efficiency becomes greater than 100% for \"T\"C &lt; 0, which is unrealistic. Subtracting 1 from the right hand side of the Equation (4) and the middle portion gives formula_22 and thus \nformula_23\nThe generalization of this equation is the Clausius theorem, which proposes the existence of a state function formula_24 (i.e., a function which depends only on the state of the system, not on how it reached that state) defined (up to an additive constant) by\nformula_25\nwhere the subscript \"rev\" indicates heat transfer in a reversible process. The function formula_24 is the entropy of the system, mentioned previously, and the change of formula_24 around any cycle is zero (as is necessary for any state function). The Equation 5 can be rearranged to get an alternative definition for temperature in terms of entropy and heat (to avoid a logic loop, we should first define entropy through statistical mechanics):\nformula_28\nFor a constant-volume system (so no mechanical work formula_29) in which the entropy formula_24 is a function formula_31 of its internal energy formula_32, formula_33 and the thermodynamic temperature formula_34 is therefore given by\nformula_35\nso that the reciprocal of the thermodynamic temperature is the rate of change of entropy with respect to the internal energy at the constant volume.\nHistory.\nGuillaume Amontons (1663\u20131705) published two papers in 1702 and 1703 that may be used to credit him as being the first researcher to deduce the existence of a fundamental (thermodynamic) temperature scale featuring an absolute zero. He made the discovery while endeavoring to improve upon the air thermometers in use at the time. His J-tube thermometers comprised a mercury column that was supported by a fixed mass of air entrapped within the sensing portion of the thermometer. In thermodynamic terms, his thermometers relied upon the volume / temperature relationship of gas under constant pressure. His measurements of the boiling point of water and the melting point of ice showed that regardless of the mass of air trapped inside his thermometers or the weight of mercury the air was supporting, the reduction in air volume at the ice point was always the same ratio. This observation led him to posit that a sufficient reduction in temperature would reduce the air volume to zero. In fact, his calculations projected that absolute zero was equivalent to \u2212240\u00a0\u00b0C\u2014only 33.15 degrees short of the true value of \u2212273.15\u00a0\u00b0C. Amonton's discovery of a one-to-one relationship between absolute temperature and absolute pressure was rediscovered a century later and popularized within the scientific community by Joseph Louis Gay-Lussac. Today, this principle of thermodynamics is commonly known as \"Gay-Lussac's law\" but is also known as \"Amonton's law\".\nIn 1742, Anders Celsius (1701\u20131744) created a \"backwards\" version of the modern Celsius temperature scale. In Celsius's original scale, zero represented the boiling point of water and 100 represented the melting point of ice. In his paper \"Observations of two persistent degrees on a thermometer\", he recounted his experiments showing that ice's melting point was effectively unaffected by pressure. He also determined with remarkable precision how water's boiling point varied as a function of atmospheric pressure. He proposed that zero on his temperature scale (water's boiling point) would be calibrated at the mean barometric pressure at mean sea level.\nCoincident with the death of Anders Celsius in 1744, the botanist Carl Linnaeus (1707\u20131778) effectively reversed Celsius's scale upon receipt of his first thermometer featuring a scale where zero represented the melting point of ice and 100 represented water's boiling point. The custom-made \"Linnaeus-thermometer\", for use in his greenhouses, was made by Daniel Ekstr\u00f6m, Sweden's leading maker of scientific instruments at the time. For the next 204 years, the scientific and thermometry communities worldwide referred to this scale as the \"centigrade scale\". Temperatures on the centigrade scale were often reported simply as \"degrees\" or, when greater specificity was desired, \"degrees centigrade\". The symbol for temperature values on this scale was \u00b0C (in several formats over the years). Because the term \"centigrade\" was also the French-language name for a unit of angular measurement (one-hundredth of a right angle) and had a similar connotation in other languages, the term \"centesimal degree\" was used when very precise, unambiguous language was required by international standards bodies such as the International Bureau of Weights and Measures (BIPM). The 9th CGPM (General Conference on Weights and Measures and the CIPM (International Committee for Weights and Measures formally adopted \"degree Celsius\" (symbol: \u00b0C) in 1948.\nIn his book \"Pyrometrie\" (1777) completed four months before his death, Johann Heinrich Lambert (1728\u20131777), sometimes incorrectly referred to as Joseph Lambert, proposed an absolute temperature scale based on the pressure/temperature relationship of a fixed volume of gas. This is distinct from the volume/temperature relationship of gas under constant pressure that Guillaume Amontons discovered 75 years earlier. Lambert stated that absolute zero was the point where a simple straight-line extrapolation reached zero gas pressure and was equal to \u2212270\u00a0\u00b0C.\nNotwithstanding the work of Guillaume Amontons 85 years earlier, Jacques Alexandre C\u00e9sar Charles (1746\u20131823) is often credited with discovering (circa 1787), but not publishing, that the volume of a gas under constant pressure is proportional to its absolute temperature. The formula he created was \"V\"1/\"T\"1 = \"V\"2/\"T\"2.\nJoseph Louis Gay-Lussac (1778\u20131850) published work in 1802 (acknowledging the unpublished lab notes of Jacques Charles fifteen years earlier) describing how the volume of gas under constant pressure changes linearly with its absolute (thermodynamic) temperature. This behavior is called Charles's law and is one of the gas laws. His are the first known formulas to use the number 273 for the expansion coefficient of gas relative to the melting point of ice (indicating that absolute zero was equivalent to \u2212273\u00a0\u00b0C).\nWilliam Thomson (1824\u20131907), also known as Lord Kelvin, wrote in his 1848 paper \"On an Absolute Thermometric Scale\" of the need for a scale whereby \"infinite cold\" (absolute zero) was the scale's zero point, and which used the degree Celsius for its unit increment. Like Gay-Lussac, Thomson calculated that absolute zero was equivalent to \u2212273\u00a0\u00b0C on the air thermometers of the time. This absolute scale is known today as the Kelvin thermodynamic temperature scale. Thomson's value of \u2212273 was derived from 0.00366, which was the accepted expansion coefficient of gas per degree Celsius relative to the ice point. The inverse of \u22120.00366 expressed to five significant digits is \u2212273.22\u00a0\u00b0C which is remarkably close to the true value of \u2212273.15\u00a0\u00b0C.\nIn the paper he proposed to define temperature using idealized heat engines. In detail, he proposed that, given three heat reservoirs at temperatures formula_36, if two reversible heat engines (Carnot engine), one working between formula_37 and another between formula_38, can produce the same amount of mechanical work formula_29 by letting the same amount of heat formula_40 pass through, then define formula_41.\nNote that like Carnot, Kelvin worked under the assumption that heat is conserved (\"the conversion of heat (or caloric) into mechanical effect is probably impossible\"), and if heat formula_40 goes into the heat engine, then heat formula_40 must come out.\nKelvin, realizing after Joule's experiments that heat is not a conserved quantity but is convertible with mechanical work, modified his scale in the 1851 work \"An Account of Carnot's Theory of the Motive Power of Heat\". In this work, he defined as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe above definition fixes the ratios between absolute temperatures, but it does not fix a scale for absolute temperature. For the scale, Thomson proposed to use the Celsius degree, that is, formula_44 the interval between the freezing and the boiling point of water.\nIn 1859 Macquorn Rankine (1820\u20131872) proposed a thermodynamic temperature scale similar to William Thomson's but which used the degree Fahrenheit for its unit increment, that is, formula_45 the interval between the freezing and the boiling point of water. This absolute scale is known today as the Rankine thermodynamic temperature scale.\nLudwig Boltzmann (1844\u20131906) made major contributions to thermodynamics between 1877 and 1884 through an understanding of the role that particle kinetics and black body radiation played. His name is now attached to several of the formulas used today in thermodynamics.\nGas thermometry experiments carefully calibrated to the melting point of ice and boiling point of water showed in the 1930s that absolute zero was equivalent to \u2212273.15\u00a0\u00b0C.\nResolution 3 of the 9th General Conference on Weights and Measures (CGPM) in 1948 fixed the triple point of water at precisely 0.01\u00a0\u00b0C. At this time, the triple point still had no formal definition for its equivalent kelvin value, which the resolution declared \"will be fixed at a later date\". The implication is that if the value of absolute zero measured in the 1930s was truly \u2212273.15\u00a0\u00b0C, then the triple point of water (0.01\u00a0\u00b0C) was equivalent to 273.16\u00a0K. Additionally, both the International Committee for Weights and Measures (CIPM) and the CGPM formally adopted the name \"Celsius\" for the \"degree Celsius\" and the \"Celsius temperature scale\".\nResolution 3 of the 10th CGPM in 1954 gave the Kelvin scale its modern definition by choosing the triple point of water as its upper defining point (with no change to absolute zero being the null point) and assigning it a temperature of precisely 273.16\u00a0kelvins (what was actually written 273.16 \"degrees Kelvin\" at the time). This, in combination with Resolution 3 of the 9th CGPM, had the effect of defining absolute zero as being precisely zero kelvins and \u2212273.15\u00a0\u00b0C.\nResolution 3 of the 13th CGPM in 1967/1968 renamed the unit increment of thermodynamic temperature \"kelvin\", symbol K, replacing \"degree absolute\", symbol \u00b0K. Further, feeling it useful to more explicitly define the magnitude of the unit increment, the 13th CGPM also decided in Resolution 4 that \"The kelvin, unit of thermodynamic temperature, is the fraction 1/273.16 of the thermodynamic temperature of the triple point of water\".\nThe CIPM affirmed in 2005 that for the purposes of delineating the temperature of the triple point of water, the definition of the Kelvin thermodynamic temperature scale would refer to water having an isotopic composition defined as being precisely equal to the nominal specification of Vienna Standard Mean Ocean Water.\nIn November 2018, the 26th General Conference on Weights and Measures (CGPM) changed the definition of the Kelvin by fixing the Boltzmann constant to when expressed in the unit J/K. This change (and other changes in the definition of SI units) was made effective on the 144th anniversary of the Metre Convention, 20 May 2019.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n \"In the following notes, wherever numeric equalities are shown in \"concise form\", such as , the two digits between the parentheses denotes the uncertainty at 1-\u03c3 (1 standard deviation, 68% confidence level) in the two least significant digits of the significand.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41790", "revid": "45955630", "url": "https://en.wikipedia.org/wiki?curid=41790", "title": "Third-order intercept point", "text": "Specific figure of merit in electronics\nIn telecommunications, a third-order intercept point (IP3 or TOI) is a specific figure of merit associated with the more general third-order intermodulation distortion (IMD3), which is a measure for weakly nonlinear systems and devices, for example receivers, linear amplifiers and mixers. It is based on the idea that the device nonlinearity can be modeled using a low-order polynomial, derived by means of Taylor series expansion. The third-order intercept point relates nonlinear products caused by the third-order nonlinear term to the linearly amplified signal, in contrast to the second-order intercept point that uses second-order terms.\nThe intercept point is a purely mathematical concept and does not correspond to a practically occurring physical power level. In many cases, it lies far beyond the damage threshold of the device.\nDefinitions.\nTwo different definitions for intercept points are in use:\nThe intercept point is obtained graphically by plotting the output power versus the input power both on logarithmic scales (e.g., decibels). Two curves are drawn; one for the linearly amplified signal at an input tone frequency, one for a nonlinear product.\nOn a logarithmic scale, the function \"xn\" translates into a straight line with slope of \"n\". Therefore, the linearly amplified signal will exhibit a slope of 1. A third-order nonlinear product will increase by 3\u00a0dB in power when the input power is raised by 1\u00a0dB.\nBoth curves are extended with straight lines of slope 1 and \"n\" (3 for a third-order intercept point). The point where the curves intersect is the intercept point. It can be read off from the input or output power axis, leading to input (IIP3) or output (OIP3) intercept point respectively.\nInput and output intercept point differ by the small-signal gain of the device.\nPractical considerations.\nThe concept of intercept point is based on the assumption of a weakly nonlinear system, meaning that higher-order nonlinear terms are small enough to be negligible.\nIn practice, the weakly nonlinear assumption may not hold for the upper end of the input power range, be it during measurement or during use of the amplifier. As a consequence, measured or simulated data will deviate from the ideal slope of \"n\".\nThe intercept point according to its basic definition should be determined by drawing the straight lines with slope 1 and \"n\" through the measured data at the smallest possible power level (possibly limited towards lower power levels by instrument or device noise).\nIt is a frequent mistake to derive intercept points by either changing the slope of the straight lines, or fitting them to points measured at too high power levels. In certain situations such a measure can be useful, but it is not an intercept point according to definition. Its value depends on the measurement conditions that need to be documented, whereas the IP according to definition is mostly unambiguous; although there is some dependency on frequency and tone spacing, depending on the physics of the device under test.\nOne of the useful applications of third-order intercept point is as a rule-of-thumb measure to estimate nonlinear products. When comparing systems or devices for linearity, a higher intercept point is better. It can be seen that the spacing between two straight lines with slopes of 3 and 1 closes with slope\u00a02.\nFor example, assume a device with an input-referred third-order intercept point of 10 dBm is driven with a test signal of \u22125\u00a0dBm. This power is 15\u00a0dB below the intercept point, therefore nonlinear products will appear at approximately 2\u00d715\u00a0dB below the test signal power at the device output (in other words, 3\u00d715\u00a0dB below the output-referred third-order intercept point).\nA rule of thumb that holds for many linear radio-frequency amplifiers is that the 1\u00a0dB compression point point falls approximately 10\u00a0dB below the third-order intercept point.\nTheory.\nThe third-order intercept point (TOI) is a property of the device transfer function \"O\" (see diagram).\nThis transfer function relates the output signal voltage level to the input signal voltage level. We assume a \"linear\" device having a transfer function whose small-signal form may be expressed in terms of a power series containing only odd terms, making the transfer function an odd function of input signal voltage, i.e., \"O\"(\u2212\"s\") = \u2212\"O\"(\"s\"). Where the signals passing through the actual device are modulated sinusoidal voltage waveforms (e.g., RF amplifier), device nonlinearities can be expressed in terms of how they affect individual sinusoidal signal components. For example, say the input voltage signal is the sine wave\nformula_11\nand the device transfer function produces an output of the form\nformula_12\nwhere \"G\" is the amplifier gain, and \"D\"3 is cubic distortion. We may substitute the first equation into the second and, using the trigonometric identity\nformula_13\nwe obtain the device output voltage waveform as\nformula_14\nThe output waveform contains the original waveform, cos(\"\u03c9t\"), plus a new harmonic term, cos(3\"\u03c9t\"), the \"third-order term\". The coefficient of the cos(\"\u03c9t\") harmonic has two terms, one that varies linearly with \"V\" and one that varies with the cube of \"V\". In fact, the coefficient of cos(\"\u03c9t\") has nearly the same form as the transfer function, except for the factor on the cubic term. In other words, as signal level \"V\" is increased, the level of the cos(\"\u03c9t\") term in the output eventually levels off, similar to how the transfer function levels off. Of course, the coefficients of the higher-order harmonics will increase (with increasing \"V\") as the coefficient of the cos(\"\u03c9t\") term levels off (the power has to go somewhere).\nIf we now restrict our attention to the portion of the cos(\"\u03c9t\") coefficient that varies linearly with \"V\", and then ask ourselves, at what input voltage level \"V\" will the coefficients of the first- and third-order terms have equal magnitudes (i.e., where the magnitudes intersect), we find that this happens when\nformula_15\nwhich is the third-order intercept point (TOI). So, we see that the TOI input power level is simply 4/3 times the ratio of the gain and the cubic distortion term in the device transfer function. The smaller the cubic term is in relation to the gain, the more linear the device is, and the higher the TOI is. The TOI, being related to the magnitude squared of the input voltage waveform, is a power quantity, typically measured in milliwatts (mW). The TOI is always beyond operational power levels because the output power saturates before reaching this level.\nThe TOI is closely related to the amplifier's \"1\u00a0dB compression point\", which is defined as that point at which the \"total\" coefficient of the cos(\"\u03c9t\") term is 1\u00a0dB below the \"linear portion\" of that coefficient. We can relate the 1\u00a0dB compression point to the TOI as follows. Since 1\u00a0dB = 20 log10 1.122, we may say, in a voltage sense, that the 1\u00a0dB compression point occurs when\nformula_16\nor\nformula_17\nor\nformula_18\nIn a power sense (\"V\"2 is a power quantity), a factor of 0.10875 corresponds to \u22129.636\u00a0dB, so by this approximate analysis, the 1\u00a0dB compression point occurs roughly 9.6\u00a0dB below the TOI.\nRecall: decibel figure = 10\u00a0dB\u00a0\u00d7 log10(power ratio) = 20\u00a0dB\u00a0\u00d7 log10(voltage ratio).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41791", "revid": "49194911", "url": "https://en.wikipedia.org/wiki?curid=41791", "title": "Threshold", "text": "Threshold may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nScience.\nBiology.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nOther science-related.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41792", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41792", "title": "Time-assignment speech interpolation", "text": "Technique to increase capacity of analog phone cables\nIn telecommunications, a time-assignment speech interpolation (TASI) was an analog technique used on certain long transmission links to increase voice transmission capacity.\nTASI was invented by Bell Labs in the early 1960s to increase the capacity of transatlantic telephone cables. It was one of their first applications requiring electronic switching of voice circuits.\nLater digital circuit multiplication equipment included TASI as a feature, not as distinct hardware.\nOperation.\nTASI takes advantage of the fact that in typical person-person conversation, speech in a single direction occurs for approximately 40% of the time, the remaining time being occupied with pauses and/or silence. Statistical analysis demonstrated that for an average voice channel usage of 40%, over 74 speech conversations could be handled using 37 full Duplex speech circuits thereby doubling potential revenue for a small capital outlay relative to a highly expensive cable. e.g. \u00a312.5 million (\u00a3263 million as of 2014) cost of the TAT-1 cable on which TASI was implemented.\nTASI worked by switching additional users onto any voice channel temporarily idled because an original user has stopped speaking. When the original user resumes speaking, that user would, in turn, be switched to any channel that happened to be idle. The speech detector function is called voice activity detection. Clipping or loss of speech would occur for all conversations that needed to be assigned to an available idle channel and in practice lasted at least 17\u00a0ms whilst information required to re-connect both parties was signalled by the TASI control circuits. An additional freezeout period lasting between 0 and 500\u00a0ms would depend on the instantaneous loading of voice circuits. In actual use, these delays presented few problems in typical conversations.\nOne of the issues with using this type of technology was that the users listening on an idled channel can sometimes hear the conversation that has been switched onto it. Generally the sound heard was of very low volume and individual words are not distinguishable. See also crosstalk for a similar phenomenon in telecommunications. Another potential issue was ensuring that non-voice type circuits (e.g. Music or radio type circuits where pauses would occur infrequently) were not routed via TASI speech channels since these could seriously degrade the level of service where callers would encounter frequent clipped speech and breaks in the conversation.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41793", "revid": "47070250", "url": "https://en.wikipedia.org/wiki?curid=41793", "title": "Time code ambiguity", "text": ""}
{"id": "41795", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=41795", "title": "Minimum spanning tree", "text": "Least-weight tree connecting graph vertices\nA minimum spanning tree (MST) or minimum weight spanning tree is a subset of the edges of a connected, edge-weighted undirected graph that connects all the vertices together, without any cycles and with the minimum possible total edge weight. That is, it is a spanning tree whose sum of edge weights is as small as possible. More generally, any edge-weighted undirected graph (not necessarily connected) has a minimum spanning forest, which is a union of the minimum spanning trees for its connected components.\nThere are many use cases for minimum spanning trees. One example is a telecommunications company trying to lay cable in a new neighborhood. If it is constrained to bury the cable only along certain paths (e.g. roads), then there would be a graph containing the points (e.g. houses) connected by those paths. Some of the paths might be more expensive, because they are longer, or require the cable to be buried deeper; these paths would be represented by edges with larger weights. Currency is an acceptable unit for edge weight \u2013 there is no requirement for edge lengths to obey normal rules of geometry such as the triangle inequality. A \"spanning tree\" for that graph would be a subset of those paths that has no cycles but still connects every house; there might be several spanning trees possible. A \"minimum spanning tree\" would be one with the lowest total cost, representing the least expensive path for laying the cable.\nProperties.\nPossible multiplicity.\nIf there are n vertices in the graph, then each spanning tree has \"n\" \u2212 1 edges.\nThere may be several minimum spanning trees of the same weight; in particular, if all the edge weights of a given graph are the same, then every spanning tree of that graph is minimum.\nUniqueness.\n\"If each edge has a distinct weight then there will be only one, unique minimum spanning tree\". This is true in many realistic situations, such as the telecommunications company example above, where it's unlikely any two paths have \"exactly\" the same cost. This generalizes to spanning forests as well.\nProof:\nMore generally, if the edge weights are not all distinct then only the (multi-)set of weights in minimum spanning trees is certain to be unique; it is the same for all minimum spanning trees.\nMinimum-cost subgraph.\nIf the weights are \"positive\", then a minimum spanning tree is, in fact, a minimum-cost subgraph connecting all vertices, since if a subgraph contains a cycle, removing any edge along that cycle will decrease its cost and preserve connectivity.\nCycle property.\n\"For any cycle C in the graph, if the weight of an edge e of C is larger than any of the individual weights of all other edges of C, then this edge cannot belong to an MST.\"\nProof: Assume the contrary, i.e. that e belongs to an MST \"T\"1. Then deleting e will break \"T\"1 into two subtrees with the two ends of e in different subtrees. The remainder of C reconnects the subtrees, hence there is an edge f of C with ends in different subtrees, i.e., it reconnects the subtrees into a tree \"T\"2 with weight less than that of \"T\"1, because the weight of f is less than the weight of e.\nCut property.\n\"For any cut C of the graph, if the weight of an edge e in the cut-set of C is strictly smaller than the weights of all other edges of the cut-set of C, then this edge belongs to all MSTs of the graph.\"\nProof: Assume that there is an MST T that does not contain e. Adding e to T will produce a cycle, that crosses the cut once at e and crosses back at another edge e'. Deleting e' we get a spanning tree \"T\"\u2216{\"e' \"} \u222a {\"e\"} of strictly smaller weight than T. This contradicts the assumption that T was a MST.\nBy a similar argument, if more than one edge is of minimum weight across a cut, then each such edge is contained in some minimum spanning tree.\nMinimum-cost edge.\n\"If the minimum cost edge e of a graph is unique, then this edge is included in any MST.\"\nProof: if e was not included in the MST, removing any of the (larger cost) edges in the cycle formed after adding e to the MST, would yield a spanning tree of smaller weight.\nContraction.\nIf T is a tree of MST edges, then we can \"contract\" T into a single vertex while maintaining the invariant that the MST of the contracted graph plus T gives the MST for the graph before contraction.\nAlgorithms.\nIn all of the algorithms below, m is the number of edges in the graph and n is the number of vertices.\nClassic algorithms.\nThe first algorithm for finding a minimum spanning tree was developed by Czech scientist Otakar Bor\u016fvka in 1926 (see Bor\u016fvka's algorithm). Its purpose was an efficient electrical coverage of Moravia. The algorithm proceeds in a sequence of stages. In each stage, called \"Boruvka step\", it identifies a forest F consisting of the minimum-weight edge incident to each vertex in the graph G, then forms the graph \"G\"1 = \"G\" \\ \"F\" as the input to the next step. Here \"G\" \\ \"F\" denotes the graph derived from G by contracting edges in F (by the Cut property, these edges belong to the MST). Each Boruvka step takes linear time. Since the number of vertices is reduced by at least half in each step, Boruvka's algorithm takes \"O\"(\"m\" log \"n\") time.\nA second algorithm is Prim's algorithm, which was invented by Vojt\u011bch Jarn\u00edk in 1930 and rediscovered by Prim in 1957 and Dijkstra in 1959. Basically, it grows the MST (T) one edge at a time. Initially, T contains an arbitrary vertex. In each step, T is augmented with a least-weight edge (\"x\",\"y\") such that x is in T and y is not yet in T. By the Cut property, all edges added to T are in the MST. Its run-time is either \"O\"(\"m\" log \"n\") or \"O\"(\"m\" + \"n\" log \"n\"), depending on the data-structures used.\nA third algorithm commonly in use is Kruskal's algorithm, which also takes \"O\"(\"m\" log \"n\") time.\nA fourth algorithm, not as commonly used, is the reverse-delete algorithm, which is the reverse of Kruskal's algorithm. Its runtime is O(\"m\" log \"n\" (log log \"n\")3).\nAll four of these are greedy algorithms. Since they run in polynomial time, the problem of finding such trees is in FP, and related decision problems such as determining whether a particular edge is in the MST or determining if the minimum total weight exceeds a certain value are in P.\nFaster algorithms.\nSeveral researchers have tried to find more computationally-efficient algorithms.\nIn a comparison model, in which the only allowed operations on edge weights are pairwise comparisons, found a linear time randomized algorithm based on a combination of Bor\u016fvka's algorithm and the reverse-delete algorithm.\nThe fastest non-randomized comparison-based algorithm with known complexity, by Bernard Chazelle, is based on the soft heap, an approximate priority queue. Its running time is \"O\"(\"m\" \u03b1(\"m\",\"n\")), where \u03b1 is the classical functional inverse of the Ackermann function. The function \u03b1 grows extremely slowly, so that for all practical purposes it may be considered a constant no greater than 4; thus Chazelle's algorithm takes very close to linear time.\nLinear-time algorithms in special cases.\nDense graphs.\nIf the graph is dense (i.e. \"m\"/\"n\" \u2265 log log log \"n\"), then a deterministic algorithm by Fredman and Tarjan finds the MST in time O(\"m\"). The algorithm executes a number of phases. Each phase executes Prim's algorithm many times, each for a limited number of steps. The run-time of each phase is O(\"m\" + \"n\"). If the number of vertices before a phase is n', the number of vertices remaining after a phase is at most formula_1. Hence, at most log*\"n\" phases are needed, which gives a linear run-time for dense graphs.\nThere are other algorithms that work in linear time on dense graphs.\nInteger weights.\nIf the edge weights are integers represented in binary, then deterministic algorithms are known that solve the problem in \"O\"(\"m\" + \"n\") integer operations.\nWhether the problem can be solved \"deterministically\" for a \"general graph\" in \"linear time\" by a comparison-based algorithm remains an open question.\nPlanar graphs.\nDeterministic algorithms are known that solve the problem for planar graphs in linear time. By the Euler characteristic of planar graphs, \"m\" \u2264 3\"n\" - 6 \u2208 \"O\"(\"n\"), so this is in time \"O\"(\"n\").\nDecision trees.\nGiven graph G where the nodes and edges are fixed but the weights are unknown, it is possible to construct a binary decision tree (DT) for calculating the MST for any permutation of weights. Each internal node of the DT contains a comparison between two edges, e.g. \"Is the weight of the edge between x and y larger than the weight of the edge between w and z?\". The two children of the node correspond to the two possible answers \"yes\" or \"no\". In each leaf of the DT, there is a list of edges from G that correspond to an MST. The runtime complexity of a DT is the largest number of queries required to find the MST, which is just the depth of the DT. A DT for a graph G is called \"optimal\" if it has the smallest depth of all correct DTs for G.\nFor every integer r, it is possible to find optimal decision trees for all graphs on r vertices by brute-force search. This search proceeds in two steps.\nA. Generating all potential DTs\nformula_4\nB. Identifying the correct DTs\nTo check if a DT is correct, it should be checked on all possible permutations of the edge weights.\nHence, the total time required for finding an optimal DT for \"all\" graphs with r vertices is:\nformula_5\nwhich is less than\nformula_6\nOptimal algorithm.\nSeth Pettie and Vijaya Ramachandran have found a provably optimal deterministic comparison-based minimum spanning tree algorithm. The following is a simplified description of the algorithm.\nThe runtime of all steps in the algorithm is \"O\"(\"m\"), \"except for the step of using the decision trees\". The runtime of this step is unknown, but it has been proved that it is optimal - no algorithm can do better than the optimal decision tree. Thus, this algorithm has the peculiar property that it is \"provably optimal\" although its runtime complexity is \"unknown\".\nParallel and distributed algorithms.\nResearch has also considered parallel algorithms for the minimum spanning tree problem.\nWith a linear number of processors it is possible to solve the problem in \"O\"(log \"n\") time.\nThe problem can also be approached in a distributed manner. If each node is considered a computer and no node knows anything except its own connected links, one can still calculate the distributed minimum spanning tree.\nMST on complete graphs with random weights.\nAlan M. Frieze showed that given a complete graph on \"n\" vertices, with edge weights that are independent identically distributed random variables with distribution function formula_7 satisfying formula_8, then as \"n\" approaches +\u221e the expected weight of the MST approaches formula_9, where formula_10 is the Riemann zeta function (more specifically is formula_11 Ap\u00e9ry's constant). Frieze and Steele also proved convergence in probability. Svante Janson proved a central limit theorem for weight of the MST.\nFor uniform random weights in formula_12, the exact expected size of the minimum spanning tree has been computed for small complete graphs.\nFractional variant.\nThere is a fractional variant of the MST, in which each edge is allowed to appear \"fractionally\". Formally, a fractional spanning set of a graph (V,E) is a nonnegative function \"f\" on \"E\" such that, for every non-trivial subset \"W\" of \"V\" (i.e., \"W\" is neither empty nor equal to \"V\"), the sum of \"f\"(\"e\") over all edges connecting a node of \"W\" with a node of \"V\"\\\"W\" is at least 1. Intuitively, \"f\"(\"e\") represents the fraction of e that is contained in the spanning set. A minimum fractional spanning set is a fractional spanning set for which the sum formula_13 is as small as possible.\nIf the fractions \"f\"(\"e\") are forced to be in {0,1}, then the set \"T\" of edges with f(e)=1 are a spanning set, as every node or subset of nodes is connected to the rest of the graph by at least one edge of \"T\". Moreover, if \"f\" minimizesformula_13, then the resulting spanning set is necessarily a tree, since if it contained a cycle, then an edge could be removed without affecting the spanning condition. So the minimum fractional spanning set problem is a relaxation of the MST problem, and can also be called the fractional MST problem.\nThe fractional MST problem can be solved in polynomial time using the ellipsoid method.248 However, if we add a requirement that \"f\"(\"e\") must be half-integer (that is, \"f\"(\"e\") must be in {0, 1/2, 1}), then the problem becomes NP-hard,248 since it includes as a special case the Hamiltonian cycle problem: in an formula_15-vertex unweighted graph, a half-integer MST of weight formula_16 can only be obtained by assigning weight 1/2 to each edge of a Hamiltonian cycle.\nApplications.\nMinimum spanning trees have direct applications in the design of networks, including computer networks, telecommunications networks, transportation networks, water supply networks, and electrical grids (which they were first invented for, as mentioned above). They are invoked as subroutines in algorithms for other problems, including the Christofides algorithm for approximating the traveling salesman problem, approximating the multi-terminal minimum cut problem (which is equivalent in the single-terminal case to the maximum flow problem),\nand approximating the minimum-cost weighted perfect matching.\nOther practical applications based on minimal spanning trees include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41796", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=41796", "title": "Time-division multiplexing", "text": "Multiplexing technique for digital signals\nTime-division multiplexing (TDM) is a method of transmitting and receiving independent signals over a common signal path by means of synchronized switches at each end of the transmission line so that each signal appears on the line only a fraction of time according to agreed rules, e.g. with each transmitter working in turn. It can be used when the bit rate of the transmission medium exceeds that of the signal to be transmitted. This form of signal multiplexing was developed in telecommunications for telegraphy systems in the late 19th century but found its most common application in digital telephony in the second half of the 20th century.\nHistory.\nTime-division multiplexing was first developed for applications in telegraphy to route multiple transmissions simultaneously over a single transmission line. In the 1870s, \u00c9mile Baudot developed a time-multiplexing system of multiple Hughes telegraph machines.\nIn 1944, the British Army used the Wireless Set No. 10 to multiplex 10 telephone conversations over a microwave relay as far as 50 miles. This allowed commanders in the field to keep in contact with the staff in England across the English Channel.\nIn 1953, a 24-channel time-division multiplexer was placed in commercial operation by RCA Communications to send audio information between RCA's facility on Broad Street, New York, their transmitting station at Rocky Point and the receiving station at Riverhead, Long Island, New York. The communication was by a microwave system throughout Long Island. The experimental TDM system was developed by RCA Laboratories between 1950 and 1953.\nIn 1962, engineers from Bell Labs developed the first D1 channel banks, which combined 24 digitized voice calls over a four-wire copper trunk line between Bell central office analogue switches. A \"channel bank\" at each end of the line allowed the single line to carry short portions, each &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20448000 of a second, of up to 24 voice calls, in turn. The discrete signals on the trunk line carried 1.544\u00a0Mbit/s divided into separate \"frames\" per second, each composed of 24 contiguous octets and one framing bit. Each octet in a frame carried a single telephone call in turn. Thus each of 24 voice calls was encoded into two constant-bit-rate streams of 64\u00a0kbit/s (one in each direction), and converted back to conventional analog signals by the complementary equipment on the receiving end of the trunk line.\nTechnology.\nTime-division multiplexing is used primarily for digital signals but may be applied in analog multiplexing, as above, in which two or more signals or bit streams are transferred appearing simultaneously as sub-channels in one communication channel, but are physically taking turns on the channel. The time domain is divided into several recurrent \"time slots\" of fixed length, one for each sub-channel. A sample byte or data block of sub-channel 1 is transmitted during time slot 1, sub-channel 2 during time slot 2, etc. One TDM frame consists of one time slot per sub-channel, and usually a synchronization channel and sometimes an error correction channel. After all of these the cycle starts again with a new frame, starting with the second sample, byte or data block from sub-channel 1, etc.\nApplication examples.\nTDM can be further extended into the time-division multiple access (TDMA) scheme, where several stations connected to the same physical medium, for example sharing the same frequency channel, can communicate. Application examples include:\nMultiplexed digital transmission.\nIn circuit-switched networks, such as the public switched telephone network (PSTN), it is desirable to transmit multiple subscriber calls over the same transmission medium to effectively utilize the bandwidth of the medium. TDM allows transmitting and receiving telephone switches to create channels (\"tributaries\") within a transmission stream. A standard DS0 voice signal has a data bit rate of 64\u00a0kbit/s. A TDM circuit runs at a much higher signal bandwidth, permitting the bandwidth to be divided into time frames (time slots) for each voice signal which is multiplexed onto the line by the transmitter. If the TDM frame consists of \"n\" voice frames, the line bandwidth is \"n\"*64\u00a0kbit/s.\nEach voice time slot in the TDM frame is called a channel. In European systems, standard TDM frames contain 30 digital voice channels (E1), and in American systems (T1), they contain 24 channels. Both standards also contain extra bits (or bit time slots) for signaling and synchronization bits.\nMultiplexing more than 24 or 30 digital voice channels is called \"higher order multiplexing\". Higher order multiplexing is accomplished by multiplexing the standard TDM frames. For example, a European 120 channel TDM frame is formed by multiplexing four standard 30 channel TDM frames. At each higher order multiplex, four TDM frames from the immediate lower order are combined, creating multiplexes with a bandwidth of \"n\"*64\u00a0kbit/s, where \"n\" = 120, 480, 1920, etc.\nTelecommunications systems.\nThere are three types of synchronous TDM: T1, SONET/SDH, and ISDN.\nPlesiochronous digital hierarchy (PDH) was developed as a standard for multiplexing higher order frames. PDH created larger numbers of channels by multiplexing the standard Europeans 30 channel TDM frames. This solution worked for a while; however PDH suffered from several inherent drawbacks which ultimately resulted in the development of the Synchronous Digital Hierarchy (SDH). The requirements which drove the development of SDH were these:\nSDH has become the primary transmission protocol in most PSTN networks. It was developed to allow streams 1.544\u00a0Mbit/s and above to be multiplexed, in order to create larger SDH frames known as Synchronous Transport Modules (STM). The STM-1 frame consists of smaller streams that are multiplexed to create a 155.52\u00a0Mbit/s frame. SDH can also multiplex packet based frames e.g. Ethernet, PPP and ATM.\nWhile SDH is considered to be a transmission protocol (Layer 1 in the OSI Reference Model), it also performs some switching functions, as stated in the third bullet point requirement listed above. The most common SDH Networking functions are these:\nSDH network functions are connected using high-speed optic fibre. Optic fibre uses light pulses to transmit data and is therefore extremely fast. Modern optic fibre transmission makes use of wavelength-division multiplexing (WDM) where signals transmitted across the fibre are transmitted at different wavelengths, creating additional channels for transmission. This increases the speed and capacity of the link, which in turn reduces both unit and total costs.\nStatistical version.\nStatistical time-division multiplexing (STDM) is an advanced version of TDM in which both the address of the terminal and the data itself are transmitted together for better routing. Using STDM allows bandwidth to be split over one line. Many college and corporate campuses use this type of TDM to distribute bandwidth.\nOn a 10-Mbit line entering a network, STDM can be used to provide 178 terminals with a dedicated 56k connection (178 * 56k = 9.96\u00a0Mb). A more common use however is to only grant the bandwidth when that much is needed. STDM does not reserve a time slot for each terminal, rather it assigns a slot when the terminal is requiring data to be sent or received.\nIn its primary form, TDM is used for circuit mode communication with a fixed number of channels and constant bandwidth per channel. Bandwidth reservation distinguishes time-division multiplexing from statistical multiplexing such as statistical time-division multiplexing. In pure TDM, the time slots are recurrent in a fixed order and pre-allocated to the channels, rather than scheduled on a packet-by-packet basis.\nIn dynamic TDMA, a scheduling algorithm dynamically reserves a variable number of time slots in each frame to variable bit-rate data streams, based on the traffic demand of each data stream. Dynamic TDMA is used in:\nAsynchronous time-division multiplexing (ATDM), is an alternative nomenclature in which STDM designates synchronous time-division multiplexing, the older method that uses fixed time slots.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41797", "revid": "12331483", "url": "https://en.wikipedia.org/wiki?curid=41797", "title": "Time-domain reflectometer", "text": "Electronic instrument\nA time-domain reflectometer (TDR) is an electronic instrument used to determine the characteristics of electrical lines by observing reflected pulses. It can be used to characterize and locate faults in metallic cables (for example, twisted pair wire or coaxial cable),\nand to locate discontinuities in a connector, printed circuit board, or any other electrical path.\nDescription.\nA TDR measures reflections along a conductor. In order to measure those reflections, the TDR will transmit an incident signal onto the conductor and listen for its reflections. If the conductor is of a uniform impedance and is properly terminated, then there will be no reflections and the remaining incident signal will be absorbed at the far-end by the termination. Instead, if there are impedance variations, then some of the incident signal will be reflected back to the source. A TDR is similar in principle to radar.\nThe impedance of the discontinuity can be determined from the amplitude of the reflected signal. The distance to the reflecting impedance can also be determined from the time that a pulse takes to return. The limitation of this method is the minimum system rise time. The total rise time consists of the combined rise time of the driving pulse and that of the oscilloscope or sampler that monitors the reflections.\nMethod.\nThe TDR analysis begins with the propagation of a step or impulse of energy into a system and the subsequent observation of the energy reflected by the system. By analyzing the magnitude, duration and shape of the reflected waveform, the nature of the impedance variation in the transmission system can be determined.\nIf a pure resistive load is placed on the output of the reflectometer and a step signal is applied, a step signal is observed on the display, and its height is a function of the resistance. The magnitude of the step produced by the resistive load may be expressed as a fraction of the input signal as given by:\nformula_1\nwhere formula_2 is the characteristic impedance of the transmission line.\nReflection.\nGenerally, the reflections will have the same shape as the incident signal, but their sign and magnitude depend on the change in impedance level. If there is a step increase in the impedance, then the reflection will have the same sign as the incident signal; if there is a step decrease in impedance, the reflection will have the opposite sign. The magnitude of the reflection depends not only on the amount of the impedance change, but also upon the loss in the conductor.\nThe reflections are measured at the output/input to the TDR and displayed or plotted as a function of time. Alternatively, the display can be read as a function of cable length because the speed of signal propagation is almost constant for a given transmission medium.\nBecause of its sensitivity to impedance variations, a TDR may be used to verify cable impedance characteristics, splice and connector locations and associated losses, and estimate cable lengths.\nIncident signal.\nTDRs use different incident signals. Some TDRs transmit a pulse along the conductor; the resolution of such instruments is often the width of the pulse. Narrow pulses can offer good resolution, but they have high frequency signal components that are attenuated in long cables. The shape of the pulse is often a half cycle sinusoid. For longer cables, wider pulse widths are used.\nFast rise time steps are also used. Instead of looking for the reflection of a complete pulse, the instrument is concerned with the rising edge, which can be very fast. A 1970s technology TDR used steps with a rise time of 25\u00a0ps.\nStill other TDRs transmit complex signals and detect reflections with correlation techniques. See spread-spectrum time-domain reflectometry.\nVariations and extensions.\nThe equivalent device for optical fiber is an optical time-domain reflectometer.\nTime-domain transmissometry (TDT) is an analogous technique that measures the transmitted (rather than reflected) impulse. Together, they provide a powerful means of analysing electrical or optical transmission media such as coaxial cable and optical fiber.\nVariations of TDR exist. For example, spread-spectrum time-domain reflectometry (SSTDR) is used to detect intermittent faults in complex and high-noise systems such as aircraft wiring. Coherent optical time domain reflectometry (COTDR) is another variant, used in optical systems, in which the returned signal is mixed with a local oscillator and then filtered to reduce noise.\nExample traces.\nThese traces were produced by a time-domain reflectometer made from common lab equipment connected to approximately of coaxial cable having a characteristic impedance of 50\u00a0ohms. The propagation velocity of this cable is approximately 66% of the speed of light in vacuum.\nThese traces were produced by a commercial TDR using a step waveform with a 25\u00a0ps risetime, a sampling head with a 35\u00a0ps risetime, and an SMA cable. The far end of the SMA cable was left open or connected to different adapters. It takes about 3\u00a0ns for the pulse to travel down the cable, reflect, and reach the sampling head. A second reflection (at about 6\u00a0ns) can be seen in some traces; it is due to the reflection seeing a small mismatch at the sampling head and causing another \"incident\" wave to travel down the cable.\nExplanation.\nIf the far end of the cable is shorted, that is, terminated with an impedance of zero ohms, and when the rising edge of the pulse is launched down the cable, the voltage at the launching point \"steps up\" to a given value instantly and the pulse begins propagating in the cable towards the short. When the pulse encounters the short, no energy is absorbed at the far end. Instead, an inverted pulse reflects back from the short towards the launching end. It is only when this reflection finally reaches the launch point that the voltage at this point abruptly drops back to zero, signaling the presence of a short at the end of the cable. That is, the TDR has no indication that there is a short at the end of the cable until its emitted pulse can travel in the cable and the echo can return. It is only after this round-trip delay that the short can be detected by the TDR. With knowledge of the signal propagation speed in the particular cable-under-test, the distance to the short can be measured.\nA similar effect occurs if the far end of the cable is an open circuit (terminated into an infinite impedance). In this case, though, the reflection from the far end is polarized identically with the original pulse and adds to it rather than cancelling it out. So after a round-trip delay, the voltage at the TDR abruptly jumps to twice the originally-applied voltage.\nPerfect termination at the far end of the cable would entirely absorb the applied pulse without causing any reflection, rendering the determination of the actual length of the cable impossible. In practice, some small reflection is nearly always observed.\nThe magnitude of the reflection is referred to as the reflection coefficient or \"\u03c1\". The coefficient ranges from 1 (open circuit) to \u22121 (short circuit). The value of zero means that there is no reflection. The reflection coefficient is calculated as follows:\nformula_3\nwhere \"Z\"o is defined as the characteristic impedance of the transmission medium and \"Z\"t is the impedance of the termination at the far end of the transmission line.\nAny discontinuity can be viewed as a termination impedance and substituted as \"Z\"t. This includes abrupt changes in the characteristic impedance. As an example, a trace width on a printed circuit board doubled at its midsection would constitute a discontinuity. Some of the energy will be reflected back to the driving source; the remaining energy will be transmitted. This is also known as a scattering junction.\nUsage.\nTime domain reflectometers are commonly used for in-place testing of very long cable runs, where it is impractical to dig up or remove what may be a kilometers-long cable. They are indispensable for preventive maintenance of telecommunication lines, as TDRs can detect resistance on joints and connectors as they corrode, and increasing insulation leakage as it degrades and absorbs moisture, long before either leads to catastrophic failures. Using a TDR, it is possible to pinpoint a fault to within centimetres.\nTDRs are also very useful tools for technical surveillance counter-measures, where they help determine the existence and location of wire taps. The slight change in line impedance caused by the introduction of a tap or splice will show up on the screen of a TDR when connected to a phone line.\nTDR equipment is also an essential tool in the failure analysis of modern high-frequency printed circuit boards with signal traces crafted to emulate transmission lines. Observing reflections can detect any unsoldered pins of a ball grid array device. Short-circuited pins can also be detected similarly.\nThe TDR principle is used in industrial settings, in situations as diverse as the testing of integrated circuit packages to measuring liquid levels. In the former, the time domain reflectometer is used to isolate failing sites in the same. The latter is primarily limited to the process industry.\nIn level measurement.\nIn a TDR-based level measurement device, the device generates an impulse that propagates down a thin waveguide (referred to as a probe) \u2013 typically a metal rod or a steel cable. When this impulse hits the surface of the medium to be measured, part of the impulse reflects back up the waveguide. The device determines the fluid level by measuring the time difference between when the impulse was sent and when the reflection returned. The sensors can output the analyzed level as a continuous analog signal or switch output signals. In TDR technology, the impulse velocity is primarily affected by the permittivity of the medium through which the pulse propagates, which can vary greatly by the moisture content and temperature of the medium. In many cases, this effect can be corrected without undue difficulty. In some cases, such as in boiling and/or high temperature environments, the correction can be difficult. In particular, determining the froth (foam) height and the collapsed liquid level in a frothy / boiling medium can be very difficult.\nUsed in anchor cables in dams.\nThe Dam Safety Interest Group of CEA Technologies, Inc. (CEATI), a consortium of electrical power organizations, has applied Spread-spectrum time-domain reflectometry to identify potential faults in concrete dam anchor cables. The key benefit of Time Domain reflectometry over other testing methods is the non-destructive method of these tests.\nUsed in the earth and agricultural sciences.\nA TDR is used to determine moisture content in soil and porous media. Over the last two decades, substantial advances have been made measuring moisture in soil, grain, food stuff, and sediment. The key to TDR's success is its ability to accurately determine the permittivity (dielectric constant) of a material from wave propagation, due to the strong relationship between the permittivity of a material and its water content, as demonstrated in the pioneering works of Hoekstra and Delaney (1974) and Topp et al. (1980). Recent reviews and reference work on the subject include, Topp and Reynolds (1998), Noborio (2001), Pettinellia et al. (2002), Topp and Ferre (2002) and Robinson et al. (2003). The TDR method is a transmission line technique, and determines apparent permittivity (Ka) from the travel time of an electromagnetic wave that propagates along a transmission line, usually two or more parallel metal rods embedded in soil or sediment. The probes are typically between 10 and 30\u00a0cm long and connected to the TDR via coaxial cable.\nIn geotechnical engineering.\nTime domain reflectometry has also been utilized to monitor slope movement in a variety of geotechnical settings, including highway cuts, rail beds, and open pit mines (Dowding &amp; O'Connor, 1984, 2000a, 2000b; Kane &amp; Beck, 1999). In TDR stability monitoring applications, a coaxial cable is installed in a vertical borehole passing through the region of concern. The electrical impedance at any point along a coaxial cable changes with deformation of the insulator between the conductors. A brittle grout surrounds the cable to translate earth movement into an abrupt cable deformation that shows up as a detectable peak in the reflectance trace. Until recently, the technique was relatively insensitive to small slope movements and could not be automated because it relied on human detection of changes in the reflectance trace over time. Farrington and Sargand (2004) developed a simple signal processing technique using numerical derivatives to extract reliable indications of slope movement from the TDR data much earlier than by conventional interpretation.\nAnother application of TDRs in geotechnical engineering is to determine the soil moisture content. This can be done by placing the TDRs in different soil layers and measuring the time of start of precipitation and the time that TDR indicates an increase in the soil moisture content. The depth of the TDR (d) is a known factor and the other is the time it takes the drop of water to reach that depth (\"t\"); therefore the speed of water infiltration (\"v\") can be determined. This is a good method to assess the effectiveness of Best Management Practices (BMPs) in reducing stormwater surface runoff.\nIn semiconductor device analysis.\nTime domain reflectometry is used in semiconductor failure analysis as a non-destructive method for the location of defects in semiconductor device packages. The TDR provides an electrical signature of individual conductive traces in the device package, and is useful for determining the location of opens and shorts.\nIn aviation wiring maintenance.\nTime domain reflectometry, specifically spread-spectrum time-domain reflectometry is used on aviation wiring for both preventive maintenance and fault location. Spread spectrum time domain reflectometry has the advantage of precisely locating the fault location within thousands of miles of aviation wiring. Additionally, this technology is worth considering for real time aviation monitoring, as spread spectrum reflectometry can be employed on live wires.\nThis method has been shown to be useful to locating intermittent electrical faults.\nMulti carrier time domain reflectometry (MCTDR) has also been identified as a promising method for embedded EWIS diagnosis or troubleshooting tools. Based on the injection of a multicarrier signal (respecting EMC and harmless for the wires), this smart technology provides information for the detection, localization and characterization of electrical defects (or mechanical defects having electrical consequences) in the wiring systems.\nHard fault (short, open circuit) or intermittent defects can be detected very quickly increasing the reliability of wiring systems and improving their maintenance.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41798", "revid": "45789152", "url": "https://en.wikipedia.org/wiki?curid=41798", "title": "Time-out", "text": ""}
{"id": "41799", "revid": "50698550", "url": "https://en.wikipedia.org/wiki?curid=41799", "title": "Time standard", "text": "Specification for measuring time\nA time standard is a specification for measuring time: either the rate at which time passes or points in time or both. In modern times, several time specifications have been officially recognized as standards, where formerly they were matters of custom and practice. An example of a kind of time standard can be a time scale, specifying a method for measuring divisions of time. A standard for civil time can specify both time intervals and time-of-day.\nStandardized time measurements are made using a clock to count periods of some period changes, which may be either the changes of a natural phenomenon or of an artificial machine.\nHistorically, time standards were often based on the Earth's rotational period. From the late 18 century to the 19th century it was assumed that the Earth's daily rotational rate was constant. Astronomical observations of several kinds, including eclipse records, studied in the 19th century, raised suspicions that the rate at which Earth rotates is gradually slowing and also shows small-scale irregularities, and this was confirmed in the early twentieth century. Time standards based on Earth rotation were replaced (or initially supplemented) for astronomical use from 1952 onwards by an \"ephemeris time\" standard based on the Earth's orbital period and in practice on the motion of the Moon. The invention in 1955 of the caesium atomic clock has led to the replacement of older and purely astronomical time standards, for most practical purposes, by newer time standards based wholly or partly on atomic time.\nVarious types of second and day are used as the basic time interval for most time scales. Other intervals of time (minutes, hours, and years) are usually defined in terms of these two.\nTerminology.\nThe term \"time\" is generally used for many close but different concepts, including:\nDefinitions of the second.\nThere have only ever been three definitions of the second: as a fraction of the day, as a fraction of an extrapolated year, and as the microwave frequency of a caesium atomic clock.\nIn early history, clocks were not accurate enough to track seconds. After the invention of mechanical clocks, the CGS system and MKS system of units both defined the second as &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204486,400 of a mean solar day. MKS was adopted internationally during the 1940s.\nIn the late 1940s, quartz crystal oscillator clocks could measure time more accurately than the rotation of the Earth. Metrologists also knew that Earth's orbit around the Sun (a year) was much more stable than Earth's rotation. This led to the definition of ephemeris time and the tropical year, and the ephemeris second was defined as \"the fraction &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204431,556,925.9747 of the tropical year for 1900 January 0 at 12 hours ephemeris time\". This definition was adopted as part of the International System of Units in 1960.\nMost recently, atomic clocks have been developed that offer improved accuracy. Since 1967, the SI base unit for time is the SI second, defined as exactly \"the duration of 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the caesium-133 atom\" (at a temperature of 0\u00a0K and at mean sea level). The SI second is the basis of all atomic timescales, e.g. coordinated universal time, GPS time, International Atomic Time, etc.\nCurrent time standards.\nGeocentric Coordinate Time (TCG) is a coordinate time having its spatial origin at the center of Earth's mass. TCG is a theoretical ideal, and any particular realization will have measurement error.\nInternational Atomic Time (TAI) is the primary physically realized time standard. TAI is produced by the International Bureau of Weights and Measures (BIPM), and is based on the combined input of many atomic clocks around the world, each corrected for environmental and relativistic effects (both gravitational and because of speed, like in GNSS). TAI is not related to TCG directly but rather is a realization of Terrestrial Time (TT), a theoretical timescale that is a rescaling of TCG such that the time rate approximately matches proper time at mean sea level.\nUniversal Time (UT1) is the Earth Rotation Angle (ERA) linearly scaled to match historical definitions of mean solar time at 0\u00b0 longitude. At high precision, Earth's rotation is irregular and is determined from the positions of distant quasars using long baseline interferometry, laser ranging of the Moon and artificial satellites, as well as GPS satellite orbits.\nCoordinated Universal Time (UTC) is an atomic time scale designed to approximate UT1. UTC differs from TAI by an integral number of seconds. UTC is kept within 0.9 second of UT1 by the introduction of one-second steps to UTC, the \"leap second\". To date these steps (and difference \"TAI-UTC\") have always been positive.\nThe Global Positioning System broadcasts a very precise time signal worldwide, along with instructions for converting GPS time (GPST) to UTC. It was defined with a constant offset from TAI: GPST = TAI - 19 s. The GPS time standard is maintained independently but regularly synchronized with or from, UTC time.\nStandard time or civil time in a time zone deviates a fixed, round amount, usually a whole number of hours, from some form of Universal Time, usually UTC. The offset is chosen such that a new day starts approximately while the Sun is crossing the nadir meridian. Alternatively the difference is not really fixed, but it changes twice a year by a round amount, usually one hour, see Daylight saving time.\nJulian day number is a count of days elapsed since Greenwich mean noon on 1 January 4713 B.C., Julian proleptic calendar. The Julian Date is the Julian day number followed by the fraction of the day elapsed since the preceding noon. Conveniently for astronomers, this avoids the date skip during an observation night. Modified Julian day (MJD) is defined as MJD = JD - 2400000.5. An MJD day thus begins at midnight, civil date. Julian dates can be expressed in UT1, TAI, TT, etc. and so for precise applications the timescale should be specified, e.g. MJD 49135.3824 TAI.\nBarycentric Coordinate Time (TCB) is a coordinate time having its spatial origin at the center of mass of the Solar System, which is called the barycenter.\nConversions.\nConversions between atomic time systems (TAI, GPST, and UTC) are for the most part exact. However, GPS time is a measured value as opposed to a computed \"paper\" scale. As such it may differ from UTC(USNO) by a few hundred nanoseconds, which in turn may differ from official UTC by as much as 26 nanoseconds. Conversions for UT1 and TT rely on published difference tables which as of 2022[ [update]] are specified to 10 microseconds and 0.1 nanoseconds respectively.\nDefinitions:\nTCG is linearly related to TT as: TCG \u2212 TT = LG \u00d7 (JD \u2212 2443144.5) \u00d7 86400 seconds, with the scale difference LG defined as 6.969290134\u00d710-10 exactly.\nTCB is a linear transformation of TDB and TDB differs from TT in small, mostly periodic terms. Neglecting these terms (on the order of 2 milliseconds for several millennia around the present epoch), TCB is related to TT by: TCB \u2212 TT = LB \u00d7 (JD \u2212 2443144.5) \u00d7 86400 seconds. The scale difference LB has been defined by the IAU to be 1.550519768e-08 exactly.\nTime standards based on Earth rotation.\nApparent solar time or true solar time is based on the solar day, which is the period between one solar noon (passage of the real Sun across the meridian) and the next. A solar day is approximately 24 hours of mean time. Because the Earth's orbit around the Sun is elliptical, and because of the obliquity of the Earth's axis relative to the plane of the orbit (the ecliptic), the apparent solar day varies a few dozen seconds above or below the mean value of 24 hours. As the variation accumulates over a few weeks, there are differences as large as 16 minutes between apparent solar time and mean solar time (see Equation of time). However, these variations cancel out over a year. There are also other perturbations such as Earth's wobble, but these are less than a second per year.\nSidereal time is time by the stars. A sidereal rotation is the time it takes the Earth to make one revolution with rotation to the stars, approximately 23 hours 56 minutes 4 seconds. A mean solar day is about 3 minutes 56 seconds longer than a mean sidereal day, or &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u2044366 more than a mean sidereal day. In astronomy, sidereal time is used to predict when a star will reach its highest point in the sky. For accurate astronomical work on land, it was usual to observe sidereal time rather than solar time to measure mean solar time, because the observations of 'fixed' stars could be measured and reduced more accurately than observations of the Sun (in spite of the need to make various small compensations, for refraction, aberration, precession, nutation and proper motion). It is well known that observations of the Sun pose substantial obstacles to the achievement of accuracy in measurement. In former times, before the distribution of accurate time signals, it was part of the routine work at any observatory to observe the sidereal times of meridian transit of selected 'clock stars' (of well-known position and movement), and to use these to correct observatory clocks running local mean sidereal time; but nowadays local sidereal time is usually generated by computer, based on time signals.\nMean solar time was a time standard used especially at sea for navigational purposes, calculated by observing apparent solar time and then adding to it a correction, the equation of time, which compensated for two known irregularities in the length of the day, caused by the ellipticity of the Earth's orbit and the obliquity of the Earth's equator and polar axis to the ecliptic (which is the plane of the Earth's orbit around the sun). It has been superseded by Universal Time.\nGreenwich Mean Time was originally mean time deduced from meridian observations made at the Royal Greenwich Observatory (RGO). The principal meridian of that observatory was chosen in 1884 by the International Meridian Conference to be the Prime Meridian. GMT either by that name or as 'mean time at Greenwich' used to be an international time standard, but is no longer so; it was initially renamed in 1928 as Universal Time (UT) (partly as a result of ambiguities arising from the changed practice of starting the astronomical day at midnight instead of at noon, adopted as from 1 January 1925). UT1 is still in reality mean time at Greenwich. Today, GMT is a time zone but is still the legal time in the UK in winter (and as adjusted by one hour for summer time). But Coordinated Universal Time (UTC) (an atomic-based time scale which is always kept within 0.9 second of UT1) is in common actual use in the UK, and the name GMT is often used to refer to it. (See articles Greenwich Mean Time, Universal Time, Coordinated Universal Time and the sources they cite.)\nVersions of Universal Time such as UT0 and UT2 have been defined but are no longer in use.\nTime standards for planetary motion calculations.\nEphemeris time (ET) and its successor time scales described below have all been intended for astronomical use, e.g. in planetary motion calculations, with aims including uniformity, in particular, freedom from irregularities of Earth rotation. Some of these standards are examples of dynamical time scales and/or of coordinate time scales. Ephemeris Time was from 1952 to 1976 an official time scale standard of the International Astronomical Union; it was a dynamical time scale based on the orbital motion of the Earth around the Sun, from which the ephemeris second was derived as a defined fraction of the tropical year. This ephemeris second was the standard for the SI second from 1956 to 1967, and it was also the source for calibration of the caesium atomic clock; its length has been closely duplicated, to within 1 part in 1010, in the size of the current SI second referred to atomic time. This Ephemeris Time standard was non-relativistic and did not fulfil growing needs for relativistic coordinate time scales. It was in use for the official almanacs and planetary ephemerides from 1960 to 1983, and was replaced in official almanacs for 1984 and after, by numerically integrated Jet Propulsion Laboratory Development Ephemeris DE200 (based on the JPL relativistic coordinate time scale Teph).\nFor applications at the Earth's surface, ET's official replacement was Terrestrial Dynamical Time (TDT), which maintained continuity with it. TDT is a uniform atomic time scale, whose unit is the SI second. TDT is tied in its rate to the SI second, as is International Atomic Time (TAI), but because TAI was somewhat arbitrarily defined at its inception in 1958 to be initially equal to a refined version of UT, TDT was offset from TAI, by a constant 32.184 seconds. The offset provided a continuity from Ephemeris Time to TDT. TDT has since been redefined as Terrestrial Time (TT).\nFor the calculation of ephemerides, Barycentric Dynamical Time (TDB) was officially recommended to replace ET. TDB is similar to TDT but includes relativistic corrections that move the origin to the barycenter, hence it is a dynamical time at the barycenter. TDB differs from TT only in periodic terms. The difference is at most 2 milliseconds. Deficiencies were found in the definition of TDB (though not affecting Teph), and TDB has been replaced by Barycentric Coordinate Time (TCB) and Geocentric Coordinate Time (TCG), and redefined to be JPL ephemeris time argument Teph, a specific fixed linear transformation of TCB. As defined, TCB (as observed from the Earth's surface) is of divergent rate relative to all of ET, Teph and TDT/TT; and the same is true, to a lesser extent, of TCG. The ephemerides of Sun, Moon and planets in current widespread and official use continue to be those calculated at the Jet Propulsion Laboratory (updated as from 2003 to DE405) using as argument Teph.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "41800", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=41800", "title": "T interface", "text": "A T-interface or T reference point is used for basic rate access in an Integrated Services Digital Network (ISDN) environment. It is a User\u2013network interface reference point that is characterized by a four-wire, 144 kbit/s (2B+D) user rate.\nOther characteristics of a T-interface are:\nThe T interface is electrically equivalent to the S interface, and the two are jointly referred to as the S/T interface.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41801", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41801", "title": "Toll switching trunk", "text": "Element of American telephony\nIn telecommunications, a toll switching trunk or toll connecting trunk is a trunk connecting an end office to a toll center as the first stage of concentration for intertoll or long-distance traffic. \nOperator assistance or participation may be an optional function. In U.S. common carrier telephony service, a toll center designated \"Class 4C\" is an office where assistance in completing incoming calls is provided in addition to other traffic; a toll center designated \"Class 4P\" is an office where operators handle only outbound calls, or where switching is performed without operator assistance.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41802", "revid": "50185868", "url": "https://en.wikipedia.org/wiki?curid=41802", "title": "Total harmonic distortion", "text": "Measurement of the harmonic distortion present in a signal\nThe total harmonic distortion (THD or THDi) is a measurement of the harmonic distortion present in a signal and is defined as the ratio of the sum of the powers of all harmonic components to the power of the fundamental frequency. Distortion factor, a closely related term, is sometimes used as a synonym.\nIn audio systems, lower distortion means that the components in a loudspeaker, amplifier or microphone or other equipment produce a more accurate reproduction of an audio recording.\nIn radio communications, devices with lower THD tend to produce less unintentional interference with other electronic devices. Since harmonic distortion can potentially widen the frequency spectrum of the output emissions from a device by adding signals at multiples of the input frequency, devices with high THD are less suitable in applications such as spectrum sharing and spectrum sensing.\nIn power systems, lower THD implies lower peak currents, less heating, lower electromagnetic emissions, and less core loss in motors. It is a key metric in the stability and quality of the U.S. electrical grid. IEEE Standard 519-2022 covers the recommended practice and requirements for harmonic control in electric power systems.\nDefinitions and examples.\nTo understand a system with an input and an output, such as an audio amplifier, we start with an ideal system where the transfer function is linear and time-invariant. When a sinusoidal signal of frequency \"\u03c9\" passes through a non-ideal, non-linear device, additional content is added at integer multiples \"n\u03c9\" (harmonics) of the original frequency. THD is a measure of that additional signal content not present in the input signal.\nWhen the main performance criterion is the \"purity\" of the original sine wave (in other words, the contribution of the original frequency with respect to its harmonics), the measurement is most commonly defined as the ratio of the RMS amplitude of a set of higher harmonic frequencies to the RMS amplitude of the first harmonic, or fundamental frequency\nformula_1\nwhere \"Vn\" is the RMS value of the \"n\"th harmonic voltage, and \"V\"1 is the RMS value of the fundamental component.\nIn practice, the THDF is commonly used in audio distortion specifications (percentage THD); however, THD is a non-standardized specification, and the results between manufacturers are not easily comparable. Since individual harmonic amplitudes are measured, it is required that the manufacturer disclose the test signal frequency range, level and gain conditions, and number of measurements taken. It is possible to measure the full 20\u00a0Hz\u201320\u00a0kHz range using a sweep (though distortion for a fundamental above 10\u00a0kHz is inaudible).\nMeasurements for calculating the THD are made at the output of a device under specified conditions. The THD is usually expressed in percent or in dB relative to the fundamental as distortion attenuation.\nA variant definition uses the fundamental plus harmonics as the reference:\nformula_2\nThese can be distinguished as THDF (for \"fundamental\"), and THDR (for \"root mean square\"). THDR cannot exceed 100%. At low distortion levels, the difference between the two calculation methods is negligible. For instance, a signal with THDF of 10% has a very similar THDR of 9.95%. However, at higher distortion levels the discrepancy becomes large. For instance, a signal with THDF 266% has a THDR of 94%. A pure square wave with infinite harmonics has THDF of 48.3% and THDR of 43.5%.\nSome use the term \"distortion factor\" as a synonym for THDR, while others use it as a synonym for THDF.\nThe International Electrotechnical Commission (IEC) also defines another term \"total harmonic factor\" for the \"ratio of the RMS value of the harmonic content of an alternating quantity to the RMS value of the quantity\" using a different equation.\nTHD\u00a0+\u00a0N.\nTHD\u00a0+\u00a0N means total harmonic distortion plus noise. This measurement is much more common and more comparable between devices. It is usually measured by inputting a sine wave, notch-filtering the output, and comparing the ratio between the output signal with and without the sine wave:\nformula_3\nLike the THD measurement, this is a ratio of RMS amplitudes and can be measured as THDF (bandpassed or calculated fundamental as the denominator) or, more commonly, as THDR (total distorted signal as the denominator).\nA meaningful measurement must include the bandwidth of measurement. This measurement includes effects from ground-loop power-line hum, high-frequency interference, intermodulation distortion between these tones and the fundamental, and so on, in addition to harmonic distortion. For psychoacoustic measurements, a weighting curve is applied such as A-weighting or ITU-R BS.468, which is intended to accentuate what is most audible to the human ear, contributing to a more accurate measurement. A-weighting is a rough way to estimate the frequency sensitivity of every persons' ears, as it does not take into account the non-linear behavior of the ear. The loudness model proposed by Zwicker includes these complexities. The model is described in the German standard DIN 45631.\nFor a given input frequency and amplitude, THD\u00a0+\u00a0N is reciprocal to SINAD, provided that both measurements are made over the same bandwidth.\nMeasurement.\nThe distortion of a waveform relative to a pure sinewave can be measured either by using a THD analyzer to analyse the output wave into its constituent harmonics and noting the amplitude of each relative to the fundamental; or by cancelling out the fundamental with a notch filter and measuring the remaining signal, which will be total aggregate harmonic distortion plus noise.\nGiven a sinewave generator of very low inherent distortion, it can be used as input to amplification equipment, whose distortion at different frequencies and signal levels can be measured by examining the output waveform.\nThere is electronic equipment both to generate sinewaves and to measure distortion; but a general-purpose digital computer equipped with a sound card can carry out harmonic analysis with suitable software. Different software can be used to generate sinewaves, but the inherent distortion may be too high for measurement of very low-distortion amplifiers.\nInterpretation.\nFor many purposes, different types of harmonics are not equivalent. For instance, crossover distortion at a given THD is much more audible than clipping distortion at the same THD, since the harmonics produced by crossover distortion are nearly as strong at higher-frequency harmonics, such as 10\u00d7 to 20\u00d7 the fundamental, as they are at lower-frequency harmonics like 3\u00d7 or 5\u00d7 the fundamental. Those harmonics appearing far away in frequency from a fundamental (desired signal) are not as easily masked by that fundamental. In contrast, at the onset of clipping, harmonics first appear at low-order frequencies and gradually start to occupy higher-frequency harmonics. A single THD number is therefore inadequate to specify audibility and must be interpreted with care. Taking THD measurements at different output levels would expose whether the distortion is clipping (which decreases with a decreasing level) or crossover (which stays constant with varying output level, and thus is a \"greater percentage\" of the sound produced at low volumes).\nTHD is a summation of a number of harmonics equally weighted, even though research performed decades ago identifies that lower-order harmonics are harder to hear at the same level, compared with higher-order ones. In addition, even-order harmonics are said to be generally harder to hear than odd-order. A number of methods have been developed to estimate the actual audibility of THD, used to quantify crossover distortion or loudspeaker rub and buzz, such as \"high-order harmonic distortion\" (HOHD) or \"higher harmonic distortion\" (HHD) which measures only the 10th and higher harmonics, or metrics that apply psychoacoustic loudness curves to the residual.\nExamples.\nFor many standard signals, the above criterion may be calculated analytically in a closed form. For example, a pure square wave has THDF equal to\nformula_4\nThe sawtooth signal possesses\nformula_5\nThe pure symmetrical triangle wave has\nformula_6\nFor the rectangular pulse train with the \"duty cycle\" \"\u03bc\" (called sometimes the \"cyclic ratio\"), the THDF has the form\nformula_7\nand logically, reaches the minimum (\u22480.483) when the signal becomes symmetrical \"\u03bc\"\u00a0=\u00a00.5, i.e. the pure square wave. Appropriate filtering of these signals may drastically reduce the resulting THD. For instance, the pure square wave filtered by the Butterworth low-pass filter of the second order (with the cutoff frequency set equal to the fundamental frequency) has THDF of 5.3%, while the same signal filtered by the fourth-order filter has THDF of 0.6%. However, analytic computation of the THDF for complicated waveforms and filters often represents a difficult task, and the resulting expressions may be quite laborious to obtain. For example, the closed-form expression for the THDF of the sawtooth wave filtered by the first-order Butterworth low-pass filter is simply\nformula_8\nwhile that for the same signal filtered by the second-order Butterworth filter is given by a rather cumbersome formula\n formula_9\nYet, the closed-form expression for the THDF of the pulse train filtered by the \"p\"th-order Butterworth low-pass filter is even more complicated and has the following form:\n formula_10\nwhere \"\u03bc\" is the duty cycle, 0 &lt; \"\u03bc\" &lt; 1, and\n formula_11\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41803", "revid": "18286929", "url": "https://en.wikipedia.org/wiki?curid=41803", "title": "Traffic-flow security", "text": ""}
{"id": "41804", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41804", "title": "Traffic intensity", "text": "Measure of the average occupancy of a server or resource during a specified period of time\nIn telecommunications networks, traffic intensity is a measure of the average occupancy of a server or resource during a specified period of time, normally a busy hour. It is measured in traffic units (erlangs) and defined as the ratio of the time during which a facility is cumulatively occupied to the time this facility is available for occupancy. \nIn a digital network, the traffic intensity is:\nformula_1\nwhere\n\"a\" is the average arrival rate of packets (e.g. in packets per second)\n\"L\" is the average packet length (e.g. in bits), and\n\"R\" is the transmission rate (e.g. bits per second)\nA traffic intensity greater than one erlang means that the rate at which bits arrive exceeds the rate bits can be transmitted and queuing delay will grow without bound (if the traffic intensity stays the same). If the traffic intensity is less than one erlang, then the router can handle more average traffic. \nTelecommunication operators are vitally interested in traffic intensity, as it dictates the amount of equipment they must supply."}
{"id": "41805", "revid": "40968262", "url": "https://en.wikipedia.org/wiki?curid=41805", "title": "Transceiver", "text": "Device that both transmits and receives\nIn radio communication, a transceiver is an electronic device which is a combination of a radio \"trans\"mitter and a re\"ceiver\", hence the name. It can both transmit and receive radio waves using an antenna, for communication purposes. These two related functions are often combined in a single device to reduce manufacturing costs. The term is also used for other devices which can both transmit and receive through a communications channel, such as \"optical transceivers\" which transmit and receive light in optical fiber systems, and \"bus transceivers\" which transmit and receive digital data in computer data buses.\nRadio transceivers are widely used in wireless devices. One large use is in two-way radios, which are audio transceivers used for bidirectional person-to-person voice communication. Examples are cell phones, which transmit and receive the two sides of a phone conversation using radio waves to a cell tower, cordless phones in which both the phone handset and the base station have transceivers to communicate both sides of the conversation, and land mobile radio systems like walkie-talkies and CB radios. Another large use is in wireless modems in mobile networked computer devices such laptops, pads, and cellphones, which both transmit digital data to and receive data from a wireless router. Aircraft carry automated microwave transceivers called transponders which, when they are triggered by microwaves from an air traffic control radar, transmit a coded signal back to the radar to identify the aircraft. Satellite transponders in communication satellites receive digital telecommunication data from a satellite ground station, and retransmit it to another ground station.\nHistory.\nThe transceiver first appeared in the 1920s. Before then, receivers and transmitters were manufactured separately and devices that wanted to receive and transmit data required both components. Almost all amateur radio equipment today uses transceivers, but there is an active market for pure radio receivers, which are mainly used by shortwave listening operators.\nAnalog.\nAnalog transceivers use frequency modulation to send and receive data. Although this technique limits the complexity of the data that can be broadcast, analog transceivers operate very reliably and are used in many emergency communication systems. They are also cheaper than digital transceivers, which makes them popular with the CB and HAM radio communities.\nDigital.\nDigital transceivers send and receive binary data over radio waves. This allows more types of data to be broadcast, including video and encrypted communication, which is commonly used by police and fire departments. Digital transmissions tend to be clearer and more detailed than their analog counterparts. Many modern wireless devices operate on digital transmissions.\nUsage.\nTelephony.\nIn a wired telephone, the handset contains the transmitter (for speaking) and receiver (for listening). Despite being able to transmit and receive data, the whole unit is colloquially referred to as a \"receiver\". On a mobile telephone or other radiotelephone, the entire unit is a transceiver for both audio and radio.\nA cordless telephone uses an audio and radio transceiver for the handset, and a radio transceiver for the base station. If a speakerphone is included in a wired telephone base or in a cordless base station, the base also becomes an audio transceiver.\nA modem is similar to a transceiver in that it sends and receives a signal, but a modem uses modulation and demodulation. It modulates the signal being transmitted and demodulates the signal being received.\nEthernet.\nTransceivers are called Medium Attachment Units (MAUs) in IEEE 802.3 documents and were widely used in 10BASE2 and 10BASE5 Ethernet networks. Fiber-optic gigabit, 10 Gigabit Ethernet, 40 Gigabit Ethernet, and 100 Gigabit Ethernet utilize GBIC, SFP, SFP+, QSFP, XFP, XAUI, CXP, and CFP transceiver systems.\nRegulation.\nBecause transceivers are capable of broadcasting information over airwaves, they are required to adhere to various regulations. In the United States, the Federal Communications Commission oversees their use. Transceivers must meet certain standards and capabilities depending on their intended use, and manufacturers must comply with these requirements. However, transceivers can be modified by users to violate FCC regulations. For instance, they might be used to broadcast on a frequency or channel that they should not have access to. For this reason, the FCC monitors not only the production but also the use of these devices.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41806", "revid": "3188090", "url": "https://en.wikipedia.org/wiki?curid=41806", "title": "Transcode", "text": ""}
{"id": "41807", "revid": "1588193", "url": "https://en.wikipedia.org/wiki?curid=41807", "title": "Transmission", "text": "Transmission or transmit may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41808", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41808", "title": "Transmission block", "text": "In telecommunications, the term transmission block has the following meanings:\nSome protocols require each transmission block to end with an end-of-message marker. This is often a control character such as End-of-Text (ETX), End-of-Transmission-Block (ETB), or End-of-Transmission (EOT).\nSome protocols (especially those requiring ETX) require each transmission block to begin with a Start-of-Text character (STX)."}
{"id": "41809", "revid": "266283", "url": "https://en.wikipedia.org/wiki?curid=41809", "title": "Transmission coefficient (optics)", "text": ""}
{"id": "41810", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41810", "title": "Transmission level point", "text": "Test point for signal monitoring\nIn telecommunications, a transmission level point (TLP) is a test point in an electronic circuit that is typically a transmission channel. At the TLP, a test signal may be introduced or measured. Various parameters, such as the power of the signal, noise, voltage levels, wave forms, may be measured at the TLP.\nThe nominal transmission level at a TLP is a function of system design and is an expression of the design gain or attenuation (loss).\nVoice-channel transmission levels at test points are measured in decibel-milliwatts (dBm) at a frequency of ~1000 hertz.\nThe dBm is an absolute reference level measurement (see ) with respect to 1 mW power. When the nominal signal power is at the TLP, the test point is called a \"zero transmission level point\", or \"zero-dBm TLP\". The abbreviation dBm0 stands for the power in dBm measured at a zero transmission level point. The TLP is thus characterized by the relation:\nTLP = dBm \u2212 dBm0\nThe term \"TLP\" is commonly used as if it were a unit, preceded by the nominal level for the test point. For example, the expression ' refers to a '. If for instance a signal is specified as -13 dBm0 at a particular point and -6 dBm is measured at that point, the TLP is +7 TLP.\nThe level at a TLP where an end instrument, such as a telephone set, is connected is usually specified as .\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41811", "revid": "50163453", "url": "https://en.wikipedia.org/wiki?curid=41811", "title": "Transmission line", "text": "Cable or other structure for carrying radio waves\nIn electrical engineering, a transmission line is a specialized cable or other structure designed to conduct electromagnetic waves in a contained manner. The term applies when the conductors are long enough that the wave nature of the transmission must be taken into account. This applies especially to radio-frequency engineering because the short wavelengths mean that wave phenomena arise over very short distances (this can be as short as millimetres depending on frequency). However, the theory of transmission lines was historically developed to explain phenomena on very long telegraph lines, especially submarine telegraph cables.\nTransmission lines are used for purposes such as connecting radio transmitters and receivers with their antennas (they are then called feed lines or feeders), distributing cable television signals, trunklines routing calls between telephone switching centres, computer network connections and high speed computer data buses. RF engineers commonly use short pieces of transmission line, usually in the form of printed planar transmission lines, arranged in certain patterns to build circuits such as filters. These circuits, known as distributed-element circuits, are an alternative to traditional circuits using discrete capacitors and inductors.\nOverview.\nOrdinary electrical cables suffice to carry low frequency alternating current (AC), such as mains power, which reverses direction 100 to 120 times per second, and audio signals. However, they are not generally used to carry currents in the radio frequency range, above about 30\u00a0kHz, because the energy tends to radiate off the cable as radio waves, causing power losses. Radio frequency currents also tend to reflect from discontinuities in the cable such as connectors and joints, and travel back down the cable toward the source. These reflections act as bottlenecks, preventing the signal power from reaching the destination. Transmission lines use specialized construction, and impedance matching, to carry electromagnetic signals with minimal reflections and power losses. The distinguishing feature of most transmission lines is that they have uniform cross sectional dimensions along their length, giving them a uniform impedance, called the \"characteristic impedance\", to prevent reflections. Types of transmission line include parallel line (ladder line, twisted pair), coaxial cable, and planar transmission lines such as stripline and microstrip. The higher the frequency of electromagnetic waves moving through a given cable or medium, the shorter the wavelength of the waves. Transmission lines become necessary when the transmitted frequency's wavelength is sufficiently short that the length of the cable becomes a significant part of a wavelength.\nAt frequencies of microwave and higher, power losses in transmission lines become excessive, and waveguides are used instead, which function as \"pipes\" to confine and guide the electromagnetic waves. Some sources define waveguides as a type of transmission line; however, this article will not include them.\nHistory.\nMathematical analysis of the behaviour of electrical transmission lines grew out of the work of James Clerk Maxwell, Lord Kelvin, and Oliver Heaviside. In 1855, Lord Kelvin formulated a diffusion model of the current in a submarine cable. The model correctly predicted the poor performance of the 1858 trans-Atlantic submarine telegraph cable. In 1885, Heaviside published the first papers that described his analysis of propagation in cables and the modern form of the telegrapher's equations.\nThe four terminal model.\nFor the purposes of analysis, an electrical transmission line can be modelled as a two-port network (also called a quadripole), as follows:\nIn the simplest case, the network is assumed to be linear (i.e. the complex voltage across either port is proportional to the complex current flowing into it when there are no reflections), and the two ports are assumed to be interchangeable. If the transmission line is uniform along its length, then its behaviour is largely described by two parameters called \"characteristic impedance\", symbol formula_1 and \"propagation delay\", symbol formula_2. formula_1 is the ratio of the complex voltage of a given wave to the complex current of the same wave at any point on the line. Typical values of formula_1 are for a coaxial cable, about for a twisted pair of wires, and about for a common type of untwisted pair used in radio transmission. Propagation delay is proportional to the length of the transmission line and is never less than the length divided by the speed of light. Typical delays for modern communication transmission lines vary from to .\nWhen sending power down a transmission line, it is usually desirable that as much power as possible will be absorbed by the load and as little as possible will be reflected back to the source. This can be ensured by making the load impedance equal to formula_1, in which case the transmission line is said to be \"matched\".\nSome of the power that is fed into a transmission line is lost because of its resistance. This effect is called \"ohmic\" or \"resistive\" loss (see ohmic heating). At high frequencies, another effect called \"dielectric loss\" becomes significant, adding to the losses caused by resistance. Dielectric loss is caused when the insulating material inside the transmission line absorbs energy from the alternating electric field and converts it to heat (see dielectric heating). The transmission line is modelled with a resistance (formula_6) and inductance (formula_7) in series with a capacitance (formula_8) and conductance (formula_9) in parallel. The resistance and conductance contribute to the loss in a transmission line.\nThe total loss of power in a transmission line is often specified in decibels per metre (dB/m), and always depends on the frequency of the signal. The manufacturer often supplies a chart showing the loss in dB/m at a range of frequencies. A loss of corresponds approximately to a halving of the power.\nPropagation delay is often specified in units of nanoseconds per metre. While propagation delay usually depends on the frequency of the signal, transmission lines are typically operated over frequency ranges where the propagation delay is approximately constant.\nTelegrapher's equations.\nThe telegrapher's equations (or just telegraph equations) are a pair of linear differential equations which describe the voltage (formula_10) and current (formula_11) on an electrical transmission line with distance and time. They were developed by Oliver Heaviside who created the \"transmission line model\", and are based on Maxwell's equations.\nThe transmission line model is an example of the distributed-element model. It represents the transmission line as an infinite series of two-port elementary components, each representing an infinitesimally short segment of the transmission line:\nThe model consists of an \"infinite series\" of the elements shown in the figure, and the values of the components are specified \"per unit length\" so the picture of the component can be misleading. formula_6, formula_7, formula_8, and formula_9 may also be functions of frequency. An alternative notation is to use formula_20, formula_21, formula_22 and formula_23 to emphasize that the values are derivatives with respect to length. These quantities can also be known as the primary line constants to distinguish from the secondary line constants derived from them, these being the propagation constant, attenuation constant and phase constant.\nThe line voltage formula_24 and the current formula_25 can be expressed in the frequency domain as\nformula_26\nformula_27\n(see differential equation, angular frequency \u03c9 and imaginary unit j)\nSpecial case of a lossless line.\nWhen the elements formula_6 and formula_9 are negligibly small the transmission line is considered as a lossless structure. In this hypothetical case, the model depends only on the formula_7 and formula_8 elements which greatly simplifies the analysis. For a lossless transmission line, the second order steady-state Telegrapher's equations are:\nformula_32\nformula_33\nThese are wave equations which have plane waves with equal propagation speed in the forward and reverse directions as solutions. The physical significance of this is that electromagnetic waves propagate down transmission lines and in general, there is a reflected component that interferes with the original signal. These equations are fundamental to transmission line theory.\nGeneral case of a line with losses.\nIn the general case the loss terms, formula_6 and formula_9, are both included, and the full form of the Telegrapher's equations become:\nformula_36\nformula_37\nwhere formula_38 is the (complex) propagation constant. These equations are fundamental to transmission line theory. They are also wave equations, and have solutions similar to the special case, but which are a mixture of sines and cosines with exponential decay factors. Solving for the propagation constant formula_38 in terms of the primary parameters formula_6, formula_7, formula_9, and formula_8 gives:\nformula_44\nand the characteristic impedance can be expressed as\nformula_45\nThe solutions for formula_24 and formula_25 are:\nformula_48\nformula_49\nThe constants formula_50 must be determined from boundary conditions. For a voltage pulse formula_51, starting at formula_52 and moving in the positive formula_53\u00a0direction, then the transmitted pulse formula_54 at position formula_53 can be obtained by computing the Fourier Transform, formula_56, of formula_51, attenuating each frequency component by formula_58, advancing its phase by formula_59, and taking the inverse Fourier Transform. The real and imaginary parts of formula_38 can be computed as\nformula_61\nformula_62\nwith\nformula_63\nformula_64\nthe right-hand expressions holding when neither formula_7, nor formula_8, nor formula_67 is zero, and with\nformula_68\nwhere atan2 is the everywhere-defined form of two-parameter arctangent function, with arbitrary value zero when both arguments are zero.\nAlternatively, the complex square root can be evaluated algebraically, to yield:\nformula_69\nand\nformula_70\nwith the plus or minus signs chosen opposite to the direction of the wave's motion through the conducting medium. (a is usually negative, since formula_9 and formula_6 are typically much smaller than formula_73 and formula_74, respectively, so \u2212a is usually positive. b is always positive.)\nSpecial, low loss case.\nFor small losses and high frequencies, the general equations can be simplified: If formula_75 and formula_76 then\nformula_77\nformula_78\nSince an advance in phase by formula_79 is equivalent to a time delay by formula_80, formula_81 can be simply computed as\nformula_82\nHeaviside condition.\nThe Heaviside condition is formula_83. \nIf R, G, L, and C are constants that are \"not\" frequency dependent and the Heaviside condition is met, \nthen waves travel down the transmission line without dispersion distortion.\nInput impedance of transmission line.\nThe characteristic impedance formula_1 of a transmission line is the ratio of the amplitude of a \"single\" voltage wave to its current wave. Since most transmission lines also have a reflected wave, the characteristic impedance is generally not the impedance that is measured on the line.\nThe impedance measured at a given distance formula_85 from the load impedance formula_86 may be expressed as\nformula_87,\nwhere formula_38 is the propagation constant and formula_89 is the voltage reflection coefficient measured at the load end of the transmission line. Alternatively, the above formula can be rearranged to express the input impedance in terms of the load impedance rather than the load voltage reflection coefficient:\nformula_90.\nInput impedance of lossless transmission line.\nFor a lossless transmission line, the propagation constant is purely imaginary, formula_91, so the above formulas can be rewritten as\nformula_92\nwhere formula_93 is the wavenumber.\nIn calculating formula_94 the wavelength is generally different \"inside\" the transmission line to what it would be in free-space. Consequently, the velocity factor of the material the transmission line is made of needs to be taken into account when doing such a calculation.\nSpecial cases of lossless transmission lines.\nHalf wave length.\nFor the special case where formula_95 where n is an integer (meaning that the length of the line is a multiple of half a wavelength), the expression reduces to the load impedance so that\nformula_96\nfor all formula_97 This includes the case when formula_98, meaning that the length of the transmission line is negligibly small compared to the wavelength. The physical significance of this is that the transmission line can be ignored (i.e. treated as a wire) in either case.\nQuarter wave length.\nFor the case where the length of the line is one quarter wavelength long, or an odd multiple of a quarter wavelength long, the input impedance becomes\nformula_99\nMatched load.\nAnother special case is when the load impedance is equal to the characteristic impedance of the line (i.e. the line is \"matched\"), in which case the impedance reduces to the characteristic impedance of the line so that\nformula_100\nfor all formula_85 and all formula_102.\nShort.\nFor the case of a shorted load (i.e. formula_103), the input impedance is purely imaginary and a periodic function of position and wavelength (frequency)\nformula_104\nOpen.\nFor the case of an open load (i.e. formula_105), the input impedance is once again imaginary and periodic\nformula_106\nMatrix parameters.\nThe simulation of transmission lines embedded into larger systems generally utilize transmission-parameters (ABCD matrix), admittance parameters (Y matrix), impedance parameters (Z matrix), and/or scattering parameters (S matrix) that embodies the full transmission line model needed to support the simulation.\nTransmission parameters.\nTransmission lines are mainly defined in using ABCD parameters or transmission parameters. The ABCD parameters of a lossless transmission line can be defined as \nformula_107 \nAs formula_108, the transmission lines are symmetric networks. It also satisfies reciprocity condition formula_109. For a lossy transmission line the ABCD matrix can be written as \nformula_110\nAdmittance parameters.\nAdmittance (Y) parameters may be defined by applying a fixed voltage to one port (V1) of a transmission line with the other end shorted to ground and measuring the resulting current running into each port (I1, I2) and computing the admittance on each port as a ratio of I/V The admittance parameter Y11 is I1/V1, and the admittance parameter Y12 is I2/V1. Since transmission lines are electrically passive and symmetric devices, Y12 = Y21, and Y11 = Y22.\nFor lossless and lossy transmission lines respectively, the Y parameter matrix is as follows:\nformula_111\nImpedance parameters.\nImpedance (Z) parameter may defines by applying a fixed current into one port (I1) of a transmission line with the other port open and measuring the resulting voltage on each port (V1, V2) and computing the impedance parameter Z11 is V1/I1, and the impedance parameter Z12 is V2/I1. Since transmission lines are electrically passive and symmetric devices, V12 = V21, and V11 = V22.\nIn the Y and Z matrix definitions, formula_112 and formula_113. Unlike ideal lumped 2 port elements (resistors, capacitors, inductors, etc.) which do not have defined Z parameters, transmission lines have an internal path to ground, which permits the definition of Z parameters.\nFor lossless and lossy transmission lines respectively, the Z parameter matrix is as follows:\nformula_114\nScattering parameters.\nScattering (S) matrix parameters model the electrical behavior of the transmission line with matched loads at each termination.\nFor lossless and lossy transmission lines respectively, the S parameter matrix is as follows, using standard hyperbolic to circular complex translations.\nformula_115\nVariable definitions.\nIn all matrix parameters above, the following variable definitions apply:\nformula_116 = characteristic impedance\nZp = port impedance, or termination impedance\nformula_117 = the propagation constant per unit length\nformula_118 = attenuation constant in nepers per unit length\nformula_119 = wave number or phase constant radians per unit length\nformula_67 = frequency radians / second\nformula_121 = Speed of propagation\nformula_102 = wave length in unit length\nL = inductance per unit length\nC = capacitance per unit length\nformula_123 = effective dielectric constant\nformula_124 = 299,792,458 meters / second = Speed of light in a vacuum\nCoupled transmission lines.\nTransmission lines may be placed in proximity to each other such that they electrically interact, such as two microstrip lines in close proximity. Such transmission lines are said to be coupled transmission lines. Coupled transmission lines are characterized by an even and odd mode analysis. The even mode is characterized by excitation of the two conductors with a signal of equal amplitude and phase. The odd mode is characterized by excitation with signals of equal and opposite magnitude. The even and odd modes each have their own characteristic impedances (Zoe, Zoo) and phase constants (formula_125). Lossy coupled transmission lines have their own even and odd mode attenuation constants (formula_126), which in turn leads to even and odd mode propagation constants (formula_127).\nCoupled matrix parameters.\nCoupled transmission lines may be modeled using even and odd mode transmission line parameters defined in the prior paragraph as shown with ports 1 and 2 on the input and ports 3 and 4 on the output,\nformula_128..\nPractical types.\nCoaxial cable.\nCoaxial lines confine virtually all of the electromagnetic wave to the area inside the cable. Coaxial lines can therefore be bent and twisted (subject to limits) without negative effects, and they can be strapped to conductive supports without inducing unwanted currents in them.\nIn radio-frequency applications up to a few gigahertz, the wave propagates in the transverse electric and magnetic mode (TEM) only, which means that the electric and magnetic fields are both perpendicular to the direction of propagation (the electric field is radial, and the magnetic field is circumferential). However, at frequencies for which the wavelength (in the dielectric) is significantly shorter than the circumference of the cable other transverse modes can propagate. These modes are classified into two groups, transverse electric (TE) and transverse magnetic (TM) waveguide modes. When more than one mode can exist, bends and other irregularities in the cable geometry can cause power to be transferred from one mode to another.\nThe most common use for coaxial cables is for television and other signals with bandwidth of multiple megahertz. In the middle 20th\u00a0century they carried long distance telephone connections.\nPlanar lines.\nPlanar transmission lines are transmission lines with conductors, or in some cases dielectric strips, that are flat, ribbon-shaped lines. They are used to interconnect components on printed circuits and integrated circuits working at microwave frequencies because the planar type fits in well with the manufacturing methods for these components. Several forms of planar transmission lines exist.\nMicrostrip.\nA microstrip circuit uses a thin flat conductor which is parallel to a ground plane. Microstrip can be made by having a strip of copper on one side of a printed circuit board (PCB) or ceramic substrate while the other side is a continuous ground plane. The width of the strip, the thickness of the insulating layer (PCB or ceramic) and the dielectric constant of the insulating layer determine the characteristic impedance. Microstrip is an open structure whereas coaxial cable is a closed structure.\nStripline.\nA stripline circuit uses a flat strip of metal which is sandwiched between two parallel ground planes. The insulating material of the substrate forms a dielectric. The width of the strip, the thickness of the substrate and the relative permittivity of the substrate determine the characteristic impedance of the strip which is a transmission line.\nCoplanar waveguide.\nA coplanar waveguide consists of a center strip and two adjacent outer conductors, all three of them flat structures that are deposited onto the same insulating substrate and thus are located in the same plane (\"coplanar\"). The width of the center conductor, the distance between inner and outer conductors, and the relative permittivity of the substrate determine the characteristic impedance of the coplanar transmission line.\nBalanced lines.\nA balanced line is a transmission line consisting of two conductors of the same type, and equal impedance to ground and other circuits. There are many formats of balanced lines, amongst the most common are twisted pair, star quad and twin-lead.\nTwisted pair.\nTwisted pairs are commonly used for terrestrial telephone communications. In such cables, many pairs are grouped together in a single cable, from two to several thousand. The format is also used for data network distribution inside buildings, but the cable is more expensive because the transmission line parameters are tightly controlled.\nStar quad.\nStar quad is a four-conductor cable in which all four conductors are twisted together around the cable axis. It is sometimes used for two circuits, such as 4-wire telephony and other telecommunications applications. In this configuration each pair uses two non-adjacent conductors. Other times it is used for a single, balanced line, such as audio applications and 2-wire telephony. In this configuration two non-adjacent conductors are terminated together at both ends of the cable, and the other two conductors are also terminated together.\nWhen used for two circuits, crosstalk is reduced relative to cables with two separate twisted pairs.\nWhen used for a single, balanced line, magnetic interference picked up by the cable arrives as a virtually perfect common mode signal, which is easily removed by coupling transformers.\nThe combined benefits of twisting, balanced signalling, and quadrupole pattern give outstanding noise immunity, especially advantageous for low signal level applications such as microphone cables, even when installed very close to a power cable. The disadvantage is that star quad, in combining two conductors, typically has double the capacitance of similar two-conductor twisted and shielded audio cable. High capacitance causes increasing distortion and greater loss of high frequencies as distance increases.\nTwin-lead.\nTwin-lead consists of a pair of conductors held apart by a continuous insulator. By holding the conductors a known distance apart, the geometry is fixed and the line characteristics are reliably consistent. It is lower loss than coaxial cable because the characteristic impedance of twin-lead is generally higher than coaxial cable, leading to lower resistive losses due to the reduced current. However, it is more susceptible to interference.\nLecher lines.\nLecher lines are a form of parallel conductor that can be used at UHF for creating resonant circuits. They are a convenient practical format that fills the gap between lumped components (used at HF/VHF) and resonant cavities (used at UHF/SHF).\nSingle-wire line.\nUnbalanced lines were formerly much used for telegraph transmission, but this form of communication has now fallen into disuse. Cables are similar to twisted pair in that many cores are bundled into the same cable but only one conductor is provided per circuit and there is no twisting. All the circuits on the same route use a common path for the return current (earth return). There is a power transmission version of single-wire earth return in use in many locations.\nGeneral applications.\nSignal transfer.\nElectrical transmission lines are very widely used to transmit high frequency signals over long or short distances with minimum power loss. One familiar example is the down lead from a TV or radio aerial to the receiver.\nTransmission line circuits.\nA large variety of circuits can also be constructed with transmission lines including impedance matching circuits, filters, power dividers and directional couplers.\nStepped transmission line.\nA stepped transmission line is used for broad range impedance matching. It can be considered as multiple transmission line segments connected in series, with the characteristic impedance of each individual element to be formula_129. The input impedance can be obtained from the successive application of the chain relation\nformula_130\nwhere formula_131 is the wave number of the formula_132-th transmission line segment and formula_133 is the length of this segment, and formula_134 is the front-end impedance that loads the formula_132-th segment.\nBecause the characteristic impedance of each transmission line segment formula_129 is often different from the impedance formula_1 of the fourth, input cable (only shown as an arrow marked formula_1 on the left side of the diagram above), the impedance transformation circle is off-centred along the formula_53 axis of the Smith Chart whose impedance representation is usually normalized against formula_1.\nApproximating lumped elements.\nAt higher frequencies, the reactive parasitic effects of real world lumped elements, including inductors and capacitors, limits their usefulness. Therefore, it is sometimes useful to approximate the electrical characteristics of inductors and capacitors with transmission lines at the higher frequencies using Richards' Transformations and then substitute the transmission lines for the lumped elements.\nMore accurate forms of multimode high frequency inductor modeling with transmission lines exist for advanced designers.\nStub filters.\nIf a short-circuited or open-circuited transmission line is wired in parallel with a line used to transfer signals from point A to point B, then it will function as a filter. The method for making stubs is similar to the method for using Lecher lines for crude frequency measurement, but it is 'working backwards'. One method recommended in the RSGB's radiocommunication handbook is to take an open-circuited length of transmission line wired in parallel with the feeder delivering signals from an aerial. By cutting the free end of the transmission line, a minimum in the strength of the signal observed at a receiver can be found. At this stage the stub filter will reject this frequency and the odd harmonics, but if the free end of the stub is shorted then the stub will become a filter rejecting the even harmonics.\nWideband filters can be achieved using multiple stubs. However, this is a somewhat dated technique. Much more compact filters can be made with other methods such as parallel-line resonators.\nPulse generation.\nTransmission lines are used as pulse generators. By charging the transmission line and then discharging it into a resistive load, a rectangular pulse equal in length to twice the electrical length of the line can be obtained, although with half the voltage. A Blumlein transmission line is a related pulse forming device that overcomes this limitation. These are sometimes used as the pulsed power sources for radar transmitters and other devices.\nSound.\nThe theory of sound wave propagation is very similar mathematically to that of electromagnetic waves, so techniques from transmission line theory are also used to build structures to conduct acoustic waves; and these are called acoustic transmission lines.\nReferences.\n\"Part of this article was derived from Federal Standard 1037C.\"\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41812", "revid": "5183450", "url": "https://en.wikipedia.org/wiki?curid=41812", "title": "Transmission medium", "text": "Conduit for signal propagation\nA transmission medium is a system or substance that can mediate the propagation of signals for the purposes of telecommunication. Signals are typically imposed on a wave of some kind suitable for the chosen medium. For example, data can modulate sound, and a transmission medium for sounds may be air, but solids and liquids may also act as the transmission medium. Vacuum or air constitutes a good transmission medium for electromagnetic waves such as light and radio waves. While a material substance is not required for electromagnetic waves to propagate, such waves are usually affected by the transmission medium they pass through, for instance, by absorption or reflection or refraction at the interfaces between media. Technical devices can therefore be employed to transmit or guide waves. Thus, an optical fiber or a copper cable is used as transmission media.\nElectromagnetic radiation can be transmitted through an optical medium, such as optical fiber, or through twisted pair wires, coaxial cable, or dielectric-slab waveguides. It may also pass through any physical material that is transparent to the specific wavelength, such as water, air, glass, or concrete. Sound is, by definition, the vibration of matter, so it requires a physical medium for transmission, as do other kinds of mechanical waves and heat energy. Historically, science incorporated various aether theories to explain the transmission medium. However, it is now known that electromagnetic waves do not require a physical transmission medium, and so can travel through the vacuum of free space. Regions of the insulative vacuum can become conductive for electrical conduction through the presence of free electrons, holes, or ions.\nTelecommunications.\nA physical medium in data communications is the transmission path over which a signal propagates. Many different types of transmission media are used as communications channel.\nIn many cases, communication is in the form of electromagnetic waves. With guided transmission media, the waves are guided along a physical path; examples of guided media include phone lines, twisted pair cables, coaxial cables, and optical fibers. Unguided transmission media are methods that allow the transmission of data without the use of physical means to define the path it takes. Examples of this include microwave, radio or infrared. Unguided media provide a means for transmitting electromagnetic waves but do not guide them; examples are propagation through air, vacuum and seawater.\nThe term direct link is used to refer to the transmission path between two devices in which signals propagate directly from transmitters to receivers with no intermediate devices, other than amplifiers or repeaters used to increase signal strength. This term can apply to both guided and unguided media.\nSimplex versus duplex.\nA signal transmission may be simplex, half-duplex, or full-duplex.\nIn simplex transmission, signals are transmitted in only one direction; one station is a transmitter and the other is the receiver. In the half-duplex operation, both stations may transmit, but only one at a time. In full-duplex operation, both stations may transmit simultaneously. In the latter case, the medium is carrying signals in both directions at the same time.\nTypes.\nIn general, a transmission medium can be classified as\nThere are two main types of transmission media:\nOne of the most common physical medium used in networking is copper wire. Copper wire to carry signals to long distances using relatively low amounts of power. The unshielded twisted pair (UTP) is eight strands of copper wire, organized into four pairs.\nGuided media.\nTwisted pair.\n\"Twisted pair\" cabling is a type of wiring in which two conductors of a single circuit are twisted together for the purposes of improving electromagnetic compatibility. Compared to a single conductor or an untwisted balanced pair, a twisted pair reduces electromagnetic radiation from the pair and crosstalk between neighboring pairs and improves rejection of external electromagnetic interference. It was invented by Alexander Graham Bell.\nCoaxial cable.\n\"Coaxial cable\", or \"coax\" (pronounced ) is a type of electrical cable that has an inner conductor surrounded by a tubular insulating layer, surrounded by a tubular conducting shield. Many coaxial cables also have an insulating outer sheath or jacket. The term coaxial comes from the inner conductor and the outer shield sharing a geometric axis. Coaxial cable was invented by English physicist, engineer, and mathematician Oliver Heaviside, who patented the design in 1880.\nCoaxial cable is a type of transmission line, used to carry high frequency electrical signals with low losses. It is used in such applications as telephone trunk lines, broadband internet networking cables, high-speed computer data busses, carrying cable television signals, and connecting radio transmitters and receivers to their antennas. It differs from other shielded cables because the dimensions of the cable and connectors are controlled to give a precise, constant conductor spacing, which is needed for it to function efficiently as a transmission line.\nOptical fiber.\n\"Optical fiber\", which has emerged as the most commonly used transmission medium for long-distance communications, is a thin strand of glass that guides light along its length. Four major factors favor optical fiber over copper: data rates, distance, installation, and costs. Optical fiber can carry huge amounts of data compared to copper. It can be run for hundreds of miles without the need for signal repeaters, in turn, reducing maintenance costs and improving the reliability of the communication system because repeaters are a common source of network failures. Glass is lighter than copper allowing for less need for specialized heavy-lifting equipment when installing long-distance optical fiber. Optical fiber for indoor applications cost approximately a dollar a foot, the same as copper.\nMultimode and single mode are two types of commonly used optical fiber. Multimode fiber uses LEDs as the light source and can carry signals over shorter distances, about 2 kilometers. Single mode can carry signals over distances of tens of miles.\nAn \"optical fiber\" is a flexible, transparent fiber made by drawing glass (silica) or plastic to a diameter slightly thicker than that of a human hair. Optical fibers are used most often as a means to transmit light between the two ends of the fiber and find wide usage in fiber-optic communications, where they permit transmission over longer distances and at higher bandwidths (data rates) than electrical cables. Fibers are used instead of metal wires because signals travel along them with less loss; in addition, fibers are immune to electromagnetic interference, a problem from which metal wires suffer excessively. Fibers are also used for illumination and imaging, and are often wrapped in bundles so they may be used to carry light into, or images out of confined spaces, as in the case of a fiberscope. Specially designed fibers are also used for a variety of other applications, some of them being fiber optic sensors and fiber lasers.\nOptical fibers typically include a core surrounded by a transparent cladding material with a lower index of refraction. Light is kept in the core by the phenomenon of total internal reflection which causes the fiber to act as a waveguide. Fibers that support many propagation paths or transverse modes are called multi-mode fibers, while those that support a single mode are called single-mode fibers (SMF). Multi-mode fibers generally have a wider core diameter and are used for short-distance communication links and for applications where high power must be transmitted. Single-mode fibers are used for most communication links longer than .\nBeing able to join optical fibers with low loss is important in fiber optic communication. This is more complex than joining electrical wire or cable and involves careful cleaving of the fibers, precise alignment of the fiber cores, and the coupling of these aligned cores. For applications that demand a permanent connection a fusion splice is common. In this technique, an electric arc is used to melt the ends of the fibers together. Another common technique is a mechanical splice, where the ends of the fibers are held in contact by mechanical force. Temporary or semi-permanent connections are made by means of specialized optical fiber connectors.\nThe field of applied science and engineering concerned with the design and application of optical fibers is known as fiber optics. The term was coined by Indian physicist Narinder Singh Kapany, who is widely acknowledged as the father of fiber optics.\nUnguided transmission media.\nRadio.\n\"Radio propagation\" is the behavior of radio waves as they travel, or are propagated, from one point to another, or into various parts of the atmosphere. As a form of electromagnetic radiation, like light waves, radio waves are affected by the phenomena of reflection, refraction, diffraction, absorption, polarization, and scattering. Understanding the effects of varying conditions on radio propagation has many practical applications, from choosing frequencies for international shortwave broadcasters, to designing reliable mobile telephone systems, to radio navigation, to operation of radar systems.\nDifferent types of propagation are used in practical radio transmission systems. Line-of-sight propagation means radio waves that travel in a straight line from the transmitting antenna to the receiving antenna. Line of sight transmission is used to medium-range radio transmission such as cell phones, cordless phones, walkie-talkies, wireless networks, FM radio and television broadcasting and radar, and satellite communication, such as satellite television. Line-of-sight transmission on the surface of the Earth is limited to the distance to the visual horizon, which depends on the height of transmitting and receiving antennas. It is the only propagation method possible at microwave frequencies and above. At microwave frequencies, moisture in the atmosphere (rain fade) can degrade transmission.\nAt lower frequencies in the MF, LF, and VLF bands, due to diffraction radio waves can bend over obstacles like hills, and travel beyond the horizon as surface waves which follow the contour of the Earth. These are called ground waves. AM broadcasting stations use ground waves to cover their listening areas. As the frequency gets lower, the attenuation with distance decreases, so very low frequency (VLF) and extremely low frequency (ELF) ground waves can be used to communicate worldwide. VLF and ELF waves can penetrate significant distances through water and earth, and these frequencies are used for mine communication and military communication with submerged submarines.\nAt medium wave and shortwave frequencies (MF and HF bands) radio waves can refract from a layer of charged particles (ions) high in the atmosphere, called the ionosphere. This means that radio waves transmitted at an angle into the sky can be reflected back to Earth beyond the horizon, at great distances, even transcontinental distances. This is called skywave propagation. It is used by amateur radio operators to talk to other countries and shortwave broadcasting stations that broadcast internationally. Skywave communication is variable, dependent on conditions in the upper atmosphere; it is most reliable at night and in the winter. Due to its unreliability, since the advent of communication satellites in the 1960s, many long-range communication that previously used skywaves now use satellites.\nIn addition, there are several less common radio propagation mechanisms, such as tropospheric scattering (troposcatter) and near vertical incidence skywave (NVIS) which are used in specialized communication systems.\nDigital encoding.\nTransmission and reception of data is typically performed in four steps:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41813", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41813", "title": "Transmit-after-receive time delay", "text": "Time interval\nIn telecommunications, transmit-after-receive time delay is the time interval from removal of RF energy at the local receiver input until the local transmitter is automatically keyed on and the transmitted RF signal amplitude has increased to 90% of its steady-state value. \"An Exception:\" High-frequency (HF) transceiver equipment is normally not designed with an interlock between receiver squelch and transmitter on-off key. The transmitter can be keyed on at any time, independent of whether or not a signal is being received at the receiver input."}
{"id": "41814", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=41814", "title": "Transmit flow control", "text": ""}
{"id": "41815", "revid": "252195", "url": "https://en.wikipedia.org/wiki?curid=41815", "title": "Transmitter attack-time delay", "text": ""}
{"id": "41817", "revid": "37005538", "url": "https://en.wikipedia.org/wiki?curid=41817", "title": "Transponder", "text": "Device that emits an identifying signal in response to a received signal\nIn telecommunications, a transponder is a device that, upon receiving a signal, emits a different signal in response. The term is a blend of \"transmitter\" and \"responder\".\nIn air navigation or radio frequency identification, a flight transponder is an automated transceiver in an aircraft that emits a coded identifying signal in response to an interrogating received signal.\nIn a communications satellite, a satellite transponder receives signals over a range of uplink frequencies, usually from a satellite ground station; the transponder amplifies them, and re-transmits them on a different set of downlink frequencies to receivers on Earth, often without changing the content of the received signal or signals.\nSatellite/broadcast communications.\nA communications satellite\u2019s channels are called transponders because each is a separate transceiver or repeater. With digital video data compression and multiplexing, several video and audio channels may travel through a single transponder on a single wideband carrier. Original analog video only has one channel per transponder, with subcarriers for audio and automatic transmission identification service (ATIS). Non-multiplexed radio stations can also travel in single channel per carrier (SCPC) mode, with multiple carriers (analog or digital) per transponder. This allows each station to transmit directly to the satellite, rather than paying for a whole transponder, or using landlines to send it to an earth station for multiplexing with other stations.\nOptical communications.\nIn fiber-optic communications, a transponder is the element that sends and receives the optical signal from a fiber. A transponder is typically characterized by its data rate and the maximum distance the signal can travel.\nThe term \"transponder\" can apply to different items with important functional differences, mentioned across academic and commercial literature:\nAs a result, differences in transponder functionality also might influence the functional description of related optical modules like transceivers and muxponders.\nAviation.\nAnother type of transponder occurs in identification friend or foe (IFF) systems in military aviation and in air traffic control secondary surveillance radar (beacon radar) systems for general aviation and commercial aviation.\nPrimary radar works best with large all-metal aircraft, but not so well on small, composite aircraft. Its range is also limited by terrain and rain or snow and also detects unwanted objects such as automobiles, hills and trees. Furthermore, it cannot always estimate the altitude of an aircraft. Secondary radar overcomes these limitations but it depends on a transponder in the aircraft to respond to interrogations from the ground station to make the plane more visible.\nDepending on the type of interrogation, the transponder sends back a transponder code (or \"squawk code\", Mode A) or altitude information (Mode C) to help air traffic controllers to identify the aircraft and to maintain separation between planes. Another mode called Mode S (Mode Select) is designed to help avoiding over-interrogation of the transponder (having many radars in busy areas) and to allow automatic collision avoidance. Mode S transponders are backward compatible with Modes A and C. Mode S is mandatory in controlled airspace in many countries. Some countries have also required, or are moving toward requiring, that all aircraft be equipped with Mode S, even in uncontrolled airspace. However, in the field of general aviation there have been objections to these moves, because of the cost, size, limited benefit to the users in uncontrolled airspace, and, in the case of balloons and gliders, the power requirements during long flights.\nTransponders are used on some military aircraft to ensure ground personnel can verify the functionality of a missile's flight termination system prior to launch. Such radar-enhancing transponders are needed as the enclosed weapon bays on modern aircraft interfere with prelaunch, flight termination system verification performed by range safety personnel during training test launches. The transponders re-radiate the signals allowing for much longer communication distances.\nMarine.\nThe International Maritime Organization's International Convention for the Safety of Life at Sea (SOLAS) requires the Automatic Identification System (AIS) to be fitted aboard international voyaging ships with \u00a0gross tonnage\u00a0(GT), and all passenger ships regardless of size. AIS transmitters/receivers are generally called \"transponders\", but they generally transmit autonomously, although coast stations can interrogate on smaller vessels for additional information. In addition, navigational aids often have transponders called RACON (radar beacons) designed to make them stand out on a ship's radar screen.\nSonar transponders operate under water and are used to measure distance and form the basis of underwater location marking, position tracking and navigation.\nOther applications.\nElectronic toll collection.\nElectronic toll collection systems such as E-ZPass in the eastern United States use RFID transponders to identify vehicles.\nLap timing.\nTransponders are used in races for lap timing. A cable loop is dug into the race circuit near to the start/finish line. Each individual runner or car has an active transponder with a unique ID code. When the individual passes the start/finish line, the lap time and the racing position is shown on the score board.\nPassive and active RFID systems are used in motor sports, and off-road events such as Enduro and Hare and Hounds racing, the riders have a transponder on their person, normally on their arm. When they complete a lap they swipe or touch the receiver which is connected to a computer and log their lap time.\nNASCAR uses transponders and cable loops placed at numerous points around the track to determine the lineup during a caution period. This system replaced a dangerous race back to the start-finish line.\nCar keys.\nMany modern automobiles have keys with transponders hidden inside the plastic head of the key. The user of the car may not even be aware that the transponder is there, because there are no buttons to press. When a key is inserted into the ignition lock cylinder and turned, the car's computer sends a signal to the transponder. Unless the transponder replies with a valid code, the computer will not allow the engine to be started. Transponder keys have no battery; they are energized by the signal itself.\nGated communities.\nTransponders may also be used by residents to enter their gated communities. \nHowever, having more than one transponder causes problems. If a resident's car with simple transponder is parked in the vicinity, any vehicle can come up to the automated gate, triggering the gate interrogation signal, which may get an acceptable response from the resident's car. Such units properly installed might involve beamforming, unique transponders for each vehicle, or simply obliging vehicles to be stored away from the gate.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41819", "revid": "76", "url": "https://en.wikipedia.org/wiki?curid=41819", "title": "Transposition", "text": "Transposition may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41820", "revid": "18779361", "url": "https://en.wikipedia.org/wiki?curid=41820", "title": "Transverse redundancy check", "text": "Telecommunications redundancy check\nIn telecommunications, a transverse redundancy check (TRC) or vertical redundancy check is a redundancy check for synchronized parallel bits applied once per bit time, across the bit streams. This requires additional parallel channels for the check bit or bits.\nThe term usually applies to a single parity bit, although it could also be used to refer to a larger Hamming code.\nThe adjective \"transverse\" is most often used when it is used in combination with additional error control coding, such as a longitudinal redundancy check. Although parity alone can only detect and not correct errors, it can be part of a system for correcting errors.\nAn example of a TRC is the parity written to the 9th track of a 9-track tape."}
{"id": "41821", "revid": "50761979", "url": "https://en.wikipedia.org/wiki?curid=41821", "title": "Tree structure", "text": "Way of representing the hierarchical nature of a structure in a graphical form\nA tree structure, tree diagram, or tree model is a way of representing the hierarchical nature of a structure in a graphical form. It is named a \"tree structure\" because the classic representation resembles a tree, although the chart is generally upside down compared to a biological tree, with the \"stem\" at the top and the \"leaves\" at the bottom.\nA tree structure is conceptual, and appears in several forms. For a discussion of tree structures in specific fields, see Tree (data structure) for computer science; insofar as it relates to graph theory, see tree (graph theory) or tree (set theory). Other related articles are listed below.\nTerminology and properties.\nThe tree elements are called \"nodes\".\nThe lines connecting elements are called \"branches\". \nNodes without children are called leaf nodes, \"end-nodes\", or \"leaves\".\nEvery finite tree structure has a member that has no superior. This member is called the \"root\" or root node. The root is the starting node. But the converse is not true: infinite tree structures may or may not have a root node.\nThe names of relationships between nodes model the kinship terminology of family relations. The gender-neutral names \"parent\" and \"child\" have largely displaced the older \"father\" and \"son\" terminology. The term \"uncle\" is still widely used for other nodes at the same level as the parent, although it is sometimes replaced with gender-neutral terms like \"ommer\".\nIn the example, \"encyclopedia\" is the parent of \"science\" and \"culture\", its children. \"Art\" and \"craft\" are siblings, and children of \"culture\", which is their parent and thus one of their ancestors. Also, \"encyclopedia\", as the root of the tree, is the ancestor of \"science\", \"culture\", \"art\" and \"craft\". Finally, \"science\", \"art\" and \"craft\", as leaves, are ancestors of no other node.\nTree structures can depict all kinds of taxonomic knowledge, such as family trees, the biological evolutionary tree, the evolutionary tree of a language family, the grammatical structure of a language (a key example being S \u2192 NP VP, meaning a sentence is a noun phrase and a verb phrase, with each in turn having other components which have other components), the way web pages are logically ordered in a web site, mathematical trees of integer sets, et cetera.\nThe Oxford English Dictionary records use of both the terms \"tree structure\" and \"tree-diagram\" from 1965 in Noam Chomsky's \"Aspects of the Theory of Syntax\".\nIn a tree structure there is one and only one path from any point to any other point.\nComputer science uses tree structures extensively (\"see\" Tree (data structure) and telecommunications.)\nFor a formal definition see set theory, and for a generalization in which children are not necessarily successors, see prefix order.\nRepresenting trees.\nThere are many ways of visually representing tree structures.\nAlmost always, these boil down to variations, or combinations,\nof a few basic styles:\nClassical node-link diagrams.\nClassical node-link diagrams, that connect nodes together with line segments:\nNested sets.\nNested sets that use enclosure or containment to show parenthood; examples include TreeMaps, fractal maps, and Euler diagrams:\nLayered \"icicle\" diagrams.\nLayered \"icicle\" diagrams that use alignment/adjacency.\nOutlines and tree views.\nLists or diagrams that use indentation, sometimes called \"outlines\" or \"tree views\".\nAn outline:\nencyclopedia\nculture\nart\ncraft\nscience\nA tree view:\n&lt;templatestyles src=\"Tree list/styles.css\" /&gt;\nNested parentheses.\nA correspondence to nested parentheses was first noticed by Sir Arthur Cayley:\n((art,craft)culture,science)encyclopedia\nor\nencyclopedia(culture(art,craft),science)\nRadial trees.\nTrees can also be represented radially:\nFurther reading.\nIdentification of some of the basic styles of tree structures can be found in:"}
{"id": "41822", "revid": "18426370", "url": "https://en.wikipedia.org/wiki?curid=41822", "title": "Troposphere", "text": "Lowest layer of Earth's atmosphere\nThe troposphere is the lowest layer of the atmosphere of Earth. Pronounced , the name comes from grc \" \"\" ()\"\u00a0'turning, change' and \" -sphere\". It contains 80% of the total mass of the planetary atmosphere and 99% of the total mass of water vapor and aerosols, and is where most weather phenomena occur. From the planetary surface of the Earth, the average height of the troposphere is in the tropics; in the middle latitudes; and in the high latitudes of the polar regions in winter; thus the average height of the troposphere is .\nThe term \"troposphere\" derives from the Greek words \"tropos\" (rotating) and \"sphaira\" (sphere) indicating that rotational turbulence mixes the layers of air and so determines the structure and the phenomena of the troposphere. The rotational friction of the troposphere against the planetary surface affects the flow of the air, and so forms the planetary boundary layer (PBL) that varies in height from hundreds of meters up to . The measures of the PBL vary according to the latitude, the landform, and the time of day when the meteorological measurement is realized. Atop the troposphere is the tropopause, which is the functional atmospheric border that demarcates the troposphere from the stratosphere. As such, because the tropopause is an inversion layer in which air-temperature increases with altitude, the temperature of the tropopause remains constant. The layer has the largest concentration of nitrogen.\nStructure.\nComposition.\nThe Earth's planetary atmosphere is water vapour which is carbonic acid rain water, which therefore has an approximate natural pH of 5.0 to 5.5 (slightly acidic). (Water other than atmospheric water vapour fallen as fresh rain, such as fresh/sweet/potable/river water, will usually be affected by the physical environment and may not be in this pH range.) Atmospheric water vapour holds suspended gasses in it (not by mass), 78.08% nitrogen as N2, 20.95% oxygen as O2, 0.93% argon, trace gases, and variable amounts of condensing water (from saturated water vapor). Any carbon dioxide released into the atmosphere from a pressurised source combines with the carbonic acid water vapour and momentarily reduces the atmospheric pH by negligible amounts. Respiration from animals releases out of equilibrium carbonic acid and low levels of other ions. Combustion of hydrocarbons releases to atmosphere carbonic acid water as; saturates, condensates, vapour or gas (invisible steam). Combustion can releases particulates (carbon/soot and ash) as well as molecules forming nitrites and sulphites which will reduce the atmospheric pH of the water slightly or harmfully in highly industrialised areas where this is classed as air pollution and can create the phenomena of acid rain, a pH lower than the natural pH5.56. The negative effects of the by-products of combustion released into the atmospheric vapour can be removed by the use of scrubber towers and other physical means, the captured pollutants can be processed into a valuable by-product. The sources of atmospheric water vapor are the bodies of water (oceans, seas, lakes, rivers, swamps), and vegetation on the planetary surface, which humidify the troposphere through the processes of evaporation and transpiration respectively, and which influences the occurrence of weather phenomena; the greatest proportion of water vapor is in the atmosphere nearest the surface of the Earth. The temperature of the troposphere decreases at high altitude by way of the inversion layers that occur in the tropopause, which is the atmospheric boundary that demarcates the troposphere from the stratosphere. At higher altitudes, the low air-temperature consequently decreases the saturation vapor pressure, the amount of atmospheric water vapor in the upper troposphere.\nPressure.\nThe maximum air pressure (weight of the atmosphere) is at sea level and decreases at high altitude because the atmosphere is in hydrostatic equilibrium, wherein the air pressure is equal to the weight of the air above a given point on the planetary surface. The relation between decreased air pressure and high altitude can be equated to the density of a fluid, by way of the following hydrostatic equation:\nformula_1\nwhere:\n*\"gn\" is the standard gravity\n*\"\u03c1\" is the density\n*\"z\" is the altitude\n*\"P\" is the pressure\n*\"R\" is the gas constant\n*\"T\" is the thermodynamic (absolute) temperature\n*\"m\" is the molar mass\nTemperature.\nThe planetary surface of the Earth heats the troposphere by means of latent heat, thermal radiation, and sensible heat.\nThe gas layers of the troposphere are less dense at the geographic poles and denser at the equator, where the average height of the tropical troposphere is 13\u00a0km, approximately 7.0\u00a0km greater than the 6.0\u00a0km average height of the polar troposphere at the geographic poles; therefore, surplus heating and vertical expansion of the troposphere occur in the tropical latitudes. At the middle latitudes, tropospheric temperatures decrease from an average temperature of at sea level to approximately at the tropopause. At the equator, the tropospheric temperatures decrease from an average temperature of at sea level to approximately at the tropopause. At the geographical poles, the Arctic and the Antarctic regions, the tropospheric temperature decreases from an average temperature of at sea level to approximately at the tropopause.\nAltitude.\nThe temperature of the troposphere decreases with increased altitude, and the rate of decrease in air temperature is measured with the environmental lapse rate (formula_2), which is the numeric difference between the temperature of the planetary surface and the temperature of the tropopause divided by the altitude. Functionally, the ELR equation presumes that the planetary atmosphere is static and that there is no mixing of the layers of air by either vertical atmospheric convection or winds that could create turbulence.\nThe difference in temperature derives from the planetary surface absorbing most of the energy from the sun, which then radiates outwards and heats the troposphere (the first layer of the atmosphere of Earth) while the radiation of surface heat to the upper atmosphere results in the cooling of that layer of the atmosphere. The ELR equation also assumes that the atmosphere is static, but heated air becomes buoyant, expands, and rises. The dry adiabatic lapse rate (DALR) accounts for the effect of the expansion of dry air as it rises in the atmosphere, and the wet adiabatic lapse rate (WALR) includes the effect of the condensation-rate of water vapor upon the environmental lapse rate.\nCompression and expansion.\nA parcel of air rises and expands because of the lower atmospheric pressure at high altitudes. The expansion of the air parcel pushes outwards against the surrounding air, and transfers energy (as work) from the parcel of air to the atmosphere. Transferring energy to a parcel of air by way of heat is a slow and inefficient exchange of energy with the environment, which is an adiabatic process (no energy transfer by way of heat). As the rising parcel of air loses energy while it acts upon the surrounding atmosphere, no heat energy is transferred from the atmosphere to the air parcel to compensate for the heat loss. The parcel of air loses energy as it reaches greater altitude, which is manifested as a decrease in the temperature of the air mass. Analogously, the reverse process occurs within a cold parcel of air that is being compressed and is sinking to the planetary surface.\nThe compression and the expansion of an air parcel are reversible phenomena in which energy is not transferred into or out of the air parcel; atmospheric compression and expansion are measured as an isentropic process (formula_3) wherein there occurs no change in entropy as the air parcel rises or falls within the atmosphere. Because the heat exchanged (formula_4) is related to the change in entropy (formula_5 by formula_6) the equation governing the air temperature as a function of altitude for a mixed atmosphere is: formula_7 where S is the entropy. The isentropic equation states that atmospheric entropy does not change with altitude; the adiabatic lapse rate measures the rate at which temperature decreases with altitude under such conditions.\nHumidity.\nIf the air contains water vapor, then cooling of the air can cause the water to condense, and the air no longer functions as an ideal gas. If the air is at the saturation vapor pressure, then the rate at which temperature decreases with altitude is called the saturated adiabatic lapse rate. The actual rate at which the temperature decreases with altitude is the environmental lapse rate. In the troposphere, the average environmental lapse rate is a decrease of about 6.5\u00a0\u00b0C for every 1.0\u00a0km (1,000m) of increased altitude.\nFor dry air, an approximately ideal gas, the adiabatic equation is: formula_8 wherein formula_9 is the heat capacity ratio (formula_10&lt;templatestyles src=\"Fraction/styles.css\" /&gt;7\u20445) for air. The combination of the equation for the air pressure yields the dry adiabatic lapse rate:formula_11.\nEnvironment.\nThe environmental lapse rate (formula_12), at which temperature decreases with altitude, usually is unequal to the adiabatic lapse rate (formula_13). If the upper air is warmer than predicted by the adiabatic lapse rate (formula_14), then a rising and expanding parcel of air will arrive at the new altitude at a lower temperature than the surrounding air. In which case, the air parcel is denser than the surrounding air, and so falls back to its original altitude as an air mass that is stable against being lifted. If the upper air is cooler than predicted by the adiabatic lapse rate, then, when the air parcel rises to a new altitude, the air mass will have a higher temperature and a lower density than the surrounding air and will continue to accelerate and rise.\nTropopause.\nThe tropopause is the atmospheric boundary layer between the troposphere and the stratosphere, and is located by measuring the changes in temperature relative to increased altitude in the troposphere and in the stratosphere. In the troposphere, the temperature of the air decreases at high altitude, however, in the stratosphere the air temperature initially is constant, and then increases with altitude. The increase of air temperature at stratospheric altitudes results from the ozone layer's absorption and retention of the ultraviolet (UV) radiation that Earth receives from the Sun. The coldest layer of the atmosphere, where the temperature lapse rate changes from a positive rate (in the troposphere) to a negative rate (in the stratosphere) locates and identifies the tropopause as an inversion layer in which limited mixing of air layers occurs between the troposphere and the stratosphere.\nAtmospheric flow.\nThe general flow of the atmosphere is from west to east, which, however, can be interrupted by polar flows, either north-to-south flow or a south-to-north flow, which meteorology describes as a zonal flow and as a meridional flow. The terms are used to describe localized areas of the atmosphere at a synoptic scale; the three-cell model more fully explains the zonal and meridional flows of the planetary atmosphere of the Earth.\nThree-cell model.\nThe three-cell model of the atmosphere of the Earth describes the actual flow of the atmosphere with the tropical-latitude Hadley cell, the mid-latitude Ferrel cell, and the polar cell to describe the flow of energy and the circulation of the planetary atmosphere. Balance is the fundamental principle of the model \u2013 that the solar energy absorbed by the Earth in a year is equal to the energy radiated (lost) into outer space. The Earth's energy balance does not equally apply to each latitude because of the varying strength of the sunlight that strikes each of the three atmospheric cells, consequent to the inclination of the axis of planet Earth within its orbit of the Sun. The resultant atmospheric circulation transports warm tropical air to the geographic poles and cold polar air to the tropics. The effect of the three cells is the tendency to the equilibrium of heat and moisture in the planetary atmosphere of Earth.\nZonal flow.\nA zonal flow regime is the meteorological term meaning that the general flow pattern is west to east along the Earth's latitude lines, with weak shortwaves embedded in the flow. The use of the word \"zone\" refers to the flow being along the Earth's latitudinal \"zones\". This pattern can buckle and thus become a meridional flow.\nMeridional flow.\nWhen the zonal flow buckles, the atmosphere can flow in a more longitudinal (or meridional) direction, and thus the term \"meridional flow\" arises. Meridional flow patterns feature strong, amplified troughs of low pressure and ridges of high pressure, with more north\u2013south flow in the general pattern than west-to-east flow.\nSolar System.\nWithin the Solar System, other planetary bodies with a substantial atmosphere have a troposphere. These include Venus, Mars, and the Saturnian moon Titan. Jupiter does not have a solid surface, and the lowest atmospheric layer, the troposphere, smoothly transitions into the planet's fluid interior.\nThe troposphere of Venus is the densest part of the atmosphere, starting at the surface and extendind upwards to 65\u00a0km. The winds are slow near the surface, but at the top of the troposphere the temperature and pressure reaches Earth-like levels and clouds pick up speed to 100\u00a0m/s (360\u00a0km/h). The large amount of CO2 in the atmosphere together with water vapour and sulfur dioxide create a strong greenhouse effect, trapping solar energy and raising the surface temperature to around 740\u00a0K (467\u00a0\u00b0C). The thick troposphere makes the difference in temperature between the day and night side small, even though the slow retrograde rotation of the planet causes a single solar day to last 116.5 Earth days. On the night side of Venus clouds can still be found at 80\u00a0km (50\u00a0mi) above the surface.\nThe troposphere of Mars contains most of the planet's weather phenomena, including convection and dust storms. Its dynamics are heavily driven by the daytime surface heating and the amount of suspended dust. Mars has a higher scale height of 11.1\u00a0km than Earth because of its weaker gravity. The theoretical dry adiabatic lapse rate of Mars is 4.3\u00a0\u00b0C km\u22121, but the measured average lapse rate is about 2.5\u00a0\u00b0C km\u22121 because the suspended dust particles absorb solar radiation and heat the air. The planetary boundary layer can extend to over 10\u00a0km thick during the daytime. The near-surface diurnal temperature range is huge (60\u00a0\u00b0C) due to the low thermal inertia. Under dusty conditions, the suspended dust particles can reduce the surface diurnal temperature range to only 5\u00a0\u00b0C. The temperature above 15\u00a0km is controlled by radiative processes instead of convection. Mars is a rare exception to the \"0.1-bar tropopause\" rule found in the other atmospheres in our solar system.\nTitan is the only planetary satellite with a substantial atmosphere, and it is the only atmosphere besides Earth's composed primarily of nitrogen. Titan's lower surface gravity creates a more extended atmosphere than Earth, with scale heights of . The troposphere of Titan is well defined, extending to a tropopause at an altitude of around 40 km, where the temperature is . Methane condenses out of Titan's atmosphere at high altitudes, with its abundance increasing below the tropopause, leveling off at a value of 4.9% between and the surface. Methane rain, haze rainout, and varying cloud layers are found in the troposphere.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41823", "revid": "49662468", "url": "https://en.wikipedia.org/wiki?curid=41823", "title": "Tropospheric wave", "text": "Type of radio wave\nIn telecommunications, a tropospheric wave is a radio wave that travels via reflection in the troposphere. Trophospheric waves are propagated from a place of abrupt change in the dielectric constant, or its gradient. In some cases, a ground wave may be so altered that new components appear to arise from reflection in regions of rapidly changing dielectric constant. When these components are distinguishable from the other components, they are called \"tropospheric waves.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41824", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=41824", "title": "Truncated binary exponential backoff", "text": ""}
{"id": "41825", "revid": "5320876", "url": "https://en.wikipedia.org/wiki?curid=41825", "title": "Trunk", "text": "Trunk may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41826", "revid": "50271833", "url": "https://en.wikipedia.org/wiki?curid=41826", "title": "Trusted computing base", "text": "Set of all computer components critical to its security\nThe trusted computing base (TCB) of a computer system is the set of all hardware, firmware, and/or software components that are critical to its security, in the sense that bugs or vulnerabilities occurring inside the TCB might jeopardize the security properties of the entire system. By contrast, parts of a computer system that lie outside the TCB must not be able to misbehave in a way that would leak any more privileges than are granted to them in accordance to the system's security policy.\nThe careful design and implementation of a system's trusted computing base is paramount to its overall security. Modern operating systems strive to reduce the size of the TCB so that an exhaustive examination of its code base (by means of manual or computer-assisted software audit or program verification) becomes feasible.\nDefinition and characterization.\nThe term goes back to John Rushby, who defined it as the combination of operating system kernel and trusted processes. The latter refers to processes which are allowed to violate the system's access-control rules.\nIn the classic paper \"Authentication in Distributed Systems: Theory and Practice\" Lampson et al. define the TCB of a computer system as simply\n \"a small amount of software and hardware that security depends on and that we distinguish from a much larger amount that can misbehave without affecting security.\"\nBoth definitions, while clear and convenient, are neither theoretically exact nor intended to be, as e.g. a network server process under a UNIX-like operating system might fall victim to a security breach and compromise an important part of the system's security, yet is not part of the operating system's TCB. The Orange Book, another classic computer security literature reference, therefore provides a more formal definition of the TCB of a computer system, as\n \"the totality of protection mechanisms within it, including hardware, firmware, and software, the combination of which is responsible for enforcing a computer security policy.\"\nIn other words, trusted computing base (TCB) is a combination of hardware, software, and controls that work together to form a trusted base to enforce your security policy.\nThe Orange Book further explains that\n \"[t]he ability of a trusted computing base to enforce correctly a unified security policy depends on the correctness of the mechanisms within the trusted computing base, the protection of those mechanisms to ensure their correctness, and the correct input of parameters related to the security policy.\"\nIn other words, a given piece of hardware or software is a part of the TCB if and only if it has been designed to be a part of the mechanism that provides its security to the computer system. In operating systems, this typically consists of the kernel (or microkernel) and a select set of system utilities (for example, setuid programs and daemons in UNIX systems). In programming languages designed with built-in security features, such as Java and E, the TCB is formed of the language runtime and standard library.\nProperties.\nPredicated upon the security policy.\nAs a consequence of the above Orange Book definition, the boundaries of the TCB depend closely upon the specifics of how the security policy is fleshed out. In the network server example above, even though, say, a Web server that serves a multi-user application is not part of the operating system's TCB, it has the responsibility of performing access control so that the users cannot usurp the identity and privileges of each other. In this sense, it definitely is part of the TCB of the larger computer system that comprises the UNIX server, the user's browsers and the Web application; in other words, breaching into the Web server through e.g. a buffer overflow may not be regarded as a compromise of the operating system proper, but it certainly constitutes a damaging exploit on the Web application.\nThis fundamental relativity of the boundary of the TCB is exemplified by the concept of the 'target of evaluation' ('TOE') in the Common Criteria security process: in the course of a Common Criteria security evaluation, one of the first decisions that must be made is the boundary of the audit in terms of the list of system components that will come under scrutiny.\nA prerequisite to security.\nSystems that don't have a trusted computing base as part of their design do not provide security of their own: they are only secure insofar as security is provided to them by external means (e.g. a computer sitting in a locked room without a network connection may be considered secure depending on the policy, regardless of the software it runs). This is because, as David J. Farber et al. put it, \"[i]n a computer system, the integrity of lower layers is typically treated as axiomatic by higher layers\". As far as computer security is concerned, reasoning about the security properties of a computer system requires being able to make sound assumptions about what it can, and more importantly, cannot do; however, barring any reason to believe otherwise, a computer is able to do everything that a general Von Neumann machine can. This obviously includes operations that would be deemed contrary to all but the simplest security policies, such as divulging an email or password that should be kept secret; however, barring special provisions in the architecture of the system, there is no denying that the computer \"could be programmed\" to perform these undesirable tasks.\nThese special provisions that aim at preventing certain kinds of actions from being executed, in essence, constitute the trusted computing base. For this reason, the Orange Book (still a reference on the design of secure operating systems as of 2007[ [update]]) characterizes the various security assurance levels that it defines mainly in terms of the structure and security features of the TCB.\nSoftware parts of the TCB need to protect themselves.\nAs outlined by the aforementioned Orange Book, software portions of the trusted computing base need to protect themselves against tampering to be of any effect. This is due to the von Neumann architecture implemented by virtually all modern computers: since machine code can be processed as just another kind of data, it can be read and overwritten by any program. This can be prevented by special memory management provisions that subsequently have to be treated as part of the TCB. Specifically, the trusted computing base must at least prevent its own software from being written to.\nIn many modern CPUs, the protection of the memory that hosts the TCB is achieved by adding in a specialized piece of hardware called the memory management unit (MMU), which is programmable by the operating system to allow and deny a running program's access to specific ranges of the system memory. Of course, the operating system is also able to disallow such programming to the other programs. This technique is called supervisor mode; compared to more crude approaches (such as storing the TCB in ROM, or equivalently, using the Harvard architecture), it has the advantage of allowing security-critical software to be upgraded in the field, although allowing secure upgrades of the trusted computing base poses bootstrap problems of its own.\nTrusted vs. trustworthy.\nAs stated above, trust in the trusted computing base is required to make any progress in ascertaining the security of the computer system. In other words, the trusted computing base is \u201ctrusted\u201d first and foremost in the sense that it \"has\" to be trusted, and not necessarily that it is trustworthy. Real-world operating systems routinely have security-critical bugs discovered in them, which attests to the practical limits of such trust.\nThe alternative is formal software verification, which uses mathematical proof techniques to show the absence of bugs. Researchers at NICTA and its spinout Open Kernel Labs have recently performed such a formal verification of seL4, a member of the L4 microkernel family, proving functional correctness of the C implementation of the kernel.\nThis makes seL4 the first operating-system kernel which closes the gap between trust and trustworthiness, assuming the mathematical proof is free from error.\nTCB size.\nDue to the aforementioned need to apply costly techniques such as formal verification or manual review, the size of the TCB has immediate consequences on the economics of the TCB assurance process, and the trustworthiness of the resulting product (in terms of the mathematical expectation of the number of bugs not found during the verification or review). In order to reduce costs and security risks, the TCB should therefore be kept as small as possible. This is a key argument in the debate preferring microkernels to monolithic kernels.\nExamples.\nAIX materializes the trusted computing base as an optional component in its install-time package management system.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41827", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=41827", "title": "Turnkey", "text": "Project constructed so it can be sold to a buyer as complete\nA turnkey project (or turnkey operation) is one constructed so that it can be sold to any buyer as a completed product. This is contrasted with build to order, where the constructor builds an item to the buyer's exact specifications, or when an incomplete product is sold with the assumption that the buyer would complete it.\nA turnkey project or contract as described by Duncan Wallace (1984) is\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2026. a contract where the essential design emanates from, or is supplied by, the Contractor and not the owner, so that the legal responsibility for the design, suitability and performance of the work after completion will be made to rest \u2026 with the contractor \u2026. 'Turnkey' is treated as merely signifying the design responsibility as the contractor's.\nA turnkey contract is typically a construction contract under which a contractor is employed to plan, design and build a project or an infrastructure and do any other necessary development to make it functional or \u2018ready to use\u2019 at an agreed price and by a fixed date.\nIn turnkey contracts, most of the time the employer provides the primary design. The contractor must follow the primary design provided by the employer.\nA turnkey computer system is a complete computer including hardware, operating system and application(s) designed and sold to satisfy specific business requirements.\nCommon usage.\n\"Turnkey\" refers to something that is ready for immediate use, generally used in the sale or supply of goods or services. The word is a reference to the fact that the customer, upon receiving the product, just needs to turn the ignition key to make it operational, or that the key just needs to be turned over to the customer. \"Turnkey\" is commonly used in the construction industry, for instance, in which it refers to bundling of materials and labour by the home builder or general contractor to complete the home without owner involvement. The word is often used to describe a home built on the developer's land with the developer's financing ready for the customer to move in. If a contractor builds a \"turnkey home\" it frames the structure and finish the interior; everything is completed down to the cabinets and carpet. \"Turnkey\" is also commonly used in motorsports to describe a car being sold with powertrain (engine, transmission, etc.) to contrast with a vehicle sold without one so that other components may be re-used.\nSimilarly, this term may be used to advertise the sale of an established business, including all the equipment necessary to run it, or by a business-to-business supplier providing complete packages for business start-up. An example would be the creation of a \"turnkey hospital\" which would be building a complete medical.\nIn manufacturing, the turnkey manufacturing contractor (the business that takes on the turnkey project) normally provide help during the initial design process, machining and tooling, quality assurance, to production, packaging and delivery. Turnkey manufacturing have advantages in saving production time, single point of contact, cost savings and price certainty and quality assurance.\nSpecific usage.\nThe term \"turnkey\" is also often used in the technology industry, most commonly to describe pre-built computer \"packages\" in which everything needed to perform a certain type of task (e.g. audio editing) is put together by the supplier and sold as a bundle. This often includes a computer with pre-installed software, various types of hardware, and accessories. Such packages are commonly called appliances. A website with a ready-made solutions and some configurations is called a turnkey website.\nIn real estate, \"turnkey\" is defined as a home or property that is ready for occupation for its intended purpose, i.e., a home that is fully functional, needs no upgrading or repairs (move-in ready). In commercial use, a building set up to do auto repairs would be defined as turnkey if it came fully stocked with all needed machinery and tools for that particular trade. The turnkey process includes all of the steps involved to open a location including the site selection, negotiations, space planning, construction coordination and complete installation. \"Turnkey real estate\" also refers to a type of investment. This process includes the purchase, construction or rehab (of an existing site), the leasing out to tenants, and then the sale of the property to a buyer. The buyer is purchasing an investment property which is producing a stream of income.\nIn drilling, the term indicates an arrangement where a contractor must fully complete a well up to some milestone to receive any payment (in exchange for greater compensation upon completion).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41828", "revid": "63286", "url": "https://en.wikipedia.org/wiki?curid=41828", "title": "Two-out-of-five code", "text": "Error-detection code for decimal digits\nA two-out-of-five code is a constant-weight code that provides exactly ten possible combinations of two bits, and is thus used for representing the decimal digits using five bits. Each bit is assigned a weight, such that the set bits sum to the desired value, with an exception for zero.\nAccording to Federal Standard 1037C:\nThe weights give a unique encoding for most digits, but allow two encodings for 3: 0+3 or 10010 and 1+2 or 01100. The former is used to encode the digit 3, and the latter is used to represent the otherwise unrepresentable zero.\nThe IBM 7070, IBM 7072, and IBM 7074 computers used this code to represent each of the ten decimal digits in a machine word, although they numbered the bit positions 0-1-2-3-4, rather than with weights. Each word also had a sign flag, encoded using a two-out-of-three code, that could be A Alphanumeric, \u2212 Minus, or + Plus. When copied to a digit, the three bits were placed in bit positions 0-3-4. (Thus producing the numeric values 3, 6 and 9, respectively.)\nA variant is the United States Postal Service POSTNET barcode, used to represent the ZIP Code for automated mail sorting and routing equipment. This uses two tall bars as ones and three short bars as zeros. Here, the weights assigned to the bit positions are 7-4-2-1-0. Again, zero is encoded specially, using the 7+4 combination (binary 11000) that would naturally encode 11. This method was also used in North American telephone multi-frequency and crossbar switching systems.\nThe USPS Postal Alpha Numeric Encoding Technique (PLANET) uses the same weights, but with the opposite bar-height convention.\nThe Code 39 barcode uses weights 1-2-4-7-0 (i.e. LSB first, Parity bit last) for the widths of its bars, but it also encodes two bits of extra information in the spacing between bars. The ||\u00a0||| spacing is used for digits.\nThe following table represents decimal digits from 0 to 9 in various two-out-of-five code systems:\nThe requirement that exactly two bits be set is strictly stronger than a parity check; like all constant-weight codes, a two-out-of-five code can detect not only any single-bit error, but any unidirectional error -- cases in which all the individual bit errors are of a single type (all 0\u21921 or all 1\u21920).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41829", "revid": "30001121", "url": "https://en.wikipedia.org/wiki?curid=41829", "title": "NSA product types", "text": "NSA certification system\nThe U.S. National Security Agency (NSA) used to rank cryptographic products or algorithms by a certification called product types. Product types were defined in the National Information Assurance Glossary (CNSSI No. 4009, 2010) which used to define Type 1, 2, 3, and 4 products. The definitions of numeric type products have been removed from the government lexicon and are no longer used in government procurement efforts.\nType 1 product.\nA Type 1 product was a device or system certified by NSA for use in cryptographically securing classified U.S. Government information. A Type 1 product was defined as:\nCryptographic equipment, assembly or component classified or certified by NSA for encrypting and decrypting classified and sensitive national security information when appropriately keyed. Developed using established NSA business processes and containing NSA approved algorithms. Used to protect systems requiring the most stringent protection mechanisms.\nThey were available to U.S. Government users, their contractors, and federally sponsored non-U.S. Government activities subject to export restrictions in accordance with International Traffic in Arms Regulations.\nType 1 certification was a rigorous process that included testing and formal analysis of (among other things) cryptographic security, functional security, tamper resistance, emissions security (EMSEC/TEMPEST), and security of the product manufacturing and distribution process.\nType 2 product.\nA Type 2 product was unclassified cryptographic equipment, assemblies, or components, endorsed by the NSA, for use in telecommunications and automated information systems for the protection of national security information, as defined as:\nCryptographic equipment, assembly, or component certified by NSA for encrypting or decrypting sensitive national security information when appropriately keyed. Developed using established NSA business processes and containing NSA approved algorithms. Used to protect systems requiring protection mechanisms exceeding best commercial practices including systems used for the protection of unclassified national security information.\nType 3 product.\nA Type 3 product was a device for use with Sensitive, But Unclassified (SBU) information on non-national security systems, defined as:\nUnclassified cryptographic equipment, assembly, or component used, when appropriately keyed, for encrypting or decrypting unclassified sensitive U.S. Government or commercial information, and to protect systems requiring protection mechanisms consistent with standard commercial practices. Developed using established commercial standards and containing NIST approved cryptographic algorithms/modules or successfully evaluated by the National Information Assurance Partnership (NIAP).\nApproved encryption algorithms included three-key Triple DES, and AES (although AES can also be used in NSA-certified Type 1 products). Approvals for DES, two-key Triple DES and Skipjack have been withdrawn as of 2015.\nType 4 product.\nA Type 4 product was an encryption algorithm that was registered with NIST but is not a Federal Information Processing Standard (FIPS), defined as:\nUnevaluated commercial cryptographic equipment, assemblies, or components that neither NSA nor NIST certify for any Government usage. These products are typically delivered as part of commercial offerings and are commensurate with the vendor\u2019s commercial practices. These products may contain either vendor proprietary algorithms, algorithms registered by NIST, or algorithms registered by NIST and published in a FIPS.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41830", "revid": "24465790", "url": "https://en.wikipedia.org/wiki?curid=41830", "title": "Type 2 product", "text": ""}
{"id": "41831", "revid": "46866511", "url": "https://en.wikipedia.org/wiki?curid=41831", "title": "Telephony", "text": "Field of telecommunication services\nTelephony ( ) is the field of technology involving the development, application, and deployment of telecommunications services for the purpose of electronic transmission of voice, fax, or data, between distant parties. The history of telephony is intimately linked to the invention and development of the telephone.\nTelephony is commonly referred to as the construction or operation of telephones and telephonic systems and as a system of telecommunications in which telephonic equipment is employed in the transmission of speech or other sound between points, with or without the use of wires. The term is also used frequently to refer to computer hardware, software, and computer network systems, that perform functions traditionally performed by telephone equipment. In this context the technology is specifically referred to as Internet telephony, or voice over Internet Protocol (VoIP).\nOverview.\nThe first telephones were connected directly in pairs: each user had a separate telephone wired to each location to be reached. This quickly became inconvenient and unmanageable when users wanted to communicate with more than a few people. The invention of the telephone exchange provided the solution for establishing telephone connections with any other telephone in service in the local area. Each telephone was connected to the exchange at first with one wire, later one wire pair, the local loop. Nearby exchanges in other service areas were connected with trunk lines, and long-distance service could be established by relaying the calls through multiple exchanges.\nInitially, exchange switchboards were manually operated by an attendant, commonly referred to as the \"switchboard operator\". When a customer cranked a handle on the telephone, it activated an indicator on the board in front of the operator, who would in response plug the operator headset into that jack and offer service. The caller had to ask for the called party by name, later by number, and the operator connected one end of a circuit into the called party jack to alert them. If the called station answered, the operator disconnected their headset and completed the station-to-station circuit. Trunk calls were made with the assistance of other operators at other exchangers in the network.\nUntil the 1970s, most telephones were permanently wired to the telephone line installed at customer premises. Later, conversion to installation of jacks that terminated the inside wiring permitted simple exchange of telephone sets with telephone plugs and allowed portability of the set to multiple locations in the premises where jacks were installed. The inside wiring to all jacks was connected in one place to the wire drop which connects the building to a cable. Cables usually bring a large number of drop wires from all over a district access network to one wire center or telephone exchange. When a telephone user wants to make a telephone call, equipment at the exchange examines the dialed telephone number and connects that telephone line to another in the same wire center, or to a trunk to a distant exchange. Most of the exchanges in the world are interconnected through a system of larger switching systems, forming the public switched telephone network (PSTN).\nIn the second half of the 20th century, fax and data became important secondary applications of the network created to carry voices, and late in the century, parts of the network were upgraded with ISDN and DSL to improve handling of such traffic.\nToday, telephony uses digital technology (digital telephony) in the provisioning of telephone services and systems. Telephone calls can be provided digitally, but may be restricted to cases in which the last mile is digital, or where the conversion between digital and analog signals takes place inside the telephone. This advancement has reduced costs in communication, and improved the quality of voice services. The first implementation of this, ISDN, permitted all data transport from end-to-end speedily over telephone lines. This service was later made much less important due to the ability to provide digital services based on the Internet protocol suite.\nSince the advent of personal computer technology in the 1980s, computer telephony integration (CTI) has progressively provided more sophisticated telephony services, initiated and controlled by the computer, such as making and receiving voice, fax, and data calls with telephone directory services and caller identification. The integration of telephony software and computer systems is a major development in the evolution of office automation. The term is used in describing the computerized services of call centers, such as those that direct your phone call to the right department at a business you're calling. It is also sometimes used for the ability to use your personal computer to initiate and manage phone calls (in which case you can think of your computer as your personal call center).\nDigital telephony.\nDigital telephony is the use of digital electronics in the operation and provisioning of telephony systems and services. Since the late 20th century, a digital core network has replaced the traditional analog transmission and signaling systems, and much of the access network has also been digitized.\nStarting with the development of transistor technology, originating from Bell Telephone Laboratories in 1947, to amplification and switching circuits in the 1950s, the public switched telephone network (PSTN) has gradually moved towards solid-state electronics and automation. Following the development of computer-based electronic switching systems incorporating metal\u2013oxide\u2013semiconductor (MOS) and pulse-code modulation (PCM) technologies, the PSTN gradually evolved towards the digitization of signaling and audio transmissions. Digital telephony has since dramatically improved the capacity, quality and cost of the network. Digitization allows wideband voice on the same channel, with improved quality of a wider analog voice channel.\nHistory.\nThe earliest end-to-end analog telephone networks to be modified and upgraded to transmission networks with Digital Signal 1 (DS1/T1) carrier systems date back to the early 1960s. They were designed to support the basic 3\u00a0kHz voice channel by sampling the bandwidth-limited analog voice signal and encoding using pulse-code modulation (PCM). Early PCM codec-filters were implemented as passive resistor\u2013capacitor\u2013inductor filter circuits, with analog-to-digital conversion (for digitizing voices) and digital-to-analog conversion (for reconstructing voices) handled by discrete devices. Early digital telephony was impractical due to the low performance and high costs of early PCM codec-filters.\nPractical digital telecommunication was enabled by the invention of the metal\u2013oxide\u2013semiconductor field-effect transistor (MOSFET), which led to the rapid development and wide adoption of PCM digital telephony. In 1957, Frosch and Derick were able to manufacture the first silicon dioxide field effect transistors at Bell Labs, the first transistors in which drain and source were adjacent at the surface. Subsequently, a team demonstrated a working MOSFET at Bell Labs 1960. MOS technology was initially overlooked by Bell because they did not find it practical for analog telephone applications, before it was commercialized by Fairchild and RCA for digital electronics such as computers. \nMOS technology eventually became practical for telephone applications with the MOS mixed-signal integrated circuit, which combines analog and digital signal processing on a single chip, developed by former Bell engineer David A. Hodges with Paul R. Gray at UC Berkeley in the early 1970s. In 1974, Hodges and Gray worked with R.E. Suarez to develop MOS switched capacitor (SC) circuit technology, which they used to develop a digital-to-analog converter (DAC) chip, using MOS capacitors and MOSFET switches for data conversion. MOS analog-to-digital converter (ADC) and DAC chips were commercialized by 1974.\nMOS SC circuits led to the development of PCM codec-filter chips in the late 1970s. The silicon-gate CMOS (complementary MOS) PCM codec-filter chip, developed by Hodges and W.C. Black in 1980, has since been the industry standard for digital telephony. By the 1990s, telecommunication networks such as the public switched telephone network (PSTN) had been largely digitized with very-large-scale integration (VLSI) CMOS PCM codec-filters, widely used in electronic switching systems for telephone exchanges, private branch exchanges (PBX) and key telephone systems (KTS); user-end modems; data transmission applications such as digital loop carriers, pair gain multiplexers, telephone loop extenders, integrated services digital network (ISDN) terminals, digital cordless telephones and digital cell phones; and applications such as speech recognition equipment, voice data storage, voice mail and digital tapeless answering machines. The bandwidth of digital telecommunication networks has been rapidly increasing at an exponential rate, as observed by Edholm's law, largely driven by the rapid scaling and miniaturization of MOS technology.\nUncompressed PCM digital audio with 8-bit depth and 8kHz sample rate requires a bit rate of 64kbit/s, which was impractical for early digital telecommunication networks with limited network bandwidth. A solution to this issue was linear predictive coding (LPC), a speech coding data compression algorithm that was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966. LPC was capable of audio data compression down to 2.4kbit/s, leading to the first successful real-time conversations over digital networks in the 1970s. LPC has since been the most widely used speech coding method. Another audio data compression method, a discrete cosine transform (DCT) algorithm called the modified discrete cosine transform (MDCT), has been widely adopted for speech coding in voice-over-IP (VoIP) applications since the late 1990s.\nThe development of transmission methods such as SONET and fiber optic transmission further advanced digital transmission. Although analog carrier systems existed that multiplexed multiple analog voice channels onto a single transmission medium, digital transmission allowed lower cost and more channels multiplexed on the transmission medium. Today the end instrument often remains analog but the analog signals are typically converted to digital signals at the serving area interface (SAI), central office (CO), or other aggregation point. Digital loop carriers (DLC) and fiber to the x place the digital network ever closer to the customer premises, relegating the analog local loop to legacy status.\nIP telephony.\nThe field of technology available for telephony has broadened with the advent of new communication technologies. Telephony now includes the technologies of Internet services and mobile communication, including video conferencing.\nThe new technologies based on Internet Protocol (IP) concepts are often referred to separately as voice over IP (VoIP) telephony, also commonly referred to as IP telephony or Internet telephony. Unlike traditional phone service, IP telephony service is relatively unregulated by government. In the United States, the Federal Communications Commission (FCC) regulates phone-to-phone connections, but says they do not plan to regulate connections between a phone user and an IP telephony service provider.\nA specialization of digital telephony, Internet Protocol (IP) telephony involves the application of digital networking technology that was the foundation to the Internet to create, transmit, and receive telecommunications sessions over computer networks. Internet telephony is commonly known as voice over Internet Protocol (VoIP), reflecting the principle, but it has been referred with many other terms. VoIP has proven to be a disruptive technology that is rapidly replacing traditional telephone infrastructure technologies. As of January 2005, up to 10% of telephone subscribers in Japan and South Korea have switched to this digital telephone service. A January 2005 \"Newsweek\" article suggested that Internet telephony may be \"the next big thing\". As of 2006, many VoIP companies offer service to consumers and businesses.\nA significant advancement in mobile telephony has been the integration of IP technologies into mobile networks, notably through Voice over LTE (VoLTE) and Voice over 5G (Vo5G). These technologies enable voice calls to be transmitted over the same IP-based infrastructure used for data services, offering improved call quality and faster connections compared to traditional circuit-switched networks. VoLTE and Vo5G are becoming the standard for mobile voice communication in many regions, as mobile operators transition to all-IP networks.\nIP telephony uses an Internet connection and hardware IP phones, analog telephone adapters, or softphone computer applications to transmit conversations encoded as data packets. While one of the most common and cost-effective uses of IP telephony is through connections over WiFi hotspots, it is also employed on private networks and over other types of Internet connections, which may or may not have a direct link to the global telephone network.\nSocial impact research.\nDirect person-to-person communication includes non-verbal cues expressed in facial and other bodily articulation, that cannot be transmitted in traditional voice telephony. Video telephony restores such interactions to varying degrees. Social Context Cues Theory is a model to measure the success of different types of communication in maintaining the non-verbal cues present in face-to-face interactions. The research examines many different cues, such as the physical context, different facial expressions, body movements, tone of voice, touch and smell.\nVarious communication cues are lost with the usage of the telephone. The communicating parties are not able to identify the body movements, and lack touch and smell. Although this diminished ability to identify social cues is well known, Wiesenfeld, Raghuram, and Garud point out that there is a value and efficiency to the type of communication for different tasks. They examine work places in which different types of communication, such as the telephone, are more useful than face-to-face interaction.\nThe expansion of communication to mobile telephone service has created a different filter of the social cues than the land-line telephone. The use of instant messaging, such as \"texting\", on mobile telephones has created a sense of community. In \"The Social Construction of Mobile Telephony\" it is suggested that each phone call and text message is more than an attempt to converse. Instead, it is a gesture which maintains the social network between family and friends. Although there is a loss of certain social cues through telephones, mobile phones bring new forms of expression of different cues that are understood by different audiences. New language additives attempt to compensate for the inherent lack of non-physical interaction.\nAnother social theory supported through telephony is the Media Dependency Theory. This theory concludes that people use media or a resource to attain certain goals. This theory states that there is a link between the media, audience, and the large social system. Telephones, depending on the person, help attain certain goals like accessing information, keeping in contact with others, sending quick communication, entertainment, etc.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41832", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=41832", "title": "U interface", "text": "Basic Rate Interface\nThe U interface or U reference point is a Basic Rate Interface (BRI) in the local loop of an Integrated Services Digital Network (ISDN), connecting the network terminator (NT1/2) on the customer's premises to the line termination (LT) in the carrier's local exchange, in other words providing the connection from subscriber to central office.\nUnlike the ISDN S/T interfaces, the U interface was not originally electrically defined by the ITU ISDN specifications, but left up to network operators to implement, although the ITU has issued recommendations G.960 and G.961 to formalize the standards adopted in the US and EU.\nIn the US, the U interface is originally defined by the ANSI T1.601 specification as a 2-wire connection using 2B1Q line coding. It is not as distance sensitive as the S interface or T interface, and can operate at distances up to 18,000 feet. Typically the U interface does not connect to terminal equipment (which typically has an S/T interface) but to an NT1 or NT2 (network terminator type 1 or 2.)\nAn NT1 is a discrete device that converts the U interface to an S/T interface, which is then connected to terminal equipment (TE) having an S/T interface. However, some TE devices integrate an NT1, and therefore have a direct U interface suitable for connection directly to the loop.\nAn NT2 is a more sophisticated local switching device such as a PBX, that may convert the signal to a different format or hand it off as S/T to terminal equipment.\nIn America, the NT1 is customer premises equipment (CPE) which is purchased and maintained by the user, which makes the U interface a User\u2013network interface (UNI). The American variant is specified by ANSI T1.601.\nIn Europe, the NT1 belongs to the network operator, so the user doesn't have direct access to the U interface. The European variant is specified by the European Telecommunications Standards Institute (ETSI) in recommendation ETR 080. The ITU-T has issued recommendations G.960 and G.961 with world-wide scope, encompassing both the European and American variants of the U interface.\nLogical interface.\nLike all other ISDN basic rate interfaces, the U interface carries two B (bearer) channels at 64\u00a0kbit/s and one D (data) channel at 16\u00a0kbit/s for a combined bitrate of 144\u00a0kbit/s (2B+D).\nDuplex transmission.\nWhile in a four-wire interface such as the ISDN S and T-interfaces one wire pair is available for each direction of transmission, a two-wire interface needs to implement both directions on a single wire pair. To that end, ITU-T recommendation G.961 specifies two duplex transmission technologies for the ISDN U interface, either of which shall be used: Echo cancellation (ECH) and Time Compression Multiplex (TCM).\nEcho cancellation (ECH).\nWhen a transmitter applies a signal to the wire-pair, parts of the signal will be reflected as a result of imperfect balance of the hybrid and because of impedance discontinuities on the line. These reflections return to the transmitter as an echo and are indistinguishable from a signal transmitted at the far end. In the echo cancellation (ECH) scheme, the transmitter locally simulates the echo it expects to receive, and subtracts it from the received signal.\nTime Compression Multiplex (TCM).\nThe Time Compression Multiplex (TCM) duplex method, also referred to as \"burst mode\", solves the echo problem indirectly. The line is operated at a rate at least twice the signal rate and both ends of the line take turns transmitting, in a time-division duplex fashion.\nLine Systems.\nITU-T G.961 specifies four line systems for the ISDN U interface: MMS43, 2B1Q, TCM, and SU32. All line systems except TCM use echo cancellation for duplex operation. The American standard ANSI T1.601 specifies the 2B1Q line system, the European ETSI TR 080 recommendation specifies 2B1Q and MMS43.\nMMMS43 (4B3T).\nThe Modified Monitoring State Code mapping 4 bits into 3 ternary symbols (MMS43), which is also referred to as 4B3T (four binary, three ternary) is a line system used in Europe and elsewhere in the world. 4B3T is a \"block code\" that uses Return-to-Zero states on the line. 4B3T converts each group of 4 data bits into 3 \"ternary\" line signal states (3 symbols). Echo cancellation techniques allow full-duplex operation on the line.\nMMS43 is defined in Appendix I of G.961, Annex B of ETR 080, and other national standards, like Germany's 1TR220. 4B3T can be transmitted reliably at up to over cable or up to over cable. An internal termination impedance of is presented to the line at each end of the U-interface.\nA 1\u00a0ms frame carrying 144\u00a0bits of 2B+D data is mapped to 108 ternary symbols. These symbols are scrambled, with different scrambling codes for the two transmission directions, in order reduce correlation between transmitted and received signal. To this frame, an 11-symbol preamble and a symbol from the CL channel are added, yielding a frame size of 120 ternary symbols and a symbol rate of 120\u00a0kilobaud. The CL channel is used to request activation or deactivation of a loopback in either the NT1 or a line regenerator.\nIn 4B3T coding, there are three states presented to line: a positive pulse (+), a negative pulse (-), or a zero-state (no pulse: 0). An analogy here is that operation is similar to B8ZS or HDB3 in T1/E1 systems, except that there is an actual gain in the information rate by coding 24=16 possible binary states to one of 33=27 ternary states. This added redundancy is used to generate a zero DC-bias signal.\nOne requirement for line transmission is that there should be no DC build-up on the line, so the accumulated DC build-up is monitored and the codewords are chosen accordingly. Of the 16 binary information words, some are always mapped to a DC-component free (ternary) code word, while others can be mapped to either one of two code words, one with a positive and the other with a negative DC-component. In the latter case, the transmitter chooses whether to send the code-word with negative or positive DC-component based on the accumulated DC-offset.\n2B1Q.\n2B1Q coding is the standard used in North America, Italy, and Switzerland. 2B1Q means that two bits are combined to form a single Quaternary line state (symbol). 2B1Q combines two bits at a time to be represented by one of four signal levels on the line. Echo cancellation techniques allow full-duplex operation on the line.\n2B1Q coding is defined in Appendix II of G.961, ANSI T1.601, and Annex A of ETR 080. It can operate at distances up to about 18,000 feet () with loss up to . An internal termination impedance of 135 ohms is presented to the line at each end of the U-interface.\nA 1.5\u00a0ms frame carrying 216 scrambled bits of 2B+D data is mapped to 108 quaternary symbols. To this frame, a 9-symbol preamble and 3 symbols from the CL channel are added, yielding a frame size of 120 quaternary symbols and a symbol rate of 80\u00a0kilobaud. The CL channel is used for communication between LT and NT1, a 12-bit cyclic redundancy check (CRC), and various other physical layer functions. The CRC covers one 12\u00a0ms multiframe (8\u00d71.5\u00a0ms frames).\nTCM / AMI.\nThe TCM / AMI ISDN line system, also referred to as TCM-ISDN, is used by Nippon Telegraph and Telephone in its \"INS-Net 64\" service.\nAppendix III of G.961 specifies a line system based on the Time Compression Multiplex (TCM) duplex method and an alternate mark inversion (AMI) line code. The AMI line code maps one input bit to one ternary symbol. Like with MMS43, the ternary symbol can either be a positive (+), zero (0), or negative (-) voltage. A 0 bit is represented by a zero voltage, while a 1 bit is alternatingly represented by a positive and a negative voltage, resulting in a DC-bias free signal. In a 2.5\u00a0ms interval, each side can send a 1.178\u00a0ms frame representing 360\u00a0bits of 2B+D data. To the 2B+D data, an 8-bit preamble, 8 bits from the CL channel, as well as a parity bit are added, yielding a frame size of 377\u00a0bits and a baud rate of 320\u00a0kilobaud. The CL channel is used for operations and maintenance, as well transmitting a 12-bit CRC covering 4 frames.\nSU32.\nAppendix IV of G.961 specifies a line system based on echo cancellation and a substitutional 3B2T (SU32) line code, which maps three bits into 2 ternary symbols. As with MMS43 and AMI, the ternary symbol can either be a positive (+), zero (0), or negative (-) voltage. The mapping from 23=8 to 32=9 symbols leaves one unused symbol. When two subsequent input (binary) information words are identical, the (ternary) code word is substituted by the unused code word. A 0.75\u00a0ms frame carrying 108 bits of 2B+D data is mapped to 72 ternary symbols. To this frame, a 6-symbol preamble, one CRC symbol, and 2 symbols from the CL channel are added, yielding a frame size of 81 ternary symbols and a symbol rate of 108\u00a0kilobaud. The CL channel is used for supervisory and maintenance functions between the LT and NT1. The 15-bit CRC covers 16 frames.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41833", "revid": "11677590", "url": "https://en.wikipedia.org/wiki?curid=41833", "title": "Unavailability", "text": ""}
{"id": "41834", "revid": "45955630", "url": "https://en.wikipedia.org/wiki?curid=41834", "title": "Uninterruptible power supply", "text": "Electrical device that uses batteries to prevent any interruption of power flow\nAn uninterruptible power supply (UPS) or uninterruptible power source is an electrical apparatus that provides emergency power to a load when the input power source or mains power fails. A UPS differs from an auxiliary or emergency power system or standby generator in that it will provide near-instantaneous protection from input power interruptions, by supplying energy stored in batteries, supercapacitors, or flywheels.\nThe on-battery run-time of most uninterruptible power sources is relatively short (typically ranging from 5 to 15 minutes) but sufficient to start a standby power source or properly shut down the protected equipment. It is a type of continual power system. A UPS is typically used to protect hardware such as computers, data centers, telecommunication equipment or other electrical equipment where an unexpected power disruption could cause injuries, fatalities, serious business disruption or data loss. UPS units range in size from units designed to protect a single computer without a video monitor (around 200 volt-ampere rating) to large units powering entire data centers or buildings.\nCommon power problems.\nThe primary role of any UPS is to provide short-term power when the input power source fails. However, most UPS units are also capable in varying degrees of correcting common utility power problems:\nSome manufacturers of UPS units categorize their products in accordance with the number of power-related problems they address.\nA UPS unit may also introduce problems with electric power quality. To prevent this, a UPS should be selected not only by capacity but also by the quality of power that is required by the equipment that is being supplied.\nTechnologies.\nThe three general categories of modern UPS systems are \"on-line\", \"line-interactive\" and \"standby\":\nUPSs are given a power rating in volt-amperes (VA) that range from 300 VA to 5,000 kVA. Most UPS below one kilovolt-ampere (1\u00a0kVA) are of the line-interactive or standby variety which are usually less expensive.\nFor large power units, dynamic uninterruptible power supplies (DUPS) are sometimes used. A synchronous motor/alternator is connected on the mains via a choke. Energy is stored in a flywheel. When the mains power fails, an eddy-current regulation maintains the power on the load as long as the flywheel's energy is not exhausted. DUPS are sometimes combined or integrated with a diesel generator that is turned on after a brief delay, forming a diesel rotary uninterruptible power supply (DRUPS).\nOffline/standby.\nThe offline/standby UPS offers only the most basic features, providing surge protection and battery backup. The protected equipment is normally connected directly to incoming utility power. When the incoming voltage falls below or rises above a predetermined level the UPS turns on its internal DC-AC inverter circuitry, which is powered from an internal storage battery. The UPS then mechanically switches the connected equipment onto its DC-AC inverter output. The switch-over time can be as long as 25 milliseconds depending on the amount of time it takes the standby UPS to detect the lost utility voltage. The UPS will be designed to power certain equipment, such as a personal computer, without any objectionable dip or brownout to that device.\nLine-interactive.\nThe line-interactive UPS is similar in operation to a standby UPS but with the addition of a multi-tap variable-voltage autotransformer. This is a special type of transformer that can add or subtract powered coils of wire, thereby increasing or decreasing the magnetic field and the output voltage of the transformer. This may also be performed by a \"buck\u2013boost transformer\" which is distinct from an autotransformer, since the former may be wired to provide galvanic isolation.\nThis type of UPS is able to tolerate continuous undervoltage brownouts and overvoltage surges without consuming the limited reserve battery power. It instead compensates by automatically selecting different power taps on the autotransformer. Depending on the design, changing the autotransformer tap can cause a very brief output power disruption, which may cause UPSs equipped with a power-loss alarm to \"chirp\" for a moment.\nThis has become popular even in the cheapest UPSes because it takes advantage of components already included. The main 50/60\u00a0Hz transformer used to convert between line voltage and battery voltage needs to provide two slightly different turns ratios: One to convert the battery output voltage (typically a multiple of 12\u00a0V) to line voltage, and a second one to convert the line voltage to a slightly higher battery charging voltage (such as a multiple of 14\u00a0V). The difference between the two voltages is because charging a battery requires a delta voltage (up to 13\u201314\u00a0V for charging a 12\u00a0V battery). Furthermore, it is easier to do the switching on the line-voltage side of the transformer because of the lower currents on that side.\nTo gain the \"buck/boost\" feature, all that is required is two separate switches so that the AC input can be connected to one of the two primary taps, while the load is connected to the other, thus using the main transformer's primary windings as an autotransformer. The battery can still be charged while \"bucking\" an overvoltage, but while \"boosting\" an undervoltage, the transformer output is too low to charge the batteries.\nAutotransformers can be engineered to cover a wide range of varying input voltages, but this requires more taps and increases complexity, as well as the expense of the UPS. It is common for the autotransformer to cover a range only from about 90\u00a0V to 140\u00a0V for 120\u00a0V power, and then switch to battery if the voltage goes much higher or lower than that range.\nIn low-voltage conditions the UPS will use more current than normal, so it may need a higher current circuit than a normal device. For example, to power a 1000\u00a0W device at 120\u00a0V, the UPS will draw 8.33\u00a0A. If a brownout occurs and the voltage drops to 100\u00a0V, the UPS will draw 10\u00a0A to compensate. This also works in reverse, so that in an overvoltage condition, the UPS will need less current.\nOnline/double-conversion.\nIn an online UPS, the batteries are always connected to the inverter, so that no power transfer switches are necessary. When power loss occurs, the rectifier simply drops out of the circuit and the batteries keep the power steady and unchanged. When power is restored, the rectifier resumes carrying most of the load and begins charging the batteries, though the charging current may be limited to prevent the high-power rectifier from damaging the batteries. The main advantage of an online UPS is its ability to provide an \"electrical firewall\" between the incoming utility power and sensitive electronic equipment.\nThe online UPS is ideal for environments where electrical isolation is necessary or for equipment that is very sensitive to power fluctuations. Although it was at one time reserved for very large installations of 10\u00a0kW or more, advances in technology have now permitted it to be available as a common consumer device, supplying 500\u00a0W or less. The online UPS may be necessary when the power environment is \"noisy\", when utility power sags, outages and other anomalies are frequent, when protection of sensitive IT equipment loads is required, or when operation from an extended-run backup generator is necessary.\nThe basic technology of the online UPS is the same as in a standby or line-interactive UPS. However, it typically costs much more, due to it having a much greater current AC-to-DC battery-charger/rectifier, and with the rectifier and inverter designed to run continuously with improved cooling systems. It is called a \"double-conversion\" UPS due to the rectifier directly driving the inverter, even when powered from normal AC current.\nOnline UPS typically has a static transfer switch (STS) for increasing reliability.\nOther designs.\nHybrid topology/double conversion on demand.\nThese hybrid rotary UPS designs do not have official designations, although one name used by UTL is \"double conversion on demand\". This style of UPS is targeted towards high-efficiency applications while still maintaining the features and protection level offered by double conversion.\nA hybrid (double conversion on demand) UPS operates as an off-line/standby UPS when power conditions are within a certain preset window. This allows the UPS to achieve very high efficiency ratings. When the power conditions fluctuate outside of the predefined windows, the UPS switches to online/double-conversion operation. In double-conversion mode the UPS can adjust for voltage variations without having to use battery power, can filter out line noise and control frequency.\nFerroresonant.\nFerroresonant units operate in the same way as a standby UPS unit; however, they are online with the exception that a ferroresonant transformer, is used to filter the output. This transformer is designed to hold energy long enough to cover the time between switching from line power to battery power and effectively eliminates the transfer time. Many ferroresonant UPSs are 82\u201388% efficient (AC/DC-AC) and offer excellent isolation.\nThe transformer has three windings, one for ordinary mains power, the second for rectified battery power, and the third for output AC power to the load.\nThis once was the dominant type of UPS and is limited to around the 150 kVA range. These units are still mainly used in some industrial settings (oil and gas, petrochemical, chemical, utility, and heavy industry markets) due to the robust nature of the UPS. Many ferroresonant UPSs utilizing controlled ferro technology may interact with power-factor-correcting equipment. This will result in fluctuating output voltage of the UPS, but may be corrected by reducing the load levels or adding other linear type loads.\nDC power.\nA UPS designed for powering DC equipment is very similar to an online UPS, except that it does not need an output inverter. Also, if the UPS's battery voltage is matched with the voltage the device needs, the device's power supply will not be needed either. Since one or more power conversion steps are eliminated, this increases efficiency and run time.\nMany systems used in telecommunications use an extra-low voltage \"common battery\" 48\u00a0V DC power, because it has less restrictive safety regulations, such as being installed in conduit and junction boxes. DC has typically been the dominant power source for telecommunications, and AC has typically been the dominant source for computers and servers.\nThere has been much experimentation with 48\u00a0V DC power for computer servers, in the hope of reducing the likelihood of failure and the cost of equipment. However, to supply the same amount of power, the current would be higher than an equivalent 115\u00a0V or 230\u00a0V circuit; greater current requires larger conductors or more energy lost as heat.\nHigh voltage DC (380\u00a0V) is finding use in some data center applications and allows for small power conductors, but is subject to the more complex electrical code rules for safe containment of high voltages.\nFor lower power devices that run on 5\u00a0V, some portable battery banks can work as a UPS.\nRotary.\nA rotary UPS uses the inertia of a high-mass spinning flywheel (flywheel energy storage) to provide short-term ride-through in the event of power loss. The flywheel also acts as a buffer against power spikes and sags, since such short-term power events are not able to appreciably affect the rotational speed of the high-mass flywheel. It is also one of the oldest designs, predating vacuum tubes and integrated circuits.\nIt can be considered to be \"on line\" since it spins continuously under normal conditions. However, unlike a battery-based UPS, flywheel-based UPS systems typically provide 10 to 20 seconds of protection before the flywheel has slowed and power output stops. It is traditionally used in conjunction with standby generators, providing backup power only for the brief period of time the engine needs to start running and stabilize its output.\nThe rotary UPS is generally reserved for applications needing more than 10,000\u00a0W of protection, to justify the expense and benefit from the advantages rotary UPS systems bring. A larger flywheel or multiple flywheels operating in parallel will increase the reserve running time or capacity.\nBecause the flywheels are a mechanical power source, it is not necessary to use an electric motor or generator as an intermediary between it and a diesel engine designed to provide emergency power. By using a transmission gearbox, the rotational inertia of the flywheel can be used to directly start up a diesel engine, and once running, the diesel engine can be used to directly spin the flywheel. Multiple flywheels can likewise be connected in parallel through mechanical countershafts, without the need for separate motors and generators for each flywheel.\nThey are normally designed to provide very high current output compared to a purely electronic UPS, and are better able to provide inrush current for inductive loads such as motor startup or compressor loads, as well as medical MRI and cath lab equipment. It is also able to tolerate short-circuit conditions up to 17 times larger than an electronic UPS, permitting one device to blow a fuse and fail while other devices still continue to be powered from the rotary UPS.\nIts life cycle is usually far greater than a purely electronic UPS, up to 30 years or more. But they do require periodic downtime for mechanical maintenance, such as ball bearing replacement. In larger systems, redundancy of the system ensures the availability of processes during this maintenance. Battery-based designs do not require downtime if the batteries can be hot-swapped, which is usually the case for larger units. Newer rotary units use technologies such as magnetic bearings and air-evacuated enclosures to increase standby efficiency and reduce maintenance to very low levels.\nTypically, the high-mass flywheel is used in conjunction with a motor-generator system. These units can be configured as:\nIn case No.\u00a03, the motor generator can be synchronous/synchronous or induction/synchronous. The motor side of the unit in case Nos.\u00a02 and 3 can be driven directly by an AC power source (typically when in inverter bypass), a 6-step double-conversion motor drive, or a 6-pulse inverter. Case No.\u00a01 uses an integrated flywheel as a short-term energy source instead of batteries to allow time for external, electrically coupled gensets to start and be brought online. Case Nos.\u00a02 and 3 can use batteries or a free-standing electrically coupled flywheel as the short-term energy source.\nForm factors.\nSmaller UPS systems come in several different forms and sizes. However, the two most common forms are tower and rack-mount.\nTower models stand upright on the ground or on a desk or shelf, and are typically used in network workstations or desktop computer applications. Rack-mount models can be mounted in standard 19-inch rack enclosures and can require anywhere from 1U to 12U (rack units). They are typically used in server and networking applications. Some devices feature user interfaces that rotate 90\u00b0, allowing the devices to be mounted vertically on the ground or horizontally as would be found in a rack.\nApplications.\n\"N\"\u00a0+\u00a01.\nIn large business environments where reliability is of great importance, a single huge UPS can also be a single point of failure that can disrupt many other systems. To provide greater reliability, multiple smaller UPS modules and batteries can be integrated together to provide redundant power protection equivalent to one very large UPS. \"\"N\"\u00a0+\u00a01\" means that if the load can be supplied by \"N\" modules, the installation will contain \"N\"\u00a0+\u00a01 modules. In this way, failure of one module will not impact system operation.\nMultiple redundancy.\nMany computer servers offer the option of redundant power supplies, so that in the event of one power supply failing, one or more other power supplies are able to power the load. This is a critical point \u2013 each power supply must be able to power the entire server by itself.\nRedundancy is further enhanced by plugging each power supply into a different circuit (i.e. to a different circuit breaker).\nRedundant protection can be extended further yet by connecting each power supply to its own UPS. This provides double protection from both a power supply failure and a UPS failure, so that continued operation is assured. This configuration is also referred to as 1\u00a0+\u00a01 or 2\"N\" redundancy. If the budget does not allow for two identical UPS units then it is common practice to plug one power supply into mains power and the other into the UPS.\nOutdoor use.\nWhen a UPS system is placed outdoors, it should have some specific features that guarantee that it can tolerate weather without any effects on performance. Factors such as temperature, humidity, rain, and snow among others should be considered by the manufacturer when designing an outdoor UPS system. Operating temperature ranges for outdoor UPS systems could be around \u221240\u00a0\u00b0C to +55\u00a0\u00b0C.\nOutdoor UPS systems can either be pole, ground (pedestal), or host mounted. Outdoor environment could mean extreme cold, in which case the outdoor UPS system should include a battery heater mat, or extreme heat, in which case the outdoor UPS system should include a fan system or an air conditioning system.\nA solar inverter, or PV inverter, or solar converter, converts the variable direct current (DC) output of a photovoltaic (PV) solar panel into a utility frequency alternating current (AC) that can be fed into a commercial electrical grid or used by a local, off-grid electrical network. It is a critical BOS\u2013component in a photovoltaic system, allowing the use of ordinary AC-powered equipment. Solar inverters have special functions adapted for use with photovoltaic arrays, including maximum power point tracking and anti-islanding protection.\nHarmonic distortion.\nThe output of some electronic UPSes can have a significant departure from an ideal sinusoidal waveform. This is especially true of inexpensive consumer-grade single-phase units designed for home and office use. These often utilize simple switching AC power supplies and the output resembles a square wave rich in harmonics. These harmonics can cause interference with other electronic devices including radio communication, and some devices (e.g. inductive loads such as AC motors) may perform with reduced efficiency or not at all. More sophisticated (and expensive) UPS units can produce nearly pure sinusoidal AC power.\nPower factor.\nA problem in the combination of a double-conversion UPS and a generator is the voltage distortion created by the UPS. The input of a double-conversion UPS is essentially a big rectifier. The current drawn by the UPS is non-sinusoidal. This can cause the voltage from the AC mains or a generator to also become non-sinusoidal. The voltage distortion then can cause problems in all electrical equipment connected to that power source, including the UPS itself. It will also cause more power to be lost in the wiring supplying power to the UPS due to the spikes in current flow. This level of \"noise\" is measured as a percentage of \"total harmonic distortion of the current\" (THD\"I\"). Classic UPS rectifiers have a THD\"I\" level of around 25%\u201330%. To reduce voltage distortion, this requires heavier mains wiring or generators more than twice as large as the UPS.\nThere are several solutions to reduce the THD\"I\" in a double-conversion UPS:\nClassic solutions such as passive filters reduce THD\"I\" to 5%\u201310% at full load. They are reliable, but big and only work at full load, and present their own problems when used in tandem with generators.\nAn alternative solution is an active filter. Through the use of such a device, THD\"I\" can drop to 5% over the full power range. The newest technology in double-conversion UPS units is a rectifier that does not use classic rectifier components (thyristors and diodes) but uses high-frequency components instead. A double-conversion UPS with an insulated-gate bipolar transistor rectifier and inductor can have a THD\"I\" as small as 2%. This completely eliminates the need to oversize the generator (and transformers), without additional filters, investment cost, losses, or space.\nCommunication.\nPower management (PM) requires:\nThe basic computer-to-UPS control methods are intended for one-to-one signaling from a single source to a single target. For example, a single UPS may connect to a single computer to provide status information about the UPS, and allow the computer to control the UPS. Similarly, the USB protocol is also intended to connect a single computer to multiple peripheral devices.\nIn some situations, it is useful for a single large UPS to be able to communicate with several protected devices. For traditional serial or USB control, a \"signal replication\" device may be used, which for example allows one UPS to connect to five computers using serial or USB connections. However, the splitting is typically only one direction from UPS to the devices to provide status information. Return control signals may only be permitted from one of the protected systems to the UPS.\nAs Ethernet has increased in common use since the 1990s, control signals are now commonly sent between a single UPS and multiple computers using standard Ethernet data communication methods such as TCP/IP. The status and control information is typically encrypted so that, for example, an outside hacker can not gain control of the UPS and command it to shut down.\nDistribution of UPS status and control data requires that all intermediary devices such as Ethernet switches or serial multiplexers be powered by one or more UPS systems, in order for the UPS alerts to reach the target systems during a power outage. To avoid the dependency on Ethernet infrastructure, the UPSs can be connected directly to the main control server by using a GSM/GPRS channel also. The SMS or GPRS data packets sent from UPSs trigger software to shut down the PCs to reduce the load.\nBatteries.\nThere are three main types of UPS batteries: valve-regulated lead\u2013acid (VRLA), flooded cell or VLA batteries, and lithium-ion batteries. The run-time for a battery-operated UPS depends on the type and size of batteries and rate of discharge, and the efficiency of the inverter. The total capacity of a lead\u2013acid battery is a function of the rate at which it is discharged, which is described as Peukert's law.\nManufacturers supply run-time rating in minutes for packaged UPS systems. Larger systems (such as for data centers) require detailed calculation of the load, inverter efficiency, and battery characteristics to ensure the required endurance is attained.\nCommon battery characteristics and load testing.\nWhen a lead\u2013acid battery is charged or discharged, this initially affects only the reacting chemicals, which are at the interface between the electrodes and the electrolyte. With time, the charge stored in the chemicals at the interface, often called \"interface charge\", spreads by diffusion of these chemicals throughout the volume of the active material.\nIf a battery has been completely discharged (e.g. the car lights were left on overnight) and next is given a fast charge for only a few minutes, then during the short charging time it develops only a charge near the interface. The battery voltage may rise to be close to the charger voltage so that the charging current decreases significantly. After a few hours, this interface charge will not spread to the volume of the electrode and electrolyte, leading to an interface charge so low that it may be insufficient to start a car.\nDue to the interface charge, brief UPS \"self-test\" functions lasting only a few seconds may not accurately reflect the true runtime capacity of a UPS, and instead an extended \"recalibration\" or \"rundown\" test that deeply discharges the battery is needed.\nThe deep discharge testing is itself damaging to batteries due to the chemicals in the discharged battery starting to crystallize into highly stable molecular shapes that will not re-dissolve when the battery is recharged, permanently reducing charge capacity. In lead\u2013acid batteries, this is known as sulfation, but deep-discharge damage also affects other types such as nickel-cadmium batteries and lithium batteries. Therefore, it is commonly recommended that rundown tests be performed infrequently, such as every six months to a year.\nTesting of strings of batteries/cells.\nMulti-kilowatt commercial UPS systems with large and easily accessible battery banks are capable of isolating and testing individual cells within a \"battery string\", which consists of either combined-cell battery units (such as 12\u00a0V lead acid batteries) or individual chemical cells wired in series. Isolating a single cell and installing a jumper in place of it allows the one battery to be discharge-tested, while the rest of the battery string remains charged and available to provide protection.\nIt is also possible to measure the electrical characteristics of individual cells in a battery string, using intermediate sensor wires that are installed at every cell-to-cell junction, and monitored both individually and collectively. Battery strings may also be wired as series-parallel, for example, two sets of 20 cells. In such a situation it is also necessary to monitor current flow between parallel strings, as current may circulate between the strings to balance out the effects of weak cells, dead cells with high resistance, or shorted cells. For example, stronger strings can discharge through weaker strings until voltage imbalances are equalized, and this must be factored into the individual inter-cell measurements within each string.\nSeries\u2013parallel battery interactions.\nBattery strings wired in series\u2013parallel can develop unusual failure modes due to interactions between the multiple parallel strings. Defective batteries in one string can adversely affect the operation and lifespan of good or new batteries in other strings. These issues also apply to other situations where series-parallel strings are used, not just in UPS systems but also in electric vehicle applications.\nConsider a series-parallel battery arrangement with all good cells, and one becomes shorted or dead:\nThe only way to prevent these subtle series-parallel string interactions is by not using parallel strings at all and using separate charge controllers and inverters for individual series strings.\nSeries new/old battery interactions.\nEven just a single string of batteries wired in series can have adverse interactions if new batteries are mixed with old batteries. Older batteries tend to have reduced storage capacity, and so will both discharge faster than new batteries and also charge to their maximum capacity more rapidly than new batteries.\nAs a mixed string of new and old batteries is depleted, the string voltage will drop, and when the old batteries are exhausted the new batteries still have charge available. The newer cells may continue to discharge through the rest of the string, but due to the low voltage this energy flow may not be useful and may be wasted in the old cells as resistance heating.\nFor cells that are supposed to operate within a specific discharge window, new cells with more capacity may cause the old cells in the series string to continue to discharge beyond the safe bottom limit of the discharge window, damaging the old cells.\nWhen recharged, the old cells recharge more rapidly, leading to a rapid rise of voltage to near the fully charged state, but before the new cells with more capacity have fully recharged. The charge controller detects the high voltage of a nearly fully charged string and reduces current flow. The new cells with more capacity now charge very slowly, so slowly that the chemicals may begin to crystallize before reaching the fully charged state, reducing new cell capacity over several charge/discharge cycles until their capacity more closely matches the old cells in the series string.\nFor such reasons, some industrial UPS management systems recommend periodic replacement of entire battery arrays potentially using hundreds of expensive batteries, due to these damaging interactions between new batteries and old batteries, within and across series and parallel strings.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41835", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=41835", "title": "Universal Time", "text": "Time standard based on the slowing rotation of the Earth\nUniversal Time (UT or UT1) is a time standard based on Earth's rotation. While originally it was mean solar time at 0\u00b0 longitude, precise measurements of the Sun are difficult. Therefore, UT1 is computed from a measure of the Earth's angle with respect to the International Celestial Reference Frame (ICRF), called the Earth Rotation Angle (ERA, which serves as the replacement for Greenwich Mean Sidereal Time). UT1 is the same everywhere on Earth. UT1 is required to follow the relationship\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;ERA = 2\u03c0(0.7790572732640 + 1.00273781191135448\"\u2009\u00b7\u2009Tu\") radians\nwhere \"Tu\" = (Julian UT1 date \u2212 2451545.0).\nHistory.\nPrior to the introduction of standard time, each municipality throughout the clock-using world set its official clock, if it had one, according to the local position of the Sun (see solar time). This served adequately until the introduction of rail travel in Britain, which made it possible to travel fast enough over sufficiently long distances as to require continuous re-setting of timepieces as a train progressed in its daily run through several towns. Starting in 1847, Britain established Greenwich Mean Time, the mean solar time at Greenwich, England, to solve this problem: all clocks in Great Britain were set to this time regardless of local solar noon. Using telescopes, GMT was calibrated to the mean solar time at the prime meridian through the Royal Observatory, Greenwich. Chronometers or telegraphy were used to synchronize these clocks.\nAs international commerce increased, the need for an international standard of time measurement emerged. Several authors proposed a \"universal\" or \"cosmic\" time (see ). The development of Universal Time began at the International Meridian Conference. At the end of this conference, on 22 October 1884, the recommended base reference for world time, the \"universal day\", was announced to be the local mean solar time at the Royal Observatory in Greenwich, counted from 0 hours at Greenwich mean midnight. This agreed with the civil Greenwich Mean Time used on the island of Great Britain since 1847. In contrast, astronomical GMT began at mean noon, i.e. astronomical day \"X\" began at noon of civil day \"X\". The purpose of this was to keep one night's observations under one date. The civil system was adopted as of 0 hours (civil) 1 January 1925. Nautical GMT began 24 hours before astronomical GMT, at least until 1805 in the Royal Navy, but persisted much later elsewhere because it was mentioned at the 1884 conference. Greenwich was chosen because by 1884 two-thirds of all nautical charts and maps already used it as their prime meridian.\nDuring the period between 1848 and 1972, all of the major countries adopted time zones based on the Greenwich meridian.\nIn 1928, the term \"Universal Time\" (\"UT\") was introduced by the International Astronomical Union to refer to GMT, with the day starting at midnight. The term was recommended as a more precise term than \"Greenwich Mean Time\", because \"GMT\" could refer to either an astronomical day starting at noon or a civil day starting at midnight. As the general public had always begun the day at midnight, the timescale continued to be presented to them as Greenwich Mean Time.\nWhen introduced, broadcast time signals were based on UT, and hence on the rotation of the Earth. In 1955 the BIH adopted a proposal by William Markowitz, effective 1 January 1956, dividing UT into UT0 (UT as formerly computed), UT1 (UT0 corrected for polar motion) and UT2 (UT0 corrected for polar motion and seasonal variation). UT1 was the version sufficient for \"many astronomical and geodetic applications\", while UT2 was to be broadcast over radio to the public.\nUT0 and UT2 soon became irrelevant due to the introduction of Coordinated Universal Time (UTC). Starting in 1956, WWV broadcast an atomic clock signal stepped by 20 ms increments to bring it into agreement with UT1. The up to 20 ms error from UT1 is on the same order of magnitude as the differences between UT0, UT1, and UT2. By 1960, the U.S. Naval Observatory, the Royal Greenwich Observatory, and the UK National Physical Laboratory had developed UTC, with a similar stepping approach. The 1960 URSI meeting recommended that all time services should follow the lead of the UK and US and broadcast coordinated time using a frequency offset from cesium aimed to match the predicted progression of UT2 with occasional steps as needed. Starting 1 January 1972, UTC was defined to follow UT1 within 0.9 seconds rather than UT2, marking the decline of UT2.\nModern civil time generally follows UTC. In some countries, the term \"Greenwich Mean Time\" persists in common usage to this day in reference to UT1, in civil timekeeping as well as in astronomical almanacs and other references. Whenever a level of accuracy better than one second is not required, UTC can be used as an approximation of UT1. The difference between UT1 and UTC is known as DUT1.\nAdoption in various countries.\nThe table shows the dates of adoption of time zones based on the Greenwich meridian, including half-hour zones.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nApart from Nepal Standard Time (UTC+05:45), the Chatham Standard Time Zone (UTC+12:45) used in New Zealand's Chatham Islands and the officially unsanctioned Central Western Time Zone (UTC+8:45) used in Eucla, Western Australia and surrounding areas, all time zones in use are defined by an offset from UTC that is a multiple of half an hour, and in most cases a multiple of an hour.\nMeasurement.\nHistorically, Universal Time was computed from observing the position of the Sun in the sky. But astronomers found that it was more accurate to measure the rotation of the Earth by observing stars as they crossed the meridian each day. Nowadays, UT in relation to International Atomic Time (TAI) is determined by Very Long Baseline Interferometry (VLBI) observations of the positions of distant celestial objects (stars and quasars), a method which can determine UT1 to within 15 microseconds or better.\nThe rotation of the Earth and UT are monitored by the International Earth Rotation and Reference Systems Service (IERS). The International Astronomical Union also is involved in setting standards, but the final arbiter of broadcast standards is the International Telecommunication Union or ITU.\nThe rotation of the Earth is somewhat irregular and also is very gradually slowing due to tidal acceleration. Furthermore, the length of the second was determined from observations of the Moon between 1750 and 1890. All of these factors cause the modern mean solar day, on the average, to be slightly longer than the nominal 86,400 SI seconds, the traditional number of seconds per day. As UT is thus slightly irregular in its rate, astronomers introduced Ephemeris Time, which has since been replaced by Terrestrial Time (TT). Because Universal Time is determined by the Earth's rotation, which drifts away from more precise atomic-frequency standards, an adjustment (called a leap second) to this atomic time is needed since (as of 2019[ [update]]) 'broadcast time' remains broadly synchronised with solar time. Thus, the civil broadcast standard for time and frequency usually follows International Atomic Time closely, but occasionally step (or \"leap\") in order to prevent them from drifting too far from mean solar time.\nBarycentric Dynamical Time (TDB), a form of atomic time, is now used in the construction of the ephemerides of the planets and other Solar System objects, for two main reasons. First, these ephemerides are tied to optical and radar observations of planetary motion, and the TDB time scale is fitted so that Newton's laws of motion, with corrections for general relativity, are followed. Next, the time scales based on Earth's rotation are not uniform and therefore, are not suitable for predicting the motion of bodies in the Solar System.\nVersions.\nUT1 is the principal form of Universal Time. However, there are also several other infrequently used time standards that are referred to as \"Universal Time\", which agree within 0.03 seconds with UT1:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41836", "revid": "50612553", "url": "https://en.wikipedia.org/wiki?curid=41836", "title": "Abstract factory pattern", "text": "Software design pattern\nThe abstract factory pattern in software engineering is a design pattern that provides a way to create families of related objects without imposing their concrete classes, by encapsulating a group of individual factories that have a common theme without specifying their concrete classes. According to this pattern, a client software component creates a concrete implementation of the abstract factory and then uses the generic interface of the factory to create the concrete objects that are part of the family. The client does not know which concrete objects it receives from each of these internal factories, as it uses only the generic interfaces of their products. This pattern separates the details of implementation of a set of objects from their general usage and relies on object composition, as object creation is implemented in methods exposed in the factory interface.\nUse of this pattern enables interchangeable concrete implementations without changing the code that uses them, even at runtime. However, employment of this pattern, as with similar design patterns, may result in unnecessary complexity and extra work in the initial writing of code. Additionally, higher levels of separation and abstraction can result in systems that are more difficult to debug and maintain.\nOverview.\nThe abstract factory design pattern is one of the 23 patterns described in the 1994 \"Design Patterns\" book. It may be used to solve problems such as:\nCreating objects directly within the class that requires the objects is inflexible. Doing so commits the class to particular objects and makes it impossible to change the instantiation later without changing the class. It prevents the class from being reusable if other objects are required, and it makes the class difficult to test because real objects cannot be replaced with mock objects.\nA factory is the location of a concrete class in the code at which objects are constructed. Implementation of the pattern intends to insulate the creation of objects from their usage and to create families of related objects without depending on their concrete classes. This allows for new derived types to be introduced with no change to the code that uses the base class.\nThe pattern describes how to solve such problems:\nThis makes a class independent of how its objects are created. A class may be configured with a factory object, which it uses to create objects, and the factory object can be exchanged at runtime.\nDefinition.\n\"Design Patterns\" describes the abstract factory pattern as \"an interface for creating families of related or dependent objects without specifying their concrete classes.\"\nUsage.\nThe factory determines the concrete type of object to be created, and it is here that the object is actually created. However, the factory only returns a reference (in Java, for instance, by the new operator) or a pointer of an abstract type to the created concrete object.\nThis insulates client code from object creation by having clients request that a factory object create an object of the desired abstract type and return an abstract pointer to the object.\nAn example is an abstract factory class codice_1 that provides interfaces to create a number of products (e.g., codice_2 and codice_3). The system would have any number of derived concrete versions of the codice_1 class such ascodice_5 or codice_6, each with a different implementation of codice_2 and codice_3 that would create corresponding objects such ascodice_9 or codice_10. Each of these products is derived from a simple abstract class such ascodice_11 or codice_12 of which the client is aware. The client code would acquire an appropriate instance of the codice_1 and call its factory methods. Each of the resulting objects would be created from the same codice_1 implementation and would share a common theme. The client would only need to know how to handle the abstract codice_11 or codice_12 class, not the specific version that was created by the concrete factory.\nAs the factory only returns a reference or a pointer to an abstract type, the client code that requested the object from the factory is not aware of\u2014and is not burdened by\u2014the actual concrete type of the object that was created. However, the abstract factory knows the type of a concrete object (and hence a concrete factory). For instance, the factory may read the object's type from a configuration file. The client has no need to specify the type, as the type has already been specified in the configuration file. In particular, this means:\nStructure.\nUML diagram.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nA sample UML class and sequence diagram for the abstract factory design pattern.\nIn the above UML class diagram, \nthe codice_17 class that requires codice_18 and codice_19 objects does not instantiate the codice_20 and codice_21 classes directly. Instead, the codice_17 refers to the codice_23 interface for creating objects, which makes the codice_17 independent of how the objects are created (which concrete classes are instantiated). The codice_25 class implements the codice_23 interface by instantiating the codice_20 and codice_21 classes.\nThe UML sequence diagram shows the runtime interactions. The codice_17 object calls codice_30 on the codice_25 object, which creates and returns a codice_20 object. Thereafter, the codice_17 calls codice_34 on codice_25, which creates and returns a codice_21 object.\nVariants.\nThe original structure of the abstract factory pattern, as defined in 1994 in \"Design Patterns\", is based on abstract classes for the abstract factory and the abstract products to be created. The concrete factories and products are classes that specialize the abstract classes using inheritance. \nA more recent structure of the pattern is based on interfaces that define the abstract factory and the abstract products to be created. This design uses native support for interfaces or protocols in mainstream programming languages to avoid inheritance. In this case, the concrete factories and products are classes that realize the interface by implementing it. \nExample.\nThis C++23 implementation is based on the pre-C++98 implementation in the book.\nimport std;\nusing std::array;\nusing std::shared_ptr;\nusing std::unique_ptr;\nusing std::vector;\nenum class Direction: char {\n NORTH, \n SOUTH, \n EAST, \n WEST\nclass MapSite {\npublic:\n virtual void enter() = 0;\n virtual ~MapSite() = default;\nclass Room: public MapSite {\nprivate:\n int roomNumber;\n shared_ptr&lt;array&lt;MapSite, 4\u00bb sides;\npublic:\n explicit Room(int n = 0): \n ~Room() = default;\n Room&amp; setSide(Direction d, MapSite* ms) {\n sides[static_cast&lt;size_t&gt;(d)] = std::move(ms);\n std::println(\"Room::setSide {} ms\", d);\n return *this;\n virtual void enter() override = 0;\n Room(const Room&amp;) = delete;\n Room&amp; operator=(const Room&amp;) = delete;\nclass Wall: public MapSite {\npublic:\n explicit Wall(int n = 0):\n ~Wall() = default;\n void enter() override {\nclass Door: public MapSite {\nprivate:\n shared_ptr&lt;Room&gt; room1;\n shared_ptr&lt;Room&gt; room2;\npublic:\n explicit Door(int n = 0, shared_ptr&lt;Room&gt; r1 = nullptr, shared_ptr&lt;Room&gt; r2 = nullptr): \n ~Door() = default;\n void enter() override {\n Door(const Door&amp;) = delete;\n Door&amp; operator=(const Door&amp;) = delete;\nclass Maze {\nprivate:\n vector&lt;shared_ptr&lt;Room\u00bb rooms;\npublic:\n Maze() = default;\n ~Maze() = default;\n Maze&amp; addRoom(shared_ptr&lt;Room&gt; r) {\n std::println(\"Maze::addRoom {}\", reinterpret_cast&lt;void*&gt;(r.get()));\n rooms.push_back(std::move(r));\n return *this;\n \n shared_ptr&lt;Room&gt; roomNo(int n) const {\n for (const Room&amp; r: rooms) {\n // actual lookup logic here...\n return nullptr;\n};\nclass MazeFactory {\npublic:\n MazeFactory() = default;\n virtual ~MazeFactory() = default;\n nodiscard\n unique_ptr&lt;Maze&gt; makeMaze() const {\n return std::make_unique&lt;Maze&gt;();\n nodiscard\n shared_ptr&lt;Wall&gt; makeWall() const {\n return std::make_shared&lt;Wall&gt;();\n nodiscard\n shared_ptr&lt;Room&gt; makeRoom(int n) const {\n return std::make_shared&lt;Room&gt;(new Room(n));\n \n nodiscard\n shared_ptr&lt;Door&gt; makeDoor(shared_ptr&lt;Room&gt; r1, shared_ptr&lt;Room&gt; r2) const {\n return std::make_shared&lt;Door&gt;(std::move(r1), std::move(r2));\n};\n// If createMaze is passed an object as a parameter to use to create rooms, walls, and doors, then you can change the classes of rooms, walls, and doors by passing a different parameter. This is an example of the Abstract Factory (99) pattern.\nclass MazeGame {\npublic:\n Maze() = default;\n ~Maze() = default;\n nodiscard\n unique_ptr&lt;Maze&gt; createMaze(MazeFactory&amp; factory) {\n unique_ptr&lt;Maze&gt; maze = factory.makeMaze();\n shared_ptr&lt;Room&gt; r1 = factory.makeRoom(1);\n shared_ptr&lt;Room&gt; r2 = factory.makeRoom(2);\n shared_ptr&lt;Door&gt; door = factory.makeDoor(r1, r2);\n maze-&gt;addRoom(r1)\n .addRoom(r2)\n .setSide(Direction::NORTH, factory.makeWall())\n .setSide(Direction::EAST, door)\n .setSide(Direction::SOUTH, factory.makeWall())\n .setSide(Direction::WEST, factory.makeWall())\n .setSide(Direction::NORTH, factory.makeWall())\n .setSide(Direction::EAST, factory.makeWall())\n .setSide(Direction::SOUTH, factory.makeWall())\n .setSide(Direction::WEST, door);\n return maze;\n};\nint main(int argc, char* argv[]) {\n MazeGame game;\n unique_ptr&lt;Maze&gt; maze = game.createMaze(MazeFactory());\nThe program output is:\nMaze::addRoom 0x1317ed0\nMaze::addRoom 0x1317ef0\nRoom::setSide 0 0x1318340\nRoom::setSide 2 0x1317f10\nRoom::setSide 1 0x1318360\nRoom::setSide 3 0x1318380\nRoom::setSide 0 0x13183a0\nRoom::setSide 2 0x13183c0\nRoom::setSide 1 0x13183e0\nRoom::setSide 3 0x1317f10\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41837", "revid": "1320215611", "url": "https://en.wikipedia.org/wiki?curid=41837", "title": "Telecommunications link", "text": "Communication channel between two or more devices\nIn a telecommunications network, a link is a communication channel that connects two or more devices for the purpose of data transmission. The link may be a dedicated physical link or a virtual circuit that uses one or more physical links or shares a physical link with other telecommunications links.\nA telecommunications link is generally based on one of several types of information transmission paths such as those provided by communication satellites, terrestrial radio communications infrastructure and computer networks to connect two or more points.\nThe term \"link\" is widely used in computer networking to refer to the communications facilities that connect nodes of a network.\nSometimes the communications facilities that provide the communication channel that constitutes a link are also included in the definition of \"link\". \nTypes.\nPoint-to-point.\nA point-to-point link is a dedicated link that connects exactly two communication facilities (e.g., two nodes of a network, an intercom station at an entryway with a single internal intercom station, a radio path between two points, etc.).\nBroadcast.\nBroadcast links connect two or more nodes and support \"broadcast transmission\", where one node can transmit so that all other nodes can receive the same transmission. Classic Ethernet is an example.\nMultipoint.\nAlso known as a \"multidrop\" link, a multipoint link is a link that connects \"two or more\" nodes. Also known as general topology networks, these include ATM and Frame Relay links, as well as X.25 networks when used as links for a network-layer protocol like IP.\nUnlike broadcast links, there is no mechanism to efficiently send a single message to all other nodes without copying and retransmitting the message.\nPoint-to-multipoint.\nA point-to-multipoint link (or simply a \"multipoint\") is a specific type of multipoint link which consists of a central connection endpoint (CE) that is connected to multiple peripheral CEs. All of the peripheral CEs receive any transmission of data that originates from the central CE while any transmission of data that originates from any of the peripheral CEs is only received by the central CE.\nPrivate and public.\nLinks are often referred to by terms that refer to the ownership or accessibility of the link.\nDirection.\nForward link.\nA forward link is the link from a fixed location (e.g., a base station) to a mobile user. If the link includes a communications relay satellite, the forward link will consist of both an uplink (base station to satellite) and a downlink (satellite to mobile user).\nReverse link.\nThe reverse link (sometimes called a \"return channel\") is the link from a mobile user to a fixed base station.\nIf the link includes a communications relay satellite, the reverse link will consist of both an uplink (mobile station to satellite) and a downlink (satellite to base station) which together constitute a half hop.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "41838", "revid": "90397", "url": "https://en.wikipedia.org/wiki?curid=41838", "title": "UPT environment", "text": ""}
{"id": "41839", "revid": "90397", "url": "https://en.wikipedia.org/wiki?curid=41839", "title": "UPT number", "text": ""}
{"id": "41840", "revid": "90397", "url": "https://en.wikipedia.org/wiki?curid=41840", "title": "UPT service profile", "text": ""}
{"id": "41842", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41842", "title": "User information bit", "text": ""}
{"id": "41843", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=41843", "title": "Utility program", "text": ""}
{"id": "41844", "revid": "40993790", "url": "https://en.wikipedia.org/wiki?curid=41844", "title": "Validation", "text": "Validation may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41845", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41845", "title": "Variable-length buffer", "text": "In telecommunications, a variable length buffer or elastic buffer is a buffer into which data may be entered at one rate and removed at another rate without changing the data sequence. \nMost first-in first-out (FIFO) storage devices are variable-length buffers in that the input rate may be variable while the output rate is constant or the output rate may be variable while the input rate is constant. Various clocking and control systems are used to allow control of underflow or overflow conditions.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41846", "revid": "11952314", "url": "https://en.wikipedia.org/wiki?curid=41846", "title": "Video teleconference", "text": ""}
{"id": "41847", "revid": "47070250", "url": "https://en.wikipedia.org/wiki?curid=41847", "title": "Video teleconferencing unit", "text": ""}
{"id": "41848", "revid": "9795500", "url": "https://en.wikipedia.org/wiki?curid=41848", "title": "View", "text": "View(s) may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41849", "revid": "1300539373", "url": "https://en.wikipedia.org/wiki?curid=41849", "title": "Viewdata", "text": "Information retrieval service and legacy system\nViewdata is a Videotex implementation. It is a type of information retrieval service in which a subscriber can access a remote database via a common carrier channel, request data and receive requested data on a video display over a separate channel. Samuel Fedida, who had the idea for Viewdata in 1968, was credited as inventor of the system which was developed while working for the British Post Office which was the operator of the national telephone system. The first prototype became operational in 1974. The access, request and reception are usually via common carrier broadcast channels. This is in contrast with teletext.\nDesign.\nViewdata offered a display of 40\u00d724 characters, based on ISO 646 (IRV IA5) \u2013 7 bits with no accented characters.\nOriginally, Viewdata was accessed with a special purpose terminal (or emulation software) and a modem running at ITU-T V.23 speed (1,200 bit/s down, 75 bit/s up). By 2004, it was normally accessed over TCP/IP using Viewdata client software on a personal computer running Microsoft Windows, or using a Web-based emulator.\nViewdata uses special symbols already widely available on telephone keypads: the \"star\" key and the \"square\" key, as formally standardised by the International Telecommunication Union. These are often treated as approximately corresponding to the ASCII asterisk (*) and number sign (#), which do not necessarily conform to the ITU specifications for the keypad symbols; the asterisk is also usually displayed smaller and raised.\nThese symbols appear as 'Sextile' and 'Viewdata square' in the Miscellaneous Symbols and Miscellaneous Technical Unicode blocks, respectively. The sextile was added due to its use in astrology, and the square had previously appeared in the BS_Viewdata character set, as a replacement for the underscore.\nIn 2013, the German national body submitted a Unicode Technical Committee proposal to align the Unicode reference glyphs with the ITU specifications for these symbols, and annotate them as telephone keypad symbols on the code charts. As of 2019[ [update]] (Unicode 12.1), these changes have not been accepted/implemented.\nUses.\nTravel industry.\nAs of 2015, Viewdata was still in use in the United Kingdom, mainly by the travel industry. Travel agents use it to look up the price and availability of package holidays and flights. Once they find what the customer is looking for they can place a booking.\nThere are a number of factors still holding up a move to a Web-based standard. Viewdata is regarded within the industry as low-cost and reliable, travel consultants have been trained to use Viewdata and would need training to book holidays on the Internet, and tour operators cannot agree on a Web-based standard. \nBulletin board systems.\nA number of Viewdata bulletin board systems existed in the 1980s, predominantly in the UK due to the proliferation of the BBC Micro, and a short-lived \"Viewdata Revival\" appeared in the late 1990s fuelled by the retrocomputing vogue. Some Viewdata boards still exist, with accessibility in the form of Java Telnet clients.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41850", "revid": "19372301", "url": "https://en.wikipedia.org/wiki?curid=41850", "title": "Virtual call capability", "text": ""}
{"id": "41851", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41851", "title": "Virtual circuit", "text": "Emulation a dedicated physical link over a packet-switched network\nA virtual circuit (VC) is a means of transporting data over a data network, based on packet switching and in which a connection is first established across the network between two endpoints. The network, rather than having a fixed data rate reservation per connection as in circuit switching, takes advantage of the statistical multiplexing on its transmission links, an intrinsic feature of packet switching. \nA 1978 standardization of virtual circuits by the CCITT imposes per-connection flow controls at all user-to-network and network-to-network interfaces. This permits participation in congestion control and reduces the likelihood of packet loss in a heavily loaded network. Some circuit protocols provide reliable communication service through the use of data retransmissions invoked by error detection and automatic repeat request (ARQ). \nBefore a virtual circuit may be used, it must be established between network nodes in the call setup phase. Once established, a bit stream or byte stream may be exchanged between the nodes, providing abstraction from low-level division into protocol data units, and enabling higher-level protocols to operate transparently.\nAn alternative to virtual-circuit networks are datagram networks.\nComparison with circuit switching.\nVirtual circuit communication resembles circuit switching, since both are connection oriented, meaning that in both cases data is delivered in correct order, and signaling overhead is required during a connection establishment phase. However, circuit switching provides a constant bit rate and latency, while these may vary in a virtual circuit service due to factors such as:\nVirtual call capability.\nIn telecommunications, a virtual call capability, sometimes called a virtual call facility, is a service feature in which:\nAn alternative approach to virtual calls is connectionless communication using datagrams.\nIn the early 1970s, \"virtual call\" \"capability\" was developed by British Telecom for EPSS (building on the work of Donald Davies at the National Physical Laboratory). The concept was enhanced by R\u00e9mi Despr\u00e9s as \"virtual circuits\" for the RCP experimental network of the French PTT.\nLayer 4 virtual circuits.\nConnection oriented transport layer protocols such as TCP may rely on a connectionless packet switching network layer protocol such as IP, where different packets may be routed over different paths, and thus be delivered out of order. However, it is possible to use TCP as a virtual circuit, since TCP includes segment numbering that allows reordering on the receiver side to accommodate out-of-order delivery.\nLayer 2/3 virtual circuits.\nData link layer and network layer virtual circuit protocols are based on connection-oriented packet switching, meaning that data is always delivered along the same network path, i.e., through the same nodes. Advantages with this over connectionless packet switching are: \nExample protocols.\nExamples of transport layer protocols that provide a virtual circuit:\nExamples of network-layer and data-link-layer virtual circuit protocols, where data always is delivered over the same path:\nPermanent and switched virtual circuits in ATM, Frame Relay, and X.25.\nSwitched virtual circuits (SVCs) are generally set up on a per-call basis and are disconnected when the call is terminated; however, a permanent virtual circuit (PVC) can be established as an option to provide a dedicated circuit link between two facilities. PVC configuration is usually preconfigured by the service provider. Unlike SVCs, PVC are usually very seldom broken/disconnected.\nA switched virtual circuit (SVC) is a virtual circuit that is dynamically established on demand and is torn down when transmission is complete, for example after a phone call or a file download. SVCs are used in situations where data transmission is sporadic and/or not always between the same data terminal equipment (DTE) endpoints.\nA permanent virtual circuit (PVC) is a virtual circuit established for repeated/continuous use between the same DTE. In a PVC, the long-term association is identical to the data transfer phase of a virtual call. Permanent virtual circuits eliminate the need for repeated call set-up and clearing.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41852", "revid": "2747", "url": "https://en.wikipedia.org/wiki?curid=41852", "title": "Virtual circuit capability", "text": ""}
{"id": "41853", "revid": "7557079", "url": "https://en.wikipedia.org/wiki?curid=41853", "title": "Virtual storage", "text": ""}
{"id": "41854", "revid": "35897031", "url": "https://en.wikipedia.org/wiki?curid=41854", "title": "Virtual terminal", "text": "Computer application for remote access\nIn open systems, a virtual terminal (VT) is an application service that:\nPuTTY is an example of a virtual terminal.\nITU-T defines a virtual terminal protocol based on the OSI application layer protocols. However, the virtual terminal protocol is not widely used on the Internet."}
{"id": "41855", "revid": "9178234", "url": "https://en.wikipedia.org/wiki?curid=41855", "title": "Voice frequency", "text": "Audio frequencies used for the transmission of speech\nA voice frequency (VF) or voice band is the range of audio frequencies used for the transmission of speech.\nFrequency band.\nIn telephony, the usable voice frequency band ranges from approximately 300 to 3400\u00a0Hz. It is for this reason that the ultra low frequency band of the electromagnetic spectrum between 300 and 3000\u00a0Hz is also referred to as \"voice frequency\", being the electromagnetic energy that represents acoustic energy at baseband. The bandwidth allocated for a single voice-frequency transmission channel is usually 4\u00a0kHz, including guard bands, allowing a sampling rate of 8\u00a0kHz to be used as the basis of the pulse-code modulation system used for the digital PSTN. Per the Nyquist\u2013Shannon sampling theorem, the sampling frequency (8\u00a0kHz) must be at least twice the highest component of the voice frequency (4\u00a0kHz) via appropriate filtering prior to sampling at discrete times for effective reconstruction of the voice signal.\nFundamental frequency.\nThe voiced speech of a typical adult male will have a fundamental frequency from 90 to 155\u00a0Hz, and that of a typical adult female from 165 to 255\u00a0Hz. Thus, the fundamental frequency of most speech falls below the bottom of the voice frequency band as defined. However, enough of the harmonic series will be present for the missing fundamental to create the impression of hearing the fundamental tone.\nWavelength.\nThe speed of sound at room temperature (20\u00b0C) is 343.15 m/s. Using the formula\nformula_1\nwe have:\nTypical female voices range from to .\nTypical male voices range from to .\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41856", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41856", "title": "Voice frequency primary patch bay", "text": "Patching facility\nIn telecommunications, a voice frequency primary patch bay (VF) is a patching facility that provides the first appearance of local-user VF circuits in the technical control facility (TCF). \nThe VF primary patch bay provides patching, http://, and testing for all VF circuits. Signals will have various levels and signaling schemes depending on the user terminal equipment."}
{"id": "41857", "revid": "2954", "url": "https://en.wikipedia.org/wiki?curid=41857", "title": "Voltage standing wave ratio", "text": ""}
{"id": "41858", "revid": "24565488", "url": "https://en.wikipedia.org/wiki?curid=41858", "title": "Volt-ampere reactive", "text": ""}
{"id": "41859", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=41859", "title": "Voice-operated switch", "text": "Switch controlled by the sound of speech\nIn telecommunications, a voice operated switch, also known as VOX or voice-operated exchange, is a switch that operates when sound over a certain threshold is detected. It is usually used to turn on a transmitter or recorder when someone speaks and turn it off when they stop speaking. It is used instead of a push-to-talk button on transmitters or to save storage space on recording devices. On cell phones, it is used to save battery life. Intercom systems that use a speaker in a room as both a speaker and a microphone will often use VOX on the main console to switch the audio direction during a conversation. The circuit usually includes a delay between the sound stopping and switching direction, to avoid the circuit turning off during short pauses in speech.\nA special case exists, if there is enough energy to power the system directly. For example, a microphone may send a voltage high enough to directly operate a transmitter.\nComparison with push-to-talk.\nUnlike manual push-to-talk (PTT) operation, VOX is\nautomatic; the user can keep his or her hands free while talking. But VOX also has some significant disadvantages that explain why PTT is still common.\nMost VOX circuits have a sensitivity adjustment, but unwanted (and sometimes undetected) VOX triggering can still occur on background noise, heavy breathing or a side conversation. Conversely, it may not activate when desired on speech that is too weak.\nThe VOX in a two-way radio can also be triggered by the loudspeaker carrying the other side of the conversation. This problem can be\nminimized with an \"anti vox\" feature to decrease VOX sensitivity when the receiver is active.\nTransmitters and recorders have short but finite activation times that\nmay clip the beginnings of phrases. Some modern VOX circuits eliminate this problem by recording or transmitting a delayed version of the input signal. An older way of overcoming this, used by pilots, and astronauts, as some of the first users of VOX, was to habitually preface every transmission with \"uh\" in place of keying the microphone.\nVOX uses a \"hang\" timer, typically 1\u20133 seconds, to remain engaged during brief speech pauses. This means the last several seconds of each transmission or recorded segment are always silence. A VOX-activated recorder can delete the end of each segment but the user of a VOX-activated half duplex radio must wait for the timer to expire before he or she can receive again.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41860", "revid": "39641301", "url": "https://en.wikipedia.org/wiki?curid=41860", "title": "Wafer (electronics)", "text": "Thin slice of semiconductor used for the fabrication of integrated circuits\nIn electronics, a wafer (also called a slice or substrate) is a thin slice of semiconductor, such as a crystalline silicon (c-Si, silicium), used for the fabrication of integrated circuits and, in photovoltaics, to manufacture solar cells.\nThe wafer serves as the substrate for microelectronic devices built in and upon the wafer. It undergoes many microfabrication processes, such as doping, ion implantation, etching, thin-film deposition of various materials, and photolithographic patterning. Finally, the individual microcircuits are separated by wafer dicing and packaged as an integrated circuit.\nHistory.\nIn the semiconductor industry, the term wafer appeared in the 1950s to describe a thin round slice of semiconductor material, typically germanium or silicon. The round shape characteristic of these wafers comes from single-crystal ingots usually produced using the Czochralski method. Though, silicon wafers were first introduced in the 1940s.\nBy 1960, silicon wafers were being manufactured in the U.S. by companies such as MEMC and SunEdison. In 1965, American engineers Eric O. Ernst, Donald J. Hurd, and Gerard Seeley, while working under IBM, filed Patent US3423629A for the first high-capacity epitaxial apparatus.\nProduction.\nFormation.\nWafers are formed of highly pure,\nnearly defect-free single crystalline material, with a purity of 99.9999999% (9N) or higher.\nOne process for forming crystalline wafers is known as the Czochralski method, invented by Polish chemist Jan Czochralski. In this process, a cylindrical ingot of high purity monocrystalline semiconductor, such as silicon or germanium, called a boule, is formed by pulling a seed crystal from a melt. Donor impurity atoms, such as boron or phosphorus in the case of silicon, can be added to the molten intrinsic material in precise amounts in order to dope the crystal, thus changing it into an extrinsic semiconductor of n-type or p-type.\nThe boule is then sliced with a wafer saw (a type of wire saw), machined to improve flatness, chemically etched to remove crystal damage from machining steps and finally polished to form wafers. The size of wafers for photovoltaics is 100\u2013200\u00a0mm square and the thickness is 100\u2013500\u00a0\u03bcm. Electronics use wafer sizes from 100 to 450\u00a0mm diameter. The largest wafers made have a diameter of 450\u00a0mm, but are not yet in general use.\nCleaning, texturing and etching.\nWafers are cleaned with weak acids to remove unwanted particles. There are several standard cleaning procedures to make sure the surface of a silicon wafer contains no contamination. One of the most effective methods is the RCA clean.\nWhen used for solar cells, the wafers are textured to create a rough surface to increase surface area and so their efficiency. The generated PSG (phosphosilicate glass) is removed from the edge of the wafer in the etching.\nWafer properties.\nStandard wafer sizes.\nSilicon substrate.\nSilicon wafers are available in a variety of diameters from 25.4\u00a0mm (1\u00a0inch) to 300\u00a0mm (11.8\u00a0inches). Semiconductor fabrication plants, colloquially known as \"fabs\", are defined by the diameter of wafers that they are tooled to produce. The diameter has gradually increased to improve throughput and reduce cost with the current state-of-the-art fab using 300 mm, with a proposal to adopt 450 mm. Intel, TSMC, and Samsung were separately conducting research to the advent of 450 mm \"prototype\" (research) fabs, though serious hurdles remain.\nWafers grown using materials other than silicon will have different thicknesses than a silicon wafer of the same diameter. Wafer thickness is determined by the mechanical strength of the material used; the wafer must be thick enough to support its own weight without cracking during handling. The tabulated thicknesses relate to when that process was introduced, and are not necessarily correct currently, for example the IBM BiCMOS7WL process is on 8-inch wafers, but these are only 200\u00a0\u03bcm thick. The weight of the wafer increases with its thickness and the square of its diameter. Date of introduction does not indicate that factories will convert their equipment immediately, in fact, many factories do not bother upgrading. Instead, companies tend to expand and build whole new lines with newer technologies, leaving a large spectrum of technologies in use at the same time.\nGallium Nitride substrate.\nGaN substrate wafers typically have had their own independent timelines, parallel but far lagging silicon substrate, but ahead of other substrates. The world's first 300 mm wafer made of GaN was announced in Sept 2024 by Infineon, suggesting in the coming future they could put into use the first factory with 300 mm GaN commercial output.\nSiC substrate.\nMeanwhile world's first Silicon Carbide (SiC) 200 mm wafers were announced in July 2021 by ST Microelectronics. It is not known if SiC 200 mm has entered volume production as of 2024, as typically the largest fabs for SiC in commercial production remain at 150 mm.\nSilicon on sapphire.\nSilicon on sapphire is different from silicon substrate as the substrate is sapphire, while superstrate is silicon, while epitaxial layers and doping can be anything. SOS in commercial production is typically maxed out at 150 mm wafer sizes as of 2024.\nGallium Arsenide substrate.\nGaAs wafers tend to be 150 mm at largest, in commercial production as of 2024.\nAluminum Nitride substrate.\nAlN tends to be 50 mm or 2 inch wafers in commercial production, while 100 mm or 4 inch wafers are https:// by wafer suppliers like Asahi Kasei. However, merely because a wafer exists commercially, does not imply in any way that processing equipment to produce chips on that wafer exists, indeed such equipment tends to lag development until paying end customer demand materializes. Even after equipment is developed (years), it can take further years for fabs to figure out how to use the machines productively.\nDiamond substrate.\nDiamond tends to be 50-55 mm or ~2 inch wafers in prototype production, while commercial production is being targeted as of 2026.\nHistorical increases of wafer size.\nA unit of wafer fabrication step, such as an etch step, can produce more chips proportional to the increase in wafer area, while the cost of the unit fabrication step goes up more slowly than the wafer area. This was the cost basis for increasing wafer size. Conversion to 300\u00a0mm wafers from 200\u00a0mm wafers began in early 2000, and reduced the price per die for about 30\u201340%.Larger diameter wafers allow for more die per wafer.\nPhotovoltaic.\nM1 wafer size (156.75\u00a0mm) is in the process of being phased out in China as of 2020. Various nonstandard wafer sizes have arisen, so efforts to fully adopt the M10 standard (182\u00a0mm) are ongoing. Like other semiconductor fabrication processes, driving down costs has been the main driving factor for this attempted size increase, in spite of the differences in the manufacturing processes of different types of devices.\nCrystalline orientation.\nWafers are grown from crystal having a regular crystal structure, with silicon having a diamond cubic structure with a lattice spacing of 5.430710 \u00c5 (0.5430710\u00a0nm). When cut into wafers, the surface is aligned in one of several relative directions known as crystal orientations. Orientation is defined by the Miller index with (100) or (111) faces being the most common for silicon.\nOrientation is important since many of a single crystal's structural and electronic properties are highly anisotropic. Ion implantation depths depend on the wafer's crystal orientation, since each direction offers distinct paths for transport.\nWafer cleavage typically occurs only in a few well-defined directions. Scoring the wafer along cleavage planes allows it to be easily diced into individual chips (\"dies\") so that the billions of individual circuit elements on an average wafer can be separated into many individual circuits.\nCrystallographic orientation notches.\nWafers under 200\u00a0mm diameter have \"flats\" cut into one or more sides indicating the crystallographic planes of the wafer (usually a {110} face). In earlier-generation wafers a pair of flats at different angles additionally conveyed the doping type (see illustration for conventions). Wafers of 200\u00a0mm diameter and above use a single small notch to convey wafer orientation, with no visual indication of doping type. 450 mm wafers are notchless, relying on a laser scribed structure on the wafer surface for orientation.\nImpurity doping.\nSilicon wafers are generally not 100% pure silicon, but are instead formed with an initial impurity doping concentration between 1013 and 1016 atoms per cm3 of boron, phosphorus, arsenic, or antimony which is added to the melt and defines the wafer as either bulk n-type or p-type. However, compared with single-crystal silicon's atomic density of 5\u00d71022 atoms per cm3, this still gives a purity greater than 99.9999%. The wafers can also be initially provided with some interstitial oxygen concentration. Carbon and metallic contamination are kept to a minimum. Transition metals, in particular, must be kept below parts per billion concentrations for electronic applications.\n450 mm wafers.\nChallenges.\nThere is considerable resistance to the 450\u00a0mm transition despite the possible productivity improvement, because of concern about insufficient return on investment. There are also issues related to increased inter-die / edge-to-edge wafer variation and additional edge defects. 450mm wafers are expected to cost 4 times as much as 300mm wafers, and equipment costs are expected to rise by 20 to 50%. Higher cost semiconductor fabrication equipment for larger wafers increases the cost of 450\u00a0mm fabs (semiconductor fabrication facilities or factories). Lithographer Chris Mack claimed in 2012 that the overall price per die for 450\u00a0mm wafers would be reduced by only 10\u201320% compared to 300\u00a0mm wafers, because over 50% of total wafer processing costs are lithography-related. Converting to larger 450\u00a0mm wafers would reduce price per die only for process operations such as etch where cost is related to wafer count, not wafer area. Cost for processes such as lithography is proportional to wafer area, and larger wafers would not reduce the lithography contribution to die cost.\nNikon planned to deliver 450-mm lithography equipment in 2015, with volume production in 2017. In November 2013 ASML paused development of 450-mm lithography equipment, citing uncertain timing of chipmaker demand.\nIn 2012, a group consisting of New York State (SUNY Poly/College of Nanoscale Science and Engineering (CNSE)), Intel, TSMC, Samsung, IBM, Globalfoundries and Nikon companies has formed a public-private partnership called Global 450mm Consortium (G450C, similar to SEMATECH) who made a 5-year plan (expiring in 2016) to develop a \"cost effective wafer fabrication infrastructure, equipment prototypes and tools to enable coordinated industry transition to 450mm wafer level\". In the mid of 2014 CNSE has announced that it will reveal first fully patterned 450mm wafers at SEMICON West. In early 2017, the G450C began to dismantle its activities over 450mm wafer research due to undisclosed reasons. Various sources have speculated that demise of the group came after charges of bid rigging made against Alain E. Kaloyeros, who at the time was a chief executive at the SUNY Poly. The industry realization of the fact that the 300mm manufacturing optimization is more cheap than costly 450mm transition may also have played a role.\nThe timeline for 450\u00a0mm has not been fixed. In 2012, it was expected that 450mm production would start in 2017, which never realized. Mark Durcan, then CEO of Micron Technology, said in February 2014 that he expects 450\u00a0mm adoption to be delayed indefinitely or discontinued. \"I am not convinced that 450mm will ever happen but, to the extent that it does, it's a long way out in the future. There is not a lot of necessity for Micron, at least over the next five years, to be spending a lot of money on 450mm.\"\n\"There is a lot of investment that needs to go on in the equipment community to make that happen. And the value at the end of the day \u2013 so that customers would buy that equipment \u2013 I think is dubious.\" As of March 2014, Intel Corporation expected 450\u00a0mm deployment by 2020 (by the end of this decade). Mark LaPedus of semiengineering.com reported in mid-2014 that chipmakers had delayed adoption of 450\u00a0mm \"for the foreseeable future.\" According to this report some observers expected 2018 to 2020, while G. Dan Hutcheson, chief executive of VLSI Research, didn't see 450mm fabs moving into production until 2020 to 2025.\nThe step up to 300\u00a0mm required major changes, with fully automated factories using 300\u00a0mm wafers versus barely automated factories for the 200\u00a0mm wafers, partly because a FOUP for 300\u00a0mm wafers weighs about 7.5 kilograms when loaded with 25 300\u00a0mm wafers where a SMIF weighs about 4.8 kilograms when loaded with 25 200\u00a0mm wafers, thus requiring twice the amount of physical strength from factory workers, and increasing fatigue. 300mm FOUPs have handles so that they can be still be moved by hand. 450mm FOUPs weigh 45 kilograms when loaded with 25 450\u00a0mm wafers, thus cranes are necessary to manually handle the FOUPs and handles are no longer present in the FOUP. FOUPs are moved around using material handling systems from Muratec or Daifuku. These major investments were undertaken in the economic downturn following the dot-com bubble, resulting in huge resistance to upgrading to 450\u00a0mm by the original timeframe. On the ramp-up to 450\u00a0mm, the crystal ingots will be 3 times heavier (total weight a metric ton) and take 2\u20134 times longer to cool, and the process time will be double. All told, the development of 450\u00a0mm wafers requires significant engineering, time, and cost to overcome.\nAnalytical die count estimation.\nIn order to minimize the cost per die, manufacturers wish to maximize the number of dies that can be made from a single wafer; dies always have a square or rectangular shape due to the constraint of wafer dicing. In general, this is a computationally complex problem with no analytical solution, dependent on both the area of the dies as well as their aspect ratio (square or rectangular) and other considerations such as the width of the scribeline or saw lane, and additional space occupied by alignment and test structures. (By simplifying the problem so that the scribeline and saw lane are both zero-width, the wafer is perfectly circular with no flats, and the dies have a square aspect ratio, we arrive at the Gauss Circle Problem, an unsolved open problem in mathematics.)\nNote that formulas estimating the gross dies per wafer (DPW) account only for the number of complete dies that can fit on the wafer; gross DPW calculations do \"not\" account for yield loss among those complete dies due to defects or parametric issues.\nNevertheless, the number of gross DPW can be estimated starting with the first-order approximation or floor function of wafer-to-die area ratio,\nformula_1,\nwhere\nThis formula simply states that the number of dies which can fit on the wafer cannot exceed the area of the wafer divided by the area of each individual die. It will always overestimate the true best-case gross DPW, since it includes the area of partially patterned dies which do not fully lie on the wafer surface (see figure). These partially patterned dies don't represent complete ICs, so they usually cannot be sold as functional parts.\nRefinements of this simple formula typically add an edge correction, to account for partial dies on the edge, which in general will be more significant when the area of the die is large compared to the total area of the wafer. In the other limiting case (infinitesimally small dies or infinitely large wafers), the edge correction is negligible.\nThe correction factor or correction term generally takes one of the forms cited by De Vries:\nformula_4 (area ratio \u2013 circumference/(die diagonal length))\nor formula_5 (area ratio scaled by an exponential factor)\nor formula_6 (area ratio scaled by a polynomial factor).\nStudies comparing these analytical formulas to brute-force computational results show that the formulas can be made more accurate, over practical ranges of die sizes and aspect ratios, by adjusting the coefficients of the corrections to values above or below unity, and by replacing the linear die dimension formula_7 with formula_8 (average side length) in the case of dies with large aspect ratio:\nformula_9\nor formula_10\nor formula_11.\nCompound semiconductors.\nWhile silicon is the prevalent material for wafers used in the electronics industry, other compound III-V or II-VI materials have also been employed. Gallium arsenide (GaAs), a III-V semiconductor produced via the Czochralski method, gallium nitride (GaN) and silicon carbide (SiC) are also common wafer materials, with GaN and sapphire being extensively used in LED manufacturing. \nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41861", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=41861", "title": "Wide area information server", "text": "Internet information retrieval service\nWide Area Information Server (WAIS) is a client\u2013server text searching system that uses the ANSI Standard Z39.50 Information Retrieval Service Definition and Protocol Specifications for Library Applications\" (Z39.50:1988) to search index databases on remote computers. It was developed in 1990 as a project of Thinking Machines, Apple Computer, Dow Jones, and KPMG Peat Marwick. \nWAIS did not adhere to either the Z39.50 standard nor its OSI framework, adopting instead TCP/IP. It created a unique protocol inspired by Z39.50:1988.\nHistory.\nThe WAIS protocol and servers were promoted by Thinking Machines Corporation (TMC) of Cambridge, Massachusetts. TMC-produced WAIS servers ran on their massively parallel CM-2 (Connection Machine) and SPARC-based CM-5 MP supercomputers. WAIS clients were developed for various operating systems and windowing systems including Microsoft Windows, Macintosh, NeXT, X, GNU Emacs, and character terminals. TMC released a free open source software version of WAIS for Unix in 1991. \nInspired by the WAIS project on full-text databases and emerging SGML projects, Z39.50 version 2 (Z39.50:1992) was released. Unlike its 1988 predecessor, it was a compatible superset of the international ISO 10162/10163 standard.\nWith the advent of Z39.50:1992, the termination of support for free WAIS by Thinking Machines and the establishment of WAIS Inc as a commercial venture, the U.S. National Science Foundation funded the Clearinghouse for Networked Information Discovery and Retrieval (CNIDR) to promote Internet search and discovery systems, open source and standards. CNIDR created a new, free open-source WAIS. This was the first freeWAIS based on the wais-8-b5 codebase of TMC, with a wholly new software suite Isite based upon Z39.50:1992 using Isearch as its full-text search engine.\nUlrich Pfeifer and Norbert G\u00f6vert of the computer science department of the University of Dortmund extended the CNIDR freeWAIS code to become freeWAIS-sf with structured fields as its main improvement. Ulrich Pfeifer rewrote freeWAIS-sf in Perl, becoming WAIT.\nInspired by WAIS' \"Directory of Servers\", Eliot Christian of USGS envisioned GILS: Government Information Locator Service. GILS (based upon Z39.50:1992 with some extensions) became a U.S. Federal mandate as part of the Paperwork Reduction Act of 1995 (\u00a0https://).\nDirectory of Servers.\nThinking Machines Corp provided a service called the Directory of Servers. It was a WAIS server like any other information source except containing information about the other WAIS servers on the Internet. A WAIS server with TMC WAIS code creates a special record containing metadata plus some common words describing its indexed content. The record is uploaded to the central server and indexed along with the records from other public servers. The directory can be searched to find servers that might have content relevant to a specific field of interest. This model of searching for (WAIS) servers to search became the model for GILS and Peter Deutsch's WHOIS++ distributed white pages directory.\nPeople.\nTwo of the developers of WAIS, Brewster Kahle and Harry Morris, left Thinking Machines to found WAIS Inc in Menlo Park, California, with Bruce Gilliat. WAIS Inc. was originally a joint project between Apple Computer, Peat Marwick, Dow Jones, and Thinking Machines. In 1992, the presidential campaign of Ross Perot used the WAIS product as a campaign wide information system, connecting the field offices to the national office. Later, Perot Systems adopted WAIS to better access the information in its corporate databases. Other early clients were the Environmental Protection Agency, Library of Congress, and the Department of Energy and later the \"Wall Street Journal\" and \"Encyclop\u00e6dia Britannica\".\nWAIS Inc was sold to AOL in May 1995 for $15 million. Following the sale, Margaret St. Pierre left WAIS Inc to start Blue Angel Technologies. Her WAIS variant formed the basis of MetaStar. Georgios Papadopoulos left to found Atypon. Fran\u00e7ois Schiettecatte left Human Genome Project at Johns Hopkins Hospital and started FS-Consult and developed his own variant of WAIS which eventually became ScienceServer, which was later sold to Elsevier Science. Kahle and Gilliat went on to found the Internet Archive and Alexa Internet.\nWAIS and Gopher.\nPublic WAIS is often used as a full-text search engine for individual Internet Gopher servers, supplementing the popular Veronica system which only searches the menu titles of Gopher sites. WAIS and Gopher share the World Wide Web's client\u2013server architecture and a certain amount of its functionality. The WAIS protocol is influenced largely by the z39.50 protocol designed for networking library catalogs. It allows a text-based search, and retrieval following a search. Gopher provides a free text search mechanism, but principally uses menus. A menu is a list of titles, from which the user may pick one. While Gopher Space is a web containing many loops, the menu system gives the user the impression of a tree.\nThe Web's data model is similar to the gopher model, except that menus are generalized to hypertext documents. In both cases, simple file servers generate the menus or hypertext directly from the file structure of a server. The Web's hypertext model permits the author more freedom to communicate the options available to the reader, as it can include headings and various forms of list structure.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41862", "revid": "359256", "url": "https://en.wikipedia.org/wiki?curid=41862", "title": "Warner exemption", "text": ""}
{"id": "41863", "revid": "20982319", "url": "https://en.wikipedia.org/wiki?curid=41863", "title": "Waveguide", "text": "Structure that guides waves efficiently\nA waveguide is a structure that guides waves by restricting the transmission of energy to one direction. Common types of waveguides include acoustic waveguides which direct sound, optical waveguides which direct light, and radio-frequency waveguides which direct electromagnetic waves other than light like radio waves.\nWithout the physical constraint of a waveguide, waves would expand into three-dimensional space and their intensities would decrease according to the inverse square law.\nThere are different types of waveguides for different types of waves. The original and most common meaning is a hollow conductive metal pipe used to carry high frequency radio waves, particularly microwaves. Dielectric waveguides are used at higher radio frequencies, and transparent dielectric waveguides and optical fibers serve as waveguides for light. In acoustics, air ducts and horns are used as waveguides for sound in musical instruments and loudspeakers, and specially-shaped metal rods conduct ultrasonic waves in ultrasonic machining.\nThe geometry of a waveguide reflects its function; in addition to more common types that channel the wave in one dimension, there are two-dimensional slab waveguides which confine waves to two dimensions. The frequency of the transmitted wave also dictates the size of a waveguide: each waveguide has a cutoff wavelength determined by its size and will not conduct waves of greater wavelength; an optical fiber that guides light will not transmit microwaves which have a much larger wavelength. Some naturally occurring structures can also act as waveguides. The SOFAR channel layer in the ocean can guide the sound of whale song across enormous distances.\nAny shape of waveguide can support EM waves, however irregular shapes are difficult to analyse. Commonly used waveguides are rectangular or circular in cross-section.\nUses.\nThe uses of waveguides for transmitting signals were known even before the term was coined. The phenomenon of sound waves guided through a taut wire have been known for a long time, as well as sound through a hollow pipe such as a cave or medical stethoscope. Other uses of waveguides are in transmitting power between the components of a system such as radio, radar or optical devices. Waveguides are the fundamental principle of guided wave testing (GWT), one of the many methods of non-destructive evaluation.\nSpecific examples:\nHistory.\nThe first structure for guiding waves was proposed by J. J. Thomson in 1893, and was first experimentally tested by Oliver Lodge in 1894. The first mathematical analysis of electromagnetic waves in a metal cylinder was performed by Lord Rayleigh in 1897. For sound waves, Lord Rayleigh published a full mathematical analysis of propagation modes in his seminal work, \"The Theory of Sound\". Jagadish Chandra Bose researched millimeter wavelengths using waveguides, and in 1897 described to the Royal Institution in London his research carried out in Kolkata.\nThe study of dielectric waveguides (such as optical fibers, see below) began as early as the 1920s, by several people, most famous of which are Rayleigh, Sommerfeld and Debye. Optical fiber began to receive special attention in the 1960s due to its importance to the communications industry.\nThe development of radio communication initially occurred at the lower frequencies because these could be more easily propagated over large distances. The long wavelengths made these frequencies unsuitable for use in hollow metal waveguides because of the impractically large diameter tubes required. Consequently, research into hollow metal waveguides stalled and the work of Lord Rayleigh was forgotten for a time and had to be rediscovered by others. Practical investigations resumed in the 1930s by George C. Southworth at Bell Labs and Wilmer L. Barrow at MIT. Southworth at first took the theory from papers on waves in dielectric rods because the work of Lord Rayleigh was unknown to him. This misled him somewhat; some of his experiments failed because he was not aware of the phenomenon of waveguide cutoff frequency already found in Lord Rayleigh's work. Serious theoretical work was taken up by John R. Carson and Sallie P. Mead. This work led to the discovery that for the TE01 mode in circular waveguide losses go down with frequency and at one time this was a serious contender for the format for long-distance telecommunications.\nThe importance of radar in World War II gave a great impetus to waveguide research, at least on the Allied side. The magnetron, developed in 1940 by John Randall and Harry Boot at the University of Birmingham in the United Kingdom, provided a good power source and made microwave radar feasible. The most important centre of US research was at the Radiation Laboratory (Rad Lab) at MIT but many others took part in the US, and in the UK such as the Telecommunications Research Establishment. The head of the Fundamental Development Group at Rad Lab was Edward Mills Purcell. His researchers included Julian Schwinger, Nathan Marcuvitz, Carol Gray Montgomery, and Robert H. Dicke. Much of the Rad Lab work concentrated on finding lumped element models of waveguide structures so that components in waveguide could be analysed with standard circuit theory. Hans Bethe was also briefly at Rad Lab, but while there he produced his small aperture theory which proved important for waveguide cavity filters, first developed at Rad Lab. The German side, on the other hand, largely ignored the potential of waveguides in radar until very late in the war. So much so that when radar parts from a downed British plane were sent to Siemens &amp; Halske for analysis, even though they were recognised as microwave components, their purpose could not be identified.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;At that time, microwave techniques were badly neglected in Germany. It was generally believed that it was of no use for electronic warfare, and those who wanted to do research work in this field were not allowed to do so.\u2014\u200a\nGerman academics were even allowed to continue publicly publishing their research in this field because it was not felt to be important.\nImmediately after World War II waveguide was the technology of choice in the microwave field. However, it has some problems; it is bulky, expensive to produce, and the cutoff frequency effect makes it difficult to produce wideband devices. Ridged waveguide can increase bandwidth beyond an octave, but a better solution is to use a technology working in TEM mode (that is, non-waveguide) such as coaxial conductors since TEM does not have a cutoff frequency. A shielded rectangular conductor can also be used and this has certain manufacturing advantages over coax and can be seen as the forerunner of the planar technologies (stripline and microstrip). However, planar technologies really started to take off when printed circuits were introduced. These methods are significantly cheaper than waveguide and have largely taken its place in most bands. However, waveguide is still favoured in the higher microwave bands from around Ku band upwards.\nProperties.\nPropagation modes and cutoff frequencies.\nA propagation mode in a waveguide is one solution of the wave equations, or, in other words, the form of the wave. Due to the constraints of the boundary conditions, there are only limited frequencies and forms for the wave function which can propagate in the waveguide. The lowest frequency in which a certain mode can propagate is the cutoff frequency of that mode. The mode with the lowest cutoff frequency is the fundamental mode of the waveguide, and its cutoff frequency is the waveguide cutoff frequency.\nPropagation modes are computed by solving the Helmholtz equation alongside a set of boundary conditions depending on the geometrical shape and materials bounding the region. The usual assumption for infinitely long uniform waveguides allows us to assume a propagating form for the wave, i.e. stating that every field component has a known dependency on the propagation direction (i.e. formula_1). More specifically, the common approach is to first replace all unknown time-varying fields formula_2 (assuming for simplicity to describe the fields in cartesian components) with their complex phasors representation formula_3, sufficient to fully describe any infinitely long single-tone signal at frequency formula_4, (angular frequency formula_5), and rewrite the Helmholtz equation and boundary conditions accordingly. Then, every unknown field is forced to have a form like formula_6, where the formula_7 term represents the propagation constant (still unknown) along the direction along which the waveguide extends to infinity. The Helmholtz equation can be rewritten to accommodate such form and the resulting equality needs to be solved for formula_7 and formula_9, yielding in the end an eigenvalue equation for formula_7 and a corresponding eigenfunction formula_11for each solution of the former.\nThe propagation constant formula_7 of the guided wave is complex, in general. For a lossless case, the propagation constant might be found to take on either real or imaginary values, depending on the chosen solution of the eigenvalue equation and on the angular frequency formula_13. When formula_7 is purely real, the mode is said to be \"below cutoff\", since the amplitude of the field phasors tends to exponentially decrease with propagation; an imaginary formula_7, instead, represents modes said to be \"in propagation\" or \"above cutoff\", as the complex amplitude of the phasors does not change with formula_1.\nImpedance matching.\nIn circuit theory, the impedance is a generalization of electrical resistance in the case of alternating current, and is measured in ohms (formula_17). A waveguide in circuit theory is described by a transmission line having a length and characteristic impedance. In other words, the impedance indicates the ratio of voltage to current of the circuit component (in this case a waveguide) during propagation of the wave. This description of the waveguide was originally intended for alternating current, but is also suitable for electromagnetic and sound waves, once the wave and material properties (such as pressure, density, dielectric constant) are properly converted into electrical terms (current and impedance for example).\nImpedance matching is important when components of an electric circuit are connected (waveguide to antenna for example): The impedance ratio determines how much of the wave is transmitted forward and how much is reflected. In connecting a waveguide to an antenna a complete transmission is usually required, so an effort is made to match their impedances.\nThe reflection coefficient can be calculated using: formula_18, where formula_19 (Gamma) is the reflection coefficient (0 denotes full transmission, 1 full reflection, and 0.5 is a reflection of half the incoming voltage), formula_20 and formula_21 are the impedance of the first component (from which the wave enters) and the second component, respectively.\nAn impedance mismatch creates a reflected wave, which added to the incoming waves creates a standing wave. An impedance mismatch can be also quantified with the standing wave ratio (SWR or VSWR for voltage), which is connected to the impedance ratio and reflection coefficient by: formula_22, where formula_23 are the minimum and maximum values of the voltage absolute value, and the VSWR is the voltage standing wave ratio, which value of 1 denotes full transmission, without reflection and thus no standing wave, while very large values mean high reflection and standing wave pattern.\nElectromagnetic waveguides.\nRadio-frequency waveguides.\nWaveguides can be constructed to carry waves over a wide portion of the electromagnetic spectrum, but are especially useful in the microwave and optical frequency ranges. Depending on the frequency, they can be constructed from either conductive or dielectric materials. Waveguides are used for transferring both power and communication signals.\nOptical waveguides.\nWaveguides used at optical frequencies are typically dielectric waveguides, structures in which a dielectric material with high permittivity, and thus high index of refraction, is surrounded by a material with lower permittivity. The structure guides optical waves by total internal reflection. An example of an optical waveguide is optical fiber.\nOther types of optical waveguide are also used, including photonic-crystal fiber, which guides waves by any of several distinct mechanisms. Guides in the form of a hollow tube with a highly reflective inner surface have also been used as light pipes for illumination applications. The inner surfaces may be polished metal, or may be covered with a multilayer film that guides light by Bragg reflection (this is a special case of a photonic-crystal fiber). One can also use small prisms around the pipe which reflect light via total internal reflection \u2014such confinement is necessarily imperfect, however, since total internal reflection can never truly guide light within a \"lower\"-index core (in the prism case, some light leaks out at the prism corners).\nAcoustic waveguides.\nAn \"acoustic waveguide\" is a physical structure for guiding sound waves. Sound in an acoustic waveguide behaves like electromagnetic waves on a transmission line. Waves on a string, like the ones in a tin can telephone, are a simple example of an acoustic waveguide. Another example are pressure waves in the pipes of an organ. The term \"acoustic waveguide\" is also used to describe elastic waves guided in micro-scale devices, like those employed in piezoelectric delay lines and in stimulated Brillouin scattering.\nInfinite tubes.\nA waveguide (or tube) impose a boundary condition on the wave equation such that the wave function must be equal to zero on the boundary and that the allowed region is finite in all but one dimension. An infinitely long cylinder is an example. Mathematically, any tube with a bulge, where the width of the tube increases, admits at least one non-propagating bound state. Using the variational principles, Jeffrey Goldstone and Robert Jaffe have shown a tube of constant width with a twist admits a bound state.\nSound synthesis.\nSound synthesis uses digital delay lines as computational elements to simulate wave propagation in tubes of wind instruments and the vibrating strings of string instruments.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "41864", "revid": "1286521267", "url": "https://en.wikipedia.org/wiki?curid=41864", "title": "Wave impedance", "text": "Constant related to electromagnetic wave propagation in a medium\nThe wave impedance of an electromagnetic wave is the ratio of the transverse components of the electric and magnetic fields (the transverse components being those at right angles to the direction of propagation). For a transverse-electric-magnetic (TEM) plane wave traveling through a homogeneous medium, the wave impedance is everywhere equal to the intrinsic impedance of the medium. In particular, for a plane wave travelling through empty space, the wave impedance is equal to the impedance of free space. The symbol \"Z\" is used to represent it and it is expressed in units of ohms. The symbol \"\u03b7\" (eta) may be used instead of \"Z\" for wave impedance to avoid confusion with electrical impedance.\nDefinition.\nThe wave impedance is given by\n formula_1\nwhere formula_2 is the electric field and formula_3 is the magnetic field, in phasor representation. The impedance is, in general, a complex number.\nIn terms of the parameters of an electromagnetic wave and the medium it travels through, the wave impedance is given by\n formula_4\nwhere \"\u03bc\" is the magnetic permeability, \"\u03b5\" is the (real) electric permittivity and \"\u03c3\" is the electrical conductivity of the material the wave is travelling through (corresponding to the imaginary component of the permittivity multiplied by omega). In the equation, \"j\" is the imaginary unit, and \"\u03c9\" is the angular frequency of the wave. Just as for electrical impedance, the impedance is a function of frequency. In the case of an ideal dielectric (where the conductivity is zero), the equation reduces to the real number\n formula_5\nIn free space.\nIn free space the wave impedance of plane waves is: \n formula_6\n(where \"\u03b5\"0 is the permittivity constant in free space and \"\u03bc\"0 is the permeability constant in free space). Now, since\n formula_7 (by definition of the metre),\n formula_8.\nThe currently accepted value of formula_9 is .\nIn an unbounded dielectric.\nIn an isotropic, homogeneous dielectric with negligible magnetic properties, i.e. formula_10 and formula_11. So, the value of wave impedance in a perfect dielectric is\n formula_12,\nwhere formula_13 is the relative dielectric constant.\nIn a waveguide.\nFor any waveguide in the form of a hollow metal tube, (such as rectangular guide, circular guide, or double-ridge guide), the wave impedance of a travelling wave is dependent on the frequency formula_14, but is the same throughout the guide. For transverse electric (TE) modes of propagation the wave impedance is:\n formula_15\nwhere \"f\"\"c\" is the cut-off frequency of the mode, and for transverse magnetic (TM) modes of propagation the wave impedance is:\n formula_16\nAbove the cut-off (\"f\" &gt; \"f\"\"c\"), the impedance is real (resistive) and the wave carries energy. Below cut-off the impedance is imaginary (reactive) and the wave is evanescent. These expressions neglect the effect of resistive loss in the walls of the waveguide. For a waveguide entirely filled with a homogeneous dielectric medium, similar expressions apply, but with the wave impedance of the medium replacing \"Z\"0. The presence of the dielectric also modifies the cut-off frequency \"f\"\"c\".\nFor a waveguide or transmission line containing more than one type of dielectric medium (such as microstrip), the wave impedance will in general vary over the cross-section of the line.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41866", "revid": "842922", "url": "https://en.wikipedia.org/wiki?curid=41866", "title": "White pages", "text": ""}
{"id": "41867", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=41867", "title": "Wide Area Telephone Service", "text": "Primitive long-distance flat-rate plan\nWide Area Telephone Service (WATS) was a flat-rate long-distance service for customer dial-type telecommunications in the service areas of the North American Numbering Plan (NANP).\nThe service was between a given customer phone (also known as a \"station\") and stations within specified geographic rate areas, employing a single telephone line between the customer location and the serving central office. Each access line could be arranged for outward (OUT-WATS) or inward (IN-WATS) service, or both.\nWATS was introduced by the Bell System in 1961 as a long-distance flat-rate plan by which a business could obtain a special line with an included number of hours ('measured time' or 'full-time') of long-distance calling to a specified area. These lines were most often connected to private branch exchanges in large businesses. WATS lines were the basis for the first direct-dial toll-free 1-800-numbers (intrastate in 1966, interstate in 1967); by 1976, WATS brought AT&amp;T Corporation a billion dollars in annual revenue ($ in 2024 dollars)\nFor outbound calls, the 1984 AT&amp;T divestiture brought multiple competitors offering similar services using standard business telephone lines; the special WATS line was ultimately supplanted by other flat-rate offerings. The requirement that an inbound toll-free number terminate at a special WATS line or fixed-rate service was also rendered obsolete by the 1980s due to intelligent network capability and technological improvement in the 800-service. A toll-free number may now terminate at a T-carrier line, at any standard local telephone number or at one of multiple destinations based on time of day, call origin, cost or other factors.\nOutbound WATS.\nFor Outbound WATS, the United States was divided into geographical Bands 0 through 5. Band zero was intrastate calling and bands 1 through 5 (or 6) were interstate calls that were progressively further from the originating number. Historically, the higher band number carried a higher price per month or per minute. These lines could be used for outbound long-distance only; not local. In the U.S., interstate WATS lines could not be used for intrastate calls, and vice versa. With wider availability of inexpensive long distance using regular business lines, OutWATS service became obsolete late in the 20th century.\nInWATS.\nA form of toll-free telephone service in North America was the Zenith number, published in distant cities from where a company expected or desired frequent customer calls. Published as \"Zenith\" and a four- or five-digit number, these collect calls required operator assistance. The subscriber of the service was charged for the call.\nWith \"inward WATS\", introduced for interstate calls by the American Telephone and Telegraph Company (AT&amp;T) in 1967, subscribers were issued a toll-free telephone number in a designated toll-free area code. Unlike a standard collect call or a call to a Zenith number, 1\u2011800 normally may be dialed directly with no live operator. Callers within a designated area could call without incurring a toll charge as the recipient paid for the calls at a fixed rate.\nThe introduction of InWATS fortuitously fell around the same time as the early centralized, automated national airline and hotel reservation systems, including Sabre (American Airlines, 1963), Holidex (Holiday Inn, 1965) and Reservatron (Sheraton, 1969). Hundreds of local reservation numbers for a major chain could be replaced with one central number, backed by a national computerized reservation system.\nInWATS exchanges were assigned to Canada and other North American Numbering Plan countries, but the original InWATS in each country accepted domestic calls only. Initially 1\u2011800\u2011NN2\u2011XXXX numbers were U.S. intrastate and specific prefixes (such as 1\u2011800\u2011387 Toronto and 1\u2011800\u2011267 Ottawa) were assigned to Canada. In the 1970s, AT&amp;T's internal routing guides included separate U.S. and Canadian 1-800 exchange maps which looked much like area code maps as each geographic area code had one or more specific freephone exchange prefixes. Sheraton's 800\u2011325\u20113535, one of the notable early adopters in late 1969, was hard-wired into St. Louis area code 314; 1\u2011800\u2011HOLIDAY at that time could not be a U.S. number if the 1\u2011800\u2011465 prefix was hard-wired to Thunder Bay's area code 807. Any attempt to call a foreign 1\u2011800 gave a pre-recorded error, \"the number you have dialed is not available from your calling area.\"\nLike the OutWATS service, AT&amp;T's InWATS was divided into intrastate and interstate, with interstate calls priced into five or six \"bands\" of calling. This favored placement of US national call centers in low-population Midwestern states such as Nebraska, whose central location meant a carefully situated \"band 3\" number reaching halfway across the US in every direction could potentially reach 47 states. A San Diego call center would be less fortunate; even with \"band 6\" (the most expensive lines), its national number would be unreachable to millions as California is a populous state and intrastate calls needed a separate toll-free number.\nThe original InWATS system was supplanted by \"Advanced 800 Service\" in the 1980s. Modern systems eliminated requirements tying toll-free numbers to dedicated flat-rate inbound WATS lines. Direct inward dial, introduced in 1983, allowed one trunk to carry calls for multiple numbers. AT&amp;T's monopoly on U.S. toll-free number routing ended in 1986, encouraging flexibility in order to match rivals Sprint and MCI. By 1989, fixed \"bands\" of coverage area had been largely replaced by distance-based billing, a growing number of 1\u2011800 numbers were being terminated at standard local business or residence lines and one number could be sent to multiple locations based on call origin, least-cost routing or time of day routing. RespOrgs were established in the U.S. in 1993 and Canada in 1994 to provide toll free number portability using the Service Management System (SMS/800) database. Calls from Canada and the U.S., intrastate and interstate, could terminate at the same 1\u2011800 number, even via different carriers. Vanity numbers became easier to obtain as a toll-free exchange prefix was no longer tied to a geographic location. By the 21st century, Voice over IP placed toll-free and foreign exchange numbers into the hands of even the smallest users, to whom dedicated inbound lines under the original InWATS model would have been prohibitively expensive.\nCivil Rights Movement.\nDuring the Civil Rights Movement in the U.S., activist organizations such as SNCC used WATS as a convenient way for eyewitnesses on the ground to convey information quickly. Notes from these phone calls were compiled into \"WATS Line Reports\" and mailed to civil rights leaders, the media, the Justice Department, and others involved in the events. WATS was also how organizations communicated with local leaders across the country. A \"Bay Area Friends of SNCC\" newsletter in 1965 described WATS:\nThe WATS (Wide Area Telephone Service) line is the heart of all SNCC security and communications. For a flat monthly rate, an unlimited number of calls can be dialed directly to any place in the country \u2014 or the state \u2014 depending on what line one uses. The Jackson office has a state-wide line, the Atlanta office has the national WATS line. Both run on a 24-hour basis. A project worker can call in news of any incident, threat or major activity to the Jackson office. The WATS operator there takes down the details and relays it to Atlanta if the event is of national importance. In the case of a threat or incident involving Federal laws, Jackson will notify the FBI and the Justice Department. Atlanta uses its national WATS line to notify SNCC groups around the country.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41868", "revid": "41798688", "url": "https://en.wikipedia.org/wiki?curid=41868", "title": "Wideband modem", "text": "Type of modem\nIn telecommunications, the term wideband modem has the following meanings: "}
{"id": "41869", "revid": "96647", "url": "https://en.wikipedia.org/wiki?curid=41869", "title": "Wildcard character", "text": "Character used to substitute for any other character/s in a string\nIn software, a wildcard character is a kind of placeholder represented by a single character, such as an asterisk (), which can be interpreted as a number of literal characters or an empty string. It is often used in file searches so the full name need not be typed.\nTelecommunication.\nIn telecommunications, a wildcard is a character that may be substituted for any of a defined subset of all possible characters.\nComputing.\nIn computer (software) technology, a wildcard is a symbol used to replace or represent zero or more characters. Algorithms for matching wildcards have been developed in a number of recursive and non-recursive varieties.\nFile and directory patterns.\nWhen specifying file names (or paths) in CP/M, Atari DOS, MS-DOS, Windows, and Unix-like operating systems, the asterisk character (, also called \"star\") matches zero or more characters. For example, matches and but not . If files are named with a date stamp, wildcards can be used to match date ranges, such as codice_1 to select video recordings from , to facilitate file operations such as copying and moving.\nIn Unix-like operating systems, MS-DOS, and Atari DOS, the question mark matches exactly one character. In MS-DOS, if the question mark is placed at the end of the word, it will also match missing (zero) trailing characters; for example, the pattern will match and , but not .\nIn Unix shells and Windows PowerShell, ranges of characters enclosed in square brackets ( and ) match a single character within the set; for example, matches any single uppercase or lowercase letter. In Unix shells, a leading exclamation mark negates the set and matches only a character not within the list. In shells that interpret as a history substitution, a leading caret can be used instead.\nThe operation of matching of wildcard patterns to multiple file or path names is referred to as \"globbing\".\nDatabases.\nIn SQL, wildcard characters can be used in LIKE expressions; the percent sign matches zero or more characters, and underscore a single character. Transact-SQL also supports square brackets ( and ) to list sets and ranges of characters to match, a leading caret negates the set and matches only a character not within the list. In Microsoft Access, the asterisk sign matches zero or more characters, the question mark matches a single character, the number sign matches a single digit (0\u20139), and square brackets can be used for sets or ranges of characters to match.\nRegular expressions.\nIn regular expressions, the period (, also called \"dot\") is the wildcard pattern which matches any single character. Followed by the Kleene star operator, which is denoted as an asterisk (), we obtain , which will match zero or more arbitrary characters.\nSearch engines.\nThe wildcard operator can be used in Google Search to fetch results which have one or more word(s) inserted between phrases; e.g. Googling \"I love * so much\" will populate results such as \"I love this game so much,\" \"I love my wife so much,\" etc."}
{"id": "41870", "revid": "1241385330", "url": "https://en.wikipedia.org/wiki?curid=41870", "title": "Wink pulsing", "text": "Telephony signalling technique\nWinking is a telephony signalling technique used both in connection with DC signalling on a trunk, and with indicator lamps on a key telephone.\nIn telephone switching systems, wink pulsing is recurring pulsing in which the \"off\" condition is relatively short compared to the \"on\" condition. In wink start trunks, the exchange at the originating seizes the trunk for an outgoing call. The terminating end indicates readiness to receive the dialled telephone number by sending an off-hook (current reversal) of approximately half a second duration, or \"wink\". Upon receiving this \"go ahead\" signal, the originating end uses multi-frequency, DTMF, or dial pulse signalling to send the phone number.\nOn 1A2 key systems or similar key-operated telephone instruments, the hold position, \"i.e.,\" the hold condition, of a line is often indicated by winking the associated lamp at 120 impulses per minute. During 6% of the pulse period the lamp is off and 94% of the period the lamp is on, \"i.e.,\" 30 ms (milliseconds) off and 470 ms on."}
{"id": "41871", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41871", "title": "Wireless mobility management", "text": "Wireless mobility management in Personal Communications Service (PCS) is the assigning and controlling of wireless links for terminal network connections. Wireless mobility management provides an \"alerting\" function for call completion to a wireless terminal, monitors wireless link performance to determine when an automatic link transfer is required, and coordinates link transfers between wireless access interfaces.\nOne use of this is wireless push technology, by pushing data across wireless networks, this coordinates the link transfers and pushes data between the backend and wireless device only when an established connection is found.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;"}
{"id": "41872", "revid": "5984052", "url": "https://en.wikipedia.org/wiki?curid=41872", "title": "Work station", "text": "Work station may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41873", "revid": "27284496", "url": "https://en.wikipedia.org/wiki?curid=41873", "title": "X-dimension of recorded spot", "text": "In fax systems, the X-dimension of recorded spot is the effective recorded spot dimension measured in the direction of the recorded line. The effective recorded spot dimension\" is the largest center-to-center spacing between recorded spots, which gives minimum peak-to-peak variation of density of the recorded line. X-dimension of recorded spot implies that the facsimile equipment response to a constant density in the object (original) is a succession of discrete recorded spots."}
{"id": "41874", "revid": "643099", "url": "https://en.wikipedia.org/wiki?curid=41874", "title": "Zero-bit insertion", "text": ""}
{"id": "41875", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=41875", "title": "Zero dBm transmission level point", "text": ""}
{"id": "41876", "revid": "252195", "url": "https://en.wikipedia.org/wiki?curid=41876", "title": "Zero-dispersion slope", "text": ""}
{"id": "41877", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=41877", "title": "Zero-dispersion wavelength", "text": "In a single-mode optical fiber, the zero-dispersion wavelength is the wavelength or wavelengths at which material dispersion and waveguide dispersion cancel one another. In all silica-based optical fibers, minimum material dispersion occurs naturally at a wavelength of approximately 1300\u00a0nm. Single-mode fibers may be made of silica-based glasses containing dopants that shift the material-dispersion wavelength, and thus, the zero-dispersion wavelength, toward the minimum-loss window at approximately 1550\u00a0nm. The engineering tradeoff is a slight increase in the minimum attenuation coefficient. Such fiber is called dispersion-shifted fiber.\nAnother way to alter the dispersion is changing the core size and the refractive indices of the material of core and cladding. Because fiber optic materials are already highly optimized for low scattering and high transparency alternative ways to change the refractive index were investigated. As a straightforward solution tapered fibers and holey fibers or photonic crystal fibers (PCF) were produced. Essentially they replace the cladding by air. This improves the contrast of refractive indices by a factor of 10. Therefore, the effective index is changed, especially for longer wavelengths. This type of refractive index change versus wavelength due to different geometry is called waveguide dispersion.\nAs these narrow waveguides (~1-3\u00a0\u03bcm core diameter) are combined with ultrashort pulses at the zero-dispersion wavelength pulses are not instantly destroyed by dispersion. After reaching a certain peak power within the pulse the non-linear refractive index starts to play an important role leading to frequency generation processes like self-phase modulation (SPM), modulational instability, soliton generation and soliton fission, cross phase modulation (XPM) and others. All these processes generate new frequency components, meaning that input light with narrow bandwidth expands into a wide range of new colours, through a process called supercontinuum generation.\nThe term is also used, more loosely, in multi-mode optical fiber. There, it refers to the wavelength at which the material dispersion is minimum, \"i.e.\" \"essentially\" zero. This is more accurately called the minimum-dispersion wavelength.\nZero-dispersion slope.\nThe rate of change of dispersion with respect to wavelength at the zero-dispersion point is called the zero-dispersion slope. Doubly and quadruply clad single-mode fibers have two zero-dispersion points."}
{"id": "41878", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=41878", "title": "Zip-cord", "text": "Zip-cord is a type of electrical cable with two or more conductors held together by an insulating jacket that can be easily separated simply by pulling apart. In Australia it is known as 'figure-8' cable. The zip-cord term is also used with optical fiber cables consisting of two optical fibers joined in a similar manner. The design of zip-cord makes it easy to keep conductors that carry related electrical or optical signals together and helps avoid tangling of cables. Typical uses include lamp cord and speaker wire. Conductors may be identified by a color tracer on the insulation, or by a ridge molded into the insulation of one wire, or by a colored tracer thread inside the insulation. Zip cords are intended for use on portable equipment, and the US and Canadian electrical codes do not permit their use for permanently installed wiring of line-voltage circuits. "}
{"id": "41879", "revid": "18953656", "url": "https://en.wikipedia.org/wiki?curid=41879", "title": "Absolute pitch", "text": "Ability to identify musical notes by ear without reference\nAbsolute pitch (AP), often called perfect pitch, is the ability to identify or re-create a given pitch without the benefit of a reference tone. AP may be demonstrated using linguistic labelling (\"naming\" a note), associating mental imagery with the note, or sensorimotor responses. For example, an AP possessor can accurately reproduce a heard tone on a musical instrument without \"hunting\" for the correct pitch. However, pitch labelling is less common than pitch recall.\nAbout.\nThe frequency of AP in the general population is not known. A proportion of 1 in 10,000 is widely reported, but may not be accurate; a 2019 review indicated a prevalence of at least 4% amongst music students.\nGenerally, absolute pitch implies some or all of these abilities, achieved without a reference tone:\nAbsolute pitch is distinct from relative pitch. While the ability to name specific pitches can be used to infer intervals, relative pitch identifies an interval directly by its sound. Absolute pitch may complement relative pitch in musical listening and practice, but it may also influence its development.\nThere has been debate as to whether absolute pitch is learnable in adulthood. Adults who possess relative pitch but do not already have absolute pitch can learn \"pseudo-absolute pitch\" and become able to identify notes in a way that superficially resembles absolute pitch. Some people have been able to develop accurate pitch identification in adulthood through training.\nScientific studies.\nHistory of study and terminologies.\nScientific studies of absolute pitch commenced in the 19th century, focusing on the phenomenon of musical pitch and methods of measuring it. It would have been difficult for the notion of absolute pitch to have formed earlier because pitch references were not consistent. For example, the note known as 'A' varied in different local or national musical traditions between what is considered as G sharp and B flat before the standardisation of the late 19th century. While the term \"absolute pitch\", or \"absolute ear\", was in use by the late 19th century by both British and German researchers, its application was not universal; other terms such as \"musical ear\", \"absolute tone consciousness\", or \"positive pitch\" referred to the same ability. The skill is not exclusively musical.\nDifference in cognition, not elementary sensation.\nPhysically and functionally, the auditory system of an absolute listener evidently does not differ from that of a non-absolute listener. Rather, \"it reflects a particular ability to analyze frequency information, presumably involving high-level cortical processing.\" Absolute pitch is an act of cognition, needing memory of the frequency, a label for the frequency (such as \"B-flat\"), and exposure to the range of sound encompassed by that categorical label. Absolute pitch may be directly analogous to recognizing colors, phonemes (speech sounds), or other categorical perception of sensory stimuli. For example, most people have learned to recognize and name the color \"blue\" by the range of frequencies of the electromagnetic radiation that are perceived as light; those who have been exposed to musical notes together with their names early in life may be more likely to identify the note C. Although it was once thought that it \"might be nothing more than a general human capacity whose expression is strongly biased by the level and type of exposure to music that people experience in a given culture\", absolute pitch may be influenced by genetic variation, possibly an autosomal dominant genetic trait.\nInfluence by music experience.\nEvidence suggests that absolute pitch sense is influenced by cultural exposure to music, especially in the familiarization of the equal-tempered C-major scale. Most of the absolute listeners that were tested in this respect identified the C-major tones more reliably and, except for B, more quickly than the five \"black key\" tones, which corresponds to the higher prevalence of these tones in ordinary musical experiences. One study of Dutch non-musicians also demonstrated a bias toward using C-major tones in ordinary speech, especially on syllables related to emphasis.\nLinguistics.\nAbsolute pitch is more common among speakers of tonal languages, such as most dialects of Chinese or Vietnamese, which depend on pitch variation to distinguish words that otherwise sound the same\u2014e.g., Mandarin with four possible tonal variations, Cantonese with nine, Southern Min with seven or eight (depending on dialect), and Vietnamese with six. Speakers of Sino-Tibetan languages have been reported to speak a word in the same absolute pitch (within a quarter-tone) on different days; it has therefore been suggested that absolute pitch may be acquired by infants when they learn to speak a tonal language (and possibly also by infants when they learn to speak a pitch-accent language). However, the brains of tonal-language speakers do not naturally process musical sound as language; such speakers may be more likely to acquire absolute pitch for musical tones when they later receive musical training. Many native speakers of a tone language, even those with little musical training, are observed to sing a given song with consistent pitch. Among music students of East Asian ethnic heritage, those who speak a tone language fluently have a higher prevalence of absolute pitch than those who do not speak a tone language.\nAfrican level-tone languages\u2014such as Yoruba, with three pitch levels, and Mambila, with four\u2014may be better suited to study the role of absolute pitch in speech than the pitch and contour tone languages of East Asia.\nSpeakers of European languages make subconscious use of an absolute pitch memory when speaking.\nPerception.\nAbsolute pitch is the ability to perceive pitch class and to mentally categorize sounds according to perceived pitch class. A pitch class is the set of all pitches that are a whole number of octaves apart. While the boundaries of musical pitch categories vary among human cultures, the recognition of octave relationships is a natural characteristic of the mammalian auditory system. Accordingly, absolute pitch is not the ability to estimate a pitch value from the dimension of pitch-evoking frequency (30\u20135000\u00a0Hz), but to identify a pitch class category within the dimension of pitch class (e.g., C-C\u266f-D\u00a0... B-C).\nAn absolute listener's sense of hearing is typically no keener than that of a non-absolute (\"normal\") listener. Absolute pitch does not depend upon a refined ability to perceive and discriminate gradations of sound frequencies, but upon detecting and categorizing a subjective perceptual quality typically referred to as \"chroma\". The two tasks\u2014 of identification (recognizing and naming a pitch) and discrimination (detecting changes or differences in rate of vibration)\u2014 are accomplished with different brain mechanisms.\nSpecial populations.\nAbsolute pitch is considerably more common among those whose early childhood was spent in East Asia. This might seem to be a genetic difference; however, people of East Asian ancestry who are reared in North America are significantly less likely to develop absolute pitch than those raised in East Asia, so the difference is more probably explained by experience. The language that is spoken may be an important factor; many East Asians speak tonal languages such as Mandarin, Cantonese, and Thai, while others (such as those in Japan and certain provinces of Korea) speak pitch-accent languages, and the prevalence of absolute pitch may be partly explained by exposure to pitches together with meaningful musical labels very early in life.\nAbsolute pitch ability has higher prevalence among those with Williams syndrome and those who are autistic, with claims estimating that up to 30% of autistic people have absolute pitch. A non-vocal piano-matching method resulted in a correlation of 97% between autism and absolute pitch, with a 53% correlation in non-autistic observers. However, the converse is not indicated by research which found no difference between those with absolute pitch and those without on measures of social and communication skills, which are core deficits in autistic spectrum disorders. Additionally, the absolute pitch group's autism-spectrum quotient was \"way below clinical thresholds\".\nNature vs. nurture.\nAbsolute pitch might be achievable by any human being during a critical period of auditory development, after which period cognitive strategies favor global and relational processing. Proponents of the critical-period theory agree that the presence of absolute pitch ability is dependent on learning, but there is disagreement about whether training causes absolute skills to occur or lack of training causes absolute perception to be overwhelmed and obliterated by relative perception of musical intervals.\nOne or more genetic loci could affect absolute pitch ability, a predisposition for learning the ability or signal the likelihood of its spontaneous occurrence.\nResearchers have been trying to teach absolute pitch ability in laboratory settings for more than a century, and various commercial absolute-pitch training courses have been offered to the public since the early 1900s. In 2013, experimenters reported that adult men who took the antiseizure drug valproate (VPA) \"learned to identify pitch significantly better than those taking placebo\u2014evidence that VPA facilitated critical-period learning in the adult human brain\". However, no adult has ever been documented to have acquired absolute listening ability, because all adults who have been formally tested after AP training have failed to demonstrate \"an unqualified level of accuracy... comparable to that of AP possessors\".\nPitch memory related to musical context.\nWhile very few people have the ability to name a pitch with no external reference, pitch memory can be activated by repeated exposure. People who are not skilled singers will often sing popular songs in the correct key, and can usually recognize when TV themes have been shifted into the wrong key. Members of the Venda culture in South Africa also sing familiar children's songs in the key in which the songs were learned.\nThis phenomenon is apparently unrelated to musical training. The skill may be associated more closely with vocal production. Violin students learning the Suzuki method are required to memorize each composition in a fixed key and play it from memory on their instrument, but they are not required to sing. When tested, these students did not succeed in singing the memorized Suzuki songs in the original, fixed key.\nPossible problems.\nMusicians with absolute perception may experience difficulties that do not exist for other musicians. Because absolute listeners are capable of recognizing that a musical composition has been transposed from its original key, or that a pitch is being produced at a nonstandard frequency (either sharp or flat), a musician with absolute pitch may become confused upon perceiving tones believed to be \"wrong\" or hearing a piece of music \"in the wrong key\". The relative pitch of the notes may be in tune to each other, but out of tune to the standard pitch or pitches the musician is familiar with or perceives as correct. This can especially apply to Baroque music, as many Baroque orchestras tune to A\u00a0= 415\u00a0Hz as opposed to 440\u00a0Hz (i.e., roughly one standard semitone lower than the ISO standard for concert A), while other recordings of Baroque pieces (especially those of French Baroque music) are performed at 392\u00a0Hz. Historically, tuning forks for concert A used on keyboard instruments (which ensembles tune to when present), have varied widely in frequency, often between 415\u00a0Hz to 456.7\u00a0Hz.\nVariances in the sizes of intervals for different keys and the method of tuning instruments also can affect musicians in their perception of correct pitch, especially with music synthesized digitally using alternative tunings (e.g., unequal well temperaments and alternative meantone tunings such as 19-tone equal temperament and 31-tone equal temperament) as opposed to 12-tone equal temperament. An absolute listener may also use absolute strategies for tasks that are more efficiently accomplished with relative strategies, such as transposition or producing harmony that is microtonal or whose frequencies do not match standard 12-tone equal temperament. It is also possible for some musicians to have displaced absolute pitch, where all notes are slightly flat or slightly sharp of their respective pitch as defined by a given convention. This may arise from learning the pitch names from an instrument that was tuned to a concert pitch convention other than the one in use (e.g., A\u00a0= 435\u00a0Hz, the Paris Opera convention of the late 19th and early 20th centuries, as opposed to the modern Euro-American convention for concert A\u00a0= 440\u00a0Hz). Concert pitches have shifted higher for a brighter sound. When playing in groups with other musicians, this may lead to playing in a tonality that is slightly different from that of the rest of the group, such as when soloists tune slightly sharp of the rest of the ensemble to stand out or to compensate for loosening strings during longer performances.\nSynesthesia.\nAbsolute pitch shows a genetic overlap with music-related and non-music-related synesthesia/ideasthesia. They may associate certain notes or keys with different colors, enabling them to tell what any note or key is. In this study, about 20% of people with absolute pitch are also synesthetes.\nCorrelations.\nThere is evidence of a higher rate of absolute pitch in the autistic population. Many studies have examined pitch abilities in autism, but not rigidly perfect pitch, which makes them controversial. It is unclear just how many autistic people have perfect pitch because of this. In a 2009 study, researchers studied 72 autistic teenagers and found that 20 percent of the teenagers had a significant ability to detect pitches. Autistic children are especially sensitive to changes in pitch.\nCorrelation with musical talent.\nAbsolute pitch is not a prerequisite for skilled musical performance or composition. However, there is evidence that musicians with absolute pitch tend to perform better on musical transcription tasks (controlling for age of onset and amount of musical training) compared with those without absolute pitch. It was previously argued that musicians with absolute pitch perform worse than those without absolute pitch on recognition of musical intervals; however experiments on which this conclusion was based contained an artifact and when this artifact was removed absolute pitch possessors were found to perform better than non-possessors on recognition of musical intervals.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41880", "revid": "30395827", "url": "https://en.wikipedia.org/wiki?curid=41880", "title": "Perfect pitch", "text": ""}
{"id": "41881", "revid": "48461984", "url": "https://en.wikipedia.org/wiki?curid=41881", "title": "All About Eve", "text": "1950 film by Joseph L. Mankiewicz\nAll About Eve is a 1950 American drama film written and directed by Joseph L. Mankiewicz, and produced by Darryl F. Zanuck. It is based on the 1946 short story (and subsequent 1949 radio drama) \"The Wisdom of Eve\" by Mary Orr, although Orr does not receive a screen credit.\nThe film stars Bette Davis as Margo Channing, a highly regarded but aging Broadway star, and Anne Baxter as Eve Harrington, an ambitious young fan who maneuvers herself into Channing's life, ultimately threatening Channing's career and her personal relationships. The film co-stars George Sanders, Celeste Holm, Gary Merrill, and Hugh Marlowe, and features Thelma Ritter, Marilyn Monroe in one of her earliest roles, Gregory Ratoff, Barbara Bates and Walter Hampden.\n\"All About Eve\" held its world premiere in New York City on October 13, 1950. Highly praised by critics at the time of its release, it received a record 14 nominations at the 23rd Academy Awards, becoming the only film in Oscar history to receive four female acting nominations (Davis and Baxter as Best Actress, Holm and Ritter as Best Supporting Actress). It went on to win six awards, including Best Picture, as well as Best Director and Best Adapted Screenplay, Mankiewicz's second consecutive wins in both categories.\nWidely considered as among the greatest films of all time, in 1990, \"All About Eve\" became one of 25 films selected that year for preservation in the United States Library of Congress's National Film Registry, deemed \"culturally, historically, or aesthetically significant\". The film was ranked No. 16 on AFI's 1998 list of the 100 best American films.\nPlot.\nAt the Sarah Siddons Award ceremony honoring rising actress Eve Harrington, narration from acerbic theatre critic Addison DeWitt introduces the attendees and hints that there is more to Eve's story.\nThe narration switches to Karen Richards, wife of playwright Lloyd Richards. She recalls the previous October, when she introduced Eve to aging Broadway star Margo Channing, who was starring in a play written by Lloyd. Eve tells Karen, Lloyd, and Margo's maid Birdie that she followed Margo's last theatrical tour to New York City after seeing her perform in San Francisco. She tells of her impoverished childhood and losing her husband in the South Pacific during World War II, and, moved by Eve's story, Margo takes her into her home as her assistant. Eve quickly manipulates her way into Margo's life as both secretary and adoring fan.\nMargo is also concerned about her romantic relationship with Bill Sampson, eight years her junior, who is directing a film in California. Without telling Margo, Eve arranges a midnight long-distance phone call from Margo to Bill on his birthday. Eve hopes the unexpected late call will show Bill that Margo forgot his birthday and also sends her own greeting. Margo realizes that Eve set her up and asks producer Max Fabian to hire Eve at his office to get her away from Bill; instead, Eve has Karen convince Fabian to make Eve Margo's understudy without Margo's knowledge.\nAs Margo's irritation grows, Karen sympathizes with Eve, believing that Margo is overdramatizing her resentment towards her. Hoping to humble Margo, Karen conspires for her to miss a performance so Eve can perform in her place. Eve secretly invites the city's theater critics, including Addison, to attend the performance. Eve's performance is a triumph. Later that night, Eve attempts to seduce Bill, but he rejects her.\nAddison interviews Eve for a column, which harshly criticizes Margo for resisting younger talent. Eve apologizes to Lloyd for the things said in the article, and subtly convinces him to consider her instead of Margo for the lead role, Cora, in his next play.\nMargo and Bill announce their engagement while dining out with Lloyd and Karen. Eve, who had been dining at the same restaurant with Addison, summons Karen to the ladies' room. After first appearing regretful, she delivers an ultimatum: Karen must recommend her to Lloyd to play Cora or she will have Addison expose Karen's part in Margo's missed performance in his newspaper column. When Karen returns to the table\u2014to her relief\u2014Margo surprisingly announces that she does not wish to play Cora. Margo admits that she is too old for the ing\u00e9nue role, and her impending marriage means that the theater no longer has to be her entire life.\nEve is cast as Cora, despite the objections of Bill, who is directing the play. Just before the out-of-town opening, Eve tells Addison that she had seduced and plans to marry Lloyd so that he can write plays for her to star in.\nAngered by Eve's audacity, Addison reveals he knows her backstory is false; her real name is Gertrude Slescynski, she never went to San Francisco, she was never married, and she was paid to leave town over an affair with her married boss. He blackmails Eve, forbidding her from trying to marry Lloyd and saying she now \"belongs\" to him.\nThe story catches up to the opening scene; months later, Eve is a Broadway star headed for Hollywood. While accepting the Sarah Siddons Award, Eve thanks Margo, Bill, Lloyd, and Karen, who react with indifference. Eve skips the after-party and returns home, where she encounters Phoebe, who claims to be a teenage fan who slipped into her apartment and fell asleep. Eve is angry but softens after Phoebe professes her adoration and ingratiates herself. Eve is considering inviting her to stay over rather than take the long subway ride back home when the doorbell buzzes. Phoebe offers to answer the door and recognizes Addison, who has brought Eve's award back from the taxi cab where she left it. Addison quickly realizes that Phoebe isn't her real name and that she, like Eve, has her sights on stardom. Phoebe lies to Eve that a taxi driver had dropped off the award. When she is alone, Phoebe puts on Eve's elegant cloak and poses in front of a floor-length mirror, holding the award and bowing.\nProduction.\nDevelopment.\n\"All About Eve\" originated from the short story \"The Wisdom of Eve\" written by Mary Orr, published in \"Cosmopolitan\" magazine in May 1946. The story was a highly fictionalized account based on an anecdote, as related by Austrian actress Elisabeth Bergner. She and her husband Paul Czinner had invited Orr and her husband Reginald Denham, who had directed Bergner in the play \"The Two Mrs. Carrolls\" during the 1943\u201344 Broadway season, for dinner in Woodstock, Vermont. There, Bergner told Orr about a young woman who stood outside at the Booth Theatre for several days. She invited the woman to her dressing room for a visit, where the woman claimed she was English and had fled to the United States during World War II. She gave her a job as her secretary to her husband, whereby the young woman later became Bergner's understudy. From there, the woman tried to \"take over\" Bergner's life.\nIn Orr's story, the young woman is named Eve Harrington, who wins the sympathy of Margola Cranston, a happily married Broadway actress. Eve becomes Margola's understudy, whereby she succeeds in taking the lead role in a new play written by Lloyd Richards, Margola's favorite playwright. Though Eve fails to win over Margola's husband, she eventually steals Lloyd away from his wife, Karen, another actress and Margola's best friend. Bergner later confirmed the basis of the story in her autobiography \"Bewundert viel und viel gescholten\" (translated as \"Greatly Admired and Greatly Scolded\"), devoting five pages to her anecdote.\nOn January 24, 1949, \"The Wisdom of Eve\" was adapted into a radio episode broadcast on NBC's \"Radio City Playhouse\". Orr wrote the radio play, whereby she renamed the character Margola into \"Margo\". Claudia Morgan was cast as Margo while Marilyn Erskine played Eve and Mary Orr as Karen Richards. A few days later, Twentieth Century-Fox optioned the film rights to Orr's story for $5,000 (). The story caught the attention of James Fisher, then the head of Twentieth Century-Fox's story department. He mimeographed the story to several contracted producers, writers, and directors. On April 29, Joseph L. Mankiewicz sent a memo to Darryl F. Zanuck, the president of Twentieth Century-Fox, suggesting they exercise their option on Orr's story. He stated the story \"fits in with an original idea [of mine] and can be combined. Superb starring role for Susan Hayward.\"\nAs he was filming \"No Way Out\" (1950), Mankiewicz wrote a 82-paged film treatment titled \"Best Performance\" during the summer and early fall of 1949. By December 1949, he spent several nights over the course of six weeks alone at the San Ysidro Ranch, near Santa Barbara, California, expanding his treatment into a first draft. Mankiewicz changed Margo's surname from Cranston to Channing, but Mankiewicz retained several of Orr's characters\u2014Eve Harrington and Lloyd and Karen Richards. He also removed Margo's husband found in the original story and replaced him with a new love interest, Bill Sampson. Mankiewicz also created the characters: Addison DeWitt, Birdie Coonan, Max Fabian and Phoebe.\nBy January 1950, Zanuck received Mankiewicz's draft, in which he provided numerous suggestions for improving the screenplay. As he made suggestive notes, Zanuck underlined a phrase in Addison DeWitt's voice-over narration: \"Eve...but more of Eve, later. All about Eve, in fact.\" Elsewhere, he suggested removing a potential foreshadowing by diluting Birdie Coonan's mistrust of Eve so the audience would not recognize Eve as a villainess until much later in the story. After inserting several of Zanuck's suggestions, Mankiewicz delivered another revised draft\u2014dubbed the \"temporary draft\"\u2014on March 1.\nOn March 7, Zanuck wrote in a memo to Mankiewicz: \"Without any question of a doubt you have done a remarkable job. The holes that were present in certain sections of the original treatment have disappeared.\" Nevertheless, Zanuck sent nine pages of notes, detailing recommended cuts or revisions: \"I have tried to sincerely point out the spots that appeared dull or overdrawn. I have not let the length of the script influence me. I have tried to cut it as I am sure I would cut if I were in the projection room.\" Mankiewicz's draft, which had run 223 pages, was then truncated to 180. According to Fox's records, Mankiewicz's writing services on the project were terminated on March 24 and by April, he started his official assignment as director.\n\"All About Eve\" was the first film to have its screenplay published in hardcover format. Published by Random House in 1951, Mankiewicz wrote the following dedication inside the publication: \"To Rosa\u2014the critic on my hearth\" (a pun of \"cricket on the hearth\".)\nCasting.\nSeveral actresses were considered for the role of Margo Channing. Mankiewicz's original choice was Susan Hayward, but at 32 years old, she was deemed too young. As the script was being written, Zanuck was favorable to casting Claudette Colbert or Barbara Stanwyck. By February 1950, the role went to Claudette Colbert but while filming \"Three Came Home\" (1950), she was hospitalized indefinitely for an injured back and had to withdraw. To replace her, Mankiewicz suggested Gertrude Lawrence. However, Lawrence's attorney Fanny Holtzmann insisted the screenplay be changed so that Lawrence did not smoke or drink in the film, and would sing a torch song (instead of \"Liebestr\u00e4ume\" by Franz Liszt) about Bill in the party scene. Mankiewicz declined her alterations.\nMankiewicz and Zanuck briefly considered Marlene Dietrich, but Mankiewicz felt her German dialect would be incompatible with the dialogue. In 1972, Mankiewicz stated: \"I was, and am, a great admirer of Marlene. But from what I knew of her work and equipment as an actress, I simply could not visualize\u2014or hear\u2014her as a possible Margo.\" Zanuck contacted Ingrid Bergman to replace Colbert, but Bergman refused to leave Italy for the production.\nMeanwhile, Bette Davis, who had ended her decades-long association with Warner Bros., was filming \"Payment on Demand\" (1951) at the time. She had received a phone call from Zanuck, but was convinced it was a prank. The two had not been on speaking terms since Davis resigned from the Academy. Zanuck sent over the script, suggesting she read it and should she like the role of Margo Channing, she was to be ready to film within ten days. In her 1962 autobiography \"The Lonely Life\", Davis recalled: \"When I finished reading \"All About Eve\", I was on cloud nine. \"Any\" inconvenience was worth it.\"\nJeanne Crain was Zanuck's first choice for Eve Harrington. Mankiewicz had worked with Crain on \"A Letter to Three Wives\" (1949) but felt her performance was unsatisfactory. He promptly told Zanuck he felt Crain lacked the \"bitch virtuosity\" required by the part. Mankiewicz suggested Anne Baxter, who was also under contract to Fox, as an alternative, to which Zanuck approved. By then, Crain had become pregnant, which took her out of consideration.\nAt least a dozen actress, including Sheree North, had tested for the role of Miss Casswell. Marilyn Monroe had been Mankiewicz's first choice for the part after her agent Johnny Hyde had brought her in to audition. Decades later, Mankiewicz reflected there \"was a breathlessness and sort-of glued on innocence about her that I found appealing.\" During filming, Monroe appeared in only two scenes. On her first day of shooting for the party scene, with most of the cast present, Monroe arrived an hour late. According to her co-star Gary Merrill, there were 25 takes for the scene with Miss Caldwell and Addison DeWitt in the theater lobby.\nMankiewicz wrote the character of Birdie Coonan for Thelma Ritter, having working with her on \"A Letter to Three Wives\". Jos\u00e9 Ferrer was Zanuck's first choice for Addison DeWitt, but he was replaced by George Sanders. Barbara Bates won the part of the minor character Phoebe.\nReception.\nBox office.\nBy January 1951, \"All About Eve\" earned $3.1\u00a0million in box office rentals in the United States and Canada during its release, more than double its original budget of $1.4\u00a0million. The film had a cumulative gross of $8.4\u00a0million.\nCritical response.\n\"All About Eve\" received widespread critical acclaim upon its release on October 13, 1950, at a New York City premiere. The film's competitor, \"Sunset Boulevard,\" released the same year, drew similar praise, and the two were often favorably compared. Bosley Crowther of \"The New York Times\" loved the picture, stating that \"a fine Darryl Zanuck production, excellent music and an air of ultra-class complete this superior satire.\" Abel Green of \"Variety\" called it \"a literate, adult film\" with \"exceedingly well-cast performances wherein Miss Davis does not spare herself, makeup wise, in the aging star assignment. Miss Baxter gives the proper shading to her cool and calculating approach in the process of ingratiation and ultimate opportunities; and the other principals mouth dialog which is real and convincing.\"\nRichard L. Coe of \"The Washington Post\" called \"All About Eve\" \"the wittiest comedy of the year\" and stated Davis gives \"the finest role of her honorable career.\" \"Harrison's Reports\" called it \"a fascinating, continually absorbing story about Broadway theatrical people, given a mature treatment and penetrated with realistic dialogue and flashes of slick, sardonic humor.\" John McCarten of \"The New Yorker\" called it \"a thoroughly entertaining movie.\"\nIn a 2000 review, Roger Ebert of the \"Chicago Sun Times\" praised the film, saying of Bette Davis that \"veteran actress Margo Channing in \"All About Eve\" was her greatest role.\"\n\"All About Eve\" holds an approval rating of 99% based on 110 reviews. The site's critics consensus reads: \"Smart, sophisticated, and devastatingly funny, \"All About Eve\" is a Hollywood classic that only improves with age.\" Metacritic assigned a weighted average score of 98 out of 100, based on 15 critics, indicating \"universal acclaim\".\nThematic content.\nCritics and academics have delineated various themes in the film. Rebecca Flint Marx, in her \"Allmovie\" review, notes the antagonism that existed between Broadway and Hollywood at the time, stating that the \"script summoned into existence a whole array of painfully recognizable theatre types, from the aging, egomaniacal grand dame to the outwardly docile, inwardly scheming ingenue to the powerful critic who reeks of malignant charm.\" Abel Green, writing in \"Variety\" said, \"The snide references to picture people, the plug for San Francisco (\"an oasis of civilization in the California desert\") and the like are purposeful and manifest an intelligent reflex from a group of hyper-talented people towards the picture business.\"\nRoger Ebert, in his review in \"The Great Movies\", says Eve Harrington is \"a universal type\", and focuses on the aging actress plot line, comparing the film to \"Sunset Boulevard.\" Similarly, Marc Lee's 2006 review of the film for \"The Daily Telegraph\" describes a subtext \"into the darker corners of show business, exposing its inherent ageism, especially when it comes to female stars.\" Kathleen Woodward's 1999 book, \"Figuring Age: Women, Bodies, Generations (Theories of Contemporary Culture)\", also discusses themes that appeared in many of the \"aging actress\" films of the 1950s and 1960s, including \"All About Eve.\" She reasons that Margo has three options: \"To continue to work, she can perform the role of a young woman, one she no longer seems that interested in. She can take up the position of the angry bitch, the drama queen who holds court (the deliberate camp that Susan Sontag finds in this film). Or she can accept her culture's gendered discourse of aging which figures her as in her moment of fading. Margo ultimately chooses the latter option, accepting her position as one of loss.\"\n\"All About Eve\" has long been a favored film among gay audiences, likely due to its campy overtones (in part due to the casting of Davis) and its general sophistication. Davis, who long had a strong gay fan base, expressed support for gay men in her 1972 interview with \"The Advocate\".\nAccolades.\nLater recognition and rankings.\nIn 1990, \"All About Eve\" was selected for preservation in the United States National Film Registry by the Library of Congress as being \"culturally, historically, or aesthetically significant.\" The Academy Film Archive preserved \"All About Eve\" in 2000. The film received in 1997 a placement on the Producers Guild of America Hall of Fame. The film has been selected by the American Film Institute for many of their 100 Years lists.\nWhen AFI named Bette Davis #2 on its list of the greatest female American screen legends, \"All About Eve\" was the film selected to highlight Davis' legendary career. The Writers Guild of America has ranked the film's screenplay as the fifth greatest ever written.\nSarah Siddons Award.\nThe film opens with the image of a fictitious award trophy, described by DeWitt as the \"highest honor our theater knows: the Sarah Siddons Award for Distinguished Achievement.\" The statuette is modeled after the famous painting of Siddons costumed as the tragic Muse by Joshua Reynolds, a copy of which hangs in the entrance of Margo's apartment and often visible during the party scene. In 1952, a small group of distinguished Chicago theater-goers began to give an award with that name, which was sculpted to look like the one used in the film. It has been given annually, with past honorees including Bette Davis and Celeste Holm.\nHome media.\n\"All About Eve\" was released on VHS in 1979, LaserDisc in 1996 and DVD in 1999. A restored Fox Studio Classics edition was released on DVD in 2003 and on Blu-ray on February 1, 2011, with an up-mixed 5.1 DTS-HD Master Audio track. It was reissued on Blu-ray by The Criterion Collection on November 25, 2019, which uses film's original mono audio.\nAdaptations.\nThe first radio adaptation was a one-hour broadcast on \"Lux Radio Theatre\" on CBS Radio on October 1, 1951, with Bette Davis, Gary Merrill and Anne Baxter reprising their original roles. \"Lux Radio Theatre\" did a follow-up adaptation on November 23, 1954, this time on NBC radio with Ann Blyth and Claire Trevor playing the lead roles, with Trevor replacing Ida Lupino when she became ill and was unable to attend the broadcast.\nA radio version of \"All About Eve\" starring Tallulah Bankhead as Margo Channing was presented on NBC's \"The Big Show\" by the Theatre Guild of the Air on November 16, 1952. Bankhead and many contemporary critics felt that the characterization of Margo Channing was patterned on her, a long-rumored charge denied by both Mankiewicz and Davis, but attested by costume designer Edith Head. Additionally, Bankhead's rivalry with her understudy (Lizabeth Scott) during the production of \"The Skin of Our Teeth\" is cited as an alternative hypothesis for the origin of Mary Orr's \"The Wisdom of Eve,\" the original short story that formed the basis for the film. Bette Davis played three roles on film that Tallulah Bankhead had originated\u00a0\u2013 \"Dark Victory\", \"Jezebel\" and \"The Little Foxes\", much to Bankhead's chagrin. Bankhead and Davis were considered to be somewhat similar in style. Several decades later Davis called Channing \"the essence of a Tallulah Bankhead kind of actress\" in an interview with Barbara Walters. The production is notable in that Mary Orr, of \"The Wisdom of Eve,\" played the role of Karen Richards. The cast also featured Alan Hewitt as Addison DeWitt (who narrated), Beatrice Pearson as Eve Harrington, Don Briggs as Lloyd Richards, Kevin McCarthy as Bill Sampson, Florence Robinson as Birdie Coonan, and Stefan Schnabel as Max Fabian.\nIn 1970, \"All About Eve\" was the inspiration for the stage musical \"Applause,\" with book by Betty Comden and Adolph Green, lyrics by Lee Adams, and music by Charles Strouse. The original production starred Lauren Bacall as Margo Channing, and it won the Tony Award for Best Musical that season. It ran for four previews and 896 performances at the Palace Theatre on Broadway. After Bacall left the production, she was replaced by Anne Baxter in the role of Margo Channing.\nIn 2019, a stage adaptation of \"All About Eve\" premiered at the No\u00ebl Coward Theatre in London, directed by Ivo van Hove and starring Gillian Anderson as Margo Channing, Julian Ovenden as Bill, and Lily James as Eve Harrington.\nReferences.\nNotes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\nStreaming audio"}
{"id": "41882", "revid": "43618068", "url": "https://en.wikipedia.org/wiki?curid=41882", "title": "MIL-STD-188", "text": "Series of U.S. military standards relating to telecommunications\nMIL-STD-188 is a series of U.S. military standards relating to telecommunications.\nPurpose.\nFaced with \"past technical deficiencies in telecommunications systems and equipment and software\u2026that were traced to basic inadequacies in the application of telecommunication standards and to the lack of a well defined\u2026program for their review, control and implementation\", the U.S. Department of Defense looked to develop a series of standards that would alleviate the problem.\nBy 1988, the U.S. Department of Defense (DoD) issued Instruction 4630.8 (reissued in 1992, 2002, 2004) stating its policy that \"all forces for joint and combined operations be supported through compatible, interoperable, and integrated Command, Control, Communications, and Intelligence systems. \u2026[and that all such] systems developed for use by U.S. forces are considered to be for joint use.\" To achieve this the director of the Defense Information Systems Agency (DISA) is charged with \"developing information technology standards to achieve interoperability and compatibility\u2026[and ensure that all] systems and equipment shall conform to technical and procedural standards for interface, interoperability, and compatibility\".\nThe MIL-STD-188 standards were created to \"address telecommunication design parameters based on proven technologies.\" To ensure interoperability, DISA made these standards mandatory for use in all new DoD systems and equipment, or major upgrades.\nThe mandatory use of these standards will aid significantly in achieving standardization and result in improvements in availability, maintainability, reliability, and supportability. This, in turn, will enhance lifecycle configuration management and logistic support with subsequent reductions in life cycle costs.\nEvolution.\nWhen first developed, Military Standard 188 covered technical standards for tactical and long-haul communications, but as it was revised (MIL-STD-188A, MIL-STD-188B) it became a document applicable to tactical communications only (MIL-STD-188C 24 Nov 1969). The Defense Information Systems Agency published circulars which announced both standards and engineering criteria relating to the long-haul Defense Communications System and to the technical support of the Worldwide Military Command and Control System. In line with a decision by the Joint Chiefs of Staff, these standards are published in the MIL-STD-188 series of documents. This series is subdivided into \"a MIL-STD-188-100 series covering common standards for tactical and long-haul communications, a MIL-STD-188-200 series covering standards for tactical communications only, and a MIL-STD-188-300 series covering standards for long-haul communications only.\"\nThe MIL-STD-188 series standards are encompassed by the DoD's Joint Technical Architecture.\nDeviations and waivers.\nFor any manufacturer seeking to deviate from the MIL\u2013STD-188 series standards (prior to the manufacture of an item) they must request to do so with the Joint Steering Committee (JSC) which is constituted under the Defense Communications Agency. For any DoD Agency to get a waiver to receive an item that deviates from the standards they also must apply to the JSC.\nRelation to other systems of standards.\nAccording to DoD documents, \"The MIL-STD-188 series may be based on, or make reference to, Joint Technical Architecture, American National Standards Institute (ANSI) standards, International Telecommunication Union - Telecommunication Standardization Sector (ITU-T) recommendations, North Atlantic Treaty Organization (NATO) Standardization Agreements (STANAG), and other standards wherever applicable.\"\nCurrent development emphasis.\nCurrently the DoD is placing its emphasis \"on the development of common standards for tactical and long-haul communications (the MIL-STD-188-100 series).\"\nDocuments.\nNote: The following list of documents are those that are presently active. Documents with three digit numbers followed by a letter of the alphabet indicate that they are revisions of an older version of that document.\nMIL-STD-188-100 series.\nAccording to the DoD the MIL-STD-188-100 series contains \"technical standards and design objectives which are common to both the long haul and tactical communications systems.\"\nThe current articles in this series include:\nMIL-STD-188-200 series.\nAccording to the DoD the MIL-STD-188-200 series \"contains current tactical communications, technical standards and design objectives\u2026[this series includes] appropriate unclassified design objectives and tactical communications systems technical standards\u2026[and] Appropriate communications-electronics systems standards and design objectives developed under joint projects\u2026[which are] integrated in the tactical communications standards.\"\nThe current articles in this segment include:\nMIL-STD-188-300 series.\nAccording to the DoD the MIL-STD-188\u2013300 Series contains \"communications system standards and design objectives applicable to the field of long haul and point-to\u2013point communications in support of the Defense Communications System (DCS) and the National Military Command System (NMCS), and also to provide the necessary interface with non-DCS equipment.\"\nThe current articles in this series include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41885", "revid": "46337890", "url": "https://en.wikipedia.org/wiki?curid=41885", "title": "Weser", "text": "River in Germany\nThe Weser () is the second longest river in Germany. Weser flows from the Thuringian Forest to the North Sea, where it flows into the sea near Bremerhaven.\nThe Weser begins at Hannoversch M\u00fcnden through the confluence of the Werra and Fulda. It passes through the Hanseatic city of Bremen. Its mouth is further north against the ports of Bremerhaven and Nordenham. The latter is on the Butjadingen Peninsula. It then merges into the North Sea via two highly saline, estuarine mouths.\nIt connects to the canal network running east\u2013west across the North German Plain.\nThe river, when combined with the Werra (a dialectal form of \"Weser\"), is long and thus, the longest river entirely situated within Germany (the Main, however, is the longest if the Weser-Werra are considered separate). The Weser itself is long. The Werra rises in Thuringia, the German state south of the main projection (tongue) of Lower Saxony.\nEtymology.\n\"Weser\" and \"Werra\" are the same words in different dialects. The difference reflects the old linguistic border between Central and Low German, passing through Hannoversch M\u00fcnden.\nThe name likely derives from the Old Germanic \"flow, ooze\". It is cognate with the Wear in England and Vistula (Polish Wis\u0142a, German Weichsel) in Poland, all of which are derived from the Proto-Indo-European root \"to flow\", which also gives rise to Old English/Old Frisian \"mud, ooze\", Old Norse \"slime, stagnant pool\", Dutch \"haze; soggy land\" (see Waasland), Old Saxon \"wet ground, mire\", Old High German \"rain\", and French \"mud, sludge\".\nCourse.\nThe Weser starts at the confluence of the Fulda and the Werra. It then runs down to the Porta Westfalica between two high hill ranges, the \u2063\u2063Wiehengebirge\u2063\u2063 in the west and the Weserbergland in the east.\nBetween Minden and the North Sea, humans have largely canalised the river up to a limit of 1,200-ton ships. Eight hydroelectric dams stand at the ends of adjacent weir weirstreams that make up the river. The navigation is linked west to the Dortmund\u2013Ems Canal via the Coastal Canal. It is linked east at Bremerhaven to the Elbe.\nA large reservoir, the Edersee, on the Eder, the main tributary of the Fulda, is used to allow enough water depth for shipping year-round. The dam, built in 1914, was bombed and severely damaged by British aircraft in May 1943, causing great destruction and about 70 deaths downstream. It was rebuilt within four months. The reservoir is a major summer resort area. Turbines driven by its sluices provide electricity.\nThe Weser enters the North Sea in the southernmost part of the German Bight. In the sea it splits into two arms \u2013the riverbed at the end of the last ice age. These sea arms are called \"Alte Weser\" (old Weser) and \"Neue Weser\" (new Weser). They are the waterways for ships heading for the ports of Bremerhaven, Nordenham, and Bremen. The Alte Weser Lighthouse marks the northernmost point of the Weser. This replaced the Roter Sand Lighthouse in 1964.\nWeser deepening.\nSince the 19th century, the Weser has been deepened twelve times by humans. This caused severe ecological damage to the river.\nWith each deepening, the tides were altered by the faster inflow of North Sea tides. This increases the risk of flooding along the river.\nTributaries.\nThe largest tributary of the Weser is the Aller, which joins south of Bremen. Tributaries of the Weser and the Werra (from source to mouth) are:\nModes of the list:\nList:\n II: km 45.3, left: Eder, 176.1\u00a0km, 3,361 km2, headwater of the strongest waterway of Weser system\n III: km 17.1, left: Schwalm, 97.1\u00a0km, 1.299 km2\n \u2191 III: km 49.4\u201370.5: Edersee reservoir\n II: 120.1, right: Haune, 66.5\u00a0km, 500 km2\nNotable towns.\nMain towns along the Weser are (from the head of the river to its mouth): Hann. M\u00fcnden, Beverungen, H\u00f6xter, Holzminden, Bodenwerder, Hamelin, Hessisch Oldendorf, Rinteln, Vlotho, Bad Oeynhausen, Porta Westfalica, Minden, Petershagen, Nienburg, Achim, Bremen, Brake, Nordenham, and Bremerhaven.\nPopular culture.\nThe river features in the legend and folk tale the Pied Piper of Hamelin.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41887", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=41887", "title": "Felix Klein", "text": "German mathematician (1849\u20131925)\nFelix Christian Klein (; ; 25 April 1849\u00a0\u2013 22 June 1925) was a German mathematician, mathematics educator and historian of mathematics, known for his work in group theory, complex analysis, non-Euclidean geometry, and the associations between geometry and group theory. His 1872 Erlangen program classified geometries by their basic symmetry groups and was an influential synthesis of much of the mathematics of the time.\nDuring his tenure at the University of G\u00f6ttingen, Klein was able to turn it into a center for mathematical and scientific research through the establishment of new lectures, professorships, and institutes. His seminars covered most areas of mathematics then known as well as their applications. Klein also devoted considerable time to mathematical instruction and promoted mathematics education reform at all grade levels in Germany and abroad. He became the first president of the International Commission on Mathematical Instruction in 1908 at the Fourth International Congress of Mathematicians in Rome.\nLife.\nFelix Klein was born on 25 April 1849 in D\u00fcsseldorf, to Prussian parents. His father, Caspar Klein (1809\u20131889), was a Prussian government official's secretary stationed in the Rhine Province. His mother was Sophie Elise Klein (1819\u20131890, n\u00e9e Kayser). He attended the Gymnasium in D\u00fcsseldorf, then studied mathematics and physics at the University of Bonn, 1865\u20131866, intending to become a physicist. At that time, Julius Pl\u00fccker had Bonn's professorship of mathematics and experimental physics, but by the time Klein became his assistant, in 1866, Pl\u00fccker's interest was mainly geometry. Klein received his doctorate, supervised by Pl\u00fccker, from the University of Bonn in 1868.\nPl\u00fccker died in 1868, leaving his book concerning the basis of line geometry incomplete. Klein was the obvious person to complete the second part of Pl\u00fccker's \"Neue Geometrie des Raumes\", and thus became acquainted with Alfred Clebsch, who had relocated to G\u00f6ttingen in 1868. Klein visited Clebsch the next year, along with visits to Berlin and Paris. In July 1870, at the beginning of the Franco-Prussian War, he was in Paris and had to leave the country. For a brief time he served as a medical orderly in the Prussian army before being appointed \"Privatdozent\" (lecturer) at G\u00f6ttingen in early 1871.\nThe University of Erlangen appointed Klein professor in 1872, when he was only 23 years old. For this, he was endorsed by Clebsch, who regarded him as likely to become the best mathematician of his time. Klein did not wish to remain in Erlangen, where there were very few students, and was pleased to be offered a professorship at the Technische Hochschule M\u00fcnchen in 1875. There he and Alexander von Brill taught advanced courses to many excellent students, including Adolf Hurwitz, Walther von Dyck, Karl Rohn, Carl Runge, Max Planck, Luigi Bianchi, and Gregorio Ricci-Curbastro.\nIn 1875, Klein married Anne Hegel, granddaughter of the philosopher Georg Wilhelm Friedrich Hegel.\nAfter spending five years at the Technische Hochschule, Klein was appointed to a chair of geometry at Leipzig University. His colleagues included Walther von Dyck, Rohn, Eduard Study and Friedrich Engel. Klein's years at Leipzig, 1880 to 1886, fundamentally changed his life. In 1882, his health collapsed and he battled with depression for the next two years. Nevertheless, his research continued; his seminal work on hyperelliptic sigma functions, published between 1886 and 1888, dates from around this period.\nKlein accepted a professorship at the University of G\u00f6ttingen in 1886. From then on, until his 1913 retirement, he sought to re-establish G\u00f6ttingen as the world's prime center for mathematics research. However, he never managed to transfer from Leipzig to G\u00f6ttingen his own leading role as developer of geometry. He taught a variety of courses at G\u00f6ttingen, mainly concerning the interface between mathematics and physics, in particular, mechanics and potential theory.\nThe research facility Klein established at G\u00f6ttingen served as model for the best such facilities throughout the world. He introduced weekly discussion meetings, and created a mathematical reading room and library. In 1895, Klein recruited David Hilbert from the University of K\u00f6nigsberg. This appointment proved of great importance; Hilbert continued to enhance G\u00f6ttingen's primacy in mathematics until his own retirement in 1932. Klein and Hilbert jointly invited Emmy Noether to G\u00f6ttingen in 1915 where she introduced Einstein to group theory and the relationship between symmetries and conservation principles.\nUnder Klein's editorship, \"Mathematische Annalen\" became one of the best mathematical journals in the world. Founded by Clebsch, it grew under Klein's management, to rival, and eventually surpass \"Crelle's Journal\", based at the University of Berlin. Klein established a small team of editors who met regularly, making decisions in a democratic spirit. The journal first specialized in complex analysis, algebraic geometry, and invariant theory. It also provided an \nimportant outlet for real analysis and the new group theory.\nIn 1893, Klein was a major speaker at the International Mathematical Congress held in Chicago as part of the World's Columbian Exposition. Due partly to Klein's efforts, G\u00f6ttingen began admitting women in 1893. He supervised the first Ph.D. thesis in mathematics written at G\u00f6ttingen by a woman, by Grace Chisholm Young, an English student of Arthur Cayley's, whom Klein admired. In 1897, Klein became a foreign member of the Royal Netherlands Academy of Arts and Sciences.\nAround 1900, Klein began to become interested in mathematical instruction in schools. In 1905, he was instrumental in formulating a plan recommending that analytic geometry, the rudiments of differential and integral calculus, and the function concept be taught in secondary schools. This recommendation was gradually implemented in many countries around the world. In 1908, Klein was elected president of the International Commission on Mathematical Instruction at the Rome International Congress of Mathematicians. Under his guidance, the German part of the Commission published many volumes on the teaching of mathematics at all levels in Germany. In 1892 the Manchester Literary and Philosophical Society awarded Klein Honorary membership of the Society.\nThe London Mathematical Society awarded Klein its De Morgan Medal in 1893. He was elected a member of the Royal Society in 1885, and was awarded its Copley Medal in 1912. He retired the following year due to ill health, but continued to teach mathematics at his home for several further years.\nKlein was one of ninety-three signatories of the Manifesto of the Ninety-Three, a document penned in support of the German invasion of Belgium in the early stages of World War I.\nHe died in G\u00f6ttingen in 1925.\nWork.\nKlein's dissertation, on line geometry and its applications to mechanics, classified second degree line complexes using Weierstrass's theory of elementary divisors.\nKlein's first important mathematical discoveries were made in 1870. In collaboration with Sophus Lie, he discovered the fundamental properties of the asymptotic lines on the Kummer surface. They later investigated W-curves, curves invariant under a group of projective transformations. It was Lie who introduced Klein to the concept of group, which was to have a major role in his later work. Klein also learned about groups from Camille Jordan.\nKlein devised the \"Klein bottle\" named after him, a one-sided closed surface which cannot be embedded in three-dimensional Euclidean space, but it may be immersed as a cylinder looped back through itself to join with its other end from the \"inside\". It may be embedded in the Euclidean space of dimensions 4 and higher. The concept of a Klein Bottle was devised as a 3-Dimensional M\u00f6bius strip, with one method of construction being the attachment of the edges of two M\u00f6bius strips.\nDuring the 1890s, Klein began studying mathematical physics more intensively, writing on the gyroscope with Arnold Sommerfeld. During 1894, he initiated the idea of an encyclopedia of mathematics including its applications, which became the \"Encyklop\u00e4die der mathematischen Wissenschaften\". This enterprise, which endured until 1935, provided an important standard reference of enduring value.\nErlangen program.\nIn 1871, while at G\u00f6ttingen, Klein made major discoveries in geometry. He published two papers \"On the So-called Non-Euclidean Geometry\" showing that Euclidean and non-Euclidean geometries could be considered metric spaces determined by a Cayley\u2013Klein metric. This insight had the corollary that non-Euclidean geometry was consistent if and only if Euclidean geometry was, giving the same status to geometries Euclidean and non-Euclidean, and ending all controversy about non-Euclidean geometry. Arthur Cayley never accepted Klein's argument, believing it to be circular.\nKlein's synthesis of geometry as the study of the properties of a space that is invariant under a given group of transformations, known as the \"Erlangen program\" (1872), profoundly influenced the evolution of mathematics. This program was initiated by Klein's inaugural lecture as professor at Erlangen, although it was not the actual speech he gave on the occasion. The program proposed a unified system of geometry that has become the accepted modern method. Klein showed how the essential properties of a given geometry could be represented by the group of transformations that preserve those properties. Thus the program's definition of geometry encompassed both Euclidean and non-Euclidean geometry.\nCurrently, the significance of Klein's contributions to geometry is evident. They have become so much part of mathematical thinking that it is difficult to appreciate their novelty when first presented, and understand the fact that they were not immediately accepted by all his contemporaries.\nComplex analysis.\nKlein saw his work on complex analysis as his major contribution to mathematics, specifically his work on:\nKlein showed that the modular group moves the fundamental region of the complex plane so as to tessellate the plane. In 1879, he examined the action of PSL(2,7), considered as an image of the modular group, and obtained an explicit representation of a Riemann surface now termed the Klein quartic. He showed that it was a complex curve in projective space, that its equation was \"x\"3\"y\"\u00a0+\u00a0\"y\"3\"z\"\u00a0+\u00a0\"z\"3\"x\"\u00a0=\u00a00, and that its group of symmetries was PSL(2,7) of order 168. His \"Ueber Riemann's Theorie der algebraischen Funktionen und ihre Integrale\" (1882) treats complex analysis in a geometric way, connecting potential theory and conformal mappings. This work drew on notions from fluid dynamics.\nKlein considered equations of degree &gt; 4, and was especially interested in using transcendental methods to solve the general equation of the fifth degree. Building on methods of Charles Hermite and Leopold Kronecker, he produced similar results to those of Brioschi and later completely solved the problem by means of the icosahedral group. This work enabled him to write a series of papers on elliptic modular functions.\nIn his 1884 book on the icosahedron, Klein established a theory of automorphic functions, associating algebra and geometry. Poincar\u00e9 had published an outline of his theory of automorphic functions in 1881, which resulted in a friendly rivalry between the two men. Both sought to state and prove a grand uniformization theorem that would establish the new theory more completely. Klein succeeded in formulating such a theorem and in describing a strategy for proving it. He came up with his proof during an asthma attack at 2:30 A.M. on 23 March 1882.\nKlein summarized his work on automorphic and elliptic modular functions in a four volume treatise, written with Robert Fricke over a period of about 20 years.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41889", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=41889", "title": "Group Theory", "text": ""}
{"id": "41890", "revid": "50699622", "url": "https://en.wikipedia.org/wiki?curid=41890", "title": "Group theory", "text": "Branch of mathematics that studies the properties of groups\nIn abstract algebra, group theory studies the algebraic structures known as groups. \nThe concept of a group is central to abstract algebra: other well-known algebraic structures, such as rings, fields, and vector spaces, can all be seen as groups endowed with additional operations and axioms. Groups recur throughout mathematics, and the methods of group theory have influenced many parts of algebra. Linear algebraic groups and Lie groups are two branches of group theory that have experienced advances and have become subject areas in their own right.\nVarious physical systems, such as crystals and the hydrogen atom, and three of the four known fundamental forces in the universe, may be modelled by symmetry groups. Thus group theory and the closely related representation theory have many important applications in physics, chemistry, and materials science. Group theory is also central to public key cryptography.\nThe early history of group theory dates from the 19th century. One of the most important mathematical achievements of the 20th century was the collaborative effort, taking up more than 10,000 journal pages and mostly published between 1960 and 2004, that culminated in a complete classification of finite simple groups.\nHistory.\nGroup theory has three main historical sources: number theory, the theory of algebraic equations, and geometry. The number-theoretic strand was begun by Leonhard Euler, and developed by Gauss's work on modular arithmetic and additive and multiplicative groups related to quadratic fields. Early results about permutation groups were obtained by Lagrange, Ruffini, and Abel in their quest for general solutions of polynomial equations of high degree. \u00c9variste Galois coined the term \"group\" and established a connection, now known as Galois theory, between the nascent theory of groups and field theory. In geometry, groups first became important in projective geometry and, later, non-Euclidean geometry. Felix Klein's Erlangen program proclaimed group theory to be the organizing principle of geometry.\nGalois, in the 1830s, was the first to employ groups to determine the solvability of polynomial equations. Arthur Cayley and Augustin Louis Cauchy pushed these investigations further by creating the theory of permutation groups. The second historical source for groups stems from geometrical situations. In an attempt to come to grips with possible geometries (such as euclidean, hyperbolic or projective geometry) using group theory, Felix Klein initiated the Erlangen programme. Sophus Lie, in 1884, started using groups (now called Lie groups) attached to analytic problems. Thirdly, groups were, at first implicitly and later explicitly, used in algebraic number theory.\nThe different scope of these early sources resulted in different notions of groups. The theory of groups was unified starting around 1880. Since then, the impact of group theory has been ever growing, giving rise to the birth of abstract algebra in the early 20th century, representation theory, and many more influential spin-off domains. The classification of finite simple groups is a vast body of work from the mid 20th century, classifying all the finite simple groups.\nMain classes of groups.\nThe range of groups being considered has gradually expanded from finite permutation groups and special examples of matrix groups to abstract groups that may be specified through a presentation by generators and relations.\nPermutation groups.\nThe first class of groups to undergo a systematic study was permutation groups. Given any set \"X\" and a collection \"G\" of bijections of \"X\" into itself (known as \"permutations\") that is closed under compositions and inverses, \"G\" is a group acting on \"X\". If \"X\" consists of \"n\" elements and \"G\" consists of \"all\" permutations, \"G\" is the symmetric group S\"n\"; in general, any permutation group \"G\" is a subgroup of the symmetric group of \"X\". An early construction due to Cayley exhibited any group as a permutation group, acting on itself (\"X\" = \"G\") by means of the left regular representation.\nIn many cases, the structure of a permutation group can be studied using the properties of its action on the corresponding set. For example, in this way one proves that for \"n\" \u2265 5, the alternating group A\"n\" is simple, i.e. does not admit any proper normal subgroups. This fact plays a key role in the impossibility of solving a general algebraic equation of degree \"n\" \u2265 5 in radicals.\nMatrix groups.\nThe next important class of groups is given by \"matrix groups\", or linear groups. Here \"G\" is a set consisting of invertible matrices of given order \"n\" over a field \"K\" that is closed under the products and inverses. Such a group acts on the \"n\"-dimensional vector space \"K\"\"n\" by linear transformations. This action makes matrix groups conceptually similar to permutation groups, and the geometry of the action may be usefully exploited to establish properties of the group \"G\".\nTransformation groups.\nPermutation groups and matrix groups are special cases of transformation groups: groups that act on a certain space \"X\" preserving its inherent structure. In the case of permutation groups, \"X\" is a set; for matrix groups, \"X\" is a vector space. The concept of a transformation group is closely related with the concept of a symmetry group: transformation groups frequently consist of \"all\" transformations that preserve a certain structure.\nThe theory of transformation groups forms a bridge connecting group theory with differential geometry. A long line of research, originating with Lie and Klein, considers group actions on manifolds by homeomorphisms or diffeomorphisms. The groups themselves may be discrete or continuous.\nAbstract groups.\nMost groups considered in the first stage of the development of group theory were \"concrete\", having been realized through numbers, permutations, or matrices. It was not until the late nineteenth century that the idea of an abstract group began to take hold, where \"abstract\" means that the nature of the elements are ignored in such a way that two isomorphic groups are considered as the same group. A typical way of specifying an abstract group is through a presentation by \"generators and relations\",\n formula_1\nA significant source of abstract groups is given by the construction of a \"factor group\", or quotient group, \"G\"/\"H\", of a group \"G\" by a normal subgroup \"H\". Class groups of algebraic number fields were among the earliest examples of factor groups, of much interest in number theory. If a group \"G\" is a permutation group on a set \"X\", the factor group \"G\"/\"H\" is no longer acting on \"X\"; but the idea of an abstract group permits one not to worry about this discrepancy.\nThe change of perspective from concrete to abstract groups makes it natural to consider properties of groups that are independent of a particular realization, or in modern language, invariant under isomorphism, as well as the classes of group with a given such property: finite groups, periodic groups, simple groups, solvable groups, and so on. Rather than exploring properties of an individual group, one seeks to establish results that apply to a whole class of groups. The new paradigm was of paramount importance for the development of mathematics: it foreshadowed the creation of abstract algebra in the works of Hilbert, Emil Artin, Emmy Noether, and mathematicians of their school.\nGroups with additional structure.\nAn important elaboration of the concept of a group occurs if \"G\" is endowed with additional structure, notably, of a topological space, differentiable manifold, or algebraic variety. If the multiplication and inversion of the group are compatible with this structure, that is, they are continuous, smooth or regular (in the sense of algebraic geometry) maps, then \"G\" is a topological group, a Lie group, or an algebraic group.\nThe presence of extra structure relates these types of groups with other mathematical disciplines and means that more tools are available in their study. Topological groups form a natural domain for abstract harmonic analysis, whereas Lie groups (frequently realized as transformation groups) are the mainstays of differential geometry and unitary representation theory. Certain classification questions that cannot be solved in general can be approached and resolved for special subclasses of groups. Thus, compact connected Lie groups have been completely classified. There is a fruitful relation between infinite abstract groups and topological groups: whenever a group \"\u0393\" can be realized as a lattice in a topological group \"G\", the geometry and analysis pertaining to \"G\" yield important results about \"\u0393\". A comparatively recent trend in the theory of finite groups exploits their connections with compact topological groups (profinite groups): for example, a single \"p\"-adic analytic group \"G\" has a family of quotients which are finite \"p\"-groups of various orders, and properties of \"G\" translate into the properties of its finite quotients.\nBranches of group theory.\nFinite group theory.\nDuring the twentieth century, mathematicians investigated some aspects of the theory of finite groups in great depth, especially the local theory of finite groups and the theory of solvable and nilpotent groups. As a consequence, the complete classification of finite simple groups was achieved, meaning that all those simple groups from which all finite groups can be built are now known.\nDuring the second half of the twentieth century, mathematicians such as Chevalley and Steinberg also increased our understanding of finite analogs of classical groups, and other related groups. One such family of groups is the family of general linear groups over finite fields. \nFinite groups often occur when considering symmetry of mathematical or\nphysical objects, when those objects admit just a finite number of structure-preserving transformations. The theory of Lie groups,\nwhich may be viewed as dealing with \"continuous symmetry\", is strongly influenced by the associated Weyl groups. These are finite groups generated by reflections which act on a finite-dimensional Euclidean space. The properties of finite groups can thus play a role in subjects such as theoretical physics and chemistry.\nRepresentation of groups.\nSaying that a group \"G\" \"acts\" on a set \"X\" means that every element of \"G\" defines a bijective map on the set \"X\" in a way compatible with the group structure. When \"X\" has more structure, it is useful to restrict this notion further: a representation of \"G\" on a vector space \"V\" is a group homomorphism:\nformula_2\nwhere GL(\"V\") consists of the invertible linear transformations of \"V\". In other words, to every group element \"g\" is assigned an automorphism \"\u03c1\"(\"g\") such that \"\u03c1\"(\"g\") \u2218 \"\u03c1\"(\"h\") = \"\u03c1\"(\"gh\") for any \"h\" in \"G\".\nThis definition can be understood in two directions, both of which give rise to whole new domains of mathematics. On the one hand, it may yield new information about the group \"G\": often, the group operation in \"G\" is abstractly given, but via \"\u03c1\", it corresponds to the multiplication of matrices, which is very explicit. On the other hand, given a well-understood group acting on a complicated object, this simplifies the study of the object in question. For example, if \"G\" is finite, it is known that \"V\" above decomposes into irreducible parts (see Maschke's theorem). These parts, in turn, are much more easily manageable than the whole \"V\" (via Schur's lemma).\nGiven a group \"G\", representation theory then asks what representations of \"G\" exist. There are several settings, and the employed methods and obtained results are rather different in every case: representation theory of finite groups and representations of Lie groups are two main subdomains of the theory. The totality of representations is governed by the group's characters. For example, Fourier polynomials can be interpreted as the characters of U(1), the group of complex numbers of absolute value \"1\", acting on the \"L\"2-space of periodic functions.\nLie theory.\nA Lie group is a group that is also a differentiable manifold, with the property that the group operations are compatible with the smooth structure. Lie groups are named after Sophus Lie, who laid the foundations of the theory of continuous transformation groups. The term \"groupes de Lie\" first appeared in French in 1893 in the thesis of Lie's student , page 3.\nLie groups represent the best-developed theory of continuous symmetry of mathematical objects and structures, which makes them indispensable tools for many parts of contemporary mathematics, as well as for modern theoretical physics. They provide a natural framework for analysing the continuous symmetries of differential equations (differential Galois theory), in much the same way as permutation groups are used in Galois theory for analysing the discrete symmetries of algebraic equations. An extension of Galois theory to the case of continuous symmetry groups was one of Lie's principal motivations.\nCombinatorial and geometric group theory.\nGroups can be described in different ways. Finite groups can be described by writing down the group table consisting of all possible multiplications \"g\" \u2022 \"h\". A more compact way of defining a group is by \"generators and relations\", also called the \"presentation\" of a group. Given any set \"F\" of generators formula_3, the free group generated by \"F\" surjects onto the group \"G\". The kernel of this map is called the subgroup of relations, generated by some subset \"D\". The presentation is usually denoted by formula_4 For example, the group presentation formula_5 describes a group which is isomorphic to formula_6 A string consisting of generator symbols and their inverses is called a \"word\".\nCombinatorial group theory studies groups from the perspective of generators and relations. It is particularly useful where finiteness assumptions are satisfied, for example finitely generated groups, or finitely presented groups (i.e. in addition the relations are finite). The area makes use of the connection of graphs via their fundamental groups. A fundamental theorem of this area is that every subgroup of a free group is free.\nThere are several natural questions arising from giving a group by its presentation. The \"word problem\" asks whether two words are effectively the same group element. By relating the problem to Turing machines, one can show that there is in general no algorithm solving this task. Another, generally harder, algorithmically insoluble problem is the group isomorphism problem, which asks whether two groups given by different presentations are actually isomorphic. For example, the group with presentation formula_7 is isomorphic to the additive group Z of integers, although this may not be immediately apparent. (Writing formula_8, one has formula_9)\nGeometric group theory attacks these problems from a geometric viewpoint, either by viewing groups as geometric objects, or by finding suitable geometric objects a group acts on. The first idea is made precise by means of the Cayley graph, whose vertices correspond to group elements and edges correspond to right multiplication in the group. Given two elements, one constructs the word metric given by the length of the minimal path between the elements. A theorem of Milnor and Svarc then says that given a group \"G\" acting in a reasonable manner on a metric space \"X\", for example a compact manifold, then \"G\" is quasi-isometric (i.e. looks similar from a distance) to the space \"X\".\nConnection of groups and symmetry.\nGiven a structured object \"X\" of any sort, a symmetry is a mapping of the object onto itself which preserves the structure. This occurs in many cases, for example\nThe axioms of a group formalize the essential aspects of symmetry. Symmetries form a group: they are closed because if you take a symmetry of an object, and then apply another symmetry, the result will still be a symmetry. The identity keeping the object fixed is always a symmetry of an object. Existence of inverses is guaranteed by undoing the symmetry and the associativity comes from the fact that symmetries are functions on a space, and composition of functions is associative.\nFrucht's theorem says that every group is the symmetry group of some graph. So every abstract group is actually the symmetries of some explicit object.\nThe saying of \"preserving the structure\" of an object can be made precise by working in a category. Maps preserving the structure are then the morphisms, and the symmetry group is the automorphism group of the object in question.\nApplications of group theory.\nApplications of group theory abound. Almost all structures in abstract algebra are special cases of groups. Rings, for example, can be viewed as abelian groups (corresponding to addition) together with a second operation (corresponding to multiplication). Therefore, group theoretic arguments underlie large parts of the theory of those entities.\nGalois theory.\nGalois theory uses groups to describe the symmetries of the roots of a polynomial (or more precisely the automorphisms of the algebras generated by these roots). The fundamental theorem of Galois theory provides a link between algebraic field extensions and group theory. It gives an effective criterion for the solvability of polynomial equations in terms of the solvability of the corresponding Galois group. For example, \"S\"5, the symmetric group in 5 elements, is not solvable which implies that the general quintic equation cannot be solved by radicals in the way equations of lower degree can. The theory, being one of the historical roots of group theory, is still fruitfully applied to yield new results in areas such as class field theory.\nAlgebraic topology.\nAlgebraic topology is another domain which prominently associates groups to the objects the theory is interested in. There, groups are used to describe certain invariants of topological spaces. They are called \"invariants\" because they are defined in such a way that they do not change if the space is subjected to some deformation. For example, the fundamental group \"counts\" how many paths in the space are essentially different. The Poincar\u00e9 conjecture, proved in 2002/2003 by Grigori Perelman, is a prominent application of this idea. The influence is not unidirectional, though. For example, algebraic topology makes use of Eilenberg\u2013MacLane spaces which are spaces with prescribed homotopy groups. Similarly algebraic K-theory relies in a way on classifying spaces of groups. Finally, the name of the torsion subgroup of an infinite group shows the legacy of topology in group theory.\nAlgebraic geometry.\nAlgebraic geometry likewise uses group theory in many ways. Abelian varieties have been introduced above. The presence of the group operation yields additional information which makes these varieties particularly accessible. They also often serve as a test for new conjectures. (For example the Hodge conjecture (in certain cases).) The one-dimensional case, namely elliptic curves is studied in particular detail. They are both theoretically and practically intriguing. In another direction, toric varieties are algebraic varieties acted on by a torus. Toroidal embeddings have recently led to advances in algebraic geometry, in particular resolution of singularities.\nAlgebraic number theory.\nAlgebraic number theory makes uses of groups for some important applications. For example, Euler's product formula,\nformula_13\ncaptures the fact that any integer decomposes in a unique way into primes. The failure of this statement for more general rings gives rise to class groups and regular primes, which feature in Kummer's treatment of Fermat's Last Theorem.\nHarmonic analysis.\nAnalysis on Lie groups and certain other groups is called harmonic analysis. Haar measures, that is, integrals invariant under the translation in a Lie group, are used for pattern recognition and other image processing techniques.\nCombinatorics.\nIn combinatorics, the notion of permutation group and the concept of group action are often used to simplify the counting of a set of objects; see in particular Burnside's lemma.\nMusic.\nThe presence of the 12-periodicity in the circle of fifths yields applications of elementary group theory in musical set theory. Transformational theory models musical transformations as elements of a mathematical group.\nPhysics.\nIn physics, groups are important because they describe the symmetries which the laws of physics seem to obey. According to Noether's theorem, every continuous symmetry of a physical system corresponds to a conservation law of the system. Physicists are very interested in group representations, especially of Lie groups, since these representations often point the way to the \"possible\" physical theories. Examples of the use of groups in physics include the Standard Model, gauge theory, the Lorentz group, and the Poincar\u00e9 group.\nGroup theory can be used to resolve the incompleteness of the statistical interpretations of mechanics developed by Willard Gibbs, relating to the summing of an infinite number of probabilities to yield a meaningful solution.\nChemistry and materials science.\nIn chemistry and materials science, point groups are used to classify regular polyhedra, and the symmetries of molecules, and space groups to classify crystal structures. The assigned groups can then be used to determine physical properties (such as chemical polarity and chirality), spectroscopic properties (particularly useful for Raman spectroscopy, infrared spectroscopy, circular dichroism spectroscopy, magnetic circular dichroism spectroscopy, UV/Vis spectroscopy, and fluorescence spectroscopy), and to construct molecular orbitals.\nMolecular symmetry is responsible for many physical and spectroscopic properties of compounds and provides relevant information about how chemical reactions occur. In order to assign a point group for any given molecule, it is necessary to find the set of symmetry operations present on it. The symmetry operation is an action, such as a rotation around an axis or a reflection through a mirror plane. In other words, it is an operation that moves the molecule such that it is indistinguishable from the original configuration. In group theory, the rotation axes and mirror planes are called \"symmetry elements\". These elements can be a point, line or plane with respect to which the symmetry operation is carried out. The symmetry operations of a molecule determine the specific point group for this molecule.\nIn chemistry, there are five important symmetry operations. They are identity operation (E), rotation operation or proper rotation (C\"n\"), reflection operation (\u03c3), inversion (i) and rotation reflection operation or improper rotation (S\"n\"). The identity operation (E) consists of leaving the molecule as it is. This is equivalent to any number of full rotations around any axis. This is a symmetry of all molecules, whereas the symmetry group of a chiral molecule consists of only the identity operation. An identity operation is a characteristic of every molecule even if it has no symmetry. Rotation around an axis (C\"n\") consists of rotating the molecule around a specific axis by a specific angle. It is rotation through the angle 360\u00b0/\"n\", where \"n\" is an integer, about a rotation axis. For example, if a water molecule rotates 180\u00b0 around the axis that passes through the oxygen atom and between the hydrogen atoms, it is in the same configuration as it started. In this case, \"n\" = 2, since applying it twice produces the identity operation. In molecules with more than one rotation axis, the Cn axis having the largest value of n is the highest order rotation axis or principal axis. For example in boron trifluoride (BF3), the highest order of rotation axis is C3, so the principal axis of rotation is C3.\nIn the reflection operation (\u03c3) many molecules have mirror planes, although they may not be obvious. The reflection operation exchanges left and right, as if each point had moved perpendicularly through the plane to a position exactly as far from the plane as when it started. When the plane is perpendicular to the principal axis of rotation, it is called \u03c3\"h\" (horizontal). Other planes, which contain the principal axis of rotation, are labeled vertical (\u03c3\"v\") or dihedral (\u03c3\"d\").\nInversion (i ) is a more complex operation. Each point moves through the center of the molecule to a position opposite the original position and as far from the central point as where it started. Many molecules that seem at first glance to have an inversion center do not; for example, methane and other tetrahedral molecules lack inversion symmetry. To see this, hold a methane model with two hydrogen atoms in the vertical plane on the right and two hydrogen atoms in the horizontal plane on the left. Inversion results in two hydrogen atoms in the horizontal plane on the right and two hydrogen atoms in the vertical plane on the left. Inversion is therefore not a symmetry operation of methane, because the orientation of the molecule following the inversion operation differs from the original orientation. And the last operation is improper rotation or rotation reflection operation (S\"n\") requires rotation of\u00a0 360\u00b0/\"n\", followed by reflection through a plane perpendicular to the axis of rotation.\nCryptography.\nVery large groups of prime order constructed in elliptic curve cryptography serve for public-key cryptography. Cryptographical methods of this kind benefit from the flexibility of the geometric objects, hence their group structures, together with the complicated structure of these groups, which make the discrete logarithm very hard to calculate. One of the earliest encryption protocols, Caesar's cipher, may also be interpreted as a (very easy) group operation. Most cryptographic schemes use groups in some way. In particular Diffie\u2013Hellman key exchange uses finite cyclic groups. So the term group-based cryptography refers mostly to cryptographic protocols that use infinite non-abelian groups such as a braid group."}
{"id": "41891", "revid": "1314950493", "url": "https://en.wikipedia.org/wiki?curid=41891", "title": "Stable nuclide", "text": "Nuclide that does not undergo radioactive decay\nStable nuclides are isotopes of a chemical element whose nucleons are in a configuration that does not permit them the surplus energy required to produce a radioactive emission. The nuclei of such isotopes are not radioactive and unlike radionuclides do not spontaneously undergo radioactive decay. When these nuclides are referred to in relation to specific elements they are usually called that element's stable isotopes.\nThe 80 elements with one or more stable isotopes comprise a total of 251 nuclides that have not been shown to decay using current equipment. Of these 80 elements, 26 have only one stable isotope and are called monoisotopic. The other 56 have more than one stable isotope. Tin has ten stable isotopes, the largest number of any element.\nDefinition of stability, and naturally occurring nuclides.\nMost naturally occurring nuclides are stable (about 251; see list at the end of this article), and about 35 more (total of 286) are known to be radioactive with long enough half-lives (also known) to occur primordially. If the half-life of a nuclide is comparable to, or greater than, the Earth's age (4.5 billion years), a significant amount will have survived since the formation of the Solar System, and then is said to be primordial. It will then contribute in that way to the natural isotopic composition of a chemical element. Primordial radioisotopes are easily detected with half-lives as short as 700 million years (e.g., 235U). This is the present limit of detection, as shorter-lived nuclides have not yet been detected undisputedly in nature except when recently produced, such as decay products or cosmic ray spallation.\nMany naturally occurring radioisotopes (another 53 or so, for a total of about 339) exhibit still shorter half-lives than 700 million years, but they are made freshly, as daughter products of decay processes of primordial nuclides (for example, radium from uranium), or from ongoing energetic reactions, such as cosmogenic nuclides produced by present bombardment of Earth by cosmic rays (for example, 14C made from nitrogen).\nSome isotopes that are classed as stable (i.e. no radioactivity has been observed for them) are predicted to have extremely long half-lives (sometimes 1018 years or more). If the predicted half-life falls into an experimentally accessible range, such isotopes have a chance to move from the list of stable nuclides to the radioactive category, once their activity is observed. For example, 209Bi and 180W were formerly classed as stable, but were found to be alpha-active in 2003. However, such nuclides do not change their status as primordial when they are found to be radioactive.\nMost stable isotopes on Earth are believed to have been formed in processes of nucleosynthesis, either in the Big Bang, or in generations of stars that preceded the formation of the Solar System. However, some stable isotopes also show abundance variations in the earth as a result of decay from long-lived radioactive nuclides. These decay-products are termed radiogenic isotopes, in order to distinguish them from the much larger group of 'non-radiogenic' isotopes.\nIsotopes per element.\nOf the known chemical elements, 80 elements have at least one stable nuclide. These comprise the first 82 elements from hydrogen to lead, with the two exceptions, technetium (element 43) and promethium (element 61), that do not have any stable nuclides. As of 2024, there are total of 251 known \"stable\" nuclides. In this definition, \"stable\" means a nuclide that has never been observed to decay against the natural background. Thus, these elements have half-lives too long to be measured by any means, direct or indirect.\nStable isotopes:\nThese last 26 are thus called \"monoisotopic elements\". The mean number of stable isotopes for elements which have at least one stable isotope is 251/80 = 3.1375.\nPhysical magic numbers and odd and even proton and neutron count.\nStability of isotopes is affected by the ratio of protons to neutrons, and also by presence of certain magic numbers of neutrons or protons which represent closed and filled quantum shells. These quantum shells correspond to a set of energy levels within the shell model of the nucleus; filled shells, such as the filled shell of 50 protons for tin, confers unusual stability on the nuclide. As in the case of tin, a magic number for \"Z\", the atomic number, tends to increase the number of stable isotopes for the element.\nJust as in the case of electrons, which have the lowest energy state when they occur in pairs in a given orbital, nucleons (both protons and neutrons) exhibit a lower energy state when their number is even, rather than odd. This stability tends to prevent beta decay (in two steps) of many even\u2013even nuclides into another even\u2013even nuclide of the same mass number but lower energy (and of course with two more protons and two fewer neutrons), because decay proceeding one step at a time would have to pass through an odd\u2013odd nuclide of higher energy. Such nuclei thus instead undergo double beta decay (or are theorized to do so) with half-lives several orders of magnitude larger than the age of the universe. This makes for a larger number of stable even\u2013even nuclides, which account for 150 of the 251 total. Stable even\u2013even nuclides number as many as three isobars for some mass numbers, and up to seven isotopes for some atomic numbers.\nConversely, of the 251 known stable nuclides, only five have both an odd number of protons \"and\" odd number of neutrons: hydrogen-2 (deuterium), lithium-6, boron-10, nitrogen-14, and tantalum-180m. Also, only four naturally occurring, radioactive odd\u2013odd nuclides have a half-life &gt;109 years: potassium-40, vanadium-50, lanthanum-138, and lutetium-176. Odd\u2013odd primordial nuclides are rare because most odd\u2013odd nuclei beta-decay, because the decay products are even\u2013even, and are therefore more strongly bound, due to nuclear pairing effects.\nYet another effect of the instability of an odd number of either type of nucleon is that odd-numbered elements tend to have fewer stable isotopes. Of the 26 monoisotopic elements (those with only one stable isotope), all but one have an odd atomic number, and all but one has an even number of neutrons: the single exception to both rules is beryllium.\nThe end of the stable elements occurs after lead, largely because nuclei with 128 neutrons\u2014two neutrons above the magic number 126\u2014are extraordinarily unstable and almost immediately alpha-decay. This contributes to the very short half-lives of astatine, radon, and francium. A similar phenomenon occurs to a much lesser extent with 84 neutrons\u2014two neutrons above the magic number 82\u2014where various isotopes of lanthanide elements alpha-decay.\nNuclear isomers, including a \"stable\" one.\nThe 251 known stable nuclides include tantalum-180m, since even though its decay is automatically implied by it being \"metastable\", this has not been observed. All \"stable\" isotopes (stable by observation, not theory) are the ground states of nuclei, except for tantalum-180m, which is a nuclear isomer or excited state. The ground state, tantalum-180, is radioactive with half-life 8 hours; in contrast, the decay of the nuclear isomer is extremely strongly forbidden by spin-parity selection rules. It has been reported by direct observation that the half-life of 180mTa to gamma decay must be &gt;1015 years. Other possible modes of 180mTa decay (beta decay, electron capture, and alpha decay) have also never been observed.\nStill-unobserved decay.\nIt is expected that improvement of experimental sensitivity will allow discovery of very mild radioactivity of some isotopes now considered stable. For example, in 2003 it was reported that bismuth-209 (the only primordial isotope of bismuth) is very mildly radioactive, with half-life (1.9 \u00b1 0.2) \u00d7 1019\u2009yr, confirming earlier theoretical predictions from nuclear physics that bismuth-209 would very slowly alpha decay.\nIsotopes that are theoretically believed to be unstable but have not been observed to decay are termed observationally stable. Currently there are 105 \"stable\" isotopes which are theoretically unstable, 40 of which have been observed in detail with no sign of decay, the lightest in any case being 36Ar. Many \"stable\" nuclides are \"metastable\" in that they would release energy if they were to decay, and are expected to undergo very rare kinds of radioactive decay, including double beta decay.\n146 nuclides from 62 elements with atomic numbers from 1 (hydrogen) to 66 (dysprosium) except 43 (technetium), 61 (promethium), 62 (samarium), and 63 (europium) are theoretically stable to any kind of nuclear decay\u00a0\u2014 except for the theoretical possibility of proton decay, which has never been observed despite extensive searches for it; and spontaneous fission (SF), which is theoretically possible for the nuclides with atomic mass numbers \u2265 93, that is all those with atomic numbers \u2265 41.\nBesides SF, other theoretical decay routes for heavier elements include:\nThese include all nuclides of mass 165 and greater. Argon-36 is the lightest known \"stable\" nuclide which is theoretically unstable.\nThe positivity of energy release in these processes means they are allowed kinematically (they do not violate conservation of energy) and, thus, in principle, can occur. They are not observed due to strong but not absolute suppression, by spin-parity selection rules (for beta decays and isomeric transitions) or by the thickness of the potential barrier (for alpha and cluster decays and spontaneous fission).\nSummary table for numbers of each class of nuclides.\nThis is a summary table from List of nuclides. Numbers are not exact and may change slightly in the future, as nuclides are observed to be radioactive, or new half-lives are determined to some precision.\nList of stable nuclides.\nThe primordial radionuclides are included for comparison; they are italicized and offset from the list of stable nuclides proper.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAbbreviations for predicted unobserved decay:\n\u03b1 for alpha decay, B for beta decay, 2B for double beta decay, E for electron capture, 2E for double electron capture, IT for isomeric transition, SF for spontaneous fission, * for the nuclides whose half-lives have lower bound. Double beta decay has only been listed when beta decay is not also possible.\n^ Tantalum-180m is a \"metastable isotope\", meaning it is an excited nuclear isomer of tantalum-180. See isotopes of tantalum. However, the half-life of this nuclear isomer is so long that it has never been observed to decay, and it thus is an \"observationally stable\" primordial nuclide, a rare isotope of tantalum. This is the only nuclear isomer with a half-life so long that it has never been observed to decay. It is thus included in this list.\n^^ Bismuth-209 was long believed to be stable, due to its half-life of 2.01\u00d71019 years, which is more than a billion times the age of the universe.\n\u00a7 Europium-151 and samarium-147 are primordial nuclides with very long half-lives of 4.62\u00d71018 years and 1.066\u00d71011 years, respectively.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41892", "revid": "46220142", "url": "https://en.wikipedia.org/wiki?curid=41892", "title": "Terminal", "text": "Terminal may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\n*\"The Terminal Man\" (film), film adaptation by Mike Hodges\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41893", "revid": "40944941", "url": "https://en.wikipedia.org/wiki?curid=41893", "title": "Teletype (disambiguation)", "text": "The teletype, or teleprinter, is a device used for communicating text over telegraph lines, public switched telephone network, Telex, radio, or satellite links.\nTeletype may also refer to:\nCompanies.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41895", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=41895", "title": "Craig Barrett", "text": "Craig Barrett may refer to:\nSee also.\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about people with the same name. "}
{"id": "41896", "revid": "48523215", "url": "https://en.wikipedia.org/wiki?curid=41896", "title": "Helmut Kohl", "text": "Chancellor of Germany from 1982 to 1998\nHelmut Josef Michael Kohl (; 3 April 1930 \u2013 16 June 2017) was a German politician who served as chancellor of Germany and governed the \"Federal Republic\" from 1982 to 1998. He was leader of the Christian Democratic Union (CDU) from 1973 to 1998 and oversaw the end of the Cold War, the German reunification and the creation of the European Union (EU). Kohl's 16-year tenure is the longest in German post-war history, and is the longest for any democratically elected chancellor of Germany.\nBorn in Ludwigshafen to a Catholic family, Kohl joined the CDU in 1946 at the age of 16. He earned a PhD in history at Heidelberg University in 1958 and worked as a business executive before becoming a full-time politician. He was elected as the youngest member of the Parliament of Rhineland-Palatinate in 1959 and from 1969 to 1976 was minister president of the Rhineland-Palatinate state. Viewed during the 1960s and the early 1970s as a progressive within the CDU, he was elected national chairman of the party in 1973. After he had become party leader, Kohl was increasingly seen as a more conservative figure. In the 1976 and 1980 federal elections his party performed well, but the social-liberal government of social democrat Helmut Schmidt was able to remain in power. After Schmidt had lost the support of the liberal FDP in 1982, Kohl was elected Chancellor through a constructive vote of no confidence, forming a coalition government with the FDP. Kohl chaired the G7 in 1985 and 1992.\nAs Chancellor, Kohl was committed to European integration and especially to the Franco-German relationship; he was also a steadfast ally of the United States and supported Ronald Reagan's more aggressive policies to weaken the Soviet Union. Following the Revolutions of 1989, his government acted decisively, culminating in the German reunification in 1990. Kohl and French president Fran\u00e7ois Mitterrand were the architects of the Maastricht Treaty which established the EU and the Euro currency. Kohl was also a central figure in the eastern enlargement of the EU, and his government led the effort to push for international recognition of Croatia, Slovenia, and Bosnia and Herzegovina when the states declared independence. He played an instrumental role in resolving the Bosnian War. Domestically Kohl's policies from 1990 focused on integrating former East Germany into reunified Germany, and he moved the federal capital from the \"provisional capital\" Bonn back to Berlin, although he never resided there because the government offices were only relocated in 1999. Kohl also greatly increased federal spending on arts and culture. After his chancellorship, Kohl became honorary chairman of the CDU in 1998 but resigned from the position in 2000 in the wake of the CDU donations scandal which damaged his reputation domestically.\nKohl received the 1988 Charlemagne Prize and was named Honorary Citizen of Europe by the European Council in 1998. Following his death, Kohl was honoured with the first-ever European act of state in Strasbourg. Kohl was described as \"the greatest European leader of the second half of the 20th century\" by US presidents George H. W. Bush and Bill Clinton.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nLife.\nYouth and education.\nKohl was born on 3 April 1930 in Ludwigshafen. He was the third child of Hans Kohl (3 January 1887 \u2013 19 October 1975), a Bavarian army veteran and civil servant, and his wife, C\u00e4cilie (\"n\u00e9e\" Schnur; 17 November 1892 \u2013 1 August 1977).\nKohl's family was conservative and Catholic and remained loyal to the Catholic Centre Party before and after 1933. His elder brother died serving in the Wehrmacht in World War II at the age of 18 in 1944. At the age of ten, Kohl joined, like most children in Germany at the time, the \"Deutsches Jungvolk\", a section of the Hitler Youth. Aged 15, on 20 April 1945, Kohl was sworn into the Hitler Youth by leader Artur Axmann at Berchtesgaden, just days before the end of the war, as membership was mandatory for all boys of his age. Kohl was also drafted for military service in 1945; he was not involved in any combat, a fact he later referred to as the \"mercy of late birth\" (German: \"Gnade der sp\u00e4ten Geburt\").\nKohl attended the Ruprecht Elementary School and continued at the Max-Planck-Gymnasium. After graduating in 1950, Kohl began to study law in Frankfurt am Main, spending two semesters commuting between Ludwigshafen and Frankfurt. Here, Kohl heard lectures from Carlo Schmid and Walter Hallstein, among others. In 1951, Kohl switched to Heidelberg University, where he studied history and political science. Kohl was the first in his family to attend university.\nLife before politics.\nAfter graduating in 1956, Kohl became a fellow at the Alfred Weber Institute of Heidelberg University under Dolf Sternberger where he was an active member of the student society AIESEC. In 1958, Kohl received his doctorate degree in history for his dissertation \"Die politische Entwicklung in der Pfalz und das Wiedererstehen der Parteien nach 1945\" (\"The Political Developments in the Palatinate and the Reconstruction of Political Parties after 1945\"), under the supervision of the historian Walther Peter Fuchs. After that, Kohl entered business, first as an assistant to the director of a foundry in Ludwigshafen, then, in April 1960, as a manager for the Industrial Union for Chemistry in Ludwigshafen.\nEarly political career.\nIn 1946, Kohl joined the recently founded CDU, becoming a full member once he turned 18 in 1948. In 1947, Kohl was one of the co-founders of the Junge Union-branch in Ludwigshafen, the CDU youth organisation. In 1953, Kohl joined the board of the Palatinate branch of the CDU. In 1954, Kohl became vice-chair of the Junge Union in Rhineland-Palatinate, being a member of the board until 1961.\nIn January 1955, Kohl ran for a seat on the board of the Rhineland-Palatinate CDU, losing just narrowly to the state's Minister of Family Affairs, Franz-Josef Wuermeling. Kohl was still able to take up a seat on the board, being sent there by his local party branch as a delegate. During his early years in the party, Kohl aimed to open it towards the young generation, turning away from a close relationship with the churches.\nIn early 1959, Kohl was elected chairman of the Ludwigshafen district branch of the CDU, as well as a candidate for the upcoming state elections. On 19 April 1959, Kohl was elected as the youngest member of the state diet, the Landtag of Rhineland-Palatinate. In 1960, he was also elected to the municipal council of Ludwigshafen where he served as leader of the CDU party until 1969. When the chairman of the CDU parliamentary group in the Landtag, Wilhelm Boden, died in late 1961, Kohl moved up into a deputy position. Following the next state election in 1963, he took over as chairman, a position he held until he became Minister-President in 1969. In 1966, Kohl and the incumbent minister-president and state party chairman, Peter Altmeier, agreed to share duties. In March 1966, Kohl was elected as chairman of the party in Rhineland-Palatinate, while Altmeier once again ran for minister-president in the state elections in 1967, agreeing to hand the post over to Kohl after two years, halfway into the legislative period.\nMinister-President of Rhineland-Palatinate.\nKohl was elected minister-president of Rhineland-Palatinate on 19 May 1969, as the successor to Peter Altmeier. As of 2017, he was the youngest person ever to be elected as head of government in a German \"Bundesland\". Just a few days after his election as minister-president, Kohl also became vice-chair of the federal CDU party. While in office, Kohl acted as a reformer, focusing on school and education. His government abolished school corporal punishment and the parochial school, topics that had been controversial with the conservative wing of his party. During his term, Kohl founded the University of Trier-Kaiserslautern. He also finalised a territorial reform of the state, standardising codes of law and re-aligning districts, an act that he had already pursued under Altmeier's tenure, taking the chairmanship of the Landtag's committee on the reform. After taking office, Kohl established two new ministries, one for economy and transportation and one for social matters, with the latter going to Heiner Gei\u00dfler, who would work closely with Kohl for the next twenty years.\nFederal party level, election as chairman of the CDU.\nKohl moved up into the federal board (\"Vorstand\") of the CDU in 1964. Two years later, shortly before his election as chairman of the party in Rhineland-Palatinate, he failed at an attempt to be voted into the executive committee (\"Pr\u00e4sidium\") of the party. After the CDU lost its involvement in the federal government for the first time since the end of World War II in the 1969 election, Kohl was elected into the committee. While former chancellor Kurt Georg Kiesinger remained chairman of the CDU until 1971, it was now parliamentary chairman Rainer Barzel who led the opposition against the newly formed social-liberal coalition of Willy Brandt.\nAs a member of the board and the executive committee, Kohl pushed towards party reform, supporting liberal stances in education and social policies, including employee participation. When a proposal by the board was put to vote at a party convention in early 1971 in D\u00fcsseldorf, Kohl was unable to prevail against protest coming from the conservative wing of the party around Alfred Dregger and the sister party CSU, costing him support at the liberal wing of the party. To make matters worse, in a mistake during the voting process, Kohl himself voted against the proposal, further angering his supporters, such as party treasurer Walther Leisler Kiep.\nNevertheless, when Kiesinger stepped down as party chairman in 1971, Kohl was a candidate for his succession. He was unsuccessful, losing the vote to Barzel 344 to 174. In April 1972, in the light of Brandt's \"Ostpolitik\", the CDU aimed to depose Brandt and his government in a constructive vote of no confidence, replacing him with Barzel. The attempt failed, as two members of the opposition voted against Barzel. After Barzel also lost the general election later that year, the path was free for Kohl to take over. After Barzel announced on 10 May 1973 that he would not run for the post of party chairman again, Kohl succeeded him at a party convention in Bonn on 12 June 1973, amassing 520 of 600 votes, with him as the only candidate. Facing stiff opposition from the left wing of the party, Kohl initially expected only to serve as chairman for a couple of months, as his critics planned to replace him at another convention set for November in Hamburg. Kohl received the support of his party and remained in office, not least due to the lauded work of Kurt Biedenkopf, whom Kohl had brought in as Secretary General of the CDU. Kohl remained chairman until 1998.\nWhen chancellor Brandt stepped down in May 1974 following the unravelling of the Guillaume Affair, Kohl urged his party to restrain from \"Schadenfreude\" and not to use the position of their political opponent for \"cheap polemics\". In June, Kohl campaigned during the state elections in Lower Saxony for his party colleague Wilfried Hasselmann, leading the CDU to a strong result of 48.8% of the vote, even though it proved not enough to prevent a continuation of the social-liberal coalition in the state.\nFirst candidacy for the chancellorship and the 1976 Bundestag election.\nOn 9 March 1975, Kohl and the CDU faced re-election in Rhineland-Palatinate. What placed Kohl, who intended to run for chancellor, under increased pressure was the fact that the sister parties of CDU and CSU were set to decide upon their leading candidate for the upcoming federal elections in mid-1975. CSU chairman Franz Josef Strauss had ambitions to run and publicly put Kohl under pressure over what result would be acceptable in the state elections. On election day, the CDU achieved a result of 53.9 per cent, the highest-ever result in the state, consolidating Kohl's position. Strau\u00df's bid for the chancellorship was further put into jeopardy when in March 1975 the magazine \"Der Spiegel\" published a transcript of a speech held in November 1974, in which Strau\u00df claimed that the Red Army Faction, a West German armed struggle group responsible for multiple attacks at the time, had sympathizers in the ranks of the SPD and FDP. The scandal deeply unsettled the public and effectively ruled out Strau\u00df for the candidacy.\nOn 12 May 1975, the federal board of the CDU unanimously nominated Kohl as the candidate for the general elections, without consulting their Bavarian sister party beforehand. In reaction, the CSU nominated Strau\u00df and only a mediation by former chancellor Kiesinger was able to resolve the issue and confirm Kohl as the candidate for both parties. In June 1975, Kohl was also re-elected as party chairman, achieving a result of 98.44 per cent.\nStrau\u00df took the discord as a starting point to evaluate chances of expanding the CSU on the federal level, such as having separate electoral lists in the states of North Rhine-Westphalia, Lower Saxony, Hamburg, and Bremen. He hoped to draw away right-wing voters from the FDP towards the CSU and went as far as having private meetings with industrialists in North Rhine-Westphalia. These attempts led to discomfort within the membership base of the CDU and hampered both parties' chances in the upcoming elections. Kohl himself remained silent during these tensions, which some interpreted as a lack of leadership, while others such as future president Karl Carstens praised him for seeking a consensus at the centre of the party. In the 1976 federal election, the CDU/CSU coalition performed very well, winning 48.6% of the vote. They were kept out of government by the centre-left cabinet formed by the Social Democratic Party of Germany (SPD) and Free Democratic Party (FDP), led by Social Democrat Helmut Schmidt. Kohl then retired as minister-president of Rhineland-Palatinate to become the leader of the CDU/CSU in the Bundestag. He was succeeded by Bernhard Vogel.\nLeader of the opposition.\nIn the 1980 federal elections, Kohl had to play second fiddle, when CSU leader Franz Josef Strauss became the CDU/CSU's candidate for chancellor. Strau\u00df was also unable to defeat the coalition of the SPD and the FDP. Unlike Kohl, Strau\u00df did not want to continue as the leader of the CDU/CSU and remained Minister-President of Bavaria. Kohl remained as leader of the opposition, under the third Schmidt cabinet (1980\u201382). On 17 September 1982, a conflict of economic policy occurred between the governing SPD/FDP coalition partners. The FDP wanted to radically liberalise the labour market, while the SPD preferred greater job security. The FDP began talks with the CDU/CSU to form a new government.\nChancellor of Germany (1982\u20131998).\nRise to power and first cabinet, 1982\u20131983.\nOn 1 October 1982, the CDU proposed a constructive vote of no confidence which was supported by the FDP. The motion carried\u2014to date, the only time that a chancellor has been deposed in this manner. Three days later, the Bundestag voted in a new CDU/CSU-FDP coalition cabinet, with Kohl as chancellor. Many of the important details of the new coalition had been hammered out on 20 September, though minor details were reportedly still being negotiated as the vote took place.\nThough Kohl's election was done according to the Basic Law, it came amid some controversy. The FDP had fought its 1980 campaign on the side of the SPD and even placed Chancellor Schmidt on some of their campaign posters. There were also doubts that the new government had the support of a majority of the people. In answer, the new government aimed at new elections at the earliest possible date. Polls suggested that a clear majority was indeed within reach. As the Basic Law only allows the dissolution of parliament after an unsuccessful confidence motion, Kohl had to take another controversial move: he called for a confidence vote only a month after being sworn in, which he intentionally lost because the members of his coalition abstained. President Karl Carstens then dissolved the Bundestag at Kohl's request and called new elections.\nThe move was controversial, as the coalition parties denied their votes to the same man they had elected Chancellor a month before and whom they wanted to re-elect after the parliamentary election. However, this step was condoned by the German Federal Constitutional Court as a legal instrument and was again applied by SPD Chancellor Gerhard Schr\u00f6der in 2005.\nSecond cabinet, 1983\u20131987.\nIn the federal elections of March 1983, Kohl won a resounding victory. The CDU/CSU won 48.8%, while the FDP won 7.0%. Some opposition members of the Bundestag, angered by what SPD figures in the Hessian regional elections had called the FDP's 'betrayal in Bonn', asked the Federal Constitutional Court to declare the whole proceeding unconstitutional. It denied their claim but did set restrictions on a similar move in the future. The second Kohl cabinet pushed through several controversial plans, including the stationing of NATO midrange missiles, against major opposition from the peace movement.\nOn 22 September 1984, Kohl met French president Fran\u00e7ois Mitterrand at Verdun, where the Battle of Verdun between France and Germany had taken place during World War I. Together, they commemorated the deaths of both World Wars. The photograph, which depicted their minutes-long handshake became an important symbol of French-German reconciliation. Kohl and Mitterrand developed a close political relationship, forming an important motor for European integration. Together they laid the foundations for European projects, like Eurocorps and Arte. In 1985, alongside European leaders from 16 other countries, they founded Eureka: a research and development network of national funding ministries and agencies (distinct from the European Union) that fund and support collaborative international projects. This French-German cooperation also was vital for important European projects, like the Treaty of Maastricht and the Euro.\nIn 1985, Kohl and US president Ronald Reagan, as part of a plan to observe the 40th anniversary of V-E Day, saw an opportunity to demonstrate the strength of the friendship that existed between Germany and its former foe. During a November 1984 visit to the White House, Kohl appealed to Reagan to join him in symbolising the reconciliation of their two countries at a German military cemetery. Reagan visited Germany as part of the 11th G7 summit in Bonn; then he and Kohl visited Bergen-Belsen concentration camp on 5 May and the German military cemetery at Bitburg. There was widespread outrage when the media reported that this cemetery had the graves of SS soldiers but no Americans. Reagan considered that escalating Cold War confrontations with the Kremlin required his strong support for Kohl.\nDomestic policies.\nKohl's chancellorship presided over a number of innovative policy measures. Extensions in unemployment benefits for older claimants were introduced, while the benefit for the young unemployed was extended to age 21. In 1986, a child-rearing allowance was introduced to benefit parents when at least one was employed. Informal carers were offered an attendance allowance together with tax incentives, both of which were established with the tax reforms of 1990, and were also guaranteed up to 25 hours a month of professional support, which was supplemented by four weeks of annual holiday relief. In 1984, an early retirement scheme was introduced that offered incentives to employers to replace elderly workers with applicants off the unemployment register. In 1989, a partial retirement plan was introduced under which elderly employees could work half-time and receive 70% of their former salary \"and be credited with 90 per cent of the full social insurance entitlement.\" In 1984, a Mother and Child Fund was established, providing discretionary grants \"to forestall abortions on grounds of material hardship,\" and in 1986 a 10 Bn DM package of Erziehungsgeld (childcare allowance) was introduced, although according to various studies, this latter initiative was heavily counterbalanced by cuts. In 1989, special provisions were introduced for the older unemployed.\nKohl's time as Chancellor also saw some controversial decisions in the field of social policy. Student aid was made reimbursable to the state while the Health Care Reform Act of 1989 introduced the concept by which patients pay up front and are reimbursed, while increasing patient co-payments for hospitalisation, spa visits, dental prostheses, and prescription drugs. In addition, while a 1986 Baby-Year Pensions reform granted women born after 1921 one year of work-credit per child, lawmakers were forced by public protest to phase in supplementary pension benefits for mothers who were born before the cut-off year.\nThird cabinet, 1987\u20131991.\nAfter the 1987 federal elections Kohl won a slightly reduced majority and formed his third cabinet. The SPD's candidate for chancellor was the Minister-President of North Rhine-Westphalia, Johannes Rau.\nIn 1987, Kohl hosted East German leader Erich Honecker \u2013 the first ever visit by an East German head of state to West Germany. This is generally seen as a sign that Kohl pursued \"Ostpolitik\", a policy of d\u00e9tente between East and West that had been begun by the SPD-led governments (and strongly opposed by Kohl's own CDU) during the 1970s.\nInternal struggle for CDU leadership.\nThe CDU's general secretary, Heiner Gei\u00dfler, considered the party to be in a downward spiral following the relatively poor showing in the 1987 elections. Behind the scenes, he attempted to find a majority to unseat Kohl as the party's chairman and replace him with Lothar Sp\u00e4th, the Minister-president of Baden-W\u00fcrttemberg. Before the CDU party convention in Bremen started on 11 September 1989, Kohl was diagnosed with an inflammation of his prostate. His doctor recommended immediate surgery, but Kohl refused to miss the convention and attended while wearing a catheter and with his doctor by his side, whom he introduced as his new speech writer. In the end, the \"coup\" was unsuccessful, as Kohl was re-elected as chairman with 79.52% of the votes. Sp\u00e4th, who did not stand for the position of chairman after support for Kohl became apparent, was punished by his party, failing to be elected as vice-chairman with just 357 of 731 votes. Gei\u00dfler meanwhile was relieved of his duties as general secretary and replaced by Volker R\u00fche.\nRoad to reunification.\nFollowing the breach of the Berlin Wall and the collapse of the East German Communist regime in 1989, Kohl's handling of the East German issue would become the turning point of his chancellorship. Kohl, like most West Germans, was initially caught unaware when the Socialist Unity Party was toppled in late 1989. Well aware of his constitutional mandate to seek German unity, he immediately moved to make it a reality. Taking advantage of the historic political changes occurring in East Germany, Kohl presented a ten-point plan for \"Overcoming of the division of Germany and Europe\" without consulting his coalition partner, the FDP, or the Western Allies. In February 1990, he visited the Soviet Union seeking a guarantee from Mikhail Gorbachev that the USSR would allow German reunification to proceed. One month later, the Party of Democratic Socialism \u2013 the renamed SED \u2013 was roundly defeated by a grand coalition headed by the East German counterpart of Kohl's CDU, which ran on a platform of speedy reunification.\nOn 18 May 1990, Kohl signed an economic and social union treaty with East Germany. This treaty stipulated that when reunification took place, it would be under the quicker provisions of Article 23 of the Basic Law. That article stated that any new states could adhere to the Basic Law by a simple majority vote. The alternative would have been the more protracted route of drafting a completely new constitution for the newly reunified country, as provided by Article 146 of the Basic Law. However, the Article 146 process would have opened up contentious issues in West Germany. Even without this to consider, by this time East Germany was in a state of utter collapse. In contrast, an Article 23 reunification could be completed in as little as six months.\nOver the objections of Bundesbank president Karl Otto P\u00f6hl, he allowed a 1:1 exchange rate for wages, interest and rent between the West and East Marks. In the end, this policy would seriously hurt companies in the new federal states. Together with Foreign Minister Hans-Dietrich Genscher, Kohl was able to resolve talks with the former Allies of World War II to allow German reunification. He received assurances from Gorbachev that a reunified Germany would be able to choose which international alliance it wanted to join, although Kohl made no secret that he wanted the reunified Germany to inherit West Germany's seats at NATO and the EC.\nA reunification treaty was signed on 31 August 1990 and was overwhelmingly approved by both parliaments on 20 September 1990. At midnight Central European Time on 3 October 1990, East Germany officially ceased to exist, and its territory joined the Federal Republic as the five states of Brandenburg, Mecklenburg-Vorpommern, Saxony, Saxony-Anhalt and Thuringia. These states had been the original five states of East Germany before being abolished in 1952 and had been reconstituted in August. East and West Berlin were reunited as a city-state which became the capital of the enlarged Federal Republic.\nAfter the fall of the Berlin Wall, Kohl affirmed that former German territories east of the Oder-Neisse line were definitively part of Poland, thereby relinquishing any claim Germany had to them in a treaty signed on 14 November 1990 in Warsaw. Though, earlier in March of that year, Kohl caused a diplomatic firestorm when he suggested that a reunified Germany would not accept the Oder\u2013Neisse line, and implied that the Federal Republic might wish to restore the frontier of 1937, by force if necessary. After the statement caused a major international backlash that threatened to halt German reunification, Kohl retracted his comments after knuckling under international rebuke and assured both the United States and the Soviet Union that a reunified Germany would accept the Oder\u2013Neisse line as the final border between Poland and Germany. In 1993, Kohl confirmed, via treaty with the Czech Republic, that Germany would no longer bring forward territorial claims as to the pre-1945 ethnic German Sudetenland. This treaty was a disappointment for the German Heimatvertriebene (\"displaced persons\").\nAfter reunification, 1990\u20131998.\nReunification placed Kohl in a momentarily unassailable position. In the 1990 elections\u00a0\u2013 the first free, fair and democratic all-German elections since the Weimar Republic era\u00a0\u2013 Kohl won by a landslide over opposition candidate and Minister-President of Saarland, Oskar Lafontaine. He then formed his fourth cabinet.\nAfter the federal elections of 1994 Kohl was reelected with a somewhat reduced majority, defeating Minister-President of Rhineland-Palatinate Rudolf Scharping. The SPD was able to win a majority in the Bundesrat, which significantly limited Kohl's power. In foreign politics, Kohl was more successful, for instance getting Frankfurt am Main as the seat for the European Central Bank. In 1997, Kohl received the Vision for Europe Award for his efforts in the unification of Europe.\nBy the late 1990s, Kohl's popularity had dropped amid rising unemployment. He was defeated by a large margin in the 1998 federal elections by the Minister-President of Lower Saxony, Gerhard Schr\u00f6der.\nThe future Chancellor Angela Merkel started her political career as Kohl's prot\u00e9g\u00e9e and was known in the 1990s as \"Kohl's girl\"; in January 1991, he lifted the then little-known Merkel to national prominence by appointing her to the federal cabinet.\nRetirement.\nA red\u2013green coalition government led by Schr\u00f6der replaced Kohl's government on 27 October 1998. He immediately resigned as CDU leader and largely retired from politics. He remained a member of the Bundestag until he decided not to run for reelection in the 2002 election.\nCDU finance affair, 1999\u20132000.\nKohl's life after political office in the beginning was dominated by the CDU donations scandal. The party financing scandal became public in 1999 when it was discovered that the CDU had received and kept illegal donations during Kohl's leadership.&lt;ref name=\"Spiegel(08/07/2009)\"&gt;Gerd Langguth, \"http://\", \"Der Spiegel\", 8 July 2009&lt;/ref&gt; \"Der Spiegel\" reported, \"It was never suggested that Kohl benefited personally from political donations \u2013 but he did lead the party financial system outside of the legal boundaries, doing such things as opening secret bank accounts and establishing civic associations that could act as middlemen, or procurement agencies, for campaign donations.\" While his reputation in Germany suffered in the immediate years after the finance affair, it did not affect his reputation internationally; outside of Germany he was perceived as a great European statesman and remembered for his role in solving the five great problems of his era: German reunification, European integration, the relations with Russia after the fall of the Soviet Union and the Bosnian War.\nLife after politics.\nIn 2002, Kohl left the Bundestag and officially retired from politics. Later, he was largely rehabilitated by his party. After taking office, Angela Merkel invited her former patron to the Chancellor's Office and Ronald Pofalla, the Secretary-General of the CDU, announced that the CDU would cooperate more closely with Kohl, \"to take advantage of the experience of this great statesman\". On 4 March 2004, he published the first of his memoirs, called \"Memories 1930\u20131982\", covering the period from 1930 to 1982, when he became chancellor. The second part, published on 3 November 2005, included the first half of his chancellorship (1982\u201390). On 28 December 2004, he was air-lifted by the Sri Lankan Air Force, after having been stranded in a hotel by the 2004 Indian Ocean earthquake. Kohl was a member of the Club of Madrid.\nAs reported in the German press, he also gave his name to the \"Helmut Kohl Centre for European Studies\" (currently \"Centre for European Studies\"), which is the new political foundation of the European People's Party. In late February 2008, Kohl suffered a stroke in combination with a fall which caused serious head injuries and required his hospitalisation, after which he was reported to be using a wheelchair due to partial paralysis and having difficulty speaking. He remained in intensive care since, marrying his 43-year-old partner, Maike Richter, on 8 May 2008, while still in hospital. In 2010, he had a gall bladder operation in Heidelberg, and heart surgery in 2012. He was reportedly in \"critical condition\" in June 2015, following intestinal surgery following a hip-replacement procedure.\nIn 2011, Kohl, despite frail health, began giving a number of interviews and issued statements in which he sharply condemned his successor Angela Merkel, whom he had formerly mentored, on her policies in favour of strict austerity in the European debt crisis which he saw as opposed to his politics of peaceful bi-lateral European integration during his time as chancellor. He published the book \"Aus Sorge um Europa\" (\"Out of Concern for Europe\") outlining these criticisms of Merkel (while also attacking his immediate successor Gerhard Schr\u00f6der's Euro policy) and was widely quoted in the press as saying, \"\" (\"That woman is destroying my Europe\"). Kohl thus joined former German chancellors Gerhard Schr\u00f6der and Helmut Schmidt in their similar criticisms of Merkel's policies in these two fields. In 2011, he also criticised Merkel for committing to nuclear power phaseout by 2022, following the Fukushima Daiichi nuclear disaster, saying that a nuclear phase-out would \"make the world a more dangerous place\", that risks are a part of life and Germany should instead focus on \"taking precautionary measures and minimizing risks\".\nOn 19 April 2016, Kohl was visited in his Oggersheim residence by Hungarian prime minister Viktor Orb\u00e1n. The two had a one-hour conversation and released a joint press statement regarding the 2015 European migrant crisis, saying they doubted that Europe was capable of continuing to absorb refugees indefinitely. Before the meeting, it had widely been interpreted as criticism of Angela Merkel's handling of the crisis, but Kohl and Orb\u00e1n refrained from attacking the chancellor directly, writing: \"It is about a good future for Europe and peace in the world. The efforts of Merkel point in the same direction.\"\nIn 2016, Kohl sued Random House, his former ghost writer Heribert Schwan and co-author Tilman Jens for publishing without his consent 116 comments allegedly made by Kohl during interviews in 2001 and 2002 and published in an unauthorised biography in 2014 called \"Legacy: The Kohl Protocols\". By April 2017, a German court ordered publisher Random House and the two journalists to pay Kohl damages of 1 million euros ($1.1 million) for violating his privacy, making it the highest judgment ever rendered for violations of privacy rights under German law.\nPolitical views.\nKohl was committed to European integration, maintaining close relations with French president Fran\u00e7ois Mitterrand. Parallel to this, he was committed to German reunification. Although he continued the \"Ostpolitik\" of his social democratic predecessors, Kohl supported Reagan's more aggressive policies to weaken the Soviet Union. He had a strained relationship with British prime minister and fellow conservative Margaret Thatcher, although Kohl did allow her secret access to his plans on reunification in March 1990, to allay the concerns she shared with Mitterrand.\nPersonality and media portrayals.\nKohl faced stiff opposition from the West German political left and was mocked for his large physical stature, alleged provinciality, simplistic language, and (slight) local Palatinate dialect including hypercorrections. Similar to historical French cartoons of Louis-Philippe of France, Hans Traxler depicted Kohl as a pear in the left-leaning satirical journal \"Titanic\". The German word \"Birne\" (\"pear\") became a widespread nickname for and symbol of the chancellor.\nComedians like Thomas Freitag and Stefan Wald imitated the chancellor, and books were sold with jokes rewritten with Kohl as the stupid protagonist. When Kohl died, left-wing newspaper TAZ presented a title page showing a flower set typical for funerals, with a pear and the caption \"flourishing landscapes\", Kohl's prediction for the future of East Germany after reunification. Following protests the editor-in-chief apologised.\nThe minister-president of Rhineland-Palatinate (1969\u20131976) was a young reformer in a somewhat backward state and a newcomer who heavily criticised the older party leaders. The national media, for as much as they took notice of him, regarded him with curiosity. But this changed when Kohl became chair of the federal party in 1973, and even more dramatically when in late 1975 his party made him a candidate for the chancellery. His opponents within the federal party, but also journalists and other observers, had their doubts whether the parochial, though successful moderniser of a manageable smaller state was the right person to lead the Federal Republic, a big and complicated industrial country.\nBiographer Hans Peter Schwarz names five problems of the 46-year-old candidate: being unfamiliar with the complicated relations in the Bundestag group, having no international experience, having no profound knowledge of economics, but also: a lack of charisma and no cultural acceptance in Northern Germany.\nIn small circles Kohl was fascinating and a perfect host; the larger the crowd, the vaguer, weaker and paler he appeared. His gaze into the TV cameras made him look helpless. When attacked, e.g. in election campaigns, he became a good fighter. But in general, he was no great orator, his speeches were lengthy and verbose, according to Schwarz. Additionally, the Catholic with his Palatinate dialect, a folksy man who had culture but was no intellectual \u2013 to North German journalists (like from the important newspapers made in Hamburg, including weeklies \"Der Spiegel\" and \"Die Zeit\") he just felt foreign, more than any previous CDU chairman.\nUnlike many politicians of his era, including predecessors Helmut Schmidt and Willy Brandt, successor Gerhard Schr\u00f6der or rival Franz Josef Strauss, Kohl was never regarded as charismatic or media-savvy and many of his peculiar coinings were heavily lampooned and criticised. Nonetheless, many of them have entered the general lexicon despite or perhaps because of attempts by his opponents to mock them. Examples of \"Kohlisms\" that have gained some currency include his description of the 1982 change in government as \"geistig-moralische Wende\u200a\" (\"spiritual and moral turnaround\") or the \"Grace of late birth\" (\"\"Gnade der sp\u00e4ten Geburt\u200a\") meaning that Kohl, born in 1930, was only involved in the war as a Flakhelfer and escaped the possibility of involvement in Nazi atrocities by virtue of being too young at the time. Another frequently mocked turn of phrase by Kohl was his prediction the New States of Germany would soon turn into \"bl\u00fchende Landschaften\u200a\"\" (\"flowering landscapes\") with some cynics pointing out that former industrial sites were indeed turning into flowering meadows in the course of ecological succession as a consequence of deindustrialisation.\nKohl was a true \"people person\" and loved to be in the company of others. His tremendous memory of people and their lives helped him to build up his networks in the Christian Democratic Union, in government and abroad. In a study of German chancellorship as political leadership, Henrik Gast highlights how much time Kohl invested in personal relationships even with the backbenchers in the Bundestag and also party officials up to the local level. This worked because it fitted Kohl's character and was authentic.\nKohl knew that all these people were the basis of his political power and that he needed their loyalty and personal affection. He could also be rude to subordinates and assistants, and confront political adversaries. \"He was capable of both \u2013 being empathetic and being extremely confrontational! If you did not do what he wanted, empathy was over!\", as Gast quotes a federal minister of Kohl's own party. There was also a difference between the younger Kohl and the chancellor in his later years. A parliamentary state secretary recalled: \"A sense of tact and politeness? The early and the later Kohl \u2013 that was a tremendous difference. In the early years, he had all of that, in the later years no more.\"\nPersonal life.\nFamily.\nOn 27 June 1960, Kohl married Hannelore Renner, after he had already asked for her hand in marriage in 1953, delaying the ceremony until he was financially stable. Both had known each other since 1948 when they met in a dancing class. They had two sons, Walter Kohl (born 1963) and Peter Kohl (born 1965). Hannelore Kohl had studied languages and spoke fluent French and English; during her husband's political career, she was an important adviser to him, especially on world affairs. She was a steadfast advocate of German reunification even before it seemed feasible and of NATO and Germany's alliance with the United States. They shared a love for German food: his commentary enhanced the cookbook \"A Culinary Voyage Through Germany\" that she edited.\nBoth sons were educated in the United States, at Harvard University and MIT, respectively. Walter Kohl worked as a financial analyst with Morgan Stanley in New York City and later founded a consulting firm with his father in 1999. Peter Kohl worked as an investment banker in London for many years. Walter Kohl was formerly married to the business administration academic Christine Volkmann and they have a son, Johannes Volkmann; he is now married to the Korean-born Kyung-Sook Kohl n\u00e9e Hwang. Peter Kohl is married to the Turkish-born investment banker Elif S\u00f6zen-Kohl, the daughter of a wealthy Turkish industrialist, and they have a daughter, Leyla Kohl (born 2002).\nOn 5 July 2001, his wife, Hannelore, died by suicide; she had suffered from photodermatitis for many years.\nSecond marriage, 2008\u20132017.\nWhile in hospital in 2008 after suffering serious head trauma, Kohl, then aged 78, married Maike Richter, a former Chancellery employee who was 44 years old; they had no children. For the entire duration of this marriage, Kohl had a brain injury, was barely able to speak, and was wheelchair-bound. According to Helmut Kohl's son Peter Kohl, Helmut Kohl did not intend to marry Richter and had stated this clearly; \"then came the accident and a loss of control,\" Peter Kohl said, suggesting that Richter had pressured his then seriously ill father into marrying her. Richter has been severely criticised in Germany, by Kohl's children, former friends and by German media. Following his new marriage, Kohl became estranged from his two sons and his grandchildren, and his sons said their father was kept \"like a prisoner\" by his new wife. His children and grandchildren were also prevented from seeing him by his new wife for the last six years of his life. In his biography of his mother, Peter Kohl wrote about the only time he had visited Richter's apartment, which he described as \"a kind of private Helmut Kohl museum\" full of Helmut Kohl photographs and artefacts everywhere; \"the whole thing looked like the result of a staggering, meticulous collecting for the purpose of hero worship, as we know it from reports on stalkers,\" Kohl wrote. Jochen Arntz criticised Maike Richter in the \"S\u00fcddeutsche Zeitung\" in 2012 for building a \"wall\" around Helmut Kohl and controlling him; as a result he had also become estranged from many former friends disliked by his new wife. Kohl biographer Heribert Schwan describes Richter as \"more than conservative, rather German nationalist,\" and said she insists on the right to \"interpretational sovereignty\" in relation to Kohl's life and that she has insisted on many proven falsehoods. It caused a scandal when Richter denied Kohl's sons and grandchildren entry to Helmut Kohl's house, the sons' childhood home, after Kohl's death. Richter was also criticised for attempting to take full control of Kohl's funeral, and for trying to prevent Chancellor Merkel from speaking at the ceremony in Strasbourg. Richter wanted Hungarian prime minister Viktor Orb\u00e1n, who has fiercely criticised Merkel's refugee policies, to speak instead; she only relented when told it would cause a scandal.\nHonours and awards.\nHelmut Kohl received numerous awards and accolades, as well as honorary titles such as doctorates and citizenships. Among others, he was a joint recipient of the Charlemagne Prize with French president Fran\u00e7ois Mitterrand for their contribution to Franco-German friendship and the European Union. In 1996, Kohl received the Prince of Asturias Award in International Cooperation from Felipe of Spain. In 1998, Kohl was named Honorary Citizen of Europe by the European heads of state or government for his extraordinary work for European integration and cooperation, an honour previously only bestowed on Jean Monnet. After leaving office in 1998, Kohl became the second person after Konrad Adenauer to receive the Grand Cross in Special Design of the Order of Merit of the Federal Republic of Germany. He received the Presidential Medal of Freedom from President Bill Clinton in 1999.\nDeath, European act of state and funeral.\nKohl died at 9:15\u00a0a.m. on Friday, 16 June 2017 in the Oggersheim district of Ludwigshafen, his home town, aged 87, of natural causes.\nKohl was honoured with an unprecedented European act of state on 1 July in Strasbourg, France. A Catholic requiem mass was subsequently celebrated in Speyer Cathedral. Kohl was interred in the Cathedral Chapter Cemetery (\"\") in Speyer, directly adjacent to the Konrad Adenauer Park and a few hundred metres to the northwest of the cathedral. It was reported that Kohl had himself chosen the burial location in the late summer of 2015 when his health began to deteriorate.\nNo member of the Kohl family\u2014Kohl's children and grandchildren\u2014participated in any of the ceremonies, owing to a feud with Kohl's controversial second wife Maike Kohl-Richter, who had among other things barred them from paying their respects to him at his house, ignored their wish for a ceremony in Berlin and their wish that Kohl should be interred alongside his parents and his wife of four decades Hannelore Kohl in the family tomb.\nTributes.\nChancellor Angela Merkel, speaking from the German Embassy in Rome, said that \"this man who was great in every sense of the word\u2014his achievement, his role as a statesman in Germany at its historical moment\u2014it's going to take a while until we can truly assess what we have lost in his passing.\" She lauded Kohl's \"supreme art of statesmanship in the service of people and peace\" and noted that Kohl had also changed her own life decisively.\nPope Francis lauded Kohl as \"a great statesman and committed European [who] worked with farsightedness and devotion for the good of the people in Germany and in neighbouring European countries.\"\nThe 14th Dalai Lama praised Kohl as \"a visionary leader and statesman\" and said he had \"great admiration for Chancellor Kohl's steady leadership when the Cold War came to a peaceful end and the reunification of Germany became possible.\"\nFlags were flown at half-staff at the European Commission headquarters in Brussels. Commission president Jean-Claude Juncker lauded Kohl as \"a great European.\" He called Kohl \"my mentor, my friend, the very essence of Europe.\" The President of the European Council, Donald Tusk, called Kohl \"a friend and a statesman, who helped to reunify Europe.\"\nFormer US president George H. W. Bush lauded Kohl as \"a true friend of freedom\" and \"one of the greatest leaders in post-War Europe.\" Former US president Bill Clinton said he was \"deeply saddened\" by the death of \"my dear friend\" whose \"visionary leadership prepared Germany and all of Europe for the 21st century.\" US president Donald Trump said Kohl was \"a friend and ally to the United States\" and that \"he was not only the father of German reunification, but also an advocate for Europe and the transatlantic relationship. The world has benefited from his vision and efforts. His legacy will live on.\" Former US secretary of state James Baker said Kohl's death meant \"Germany has lost one of its greatest leaders, the United States has lost one of its best friends and the world has lost a ringing voice for freedom,\" and that Kohl \"more than anyone at the end of the Cold War [...] was the architect of the reunification of Germany\" which had \"brought freedom to millions and has helped make Europe safer and more prosperous.\"\nFrench president Emmanuel Macron called Kohl a \"great European\" and \"an architect of united Germany and Franco-German friendship.\" Belgian prime minister Charles Michel called Kohl \"a true European\" who \"will be greatly missed.\" Dutch prime minister Mark Rutte said Kohl was \"a great statesman\" who had shaped European history. Spanish prime minister Mariano Rajoy lauded Kohl's role in European history and in the German reunification. Polish prime minister Beata Szyd\u0142o called Kohl \"an outstanding figure and statesman, a great politician in exceptional times\". Italian president Sergio Mattarella called Kohl one of Europe's founding fathers, and said that \"he who was, rightly, described as 'the Chancellor of Reunification', worked with far-sightedness and determination, in years marked by deep and epochal changes in world equilibria, to give back unity to his country in the framework of the great project of European integration. As an authentic statesman, he knew how to combine pragmatism and a capacity of vision, furnishing a courageous contribution not only to the fall of the Berlin Wall and the reunification of Germany, but also to overcoming the dramatic divisions which, for decades, had torn Europe.\" Former Italian prime minister and President of the European Commission Romano Prodi called Kohl \"a giant of a united Europe.\" Hungarian prime minister Viktor Orb\u00e1n called Kohl the \"great old man\" of European politics and \"Hungary's friend\".\nFormer British prime minister John Major said Kohl was \"a towering figure in German and European history\" who \"entrenched Germany in a wider Europe, in the hope of achieving a unity and peace that the continent had never known before. This required great political strength and courage \u2013 both of which qualities Helmut had in abundance.\" British prime minister Theresa May called Kohl \"a giant of European history\" and said that \"I pay tribute to the role he played in helping to end the Cold War and reunify Germany. We have lost the father of modern Germany.\"\nFormer Soviet president Mikhail Gorbachev said that \"it was real luck that at that difficult time [1989\u20131990] leading nations were headed by statesmen with a sense of responsibility, adamant about defending the interests of their countries but also able to consider the interests of others, able to overcome the barrier of prevailing suspicion about partnership and mutual trust. The name of this outstanding German politician will stay in the memory of his compatriots and all Europeans.\" Russian president Vladimir Putin said \"I was lucky to know Helmut Kohl in person. I profoundly admired his wisdom and the ability to make well-considered, far-reaching decisions even in the most difficult situations.\" He called Kohl a \"highly reputed statesman, one of the patriarchs of European and world politics.\"\nNATO secretary-general Jens Stoltenberg said Kohl was \"a true European\" and the \"embodiment of a united Germany in a united Europe.\" UN secretary-general Ant\u00f3nio Guterres said Kohl had \"played an instrumental role in the peaceful reunification of his country\" and that \"today's Europe is a product of his vision and his tenacity, in the face of enormous obstacles.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41898", "revid": "11952314", "url": "https://en.wikipedia.org/wiki?curid=41898", "title": "Modern Algebra", "text": ""}
{"id": "41901", "revid": "48610686", "url": "https://en.wikipedia.org/wiki?curid=41901", "title": "Helmut Schmidt", "text": "Chancellor of Germany from 1974 to 1982\nHelmut Heinrich Waldemar Schmidt (; 23 December 1918 \u2013 10 November 2015) was a German politician and member of the Social Democratic Party of Germany (SPD), who served as the chancellor of West Germany from 1974 to 1982. He was the longest lived chancellor in German history and had the longest post-chancellorship, at over 33 years.\nBefore becoming chancellor, he served as the minister of defence (1969\u20131972) and the minister of finance (1972\u20131974) in the government of Willy Brandt. In the latter role he gained credit for his financial policies. He had also briefly been minister of economics and acting foreign minister.\nAs chancellor, he focused on international affairs, seeking \"political unification of Europe in partnership with the United States\". He was an energetic diplomat who sought European co-operation and international economic co-ordination. He was re-elected chancellor in 1976 and 1980, but his coalition fell apart in 1982 with the switch by his coalition allies, the Free Democratic Party.\nHe retired from Parliament in 1986, after clashing with the SPD's left wing, which opposed him on defence and economic issues. In 1986, he was a leading proponent of the European monetary union and a European Central Bank.\nBackground, family, early life and education.\nHelmut Schmidt was the elder of two sons to Ludovica Koch (10 November 1890 \u2013 29 November 1968) and Gustav Ludwig Schmidt (18 April 1888 \u2013 26 March 1981) in Barmbek, a working-class district of Hamburg, in 1918. Schmidt studied at Hamburg Lichtwark School, graduating in 1937. Schmidt's father was born the biological son of a German Jewish banker, Ludwig Gumpel, and a Christian waitress, Friederike Wenzel, and then covertly adopted, although this was kept a family secret for many years. This was confirmed publicly by Schmidt in 1984, after Val\u00e9ry Giscard d'Estaing revealed the fact to journalists, apparently with Schmidt's assent. Helmut Schmidt was a non-practising Protestant.\nSchmidt was a group leader (Scharf\u00fchrer) in the Hitler Youth organisation until 1936, when he was demoted and sent on leave because of his anti-Nazi views. However, documents from 1942 praise his \"Impeccable national socialist [Nazi] behaviour\", and in 1944 his superiors mentioned that Schmidt \"stands the ground of national socialist ideology, knowing that he must pass it on.\" On 27 June 1942, he married his childhood sweetheart Hannelore \"Loki\" Glaser (3 March 1919 \u2013 21 October 2010). They had two children: Helmut Walter (26 June 1944 \u2013 19 February 1945, died of meningitis), and Susanne (born 8 May 1947), who works in London for Bloomberg Television. Schmidt resumed his education in Hamburg after the war, graduating in economics and political science in 1949.\nMilitary service.\nSchmidt had planned to study without interruption. Therefore, he volunteered at age 18 for military service in 1937. He began serving with an anti-aircraft battery of Luftwaffe at Vegesack near Bremen.\nIn World War II, after brief service on the Eastern Front during the invasion of the Soviet Union in 1941 (including the Siege of Leningrad), he returned to Germany in 1942 to work as a trainer and advisor at the Ministry of Aviation. During his service in World War II, Schmidt was awarded the Iron Cross 2nd Class.\nHe attended the People's Court as a military spectator at some of the show trials for officers involved in the 20 July plot, in which an unsuccessful attempt was made to assassinate Hitler at Rastenburg, and was disgusted by Judge Roland Freisler's conduct.\nToward the end of the war, from December 1944 onwards, he served as an Oberleutnant in the Flak artillery on the Western Front during the Battle of the Bulge and the Ardennes Offensive. He was captured by the British in April 1945 on L\u00fcneburg Heath, and was a prisoner of war until August of that year in Belgium. In 1958 Schmidt was promoted to Hauptmann of the Bundeswehr reserve.\nPost-WWII.\nSchmidt joined the Social Democratic Party of Germany (SPD) in 1946, and from 1947 to 1948 was the leader of the Socialist German Student League, the student organisation of the SPD. Upon graduating from the University of Hamburg, where he read economics, he worked for the government of the city-state of Hamburg, working in the department of Economic Policy. Beginning in 1952, under Karl Schiller, he was a senior figure heading up the (the Hamburg State Ministry for Economy and Transport).\nHe was elected to the \"Bundestag\" in 1953, and in 1957 he became a member of the SPD parliamentary party executive. A vocal critic of conservative government policy, his outspoken rhetoric in parliament earned him the nickname (\"Schmidt the Lip\"). In 1958, he joined the national board of the SPD (), and campaigned against nuclear weapons and the equipping of the Bundeswehr with such devices. He alarmed some in his party by taking part in manoeuvres as a reserve officer in the newly formed Bundeswehr. In 1962, he gave up his seat in parliament to concentrate on his tasks in Hamburg.\nSenator.\nThe government of the city-state of Hamburg is known as the Senate of Hamburg, and from 1961 to 1965, Schmidt was the : the senator of the interior. He gained a reputation as a \u2013 someone who gets things done regardless of obstacles \u2013 by his effective management during the emergency caused by the 1962 flood, during which 300 people drowned. Schmidt used all means at his disposal to alleviate the situation, even when that meant overstepping his legal authority, including employing the federal police and army units (ignoring the German constitution's prohibition on using the army for \"internal affairs\"; a clause excluding disasters was not added until 1968). Describing his actions, Schmidt said, \"I wasn't put in charge of these units \u2013 I took charge of them!\" He saved a further 1,000 lives and swiftly managed the re-housing of thousands of the homeless.\nReturn to federal politics.\nIn 1965, he was re-elected to the Bundestag. In 1967, after the formation of the Grand Coalition between the SPD and the Christian Democratic Union (CDU), he became chairman of the Social Democratic parliamentary party, a post he held until the elections of 1969. In 1968, he was elected deputy party chairman, a post that he held until 1983. Unlike Willy Brandt and Gerhard Schr\u00f6der, he never became chairman of the party.\nIn October 1969, he entered the government of Willy Brandt as defense minister. During his term in office, the military conscription time was reduced from 18 to 15 months, while at the same time increasing the number of young men being conscripted. Additionally, Schmidt decided to introduce the Bundeswehr universities in Hamburg and Munich to broaden the academic education of the German officer corps, and the situation of non-commissioned officers was improved. In July 1972, he succeeded Karl Schiller as Minister for Economics and Finance, but in November 1972, he relinquished the Economics department, which was again made a separate ministry. Schmidt remained Minister of Finance and faced the prospect of rising inflation. Shortly before the Oil Shock of 1973, which rattled Britain and the United States, Schmidt agreed that European currencies should be floated against the US dollar. He remained in charge of finance until May 1974.\nChancellor of West Germany (1974\u20131982).\nSchmidt became Chancellor of West Germany on 16 May 1974, after Brandt's resignation in the wake of an espionage scandal. The worldwide economic recession was the main problem his administration faced, and Schmidt took a tough and disciplined line, in reduction of public spending. Schmidt was also active in improving relations with France. Together with the French President Val\u00e9ry Giscard d'Estaing, he was one of the fathers of the world economic summits, the first of which assembled in 1975. In 1975, he was a signatory of the Helsinki Accords to create the Conference for Security and Co-operation in Europe, the precursor of today's OSCE. In 1978, he helped set up the European Monetary System (EMS).\nHe remained as Chancellor after the 1976 federal election, in coalition with the liberal Free Democratic Party (FDP). He adopted a tough, uncompromising line with the indigenous Red Army Faction (RAF) extremists. In October 1977, he ordered an anti-terrorist unit of Bundesgrenzschutz policemen to end the Palestinian terrorist hijacking of a Lufthansa aircraft named \"Landshut\", staged to secure the release of imprisoned RAF leaders, after it landed in Mogadishu, Somalia. Three of the four kidnappers were killed during the assault on the plane, but all 86 passengers were rescued unharmed.\nSchmidt was re-elected as Chancellor in November 1980. Concerned about the Soviet invasion of Afghanistan, and the Soviet superiority regarding missiles in Central Europe, Schmidt issued proposals resulting in the NATO Double-Track Decision, concerning the deployment of medium-range nuclear missiles in Western Europe, should the Soviets not disarm. This decision was unpopular with the German public. A mass demonstration against the deployment mobilised 400,000 people in October 1981.\nAt the beginning of his period as chancellor, Schmidt was a proponent of Keynesian economics, and pursued expansionary monetary and fiscal policies during his tenure. Between 1979 and 1982, the Schmidt administration pursued such policies in an effort to reduce unemployment. These were moderately successful, as the fiscal measures introduced after 1977, with reductions in income and wealth taxes and an increase in the medium-term public investment programme, were estimated to have created 160,000 additional jobs in 1978\u201379, or 300,000 if additional public sector employment was included in the figure. The small reduction in the unemployment rate, however, was achieved at the cost of a larger budget deficit (which rose from 31.2 billion DM to 75.7 billion DM in 1981), brought about by fiscal expansion.\nDuring the 1970s, West Germany was able to weather the global financial storm far better than almost all the other developed countries, with unemployment and inflation kept at comparatively low levels. During the 1976 election campaign, the SPD/FDP coalition was able to win the battle of statistics, whether the figures related to employees' incomes, strikes, unemployment, growth, or public sector debts. Amongst other social improvements, old age pensions had been doubled between 1969 and 1976, and unemployment benefits increased to 68% of previous earnings.\nWhilst visiting Saudi Arabia in April 1981, Schmidt made some unguarded remarks about the Israel-Palestine conflict that succeeded in aggravating the delicate relations between Israel and West Germany. Asked by a reporter about the moral aspect of German-Israeli relations, he stated that Israel was not in a position to criticise Germany due to its handling of Palestinians, and \"That won't do. And in particular, it won't do for a German living in a divided nation and laying moral claim to the right of self-determination for the German people. One must then recognize the moral claim of the Palestinian people to the right of self-determination.\" On 3 May, Israeli Prime Minister Menachem Begin denounced Schmidt as \"unprincipled, avaricious, heartless, and lacking in human feeling\", and stated that he had \"willingly served in the German armies that murdered millions.\" Begin was also upset over remarks that Schmidt had made on West German television the previous week, in which he spoke apologetically about the suffering Germany inflicted on various nations during World War II; but made no mention of the Jews. On his flight home from Riyadh, Schmidt told his advisers that war guilt could not continue to affect Germany's foreign relations.\nSchmidt was the first world leader to call upon newly elected French president Fran\u00e7ois Mitterrand, who visited Bonn in July 1981. The two found themselves in \"complete agreement\" on foreign policy matters and relations with the United States and the Soviet Union, but differed on trade and economic issues.\nBy the end of his term, however, Schmidt had turned away from deficit spending, due to a deteriorating economic situation, and a number of welfare cuts were carried out, including smaller increases in child benefits and higher unemployment and health contributions. Large sections of the SPD increasingly opposed his security policy, while most of the FDP politicians strongly supported that policy. While representatives of the left wing of the Social Democratic Party opposed reduction of the state expenditures, the FDP began proposing a monetarist economic policy. In February 1982, Schmidt won a motion of confidence; however, on 17 September 1982, the coalition broke apart, with the four FDP ministers leaving his cabinet. Schmidt continued to lead a minority government composed only of SPD members, while the FDP negotiated a coalition with the CDU/CSU. During this time, Schmidt also headed the Ministry of Foreign Affairs. On 1 October 1982, the FDP supported a CDU-proposed constructive vote of no confidence, ousting Schmidt in favour of CDU chairman Helmut Kohl as the new chancellor. This was the only time in the history of the Federal Republic that a chancellor was removed from office in this way.\nDomestic reforms.\nAlthough Schmidt did not feel that he was in a position to substantially extend the social reforms of the Brandt Administration, due to the economic problems he encountered during his time as chancellor, a wide range of reforms were nevertheless carried out under his administration. Increases were made to pensions, which went up in numerical terms. Adjusted for changes in the annual price index, pensions went up in real terms. However, the rate of pension was not changed in 1978 (even though prices increased by 2.7%), and in 1980 and 1981 the real value of pensions fell by 1.5% and 2.3%, respectively. Improvements were made in family allowances, with monthly subsidies for children increased by over 100% in 1975.\nImprovements were made to invalidity and old-age pension provision for the unemployed, who (from 1977 onwards) were technically insured free of charge under the old-age pension and invalidity scheme. Previously, there had only existed partial and restricted coverage for the unemployed. The Law to Improve Occupational Old Age Pensions (1974) extended coverage of occupational pensions, whilst also \"co-ordinating them more closely with state pensions and setting minimum standards as regards benefit levels and the preservation of pension rights\". By 1976, as a result of this legislation, 65% of private sector employees were covered by occupational schemes, and over two-thirds of these workers were eligible for benefits equal to more than 15% of their earnings at retirement. This legislation also acquired that entitlements to occupational pensions must not expire after leaving a firm, and that occupational pensions must not be reduced as a result of receipt of benefits under the public insurance system. The Social Insurance Law for the Handicapped (1975) extended compulsory coverage to disabled persons working in special establishments for the disabled (medical benefits and cash benefits to replace earnings from work). In 1976, a new declaration of social rights was made, and in 1979, an Act was passed which lowered the pensionable age for severely disabled persons to 61 years, and to 60 years as from 1980.\nIn October 1974, a Rehabilitation Benefits Alignment Act was passed, with the intention of promoting rehabilitation of the disabled by extending certain benefits to them. To meet the need for more uniform medical treatment in rural areas and on the peripheral of cities due to a lack of panel doctors in those areas, a bill was passed in December 1976 which improved the possibilities of panel doctors' associations by ensuring that panel doctors were available to provide treatment, while also providing for planning according to need and the participation of the sickness insurances. An Act of August 1975 on criminal law reform introduced \"other forms of assistance\" such as medical advice on contraception, together with assistance pertaining to sterilisation and abortion. New assistance benefits were created in 1975 for family planning and maternity consultations, whilst a constant attendance allowance was increased. Housing renovation and energy savings legislation was introduced in 1977, while a constitutional reform of 1981 increased federal powers in health and education.\nIn July 1974, special benefits were introduced to compensate for wages not paid as a result of bankruptcy for a maximum of up to three months. Increases in income-limits for housing allowances were carried out, together with housing allowance rates, while major improvements were made in welfare provision for the elderly. By 1982, the purchasing power of the average pension was 2.5% better than in 1975. In 1975, tax allowances were replaced by child benefits, while payment for the first child was introduced. A tax relief act reduced income taxes and provided additional tax benefits for housing allowances. The Schmidt administration also introduced social policy legislation in the late 1970s, which increased family allowances (though by a smaller amount than in 1974) and maternity leave benefits. The increases in benefits under the Schmidt administration arguably had a positive impact on reducing inequalities, with the percentage of West Germans living in poverty (according to one measurement) falling between 1978 and 1982.\nUnder the law of June 1974, the residents could participate in the management of the establishment through a consultative committee. A law of June 1975 amended the Employment Protection Law and the Law on the provision of temporary workers which improved the legal protection of temporary migrant workers in West Germany. A law of December 1975 gave the right to claim under the sickness insurance scheme for medical consultations for family planning purposes. A law of May 1975 extended social security to disabled persons according to various procedures.\nA law of April 1976 on youth employment limited working hours to 40 hours in a 5-day week, raised the minimum working age from 14 to 15, increased leave, improved conditions for release from work for day attendance at vocational training school and for periods of weeks under the block release system, and improved protection at work by restrictions on employment in dangerous or unhealthy work. A law on protection against dismissal was amended by abolishing the minimum age limit of 18, so that young workers under eighteen were now also protected against dismissal. The Ministry for Youth, Family Affairs and Health encouraged a pilot scheme, of a scientific nature, aimed at promoting the development of qualified advisory services on family planning, sexual problems and problems linked with pregnancy. A regulation of June 1976 laid down detailed rules governing 'aid to overcome particular social difficulties'. This measure was specially aimed at marginal social groups, such as former convicts and the homeless, and consisted of providing information, personal guidance, help in obtaining and maintaining a home and in obtaining and keeping a job, in addition to guidance as regards training and the organization of leisure time. The general section of the Social Code, which came into effect in January 1976, introduced basic measures concerning the social services. It laid down an obligation to establish the services and institutions needed by the population and to provide them with information and advice on their social rights. These provisions had already had certain effects, in particular a considerable growth in home help services and social centres. A regulation in application of a 1974 law on old people's homes and adult hostels was introduced, according to which compulsory consultative committees could be set up by the residents to ensure their participation in the running of these establishments in a greater measure than in the past. A law passed in August 1974 supplemented the protection provided for handicapped people under a law passed during the Brandt Administration in April 1974 by providing that, henceforth, the benefits for the purposes of medical and occupational rehabilitation would be the same for all the categories of persons concerned: war victims, the sick, the victims of industrial accidents, congenitally handicapped persons: a total of about 4 million persons in all.\nThe 1976 Act for the Promotion of Urban Development and the 1977 Housing Modernisation Act, together with the 1971 Act for the Promotion of Urban Development passed by the Brandt Administration, enabled most West German cities by the end of the Seventies to introduce programmes aimed at renovating their pre-war residential areas. Additional tax reforms were introduced that lowered the tax burden on low-income households, and which played an important role \"in pre-empting a real decline in the income and purchasing power of workers\". A law was passed to encourage low-income home ownership, while 250 million marks was provided in 1978 for the promotion of sports and physical education. That same year, entitlement to educational allowances was extended to all tenth-grade pupils in vocational education.\nThe Introductory Tax Reform Law (1974) increased bad weather payments, part-time workers' benefits and insurance benefits to 68% of net wages, fixed special benefits during vocational training at 90% of net earnings, increased assistance benefits to 58% of net earnings, and abolished special family benefits \"in favour of the inclusion of the unemployed under general child allowance scheme\". A special tax credit was introduced in 1978 in cases of particular financial burden due to children, while a substantial increase in the child allowance was made in 1979. Several policy changes were carried out between 1976 and 1982, such as tax credits and family allowances, which compensated unions for wage restraint and \"guaranteed the maintenance of a constant income level for employed persons and their families\". Increases were made in child benefits, which rose on a regular basis (particularly for families with more than one child) for most of the years that the Schmidt Administration was in office.\nVarious measures were also carried out to mitigate the effects of unemployment. Employment creation schemes were introduced to help young workers. The Training Opportunities Act (1976) helped (over a four-year period) to increase the number of vocational training places from 450,000 to 630,000 a year. In 1976, a provisional law was introduced to boost the number of apprentices, which reduced the numbers of young people out of work. An experimental retraining programme was launched on the shop floor (lasting from 1979 to 1981), which benefited 45,680 people.\nIn June 1974, a reformed food law was passed into law, which aimed to safeguard consumers from physical harm. The Students' Sickness Insurance Law (1975) extended compulsory coverage to students (medical benefits only), while the Artists' Social Insurance Law (1981) introduced compulsory insurance for artists below a certain income-limit. The Detergents Law (1975) and the Effluency Levies Act (1978) were passed to encourage environmental protection. In 1975, the allowable duration of unemployment benefit payment was extended to twenty-four months during periods of general recession. The 1976 law on standard terms of sale gave consumer groups the right to file suits against companies employing unfair terms of sale. The Higher Education Framework Act of 1976 pronounced that scientific continuing education was a task to be implemented by the institutions of the system of higher education, thus exceeding their traditional tasks of research and lecturing. In 1977, an \"investment programme for the future\" was decided upon by the Schmidt Administration, which provided DM 16 thousand million for the improvement of the transport system, an efficient and ecological energy supply, provisions for water supply, vocational training, and the safeguarding of the environment.\nUnder a regulation of December 1976, four new occupational diseases were recognised. To expand training opportunities for girls, a pilot scheme was launched in 1978 to open up certain skilled industrial and technical occupations to them. Laws restricting the access of migrant workers to certain regions were repealed in 1977, and the existing provisions were made more flexible in order to allow the children of migrant workers who had entered the Federal Republic of Germany in 1975/76 access to employment. Legislation governing old people's homes and adult assistance establishments was further supplemented by two regulations, one imposing minimum requirements concerning premises, and the other laying down rules for financial management to ensure that residents were not financially exploited.\nThe Fifth Amendment of July 1979 to the Employment Promotion Law provided among other things for an improvement in conditions governing financial support towards basic vocational training for unemployed young people with at least one year's vocational experience, the expansion of training activities for jobs in which there is a shortage of skilled workers and easier access to further vocational training facilities for problem groups (such as the unskilled, the unemployed, and women generally). In 1979, the Federal Minister for Education and Science made funds available for a new further education establishment to train instructors. Under a law amending the law respecting technical working media and the Industrial Code of August 1979, machines and equipment which had been voluntarily submitted for testing and passed by an established body may bear the marking 'GS' (=safety-tested). For medical equipment, the Federal Minister of Labour and Social Affairs was authorized to issue orders containing further safety provisions, while the resale of hazardous equipment and its display at exhibitions may be prohibited in future by factory inspectors even in the case of trading companies.\nIn 1979 DM 219 million was set aside for about 80,000 dwellings under the modernisation programme for dwellings worthy of preservation run jointly by the Federal authorities and the individual (50% of this money was earmarked for modernization priority areas). In addition, DM 2,350 million was made available under a five-year programme to improve the housing stock. Loans and higher tax rebates were also used to encourage modernisation of dwellings and energy-saving measures. 577 slum clearance and urban development schemes in 459 municipalities were also accorded financial support amounting to DM 183.5 million under a law on the promotion of urban development. A law of October 1979 granted a lump-sum allowance for the winter of 1979/80 to help low-income groups to meet the additional outlay incurred by the rise in fuel costs. In August 1979, a programme was adopted for foreign refugees, with resources allocated for aid concerning information, legal advice, psycho-social and medical assistance and for measures to facilitate the integration of refugees or their emigration to other countries.\nUnder a law of July 1980, a farmer's surviving spouse wishing to continue working on the farm could obtain a helper or temporary aid from the agricultural pension fund. Any spouse choosing not to do so was entitled to a survivor's allowance if he or she was no longer able to find suitable paid employment either for reasons of age (over 45) or because there were children to bring up. In other cases, the allowance was designed to facilitate reintegration into working life. This allowance guaranteed the spouse protection under the agricultural sickness insurance scheme, which also covered self-employed fishermen and beekeepers.\nA special programme was introduced, specially designed for young people who, because of their poor level of education and language ability, were unable to find a suitable job or training place. The young people were offered a one-year full-time course of training to qualify them for a training place or job, and in September 1980, approximately 15,000 young people were participating in these courses. From 1980 onwards, parents could deduct the cost of day care for their children (in day nurseries and nursery schools in particular) from their taxable income up to an annual maximum of DM 600 or DM 1,200 depending on whether the income of a single parent or that of a married couple was involved. Major additions were also made to the regulations on dangerous substances, while comprehensive new regulations concerning installations requiring supervision were introduced. The Federal Ministry for Youth, Family Affairs and Health gave particular attention to assisting parents in assuming their educational responsibilities towards their children. For instance, special 'letters to parents' were distributed free of charge to parents of children under 8, with some 3 million sent in 1979. A determined effort was also made to provide better education for socially disadvantaged children by supporting pilot schemes and research projects. Public funds had been allocated from 1979 onwards to a pilot scheme entitled 'Aid to children in need' under which children's communities were set up in Berlin and G\u00fctersloh to protect and care for children who had been or were at risk of being ill-treated by their parents, while at the same time the family education and advisory services were assigned the task of educating these parents.\nIn terms of workplace rights, a \"parity\" system was introduced (although in a weakened form) on the supervisory boards of all companies employing over 2,000 workers, a reform which West German trade unions had long fought for. This law improved employee representation on the supervisory boards of companies outside the steel and coal industries. The main provision of this new piece of legislation was that in the 650 major companies that accounted for 70% of West Germany's output, employee representation on the supervisory boards rose from one-third to one-half. In 1976, the Young Persons (Protection of Employment) Act was passed, which forbade the employment of children and young persons required to attend full-time education, with minor exceptions.\nThe social protection of civil servants and judges ( and ) was standardised and improved by a law of August 1974. Under a law of May 1976, victims of acts of violence and their survivors would in future have the right to compensation in respect of the physical and economic consequences in the same manner as protection for war victims. In 1977, DM 8 million was made available by the federal government to welfare bodies to build and modernise holiday homes for families. That same year, the conditions for investment in the privately financed construction of rented dwellings were improved by the reintroduction of decreasing depreciation for buildings. In order to take the situation of the unemployed into account to the maximum possible extent in asset formation policy, certain legal provisions were amended so that in the event of unemployment, personal payments could be made to continue savings plans which entailed employers' contributions. In addition, workers who had been unemployed for a year or more could unblock savings plans before the end of the freeze without losing the financial benefits offered by the State. A new special programme with funds of DM 100 million was launched at the start of 1978 to improve training and job opportunities for the disabled. The budget of the Federal Labour Office was increased exceptionally by more than 20%, whilst special emphasis was placed on measures to promote vocational training, job creation, advanced training and retraining. The aim was to reduce the high proportion of unemployed persons lacking training and increase the chances of this group to obtain employment.\nA wide range of social liberal reforms were also carried out during Schmidt's time in office. A marriage and divorce law of 1976 instituted the principle of maintenance obligations of each economically stronger partner, That same year, a reform of naming for partners after marriage was carried out, together with a reform of marriage law, which eliminated \"moral guilt\" as a criterion for alimony payment obligations. The First Marriage Reform Law of 1976 stated that pension entitlements acquired during marriage must be shared with the economically weaker spouse following divorce. In 1977, a law was introduced which enabled married women to enter employment without the permission of their husbands, while prison reforms guaranteed inmates access to courts for any violations of their rights, limited sentences in all but the gravest cases to 15 years, and proclaimed rehabilitation to be the objective of incarceration. In 1977, a Sex Discrimination Act was passed. In 1981, a legal aid system was established to facilitate access to courts of law.\nLife after politics.\nIn 1982, along with his friend Gerald Ford, he co-founded the annual AEI World Forum. The following year he joined the nationwide weekly \"Die Zeit\" newspaper as co-publisher, also acting as its director from 1985 to 1989. In 1985, he became managing director. With Takeo Fukuda he founded the Inter Action Councils in 1983. He retired from the Bundestag in 1986. In December 1986, he was one of the founders of the committee supporting the EMU and the creation of the European Central Bank.\nContrary to the line of his party, Schmidt was a determined opponent of Turkey's bid to join the EU. He also opposed phasing out nuclear energy, something that the Red-Green coalition of Gerhard Schr\u00f6der supported. In 2007, Schmidt described the climate debate as \"hysterically overheated\". When asked about social media, Schmidt said he perceived the internet as \"threatening\". He was particularly concerned about the superficiality of communication on the web.\nSchmidt was highly critical of allowing immigration from outside of Europe, believing that people from these cultures would not integrate well. He said in a 2004 interview with Hamburger Abendblatt that \"a multicultural society can function peacefully only under a strong authoritarian state like Singapore, the cultures there all speak English and the political system is based on authority.\" In 2005, he spoke out against attempts to remedy Germany's aging population with more immigration: \"Immigration of people from East of Anatolia or from Subsaharan Africa does not solve the problem, it only creates a much bigger problem.\" In a 2010 interview with Sandra Maischberger, he said that \"Immigration from foreign civilizations creates more problems than it can bring us in terms of benefits on the labor market. Immigration from Europe is no problem, the problem starts from somewhat more eastern regions. These are different cultures, not because of their different genes or ancestry, but because of the way they were raised.\"\nOn 16 May 2014, Schmidt said the Russo-Ukrainian War was dangerous, because, \"Europe, the Americans and also Russia are behaving in a way that Christopher Clark described in his book \"The Sleepwalkers: How Europe Went to War in 1914\" that's very much worth reading, as the beginning of World War I: like sleepwalkers.\" Clark later disputed comparisons between the Russo-Ukrainian War and World War I, saying in 2022, \"The first world war began in an incredibly complex, around-the-houses way. Whereas in the case of the invasion of Ukraine, in 2014 and this year, it's quite clearly a case of the breach of the peace by just one power.\"\nSchmidt was the author of numerous books on his political life, on foreign policy, and political ethics. He made appearances in numerous television talk shows, and remained one of the most renowned political publicists in Germany until his death.\nIn his later years, Schmidt gained a positive reputation as an elder statesman across party lines in Germany.\nFriendships.\nSchmidt described the assassinated Egyptian president Anwar Sadat as one of his friends from the world of politics, and maintained a friendship with ex-president Val\u00e9ry Giscard d'Estaing of France. His circle also included former Singapore Prime Minister Lee Kuan Yew and former U.S. Secretaries of State George Shultz and Henry Kissinger. Kissinger went on record as stating that he wished to predecease Helmut Schmidt, because he would not wish to live in a world without him.\nHe was also good friends with former Canadian Prime Minister Pierre Trudeau. At the 4th G7 summit in 1978, the two discussed strategies for the upcoming Canadian federal election, and Schmidt gave him advice on economic policy. In 2011, Schmidt made a pilgrimage to the Trudeau family vault in St-R\u00e9mi-de-Napierville Cemetery, accompanied by Jean Chr\u00e9tien and Tom Axworthy.\nPersonal life.\nSchmidt admired the philosopher Karl Popper, and contributed a foreword to the 1982 \"Festschrift\" in Popper's honour.\nSchmidt was a talented pianist, and recorded piano concertos of both Mozart and Bach with German pianist and conductor Christoph Eschenbach. Schmidt recorded Mozart's piano concerto for three pianos, K. 242, with the London Philharmonic Orchestra directed by Eschenbach in 1982 with pianists Eschenbach and Justus Frantz for EMI Records (CDC 7 47473 2). In that recording, according to the CDs liner notes, Schmidt played the part written for Countess Antonia Lodron's youngest daughter Giuseppina, \"almost a beginner\" who commissioned the work. The part brilliantly \"enables any reasonably practiced amateur to participate in a performance\". The same musical notes also indicate that Schmidt and Frantz had played duets during Frantz's student days. In 1990 Schmidt joined Eschenbach, Frantz, Gerhard Oppitz and the Hamburg Philharmonic Orchestra in Deutsche Grammophon's recording of Bach's Concerto in A minor for four harpsichords, BWV 1065.\nAll his adult life, Schmidt was a heavy smoker. He was well known for lighting up during TV interviews and talk shows. On 13 October 1981, Schmidt was fitted with a cardiac pacemaker. On 24 August 2002, he suffered a heart attack and subsequently underwent bypass surgery.\nOn 25 January 2008, German police launched an inquiry after an anti-smoking initiative charged that Schmidt was defying the recently introduced smoking ban. The initiative claimed that Schmidt had been flagrantly ignoring anti-smoking laws. Despite pictures in the press, the case was subsequently dropped after the public prosecutor's office ruled that Schmidt's actions had not been a threat to public health.\nOn 6 April 2010, with a lifespan of 33,342 days, he surpassed Konrad Adenauer in terms of longevity, and at the time of his death was the oldest former chancellor in German history.\nHis wife of 68 years, Loki Schmidt, died on 21 October 2010, aged 91.\nAt the beginning of August 2012, Schmidt gave an interview on German television and revealed that at 93 years of age, he had fallen in love again. His new life partner was his associate of over 57 years, Ruth Loah (27 September 1933 \u2013 23 February 2017).\nIllness, death and state funeral.\nOn 2 September 2015, Schmidt underwent surgery for a vascular occlusion in his right leg. On 17 September, he was discharged from hospital. After initial improvement, his condition worsened again on 9 November, with his doctor saying he \"feared for the worst\". Schmidt died in his Hamburg home on the afternoon of 10 November 2015, aged 96. At the time of his death, he was the longest-lived German Chancellor.\nA state funeral for Schmidt was held on 23 November at the Protestant (Lutheran) St. Michael's Church, Hamburg, where Loki Schmidt's funeral had been held. German Chancellor Angela Merkel, in remarks to mourners, said, \"He will be missed. He was an astute observer and commentator, and it was with good reason that he had a reputation for dependability.\" Others who spoke included former U.S. Secretary of State Henry Kissinger. Speaking in German, he lauded Schmidt for \"vision and courage\", based on the principles of \"reason, law, peace and faith\", and said Schmidt had been \"a kind of world conscience\".\nAmong the 1,800 who attended were German President Joachim Gauck, former U.S. Secretary of State Henry Kissinger and former French President Val\u00e9ry Giscard d'Estaing, whose tenure in office paralleled Schmidt's as German chancellor. Other guests included former chancellor Gerhard Schr\u00f6der, former presidents Christian Wulff, Horst K\u00f6hler, Roman Herzog and Hamburg's mayor Olaf Scholz. A flag-draped coffin containing the remains of the former chancellor, also a former German defense minister, was escorted by the German Army's Wachbataillon from St. Michael's to Ohlsdorf Cemetery for a private interment ceremony. Helmut Schmidt's remains were buried there one day later, in the family grave alongside the remains of his parents and his wife, Loki.\nHonours and awards.\nHelmut Schmidt received a number of accolades. Among those offered was the Grand Cross Order of Merit of the Federal Republic of Germany, which he chose not to accept in Hanseatic tradition in line with the history of independence of Hamburg.\nIn 2003, the university of Germany's federal armed forces in Hamburg was renamed Helmut Schmidt University \u2013 University of the Federal Armed Forces Hamburg in 2003, in honour of the politician who\u00a0\u2013 as minister of defense\u00a0\u2013 had introduced mandatory academic education for German career officers.\nIn November 2016, Hamburg Airport was renamed \"Hamburg Airport Helmut Schmidt\" in his honour.\nHonorary degrees.\nThroughout his tenure as chancellor, and even thereafter, Helmut Schmidt received 24\u00a0honorary degrees. They include degrees from the British universities Oxford and Cambridge, Paris Sorbonne, the American Harvard and Johns Hopkins universities, the Belgian Katholieke Universiteit Leuven, and the Keio University in Japan.\nFoundations.\nThe Bundeskanzler-Helmut-Schmidt-Stiftung was established in 2016 by the German Bundestag as one of six non-partisan foundations commemorating politicians. It aims to honour Helmut Schmidt's historic achievements and to work on political issues Helmut Schmidt was concerned with throughout his political life and which have lost none of their relevance today. The foundation's headquarters are located in Hamburg.\nControversies over service in World War II.\nIn 2017, after Minister of Defence Ursula von der Leyen issued an order to remove \"Wehrmacht\" memorabilia from barracks and other institutions of the \"Bundeswehr\", a photo of the young Lieutenant Helmut Schmidt in \"Wehrmacht\" uniform was removed from the military's Helmut Schmidt University in Hamburg. Although the photo is now displayed again, the initial decision has caused a debate over Schmidt's service in the \"Wehrmacht\". According to \"Der Spiegel\", von der Leyen initially distanced herself from this decision, yet after a few days, she explained that Schmidt, as Minister of Defense and later Chancellor, was important in the formation of the \"Bundeswehr\" as a democratic army, but his time in the \"Wehrmacht\" had nothing to do with this. Historian Michael Wolffsohn argues that Schmidt avoided explaining about \"what he had done between 1940 and 1945.\" He further comments that the whole Schmidt affair reveals that while the \"Bundeswehr\" is not \"a state within state\", there is an uncritical milieu in the \"Bundeswehr\" that does not correspond to the spirit of the majority in the German society and might get larger if unchecked. He recommends that the photo be displayed again, but with explanations. Theo Sommer, a prominent journalist and former Chief of Planning Staff for the Ministry of Defence, while agreeing that the military leadership should pay attention to extremism within the \"Bundeswehr\", criticizes von der Leyen for her overreaction and Wolffsohn for false representation of Schmidt's attitude. According to Sommer, Schmidt had always been frank about his service on the Eastern Front: while he denied that he had ever seen or known about mass extermination of Jews in Russia, Schmidt admitted he often had to shoot at villages and then recognized the smell of burnt flesh. Schmidt said the troops were never taught about the Geneva Conventions, and by standards of today, he would have to go to court \"a dozen times\". According to \"Der Spiegel\", Schmidt dated his departure from \"idea and practice of National Socialism\" to 1942 and his recognition of the criminal character of the regime to 1944.\nNotes and references.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41902", "revid": "48610686", "url": "https://en.wikipedia.org/wiki?curid=41902", "title": "Ludwig Erhard", "text": "Chancellor of West Germany from 1963 to 1966\nLudwig Wilhelm Erhard (; 4 February 1897 \u2013 5 May 1977) was a German politician and economist who served as the second chancellor of West Germany from 1963 until 1966. Affiliated with the Christian Democratic Union (CDU), he is known for leading the West German postwar economic reforms and economic recovery (\"Wirtschaftswunder\", German for \"economic miracle\") in his role as Minister of Economic Affairs under Chancellor Konrad Adenauer from 1949 to 1963. During that period he promoted the concept of the social market economy (\"soziale Marktwirtschaft\"), on which Germany's economic policy in the 21st century continues to be based.\nIn his tenure as Chancellor, however, Erhard lacked support from Adenauer, who remained chairman of the CDU party until 1966. Erhard failed to win the German public's confidence in his handling of a budget deficit and lacked public support for his direction of foreign policy. His popularity waned, and he resigned his chancellorship on 30 November 1966.\nEarly life.\nLudwig Erhard was born in F\u00fcrth, then in the Kingdom of Bavaria, on 4 February 1897. His father Wilhelm Erhard (born 1859) was a Catholic Church clothing store proprietor, while his mother Augusta adhered to Protestantism. Ludwig had two brothers and a sister, all of whom were raised as Protestants. Ludwig suffered from polio in his third year, resulting in a deformed right foot and forcing him to wear orthopedic shoes for the remainder of his life.\nErhard entered primary school in F\u00fcrth at the age of six in 1903 and performed poorly. In 1907, he entered F\u00fcrth's Royal Bavarian Vocational High School, where his grades were average. He received his secondary school certificate in 1913. In the following years, he was a commercial apprentice at the Georg Eisenbach textile company in Nuremberg until 1916 and worked thereafter as a retail salesman in his father's draper's shop.\nMilitary service and university.\nIn 1916, Erhard volunteered for the German military. During World War I he was transferred to the 22nd Royal Bavarian Artillery Regiment and trained as a gunner. He first served in the quiet Vosges sector on the Western Front. The regiment was then deployed in the Romanian Campaign on the Eastern Front. He personally saw little combat, but contracted typhus and was sent back to Germany. After he managed a recovery Erhard returned to his unit. He was badly wounded on his left shoulder, side and leg by an Allied artillery shell on 28 September 1918 during the Fifth Battle of Ypres. Erhard was committed to a military hospital in Recklinghausen, where he underwent seven operations until June 1919. His left arm ended up permanently shorter than his right one.\nDue to his injury he could no longer work as a draper so Erhard started learning economics in late 1919 at a business college in Nuremberg. He passed the school's exit examination on 22 March 1922 and received a degree in business administration. During his time at school, he developed a friendship with the economist and professor Wilhelm Rieger, to whom Erhard owed much of his convictions of economic liberalism. Thanks to Rieger's intervention, Erhard was able to enroll at the Goethe University Frankfurt in the autumn of 1922. He received his PhD from the university on 12 December 1925 for a dissertation finished in the summer of 1924 under Franz Oppenheimer. Oppenheimer's liberal socialist ideology had a heavy influence on Erhard, especially Oppenheimer's opposition to monopolies. In Frankfurt he married Luise Schuster, a fellow economist, on 11 December 1923. They had known each other since childhood.\nEarly career.\nAfter his graduation they moved to F\u00fcrth and he became an executive in his father's company in 1925. Erhard spent the next three years as a mostly unemployed academic. His father retired in 1928. The same year, thanks to the help of Rieger and Oppenheimer, Erhard became a part-time research assistant at the \"Institut f\u00fcr Wirtschaftsbeobachtung der deutschen Fertigware\" (Economic Observation of the German Finished Goods Industry), a marketing research institute founded by Wilhelm Rudolf Mann and . Later, he became deputy director of the institute.\nDuring World War II he worked on concepts for a postwar peace; however, officially such studies were forbidden by the Nazis, who had declared 'total war'. As a result, Erhard lost his job in 1942, but continued to work on the subject by order of the Reichsgruppe Industrie. He wrote \"War Finances and Debt Consolidation\" (orig: \"Kriegsfinanzierung und Schuldenkonsolidierung\") in 1944; in this study he assumed that Germany had already lost the war. He sent his thoughts to Carl Friedrich Goerdeler, a central figure in the German resistance to Nazism, who recommended Erhard to his comrades. Erhard also discussed his concept with Otto Ohlendorf, deputy secretary of state in the Reichsministerium f\u00fcr Wirtschaft. Ohlendorf himself spoke out for \"active and courageous entrepreneurship (\"aktives und wagemutiges Unternehmertum\")\", which was intended to replace bureaucratic state planning of the economy after the war.\nPost-war career.\nWhen the war had finished, Erhard became an economic consultant. Under the Bizone established by the American and British administration in 1947, he led the \"Sonderstelle Geld und Kredit\" (\"Special Office for Money and Credit\"), an expert commission preparing the currency reform in Germany's western zones of occupation. The commission began its deliberations in October 1947, and the following April produced the so-called Homburg plan, elements of which were adopted by the Allies in the currency reform that set the stage for the recovery of the economy.\nIn April 1948, Erhard was elected director of economics by the Bizonal Economic Council. On 20 June 1948, the Deutsche Mark was introduced. Erhard abolished the price-fixing and production controls that had been enacted by the military administration. This exceeded his authority, but he succeeded with this step. In July 1948, a group of southwest German businessmen attacked the restrictive credit policy of Erhard as Economic Director. While Erhard had designed this policy to assure currency stability and stimulate the economy via consumption, business feared the scarcity of investment capital would hinder economic recovery.\nMinister of Economic Affairs.\nIn the first free elections of the federal parliament in September 1949, Erhard was elected in a Baden-W\u00fcrttemberg district as candidate of the Christian Democratic Union. He was appointed Federal Minister for Economic Affairs, a position he would hold for the next 14 years; from 1957 to 1963 he was also the vice-chancellor of Germany. Erhard's financial and economic policies soon proved widely popular as the German economy made a miracle recovery to rapid growth and widespread prosperity in the 1950s, overcoming wartime destruction and successfully integrating millions of refugees from the east.\nA staunch believer in economic liberalism, Erhard joined the Mont Pelerin Society in 1950, and used this influential body of liberal economic and political thinkers to test his ideas for the reorganization of the West German economy. Some of the society's members were members of the Allied High Commission and Erhard was able to make his case directly to them. The Mont P\u00e9lerin Society welcomed Erhard because this gave its members a welcome opportunity to have their ideas tested in real life. Alfred M\u00fcller-Armack, the secretary of state of Erhard's ministry, helped him guide German economy with theories until the beginning of 1960s.\nLate in the 1950s, Erhard's ministry became involved in the struggle within the society between the European and the Anglo-American factions, and sided with the former. Erhard viewed the market itself as social and supported only a minimum of welfare legislation. However, Erhard suffered a series of decisive defeats in his effort to create a free, competitive economy in 1957; he had to compromise on such key issues as the anti-cartel legislation. Thereafter, the West German economy evolved into a conventional welfare state from the basis that had been already laid in the 1880s by Bismarck. According to Alfred Mierzejewski the generally accepted view is that Germany has a social market economy, that the post-war German economy has evolved since 1948, but the fundamental characteristics of that economic system have not changed, while in his opinion the social market economy had begun to fade in 1957, disappearing entirely by the late 1960s.\nErhard was also deeply critical of a bureaucratic-institutional integration of Europe on the model of the European Coal and Steel Community.\nChancellor of West Germany (1963\u20131966).\nAfter the resignation of Adenauer in 1963, Erhard was elected chancellor with 279 against 180 votes in the Bundestag on 16 October. In 1965, he was re-elected. From 1966 to 1967, he also headed the Christian Democratic Union as \"de facto\" chairman, despite the fact that he was never a member of that party (which made his election to the chairmanship irregular and void \"de jure\"), as he never formally filed a membership application despite pressure from Chancellor Adenauer. The reasons for Erhard's reluctance are unknown, but it is probable that they stemmed from Erhard's general scepticism about party politics. However, Erhard was regarded and treated as a long-time CDU member and as the party chairman by almost everyone in Germany at the time, including the vast majority of the CDU itself. The fact that he was not a member was known only to a very small circle of party leaders, and it did not become known to the public until 2007, when the silence was finally broken by Erhard's close advisor Horst W\u00fcnsche.\nDomestically, a number of progressive reforms were carried out during Erhard's time as chancellor. In the field of social security, Housing Benefit was introduced in 1965.\nForeign policy and international trips.\nErhard considered using money to bring about the reunification of Germany, which would have broken a diplomatic stalemate that had existed since the end of the Second World War regarding the status of West and East Germany. Despite Washington's reluctance, Erhard envisaged offering Nikita Khrushchev, the leader in Moscow, massive economic aid in exchange for more political liberty in East Germany and eventually for reunification. Erhard believed that if West Germany were to offer a \"loan\" worth $25 billion US to the Soviet Union (which Erhard did not expect to be repaid), then the Soviet Union would permit German reunification. Erhard did not have a specific, concrete plan in mind, however, believing that reality, and especially negotiations over such a major proposition, were too complex to be forecasted in advance with any accuracy, and as a result, he prepared to negotiate without any predetermined agenda. The acting American Secretary of State George Wildman Ball described Erhard's plan to essentially buy East Germany from the Soviet Union as \"half-baked and unrealistic.\" Erhard's objective coincided with Khrushchev rethinking his relations with West Germany. The Soviet leader secretly encouraged Erhard to present a realistic proposal for a \"modus vivendi\" and officially accepted the Chancellor's invitation to visit Bonn. However, Khrushchev fell from power in October 1964, and nothing developed out of Erhard's envisioned idea for the reunification of Germany. Perhaps more importantly, the Soviet Union had received a vast series of loans from the international money markets by late 1964, and no longer felt the need for Erhard's money.\nSupport for the American role in the Vietnam War proved fatal for Erhard's coalition. Through his endorsement of the American goal of military victory in Vietnam, Erhard sought closer collaboration with Washington and less with Paris. Erhard's policy complicated Allied initiatives toward German unification, a dilemma that the United States placed on the back burner as it focused on Southeast Asia. Erhard failed to understand that American global interests\u2014not Europe's needs\u2014dictated policy in Washington, D.C., and he rejected Adenauer's policy of fostering good relations with both the United States and France in the pursuit of West German national interest. Faced with a dangerous budget deficit in the 1966\u20131967 recession, Erhard fell from office in part because of concessions that he made during a visit to U.S. President Lyndon B. Johnson.\nErhard's fall suggested that progress on German unification required a broader approach and a more active foreign policy. Chancellor Willy Brandt in the late 1960s abandoned the Hallstein Doctrine of previous chancellors and employed a new \"Ostpolitik\", seeking improved relations with the Soviet Union and Eastern Europe and thereby laying the groundwork for d\u00e9tente and coexistence between East and West. In the 1980s Chancellor Helmut Kohl, however, reverted to Erhard's approach in collaborating with the Reagan administration in its hard-line anti-Soviet policy.\nUnder Erhard's government the Federal Republic entered into diplomatic relations with Israel in 1965.\nResignation and retirement.\nOn 26 October 1966, Minister Walter Scheel (FDP) resigned, protesting against the budget released the day before. The other ministers who were members of the FDP followed his example \u2014 the coalition was broken. On 30 November 1966, Erhard resigned. His successor was Kurt Georg Kiesinger (CDU), who formed a grand coalition with the SPD.\nErhard continued his political work by remaining a member of the West German parliament until his death in Bonn from heart failure on 5 May 1977. He was buried in his living place Gmund at the Tegernsee in Upper Bavaria. The Ludwig Erhard-Berufsschule (professional college) in Paderborn, F\u00fcrth and M\u00fcnster are named in his honour.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "41904", "revid": "12765036", "url": "https://en.wikipedia.org/wiki?curid=41904", "title": "Storage", "text": "Storage may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41905", "revid": "14383484", "url": "https://en.wikipedia.org/wiki?curid=41905", "title": "CDROM", "text": ""}
{"id": "41906", "revid": "47587808", "url": "https://en.wikipedia.org/wiki?curid=41906", "title": "Al Pacino", "text": "American actor (born 1940)\nAlfredo James Pacino ( ; ; born April 25, 1940) is an American actor. Known for his intense performances on stage and screen, Pacino is widely regarded as one of the greatest actors of all time. His career spans more than five decades, during which he has earned many accolades, including an Academy Award, two Tony Awards, and two Primetime Emmy Awards, achieving the Triple Crown of Acting. He has also received four Golden Globe Awards, a BAFTA, two Screen Actors Guild Awards, and was honored with the Cecil B. DeMille Award in 2001, the AFI Life Achievement Award in 2007, the National Medal of Arts in 2011, and the Kennedy Center Honors in 2016. Films in which he has appeared have grossed over $3 billion worldwide.\nA method actor, Pacino studied at HB Studio and the Actors Studio, where he was taught by Charlie Laughton and Lee Strasberg. Pacino went on to receive the Academy Award for Best Actor for his role in \"Scent of a Woman\" (1992). His other Oscar-nominated roles were in \"The Godfather\" (1972), \"Serpico\" (1973), \"The Godfather Part II\" (1974), \"Dog Day Afternoon\" (1975), \"...And Justice for All\" (1979), \"Dick Tracy\" (1990), \"Glengarry Glen Ross\" (1992), and \"The Irishman\" (2019). Pacino has starred in many other notable films, including \"The Panic in Needle Park\" (1971), \"Scarecrow\" (1973), \"Scarface\" (1983), \"Sea of Love\" (1989), \"The Godfather Part III\" (1990), \"Frankie and Johnny\" (1991), \"Carlito's Way\" (1993), \"Heat\" (1995), \"Donnie Brasco\", \"The Devil's Advocate\" (both 1997), \"The Insider\", \"Any Given Sunday\" (both 1999), \"Insomnia\" (2002), \"The Recruit\" (2003), \"Ocean's Thirteen\" (2007), \"Once Upon a Time in Hollywood\" (2019), and \"House of Gucci\" (2021).\nOn television, Pacino has acted in multiple productions for HBO, including \"Angels in America\" (2003) and the Jack Kevorkian biopic \"You Don't Know Jack\" (2010), winning a Primetime Emmy Award for Outstanding Lead Actor in a Miniseries or a Movie for each. Pacino starred in the Amazon Prime Video series \"Hunters\" (2020\u201323). He has also had an extensive career on stage. He is a two-time Tony Award winner, winning Best Featured Actor in a Play in \"Does a Tiger Wear a Necktie?\" (1969) and Best Actor in a Play for \"The Basic Training of Pavlo Hummel\" (1977). He has also acted as Shylock in a 2004 feature film adaptation and 2010 stage production of \"The Merchant of Venice\".\nPacino made his directorial debut with the documentary \"Looking for Richard\" (1996). He directed and starred in \"Chinese Coffee\" (2000), \"Wilde Salom\u00e9\" (2011), and \"Salom\u00e9\" (2013). In 2006, he allowed for his likeness to be used in the video game \"\". Since 1994, he has been the joint president of the Actors Studio.\nEarly life and education.\nAlfredo James Pacino was born in the East Harlem neighborhood of Manhattan, New York City, on April 25, 1940, the only child of Sicilian Italian-American parents Rose (n\u00e9e\u00a0Gerardi) and Salvatore Pacino. His father had emigrated from San Fratello. His parents divorced when he was two years old. His mother took him to the South Bronx and they lived with her parents, Kate and James Gerardi. They had emigrated from Corleone when young. Pacino's father moved to California to work as an insurance salesman and restaurateur in Covina, California.\nIn his teenage years, Pacino was known as \"Sonny\" to his friends. He had ambitions to become a baseball player and was also nicknamed \"The Actor\". He attended Herman Ridder Junior High School, but soon dropped out of most of his classes except for English. He subsequently attended the High School of Performing Arts, after gaining admission by audition. His mother disagreed with his decision and, after an argument, he left home. To finance his acting studies, Pacino took low-paying jobs as a messenger, busboy, janitor, and postal clerk, as well as once working in the mailroom for \"Commentary\".\nPacino began smoking and drinking at age nine, and used marijuana casually at age 13, but he abstained from hard drugs. His two closest friends died from drug abuse at the ages of 19 and 30. Growing up in the South Bronx, Pacino got into occasional fights and was considered something of a troublemaker at school. He acted in basement plays in New York's theatrical underground, but was rejected as a teenager by the Actors Studio a membership organization of professional actors, theater directors, and playwrights based in the Hell's Kitchen neighborhood of Manhattan. Instead, Pacino joined the HB Studio, where he met acting teacher Charlie Laughton, who became his mentor and best friend. In this period, he was often unemployed or homeless, and sometimes slept on the street, in theaters, or at a friend's home.\nIn 1962, Pacino's mother died at the age of 43. The following year, his maternal grandfather also died. Pacino recalled it as the lowest point of his life and said, \"I was 22 and the two most influential people in my life had gone, so that sent me into a tailspin.\"\nAfter four years at HB Studio, Pacino successfully auditioned for the Actors Studio. Pacino studied \"method acting\" under acting coach Lee Strasberg, who appeared with Pacino in the films \"The Godfather Part II\" and in \"...And Justice for All\". During later interviews, he spoke about Strasberg and the Studio's effect on his career. \"The Actors Studio meant so much to me in my life. Lee Strasberg hasn't been given the credit he deserves ... Next to Charlie, it sort of launched me. It really did. That was a remarkable turning point in my life. It was directly responsible for getting me to quit all those jobs and just stay acting.\" In another interview, he added, \"It was exciting to work for him [Lee Strasberg] because he was so interesting when he talked about a scene or talked about people. One would just want to hear him talk, because things he would say, you'd never heard before ... He had such a great understanding ... he loved actors so much.\"\nIn 2000, Pacino was selected as co-president of the Actors Studio, along with Ellen Burstyn and Harvey Keitel.\nIn 2025, Pacino became the first movie star to meet with Pope Leo XIV.\nCareer.\n1967\u20131971: Theater roles and film debut.\nIn 1967, Pacino spent a season at the Charles Playhouse in Boston, performing in Clifford Odets' \"Awake and Sing!\" (his first major paycheck: US$125 a week); and in Jean-Claude Van Itallie's \"America Hurrah\". He met actress Jill Clayburgh on this play. They had a five-year romance and moved back to New York City. In 1968, Pacino starred in Israel Horovitz's \"The Indian Wants the Bronx\" at the Astor Place Theatre, playing Murph, a street punk. The play opened January 17, 1968, and ran for 177 performances; it was staged in a double bill with Horovitz's \"It's Called the Sugar Plum\", starring Clayburgh. Pacino won an Obie Award for Best Actor for his role, with John Cazale winning for Best Supporting Actor and Horowitz for Best New Play. Martin Bregman saw the play and became Pacino's manager, a partnership that became fruitful in the years to come, as Bregman encouraged Pacino to do \"The Godfather\", \"Serpico\", and \"Dog Day Afternoon\". About his stage career, Pacino said, \"Martin Bregman discovered me ... I was 26, 25 ... he discovered me and became my manager. And that's why I'm here. I owe it to Marty, I really do\".\nPacino took the production of \"The Indian Wants the Bronx\" to Italy for a performance at the Festival dei Due Mondi in Spoleto. It was Pacino's first journey to Italy; he later recalled that \"performing for an Italian audience was a marvelous experience\". Pacino and Clayburgh were cast in \"Deadly Circle of Violence\", an episode of the ABC television series \"NYPD\", premiering November 12, 1968. Clayburgh at the time was also appearing on the soap opera \"Search for Tomorrow\", playing the role of Grace Bolton. Her father would send the couple money each month to help with finances.\nOn February 25, 1969, Pacino made his Broadway debut in Don Petersen's \"Does a Tiger Wear a Necktie?\" at the Belasco Theater, produced by A&amp;P heir Huntington Hartford. It closed after 39 performances on March 29, 1969, but Pacino received rave reviews and won the Tony Award on April 20, 1969. Pacino continued performing onstage in the 1970s, winning a second Tony Award for \"The Basic Training of Pavlo Hummel\" and performing the title role in \"Richard III\". In the 1980s, Pacino again achieved critical success on stage while appearing in David Mamet's \"American Buffalo,\" for which Pacino was nominated for a Drama Desk Award. Since 1990, Pacino's stage work has included revivals of Eugene O'Neill's \"Hughie\", Oscar Wilde's \"Salome\" and in 2005 Lyle Kessler's \"Orphans\". Pacino found acting enjoyable and realized he had a gift for it while studying at The Actors Studio. However, his early work was not financially rewarding. After his success on stage, Pacino made his film debut in 1969 with a brief appearance in \"Me, Natalie\", an independent film starring Patty Duke. In 1970, Pacino signed with the talent agency Creative Management Associates (CMA). Pacino made his feature film debut portraying a heroin addict in \"The Panic in Needle Park\" (1971).\n1972\u20131983: Stardom and acclaim.\nFrancis Ford Coppola cast him as Michael Corleone in what became a blockbuster Mafia film, \"The Godfather\" (1972). Although Jack Nicholson, Robert Redford, Warren Beatty, and the little-known Robert De Niro tried out for the part, Coppola selected Pacino, to the dismay of studio executives who wanted someone better known. Pacino's performance earned him an Academy Award nomination, and offered a prime example of his early acting style, described by \"Halliwell's Film Guide\" as \"intense\" and \"tightly clenched\". Pacino boycotted the Academy Award ceremony, insulted at being nominated for the Supporting Acting award, as he noted that he had more screen time than co-star and Best Actor winner Marlon Brando\u2014who also boycotted the awards, but for unrelated reasons. In 1973, Pacino co-starred in \"Scarecrow\" with Gene Hackman, which won the Palme d'Or at the Cannes Film Festival. That same year, Pacino was nominated for an Academy Award for Best Actor after starring in \"Serpico\", based on the true story of New York City policeman Frank Serpico, who went undercover to expose the corruption of fellow officers. In 1974, Pacino reprised his role as Michael Corleone in \"The Godfather Part II\", which was the first sequel to win the Best Picture Oscar; Pacino was nominated a third time for an Oscar, this second nomination for the Corleone role being in the lead category. \"Newsweek\" has described his performance in \"The Godfather Part II\" as \"arguably cinema's greatest portrayal of the hardening of a heart\".\nIn 1975, he enjoyed further success with the release of \"Dog Day Afternoon\", based on the true story of bank robber John Wojtowicz. It was directed by Sidney Lumet, who had directed him in \"Serpico\" a few years earlier, and Pacino was again nominated for Best Actor. In 1977, Pacino starred as a race-car driver in \"Bobby Deerfield\", directed by Sydney Pollack, and received a Golden Globe nomination for Best Actor \u2013 Motion Picture Drama for his portrayal of the title role. His next film was the courtroom drama \"...And Justice for All\". Pacino was lauded by critics for his wide range of acting abilities, and nominated for the Best Actor Oscar for a fourth time. He lost out that year to Dustin Hoffman in \"Kramer vs. Kramer\"\u2014a role that Pacino had declined. During the 1970s, Pacino had five Oscar nominations, including four for Best Actor for his performances in \"Serpico\", \"The Godfather Part II\", \"Dog Day Afternoon\", and \"...And Justice for All\".\nPacino's career slumped in the early 1980s; his appearances in the controversial \"Cruising\", a film that provoked protests from New York's gay community, and the comedy-drama \"Author! Author!\", were critically panned.\nHowever, his performance in \"Scarface\" (1983), directed by Brian De Palma, proved to be a career highlight and a defining role. Upon its initial release, the film was critically panned due to violent content, but later received critical acclaim. The film did well at the box office, grossing over US$45\u00a0million domestically. Pacino earned a Golden Globe nomination for his role as Cuban drug lord Tony Montana.\nIn 1983, Pacino became a major donor for The Mirror Theater Ltd, alongside Dustin Hoffman and Paul Newman, matching a grant from Laurance Rockefeller. The men were inspired to invest by their connection with Lee Strasberg, as Strasberg's daughter-in-law Sabra Jones was the founder and Producing Artistic Director of The Mirror. In 1985, Pacino offered the company his production of \"Hughie\" by Eugene O'Neill, but the company was unable to do it at the time due to the small cast. In 1985, Pacino worked on his personal project, \"The Local Stigmatic\", a 1969 off-Broadway play by the English writer Heathcote Williams. He starred in the play, remounting it with director David Wheeler and the Theater Company of Boston in a 50-minute film version. The film was not released theatrically, but was later released as part of the \"Pacino: An Actor's Vision\" box set in 2007.\n1984\u20131999: Established career.\nHis 1985 film \"Revolution\" about a fur trapper during the American Revolutionary War, was a commercial and critical failure, which Pacino blamed on a rushed production, resulting in a four-year hiatus from films. At this time Pacino returned to the stage. He mounted workshop productions of \"Crystal Clear\", \"National Anthems\" and other plays; he appeared in \"Julius Caesar\" in 1988 in producer Joseph Papp's New York Shakespeare Festival. Pacino remarked on his hiatus from film: \"I remember back when everything was happening, '74, '75, doing \"The Resistible Rise of Arturo Ui\" on stage and reading that the reason I'd gone back to the stage was that my movie career was waning! That's been the kind of ethos, the way in which theater's perceived, unfortunately.\" Pacino returned to film in 1989's \"Sea of Love\", when he portrayed a detective hunting a serial killer who finds victims through the singles column in a newspaper. The film earned solid reviews. Pacino received an Academy Award nomination for playing Big Boy Caprice in the box office hit \"Dick Tracy\" in 1990, of which critic Roger Ebert described Pacino as \"the scene-stealer\". Later in the year he followed this up in a return to one of his most famous characters, Michael Corleone, in \"The Godfather Part III\" (1990).\nIn 1991, Pacino starred in \"Frankie and Johnny\" with Michelle Pfeiffer, who co-starred with Pacino in \"Scarface\". Pacino played a recently paroled cook who begins a relationship with a waitress (Pfeiffer) in the diner where they work. It was adapted by Terrence McNally from his own off-Broadway play \"Frankie and Johnny in the Clair de Lune\" (1987), that featured Kenneth Welsh and Kathy Bates. The film received mixed reviews, although Pacino later said he enjoyed playing the part. Janet Maslin in \"The New York Times\" wrote, \"Mr. Pacino has not been this uncomplicatedly appealing since his \"Dog Day Afternoon\" days, and he makes Johnny's endless enterprise in wooing Frankie a delight. His scenes alone with Ms. Pfeiffer have a precision and honesty that keep the film's maudlin aspects at bay.\" For his portrayal of the irascible, blind U.S. Army Lieutenant Colonel Frank Slade in Martin Brest's \"Scent of a Woman\" (1992) Pacino won the Academy Award for Best Actor next year. He was also nominated for Best Supporting Actor for \"Glengarry Glen Ross\", making Pacino the first male actor ever to receive two acting nominations for two movies in the same year, and to win for the lead role.\nPacino starred alongside Sean Penn in the crime drama \"Carlito's Way\" in 1993, in which he played Carlito Brigante, a gangster released from prison with the help of his corrupt lawyer (Penn) and vows to go straight. Pacino starred in Michael Mann's \"Heat\" (1995), in which he and Robert De Niro appeared on-screen together for the first time (though both Pacino and De Niro starred in \"The Godfather Part II\", they did not share any scenes). In 1996, Pacino starred in his theatrical docudrama \"Looking for Richard\", a performance of selected scenes of William Shakespeare's \"Richard III\" and a broader examination of Shakespeare's continuing role and relevance in popular culture. The cast brought together for the performance included Alec Baldwin, Kevin Spacey, and Winona Ryder.\nPacino played Satan in the supernatural thriller \"The Devil's Advocate\" (1997) which co-starred Keanu Reeves. The film was a success at the box office, taking US$150 million worldwide. Roger Ebert wrote in the \"Chicago Sun-Times\", \"The satanic character is played by Pacino with relish bordering on glee.\" In 1997's \"Donnie Brasco\", Pacino played gangster \"Lefty\" in the true story of undercover FBI agent Donnie Brasco (Johnny Depp) and his work in bringing down the Mafia from the inside. In 1999, Pacino starred as \"60 Minutes\" producer Lowell Bergman in the multi-Oscar nominated \"The Insider\" opposite Russell Crowe, and in Oliver Stone's \"Any Given Sunday\".\n2000\u20132018: Television roles and return to Broadway.\nPacino won three Golden Globes since 2000; the first being the Cecil B. DeMille Award in 2001 for lifetime achievement in motion pictures. In 2000, Pacino starred alongside Jerry Orbach in a low-budget film adaptation of Ira Lewis' play \"Chinese Coffee\", which was released to film festivals. Shot almost exclusively as a one-on-one conversation between two main characters, the project took nearly three years to complete and was funded entirely by Pacino. \"Chinese Coffee\" was included with Pacino's two other rare films he was involved in producing, \"The Local Stigmatic\" and \"Looking for Richard\", on a special DVD box set titled \"Pacino: An Actor's Vision\", which was released in 2007. Pacino produced prologues and epilogues for the discs containing the films. Pacino turned down an offer to reprise his role as Michael Corleone in the computer game version of ' (2006). As a result, Electronic Arts was not permitted to use Pacino's likeness or voice in the game, although his character does appear in it. He did allow his likeness to appear in the video game adaptation of 1983's \"Scarface\", the quasi-sequel '.\nIn October 2002, Pacino starred in Bertolt Brecht's \"The Resistible Rise of Arturo Ui\" for the National Actor's Theater and Complicite. Directed by Simon McBurney, the production starred a host of Hollywood names, including John Goodman, Charles Durning, Tony Randall, Steve Buscemi, Chazz Palminteri, Paul Giamatti, Jacqueline McKenzie, Billy Crudup, Lothaire Bluteau, Dominic Chianese, and Sterling K. Brown. The production was a critical success in which \"Pacino grabs and holds the attention like a coiled spring about to snap. He is all brooding menace and crocodile grimace, butchering his way to the top with unnervingly sinister glee.\" Director Christopher Nolan worked with Pacino on \"Insomnia\", a remake of the Norwegian film of the same name, co-starring Robin Williams. \"Newsweek\" stated that \"he [Pacino] can play small as rivetingly as he can play big, that he can implode as well as explode\". The film and Pacino's performance were well received, gaining a favorable rating of 93 percent on the review aggregation website Rotten Tomatoes. The film did moderately well at the box office, taking in $113\u00a0million worldwide. His next film, \"S1m0ne\", however, did not receive much critical praise or box office success.\nHe played a publicist in \"People I Know\" (2002), a small film that received little attention despite Pacino's well-received performance. Rarely taking a supporting role since his commercial breakthrough, he accepted a small part in the critical and box office flop \"Gigli\", in 2003, as a favor to director Martin Brest. \"The Recruit\", released in 2003, featured Pacino as a CIA recruiter and co-stars Colin Farrell. The film received mixed reviews, and has been described by Pacino as something he \"personally couldn't follow\". Pacino next starred as lawyer Roy Cohn in the 2003 HBO miniseries \"Angels in America\", an adaptation of Tony Kushner's Pulitzer Prize winning play of the same name. For this performance, Pacino won his third Golden Globe, for Best Performance by an Actor, in 2004.\nPacino starred as Shylock in Michael Radford's 2004 film adaptation of \"The Merchant of Venice\". Critics praised him for bringing compassion and depth to a character traditionally played as a villainous caricature. In \"Two for the Money\", Pacino portrays a sports gambling agent and mentor for Matthew McConaughey, alongside Rene Russo. The film was released on October 8, 2005, to mixed reviews. Desson Thomson wrote in \"The Washington Post\", \"Al Pacino has played the mentor so many times, he ought to get a kingmaker's award\u00a0... the fight between good and evil feels fixed in favor of Hollywood redemption.\" On October 20, 2006, the American Film Institute named Pacino the recipient of the 35th AFI Life Achievement Award. On November 22, 2006, the University Philosophical Society of Trinity College Dublin awarded Pacino the Honorary Patronage of the Society.\nPacino starred in Steven Soderbergh's \"Ocean's Thirteen\" (2007), alongside George Clooney, Brad Pitt, Matt Damon, Elliott Gould, and Andy Garc\u00eda, as the villain Willy Bank, a casino tycoon targeted by Danny Ocean and his crew. The film received generally favorable reviews. \"88 Minutes\" was released on April 18, 2008, in the United States, after having been released in various other countries in 2007. The film co-starred Alicia Witt and was critically panned, although critics found fault with the plot, and not Pacino's acting. In \"Righteous Kill\", Pacino and Robert De Niro co-star as New York detectives searching for a serial killer. The film was released to theaters on September 12, 2008. While it was an anticipated return for the two stars, it was not well received by critics.\nPacino returned to the stage in the summer of 2010, playing Shylock in the Shakespeare in the Park production, \"The Merchant of Venice\". The acclaimed production moved to Broadway at the Broadhurst Theatre in October, earning US$1\u00a0million at the box office in its first week. The performance also garnered him a Tony Award nomination for Best Leading Actor in a Play. Pacino played Jack Kevorkian in an HBO Films biopic titled \"You Don't Know Jack\", which premiered April 2010. The film is about the life and work of the physician-assisted suicide advocate. The performance earned Pacino his second Emmy Award for lead actor and his fourth Golden Globe award. He co-starred as himself in the 2011 comedy film \"Jack and Jill\". The film was panned by critics, and Pacino \"won\" the Golden Raspberry Award for Worst Supporting Actor at the 32nd ceremony. Elaborating on his decision to join the cast of the film, he stated: \"It came at a time in my life that I needed it, because it was after I found out I had no more money. My accountant [Kenneth I. Starr] was in prison, and I needed something quickly. So I took (\"Jack and Jill\".)\"\nHe was presented with Jaeger-LeCoultre Glory to the Filmmaker Award on September 4, 2011, prior to the premiere of \"Wilde Salom\u00e9\", a 2011 American documentary-drama film written, directed by and starring Pacino. Its US premiere on the evening of March 21, 2012, before a full house at the 1,400-seat Castro Theatre in San Francisco's Castro District, marked the 130th anniversary of Oscar Wilde's visit to San Francisco. The event was a benefit for the GLBT Historical Society. Pacino, who plays the role of Herod in the film, describes it as his \"most personal project ever\". In February 2012, President Barack Obama awarded Pacino the National Medal of Arts. Pacino starred in the 30th-anniversary Broadway revival of David Mamet's play, \"Glengarry Glen Ross\", which ran from October 2012 to January 20, 2013. He starred on Broadway in \"China Doll\", a play written for him by Mamet, which opened on December 5, 2015, and closed on January 21, 2016, after 97 performances. The previews were done in October 2015.\nPacino starred in a 2013 HBO biographical picture about record producer Phil Spector's murder trial, titled \"Phil Spector\". He took the title role in the comedy-drama \"Danny Collins\" (2015). His performance as an aging rock star garnered him a Golden Globe Award for Best Actor \u2013 Motion Picture Musical or Comedy nomination. In 2016, Pacino received the Kennedy Center Honor. The tribute included remarks by his former costars Sean Penn, Kevin Spacey, Bobby Cannavale and Chris O'Donnell. In September 2012, \"Deadline Hollywood\" reported that Pacino would play the former Penn State University football coach Joe Paterno in the television film \"Paterno\" based on a 2012 biography by sportswriter Joe Posnanski. \"Paterno\" premiered on HBO on April 7, 2018.\n2019\u2013present.\nPacino starred alongside Brad Pitt and Leonardo DiCaprio in Quentin Tarantino's comedy-drama \"Once Upon a Time in Hollywood\", which was released on July 26, 2019. Later in 2019, Pacino played Teamsters chief Jimmy Hoffa, alongside Robert De Niro and Joe Pesci, in Martin Scorsese's Netflix film \"The Irishman\", based on the 2004 book \"I Heard You Paint Houses\" by Charles Brandt. This was the first time Pacino was directed by Scorsese, and he received a Best Supporting Actor nomination at the 92nd Academy Awards\u2014his ninth to date. Pacino's performance received positive reviews. Peter Bradshaw described it as \"glorious\" in \"The Guardian\". Justin Chang wrote, \"De Niro, Pesci and Pacino are at the top of their game, in part because they aren't simply rehashing the iconic gangster types they've played before.\"\nIn February 2020, Pacino starred as Meyer Offerman, a fictional Nazi hunter, in the Amazon Prime Video series \"Hunters\". This is Pacino's first television series since \"Angels in America\" (2003). \"Hunters\" was renewed for a second season in August 2020. In 2021, Pacino played Aldo Gucci in Ridley Scott's \"House of Gucci\". The film received mixed to positive reviews, with Pacino's performance being highlighted as a standout, along with Lady Gaga's and Jared Leto's. That same year, he played the lead defense attorney in \"\".\nIn 2024, Pacino starred in \"Mod\u00ec, Three Days on the Wing of Madness\", a film about Amedeo Modigliani, which he co-produced alongside Johnny Depp and Barry Navidi. The film is based on a play by Dennis McIntyre, which was previously adapted for the 2004 film of the same name. Principal photography commenced in September 2023. On March 10, 2024, Pacino presented the Academy Award for Best Picture at the 96th Academy Awards.\nIn 2025, Pacino appeared alongside Robert De Niro in Moncler's \"Warmer Together\" fashion campaign.\nPersonal life.\nRelationships.\nPacino has four children. The eldest, Julie Marie (born October 16, 1989), is his daughter with acting coach Jan Tarrant. He has twins, son Anton James and daughter Olivia Rose (born January 25, 2001), with actress Beverly D'Angelo, with whom he had a relationship from 1997 until 2003. He has a son, Roman (born June 15, 2023) with his producer girlfriend Noor Alfallah, who is 53 years younger than he is. Pacino, at age 83, is one of the oldest fathers on record. He has never been married.\nPacino had a relationship with his \"The Godfather Trilogy\" co-star Diane Keaton. Their on-again, off-again relationship ended after the filming of \"The Godfather Part III\". Keaton said of Pacino, \"Al was simply the most entertaining man... To me, that's, that is the most beautiful face. I think Warren [Beatty] was gorgeous, very pretty, but Al's face is like whoa. Killer, killer face.\" He has had relationships with Jill Clayburgh, Tuesday Weld, Marthe Keller, Veruschka von Lehndorff, Kathleen Quinlan, Lyndall Hobbs, and Penelope Ann Miller. Pacino had a ten-year relationship with Argentine actress Lucila Polak from 2008 to 2018.\nSubstance abuse issues.\nPacino has admitted to abusing drugs and alcohol early in his career, partly because he found his sudden fame after \"The Godfather\" difficult to cope with. He achieved sobriety in 1977.\nHealth.\nPacino revealed in 2024 that he almost died of COVID-19 in 2020; his near-death experience has led him to not believe in an afterlife.\nActing credits and accolades.\nPacino has won and been nominated for many awards during his acting career, including nine Oscar nominations (winning one) and five BAFTA nominations (winning one) for his film work; 19 Golden Globe nominations (winning four) and seven SAG Award nominations (winning two), each recognizing both his film and TV work; three Primetime Emmy Award nominations (winning two) solely for his work on television; and three Tony Award nominations (winning two) for his stage work. In 2007, the American Film Institute awarded Pacino with a lifetime achievement award and, in 2003, British television viewers voted Pacino as the greatest film star of all time in a poll for Channel 4.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n Citations \n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n General and cited references "}
{"id": "41907", "revid": "43933683", "url": "https://en.wikipedia.org/wiki?curid=41907", "title": "Dick Tracy", "text": "American comic strip starting 1931\nDick Tracy is an American comic strip featuring Dick Tracy, a tough and intelligent police detective created by Chester Gould. It made its debut on Sunday, October 4, 1931, in the \"Detroit Mirror\", and was distributed by the Chicago Tribune New York News Syndicate. Gould wrote and drew the strip until 1977, and various artists and writers have continued it. \nDick Tracy has also been the hero in a number of films, including \"Dick Tracy\" (1990) in which Warren Beatty played the lead.\nTom De Haven praised Gould's \"Dick Tracy\" as an \"outrageously funny American Gothic\", while Brian Walker described it as a \"ghoulishly entertaining creation\" which had \"gripping stories filled with violence and pathos\".\nComic strip.\nCreation and early years.\nBasing the character on U.S. federal agent Eliot Ness, Gould drafted an idea for a detective named \"Plainclothes Tracy\" and sent it to Joseph Medill Patterson of the Chicago Tribune New York News Syndicate. Patterson suggested changing the hero's name to Dick Tracy, and he also put forward an opening storyline in which Tracy joined the police after his girlfriend's father was murdered by robbers. Gould agreed to these ideas, and \"Dick Tracy\" was first published on October 4, 1931. The strip was instantly popular and was soon appearing in newspapers across the United States. The strip's popularity also resulted in the creation of numerous \"Dick Tracy\" merchandise, including novelizations, toys, and games. In April 1937, a poll of adult comic strip readers in \"Fortune\" voted \"Dick Tracy\" their third favorite comic strip after \"Little Orphan Annie\" and \"Popeye\". However, \"Dick Tracy\" was also attacked by some journalists as being too violent, a criticism that would dog Gould throughout his time on the strip.\nEvolution of the strip.\nOn January 13, 1946, the Two-Way Wrist Radio was introduced; it would become one of the strip's most immediately recognizable icons. This radio wristwatch, worn by Tracy and members of the police force, inspired Al Gross' invention of several hand held communications and may have inspired later smartwatches. The Two-Way Wrist Radio was upgraded to a Two-Way Wrist TV in 1964. This development also led to the introduction of an important supporting character, Diet Smith, an eccentric industrialist who financed the development of this equipment.\nIn late 1948, with the death of Joseph Medill Patterson, the strip went through several revisions of the characters: a botched security detail personally overseen by Chief Brandon allowed the villain Big Frost (A caricature of Patterson) to murder the semi-regular character Brilliant, the blind inventor of the Two-Way Wrist Radio (among other devices) whereupon Chief Brandon, Dick Tracy's superior on the police force and a presence in the strip since 1931, resigned in shame and Pat Patton (the \"o\" in this surname has since been replaced by an \"e\") was promoted to police chief in Brandon's place on Tracy's recommendation after declining promotion himself, previously having been Tracy's buffoonish partner. A new character was introduced in December of 1948 named Sam Catchem to take Patton's place as Tracy's sidekick.\nThe 1950s.\nGould introduced topical story lines about television, juvenile delinquency, graft, organized crime, and other developments in American life during the 1950s; elements of soap opera depicted Dick, Tess, and Junior (along with the Tracys' baby daughter Bonnie Braids) at home as a family. Depictions of family life alternated with the story's crime drama, as in the kidnapping of Bonnie Braids by fugitive Crewy Lou, or Junior's girlfriend Model being accidentally killed by her brother.\nGould incurred some controversy when he had Tracy live in an unaccountably ostentatious manner on a police officer's salary, and he responded with a story wherein Tracy was accused of corruption and had to explain the origin of his possessions in detail. In his book-length examination of the strip, \"Dick Tracy \u2013 The Official Biography\", Jay Maeder suggested that Gould's critics were unsatisfied by his explanation. Nevertheless, the controversy eventually faded, and the cartoonist reduced exposure to Tracy's home life.\nTracy's cases generally incriminated independent operators rather than organized crime\u2014with a few exceptions, such as Big Boy, a fictionalized version of Al Capone and the strip's first villain. Tracy contended with a series of big-time mobsters in the 1950s, such as the King, George \"Mr. Crime\" Alpha, Odds Zonn, and Willie \"The Fifth\" Millyun, after events like the Kefauver Hearings. As Tess faded into the background, Tracy took, as his assistant, the rookie policewoman Lizz Worthington, a photographer who becomes a highly capable police officer, which was a rare female character type for its time.\nFrom 1956 to 1964, the \"Dick Tracy\" Sunday page was accompanied by a topper humor strip called \"The Gravies\" and drawn by Gould and his assistants.\nThe 1950s are often considered the strip's artistic and commercial prime, which is thought to come to an end with the 1959 story with the villains The Fifth and his colleague, Flyface. In that story, The Fifth was Gould's criticism of the constitutional right to silence with the gangster invoking that right for any question, while his cohort and legal representation, Flyface, was a caricature of lawyers as a repellent man constantly swarmed by flies as was most of his family as well. In that story, Gould's creative weaknesses began to become more obvious with his vitriolic overlong condemnation of the rights of the accused and any new restraint on police practices no matter how justified, while his grotesque style for his villain characters began to alienate contemporary readers enough to prompt newspapers to drop the strip.\nSpace period.\nAs technology progressed, the methods that Tracy and the police used to track and capture criminals took the form of increasingly fanciful atomic-powered gadgets developed by Diet Smith Industries. This eventually led to the 1960s advent of the Space Coupe, a spacecraft with a magnetic propulsion system. This marked the beginning of the strip's \"Space Period,\" which saw Tracy and friends having adventures on the Moon and meeting Moon Maid, the daughter of the leader of a race of humanoid people living in \"Moon Valley\" in 1964. After an eventual sharing of technological information, Moon technology became standard issue on Tracy's police force, including air cars, flying cylindrical vehicles. The villains became even more exaggerated in power, resulting in an escalating series of stories that no longer resembled the urban crime drama roots of the strip. During this period, Tracy met famed cartoonist Chet Jade, creator of the comic strip \"Sawdust\", in which the only characters are talking dots.\nOne of the new characters, Mr. Intro, was only manifested as a disembodied voice. His goal was world domination in the vein of a James Bond villain. Tracy eventually used an atomic laser beam to annihilate Intro and his island base.\nJunior married Moon Maid in October 1964. Their daughter Honey Moon Tracy had antennae and magnetic hands. In the spring of 1969, Tracy was offered the post of Chief of Police in Moon Valley. However, he ended up back on Earth when the Apollo 11 mission in 1969 showed that the moon was barren of all life. Many of the accoutrements of the space period stories remained for many years afterward, such as the Space Coupe and much of the high-tech gadgetry. Moon Maid receded from the storyline.\nThe stories of this period took an increasingly condemnatory tone pertaining to contemporary court decisions concerning the rights of the accused, which often involved Tracy being frustrated by legal technicalities. For example, having caught a gang of diamond thieves red-handed, Tracy was forced to let them walk because he could not \"prove\" beyond a reasonable doubt that the diamonds were stolen. As he saw the thieves get off without penalty, Tracy was heard to grumble, \"Yes, under today's interpretation of the laws, it seems it's the police who are handcuffed!\"\nThe strip was criticized for advocating violence. For instance, Moon Maid, incensed at a woman being attacked by a criminal and no one helping her in an obvious reference of the Murder of Kitty Genovese, becomes a mysterious murderous vigilante to Dick Tracy's open approval in violation of his profession's ethics In 1968. On June 7 \u2014 the day after Senator Robert F. Kennedy was killed by an assassin \u2014 the strip's final panel announced, \"Violence is golden, when it's used to put down evil.\" The strip was obviously prepared weeks before the assassination, but the timing of the strip's publication attracted negative attention. Some newspapers dropped the strip as a result. From 1960 to 1974, the strip's newspaper coverage dropped from 550 to roughly 375\n1970s.\nIn the 1970s, Gould modernized Tracy by giving him a longer hairstyle and a mustache and added a hippie sidekick, Groovy Grove, to appeal to young audiences. Groovy's first appearance in print, as it happened, occurred during the same week as the Kent State shootings. Groovy remained with the strip on and off until his death in 1984.\nShortly before his retirement, Gould drew a strip in which Sam, Lizz, and Groovy held Tracy down to shave off his mustache.\nAt this time, the standard publication size and space of newspaper comics was sharply reduced; for example, the \"Dick Tracy\" Sunday strip, which had traditionally been a full-page episode containing 12 panels, was cut in size to a half-page format that offered, at most, eight panels\u2014these new restrictions created challenges for all comic artists.\nPlenty family.\nThe Plenty family was a group of goofy redneck yokels headed by the former villain Bob Oscar (\"B.O.\"), along with Gertrude (\"Gravel Gertie\") Plenty. Gravel Gertie was introduced as the unwitting dupe of the villain the Brow, who was on the run from Dick Tracy. The family provided a humorous counterpoint to Tracy's adventures. The Plenty sub-story was decades long and saw Sparkle Plenty grow from an infant to a young married lady, eventually becoming a beautiful fashion model. Sparkle Plenty's 30 May 1947 birth became a significant mainstream media event, with spinoff merchandising and magazine coverage.\nThe Plenty family appeared with Tracy in a story that occurred in a bank, where \"B.O.\" found a way to prevent thieves from snatching an envelope of money from a counter.\nIn the 24 April 2011 strip, B.O. and Gertie had a second child, Attitude, a boy who is as ugly as Sparkle is beautiful. His face has yet to be shown.\nCrimestoppers' Textbook.\nBeginning September 11, 1949, the Sunday strip included a frame devoted to a page from the \"Crimestoppers' Textbook\", a series of handy illustrated hints for the amateur crime-fighter. This was named after a short-lived youth group seen in the strip during the late 1940s, led by Junior Tracy, called \"Dick Tracy's Crimestoppers.\" This feature ended when Gould retired from the strip in 1977, but Max Allan Collins reinstated it, and it is still part of the strip. After Gould's retirement, Collins initially replaced the Textbook with \"Dick Tracy's Rogues Gallery,\" a salute to memorable \"Tracy\" villains of the past.\nAfter Gould.\nChester Gould retired from comics in 1977; his last \"Dick Tracy\" strip appeared in print on Sunday, December 25 (Christmas Day) of that same year. The following Monday, \"Dick Tracy\" was taken over by Max Allan Collins and longtime Gould assistant Rick Fletcher. Gould's name remained in the byline for a few years after his retirement as a story consultant.\nIn one of Collins' first stories as the strip's writer, the gangster known as \"Big Boy\" learned that he was dying and had less than a year to live. Big Boy was still seeking revenge on Tracy, who had sent him up the river to prison, and he wanted to live just long enough to see Tracy's death. He put out an open $1 million contract on Tracy, knowing that every small-time hood in the city would take a crack at the famous cop for that amount of money. One of the would-be collectors rigged Tracy's car to explode, but inadvertently killed Moon Maid instead of Tracy in the explosion. A funeral strip for Moon Maid explicitly stated that this officially severed all ties between Earth and the Moon in the strip, thus eliminating the last remnants of the Space Period. Honeymoon received a new hairstyle that covered her antennae and she was ultimately phased out of the strip. Junior later married Sparkle Plenty (the daughter of B.O. and 'Gravel' Gertie Plenty), and they had a daughter named Sparkle Plenty Jr. Sparkle had been divorced by her cartoonist husband Vera Aldid, who was thus also removed from the cast. Collins felt that their original marriages were a mistake on Gould's part. In the 1990s, Tracy's son Joseph Flintheart Tracy took on a role similar to Junior's in the earlier strips.\nIn addition, Collins removed other Gould creations of the 1960s and 1970s (including Groovy Grove, who was gravely wounded in the line of duty and later died in the hospital; Lizz married him before his death). On a more philosophical level, Collins took a generally less cynical view of the justice system than Gould; Tracy came to accept its limitations and requirements as a normal part of the process which he could manage. Extreme technology was phased out, such as the Space Coupe, in favor of more realistic advanced tools such as the Two-Way Wrist Computer in 1987.\nNew semi-regular characters introduced by Collins and Fletcher included: Dr. Will Carver, a plastic surgeon with underworld ties who often worked on known felons; Wendy Wichel, a smarmy newspaper reporter/editorialist with a strong anti-Tracy bias in her articles; and Lee Ebony, an African-American female detective. Vitamin Flintheart reappeared occasionally as a comic-relief figure, the aged ham actor created by Gould in 1944 who had not been seen in the strip for almost three decades. The Plenty family (B.O., Gravel Gertie, and Sparkle) were also brought back as semi-regulars.\nOriginal villains seen during this period included Angeltop (the revenge-seeking, psychopathic daughter of the slain Flattop), Torcher (whose scheme was arson-for-profit), and Splitscreen (a video pirate). Collins brought back at least one \"classic\" Gould villain or revenge-seeking family member per year. The revived Gould villains were often provided with full names and marriages, as well as children, and other family connections were developed, bringing more humanity to many of the originally grotesque brutes. \"Flattop\", particularly, had a number of relatives, all with his characteristic head structure and facial attributes, who turned up one by one to avenge their ancestor on Tracy.\nRick Fletcher died in 1983 and was succeeded by editorial cartoonist Dick Locher, who had assisted Gould on the strip in the late 1950s and early 1960s. Locher was assisted by his son John, who died in 1986.\nMax Allan Collins was fired from the strip in 1992, following a financial reorganization of their comic strip holdings, and \"Tribune\" staff writer and columnist Mike Kilian took over the writing. Kilian continued until his death on October 27, 2005.\n2000s.\nDick Locher was both author and artist for over three years, beginning on January 9, 2006. On March 16, 2009, Jim Brozman began collaborating with Locher, taking over the drawing duties while Locher continued to write the strip.\nIn 2005, Tracy was a guest at Blondie and Dagwood's 75th anniversary party in the comic strip \"Blondie\". Later, Dick Tracy appeared in the comic strip \"Gasoline Alley\".\nOn January 19, 2011, Tribune Media Services announced that Locher was retiring from the strip and handing the reins to artist Joe Staton and writer Mike Curtis. The new creative team has previously worked together on \"Scooby-Doo\", \"Richie Rich\", and\" Casper the Friendly Ghost\". Their first Dick Tracy strip was published March 14, 2011. Until Staton's retirement in October 2021, Staton and Curtis were assisted by Shelley Pleger, who inked and lettered Staton's drawings, along with Shane Fisher, who provides the coloring on the Sunday strips. After Staton's retirement, Pleger took over his artist duties, too, having previously substituted for him in 2017. Pleger was in turn succeeded by Charles Ettinger in February 2024. Chicago-area police sergeant Jim Doherty provided \"Crimestopper\" captions for the Sunday strips and acted as the feature's technical advisor. Doherty also introduced a new feature, \"Tracy's Hall of Fame\" (which replaces the \"Crimestopper\" panel approximately once each month), in which a real-life police officer is profiled and honored. Doherty was replaced in 2016 by police lieutenant Walter Reimer, who introduced the \"First Responders Roll of Honor\", which honors real-life police officers, firefighters, and paramedics who died on duty.\nStaton and Curtis reintroduced many of the characters of the \u201840s through the \u201860s, including a second Mr. Crime and a reformed Mole, while introducing more deformed and grotesque villains such as Abner Kadaver, Panda, and the Jumbler. They also brought back all the gadgets and plot elements of the 1960s space era, starting in early 2013, although the reintroduced Moon Maid is not the same as the original; rather, she is a human genetically modified to resemble the original Moon Maid and, thus, is christened Mysta Chimera and placed under Diet Smith's care. They have also done crossovers, with cameos from \"Popeye\", \"Brenda Starr, Reporter\", \"Funky Winkerbean\", \"Fearless Fosdick\", \"The Spirit\", \"The Green Hornet\", \"For Better or For Worse\", \"Friday Foster\", and several long sequences involving \"Little Orphan Annie\".\nAwards and honors.\nChester Gould won the Reuben Award for the strip in 1959 and 1977.\nThe Mystery Writers of America honored Gould and his work with a Special Edgar Award in 1980. This was the first time MWA ever honored a comic strip.\nIn 1995, the strip was one of 20 included in the Comic Strip Classics series of commemorative postage stamps and postcards.\nOn May 2, 2011, the Tennessee Senate passed Resolution 30, congratulating Mike Curtis and Joe Staton on their professional accomplishments, including \"Dick Tracy\".\nOn September 7, 2013, at the Baltimore Comics Convention, \"Dick Tracy\" was awarded the Harvey in the \"Best Syndicated Strip or Panel\" category. \"Tracy\" was simultaneously the oldest continually running strip and the first adventure strip ever to win the Harvey Award in this category. On September 6, 2014, \"Tracy\" was awarded a second Harvey Award in the newspaper strip category, becoming one of only three strips to win in this category in consecutive years. On September 26, 2015, \"Tracy\" won a third Harvey in the same category, becoming one of only three strips to win in three consecutive years.\nOn November 6, 2016, at their panel at Akron Comicon, Mike Curtis and Joe Staton were each presented with an Akron Comicon Excellence Award. The inscription on the plaques reads: \"2016 Akron Comicon Excellence Award Presented to Mike Curtis and Joe Staton for Their Contribution to One of the Longest Running Newspaper Strips in the History of Newspaper Comics!\"\nIn other media.\nRadio.\n\"Dick Tracy\" had a long run on radio, from 1934 weekdays on NBC's New England stations to the ABC network in 1948. Bob Burlen was the first radio Tracy in 1934, and others heard in the role during the 1930s and 1940s were Barry Thomson, Ned Wever and Matt Crowley. The early shows all had 15-minute episodes.\nOn CBS, with Sterling Products as sponsor, the serial aired four times a week from February 4, 1935, to July 11, 1935, moving to Mutual from September 30, 1935, to March 24, 1937, with Bill McClintock doing the sound effects. NBC's weekday afternoon run from January 3, 1938, to April 28, 1939, had sound effects by Keene Crockett and was sponsored by Quaker Oats, which brought \"Dick Tracy\" into primetime (Saturdays at 7\u00a0pm and, briefly, Mondays at 8\u00a0pm) with 30-minute episodes from April 29, 1939, to September 30, 1939. The series returned to 15-minute episodes on the ABC Blue Network from March 15, 1943, to July 16, 1948, sponsored by Tootsie Roll, which used the music theme of \"Toot Toot, Tootsie\" for its 30-minute Saturday ABC series from October 6, 1945, to June 1, 1946. Sound effects on ABC were supplied by Walt McDonough and Al Finelli.\nOn February 15, 1945, \"Command Performance\" broadcast the musical comedy \"Dick Tracy in B-Flat\" with Bing Crosby as Tracy, Bob Hope as Flattop, Dinah Shore as Tess Trueheart, among the cast. Dick Tracy's wedding is repeatedly interrupted as Tracy chases after one villain after another. In the strip, his marriage wasn't until 1950 and his honeymoon was disrupted by his going after Wormy.\nRecordings.\nJim Ameche portrayed Tracy in a two-record set recorded by Mercury Records in 1947. The record sleeves were illustrated with Sunday strips reprinted in black-and-white for children to color.\nComic books.\nTracy made his first comic book appearance in 1936 as one of the features included in the first issue of Dell's \"Popular Comics\". These were reprints from the newspaper strip, reconfigured to fit the pages of a comic book, as was the case with most Tracy comic book appearances. Tracy remained a regular feature in \"Popular Comics\" through the publication's 21st issue.\nThe first comic book to feature Tracy exclusively was the \"Dick Tracy Feature Book\", published in May 1937 by David McKay Publications. McKay's Feature Books were magazines that rotated several popular characters from comics strips through 1938. Three more of McKay's Feature Books starred Tracy in the following months.\nIn 1939, Dell started a comic magazine series called \"Black and White Comics,\" essentially identical to McKay's \"Feature Books.\" Six of the 15 issues featured Tracy. In 1941, Dell's \"Black and White\" series was replaced by the \"Large Feature Books,\" the third issue of which featured Tracy. As with the McKay series, the Dell \"Black and White\" and \"Large Feature\" series were abridged reprints of the strip.\nIn 1938, \"Tracy\" became one of several regular newspaper strips featured in Dell's regular monthly \"Super Comics\", remaining a regular part of that publication until 1948. In 1939, \"Tracy\" was the sole feature in the very first issue of Dell's \"Four-Color Comics\", which put out more than 1,300 issues starring hundreds of characters between 1939 and 1962. Tracy was featured in seven more \"Four-Color\" issues throughout the 1940s.\nTracy was frequently featured in comic books used as promotional items by various companies. In 1947, for example, Sig Feuchtwanger produced a comic book that was a giveaway prize in boxes of Quaker Puffed Wheat cereal, sponsor of the popular \"Dick Tracy\" radio series.\nIn January 1948, Dell began the first regular \"Dick Tracy\" comic book series, \"Dick Tracy Monthly\". This series ultimately ran for 145 issues, the first 24 of which were published by Dell, after which it was picked up by Harvey Comics. Continuing the same numbering, Harvey published the series until 1961. As with most previous Tracy comic book incarnations, these were, with the exception of the last few Dell issues which featured original material, slightly abridged and reconfigured reprints of the newspaper strips.\n\"Dick Tracy\" was revived in 1986 by Blackthorne Publishing which began as a monthly series (also called \"Dick Tracy Monthly\") but became a weekly one (\"Dick Tracy Weekly\") with issue 25 and lasted 99 issues. Disney produced a series of three issues as a tie-in for their 1990 film. This miniseries, \"True Hearts and Tommy Guns\", was drawn by Kyle Baker and edited by Len Wein. The third issue was a direct adaptation of the film.\nIn 2018, IDW Publishing announced a new \"Dick Tracy\" comic book by Mike Allred (co-writer/cover artist/inker), Lee Allred (co-writer), Rich Tommaso (penciller) and Laura Allred (colorist).\nBooks.\nOver the years, many reprints of \"Dick Tracy\" newspaper strips have been published. Beginning in 2006, IDW Publishing started the series \"The Complete Chester Gould's Dick Tracy\", reprinting the complete strip in hardcover volumes, eventually being done under their The Library of American Comics imprint. The series concluded with the 29th and final volume being released in December 2020.\nOther collections include:\nOther editions:\nFilm.\nFilm serials.\nDick Tracy made his film debut in \"Dick Tracy\" (1937), a 15-chapter movie serial by Republic Pictures starring Ralph Byrd. The Spider Gang was on the loose, tired of Dick Tracy's cunning skills. Through the 15-chapter serial, 15 different cases were solved, all plots by the Spider Gang. Dick Tracy was also in search of his missing brother, Gordon Tracy (Carleton Young). The Dick Tracy character proved very popular, and a second serial, \"Dick Tracy Returns\", appeared in 1938 (reissued in 1948). \"Dick Tracy's G-Men\" was released in 1939 (reissued in 1955). The last was \"Dick Tracy vs. Crime Inc.\" in 1941 (reissued as \"Dick Tracy vs. Phantom Empire\" in 1952).\nThe sequels were produced under an interpretation of the contract for the first \"Dick Tracy\" serial, which gave license for \"a series or serial\". As a result, Chester Gould received no further money for the sequel serials.\nDick Tracy is portrayed as an FBI agent, or \"G-Man\", based in California rather than as a detective in the police force of a Midwestern city resembling Chicago, and, aside from himself and Junior, no characters from the strip appear in any of the four serials.\nHowever, comic relief sidekick \"Mike McGurk\" bears some resemblance to Tracy's partner from the strip, Pat Patton; Tracy's secretary, Gwen Andrews (played by several actresses in the course of the series, including Jennifer Jones under a variation of her real name, Phyllis Isley), provides the same kind of feminine interest as Tess Trueheart; and FBI Director Clive Anderson (Francis X. Bushman and others) is the same kind of avuncular superior as Chief Brandon.\nThe first serial, \"Dick Tracy\", is now in the public domain.\nEarly feature films.\nFour years after the release of the final Republic serial, Dick Tracy would headline the first of four feature films, produced by RKO Radio Pictures. \"Dick Tracy\" (1945), retitled \"Dick Tracy, Detective\" for TV syndication and video, was followed by \"Dick Tracy vs. Cueball\" in 1946, both with Morgan Conway as Tracy. Conway's low-key interpretation of the character, calm and businesslike, was entirely in keeping with a police procedural. Conway was well received by the press; the trade publication \"Showmen's Trade Review\" reported, \"It is Conway's splendid interpretation of Dick Tracy that makes this film such good entertainment and a very auspicious first in the series.\" Dick Tracy writer Max Allan Collins strongly approves of his performances: \"To the late Morgan Conway, wherever you are, a tip of the fedora. You did very, very well.\" \nRalph Byrd had played the role in four hit serials, and some exhibitors petitioned RKO to make more Tracy features, but with Byrd. RKO made the substitution and two more features followed: \"Dick Tracy's Dilemma\" and \"Dick Tracy Meets Gruesome\" (both 1947). \"Gruesome\" is probably the best known of the four, with the villain portrayed by Boris Karloff. All four movies had many of the visual features associated with film noir: dramatic, shadowy photographic compositions, with many exterior scenes filmed at night (at the RKO Encino movie ranch). Lyle Latell co-starred in all four films as Pat Patton. Anne Jeffreys played Tess Trueheart in the first two, succeeded by Kay Christopher and finally Anne Gwynne; Ian Keith joined the cast as the actor Vitamin Flintheart for two films; Joseph Crehan played Chief Brandon. RKO stocked the films with familiar faces, creating a veritable rogues' gallery of colorful characters: Mike Mazurki as Splitface, Dick Wessel as Cueball, Esther Howard as Filthy Flora, Jack Lambert as hook-handed villain the Claw; baldheaded, pop-eyed Milton Parsons, mild-mannered Byron Foulger, dangerous Trevor Bardette, and pockmarked, gently sinister Skelton Knaggs. The studio discontinued most of its \"B\" product in 1947 and Conway's contract was not renewed. In 1948, Chester Gould proposed that RKO should continue the series, stipulating that Morgan Conway should play the lead, but RKO (then in organizational turmoil after the studio's sale to Howard Hughes) declined.\n1990 feature film.\nWarren Beatty produced, directed, co-wrote (uncredited), and starred in the 1990 film \"Dick Tracy\", whose supporting cast includes Al Pacino, Madonna, Glenne Headly, and Charlie Korsmo. \"Dick Tracy\" depicts the detective's romantic relationships with Breathless Mahoney and Tess Trueheart, as well as his conflicts with crime boss Alphonse \"Big Boy\" Caprice and his henchmen. Tracy also begins fostering a young street urchin named Kid. Development of the film began in the early 1980s with Tom Mankiewicz assigned to write the script. The screenplay was written instead by Jim Cash and Jack Epps Jr., both of \"Top Gun\" fame. The project also went through directors (Steven Spielberg, John Landis, Walter Hill, and Richard Benjamin) before the arrival of Beatty. It was filmed mainly at Universal Studios. Danny Elfman was hired to compose the score, and the film's music and songs were featured on three separate soundtrack albums.\nTelevision.\nThe strip has had limited exposure on television with one early live-action series, two animated series, one unsold pilot that was never picked up, and a proposed TV series currently held up in litigation.\nFirst live-action series.\nRalph Byrd, who had played the square-jawed sleuth in all four Republic movie serials and two of the RKO feature-length films, reprised his role in a short-lived live action \"Dick Tracy\" series that ran on ABC from 1950 to 1951. Additional episodes intended for first-run syndication continued to be produced into 1952. Produced by P. K. Palmer, who also wrote many of the scripts, the series often featured Gould-created villains such as Flattop, Shaky, the Mole, Breathless Mahoney, Heels Beals and Influence, all of whom appeared on film for the first time on this series. Other cast members included Joe Devlin as Sam Catchem, Angela Greene as Tess Tracy (n\u00e9e Trueheart), Martin Dean as Junior, and Pierre Watkin as Chief Patton. Criticized for its violence, the series remained popular. The series was filmed on a low budget, with many long hours and a rushed shooting schedule, and the strenuous conditions may well have affected Byrd's health; he died prematurely in 1952, ending the series. Many episodes of this series have been released on various public domain TV detective DVD sets.\nAnimated cartoons.\nThe first cartoon series was produced from 1960 to 1961 by UPA. Tracy employed a series of cartoon-like subordinate flatfoots to fight crime each week, contacting them on his two-way wrist radio. Everett Sloane voiced Tracy and supporting characters and villains were voiced by Jerry Hausner, Mel Blanc, Benny Rubin, Johnny Coons, Paul Frees and others. These subordinates included \"Go-Go\" Gomez, Joe Jitsu, Hemlock Holmes and the Retouchables, and Officer Heap O'Calorie. 130 five-minute cartoons were designed and packaged for syndication, usually intended for local children's shows.\nUPA was also the production company behind the Mr. Magoo cartoons, so it was possible for them to arrange a meeting between Tracy and Magoo in a 1965 episode of the season-long TV series \"The Famous Adventures of Mr. Magoo\". In the episode \"Dick Tracy and the Mob\", Tracy persuades Magoo (a well-known actor in the context of the \"Famous Adventures\" series) to impersonate an international hit man named Squinty Eyes, who he resembles, and infiltrate a gang of criminals made up of Flattop, Pruneface, Itchy, Mumbles and others. Unlike the earlier animated Tracy shorts, this longer episode was played relatively straight, with Tracy getting much more screen time. Pitting Tracy against a coalition of several of his foes was adopted more than two decades later in the 1990 film.\nA second cartoon series was produced in 1971 and was a feature in \"Archie's TV Funnies\", produced by Filmation. It adhered more closely to the comic strip, although it was hampered by cruder animation than the UPA shorts, typical of the studio's production standards.\nLive action television pilot.\nWilliam Dozier produced a pilot for a live action Dick Tracy series in 1967 starring Ray MacDonnell in the title role. (Dozier was the producer responsible for the 1966 \"Batman\" TV series.) The pilot was \"The Plot to Kill NATO\", featuring \"Special Guest Villain\" Victor Buono as 'Mr. Memory'. The series was not purchased by either ABC or NBC. Eve Plumb, who would later find fame as Jan Brady on \"The Brady Bunch\", is credited as Bonnie Braids, who does not appear in the pilot, nor does Davey Davison as Tess.\nLicensed products.\nIn the 1960s, Aurora produced a plastic model kit of Dick Tracy sliding down a fire escape ladder into an alley, in hot pursuit with gun drawn. A Dick Tracy Space Coupe model came next. Both have been reissued by Polar Lights. Also in the market were Mattel's Dick Tracy range of toy guns.\nIn 1990, Playmates Toys released a line of action figures called \"Dick Tracy: Coppers and Gangsters\" to coincide with the Dick Tracy movie. The figures were 5\" tall, stylized with exaggerated comic looks and was accompanied by many accessories. Two figures in the line had limited availability; Steve the Tramp (called \"The Tramp\" on the package front) was pulled from the assortment after complaints of portrayal of a homeless person as a criminal. The figure of \"The Blank\" was added to the assortment well after the film's release to keep the secret of the identity of the character. As a result, only limited quantities of these two figures made it to store shelves.\nVarious distinct video games tied in with the film were developed. Titus Software did versions many platforms including Amiga, Commodore and MS-DOS. \"Dick Tracy\" is a side scrolling action shooting game. The player controls Dick Tracy through five stages. The Commodore 64 version is infamous for being released in an unfinished state (minimal animation for the main character, missing headlines in the linking screens, flick scrolling), and scored Commodore Format magazine's lowest ever review score of 11%. There were also games made for the Nintendo Entertainment System (1990), Master System (1990), Sega Genesis (1990), and Game Boy (1991)., and a graphic adventure for MS-DOS and the Amiga.\nIn 2009, Shocker Toys released a monochromatic Dick Tracy action figure as an exclusive product for San Diego Comic-Con. The figure appears in a suit with two-way wrist radio. There was also a variant figure released of Dick Tracy in his signature trench coat and fedora with a tommy gun accessory.\nRights to adapt in other media.\nMedia outlets reported a legal battle being waged over rights to the Dick Tracy character. Warren Beatty announced plans to make a sequel to his 1990 movie. At the same time, television producers announced plans for a new \"Dick Tracy\" TV series. Both sides claimed that they were the legal owners of the rights to Dick Tracy. In May 2005, Beatty sued the Tribune Company, claiming he has owned the rights to the Dick Tracy character since 1985. Pressure from Beatty led to the cancellation of a proposed collaboration between artist Mike Oeming and writer Brian Bendis on a new serialized Dick Tracy comic.\nThe lawsuit was resolved in Beatty's favor, with a U.S. District judge ruling that Beatty did everything contractually required of him to keep the rights to the character. Beatty has maintained the rights to Tracy since then by producing two made-for-TV specials, which regarded as having minimal artistic value. While the first special is believed to have been part of the rights battle, the second special does not seem to have had a direct legal impetus, as it was claimed that Dick Tracy will enter the public domain in 2027. However, it seems that the earliest comic versions of Dick Tracy are already in the public domain as the Tribune did not renew the copyright to the original 1931 strip at the required time.\nReferences.\nNotes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography"}
{"id": "41908", "revid": "38427", "url": "https://en.wikipedia.org/wiki?curid=41908", "title": "Key Word in Context", "text": "Common format for concordance lines\nKey Word In Context (KWIC) is the most common format for concordance lines. The term KWIC was coined by Hans Peter Luhn. The system was based on a concept called \"keyword in titles\", which was first proposed for Manchester libraries in 1864 by Andrea Crestadoro.\nA KWIC index is formed by sorting and aligning the words within an article title to allow each word (except the stop words) in titles to be searchable alphabetically in the index. It was a useful indexing method for technical manuals before computerized full text search became common.\nFor example, a search query including all of the words in an example definition (\"KWIC is an acronym for Key Word In Context, the most common format for concordance lines\") and the Wikipedia slogan in English (\"the free encyclopedia\"), searched against a Wikipedia page, might yield a KWIC index as follows. A KWIC index usually uses a wide layout to allow the display of maximum 'in context' information (not shown in the following example).\nA KWIC index is a special case of a \"permuted index\". This term refers to the fact that it indexes all cyclic permutations of the headings. Books composed of many short sections with their own descriptive headings, most notably collections of manual pages, often ended with a permuted index section, allowing the reader to easily find a section by any word from its heading. This practice, also known as Key Word Out of Context (KWOC), is no longer common.\nReferences in literature.\n\"Note: The first reference does not show the KWIC index unless you pay to view the paper. The second reference does not even list the paper at all.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41909", "revid": "25046916", "url": "https://en.wikipedia.org/wiki?curid=41909", "title": "Accrual bond", "text": " \nAn accrual bond is a fixed-interest bond that is issued at its face value and repaid at the end of the maturity period together with the accrued interest. However, another definition states that the interest periods maybe paid periodically.\nIn Germany, the accrued interest is compounded.\nIn contrast to zero-coupon bonds, accrual bonds have a clearly stated coupon rate.\nSee also.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; The dictionary definition of \"Accrual bond\" at Wiktionary\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41910", "revid": "37987116", "url": "https://en.wikipedia.org/wiki?curid=41910", "title": "Aftermarket", "text": "Aftermarket may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41911", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=41911", "title": "Second market", "text": ""}
{"id": "41912", "revid": "1152308", "url": "https://en.wikipedia.org/wiki?curid=41912", "title": "Allotment", "text": "Allotment may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41913", "revid": "1317134718", "url": "https://en.wikipedia.org/wiki?curid=41913", "title": "Subscription (finance)", "text": "Process of investors\nSubscription refers to the process of investors signing up and committing to invest in a financial instrument, before the actual closing of the purchase. The term comes from the Latin word \"subscribere\".\nHistorical.\nPraenumeration.\nAn early form of subscription was praenumeration, a common business practice in the 18th-century book trade in Germany. The publisher offered to sell a book that was planned but had not yet been printed, usually at a discount, so as to cover their costs in advance. The business practice was particularly common with magazines, helping to determine in advance how many subscribers there would be. Praenumeration is similar to the recent crowdfunding financing model.\nNew issues.\nSubscription agreement.\nSubscription to new issues can be covered by a subscription agreement, legally committing the investor to invest in the financial instrument, and committing the company to certain obligations and warranties. In some jurisdictions, it is possible for the issuer and subscriber to use a template subscription agreement as the basis of this agreement, although bespoke contract drafting by a qualified specialist may be required in more complex cases.\nSubscription period.\nWhen a new security is to be issued, investors typically have two weeks to submit their subscription orders. At the end of this subscription period, the issuer announces the offering price and the method of allotment.\nAllotment.\nAllotment is a method of distributing securities to investors when an issue has been oversubscribed. At the end of the subscription period, the demand for a new issue can exceed the number of the company's shares or bonds being issued. In such cases, the underwriting bank allots the securities with the approval of the issuer, either by lottery or on the basis of a formula. An allotment formula usually takes into account the issuer's preferred target investor groups.\nOversubscription.\nA funding round is oversubscribed when the company has obtained funding commitments from subscribers that, in aggregate, amount to more money than the company needs or intends to raise. The term may be used informally to describe a state where there is more money available than the company needs.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41914", "revid": "48296011", "url": "https://en.wikipedia.org/wiki?curid=41914", "title": "Capital market", "text": "Financial market\nA capital market is a financial market in which long-term debt (over a year) or equity-backed securities are bought and sold, in contrast to a money market where short-term debt is bought and sold. Capital markets channel the wealth of savers to those who can put it to long-term productive use, such as companies or governments making long-term investments. Financial regulators like Securities and Exchange Board of India (SEBI), Bank of England (BoE) and the U.S. Securities and Exchange Commission (SEC) oversee capital markets to protect investors against fraud, among other duties.\nTransactions on capital markets are generally managed by entities within the financial sector or the treasury departments of governments and corporations, but some can be accessed directly by the public. As an example, in the United States, any American citizen with an internet connection can create an account with TreasuryDirect and use it to buy bonds in the primary market. However, sales to individuals form only a small fraction of the total volume of bonds sold. Various private companies provide browser-based platforms that allow individuals to buy shares and sometimes even bonds in the secondary markets. There are many thousands of such systems, most serving only small parts of the overall capital markets. Entities hosting the systems include investment banks, stock exchanges and government departments. Physically, the systems are hosted all over the world, though they tend to be concentrated in financial centres like London, New York, and Hong Kong.\nDefinition.\nA capital market can be either a primary market or a secondary market. In a primary market, new stock or bond issues are sold to investors, often via a mechanism known as underwriting. The main entities seeking to raise long-term funds on the primary capital markets are governments (which may be municipal, local or national) and business enterprises (companies). Governments issue only bonds, whereas companies often issue both equity and bonds. The main entities purchasing the bonds or stock on primary markets include pension funds, hedge funds, sovereign wealth funds, and less commonly wealthy individuals and investment banks trading on their own behalf. In the secondary market, existing securities are sold and bought among investors or traders, usually on an exchange, over-the-counter, or elsewhere. The existence of secondary markets increases the willingness of investors in primary markets, as they know they are likely to be able to swiftly cash out their investments if the need arises.\nA second important division falls between the stock markets (for equity securities, also known as shares, where investors acquire ownership of companies) and the bond markets (where investors become creditors).\nContrast with money markets.\nThe money markets are used to raise short-term finance; including loans that are expected to be paid back as early as overnight. In contrast, the \"capital markets\" are used to raise long-term finance, in the form of shares/equities, and loans that are not expected to be fully paid back for at least a year.\nFunds borrowed from money markets are typically used for general operating expenses, to provide liquid assets for brief periods. For example, a company may have inbound payments from customers that have not yet cleared, but need immediate cash to pay its employees. But when a company borrows from the primary capital markets, often the purpose is to invest in additional physical capital goods, which will be used to help increase its income. It can take many months or years before the investment generates sufficient return to pay back its cost, and hence the finance is long term.\nTogether, money markets and capital markets form the financial markets, as the term is narrowly understood. The capital market is concerned with long-term finance. In the widest sense, it consists of a series of channels through which the savings of individuals and institutions are made available for industrial and commercial enterprises and public authorities. This process of channeling savings into productive investments is crucial for economic growth and development. Moreover, capital markets provide opportunities for both individuals and institutions to diversify their investments, thereby managing risk and potentially enhancing returns over the long term.\nCapital market versus bank loans.\nNormal bank lending is not usually classed as a capital market transaction, even when loans are extended for a period longer than a year. First, these bank loans are not securitized (i.e. they are not packaged into a resaleable security like a share or bond that can be traded on the markets). Second, lending by banks is more heavily regulated than capital market lending. Third, bank depositors tend to be more risk-averse than capital market investors. These three differences all act to limit institutional lending as a source of finance. Two additional differences, this time favoring lending by banks, are that banks are more accessible for small and medium-sized companies, and that they have the ability to create money as they lend. In the 20th century, most company finance apart from share issues was raised by bank loans. But since about 1980 there has been an ongoing trend for disintermediation, where large and creditworthy companies have found they effectively have to pay out less interest if they borrow directly from capital markets rather than from banks. The tendency for companies to borrow from capital markets instead of banks has been especially strong in the United States. According to the \"Financial Times\", capital markets overtook bank lending as the leading source of long-term finance in 2009, which reflects the risk aversion and bank regulation due to the 2008 financial crisis.\nCompared to the United States, companies in the European Union have a greater reliance on bank lending for funding. Efforts to enable companies to raise more funding through capital markets are being coordinated through the EU's Capital Markets Union initiative.\nExamples.\nGovernment on primary markets.\nWhen a government wants to raise long-term finance it will often sell bonds in the capital markets. In the 20th and early 21st centuries, many governments would use investment banks to organize the sale of their bonds. The leading bank would underwrite the bonds, and would often head up a syndicate of brokers, some of whom might be based in other investment banks. The syndicate would then sell to various investors. For developing countries, a multilateral development bank would sometimes provide an additional layer of underwriting, resulting in risk being shared between the investment bank(s), the multilateral organization, and the end investors. However, since 1997 it has been increasingly common for governments of the larger nations to bypass investment banks by making their bonds directly available for purchase online. Many governments now sell most of their bonds by computerized auction. Typically, large volumes are put up for sale in one go; a government may only hold a small number of auctions each year. Some governments will also sell a continuous stream of bonds through other channels. The biggest single seller of debt is the U.S. government; there are usually several transactions for such sales every second, which corresponds to the continuous updating of the U.S. real-time debt clock.\nCompany on primary markets.\nWhen a company wants to raise money for long-term investment, one of its first decisions is whether to do so by issuing bonds or shares. If it chooses shares, it avoids increasing its debt, and in some cases the new shareholders may also provide non-monetary help, such as expertise or useful contacts. On the other hand, a new issue of shares will dilute the ownership rights of the existing shareholders, and if they gain a controlling interest, the new shareholders may even replace senior managers. From an investor's point of view, shares offer the potential for higher returns and capital gains if the company does well. Conversely, bonds are safer if the company does poorly, as they are less prone to severe falls in price, and in the event of bankruptcy, bond owners may be paid something, while shareholders will receive nothing.\nWhen a company raises finance from the primary market, the process is more likely to involve face-to-face meetings than other capital market transactions. Whether they choose to issue bonds or shares, companies will typically enlist the services of an investment bank to mediate between themselves and the market. A team from the investment bank often meets with the company's senior managers to ensure their plans are sound. The bank then acts as an underwriter, and will arrange for a network of brokers to sell the bonds or shares to investors. This second stage is usually done mostly through computerized systems, though brokers will often phone up their favored clients to advise them of the opportunity. Companies can avoid paying fees to investment banks by using a direct public offering, though this is not a common practice as it incurs other legal costs and can take up considerable management time.\nSecondary market trading.\nMost capital market transactions take place on the secondary market. On the primary market, each security can be sold only once, and the process to create batches of new shares or bonds is often lengthy due to regulatory requirements. On the secondary markets, there is no limit to the number of times a security can be traded, and the process is usually very quick. Transactions on the secondary market do not directly raise finance, but they do make it easier for companies and governments to raise finance on the primary market, as investors know that if they want to get their money back quickly, they will usually be easily able to re-sell their securities. Sometimes, however, secondary capital market transactions can have a negative effect on the primary borrowers: for example, if a large proportion of investors try to sell their bonds, this can push up the yields for future issues from the same entity. An extreme example occurred shortly after Bill Clinton began his first term as President of the United States; Clinton was forced to abandon some of the spending increases he had promised in his election campaign due to pressure from the bond markets. In the 21st century, several governments have tried to lock in as much as possible of their borrowing into long-dated bonds, so they are less vulnerable to pressure from the markets. Following the 2008 financial crisis, the introduction of quantitative easing further reduced the ability of private actors to push up the yields of government bonds, at least for countries with a central bank able to engage in substantial open market operations.\nA variety of different players are active in the secondary markets. Individual investors account for a small proportion of trading, though their share has slightly increased; in the 20th century it was mostly only a few wealthy individuals who could afford an account with a broker, but accounts are now much cheaper and accessible over the internet. There are now numerous small traders who can buy and sell on the secondary markets using platforms provided by brokers which are accessible via web browsers. When such an individual trades on the capital markets, it will often involve a two-stage transaction. First they place an order with their broker, then the broker executes the trade. If the trade can be done on an exchange, the process will often be fully automated. If a dealer needs to manually intervene, this will often mean a larger fee. Traders in investment banks will often make deals on their bank's behalf, as well as executing trades for their clients. Investment banks will often have a division (or department) called \"capital markets\": staff in this division try to keep aware of the various opportunities in both the primary and secondary markets, and will advise major clients accordingly. Pension and sovereign wealth funds tend to have the largest holdings, though they tend to buy only the highest grade (safest) types of bonds and shares, and some of them do not trade all that frequently. According to a 2012 \"Financial Times\" article, hedge funds are increasingly making most of the short-term trades in large sections of the capital market (like the UK and US stock exchanges), which is making it harder for them to maintain their historically high returns, as they are increasingly finding themselves trading with each other rather than with less sophisticated investors.\nThere are several ways to invest in the secondary market without directly buying shares or bonds. A common method is to invest in mutual funds or exchange-traded funds. It is also possible to buy and sell derivatives that are based on the secondary market; one of the most common type of these is contracts for difference \u2013 these can provide rapid profits, but can also cause buyers to lose more money than they originally invested.\nSize.\nAll figures given are in billions of US$ and are sourced to the IMF. There is no universally recognized standard for measuring all of these figures, so other estimates may vary. A GDP column is included for comparison.\nForecasting and analyses.\nA great deal of work goes into analyzing capital markets and predicting their future movements. This includes academic study, work within the financial industry for the purposes of making money and risk management, and work done by governments and multilateral institutions for the purposes of regulation and understanding the impact of capital markets on the wider economy. Methods range from the gut instincts of experienced traders, to various forms of stochastic calculus and algorithms such as the Stratonovich-Kalman-Bucy filtering algorithm.\nCapital controls.\nCapital controls are measures imposed by a state's government aimed at managing capital account transactions \u2013 in other words, capital market transactions where one of the counter-parties involved is in a foreign country. Whereas domestic regulatory authorities try to ensure that capital market participants trade fairly with each other, and sometimes to ensure institutions like banks do not take excessive risks, capital controls aim to ensure that the macroeconomic effects of the capital markets do not have a negative impact. Most advanced nations like to use capital controls sparingly if at all, as in theory allowing markets freedom is a win-win situation for all involved: investors are free to seek maximum returns, and countries can benefit from investments that will develop their industry and infrastructure. However, sometimes capital market transactions can have a net negative effect: for example, in a financial crisis, there can be a mass withdrawal of capital, leaving a nation without sufficient foreign-exchange reserves to pay for needed imports. On the other hand, if too much capital is flowing into a country, it can increase inflation and the value of the nation's currency, making its exports uncompetitive. Countries like India employ capital controls to ensure that their citizens' money is invested at home rather than abroad.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41915", "revid": "48296011", "url": "https://en.wikipedia.org/wiki?curid=41915", "title": "Primary market", "text": "Market for direct issue of securitiesThe primary market is the part of the capital market that deals with the issuance and sale of securities to purchasers directly by the issuer, with the issuer being paid the proceeds. A primary market means the market for new issues of securities, as distinguished from the secondary market, where previously issued securities are bought and sold. A market is primary if the proceeds of sales go to the issuer of the securities sold. Buyers buy securities that were not previously traded.\nConcept.\nIn a primary market, companies, governments, or public sector institutions can raise funds through bond issues, and corporations can raise capital through the sale of new stock through an initial public offering (IPO). This is often done through an investment bank or underwriter or finance syndicate of securities dealers. The process of selling new shares to buyers is called underwriting. Dealers earn a commission that is commonly built into the price of the security offering, though it can be found in the prospectus.\nIPOs are not the only way new securities are issued. Publicly traded companies can issue new shares in what is called a \"primary issue\" of debt or stock, which involves the issue by a corporation of its own debt or new stock directly to buyers like pension funds, or to private investors and shareholders.\nSince the securities are issued directly by the company to its buyers, the company receives the money and issues new security certificates to the buyers. The primary market plays the crucial function of facilitating capital formation within the economy. The securities issued at the primary market can be issued in \"face value\", \"premium value,\" or \"at par value.\"\nPrimary markets create long-term instruments through which corporate entities raise funds from the capital market. It is also known as the New Issue Market (NIM).\nOnce issued, the securities typically trade thereafter on a secondary market such as a stock exchange, bond market, or derivatives exchange.\nRaising funds.\nCorporate entities raise funds from the primary market in three ways:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41916", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=41916", "title": "Financial market", "text": "Generic term for all markets in which trading takes place with capital\nA financial market is a market in which people trade financial securities and derivatives at low transaction costs. Some of the securities include stocks and bonds, raw materials and precious metals, which are known in the financial markets as commodities.\nThe term \"market\" is sometimes used for what are more strictly \"exchanges\", that is, organizations that facilitate the trade in financial securities, e.g., a stock exchange or commodity exchange. This may be a physical location (such as the New York Stock Exchange (NYSE), London Stock Exchange (LSE), Bombay Stock Exchange (BSE), or Johannesburg Stock Exchange (JSE Limited)), or an electronic system such as NASDAQ. Much trading of stocks takes place on an exchange; still, corporate actions (mergers, spinoffs) are outside an exchange, while any two companies or people, for whatever reason, may agree to sell the stock from the one to the other without using an exchange.\nTrading of currencies and bonds is largely on a bilateral basis, although some bonds trade on a stock exchange, and people are building electronic systems for these as well.\nTypes of financial markets.\nWithin the financial sector, the term \"financial markets\" is often used to refer just to the markets that are used to raise finances. For long term finance, they are usually called the capital markets; for short term finance, they are usually called money markets. The money market deals in short-term loans, generally for a period of a year or less. Another common use of the term is as a catchall for all the markets in the financial sector, as per examples in the breakdown below.\nThe capital markets may also be divided into primary markets and secondary markets. Newly formed (issued) securities are bought or sold in primary markets, such as during initial public offerings. Secondary markets allow investors to buy and sell existing securities. The transactions in primary markets exist between issuers and investors, while secondary market transactions exist among investors.\nLiquidity is a crucial aspect of securities that are traded in secondary markets. Liquidity refers to the ease with which a security can be sold without a loss of value. Securities with an active secondary market mean that there are many buyers and sellers at a given point in time. Investors benefit from liquid securities because they can sell their assets whenever they want; an illiquid security may force the seller to get rid of their asset at a large discount.\nRaising capital.\nFinancial markets attract funds from investors and channels them to corporations\u2014they thus allow corporations to finance their operations and achieve growth. Money markets allow firms to borrow funds on a short-term basis, while capital markets allow corporations to gain long-term funding to support expansion (known as maturity transformation).\nWithout financial markets, borrowers would have difficulty finding lenders themselves. Intermediaries such as banks, Investment Banks, and Boutique Investment Banks can help in this process. Banks take deposits from those who have money to save on the form of savings a/c. They can then lend money from this pool of deposited money to those who seek to borrow. Banks popularly lend money in the form of loans and mortgages.\nMore complex transactions than a simple bank deposit require markets where lenders and their agents can meet borrowers and their agents, and where existing borrowing or lending commitments can be sold on to other parties. A good example of a financial market is a stock exchange. A company can raise money by selling shares to investors and its existing shares can be bought or sold.\nThe following table illustrates where financial markets fit in the relationship between lenders and borrowers:\nLenders.\nThe lender temporarily gives money to somebody else, on the condition of getting back the principal amount together with some interest or profit or charge.\nIndividuals and doubles.\nMany individuals are not aware that they are lenders, but almost everybody does lend money in many ways. A person lends money when he or she:\nCompanies.\n\"Companies\" tend to be lenders of capital. When companies have surplus cash that is not needed for a short period of time, they may seek to make money from their cash surplus by lending it via short term markets called money markets. Alternatively, such companies may decide to return the cash surplus to their shareholders (e.g. via a share repurchase or dividend payment).\nBanks.\nBanks can be lenders themselves as they are able to create new debt money in the form of deposits.\nBorrowers.\nGovernments borrow by issuing bonds. In the UK, the government also borrows from individuals by offering bank accounts and Premium Bonds. Government debt seems to be permanent. Indeed, the debt seemingly expands rather than being paid off. One strategy used by governments to reduce the \"value\" of the debt is to influence \"inflation\".\n\"Municipalities and local authorities\" may borrow in their own name as well as receiving funding from national governments. In the UK, this would cover an authority like Hampshire County Council.\n\"Public Corporations\" typically include nationalized industries. These may include the postal services, railway companies and utility companies.\nMany borrowers have difficulty raising money locally. They need to borrow internationally with the aid of Foreign exchange markets.\nBorrowers having similar needs can form into a group of borrowers. They can also take an organizational form like Mutual Funds. They can provide mortgage on weight basis. The main advantage is that this lowers the cost of their borrowings.\nDerivative products.\nDuring the 1980s and 1990s, a major growth sector in financial markets was the trade in so called derivatives.\nIn the financial markets, stock prices, share prices, bond prices, currency rates, interest rates and dividends go up and down, creating \"risk\". Derivative products are financial products that are used to \"control\" risk or paradoxically \"exploit\" risk. It is also called financial economics.\nDerivative products or instruments help the issuers to gain an unusual profit from issuing the instruments. For using the help of these products a contract has to be made. Derivative contracts are mainly four types:\nOver the past few decades, the derivatives market has increased and become essential to the financial industry. As the market expands, establishing and improving the regulatory framework becomes particularly critical. In response to the systemic risks exposed by the global economic crisis in 2008, essential regulations such as the Dodd-Frank Act (US) and the EU Market Fundamentals Regulation (MiFID II) were enacted.\nThese regulations have significantly changed the market structure and strengthened supervision and risk management of the derivatives market. Although regulatory measures have enhanced market stability, they have also had a broad impact on market participants' operating models and strategies.\nSeemingly, the most obvious buyers and sellers of currency are importers and exporters of goods. While this may have been true in the distant past, when international trade created the demand for currency markets, importers and exporters now represent only 1/32 of foreign exchange dealing, according to the Bank for International Settlements.\nThe picture of foreign currency transactions today shows:\n \"See Statistical analysis of financial markets\", \"statistical finance\"\nAnalysis of financial markets.\nMuch effort has gone into the study of financial markets and how prices vary with time. Charles Dow, one of the founders of Dow Jones &amp; Company and The Wall Street Journal, enunciated a set of ideas on the subject which are now called Dow theory. This is the basis of the so-called technical analysis method of attempting to predict future changes. One of the tenets of \"technical analysis\" is that market trends give an indication of the future, at least in the short term. The claims of the technical analysts are disputed by many academics, who claim that the evidence points rather to the random walk hypothesis, which states that the next change is not correlated to the last change. The role of human psychology in price variations also plays a significant factor. Large amounts of volatility often indicate the presence of strong emotional factors playing into the price. Fear can cause excessive drops in price and greed can create bubbles. In recent years the rise of algorithmic and high-frequency program trading has seen the adoption of momentum, ultra-short term moving average and other similar strategies which are based on technical as opposed to fundamental or theoretical concepts of market behaviour. For instance, according to a study published by the European Central Bank, high frequency trading has a substantial correlation with news announcements and other relevant public information that are able to create wide price movements (e.g., interest rates decisions, trade of balances etc.)\nThe scale of changes in price over some unit of time is called the volatility.\nIt was discovered by Benoit Mandelbrot that changes in prices do not follow a normal distribution, but are rather modeled better by L\u00e9vy stable distributions. The scale of change, or volatility, depends on the length of the time unit to a power a bit more than 1/2. Large changes up or down are more likely than what one would calculate using a normal distribution with an estimated standard deviation.\nComponents of financial market.\nBased on market levels.\nSimply put, primary market is the market where the newly started company issued shares to the public for the first time through IPO (initial public offering). Secondary market is the market where the second hand securities are sold (security Commodity Markets).\nSources.\n\u00a0This article incorporates text from a free content work. Licensed under CC BY 4.0. Text taken from https://, FAO, IFAD, UNICEF, WFP and WHO, FAO. \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt; "}
{"id": "41917", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=41917", "title": "Sodium laureth sulphate", "text": ""}
{"id": "41918", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=41918", "title": "Bond", "text": "Bond or bonds may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "41919", "revid": "86247", "url": "https://en.wikipedia.org/wiki?curid=41919", "title": "Bonds", "text": ""}
{"id": "41920", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=41920", "title": "Compact Disc Digital Audio", "text": "Data format used for audio compact discs\nCompact Disc Digital Audio (CDDA or CD-DA), also known as Digital Audio Compact Disc or simply as Audio CD, is the standard format for audio compact discs. The standard is defined in the \"Red Book\" technical specifications, which is why the format is also dubbed \"Redbook audio\" in some contexts. CDDA utilizes pulse-code modulation (PCM) and uses a 44,100 Hz sampling frequency and 16-bit resolution, and was originally specified to store up to 74 minutes of stereo audio per disc.\nThe first commercially available audio CD player, the Sony CDP-101, was released in October 1982 in Japan. The format gained worldwide acceptance in 1983\u201384, selling more than a million CD players in its first two years, to play 22.5 million discs, before overtaking records and cassette tapes to become the dominant standard for commercial music. Peaking around year 2000, the audio CD contracted over the next decade due to rising popularity and revenue from digital downloading, and during the 2010s by digital music streaming, but has remained as one of the primary distribution methods for the music industry. In the United States, phonograph record revenues surpassed the CD in 2020 for the first time since the 1980s, but in other major markets like Japan it remains the premier music format by a distance and in Germany it outsold other physical formats at least fourfold in 2022.\nIn the music industry, audio CDs have been generally sold as either a CD single (now largely dormant), or as full-length albums, the latter of which has been more commonplace since the 2000s. The format has also been influential in the progression of video game music, used in mixed mode CD-ROMs, providing CD-quality audio popularized during the 1990s on hardware such as PlayStation, Sega Saturn and personal computers with 16-bit sound cards like the Sound Blaster 16.\nHistory.\nThe optophone, first presented in 1913, was an early device that used light for both recording and playback of sound signals on a transparent photograph. More than thirty years later, American inventor James T. Russell has been credited with inventing the first system to record digital media on a photosensitive plate. Russell's patent application was filed in 1966, and he was granted a patent in 1970. Following litigation, Sony and Philips licensed Russell's patents for recording in 1988. It is debatable whether Russell's concepts, patents, and prototypes instigated and in some measure influenced the compact disc's design.\nThe compact disc is an evolution of LaserDisc technology, where a focused laser beam is used that enables the high information density required for high-quality digital audio signals. Unlike the prior art by Optophonie and James Russell, the information on the disc is read from a reflective layer using a laser as a light source through a protective substrate. Prototypes were developed by Philips and Sony independently in the late 1970s. Although originally dismissed by Philips Research management as a trivial pursuit, the CD became the primary focus for Philips as the LaserDisc format struggled. \nIn 1979, Sony and Philips set up a joint task force of engineers to design a new digital audio disc. The group of experts analyzed every detail of the proposed CD system and meet every two months alternating between Eindhoven and Tokyo for discussions. Each time, the experiments conducted were discussed and the best solution was chosen from the prototypes developed by Sony and Philips. After experimentation, the group decided to adopt Sony\u2019s error correction system, CIRC. Immink, in a few months' time, developed the recording code called eight-to-fourteen modulation (EFM). EFM increases the playing time by more than 30% compared to the code used in the Philips prototype, without causing any issues with tracking. Sony and Philips decide to include EFM in the official Philips/Sony CD standard. EFM and Sony\u2019s error correction code, CIRC are the only standard essential patents, (SEP)s, of the compact disc.\nAfter a year of experimentation and discussion, the \"Red Book\" CD-DA standard was published in 1980. After their commercial release in 1982, compact discs and their players were extremely popular. Despite costing up to $1,000, over 400,000 CD players were sold in the United States between 1983 and 1984. By 1988, CD sales in the United States surpassed those of vinyl LPs, and, by 1992, CD sales surpassed those of prerecorded music-cassette tapes. The success of the compact disc has been credited to the cooperation between Philips and Sony, which together agreed upon and developed compatible hardware. The unified design of the compact disc allowed consumers to purchase any disc or player from any company and allowed the CD to dominate the at-home music market unchallenged.\nDigital audio laser-disc prototypes.\nIn 1974, Lou Ottens, director of the audio division of Philips, started a small group to develop an analog optical audio disc with a diameter of and a sound quality superior to that of the vinyl record. However, due to the unsatisfactory performance of the analog format, two Philips research engineers recommended a digital format in March 1974. In 1977, Philips then established a laboratory with the mission of creating a digital audio disc. The diameter of Philips's prototype compact disc was set at , the diagonal of an audio cassette.\nHeitaro Nakajima, who developed an early digital audio recorder within Japan's national public broadcasting organization, NHK, in 1970, became general manager of Sony's audio department in 1971. In 1973, his team developed a digital PCM adaptor that made audio recordings using a Betamax video recorder. After this, in 1974 the leap to storing digital audio on an optical disc was easily made. Sony first publicly demonstrated an optical digital audio disc in September 1976. A year later, in September 1977, Sony showed the press a disc that could play an hour of digital audio (44,100\u00a0Hz sampling rate and 16-bit resolution) using modified frequency modulation encoding. \nIn September 1978, Sony demonstrated an optical digital audio disc with a diameter of with a 150-minute playing time, 44,056\u00a0Hz sampling rate, 16-bit linear resolution, and cross-interleaved Reed-Solomon coding (CIRC) error correction code\u2014specifications similar to those later settled upon for the standard compact disc format in 1980. Technical details of Sony's digital audio disc were presented during the 62nd AES Convention, held on 13\u201316 March 1979, in Brussels. Sony's AES technical paper was published on 1 March 1979. A week later, on 8 March, Philips publicly demonstrated a prototype of an optical digital audio disc at a press conference called \"Philips Introduce Compact Disc\" in Eindhoven, Netherlands. Sony executive Norio Ohga, later CEO and chairman of Sony, and Heitaro Nakajima were convinced of the format's commercial potential and pushed further development despite widespread skepticism.\nCollaboration and standardization.\nIn 1979, Sony and Philips set up a joint task force of engineers to design a new digital audio disc. Led by engineers Kees Schouhamer Immink and Toshitada Doi, the research pushed forward laser and optical disc technology. After a year of experimentation and discussion, the task force produced the \"Red Book\" CD-DA standard. First published in 1980, the standard was formally adopted by the IEC as an international standard in 1987, with various amendments becoming part of the standard in 1996.\nPhilips coined the term \"compact disc\" in line with another audio product, the Compact Cassette, and contributed the general manufacturing process, based on video LaserDisc technology. Philips also contributed eight-to-fourteen modulation (EFM), while Sony contributed the error-correction method, CIRC, which offers resilience to defects such as scratches and fingerprints.\n\"The Compact Disc Story\", told by a former member of the task force, gives background information on the many technical decisions made, including the choice of the sampling frequency, playing time, and disc diameter. The task force consisted of around 6 persons, though according to Philips, the compact disc was \"invented collectively by a large group of people working as a team\".\nInitial launch and adoption.\nEarly milestones in the launch and adoption of the format included:\nThe first artist to sell a million copies on CD was Dire Straits, with their 1985 album \"Brothers in Arms\". One of the first CD markets was devoted to reissuing popular music whose commercial potential was already proven. The first major artist to have their entire catalog converted to CD was David Bowie, whose first fourteen studio albums (up to \"Scary Monsters (and Super Creeps)\") of (then) sixteen were made available by RCA Records in February 1985, along with four greatest hits albums; his fifteenth and sixteenth albums (\"Let's Dance\" and \"Tonight\", respectively) had already been issued on CD by EMI Records in 1983 and 1984, respectively. On 26 February 1987, the first four UK albums by the Beatles were released in mono on compact disc.\nThe growing acceptance of the CD in 1983 marked the beginning of the popular digital audio revolution. It was enthusiastically received, especially in the early-adopting classical music and audiophile communities, and its handling quality received particular praise. As the price of players gradually came down, and with the introduction of the portable Discman, the CD began to gain popularity in the larger popular and rock music markets. With the rise in CD sales, pre-recorded cassette tape sales began to decline in the late 1980s; CD sales overtook cassette sales in the early 1990s. In 1988, 400 million CDs were manufactured by 50 pressing plants around the world.\nFurther development.\nEarly CD players employed binary-weighted digital-to-analog converters (DAC), which contained individual electrical components for each bit of the DAC. Even when using high-precision components, this approach was prone to decoding errors. Another issue was jitter, a time-related defect. Confronted with the instability of DACs, manufacturers initially turned to increasing the number of bits in the DAC and using several DACs per audio channel, averaging their output. This increased the cost of CD players but did not solve the core problem.\nA breakthrough in the late 1980s culminated in development of the 1-bit DAC, which converts high-resolution low-frequency digital input signal into a lower-resolution high-frequency signal that is mapped to voltages and then smoothed with an analog filter. The temporary use of a lower-resolution signal simplified circuit design and improved efficiency, which is why it became dominant in CD players starting from the early 1990s. Philips used a variation of this technique called pulse-density modulation (PDM), while Matsushita (now Panasonic) chose pulse-width modulation (PWM), advertising it as MASH, which is an acronym derived from their patented Multi-stAge noiSe-sHaping PWM topology.\nThe CD was primarily planned as the successor to the vinyl record for playing music, rather than as a data storage medium. However, CDs have grown to encompass other applications. In 1983, following the CD's introduction, Immink and Joseph Braat presented the first experiments with erasable compact discs during the 73rd AES Convention. In June 1985, the computer-readable CD-ROM (read-only memory) and, in 1990, recordable CD-R discs were introduced. Recordable CDs became an alternative to tape for recording and distributing music and could be duplicated without degradation in sound quality.\nOther newer video formats such as DVD and Blu-ray use the same physical geometry as CD, and most DVD and Blu-ray players are backward compatible with audio CDs.\nPeak.\nCD sales in the United States peaked by 2000. By the early 2000s, the CD player had largely replaced the audio cassette player as standard equipment in new automobiles, with 2010 being the final model year for any car in the United States to have a factory-equipped cassette player.\nTwo new formats were marketed in the 2000s designed as successors to the CD: the Super Audio CD (SACD) and DVD-Audio. However neither of these were adopted partly due to increased relevance of digital (virtual) music and the apparent lack of audible improvements in audio quality to most human ears. These effectively extended the CD's longevity in the music market.\nDecline.\nWith the advent and popularity of Internet-based distribution of files in lossy-compressed audio formats such as MP3, sales of CDs began to decline in the 2000s. For example, between 2000 and 2008, despite overall growth in music sales and one anomalous year of increase, major-label CD sales declined overall by 20%. Despite rapidly declining sales year-over-year, the pervasiveness of the technology lingered for a time, with companies placing CDs in pharmacies, supermarkets, and filling station convenience stores to target buyers less likely to be able to use Internet-based distribution. \nIn 2012, CDs and DVDs made up only 34% of music sales in the United States. By 2015, only 24% of music in the United States was purchased on physical media, two thirds of this consisting of CDs; however, in the same year in Japan, over 80% of music was bought on CDs and other physical formats. In 2018, U.S. CD sales were 52 million units\u2014less than 6% of the peak sales volume in 2000. In the UK, 32\u00a0million units were sold, almost 100\u00a0million fewer than in 2008. In 2018, Best Buy announced plans to decrease their focus on CD sales, however, while continuing to sell records, sales of which are growing during the vinyl revival. \nDuring the 2010s, the increasing popularity of solid-state media and music streaming services caused automakers to remove automotive CD players in favor of minijack auxiliary inputs, wired connections to USB devices and wireless Bluetooth connections. Automakers viewed CD players as using up valuable space and taking up weight which could be reallocated to more popular features, like large touchscreens. By 2021, only Lexus and General Motors were still including CD players as standard equipment with certain vehicles.\nCurrent status.\nCDs continued to be strong in some markets such as Japan where 132 million units were produced in 2019.\nThe decline in CD sales has slowed in recent years; in 2021, CD sales increased in the US for the first time since 2004, with Axios citing its rise to \"young people who are finding they like hard copies of music in the digital age\". It came at the same time as both vinyl and cassette reached sales levels not seen in 30 years. The RIAA reported that CD revenue made a dip in 2022, before increasing again in 2023 and overtook downloading for the first time in over a decade.\nIn the US, 33.4 million CD albums were sold in the year 2022. In France in 2023, 10.5 million CDs were sold, almost double that of vinyl, but both of them represented generated 12% each of the French music industry revenues.\nAwards and accolades.\nSony and Philips received praise for the development of the compact disc from professional organizations. These awards include:\nStandard.\nThe \"Red Book\" specifies the physical parameters and properties of the CD, the optical parameters, deviations and error rate, modulation system (eight-to-fourteen modulation, EFM) and error correction facility (CIRC), and the eight subcode channels. These parameters are common to all compact discs and used by all logical formats: audio CD, CD-ROM, etc. The standard also specifies the form of digital audio encoding.\nThe first edition of the \"Red Book\" was released in 1980 by Philips and Sony; it was adopted by the Digital Audio Disc Committee and ratified by the International Electrotechnical Commission (IEC) Technical Committee 100 as an international standard in 1987 with the reference IEC 60908. The second edition of IEC 60908 was published in 1999 and it replaces the first edition, amendment 1 (1992) and the corrigendum to amendment 1. The IEC 60908 however does not contain all the information for extensions that is available in the \"Red Book\", such as the details for CD-Text, CD+G and CD+EG.\nThe standard is not freely available and must be licensed. It is available from Philips and the IEC. As of 2013[ [update]], Philips outsources licensing of the standard to Adminius, which charges US$ for the \"Red Book\", plus US$ each for the \"Subcode Channels R-W\" and \"CD Text Mode\" annexes.\nAudio format.\nThe audio contained in a CD-DA consists of two-channel signed 16-bit LPCM sampled at 44,100 Hz and written as a little-endian interleaved stream with left channel coming first.\nThe sampling rate is adapted from that attained when recording digital audio on videotape with a PCM adaptor, an earlier way of storing digital audio. An audio CD can represent frequencies up to 22.05\u00a0kHz, the Nyquist frequency of the 44.1\u00a0kHz sample rate.\nThere was a long debate over the use of 16-bit (Sony) or 14-bit (Philips) quantization, and 44,056 or 44,100 samples/s (Sony) or approximately 44,000 samples/s (Philips). When the Sony/Philips task force designed the Compact Disc, Philips had already developed a 14-bit D/A converter (DAC), but Sony insisted on 16-bit. In the end Sony won, so 16 bits and 44.1 kilosamples per second prevailed. Philips found a way to produce 16-bit quality using its 14-bit DAC by using four times oversampling.\nSome early CDs were mastered with pre-emphasis, an artificial boost of high audio frequencies. The pre-emphasis improves the apparent signal-to-noise ratio by making better use of the channel's dynamic range. On playback, the player applies a de-emphasis filter to restore the frequency response curve to an overall flat one. Pre-emphasis time constants are 50\u00a0\u03bcs and 15\u00a0\u03bcs (9.49\u00a0dB boost at 20\u00a0kHz), and a binary flag in the disc subcode instructs the player to apply de-emphasis filtering if appropriate. Playback of such discs in a computer or ripping to WAV files typically does not take into account the pre-emphasis, so such files play back with an incorrect frequency response. FFmpeg has a filter to remove (or apply) the pre-emphasis in order to create standard WAV files, or to create CDs with pre-emphasis.\nFour-channel, or quadraphonic, support was originally intended to be included in CD-DA. The \"Red Book\" specification briefly mentioned a four-channel mode in its June 1980, September 1983, and November 1991 editions. On the first page, it lays out the \"Main parameters\" of the CD system, including: \"Number of channels: 2 and/or 4 simultaneously[*] sampled.\" The footnote says, \"In the case of more than two channels the encoder and decoder diagrams have to be adapted.\"\nIn reality, however, the underspecified \"four-channel\" mode was dropped from the CD standard when it was adopted by the International Electrotechnical Commission and became IEC 908:1987, and later IEC 60908:1999. Since the behavior of the \"four-channel\" or \"Broadcasting use\" bit was never specified by either CD standard, no mass-marketed discs have attempted to use the Red Book's four-channel mode, and no players have purported to implement it.\nStorage capacity and playing time.\nThe creators of the CD originally aimed at a playing time of 60 minutes with a disc diameter of 100\u00a0mm (Sony) or 115\u00a0mm (Philips). Sony vice-president Norio Ohga suggested extending the capacity to 74 minutes and 33 seconds to accommodate the recording of Wilhelm Furtw\u00e4ngler conducting Ludwig van Beethoven's Ninth Symphony at the 1951 Bayreuth Festival. The additional 14-minute playing time required increasing disc diameter. Kees Schouhamer Immink, Philips' chief engineer, however, denies this, claiming that the increase was motivated by technical considerations and that even after the increase in size, the Furtw\u00e4ngler recording would not have fit onto one of the earliest CDs.\nAccording to a \"Sunday Tribune\" interview, the story is slightly more involved. In 1979, Philips owned PolyGram, one of the world's largest music distributors. PolyGram had set up a large experimental CD plant in Hannover, Germany, which could produce huge numbers of CDs having a diameter of 115\u00a0mm. Sony did not yet have such a facility. If Sony had agreed on the 115-mm disc, Philips would have had a significant competitive edge in the market. The long playing time of Beethoven's Ninth Symphony imposed by Ohga was used to push Philips to accept 120\u00a0mm, so that Philips' PolyGram lost its edge on disc fabrication.\nThe 74:33 playing time of a CD, which is longer than the 22 minutes per side typical of long-playing (LP) vinyl albums, was often used to the CD's advantage during the early years when CDs and LPs vied for commercial sales. CDs would often be released with one or more bonus tracks, enticing consumers to buy the CD for the extra material. However, attempts to combine double LPs onto one CD occasionally resulted in the opposite situation in which the CD would instead offer less audio than the LP. One such example was with DJ Jazzy Jeff &amp; The Fresh Prince's double album \"He's the DJ, I'm the Rapper\", in which initial CD releases of the album had multiple tracks edited down for length to fit on a single disc; recent CD reissues package the album across two discs as a result. Furthermore, early CD releases were restricted by the 72-minute limit of 3/4\u00a0inch U-matic tapes used by early PCM adaptors; by 1988, higher-capacity alternatives would arrive on the market, allowing for releases to make use of the full 74:33. This and the emergence of 80-minute CDs allowed for some double albums that were previously edited for length, e.g. \"1999\" by Prince, or packaged as double CDs, e.g. \"Tommy\" by the Who, to be re-released on a single disc.\nPlaying times beyond 74:33 are achieved by decreasing track pitch (the distance separating the track as it spirals the disc). However, most players can still accommodate the more closely spaced data if it is still within \"Red Book\" tolerances. Manufacturing processes used in the final years of CD technology allowed an audio CD to contain up to 82 minutes (variable from one replication plant to another) without requiring the content creator to sign a waiver releasing the plant owner from responsibility if the CD produced is marginally or entirely unreadable by some playback equipment. In this final practice, maximum CD playing time crept higher by reducing minimum engineering tolerances.\nTechnical specifications.\nData encoding.\nEach audio sample is a signed 16-bit two's complement integer, which has sample values ranging from \u221232768 to +32767. The source audio data is divided into frames, containing twelve samples each (six left and six right samples, alternating), for a total of 192 bits (24 bytes) of audio data per frame.\nThis stream of audio frames is then subjected to CIRC encoding, which segments and rearranges the data and expands it with error correction codes in a way that allows occasional read errors to be detected and corrected. CIRC encoding interleaves the audio frames throughout the disc over several consecutive frames so that the information will be more resistant to burst errors. Therefore, a physical frame on the disc will actually contain information from multiple logical audio frames. This process adds 64 bits of error correction codes to each frame. After this, 8 bits of subcode data are added to each of these encoded frames, which is used for control and addressing when playing the CD.\nCIRC encoding plus the subcode byte generates 33-byte long frames, called \"channel-data\" frames. These frames are then modulated through eight-to-fourteen modulation (EFM), where each 8-bit byte is replaced with a corresponding 14-bit word designed to reduce the number of transitions between 0 and 1. This reduces the density of physical pits on the disc and provides an additional degree of error tolerance. Three \"merging\" bits are added before each 14-bit word for disambiguation and synchronization. In total, there are 33\u00a0\u00d7 (14\u00a0+ 3)\u00a0= 561 bits. A 27-bit word (a 24-bit pattern plus 3 merging bits) is added to the beginning of each frame to assist with synchronization, so the reading device can locate frames easily. With this, a frame ends up containing 588 bits of \"channel data\" which are decoded to 192 bits of digital audio.\nThe frames of channel data are finally written to disc physically in the form of pits and lands, with each pit or land representing a series of zeroes, and with the transition points\u2014the edge of each pit\u2014representing a 1. A \"Red Book\"-compatible CD-R has pit-and-land-shaped spots on a layer of organic dye instead of actual pits and lands; a laser creates the spots by altering the reflective properties of the dye.\nDue to the weaker error correction sector structure used on audio CDs and video CDs (\"Mode 2 Form 2\") than on data discs (\"Mode 1\" or \"Mode 2 Form 1\"), C2 errors are not correctable and signify data loss. Even with uncorrectable errors, a compact disc player uses error concealment with the aim of making the damage unhearable.\nData structure.\nThe audio data stream in an audio CD is continuous but has three parts. The main portion, further divided into playable audio tracks, is the \"program area\". This section is preceded by a \"lead-in\" track and followed by a \"lead-out\" track. The lead-in and lead-out tracks encode only silent audio, but all three sections contain subcode data streams.\nThe lead-in's subcode contains repeated copies of the disc's table of contents (TOC), which provides an index of the start positions of the tracks in the program area and of the lead-out. The track positions are referenced by absolute timecode, relative to the start of the program area, in MSF format: minutes, seconds, and fractional seconds called \"frames\". Each \"timecode frame\" is one seventy-fifth of a second, and corresponds to a block of 98 \"channel-data frames\"\u2014ultimately, a block of 588 pairs of left and right audio samples. Timecode contained in the subchannel data allows the reading device to locate the region of the disc that corresponds to the timecode in the TOC. The TOC on discs is analogous to the partition table on hard drives. Nonstandard or corrupted TOC records are abused as a form of CD/DVD copy protection, in e.g. the key2Audio scheme.\nTracks.\nThe largest entity on a CD is called a track. A CD can contain up to 99 tracks (including a data track for mixed mode discs). Each track can in turn have up to 100 indexes, though players that still support this feature have become rarer over time. The vast majority of songs are recorded under index 1, with the pregap being index 0. Sometimes hidden tracks are placed at the end of the last track of the disc, often using index 2 or 3, or using the pregap as index 0 (this latter usage will result in the track playing as the time counter counts down to time 0:00 at the start of the track, index 1.) This is also the case with some discs offering \"101 sound effects\", with 100 and 101 being indexed as two and three on track 99. The index, if used, is occasionally put on the track listing as a decimal part of the track number, such as 99.2 or 99.3. The track and index structure of the CD were carried forward to the DVD format as title and chapter, respectively.\nTracks, in turn, are divided into timecode frames, which are further subdivided into channel-data frames.\nFrames and timecode frames.\nThe smallest entity in a CD is a channel-data \"frame\", which consists of 33 bytes and contains six complete 16-bit stereo samples: 24 bytes for the audio (two bytes\u00a0\u00d7 two channels\u00a0\u00d7 six samples\u00a0= 24 bytes), eight CIRC error-correction bytes, and one subcode byte. As described in , after the EFM modulation the number of bits in a frame totals 588.\nOn a \"Red Book\" audio CD, data is addressed using the \"MSF scheme\", with timecodes expressed in minutes, seconds and another type of \"frames\" (mm:ss:ff), where one frame corresponds to 1/75th of a second of audio: 588 pairs of left and right samples. This timecode frame is distinct from the 33-byte channel-data frame described above, and is used for time display and positioning the reading laser. When editing and extracting CD audio, this timecode frame is the smallest addressable time interval for an audio CD; thus, track boundaries only occur on these frame boundaries. Each of these structures contains 98 channel-data frames, totaling 98\u00a0\u00d7 24\u00a0= 2,352 bytes of music. The CD is played at a speed of 75 frames per second, 44,100 samples and 176,400 bytes per second.\nIn the 1990s, CD-ROM and related digital audio extraction (DAE) technology introduced the term \"sector\" to refer to each timecode frame, with each sector being identified by a sequential integer starting at zero, and with tracks aligned on sector boundaries. An audio CD sector corresponds to 2,352 bytes of decoded data. The \"Red Book\" does not refer to sectors, nor does it distinguish the corresponding sections of the disc's data stream except as \"frames\" in the MSF addressing scheme.\nThe following table shows the relation between tracks, timecode frames (sectors) and channel-data frames:\nBit rate.\nThe audio bit rate for a \"Red Book\" audio CD is 1,411,200 bits per second (1,411\u00a0kbit/s) or 176,400 bytes per second; 2 channels\u00a0\u00d7 44,100 samples per second per channel\u00a0\u00d7 16 bits per sample. Audio data coming in from a CD is contained in sectors, each sector being 2,352 bytes, and with 75 sectors representing 1 second of audio. For comparison, the bit rate of an original speed CD-ROM is 2,048 bytes per sector\u00a0\u00d7 75 sectors per second\u00a0= 153,600 bytes per second. The remaining 304 bytes in a CD-ROM sector are used for additional data error correction.\nData access from computers.\nUnlike on a DVD or CD-ROM, there are no files on a \"Red Book\" audio CD; there is only one continuous stream of LPCM audio data, and a parallel, smaller set of 8 subcode data streams. Computer operating systems, however, may provide access to an audio CD as if it contains files. For example, Windows represents the CD's table of contents as a set of Compact Disc Audio track (CDA) files, each file containing indexing information, not audio data. By contrast however, Finder on macOS presents the CD's content as an actual set of files, with the AIFF-extension, which can be copied directly, randomly and individually by track as if it were actual files. In reality, macOS performs rips as needed in the background, transparent to the user. The copied tracks are fully playable and editable on the user's computer.\nIn a process called ripping, digital audio extraction software can be used to read CD-DA audio data and store it in files. Common audio file formats for this purpose include WAV and AIFF, which simply preface the LPCM data with a short header; FLAC, ALAC, and Windows Media Audio Lossless, which compress the LPCM data in ways that conserve space yet allow it to be restored without any changes; and various lossy, perceptual coding formats like MP3, AAC, and Opus, compress the audio data to a greater degree in ways that irreversibly change the audio, but that exploit features of human hearing to make the changes difficult to discern.\nFormat variations.\nRecording publishers have created CDs that violate the \"Red Book\" standard. Some do so for the purpose of copy protection, using systems like Copy Control. Some do so for extra features such as DualDisc, which includes both a CD layer and a DVD layer in which the CD layer is thinner, 0.9\u00a0mm, than required by the \"Red Book\", which stipulates a nominal 1.2\u00a0mm, but at least 1.1\u00a0mm. Philips and many other companies have stated that including the Compact Disc Digital Audio logo on such non-conforming discs may constitute trademark infringement.\nSuper Audio CD was a standard published in 1999 that aimed to provide better audio quality than CDs. DVD-Audio emerged at around the same time. Both formats were designed to use a higher sampling rate and DVD media. Neither format was widely accepted.\nCopyright issues.\nThere have been moves by the recording industry to make audio CDs (Compact Disc Digital Audio) unplayable on computer CD-ROM drives, to prevent the copying of music. This is done by intentionally introducing errors onto the disc that the embedded circuits on most stand-alone audio players can automatically compensate for, but which may confuse CD-ROM drives. Consumer rights advocates as of October 2001 pushed to require warning labels on compact discs that do not conform to the official Compact Disc Digital Audio standard (often called the \"Red Book\") to inform consumers which discs do not permit full fair use of their content.\nIn 2005, Sony BMG Music Entertainment was criticized when a copy protection mechanism known as Extended Copy Protection (XCP) used on some of their audio CDs automatically and surreptitiously installed copy-prevention software on computers (see Sony BMG copy protection rootkit scandal). Such discs are not legally allowed to be called CDs or Compact Discs because they break the \"Red Book\" standard governing CDs, and Amazon.com for example describes them as \"copy protected discs\" rather than \"compact discs\" or \"CDs\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41923", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=41923", "title": "Red book", "text": ""}
{"id": "41924", "revid": "49195408", "url": "https://en.wikipedia.org/wiki?curid=41924", "title": "Mnemonic major system", "text": "Mnemonic technique for memorizing long strings of numbers\nThe mnemonic major system (also called the phonetic number system, phonetic mnemonic system, or H\u00e9rigone's mnemonic system) is a mnemonic technique used to help in memorizing numbers.\nThe system works by converting numbers into consonants, then into words by adding vowels. The system works on the principle that images can be remembered more easily than numbers.\nOne notable explanation of this system was given in Martin Gardner's book \"The First Scientific American Book of Mathematical Puzzles and Diversions\" (just \"Mathematical Puzzles and Diversions\" in the UK edition), which has since been republished in \"The New Martin Gardner Mathematical Library\" as \"Hexaflexagons, Probability Paradoxes, and the Tower of Hanoi\". In this, Gardner traces the history of the system back to similar systems of Pierre H\u00e9rigone and Richard Grey with uses by Lewis Carroll and Gottfried Wilhelm Leibniz.\nThe system.\nEach numeral is associated with one or more consonants. The link is to the sound, not the letter. (For example, the letters C in \"call\", \"cell\", and \"cello\" each have different values in the system: 7, 0, and 6, respectively.) Vowels, semivowels and the consonant /h/ are ignored. These can be used as \"fillers\" to make sensible words from the resulting consonant sequences. A standard mapping is:\nThe groups of similar sounds and the rules for applying the mappings are almost always fixed, but other hooks and mappings can be used as long as the person using the system can remember them and apply them consistently.\nEach numeral maps to a set of similar sounds with similar mouth and tongue positions. The link is phonetic, that is to say, it is the consonant sounds that matter, not the spelling. Therefore, a word like \"action\" would encode the number \"762\" (/k/-/\u0283/-/n/), not \"712\" (\"k\"-\"t\"-\"n\"). Double letters are disregarded when not pronounced separately, e.g. \"muddy\" encodes \"31\" (/m/-/d/), not \"311\", but \"midday\" encodes \"311\" (/m/-/d/-/d/) while \"accept\" encodes \"7091\" (/k/-/s/-/p/-/t/) since the \"d\"s and \"c\"s are pronounced separately. \"x\" encodes \"70\" when pronounced as /ks/ or /gz/ (e.g. in \"fax\" and \"exam\") and \"76\" when pronounced /k\u0283/ or /g\u0292/ (e.g. in \"anxious\" or \"luxury\"); \"z\" encodes \"10\" when pronounced /ts/ (e.g. in \"pizza\"). In \"ghost\" (\"701\", /\u0261/-/s/-/t/) and \"enough\" (\"28\", /n/-/f/), \"gh\" is being encoded by different numerals. Usually, a rhotic accent is assumed, e.g. \"fear\" would encode \"84\" (/f/-/r/) rather than \"8\" (/f/).\nOften the mapping is compact. \"Hindquarters\", for example, translates unambiguously to \"2174140\" (/n/-/d/-/k/-/r/-/t/-/r/-/z/), which amounts to a twelve-letter word encoded by seven digits in seven letters, and can be easily visualized.\nEach numeral maps to a set of similar sounds with similar mouth and tongue positions.\nFor most people it would be easier to remember \"3.1415927\" (an approximation of the mathematical constant pi) as:\n \"meteor\" (\"314\", /m/-/t/-/r/)\n \"tail\" (\"15\", /t/-/l/)\n \"pink\" (\"927\", /p/-/\u014b/-/k/, and taking /\u014b/ to be \"2\")\nShort term visual memory of imagined scenes allows large numbers of digits to be memorized with ease. Longer-term memory may require the formulation of more object-related mnemonics with greater logical connection, perhaps forming grammatical sentences that apply to the matter rather than just strings of images.\nThe system can be employed with phone numbers. One would typically make up multiple words, preferably a sentence, or an ordered sequence of images featuring the owner of the number.\nThe Major System can be combined with a peg system for remembering lists, and is sometimes used also as a method of generating the pegs. It can also be combined with other memory techniques such as rhyming, substitute words, or the method of loci. Repetition and concentration using the ordinary memory is still required.\nIt is possible to use a computer to automatically translate the number into a set of words. One can then pick the best of several alternatives. Such programs include \"Numzi\" \"Rememberg\" \"Fonbee\", the freeware \"2Know\", and the website \"pinfruit\".\nExample words.\nSome of these example words may belong to more than one word category.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nHistory.\nThe mnemonic major system is a widely used phonetic number memorization technique that associates numbers with sounds or words to make them easier to recall. This system is part of a broader tradition of phonetic number systems found across different cultures. For instance, in India, the Katapayadi system, which dates back to at least the 7th century, represents another ancient and sophisticated approach to encoding numbers using phonetic values.\nA different memory system, the method of loci, was taught to schoolchildren for centuries, at least until 1584, \"when Puritan reformers declared it unholy for encouraging bizarre and irreverent images.\" The same objection can be made over the major system, with or without the method of loci. Mental images may be easier to remember if they are insulting, violent, or obscene (see Von Restorff effect).\nPierre H\u00e9rigone (1580\u20131643) devised the earliest version of the major system and published it in 1634. The system was further developed by Johann Just Winckelmann (pseudonym Stanislaus Mink von Weunsshein and published in 1648. It was later elaborated upon by other users. In 1730, Richard Grey set forth a complicated system that used both consonants and vowels to represent the digits. In 1808 Gregor von Feinaigle introduced the improvement of representing the digits by consonants (but reversed the values of 8 and 9 compared to those listed above).\nIn 1825 Aim\u00e9 Paris published the first known version of the major system in its modern form.\nIn 1843, Carl Otto Reventlow (1817\u20131873) published a mnemonics textbook on a method similar to Paris' and traveled throughout Germany promoting it.\nIn 1844 Francis Fauvel Gouraud (1808\u20131847) delivered a series of lectures introducing his mnemonic system which was based on Aim\u00e9 Paris' version. The lectures drew some of the largest crowds ever assembled to hear lectures of a \"scientific\" nature up to that time. This series of lectures was later published as \"Phreno-Mnemotechny or The Art of Memory\" in 1845 and his system received wide acclaim. According to Gouraud, Richard Grey indicated that a discussion on Hebrew linguistics in William Beveridge's \"Institutionum chronotogicarum libri duo, una cum totidem arithmetices chronologic\u00e6 libellis\" (London, 1669) inspired him to create his system of mnemotechniques which later evolved in to the major system.\nIn the 1880s Marcus Dwight Larrowe, alias Silas Holmes, was teaching memory courses in the United States based on the Major System using a third alias Dr. Antoine Loisette. Because he was charging inordinate sums of money for a system which had obviously existed before, George S. Fellows published \"\"Loisette\" exposed\" (1888) and included all the material of Larrowe's course which he determined not to be under copyright. The incident was notable enough to gain coverage by way of a book review in the journal \"Science\". A well-known student of Loisette's included Mark Twain whose endorsement Loisette used regularly to sell his course. Following the revelation that he had not originated the system, Larrowe self-published his material under the pseudonym Dr. Antoine Loisette in 1895 and 1896 and it was later re-published by Funk &amp; Wagnalls in 1899.\nIn the late 1800s Christof Ludwig Poehlmann (aka Christopher Louis Pelman), a German who had emigrated to the United States, and William Joseph Ennever created and ran a series of booklets and memory courses using the system which resulted in The Pelman Schools, The Pelman Institute, and were generally known as Pelmanism.\nPoehlmann eventually moved back to Germany around 1910 where he continued offering his memory courses and training apparently with a focus on language learning. Bruno F%C3%BCrst indicated that he studied under him for a year in 1911. F\u00fcrst later practiced criminal law in Frankfort in pre-Hitler Germany before fleeing, as a Jew, to Prague where he taught at Masaryk University until emigrating to New York in 1939. In 1939, F\u00fcrst published \"Use your Head\" followed by \"How to Remember\" (1944), which was later reprinted as \"The Practical Way to Better Memory\", and followed up with a series of 12 booklets entitled \"You Can Remember! A Home Study Course in Memory and Concentration\" (1946) which all extolled the system, which he called the \"Basic List\" and the \"Number System\" along with other mnemonic systems. In a 1946 profile in \"The New Yorker\", Bruno indicates that German scholar Conradus Celtes originated the system.\nThe system described in this article would be re-popularized after 1957 and through the 1980s in several books by Harry Lorayne, a magician and best selling contemporary author on memory. The most popular of the titles featuring the system is \"The Memory Book: The Classic Guide to Improving Your Memory at Work, at School, and at Play\" (1974, with Jerry Lucas).\nThis phonetic system had another resurgence in the 1990s thanks to the late night infomercials of Kevin Trudeau who sold a series of tapes called . He also published a similar book \"Kevin Trudeau's Mega Memory\" which used this same system with some slight modifications.\nThe name \"Major System\" may refer to Major Bartlomiej Beniowski, who published a version of the system in his book, \"The Anti-Absurd or Phrenotypic English Pronouncing and Orthographical Dictionary\" in 1845.\nThere is a reasonable historical possibility that the roots of the Major System are entangled with older systems of shorthand. It is certainly the case that the underlying structure of the Major System has a direct overlap with Gregg shorthand, which was a popular shorthand system in the late 1800s and early 1900s.\nPractice.\nMemory feats centered around numbers can be performed by experts who have learned a 'vocabulary' of at least one image for each 1 and 2-digit number, as these can then be combined to form narratives. Learning a vocabulary of 3-digit numbers is harder, because ten times more images need to be learned for each extra digit. Many mnemonists, however, can use a set of over 1000 images.\nThe combination of images into a narrative is easier to do rapidly than forming a coherent grammatical sentence. This pre-memorisation and practice at forming images reduces the time required to think up a good imaginary object while creating a strong memorable impression of it. The best words for this purpose are usually nouns, especially those for distinctive objects such as those which make strong impressions on a variety of senses (e.g. \"Lime\" for 53, as its taste, smell, colour, and even texture are distinctive) or which move (e.g. \"arrow\" for 4). For basic proficiency, a large vocabulary of image words is not really necessary, since when the table above is reliably learned, it is easy to form your own words ad hoc.\nIndexing sequences.\nMnemonics often center around learning a complete sequence where all objects in that sequence that come before the one you are trying to recall must be recalled first. For instance, when using the mnemonic \"Richard of York gave battle in vain\" to learn the colours of the rainbow, (red, orange, yellow, green, blue, indigo and violet) to remember what colour comes after indigo, one would have to recall the whole sequence. For a short sequence this may be trivial; for longer lists, it can become complicated and error-prone.\nA good example would be in recalling the 53rd element of the periodic table. It might be possible to construct and learn a string of 53 or more items, each of which links to an element and then to recall them one by one sequentially. But it would be a great deal easier to directly associate element 53 with, for example, a lime (a suitable mnemonic for 53) recalling some prior imagining of a mishap where lime juice gets into one's eye - \"eye\" sounding like \"I\", the symbol for \"Iodine\". This allows random access directly to the item, without the need for recalling any previous items.\nTo remember element 54 one might then recall an image for 54, for instance a friend called \"Laura\" (54), in the lotus position looking very Zen-like as a mnemonic that element 54 is \"Xenon\".\nThis is an example of combining the Major System with the peg system.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "41925", "revid": "25859633", "url": "https://en.wikipedia.org/wiki?curid=41925", "title": "Php", "text": ""}
{"id": "41926", "revid": "1262140707", "url": "https://en.wikipedia.org/wiki?curid=41926", "title": "Nearest neighbour algorithm", "text": "Algorithm for the travelling salesman problem\nThe nearest neighbour algorithm was one of the first algorithms used to solve the travelling salesman problem approximately. In that problem, the salesman starts at a random city and repeatedly visits the nearest city until all have been visited. The algorithm quickly yields a short tour, but usually not the optimal one.\nAlgorithm.\nThese are the steps of the algorithm:\nThe sequence of the visited vertices is the output of the algorithm.\nThe nearest neighbour algorithm is easy to implement and executes quickly, but it can sometimes miss shorter routes which are easily noticed with human insight, due to its \"greedy\" nature. As a general guide, if the last few stages of the tour are comparable in length to the first stages, then the tour is reasonable; if they are much greater, then it is likely that much better tours exist. Another check is to use an algorithm such as the lower bound algorithm to estimate if this tour is good enough.\nIn the worst case, the algorithm results in a tour that is much longer than the optimal tour. To be precise, for every constant r there is an instance of the traveling salesman problem such that the length of the tour computed by the nearest neighbour algorithm is greater than r times the length of the optimal tour. Moreover, for each number of cities there is an assignment of distances between the cities for which the nearest neighbour heuristic produces the unique worst possible tour. (If the algorithm is applied on every vertex as the starting vertex, the best path found will be better than at least N/2-1 other tours, where N is the number of vertices.)\nThe nearest neighbour algorithm may not find a feasible tour at all, even when one exists."}
