{"id": "32496", "revid": "1883085", "url": "https://en.wikipedia.org/wiki?curid=32496", "title": "Vacuum tube", "text": "Device that controls current between electrodes\nA vacuum tube, electron tube, thermionic valve (British usage), or tube (North America) is a device that controls electric current flow in a high vacuum between electrodes to which an electric potential difference has been applied. It takes the form of an evacuated tubular envelope of glass or sometimes metal containing electrodes connected to external connection pins.\nThe type known as a thermionic tube or thermionic valve utilizes thermionic emission of electrons from a hot cathode for fundamental electronic functions such as signal amplification and current rectification. Non-thermionic types such as vacuum phototubes achieve electron emission through the photoelectric effect, and are used for such purposes as the detection of light and measurement of its intensity. In both types the electrons are accelerated from the cathode to the anode by the electric field in the tube.\nThe first, and simplest, vacuum tube, the diode or Fleming valve, was invented in 1904 by John Ambrose Fleming. It contains only a heated electron-emitting cathode and an anode. Electrons can flow in only one direction through the device: from the cathode to the anode (hence the name \"valve\", like a device permitting one-way flow of water). Adding one or more control grids within the tube, creating the triode, tetrode, etc., allows the current between the cathode and anode to be controlled by the voltage on the grids, creating devices able to amplify as well as rectify electric signals. Multiple grids (e.g., a heptode) allow signals applied to different electrodes to be mixed.\nThese devices became a key component of electronic circuits for the first half of the twentieth century. They were crucial to the development of radio, television, radar, sound recording and reproduction, long-distance telephone networks, and analog and early digital computers. Although some applications had used earlier technologies such as the spark gap transmitter and crystal detector for radio or mechanical and electromechanical computers, the invention of the thermionic vacuum tube made these technologies widespread and practical, and created the discipline of electronics.\nIn the 1940s, the invention of semiconductor devices made it possible to produce solid-state electronic devices, which are smaller, safer, cooler, and more efficient, reliable, durable, and economical than thermionic tubes. Beginning in the mid-1960s, thermionic tubes were being replaced by the transistor. However, the cathode-ray tube (CRT), functionally an electron tube/valve though not usually so named, remained in use for electronic visual displays in television receivers, computer monitors, and oscilloscopes until the early 21st century.\nThermionic tubes are still employed in some applications, such as the magnetron used in microwave ovens, and some high-frequency amplifiers. Many audio enthusiasts prefer otherwise obsolete tube/valve amplifiers for the claimed \"warmer\" tube sound, and they are used for electric musical instruments such as electric guitars for desired effects, such as \"overdriving\" them to achieve a certain sound or tone.\nNot all electronic circuit valves or electron tubes are vacuum tubes. Gas-filled tubes are similar devices, but containing a gas, typically at low pressure, which exploit phenomena related to electric discharge in gases, usually without a heater.\nClassifications.\nOne classification of thermionic vacuum tubes is by the number of active electrodes. A device with two active elements is a diode, usually used for rectification. Devices with three elements are triodes used for amplification and switching. Additional electrodes create tetrodes, pentodes, and so forth, which have multiple additional functions made possible by the additional controllable electrodes.\nOther classifications are:\nVacuum tubes may have other components and functions than those described above, and are described elsewhere. These include as cathode-ray tubes, which create a beam of electrons for display purposes (such as the television picture tube, in electron microscopy, and in electron beam lithography); X-ray tubes; phototubes and photomultipliers (which rely on electron flow through a vacuum where electron emission from the cathode depends on energy from photons rather than thermionic emission).\nDescription.\nA vacuum tube consists of two or more electrodes in a vacuum inside an airtight envelope, with pins accessible from outside the envelope to make electrical connections to the electrodes. Most tubes have glass envelopes with a glass-to-metal seal based on kovar sealable borosilicate glasses, although ceramic and metal envelopes (atop insulating bases) have been used. The electrodes are attached to leads which pass through the envelope via an airtight seal.\nMost vacuum tubes have a limited lifetime, due mainly to the filament burning out or the cathode coating becoming depleted, gradually reducing performance, with other failure modes, so they are made as replaceable units; the electrode leads connect to pins on the tube's base which plug into a tube socket making tubes, a frequent cause of failure in electronic equipment, easy to remove and replace.\nIn addition to the base terminals, some tubes had an electrode terminating at a connection at the top of the tube, a top cap. This avoids leakage resistance, particularly for the high impedance grid input, through the tube base (sometimes made with phenolic insulation which performs poorly as an insulator in humid conditions) and improves stability and high-frequency performance by reducing capacitance between the grid and other electrodes. Some tubes requiring a very high anode voltage used a top cap for the anode connection, helping to isolate it from the lower potential of other electrodes. In tubes with a base accommodating a limited number of electrodes, a top cap provided an extra connection. A few tubes had two top cap connections.\nThe earliest vacuum tubes evolved from incandescent light bulbs, containing a filament sealed in an evacuated glass envelope. When hot, the filament releases electrons into the vacuum, a process called thermionic emission. An added second electrode at a positive voltage relative to the filament, the anode or \"plate\", will attract those electrons. The result is a net unidirectional flow of electrons from the filament to plate; there is no flow in the reverse direction because the plate does not emit positive ions. The filament has a dual function: it emits electrons when heated; and, together with the plate, it creates an electric field due to the potential difference between them. A tube with only two electrodes is termed a diode, and is used for rectification. Since current can only pass in one direction, such a diode (or \"rectifier\") will convert alternating current (AC) to pulsating DC. This allow diodes to be used to convert AC to DC in a power supply, as a demodulator of amplitude modulated (AM) radio signals, and for similar functions.\nEarly tubes used the filament as the negative electrode, the cathode; this is called a \"directly heated\" tube. Most later tubes are \"indirectly heated\" by a filament or heater element inside a metal tube functioning as the cathode, with an oxide coating that much improves electron emission. The heater is electrically isolated from the surrounding cathode and simply serves to heat the cathode sufficiently for thermionic emission of electrons. H. J. Round invented the indirectly heated tube around 1913. The electrical isolation allows all the tubes' heaters to be supplied from a common circuit (which can be AC, although the cathodes must be at a steady potential) separate from operating voltages; in particular the cathodes in different tubes can operate at different voltages. The filaments require constant and often considerable power, even when amplifying signals at the microwatt level.\nPower is dissipated by the filaments, and by electrons from the cathode impacting and heating the anode (plate); this occurs even in an idle amplifier due to the quiescent current necessary to ensure linearity and low distortion. In a power amplifier, this heating can be considerable and can destroy the tube if driven beyond its safe limits. Since the tube is evacuated, convective electrode cooling is not possible; the anodes in most small and medium power tubes are cooled by radiation through the glass envelope. In some very high power applications, cooling is drastically improved by making the anode part of the (metal) tube envelope, in thermal contact with a heat sink cooled by forced air or water (the anode would normally be at ground potential, with the cathode and grids at a high negative potential). Klystrons and magnetrons are tubes that often operate their anodes (called \"collectors\" in klystrons) at ground potential to facilitate cooling, particularly with water, without high-voltage insulation.\nExcept for diodes, additional electrodes are positioned between the cathode and the plate (anode). These electrodes are not solid sheets but sparse elements through which electrons can pass, referred to as grids, influencing but not obstructing the flow of electrons to the anode. The vacuum tube is then known as a triode, tetrode, pentode, etc., depending on the number of grids. A triode has three electrodes: the anode, cathode, and one grid, and so on. The first grid, known as the control grid, (and sometimes other grids) transforms the diode into a \"voltage-controlled device\": the voltage applied to the control grid affects the current between the cathode and the plate. When held negative with respect to the cathode, the control grid creates an electric field that repels electrons emitted by the cathode, thus reducing or even stopping the current between cathode and anode. As long as the control grid is negative relative to the cathode, essentially no current flows into it, yet a change of several volts on the control grid is sufficient to make a large difference in the plate current, possibly changing the output by hundreds of volts (depending on the circuit). The solid-state device which operates most like the pentode tube, although usually using much lower voltages, is the junction field-effect transistor (JFET).\nHistory and development.\nThe 19th century saw increasing research with evacuated tubes, such as the Geissler and Crookes tubes. The many scientists and inventors who experimented with such tubes include Thomas Edison, Eugen Goldstein, Nikola Tesla, and Johann Wilhelm Hittorf. With the exception of early light bulbs, such tubes were only used in scientific research or as novelties. The groundwork laid by these scientists and inventors, however, was critical to the development of subsequent vacuum tube technology.\nAlthough thermionic emission was originally reported in 1873 by Frederick Guthrie, it was Thomas Edison's apparently independent discovery of the phenomenon in 1883, referred to as the \"Edison effect\", that became well known. Although Edison was aware of the unidirectional property of current flow between the filament and the anode, his interest (and patent) concentrated on the sensitivity of the anode current to the current through the filament (and thus filament temperature). It was years later that John Ambrose Fleming applied the rectifying property of the Edison effect to detection of radio signals, as an improvement over the magnetic detector.\nAmplification by vacuum tube became practical only with Lee de Forest's 1907 invention of the three-terminal \"audion\" tube, a crude form of what was to become the triode. Being essentially the first electronic amplifier, such tubes were instrumental in long-distance telephony (such as the first coast-to-coast telephone line in the US) and public address systems, and introduced a far superior and versatile technology for use in radio transmitters and receivers.\nDiodes.\nAt the end of the 19th century, radio or wireless technology was in an early stage of development and the Marconi Company was engaged in development and construction of radio communication systems. Guglielmo Marconi appointed English physicist John Ambrose Fleming as scientific advisor in 1899. Fleming had been engaged as scientific advisor to Edison Telephone (1879), as scientific advisor at Edison Electric Light (1882), and was also technical consultant to Edison-Swan. One of Marconi's needs was for improvement of the detector, a device that extracts information from a modulated radio frequency. Marconi had developed a magnetic detector, which was less responsive to natural sources of radio frequency interference than the coherer, but the magnetic detector only provided an audio frequency signal to a telephone receiver. A reliable detector that could drive a printing instrument was needed.\nAs a result of experiments conducted on Edison effect bulbs, Fleming developed a vacuum tube that he termed the \"oscillation valve\" because it passed current in only one direction. The cathode was a carbon lamp filament, heated by passing current through it, that produced thermionic emission of electrons. Electrons that had been emitted from the cathode were attracted to the \"plate\" (\"anode\") when the plate was at a positive voltage with respect to the cathode. Fleming patented these tubes for the Marconi company in the UK, filing in November 1904, with patent issued in September 1905. Later known as the Fleming valve, the \"oscillation valve\" was developed for the purpose of rectifying radio-frequency current as the detector component of radio receiver circuits.\nWhile not more sensitive than a properly working crystal detector, the Fleming valve did not need the fiddly adjustment the whisker of a crystal detector required, and was not susceptible to becoming bumped out of the optimum position by vibration or movement, which was particularly advantageous for use on a moving ship.\nTriodes.\nIn the 19th century, telegraph and telephone engineers had recognized the need to extend the distance that signals could be transmitted. In 1906, Robert von Lieben filed for a patent for a cathode-ray tube which used an external magnetic deflection coil and was intended for use as an amplifier in telephony equipment. This von Lieben magnetic deflection tube was not a successful amplifier, however, because of the power used by the deflection coil. Von Lieben would later make refinements to triode vacuum tubes.\nLee de Forest is credited with inventing the triode tube in 1907 while experimenting to improve his original (diode) Audion. By placing an additional electrode between the filament (cathode) and plate (anode), he discovered the ability of the resulting device to amplify signals. As the voltage applied to the control grid (or simply \"grid\") was lowered below the cathode voltage, the current flowing from the filament to the plate decreased. The negative electrostatic field created by the grid in the vicinity of the cathode inhibited the passage of emitted electrons and reduced the current to the plate. With the grid negative relative to the cathode, no direct current could pass from the cathode to the grid. Consequently, a change of voltage applied to the grid, requiring no power input as no current flowed, could make a change in the plate current and could lead to a much larger voltage change at the plate; the result was voltage and power amplification. In 1908, de Forest was granted a patent (https://) for such a three-electrode version of his original Audion for use as an electronic amplifier in radio communications. This eventually became known as the triode.\nDe Forest's original device was made with conventional vacuum technology. The vacuum was not a \"hard vacuum\" but rather left a very small amount of residual gas. The physics behind the device's operation was not fully understood. The residual gas would cause a blue glow due to visible ionization when the plate voltage exceeded about 60 volts. In 1912, de Forest and John Stone Stone brought the Audion for demonstration to AT&amp;T's engineering department, where Harold D. Arnold of realized that the blue glow was caused by ionized gas. He recommended that AT&amp;T purchase the patent. Arnold developed high-vacuum tubes which operated at high plate voltages without a blue glow; they were tested in the summer of 1913 on AT&amp;T's long-distance network.\nFinnish inventor Eric Tigerstedt significantly improved on the original triode design in 1914, while working on his sound-on-film process in Berlin, Germany. Tigerstedt's innovation was to make the electrodes concentric cylinders with the cathode at the centre, thus greatly increasing the collection of emitted electrons at the anode.\nIrving Langmuir at the General Electric research laboratory (Schenectady, New York) had improved Wolfgang Gaede's high-vacuum diffusion pump and used it to settle the question of thermionic emission and conduction in a vacuum. Consequently, General Electric started producing hard vacuum triodes (which were branded Pliotrons) in 1915. Langmuir patented the hard vacuum triode, but de Forest and AT&amp;T successfully asserted priority and invalidated the patent.\nPliotrons were closely followed by the French type 'TM' and later the British type 'R', which were in widespread use by the allied military by 1916. Historically, vacuum levels in production vacuum tubes typically ranged from 10 \u03bcPa down to 10\u00a0nPa ( down to ).\nThe triode and its derivatives (tetrodes and pentodes) are transconductance devices, in which the controlling signal applied to the grid is a \"voltage\", and the resulting amplified signal appearing at the anode is a \"current\". By comparison the later bipolar junction transistor uses a small current to control a larger current.\nFor vacuum tubes, transconductance or mutual conductance (\"g\"m) is defined as the change in the plate(anode)/cathode current divided by the corresponding change in the grid to cathode voltage, with a constant plate(anode) to cathode voltage. Typical values of \"g\"m for a small-signal vacuum tube are 1 to 10 millisiemens. It is one of the three main parameters of a vacuum tube, the other two being its gain \u03bc and plate resistance \"R\"p or \"R\"a; these parameters are related by the Van der Bijl equation: formula_1\nThe plate current of the triode was not accurately proportional to the grid voltage, i.e. the operating characteristic was non-linear, causing early tube audio amplifiers to exhibit harmonic distortion at low volumes. Plotting plate current as a function of applied grid voltage, it was seen that there was a range of grid voltages for which the transfer curve was approximately linear.\nTo use this range, a negative bias voltage had to be applied to the grid to position the DC operating point in the linear region. This was called the idle condition, and the plate current at this point the \"idle current\". The controlling voltage was superimposed onto the bias voltage, resulting in a nearly linear variation of plate current in response to positive and negative variation of the input voltage around that point.\nThis concept is called \"grid bias\". Many early radio sets had a third battery called the \"C battery\" (unrelated to the present-day C cell, a format). The C battery's positive terminal was connected to the cathode of the tubes (\"ground\" in most circuits) and the negative terminal supplied bias voltage to the grids of the tubes.\nLater circuits, after tubes were made with heaters isolated from their cathodes, used cathode biasing, avoiding the need for a separate negative power supply. For cathode biasing, a relatively low-value resistor is connected between the cathode and ground. Current flow through the resistor makes the cathode positive with respect to the grid, which is at ground potential for DC.\nHowever C batteries continued to be included in some equipment even when the \"A\" and \"B\" batteries had been replaced by power from the AC mains. That was possible because there was essentially no current draw on these batteries; they could thus last for many years (often longer than all the tubes) without requiring replacement.\nWhen triodes were first used with tuned rather than resistive loads in radio-frequency transmitters and receivers, it was found that tuned amplification stages had a tendency to oscillate unless their gain was very limited, due to the parasitic capacitance, termed Miller capacitance, between the plate (the amplifier's output) and the control grid (the amplifier's input).\nEventually the technique of \"neutralization\" was developed whereby the RF transformer connected to the plate (anode) included an additional winding in the opposite phase, connected to the grid through a small capacitor. When properly adjusted this cancelled the Miller capacitance. This technique was successfully employed in the Neutrodyne radio during the 1920s. Neutralization was dependent upon the frequency; it required careful adjustment and did not work over a wide range of frequencies.\nTetrodes and pentodes.\nTo combat the stability problems of the triode as a radio frequency amplifier due to grid-to-plate capacitance, the physicist Walter H. Schottky invented the tetrode or \"screen grid tube\" in 1919. He showed that the addition of an electrostatic shield between the control grid and the plate could solve the problem. This design was refined by Hull and Williams. The added grid became known as the \"screen grid\" or \"shield grid\". The screen grid is operated at a positive voltage significantly less than the plate voltage and it is bypassed to ground with a capacitor of low impedance at the frequencies to be amplified.\nThis arrangement substantially decouples the plate and the control grid, eliminating the need for neutralizing circuitry at medium wave broadcast frequencies. The screen grid also largely reduces the influence of the plate voltage on the space charge near the cathode, permitting the tetrode to produce greater voltage gain than the triode in amplifier circuits. While the amplification factors of typical triodes commonly range from below ten to around 100, tetrode amplification factors of 500 are common. Consequently, higher voltage gains from a single tube amplification stage became possible, reducing the number of tubes required. Screen grid tubes were marketed by late 1927.\nHowever, the useful region of operation of the screen grid tube as an amplifier was limited to plate voltages greater than the screen grid voltage, due to secondary emission from the plate. In any tube, electrons strike the plate with sufficient energy to cause the emission of electrons from its surface. In a triode this secondary emission of electrons is not important since they are simply re-captured by the plate. But in a tetrode they can be captured by the screen grid since it is also at a positive voltage, robbing them from the plate current and reducing the amplification of the tube. Since secondary electrons can outnumber the primary electrons over a certain range of plate voltages, the plate current can decrease with increasing plate voltage. This is the \"dynatron region\" or \"tetrode kink\" and is an example of negative resistance which can itself cause instability. Another undesirable consequence of secondary emission is that screen current is increased, which may cause the screen to exceed its power rating.\nThe otherwise undesirable negative resistance region of the plate characteristic was exploited with the dynatron oscillator circuit to produce a simple oscillator only requiring connection of the plate to a resonant LC circuit to oscillate. The dynatron oscillator operated on the same principle of negative resistance as the tunnel diode oscillator many years later.\nThe dynatron region of the screen grid tube was eliminated by adding a grid between the screen grid and the plate to create the pentode. The suppressor grid of the pentode was usually connected to the cathode and its negative voltage relative to the anode repelled secondary electrons so that they would be collected by the anode instead of the screen grid. The term \"pentode\" means the tube has five electrodes. The pentode was invented in 1926 by Bernard D. H. Tellegen and became generally favored over the simple tetrode. Pentodes are made in two classes: those with the suppressor grid wired internally to the cathode (e.g. EL84/6BQ5) and those with the suppressor grid wired to a separate pin for user access (e.g. 803, 837). An alternative solution for power applications is the beam tetrode or \"beam power tube\", discussed below.\nMultifunction and multisection tubes.\nSuperheterodyne receivers require a local oscillator and mixer, combined in the function of a single pentagrid converter tube. Various alternatives such as using a combination of a triode with a hexode and even an octode have been used for this purpose. The additional grids include control grids (at a low potential) and screen grids (at a high voltage). Many designs use such a screen grid as an additional anode to provide feedback for the oscillator function, whose current adds to that of the incoming radio frequency signal. The pentagrid converter thus became widely used in AM receivers, including the miniature tube version of the \"All American Five\". Octodes, such as the 7A8, were rarely used in the United States, but much more common in Europe, particularly in battery operated radios where the lower power consumption was an advantage.\nTo further reduce the cost and complexity of radio equipment, two separate structures (triode and pentode for instance) can be combined in the bulb of a single \"multisection tube\". An early example is the Loewe 3NF. This 1920s device has three triodes in a single glass envelope together with all the fixed capacitors and resistors required to make a complete radio receiver. As the Loewe set had only one tube socket, it was able to substantially undercut the competition, since, in Germany, state tax was levied by the number of sockets. However, reliability was compromised, and production costs for the tube were much greater. In a sense, these were akin to integrated circuits. In the United States, Cleartron briefly produced the \"Multivalve\" triple triode for use in the Emerson Baby Grand receiver. This Emerson set also has a single tube socket, but because it uses a four-pin base, the additional element connections are made on a \"mezzanine\" platform at the top of the tube base.\nBy 1940 multisection tubes had become commonplace. There were constraints, however, due to patents and other licensing considerations (see British Radio Valve Manufacturers' Association). Constraints due to the number of external pins (leads) often forced the functions to share some of those external connections such as their cathode connections (in addition to the heater connection). The RCA Type 55 is a double diode triode used as a detector, automatic gain control rectifier and audio preamplifier in early AC powered radios. These sets often include the 53 Dual Triode Audio Output. Another early type of multi-section tube, the 6SN7, is a \"dual triode\" which performs the functions of two triode tubes while taking up half as much space and costing less.\nThe 12AX7 is a dual \"high mu\" (high voltage gain) triode in a miniature enclosure, and became widely used in audio signal amplifiers, instruments, and guitar amplifiers.\nThe introduction of the miniature tube base (see below) which can have 9 pins, more than previously available, allowed other multi-section tubes to be introduced, such as the 6GH8/ECF82 triode-pentode, quite popular in television receivers. The desire to include even more functions in one envelope resulted in the General Electric Compactron which has 12 pins. A typical example, the 6AG11, contains two triodes and two diodes.\nSome otherwise conventional tubes do not fall into standard categories; the 6AR8, 6JH8 and 6ME8 have several common grids, followed by a pair of beam deflection electrodes which deflected the current towards either of two anodes. They were sometimes known as the 'sheet beam' tubes and used in some color TV sets for color demodulation. The similar 7360 was popular as a balanced SSB (de)modulator.\nBeam power tubes.\nA beam tetrode (or \"beam power tube\") forms the electron stream from the cathode into multiple partially collimated beams to produce a low potential space charge region between the anode and screen grid to return anode secondary emission electrons to the anode when the anode potential is less than that of the screen grid. Formation of beams also reduces screen grid current. In some cylindrically symmetrical beam power tubes, the cathode is formed of narrow strips of emitting material that are aligned with the apertures of the control grid, reducing control grid current. This design helps to overcome some of the practical barriers to designing high-power, high-efficiency power tubes.\nManufacturer's data sheets often use the terms \"beam pentode\" or \"beam power pentode\" instead of \"beam power tube\", and use a pentode graphic symbol instead of a graphic symbol showing beam forming plates.\nBeam power tubes offer the advantages of a longer load line, less screen current, higher transconductance and lower third harmonic distortion than comparable power pentodes. Beam power tubes can be connected as triodes for improved audio tonal quality but in triode mode deliver significantly reduced power output.\nGas-filled tubes.\nGas-filled tubes such as discharge tubes and cold cathode tubes are not \"hard\" vacuum tubes, though are always filled with gas at less than sea-level atmospheric pressure. Types such as the voltage-regulator tube and thyratron resemble hard vacuum tubes and fit in sockets designed for vacuum tubes. Their distinctive orange, red, or purple glow during operation indicates the presence of gas; electrons flowing in a vacuum do not produce light within that region. These types may still be referred to as \"electron tubes\" as they do perform electronic functions. High-power rectifiers use mercury vapor to achieve a lower forward voltage drop than high-vacuum tubes.\nMiniature tubes.\nEarly tubes used a metal or glass envelope atop an insulating bakelite base. In 1938 a technique was developed to use an all-glass construction with the pins fused in the glass base of the envelope. This allowed the design of a much smaller tube (typically about 20mm in diameter), known as the miniature tube; tubes with standard seven and nine-pin (noval) bases were made. Tubes with different bases of about the same size were also introduced. Making tubes smaller reduced the voltage where they could safely operate, and also reduced the filament power required. Miniature tubes became predominant in consumer applications such as radio receivers and hi-fi amplifiers. However, the larger styles continued to be required for tubes dissipating more power, such as higher-power rectifiers, in higher-power audio output stages and as RF power transmitting tubes.\nSub-miniature tubes.\nTubes requiring little power, such as hearing-aid amplifiers, could be much smaller than those dissipating significant heat; sub-miniature tubes with a size roughly that of half a cigarette were used. These tubes tended to be long-lived due to their low power; they did not have pins plugging into a socket for easy replacement, but were soldered in place. For higher radio frequencies larger tubes introduced frequency-limiting stray capacitance that could be reduced by reducing the size. Small tubes for high frequencies included the \"acorn tube\" type (named for its shape and size), and the metal-cased RCA nuvistor type from 1959, about the size of a thimble. The nuvistor was developed to compete with transistors, and could operate at higher frequencies than early transistors, and also bigger tubes, due to the nuvistor's small size (compared to signal wavelength). Nuvistors were used in aircraft radio transceivers, UHF television tuners, and some HiFi FM radio tuners (Sansui 500A) until replaced by newer high-frequency-capable transistors.\nImprovements in construction and performance.\nThe earliest vacuum tubes strongly resembled incandescent light bulbs and were made by lamp manufacturers, who had the equipment needed to manufacture glass envelopes and the vacuum pumps required to evacuate the enclosures. de Forest used Heinrich Geissler's mercury displacement pump, which left behind a partial vacuum. The development of the diffusion pump in 1915 and improvement by Irving Langmuir led to the development of high-vacuum tubes. After World War I, specialized manufacturers using more economical construction methods were set up to fill the growing demand for broadcast receivers. Bare tungsten filaments operated at a temperature of around 2200\u00a0\u00b0C. The development of oxide-coated filaments in the mid-1920s reduced filament operating temperature to a dull red heat (around 700\u00a0\u00b0C), which in turn reduced thermal distortion of the tube structure and allowed closer spacing of tube elements. This in turn improved tube gain, since the gain of a triode is inversely proportional to the spacing between grid and cathode. Bare tungsten filaments remain in use in small transmitting tubes but are brittle and tend to fracture if handled roughly\u00a0\u2013 e.g. in the postal services. These tubes are best suited to stationary equipment where impact and vibration is not present.\nIndirectly heated cathodes.\nThe desire to power electronic equipment using AC mains power faced a difficulty with respect to the powering of the tubes' filaments, as these were also the cathode of each tube. Powering the filaments directly from a power transformer introduced mains-frequency (50 or 60\u00a0Hz) hum into audio stages. The invention of the \"equipotential cathode\" reduced this problem, with the filaments being powered by a balanced AC power transformer winding having a grounded center tap.\nA superior solution, and one which allowed each cathode to \"float\" at a different voltage, was that of the indirectly heated cathode: a cylinder of oxide-coated nickel acted as an electron-emitting cathode and was electrically isolated from the filament inside it. Indirectly heated cathodes enable the cathode circuit to be separated from the heater circuit. The filament, no longer electrically connected to the tube's electrodes, became simply known as a \"heater\", and could as well be powered by AC without any introduction of hum. In the 1930s, indirectly heated cathode tubes became widespread in equipment using AC power. Directly heated cathode tubes continued to be widely used in battery-powered equipment as their filaments required considerably less power than the heaters required with indirectly heated cathodes.\nTubes designed for high gain audio applications may have twisted heater wires to cancel out stray electric fields, fields that could induce objectionable hum into the program material.\nHeaters may be energized with either alternating current (AC) or direct current (DC). DC is often used where low hum is required.\nUse in electronic computers.\nVacuum tubes used as switches made electronic computing possible for the first time, but the cost and relatively short mean time to failure of tubes were limiting factors. \"The common wisdom was that valves\u00a0\u2013 which, like light bulbs, contained a hot glowing filament\u00a0\u2013 could never be used satisfactorily in large numbers, for they were unreliable, and in a large installation too many would fail in too short a time\". Tommy Flowers, who later designed Colossus, \"discovered that, so long as valves were switched on and left on, they could operate reliably for very long periods, especially if their 'heaters' were run on a reduced current\". In 1934 Flowers built a successful experimental installation using over 3,000 tubes in small independent modules; when a tube failed, it was possible to switch off one module and keep the others going, thereby reducing the risk of another tube failure being caused; this installation was accepted by the Post Office (who operated telephone exchanges). Flowers was also a pioneer of using tubes as very fast (compared to electromechanical devices) electronic switches. Later work confirmed that tube unreliability was not as serious an issue as generally believed; the 1946 ENIAC, with over 17,000 tubes, had a tube failure (which took 15 minutes to locate) on average every two days. The quality of the tubes was a factor, and the diversion of skilled people during the Second World War lowered the general quality of tubes. During the war Colossus was instrumental in breaking German codes. After the war, development continued with tube-based computers including, military computers ENIAC and Whirlwind, the Ferranti Mark 1 (one of the first commercially available electronic computers), and UNIVAC I, also available commercially.\nAdvances using subminiature tubes included the Jaincomp series of machines produced by the Jacobs Instrument Company of Bethesda, Maryland. Models such as its Jaincomp-B employed just 300 such tubes in a desktop-sized unit that offered performance to rival many of the then room-sized machines.\nColossus.\nColossus I and its successor Colossus II (Mk2) were designed by Tommy Flowers and built by the General Post Office for Bletchley Park (BP) during World War II to substantially speed up the task of breaking the German high level Lorenz encryption. Colossus replaced an earlier machine based on relay and switch logic (the Heath Robinson). Colossus was able to break in a matter of hours messages that had previously taken several weeks; it was also much more reliable. Colossus was the first use of vacuum tubes \"working in concert\" on such a large scale for a single machine.\nTommy Flowers (who conceived Colossus) wrote that most radio equipment was \"carted round, dumped around, switched on and off and generally mishandled. But I'd introduced valves into telephone equipment in large numbers before the war and I knew that if you never moved them and never switched them on and off they would go on forever\". Colossus was \"that reliable, extremely reliable\". On its first day at BP a problem with a known answer was set. To the amazement of BP (Station X), after running for four hours with each run taking half an hour the answer was the same every time (the Robinson did not always give the same answer). Colossus I used about 1600 valves, and Colossus II about 2400 valves (some sources say 1500 (Mk I) and 2500 (Mk II); the Robinson used about a hundred valves; some sources say fewer).\nWhirlwind and \"special-quality\" tubes.\nTo meet the reliability requirements of the 1951 US digital computer Whirlwind, \"special-quality\" tubes with extended life, and a long-lasting cathode in particular, were produced. The problem of short lifetime was traced largely to evaporation of silicon, used in the tungsten alloy to make the heater wire easier to draw. The silicon forms barium orthosilicate at the interface between the nickel sleeve and the cathode barium oxide coating. This \"cathode interface\" is a high-resistance layer (with some parallel capacitance) which greatly reduces the cathode current when the tube is switched into conduction mode. Elimination of silicon from the heater wire alloy (and more frequent replacement of the wire drawing dies) allowed the production of tubes that were reliable enough for the Whirlwind project. High-purity nickel tubing and cathode coatings free of materials such as silicates and aluminum that can reduce emissivity also contribute to long cathode life.\nThe first such \"computer tube\" was Sylvania's 7AK7 pentode of 1948 (these replaced the 7AD7, which was supposed to be better quality than the standard 6AG7 but proved too unreliable). Computers were the first tube devices to run tubes at cutoff (enough negative grid voltage to make them cease conduction) for quite-extended periods of time. Running in cutoff with the heater on accelerates cathode poisoning and the output current of the tube will be greatly reduced when switched into conduction mode. The 7AK7 tubes improved the cathode poisoning problem, but that alone was insufficient to achieve the required reliability. Further measures included switching off the heater voltage when the tubes were not required to conduct for extended periods, turning on and off the heater voltage with a slow ramp to avoid thermal shock on the heater element, and stress testing the tubes during offline maintenance periods to bring on early failure of weak units.\nAnother commonly used computer tube was the 5965 double triode. This, according to a memorandom from MIT for Project Whirwind, was developed for IBM by General Electric, primarily for use in the IBM 701 calculator, and was designated as a general-purpose triode tube. Tubes using a European designation standard used letters to indicate heater voltage and construction, followed by an indicator of base type and series number; e.g. the ECC82 was a 6.3V (E) double triode (CC) with a noval base (8x), as was the ECC83. Special quality tubes placed the number immediately after the voltage letter; e.g. the European version of the 5965 was labeled E180CC.\nThe tubes developed for Whirlwind were later used in the giant SAGE air-defense computer system. By the late 1950s, it was routine for special-quality small-signal tubes to last for hundreds of thousands of hours if operated conservatively. This increased reliability and also made mid-cable amplifiers in submarine cables possible.\nHeat generation and cooling.\nA considerable amount of heat is produced when tubes operate, from both the filament (heater) and the stream of electrons bombarding the plate. In power amplifiers, this source of heat is greater than cathode heating. A few types of tube permit operation with the anodes at a dull red heat; in other types, red heat indicates severe overload.\nThe requirements for heat removal can significantly change the appearance of high-power vacuum tubes. High power audio amplifiers and rectifiers required larger envelopes to dissipate heat. Transmitting tubes could be much larger still.\nHeat escapes the device by black-body radiation from the anode (plate) as infrared radiation, and by convection of air over the tube envelope.https:// Convection is not possible inside most tubes since the anode is surrounded by vacuum.\nTubes which generate relatively little heat, such as the 1.4-volt filament directly heated tubes designed for use in battery-powered equipment, often have shiny metal anodes. 1T4, 1R5 and 1A7 are examples. Gas-filled tubes such as thyratrons may also use a shiny metal anode since the gas present inside the tube allows for heat convection from the anode to the glass enclosure.\nThe anode is often treated to make its surface emit more infrared energy. High-power amplifier tubes are designed with external anodes that can be cooled by convection, forced air or circulating water. The water-cooled 80\u00a0kg, 1.25\u00a0MW 8974 is among the largest commercial tubes available today.\nIn a water-cooled tube, the anode voltage appears directly on the cooling water surface, thus requiring the water to be an electrical insulator to prevent high voltage leakage through the cooling water to the radiator system. Water as usually supplied has ions that conduct electricity; deionized water, a good insulator, is required. Such systems usually have a built-in water-conductance monitor which will shut down the high-tension supply if the conductance becomes too high.\nThe screen grid may also generate considerable heat. Limits to screen grid dissipation, in addition to plate dissipation, are listed for power devices. If these are exceeded then tube failure is likely.\nTube packages.\nMost modern tubes have glass envelopes, but metal, fused quartz (silica) and ceramic have also been used. A first version of the 6L6 used a metal envelope sealed with glass beads, while a glass disk fused to the metal was used in later versions. Metal and ceramic are used almost exclusively for power tubes above 2\u00a0kW dissipation. The nuvistor was a modern receiving tube using a very small metal and ceramic package.\nThe internal elements of tubes have always been connected to external circuitry via pins at their base which plug into a socket. Subminiature tubes were produced using wire leads rather than sockets; however, these were restricted to rather specialized applications. In addition to the connections at the base of the tube, many early triodes connected the grid using a metal cap at the top of the tube; this reduces stray capacitance between the grid and the plate leads. Tube caps were also used for the plate (anode) connection, particularly in transmitting tubes and tubes using a very high plate voltage.\nHigh-power tubes such as transmitting tubes have packages designed more to enhance heat transfer. In some tubes, the metal envelope is also the anode. The 4CX1000A is an external anode tube of this sort. Air is blown through an array of fins attached to the anode, thus cooling it. Power tubes using this cooling scheme are available up to 150\u00a0kW dissipation. Above that level, water or water-vapor cooling are used. The highest-power tube currently available is the Eimac 4CM2500KG, a forced water-cooled power tetrode capable of dissipating 2.5 megawatts. By comparison, the largest power transistor can only dissipate about 1 kilowatt.\nNames.\nThe generic name \"[thermionic] valve\" used in the UK derives from the unidirectional current flow allowed by the earliest device, the thermionic diode emitting electrons from a heated filament, by analogy with a non-return valve in a water pipe. The US names \"vacuum tube\", \"electron tube\", and \"thermionic tube\" all simply describe a tubular envelope which has been evacuated (\"vacuum\"), has a heater and controls electron flow.\nIn many cases, manufacturers and the military gave tubes designations that said nothing about their purpose (e.g., 1614). In the early days some manufacturers used proprietary names which might convey some information, but only about their products; the KT66 and KT88 were \"kinkless tetrodes\". Later, consumer tubes were given names that conveyed some information, with the same name often used generically by several manufacturers. In the US, Radio Electronics Television Manufacturers' Association (RETMA) designations comprise a number, followed by one or two letters, and a number. The first number is the (rounded) heater voltage; the letters designate a particular tube but say nothing about its structure; and the final number is the total number of electrodes (without distinguishing between, say, a tube with many electrodes, or two sets of electrodes in a single envelope\u00a0\u2013 a double triode, for example). For example, the 12AX7 is a double triode (two sets of three electrodes plus heater) with a 12.6V heater (which, as it happens, can also be connected to run from 6.3V). The \"AX\" designates this tube's characteristics. Similar, but not identical, tubes are the 12AD7, 12AE7...12AT7, 12AU7, 12AV7, 12AW7 (rare), 12AY7, and the 12AZ7.\nA system widely used in Europe known as the Mullard\u2013Philips tube designation, also extended to transistors, uses a letter, followed by one or more further letters, and a number. The type designator specifies the heater voltage or current (one letter), the functions of all sections of the tube (one letter per section), the socket type (first digit), and the particular tube (remaining digits). For example, the ECC83 (equivalent to the 12AX7) is a 6.3V (E) double triode (CC) with a miniature base (8). In this system special-quality tubes (e.g., for long-life computer use) are indicated by moving the number immediately after the first letter: the E83CC is a special-quality equivalent of the ECC83, the E55L a power pentode with no consumer equivalent.\nSpecial-purpose tubes.\nSome special-purpose tubes are constructed with particular gases in the envelope. For instance, voltage-regulator tubes contain various inert gases such as argon, helium or neon, which will ionize at predictable voltages. The thyratron is a special-purpose tube filled with low-pressure gas or mercury vapor. Like vacuum tubes, it contains a hot cathode and an anode, but also a control electrode which behaves somewhat like the grid of a triode. When the control electrode starts conduction, the gas ionizes, after which the control electrode can no longer stop the current; the tube \"latches\" into conduction. Removing anode (plate) voltage lets the gas de-ionize, restoring its non-conductive state.\nSome thyratrons can carry large currents for their physical size. One example is the miniature type 2D21, often seen in 1950s jukeboxes as control switches for relays. A cold-cathode version of the thyratron, which uses a pool of mercury for its cathode, is called an ignitron; some can switch thousands of amperes. Thyratrons containing hydrogen have a very consistent time delay between their turn-on pulse and full conduction; they behave much like modern silicon-controlled rectifiers, also called thyristors due to their functional similarity to thyratrons. Hydrogen thyratrons have long been used in radar transmitters.\nA specialized tube is the krytron, which is used for rapid high-voltage switching. Krytrons are used to initiate the detonations used to set off a nuclear weapon; krytrons are heavily controlled at an international level.\nX-ray tubes are used in medical imaging among other uses. X-ray tubes used for continuous-duty operation in fluoroscopy and CT imaging equipment may use a focused cathode and a rotating anode to dissipate the large amounts of heat thereby generated. These are housed in an oil-filled aluminum housing to provide cooling.\nThe photomultiplier tube is an extremely sensitive detector of light, which uses the photoelectric effect and secondary emission, rather than thermionic emission, to generate and amplify electrical signals. Nuclear medicine imaging equipment and liquid scintillation counters use photomultiplier tube arrays to detect low-intensity scintillation due to ionizing radiation.\nThe Ignatron tube was used in resistance welding equipment in the early 1970s. The Ignatron had a cathode, anode and an igniter. The tube base was filled with mercury and the tube was used as a very high current switch. A large current potential was placed between the anode and cathode of the tube but was only permitted to conduct when the igniter in contact with the mercury had enough current to vaporize the mercury and complete the circuit. Because this was used in resistance welding there were two Ignatrons for the two phases of an AC circuit. Because of the mercury at the bottom of the tube they were extremely difficult to ship. These tubes were eventually replaced by SCRs (Silicon Controlled Rectifiers).\nUse of Radioactive Materials.\nCertain vacuum tubes have utilized radioactive materials to enhance their performance. These radioative materials are used to ionize the fill gas within the tube. This ionization process ensures reliable and consistent operation by providing a steady current when a high voltage is applied, thereby improving the tube's performance and stability. The radioactive source speeds up the operation of the tube and ensures that the tube output is steady and not subject to random fluctuations by providing an instantaneous current when a high voltage is applied.\nThe various radioactive sources that have been used in these devices include:\nExamples include the Western Electric 346B tube, which contains radium-226, and the Zellweger ZE22/3 glow tube, which may contain either radium-226 or tritium.\nPowering the tube.\nBatteries.\nBatteries provided the voltages required by tubes in early radio sets. Three different voltages were generally required, using three different batteries designated as the A, B, and C battery. The \"A\" battery or LT (low-tension) battery provided the filament voltage. Tube heaters were designed for single, double or triple-cell lead-acid batteries, giving nominal heater voltages of 2 V, 4 V or 6 V. In portable radios, dry batteries were sometimes used with 1.5 or 1 V heaters. Reducing filament consumption improved the life span of batteries. By 1955 towards the end of the tube era, tubes using only 50 mA down to as little as 10 mA for the heaters had been developed.\nThe high voltage applied to the anode (plate) was provided by the \"B\" battery or the HT (high-tension) supply or battery. These were generally of dry cell construction and typically came in 22.5-, 45-, 67.5-, 90-, 120- or 135-volt versions. After the use of B-batteries was phased out and rectified line-power was employed to produce the high voltage needed by tubes' plates, the term \"B+\" persisted in the US when referring to the high voltage source. Most of the rest of the English speaking world refers to this supply as just HT (high tension).\nEarly sets used a grid bias battery or \"C\" battery which was connected to provide a \"negative\" voltage. Since no current flows through a tube's grid connection, these batteries had no current drain and lasted the longest, usually limited by their own shelf life. The supply from the grid bias battery was rarely, if ever, disconnected when the radio was otherwise switched off. Even after AC power supplies became commonplace, some radio sets continued to be built with C batteries, as they would almost never need replacing. However more modern circuits were designed using cathode biasing, eliminating the need for a third power supply voltage; this became practical with tubes using indirect heating of the cathode along with the development of resistor/capacitor coupling which replaced earlier interstage transformers.\nThe \"C battery\" for bias is a designation having no relation to the \"C cell\" battery size.\nAC power.\nBattery replacement was a major operating cost for early radio receiver users. The development of the battery eliminator, and, in 1925, batteryless receivers operated by household power, reduced operating costs and contributed to the growing popularity of radio. A power supply using a transformer with several windings, one or more rectifiers (which may themselves be vacuum tubes), and large filter capacitors provided the required direct current voltages from the alternating current source.\nAs a cost reduction measure, especially in high-volume consumer receivers, all the tube heaters could be connected in series across the AC supply using heaters requiring the same current and with a similar warm-up time. In one such design, a tap on the tube heater string supplied the 6 volts needed for the dial light. By deriving the high voltage from a half-wave rectifier directly connected to the AC mains, the heavy and costly power transformer was eliminated. This also allowed such receivers to operate on direct current, a so-called AC/DC receiver design. Many different US consumer AM radio manufacturers of the era used a virtually identical circuit, given the nickname All American Five.\nWhere the mains voltage was in the 100\u2013120 V range, this limited voltage proved suitable only for low-power receivers. Television receivers either required a transformer or could use a voltage doubling circuit. Where 230 V nominal mains voltage was used, television receivers as well could dispense with a power transformer.\nTransformer-less power supplies required safety precautions in their design to limit the shock hazard to users, such as electrically insulated cabinets and an interlock tying the power cord to the cabinet back, so the line cord was necessarily disconnected if the user or service person opened the cabinet. A \"cheater cord\" was a power cord ending in the special socket used by the safety interlock; servicers could then power the device with the hazardous voltages exposed.\nTo avoid the warm-up delay, \"instant on\" television receivers passed a small heating current through their tubes even when the set was nominally off. At switch on, full heating current was provided and the set would play almost immediately.\nReliability.\nOne reliability problem of tubes with oxide cathodes is the possibility that the cathode may slowly become \"poisoned\" by gas molecules from other elements in the tube, which reduce its ability to emit electrons. Trapped gases or slow gas leaks can also damage the cathode or cause plate (anode) current runaway due to ionization of free gas molecules. Vacuum hardness and proper selection of construction materials are the major influences on tube lifetime. Depending on the material, temperature and construction, the surface material of the cathode may also diffuse onto other elements. The resistive heaters that heat the cathodes may break in a manner similar to incandescent lamp filaments, but rarely do, since they operate at much lower temperatures than lamps.\nThe heater's failure mode is typically a stress-related fracture of the tungsten wire or at a weld point and generally occurs after accruing many thermal (power on-off) cycles. Tungsten wire has a very low resistance when at room temperature. A negative temperature coefficient device, such as a thermistor, may be incorporated in the equipment's heater supply or a ramp-up circuit may be employed to allow the heater or filaments to reach operating temperature more gradually than if powered-up in a step-function. Low-cost radios had tubes with heaters connected in series, with a total voltage equal to that of the line (mains). Some receivers made before World War II had series-string heaters with total voltage less than that of the mains. Some had a resistance wire running the length of the power cord to drop the voltage to the tubes. Others had series resistors made like regular tubes; they were called ballast tubes.\nFollowing World War II, tubes intended to be used in series heater strings were redesigned to all have the same (\"controlled\") warm-up time. Earlier designs had quite-different thermal time constants. The audio output stage, for instance, had a larger cathode and warmed up more slowly than lower-powered tubes. The result was that heaters that warmed up faster also temporarily had higher resistance, because of their positive temperature coefficient. This disproportionate resistance caused them to temporarily operate with heater voltages well above their ratings, and shortened their life.\nAnother important reliability problem is caused by air leakage into the tube. Usually oxygen in the air reacts chemically with the hot filament or cathode, quickly ruining it. Designers developed tube designs that sealed reliably. This was why most tubes were constructed of glass. Metal alloys (such as Cunife and Fernico) and glasses had been developed for light bulbs that expanded and contracted in similar amounts, as temperature changed. These made it easy to construct an insulating envelope of glass, while passing connection wires through the glass to the electrodes.\nWhen a vacuum tube is overloaded or operated past its design dissipation, its anode (plate) may glow red. In consumer equipment, a glowing plate is universally a sign of an overloaded tube. However, some large transmitting tubes are designed to operate with their anodes at red, orange, or in rare cases, white heat\nThe longest recorded valve life was of a Mazda AC/P pentode valve (serial No. 4418) in operation at the BBC's main Northern Ireland transmitter at Lisnagarvey. The valve was in service from 1935 until 1961 and had a recorded life of 232,592 hours. The BBC maintained meticulous records of their valves' lives with periodic returns to their central valve stores.\nSpecial quality.\n\"Special quality\" tubes were made for some applications, designed for improved performance in some respect, such as a longer life cathode, low noise construction, mechanical ruggedness via ruggedized filaments, low microphony, for applications where the tube will spend much of its time cut off, etc. Some special quality tubes were specialised versions of standard tubes, while others were purpose-designed. \"Special quality\" does not mean \"better in all respects\", but that certain characteristics have been optimised; the only way to know the particular features of a special quality part is by reading the datasheet. In particular, tubes made for computing use are designed for long life when used biased to cut-off most of the time, but significant hum, microphony and noise\u2014very undesirable in audio applications\u2014are not important.\nNames may reflect the name of an equivalent standard tube, if there is one (12AU7==&gt;12AU7A, ECC82==&gt;E82CC, etc.), or be absolutely anything (standard and special-quality equivalents of the same tube include 12AU7, ECC82, B329, CV491, E2163, E82CC, E812CC, M8136, CV4003, 6067, VX7058, 5814A and 12AU7A). In the European Mullard\u2013Philips tube designation special-quality tubes move the numeric part immediately after the first letter; the E82CC is an ECC82 optimised for computer applications.\nVacuum.\nA vacuum tube needs an extremely high vacuum (or \"hard\" vacuum, from X-ray terminology) to avoid the consequences of generating positive ions within the tube. Residual gas atoms ionize when struck by an electron and can adversely affect the cathode, reducing emission. Larger amounts of residual gas can create a visible glow discharge between the tube electrodes and cause overheating of the electrodes, producing more gas, damaging the tube and possibly other components due to excess current. To avoid these effects, the residual pressure within the tube must be low enough that the mean free path of an electron is much longer than the size of the tube (so an electron is unlikely to strike a residual atom and very few ionized atoms will be present). Commercial vacuum tubes are evacuated at manufacture to about .\nTo prevent gases from compromising the tube's vacuum, modern tubes are constructed with getters, which are usually metals that oxidize quickly, barium being the most common. For glass tubes, while the tube envelope is being evacuated, the internal parts except the getter are heated by RF induction heating to evolve any remaining gas from the metal parts. The tube is then sealed and the getter trough or pan, for flash getters, is heated to a high temperature, again by radio frequency induction heating, which causes the getter material to vaporize and react with any residual gas. The vapor is deposited on the inside of the glass envelope, leaving a silver-colored metallic patch that continues to absorb small amounts of gas that may leak into the tube during its working life. Great care is taken with the valve design to ensure this material is not deposited on any of the working electrodes. If a tube develops a serious leak in the envelope, this deposit turns a white color as it reacts with atmospheric oxygen. Large transmitting and specialized tubes often use more exotic getter materials, such as zirconium. Early gettered tubes used phosphorus-based getters, and these tubes are easily identifiable, as the phosphorus leaves a characteristic orange or rainbow deposit on the glass. The use of phosphorus was short-lived and was quickly replaced by the superior barium getters. Unlike the barium getters, the phosphorus did not absorb any further gases once it had fired.\nGetters act by chemically combining with residual or infiltrating gases, but are unable to counteract (non-reactive) inert gases. A known problem, mostly affecting valves with large envelopes such as cathode-ray tubes and camera tubes such as iconoscopes, orthicons, and image orthicons, comes from helium infiltration. The effect appears as impaired or absent functioning, and as a diffuse glow along the electron stream inside the tube. This effect cannot be rectified (short of re-evacuation and resealing), and is responsible for working examples of such tubes becoming rarer and rarer. Unused (\"New Old Stock\") tubes can also exhibit inert gas infiltration, so there is no long-term guarantee of these tube types surviving into the future.\nTransmitting tubes.\nLarge transmitting tubes have carbonized tungsten filaments containing a small trace (1% to 2%) of thorium. An extremely thin (molecular) layer of thorium atoms forms on the outside of the wire's carbonized layer and, when heated, serve as an efficient source of electrons. The thorium slowly evaporates from the wire surface, while new thorium atoms diffuse to the surface to replace them. Such thoriated tungsten cathodes usually deliver lifetimes in the tens of thousands of hours. The end-of-life scenario for a thoriated-tungsten filament is when the carbonized layer has mostly been converted back into another form of tungsten carbide and emission begins to drop off rapidly; a complete loss of thorium has never been found to be a factor in the end-of-life in a tube with this type of emitter.\nWAAY-TV in Huntsville, Alabama achieved 163,000 hours (18.6 years) of service from an Eimac external cavity klystron in the visual circuit of its transmitter; this is the highest documented service life for this type of tube. \nIt has been said that transmitters with vacuum tubes are better able to survive lightning strikes than transistor transmitters do. While it was commonly believed that vacuum tubes were more efficient than solid-state circuits at RF power levels above approximately 20 kilowatts, this is no longer the case, especially in medium wave (AM broadcast) service where solid-state transmitters at nearly all power levels have measurably higher efficiency. FM broadcast transmitters with solid-state power amplifiers up to approximately 15\u00a0kW also show better overall power efficiency than tube-based power amplifiers.\nReceiving tubes.\nCathodes in small \"receiving\" tubes are coated with a mixture of barium oxide and strontium oxide, sometimes with addition of calcium oxide or aluminium oxide. An electric heater is inserted into the cathode sleeve and insulated from it electrically by a coating of aluminum oxide. This complex construction causes barium and strontium atoms to diffuse to the surface of the cathode and emit electrons when heated to about 780 degrees Celsius (1400\u00a0\u00b0F).\nFailure modes.\nCatastrophic failures.\nA catastrophic failure is one that suddenly makes the vacuum tube unusable. A crack in the glass envelope will allow air into the tube and destroy it. Cracks may result from stress in the glass, bent pins or impacts; tube sockets must allow for thermal expansion, to prevent stress in the glass at the pins. Stress may accumulate if a metal shield or other object presses on the tube envelope and causes differential heating of the glass. Glass may also be damaged by high-voltage arcing.\nTube heaters may also fail without warning, especially if exposed to over voltage or as a result of manufacturing defects. Tube heaters do not normally fail by evaporation like lamp filaments since they operate at much lower temperature. The surge of inrush current when the heater is first energized causes stress in the heater and can be avoided by slowly warming the heaters, gradually increasing current with a NTC thermistor included in the circuit. Tubes intended for series-string operation of the heaters across the supply have a specified controlled warm-up time to avoid excess voltage on some heaters as others warm up. Directly heated filament-type cathodes as used in battery-operated tubes or some rectifiers may fail if the filament sags, causing internal arcing. Excess heater-to-cathode voltage in indirectly heated cathodes can break down the insulation between elements and destroy the heater.\nArcing between tube elements can destroy the tube. An arc can be caused by applying voltage to the anode (plate) before the cathode has come up to operating temperature, or by drawing excess current through a rectifier, which damages the emission coating. Arcs can also be initiated by any loose material inside the tube, or by excess screen voltage. An arc inside the tube allows gas to evolve from the tube materials, and may deposit conductive material on internal insulating spacers.\nTube rectifiers have limited current capability and exceeding ratings will eventually destroy a tube.\nDegenerative failures.\nDegenerative failures are those caused by the slow deterioration of performance over time.\nOverheating of internal parts, such as control grids or mica spacer insulators, can result in trapped gas escaping into the tube; this can reduce performance. A getter is used to absorb gases evolved during tube operation but has only a limited ability to combine with gas. Control of the envelope temperature prevents some types of gassing. A tube with an unusually high level of internal gas may exhibit a visible blue glow when plate voltage is applied. The getter (being a highly reactive metal) is effective against many atmospheric gases but has no (or very limited) chemical reactivity to inert gases such as helium. One progressive type of failure, especially with physically large envelopes such as those used by camera tubes and cathode-ray tubes, comes from helium infiltration. The exact mechanism is not clear: the metal-to-glass lead-in seals are one possible infiltration site.\nGas and ions within the tube contribute to grid current which can disturb operation of a vacuum-tube circuit. Another effect of overheating is the slow deposit of metallic vapors on internal spacers, resulting in inter-element leakage.\nTubes on standby for long periods, with heater voltage applied, may develop high cathode interface resistance and display poor emission characteristics. This effect occurred especially in pulse and digital circuits, where tubes had no plate current flowing for extended times. Tubes designed specifically for this mode of operation were made.\nCathode depletion is the loss of emission after thousands of hours of normal use. Sometimes emission can be restored for a time by raising heater voltage, either for a short time or a permanent increase of a few percent. Cathode depletion was uncommon in signal tubes but was a frequent cause of failure of monochrome television cathode-ray tubes. Usable life of this expensive component was sometimes extended by fitting a boost transformer to increase heater voltage.\nOther failures.\nVacuum tubes may develop defects in operation that make an individual tube unsuitable in a given device, although it may perform satisfactorily in another application. \"Microphonics\" refers to internal vibrations of tube elements which modulate the tube's signal in an undesirable way; sound or vibration pick-up may affect the signals, or even cause uncontrolled howling if a feedback path (with greater than unity gain) develops between a microphonic tube and, for example, a loudspeaker. Leakage current between AC heaters and the cathode may couple into the circuit, or electrons emitted directly from the ends of the heater may also inject hum into the signal. Leakage current due to internal contamination may also inject noise. Some of these effects make tubes unsuitable for small-signal audio use, although unobjectionable for other purposes. Selecting the best of a batch of nominally identical tubes for critical applications can produce better results.\nTube pins can develop non-conducting or high resistance surface films due to heat or dirt. Pins can be cleaned to restore conductance.\nTesting.\nVacuum tubes can be tested outside of their circuitry using a vacuum tube tester.\nOther vacuum tube devices.\nMost small signal vacuum tube devices have been superseded by semiconductors, but some vacuum tube electronic devices are still in common use. The magnetron is the type of tube used in all microwave ovens. In spite of the advancing state of the art in power semiconductor technology, the vacuum tube still has reliability and cost advantages for high-frequency RF power generation.\nSome tubes, such as magnetrons, traveling-wave tubes, Carcinotrons, and klystrons, combine magnetic and electrostatic effects. These are efficient (usually narrow-band) RF generators and still find use in radar, microwave ovens and industrial heating. Traveling-wave tubes (TWTs) are very good amplifiers and are even used in some communications satellites. High-powered klystron amplifier tubes can provide hundreds of kilowatts in the UHF range.\nCathode-ray tubes.\nThe cathode-ray tube (CRT) is a vacuum tube used particularly for display purposes. Although there were previously many televisions and computer monitors using cathode-ray tubes, most of these have since been replaced by flat panel displays as their prices dropped and quality increased. This is also true of digital oscilloscopes (based on internal computers and analog-to-digital converters), although traditional analog scopes (dependent upon CRTs) continue to be produced, are economical, and preferred by many technicians. At one time many radios used \"magic eye tubes\", a specialized sort of CRT used in place of a meter movement to indicate signal strength or input level in a tape recorder. A modern indicator device, the vacuum fluorescent display (VFD) is also a sort of cathode-ray tube.\nThe X-ray tube is a type of cathode-ray tube that generates X-rays when high voltage electrons hit the anode.\nGyrotrons or vacuum masers, used to generate high-power millimeter band waves, are magnetic vacuum tubes in which a small relativistic effect, due to the high voltage, is used for bunching the electrons. Gyrotrons can generate very high powers (hundreds of kilowatts)., \nFree-electron lasers, used to generate high-power coherent light and even X-rays, are highly relativistic vacuum tubes driven by high-energy particle accelerators. Thus, these are sorts of cathode-ray tubes.\nElectron multipliers.\nA photomultiplier is a phototube whose sensitivity is greatly increased through the use of electron multiplication. This works on the principle of secondary emission, whereby a single electron emitted by the photocathode strikes a special sort of anode known as a dynode causing more electrons to be released from that dynode. Those electrons are accelerated toward another dynode at a higher voltage, releasing more secondary electrons; as many as 15 such stages provide a huge amplification. Despite great advances in solid-state photodetectors (e.g. Single-photon avalanche diode), the single-photon detection capability of photomultiplier tubes makes this vacuum tube device excel in certain applications. Such a tube can also be used for detection of ionizing radiation as an alternative to the Geiger\u2013M\u00fcller tube (itself not an actual vacuum tube). Historically, the image orthicon TV camera tube widely used in television studios prior to the development of modern CCD arrays also used multistage electron multiplication.\nFor decades, electron-tube designers tried to augment amplifying tubes with electron multipliers in order to increase gain, but these suffered from short life because the material used for the dynodes \"poisoned\" the tube's hot cathode. (For instance, the interesting RCA 1630 secondary-emission tube was marketed, but did not last.) However, eventually, Philips of the Netherlands developed the EFP60 tube that had a satisfactory lifetime and was used in at least one product, a laboratory pulse generator. By that time, however, transistors were rapidly improving, making such developments superfluous.\nOne variant called a \"channel electron multiplier\" does not use individual dynodes but consists of a curved tube, such as a helix, coated on the inside with material with good secondary emission. One type had a funnel of sorts to capture the secondary electrons. The continuous dynode was resistive, and its ends were connected to enough voltage to create repeated cascades of electrons. The microchannel plate consists of an array of single stage electron multipliers over an image plane; several of these can then be stacked. This can be used, for instance, as an image intensifier in which the discrete channels substitute for focusing.\nTektronix made a high-performance wideband oscilloscope CRT with a channel electron multiplier plate behind the phosphor layer. This plate was a bundled array of a huge number of short individual c.e.m. tubes that accepted a low-current beam and intensified it to provide a display of practical brightness. (The electron optics of the wideband electron gun could not provide enough current to directly excite the phosphor.)\nVacuum tubes in the 21st century.\nIndustrial, commercial, and military niche applications.\nAlthough vacuum tubes have been largely replaced by solid-state devices in most amplifying, switching, and rectifying applications, there are certain exceptions. In addition to the special functions noted above, tubes still[ [update]] have some niche applications.\nIn general, vacuum tubes are much less susceptible than corresponding solid-state components to transient overvoltages, such as mains voltage surges or lightning, the electromagnetic pulse effect of nuclear explosions, or geomagnetic storms produced by giant solar flares. This property kept them in use for certain military applications long after more practical and less expensive solid-state technology was available for the same applications, as for example with the MiG-25 aircraft.\nVacuum tubes are practical alternatives to solid-state devices in generating high power at radio frequencies in applications such as industrial radio frequency heating, particle accelerators, and broadcast transmitters. This is particularly true at microwave frequencies where such devices as the klystron and traveling-wave tube provide amplification at power levels unattainable using current[ [update]] semiconductor devices. The household microwave oven uses a magnetron tube to efficiently generate hundreds of watts of microwave power. Solid-state devices such as gallium nitride are promising replacements, but are very expensive and in early stages of development.\nIn military applications, a high-power vacuum tube can generate a 10\u2013100\u00a0megawatt signal that can burn out an unprotected receiver's frontend. Such devices are considered non-nuclear electromagnetic weapons; they were introduced in the late 1990s by both the U.S. and Russia.\nIn music.\nTube amplifiers remain commercially viable in three niches where their warm sound, performance when overdriven, and ability to replicate prior-era tube-based recording are prized: audiophile equipment, musical instrument amplifiers, and devices used in recording studios.\nMany guitarists prefer using valve amplifiers to solid-state models, often due to the way they tend to distort when overdriven. Any amplifier can only accurately amplify a signal to a certain volume; past this limit, the amplifier will begin to distort the signal. Different circuits will distort the signal in different ways; some guitarists prefer the distortion characteristics of vacuum tubes. Most popular vintage models use vacuum tubes.\nA UK company, Blackburn MicroTech Solutions, developed radically different versions of standard tubes for the audiophile market. Instead of using a tubular construction with radial electron flow, the design was planar. The first product was the E813CC double triode, interchangeable with the ECC83. However, the company failed in 2009, a few months after introducing the E813CC.\nDisplays.\nCathode-ray tube.\nThe cathode-ray tube was the dominant display technology for televisions and computer monitors at the start of the 21st century. However, rapid advances and falling prices of LCD flat panel technology soon took the place of CRTs in these devices. By 2010, most CRT production had ended.\nVacuum tubes using field electron emitters.\nIn the early years of the 21st century there has been renewed interest in vacuum tubes, this time with the electron emitter formed on a flat silicon substrate, as in integrated circuit technology. This subject is now called vacuum nanoelectronics. The most common design uses a cold cathode in the form of a large-area field electron source (for example a field emitter array). With these devices, electrons are field-emitted from a large number of closely spaced individual emission sites.\nSuch integrated microtubes may find application in microwave devices including mobile phones, for Bluetooth and Wi-Fi transmission, and in radar and satellite communication. As of 2012[ [update]], they were being studied for possible applications in field emission display technology, but there were significant production problems.\nAs of 2014, NASA's Ames Research Center was reported to be working on vacuum-channel transistors produced using CMOS techniques.\nCharacteristics.\nSpace charge.\nWhen a cathode is heated and reaches an operating temperature around , free electrons are driven from its surface. These free electrons form a cloud in the empty space between the cathode and the anode, known as the space charge. This space charge cloud supplies the electrons that create the current flow from the cathode to the anode. As electrons are drawn to the anode during the operation of the circuit, new electrons will boil off the cathode to replenish the space charge. The space charge is an example of an electric field.\nCharacteristic curves.\nAll tubes with one or more control grids are controlled by an AC (Alternating Current) input \"voltage\" applied to the control grid, while the resulting amplified signal appears at the anode as a \"current\". Due to the high voltage placed on the anode, a relatively small anode current can represent a considerable increase in energy over the value of the original signal voltage. The \"space charge\" electrons driven off the heated cathode are strongly attracted by the positive anode. The control grid(s) in a tube mediate this current flow by combining the small AC signal current with the grid's slightly negative value. When the signal sine (AC) wave is applied to the grid, it \"rides\" on this negative value, driving it both positive and negative as the AC signal wave changes.\nThis relationship is shown with a set of \"Plate Characteristics curves,\" (see example above,) which visually display how the output current from the anode (\"I\"a) can be affected by a small input voltage applied on the grid (\"V\"g), for any given voltage on the plate(anode) (\"V\"a).\nEvery tube has a unique set of such characteristic curves. The curves graphically relate the changes to the instantaneous plate current driven by a much smaller change in the grid-to-cathode voltage (\"V\"gk) as the input signal varies.\nThe V-I characteristic depends upon the size and material of the plate and cathode.\nExpress the ratio between voltage plate and plate current.\nSize of electrostatic field.\nSize of electrostatic field is the size between two or more plates in the tube.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "32497", "revid": "25511559", "url": "https://en.wikipedia.org/wiki?curid=32497", "title": "Venice Film Festival", "text": "Annual film festival in Italy\nThe Venice Film Festival or Venice International Film Festival (, \"International Exhibition of Cinematographic Art of the Venice Biennale\") is an annual film festival held in Venice, Italy. It is the world's oldest film festival and one of the \"Big Five\" International film festivals worldwide, which include the Big Three European Film Festivals (Venice, Cannes, Berlin), alongside the Toronto International Film Festival in Canada and the Sundance Film Festival in the United States. In 1951, FIAPF formally accredited the festival. \nFounded by Giuseppe Volpi, member of the National Fascist Party and grandfather of producer Marina Cicogna, in Venice in August 1932, the festival is part of the Venice Biennale, one of the world's oldest exhibitions of art, created by the Venice City Council on 19 April 1893. The range of work at the Venice Biennale now covers Italian and international art, architecture, dance, music, theatre, and cinema. These works are experienced at separate exhibitions: the International Art Exhibition, the International Festival of Contemporary Music, the International Theatre Festival, the International Architecture Exhibition, the International Festival of Contemporary Dance, the International Kids' Carnival, and the annual Venice Film Festival, which is arguably the best-known of all the events.\nThe film festival branch is held in late August and early September on the island of the Lido in the Venice Lagoon. During the festival, Venice hosts many events and parties, interviews and meetings with filmmakers and actors every night, venues open all night, and parties are held in beautiful casino palaces and gardens. Screenings take place in the historic Palazzo del Cinema on the Lungomare Marconi. The festival continues to be one of the world's most popular and fastest-growing. Recently, due to the growing number of American productions in its sections, besides international critically acclaimed titles, the festival became a launchpad of many films for the awards season, prompting higher chance of Academy Award recognition for selected films.\nThe 82nd Venice International Film Festival was held from 27 August to 6 September 2025.\nHistory.\n1930s.\nDuring the 1930s, the government and Italian citizens were heavily interested in film. Of the money Italians spent on cultural or sporting events, most of it went for movies. The majority of films screened in Italy were American, which led to government involvement in the film industry and the yearning to celebrate Italian culture in general. With this in mind, the Venice International Film Festival was created by Giuseppe Volpi, Luciano de Feo, and Antonio Maraini in 1932. Volpi, a statesman, wealthy businessman, and avid fascist who had been Benito Mussolini's minister of finance, was appointed president of the Venice Biennale the same year. Maraini served as the festival's secretary general, and de Feo headed its executive committee.\nOn the night of 6 August 1932, the festival opened with a screening of the American film \"Dr. Jekyll and Mr. Hyde\" on the terrace of the Excelsior Palace Hotel. Nine countries participated in the festival, which ended on 21 August. No awards were given at the first festival, but an audience referendum was held to determine which films and performances were most praiseworthy. The French film \"\u00c0 Nous la Libert\u00e9\" was voted the Film Pi\u00f9 Divertente (the Funniest Film). \"The Sin of Madelon Claudet\" was chosen the Film Pi\u00f9 Commovente (the Most Moving Film) and its star, Helen Hayes, the best actress. Most Original Film (Film dalla fantasia pi\u00f9 originale) was given to \"Dr. Jekyll and Mr. Hyde\", and its leading man, Fredric March, was voted best actor.\nDespite the success of the first festival, it did not return in 1933. In 1934, the festival was declared to be an annual event, and participation grew from nine countries to seventeen. That year the festival gave its first official awards, namely the Mussolini Cup for Best Italian Film, the Mussolini Cup for Best Foreign Film, and the Corporations Ministry Cup. Seventeen awards were given: fourteen to films and three to individuals. Five films received honorable mentions. The third installment of the festival in 1935 was headed by its first artistic director, Ottavio Croze, who maintained this position until World War II. In 1936, a jury was added to the festival's governing body. It had no foreign members. The majority of funds for the festival came from the Ministry of Popular Culture, with other portions from the Biennale and the city of Venice.\n1936 marked another important development in the festival. A law crafted by the Ministry of Popular Culture made the festival an autonomous entity, separate from the main Venice Biennale. This allowed additional fascist organizations, such as the Department of Cinema and the Fascist National Federation of Entertainment Industries, to control it. The fifth year of the festival saw the establishment of its permanent home. Designed and completed in 1937, the Palazzo del Cinema was built on the Lido. It has since been the site for every Venice Film Festival, except the three years from 1940 to 1942, when it was held outside of Venice, due to fear of a bombing that never came.\n1940s.\nThe 1940s represent one of the most difficult moments for the festival. In 1941, Nazi propaganda movie \"Heimkehr\" was presented, winning an award from the Italian Ministry of Popular Culture. With the advent of the conflict the situation degenerated to such a point that the 1940, 1941 and 1942 festivals are regarded as if they did not happen, because they were carried out in places far away from Lido. In 1940, the festival was renamed the Italian-German Film Festival (Manifestazione Cinematografica Italo-Germanica) The festival carried this title until 1942, when the festival was suspended due to war.\nThe festival resumed full speed in 1946, after the war. For the first time, the 1946 edition was held in September, in accordance with an agreement with the newly reborn Cannes Film Festival, which had just held its first review in the spring of that year. With the return to normality, Venice once again became a great icon of the film world.\nIn 1947, the festival was held in the courtyard of the Doge's Palace, a most magnificent backdrop for hosting a record 90 thousand participants. The 1947 festival is widely considered one of the most successful editions in the history of the festival.\nDevelopment and closure.\nIn 1963 the winds of change blew strongly during Luigi Chiarini\u2019s directorship of the festival (1963\u20131968). During the years of his directorship, Chiarini aspired to renew the spirit and the structures of the festival, pushing for a total reorganization of the entire system. For six years the festival followed a consistent path, according to the rigid criteria put in place for the selection of works in competition, and took a firm stand against the political pressures and interference of more and more demanding movie studios, preferring the artistic quality of films to the growing commercialization of the film industry.\nThe social and political unrest of 1968 had strong repercussions on the Venice Bienniale. From 1969 to 1979 no prizes were awarded and the festival returned to the non-competitiveness of the first edition due to the Years of Lead. In 1973, 1977 and 1978, the festival was not even held. The Golden Lion did not make its return until 1980.\nRebirth.\nThe long-awaited rebirth came in 1979, thanks to the new director Carlo Lizzani (1979\u20131983), who decided to restore the image and value the festival had lost over the last decade. The 1979 edition laid the foundation for the restoration of international prestige. In an attempt to create a more modern image of the festival, the neo-director created a committee of experts to assist in selecting the works and to increase the diversity of submissions to the festival.\nIn 2004 an independent and parallel film festival Giornate degli Autori was created in association with the festival.\nTo celebrate the 70th edition of the festival, in 2013, the section \"Venezia 70 \u2013 Future Reloaded\" was specially created for the edition.\n During the recent years, under the direction of Alberto Barbera, the festival established itself as an Oscars launchpad, increasing the presence of American movies and hosting the world premieres of Academy Award\u2013winning films such as \"Gravity\" (2013), \"Birdman\" (2014), \"Spotlight\" (2015), \"La La Land\" (2016), \"The Shape of Water\" (2017), \"A Star Is Born\" (2018), \"The Favourite\" (2018), \"Roma\" (2018), \"Joker\" (2019), \"Nomadland\" (2020), \"Dune\" (2021), \"The Whale\" (2022), \"Poor Things\" (2023) and \"The Brutalist\" (2024).\nIn 2017 a new section for virtual reality films was introduced. Initially this section was called \"Venice Virtual Reality\", but in 2022 the organisation announced the new name to be \"Venice Immersive\". The Venice Film Festival was the first of the \"Big Five\" international film festivals worldwide to introduce virtual reality to the festival program. Therefore, \"Venice Immersive\" quickly became the most important podium for the emerging medium within film to date.\nIn 2018 \"Roma\" by Alfonso Cuar\u00f3n won the Golden Lion and became the first movie produced by a streaming service, Netflix, to win at a major film festival.\nDirection.\nThe president of the Venice Biennale represents the festival in front of its financial partner, the public authorities, and the media. He is chosen by the Italian Ministry of Culture every 4 years. The current president is Pietrangelo Buttafuoco, appointed in March 2024. Previously the post has been held by Paolo Baratta (2008\u20132020) and Roberto Cicutto (2020\u20132024).\nThe director of the Festival is responsible for coordinating the events and is chosen by the president of the Venice Biennale and its delegates. The current director Alberto Barbera was appointed in December 2011. On 27 October 2020 Barbera's term was renewed for 4 more years until 2024. In May 2024, his last mandate was extended until 2026. He previously held the position from 1998 to 2002.\nFestival programme.\nThe goal of the Venice Film Festival is to \"raise awareness and promote international cinema in all its forms, including art, entertainment and industry, in a spirit of freedom and dialogue.\" The Venice Film Festival is organized in various sections:\nAwards.\nThe Film Festival has four Juries to judge the entries: Venezia 79, Orizzonti, Premio Venezia Opera Prima \"Luigi De Laurentiis\", and Venice Immersive. The Film Festival's current awards are:\n\"Orizzonti\" (Horizons).\nThis section is open to all \"custom-format\" works, with a wider view towards new trends in the expressive languages that converge in film. Starting from the 67th edition of the festival, four awards of the Orizzonti section have been established:\nMore awards were added in the following years:\nVenice Immersive.\nThis is the Extended Reality section of the Venice Film Festival and Venice Biennale, founded in 2017. This section is devoted entirely to immersive media and includes all Extended Reality means of creative and cinematographic expression.\nThe awards under this section are:\n\"Giornate degli Autori\".\nThe Giornate degli Autori (formerly Venice Days) is an independent and parallel section founded in 2004 in association with Venice Film Festival. It is modeled on the Directors' Fortnight at the Cannes Film Festival. Anac and 100autori which are both associations of Italian film directors and authors are engaged to support and promote the Giornate.\nThe awards under this sections are:\nLion of the Future (\"Luigi De Laurentis\").\nAll the debut feature films in the various competitive sections in the Venice Film Festival, whether in Official Selection or Independent and Parallel Sections, are eligible for this award. The winner will be awarded a prize of US$100,000, which to be divided equally between the director and the producer.\nGlory to the Filmmaker Award.\nGlory to the Filmmaker Award, organized in collaboration with Jaeger-LeCoultre (2006\u20132020) and Cartier (from 2021), is dedicated to personalities who have made a significant contribution to contemporary cinema.\nPast awards.\nAudience referendum.\nIn the first edition of the festival in 1932, due to the lack of a jury and the awarding of official prizes, a list of acknowledgements was decided by popular vote, a tally determined by the number of people flocking to the films, and announced by the Organizing Committee. From this, the \"Best Director\" was awarded to Russian Nikolai Ekk for the film \"Road to Life\", while by Ren\u00e9 Clair was voted Best Film.\nMussolini Cup ().\nThe Mussolini Cup was the top award from 1934 to 1942 for Best Italian and Best Foreign Film. Named after Italy's dictator Benito Mussolini, it was abandoned upon his ousting in 1943.\nGreat Gold Medals of the National Fascist Association for Entertainment.\n was awarded to Best Actor and Best Actress. It was later replaced by the Volpi Cup for actors and actresses.\nThe first time this prize was awarded to Katharine Hepburn for her role in \"Little Women\" by George Cukor.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32498", "revid": "69412", "url": "https://en.wikipedia.org/wiki?curid=32498", "title": "Volume", "text": "Quantity of three-dimensional space\nVolume is a measure of regions in three-dimensional space. It is often quantified numerically using SI derived units (such as the cubic metre and litre) or by various imperial or US customary units (such as the gallon, quart, cubic inch). The definition of length and height (cubed) is interrelated with volume. The volume of a container is generally understood to be the capacity of the container; i.e., the amount of fluid (gas or liquid) that the container could hold, rather than the amount of space the container itself displaces. \nBy metonymy, the term \"volume\" sometimes is used to refer to the corresponding region (e.g., bounding volume).\nIn ancient times, volume was measured using similar-shaped natural containers. Later on, standardized containers were used. Some simple three-dimensional shapes can have their volume easily calculated using arithmetic formulas. Volumes of more complicated shapes can be calculated with integral calculus if a formula exists for the shape's boundary. Zero-, one- and two-dimensional objects have no volume; in four and higher dimensions, an analogous concept to the normal volume is the hypervolume.\nHistory.\nAncient history.\nThe precision of volume measurements in the ancient period usually ranges between .8 The earliest evidence of volume calculation came from ancient Egypt and Mesopotamia as mathematical problems, approximating volume of simple shapes such as cuboids, cylinders, frustum and cones. These math problems have been written in the Moscow Mathematical Papyrus (c. 1820 BCE). In the Reisner Papyrus, ancient Egyptians have written concrete units of volume for grain and liquids, as well as a table of length, width, depth, and volume for blocks of material.116 The Egyptians use their units of length (the cubit, palm, digit) to devise their units of volume, such as the volume cubit117 or deny (1 cubit \u00d7 1 cubit \u00d7 1 cubit), volume palm (1 cubit \u00d7 1 cubit \u00d7 1 palm), and volume digit (1 cubit \u00d7 1 cubit \u00d7 1 digit).117\nThe last three books of Euclid's \"Elements\", written in around 300 BCE, detailed the exact formulas for calculating the volume of parallelepipeds, cones, pyramids, cylinders, and spheres. The formula were determined by prior mathematicians by using a primitive form of integration, by breaking the shapes into smaller and simpler pieces. A century later, Archimedes (c.\u2009287 \u2013 212 BCE) devised approximate volume formula of several shapes using the method of exhaustion approach, meaning to derive solutions from previous known formulas from similar shapes. Primitive integration of shapes was also discovered independently by Liu Hui in the 3rd century CE, Zu Chongzhi in the 5th century CE, the Middle East and India.\nArchimedes also devised a way to calculate the volume of an irregular object, by submerging it underwater and measure the difference between the initial and final water volume. The water volume difference is the volume of the object. Though highly popularized, Archimedes probably does not submerge the golden crown to find its volume, and thus its density and purity, due to the extreme precision involved. Instead, he likely have devised a primitive form of a hydrostatic balance. Here, the crown and a chunk of pure gold with a similar weight are put on both ends of a weighing scale submerged underwater, which will tip accordingly due to the Archimedes' principle.\nCalculus and standardization of units.\nIn the Middle Ages, many units for measuring volume were made, such as the sester, amber, coomb, and seam. The sheer quantity of such units motivated British kings to standardize them, culminated in the Assize of Bread and Ale statute in 1258 by Henry III of England. The statute standardized weight, length and volume as well as introduced the peny, ounce, pound, gallon and bushel. In 1618, the \"London Pharmacopoeia\" (medicine compound catalog) adopted the Roman gallon or \"congius\" as a basic unit of volume and gave a conversion table to the apothecaries' units of weight. Around this time, volume measurements are becoming more precise and the uncertainty is narrowed to between .8\nAround the early 17th century, Bonaventura Cavalieri applied the philosophy of modern integral calculus to calculate the volume of any object. He devised Cavalieri's principle, which said that using thinner and thinner slices of the shape would make the resulting volume more and more accurate. This idea would then be later expanded by Pierre de Fermat, John Wallis, Isaac Barrow, James Gregory, Isaac Newton, Gottfried Wilhelm Leibniz and Maria Gaetana Agnesi in the 17th and 18th centuries to form the modern integral calculus, which remains in use in the 21st century.\nMetrication and redefinitions.\nOn 7 April 1795, the metric system was formally defined in French law using six units. Three of these are related to volume: the \"st\u00e8re\"\u00a0(1\u00a0m3) for volume of firewood; the \"litre\"\u00a0(1\u00a0dm3) for volumes of liquid; and the \"gramme\", for mass\u2014defined as the mass of one cubic centimetre of water at the temperature of melting ice. Thirty years later in 1824, the imperial gallon was defined to be the volume occupied by ten pounds of water at . This definition was further refined until the United Kingdom's Weights and Measures Act 1985, which makes 1 imperial gallon precisely equal to 4.54609\u00a0litres with no use of water.\nThe 1960 redefinition of the metre from the International Prototype Metre to the orange-red emission line of krypton-86 atoms unbounded the metre, cubic metre, and litre from physical objects. This also make the metre and metre-derived units of volume resilient to changes to the International Prototype Metre. The definition of the metre was redefined again in 1983 to use the speed of light and second (which is derived from the caesium standard) and reworded for clarity in 2019.\nProperties.\nAs a measure of the Euclidean three-dimensional space, volume cannot be physically measured as a negative value, similar to length and area. Like all continuous monotonic (order-preserving) measures, volumes of bodies can be compared against each other and thus can be ordered. Volume can also be added together and be decomposed indefinitely; the latter property is integral to Cavalieri's principle and to the infinitesimal calculus of three-dimensional bodies. A 'unit' of infinitesimally small volume in integral calculus is the volume element; this formulation is useful when working with different coordinate systems, spaces and manifolds.\nMeasurement.\nThe oldest way to roughly measure a volume of an object is using the human body, such as using hand size and pinches. However, the human body's variations make it extremely unreliable. A better way to measure volume is to use roughly consistent and durable containers found in nature, such as gourds, sheep or pig stomachs, and bladders. Later on, as metallurgy and glass production improved, small volumes nowadays are usually measured using standardized human-made containers. This method is common for measuring small volume of fluids or granular materials, by using a multiple or fraction of the container. For granular materials, the container is shaken or leveled off to form a roughly flat surface. This method is not the most accurate way to measure volume but is often used to measure cooking ingredients.\nAir displacement pipette is used in biology and biochemistry to measure volume of fluids at the microscopic scale. Calibrated measuring cups and spoons are adequate for cooking and daily life applications, however, they are not precise enough for laboratories. There, volume of liquids is measured using graduated cylinders, pipettes and volumetric flasks. The largest of such calibrated containers are petroleum storage tanks, some can hold up to of fluids. Even at this scale, by knowing petroleum's density and temperature, very precise volume measurement in these tanks can still be made.\nFor even larger volumes such as in a reservoir, the container's volume is modeled by shapes and calculated using mathematics.\nUnits.\nTo ease calculations, a unit of volume is equal to the volume occupied by a unit cube (with a side length of one). Because the volume occupies three dimensions, if the metre (m) is chosen as a unit of length, the corresponding unit of volume is the cubic metre (m3). The cubic metre is also a SI derived unit. Therefore, volume has a unit dimension of L3.\nThe metric units of volume uses metric prefixes, strictly in powers of ten. When applying prefixes to units of volume, which are expressed in units of length cubed, the cube operators are applied to the unit of length including the prefix. An example of converting cubic centimetre to cubic metre is: 2.3\u00a0cm3 = 2.3 (cm)3 = 2.3 (0.01 m)3 = 0.0000023 m3 (five zeros).143\nCommonly used prefixes for cubed length units are the cubic millimetre (mm3), cubic centimetre (cm3), cubic decimetre (dm3), cubic metre (m3) and the cubic kilometre (km3). The conversion between the prefix units are as follows: 1000\u00a0mm3 = 1\u00a0cm3, 1000\u00a0cm3 = 1\u00a0dm3, and 1000\u00a0dm3 = 1\u00a0m3. The metric system also includes the litre (L) as a unit of volume, where 1 L = 1\u00a0dm3 = 1000\u00a0cm3 = 0.001\u00a0m3.145 For the litre unit, the commonly used prefixes are the millilitre (mL), centilitre (cL), and the litre (L), with 1000\u00a0mL = 1\u00a0L, 10\u00a0mL = 1\u00a0cL, 10\u00a0cL = 1\u00a0dL, and 10\u00a0dL = 1\u00a0L.\nVarious other imperial or U.S. customary units of volume are also in use, including:\nCapacity and volume.\nCapacity is the maximum amount of material that a container can hold, measured in volume or weight. However, the contained volume does not need to fill towards the container's capacity, or vice versa. Containers can only hold a specific amount of physical volume, not weight (excluding practical concerns). For example, a tank that can just hold of fuel oil will not be able to contain the same of naphtha, due to naphtha's lower density and thus larger volume.\nComputation.\nBasic shapes.\nFor many shapes such as the cube, cuboid and cylinder, they have an essentially the same volume calculation formula as one for the prism: the base of the shape multiplied by its height.\nIntegral calculus.\nThe calculation of volume is a vital part of integral calculus. One of which is calculating the volume of solids of revolution, by rotating a plane curve around a line on the same plane. The washer or disc integration method is used when integrating by an axis parallel to the axis of rotation. The general equation can be written as:formula_1where formula_2 and formula_3 are the plane curve boundaries. The shell integration method is used when integrating by an axis perpendicular to the axis of rotation. The equation can be written as:formula_4 The volume of a region \"D\" in three-dimensional space is given by the triple or volume integral of the constant function formula_5 over the region. It is usually written as:Section 14.4\nformula_6\nIn cylindrical coordinates, the volume integral is\nformula_7\nIn spherical coordinates (using the convention for angles with formula_8 as the azimuth and formula_9 measured from the polar axis; see more on conventions), the volume integral is\nformula_10\nGeometric modeling.\nA polygon mesh is a representation of the object's surface, using polygons. The volume mesh explicitly define its volume and surface properties.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32499", "revid": "24013162", "url": "https://en.wikipedia.org/wiki?curid=32499", "title": "Vector graphics", "text": "Computer graphics images defined by points, lines and curves\nVector graphics are a form of computer graphics in which visual images are created directly from geometric shapes defined on a Cartesian plane, such as points, lines, curves and polygons. The associated mechanisms may include vector display and printing \"hardware\", vector \"data models\" and file formats, as well as the \"software\" based on these data models (especially graphic design software, computer-aided design, and geographic information systems). Vector graphics are an alternative to raster or bitmap graphics, with each having advantages and disadvantages in specific situations.\nWhile vector hardware has largely disappeared in favor of raster-based monitors and printers, vector data and software continue to be widely used, especially when a high degree of geometric precision is required, and when complex information can be decomposed into simple geometric primitives. Thus, it is the preferred model for domains such as engineering, architecture, surveying, 3D rendering, and typography, but is entirely inappropriate for applications such as photography and remote sensing, where raster is more effective and efficient. Some application domains, such as geographic information systems (GIS) and graphic design, use both vector and raster graphics at times, depending on purpose.\nVector graphics are based on the mathematics of analytic or coordinate geometry, and is not related to other mathematical uses of the term vector. This can lead to some confusion in disciplines in which both meanings are used.\nData model.\nThe logical data model of vector graphics is based on the mathematics of coordinate geometry, in which shapes are defined as a set of points in a two- or three-dimensional cartesian coordinate system, as \"p\" = (\"x, y\") or \"p\" = (\"x, y, z\"). Because almost all shapes consist of an infinite number of points, the vector model defines a limited set of geometric primitives that can be specified using a finite sample of salient points called vertices. For example, a square can be unambiguously defined by the locations of three of its four corners, from which the software can interpolate the connecting boundary lines and the interior space. Because it is a regular shape, a square could also be defined by the location of one corner, a size (width=height), and a rotation angle.\nThe fundamental geometric primitives are:\nA variety of more complex shapes may be supported:\nIn many vector datasets, each shape can be combined with a set of properties. The most common are visual characteristics, such as color, line weight, or dash pattern. In systems in which shapes represent real-world features, such as GIS and BIM, a variety of attributes of each represented feature can be stored, such as name, age, size, and so on.\nIn some Vector data, especially in GIS, information about topological relationships between objects may be represented in the data model, such as tracking the connections between road segments in a transport network.\nIf a dataset stored in one vector file format is converted to another file format that supports all the primitive objects used in that particular image, then the conversion can be lossless.\nVector display hardware.\nVector-based devices, such as the vector CRT and the pen plotter, directly control a drawing mechanism to produce geometric shapes. Since vector display devices can define a line by dealing with just two points (that is, the coordinates of each end of the line), the device can reduce the total amount of data it must deal with by organizing the image in terms of pairs of points.\nVector graphic displays were first used in 1958 by the US SAGE air defense system. Vector graphics systems were retired from the U.S. en route air traffic control in 1999. Vector graphics were also used on the TX-2 at the Massachusetts Institute of Technology Lincoln Laboratory by computer graphics pioneer Ivan Sutherland to run his program Sketchpad in 1963.\nSubsequent vector graphics systems, most of which iterated through dynamically modifiable stored lists of drawing instructions, include the IBM 2250, Imlac PDS-1, and DEC GT40. There was a video game console that used vector graphics called Vectrex as well as various arcade games like \"Asteroids\", \"Space Wars\", \"Tempest\" and many cinematronics titles such as \"Rip Off\", and \"Tail Gunner\" using vector monitors. Storage scope displays, such as the Tektronix 4014, could display vector images but not modify them without first erasing the display. However, these were never as widely used as the raster-based scanning displays used for television, and had largely disappeared by the mid-1980s except for specialized applications.\nPlotters used in technical drawing still draw vectors directly to paper by moving a pen as directed through the two-dimensional space of the paper. However, as with monitors, these have largely been replaced by the wide-format printer that prints a raster image (which may be rendered from vector data).\nSoftware.\nBecause this model is useful in a variety of application domains, many different software programs have been created for drawing, manipulating, and visualizing vector graphics. While these are all based on the same basic vector data model, they can interpret and structure shapes very differently, using very different file formats.\nFile formats.\nVector graphics are commonly found today in the SVG, WMF, EPS, PDF, CDR or AI types of graphic file formats, and are intrinsically different from the more common raster graphics file formats such as JPEG, PNG, APNG, GIF, WebP, BMP and MPEG4.\nThe World Wide Web Consortium (W3C) standard for vector graphics is Scalable Vector Graphics (SVG). The standard is complex and has been relatively slow to be established at least in part owing to commercial interests. Many web browsers now have some support for rendering SVG data but full implementations of the standard are still comparatively rare.\nIn recent years, SVG has become a significant format that is completely independent of the resolution of the rendering device, typically a printer or display monitor. SVG files are essentially printable text that describes both straight and curved paths, as well as other attributes. Wikipedia prefers SVG for images such as simple maps, line illustrations, coats of arms, and flags, which generally are not like photographs or other continuous-tone images. Rendering SVG requires conversion to a raster format at a resolution appropriate for the current task. SVG is also a format for animated graphics.\nThere is also a version of SVG for mobile phones called SVGT (SVG Tiny version). These images can count links and also exploit anti-aliasing. They can also be displayed as wallpaper.\nCAD software uses its own vector data formats, usually proprietary formats created by software vendors, such as Autodesk's DWG and public exchange formats such as DXF. Hundreds of distinct vector file formats have been created for GIS data over its history, including proprietary formats like the Esri file geodatabase, proprietary but public formats like the Shapefile and the original KML, open source formats like GeoJSON, and formats created by standards bodies like Simple Features and GML from the Open Geospatial Consortium.\nConversion.\nTo raster.\nModern displays and printers are raster devices; vector formats have to be converted to a raster format (bitmaps \u2013 pixel arrays) before they can be rendered (displayed or printed). The size of the bitmap/raster-format file generated by the conversion will depend on the resolution required, but the size of the vector file generating the bitmap/raster file will always remain the same. Thus, it is easy to convert from a vector file to a range of bitmap/raster file formats but it is much more difficult to go in the opposite direction, especially if subsequent editing of the vector picture is required. It might be an advantage to save an image created from a vector source file as a bitmap/raster format, because different systems have different (and incompatible) vector formats, and some might not support vector graphics at all. However, once a file is converted from the vector format, it is likely to be bigger, and it loses the advantage of scalability without loss of resolution. It will also no longer be possible to edit individual parts of the image as discrete objects. The file size of a vector graphic image depends on the number of graphic elements it contains; it is a list of descriptions.\nPrinting.\nVector art is ideal for printing since the art is made from a series of mathematical curves; it will print very crisply even when resized. For instance, one can print a vector logo on a small sheet of copy paper, and then enlarge the same vector logo to billboard size and keep the same crisp quality. A low-resolution raster graphic would blur or pixelate excessively if it were enlarged from business card size to billboard size. (The precise resolution of a raster graphic necessary for high-quality results depends on the viewing distance; e.g., a billboard may still appear to be of high quality even at low resolution if the viewing distance is great enough.)\nIf we regard typographic characters as images, then the same considerations that we have made for graphics apply even to the composition of written text for printing (typesetting). Older character sets were stored as bitmaps. Therefore, to achieve maximum print quality they had to be used at a given resolution only; these font formats are said to be non-scalable. High-quality typography is nowadays based on character drawings (fonts) which are typically stored as vector graphics, and as such are scalable to any size. Examples of these vector formats for characters are Postscript fonts and TrueType fonts.\nOperation.\nAdvantages of this style of drawing over raster graphics:\nFor example, consider a circle of radius \"r\". The main pieces of information a program needs in order to draw this circle are\nVector formats are not always appropriate in graphics work and also have numerous disadvantages. For example, devices such as cameras and scanners produce essentially continuous-tone raster graphics that are impractical to convert into vectors, and so for this type of work, an image editor will operate on the pixels rather than on drawing objects defined by mathematical expressions. Comprehensive graphics tools will combine images from vector and raster sources, and may provide editing tools for both, since some parts of an image could come from a camera source, and others could have been drawn using vector tools.\nSome authors have criticized the term \"vector graphics\" as being confusing. In particular, \"vector graphics\" does not simply refer to graphics described by Euclidean vectors. Some authors have proposed to use \"object-oriented graphics\" instead. However this term can also be confusing as it can be read as any kind of graphics implemented using object-oriented programming.\nVector operations.\nVector graphics editors typically allow translation, rotation, mirroring, stretching, skewing, affine transformations, changing of z-order (loosely, what's in front of what) and combination of primitives into more complex objects. More sophisticated transformations include set operations on closed shapes (union, difference, intersection, etc.). In SVG, the composition operations are based on alpha composition.\nVector graphics are ideal for simple or composite drawings that need to be device-independent, or do not need to achieve photo-realism. For example, the PostScript and PDF page description languages use a vector graphics model.\nVector image repositories.\nMany stock photo websites provide vectorized versions of hosted images, while specific repositories specialize in vector images given their growing popularity among graphic designers.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32500", "revid": "38475895", "url": "https://en.wikipedia.org/wiki?curid=32500", "title": "Vacuum pump", "text": "Equipment generating a relative vacuum\nA vacuum pump is a type of pump device that draws gas particles from a sealed volume in order to leave behind a partial vacuum. The first vacuum pump was invented in 1650 by Otto von Guericke, and was preceded by the suction pump, which dates to antiquity.\nHistory.\nEarly pumps.\nThe predecessor to the vacuum pump was the suction pump. Dual-action suction pumps were found in the city of Pompeii. Arabic engineer Al-Jazari later described dual-action suction pumps as part of water-raising machines in the 13th century. He also said that a suction pump was used in siphons to discharge Greek fire. The suction pump later appeared in medieval Europe from the 15th century.\nBy the 17th century, water pump designs had improved to the point that they produced measurable vacuums, but this was not immediately understood. What was known was that suction pumps could not pull water beyond a certain height: 18 Florentine yards according to a measurement taken around 1635, or about . This limit was a concern in irrigation projects, mine drainage, and decorative water fountains planned by the Duke of Tuscany, so the duke commissioned Galileo Galilei to investigate the problem. Galileo suggested, incorrectly, in his \"Two New Sciences\" (1638) that the column of a water pump will break of its own weight when the water has been lifted to 34 feet. Other scientists took up the challenge, including Gasparo Berti, who replicated it by building the first water barometer in Rome in 1639. Berti's barometer produced a vacuum above the water column, but he could not explain it. A breakthrough was made by Galileo's student Evangelista Torricelli in 1643. Building upon Galileo's notes, he built the first mercury barometer and wrote a convincing argument that the space at the top was a vacuum. The height of the column was then limited to the maximum weight that atmospheric pressure could support; this is the limiting height of a suction pump.\nIn 1650, Otto von Guericke invented the first vacuum pump. Four years later, he conducted his famous Magdeburg hemispheres experiment, showing that teams of horses could not separate two hemispheres from which the air had been evacuated. Robert Boyle improved Guericke's design and conducted experiments on the properties of vacuum. Robert Hooke also helped Boyle produce an air pump that helped to produce the vacuum.\nBy 1709, Francis Hauksbee improved on the design further with his two-cylinder pump, where two pistons worked via a rack-and-pinion design that reportedly \"gave a vacuum within about one inch of mercury of perfect.\" This design remained popular and only slightly changed until well into the nineteenth century.\n19th century.\nHeinrich Geissler invented the mercury displacement pump in 1855 and achieved a record vacuum of about 10\u00a0Pa (0.1 Torr). A number of electrical properties become observable at this vacuum level, and this renewed interest in vacuum. This, in turn, led to the development of the vacuum tube. The Sprengel pump was a widely used vacuum producer of this time.\n20th century.\nThe early 20th century saw the invention of many types of vacuum pump, including the molecular drag pump, the diffusion pump, and the turbomolecular pump.\nTypes.\nPumps can be broadly categorized according to three techniques: positive displacement, momentum transfer, and entrapment. Positive displacement pumps use a mechanism to repeatedly expand a cavity, allow gases to flow in from the chamber, seal off the cavity, and exhaust it to the atmosphere. Momentum transfer pumps, also called molecular pumps, use high-speed jets of dense fluid or high-speed rotating blades to knock gas molecules out of the chamber. Entrapment pumps capture gases in a solid or adsorbed state; this includes cryopumps, getters, and ion pumps.\nPositive displacement pumps are the most effective for low vacuums. Momentum transfer pumps, in conjunction with one or two positive displacement pumps, are the most common configuration used to achieve high vacuums. In this configuration the positive displacement pump serves two purposes. First it obtains a rough vacuum in the vessel being evacuated before the momentum transfer pump can be used to obtain the high vacuum, as momentum transfer pumps cannot start pumping at atmospheric pressures. Second the positive displacement pump backs up the momentum transfer pump by evacuating to low vacuum the accumulation of displaced molecules in the high vacuum pump. Entrapment pumps can be added to reach ultrahigh vacuums, but they require periodic regeneration of the surfaces that trap air molecules or ions. Due to this requirement their available operational time can be unacceptably short in low and high vacuums, thus limiting their use to ultrahigh vacuums. Pumps also differ in details like manufacturing tolerances, sealing material, pressure, flow, admission or no admission of oil vapor, service intervals, reliability, tolerance to dust, tolerance to chemicals, tolerance to liquids and vibration.\nPositive displacement pump.\nA partial vacuum may be generated by increasing the volume of a container. To continue evacuating a chamber indefinitely without requiring infinite growth, a compartment of the vacuum can be repeatedly closed off, exhausted, and expanded again. This is the principle behind a positive displacement pump, for example the manual water pump. Inside the pump, a mechanism expands a small sealed cavity to reduce its pressure below that of the atmosphere. Because of the pressure differential, some fluid from the chamber (or the well, in our example) is pushed into the pump's small cavity. The pump's cavity is then sealed from the chamber, opened to the atmosphere, and squeezed back to a minute size.\nMore sophisticated systems are used for most industrial applications, but the basic principle of cyclic volume removal is the same:\nThe base pressure of a rubber- and plastic-sealed piston pump system is typically 1 to 50 kPa, while a scroll pump might reach 10 Pa (when new) and a rotary vane oil pump with a clean and empty metallic chamber can easily achieve 0.1 Pa.\nA positive displacement vacuum pump moves the same volume of gas with each cycle, so its pumping speed is constant unless it is overcome by backstreaming.\nMomentum transfer pump.\nIn a momentum transfer pump (or kinetic pump), gas molecules are accelerated from the vacuum side to the exhaust side (which is usually maintained at a reduced pressure by a positive displacement pump). Momentum transfer pumping is only possible below pressures of about 0.1 kPa. Matter flows differently at different pressures based on the laws of fluid dynamics. At atmospheric pressure and mild vacuums, molecules interact with each other and push on their neighboring molecules in what is known as viscous flow. When the distance between the molecules increases, the molecules interact with the walls of the chamber more often than with the other molecules, and molecular pumping becomes more effective than positive displacement pumping. This regime is generally called high vacuum.\nMolecular pumps sweep out a larger area than mechanical pumps, and do so more frequently, making them capable of much higher pumping speeds. They do this at the expense of the seal between the vacuum and their exhaust. Since there is no seal, a small pressure at the exhaust can easily cause backstreaming through the pump; this is called stall. In high vacuum, however, pressure gradients have little effect on fluid flows, and molecular pumps can attain their full potential.\nThe two main types of molecular pumps are the diffusion pump and the turbomolecular pump. Both types of pumps blow out gas molecules that diffuse into the pump by imparting momentum to the gas molecules. Diffusion pumps blow out gas molecules with jets of an oil or mercury vapor, while turbomolecular pumps use high speed fans to push the gas. Both of these pumps will stall and fail to pump if exhausted directly to atmospheric pressure, so they must be exhausted to a lower grade vacuum created by a mechanical pump, in this case called a backing pump.\nAs with positive displacement pumps, the base pressure will be reached when leakage, outgassing, and backstreaming equal the pump speed, but now minimizing leakage and outgassing to a level comparable to backstreaming becomes much more difficult.\nEntrapment pump.\nAn entrapment pump may be a cryopump, which uses cold temperatures to condense gases to a solid or adsorbed state, a chemical pump, which reacts with gases to produce a solid residue, or an ion pump, which uses strong electrical fields to ionize gases and propel the ions into a solid substrate. A cryomodule uses cryopumping. Other types are the sorption pump, non-evaporative getter pump, and titanium sublimation pump (a type of evaporative getter that can be used repeatedly).\nOther types.\nRegenerative pump.\nRegenerative pumps utilize vortex behavior of the fluid (air). The construction is based on hybrid concept of centrifugal pump and turbopump. Usually it consists of several sets of perpendicular teeth on the rotor circulating air molecules inside stationary hollow grooves like multistage centrifugal pump. They can reach to 1\u00d710\u22125 mbar (0.001 Pa) (when combining with Holweck pump) and directly exhaust to atmospheric pressure. Examples of such pumps are Edwards EPX (technical paper ) and Pfeiffer OnTool\u2122 Booster 150. It is sometimes referred as side channel pump. Due to high pumping rate from atmosphere to high vacuum and less contamination since bearing can be installed at exhaust side, this type of pumps are used in load lock in semiconductor manufacturing processes.\nThis type of pump suffers from high power consumption (~1\u00a0kW) compared to turbomolecular pump (&lt;100W) at low pressure since most power is consumed to back atmospheric pressure. This can be reduced by nearly 10 times by backing with a small pump.\nMore examples.\nAdditional types of pump include the:\nPerformance measures.\nPumping speed refers to the volume flow rate of a pump at its inlet, often measured in volume per unit of time. Momentum transfer and entrapment pumps are more effective on some gases than others, so the pumping rate can be different for each of the gases being pumped, and the average volume flow rate of the pump will vary depending on the chemical composition of the gases remaining in the chamber.\nThroughput refers to the pumping speed multiplied by the gas pressure at the inlet, and is measured in units of pressure\u00b7volume/unit time. At a constant temperature, throughput is proportional to the number of molecules being pumped per unit time, and therefore to the mass flow rate of the pump. When discussing a leak in the system or backstreaming through the pump, throughput refers to the volume leak rate multiplied by the pressure at the vacuum side of the leak, so the leak throughput can be compared to the pump throughput.\nPositive displacement and momentum transfer pumps have a constant volume flow rate (pumping speed), but as the chamber's pressure drops, this volume contains less and less mass. So although the pumping speed remains constant, the throughput and mass flow rate drop exponentially. Meanwhile, the leakage, evaporation, sublimation and backstreaming rates continue to produce a constant throughput into the system.\nTechniques.\nVacuum pumps are combined with chambers and operational procedures into a wide variety of vacuum systems. Sometimes more than one pump will be used (in series or in parallel) in a single application. A partial vacuum, or rough vacuum, can be created using a positive displacement pump that transports a gas load from an inlet port to an outlet (exhaust) port. Because of their mechanical limitations, such pumps can only achieve a low vacuum. To achieve a higher vacuum, other techniques must then be used, typically in series (usually following an initial fast pump down with a positive displacement pump). Some examples might be use of an oil sealed rotary vane pump (the most common positive displacement pump) backing a diffusion pump, or a dry scroll pump backing a turbomolecular pump. There are other combinations depending on the level of vacuum being sought.\nAchieving high vacuum is difficult because all of the materials exposed to the vacuum must be carefully evaluated for their outgassing and vapor pressure properties. For example, oils, greases, and rubber or plastic gaskets used as seals for the vacuum chamber must not boil off when exposed to the vacuum, or the gases they produce would prevent the creation of the desired degree of vacuum. Often, all of the surfaces exposed to the vacuum must be baked at high temperature to drive off adsorbed gases.\nOutgassing can also be reduced simply by desiccation prior to vacuum pumping.\nHigh-vacuum systems generally require metal chambers with metal gasket seals such as Klein flanges or ISO flanges, rather than the rubber gaskets more common in low vacuum chamber seals. The system must be clean and free of organic matter to minimize outgassing. All materials, solid or liquid, have a small vapour pressure, and their outgassing becomes important when the vacuum pressure falls below this vapour pressure. As a result, many materials that work well in low vacuums, such as epoxy, will become a source of outgassing at higher vacuums. With these standard precautions, vacuums of 1 mPa are easily achieved with an assortment of molecular pumps. With careful design and operation, 1 \u03bcPa is possible.\nSeveral types of pumps may be used in sequence or in parallel. In a typical pumpdown sequence, a positive displacement pump would be used to remove most of the gas from a chamber, starting from atmosphere (760 Torr, 101 kPa) to 25 Torr (3 kPa). Then a sorption pump would be used to bring the pressure down to 10\u22124 Torr (10 mPa). A cryopump or turbomolecular pump would be used to bring the pressure further down to 10\u22128 Torr (1 \u03bcPa). An additional ion pump can be started below 10\u22126 Torr to remove gases which are not adequately handled by a cryopump or turbo pump, such as helium or hydrogen.\nUltra-high vacuum generally requires custom-built equipment, strict operational procedures, and a fair amount of trial-and-error. Ultra-high vacuum systems are usually made of stainless steel with metal-gasketed vacuum flanges. The system is usually baked, preferably under vacuum, to temporarily raise the vapour pressure of all outgassing materials in the system and boil them off. If necessary, this outgassing of the system can also be performed at room temperature, but this takes much more time. Once the bulk of the outgassing materials are boiled off and evacuated, the system may be cooled to lower vapour pressures to minimize residual outgassing during actual operation. Some systems are cooled well below room temperature by liquid nitrogen to shut down residual outgassing and simultaneously cryopump the system.\nIn ultra-high vacuum systems, some very odd leakage paths and outgassing sources must be considered. The water absorption of aluminium and palladium becomes an unacceptable source of outgassing, and even the absorptivity of hard metals such as stainless steel or titanium must be considered. Some oils and greases will boil off in extreme vacuums. The porosity of the metallic vacuum chamber walls may have to be considered, and the grain direction of the metallic flanges should be parallel to the flange face.\nThe impact of molecular size must be considered. Smaller molecules can leak in more easily and are more easily absorbed by certain materials, and molecular pumps are less effective at pumping gases with lower molecular weights. A system may be able to evacuate nitrogen (the main component of air) to the desired vacuum, but the chamber could still be full of residual atmospheric hydrogen and helium. Vessels lined with a highly gas-permeable material such as palladium (which is a high-capacity hydrogen sponge) create special outgassing problems.\nApplications.\nVacuum pumps are used in many industrial and scientific processes, including:\nIn the field of oil regeneration and re-refining, vacuum pumps create a low vacuum for oil dehydration and a high vacuum for oil purification.\nA vacuum may be used to power, or provide assistance to mechanical devices. In hybrid and diesel engine motor vehicles, a pump fitted on the engine (usually on the camshaft) is used to produce a vacuum. In petrol engines, instead, the vacuum is typically obtained as a side-effect of the operation of the engine and the flow restriction created by the throttle plate but may be also supplemented by an electrically operated vacuum pump to boost braking assistance or improve fuel consumption. This vacuum may then be used to power the following motor vehicle components: vacuum servo booster for the hydraulic brakes, motors that move dampers in the ventilation system, throttle driver in the cruise control servomechanism, door locks or trunk releases.\nIn an aircraft, the vacuum source is often used to power gyroscopes in the various flight instruments. To prevent the complete loss of instrumentation in the event of an electrical failure, the instrument panel is deliberately designed with certain instruments powered by electricity and other instruments powered by the vacuum source.\nDepending on the application, some vacuum pumps may either be electrically driven (using electric current) or pneumatically-driven (using air pressure), or powered and actuated by other means.\nHazards.\nOld vacuum-pump oils that were produced before circa 1980 often contain a mixture of several different dangerous polychlorinated biphenyls (PCBs), which are highly toxic, carcinogenic, persistent organic pollutants.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "32502", "revid": "173996", "url": "https://en.wikipedia.org/wiki?curid=32502", "title": "Vacuum", "text": "Space that is empty of matter\nA vacuum (pl.: vacuums or vacua) is space devoid of matter. The word is derived from the Latin adjective (neuter ) meaning \"vacant\" or \"void\". An approximation to such vacuum is a region with a gaseous pressure much less than atmospheric pressure. Physicists often discuss ideal test results that would occur in a \"perfect\" vacuum, which they sometimes simply call \"vacuum\" or free space, and use the term partial vacuum to refer to an actual imperfect vacuum as one might have in a laboratory or in space. In engineering and applied physics on the other hand, vacuum refers to any space in which the pressure is considerably lower than atmospheric pressure. The Latin term in vacuo is used to describe an object that is surrounded by a vacuum.\nThe \"quality\" of a partial vacuum refers to how closely it approaches a perfect vacuum. Other things equal, lower gas pressure means higher-quality vacuum. For example, a typical vacuum cleaner produces enough suction to reduce air pressure by around 20%. But higher-quality vacuums are possible. Ultra-high vacuum chambers, common in chemistry, physics, and engineering, operate below one trillionth (10\u221212) of atmospheric pressure (100\u00a0nPa), and can reach around 100\u00a0particles/cm3. Outer space is an even higher-quality vacuum, with the equivalent of just a few hydrogen atoms per cubic meter on average in intergalactic space.\nVacuum has been a frequent topic of philosophical debate since ancient Greek times, but was not studied empirically until the 17th century. Clemens Timpler (1605) philosophized about the experimental possibility of producing a vacuum in small tubes. Evangelista Torricelli produced the first laboratory vacuum in 1643, and other experimental techniques were developed as a result of his theories of atmospheric pressure. A Torricellian vacuum is created by filling with mercury a tall glass container closed at one end, and then inverting it in a bowl to contain the mercury (see below).\nVacuum became a valuable industrial tool in the 20th century with the introduction of incandescent light bulbs and vacuum tubes, and a wide array of vacuum technologies has since become available. The development of human spaceflight has raised interest in the impact of vacuum on human health, and on life forms in general.\nEtymology.\nThe word \"vacuum\" comes from la\u00a0'an empty space, void', noun use of neuter of \"vacuus\", meaning \"empty\", related to \"vacare\", meaning \"to be empty\".\n\"Vacuum\" is one of the few words in the English language that contains two consecutive instances of the vowel \"u\".\nHistorical understanding.\nHistorically, there has been much dispute over whether such a thing as a vacuum can exist. Ancient Greek philosophers debated the existence of a vacuum, or void, in the context of atomism, which posited void and atom as the fundamental explanatory elements of physics. Lucretius argued for the existence of vacuum in the first century BC and Hero of Alexandria tried unsuccessfully to create an artificial vacuum in the first century AD.\nFollowing Plato, however, even the abstract concept of a featureless void faced considerable skepticism: it could not be apprehended by the senses, it could not, itself, provide additional explanatory power beyond the physical volume with which it was commensurate and, by definition, it was quite literally nothing at all, which cannot rightly be said to exist. Aristotle believed that no void could occur naturally, because the denser surrounding material continuum would immediately fill any incipient rarity that might give rise to a void. In his \"Physics\", book IV, Aristotle offered numerous arguments against the void: for example, that motion through a medium which offered no impediment could continue \"ad infinitum\", there being no reason that something would come to rest anywhere in particular. \nIn the medieval Muslim world, the physicist and Islamic scholar Al-Farabi wrote a treatise rejecting the existence of the vacuum in the 10th century. He concluded that air's volume can expand to fill available space, and therefore the concept of a perfect vacuum was incoherent. According to Ahmad Dallal, Ab\u016b Rayh\u0101n al-B\u012br\u016bn\u012b states that \"there is no observable evidence that rules out the possibility of vacuum\". The suction pump was described by Arab engineer Al-Jazari in the 13th century, and later appeared in Europe from the 15th century.\nEuropean scholars such as Roger Bacon, Blasius of Parma and Walter Burley in the 13th and 14th century focused considerable attention on issues concerning the concept of a vacuum. The commonly held view that nature abhorred a vacuum was called \"horror vacui\". There was even speculation that even God could not create a vacuum if he wanted and the 1277 Paris condemnations of Bishop \u00c9tienne Tempier, which required there to be no restrictions on the powers of God, led to the conclusion that God could create a vacuum if he so wished. From the 14th century onward increasingly departed from the Aristotelian perspective, scholars widely acknowledged that a supernatural void exists beyond the confines of the cosmos itself by the 17th century. This idea, influenced by Stoic physics, helped to segregate natural and theological concerns.\nAlmost two thousand years after Plato, Ren\u00e9 Descartes also proposed a geometrically based alternative theory of atomism, without the problematic nothing\u2013everything dichotomy of void and atom. Although Descartes agreed with the contemporary position, that a vacuum does not occur in nature, the success of his namesake coordinate system and more implicitly, the spatial\u2013corporeal component of his metaphysics would come to define the philosophically modern notion of empty space as a quantified extension of volume. By the ancient definition however, directional information and magnitude were conceptually distinct.\nMedieval thought experiments into the idea of a vacuum considered whether a vacuum was present, if only for an instant, between two flat plates when they were rapidly separated. There was much discussion of whether the air moved in quickly enough as the plates were separated, or, as Walter Burley postulated, whether a 'celestial agent' prevented the vacuum arising. Jean Buridan reported in the 14th century that teams of ten horses could not pull open bellows when the port was sealed.\nThe 17th century saw the first attempts to quantify measurements of partial vacuum. Evangelista Torricelli's mercury barometer of 1643 and Blaise Pascal's experiments both demonstrated a partial vacuum.\nIn 1654, Otto von Guericke invented the first vacuum pump and conducted his famous Magdeburg hemispheres experiment, showing that, owing to atmospheric pressure outside the hemispheres, teams of horses could not separate two hemispheres from which the air had been partially evacuated. Robert Boyle improved Guericke's design and with the help of Robert Hooke further developed vacuum pump technology. Thereafter, research into the partial vacuum lapsed until 1850 when August Toepler invented the Toepler pump and in 1855 when Heinrich Geissler invented the mercury displacement pump, achieving a partial vacuum of about 10\u00a0Pa (0.1\u00a0Torr). A number of electrical properties become observable at this vacuum level, which renewed interest in further research.\nWhile outer space provides the most rarefied example of a naturally occurring partial vacuum, the heavens were originally thought to be seamlessly filled by a rigid indestructible material called aether. Borrowing somewhat from the pneuma of Stoic physics, aether came to be regarded as the rarefied air from which it took its name, (see Aether (mythology)). Early theories of light posited a ubiquitous terrestrial and celestial medium through which light propagated. Additionally, the concept informed Isaac Newton's explanations of both refraction and of radiant heat. 19th century experiments into this luminiferous aether attempted to detect a minute drag on the Earth's orbit. While the Earth does, in fact, move through a relatively dense medium in comparison to that of interstellar space, the drag is so minuscule that it could not be detected. In 1912, astronomer Henry Pickering commented: \"While the interstellar absorbing medium may be simply the ether, [it] is characteristic of a gas, and free gaseous molecules are certainly there\". Thereafter, however, luminiferous aether was discarded.\nLater, in 1930, Paul Dirac proposed a model of the vacuum as an infinite sea of particles possessing negative energy, called the Dirac sea. This theory helped refine the predictions of his earlier formulated Dirac equation, and successfully predicted the existence of the positron, confirmed two years later. Werner Heisenberg's uncertainty principle, formulated in 1927, predicted a fundamental limit within which instantaneous position and momentum, or energy and time can be measured. These far-reaching consequences also threatened whether the \"emptiness\" of space between particles exists.\nClassical field theories.\nThe strictest criterion to define a vacuum is a region of space and time where all the components of the stress\u2013energy tensor are zero. This means that this region is devoid of energy and momentum, and by consequence, it must be empty of particles and other physical fields (such as electromagnetism) that contain energy and momentum.\nGravity.\nIn general relativity, a vanishing stress\u2013energy tensor implies, through Einstein field equations, the vanishing of all the components of the Ricci tensor. Vacuum does not mean that the curvature of space-time is necessarily flat: the gravitational field can still produce curvature in a vacuum in the form of tidal forces and gravitational waves (technically, these phenomena are the components of the Weyl tensor). The black hole (with zero electric charge) is an elegant example of a region completely \"filled\" with vacuum, but still showing a strong curvature.\nElectromagnetism.\nIn classical electromagnetism, the vacuum of free space, or sometimes just \"free space\" or \"perfect vacuum\", is a standard reference medium for electromagnetic effects. Some authors refer to this reference medium as \"classical vacuum\", a terminology intended to separate this concept from QED vacuum or QCD vacuum, where vacuum fluctuations can produce transient virtual particle densities and a relative permittivity and relative permeability that are not identically unity.\nIn the theory of classical electromagnetism, free space has the following properties:\nThe vacuum of classical electromagnetism can be viewed as an idealized electromagnetic medium with the constitutive relations in SI units:\n formula_1\n formula_2\nrelating the electric displacement field D to the electric field E and the magnetic field or \"H\"-field H to the magnetic induction or \"B\"-field B. Here r is a spatial location and t is time.\nQuantum mechanics.\nIn quantum mechanics and quantum field theory, the vacuum is defined as the state (that is, the solution to the equations of the theory) with the lowest possible energy (the ground state of the Hilbert space). In quantum electrodynamics this vacuum is referred to as 'QED vacuum' to distinguish it from the vacuum of quantum chromodynamics, denoted as QCD vacuum. QED vacuum is a state with no matter particles (hence the name), and no photons. As described above, this state is impossible to achieve experimentally. (Even if every matter particle could somehow be removed from a volume, it would be impossible to eliminate all the blackbody photons.) Nonetheless, it provides a good model for realizable vacuum, and agrees with a number of experimental observations as described next.\nQED vacuum has interesting and complex properties. In QED vacuum, the electric and magnetic fields have zero average values, but their variances are not zero. As a result, QED vacuum contains vacuum fluctuations (virtual particles that hop into and out of existence), and a finite energy called vacuum energy. Vacuum fluctuations are an essential and ubiquitous part of quantum field theory. Some experimentally verified effects of vacuum fluctuations include spontaneous emission and the Lamb shift. Coulomb's law and the electric potential in vacuum near an electric charge are modified.\nTheoretically, in QCD multiple vacuum states can coexist. The starting and ending of cosmological inflation is thought to have arisen from transitions between different vacuum states. For theories obtained by quantization of a classical theory, each stationary point of the energy in the configuration space gives rise to a single vacuum. String theory is believed to have a huge number of vacua \u2013 the so-called string theory landscape.\nOuter space.\nOuter space has very low density and pressure, and is the closest physical approximation of a perfect vacuum. But no vacuum is truly perfect, not even in interstellar space, where there are still a few hydrogen atoms per cubic meter.\nStars, planets, and moons keep their atmospheres by gravitational attraction, and as such, atmospheres have no clearly delineated boundary: the density of atmospheric gas simply decreases with distance from the object. The Earth's atmospheric pressure drops to about at of altitude, the K\u00e1rm\u00e1n line, which is a common definition of the boundary with outer space. Beyond this line, isotropic gas pressure rapidly becomes insignificant when compared to radiation pressure from the Sun and the dynamic pressure of the solar winds, so the definition of pressure becomes difficult to interpret. The thermosphere in this range has large gradients of pressure, temperature and composition, and varies greatly due to space weather. Astrophysicists prefer to use number density to describe these environments, in units of particles per cubic centimetre.\nBut although it meets the definition of outer space, the atmospheric density within the first few hundred kilometers above the K\u00e1rm\u00e1n line is still sufficient to produce significant drag on satellites. Most artificial satellites operate in this region, called low Earth orbit, and must fire their engines every couple of weeks or a few times a year (depending on solar activity). The drag here is low enough that it could theoretically be overcome by radiation pressure on solar sails, a proposed propulsion system for interplanetary travel. \nAll of the observable universe is filled with large numbers of photons, the so-called cosmic background radiation, and quite likely a correspondingly large number of neutrinos. The current temperature of this radiation is about .\nMeasurement.\nThe quality of a vacuum is indicated by the amount of matter remaining in the system, so that a high quality vacuum is one with very little matter left in it. Vacuum is primarily measured by its absolute pressure, but a complete characterization requires further parameters, such as temperature and chemical composition. One of the most important parameters is the mean free path (MFP) of residual gases, which indicates the average distance that molecules will travel between collisions with each other. As the gas density decreases, the MFP increases, and when the MFP is longer than the chamber, pump, spacecraft, or other objects present, the continuum assumptions of fluid mechanics do not apply. This vacuum state is called \"high vacuum\", and the study of fluid flows in this regime is called particle gas dynamics. The MFP of air at atmospheric pressure is very short, 70\u00a0nm, but at 100\u00a0mPa (\u2248) the MFP of room temperature air is roughly 100\u00a0mm, which is on the order of everyday objects such as vacuum tubes. The Crookes radiometer turns when the MFP is larger than the size of the vanes.\nVacuum quality is subdivided into ranges according to the technology required to achieve it or measure it. These ranges were defined in ISO 3529-1:2019 as shown in the following table (100\u00a0Pa corresponds to 0.75\u00a0Torr; Torr is a non-SI unit):\nRelative versus absolute measurement.\nVacuum is measured in units of pressure, typically as a subtraction relative to ambient atmospheric pressure on Earth. But the amount of relative measurable vacuum varies with local conditions. On the surface of Venus, where ground-level atmospheric pressure is much higher than on Earth, much higher relative vacuum readings would be possible. On the surface of the Moon with almost no atmosphere, it would be extremely difficult to create a measurable vacuum relative to the local environment.\nSimilarly, much higher than normal relative vacuum readings are possible deep in the Earth's ocean. A submarine maintaining an internal pressure of 1 atmosphere submerged to a depth of 10 atmospheres (98 metres; a 9.8-metre column of seawater has the equivalent weight of 1 atm) is effectively a vacuum chamber keeping out the crushing exterior water pressures, though the 1\u00a0atm inside the submarine would not normally be considered a vacuum.\nTherefore, to properly understand the following discussions of vacuum measurement, it is important that the reader assumes the relative measurements are being done on Earth at sea level, at exactly 1 atmosphere of ambient atmospheric pressure.\nMeasurements relative to 1\u00a0atm.\nThe SI unit of pressure is the pascal (symbol Pa), but vacuum is often measured in torrs, named for an Italian physicist Torricelli (1608\u20131647). A torr is equal to the displacement of a millimeter of mercury (mmHg) in a manometer with 1\u00a0torr equaling 133.3223684 pascals above absolute zero pressure. Vacuum is often also measured on the barometric scale or as a percentage of atmospheric pressure in bars or atmospheres. Low vacuum is often measured in millimeters of mercury (mmHg) or pascals (Pa) below standard atmospheric pressure. \"Below atmospheric\" means that the absolute pressure is equal to the current atmospheric pressure.\nIn other words, most low vacuum gauges that read, for example 50.79\u00a0Torr. Many inexpensive low vacuum gauges have a margin of error and may report a vacuum of 0\u00a0Torr but in practice this generally requires a two-stage rotary vane or other medium type of vacuum pump to go much beyond (lower than) 1\u00a0torr.\nMeasuring instruments.\nMany devices are used to measure the pressure in a vacuum, depending on what range of vacuum is needed.\nHydrostatic gauges (such as the mercury column manometer) consist of a vertical column of liquid in a tube whose ends are exposed to different pressures. The column will rise or fall until its weight is in equilibrium with the pressure differential between the two ends of the tube. The simplest design is a closed-end U-shaped tube, one side of which is connected to the region of interest. Any fluid can be used, but mercury is preferred for its high density and low vapour pressure. Simple hydrostatic gauges can measure pressures ranging from 1\u00a0torr (100\u00a0Pa) to above atmospheric. An important variation is the McLeod gauge which isolates a known volume of vacuum and compresses it to multiply the height variation of the liquid column. The McLeod gauge can measure vacuums as high as 10\u22126\u00a0torr (0.1\u00a0mPa), which is the lowest direct measurement of pressure that is possible with current technology. Other vacuum gauges can measure lower pressures, but only indirectly by measurement of other pressure-controlled properties. These indirect measurements must be calibrated via a direct measurement, most commonly a McLeod gauge.\nThe kenotometer is a particular type of hydrostatic gauge, typically used in power plants using steam turbines. The kenotometer measures the vacuum in the steam space of the condenser, that is, the exhaust of the last stage of the turbine.\nMechanical or elastic gauges depend on a Bourdon tube, diaphragm, or capsule, usually made of metal, which will change shape in response to the pressure of the region in question. A variation on this idea is the capacitance manometer, in which the diaphragm makes up a part of a capacitor. A change in pressure leads to the flexure of the diaphragm, which results in a change in capacitance. These gauges are effective from 103\u00a0torr to 10\u22124\u00a0torr, and beyond.\nThermal conductivity gauges rely on the fact that the ability of a gas to conduct heat decreases with pressure. In this type of gauge, a wire filament is heated by running current through it. A thermocouple or Resistance Temperature Detector (RTD) can then be used to measure the temperature of the filament. This temperature is dependent on the rate at which the filament loses heat to the surrounding gas, and therefore on the thermal conductivity. A common variant is the Pirani gauge which uses a single platinum filament as both the heated element and RTD. These gauges are accurate from 10\u00a0torr to 10\u22123\u00a0torr, but they are sensitive to the chemical composition of the gases being measured.\nIonization gauges are used in ultrahigh vacuum. They come in two types: hot cathode and cold cathode. In the hot cathode version an electrically heated filament produces an electron beam. The electrons travel through the gauge and ionize gas molecules around them. The resulting ions are collected at a negative electrode. The current depends on the number of ions, which depends on the pressure in the gauge. Hot cathode gauges are accurate from 10\u22123\u00a0torr to 10\u221210 torr. The principle behind cold cathode version is the same, except that electrons are produced in a discharge created by a high voltage electrical discharge. Cold cathode gauges are accurate from 10\u22122\u00a0torr to 10\u22129\u00a0torr. Ionization gauge calibration is very sensitive to construction geometry, chemical composition of gases being measured, corrosion and surface deposits. Their calibration can be invalidated by activation at atmospheric pressure or low vacuum. The composition of gases at high vacuums will usually be unpredictable, so a mass spectrometer must be used in conjunction with the ionization gauge for accurate measurement.\nUses.\nVacuum is useful in a variety of processes and devices. Its first widespread use was in the incandescent light bulb to protect the filament from chemical degradation. The chemical inertness produced by a vacuum is also useful for electron-beam welding, cold welding, vacuum packing and vacuum frying. Ultra-high vacuum is used in the study of atomically clean substrates, as only a very good vacuum preserves atomic-scale clean surfaces for a reasonably long time (on the order of minutes to days). High to ultra-high vacuum removes the obstruction of air, allowing particle beams to deposit or remove materials without contamination. This is the principle behind chemical vapor deposition, physical vapor deposition, and dry etching which are essential to the fabrication of semiconductors and optical coatings, and to surface science. The reduction of convection provides the thermal insulation of thermos bottles. Deep vacuum lowers the boiling point of liquids and promotes low temperature outgassing which is used in freeze drying, adhesive preparation, distillation, metallurgy, and process purging. The electrical properties of vacuum make electron microscopes and vacuum tubes possible, including cathode-ray tubes. Vacuum interrupters are used in electrical switchgear. Vacuum arc processes are industrially important for production of certain grades of steel or high purity materials. The elimination of air friction is useful for flywheel energy storage and ultracentrifuges.\nVacuum-driven machines.\nVacuums are commonly used to produce suction, which has an even wider variety of applications. The Newcomen steam engine used vacuum instead of pressure to drive a piston. In the 19th century, vacuum was used for traction on Isambard Kingdom Brunel's experimental atmospheric railway. Vacuum brakes were once widely used on trains in the UK but, except on heritage railways, they have been replaced by air brakes.\nManifold vacuum can be used to drive accessories on automobiles. The best known application is the vacuum servo, used to provide power assistance for the brakes. Obsolete applications include vacuum-driven windscreen wipers and Autovac fuel pumps. Some aircraft instruments (Attitude Indicator (AI) and the Heading Indicator (HI)) are typically vacuum-powered, as protection against loss of all (electrically powered) instruments, since early aircraft often did not have electrical systems, and since there are two readily available sources of vacuum on a moving aircraft, the engine and an external venturi.\nVacuum induction melting uses electromagnetic induction within a vacuum.\nMaintaining a vacuum in the condenser is an important aspect of the efficient operation of steam turbines. A steam jet ejector or liquid ring vacuum pump is used for this purpose. The typical vacuum maintained in the condenser steam space at the exhaust of the turbine (also called condenser backpressure) is in the range 5 to 15 kPa (absolute), depending on the type of condenser and the ambient conditions.\nOutgassing.\nEvaporation and sublimation into a vacuum is called outgassing. All materials, solid or liquid, have a small vapour pressure, and their outgassing becomes important when the vacuum pressure falls below this vapour pressure. Outgassing has the same effect as a leak and will limit the achievable vacuum. Outgassing products may condense on nearby colder surfaces, which can be troublesome if they obscure optical instruments or react with other materials. This is of great concern to space missions, where an obscured telescope or solar cell can ruin an expensive mission.\nThe most prevalent outgassing product in vacuum systems is water absorbed by chamber materials. It can be reduced by desiccating or baking the chamber, and removing absorbent materials. Outgassed water can condense in the oil of rotary vane pumps and reduce their net speed drastically if gas ballasting is not used. High vacuum systems must be clean and free of organic matter to minimize outgassing.\nUltra-high vacuum systems are usually baked, preferably under vacuum, to temporarily raise the vapour pressure of all outgassing materials and boil them off. Once the bulk of the outgassing materials are boiled off and evacuated, the system may be cooled to lower vapour pressures and minimize residual outgassing during actual operation. Some systems are cooled well below room temperature by liquid nitrogen to shut down residual outgassing and simultaneously cryopump the system.\nPumping and ambient air pressure.\nFluids cannot generally be pulled, so a vacuum cannot be created by suction. Suction can spread and dilute a vacuum by letting a higher pressure push fluids into it, but the vacuum has to be created first before suction can occur. The easiest way to create an artificial vacuum is to expand the volume of a container. For example, the diaphragm muscle expands the chest cavity, which causes the volume of the lungs to increase. This expansion reduces the pressure and creates a partial vacuum, which is soon filled by air pushed in by atmospheric pressure.\nTo continue evacuating a chamber indefinitely without requiring infinite growth, a compartment of the vacuum can be repeatedly closed off, exhausted, and expanded again. This is the principle behind positive displacement pumps, like the manual water pump for example. Inside the pump, a mechanism expands a small sealed cavity to create a vacuum. Because of the pressure differential, some fluid from the chamber (or the well, in our example) is pushed into the pump's small cavity. The pump's cavity is then sealed from the chamber, opened to the atmosphere, and squeezed back to a minute size.\nThe above explanation is merely a simple introduction to vacuum pumping, and is not representative of the entire range of pumps in use. Many variations of the positive displacement pump have been developed, and many other pump designs rely on fundamentally different principles. Momentum transfer pumps, which bear some similarities to dynamic pumps used at higher pressures, can achieve much higher quality vacuums than positive displacement pumps. Entrapment pumps can capture gases in a solid or absorbed state, often with no moving parts, no seals and no vibration. None of these pumps are universal; each type has important performance limitations. They all share a difficulty in pumping low molecular weight gases, especially hydrogen, helium, and neon.\nThe lowest pressure that can be attained in a system is also dependent on many things other than the nature of the pumps. Multiple pumps may be connected in series, called stages, to achieve higher vacuums. The choice of seals, chamber geometry, materials, and pump-down procedures will all have an impact. Collectively, these are called \"vacuum technique\". And sometimes, the final pressure is not the only relevant characteristic. Pumping systems differ in oil contamination, vibration, preferential pumping of certain gases, pump-down speeds, intermittent duty cycle, reliability, or tolerance to high leakage rates.\nIn ultra high vacuum systems, some very \"odd\" leakage paths and outgassing sources must be considered. The water absorption of aluminium and palladium becomes an unacceptable source of outgassing, and even the adsorptivity of hard metals such as stainless steel or titanium must be considered. Some oils and greases will boil off in extreme vacuums. The permeability of the metallic chamber walls may have to be considered, and the grain direction of the metallic flanges should be parallel to the flange face.\nThe lowest pressures currently achievable in laboratory are about . However, pressures as low as have been indirectly measured in a cryogenic vacuum system. This corresponds to \u2248100 particles/cm3.\nEffects on humans and animals.\nHumans and animals exposed to vacuum will lose consciousness after a few seconds and die of hypoxia within minutes, but the symptoms are not nearly as graphic as commonly depicted in media and popular culture. The reduction in pressure lowers the temperature at which blood and other body fluids boil, but the elastic pressure of blood vessels ensures that this boiling point remains above the internal body temperature of 37 \u00b0C. Although the blood will not boil, the formation of gas bubbles in bodily fluids at reduced pressures, known as ebullism, is still a concern. The gas may bloat the body to twice its normal size and slow circulation, but tissues are elastic and porous enough to prevent rupture. Swelling and ebullism can be restrained by containment in a flight suit. Shuttle astronauts wore a fitted elastic garment called the Crew Altitude Protection Suit (CAPS) which prevents ebullism at pressures as low as 2\u00a0kPa (15\u00a0Torr). Rapid boiling will cool the skin and create frost, particularly in the mouth, but this is not a significant hazard.\nAnimal experiments show that rapid and complete recovery is normal for exposures shorter than 90 seconds, while longer full-body exposures are fatal and resuscitation has never been successful. A study by NASA on eight chimpanzees found all of them survived two and a half minute exposures to vacuum. There is only a limited amount of data available from human accidents, but it is consistent with animal data. Limbs may be exposed for much longer if breathing is not impaired. Robert Boyle was the first to show in 1660 that vacuum is lethal to small animals.\nAn experiment indicates that plants are able to survive in a low pressure environment (1.5\u00a0kPa) for about 30 minutes.\nCold or oxygen-rich atmospheres can sustain life at pressures much lower than atmospheric, as long as the density of oxygen is similar to that of standard sea-level atmosphere. The colder air temperatures found at altitudes of up to 3\u00a0km generally compensate for the lower pressures there. Above this altitude, oxygen enrichment is necessary to prevent altitude sickness in humans that did not undergo prior acclimatization, and spacesuits are necessary to prevent ebullism above 19\u00a0km. Most spacesuits use only 20\u00a0kPa (150\u00a0Torr) of pure oxygen. This pressure is high enough to prevent ebullism, but decompression sickness and gas embolisms can still occur if decompression rates are not managed.\nRapid decompression can be much more dangerous than vacuum exposure itself. Even if the victim does not hold his or her breath, venting through the windpipe may be too slow to prevent the fatal rupture of the delicate alveoli of the lungs. Eardrums and sinuses may be ruptured by rapid decompression, soft tissues may bruise and seep blood, and the stress of shock will accelerate oxygen consumption leading to hypoxia. Injuries caused by rapid decompression are called barotrauma. A pressure drop of 13\u00a0kPa (100\u00a0Torr), which produces no symptoms if it is gradual, may be fatal if it occurs suddenly.\nSome extremophile microorganisms, such as tardigrades, can survive vacuum conditions for periods of days or weeks.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32503", "revid": "17859592", "url": "https://en.wikipedia.org/wiki?curid=32503", "title": "Villa Savoye", "text": "1931 building by Le Corbusier in Poissy, France\nVilla Savoye () is a modernist villa and gatelodge in Poissy, on the outskirts of Paris, France. It was designed by the Swiss-French architect Le Corbusier and his cousin Pierre Jeanneret, and built between 1928 and 1931 using reinforced concrete.\nAs an exemplar of Le Corbusier's \"five points\" for new constructions, the villa is representative of the origins of modern architecture and is one of the most easily recognizable and renowned examples of the International style.\nThe house was originally built as a country retreat for the Savoye family. After being purchased by the neighbouring school, it became the property of the French state in 1958. Due to many different problems it was rarely inhabited. After surviving several proposals to demolish it, it was designated as an official French historical monument in 1965 (a rare event, as Le Corbusier was still alive). It was thoroughly renovated between 1985 and 1997, and the refurbished house is now open to visitors year round under the care of the Centre des monuments nationaux.\nIn July 2016, the house and 16 other buildings by Le Corbusier, spread over seven countries, were inscribed as The Architectural Work of Le Corbusier World Heritage Site by UNESCO.\nBackground.\nBy the end of the 1920s Le Corbusier was already an internationally renowned architect. His book \"Vers une Architecture\" had been translated into several languages, his work with the Centrosoyuz in Moscow had involved him with the Russian avant-garde, and his problems with the League of Nations competition had been widely publicised. He was also one of the first members of the Congr\u00e8s International d'Architecture Moderne (CIAM) and was becoming known as a champion of modern architecture.\nThe villas designed by Le Corbusier in the early 1920s demonstrated what he termed the \"precision\" of architecture, where each feature of the design needed to be justified in design and urban terms. His work in the later part of the decade, including his urban designs for Algiers, began to be more free-form.\nPierre and Eug\u00e9nie Savoye approached Le Corbusier about building a country home in Poissy in the spring of 1928. The prospective site was a green field on an otherwise wooded plot of land, with views of the landscape to the north west that matched the approach to the plot along the road. Other than an initial brief prepared by Emile for a summer house, space for cars, an extra bedroom and a caretaker's lodge, Le Corbusier had such freedom in executing the commission that he was limited only by his own architectural aesthetic. He began work on the project in September 1928. His initial ideas were ultimately manifested in the final building, though between Autumn 1928 and Spring 1929 he drew up a set of alternative designs that were governed primarily by the Savoye couple's concerns regarding cost. The eventual solution to the cost problem was to reduce the volume of the building by moving the master bedroom down to the first floor and reducing the grid spacing from 5 metres to 4.75 metres.\nConstruction.\nEstimates of the cost in February 1929 lay in the region of half a million francs, although this excluded the cost of the lodge and the landscaping elements (almost twice the original budget). The project was tendered in February, with contracts being awarded in March 1929. Changes made to the design while the project was being built, which included an amendment to the storey height and the removal and reinstatement of the chauffeur's accommodation, led to the costs rising to approximately 900,000 francs. When the construction of the project started, no design work had been done on the lodge, and the final design was only presented to the client in June 1929. The design was for a double lodge, but this was reduced to a single lodge for cost reasons. Although the construction of the entire house was completed within a year, it was not habitable until 1931.\nDesign.\nThe Villa Savoye, which is probably Le Corbusier's best known building from the 1930s, had an enormous influence on international modernism. Its design embodied his emblematic \"Five Points\", the basic tenets in his new architectural aesthetic: \nUnlike with his earlier town villas, Le Corbusier was able to carefully design all four sides of the Villa Savoye so that they took the view and the orientation of the sun into account. On the ground floor he placed the main entrance hall, ramp and stairs, garage, and the rooms of the chauffeur and maid. The first floor contained the master bedroom, the son's bedroom, guest bedroom, kitchen, salon and external terraces. The salon was oriented to the south east whilst the terrace faced the east. The son's bedroom faced the north west, and the kitchen and service terrace faced south-west. On the second-floor level was a series of sculpted spaces that formed a solarium.\nThe plan was set out using the principal ratios of the Golden section: in this case a square divided into sixteen equal parts, extended on two sides to incorporate the projecting fa\u00e7ades, and then further divided so as to fix the position of the ramp and the entrance.\nIn his book \"Vers une Architecture\", Corbusier exclaimed \"The motor car is an object with a simple function (to travel) and complicated aims (comfort, resistance, appearance)...\". The house, designed as a second residence and located outside Paris, was designed with the car in mind. The sense of mobility that the car conferred was translated into a feeling of movement that is integral to the building. The approach to the house was by car, past the caretaker's lodge, and eventually under the building itself. Even the curved arc of the industrial glazing of the ground floor entrance was determined by the turning circle of a car. After its principal occupants had been dropped off by the chauffeur, the car proceeded around the curve to park in the garage. Meanwhile, the arrivals entered the house transversely into the main hall through a portico of flanking columns.\nThe four columns in the entrance hall seemingly direct the visitor up the ramp. This ramp, which can be seen from almost everywhere in the house, continues up to the first-floor living area and salon before continuing externally from the first-floor roof terrace up to the second-floor solarium. Throughout his career, Le Corbusier was interested in bringing a feeling of sacredness into the act of dwelling, and acts such as washing and eating were given significance by their locations. At the Villa Savoye, the act of cleansing is represented both by the sink in the entrance hall and the celebration of the health-giving properties of the sun in the solarium on the roof, which is given significance by being the terminal upper point of the ramp.\nLe Corbusier's piloti perform a number of functions around the house, both inside and out. On the two longer elevations they are flush with the face of the fa\u00e7ade and imply heaviness and support, but on the shorter sides they are set back, giving a floating effect that emphasises the horizontal dimension of the house. The wide strip window of the first-floor terrace has two baby piloti to support and stiffen the wall above. Although these piloti are in a similar plane to the larger columns below, a false perspective when viewed from outside the house gives the impression that they are located deeper within the house than they actually are.\nThe Villa Savoye uses the horizontal ribbon windows found in his earlier villas. Unlike his contemporaries, Le Corbusier often chose to use timber windows rather than metal ones. It has been suggested that this is because he was interested in glass for its planar properties, and that the set-back position of the glass in the timber frame allowed the fa\u00e7ade to be seen as a series of parallel planes.\nLater history.\nProblems with the Savoyes caused by all the requests for additional payment from the contractors for all the changes were compounded by the need for early repairs to the new house. Each autumn, the Savoyes suffered rainwater leaks through the roof. The exclusion of downpipes and sills which would have disturbed their aesthetic made the white surfaces more susceptible to staining and erosion from overflowing rainwater. The building was also marred by cracks because the material was not designed for structural durability. The Savoyes continued to live in the house until 1940, leaving during World War II. It was occupied twice during the war: first by the Germans \u2013 when it was used as a hay store \u2013 and then by the Americans, with both occupations severely damaging the building. The Savoyes returned to their estate after the war, but were no longer in a position to live as they had before the war, and soon abandoned the house again.\nThe villa was expropriated by the town of Poissy in 1958, which first used it as a public youth centre and later considered demolishing it to make way for a schoolhouse complex. Protests from architects who felt the house should be saved, and the intervention of Le Corbusier himself, spared the house from demolition. A first attempt at restoration was begun in 1963 by architect Jean Debuisson, despite opposition from Le Corbusier. The villa was added to the French register of historical monuments in 1965, becoming France's first modernist building to be designated as a historical monument, and also the first to be the object of restoration while its architect was still living. In 1985, a thorough state-funded restoration process led by architect Jean-Louis V\u00e9ret was undertaken. It was completed in 1997. The restoration included structural and surface repairs to the fa\u00e7ades and terraces because of the deterioration of the concrete; the installation of lighting and security cameras; and the reinstatement of some of the original fixtures and fittings.\nLegacy.\nThe Villa Savoye was a very influential building of the 1930s, and imitations can be found all over the world. The building featured in two hugely influential books of the time: Hitchcock and Johnson's \"The International Style\" published in 1932, and F. R. S. Yorke's \"The Modern House\" published in 1934, as well as the second volume of Le Corbusier's own series \"The Complete Works\". In his 1947 essay \"The Mathematics of the Ideal Villa\", Colin Rowe compared the Villa Savoye to Palladio's Villa Rotunda. Alice T. Friedman said in 1998 that the Villa Savoye was one of a few 20th-century residences, along with the Farnsworth House and Fallingwater, which consistently captivated visitors despite being widely covered in the media. \nThe freedom given to Le Corbusier by the Savoyes resulted in a house that was governed more by his five principles than by any requirements of the occupants. Nevertheless, it was the last time these five principles were expressed so fully, and the house marked the end of one phase of his design approach, as well as being the last in a series of buildings dominated by the colour white.\nSome general criticisms have been made with regard to Le Corbusier's five points of architecture, and these apply specifically to the Villa Savoye in terms of:\nAfter the Villa Savoye, Le Corbusier's experimentation with Surrealism informed his design for the Beistegui apartments, but his next villa design, for Mademoiselle Mandrot near Toulon, embodied a regionalist agenda and relied on local stone for its finish.\nThe west wing of the Australian Institute of Aboriginal and Torres Strait Islander Studies in Canberra, designed by Ashton Raggatt McDougall, is a nearly exact replica of the Villa Savoye, except that it is black. According to Howard Raggat, this antipodean architectural quotation is \"a kind of inversion, a reflection, but also a kind of shadow\".\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32504", "revid": "167282", "url": "https://en.wikipedia.org/wiki?curid=32504", "title": "Vancouver (disambiguation)", "text": "Vancouver is the most populous city in British Columbia, Canada.\nVancouver may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "32505", "revid": "45266726", "url": "https://en.wikipedia.org/wiki?curid=32505", "title": "Vapor", "text": "Substances in the gas phase at a temperature lower than its critical point\nIn physics, a vapor (American English) or vapour (Commonwealth English; see spelling differences) is a substance in the gas phase at a temperature lower than its critical temperature, which means that the vapor can be condensed to a liquid by increasing the pressure on it without reducing the temperature of the vapor. A vapor is different from an aerosol. An aerosol is a suspension of tiny particles of liquid, solid, or both within a gas.\nFor example, water has a critical temperature of , which is the highest temperature at which liquid water can exist at any pressure. In the atmosphere at ordinary temperatures gaseous water (known as water vapor) will condense into a liquid if its partial pressure is increased sufficiently.\nA vapor may co-exist with a liquid (or a solid). When this is true, the two phases will be in equilibrium, and the gas-partial pressure will be equal to the equilibrium vapor pressure of the liquid (or solid).\nProperties.\n\"Vapor\" refers to a gas phase at a temperature where the same substance can also exist in the liquid or solid state, below the critical temperature of the substance. (For example, water has a critical temperature of 374\u00a0\u00b0C (647 K), which is the highest temperature at which liquid water can exist.) If the vapor is in contact with a liquid or solid phase, the two phases will be in a state of equilibrium. The term \"gas\" refers to a compressible fluid phase. Fixed gases are gases for which no liquid or solid can form at the temperature of the gas, such as air at typical ambient temperatures. A liquid or solid does not have to boil to release a vapor.\nVapor is responsible for the familiar processes of cloud formation and condensation. It is commonly employed to carry out the physical processes of distillation and headspace extraction from a liquid sample prior to gas chromatography.\nThe constituent molecules of a vapor possess vibrational, rotational, and translational motion. These motions are considered in the kinetic theory of gases.\nVapor pressure.\nThe vapor pressure is the equilibrium pressure from a liquid or a solid at a specific temperature. The equilibrium vapor pressure of a liquid or solid is not affected by the amount of contact with the liquid or solid interface.\nThe normal boiling point of a liquid is the temperature at which the vapor pressure is equal to normal atmospheric pressure.\nFor two-phase systems (e.g., two liquid phases), the vapor pressure of the individual phases are equal. In the absence of stronger inter-species attractions between like-like or like-unlike molecules, the vapor pressure follows Raoult's law, which states that the partial pressure of each component is the product of the vapor pressure of the pure component and its mole fraction in the mixture. The total vapor pressure is the sum of the component partial pressures.\nExamples.\nE-cigarettes produce aerosols, not vapors.\nMeasuring vapor.\nSince it is in the gas phase, the amount of vapor present is quantified by the partial pressure of the gas. Also, vapors obey the barometric formula in a gravitational field, just as conventional atmospheric gases do.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32506", "revid": "6675779", "url": "https://en.wikipedia.org/wiki?curid=32506", "title": "Venus (disambiguation)", "text": "Venus is the second planet from the Sun.\nVenus or VENUS may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "32507", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=32507", "title": "Vitamins", "text": ""}
{"id": "32509", "revid": "32720263", "url": "https://en.wikipedia.org/wiki?curid=32509", "title": "Vitamin C", "text": "Essential nutrient found in citrus fruits and other foods\n&lt;templatestyles src=\"Infobox drug/styles.css\"/&gt;\nVitamin C (also known as ascorbic acid and ascorbate) is a water-soluble vitamin found in citrus and other fruits, berries and vegetables. It is also a generic prescription medication and in some countries is sold as a non-prescription dietary supplement. As a therapy, it is used to prevent and treat scurvy, a disease caused by vitamin C deficiency.\nVitamin C is an essential nutrient involved in the repair of tissue, the formation of collagen, and the enzymatic production of certain neurotransmitters. It is required for the functioning of several enzymes and is important for immune system function. It also functions as an antioxidant. Vitamin C may be taken by mouth or by intramuscular, subcutaneous or intravenous injection. Various health claims exist on the supposition that moderate vitamin C deficiency increases disease risk, such as for the common cold, cancer or COVID-19.xi There are also claims of benefits from vitamin C supplementation in excess of the recommended dietary intake for people who are not considered vitamin C deficient. Vitamin C is generally well tolerated. Large doses may cause gastrointestinal discomfort, headache, trouble sleeping, and flushing of the skin. The United States National Academy of Medicine recommends against consuming large amounts.\nMost animals are able to synthesize their own vitamin C. However, higher primates (including humans), most bats, guinea pigs, some fish species, and some bird species must acquire it from dietary sources because a gene for a synthesis enzyme has mutations that render it dysfunctional.\nVitamin C was discovered in 1912, isolated in 1928, and in 1933, was the first vitamin to be chemically produced. Partly for its discovery, Albert Szent-Gy\u00f6rgyi was awarded the 1937 Nobel Prize in Physiology or Medicine.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nChemistry.\nThe name \"vitamin C\" always refers to the l-enantiomer of ascorbic acid and its oxidized form, dehydroascorbate (DHA). Therefore, unless written otherwise, \"ascorbate\" and \"ascorbic acid\" refer in the nutritional literature to l-ascorbate and l-ascorbic acid respectively. Ascorbic acid is a weak sugar acid structurally related to glucose. In biological systems, ascorbic acid can be found only at low pH, but in solutions above pH 5 it is predominantly found in the ionized form, ascorbate.\nMany analytical methods have been developed for ascorbic acid detection. For example, vitamin C content of a food sample such as fruit juice can be calculated by measuring the volume of the sample required to decolorize a solution of dichlorophenolindophenol (DCPIP) and then calibrating the results by comparison with a known concentration of vitamin C.\nDeficiency.\nPlasma vitamin C is the most widely applied test for vitamin C status. Adequate levels are defined as near 50 \u03bcmol/L. Hypovitaminosis of vitamin C is defined as less than 23 \u03bcmol/L, and deficiency as less than 11.4 \u03bcmol/L. For people 20 years of age or above, data from the US 2017\u201318 National Health and Nutrition Examination Survey showed mean serum concentrations of 53.4 \u03bcmol/L. The percent of people reported as deficient was 5.9%. Globally, vitamin C deficiency is common in low and middle-income countries, and not uncommon in high income countries. In the latter, prevalence is higher in males than in females.\nPlasma levels are considered saturated at about 65 \u03bcmol/L, achieved by intakes of 100 to 200\u00a0mg/day, which are well above the recommended intakes. Even higher oral intake does not further raise plasma nor tissue concentrations because absorption efficiency decreases and any excess that is absorbed is excreted in urine.\nDiagnostic testing.\nVitamin C content in plasma is used to determine vitamin status. For research purposes, concentrations can be assessed in leukocytes and tissues, which are normally maintained at an order of magnitude higher than in plasma via an energy-dependent transport system, depleted slower than plasma concentrations during dietary deficiency and restored faster during dietary repletion, but these analysis are difficult to measure, and hence not part of standard diagnostic testing.\nDiet.\nRecommended consumption.\nRecommendations for vitamin C intake by adults have been set by various national agencies:\nIn 2000, the chapter on Vitamin C in the North American Dietary Reference Intake was updated to give the Recommended Dietary Allowance (RDA) as 90 milligrams per day for adult men, 75\u00a0mg/day for adult women, and setting a tolerable upper intake level (UL) for adults of 2,000\u00a0mg/day. The table here shows RDAs for the United States and Canada for children, and for pregnant and lactating women, as well as the ULs for adults.\nFor the European Union, the EFSA set higher recommendations for adults, and also for children: 20\u00a0mg/day for ages 1\u20133, 30\u00a0mg/day for ages 4\u20136, 45\u00a0mg/day for ages 7\u201310, 70\u00a0mg/day for ages 11\u201314, 100\u00a0mg/day for males ages 15\u201317, 90\u00a0mg/day for females ages 15\u201317. For pregnancy 100\u00a0mg/day; for lactation 155\u00a0mg/day.\nCigarette smokers and people exposed to secondhand smoke have lower serum vitamin C levels than nonsmokers. The reasoning is that inhalation of smoke causes oxidative damage, depleting this antioxidant vitamin. The US Institute of Medicine estimated that smokers need 35\u00a0mg more vitamin C per day than nonsmokers, but did not formally establish a higher RDA for smokers.\nThe US National Center for Health Statistics conducts biannual National Health and Nutrition Examination Survey (NHANES) to assess the health and nutritional status of adults and children in the United States. Some results are reported as What We Eat In America. The 2013\u20132014 survey reported that for adults ages 20 years and older, men consumed on average 83.3\u00a0mg/d and women 75.1\u00a0mg/d. This means that half the women and more than half the men are not consuming the RDA for vitamin C. The same survey stated that about 30% of adults reported they consumed a vitamin C dietary supplement or a multi-vitamin/mineral supplement that included vitamin C, and that for these people total consumption was between 300 and 400\u00a0mg/d.\nTolerable upper intake level.\nIn 2000, the Institute of Medicine of the US National Academy of Sciences set a tolerable upper intake level (UL) for adults of 2,000\u00a0mg/day. The amount was chosen because human trials had reported diarrhea and other gastrointestinal disturbances at intakes of greater than 3,000\u00a0mg/day. This was the Lowest-Observed-Adverse-Effect Level (LOAEL), meaning that other adverse effects were observed at even higher intakes. ULs are progressively lower for younger and younger children. In 2006, the European Food Safety Authority (EFSA) also pointed out the disturbances at that dose level, but reached the conclusion that there was not sufficient evidence to set a UL for vitamin C, as did the Japan National Institute of Health and Nutrition in 2010.\nFood labeling.\nFor US food and dietary supplement labeling purposes, the amount in a serving is expressed as a percent of Daily Value (%DV). For vitamin C labeling purposes, 100% of the Daily Value was 60\u00a0mg, but as of May 27, 2016, it was revised to 90\u00a0mg to bring it into agreement with the RDA. A table of the old and new adult daily values is provided at Reference Daily Intake.\nEuropean Union regulations require that labels declare energy, protein, fat, saturated fat, carbohydrates, sugars, and salt. Voluntary nutrients may be shown if present in significant amounts. Instead of Daily Values, amounts are shown as percent of Reference Intakes (RIs). For vitamin C, 100% RI was set at 80\u00a0mg in 2011.\nSources.\nAlthough also present in other plant-derived foods, the richest natural sources of vitamin C are fruits and vegetables. Vitamin C is the most widely taken dietary supplement.\nPlant sources.\nThe following table is approximate and shows the relative abundance in different raw plant sources. The amount is given in milligrams per 100\u00a0grams of the edible portion of the fruit or vegetable:\nAnimal sources.\nAnimal-sourced foods do not generally provide much vitamin C, and what there is, is largely destroyed by heat during cooking. For example, raw chicken liver contains 17.9\u00a0mg/100\u00a0g, but fried, the content is reduced to 2.7\u00a0mg/100\u00a0g. Vitamin C is present in human breast milk at 5.0\u00a0mg/100\u00a0g. Cow's milk contains 1.0\u00a0mg/100\u00a0g, but the heat of pasteurization destroys it.\nFood preparation.\nVitamin C chemically decomposes under certain conditions, many of which may occur during the cooking of food. Vitamin C concentrations in various food substances decrease with time in proportion to the temperature at which they are stored. Cooking can reduce the vitamin C content of vegetables by around 60%, possibly due to increased enzymatic destruction. Longer cooking times may add to this effect. Another cause of vitaminC loss from food is leaching, which transfers vitaminC to the cooking water, which is decanted and not consumed.\nSupplements.\nVitamin C dietary supplements are available as tablets, capsules, drink mix packets, in multi-vitamin/mineral formulations, in antioxidant formulations, and as crystalline powder. Vitamin C is also added to some fruit juices and juice drinks. Tablet and capsule content ranges from 25\u00a0mg to 1500\u00a0mg per serving. The most commonly used supplement compounds are ascorbic acid, sodium ascorbate and calcium ascorbate. Vitamin C molecules can also be bound to the fatty acid palmitate, creating ascorbyl palmitate, or else incorporated into liposomes.\nFood fortification.\nCountries fortify foods with nutrients to address known deficiencies. While many countries mandate or have voluntary programs to fortify wheat flour, maize (corn) flour or rice with vitamins, none include vitamin C in those programs. As described in \"Vitamin C Fortification of Food Aid Commodities\" (1997), the United States provides rations to international food relief programs, later under the auspices of the Food for Peace Act and the Bureau for Humanitarian Assistance. Vitamin C is added to corn-soy blend and wheat-soy blend products at 40\u00a0mg/100 grams. (along with minerals and other vitamins). Supplemental rations of these highly fortified, blended foods are provided to refugees and displaced persons in camps and to beneficiaries of development feeding programs that are targeted largely toward mothers and children. The report adds: \"The stability of vitamin C (L-ascorbic acid) is of concern because this is one of the most labile vitamins in foods. Its main loss during processing and storage is from oxidation, which is accelerated by light, oxygen, heat, increased pH, high moisture content (water activity), and the presence of copper or ferrous salts. To reduce oxidation, the vitamin C used in commodity fortification is coated with ethyl cellulose (2.5 percent). Oxidative losses also occur during food processing and preparation, and additional vitamin C may be lost if it dissolves into cooking liquid and is then discarded.\"\nFood preservation additive.\nAscorbic acid and some of its salts and esters are common additives added to foods such as canned fruits, mostly to slow oxidation and enzymatic browning. It may be used as a flour treatment agent used in breadmaking. As food additives, they are assigned E numbers, with safety assessment and approval the responsibility of the European Food Safety Authority. The relevant E numbers are:\nThe stereoisomers of Vitamin C have a similar effect in food despite their lack of efficacy in human scurvy. They include erythorbic acid and its sodium salt (E315, E316).\nPharmacology.\nPharmacodynamics.\nPharmacodynamics includes enzymes for which vitamin C is a cofactor, with function potentially compromised in a deficiency state, and any enzyme cofactor or other physiological function affected by administration of vitamin C, orally or injected, in excess of normal requirements. At normal physiological concentrations, vitamin C serves as an enzyme substrate or cofactor and an electron donor antioxidant. The enzymatic functions include the synthesis of collagen, carnitine, and neurotransmitters; the synthesis and catabolism of tyrosine; and the metabolism of microsomes. In nonenzymatic functions it acts as a reducing agent, donating electrons to oxidized molecules and preventing oxidation in order to keep iron and copper atoms in their reduced states. At non-physiological concentrations achieved by intravenous dosing, vitamin C may function as a pro-oxidant, with therapeutic toxicity against cancer cells.\nVitamin C functions as a cofactor for the following enzymes:\nAs an antioxidant, ascorbate scavenges reactive oxygen and nitrogen compounds, thus neutralizing the potential tissue damage of these free radical compounds. Dehydroascorbate, the oxidized form, is then recycled back to ascorbate by endogenous antioxidants such as glutathione. In the eye, ascorbate is thought to protect against photolytically generated free-radical damage; higher plasma ascorbate is associated with lower risk of cataracts. Ascorbate may also provide antioxidant protection indirectly by regenerating other biological antioxidants such as \u03b1-tocopherol back to an active state. In addition, ascorbate also functions as a non-enzymatic reducing agent for mixed-function oxidases in the microsomal drug-metabolizing system that inactivates a wide variety of substrates such as drugs and environmental carcinogens.\nPharmacokinetics.\nAscorbic acid is absorbed in the body by both active transport and passive diffusion. Approximately 70%\u201390% of vitamin C is active-transport absorbed when intakes of 30\u2013180\u00a0mg/day from a combination of food sources and moderate-dose dietary supplements such as a multi-vitamin/mineral product are consumed. However, when large amounts are consumed, such as a vitamin C dietary supplement, the active transport system becomes saturated, and while the total amount being absorbed continues to increase with dose, absorption efficiency falls to less than 50%. Active transport is managed by Sodium-Ascorbate Co-Transporter proteins (SVCTs) and Hexose Transporter proteins (GLUTs). SVCT1 and SVCT2 import ascorbate across plasma membranes. The Hexose Transporter proteins GLUT1, GLUT3 and GLUT4 transfer only the oxydized dehydroascorbic acid (DHA) form of vitamin C. The amount of DHA found in plasma and tissues under normal conditions is low, as cells rapidly reduce DHA to ascorbate.\nSVCTs are the predominant system for vitamin C transport within the body. In both vitamin C synthesizers (example: rat) and non-synthesizers (example: human) cells maintain ascorbic acid concentrations much higher than the approximately 50 micromoles/liter (\u03bcmol/L) found in plasma. For example, the ascorbic acid content of pituitary and adrenal glands can exceed 2,000\u00a0\u03bcmol/L, and muscle is at 200\u2013300\u00a0\u03bcmol/L. The known coenzymatic functions of ascorbic acid do not require such high concentrations, so there may be other, as yet unknown functions. A consequence of all this high concentration organ content is that plasma vitamin C is not a good indicator of whole-body status, and people may vary in the amount of time needed to show symptoms of deficiency when consuming a diet very low in vitamin C.\nExcretion (via urine) is as ascorbic acid and metabolites. The fraction that is excreted as unmetabolized ascorbic acid increases as intake increases. In addition, ascorbic acid converts (reversibly) to DHA and from that compound non-reversibly to 2,3-diketogulonate and then oxalate. These three metabolites are also excreted via urine. During times of low dietary intake, vitamin C is reabsorbed by the kidneys rather than excreted. This salvage process delays onset of deficiency. Humans are better than guinea pigs at converting DHA back to ascorbate, and thus take much longer to become vitamin C deficient.\nSynthesis.\nMost animals and plants are able to synthesize vitamin C through a sequence of enzyme-driven steps, which convert monosaccharides to vitamin C. Yeasts do not make l-ascorbic acid but rather its stereoisomer, erythorbic acid. In plants, synthesis is accomplished through the conversion of mannose or galactose to ascorbic acid. In animals, the starting material is glucose. In some species that synthesize ascorbate in the liver (including mammals and perching birds), the glucose is extracted from glycogen; ascorbate synthesis is a glycogenolysis-dependent process. In humans and in animals that cannot synthesize vitamin C, the enzyme l-gulonolactone oxidase (GULO), which catalyzes the last step in the biosynthesis, is highly mutated and non-functional.\nAnimal synthesis.\nThere is some information on serum vitamin C concentrations maintained in animal species that are able to synthesize vitamin C. One study of several breeds of dogs reported an average of 35.9\u00a0\u03bcmol/L. A report on goats, sheep and cattle reported ranges of 100\u2013110, 265\u2013270 and 160\u2013350\u00a0\u03bcmol/L, respectively.\nThe biosynthesis of ascorbic acid in vertebrates starts with the formation of UDP-glucuronic acid. UDP-glucuronic acid is formed when UDP-glucose undergoes two oxidations catalyzed by the enzyme UDP-glucose 6-dehydrogenase. UDP-glucose 6-dehydrogenase uses the co-factor NAD+ as the electron acceptor. The transferase UDP-glucuronate pyrophosphorylase removes a UMP and glucuronokinase, with the cofactor ADP, removes the final phosphate leading to d-glucuronic acid. The aldehyde group of this compound is reduced to a primary alcohol using the enzyme glucuronate reductase and the cofactor NADPH, yielding l-gulonic acid. This is followed by lactone formation\u2014utilizing the hydrolase gluconolactonase\u2014between the carbonyl on C1 and hydroxyl group on C4. l-Gulonolactone then reacts with oxygen, catalyzed by the enzyme L-gulonolactone oxidase (which is nonfunctional in humans and other Haplorrhini primates; see Unitary pseudogenes) and the cofactor FAD+. This reaction produces 2-oxogulonolactone (2-keto-gulonolactone), which spontaneously undergoes enolization to form ascorbic acid. Reptiles and older orders of birds make ascorbic acid in their kidneys. Recent orders of birds and most mammals make ascorbic acid in their liver.\nNon-synthesizers.\nSome mammals have lost the ability to synthesize vitamin C, including simians and tarsiers, which together make up one of two major primate suborders, Haplorhini. This group includes humans. The other more primitive primates (Strepsirrhini) have the ability to make vitamin C. Synthesis does not occur in some species in the rodent family Caviidae, which includes guinea pigs and capybaras, but does occur in other rodents, including rats and mice.\nSynthesis does not occur in most bat species, but there are at least two species, frugivorous bat \"Rousettus leschenaultii\" and insectivorous bat \"Hipposideros armiger\", that retain (or regained) their ability of vitamin C production. A number of species of passerine birds also do not synthesize, but not all of them, and those that do not are not clearly related; it has been proposed that the ability was lost separately a number of times in birds. In particular, the ability to synthesize vitamin C is presumed to have been lost and then later re-acquired in at least two cases. The ability to synthesize vitaminC has also been lost in about 96% of extant fish (the teleosts).\nOn a milligram consumed per kilogram of body weight basis, simian non-synthesizer species consume the vitamin in amounts 10 to 20 times higher than what is recommended by governments for humans. This discrepancy constituted some of the basis of the controversy on human recommended dietary allowances being set too low. However, simian consumption does not indicate simian requirements. Merck's veterinary manual states that daily intake of vitamin C at 3\u20136\u00a0mg/kg prevents scurvy in non-human primates. By way of comparison, across several countries, the recommended dietary intake for adult humans is in the range of 1\u20132\u00a0mg/kg.\nEvolution of animal synthesis.\nAscorbic acid is a common enzymatic cofactor in mammals used in the synthesis of collagen, as well as a powerful reducing agent capable of rapidly scavenging a number of reactive oxygen species (ROS). Given that ascorbate has these important functions, it is surprising that the ability to synthesize this molecule has not always been conserved. In fact, anthropoid primates, \"Cavia porcellus\" (guinea pigs), teleost fishes, most bats, and some passerine birds have all independently lost the ability to internally synthesize vitamin C in either the kidney or the liver. In all of the cases where genomic analysis was done on an ascorbic acid auxotroph, the origin of the change was found to be a result of loss-of-function mutations in the gene that encodes -gulono-\u03b3-lactone oxidase, the enzyme that catalyzes the last step of the ascorbic acid pathway outlined above. One explanation for the repeated loss of the ability to synthesize vitamin C is that it was the result of genetic drift; assuming that the diet was rich in vitaminC, natural selection would not act to preserve it.\nIn the case of the simians, it is thought that the loss of the ability to make vitamin C may have occurred much farther back in evolutionary history than the emergence of humans or even apes, since it evidently occurred soon after the appearance of the first primates, yet sometime after the split of early primates into the two major suborders Haplorrhini (which cannot make vitamin C) and its sister suborder of non-tarsier prosimians, the Strepsirrhini (\"wet-nosed\" primates), which retained the ability to make vitamin C. According to molecular clock dating, these two suborder primate branches parted ways about 63 to 60 million years ago. Approximately three to five million years later (58 million years ago), only a short time afterward from an evolutionary perspective, the infraorder Tarsiiformes, whose only remaining family is that of the tarsier (Tarsiidae), branched off from the other haplorrhines. Since tarsiers also cannot make vitamin C, this implies the mutation had already occurred, and thus must have occurred between these two marker points (63 to 58 million years ago).\nIt has also been noted that the loss of the ability to synthesize ascorbate strikingly parallels the inability to break down uric acid, also a characteristic of primates. Uric acid and ascorbate are both strong reducing agents. This has led to the suggestion that, in higher primates, uric acid has taken over some of the functions of ascorbate.\nPlant synthesis.\nThere are many different biosynthesis pathways to ascorbic acid in plants. Most proceed through products of glycolysis and other metabolic pathways. For example, one pathway utilizes plant cell wall polymers. The principal plant ascorbic acid biosynthesis pathway seems to be via l-galactose. The enzyme l-galactose dehydrogenase catalyzes the overall oxidation to the lactone and isomerization of the lactone to the C4-hydroxyl group, resulting in l-galactono-1,4-lactone. l-Galactono-1,4-lactone then reacts with the mitochondrial flavoenzyme l-galactonolactone dehydrogenase to produce ascorbic acid. l-Ascorbic acid has a negative feedback on l-galactose dehydrogenase in spinach. Ascorbic acid efflux by embryos of dicot plants is a well-established mechanism of iron reduction and a step obligatory for iron uptake.\nAll plants synthesize ascorbic acid. Ascorbic acid functions as a cofactor for enzymes involved in photosynthesis, synthesis of plant hormones, as an antioxidant and regenerator of other antioxidants. Plants use multiple pathways to synthesize vitamin C. The major pathway starts with glucose, fructose or mannose (all simple sugars) and proceeds to l-galactose, l-galactonolactone and ascorbic acid. This biosynthesis is regulated following a diurnal rhythm. Enzyme expression peaks in the morning to supporting biosynthesis for when mid-day sunlight intensity demands high ascorbic acid concentrations. Minor pathways may be specific to certain parts of plants; these can be either identical to the vertebrate pathway (including the GLO enzyme), or start with inositol and get to ascorbic acid via l-galactonic acid to l-galactonolactone.\nIndustrial synthesis.\nVitamin C can be produced from glucose by two main routes. The no longer utilized Reichstein process, developed in the 1930s, used a single fermentation followed by a purely chemical route. The modern two-step fermentation process, originally developed in China in the 1960s, uses additional fermentation to replace part of the later chemical stages. The Reichstein process and the modern two-step fermentation processes both use glucose as the starting material, convert that to sorbitol, and then to sorbose using fermentation. The two-step fermentation process then converts sorbose to 2-keto-l-gulonic acid (KGA) through another fermentation step, avoiding an extra intermediate. Both processes yield approximately 60% vitamin C from the glucose starting point. Researchers are exploring means for one-step fermentation.\nChina produces about 70% of the global vitamin C market. The rest is split among European Union, India and North America. The global market was expected to exceed 141 thousand metric tons in 2024. Cost per metric ton (1000\u00a0kg) in US dollars was $2,220 in Shanghai, $2,850 in Hamburg and $3,490 in the US.\nHealth effects.\nVitamin C has a definitive role in treating scurvy, which is a disease caused by vitaminC deficiency. Beyond that, a role for vitaminC as prevention or treatment for various diseases is disputed, with reviews often reporting conflicting results. No effect of vitaminC supplementation reported for overall mortality. It is on the World Health Organization's List of Essential Medicines and on the World Health Organization's Model Forumulary. In 2023, it was the 226th most commonly prescribed medication in the United States, with more than 1million prescriptions.\nScurvy.\nScurvy is a disease resulting from a deficiency of vitamin C. Without this vitamin, collagen made by the body is too unstable to perform its function and several other enzymes in the body do not operate correctly. Early symptoms are malaise and lethargy, progressing to shortness of breath, bone pain and susceptibility to bruising. As the disease progressed, it is characterized by spots on and bleeding under the skin and bleeding gums. The skin lesions are most abundant on the thighs and legs. A person with the ailment looks pale, feels depressed, and is partially immobilized. In advanced scurvy there is fever, old wounds may become open and suppurating, loss of teeth, convulsions and, eventually, death. Until quite late in the disease the damage is reversible, as healthy collagen replaces the defective collagen with vitaminC repletion.\nNotable human dietary studies of experimentally induced scurvy were conducted on conscientious objectors during World War II in Britain and on Iowa state prisoners in the late 1960s to the 1980s. Men in the prison study developed the first signs of scurvy about four weeks after starting the vitamin C-free diet, whereas in the earlier British study, six to eight months were required, possibly due to the pre-loading of this group with a 70\u00a0mg/day supplement for six weeks before the scorbutic diet was fed. Men in both studies had blood levels of ascorbic acid too low to be accurately measured by the time they developed signs of scurvy. These studies both reported that all obvious symptoms of scurvy could be completely reversed by supplementation of only 10\u00a0mg a day. Treatment of scurvy can be with vitaminC-containing foods or dietary supplements or injection.101\nSepsis.\nPeople in sepsis may have micronutrient deficiencies, including low levels of vitamin C. An intravenous intake of doses much higher than the RDA, such as or more, appears to be needed to maintain normal plasma concentrations in people with sepsis, as the body's demand for vitamin C may increase significantly due to the heightened inflammatory response and oxidative stress. Sepsis mortality may be reduced with administration of intravenous vitamin C.\nCommon cold.\nResearch on vitaminC in the common cold has been divided into effects on prevention, duration, and severity. Oral intakes of more than 200\u00a0mg/day taken on a regular basis was not effective in prevention of the common cold. Restricting analysis to trials that used at least 1000\u00a0mg/day also saw no prevention benefit. However, taking a vitaminC supplement on a regular basis did reduce the average duration of the illness by 8% in adults and 14% in children, and also reduced the severity of colds. Vitamin C taken on a regular basis reduced the duration of severe symptoms but had no effect on the duration of mild symptoms. Therapeutic use, meaning that the vitamin was not started unless people started to feel the beginnings of a cold, had no effect on the duration or severity of the illness.\nVitamin C distributes readily in high concentrations into immune cells, promotes natural killer cell activities, promotes lymphocyte proliferation, and is depleted quickly during infections, effects suggesting a prominent role in immune system function. The European Food Safety Authority concluded there is a cause and effect relationship between the dietary intake of vitamin C and functioning of a normal immune system in adults and in children under three years of age.\nCOVID-19.\nFrom March through July 2020, vitamin C was the subject of more US FDA warning letters than any other ingredient for claims for prevention and/or treatment of COVID-19. In April 2021, the US National Institutes of Health (NIH) COVID-19 Treatment Guidelines stated that \"there are insufficient data to recommend either for or against the use of vitaminC for the prevention or treatment of COVID-19.\" In an update posted December 2022, the NIH position was unchanged:\nFor people hospitalized with severe COVID-19 there are reports of a significant reduction in the risk of all-cause, in-hospital mortality with the administration of vitamin C relative to no vitamin C. There were no significant differences in ventilation incidence, hospitalization duration or length of intensive care unit stay between the two groups. The majority of the trials incorporated into these meta-analyses used intravenous administration of the vitamin. Acute kidney injury was lower in people treated with vitamin C treatment. There were no differences in the frequency of other adverse events due to the vitamin. The conclusion was that further large-scale studies are needed to affirm its mortality benefits before issuing updated guidelines and recommendations.\nCancer.\nHigher vitamin C intake appears to reduce the risk for lung cancer. There is no evidence that vitamin C supplementation reduces the risk of prostate cancer, colorectal cancer or breast cancer.\nCardiovascular disease.\nThere is no evidence that vitamin C supplementation decreases the risk of cardiovascular disease, although there may be an association between higher circulating vitamin C levels or dietary vitamin C and a lower risk of stroke. There is a positive effect of vitamin C on endothelial dysfunction when taken at doses greater than 500\u00a0mg per day. (The endothelium is a layer of cells that line the interior surface of blood vessels.)\nBlood pressure.\nSerum vitamin C was reported to be 15.13 \u03bcmol/L lower in people with hypertension compared to normotensives. The vitamin was inversely associated with both systolic blood pressure (SBP) and diastolic blood pressure (DBP). Oral supplementation of the vitamin resulted in a very modest but statistically significant decrease in SBP in people with hypertension. The proposed explanation is that vitamin C increases intracellular concentrations of tetrahydrobiopterin, an endothelial nitric oxide synthase cofactor that promotes the production of nitric oxide, which is a potent vasodilator. Vitamin C supplementation might also reverse the nitric oxide synthase inhibitor NG-monomethyl-L-arginine 1, and there is also evidence cited that vitamin C directly enhances the biological activity of nitric oxide\nType 2 diabetes.\nThere are contradictory reviews. From one, vitamin C supplementation cannot be recommended for management of type 2 diabetes. However, another reported that supplementation with high doses of vitamin C can decrease blood glucose, insulin and hemoglobin A1c.\nIron deficiency.\nOne of the causes of iron-deficiency anemia is reduced absorption of iron. Iron absorption can be enhanced through ingestion of vitamin C alongside iron-containing food or supplements. Vitamin C helps to keep iron in the reduced ferrous state, which is more soluble and more easily absorbed. It also chelates iron into a soluble complex. It specifically helps the absorption of non-heme iron, which is found in non-meat sources and absorbed via DMT1.\nAlzheimer's disease.\nLower plasma vitamin C concentrations were reported in people with Alzheimer's disease. Reviews do not present reporting on supplement intervention clinical trials.\nEye health.\nHigher dietary intake of vitamin C was associated with lower risk of age-related cataracts. Vitamin C supplementation did not prevent age-related macular degeneration.\nPeriodontal disease.\nLow intake and low serum concentration were associated with greater progression of periodontal disease.\nAdverse effects.\nOral intake of dietary supplements vitamin C in excess of requirements is poorly absorbed, and excess amounts in the blood are rapidly excreted in the urine, so it exhibits low acute toxicity. More than two to three grams, consumed orally, may cause nausea, abdominal cramps and diarrhea. These effects are attributed to the osmotic effect of unabsorbed vitamin C passing through the intestine.156 In theory, high vitamin C intake may cause excessive absorption of iron. A summary of reviews of supplementation in healthy subjects did not report this problem, but left as untested the possibility that individuals with hereditary hemochromatosis might be adversely affected.158\nIn the 20th century, there was belief that excessive vitamin C supplementation could increase the risk of developing kidney stones. However, more recent \"reports of kidney stone formation associated with excess ascorbic acid intake are limited to individuals with renal disease\". A 2003 review stated that \"data from epidemiological studies do not support an association between excess ascorbic acid intake and kidney stone formation in apparently healthy individuals\". A 2022 review found only limited evidence that vitamin C supplementation could cause kidney stones.\nThere is extensive research on the purported benefits of intravenous vitamin C for treatment of sepsis, severe COVID-19 and cancer. Reviews list trials with doses as high as 24 grams per day. Concerns about possible adverse effects are that intravenous high-dose vitamin C leads to a supraphysiological level of vitamin C followed by oxidative degradation to dehydroascorbic acid and hence to oxalate, increasing the risk of oxalate kidney stones and oxalate nephropathy. The risk may be higher in people with renal impairment, as kidneys efficiently excrete excess vitamin C. Second, treatment with high dose vitamin C should be avoided in patients with glucose-6-phosphate dehydrogenase deficiency as it can lead to acute hemolysis. Third, treatment might interfere with the accuracy of glucometer measurement of blood glucose levels, as both vitamin C and glucose have similar molecular structure, which could lead to false high blood glucose readings. Despite all these concerns, meta-analyses of patients in intensive care for sepsis, septic shock, COVID-19 and other acute conditions reported no increase in new-onset kidney stones, acute kidney injury or requirement for renal replacement therapy for patients receiving short-term, high-dose, intravenous vitamin C treatment. This suggests that intravenous vitamin C is safe under these short-term applications.\nHistory.\nScurvy was known to Hippocrates, described in book two of his \"Prorrheticorum\" and in his \"Liber de internis affectionibus\", and cited by James Lind. Symptoms of scurvy were also described by Pliny the Elder: (i) ; and (ii) Strabo, in \"Geographicorum\", book 16, cited in the 1881 International Encyclopedia of Surgery.\nScurvy at sea.\nIn the 1497 expedition of Vasco da Gama, the curative effects of citrus fruit were known. In the 1500s, Portuguese sailors put in to the island of Saint Helena to avail themselves of planted vegetable gardens and wild-growing fruit trees. Authorities occasionally recommended plant food to prevent scurvy during long sea voyages. John Woodall, the first surgeon to the British East India Company, recommended the preventive and curative use of lemon juice in his 1617 book, \"The Surgeon's Mate\". In 1734, the Dutch writer Johann Bachstrom gave the firm opinion, \"scurvy is solely owing to a total abstinence from fresh vegetable food, and greens.\" Scurvy had long been a principal killer of sailors during the long sea voyages. According to Jonathan Lamb, \"In 1499, Vasco da Gama lost 116 of his crew of 170; In 1520, Magellan lost 208 out of 230;\u00a0... all mainly to scurvy.\"\nThe first attempt to give scientific basis for the cause of this disease was by a ship's surgeon in the Royal Navy, James Lind. While at sea in May 1747, Lind provided some crew members with two oranges and one lemon per day, in addition to normal rations, while others continued on cider, vinegar, sulfuric acid or seawater, along with their normal rations, in one of the world's first controlled experiments. The results showed that citrus fruits prevented the disease. Lind published his work in 1753 in his \"Treatise on the Scurvy\".\nFresh fruit was expensive to keep on board, whereas boiling it down to juice allowed easy storage, but destroyed the vitamin (especially if it was boiled in copper kettles). It was 1796 before the British navy adopted lemon juice as standard issue at sea. In 1845, ships in the West Indies were provided with lime juice instead, and in 1860 lime juice was used throughout the Royal Navy, giving rise to the American use of the nickname \"limey\" for the British. Captain James Cook had previously demonstrated the advantages of carrying \"Sour krout\" on board by taking his crew on a 1772\u201375 Pacific Ocean voyage without losing any of his men to scurvy. For his report on his methods the British Royal Society awarded him the Copley Medal in 1776.\nThe name \"antiscorbutic\" was used in the eighteenth and nineteenth centuries for foods known to prevent scurvy. These foods included lemons, limes, oranges, sauerkraut, cabbage, malt, and portable soup. In 1928, the Canadian Arctic anthropologist Vilhjalmur Stefansson showed that the Inuit avoided scurvy on a diet largely of raw meat. Later studies on traditional food diets of the Yukon First Nations, Dene, Inuit, and M\u00e9tis of Northern Canada showed that their daily intake of vitamin C averaged between 52 and 62\u00a0mg/day.\nDiscovery.\nVitamin C was discovered in 1912, isolated in 1928 and synthesized in 1933, making it the first vitamin to be synthesized. Shortly thereafter Tadeus Reichstein succeeded in synthesizing the vitamin in bulk by what is now called the Reichstein process. This made possible the inexpensive mass-production of vitamin C. In 1934, Hoffmann\u2013La Roche bought the Reichstein process patent, trademarked synthetic vitamin C under the brand name Redoxon, and began to market it as a dietary supplement.\nIn 1907, a laboratory animal model which would help to identify the antiscorbutic factor was serendipitously discovered by the Norwegian physicians Axel Holst and Theodor Fr\u00f8lich, who when studying shipboard beriberi, fed guinea pigs their test diet of grains and flour and were surprised when scurvy resulted instead of beriberi. Unknown at that time, this species did not make its own vitamin C (being a caviomorph), whereas mice and rats do. In 1912, the Polish biochemist Casimir Funk developed the concept of vitamins. One of these was thought to be the anti-scorbutic factor. In 1928, this was referred to as \"water-soluble C\", although its chemical structure had not been determined.\nFrom 1928 to 1932, Albert Szent-Gy\u00f6rgyi and Joseph L. Svirbely's Hungarian team, and Charles Glen King's American team, identified the anti-scorbutic factor. Szent-Gy\u00f6rgyi isolated hexuronic acid from animal adrenal glands, and suspected it to be the antiscorbutic factor. In late 1931, Szent-Gy\u00f6rgyi gave Svirbely the last of his adrenal-derived hexuronic acid with the suggestion that it might be the anti-scorbutic factor. By the spring of 1932, King's laboratory had proven this, but published the result without giving Szent-Gy\u00f6rgyi credit for it. This led to a bitter dispute over priority. In 1933, Walter Norman Haworth chemically identified the vitamin as l-hexuronic acid, proving this by synthesis in 1933. Haworth and Szent-Gy\u00f6rgyi proposed that L-hexuronic acid be named a-scorbic acid, and chemically l-ascorbic acid, in honor of its activity against scurvy. The term's etymology is from Latin, \"a-\" meaning away, or off from, while -scorbic is from Medieval Latin \"scorbuticus\" (pertaining to scurvy), cognate with Old Norse \"skyrbjugr\", French \"scorbut\", Dutch \"scheurbuik\" and Low German \"scharbock\". Partly for this discovery, Szent-Gy\u00f6rgyi was awarded the 1937 Nobel Prize in Medicine, and Haworth shared that year's Nobel Prize in Chemistry.\nIn 1957, J. J. Burns showed that some mammals are susceptible to scurvy as their liver does not produce the enzyme l-gulonolactone oxidase, the last of the chain of four enzymes that synthesize vitamin C. American biochemist Irwin Stone was the first to exploit vitamin C for its food preservative properties. He later developed the idea that humans possess a mutated form of the l-gulonolactone oxidase coding gene.\nStone introduced Linus Pauling to the theory that humans needed to consume vitamin C in quantities far higher than what was considered a recommended daily intake in order to optimize health.\nIn 2008, researchers discovered that in humans and other primates the red blood cells have evolved a mechanism to more efficiently utilize the vitamin C present in the body by recycling oxidized l-dehydroascorbic acid (DHA) back into ascorbic acid for reuse by the body. The mechanism was not found to be present in mammals that synthesize their own vitamin C.\nHistory of large dose therapies.\nVitamin C megadosage is a term describing the consumption or injection of vitamin C in doses comparable to or higher than the amounts produced by the livers of mammals which are able to synthesize vitamin C. An argument for this, although not the actual term, was described in 1970 in an article by Linus Pauling. Briefly, his position was that for optimal health, humans should be consuming at least 2,300\u00a0mg/day to compensate for the inability to synthesize vitamin C. The recommendation also fell into the consumption range for gorillas\u2014a non-synthesizing near-relative to humans. A second argument for high intake is that serum ascorbic acid concentrations increase as intake increases until it plateaus at about 190 to 200 micromoles per liter (\u03bcmol/L) once consumption exceeds 1,250 milligrams. As noted, government recommendations are a range of 40 to 110\u00a0mg/day and normal plasma is approximately 50\u00a0\u03bcmol/L, so \"normal\" is about 25% of what can be achieved when oral consumption is in the proposed megadose range.\nPauling popularized the concept of high dose vitamin C as prevention and treatment of the common cold in 1970. A few years later he proposed that vitamin C would prevent cardiovascular disease, and that 10 grams/day, initially administered intravenously and thereafter orally, would cure late-stage cancer. Mega-dosing with ascorbic acid has other champions, among them chemist Irwin Stone and the controversial Matthias Rath and Patrick Holford, who both have been accused of making unsubstantiated treatment claims for treating cancer and HIV infection. The idea that large amounts of intravenous ascorbic acid can be used to treat late-stage cancer or ameliorate the toxicity of chemotherapy is\u2014some forty years after Pauling's seminal paper\u2014still considered unproven and still in need of high quality research.\nResearch directions.\nCancer research.\nThere is research investigating whether high dose intravenous vitamin C administration as a co-treatment will suppress cancer stem cells, which are responsible for tumor recurrence, metastasis and chemoresistance.\nSkin aging research.\nThere is also ongoing research on topical application of vitamin C to prevent signs of skin aging. Human skin physiologically contains small amounts of vitamin C, which supports collagen synthesis, decreases collagen degradation, and assists in antioxidant protection against UV-induced photo-aging, including photocarcinogenesis. This knowledge is often used as a rationale for the marketing of vitamin C as a topical \"serum\" ingredient to prevent or treat facial skin aging, melasma (dark pigmented spots), and wrinkles; however, these claims are unsubstantiated and are not supported by research conducted so far; the supposed efficacy of topical treatment as opposed to oral intake is poorly understood. The purported mechanism on supposed benefit of topical vitamin C application to slow skin aging is that vitamin C functions as an antioxidant, neutralizing free radicals from sunlight exposure, air pollutants or normal metabolic processes. The clinical trial literature is characterized as insufficient to support health claims; one reason being put forward was that \"All the studies used vitamin C in combination with other ingredients or therapeutic mechanisms, thereby complicating any specific conclusions regarding the efficacy of vitamin C.\"\nPneumonia.\nFurther research is needed to determine if prophylactic vitamin C treatment is helpful for preventing or treating pneumonia.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32511", "revid": "50299840", "url": "https://en.wikipedia.org/wiki?curid=32511", "title": "Vietnamese language", "text": "Austroasiatic language\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nVietnamese () is an Austroasiatic language primarily spoken in Vietnam where it is the official language. It belongs to the Vietic subgroup of the Austroasiatic language family. Vietnamese is spoken natively by around 86 million people, and as a second language by 11 million people, several times as many as the rest of the Austroasiatic family combined. It is the native language of ethnic Vietnamese (Kinh), as well as the second or first language for other ethnicities of Vietnam, and used by Vietnamese diaspora in the world.\nLike many languages in Southeast Asia and East Asia, Vietnamese is highly analytic and is tonal. It has head-initial directionality, with subject\u2013verb\u2013object order and modifiers following the words they modify. It also uses noun classifiers. Its vocabulary has had significant influence from Middle Chinese and French. Vietnamese morphemes and phonological words are predominantly monosyllabic, however many multisyllabic words do occur, usually as a result of compounding and reduplication.\nVietnamese is written using the Vietnamese alphabet (). The alphabet is based on the Latin script and was officially adopted in the early 20th century during French rule of Vietnam. It uses digraphs and diacritics to mark tones and some phonemes. Vietnamese was historically written using , a logographic script using Chinese characters () to represent Sino-Vietnamese vocabulary and some native Vietnamese words, together with many locally invented characters representing other words.\nClassification.\nEarly linguistic work in the late 19th and early 20th centuries (Logan 1852, Forbes 1881, M\u00fcller 1888, Kuhn 1889, Schmidt 1905, Przyluski 1924, and Benedict 1942) classified Vietnamese as belonging to the Mon\u2013Khmer branch of the Austroasiatic language family (which also includes the Khmer language spoken in Cambodia, as well as various smaller and/or regional languages, such as the Munda and Khasi languages spoken in eastern India, and others in Laos, southern China and parts of Thailand). In 1850, British lawyer James Richardson Logan detected striking similarities between the Korku language in Central India and Vietnamese. He suggested that Korku, Mon, and Vietnamese were part of what he termed \"Mon\u2013Annam languages\" in a paper published in 1856. Later, in 1920, French-Polish linguist Jean Przyluski found that M\u01b0\u1eddng is more closely related to Vietnamese than other Mon\u2013Khmer languages, and a Viet\u2013Muong subgrouping was established, also including Thavung, Chut, Cuoi, etc. The term \"Vietic\" was proposed by Hayes (1992), who proposed to redefine Viet\u2013Muong as referring to a subbranch of Vietic containing only Vietnamese and M\u01b0\u1eddng. The term \"Vietic\" is used, among others, by G\u00e9rard Diffloth, with a slightly different proposal on subclassification, within which the term \"Viet\u2013Muong\" refers to a lower subgrouping (within an eastern Vietic branch) consisting of Vietnamese dialects, M\u01b0\u1eddng dialects, and Ngu\u1ed3n (of Qu\u1ea3ng B\u00ecnh Province).\nHistory.\nAustroasiatic is believed to have dispersed around 2000 BC.\nThe arrival of the agricultural Ph\u00f9ng Nguy\u00ean culture in the Red River Delta at that time may correspond to the Vietic branch.\nThis ancestral Vietic was typologically very different from later Vietnamese.\nAs well as monosyllabic roots, it had sesquisyllabic roots consisting of a reduced syllable followed by a full syllable, and featured many consonant clusters.\nBoth of these features are found elsewhere in Austroasiatic and in modern conservative Vietic languages south of the Red River area.\nThe language was non-tonal, but featured glottal stop and voiceless fricative codas.\nBorrowed vocabulary indicates early contact with speakers of Tai languages in the last millennium BC, which is consistent with genetic evidence from Dong Son culture sites.\nExtensive contact with Chinese began from the Han dynasty (2nd century BC).\nAt this time, Vietic groups began to expand south from the Red River Delta and into the adjacent uplands, possibly to escape Chinese encroachment.\nThe oldest layer of loans from Chinese into northern Vietic (which would become the Viet\u2013Muong subbranch) date from this period.\nThe northern Vietic varieties thus became part of the Mainland Southeast Asia linguistic area, in which languages from genetically unrelated families converged toward characteristics such as isolating morphology and similar syllable structure. Many languages in this area, including Viet\u2013Muong, underwent a process of tonogenesis, in which distinctions formerly expressed by final consonants became phonemic tonal distinctions when those consonants disappeared. These characteristics have become part of many of the genetically unrelated languages of Southeast Asia; for example, Tsat (a member of the Malayo-Polynesian group within Austronesian), and Vietnamese each developed tones as a phonemic feature.\nAfter the split from Muong around the end of the first millennium AD, the following stages of Vietnamese are commonly identified:\n(to c.\u20091500) Sources include the Ming glossary (, c. 15th century) from the \"Huayi yiyu\" series, and a Buddhist sutra recorded in an early form of chu Nom, variously dated to the 12th and 15th centuries. Compared with Proto-Vietic, the language had lost the voicing distinction on stop initials, giving rise to a tone split, and implosive initials had become nasals. Most of the minor syllables of Proto-Vietic were still present.\n(16th to 19th centuries) The language found in \"Dictionarium Annamiticum Lusitanum et Latinum\" (1651) of the Jesuit missionary Alexandre de Rhodes. Another famous dictionary of this period was written by Pierre Pigneau de Behaine in 1773 and published by Jean-Louis Taberd in 1838.\n(from the 19th century)\nAfter expelling the Chinese at the beginning of the 10th century, the Ng\u00f4 dynasty adopted Classical Chinese as the formal medium of government, scholarship and literature. With the dominance of Chinese came wholesale importation of Chinese vocabulary. The resulting Sino-Vietnamese vocabulary makes up about a third of the Vietnamese lexicon in all realms, and may account for as much as 60% of the vocabulary used in formal texts.\nVietic languages were confined to the northern third of modern Vietnam until the \"southward advance\" (Nam ti\u1ebfn) from the late 15th century.\nThe conquest of the ancient nation of Champa and the conquest of the Mekong Delta led to an expansion of the Vietnamese people and language, with distinctive local variations emerging.\nAfter France invaded Vietnam in the late 19th century, French gradually replaced Literary Chinese as the official language in education and government. Vietnamese adopted many French terms, such as ('dame', from ), ('train station', from ), ('shirt', from ), and ('doll', from ), resulting in a language that was Austroasiatic but with major Sino-influences and some minor French influences from the French colonial era.\nProto-Vietic.\nThe following diagram shows the consonants of Proto-Vietic, along with the outcomes in the modern language:\nThe aspirated stops are infrequent and result from clusters of stops and *.\nThe proto-phoneme * is also infrequent, and has reflexes only in Viet-Muong. However, it occurs in some important words and is cognate with Khmu .\nFerlus 1992 also had additional phonemes * and *.\nProto-Vietic had monosyllables CV(C) and sesquisyllables C-CV(C).\nThe following initial clusters occurred, with outcomes indicated:\nLenition of medial consonants.\nAs noted above, Proto-Vietic had sesquisyllabic words with an initial minor syllable (in addition to, and independent of, initial clusters in the main syllable). When a minor syllable occurred, the main syllable's initial consonant was intervocalic and as a result suffered lenition, becoming a voiced fricative. These fricatives were not present in Proto-Viet\u2013Muong, as indicated by their absence in M\u01b0\u1eddng, but were present in Vietnamese until the 15th or 16th centuries. Subsequent loss of the minor-syllable prefixes phonemicized the fricatives. Ferlus 1992 proposes that originally there were both voiced and voiceless fricatives, corresponding to original voiced or voiceless stops, but Ferlus 2009 appears to have abandoned that hypothesis, suggesting that stops were softened and voiced at approximately the same time, according to the following pattern:\nOrigin of tones.\nProto-Vietic did not have tones. Tones developed later in some of the daughter languages from distinctions in the initial and final consonants. Vietnamese tones developed as follows:\nGlottal-ending syllables ended with a glottal stop , while fricative-ending syllables ended with or . Both types of syllables could co-occur with a resonant (e.g. or ).\nAt some point, a tone split occurred, as in many other mainland Southeast Asian languages. Essentially, an allophonic distinction developed in the tones, whereby the tones in syllables with voiced initials were pronounced differently from those with voiceless initials. (Approximately speaking, the voiced allotones were pronounced with additional breathy voice or creaky voice and with lowered pitch. The quality difference predominates in today's northern varieties, e.g. in Hanoi, while in the southern varieties the pitch difference predominates, as in Ho Chi Minh City.) Subsequent to this, the plain-voiced stops became voiceless and the allotones became new phonemic tones.\nThe implosive stops (, and ) were unaffected, and in fact developed tonally as if they were unvoiced. (This behavior is common to all East Asian languages with implosive stops.)\nThese stops merged with the corresponding nasals (, and ) before the Old Vietnamese period.\nAs noted above, consonants following minor syllables became voiced fricatives. The minor syllables were eventually lost, but not until the tone split had occurred. As a result, words in modern Vietnamese with voiced fricatives occur in all six tones, and the tonal register reflects the voicing of the minor-syllable prefix and not the voicing of the main-syllable stop in Proto-Vietic that produced the fricative. For similar reasons, words beginning with and occur in both registers. (Thompson 1976 reconstructed voiceless resonants to account for outcomes where resonants occur with a first-register tone, but this is no longer considered necessary, at least by Ferlus.)\nA large number of words were borrowed from Middle Chinese, forming part of the Sino-Vietnamese vocabulary. These caused the original introduction of the retroflex sounds and (modern \"s\", \"tr\") into the language.\nOld Vietnamese.\nOld (or Ancient) Vietnamese separated from Muong around the 9th century. The sources for the reconstruction of Old Vietnamese are Nom texts, such as the 12th-century/1486 Buddhist scripture \"Ph\u1eadt thuy\u1ebft \u0110\u1ea1i b\u00e1o ph\u1ee5 m\u1eabu \u00e2n tr\u1ecdng kinh\" (\"S\u016btra explained by the Buddha on the Great Repayment of the Heavy Debt to Parents\"), old inscriptions, and a late 13th-century (possibly 1293) \"https://\" glossary by Chinese diplomat (c. 1259 \u2013 1309).\nThe used Chinese characters phonetically where each word, monosyllabic in Modern Vietnamese, is written with two Chinese characters or in a composite character made of two different characters. This conveys the transformation of the Vietnamese lexicon from sesquisyllabic to fully monosyllabic under the pressure of Chinese linguistic influence, characterized by linguistic phenomena such as the reduction of minor syllables; loss of affixal morphology drifting towards analytical grammar; simplification of major syllable segments, and the change of suprasegment instruments. For example, the modern Vietnamese word 'heaven' was \"*pl\u1eddi\" in Old Vietnamese and \"bl\u1eddi\" in Middle Vietnamese.\nSubsequent changes to initial consonants included:\nMiddle Vietnamese.\nThe writing system used for Vietnamese is based closely on the system developed by Alexandre de Rhodes for his 1651 \"Dictionarium Annamiticum Lusitanum et Latinum\". It reflects the pronunciation of the Vietnamese of Hanoi at that time, a stage commonly termed \"Middle Vietnamese\" (). The pronunciation of the \"rime\" of the syllable, i.e. all parts other than the initial consonant (optional glide, vowel nucleus, tone and final consonant), appears nearly identical between Middle Vietnamese and modern Hanoi pronunciation. On the other hand, the Middle Vietnamese pronunciation of the initial consonant differs greatly from all modern dialects, and in fact is significantly closer to the modern Saigon dialect than the modern Hanoi dialect.\nThe following diagram shows the orthography and pronunciation of Middle Vietnamese:\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;^1 occurs only at the end of a syllable.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;^2 This letter, \u27e8\ua797\u27e9, is no longer used.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;^3 does not occur at the beginning of a syllable, but can occur at the end of a syllable, where it is notated \"i\" or \"y\" (with the difference between the two often indicating differences in the quality or length of the preceding vowel), and after and , where it is notated \"\u0115\". This \"\u0115\", and the it notated, have disappeared from the modern language.\nNote that \"b\" and \"p\" never contrast in any position, suggesting that they are allophones.\nThe language also has three clusters at the beginning of syllables, which have since disappeared:\nMost of the unusual correspondences between spelling and modern pronunciation are explained by Middle Vietnamese. Note in particular:\nDe Rhodes's orthography also made use of an apex diacritic on \"o\u1dc3\" and \"u\u1dc3\" to indicate a final labial-velar nasal , an allophone of that is peculiar to the Hanoi dialect to the present day. An example is , which later became . This diacritic is often mistaken for a tilde in modern reproductions of early Vietnamese writing.\nAfter the Vietnam War.\nFollowing the defeat of Southern Vietnam in 1975 by Northern Vietnam in the Vietnam War, the Vietnamese language within Vietnam has gradually shifted towards the Northern dialect. Hanoi, the largest city in Northern Vietnam was made the capital of Vietnam in 1976. A study stated that \"The gap in vocabulary use between speakers in North and South Vietnam is now much narrower than before. There is little to distinguish between how the generations that were born and grew up in the South after 1975 now speak, compared to their peers in the North. This gap is almost non-existent in newspapers, on radio and television, and in websites.\" However, this convergence does not apply to emigrants, in which the study states represent \"culture freeze,\" a phenomenon that describes when culture among emigrants is frozen in time and does not evolve with culture in their home country once they move to a new country. Here, culture freeze describes that the use of the language of emigrants from Vietnam has been \"frozen\" in both vocabulary and pronunciation, and as languages gradually evolve over time, has become a little different than the present Vietnamese language in Vietnam. Additionally, as immigration to the United States following the Vietnam war was primarily driven due to political reasons, the Southern Vietnamese dialect was initially strongly linked to social identity. During and after the Vietnam War, thousands of Southern Vietnamese immigrated to the United States with the partnership between Saigon and the US. In contrast, during and following the Vietnam War, thousands of Northern Vietnamese moved to the Czech Republic due to Hanoi's partnership with the now obsolete Czechoslovak Socialist Republic. As a result, today, the Vietnamese language is generally taught through the Northern dialect in the Czech Republic in contrast with the Southern dialect in the United States.[]\nGeographic distribution.\nAs a result of emigration, Vietnamese speakers are also found in other parts of Southeast Asia, East Asia, North America, Europe, and Australia. Vietnamese has also been officially recognized as a minority language in the Czech Republic.\nAs the national language, Vietnamese is the \"lingua franca\" in Vietnam. It is also spoken by the Jing people traditionally residing on three islands (now joined to the mainland) off Dongxing in southern Guangxi Province, China. A large number of Vietnamese speakers also reside in neighboring countries of Cambodia and Laos.\nIn the United States, Vietnamese is the sixth most spoken language, with over 1.5 million speakers, who are concentrated in a handful of states. It is the third-most spoken language in Texas and Washington; fourth-most in Georgia, Louisiana, and Virginia; and fifth-most in Arkansas and California. Vietnamese is the third most spoken language in Australia other than English, after Mandarin and Arabic. In France, it is the most spoken Asian language and the eighth most spoken immigrant language at home.\nOfficial status.\nVietnamese is the sole official and national language of Vietnam. It is the first language of the majority of the Vietnamese population, as well as a first or second language for the country's ethnic minority groups.\nIn the Czech Republic, Vietnamese has been recognized as one of 14 minority languages, on the basis of communities that have resided in the country either traditionally or on a long-term basis. This status grants the Vietnamese community in the country a representative on the Government Council for Nationalities, an advisory body of the Czech Government for matters of policy towards national minorities and their members. It also grants the community the right to use Vietnamese with public authorities and in courts anywhere in the country.\nIn the U.S. city of San Francisco, municipal services began to be offered in Vietnamese starting in 2024.\nAs a foreign language.\nVietnamese is taught in schools and institutions outside of Vietnam, a large part contributed by its diaspora. In countries with Vietnamese-speaking communities Vietnamese language education largely serves as a role to link descendants of Vietnamese immigrants to their ancestral culture. In neighboring countries and vicinities near Vietnam such as Southern China, Cambodia, Laos, and Thailand, Vietnamese as a foreign language is largely due to trade, as well as recovery and growth of the Vietnamese economy.\nSince the 1980s, Vietnamese language schools () have been established for youth in many Vietnamese-speaking communities around the world such as in the United States, Germany, and France.\nPhonology.\nVowels.\nVietnamese has a large number of vowels. Below is a vowel diagram of Standard Vietnamese and Vietnamese from Hanoi (including centering diphthongs):\nFront and central vowels (i, \u00ea, e, \u01b0, \u00e2, \u01a1, \u0103, a) are unrounded, whereas the back vowels (u, \u00f4, o) are rounded. The vowels \u00e2 and \u0103 are pronounced very short, much shorter than the other vowels. Thus, \u01a1 and \u00e2 are basically pronounced the same except that \u01a1 is of normal length while \u00e2 is short \u2013 the same applies to the vowels long a and short \u0103 .\nThe centering diphthongs are formed with only the three high vowels (i, \u01b0, u). They are generally spelled as ia, \u01b0a, ua when they end a word and are spelled i\u00ea, \u01b0\u01a1, u\u00f4, respectively, when they are followed by a consonant.\nIn addition to single vowels (or monophthongs) and centering diphthongs, Vietnamese has closing diphthongs and triphthongs. The closing diphthongs and triphthongs consist of a main vowel component followed by a shorter semivowel offglide or . There are restrictions on the high offglides: cannot occur after a front vowel (i, \u00ea, e) nucleus and cannot occur after a back vowel (u, \u00f4, o) nucleus.\nThe correspondence between the orthography and pronunciation is complicated. For example, the offglide is usually written as \"i\"; however, it may also be represented with \"y\". In addition, in the diphthongs and the letters \"y\" and \"i\" also indicate the pronunciation of the main vowel: ay = \u0103 + , ai = a + . Thus, \"tay\" \"hand\" is while \"tai\" \"ear\" is . Similarly, u and o indicate different pronunciations of the main vowel: au = \u0103 + , ao = a + . Thus, \"thau\" \"brass\" is while \"thao\" \"raw silk\" is .\nConsonants.\nThe consonants that occur in Vietnamese are listed below in the Vietnamese orthography with the phonetic pronunciation to the left.\nSome consonant sounds are written with only one letter (like \"p\"), other consonant sounds are written with a digraph (like \"ph\"), and others are written with more than one letter or digraph (the velar stop is written variously as \"c\", \"k\", or \"q\"). In some cases, they are based on their Middle Vietnamese pronunciation; since that period, \"ph\" and \"kh\" (but not \"th\") have evolved from aspirated stops into fricatives (like Greek phi and chi), while \"d\" and \"gi\" have collapsed and converged together (into /z/ in the north and /j/ in the south).\nNot all dialects of Vietnamese have the same consonant in a given word (although all dialects use the same spelling in the written language). See the language variation section for further elaboration.\nSyllable-final orthographic \"ch\" and \"nh\" in Vietnamese has had different analyses. One analysis has final \"ch\", \"nh\" as being phonemes contrasting with syllable-final \"t\", \"c\" and \"n\", \"ng\" and identifies final \"ch\" with the syllable-initial \"ch\" . The other analysis has final \"ch\" and \"nh\" as predictable allophonic variants of the velar phonemes and that occur after the upper front vowels \"i\" and \"\u00ea\" ; although they also occur after \"a\", but in such cases are believed to have resulted from an earlier \"e\" which diphthongized to \"ai\" (cf. \"ach\" from \"aic\", \"anh\" from \"aing\"). (See Vietnamese phonology: Analysis of final \"ch\", \"nh\" for further details.)\nTones.\nEach Vietnamese syllable is pronounced with one of six inherent tones, centered on the main vowel or group of vowels. Tones differ in:\nTone is indicated by diacritics written above or below the vowel (most of the tone diacritics appear above the vowel; except the \"n\u1eb7ng\" tone dot diacritic goes below the vowel). The six tones in the northern varieties (including Hanoi), with their self-referential Vietnamese names, are:\nOther dialects of Vietnamese may have fewer tones (typically only five).\nIn Vietnamese poetry, tones are classed into two groups: (tone pattern)\nWords with tones belonging to a particular tone group must occur in certain positions within the poetic verse.\nVietnamese Catholics practice a distinctive style of prayer recitation called , in which each tone is assigned a specific note or sequence of notes.\nOld tonal classification.\nBefore Vietnamese switched from a Chinese-based script to a Latin-based script, Vietnamese had used the traditional Chinese system of classifying tones. Using this system, Vietnamese has 8 tones, but modern linguists only count 6 phonemic tones.\nVietnamese tones were classified into two main groups, \"b\u1eb1ng\" (\u5e73; 'level tones') and \"tr\u1eafc\" (\u4ec4; 'sharp tones'). Some tones such as \"ngang\" belong to the \"b\u1eb1ng\" group, while others such as \"ng\u00e3\" belong to the \"tr\u1eafc\" group. Then, these tones were further divided in several other categories: \"b\u00ecnh\" (\u5e73; 'even'), \"th\u01b0\u1ee3ng\" (\u4e0a; 'rising'), \"kh\u1ee9\" (\u53bb; 'departing'), and \"nh\u1eadp\" (\u5165; 'entering').\n\"S\u1eafc\" and \"n\u1eb7ng\" are counted twice in the system, once in \"kh\u1ee9\" (\u53bb; 'departing') and again in \"nh\u1eadp\" (\u5165; 'entering'). The reason for the extra two tones is that syllables ending in the stops /p/, /t/, /c/ and /k/ are treated as having entering tones, but phonetically they are exactly the same.\nThe tones in the old classification were called \"\u00c2m b\u00ecnh\" \u9670\u5e73 (\"ngang\"), \"D\u01b0\u01a1ng b\u00ecnh\" \u967d\u5e73 (\"huy\u1ec1n\"), \"\u00c2m th\u01b0\u1ee3ng\" \u9670\u4e0a (\"h\u1ecfi\"), \"D\u01b0\u01a1ng th\u01b0\u1ee3ng\" \u967d\u4e0a (\"ng\u00e3\"), \"\u00c2m kh\u1ee9\" \u9670\u53bb (\"s\u1eafc\"; for words that do not end in /p/, /t/, /c/ and /k/), \"D\u01b0\u01a1ng kh\u1ee9\" \u967d\u53bb (\"n\u1eb7ng\"; for words that do not end in /p/, /t/, /c/ and /k/), \"\u00c2m nh\u1eadp\" \u9670\u5165 (\"s\u1eafc\"; for words that do end in /p/, /t/, /c/ and /k/), and \"D\u01b0\u01a1ng nh\u1eadp\" \u967d\u5165 (\"n\u1eb7ng\"; for words that do end in /p/, /t/, /c/ and /k/).\nGrammar.\nVietnamese, like Thai and many languages in Southeast Asia, is an analytic language. Vietnamese does not use morphological marking of case, gender, number or tense (and, as a result, has no finite/nonfinite distinction). Also like other languages in the region, Vietnamese syntax conforms to subject\u2013verb\u2013object word order, is head-initial (displaying modified-modifier ordering), and has a noun classifier system. The topic\u2013comment structure is also prevalent in Vietnamese. Additionally, it is pro-drop, wh-in-situ, and allows verb serialization.\nSome Vietnamese sentences with English word glosses and translations are provided below.\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nLexicon.\nAustroasiatic origins.\nMany early studies hypothesized Vietnamese language-origins to have been either Kra-Dai, Sino-Tibetan, or Austroasiatic. Austroasiatic origins are so far the most tenable to date, with some of the oldest words in Vietnamese being Austroasiatic in origin.\nVietnamese shares a large amount of vocabulary with the M\u01b0\u1eddng languages, a close relative of the Vietnamese language.\nOther compound words, such as n\u01b0\u1edbc non (ch\u1eef N\u00f4m: \u6e03\ud847\udf6b, \"country/nation\", lit. \"water and mountains\"), appear to be of purely Vietnamese origin and used to be inscribed in ch\u1eef N\u00f4m characters (compounded, self-coined Chinese characters) but are now written in the Vietnamese alphabet.\nChinese contact.\nAlthough Vietnamese roots are classified as Austroasiatic, Vietic, and Viet-Muong, language contact with Chinese heavily influenced the Vietnamese language, causing it to diverge from Viet-Muong around the 10th to 11th century and become Modern Vietnamese. For instance, the Vietnamese word \"qu\u1ea3n l\u00fd,\" meaning \"management\" (noun) or \"manage\" (verb), likely descended from the same word as \"gu\u01cenl\u01d0\" () in Chinese (also \"kanri\" (, ) in Japanese and \"gwalli\" (\"gwan+ri\"; Korean:\u00a0; Hanja:\u00a0) in Korean). Instances of Chinese contact include the historical Nam Vi\u1ec7t (aka Nanyue) as well as other periods of influence. Besides English and French, which have made some contributions to the Vietnamese language, Japanese loanwords into Vietnamese are also a more recently studied phenomenon.\nModern linguists describe modern Vietnamese having lost many Proto-Austroasiatic phonological and morphological features that original Vietnamese had. The Chinese influence on Vietnamese corresponds to various periods when Vietnam was under Chinese rule and subsequent influence after Vietnam became independent. Early linguists thought that this meant the Vietnamese lexicon had only two influxes of Chinese words, one stemming from the period under actual Chinese rule and a second from afterwards. These words are grouped together as Sino-Vietnamese vocabulary.\nHowever, according to linguist John Phan, \"Annamese Middle Chinese\" was already used and spoken in the Red River Valley by the 1st century CE, and its vocabulary significantly fused with the co-existing Proto-Viet-Muong language, the immediate ancestor of Vietnamese. He lists three major classes of Sino-Vietnamese borrowings: Early Sino-Vietnamese (Han dynasty ca. 1st century CE and Jin dynasty ca. 4th century CE), Late Sino-Vietnamese (Tang dynasty), and Recent Sino-Vietnamese (Ming dynasty and afterwards)\nFrench era.\nVietnam became a French protectorate/colonial territory in 1883 (until the Geneva Accords of 1954), which resulted in significant influence from French into the Indochina region (Laos, Cambodia and Vietnam). Examples include:\n\"C\u00e0 ph\u00ea\" in Vietnamese was derived from the French \"caf\u00e9\" (coffee). Yogurt in Vietnamese is \"s\u1eefa chua\" (lit.\u2009'sour milk'), but it is also calqued from French (\"yaourt\") into Vietnamese (\"da ua -\" /j/a ua). \"Ph\u00f4 mai\" (cheese) is from the French \"fromage\". Musical note was borrowed into Vietnamese as \"n\u1ed1t\" or \"n\u1ed1t nh\u1ea1c\", from the French \"note de musique\". The Vietnamese term for steering wheel is \"v\u00f4 l\u0103ng\", a partial derivation from the French \"volant directionnel\". A necktie (\"cravate\" in French) is rendered into Vietnamese as \"c\u00e0 v\u1ea1t\".\nIn addition, modern Vietnamese pronunciations of French names correspond directly to the original French pronunciations (\"Pa-ri\" for Paris, \"M\u00e1c-x\u00e2y\" for Marseille, \"Bo\u00f3c-\u0111\u00f4\" for Bordeaux, etc.), whereas pronunciations of other foreign names (Chinese excluded) are generally derived from English.\nEnglish.\nSome English words were incorporated into Vietnamese as loan words - such as \"TV\", borrowed as \"tivi\" or just TV, but still officially called \"truy\u1ec1n h\u00ecnh\". Some other borrowings are calques, translated into Vietnamese. For example, 'software' is translated into \"ph\u1ea7n m\u1ec1m\" (literally meaning \"soft part\"). Some scientific terms, such as \"biological cell\", were derived from ch\u1eef H\u00e1n. For example, the word \"t\u1ebf b\u00e0o\" is in ch\u1eef H\u00e1n, whilst other scientific names such as \"acetylcholine\" are unaltered. Words like \"peptide\" may be seen as \"peptit\".\nJapanese.\nJapanese loanwords are a more recently studied phenomenon, with a paper by Nguy\u1ec5n &amp; L\u00ea (2020) classifying three waves of Japanese influence - with the first two waves being the principal influxes and the third wave coming from the Vietnamese who studied Japanese. The first wave consisted of Kanji words created by Japanese to represent Western concepts that were not readily available in Chinese or Japanese, where by the end of the 19th century they were imported to other Asian languages. This first influx is called Sino-Vietnamese words of Japanese origins. For example, the Vietnamese term for \"association club\", \"c\u00e2u l\u1ea1c b\u1ed9,\" which was borrowed from Chinese (, pinyin: \"j\u00f9l\u00e8b\u00f9\", jyutping: \"keoi1 lok6 bou6\"), and then in turn from Japanese (kanji: , katakana: , r\u014dmaji: \"kurabu\") which came from the English \"club\", resulting in indirect borrowing from Japanese.\nThe second wave was during the brief Japanese occupation of Vietnam from 1940 until 1945. However, Japanese cultural influence in Vietnam started significantly from the 1980s. This newer second wave of Japanese-origin loanwords is distinctive from the Sino-Vietnamese words of Japanese origin in that they were borrowed directly from Japanese. This vocabulary includes words representative of Japanese culture, such as \"kimono\", \"sumo\", \"samurai\", and \"bonsai\" from modified Hepburn romanisation. These loanwords are coined as \"new Japanese loanwords\". A significant number of new Japanese loanwords were also of Chinese origin. Sometimes the same concept can be described using both Sino-Vietnamese words of Japanese origin (first wave) and new Japanese loanwords (second wave). For example, judo can be referred to as both \"judo\" and \"nhu \u0111\u1ea1o\", the Vietnamese reading of \u67d4\u9053.\nModern Chinese influence.\nSome words, such as \"l\u1ea1p x\u01b0\u1edfng\" from \u81d8\u8178 (Chinese sausage), primarily keep to the Cantonese pronunciations, having been brought over by southern Chinese migrants, whereas in H\u00e1n-Vi\u1ec7t, which has been described as being close to Middle Chinese pronunciation, it is actually pronounced \"l\u1ea1p tr\u01b0\u1eddng.\" However, the Cantonese term is the better-known name for Chinese sausage in Vietnam. Meanwhile, any new terms calqued from Chinese would be based on the Mandarin pronunciation. Additionally, in the southern provinces of Vietnam, the term \"\" can be used to refer to dice, which may have derived from a Cantonese or Teochew idiom, \"x\u1eadp x\u00ed, x\u1eadp ng\u1ea7u\" (\u5341\u56db, \u5341\u4e94, Sino-Vietnamese: \"th\u1eadp t\u1ee9, th\u1eadp ng\u0169\"), literally \"fourteen, fifteen\" to mean 'uncertain'.\nSlang.\nVietnamese slang (ti\u1ebfng l\u00f3ng) has changed over time. Vietnamese slang consists of pure Vietnamese words as well as words borrowed from other languages such as Mandarin or Indo-European languages. It is estimated that Vietnamese slang originating from Mandarin accounts for a tiny proportion (4.6% of surveyed data in newspapers). On the other hand, slang originating from Indo-European languages accounts for a more significant proportion (12%) and is much more common in today's usage. Slang borrowed from these languages can be either transliteral or vernacular. Some examples:\nWith the rise of the Internet, new slang is generated and popularized through social media. This modern slang is commonly used in the younger generation's teenspeak in Vietnam. This recent slang is mostly pure Vietnamese, and almost all the words are homonyms or some form of wordplay. Some slang words may include profanity swear words (derogatory) or just a play on words.\nSome examples with newer and older slang that originate from northern, central, or southern Vietnamese dialects include:\nWhilst older slang has been used by previous generations, the prevalence of modern slang used by young people in Vietnam (as teenspeak) has made conversations more difficult for older generations to understand. This has become subject for debate. Some believe that incorporating teenspeak or internet slang in daily conversation among teenagers will affect the formality and cadence of their general speech. Others argue that it is not slang that is the problem, but rather the lack of communication techniques for the instant internet messaging era. They believe slang should not be dismissed, but instead, youth should be adequately informed to recognise when to use it and when it is inappropriate.\nWriting systems.\nAfter ending a millennium of Chinese rule in 939, the Vietnamese state adopted Literary Chinese (called \u6587\u8a00 or \u6f22\u6587 in Vietnamese) for official purposes.\nUp to the late 19th century (except for two brief interludes), all formal writing, including government business, scholarship and formal literature, was done in Literary Chinese, written with Chinese characters (). Although the writing system is now mostly in \"ch\u1eef\" \"Qu\u1ed1c ng\u1eef\" (Latin script), Chinese script known as ch\u1eef H\u00e1n in Vietnamese as well as ch\u1eef N\u00f4m (together, H\u00e1n-N\u00f4m) is still present in such activities such as Vietnamese calligraphy.\nCh\u1eef N\u00f4m.\nFrom around the 13th century, Vietnamese scholars used their knowledge of the Chinese script to develop the (lit.\u2009'Southern characters') script to record folk literature in Vietnamese. The script used Chinese characters to represent both borrowed Sino-Vietnamese vocabulary and native words with similar pronunciation or meaning. In addition, thousands of new compound characters were created to write Vietnamese words using a variety of methods, including phono-semantic compounds.\nFor example, in the opening lines of the classic poem \"The Tale of Ki\u1ec1u\",\nThe oldest example of an early form of the is found in a list of names in the Th\u00e1p Mi\u1ebfu Temple Inscription, dating from the early 13th century AD.\n writing reached its zenith in the 18th century when many Vietnamese writers and poets composed their works in , most notably Nguy\u1ec5n Du and H\u1ed3 Xu\u00e2n H\u01b0\u01a1ng (dubbed \"the Queen of N\u00f4m poetry\"). However, it was only used for official purposes during the brief H\u1ed3 and T\u00e2y S\u01a1n dynasties (1400\u20131406 and 1778\u20131802 respectively).\nA Vietnamese Catholic, Nguy\u1ec5n Tr\u01b0\u1eddng T\u1ed9, unsuccessfully petitioned the Court suggesting the adoption of a script for Vietnamese based on Chinese characters.\nVietnamese alphabet.\nA romanisation of Vietnamese was codified in the 17th century by the Avignonese Jesuit missionary Alexandre de Rhodes (1591\u20131660), based on works of earlier Portuguese missionaries, particularly Francisco de Pina, Gaspar do Amaral and Antonio Barbosa.\nIt reflects a \"Middle Vietnamese\" dialect close to the Hanoi variety as spoken in the 17th century. Its vowels and final consonants correspond most closely to northern dialects while its initial consonants are most similar to southern dialects. (This is not unlike how English orthography is based on the Chancery Standard of Late Middle English, with many spellings retained even after the Great Vowel Shift.)\nThe Vietnamese alphabet contains 29 letters, supplementing the Latin alphabet with an additional consonant letter (\"\u0111\") and 6 additional vowel letters (\"\u0103\", \"\u00e2/\u00ea/\u00f4\", \"\u01a1\", \"\u01b0\") formed with diacritics. The Latin letters \"f\", \"j\", \"w\" and \"z\" are not used.\nThe script also represents additional phonemes using ten digraphs (\"ch\", \"gh\", \"gi\", \"kh\", \"ng\", \"nh\", \"ph\", \"qu\", \"th\", and \"tr\") and a single trigraph (\"ngh\").\nFurther diacritics are used to indicate the tone of each syllable:\nThus, it is possible for diacritics to be stacked e.g. \u1ec3, combining letter with diacritic, \u00ea, with diacritic for tone, \u1ebb, to make \u1ec3.\nDespite the missionaries' creation of the alphabetic script, remained the dominant script in Vietnamese Catholic literature for more than 200 years. Starting from the late 19th century, the Vietnamese alphabet ( or 'national language script') gradually expanded from its initial usage in Christian writing to become more popular among the general public.\nThe romanised script became predominant over the course of the early 20th century, when education became widespread and a simpler writing system was found to be more expedient for teaching and communication with the general population. The French colonial administration sought to eliminate Chinese writing, Confucianism, and other Chinese influences from Vietnam. French superseded Literary Chinese in administration. Vietnamese written with the alphabet became required for all public documents in 1910 by issue of a decree by the French R\u00e9sident Sup\u00e9rieur of the protectorate of Tonkin. In turn, Vietnamese reformists and nationalists themselves encouraged and popularized the use of . By the middle of the 20th century, most writing was done in , which became the official script on independence.\nNevertheless, was still in use during the French colonial period and as late as World War II was still featured on banknotes, but fell out of official and mainstream use shortly thereafter. The education reform by North Vietnam in 1950 eliminated the use of and . Today, only a few scholars and some extremely elderly people are able to read or use it in Vietnamese calligraphy. Priests of the Jing minority in China (descendants of 16th-century migrants from Vietnam) use songbooks and scriptures written in in their ceremonies.\nComputer support.\nThe Unicode character set contains all Vietnamese characters and the Vietnamese currency symbol. On systems that do not support Unicode, many 8-bit Vietnamese code pages are available such as Vietnamese Standard Code for Information Interchange (VSCII) or Windows-1258. Where ASCII must be used, Vietnamese letters are often typed using the VIQR convention, though this is largely unnecessary with the increasing ubiquity of Unicode. There are many software tools that help type Roman-script Vietnamese on English keyboards, such as http:// and https:// on Windows, or http:// on Macintosh, with popular methods of https:// Vietnamese using Telex, VNI or VIQR input methods all included. Telex input method is often set as the default for many devices. Besides third-party software tools, operating systems such as Windows or macOS can also be installed with Vietnamese and Vietnamese keyboard, e.g. \"Vietnamese Telex\" in Microsoft Windows.\nDates and numbers writing formats.\nVietnamese speak date in the format \"day month year\". Each month's name is just the ordinal of that month appended after the word \"th\u00e1ng\", which means \"month\". Traditional Vietnamese, however, assigns other names to some months; these names are mostly used in the lunar calendar and in poetry.\nWhen written in the short form, \"DD/MM/YYYY\" is preferred.\n\"Example:\"\nThe Vietnamese prefer writing numbers with a comma as the decimal separator in lieu of dots, and either spaces or dots to group the digits. An example is 1 629,15 (one thousand six hundred twenty-nine point one five). Because a comma is used as the decimal separator, a semicolon is used to separate two numbers instead.\nLiterature.\n\"The Tale of Ki\u1ec1u\" is an epic narrative poem by the celebrated poet Nguy\u1ec5n Du, (&lt;templatestyles src=\"vi-nom/fonts.css\" /&gt;\u962e\u6538), which is often considered the most significant work of Vietnamese literature. It was originally written in ch\u1eef N\u00f4m (titled &lt;templatestyles src=\"vi-nom/fonts.css\" /&gt;\u65b7\u8178\u65b0\u8072) and is widely taught in Vietnam (in \"ch\u1eef Qu\u1ed1c ng\u1eef\" transliteration).\nLanguage variation.\nCurrently the Ngu\u1ed3n language is considered by the Vietnamese government to be a dialect of Vietnamese, however it is also considered a separate Vi\u1ec7t-M\u01b0\u1eddng language or the southernmost dialect of M\u01b0\u1eddng language. The Vietnamese language also has several mutually intelligible regional varieties:\nVietnamese has traditionally been divided into three dialect regions: North (45%), Central (10%), and South (45%). Michel Ferlus and Nguy\u1ec5n T\u00e0i C\u1ea9n found that there was a separate North-Central dialect for Vietnamese as well. The term \"Haut-Annam\" refers to dialects spoken from the northern Ngh\u1ec7 An Province to the southern (former) Th\u1eeba Thi\u00ean Province that preserve archaic features (like consonant clusters and undiphthongized vowels) that have been lost in other modern dialects.\nThe dialect regions differ mostly in their sound systems (see below) but also in vocabulary (including basic and non-basic vocabulary) and grammar. The North-Central and the Central regional varieties, which have a significant number of vocabulary differences, are generally less mutually intelligible to Northern and Southern speakers. There is less internal variation within the Southern region than the other regions because of its relatively late settlement by Vietnamese-speakers (around the end of the 15th century). The North-Central region is particularly conservative since its pronunciation has diverged less from Vietnamese orthography than the other varieties, which tend to merge certain sounds. Along the coastal areas, regional variation has been neutralized to a certain extent, but more mountainous regions preserve more variation. As for sociolinguistic attitudes, the North-Central varieties are often felt to be \"peculiar\" or \"difficult to understand\" by speakers of other dialects although their pronunciation fits the written language the most closely; that is typically because of various words in their vocabulary that are unfamiliar to other speakers (see the example vocabulary table below).\nThe large movements of people between North and South since the mid-20th century has resulted in a sizable number of Southern residents speaking in the Northern accent/dialect and, to a greater extent, Northern residents speaking in the Southern accent/dialect. After the Geneva Accords of 1954, which called for the temporary division of the country, about a million northerners (mainly from Hanoi, Haiphong, and the surrounding Red River Delta areas) moved south (mainly to Saigon and heavily to Bi\u00ean H\u00f2a and V\u0169ng T\u00e0u and the surrounding areas) as part of Operation Passage to Freedom. About 150,000 moved in the reverse direction (\"T\u1eadp k\u1ebft ra B\u1eafc\", literally \"regroup to the North\".)\nAfter the Fall of Saigon in 1975, Northern and North-Central speakers from the densely populated Red River Delta and the traditionally-poorer provinces of Ngh\u1ec7 An, H\u00e0 T\u0129nh, and Qu\u1ea3ng B\u00ecnh have continued to move south to look for better economic opportunities allowed by the new government's New Economic Zones, a program that lasted from 1975 to 1985. The first half of the program (1975\u20131980) resulted in 1.3 million people sent to the New Economic Zones (NEZs), most of which were relocated to the southern half of the country in previously uninhabited areas, and 550,000 of them were Northerners. The second half (1981\u20131985) saw almost 1 million Northerners relocated to the New Economic Zones. Government and military personnel from Northern and North-Central Vietnam are also posted to various locations throughout the country that were often away from their home regions. More recently, the growth of the free market system has resulted in increased interregional movement and relations between distant parts of Vietnam through business and travel. The movements have also resulted in some blending of dialects and more significantly have made the Northern dialect more easily understood in the South and vice versa. Most Southerners, when singing modern/old popular Vietnamese songs or addressing the public, do so in the standardized accent if possible, which uses the Northern pronunciation. That is true in both Vietnam and overseas Vietnamese communities.\nModern Standard Vietnamese is based on the Hanoi dialect. Nevertheless, the major dialects are still predominant in their respective areas and have also evolved over time with influences from other areas. Historically, accents have been distinguished by how each region pronounces the letters \"d\" ( in the Northern dialect and in the Central and Southern dialect) and \"r\" ( in the Northern dialect and in the Central and Southern dialects). Thus, the Central and the Southern dialects can be said to have retained a pronunciation closer to Vietnamese orthography and resemble how Middle Vietnamese sounded, in contrast to the modern Northern (Hanoi) dialect, which has since undergone pronunciation shifts. \nVocabulary.\nAlthough regional variations developed over time, most of those words can be used interchangeably and be understood well, albeit with more or less frequency then others or with slightly different but often discernible word choices and pronunciations. Some accents may mix, with words such \"d\u1ea1 v\u00e2ng\" combining \"d\u1ea1\" and \"v\u00e2ng,\" being created\".\"\nConsonants.\nThe syllable-initial \"ch\" and \"tr\" digraphs are pronounced distinctly in the North-Central, Central, and Southern varieties but are merged in Northern varieties, which pronounce them the same way. Many North-Central varieties preserve three distinct pronunciations for \"d\", \"gi\", and \"r\", but the Northern varieties have a three-way merger, and the Central and the Southern varieties have a merger of \"d\" and \"gi\" but keep \"r\" distinct. At the end of syllables, the palatals \"ch\" and \"nh\" have merged with the alveolars \"t\" and \"n\", which, in turn, have also partially merged with velars \"c\" and \"ng\" in the Central and the Southern varieties.\nIn addition to the regional variation described above, there is a merger of \"l\" and \"n\" in certain rural varieties in the North:\nVariation between \"l\" and \"n\" can be found even in mainstream Vietnamese in certain words. For example, the numeral \"five\" appears as \"n\u0103m\" by itself and in compound numerals like \"n\u0103m m\u01b0\u01a1i\" \"fifty\", but it appears as in \"fifteen\" (see Vietnamese grammar#Cardinal). In some northern varieties, the numeral appears with an initial \"nh\" instead of \"l\": \"twenty-five\", instead of the mainstream .\nThere is also a merger of \"r\" and \"g\" in certain rural varieties in the South:\nThe consonant clusters that were originally present in Middle Vietnamese (in the 17th century) have been lost in almost all modern Vietnamese varieties although they have been retained in other closely related Vietic languages. However, some speech communities have preserved some of these archaic clusters: \"sky\" is with a cluster in H\u1ea3o Nho (Y\u00ean M\u00f4, Ninh B\u00ecnh Province) but \"tr\u1eddi\" in Southern Vietnamese and in Hanoi Vietnamese (initial single consonants , respectively).\nTones.\nThere are six tones in Vietnamese, with phonetic differences between dialects, mostly in the pitch contour and phonation type.\nThe table above shows the pitch contour of each tone using Chao tone number notation in which 1 represents the lowest pitch, and 5 the highest; glottalization (creaky, stiff, harsh) is indicated with the \u27e8\u27e9 symbol; murmured voice with \u27e8\u27e9; glottal stop with \u27e8\u27e9; sub-dialectal variants are separated with commas. (See also the tone section below.)\nWord play.\nA basic form of word play in Vietnamese involves disyllabic words in which the last syllable forms the first syllable of the next word in the chain. This game involves two members versing each other until the opponent is unable to think of another word. For instance: \nAnother language game known as \"n\u00f3i l\u00e1i\" is used by Vietnamese speakers. \"N\u00f3i l\u00e1i\" involves switching, adding or removing the tones in a pair of words and may also involve switching the order of words or the first consonant and the rime of each word. Some examples:\nThe resulting transformed phrase often has a different meaning but sometimes may just be a nonsensical word pair. \"N\u00f3i l\u00e1i\" can be used to obscure the original meaning and thus soften the discussion of a socially sensitive issue, as with \"d\u1ea5m \u0111\u00e0i\" and \"ho\u1ea3ng ch\u01b0a\" (above), or when implied (and not overtly spoken), to deliver a hidden subtextual message, as with \"b\u1ed3i t\u00e2y\". Naturally, \"n\u00f3i l\u00e1i\" can be used for a humorous effect.\nAnother word game somewhat reminiscent of pig latin is played by children. Here a nonsense syllable (chosen by the child) is prefixed onto a target word's syllables, then their initial consonants and rimes are switched with the tone of the original word remaining on the new switched rime.\nThis language game is often used as a \"secret\" or \"coded\" language useful for obscuring messages from adult comprehension.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nResearch projects and data resources"}
{"id": "32512", "revid": "50865928", "url": "https://en.wikipedia.org/wiki?curid=32512", "title": "Vitamin", "text": "Nutrients required by organisms in small amounts\nVitamins are organic molecules (or a set of closely related molecules called vitamers) that are essential to an organism in small quantities for proper metabolic function. These essential nutrients cannot be synthesized in the organism in sufficient quantities for survival, and therefore must be obtained through the diet. For example, vitamin C can be synthesized by some species but not by others; it is not considered a vitamin in the first instance but is in the second. Most vitamins are not single molecules, but groups of related molecules called vitamers. For example, there are eight vitamers of vitamin E: four tocopherols and four tocotrienols.\nThe term \"vitamin\" does not include the three other groups of essential nutrients: minerals, essential fatty acids, and essential amino acids.\nMajor health organizations list thirteen vitamins:\nSome sources include a fourteenth, choline.\nVitamins have diverse biochemical functions. Vitamin A acts as a regulator of cell and tissue growth and differentiation. Vitamin D provides a hormone-like function, regulating mineral metabolism for bones and other organs. The B complex vitamins function as enzyme cofactors (coenzymes) or the precursors for them. Vitamins C and E function as antioxidants. Both deficient and excess intake of a vitamin can potentially cause clinically significant illness, although excess intake of water-soluble vitamins is less likely to do so.\nAll the vitamins were discovered between 1910 and 1948. Historically, when intake of vitamins from the diet was lacking, the results were vitamin deficiency diseases. Then, starting in 1935, commercially produced tablets of yeast-extract vitamin B complex and semi-synthetic vitamin C became available. This was followed in the 1950s by the mass production and marketing of vitamin supplements, including multivitamins, to prevent vitamin deficiencies in the general population. Governments have mandated the addition of some vitamins to staple foods such as flour or milk, referred to as food fortification, to prevent deficiencies. Recommendations for folic acid supplementation during pregnancy reduced the risk of infant neural tube defects.\nHistory.\nThe value of eating certain foods to maintain health was recognized long before vitamins were identified. The ancient Egyptians knew that feeding liver to a person may help with night blindness, an illness now known to be caused by a vitamin A deficiency. The advance of ocean voyages during the Age of Discovery resulted in prolonged periods without access to fresh fruits and vegetables, and made illnesses from vitamin deficiency common among ships' crews.\nIn 1747, the Scottish surgeon James Lind discovered that citrus foods helped prevent scurvy, a particularly deadly disease in which collagen is not properly formed, causing poor wound healing, bleeding of the gums, severe pain, and death. In 1753, Lind published his \"Treatise on the Scurvy\", which recommended using lemons and limes to avoid scurvy, which was adopted by the British Royal Navy. This led to the nickname \"limey\" for British sailors. However, during the 19th century, limes grown in the West Indies were substituted for lemons; these were subsequently found to be much lower in vitamin C. As a result, Arctic expeditions continued to be plagued by scurvy and other deficiency diseases. In the early 20th century, when Robert Falcon Scott made his two expeditions to the Antarctic, the prevailing medical theory was that scurvy was caused by \"tainted\" canned food.\nIn 1881, Russian medical doctor Nikolai Lunin studied the effects of scurvy at the University of Tartu. He fed mice an artificial mixture of all the separate constituents of milk known at that time, namely the proteins, fats, carbohydrates, and salts. The mice that received only the individual constituents died, while the mice fed by milk itself developed normally. He made a conclusion that \"a natural food such as milk must therefore contain, besides these known principal ingredients, small quantities of unknown substances essential to life.\" However, his conclusions were rejected by his advisor, Gustav von Bunge. A similar result by Cornelis Adrianus Pekelharing appeared in Dutch medical journal \"Nederlands Tijdschrift voor Geneeskunde\" in 1905, but it was not widely reported.\nIn East Asia, where polished white rice was the common staple food of the middle class, beriberi resulting from lack of vitamin B1 was endemic. In 1884, Takaki Kanehiro, a British-trained medical doctor of the Imperial Japanese Navy, observed that beriberi was endemic among low-ranking crew who often ate nothing but rice, but not among officers who consumed a Western-style diet. With the support of the Japanese navy, he experimented using crews of two battleships; one crew was fed only white rice, while the other was fed a diet of meat, fish, barley, rice, and beans. The group that ate only white rice documented 161 crew members with beriberi and 25 deaths, while the latter group had only 14 cases of beriberi and no deaths. This convinced Takaki and the Japanese Navy that diet was the cause of beriberi, but they mistakenly believed that sufficient amounts of protein prevented it. That diseases could result from some dietary deficiencies was further investigated by Christiaan Eijkman, who in 1897 discovered that feeding unpolished rice instead of the polished variety to chickens helped to prevent a kind of polyneuritis that was the equivalent of beriberi. The following year, Frederick Hopkins postulated that some foods contained \"accessory factors\"\u00a0\u2013 in addition to proteins, carbohydrates, fats \"etc.\"\u00a0\u2013 that are necessary for the functions of the human body.\n\"Vitamine\" to vitamin.\nIn 1910, the first vitamin complex was isolated by Japanese scientist Umetaro Suzuki, who succeeded in extracting a water-soluble complex of micronutrients from rice bran and named it aberic acid (later \"Orizanin\"). He published this discovery in a Japanese scientific journal. When the article was translated into German, the translation failed to state that it was a newly discovered nutrient, a claim made in the original Japanese article, and hence his discovery failed to gain publicity. In 1912 Polish-born biochemist Casimir Funk, working in London, isolated the same complex of micronutrients and proposed the complex be named \"vitamine\". It was later to be known as vitamin B3 (niacin), though he described it as \"anti-beri-beri-factor\" (which would today be called thiamine or vitamin B1). Funk proposed the hypothesis that other diseases, such as rickets, pellagra, coeliac disease, and scurvy could also be cured by vitamins. Max Nierenstein a friend and Reader of Biochemistry at Bristol University reportedly suggested the \"vitamine\" name (from \"vital amine\"). The name soon became synonymous with Hopkins' \"accessory factors\", and, by the time it was shown that not all vitamins are amines, the word was already ubiquitous. In 1920, Jack Cecil Drummond proposed that the final \"e\" be dropped to deemphasize the \"amine\" reference, hence \"vitamin\", after researchers began to suspect that not all \"vitamines\" (in particular, vitamin A) have an amine component.\nNobel Prizes for vitamin research.\nThe Nobel Prize for Chemistry for 1928 was awarded to Adolf Windaus \"for his studies on the constitution of the sterols and their connection with vitamins\", the first person to receive an award mentioning vitamins, even though it was not specifically about vitamin D.\nThe Nobel Prize in Physiology or Medicine for 1929 was awarded to Christiaan Eijkman and Frederick Gowland Hopkins for their contributions to the discovery of vitamins. Thirty-five years earlier, Eijkman had observed that chickens fed polished white rice developed neurological symptoms similar to those observed in military sailors and soldiers fed a rice-based diet, and that the symptoms were reversed when the chickens were switched to whole-grain rice. He called this \"the anti-beriberi factor\", which was later identified as vitamin B1, thiamine.\nIn 1930, Paul Karrer elucidated the correct structure for beta-carotene, the main precursor of vitamin A, and identified other carotenoids. Karrer and Norman Haworth confirmed Albert Szent-Gy\u00f6rgyi's discovery of ascorbic acid and made significant contributions to the chemistry of flavins, which led to the identification of lactoflavin. For their investigations on carotenoids, flavins and vitamins A and B2, they both received the Nobel Prize in Chemistry in 1937.\nIn 1931, Albert Szent-Gy\u00f6rgyi and a fellow researcher Joseph Svirbely suspected that \"hexuronic acid\" was actually vitamin C, and gave a sample to Charles Glen King, who proved its ability to counter scurvy in his long-established guinea pig scorbutic assay. In 1937, Szent-Gy\u00f6rgyi was awarded the Nobel Prize in Physiology or Medicine for his discovery. In 1943, Edward Adelbert Doisy and Henrik Dam were awarded the Nobel Prize in Physiology or Medicine for their discovery of vitamin K and its chemical structure.\nIn 1938, Richard Kuhn was awarded the Nobel Prize in Chemistry for his work on carotenoids and vitamins, specifically B2 and B6.\nFive people have been awarded Nobel Prizes for direct and indirect studies of vitamin B12: George Whipple, George Minot and William P. Murphy (1934), Alexander R. Todd (1957), and Dorothy Hodgkin (1964).\nIn 1967, George Wald, Ragnar Granit and Haldan Keffer Hartline were awarded the Nobel Prize in Physiology and Medicine \"...for their discoveries concerning the primary physiological and chemical visual processes in the eye.\" Wald's contribution was discovering the role vitamin A had in the process.\nHistory of promotional marketing.\nOnce discovered, vitamins were actively promoted in articles and advertisements in \"McCall's\", \"Good Housekeeping\", and other media outlets. Marketers enthusiastically promoted cod-liver oil, a source of vitamin D, as \"bottled sunshine\", and bananas as a \"natural vitality food\". They promoted foods such as yeast cakes, a source of B vitamins, on the basis of scientifically determined nutritional value, rather than taste or appearance. In 1942, when flour enrichment with nicotinic acid began, a headline in the popular press said \"Tobacco in Your Bread.\" In response, the Council on Foods and Nutrition of the American Medical Association approved of the Food and Nutrition Board's new names \"niacin\" and \"niacin amide\" for use primarily by non-scientists. It was thought appropriate to choose a name to dissociate nicotinic acid from nicotine, to avoid the perception that vitamins or niacin-rich food contains nicotine, or that cigarettes contain vitamins. The resulting name \"niacin\" was derived from \"nicotinic acid\" + \"vitamin\". Researchers also focused on the need to ensure adequate nutrition, especially to compensate for what was lost in the manufacture of processed foods. \nRobert W. Yoder is credited with first using the term \"vitamania\", in 1942, to describe the appeal of relying on nutritional supplements rather than on obtaining vitamins from a varied diet of foods. The continuing preoccupation with a healthy lifestyle led to an obsessive consumption of vitamins and multi-vitamins, the beneficial effects of which are questionable. As one example, in the 1950s, the Wonder Bread company sponsored the Howdy Doody television show, with host Buffalo Bob Smith telling the audience, \"Wonder Bread builds strong bodies 8 ways\", referring to the number of added nutrients.\nEtymology.\nThe term \"vitamin\" was derived from \"vitamine\", a portmanteau coined in 1912 by the biochemist Casimir Funk while working at the Lister Institute of Preventive Medicine. Funk created the name from \"vital\" and \"amine\", because it appeared that these organic micronutrient food factors that prevent beriberi and perhaps other similar dietary-deficiency diseases were required for life, hence \"vital\", and were chemical amines, hence \"amine\". This was true of thiamine, but after it was found that vitamin C and other such micronutrients were not amines, the word was shortened to \"vitamin\" in English.\nClassification.\nVitamins are classified as either water-soluble or fat-soluble. In humans there are 13 vitamins: 4 fat-soluble (A, D, E, and K) and 9 water-soluble (8 B vitamins and vitamin C). Water-soluble vitamins dissolve easily in water and, in general, are readily excreted from the body, to the degree that urinary output is a strong predictor of vitamin consumption. Because they are not as readily stored, more consistent intake is important. Fat-soluble vitamins are absorbed through the gastrointestinal tract with the help of lipids (fats). Vitamins A and D can accumulate in the body, which can result in dangerous hypervitaminosis. Fat-soluble vitamin deficiency due to malabsorption is of particular significance in cystic fibrosis.\nAnti-vitamins.\nAnti-vitamins are chemical compounds that inhibit the absorption or actions of vitamins. For example, avidin is a protein in raw egg whites that inhibits the absorption of biotin; it is deactivated by cooking. Pyrithiamine, a synthetic compound, has a molecular structure similar to thiamine, vitamin B1, and inhibits the enzymes that use thiamine.\nBiochemical functions.\nEach vitamin is typically used in multiple reactions, and therefore most have multiple functions.\nOn fetal growth and childhood development.\nVitamins are essential for the normal growth and development of a multicellular organism. Using the genetic blueprint inherited from its parents, a fetus develops from the nutrients it absorbs. It requires certain vitamins and minerals to be present at certain times. These nutrients facilitate the chemical reactions that produce among other things, skin, bone, and muscle. If there is serious deficiency in one or more of these nutrients, a child may develop a deficiency disease. Even minor deficiencies may cause permanent damage.\nOn adult health maintenance.\nOnce growth and development are completed, vitamins remain essential nutrients for the healthy maintenance of the cells, tissues, and organs that make up a multicellular organism; they also enable a multicellular life form to efficiently use chemical energy provided by food it eats, and to help process the proteins, carbohydrates, and fats required for cellular respiration.\nIntake.\nSources.\nFor the most part, vitamins are obtained from the diet, but some are acquired by other means: for example, microorganisms in the gut flora produce vitamin K and biotin; and one form of vitamin D is synthesized in skin cells when they are exposed to a certain wavelength of ultraviolet light present in sunlight. Humans can produce some vitamins from precursors they consume: for example, vitamin A is synthesized from beta carotene; and niacin is synthesized from the amino acid tryptophan. Vitamin C can be synthesized by some species but not by others. Vitamin B12 is the only vitamin or nutrient not available from plant sources. The Food Fortification Initiative lists countries which have mandatory fortification programs for vitamins folic acid, niacin, vitamin A and vitamins B1, B2 and B12.\nDeficient intake.\nThe body's stores for different vitamins vary widely; vitamins A, D, and B12 are stored in significant amounts, mainly in the liver, and an adult's diet may be deficient in vitamins A and D for many months and B12 in some cases for years, before developing a deficiency condition. However, vitamin B3 (niacin and niacinamide) is not stored in significant amounts, so stores may last only a couple of weeks. For vitamin C, the first symptoms of scurvy in experimental studies of complete vitamin C deprivation in humans have varied widely, from a month to more than six months, depending on previous dietary history that determined body stores.\nDeficiencies of vitamins are classified as either primary or secondary. A primary deficiency occurs when an organism does not get enough of the vitamin in its food. A secondary deficiency may be due to an underlying disorder that prevents or limits the absorption or use of the vitamin, due to a \"lifestyle factor\", such as smoking, excessive alcohol consumption, or the use of medications that interfere with the absorption or use of the vitamin. People who eat a varied diet are unlikely to develop a severe primary vitamin deficiency, but may be consuming less than the recommended amounts; a national food and supplement survey conducted in the US over 2003\u20132006 reported that over 90% of individuals who did not consume vitamin supplements were found to have inadequate levels of some of the essential vitamins, notably vitamins D and E.\nWell-researched human vitamin deficiencies involve thiamine (beriberi), niacin (pellagra), vitamin C (scurvy), folate (neural tube defects) and vitamin D (rickets). In much of the developed world these deficiencies are rare due to an adequate supply of food and the addition of vitamins to common foods. In addition to these classical vitamin deficiency diseases, some evidence has also suggested links between vitamin deficiency and a number of different disorders.\nExcess intake.\nSome vitamins have documented acute or chronic toxicity at larger intakes, which is referred to as hypertoxicity. The European Union and the governments of several countries have established tolerable upper intake levels (ULs) for those vitamins which have documented toxicity (see table). The likelihood of consuming too much of any vitamin from food is remote, but excessive intake (vitamin poisoning) from dietary supplements does occur. In 2016, overdose exposure to all formulations of vitamins and multi-vitamin/mineral formulations was reported by 63,931 individuals to the American Association of Poison Control Centers with 72% of these exposures in children under the age of five. In the US, analysis of a national diet and supplement survey reported that about 7% of adult supplement users exceeded the UL for folate and 5% of those older than age 50 years exceeded the UL for vitamin A.\nEffects of cooking.\nThe USDA has conducted extensive studies on the percentage losses of various nutrients from food types and cooking methods. Some vitamins may become more \"bio-available\" \u2013 that is, usable by the body \u2013 when foods are cooked. The table below shows whether various vitamins are susceptible to loss from heat\u2014such as heat from boiling, steaming, frying, etc. The effect of cutting vegetables can be seen from exposure to air and light. Water-soluble vitamins such as B and C dissolve into the water when a vegetable is boiled, and are then lost when the water is discarded.\nRecommended levels.\nIn setting human nutrient guidelines, government organizations do not necessarily agree on amounts needed to avoid deficiency or maximum amounts to avoid the risk of toxicity. For example, for vitamin C, recommended intakes range from 40\u00a0mg/day in India to 155\u00a0mg/day for the European Union. The table below shows U.S. Estimated Average Requirements (EARs) and Recommended Dietary Allowances (RDAs) for vitamins, PRIs for the European Union (same concept as RDAs), followed by what three government organizations deem to be the safe upper intake. RDAs are set higher than EARs to cover people with higher than average needs. Adequate Intakes (AIs) are set when there is not sufficient information to establish EARs and RDAs. Governments are slow to revise information of this nature. For the U.S. values, with the exception of calcium and vitamin D, all of the data date to 1997\u20132004.\nAll values are consumption per day:\nEAR US Estimated Average Requirements.\nRDA US Recommended Dietary Allowances; higher for adults than for children, and may be even higher for women who are pregnant or lactating.\nAI US and EFSA Adequate Intake; AIs established when there is not sufficient information to set EARs and RDAs.\nPRI Population Reference Intake is European Union equivalent of RDA; higher for adults than for children, and may be even higher for women who are pregnant or lactating. For Thiamin and Niacin the PRIs are expressed as amounts per MJ of calories consumed. MJ = megajoule = 239 food calories.\nUL or Upper Limit Tolerable upper intake levels.\nND ULs have not been determined.\nNE EARs have not been established.\nSupplementation.\nIn those who are otherwise healthy, there is little evidence that supplements have any benefits with respect to cancer or heart disease. Vitamin A and E supplements not only provide no health benefits for generally healthy individuals, but they may increase mortality, though the two large studies that support this conclusion included smokers for whom it was already known that beta-carotene supplements can be harmful. A 2018 meta-analysis found no evidence that intake of vitamin D or calcium for community-dwelling elderly people reduced bone fractures.\nEurope has regulations that define limits of vitamin (and mineral) dosages for their safe use as dietary supplements. Most vitamins that are sold as dietary supplements are not supposed to exceed a maximum daily dosage referred to as the tolerable upper intake level (UL or Upper Limit). Vitamin products above these regulatory limits are not considered supplements and should be registered as prescription or non-prescription (over-the-counter drugs) due to their potential side effects. The European Union, United States and Japan establish ULs.\nDietary supplements often contain vitamins, but may also include other ingredients, such as minerals, herbs, and botanicals. Scientific evidence supports the benefits of dietary supplements for persons with certain health conditions. In some cases, vitamin supplements may have unwanted effects, especially if taken before surgery, with other dietary supplements or medicines, or if the person taking them has certain health conditions. They may also contain levels of vitamins many times higher, and in different forms, than one may ingest through food.\nGovernmental regulation.\nMost countries place dietary supplements in a special category under the general umbrella of \"foods\", not drugs. As a result, the manufacturer, and not the government, has the responsibility of ensuring that its dietary supplement products are safe before they are marketed. Regulation of supplements varies widely by country. In the United States, a dietary supplement is defined under the Dietary Supplement Health and Education Act of 1994. There is no FDA approval process for dietary supplements, and no requirement that manufacturers prove the safety or efficacy of supplements introduced before 1994. The Food and Drug Administration must rely on its Adverse Event Reporting System to monitor adverse events that occur with supplements.\nIn 2007, the US Code of Federal Regulations (CFR) Title 21, part III took effect, regulating Good Manufacturing Practices (GMPs) in the manufacturing, packaging, labeling, or holding operations for dietary supplements. Even though product registration is not required, these regulations mandate production and quality control standards (including testing for identity, purity and adulterations) for dietary supplements. In the European Union, the Food Supplements Directive requires that only those supplements that have been proven safe can be sold without a prescription. For most vitamins, pharmacopoeial standards have been established. In the United States, the United States Pharmacopeia (USP) sets standards for the most commonly used vitamins and preparations thereof. Likewise, monographs of the European Pharmacopoeia (Ph.Eur.) regulate aspects of identity and purity for vitamins on the European market.\nNaming.\nThe reason that the set of vitamins skips directly from E to K is that the vitamins corresponding to letters F\u2013J were either reclassified over time, discarded as false leads, or renamed because of their relationship to vitamin\u00a0B, which became a complex of vitamins.\nThe Danish-speaking scientists who isolated and described vitamin\u00a0K (in addition to naming it as such) did so because the vitamin is intimately involved in the coagulation of blood following wounding (from the Danish word \"Koagulation\"). At the time, most (but not all) of the letters from F through to J were already designated, so the use of the letter K was considered quite reasonable. The table \"Nomenclature of reclassified vitamins\" lists chemicals that had previously been classified as vitamins, as well as the earlier names of vitamins that later became part of the B-complex.\nThe missing numbered B vitamins were reclassified or determined not to be vitamins. For example, B9 is folic acid and five of the folates are in the range B11 through B16. Others, such as PABA (formerly B10), are biologically inactive, toxic, or with unclassifiable effects in humans, or not generally recognised as vitamins by science, such as the highest-numbered, which some naturopath practitioners call B21 and B22. There are also lettered B substances (e.g., Bm) listed at B vitamins that are not recognized as vitamins. There are other \"D vitamins\" now recognised as other substances, which some sources of the same type number up to D7. The controversial cancer treatment laetrile was at one point lettered as vitamin B17. There appears to be no consensus on the existence of substances that may have at one time been named as vitamins Q, R, T, V, W, X, Y or Z.\n\"Vitamin N\" is a term popularized for the mental health benefits of spending time in nature settings. \"Vitamin I\" is slang among athletes for frequent/daily consumption of ibuprofen as a pain-relieving treatment.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32513", "revid": "19868248", "url": "https://en.wikipedia.org/wiki?curid=32513", "title": "Viroid", "text": "Pathogenic small single-stranded circular RNA\nViroids are small single-stranded, circular RNAs that are infectious pathogens. Unlike viruses, they have no protein coating. All known viroids are inhabitants of angiosperms (flowering plants), and most cause diseases, whose respective economic importance to humans varies widely. A recent metatranscriptomics study suggests that the host diversity of viroids and viroid-like elements is broader than previously thought and is not limited to plants, encompassing even the prokaryotes.\nThe first discoveries of viroids in the 1970s triggered the historically third major extension of the biosphere\u2014to include smaller lifelike entities\u2014after the discoveries in 1675 by Antonie van Leeuwenhoek (of the \"subvisible\" microorganisms) and in 1892\u20131898 by Dmitri Iosifovich Ivanovsky and Martinus Beijerinck (of the \"submicroscopic\" viruses). \nThe unique properties of viroids have been recognized by the International Committee on Taxonomy of Viruses, in creating a new order of subviral agents.\nThe first recognized viroid, the pathogenic agent of the potato spindle tuber disease, was discovered, initially molecularly characterized, and named by Theodor Otto Diener, plant pathologist at the U.S Department of Agriculture's Research Center in Beltsville, Maryland, in 1971. This viroid is now called potato spindle tuber viroid, abbreviated PSTVd. The \"Citrus exocortis viroid\" (CEVd) was discovered soon thereafter, and together understanding of PSTVd and CEVd shaped the concept of the viroid.\nAlthough viroids are composed of nucleic acid, they do not code for any protein. The viroid's replication mechanism uses RNA polymerase II, a host cell enzyme normally associated with synthesis of messenger RNA from DNA, which instead catalyzes \"rolling circle\" synthesis of new RNA using the viroid's RNA as a template. Viroids are often ribozymes, having catalytic properties that allow self-cleavage and ligation of unit-size genomes from larger replication intermediates.\nDiener initially hypothesized in 1989 that viroids may represent \"living relics\" from the widely assumed, ancient, and non-cellular RNA world, and others have followed this conjecture. Following the discovery of retrozymes, it has been proposed that viroids and other viroid-like elements may derive from this newly found class of retrotransposon.\nTaxonomy.\nAs of 2024[ [update]]:\nTransmission and replication.\nViroids are only known to infect plants, and infectious viroids can be transmitted to new plant hosts by aphids, by cross contamination following mechanical damage to plants as a result of horticultural or agricultural practices, or from plant to plant by leaf contact. Upon infection, viroids replicate in the nucleus (\"Pospiviroidae\") or chloroplasts (\"Avsunviroidae\") of plant cells in three steps through an RNA-based mechanism. They require RNA polymerase II, a host cell enzyme normally associated with synthesis of messenger RNA from DNA, which instead catalyzes \"rolling circle\" synthesis of new RNA using the viroid as template.\nUnlike plant viruses which produce movement proteins, viroids are entirely passive, relying entirely on the host. This is useful in the study of RNA kinetics in plants.\nRNA silencing.\nThere has long been uncertainty over how viroids induce symptoms in plants without encoding any protein products within their sequences. Evidence suggests that RNA silencing is involved in the process. First, changes to the viroid genome can dramatically alter its virulence. This reflects the fact that any siRNAs produced would have less complementary base pairing with target messenger RNA. Secondly, siRNAs corresponding to sequences from viroid genomes have been isolated from infected plants. Finally, transgenic expression of the noninfectious hpRNA of potato spindle tuber viroid develops all the corresponding viroid-like symptoms. This indicates that when viroids replicate via a double stranded intermediate RNA, they are targeted by a dicer enzyme and cleaved into siRNAs that are then loaded onto the RNA-induced silencing complex. The viroid siRNAs contain sequences capable of complementary base pairing with the plant's own messenger RNAs, and induction of degradation or inhibition of translation causes the classic viroid symptoms.\nViroid-like elements.\nViroid-like elements are pieces of covalently closed circular (ccc) RNA molecules that do not share the viroid's lifecycle. The category encompasses satellite RNAs (including small plant satRNAs \"virusoids\", fungal \"ambivirus\", and the much larger HDV-like \"Ribozyviria\") and \"retroviroids\". Most of them also carry some type of a ribozyme.\nViroid-like satellite RNAs.\nViroid-like satellite RNAs are infectious circular RNA molecules that depend on a carrier virus to reproduce, being carried in their capsids. Like Avsunviroidae, however, they are capable of self-clevage.\nAmbiviruses.\nIn the 2020s, mobile genetic elements called ambiviruses were discovered in fungi. Their RNA genomes are circular, circa 5 kb in length. One of at least two open reading frames encodes a viral RNA-directed RNA polymerase, that firmly places \"ambiviruses\" into ribovirian kingdom \"Orthornavirae\"; a separate phylum \"Ambiviricota\" has been established since the 2023 ICTV Virus Taxonomy Release because of the unique features of encoding RNA-directed RNA polymerases but also having divergent ribozymes in various combinations in both sense and antisense orientation \u2013 the detection of circular forms in both sense orientations suggest that \"ambiviruses\" use rolling circle replication for propagation.\nRetroviroids.\n\"Retroviroids\", more formally \"retroviroid-like elements\", are viroid-like circular RNA sequences that are also found with homologous copies in the DNA genome of the host. The only types found are closely related to the original \"carnation small viroid-like RNA\" (CarSV). These elements may act as a homologous substrate upon which recombination may occur and are linked to double-stranded break repair.\nThese elements are dubbed retroviroids as the homologous DNA is generated by reverse transcriptase that is encoded by retroviruses. They are neither true viroids nor viroid-like satellite RNAs: there is no extracellular form of these elements; instead, they are spread only through pollen or egg-cells. They appear to co-occur with a pararetrovirus.\nObelisks.\nAfter applying metatranscriptomics \u2013 the computer-aided search for RNA sequences and their analysis \u2013 biologists reported in January 2024 the discovery of \"obelisks\", a new class of viroid-like elements, and \"oblins\", their related group of proteins, in the human microbiome. Given that the RNA sequences recovered do not have homologies in any other known life form, the researchers suggest that the obelisks are distinct from viruses, viroids and viroid-like entities, and thus form an entirely new class of organisms.\nRNA world hypothesis.\nDiener's 1989 hypothesis had proposed that the unique properties of viroids make them more plausible macromolecules than introns, or other RNAs considered in the past as possible \"living relics\" of a hypothetical, pre-cellular RNA world. If so, viroids have assumed significance beyond plant virology for evolutionary theory, because their properties make them more plausible candidates than other RNAs to perform crucial steps in the evolution of life from inanimate matter (abiogenesis). Diener's hypothesis was mostly forgotten until 2014, when it was resurrected in a review article by Flores et al., in which the authors summarized Diener's evidence supporting his hypothesis as:\nThe presence, in extant cells, of RNAs with molecular properties predicted for RNAs of the RNA world constitutes another powerful argument supporting the RNA world hypothesis. However, the origins of viroids themselves from this RNA world has been cast into doubt by several factors, including the discovery of retrozymes (a family of retrotransposon likely representing their ancestors) and their complete absence from organisms outside of the plants (especially their complete absence from prokaryotes including bacteria and archaea). However, recent studies suggest that the diversity of viroids and others viroid-like elements is broader than previously thought and that it would not be limited to plants, encompassing even the prokaryotes. Matches between viroid cccRNAs and CRISPR spacers suggest that some of them might replicate in prokaryotes.\nControl.\nThe development of tests based on ELISA, PCR, and nucleic acid hybridization has allowed for rapid and inexpensive detection of known viroids in biosecurity inspections, phytosanitary inspections, and quarantine.\nHistory.\nIn the 1920s, symptoms of a previously unknown potato disease were noticed in New York and New Jersey fields. Because tubers on affected plants become elongated and misshapen, they named it the potato spindle tuber disease.\nThe symptoms appeared on plants onto which pieces from affected plants had been budded\u2014indicating that the disease was caused by a transmissible pathogenic agent. A fungus or bacterium could not be found consistently associated with symptom-bearing plants, however, and therefore, it was assumed the disease was caused by a virus. Despite numerous attempts over the years to isolate and purify the assumed virus, using increasingly sophisticated methods, these were unsuccessful when applied to extracts from potato spindle tuber disease-afflicted plants.\nIn 1971, Theodor O. Diener showed that the agent was not a virus, but a totally unexpected novel type of pathogen, 1/80th the size of typical viruses, for which he proposed the term \"viroid\". Parallel to agriculture-directed studies, more basic scientific research elucidated many of viroids' physical, chemical, and macromolecular properties. Viroids were shown to consist of short stretches (a few hundred nucleotides) of single-stranded RNA and, unlike viruses, did not have a protein coat. Viroids are extremely small, from 246 to 467 nucleotides, smaller than other infectious plant pathogens; they thus consist of fewer than 10,000 atoms. In comparison, the genomes of the smallest known viruses capable of causing an infection by themselves are around 2,000 nucleotides long.\nIn 1976, Sanger et al. presented evidence that potato spindle tuber viroid is a \"single-stranded, covalently closed, circular RNA molecule, existing as a highly base-paired rod-like structure\"\u2014believed to be the first such molecule described. Circular RNA, unlike linear RNA, forms a covalently closed continuous loop, in which the 3' and 5' ends present in linear RNA molecules have been joined. Sanger et al. also provided evidence for the true circularity of viroids by finding that the RNA could not be phosphorylated at the 5' terminus. In other tests, they failed to find even one free 3' end, which ruled out the possibility of the molecule having two 3' ends. Viroids thus are true circular RNAs.\nThe single-strandedness and circularity of viroids was confirmed by electron microscopy, The complete nucleotide sequence of potato spindle tuber viroid was determined in 1978. PSTVd was the first pathogen of a eukaryotic organism for which the complete molecular structure has been established. Over thirty plant diseases have since been identified as viroid-, not virus-caused, as had been assumed.\nFour additional viroids or viroid-like RNA particles were discovered between 2009 and 2015.\nIn 2014, \"New York Times\" science writer Carl Zimmer published a popularized piece that mistakenly credited Flores et al. with the virioid - RNA world hypothesis' original conception.\nIn January 2024, biologists reported the discovery of \"obelisks\", a new class of viroid-like elements, and \"oblins\", their related group of proteins, in the human microbiome.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32516", "revid": "41163249", "url": "https://en.wikipedia.org/wiki?curid=32516", "title": "Vladimir Vernadsky", "text": "Soviet geochemist (1863\u20131945)\nVladimir Ivanovich Vernadsky (), also spelt Volodymyr Ivanovych Vernadsky (; 12 March\u00a0[O.S. 28 February]\u00a01863 \u2013 6 January 1945), was a Russian, Ukrainian, and Soviet mineralogist and geochemist who is considered one of the founders of geochemistry, biogeochemistry, and radiogeology. He was one of the founders and the first president of the Ukrainian Academy of Sciences (now National Academy of Sciences of Ukraine). Vladimir Vernadsky is most noted for his 1926 book \"The Biosphere\" in which he inadvertently worked to popularize Eduard Suess's 1875 term biosphere, by hypothesizing that life is the geological force that shapes the earth. In 1943 he was awarded the Stalin Prize. Vernadsky's portrait is depicted on the Ukrainian \u20b41,000 hryvnia banknote.\nEarly life.\nVernadsky was born in Saint Petersburg, Russian Empire, on 12 March\u00a0[O.S. 28 February]\u00a01863 in the family of the native Kyiv residents Russian Imperial economist Ivan Vernadsky and Anna Konstantinovich, who came from an old Russia noble family. According to family legend, his father's ancestors were Zaporozhian Cossacks. Ivan Vernadsky had been a professor of political economy in Kyiv at the St. Vladimir University before moving to Saint Petersburg; then he was an Active State Councillor and worked in the Governing Senate in St. Petersburg. Ivan was a Russian Imperial economist and the editor of a liberal journal which opposed censorship and serfdom, while Anna Konstantinovic was a music instructor as well as a Russian noblewoman of Ukrainian Cossack descent.\"\"Vladimir's mother was a Russian noblewoman.\nIn 1868 his family relocated to Kharkiv, where he continued his education, and in 1873 he entered the Kharkiv provincial gymnasium. His father gifted scientific books that including The Origin of Species by Charles Darwin and Cosmos by Alexander Humboldt, which was his introduction to early evolutionary theory in relation to nature. Along with the books, his uncle Evgraf Korolenko, a retired civil servant, mentored Vernadsky, taking him on long walks under the stars to discuss the earth and the cosmos. This introduction turned Vernadsky's attention from humanities to science.\nVernadsky graduated from Saint Petersburg State University in 1885. As the position of mineralogist in Saint Petersburg State University was vacant, and Vasily Dokuchaev, a soil scientist, and Alexey Pavlov, a geologist, had been teaching Mineralogy for a while, Vernadsky chose to enter Mineralogy.\nHe made the decision to fill this role because the proximity to his childhood home allowed him to care for his recently widowed mother. This influenced Vernadsky's decision to specialize in mineralogy. Vernadsky went on to study as faculty at Saint Petersburg State University in the Physics-Mathematics program where he specialized in crystallography and mineralogy. Vernadsky graduated from Saint Petersburg State University in 1885 with a thesis on isomorphous mixtures in minerals.\nIn 1886, Vernadsky married a woman named Natalya E. Staritskaya, although there is not much documented information on her as an individual. He wrote to his wife Nataliia on 20 June 1888 from Switzerland:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;To collect facts for their own sake, as many now gather facts, without a program, without a question to answer or a purpose, is not interesting. However, there is a task which someday the human mind will solve, and which is extremely interesting. Minerals are remains of those chemical reactions which took place at various times on earth; these reactions take place according to laws which are not always known to us, but which, we are allowed to think, are closely tied to general changes which the earth has undergone as a planet. The task is to connect the various phases of changes undergone by the earth with the general laws of celestial mechanics. In 1888\u20131890, he traveled through Europe, studying the museums of Paris and London, and worked in Munich and Paris. During this time, he studied in Germany, France, England, Switzerland, and Italy and studying the museums of Paris and London, and worked in Munich and Paris. While abroad, he studied under Henry Le Chatelier, Paul Von Groth, and Ferdinand Andr\u00e9 Fouqu\u00e9, supporting his decision to focus his studies in crystallography and minerology. While trying to find a topic for his doctorate, he first went to Naples to study under crystallographer Arcangelo Scacchi, who was senile by that time. Scacchi's condition led Vernadsky to go to Germany to study under Paul Groth, curator of minerals in the Deutsches Museum in Munich. Vernadsky learned to use Groth's modern equipment, which included a machine to study the optical, thermal, elastic, magnetic and electrical properties of crystals. He also gained access to the physics lab of Leonhard Sohncke (Direktor, , 1883\u20131886; Professor der Physik an der Technischen Hochschule M\u00fcnchen 1886\u20131897), who was studying crystallisation during that period. In the year 1888, Vernadsky had the opportunity to attend the 4th International Geological Congress held in London before moving on to study under Fouqu\u00e9 and Chatelier in Paris. In 1889, when Dokuchaev declined to attend, Vernadsky took over the World Exhibition in Paris on his behalf. His exhibit featured a display on Russian soils where he earned a gold medal for his organization and presentation.\nIn his childhood, his father had a huge influence on his development, he very carefully and consistently engaged in the upbringing and education of his son. It was he who instilled in Volodymyr interest and love for the Ukrainian people, their history and culture. The future scientist recalled that before moving from Kharkiv to St. Petersburg, he and his father were abroad and in Milan, they read about a circular in Pyotr Lavrov's newspaper \"Forward\" that forbade printing in Ukrainian in Russia. In his memoirs, he wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This made a huge impression on my father, and the conversations related to this had a strong effect on me at the time. My father told the history of Ukraine in a completely different way than it was taught in the gymnasium. He often mentioned that Petersburg was built on the bones of Ukrainians (Cossacks from Ivan Mazepa's regiments built Petersburg). After returning to St. Petersburg, I tried to familiarize myself with Ukrainian literature. In his father's library, he found scattered issues of Osnovy and other Ukrainian publications. Obtained Ukrainian books from second-hand booksellers, and received some from abroad. He asked his father in detail about Shevchenko, Kulish, Maksymovich, Kvitka-Osnovianenko, whom he knew personally, as well as about the Cyril-Methodiev brotherhood, about Kostomarov, etc.\nIn St. Petersburg, a 15-year-old boy noted in his diary on 29 March 1878:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Ukrainians are terribly oppressed. Even in Austria, Drahomanov was not allowed to publish a newspaper in Ukrainian. In Russia, it is completely forbidden to print books in my native language. During the holidays, I will take care of her with all respect. In Kyiv, when a portrait of Shevchenko is seen in a house, it is taken away.\nPolitical activities.\nVernadsky participated in the First General Congress of the zemstvos, held in Petersburg on the eve of the 1905 Russian Revolution to discuss how best to pressure the government to the needs of the Russian society; became a member of the liberal Constitutional Democratic Party (KD); and served in parliament, resigning to protest the Tsar's proroguing of the Duma. He served as professor and later as vice rector of Moscow University, from which he also resigned in 1911 in protest over the government's reactionary policies .\nFollowing the advent of the First World War, his proposal for the establishment of the Commission for the Study of the Natural Productive Forces (KEPS) was adopted by the Imperial Academy of Sciences in February 1915. He published \"War and the Progress of Science\" where he stressed the importance of science as regards to its contribution to the war effort:\nAfter the war of 1914\u20131915 we will have to make known and accountable the natural productive forces of our country, i.e. first of all to find means for broad scientific investigations of Russia's nature and for the establishment of a network of well-equipped research laboratories, museums and institutions ... This is no less necessary than the need for an improvement in the conditions of our civil and political life, which is so acutely perceived by the entire country.\nAfter the February Revolution of 1917, he served on several commissions of agriculture and education of the provisional government, including as assistant minister of education.\nVladimir Vernadsky had dual \"Russian\u2013Ukrainian\" identity and considered the Ukrainian culture as part of Russian imperial culture, and even declined to become a Ukrainian citizen in 1918.\nScientific activities.\nIn 1898, Vernadsky moved to Moscow in order to teach at Moscow University. As head of the mineralogical office, he had the opportunity to restore the Freyesleben collection where he fully cataloged and systemized it. During his work as a professor at Moscow University, he conducted 65 field excursions across Russia with students to Siberia, Urals, Caucasus, and Crimea.\nThrough his work, Vernadsky first popularized the concept of the noosphere and deepened the idea of the biosphere to the meaning largely recognized by today's scientific community. The word 'biosphere' was invented by Austrian geologist Eduard Suess, whom Vernadsky met in 1911.\nIn Vernadsky's theory of the Earth's development, the noosphere is the third stage in the earth's development, after the geosphere (inanimate matter) and the biosphere (biological life). Just as the emergence of life fundamentally transformed the geosphere, the emergence of human cognition will fundamentally transform the biosphere. In this theory, the principles of both life and cognition are essential features of the Earth's evolution and must have been implicit in the earth all along. \nVernadsky's visionary pronouncements were not widely accepted in the West. However, he was one of the first scientists to recognize that the oxygen, nitrogen and carbon dioxide in the Earth's atmosphere result from biological processes. During the 1920s he published works arguing that living organisms could reshape the planets as surely as any physical force. Vernadsky was an important pioneer of the scientific bases for the environmental sciences.\nVernadsky was a member of the Russian and Soviet Academies of Sciences since 1912 and was a founder and first president of the Ukrainian Academy of Sciences in Kyiv, Ukraine (1918). He was a founder of the National Library of Ukrainian State and worked closely with the Tavrida University in Crimea. During the Russian Civil War, he hosted gatherings of the young intellectuals who later founded the \u00e9migr\u00e9 Eurasianism movement.\nIn the late 1930s and early 1940s Vernadsky played an early advisory role in the Soviet atomic bomb project, as one of the most forceful voices arguing for the exploitation of nuclear power, the surveying of Soviet uranium sources, and having nuclear fission research conducted at his Radium Institute. He died, however, before a full project was pursued.\nOn religious views, Vernadsky was an atheist. He was interested in Hinduism and Rig Veda.\nVernadsky's son George Vernadsky (1887\u20131973) emigrated to the United States where he published numerous books on medieval and modern Russian history.\nThe National Library of Ukraine, the Tavrida National University in Crimea and many streets and avenues in Ukraine and Russia are named in honor of Vladimir Vernadsky.\nUNESCO sponsored an international scientific conference, \"Globalistics-2013\", at Moscow State University on 23\u201325 October 2013, in honor of Vernadsky's 150th birthday.\nImpact of early and later life experiences on scientific theory.\nVernadsky was born into a Ukrainian family of intellects and progressives. His grandfather was a military doctor, who was honored by Napoleon for his humanitarianism, and his father freed his serfs before serfdom was officially abolished. Throughout Vernadsky's life, there were many influential moments that led to many of his important philosophical and scientific beliefs that paved the way for the biogeochemistry, minerology, and chemistry that exists today. Vernadsky's father's background in politics encouraged Vernadsky's own interests in humanistic and interdisciplinary perspectives in scientific fields, and was a big reason why this was his first choice of study before he made his way to minerology. In addition to his father's background, the gift of the scientific books from him to Vernadsky was also his first introduction to evolutionary theory and the interconnectedness of nature. His upbringing was immersed in his Ukrainian culture, as he was surrounded by the music from his mother, and the intellectual discussion with his uncle and father. While at school at St. Petersburg, Vernadsky was engaged in student activism and was even a part of the Priyutino Brotherhood, which emphasized ethical living and societal reform.\nWhen Vernadsky was teaching at Moscow University in 1891, the link between biology and biochemistry was made to inspire his theories in the biogeochemistry realm. His work with various collections, such as the Freyesleben collection, helped to advance the way that collections had been previously organized. His methods transitions this organization from a description classification, to a mechanism and deeper chemical explanation classification. This new organization strategy emphasized Vernadsky's personal view that the Earth's crust is a massive chemical laboratory forming minerals.\nVernadksy was not shy to participating in politics. Close friendships with those involved in revolutionary groups, such as those of Ivan Pokhitonov, also helped to expose him to different political ideas and underground literature. Vernadsky was in the opinion that society could be improved through science and that it must not be kept hidden and isolated from the public. His philosophies reflected this sentiment and they smoothly integrated natural science, philosophy, and ethics together, promoting freedom of thought and intellectual change. Throughout his life and career, Vernadsky emphasized this idea of sharing scientific thought and knowledge as he remained deeply connected to different universities with the main goal and supporting and mentoring young scientists. He was in the strongest belief that the key to national progress and reform was through the support of academic institutions.\nLegacy.\nOn 25 October 2019 the National Bank of Ukraine put in circulation a \u20b41,000 hryvnia banknote with Vernadsky's portrait.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32517", "revid": "33540580", "url": "https://en.wikipedia.org/wiki?curid=32517", "title": "VAX", "text": "Line of computers sold by Digital Equipment Corporation\nVAX (an acronym for virtual address extension) is a series of computers featuring a 32-bit instruction set architecture (ISA) and virtual memory that was developed and sold by Digital Equipment Corporation (DEC) in the late 20th century. The VAX-11/780, introduced October 25, 1977, was the first of a range of popular and influential computers implementing the VAX ISA. The VAX family was a huge success for DEC, with the last members arriving in the early 1990s. The VAX was succeeded by the DEC Alpha, which included several features from VAX machines to make porting from the VAX easier.\nDescription.\nVAX was designed by Digital Equipment Corporation (DEC) as a successor to the 16-bit PDP-11, one of the most successful minicomputers in history with approximately 600,000 units sold. The system was designed to offer backward compatibility with the PDP-11 while extending the memory to a full 32-bit implementation and adding demand paged virtual memory. The name VAX refers to its \"virtual address extension\" concept that allowed programs to make use of this newly available memory while still being compatible with unmodified user mode PDP-11 code. The name \"VAX-11\", used on early models, was chosen to highlight this capability. The VAX ISA is considered a complex instruction set computer (CISC) design.\nDEC quickly dropped the \u221211 branding as PDP-11 compatibility was no longer a major concern. The line expanded to both high-end mainframes like the VAX 9000 as well as to the workstation-scale systems like the VAXstation series. The VAX family ultimately contained ten distinct designs and over 100 individual models in total. All of them were compatible with each other and normally ran the VAX/VMS operating system.\nVAX has been perceived as the quintessential CISC ISA, with its very large number of assembly language programmer-friendly addressing modes and machine instructions, highly orthogonal instruction set architecture, and instructions for complex operations such as queue insertion or deletion, number formatting, and polynomial evaluation.\nName.\nThe name \"VAX\" originated as an acronym for \"virtual address extension\", both because the VAX was seen as a 32-bit extension of the 16-bit PDP-11 and because it was (after Prime Computer) an early adopter of virtual memory to manage this larger address space.\nEarly versions of the VAX processor implement a \"compatibility mode\" that emulates many of the PDP-11's instructions, giving it the 11 in VAX-11 to highlight this compatibility. Later versions offloaded the compatibility mode and some of the less used CISC instructions to emulation in the operating system software.\nInstruction set.\nThe VAX instruction set was designed to be powerful, orthogonal, and \"compiler-friendly\". When it was introduced, many programs were written in assembly language, so having a \"programmer-friendly\" instruction set was important. In time, as more programs were written in high-level programming languages, the instruction set became less visible, and the only ones much concerned about it were compiler writers.\nOne unusual aspect of the VAX instruction set is the presence of register masks at the start of each subprogram. These are arbitrary bit patterns that specify, when control is passed to the subprogram, which registers are to be preserved. On most architectures, it is up to the compiler to produce instructions to save out the needed data, typically using the call stack for temporary storage. On the VAX, with 16 registers, this might require 16 instructions to save the data and another 16 to restore it. Using the mask, a single 16-bit value performs the same operations internally in hardware, saving time and memory.\nSince register masks are a form of data embedded within the executable code, they can make linear parsing of the machine code difficult. This can complicate optimization techniques that are applied on machine code.\nOperating systems.\nThe native VAX operating system is Digital's VAX/VMS (renamed to OpenVMS in 1991 or early 1992 when it was ported to Alpha, modified to comply with POSIX standards, and branded as compliant with XPG4 by the X/Open consortium). The company wanted to avoid VAX having many incompatible operating systems like PDP-11; VAX and VMS were \"engineered concurrently\" to take maximum advantage of each other, as was the initial implementation of the VAXcluster facility.\nDuring the 1980s, a hypervisor for the VAX architecture named \"VMM\" (Virtual Machine Monitor), also known as the \"VAX Security Kernel\", was developed at Digital with the aim of allowing multiple isolated instances of VMS and ULTRIX to be run on the same hardware. VMM was intended to achieve TCSEC A1 compliance. By the late 1980s, it was operational on VAX 8000 series hardware, but was abandoned before release to customers.\nOther VAX operating systems have included various releases of Berkeley Software Distribution (BSD) UNIX up to 4.3BSD, Ultrix-32, VAXELN, and Xinu. More recently, NetBSD and OpenBSD have supported various VAX models and some work has been done on porting Linux to the VAX architecture. OpenBSD discontinued support for the architecture in September 2016.\nHistory.\nVAX design began in 1975, about when DEC recognized that PDP-11's 16-bit architecture was too limiting in the amount of addressable memory. The first VAX model sold was the VAX-11/780, introduced on October 25, 1977 at DEC's annual shareholder meeting. Bill Strecker, C. Gordon Bell's doctoral student at Carnegie Mellon University, was responsible for the architecture. Like PDP-11, VAX was very successful; it provided the majority of DEC's sales, sales growth, and profit from the early 1980s to early 1990s. VAX and VMS became DEC's only actively developed computer architecture. Many different models with different prices, performance levels, and capacities were subsequently created. VAX superminicomputers were very popular in the early 1980s.\nFor a while the VAX-11/780 was used as a standard in CPU benchmarks. It was initially described as a one-MIPS machine, because its performance was equivalent to an IBM System/360 that ran at one MIPS, and the System/360 implementations had previously been de facto performance standards. The actual number of instructions executed in 1 second was about 500,000, which led to complaints of marketing exaggeration. The result was the definition of a \"VAX MIPS\", the speed of a VAX-11/780; a computer performing at 27 VAX MIPS would run the same program roughly 27 times faster than the VAX-11/780.\nWithin the Digital community the term \"VUP\" (VAX Unit of Performance) was the more common term, because MIPS do not compare well across different architectures. The related term \"cluster VUPs\" was informally used to describe the aggregate performance of a VAXcluster. (The performance of the VAX-11/780 still serves as the baseline metric in the BRL-CAD Benchmark, a performance analysis suite included in the BRL-CAD solid modeling software distribution.) The VAX-11/780 included a subordinate stand-alone LSI-11 computer that performed microcode load, booting, and diagnostic functions for the parent computer. This was dropped from subsequent VAX models. Enterprising VAX-11/780 users could therefore run three different Digital Equipment Corporation operating systems: VMS on the VAX processor (from the hard drives), and either RSX-11S or RT-11 on the LSI-11 (from the single density single drive floppy disk).\nThe VAX went through many different implementations. The original VAX 11/780 was implemented in TTL and filled a four-by-five-foot cabinet with a single CPU. Through the 1980s, the high-end of the family was continually improved using ever-faster discrete components, an evolution that ended with the introduction of the VAX 9000 in October 1989. This design proved too complex and expensive and was ultimately abandoned not long after introduction. CPU implementations that consisted of multiple emitter-coupled logic (ECL) gate array or macrocell array chips included the VAX 8600 and 8800 superminis and finally the VAX 9000 mainframe class machines. CPU implementations that consisted of multiple MOSFET custom chips included the 8100 and 8200 class machines. The VAX 11-730 and 725 low-end machines were built using AMD Am2901 bit-slice components for the ALU.\nThe MicroVAX I represented a major transition within the VAX family. At the time of its design, it was not yet possible to implement the full VAX architecture as a single VLSI chip (or even a few VLSI chips as was later done with the V-11 CPU of the VAX 8200/8300). Instead, the MicroVAX I was the first VAX implementation to move some of the more complex VAX instructions (such as the packed decimal and related opcodes) into emulation software. This partitioning substantially reduced the amount of microcode required and was referred to as the \"MicroVAX\" architecture. In the MicroVAX I, the ALU and registers were implemented as a single gate-array chip while the rest of the machine control was conventional logic.\nA full VLSI (microprocessor) implementation of the MicroVAX architecture arrived with the MicroVAX II's 78032 (or DC333) CPU and 78132 (DC335) FPU. The 78032 was the first microprocessor with an on-board memory management unit The MicroVAX II was based on a single, quad-sized processor board which carried the processor chips and ran the MicroVMS or Ultrix-32 operating systems. The machine featured 1 MB of on-board memory and a Q22-bus interface with DMA transfers. The MicroVAX II was succeeded by many further MicroVAX models with much improved performance and memory.\nFurther VLSI VAX processors followed in the form of the V-11, CVAX, CVAX SOC (\"System On Chip\", a single-chip CVAX), Rigel, Mariah and NVAX implementations. The VAX microprocessors extended the architecture to inexpensive workstations and later also supplanted the high-end VAX models. This wide range of platforms (mainframe to workstation) using one architecture was unique in the computer industry at that time. Sundry graphics were etched onto the CVAX microprocessor die. The phrase \"CVAX... when you care enough to steal the very best\" was etched in broken Russian as a play on a Hallmark Cards slogan, intended as a message to Soviet engineers who were known to be both purloining DEC computers for military applications and reverse engineering their chip design. By the late 1980s, the VAX microprocessors had grown in power to be competitive with discrete designs. This led to the abandonment of the 8000 and 9000 series and their replacement by Rigel-powered models of the VAX 6000, and later by NVAX-powered VAX 7000 systems.\nExtrapolating from Moore's Law, DEC expected that VAX's 32-bit design would be a viable architecture until about 1999. The company did not foresee that RISC would, during the 1980s, usurp traditional computing architectures with significantly more performance per cost. As Unix RISC systems from Sun Microsystems and others lured VAX customers, in 1989 DEC introduced a range of RISC workstations and servers that ran Ultrix, the DECstation and DECsystem respectively, using processors from MIPS Computer Systems. In 1992 DEC introduced its own RISC instruction set architecture, the Alpha AXP (later renamed Alpha), and their own Alpha-based microprocessor, the DECchip 21064, a high performance 64-bit design capable of running OpenVMS.\nIn August 2000, Compaq announced that the remaining VAX models would be discontinued by the end of the year, but old systems remain in widespread use. The Stromasys CHARON-VAX and SIMH software-based VAX emulators remain available. VMS is now developed by VMS Software Incorporated, albeit only for the Alpha, HPE Integrity, and x86-64 platforms.\nProcessor architecture.\nVirtual memory map.\nThe VAX virtual memory is divided into four sections. Each is one gigabyte (in the context of addressing, 230 bytes) in size:\nFor VMS, P0 was used for user process space, P1 for process stack, S0 for the operating system, and S1 was reserved.\nPrivilege modes.\nThe VAX has four hardware implemented privilege modes:\nProcessor status longword.\nThe process status longword contains 32 bits:\nVAX-based systems.\nThe first VAX-based system was the VAX-11/780, a member of the VAX-11 family. The high-end VAX 8600 replaced the VAX-11/780 in October 1984 and was joined by the entry-level MicroVAX minicomputers and the VAXstation workstations in the mid-1980s. The MicroVAX was superseded by the VAX 4000, the VAX 8000 was superseded by the VAX 6000 in the late 1980s and the mainframe-class VAX 9000 was introduced. In the early 1990s, the fault-tolerant VAXft was introduced, as were the Alpha compatible VAX 7000/10000. A variant of various VAX-based systems were sold as the VAXserver.\nSIMACS.\n\"System Industries\" developed an ability to give more than one DEC CPU, but not at the same time, write access to a shared disk. They implemented an enhancement named SIMACS (simultaneous machine access), which allowed their special disk controller to set a semaphore flag for disk access, allowing multiple WRITES to the same files; the disk is shared by multiple DEC systems. \"SIMACS\" also existed on PDP-11 RSTS systems.\nCanceled systems.\nCanceled systems include the \"BVAX\", a high-end emitter-coupled logic (ECL) based VAX, and two other ECL-based VAX models: \"Argonaut\" and \"Raven\". Raven was canceled in 1990. A VAX named \"Gemini\" was also canceled, which was a fall-back in case the LSI-based \"Scorpio\" failed. It never shipped.\nClones.\nA number of VAX clones, both authorized and unauthorized, were produced. Examples include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32518", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=32518", "title": "Verlons", "text": ""}
{"id": "32519", "revid": "11423495", "url": "https://en.wikipedia.org/wiki?curid=32519", "title": "Valens", "text": "Roman emperor from 364 to 378\nValens (; ; 328 \u2013 9 August 378) was Roman emperor from 364 to 378. Following a largely unremarkable military career, he was named co-emperor by his elder brother Valentinian I, who gave him the eastern half of the Roman Empire to rule. In 378, Valens was defeated and killed at the Battle of Adrianople against the invading Goths, which astonished contemporaries and marked the beginning of barbarian encroachment into Roman territory.\nAs emperor, Valens continually faced threats both internal and external. He defeated, after some dithering, the usurper Procopius in 366, and campaigned against the Goths across the Danube in 367 and 369. In the following years, Valens focused on the eastern frontier, where he faced the perennial threat of Persia, particularly in Armenia, as well as additional conflicts with the Saracens and Isaurians. Domestically, he inaugurated the Aqueduct of Valens in Constantinople, which was longer than all the aqueducts of Rome. In 376\u201377, the Gothic War broke out, following a mismanaged attempt to settle the Goths in the Balkans. Valens returned from the east to fight the Goths in person, but lack of coordination with his nephew, the western emperor Gratian (Valentinian I's son), as well as poor battle tactics, led to Valens and much of the eastern Roman army dying in a battle near Adrianople in 378.\nA capable administrator who significantly relieved the burden of taxation on the population, Valens is also described as indecisive, impressionable, a mediocre general and overall \"utterly undistinguished\". His suspicious and fearful disposition resulted in numerous treason trials and executions which heavily stained his reputation. In religious matters, Valens favored a compromise between Nicene Christianity and the various non-trinitarian Christian sects, and interfered little in the affairs of the pagans.\nEarly life and military career.\nValens and his brother Valentinian were born, in 328 and 321 respectively, to an Illyrian family resident in Cibalae (Vinkovci) in Pannonia Secunda. Their father Gratianus Funarius, a native of Cibalae, had served as a senior officer in the Roman army and as \"comes Africae\". The brothers grew up on estates purchased by Gratianus in Africa and Britain. Both were Christians, but favored different sects: Valentinian was a Nicene Christian and Valens was an Arian Christian (specifically a Homoean). In adulthood, Valens served in the \"protectores domestici\" under the emperors Julian and Jovian. According to the 5th-century Greek historian Socrates Scholasticus, Valens refused pressure to offer pagan sacrifices during the reign of the polytheist emperor Julian.\nJulian was killed in battle against the Persians in June 363, and his successor Jovian died the following February while traveling home to Constantinople. The Latin historian Ammianus Marcellinus relates that Valentinian was summoned to Nicaea by a council of military and civil officials, who acclaimed him \"augustus\" on 25 February 364.\nValentinian appointed his brother Valens \"tribunus stabulorum\" (or \"stabuli\") on 1 March 364. It was the general opinion that Valentinian needed help to handle the administration, civil and military, of the large and unwieldy empire, and, on 28 March, at the express demand of the soldiers for a second \"augustus\", he selected Valens as co-emperor at the Hebdomon, before the Constantinian Walls.\nReign.\nBoth emperors were briefly ill, delaying them in Constantinople. As soon as they recovered, the two \"augusti\" travelled together through Adrianople and Naissus to Mediana, where they divided their territories. Valens obtained the eastern half of the Empire: Greece, the Balkans, Egypt, Anatolia and the Levant as far as the border with the Sasanian Empire. Valentinian took the western half, where the Alemannic wars required his immediate attention. The brothers began their consulships in their respective capitals, Constantinople and Mediolanum (Milan).\nIn the summer of 365, the 365 Crete earthquake and ensuing tsunami caused destruction around the Eastern Mediterranean.\nThe empire had recently retreated from most of its holdings in Mesopotamia and Armenia, because of a treaty that Jovian had made with Shapur II of the Sasanian Empire. Valens' first priority after the winter of 365 was to move east in hopes of shoring up the situation.\nUsurpation of Procopius (365\u2013366).\nRecent tax increases, and Valens' dismissal of Julian's popular minister Salutius, contributed to a general disaffection and to the acceptability of a revolution. With the emperor absent from the imperial city, Procopius, a maternal cousin of Julian, declared himself \"augustus\" on 28 September 365. Procopius had held office under Constantius II and Julian and was rumored to have been Julian's intended successor, despite how he had died without naming one. Jovian, aside from depriving him of his command, took no measures against this potential rival, but Valentinian regarded Procopius with hostility. Procopius met the danger from the new emperors with his own bid for power, emphasizing his connection to the revered Constantinian Dynasty: during his public appearances he was always accompanied by Constantia, the posthumous daughter of Constantius II, and her mother Faustina, the dowager empress.\nNews of the revolt reached Valens at Caesarea (Kayseri) in Cappadocia, after most of his troops had already crossed the Cilician Gates into Syria. His first reaction was despair, and he considered abdication and perhaps even suicide. Procopius quickly gained control of the provinces of Asia and Bithynia, winning increasing support for his insurrection. Valens recovered his nerve and sent an army to Constantinople; according to Ammianus Marcellinus, the soldiers defected to Procopius, whose use of his Constantinian hostages had met with some success.\nHaving reappointed Salutius, Valens dispatched more troops under veteran generals, Arinthaeus and Arbitio, to march on Procopius. According to Ammianus Marcellinus and the later Greek historians Socrates Scholasticus and Sozomen, the forces of Valens eventually prevailed after eight months, defeating Procopius in battles at Thyatira and Nacoleia. On both occasions, Procopius was deserted by his own following in fear of their adversaries' formidable commanders. Put on trial by members of his own escort, Procopius was executed on 27 May 366. Ammianus Marcellinus relates that Procopius' relative Marcellus was proclaimed emperor in his place, but according to Zosimus he was swiftly captured and executed. Valens could turn his attention back to external enemies, the Sasanian Empire and the Goths.\nFirst Gothic War: 367\u2013369.\nDuring Procopius' insurrection, the Gothic king Ermanaric, who ruled a powerful kingdom north of the Danube from the Euxine to the Baltic Sea, had engaged to supply him with troops for the struggle against Valens. The Gothic army, reportedly numbering 30,000 men, arrived too late to help Procopius, but nevertheless invaded Thrace and began plundering the farms and vineyards of the province. Valens, marching north after defeating Procopius, surrounded them with a superior force and forced them to surrender. Ermanaric protested, and when Valens, encouraged by Valentinian, refused to make atonement to the Goths for his conduct, war was declared.\nIn spring 367, Valens crossed the Danube and attacked the Visigoths under Athanaric, Ermanaric's tributary. The Goths fled into the Carpathian Mountains, and the campaign ended with no decisive conclusion. The following spring, a Danube flood prevented Valens from crossing; instead the Emperor occupied his troops with the construction of fortifications. In 369, Valens crossed again, from Noviodunum, and by devastating the country forced Athanaric into giving battle. Valens was victorious, and took the title \"Gothicus Maximus\" in time for the celebration of his \"quinquennalia\". Athanaric and his forces were able to withdraw in good order and pleaded for peace.\nFortunately for the Goths, Valens expected a new war with the Sasanid Empire in the Middle East and was therefore willing to come to terms. In early 370 Valens and Athanaric met in the middle of the Danube and agreed to a treaty that ended the war. The treaty seems to have largely cut off relations between Goths and Romans, confining trade and the exchange of troops for tribute.\nPersian War: 373.\nAs mentioned before, among Valens' reasons for contracting a hasty and not entirely favorable peace in 369 was the deteriorating state of affairs in the East. Jovian had surrendered Rome's much disputed claim to control over Armenia in 363, and Shapur II was eager to make good on this new opportunity. The Persian emperor began enticing Armenian lords over to his camp and eventually forced the defection of the Arsacid Armenian king, Arshak II (Arsaces II), whom he quickly arrested and incarcerated. The Armenian nobility responded by asking Valens to return Arshak's son, Pap. Valens agreed and sent Pap back to Armenia, but as these events took place during the war with the Goths he could not support him militarily.\nIn response to the return of Pap, Shapur personally led an invasion force to seize control of Armenia. Pap and his followers took refuge in the mountains while Artaxata, the Armenian capital, and the city of Artogerassa along with several strongholds and castles were destroyed. Shapur sent a second invasion force to Caucasian Iberia to drive out the pro-Roman king Sauromaces II, and put his own appointee, Sauromaces's uncle Aspacures II, on the throne.\nIn the summer following his Gothic settlement, Valens sent his \"magister peditum\" (Master of Foot) Arinthaeus to support Pap. The following spring twelve legions were sent under Terentius to regain Iberia and to garrison Armenia near Mount Npat. When Shapur counterattacked into Armenia in 371, his forces were bested by Valens' generals Traianus and Vadomarius and the Armenian \"sparapet\" (general) Mushegh Mamikonian at Bagavan and Gandzak. Valens had overstepped the 363 treaty and then successfully defended his transgression. A truce settled after the 371 victory held as a quasi-peace for the next five years while Shapur was forced to deal with a Kushan invasion on his eastern frontier.\nMeanwhile, troubles broke out with the boy-king Pap, who purportedly had the Armenian patriarch Nerses assassinated and demanded control of a number of Roman cities, including Edessa. Controversy also ensued over the issue of the appointment of a new patriarch of Armenia, with Pap appointing a candidate without the traditional approval from Caesarea. Pressed by his generals and fearing that Pap would defect to the Persians, Valens made an unsuccessful attempt to capture the prince and later had him executed inside Armenia. In his stead, Valens imposed another Arsacid, Varazdat, who ruled under the regency of the \"sparapet\" Mushegh Mamikonian, a friend of Rome.\nNone of this sat well with the Persians, who began agitating again for compliance with the 363 treaty. As the eastern frontier heated up in 375, Valens began preparations for a major expedition. Meanwhile, trouble was brewing elsewhere. In Isauria, the mountainous region of western Cilicia, a major revolt had broken out in 375 which diverted troops formerly stationed in the East. Furthermore, by 377, the Saracens under Queen Mavia had broken into revolt and devastated a swath of territory stretching from Phoenicia and Palestine as far as the Sinai. Though Valens successfully brought both uprisings under control, the opportunities for action on the eastern frontier were limited by these skirmishes closer to home.\nLater reign: 373\u2013376.\nValens became the senior \"augustus\" on 17 November 375, after his older brother Valentinian died suddenly at Brigetio (Sz\u0151ny) while on campaign against the Quadi in Pannonia. In the west, Valentinian was succeeded by his elder son Gratian, co-emperor since 367, and his younger son Valentinian II, whom the army on the Danube proclaimed \"augustus\" without consulting Gratian or Valens.\nSecond Gothic War: 376\u2013378.\nValens' eastern campaign required an ambitious recruitment program, designed to fill gaps left in his mobile forces when troops were transferred to the Western Empire in 374. Meanwhile, migrations of the Huns began to displace the Goths, who sought Roman protection. Refugees from the former kingdom of Ermanaric, unable to hold the Dniester or Prut rivers against Hunnic invaders, retreated southward in a massive emigration, seeking more defensible lands on the Roman side of the Danube. In 376, the Visigoths under their leader Fritigern advanced to the far shores of the lower Danube and sent requests for asylum to Valens in Antioch.\nValens granted permission for a Danube crossing to Fritigern and his followers, who had allied with the Romans in the 370s against Athanaric's persecution of Gothic Christians, and, it was hoped, could now be hired to bolster the eastern army. The Gothic troops would have to be paid in gold or silver, but their presence would decrease Valens' dependence on conscription from the provinces\u2014thereby increasing revenues from the recruitment tax. Though a number of Gothic groups apparently requested entry, Valens granted admission only to Fritigern's people. Others would soon follow, however.\nValens' mobile forces were tied down on the Persian frontier, where the emperor was attempting to withdraw from the harsh terms imposed by Shapur and was meeting some resistance on the latter's part. This meant that only \"limitanei\" units were present to oversee the arrival of Fritigern and his Goths, to the number of 200,000 warriors and almost a million all told. The sparse imperial troops could not stop subsequent Danube crossings by groups of Ostrogoths, Huns, and Alans, none of whom had been included in the original treaty. The controlled resettlement foreseen by the government threatened to turn into a major invasion, and the situation was worsened by corruption in the local Roman administration. Valens' generals accepted bribes rather than depriving the Goths of their weapons as Valens had stipulated, then enraged the settlers by imposing exorbitant prices for food. In early 377, the Goths revolted after a commotion with the people of Marcianopolis, and defeated the corrupt Roman governor Lupicinus near the city at the Battle of Marcianople.\nAfter joining forces with the Ostrogoths under Alatheus and Saphrax who had crossed without Valens' consent, the combined barbarian group spread out to devastate the country before combining to meet Roman advance forces under Traianus and Richomeres. In a sanguinary battle at \"Ad Salices\", the Goths were momentarily checked, and Saturninus, now Valens' lieutenant in the province, undertook a strategy of hemming them in between the lower Danube and the Euxine, hoping to starve them into surrender. However, Fritigern forced him to retreat by inviting some of the Huns to cross the river in the rear of Saturninus' ranged defenses. The Romans then fell back, incapable of containing the irruption, though with an elite force of his best soldiers the general Sebastian was able to fall upon and destroy several of the smaller predatory bands.\nValens requested assistance in Thrace from his nephew and co-emperor Gratian, but ultimately took the offensive before Gratian could join him. Leaving behind a skeletal force\u2014some of them Goths\u2014the eastern army withdrew from the frontier, reaching Constantinople by 30 May, 378. The imperial councillors, \"comes\" Richomeres, the generals Frigeridus and Victor, and letters from Gratian all cautioned Valens to wait for the arrival of the western army, but the populace of Constantinople became impatient at the delay. Public opinion criticized Valens for failing to control the Goths after inviting them into his territory, and compared him unfavourably with Gratian as a military commander. Valens decided to advance at once and win a victory on his own.\nBattle of Adrianople.\nAccording to the Latin historians Ammianus Marcellinus and Paulus Orosius, on 9 August 378, Valens and most of his army were killed fighting the Goths near Hadrianopolis in Thrace (Adrianople, Edirne). Ammianus is the primary source for the battle.\nValens opened the campaign with arrangements aimed at building his troop strength and gaining a toehold in Thrace, then moved out to Adrianople, from whence he marched against the confederated barbarian army. Although negotiations were attempted, these broke down when a Roman unit sallied forth and carried both sides into battle. Valens had left a sizeable guard with his baggage and treasures, depleting his force. His right cavalry wing arrived at the Gothic camp sometime before the left wing arrived. It was a very hot day and the Roman cavalry was engaged without strategic support, wasting its efforts and suffering in the heat.\nMeanwhile, Fritigern once again sent an emissary of peace in his continued manipulation of the situation. The resultant delay meant that the Romans present on the field began to succumb to the heat. The army's resources were further diminished when an ill-timed attack by the Roman archers made it necessary to recall Valens' emissary, \"comes\" Richomeres. The archers were beaten and retreated in humiliation. Returning from foraging to find the battle in full swing, Gothic cavalry under the command of Alatheus and Saphrax now struck and, in what was probably the most decisive event of the battle, the Roman cavalry fled.\nFrom here, Ammianus gives two accounts of Valens' demise. In the first account, Ammianus states that Valens was \"mortally wounded by an arrow, and presently breathed his last breath\" (XXXI.12). His body was never found or given a proper burial. In the second account, Ammianus states the Roman infantry was abandoned, surrounded and cut to pieces. Valens was wounded and carried to a small wooden hut. He died when the Goths, evidently unaware of the prize within, set the hut on fire (XXXI.13.14\u201316).\nA third, apocryphal, account states that Valens was struck in the face by a Gothic dart and then perished while leading a charge. He wore no helmet, in order to encourage his men. This action turned the tide of the battle which resulted in a tactical victory but a strategic loss. The church historian Socrates likewise gives two accounts for the death of Valens.\nSome have asserted that he was burnt to death in a village whither he had retired, which the barbarians assaulted and set on fire. But others affirm that having put off his imperial robe he ran into the midst of the main body of infantry; and that when the cavalry revolted and refused to engage, the infantry were surrounded by the barbarians, and completely destroyed in a body. Among these it is said the Emperor fell, but could not be distinguished, in consequence of his not having on his imperial habit.\nWhen the battle was over, two-thirds of the eastern army lay dead. Many of their best officers had also perished. What was left of the army of Valens was led from the field under the cover of night by \"comes\" Richomeres and general Victor.\nJ. B. Bury, a noted historian of the period, provides a specific interpretation on the significance of the battle: it was \"a disaster and disgrace that need not have occurred.\"\nFor Rome, the battle incapacitated the government. Emperor Gratian, nineteen years old, was unable to deal with the catastrophe, until he appointed Theodosius I. The total defeat cost the administration important precious metal resources, as bullion had been centralized with the imperial court. Valens was deified by \"consecratio\" as .\nAssessment and legacy.\n\"Valens was utterly undistinguished, still only a \"protector\", and possessed no military ability: he betrayed his consciousness of inferiority by his nervous suspicion of plots and savage punishment of alleged traitors,\" writes A. H. M. Jones, a modern historian. But Jones admits that \"he was a conscientious administrator, careful of the interests of the humble. Like his brother, he was an earnest Christian.\" According to Edward Gibbon (c. 1776\u20131789), Valens diminished the oppressive burden of the taxes which had been instituted by Constantine and his sons, and was humbly deferential to Valentinian's edicts of reform, as with the institution of \"Defensors\" (a sort of substitute for the ancient Tribunes, guardians of the lower classes). Gibbon continues that his moderation and chastity in his private life were everywhere celebrated. At the same time, continuous proscriptions and executions, originating in his weak and fearful disposition, disgraced the dozen years of his reign. \"An anxious regard to his personal safety was the ruling principle of the administration of Valens\", writes Gibbon. To have died in so inglorious a battle has thus come to be regarded as the nadir of an unfortunate career. This is especially true because of the profound consequences of Valens' defeat. Adrianople spelled the beginning of the end for Roman territorial integrity in the late Empire and this fact was recognized even by contemporaries. Ammianus understood that it was the worst defeat in Roman history since the Battle of Edessa, and Rufinus called it \"the beginning of evils for the Roman empire then and thereafter.\"\nValens is also credited with the commission of a short history of the Roman State. This work, produced by Valens' secretary Eutropius, and known by the name \"Breviarium ab Urbe condita\", tells the story of Rome from its founding. According to some historians, Valens was motivated by the necessity of learning Roman history, that he, the royal family, and their appointees might better mix with the Roman senatorial class.\nReligious policy.\nDuring his reign, Valens had to confront the theological diversity that was beginning to create division in the Empire. Julian (361\u2013363), had tried to revive the pagan religions. His reactionary attempt took advantage of the dissensions among the different Christian factions, and a largely Pagan rank and file military. However, in spite of broad support, his actions were often viewed as excessive, and before he died in a campaign against the Persians, he was often treated with disdain. His death was considered a sign from the Christian God.\nValens was baptised by the Arian bishop of Constantinople before he set out on his first war against the Goths. While the Nicene Christian writers of his time identified Valens with the Arian faction and accused him of persecuting Nicene Christians, modern historians have described both Valens and Valentinian I as primarily interested in maintaining social order and have minimized their theological concerns. Although Athanasius was impelled, under his reign, to briefly go into hiding, Valens maintained a close dependency on his brother Valentinian and treated St. Basil mildly, both of whom supported the Nicene position. Not long after Valens died the cause of Arianism in the Roman East was to come to an end. His successor Theodosius I made Nicene Christianity the state religion of Rome and suppressed the Arians.\nAppearance.\nThe coin portraits of Valentinian and Valens give the faces of both emperors \"heavy features\", rendered with \"no animation, and little consistency\". Toward the end of his \"Res Gestae\" (XXXI.14.7), Ammianus says that Valens was physically compact, dark-complected, and of average height, \"knock-kneed, and somewhat pot-bellied\", and had a \"dimmed\" pupil in one eye (the translator John C. Rolfe suggests that this is a description of a cataract).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "32521", "revid": "42316734", "url": "https://en.wikipedia.org/wiki?curid=32521", "title": "VCR (disambiguation)", "text": "A VCR is a videocassette recorder.\nVCR may also refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "32523", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=32523", "title": "VM/CMS", "text": ""}
{"id": "32524", "revid": "10289486", "url": "https://en.wikipedia.org/wiki?curid=32524", "title": "Batavia (1628 ship)", "text": "Dutch East India Company flagship\nBatavia () was a ship of the Dutch East India Company (VOC). She was built in Amsterdam in 1628 as the flagship of one of the three annual fleets of company ships and sailed that year on her maiden voyage for Batavia, capital of the Dutch East Indies. On 4 June 1629, \"Batavia\" was wrecked on the Houtman Abrolhos, a chain of small islands off Western Australia.\nAs the ship broke apart, approximately 300 of the \"Batavia\"'s 341 passengers and crew made their way ashore, the rest drowning in their attempts. Her commander, Francisco Pelsaert, sailed to Batavia to get help, leaving in charge senior VOC official Jeronimus Cornelisz, unaware he had been plotting a mutiny prior to the wreck. Cornelisz tricked about twenty men under soldier Wiebbe Hayes into searching for fresh water on nearby islands, leaving them to die. With the help of other mutineers, he then orchestrated a massacre that, over the course of several weeks, resulted in the murder of approximately 125 of the remaining survivors, including women, children and infants; a small number of women were kept as sex slaves.\nMeanwhile, Hayes' group had unexpectedly found fresh water and, after learning of the atrocities, waged battles with Cornelisz's group. In October 1629, at the height of their last and deadliest battle, they were interrupted by the return of Pelsaert aboard the rescue vessel \"Sardam\". Pelsaert subsequently tried and convicted Cornelisz and six of his men, who became the first Europeans to be legally executed in Australia. Two other mutineers, convicted of comparatively minor crimes, were marooned on mainland Australia, thus becoming the first Europeans to permanently inhabit the Australian continent, although nothing more was heard of them. Only 122 of the original passengers made it to the port of Batavia.\nAssociated today with \"one of the worst horror stories in maritime history\", \"Batavia\" has been the subject of numerous published histories. Due to its unique place in the history of European contact with Australia, the story of \"Batavia\" is sometimes offered as an alternative founding narrative to the landing of the First Fleet in Sydney. \nOf the forty-seven or so VOC wrecks which have been located and identified, \"Batavia\" is the only early 17th century example from which the remaining hull components have been retrieved, conserved and subject to detailed study. Many \"Batavia\" artifacts are housed at the Western Australian Shipwrecks Museum in Fremantle, while a replica of the ship is moored as a museum ship in Lelystad in the Netherlands.\nConstruction.\nIn the 16th and 17th centuries, the Dutch were the major shipbuilders of northern Europe, innovating both designs (e.g. the Fluyt) and technology (the windmill driven sawmill). They did, though, use the \"bottom-based\" construction sequence, which uses a shell-first system for the lower part of the hull. The planks are shaped and then laid edge to edge, having the appearance of carvel construction, but are put in position before the s are installed. The shape of the bottom of the hull is therefore derived from the shaping of the hull planks. The \"bottom-based\" construction sequence is the same as used on Medieval cogs and some argue that this is an older Romano-Celtic building tradition.\nShips belonging to the Dutch East India Company (VOC) were generally built in the company's own shipyards. The VOC issued charters which gave detailed specifications for these ships; these were updated from time to time. The charters gave a range of key hull dimensions and scheduled the sizes of the &lt;templatestyles src=\"Template:Tooltip/styles.css\" /&gt;. However, the designs did not exist as plans or drawings that determined the shape of the hull. Unlike ships built for European trade, the VOC East Indiamen were planked with a double skin of oak structural planking. This was sheathed with a double layer of pine which incorporated tar and animal hair, together with closely spaced iron nails. The pine layer was intended to resist teredo worm.\nThe length to beam ratio of Batavia was 4.4:1. This made her narrower than preceding VOC ships. A 1619 VOC shipbuilding charter gives a length to beam ratio of 3.9:1. It is suggested that there was a trend for VOC to have increasingly narrower designs in the early part of the 17th century. All VOC ships had a relatively high length to beam ratio, covering a range of 3.7:1 to 4.5:1. This was at a time when a 3:1 ratio would not have been unusual.\n\"Batavia\", in common with other Dutch ships of the time, was built from oak imported from the forests bordering the Vistula. The Dutch trade in timber from the Baltic, particularly oak, dates back to the early 13th century. (By the early 17th century, Dutch merchants dominated the European timber trade.) Oak from the Vistula region ceased to be used after 1643. It is possible that Dutch shipbuilding had, by then, been a cause of deforestation of the area.\n\"Batavia\" may have been one of two ships specified in the VOC shipbuilding charter of 29 March 1626\u00a0\u2013 normally it took 18 months to build one of these vessels, so a small delay would fit the dates. The name \"Batavia\" was chosen on 29 June 1628. The leaders of the VOC pushed for the ship to be ready for the next fleet (consisting of five other ships), which was due to leave in September or October 1628. \"Batavia\" would be the flagship of this fleet.\nMaiden voyage.\nOn 29 October 1628, the newly built \"Batavia\", commissioned by the VOC, sailed from Texel in the Netherlands for the Dutch East Indies, to obtain spices. Their orders were to use the Brouwer Route, like all ships of the Dutch East India Company. This involved sailing to the south of a direct course to Jakarta, but without any way of measuring longitude, it was difficult to judge when to make the turn north. A late turn gave the risk of running aground on the coast of Australia.\nShe sailed under commander and senior merchant Francisco Pelsaert, with Ariaen Jacobsz serving as skipper. Pelsaert and Jacobsz had previously encountered each other in Dutch Suratte, when Pelsaert publicly dressed-down Jacobsz after he became drunk and insulted Pelsaert in front of other merchants. Animosity existed between the two men after this incident. Also on board was the junior merchant Jeronimus Cornelisz, a bankrupt apothecary from Haarlem who was fleeing the Netherlands, in fear of arrest because of his heretical beliefs associated with the painter Johannes van der Beeck.\nMutiny plot.\nAccording to Pelsaert's account, Jacobsz and Cornelisz conceived a plan to take the ship during the voyage, which would allow them to start a new life elsewhere, using the huge supply of trade gold and silver on board. After leaving the Cape of Good Hope, where they had stopped for supplies, Jacobsz is alleged by Pelsaert to have deliberately steered the ship off course, and away from the rest of the fleet. Jacobsz and Cornelisz had already gathered a small group of men around them and arranged an incident from which the mutiny was to ensue. This involved sexually assaulting a prominent young female passenger, Lucretia Jans, in order to provoke Pelsaert into disciplining the crew. They hoped to paint his discipline as unfair and recruit more members out of sympathy. However, Jans was unable to identify her attackers.\nShipwreck.\nOn 4 June 1629, \"Batavia\" struck Morning Reef near Beacon Island, part of the Houtman Abrolhos off the western coast of Australia. Of the 322\u00a0aboard, most of the passengers and crew managed to get ashore, although 40 people drowned. The survivors, including all the women and children, were then transferred to nearby islands in the ship's longboat and yawl.\nAn initial survey of the islands found no fresh water and only limited food (sea lions and birds). Pelsaert realised the dire situation and decided to search for water on the mainland. A group consisting of Jacobsz, Pelsaert, senior officers, a few crew members, and some passengers left the wreck site in a longboat in search of drinking water. After an unsuccessful search for water on the mainland, they left the other survivors and headed north in a danger-fraught voyage to the city of Batavia, Dutch East Indies, the ship's namesake, to seek rescue. (Batavia was in the area of what is now Jakarta.) En route the crew made further forays onto the mainland in search of fresh water.\nIn his journal, Pelsaert stated that on 15 June 1629, they sailed through a channel between a reef and the coast, finding an opening around midday at a latitude guessed to be about 23 degrees south where they were able to land, and water was found. The group spent the night on land. Pelsaert commented on the vast number of termite mounds in the vicinity and the plague of flies that afflicted them. Pelsaert stated that they continued north with the intention of finding the \"river of Jacob Remmessens\", identified first in 1622, but owing to the wind were unable to land. Drake-Brockman has suggested that this location is to be identified with Yardie Creek.\nIt was not until the longboat reached the island of Nusa Kambangan in the Dutch East Indies that Pelsaert and the others found more water. The journey took 33 days, with everyone surviving. After their arrival in Batavia, the boatswain, Jan Evertsz, was arrested and executed for negligence and \"outrageous behavior\" before the loss of the ship (he was suspected to have been involved). Jacobsz was also arrested for negligence, although his culpability in the potential mutiny was not guessed by Pelsaert.\nGovernor-General Jan Pieterszoon Coen immediately gave Pelsaert command of to rescue the other survivors, as well as to attempt to salvage riches from \"Batavia\"'s wreck. Within a month, Pelsaert reached the general area where the shipwreck had occurred, but it took another month of searching to locate the islands again. He finally arrived at the site only to discover that a bloody massacre had taken place among the survivors, reducing their numbers by at least a hundred.\nMurders.\nCornelisz was one of the few men who stayed on \"Batavia\" to pillage and steal. He was one of the few who survived the final break-up of the ship and made it to Beacon Island after floating for two days. Though neither sailor nor soldier, Cornelisz was elected to be in charge of the survivors due to his senior rank in the Dutch East India Company. He made plans to hijack any rescue ship that might return and use the vessel to seek another safe haven. Cornelisz made far-fetched plans to start a new kingdom, using the gold and silver from the wreck. However, to carry out this plan, he first needed to eliminate possible opponents.\nCornelisz's first deliberate act was to have all weapons and food supplies commandeered and placed under his control. He then moved a group of soldiers, led by Wiebbe Hayes, to nearby West Wallabi Island (located roughly to the northwest), under the pretense of having them search for water. They were told to send smoke signals when they found water and they would then be rescued. Convinced that they would be unsuccessful, he then left them there to die, taking complete control of the remaining survivors.\nCornelisz never committed any of the murders himself, although he tried and failed to poison a baby (who was eventually strangled). Instead, he coerced others into doing it for him, usually under the pretense that the victim had committed a crime such as theft. Cornelisz and his henchmen had originally murdered to save themselves, but eventually they began to kill for pleasure or out of habit. Cornelisz planned to reduce the island's population to around 45 so that their supplies would last as long as possible. He also feared that many of the survivors remained loyal to the Dutch East India Company. In total, Cornelisz's followers murdered at least 110 men, women, and children. A small number of women were kept as sex slaves; among them was Jans, who Cornelisz reserved for himself.\nIn the May 2025 issue of the \"International Journal of Maritime History\", Dutch academic and cultural psychologist Jacob Koehler published an article entitled \"The Batavia disaster: A new scenario to explain the massacre after the shipwreck\", in which he argued that the \"unlikely story about a mad heretic\" which has been repeated for 400 years may be wrong. He proposed an alternative theory that rather than a dastardly plot, ordinary men were driven to terrible acts by starvation.\nRescue.\nAlthough Cornelisz had left the soldiers, led by Hayes, to die, they had in fact found good sources of water and food on West Wallabi Island. Initially, they were unaware of the massacres taking place and sent pre-arranged smoke signals announcing their finds. However, they soon learned of the killings from survivors fleeing Beacon Island. In response, the soldiers devised makeshift weapons from materials washed up from the wreck. They also set a watch so that they were ready for Cornelisz's men, and built a small fort out of limestone and coral blocks.\nCornelisz seized on the news of water on the other island, as his own supply was dwindling and the continued survival of the soldiers threatened his own success. He was fearful that any rescue vessel would sight the soldiers first, therefore dispatched his men to eliminate this threat. But the trained soldiers were by now much better fed than Cornelisz' group and easily defeated them in several battles. Seeking to bring Hayes under his command he traveled to the island himself, whereby Hayes and his soldiers took Cornelisz hostage. The men who escaped regrouped under soldier Wouter Loos and tried again, this time employing muskets to besiege Hayes' fort and almost defeating the soldiers. However, Hayes' men prevailed again just as \"Sardam\" arrived. A race to the rescue ship ensued between Cornelisz' men and the soldiers. Hayes reached the ship first and was able to present his side of the story to Pelsaert. After a short battle, the combined force captured all of Cornelisz's group.\nAftermath.\nPelsaert decided to conduct a trial on the islands, because \"Sardam\" on the return voyage to Batavia would have been overcrowded with both survivors and prisoners. After a brief trial, the worst offenders were taken to Seal Island and executed. Cornelisz and several of his henchmen had both hands chopped off before being hanged.\nLoos and a cabin boy, Jan Pelgrom de Bye, who were considered only minor offenders, were marooned on mainland Australia, and were never heard of again. This made them the first Europeans to have permanently lived on the Australian continent. This location is now thought to be Wittecarra Creek near Kalbarri, Western Australia, though another suggestion is nearby Port Gregory.\nThe rest of Cornelisz' henchmen were taken to Batavia for trial. Five were hanged, while several others were flogged, keelhauled or dropped from the yardarm on the later voyage back home. Cornelisz' second in command, Jacop Pietersz, was broken on the wheel, the most severe punishment available at the time. Jacobsz, despite being tortured, did not confess to his part in plotting the mutiny and escaped execution due to lack of evidence. What finally became of him is unknown; he might have died in prison in Batavia. A board of inquiry decided that Pelsaert had exercised a lack of authority and was therefore partly responsible for what had happened. His financial assets were seized, and he died within a year of disease. His journals on the matter would be published in 1647 and widely read, spreading knowledge of the dangers of the coast of Western Australia.\nHayes was hailed a hero and promoted to sergeant, which increased his salary, while those who had been under his command were promoted to the rank of corporal. Of the original 332\u00a0people on board \"Batavia\", only\u00a0122 made it to the port of Batavia. \"Sardam\" eventually sailed home with most of the treasure previously carried on \"Batavia\". Of the twelve treasure chests that were originally on board, ten were recovered and taken aboard \"Sardam\".\nWreck.\nSurveying the north-west coast of the Abrolhos Islands for the British Admiralty in April 1840, Captain John Lort Stokes reported that \"the beams of a large vessel were discovered\", assumed to be , \"on the south west point of an island\", reminding them that since \"Zeewijk\"'s crew \"reported having seen a wreck of a ship on this part, there is little doubt that the remains were those of the \"Batavia\"\".\nIn the 1950s, historian Henrietta Drake-Brockman argued, from extensive archival research, that the \"Batavia\" wreck must lie in the Wallabi group of islands. The wreck was first sighted in 1963 by lobster fisherman David Johnson.\nA systematic archaeological investigation was carried out in the 1970s. Most of the excavation work was carried out over four years, starting in 1972, with an initial survey in 1971. A large amount of the surviving hull was raised and conserved. This is about 20 tons of timber, which is about 3.5% of the original ship's hull. Other large items included port-side stern timbers, cannons and an anchor. A large selection of smaller items were excavated, with many pottery containers, weapons, cooking equipment, navigation items (including four astrolabes). Added to this were various trade items carried as part of the ship's cargo.\nThe excavation was carried out in challenging conditions, with the swell coming in from the Indian Ocean preventing diving on 173 days of the 447 days spent on site. Some of that diving was restricted to the inner wreck site, where material had been carried to an area sheltered from the swell inside the reef. In the fourth season on site (starting September 1975) only 10 days of diving were possible on the more exposed main wreck site. \nTo facilitate the monitoring and any future treatment, the hull timbers were erected on a steel frame. Its design\u2014and that of a stone arch, also recovered\u2014was such that individual components could be easily removed.\nIn 1972, the Dutch government transferred rights to Dutch shipwrecks in Australian waters to the Australian government. Excavated items are on display at the Western Australian Museum's various locations, though the majority of cannons and anchors have been left \"in situ\". The wreck remains one of the premier diving sites on the Western Australian coast.\nIn 2015 archaeological researchers from the University of Western Australia unearthed several skeletons believed to be from the \"Batavia\". It was later reported that subsequent research over five years by an international research team of anthropologists and archaeologists had \"discovered the remains of 12 victims, interred in both individual and mass graves, as well as evidence of a fierce struggle between survivors and a group of mutineers.\"\nBullion and jewels.\n\"Batavia\" carried a considerable amount of silver coins, manufactured silver items and jewels. The manufactured silverware were trade goods that Pelsaert had specifically requested to use in improving the VOC's trading capability\u00a0\u2013 he had found that these were sought after by the \"great men\" he had dealt with in Agra. Though Pelsaert's divers recovered some of the silverware in his salvage operations, a large quantity still remained to be recovered in the archaeolocial investigation. As well as more usual tableware, the silver finds included parts of bedsteads. \nEach ship in the \"Batavia\" class carried an estimated 250,000\u00a0guilders in twelve wooden chests, each containing about 8,000\u00a0silver coins. This money was intended for the purchase of spices and other commodities in Java. The bulk of these coins were silver rijksdaalder produced by the individual Dutch states, with the remainder being mostly made up of similar coins produced by German cities such as Hamburg.\nPelsaert was instructed to recover as much of the money as possible on his return to the Abrolhos Islands, using divers \"to try if it is possible to salvage all the money [and] the casket of jewels that before your departure was already saved on the small island\". Recovery of the money was far from easy. Pelsaert reported difficulties in pulling up heavy chests, e.g. 27\u00a0October 1629, when a chest had to be marked with a buoy for later recovery. On 9\u00a0November, he recorded sending four money chests to \"Sardam\", and three the next day, but then abandoned further recovery work. By 13\u00a0November, Pelsaert recorded that ten money chests had been recovered\u2014about 80,000\u00a0coins\u2014leaving two lost since there had been twelve loaded originally. One was jammed under a cannon, and the other one had been broken open by Cornelisz' men.\n\"Batavia\"'s cargo also included special items being carried by Pelsaert for sale to the Mughal Court in India where he had intended to travel on to. There were four jewel bags, stated to be worth about 60,000\u00a0guilders, and an early-fourth-century Roman cameo, as well as numerous other items either now displayed in Fremantle and Geraldton, Western Australia, or recovered by Pelsaert.\nReplica.\nA \"Batavia\" ship replica was built from 1985 to 1995, using the same materials and methods utilized in the early 17th\u00a0century. Her design was based on contemporary accounts, recovered wreckage, and other contemporary ships such as . After a number of commemorative voyages, the vessel is now moored as a museum ship in Lelystad in the Netherlands. The 40th anniversary of the project was celebrated in October 2025.\nMedia.\nNon-fiction.\nHenrietta Drake-Brockman's book \"Voyage to Disaster\" (1963) was largely a biography of the \"Batavia\"'s captain Francisco Pelsaert.\nThe \"Batavia\" story was retold in the book \"Islands of Angry Ghosts\" (1966) by Australian journalist and writer Hugh Edwards. It described the wreck and aftermath, and then followed with the story of the discovery and recovery. \nIn 2001 the Welsh author Mike Dash published his book, \"Batavia's Graveyard: The True Story of the Mad Heretic Who Led History's Bloodiest Mutiny\", a historiographic account of the events and people aboard the \"Batavia\". \nSimon Leys' book \"The Wreck of the Batavia\" was published in 2005, and includes \"a concise and pungently written summary of those terrible events.\"\nIn 2011 Australian author, journalist, and TV presenter Peter FitzSimons released his book \"Batavia. Betrayal, Shipwreck, Murder, Sexual Slavery, Courage: a Spine-chilling Chapter in Australian History\", discussing the events in detail. He describes the story of the \"Batavia\" as a 17th-century \"Adults Only version of Lord of the Flies meets Nightmare on Elm Street.\"\nFiction.\nAustralian journalist and novelist Henrietta Drake-Brockman's last novel, \"The Wicked and The Fair\" (1957), centred on the voyage and shipwreck of the \"Batavia\".\n\"The Devil's Own\" by Deborah Lisson is a 1990 book for young adults that was short-listed for the Australian Children's Book of the Year Award and has been covered in some school curriculums. It tells the story of a 15-year-old girl who finds herself in the past in the \"Batavia\"'s story of shipwreck, mutiny and murder.\nGary Crew won the 1991 Children's Book of the Year Award for Older Readers and the 1991 Victorian Premier's Literary Award for his novel \"Strange Objects\" (1990). It takes the premise that survivors from the Batavia made it to the mainland, and lived with the Aboriginal people of the area. \nArabella Edge's debut novel, \"\" (2000) provided a fictionalised account of the wreck of the ship and of the aftermath. \"Lucretia's Batavia Diary\" (2016) by Australian author Howard Gray presents a fictional diary of what it was like to live through the Batavia story through the eyes of one of the passengers, Lucretia van der Mijlen. \nThe voyage, shipwreck and subsequent events are also the subject of David Mark's 2022 novel \"Anatomy of a Heretic\", as well as the 2022 novel \"The Night Ship\" by Jess Kidd, and the 2025 historical novel \"Daughters of Batavia\" by Stefanie Koens, which won the Banjo Prize from HarperCollins.\nFilm.\nIn 1973, Bruce Beresford produced a film about the ship called \"The Wreck of the Batavia\". Another documentary film, \"The Batavia \u2013 Wreck, Mutiny and Murder\", was aired on the Nine Network in 1995. \nIt was reported in 2016 that Russell Crowe's production company purchased an option to turn Hugh Edwards 1966 novel \"Islands of Angry Ghosts\" into a film.\nIn 2017, a \"60 Minutes\" report detailed the archaeological recovery of the skeletal remains of some of the victims. The documentary \"Batavia Revealed: Shipwreck Psycho\" was aired on SBS in 2018.\nTelevision.\nIn a 2023 interview, the developer of reality TV show The Traitors, Jasper Hoogendoorn, stated that the original concept of the show was strongly influenced by the story of the \"Batavia.\"\nPodcasts.\nPodcasts which have covered the incident in depth include:\nMusic.\nThe Dutch music ensemble Flairck based their 1996 album \"De Gouden Eeuw\", and a subsequent tour and stage performances, on the unfortunate voyage of the Batavia.\nThe extreme metal band Destr\u00f6yer 666 wrote a song about the mutiny, \"Batavia's Graveyard\", which is featured on their album \"Never Surrender\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "32525", "revid": "10289486", "url": "https://en.wikipedia.org/wiki?curid=32525", "title": "Amsterdam (1748)", "text": "18th-century cargo ship of the Dutch East India Company\nAmsterdam () was an 18th-century cargo ship of the Dutch East India Company (Dutch: \"Vereenigde Oost-Indische Compagnie\"; \"VOC\"). The ship started its maiden voyage from Texel to Batavia on 8 January 1749, but was wrecked in a storm on the English Channel on 26 January 1749. The shipwreck was discovered in 1969 in the bay of Bulverhythe, near Hastings on the English south coast, and is sometimes visible during low tides. The location was found by Bill Young, the site agent/project manager for the sewage outfall being built by the William Press Group. With time on his hands during the long stay away from home, he followed up the rumour of the going aground. He was castigated by the Museum of London for scooping out the interior of the bow with a digger as it could have led to the structure collapsing. However, it uncovered the initial items which led to a more extensive excavation of the cargo which reflected life at the time. The wreck is a Protected Wreck managed by Historic England. Some of the findings from the site are in The Shipwreck Museum in Hastings. A replica of the ship is on display in Amsterdam.\nShip.\nThe \"Amsterdam\" was a Dutch () built as an East Indiaman for transport between the Dutch Republic and the settlements and strongholds of the Dutch East India Company in the East Indies. On an outward voyage these ships carried guns and bricks for the settlements and strongholds, and silver and golden coins to purchase Asian goods. On a return journey the ships carried the goods that were purchased, such as spices, fabrics, and china. In both directions the ships carried victuals, clothes, and tools for the sailors and soldiers on the ship. On an outward voyage of eight months, the ships were populated by around 240 men, and on a return journey by around 70.\nThe \"Amsterdam\" was built in the shipyard for the Amsterdam chamber of the Dutch East India Company in Amsterdam. The ship was made of oak wood.\nMaiden voyage.\nThe maiden voyage of the \"Amsterdam\" was planned from the Dutch island Texel to the settlement Batavia in the East Indies. The ship, commanded by the 33-year-old captain Willem Klump, had 203 crew, 127 soldiers, and 5 passengers. The \"Amsterdam\" was laden with textiles, wine, stone ballast, cannon, paper, pens, pipes, domestic goods and 27 chests of silver guilder coins. The whole cargo would be worth several million euros in modern money.\nOn 15 November 1748 the ship made its first attempt but returned on 19 November 1748 due to an adverse wind. The ship made a second attempt on 21 November 1748, which also failed and from which the ship returned on 6 December 1748. The third attempt was made on 8 January 1749. The \"Amsterdam\" had problems in the English Channel tacking into a strong westerly storm. For many days she got no further than Beachy Head near Eastbourne. An epidemic appeared amongst the crew and a mutiny broke out. Finally the rudder broke off and the ship, helpless in a storm, grounded in the mud and sand in the bay of Bulverhythe on 26 January 1749, to the west of Hastings.\nShe began to sink into the mud, where much of the keel remains today, perfectly preserved. Some of the cargo, including silver coinage, was removed for safekeeping by local authorities. There was an outbreak of fighting between scavengers and British troops had to be called in to bring the situation to order. The crew were looked after locally before being returned to Dutch soil.\nShipwreck.\nIn 1969, the \"Amsterdam\" was discovered after being exposed by a low spring tide. It is the best-preserved VOC ship ever found. Archaeologist Peter Marsden did the first surveying of the wreck, and he advised further excavation.\nThe wrecksite was designated under the Protection of Wrecks Act on 5 February 1974.\nThe VOC Ship Amsterdam Foundation started researching the wreck, followed by major excavations in 1984, 1985 and 1986, during which huge numbers of artefacts were found. Although the wreck is submerged in the sand and mud of the beach (and is even visible at very low tides), much of the excavation was done by divers, for whom a small tower was constructed near the wreck. Additionally the wreck was surrounded by an iron girder frame. The archeological output was so dense that new ways of researching needed to be developed, all of which were needed to understand the technological, socio-economic and cultural features of the VOC. Some of the finds are on show at the Shipwreck Museum in Hastings, East Sussex, UK, including one of the anchors, the other being on display as public art at St Katharine Docks in London. The wreck is protected and diving on it or removing timbers or any artefacts is forbidden. The ship may be visited as the timbers are exposed at very low tides in the sand just opposite the footbridge over the railway line at Bulverhythe.\nShip replica.\nA replica of the ship was built in Iroko wood by 300 volunteers using modern tools as well as tools of the period, between 1985 and 1990 at the Zouthaven (now Piet Heinkade), Amsterdam. It is moored next to the Netherlands Maritime Museum, where it is open to visitors of the museum (which has now reopened after being closed for several years for renovations). \nAs for the original ship, there had been hopes in the 1980s that the Dutch Government, which still owns it, might excavate the whole wreck and return it for restoration and display in Amsterdam, like the \"Regalskeppet Vasa\" in Sweden, or the \"Mary Rose\" in Portsmouth, but the funds were not forthcoming. Several decks and much of the bowsprit lie submerged in the mud and are in remarkably good condition, being naturally preserved by the mud, and much of the cargo is still aboard.\nPopular culture.\nThe comic book \"Angst op de \"Amsterdam\"\" of Spike and Suzy is about the \"Amsterdam\". The book was published in 1985 in The Red Series of Spike and Suzy.\nIn the miniature park Madurodam in The Hague is a model of the \"Amsterdam\" on a scale of 1:25. The Amsterdam Museum also has a wooden model of the ship with to the side a 'Camel' lifting mechanism.\nShanty Punk band Skinny Lister, some of whom live in Hastings, released a single \"Damn the Amsterdam\" about the ship.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32526", "revid": "6675779", "url": "https://en.wikipedia.org/wiki?curid=32526", "title": "Vasa", "text": "Vasa may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "32527", "revid": "3808", "url": "https://en.wikipedia.org/wiki?curid=32527", "title": "Viollet le Duc", "text": ""}
{"id": "32528", "revid": "37284", "url": "https://en.wikipedia.org/wiki?curid=32528", "title": "Visual cortex", "text": "Region of the brain that processes visual information\nThe visual cortex of the brain is the area of the cerebral cortex that processes visual information. It is located in the occipital lobe. Sensory input originating from the eyes travels through the lateral geniculate nucleus in the thalamus and then reaches the visual cortex. The area of the visual cortex that receives the sensory input from the lateral geniculate nucleus is the primary visual cortex, also known as visual area 1 (V1), Brodmann area 17, or the striate cortex. The extrastriate areas consist of visual areas 2, 3, 4, and 5 (also known as V2, V3, V4, and V5, or Brodmann area 18 and all Brodmann area 19).\nBoth hemispheres of the brain include a visual cortex; the visual cortex in the left hemisphere receives signals from the right visual field, and the visual cortex in the right hemisphere receives signals from the left visual field.\nIntroduction.\nThe primary visual cortex (V1) is located in and around the calcarine fissure in the occipital lobe. Each hemisphere's V1 receives information directly from its ipsilateral lateral geniculate nucleus that receives signals from the contralateral visual hemifield.\nNeurons in the visual cortex fire action potentials when visual stimuli appear within their receptive field. By definition, the receptive field is the region within the entire visual field that elicits an action potential. But, for any given neuron, it may respond best to a subset of stimuli within its receptive field. This property is called \"neuronal tuning\". In the earlier visual areas, neurons have simpler tuning. For example, a neuron in V1 may fire to any vertical stimulus in its receptive field. In the higher visual areas, neurons have complex tuning. For example, in the inferior temporal cortex (IT), a neuron may fire only when a certain face appears in its receptive field.\nFurthermore, the arrangement of receptive fields in V1 is retinotopic, meaning neighboring cells in V1 have receptive fields that correspond to adjacent portions of the visual field. This spatial organization allows for a systematic representation of the visual world within V1. Additionally, recent studies have delved into the role of contextual modulation in V1, where the perception of a stimulus is influenced not only by the stimulus itself but also by the surrounding context, highlighting the intricate processing capabilities of V1 in shaping our visual experiences.\nThe visual cortex receives its blood supply primarily from the calcarine branch of the posterior cerebral artery.\nThe size of V1, V2, and V3 can vary three-fold, a difference that is partially inherited.\nPsychological model of the neural processing of visual information.\nVentral-dorsal model.\nV1 transmits information to two primary pathways, called the ventral stream and the dorsal stream.\nThe what vs. where account of the ventral/dorsal pathways was first described by Ungerleider and Mishkin.\nMore recently, Goodale and Milner extended these ideas and suggested that the ventral stream is critical for visual perception whereas the dorsal stream mediates the visual control of skilled actions. It has been shown that visual illusions such as the Ebbinghaus illusion distort judgements of a perceptual nature, but when the subject responds with an action, such as grasping, no distortion occurs.\nWork such as that from Franz \"et al.\" suggests that both the action and perception systems are equally fooled by such illusions. Other studies, however, provide strong support for the idea that skilled actions such as grasping are not affected by pictorial illusions and suggest that the action/perception dissociation is a useful way to characterize the functional division of labor between the dorsal and ventral visual pathways in the cerebral cortex.\nPrimary visual cortex (V1).\nThe primary visual cortex is the most studied visual area in the brain. In mammals, it is located in the posterior pole of the occipital lobe and is the simplest, earliest cortical visual area. It is highly specialized for processing information about static and moving objects and is excellent in pattern recognition.\nMoreover, V1 is characterized by a laminar organization, with six distinct layers, each playing a unique role in visual processing. Neurons in the superficial layers (II and III) are often involved in local processing and communication within the cortex, while neurons in the deeper layers (V and VI) often send information to other brain regions involved in higher-order visual processing and decision-making.\nResearch on V1 has also revealed the presence of orientation-selective cells, which respond preferentially to stimuli with a specific orientation, contributing to the perception of edges and contours. The discovery of these orientation-selective cells has been fundamental in shaping our understanding of how V1 processes visual information.\nFurthermore, V1 exhibits plasticity, allowing it to undergo functional and structural changes in response to sensory experience. Studies have demonstrated that sensory deprivation or exposure to enriched environments can lead to alterations in the organization and responsiveness of V1 neurons.\nThe primary visual cortex, which is defined by its function or stage in the visual system, is approximately equivalent to the striate cortex, also known as Brodmann area 17, which is defined by its anatomical location. The name \"striate cortex\" is derived from the line of Gennari, a distinctive stripe visible to the naked eye that represents myelinated axons from the lateral geniculate body terminating in layer 4 of the gray matter.\nIn the case of the striate cortex, the line of Gennari corresponds to a band rich in myelinated nerve fibers, providing a clear marker for the primary visual processing region.\nAdditionally, the functional significance of the striate cortex extends beyond its role as the primary visual cortex. It serves as a crucial hub for the initial processing of visual information, such as the analysis of basic features like orientation, spatial frequency, and color. The integration of these features in the striate cortex forms the foundation for more complex visual processing carried out in higher-order visual areas. Recent neuroimaging studies have contributed to a deeper understanding of the dynamic interactions within the striate cortex and its connections with other visual and non-visual brain regions, shedding light on the neural circuits that underlie visual perception.\nThe primary visual cortex is divided into six functionally distinct layers, labeled 1 to 6. Layer 4, which receives most visual input from the lateral geniculate nucleus (LGN), is further divided into 4 layers, labelled 4A, 4B, 4C\u03b1, and 4C\u03b2. Sublamina 4C\u03b1 receives mostly magnocellular input from the LGN, while layer 4C\u03b2 receives input from parvocellular pathways.\nThe average number of neurons in the adult human primary visual cortex in each hemisphere has been estimated at 140 million. The volume of each V1 area in an adult human is about 5400mmformula_1 on average. A study of 25 hemispheres from 15 normal individuals with average age 59 years at autopsy found a very high variation, from 4272 to 7027mmformula_1 for the right hemisphere (mean 5692mmformula_1), and from 3185 to 7568mmformula_1 for the left hemisphere (mean 5119mmformula_1), with 0.81 correlation between left and right hemispheres. The same study found average V1 area 2400mmformula_6 per hemisphere, but with very high variability. (Right hemisphere mean 2477mmformula_6, range 1441\u20133221mmformula_6. Left hemisphere mean 2315mmformula_6, range 1438\u20133365mmformula_6.)\nFunction.\nThe initial stage of visual processing within the visual cortex, known as V1, plays a fundamental role in shaping our perception of the visual world. V1 possesses a meticulously defined map, referred to as the retinotopic map, which intricately organizes spatial information from the visual field. In humans, the upper bank of the calcarine sulcus in the occipital lobe robustly responds to the lower half of the visual field, while the lower bank responds to the upper half. This retinotopic mapping conceptually represents a projection of the visual image from the retina to V1.\nThe importance of this retinotopic organization lies in its ability to preserve spatial relationships present in the external environment. Neighboring neurons in V1 exhibit responses to adjacent portions of the visual field, creating a systematic representation of the visual scene. This mapping extends both vertically and horizontally, ensuring the conservation of both horizontal and vertical relationships within the visual input.\nMoreover, the retinotopic map demonstrates a remarkable degree of plasticity, adapting to alterations in visual experience. Studies have revealed that changes in sensory input, such as those induced by visual training or deprivation, can lead to shifts in the retinotopic map.\nBeyond its spatial processing role, the retinotopic map in V1 establishes connections with other visual areas, forming a network crucial for integrating diverse visual features and constructing a coherent visual percept. This dynamic mapping mechanism is indispensable for our ability to navigate and interpret the visual world effectively.\nThe correspondence between specific locations in V1 and the subjective visual field is exceptionally precise, even extending to map the blind spots of the retina. Evolutionarily, this correspondence is a fundamental feature found in most animals possessing a V1. In humans and other species with a fovea (cones in the retina), a substantial portion of V1 is mapped to the small central portion of the visual field, a phenomenon termed cortical magnification. This magnification reflects an increased representation and processing capacity devoted to the central visual field, essential for detailed visual acuity and high-resolution processing.\nNotably, neurons in V1 have the smallest receptive field size, signifying the highest resolution, among visual cortex microscopic regions. This specialization equips V1 with the ability to capture fine details in the visual input.\nIn addition to its role in spatial processing, the retinotopic map in V1 is connected with other visual areas, forming a network that contributes to the integration of various visual features and the construction of a coherent visual percept. The correspondence between a given location in V1 and in the subjective visual field is very precise: even the blind spots of the retina are mapped into V1. In terms of evolution, this correspondence is very basic and found in most animals that possess a V1. In humans and other animals with a fovea (cones in the retina), a large portion of V1 is mapped to the small, central portion of visual field, a phenomenon known as cortical magnification. Perhaps for the purpose of accurate spatial encoding, neurons in V1 have the smallest receptive field size (that is, the highest resolution) of any visual cortex microscopic regions.\nThe tuning properties of V1 neurons (what the neurons respond to) differ greatly over time. Early in time (40 ms and further) individual V1 neurons have strong tuning to a small set of stimuli. That is, the neuronal responses can discriminate small changes in visual orientations, spatial frequencies and colors (as in the optical system of a camera obscura, but projected onto retinal cells of the eye, which are clustered in density and fineness). Each V1 neuron propagates a signal from a retinal cell, in continuation. Furthermore, individual V1 neurons in humans and other animals with binocular vision have ocular dominance, namely tuning to one of the two eyes. In V1, and primary sensory cortex in general, neurons with similar tuning properties tend to cluster together as cortical columns. David Hubel and Torsten Wiesel proposed the classic ice-cube organization model of cortical columns for two tuning properties: ocular dominance and orientation. However, this model cannot accommodate the color, spatial frequency and many other features to which neurons are tuned . The exact organization of all these cortical columns within V1 remains a hot topic of current research.\nThe receptive fields of V1 neurons resemble Gabor functions, so the operation of the visual cortex has been compared to the Gabor transform.\nLater in time (after 100 ms), neurons in V1 are also sensitive to the more global organisation of the scene. These response properties probably stem from recurrent feedback processing (the influence of higher-tier cortical areas on lower-tier cortical areas) and lateral connections from pyramidal neurons. While feedforward connections are mainly driving, feedback connections are mostly modulatory in their effects. Evidence shows that feedback originating in higher-level areas such as V4, IT, or MT, with bigger and more complex receptive fields, can modify and shape V1 responses, accounting for contextual or extra-classical receptive field effects.\nThe visual information relayed by V1 is sometimes described as edge detection. As an example, for an image comprising half side black and half side white, the dividing line between black and white has strongest local contrast (that is, edge detection) and is encoded, while few neurons code the brightness information (black or white per se). As information is further relayed to subsequent visual areas, it is coded as increasingly non-local frequency/phase signals. Note that, at these early stages of cortical visual processing, spatial location of visual information is well preserved amid the local contrast encoding (edge detection).\nIn primates, one role of V1 might be to create a saliency map (highlights what is important) from visual inputs to guide the shifts of attention known as gaze shifts.\nAccording to the V1 Saliency Hypothesis, V1 does this by transforming visual inputs to neural firing rates from millions of neurons, such that the visual location signaled by the highest firing neuron is the most salient location to attract gaze shift. V1's outputs are received by the superior colliculus (in the mid-brain), among other locations, which reads out the V1 activities to guide gaze shifts.\nDifferences in size of V1 also seem to have an effect on the perception of illusions.\nV2.\nVisual area V2, or secondary visual cortex, also called prestriate cortex, receives strong feedforward connections from V1 (direct and via the pulvinar) and sends robust connections to V3, V4, and V5. Additionally, it plays a crucial role in the integration and processing of visual information.\nThe feedforward connections from V1 to V2 contribute to the hierarchical processing of visual stimuli. V2 neurons build upon the basic features detected in V1, extracting more complex visual attributes such as texture, depth, and color. This hierarchical processing is essential for the construction of a more detailed representation of the visual scene.\nFurthermore, the reciprocal feedback connections from V2 to V1 play a significant role in modulating the activity of V1 neurons. This feedback loop is thought to be involved in processes such as attention, perceptual grouping, and figure-ground segregation. The dynamic interplay between V1 and V2 highlights the intricate nature of information processing within the visual system.\nMoreover, V2's connections with subsequent visual areas, including V3, V4, and V5, contribute to the formation of a distributed network for visual processing. These connections enable the integration of different visual features, such as motion and form, across multiple stages of the visual hierarchy.\nIn terms of anatomy, V2 is split into four quadrants, a dorsal and ventral representation in the left and the right hemispheres. Together, these four regions provide a complete map of the visual world. V2 has many properties in common with V1: Cells are tuned to simple properties such as orientation, spatial frequency, and color. The responses of many V2 neurons are also modulated by more complex properties, such as the orientation of illusory contours, binocular disparity, and whether the stimulus is part of the figure or the ground. Recent research has shown that V2 cells show a small amount of attentional modulation (more than V1, less than V4), are tuned for moderately complex patterns, and may be driven by multiple orientations at different subregions within a single receptive field.\nIt is argued that the entire ventral visual-to-hippocampal stream is important for visual memory. This theory, unlike the dominant one, predicts that object-recognition memory (ORM) alterations could result from the manipulation in V2, an area that is highly interconnected within the ventral stream of visual cortices. In the monkey brain, this area receives strong feedforward connections from the primary visual cortex (V1) and sends strong projections to other secondary visual cortices (V3, V4, and V5). Most of the neurons of this area in primates are tuned to simple visual characteristics such as orientation, spatial frequency, size, color, and shape. Anatomical studies implicate layer 3 of area V2 in visual-information processing. In contrast to layer 3, layer 6 of the visual cortex is composed of many types of neurons, and their response to visual stimuli is more complex.\nIn one study, the Layer 6 cells of the V2 cortex were found to play a very important role in the storage of Object Recognition Memory as well as the conversion of short-term object memories into long-term memories.\nThird visual cortex, including area V3.\nThe term third visual complex refers to the region of cortex located immediately in front of V2, which includes the region named visual area V3 in humans. The \"complex\" nomenclature is justified by the fact that some controversy still exists regarding the exact extent of area V3, with some researchers proposing that the cortex located in front of V2 may include two or three functional subdivisions. For example, David Van Essen and others (1986) have proposed the existence of a \"dorsal V3\" in the upper part of the cerebral hemisphere, which is distinct from the \"ventral V3\" (or ventral posterior area, VP) located in the lower part of the brain. Dorsal and ventral V3 have distinct connections with other parts of the brain, appear different in sections stained with a variety of methods, and contain neurons that respond to different combinations of visual stimulus (for example, colour-selective neurons are more common in the ventral V3). Additional subdivisions, including V3A and V3B have also been reported in humans. These subdivisions are located near dorsal V3, but do not adjoin V2.\nDorsal V3 is normally considered to be part of the dorsal stream, receiving inputs from V2 and from the primary visual area and projecting to the posterior parietal cortex. It may be anatomically located in Brodmann area 19. Braddick using fMRI has suggested that area V3/V3A may play a role in the processing of global motion Other studies prefer to consider dorsal V3 as part of a larger area, named the dorsomedial area (DM), which contains a representation of the entire visual field. Neurons in area DM respond to coherent motion of large patterns covering extensive portions of the visual field (Lui and collaborators, 2006).\nVentral V3 (VP), has much weaker connections from the primary visual area, and stronger connections with the inferior temporal cortex. While earlier studies proposed that VP contained a representation of only the upper part of the visual field (above the point of fixation), more recent work indicates that this area is more extensive than previously appreciated, and like other visual areas it may contain a complete visual representation. The revised, more extensive VP is referred to as the ventrolateral posterior area (VLP) by Rosa and Tweedale.\nV4.\nVisual area V4 is one of the visual areas in the extrastriate visual cortex. In macaques, it is located anterior to V2 and posterior to the posterior inferotemporal area (PIT). It comprises at least four regions (left and right V4d, left and right V4v), and some groups report that it contains rostral and caudal subdivisions as well. It is unknown whether the human V4 is as expansive as that of the macaque homologue. This is a subject of debate.\nV4 is the third cortical area in the ventral stream, receiving strong feedforward input from V2 and sending strong connections to the PIT. It also receives direct input from V1, especially for central space. In addition, it has weaker connections to V5 and the dorsal prelunate gyrus (DP).\nV4 is the first area in the ventral stream to show strong attentional modulation. Most studies indicate that selective attention can change firing rates in V4 by about 20%. A seminal paper by Moran and Desimone characterizing these effects was the first paper to find attention effects anywhere in the visual cortex.\nLike V2, V4 is tuned for orientation, spatial frequency, and color. Unlike V2, V4 is tuned for object features of intermediate complexity, like simple geometric shapes, although no one has developed a full parametric description of the tuning space for V4. Visual area V4 is not tuned for complex objects such as faces, as areas in the inferotemporal cortex are.\nThe firing properties of V4 were first described by Semir Zeki in the late 1970s, who also named the area. Before that, V4 was known by its anatomical description, the prelunate gyrus. Originally, Zeki argued that the purpose of V4 was to process color information. Work in the early 1980s proved that V4 was as directly involved in form recognition as earlier cortical areas. This research supported the two-streams hypothesis, first presented by Ungerleider and Mishkin in 1982.\nRecent work has shown that V4 exhibits long-term plasticity, encodes stimulus salience, is gated by signals coming from the frontal eye fields, and shows changes in the spatial profile of its receptive fields with attention. In addition, it has recently been shown that activation of area V4 in humans (area V4h) is observed during the perception and retention of the color of objects, but not their shape.\nMiddle temporal visual area (V5).\nThe middle temporal visual area (MT or V5) is a region of extrastriate visual cortex. In several species of both New World monkeys and Old World monkeys the MT area contains a high concentration of direction-selective neurons. The MT in primates is thought to play a major role in the perception of motion, the integration of local motion signals into global percepts, and the guidance of some eye movements.\nConnections.\nMT is connected to a wide array of cortical and subcortical brain areas. Its input comes from visual cortical areas V1, V2 and dorsal V3 (dorsomedial area), the koniocellular regions of the LGN, and the inferior pulvinar. The pattern of projections to MT changes somewhat between the representations of the foveal and peripheral visual fields, with the latter receiving inputs from areas located in the midline cortex and retrosplenial region.\nA standard view is that V1 provides the \"most important\" input to MT. Nonetheless, several studies have demonstrated that neurons in MT are capable of responding to visual information, often in a direction-selective manner, even after V1 has been destroyed or inactivated. Moreover, research by Semir Zeki and collaborators has suggested that certain types of visual information may reach MT before it even reaches V1.\nMT sends its major output to areas located in the cortex immediately surrounding it, including areas FST, MST, and V4t (middle temporal crescent). Other projections of MT target the eye movement-related areas of the frontal and parietal lobes (frontal eye field and lateral intraparietal area).\nFunction.\nThe first studies of the electrophysiological properties of neurons in MT showed that a large portion of the cells are tuned to the speed and direction of moving visual stimuli.\nLesion studies have also supported the role of MT in motion perception and eye movements. Neuropsychological studies of a patient unable to see motion, seeing the world in a series of static 'frames' instead, suggested that V5 in the primate is homologous to MT in the human.\nHowever, since neurons in V1 are also tuned to the direction and speed of motion, these early results left open the question of precisely what MT could do that V1 could not. Much work has been carried out on this region, as it appears to integrate local visual motion signals into the global motion of complex objects.\nFor example, \"lesion\" to the V5 leads to deficits in perceiving motion and processing of complex stimuli. It contains many neurons selective for the motion of complex visual features (line ends, corners). \"Microstimulation\" of a neuron located in the V5 affects the perception of motion. For example, if one finds a neuron with preference for upward motion in a monkey's V5 and stimulates it with an electrode, then the monkey becomes more likely to report 'upward' motion when presented with stimuli containing 'left' and 'right' as well as 'upward' components.\nThere is still much controversy over the exact form of the computations carried out in area MT and some research suggests that feature motion is in fact already available at lower levels of the visual system such as V1.\nFunctional organization.\nMT was shown to be organized in direction columns. DeAngelis argued that MT neurons were also organized based on their tuning for binocular disparity.\nV6.\nThe dorsomedial area (DM) also known as V6, appears to respond to visual stimuli associated with self-motion and wide-field stimulation. V6 is a subdivision of the visual cortex of primates first described by John Allman and Jon Kaas in 1975. V6 is located in the dorsal part of the extrastriate cortex, near the deep groove through the centre of the brain (medial longitudinal fissure), and typically also includes portions of the medial cortex, such as the parieto-occipital sulcus (POS). DM contains a topographically organized representation of the entire field of vision.\nThere are similarities between the visual area V5 and V6 of the common marmoset. Both areas receive direct connections from the primary visual cortex. And both have a high myelin content, a characteristic that is usually present in brain structures involved in fast transmission of information.\nFor many years, it was considered that DM only existed in New World monkeys. However, more recent research has suggested that DM also exists in Old World monkeys and humans. V6 is also sometimes referred to as the parieto-occipital area (PO), although the correspondence is not exact.\nProperties.\nNeurons in area DM/V6 of night monkeys and common marmosets have unique response properties, including an extremely sharp selectivity for the orientation of visual contours, and preference for long, uninterrupted lines covering large parts of the visual field.\nHowever, in comparison with area MT, a much smaller proportion of DM cells shows selectivity for the direction of motion of visual patterns. Another notable difference with area MT is that cells in DM are attuned to low spatial frequency components of an image, and respond poorly to the motion of textured patterns such as a field of random dots. These response properties suggest that DM and MT may work in parallel, with the former analyzing self-motion relative to the environment, and the latter analyzing the motion of individual objects relative to the background.\nRecently, an area responsive to wide-angle flow fields has been identified in the human and is thought to be a homologue of macaque area V6.\nPathways.\nThe connections and response properties of cells in DM/V6 suggest that this area is a key node in a subset of the \"dorsal stream\", referred to by some as the \"dorsomedial pathway\". This pathway is likely to be important for the control of skeletomotor activity, including postural reactions and reaching movements towards objects The main 'feedforward' connection of DM is to the cortex immediately rostral to it, in the interface between the occipital and parietal lobes (V6A). This region has, in turn, relatively direct connections with the regions of the frontal lobe that control arm movements, including the premotor cortex.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32529", "revid": "29695", "url": "https://en.wikipedia.org/wiki?curid=32529", "title": "Velociraptor", "text": "Genus of Late Cretaceous dinosaur\nVelociraptor (; lit.\u2009'swift thief') is a genus of small dromaeosaurid dinosaurs that lived in Asia during the Late Cretaceous epoch, about 75 million to 71 million years ago (Mya). Two species are currently recognized, although others have been assigned in the past. The type species is V. mongoliensis, named and described in 1924. Fossils of this species have been discovered in the Djadochta Formation, Mongolia. A second species, V. osmolskae, was named in 2008 for skull material from the Bayan Mandahu Formation, China. A possible record is known from the Nemegt Formation.\nSmaller than other dromaeosaurids like \"Deinonychus\" and \"Achillobator\", \"Velociraptor\" was about long with a body mass around . It nevertheless shared many of the same anatomical features. It was a bipedal, feathered carnivore with a long tail and an enlarged sickle-shaped claw on each hindfoot, which is thought to have been used to tackle and restrain prey. \"Velociraptor\" can be distinguished from other dromaeosaurids by its long and low skull, with an upturned snout.\n\"Velociraptor\" (commonly referred to as \"raptor\") is one of the dinosaur genera most familiar to the general public due to its prominent role in the \"Jurassic Park\" films. In reality, however, \"Velociraptor\" was roughly the size of a turkey, considerably smaller than the approximately tall and reptiles seen in the novels and films (which were based on members of the related genus \"Deinonychus\"). Today, \"Velociraptor\" is well known to paleontologists, with over a dozen described fossil skeletons. One particularly famous specimen preserves a \"Velociraptor\" locked in combat with a \"Protoceratops\".\nHistory of discovery.\nDuring an American Museum of Natural History expedition to the Flaming Cliffs (Bayn Dzak or Bayanzag) of the Djadochta Formation, Gobi Desert, on 11 August 1923, Peter Kaisen discovered the first \"Velociraptor\" fossil known to science\u2014a crushed but complete skull, associated with one manual claw and adjoining phalanges (AMNH 6515). In 1924, museum president Henry Fairfield Osborn designated the skull and part of the manus as the type specimen of his new genus, \"Velociraptor\". This name is derived from the Latin words ('swift') and ('robber' or 'plunderer') and refers to the animal's cursorial nature and carnivorous diet. Osborn named the type species \"V. mongoliensis\" after its country of origin. Earlier that year, Osborn had informally mentioned the animal in a popular press article, under the name \"Ovoraptor djadochtari\" (not to be confused with the similarly named \"Oviraptor\"), eventually changed into \"V. mongoliensis\" during its formal description.\nWhile North American teams were shut out of communist Mongolia during the Cold War, expeditions by Soviet and Polish scientists, in collaboration with Mongolian colleagues, recovered several more specimens of \"Velociraptor\". The most famous is part of the \"Fighting Dinosaurs\" specimen (MPC-D 100/25; formerly IGM, GIN, or GI SPS), discovered by a Polish-Mongolian team in 1971. The fossil preserves a \"Velociraptor\" in battle against a \"Protoceratops\". It is considered a national treasure of Mongolia, and in 2000 it was loaned to the American Museum of Natural History in New York City for a temporary exhibition.\nBetween 1988 and 1990, a joint Chinese-Canadian team discovered \"Velociraptor\" remains in northern China. American scientists returned to Mongolia in 1990, and a joint Mongolian-American expedition to the Gobi, led by the American Museum of Natural History and the Mongolian Academy of Sciences, turned up several well-preserved skeletons. One such specimen, MPC-D 100/980, was nicknamed \"Ichabodcraniosaurus\" by Norell's team because the fairly complete specimen was found without its skull (an allusion to the Washington Irving character Ichabod Crane). While Norell and Makovicky provisionally considered it a specimen of \"Velociraptor mongoliensis\", it was named as a new species \"Shri devi\" in 2021.\nIn 1999, Rinchen Barsbold and Halszka Osm\u00f3lska reported a juvenile \"Velociraptor\" specimen (GIN or IGM 100/2000), represented by a complete skeleton including the skull of a young individual. It was found at the Tugriken Shireh locality of the Djadochta Formation during the context of the Mongolian-Japanese Palaeontological Expeditions. The coauthors stated that detailed descriptions of this and other specimens would be published at a later date.\nAdditional species.\nMaxillae and a lacrimal (the main tooth-bearing bones of the upper jaw, and the bone that forms the anterior margin of the eye socket, respectively) recovered from the Bayan Mandahu Formation in 1999 by the Sino-Belgian Dinosaur Expeditions were found to pertain to \"Velociraptor\", but not to the type species \"V. mongoliensis\". Pascal Godefroit and colleagues named these bones \"V. osmolskae\" (for Polish paleontologist Halszka Osm\u00f3lska) in 2008. However, the 2013 study noted that while \"the elongate shape of the maxilla in \"V. osmolskae\" is similar to that of \"V. mongoliensis\",\" phylogenetic analysis found it to be closer to \"Linheraptor\", making the genus paraphyletic; thus, \"V. osmolskae\" might not actually belong to the genus \"Velociraptor\" and requires reassessment.\nPaleontologists Mark A. Norell and Peter J. Makovicky in 1997 described new and well preserved specimens of \"V. mongoliensis\", namely MPC-D 100/985 collected from the Tugrik Shireh locality in 1993, and MPC-D 100/986 collected in 1993 from the Chimney Buttes locality. The team briefly mentioned another specimen, MPC-D 100/982, which by the time of this publication remained undescribed. In 1999 Norell and Makovicky provided more insights into the anatomy of \"Velociraptor\" with additional specimens. Among these, MPC-D 100/982 was partially described and figured, and referred to \"V. mongoliensis\" mainly based on cranial similarities with the holotype skull, although they stated that differences were present between the pelvic region of this specimen and other \"Velociraptor\" specimens. This relatively well-preserved specimen including the skull was discovered and collected in 1995 at the Bayn Dzak locality (specifically at the \"Volcano\" sub-locality). Martin Kundr\u00e1t in a 2004 abstract compared the neurocranium of MPC-D 100/982 to another \"Velociraptor\" specimen, MPC-D 100/976. He concluded that the overall morphology of the former was more derived (advanced) than the latter, suggesting that they could represent distinct taxa.\nMark J. Powers in his 2020 master thesis fully described MPC-D 100/982, which he concluded to represent a new and third species of \"Velociraptor\". This species, which he considered distinct, was stated to mainly differ from other \"Velociraptor\" species in having a shallow maxilla morphology. Powers and colleagues also in 2020 used morphometric analyses to compare several dromaeosaurid maxillae, and found the maxilla of MPC-D 100/982 to strongly differ from specimens referred to \"Velociraptor\". They indicated that this specimen, based on these results, represents a different species. In 2021 Powers with team used Principal Component Analysis to separate dromaeosaurid maxillae, most notably finding that MPC-D 100/982 falls outside the instraspecific variability of \"V. mongoliensis\", arguing for a distinct species. They considered that both \"V. mongoliensis\" and this new species were ecologically separated based on their skull anatomy. The team in another 2021 abstract reinforced again the species-level separation, noting that additional differences can be found in the hindlimbs.\nDescription.\n\"Velociraptor\" was a small to medium-sized dromaeosaurid, with adults measuring between long, approximately high at the hips, and weighing about .\nProminent quill knobs\u2014attachment site of \"wing\" feathers and direct indicator of a feather covering\u2014have been reported from the ulna of a single \"Velociraptor\" specimen (IGM 100/981), which represents an animal of estimated long and in weight. The spacing of 6 preserved knobs suggests that 8 additional knobs may have been present, giving a total of 14 quill knobs that developed large secondaries (\"wing\" feathers stemming from the forearm). However, the specimen number has been corrected to IGM 100/3503 and its referral to \"Velociraptor\" may require reevaluation, pending further study. Nevertheless, there is strong phylogenetic evidence from other dromaeosaurid relatives that indicates the presence of feathers in \"Velociraptor\", including dromaeosaurids such as \"Daurlong\", \"Microraptor\", or \"Zhenyuanlong\".\nSkull.\nThe skull of \"Velociraptor\" was rather elongated and grew up to long. It was uniquely up-curved at the snout region, concave on the upper surface, and convex on the lower surface. The snout, which occupied about 60% of the entire skull length, was notably narrow and mainly formed by the nasal, premaxilla, and maxilla bones. The &lt;dfn id=\"\"&gt;premaxilla&lt;/dfn&gt; was the anteriormost bone in the skull, and it was longer than taller. While its posterior end joined the nasal, the main body of the premaxilla touched the maxilla. The &lt;dfn id=\"\"&gt;maxilla&lt;/dfn&gt; was nearly triangular in shape and the largest element of the snout. On its center or main body, there was a depression developing a small oval to circular-shaped hole, called maxillary fenestra. Though in front of this fenestra were two small openings, referred to as promaxillary fenestrae. The posterior border of the maxilla formed (predominantly) the antorbital fenestra, one of the several large holes in the skull. Both premaxilla and maxilla had several alveoli (tooth sockets) on their bottom surfaces. Above the maxilla and making contact with the premaxilla, there was the &lt;dfn id=\"\"&gt;nasal&lt;/dfn&gt; bone. It was a thin/narrow and elongated bone contributing to the top surface of the snout. Together, both premaxilla and nasal bones gave form to the naris or narial fenestra (nostril opening), which was relatively large and circular. The posterior end of the nasal was joined by the frontal and lacrimal bones.\nThe back or posterior region of the skull was built by the frontal, lacrimal, postorbital, jugal, parietal, quadrate, and quadratojugal bones. The &lt;dfn id=\"\"&gt;frontal&lt;/dfn&gt; was large element, having a vaguely rectangular shape when seen from above. On its posterior end, this bone was in contact with the &lt;dfn id=\"\"&gt;parietal&lt;/dfn&gt;, and such elements were the main bodies of the skull roof. The &lt;dfn id=\"\"&gt;lacrimal&lt;/dfn&gt; was a T-shaped bone and its main body was thin and delicated. Its lower end meet the &lt;dfn id=\"\"&gt;jugal&lt;/dfn&gt; (often called cheek bone), which was a large, sub-triangular-shaped element. Its lower border was notably straight/horizontal. The &lt;dfn id=\"\"&gt;postorbital&lt;/dfn&gt; was located just above the jugal: a stocky and strongly T-shaped bone. As a whole, the orbit or orbital fenestra (eye socket)\u2014formed by the lacrimal, jugal, frontal, and postorbital\u2014was large and near circular in shape, being longer than taller. When seen from above, a pair of large and markedly rounded holes were present near the rear of the skull (the temporal fenestrae), whose main components were the postorbital and squamosal. Behind the jugal, an inverted T-shaped bone (also seen in other dromaeosaurids), known as the &lt;dfn id=\"\"&gt;quadratojugal&lt;/dfn&gt;, was developed. While the upper end of the quadratojugal joined the &lt;dfn id=\"\"&gt;squamosal&lt;/dfn&gt;, an irregularly-shaped element, its inner side meet the &lt;dfn id=\"\"&gt;quadrate&lt;/dfn&gt;. The latter was of great importance for the articulation with the lower jaw. The posteriormost bone was the &lt;dfn id=\"\"&gt;occipital bone&lt;/dfn&gt; and its projection the occipital condyle: a rounded and bulbous protuberance that meet the first vertebra of the neck.\nThe lower jaw of \"Velociraptor\" comprised mainly the dentary, splenial, angular, surangular, and articular bones. The &lt;dfn id=\"\"&gt;dentary&lt;/dfn&gt; was a very long, weakly curved, and narrow element that developed several alveoli on its top surface. On its posterior end, it meet the &lt;dfn id=\"\"&gt;surangular&lt;/dfn&gt;. It had a small hole near its posterior end, called surangular foramen or fenestra. Both bones were the largest elements of the lower jaw of \"Velociraptor\", contributing to virtually its entire length. Below them were the smaller &lt;dfn id=\"\"&gt;splenial&lt;/dfn&gt; and &lt;dfn id=\"\"&gt;angular&lt;/dfn&gt;, closely articulated to each other. The &lt;dfn id=\"\"&gt;articular&lt;/dfn&gt;, located on the inner side of the surangular, was a small element that joined the quadrate of the upper skull, enabling the articulation with the lower jaw. An elongated, near oval-shaped hole was developed in the center of the lower jaw (the mandibular fenestra), and it was produced by the joint of the dentary, surangular, and angular bones.\nThe teeth of \"Velociraptor\" were fairly homodont (equal in shape) and had several denticles (serrations), each more strongly serrated on the back edge than the front. The premaxilla had 4 alveoli (meaning that 4 teeth were developed), and the maxilla had 11 alveoli. At the dentary, between 14\u201315 alveoli were present. All teeth present at the premaxilla were poorly curved, and the two first teeth were the longest, with the second having a characteristic large size. The maxillary teeth were more slender, recurved, and most notably, the lower end was strongly more serrated than the upper one.\nPostcranial skeleton.\nThe arm of \"Velociraptor\" was formed by the humerus (upper arm bone), radius and ulna (forearm bones), and manus (hand). \"Velociraptor\", like other dromaeosaurids, had a large manus with three elongated digits (fingers), which ended up in strongly curved unguals (claw bones) that were similar in construction and flexibility to the wing bones of modern birds. The second digit was the longest of the three digits present, while the first was shortest. The structure of the carpal (wrist) bones prevented pronation of the wrist and forced the manus to be held with the palmar surface facing inward (medially), not downward. The pes (foot) anatomy of \"Velociraptor\" consisted of the metatarsus\u2014a large element composed of three metatarsals of which the first one was extremely reduced in size\u2014and four digits that developed large unguals. The first digit, as in other theropods, was a small dewclaw. The second digit, for which \"Velociraptor\" is most famous, was highly modified and held retracted off the ground, which caused \"Velociraptor\" and other dromaeosaurids to walk on only their third and fourth digits. It bore a relatively large, sickle-shaped claw, typical of dromaeosaurid and troodontid dinosaurs. This enlarged claw, which could grow to over long around its outer edge, was most likely a predatory device used to restrain struggling prey.\nAs in other dromaeosaurs, \"Velociraptor\" tails had prezygapophyses (long bony projections) on the upper surfaces of the vertebrae, as well as ossified tendons underneath. The prezygapophyses began on the tenth tail (caudal) vertebra and extended forward to brace four to ten additional vertebrae, depending on position in the tail. These were once thought to fully stiffen the tail, forcing the entire tail to act as a single rod-like unit. However, at least one specimen has preserved a series of intact tail vertebrae curved sideways into an \"S\"-shape, suggesting that there was considerably more horizontal flexibility than once thought.\nClassification.\n\"Velociraptor\" is a member of the group Eudromaeosauria, a derived sub-group of the larger family Dromaeosauridae. It is often placed within its own subfamily, Velociraptorinae. In phylogenetic taxonomy, Velociraptorinae is usually defined as \"all dromaeosaurs more closely related to \"Velociraptor\" than to \"Dromaeosaurus\".\" However, dromaeosaurid classification is highly variable. Originally, the subfamily Velociraptorinae was erected solely to contain \"Velociraptor\". Other analyses have often included other genera, usually \"Deinonychus\" and \"Saurornitholestes\", and more recently \"Tsaagan\". Several studies published during the 2010s, including expanded versions of the analyses that found support for Velociraptorinae, have failed to resolve it as a distinct group, but rather have suggested it is a paraphyletic grade which gave rise to the Dromaeosaurinae.\nWhen first described in 1924, \"Velociraptor\" was placed in the family Megalosauridae, as was the case with most carnivorous dinosaurs at the time (Megalosauridae, like \"Megalosaurus\", functioned as a sort of 'wastebin' taxon, where many unrelated species were grouped together). As dinosaur discoveries multiplied, \"Velociraptor\" was later recognized as a dromaeosaurid. All dromaeosaurids have also been referred to the family Archaeopterygidae by at least one author (which would, in effect, make \"Velociraptor\" a flightless bird). In the past, other dromaeosaurid species, including \"Deinonychus antirrhopus\" and \"Saurornitholestes langstoni\", have sometimes been classified in the genus \"Velociraptor\". Since \"Velociraptor\" was the first to be named, these species were renamed \"Velociraptor antirrhopus\" and \"V. langstoni\". the only currently recognized species of \"Velociraptor\" are \"V. mongoliensis\" and \"V. osmolskae\". However, several studies have found \"V.\" \"osmolskae\" to be distantly related to \"V. mongoliensis\".\nBelow are the results for the Eudromaeosauria phylogeny based on the phylogenetic analysis conducted by James G. Napoli and team in 2021 during the description of \"Kuru\", showing the position of \"Velociraptor\":\nPaleobiology.\nFeathers.\nIn 2007 Alan H. Turner and colleagues reported the presence of six quill knobs in the ulna of a referred \"Velociraptor\" specimen (IGM 100/981) from the Ukhaa Tolgod locality of the Djadochta Formation. Turner and colleagues interpreted the presence of feathers on \"Velociraptor\" as evidence against the idea that the larger, flightless maniraptorans lost their feathers secondarily due to larger body size. Furthermore, they noted that quill knobs are almost never found in flightless bird species today, and that their presence in \"Velociraptor\" (presumed to have been flightless due to its relatively large size and short forelimbs) is evidence that the ancestors of dromaeosaurids could fly, making \"Velociraptor\" and other large members of this family secondarily flightless, though it is possible the large wing feathers inferred in the ancestors of \"Velociraptor\" had a purpose other than flight. The feathers of the flightless \"Velociraptor\" may have been used for display, for covering their nests while brooding, or for added speed and thrust when running up inclined slopes.\nBecause of the presence of another dromaeosaurid in Ukhaa Tolgod, \"Tsaagan\", Napoli and team have noted that the referral of this specimen to \"Velociraptor\" is currently subject to reexamination.\nSenses.\nExaminations of the endocranium of \"Velociraptor\" indicate that it was able to detect and hear a wide range of sound frequencies (2,368\u20133,965\u00a0Hz) and could track prey with ease as a result. The endocranium examinations also further cemented the theory that the dromaeosaur was an agile, swift predator. Fossil evidence suggesting \"Velociraptor\" scavenged also indicates that it was an opportunistic and actively predatory animal, feeding on carrion during times of drought or famine, if in poor health, or depending on the animal's age.\nFeeding.\nIn 2020, Powers and colleagues re-examined the maxillae of several eudromaeosaur taxa concluding that most Asian and North American eudromaeosaurs were separated by snout morphology and ecological strategies. They found the maxilla to be a reliable reference when inferring the shape of the premaxilla and overall snout. For instance, most Asian species have elongated snouts based on the maxilla (namely velociraptorines), indicating a selective feeding in \"Velociraptor\" and relatives, such as picking up small, fast prey. In contrast, most North American eudromaeosaurs, mostly dromaeosaurines, feature a robust and deep maxillar morphology. However, the large dromaeosurine \"Achillobator\" is a unique exception to Asian taxa with its deep maxilla.\nManabu Sakamoto in 2022 performed a Bayesian phylogenetic predictive modelling framework for estimating jaw muscle parameters and bite forces of several extinct archosaurs, based on skull widths and phylogenetic relationships between groups. Among studied taxa, \"Velociraptor\" was scored with a bite force of 304 N, which was lower than that of other dromaeosaurids such as \"Dromaeosaurus\" (885 N) or \"Deinonychus\" (706 N).\nPredatory behavior.\nThe \"Fighting Dinosaurs\" specimen, found in 1971, preserves a \"Velociraptor mongoliensis\" and \"Protoceratops andrewsi\" in combat and provides direct evidence of predatory behavior. When originally reported, it was hypothesized that the two animals drowned. However, as the animals were preserved in ancient sand dune deposits, it is now thought that the animals were buried in sand, either from a collapsing dune or in a sandstorm. Burial must have been extremely rapid, judging from the lifelike poses in which the animals were preserved. Parts of the \"Protoceratops\" are missing, which has been seen as evidence of scavenging by other animals. Comparisons between the scleral rings of \"Velociraptor\", \"Protoceratops\", and modern birds and reptiles indicates that \"Velociraptor\" may have been nocturnal, while \"Protoceratops\" may have been cathemeral, active throughout the day during short intervals, suggesting that the fight may have occurred at twilight or during low-light conditions.\nThe distinctive claw, on the second digit of dromaeosaurids, has traditionally been depicted as a slashing weapon; its assumed use being to cut and disembowel prey. In the \"Fighting Dinosaurs\" specimen, the \"Velociraptor\" lies underneath, with one of its sickle claws apparently embedded in the throat of its prey, while the beak of \"Protoceratops\" is clamped down upon the right forelimb of its attacker. This suggests \"Velociraptor\" may have used its sickle claw to pierce vital organs of the throat, such as the jugular vein, carotid artery, or trachea (windpipe), rather than slashing the abdomen. The inside edge of the claw was rounded and not unusually sharp, which may have precluded any sort of cutting or slashing action, although only the bony core of the claw is preserved. The thick abdominal wall of skin and muscle of large prey species would have been difficult to slash without a specialized cutting surface. The slashing hypothesis was tested during a 2005 BBC documentary, \"The Truth About Killer Dinosaurs\". The producers of the program created an artificial \"Velociraptor\" leg with a sickle claw and used a pork belly to simulate the dinosaur's prey. Though the sickle claw did penetrate the abdominal wall, it was unable to tear it open, indicating that the claw was not used to disembowel prey.\nRemains of \"Deinonychus\", a closely related dromaeosaurid, have commonly been found in aggregations of several individuals. \"Deinonychus\" has also been found in association with the large ornithopod \"Tenontosaurus\", which has been cited as evidence of cooperative (pack) hunting. However, the only solid evidence for social behavior of any kind among dromaeosaurids comes from a Chinese trackway which shows six individuals of a large species moving as a group. Although many isolated fossils of \"Velociraptor\" have been found in Mongolia, none were closely associated with other individuals. Therefore, while \"Velociraptor\" is commonly depicted as a pack hunter, as in \"Jurassic Park\", there is only limited fossil evidence to support this theory for dromaeosaurids in general and none specific to \"Velociraptor\" itself. Dromeosaur footprints in China suggest that a few other raptor genera may have hunted in packs, but there have been no conclusive examples of pack behavior found.\nIn 2011, Denver Fowler and colleagues suggested a new method by which dromaeosaurs like \"Velociraptor\" and similar dromaeosaurs may have captured and restrained prey. This model, known as the \"raptor prey restraint\" (RPR) model of predation, proposes that dromaeosaurs killed their prey in a manner very similar to extant accipitrid birds of prey: by leaping onto their quarry, pinning it under their body weight, and gripping it tightly with the large, sickle-shaped claws. These researchers proposed that, like accipitrids, the dromaeosaur would then begin to feed on the animal while it was still alive, and prey death would eventually result from blood loss and organ failure. This proposal is based primarily on comparisons between the morphology and proportions of the feet and legs of dromaeosaurs to several groups of extant birds of prey with known predatory behaviors. Fowler found that the feet and legs of dromaeosaurs most closely resemble those of eagles and hawks, especially in terms of having an enlarged second claw and a similar range of grasping motion. The short metatarsus and foot strength, however, would have been more similar to that of owls. The RPR method of predation would be consistent with other aspects of \"Velociraptor\"'s anatomy, such as their unusual jaw and arm morphology. The arms, which could exert a lot of force but were likely covered in long feathers, may have been used as flapping stabilizers for balance while atop a struggling prey animal, along with the stiff counterbalancing tail. The jaws, thought by Fowler and colleagues to be comparatively weak, would have been useful for row saw motion bites like the modern day Komodo dragon, which also has a weak bite, to finish off its prey if the kicks were not powerful enough. These predatory adaptations working together may also have implications for the origin of flapping in paravians.\nScavenging behavior.\nIn 2010, Hone and colleagues published a paper on their 2008 discovery of shed teeth of what they believed to be a \"Velociraptor\" near a tooth-marked jaw bone of what they believed to be a \"Protoceratops\" in the Bayan Mandahu Formation. The authors concluded that the find represented \"late-stage carcass consumption by \"Velociraptor\"\" as the predator would have eaten other parts of a freshly killed \"Protoceratops\" before biting in the jaw area. The evidence was seen as supporting the inference from the \"Fighting Dinosaurs\" fossil that \"Protoceratops\" was part of the diet of \"Velociraptor\".\nIn 2012, Hone and colleagues published a paper that described a \"Velociraptor\" specimen with a long bone of an azhdarchid pterosaur in its gut. This was interpreted as showing scavenging behaviour.\nIn a 2024 study by Tse, Miller, and Pittman et al., focusing on the skull morphology and bite forces of various dromaeosaurids, it was discovered that \"Velociraptor\" had high bite force resistance compared to other dromaeosaurids such as \"Dromaeosaurus\" itself and \"Deinonychus\", the latter of which was much larger. It is theorized by the authors that high bite force resistance was an adaptation towards obtaining food through scavenging more often than through active predation in \"Velociraptor\".\nMetabolism.\n\"Velociraptor\" was warm-blooded to some degree, as it required a significant amount of energy to hunt. Modern animals that possess feathery or furry coats, like \"Velociraptor\" did, tend to be warm-blooded, since these coverings function as insulation. However, bone growth rates in dromaeosaurids and some early birds suggest a more moderate metabolism, compared with most modern warm-blooded mammals and birds. The kiwi is similar to dromaeosaurids in anatomy, feather type, bone structure and even the narrow anatomy of the nasal passages (usually a key indicator of metabolism). The kiwi is a highly active, if specialized, flightless bird, with a stable body temperature and a fairly low resting metabolic rate, making it a good model for the metabolism of primitive birds and dromaeosaurids.\nIn 2023, Seishiro Tada and team examined the nasal cavities of ectotherm (cold-blooded) or endotherm (warm-blooded) species, in order to evaluate the thermoregulatory physiology of non-avian dinosaurs compared to these groups. They found that the size of the nasal cavity relative to the head size of extant endotherms is larger than those of extant ectotherms, and among taxa, \"Velociraptor\" was recovered below the extant endotherms level by reconstructing its nasal respiratory cavity. Tada with team suggested that \"Velociraptor\" and most other non-avian dinosaurs may not have possessed a fully or well-developed nasal thermoregulation apparatus as modern endothermic animals do.\nPaleopathology.\nNorell with colleagues in 1995 reported one \"V. mongoliensis\" skull bearing two parallel rows of small punctures on its frontal bones that, upon closer examination, match the spacing and size of \"Velociraptor\" teeth. They suggested that the wound was likely inflicted by another \"Velociraptor\" during a fight within the species. Because its bone structure shows no sign of healing near the bite wounds and the overall specimen was not scavenged, this individual was likely killed by this fatal wound. In 2001 Molnar and team noted that this specimen is MPC-D 100/976 hailing from the Tugrik Shireh locality, which has also yielded the Fighting Dinosaurs specimen.\nIn 2012 David Hone and team reported another injured \"Velociraptor\" specimen (MPC-D 100/54, roughly a sub-adult individual) found with the bones of an azhdarchid pterosaur within its stomach cavity, was carrying or recovering from an injury sustained to one broken rib. From evidence on the pterosaur bones, which were devoid of pitting or deformations from digestion, the \"Velociraptor\" died shortly after, possibly from the earlier injury. Nevertheless, the team noted that this broken ribs shows signs of bone healing.\nPaleoenvironment.\nBayan Mandahu Formation.\nIn both Bayan Mandahu and Djadochta formations many of the same genera were present, though they varied at the species level. These differences in species composition may be due a natural barrier separating the two formations, which are relatively close to each other geographically. However, given the lack of any known barrier which would cause the specific faunal compositions found in these areas, it is more likely that those differences indicate a slight time difference.\n\"V. osmolskae\" lived alongside the ankylosaurid \"Pinacosaurus mephistocephalus\"; alvarezsaurid \"Linhenykus\"; closely related dromaeosaurid \"Linheraptor\"; oviraptorids \"Machairasaurus\" and \"Wulatelong\"; protoceratopsids \"Bagaceratops\" and \"Protoceratops hellenikorhinus\"; and troodontids \"Linhevenator\", \"Papiliovenator\", and \"Philovenator\". Sediments across the formation indicate a similar depositional environment to that of the Djadochta Formation.\nDjadochta Formation.\nKnown specimens of \"Velociraptor mongoliensis\" have been recovered from the Djadochta Formation (also spelled Djadokhta), in the Mongolian province of \u00d6mn\u00f6govi. This geological formation is estimated to date back to the Campanian stage (between 75 million and 71 million years ago) of the Late Cretaceous epoch. The abundant sediments\u2014sands, sandstones, or caliche\u2014of the Djadochta Formation were deposited by eolian (wind) processes in arid settings with fields of sand dunes and only intermittent streams, as indicated by very sparse fluvial (river-deposited) sedimentation, under a semi-arid climate.\nThe Djadochta Formation is separated into a lower Bayn Dzak Member and upper Turgrugyin Member. \"V. mongoliensis\" is known from both members, represented by numerous specimens. The Bayn Dzak Member (mainly Bayn Dzak locality) has yielded the oviraptorid \"Oviraptor\"; ankylosaurid \"Pinacosaurus grangeri\"; protoceratopsid \"Protoceratops andrewsi\"; and troodontid \"Saurornithoides\". The younger Turgrugyin Member (mainly Tugriken Shireh locality) has produced the bird \"Elsornis\"; dromaeosaurid \"Mahakala\": ornithomimid \"Aepyornithomimus\"; and protoceratopsid \"Protoceratops andrewsi\".\n\"V. mongoliensis\" has been found at many of the most famous and prolific Djadochta localities. The type specimen was discovered at the Flaming Cliffs site (sublocality of the larger Bayn Dzak locality/region), while the \"Fighting Dinosaurs\" were found at the Tugrik Shire locality (also known as Tugrugeen Shireh and many other spellings). The latter is notorious for its exceptional \"in situ\" fossil preservation. Based on deposits (such as structureless sandstones), it has been concluded that a large number of specimens were buried alive during powerful sand-bearing events, common to these paleoenvironments.\nCultural significance.\n\"Velociraptor\" is commonly perceived as a vicious and cunning killer thanks to their portrayal in the 1990 novel \"Jurassic Park\" by Michael Crichton and its 1993 film adaptation, directed by Steven Spielberg. The \"raptors\" portrayed in \"Jurassic Park\" were actually modeled after the closely related dromaeosaurid \"Deinonychus\". Paleontologists in both the novel and film excavate a skeleton in Montana, far from the central Asian range of \"Velociraptor\" but characteristic of the \"Deinonychus\" range. Crichton met with the discoverer of \"Deinonychus\", John Ostrom, several times at Yale University to discuss details of the animal's possible range of behaviors and appearance. Crichton at one point apologetically told Ostrom that he had decided to use the name \"Velociraptor\" in place of \"Deinonychus\" because the former name was \"more dramatic.\" According to Ostrom, Crichton stated that the \"Velociraptor\" of the novel was based on \"Deinonychus\" in almost every detail, and that only the name had been changed. The \"Jurassic Park\" filmmakers also requested all of Ostrom's published papers on \"Deinonychus\" during production. They portrayed the animals with the size, proportions, and snout shape of \"Deinonychus\" rather than \"Velociraptor\".\nProduction on \"Jurassic Park\" began before the discovery of the large dromaeosaurid \"Utahraptor\" was made public in 1991, but as Jody Duncan wrote about this discovery: \"Later, after we had designed and built the raptor, there was a discovery of a raptor skeleton in Utah, which they labeled 'super-slasher.' They had uncovered the largest Velociraptor to date and it measured five-and-a-half-feet tall, just like ours. So we designed it, we built it, and then they discovered it. That still boggles my mind.\" Spielberg's name was briefly considered for naming of the new dinosaur in exchange for funding of field work, but no agreement was reached. \n\"Jurassic Park\" and its sequel \"\" were released before the discovery that dromaeosaurs had feathers, so the \"Velociraptor\" in both films were depicted as scaled and featherless. For \"Jurassic Park III,\" the male \"Velociraptor\" was given quill-like structures along the back of the head and neck, but these structures do not resemble the feathers that \"Velociraptor\" would have had in reality due to reasons of continuity. The \"Jurassic World\" sequel trilogy ignored the feathers of \"Velociraptor\", adhering to the designs from \"Jurassic Park\". However, the dromaeosaur \"Pyroraptor\" was feathered for \"Jurassic World Dominion\", along with other changes such as stiffening the tail to account for ossified tendons and de-pronating the hands.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32530", "revid": "367949", "url": "https://en.wikipedia.org/wiki?curid=32530", "title": "Visigoths", "text": "Germanic people of late antiquity and the early Middle Ages\nThe Visigoths (; ) were a Gothic people who emerged in the Balkans during late antiquity. Likely descended from the Thervingi who entered the Roman Empire in 376 and defeated the Romans at the Battle of Adrianople (378), they were first united under Alaric I (395\u2013410), whose forces alternately fought and allied with Rome before famously sacking the city in 410.\nIn 418, the Visigoths were settled as \"foederati\" in southern Gaul, establishing a kingdom with its capital at Toulouse. From there they expanded into Hispania, displacing the Suebi and Vandals. Defeat by the Franks under Clovis I at the Battle of Vouill\u00e9 (507) ended Visigothic rule in Gaul, but the kingdom consolidated in Spain and Portugal, where it endured for two centuries.\nThe Visigoths are remembered for their cultural and religious transformation of Iberia. Under King Reccared I, they converted from Arian Christianity to Nicene Christianity at the Third Council of Toledo (589), integrating with their Hispano-Roman subjects and strengthening royal legitimacy. Their \"Visigothic Code\" (654) abolished legal distinctions between Goths and Romans, creating a common identity as \"Hispani\". The kingdom fostered churches and artistic treasures such as the Treasure of Guarrazar, and its legal code remained influential in Iberian law until the Late Middle Ages.\nIn 711, the Visigothic kingdom collapsed after defeat by an Umayyad army at the Battle of Guadalete, where King Roderic was killed. In the north, the Kingdom of Asturias soon emerged under Pelagius, marking the beginning of the Reconquista. Despite their fall, the Visigoths left a lasting legacy through their legal system, cultural influence, and role in the formation of medieval Iberia.\nNomenclature: Vesi, Tervingi, Visigoths.\nThe Visigoths were never called Visigoths, only Goths, until Cassiodorus used the term, when referring to their loss against Clovis I in the Franco\u2013Gothic War about 507. Cassiodorus apparently invented the term based on the model of the \"Ostrogoths\", but using the older name of the Vesi, one of the tribal names which the fifth-century poet Sidonius Apollinaris, had already used when referring to the Visigoths. The first part of the Ostrogoth name is related to the word \"east\", and Jordanes, the medieval writer, later clearly contrasted them in his \"Getica\", stating that \"Visigoths were the Goths of the western country.\" According to Wolfram, Cassiodorus created this east\u2013west understanding of the Goths, which was a simplification and literary device, while political realities were more complex. Cassiodorus used the term \"Goths\" to refer to only the Ostrogoths, whom he served, and reserved the geographic reference \"Visigoths\" for the Gallo-Spanish Goths. The term \"Visigoths\" was later used by the Visigoths themselves in their communications with the Byzantine Empire, and was still in use in the 7th century.\nTwo older tribal names from outside the Roman empire are associated with Visigoths who formed within the empire. The first references to any Gothic tribes by Roman and Greek authors were in the third century, notably including the Thervingi, who were once referred to as Goths by Ammianus Marcellinus. Much less is known of the \"Vesi\" or \"Visi\", from whom the term \"Visigoth\" was derived. Before Sidonius Apollinaris, the Vesi were first mentioned in the , a late-4th- or early-5th-century list of Roman military forces. This list also contains the last mention of the \"Thervingi\" in a classical source.\nAlthough he did not refer to the Vesi, Tervingi or Greuthungi, Jordanes identified the Visigothic kings from Alaric I to Alaric II as the successors of the fourth-century Tervingian king Athanaric, and the Ostrogoth kings from Theoderic the Great to Theodahad as the heirs of the Greuthungi king Ermanaric. Based on this, many scholars have traditionally treated the terms \"Vesi\" and \"Tervingi\" as referring to one distinct tribe, while the terms \"Ostrogothi\" and \"Greuthungi\" were used to refer to another.\nWolfram, who still recently defends the equation of Vesi with the Tervingi, argues that while primary sources occasionally list all four names (as in, for example, \"Gruthungi, Austrogothi, Tervingi, Visi\"), whenever they mention two different tribes, they always refer either to \"the Vesi and the Ostrogothi\" or to \"the Tervingi and the Greuthungi\", and they never pair them up in any other combination. In addition, Wolfram interprets the as equating the Vesi with the Tervingi in a reference to the years 388\u2013391. On the other hand, another recent interpretation of the \"Notitia\" is that the two names, Vesi and Tervingi, are found in different places in the list, \"a clear indication that we are dealing with two different army units, which must also presumably mean that they are, after all, perceived as two different peoples\". Peter Heather has written that Wolfram's position is \"entirely arguable, but so is the opposite\".\nWolfram believes that \"Vesi\" and \"Ostrogothi\" were terms each tribe used to boastfully describe itself and argues that \"Tervingi\" and \"Greuthungi\" were geographical identifiers each tribe used to describe the other. This would explain why the latter terms dropped out of use shortly after 400, when the Goths were displaced by the Hunnic invasions. Wolfram believes that the people Zosimus describes were those Tervingi who had remained behind after the Hunnic conquest. For the most part, all of the terms discriminating between different Gothic tribes gradually disappeared after they moved into the Roman Empire.\nMany recent scholars, such as Peter Heather, have concluded that Visigothic group identity emerged only within the Roman Empire. Roger Collins also believes that the Visigothic identity emerged from the Gothic War of 376\u2013382 when a collection of Tervingi, Greuthungi and other \"barbarian\" contingents banded together in multiethnic \"foederati\" (Wolfram's \"federate armies\") under Alaric I in the eastern Balkans, since they had become a multi ethnic group and could no longer claim to be exclusively Tervingian.\nOther names for other Gothic divisions abounded. In 469, the Visigoths were called the \"Alaric Goths\". The Frankish Table of Nations, probably of Byzantine or Italian origin, referred to one of the two peoples as the \"Walagothi\", meaning \"Roman Goths\" (from Germanic *\"walhaz\", foreign). This probably refers to the Romanized Visigoths after their entry into Spain. Landolfus Sagax, writing in the 10th or 11th century, calls the Visigoths the \"Hypogothi\".\nEtymology of Tervingi and Vesi/Visigothi.\nThe name \"Tervingi\" may mean \"forest people\", with the first part of the name related to Gothic \"triu\", and English \"tree\". This is supported by evidence that geographic descriptors were commonly used to distinguish people living north of the Black Sea both before and after Gothic settlement there, by evidence of forest-related names among the Tervingi, and by the lack of evidence for an earlier date for the name pair Tervingi\u2013Greuthungi than the late third century. That the name \"Tervingi\" has pre-Pontic, possibly Scandinavian, origins still has support today.\nThe Visigoths are called \"Wesi\" or \"Wisi\" by Trebellius Pollio, Claudian and Sidonius Apollinaris. The word is Gothic for \"good\", implying the \"good or worthy people\", related to Gothic \"iusiza\" \"better\" and a reflex of Indo-European *\"wesu\" \"good\", akin to Welsh \"gwiw\" \"excellent\", Greek \"eus\" \"good\", Sanskrit \"v\u00e1su-\u015f\" \"id.\". Jordanes relates the tribe's name to a river, though this is probably a folk etymology or legend like his similar story about the Greuthung name.\nHistory.\nEarly origins.\nThe Visigoths emerged from the Gothic tribes, probably a derivative name for the Gutones, a people believed to have their origins in Scandinavia and who migrated southeastwards into eastern Europe. Such understanding of their origins is largely the result of Gothic traditions and their true genesis as a people is as obscure as that of the Franks and Alamanni. The Visigoths spoke an eastern Germanic language that was distinct by the 4th century. Eventually the Gothic language died as a result of contact with other European people during the Middle Ages.\nLong struggles between the neighboring Vandili and Lugii people with the Goths may have contributed to their earlier exodus into mainland Europe. The vast majority of them settled between the Oder and Vistula rivers until overpopulation (according to Gothic legends or tribal sagas) forced them to move south and east, where they settled just north of the Black Sea. However, this legend is not supported by archaeological evidence so its validity is disputable. Historian Malcolm Todd contends that while this large \"en masse\" migration is possible, the movement of Gothic peoples south-east was probably the result of warrior bands moving closer to the wealth of Ukraine and the cities of the Black Sea coast. Perhaps what is most notable about the Gothic people in this regard was that by the middle of the third century AD, they were \"the most formidable military power beyond the lower Danube frontier\".\nContact with Rome.\nThroughout the 3rd and 4th centuries there were numerous conflicts and exchanges of varying types between the Goths and their neighbors. After the Romans withdrew from the territory of Dacia, the local population was subjected to constant invasions by the migratory tribes, among the first being the Goths. In 238, the Goths invaded across the Danube into the Roman province of Moesia, pillaging and exacting payment through hostage taking. During the war with the Persians that year, Goths also appeared in the Roman armies of Gordian III. When subsidies to the Goths were stopped, the Goths organized and in 250 joined a major barbarian invasion led by the Germanic king, Kniva. Success on the battlefield against the Romans inspired additional invasions into the northern Balkans and deeper into Anatolia. Starting in approximately 255, the Goths added a new dimension to their attacks by taking to the sea and invading harbors which brought them into conflict with the Greeks as well. When the city of Pityus fell to the Goths in 256, the Goths were further emboldened. Sometime between 266 and 267, the Goths raided Greece but when they attempted to move into the Bosporus straits to attack Byzantium, they were repulsed. Along with other Germanic tribes, they attacked further into Anatolia, assaulting Crete and Cyprus on the way; shortly thereafter, they pillaged Troy and the temple of Artemis at Ephesus. Throughout the reign of emperor Constantine the Great, the Visigoths continued to conduct raids on Roman territory south of the Danube River. By 332, relations between the Goths and Romans were stabilized by a treaty but this was not to last.\nWar with Rome (376\u2013382).\nThe Goths remained in Dacia until 376, when one of their leaders, Fritigern, appealed to the Eastern Roman Emperor Valens to be allowed to settle with his people on the south bank of the Danube. Here, they hoped to find refuge from the Huns. Valens permitted this, as he saw in them \"a splendid recruiting ground for his army\". However, a famine broke out and Rome was unwilling to supply them with either the food they were promised or the land. Generally, the Goths were abused by the Romans, who began forcing the now starving Goths to trade away their children so as to stave off starvation. Open revolt ensued, leading to 6 years of plundering throughout the Balkans, the death of a Roman Emperor and a disastrous defeat of the Roman army.\nThe Battle of Adrianople in 378 was the decisive moment of the war. The Roman forces were slaughtered and the Emperor Valens was killed during the fighting. Precisely how Valens fell remains uncertain but Gothic legend tells of how the emperor was taken to a farmhouse, which was set on fire above his head, a tale made more popular by its symbolic representation of a heretical emperor receiving hell's torment. Many of Rome's leading officers and some of their most elite fighting men died during the battle which struck a major blow to Roman prestige and the Empire's military capabilities. Adrianople shocked the Roman world and eventually forced the Romans to negotiate with and settle the tribe within the empire's boundaries, a development with far-reaching consequences for the eventual fall of Rome. Fourth-century Roman soldier and historian Ammianus Marcellinus ended his chronology of Roman history with this battle.\nDespite the severe consequences for Rome, Adrianople was not nearly as productive overall for the Visigoths and their gains were short-lived. Still confined to a small and relatively impoverished province of the Empire, another Roman army was being gathered against them, an army which also had amid its ranks other disaffected Goths. Intense campaigns against the Visigoths followed their victory at Adrianople for upwards of three years. Approach routes across the Danube provinces were effectively sealed off by concerted Roman efforts, and while there was no decisive victory to claim, it was essentially a Roman triumph ending in a treaty in 382. The treaty struck with the Goths was to be the first \"foedus\" on imperial Roman soil. It required these semi-autonomous Germanic tribes to raise troops for the Roman army in exchange for arable land and freedom from Roman legal structures within the Empire.\nReign of Alaric I.\nThe new emperor, Theodosius I, made peace with the rebels, and this peace held essentially unbroken until Theodosius died in 395. In that year, the Visigoths' most famous king, Alaric I, made a bid for the throne, but controversy and intrigue erupted between the East and West, as General Stilicho tried to maintain his position in the empire. Theodosius was succeeded by his incompetent sons: Arcadius in the east and Honorius in the west. In 397, Alaric was named military commander of the eastern Illyrian prefecture by Arcadius.\nOver the next 15 years, an uneasy peace was broken by occasional conflicts between Alaric and the powerful Germanic generals who commanded the Roman armies in the east and west, wielding the real power of the empire. Finally, after the western general Stilicho was executed by Honorius in 408 and the Roman legions massacred the families of thousands of barbarian soldiers who were trying to assimilate into the Roman empire, Alaric decided to march on Rome. After two defeats in Northern Italy and a siege of Rome ended by a negotiated pay-off, Alaric was cheated by another Roman faction. He resolved to cut the city off by capturing its port. On August 24, 410, however, Alaric's troops entered Rome through the Salarian Gate, and sacked the city. However, Rome, while still the official capital, was no longer the \"de facto\" seat of the government of the Western Roman Empire. From the late 370s up to 402, Milan was the seat of government, but after the siege of Milan the Imperial Court moved to Ravenna in 402. Honorius visited Rome often, and after his death in 423 the emperors resided mostly there. Rome's fall severely shook the Empire's confidence, especially in the West. Loaded with booty, Alaric and the Visigoths extracted as much as they could with the intention of leaving Italy from Basilicata to northern Africa. Alaric died before the disembarkation and was buried supposedly near the ruins of Croton. He was succeeded by his wife's brother.\nVisigothic Kingdom.\nThe Visigothic Kingdom was a Western European power in the 5th to 8th centuries, created first in Gaul, when the Romans lost their control of the western half of their empire and then in Hispania until 711. For a brief period, the Visigoths controlled the strongest kingdom in Western Europe. In response to the invasion of Roman Hispania of 409 by the Vandals, Alans, and Suebi, Honorius, the emperor in the West, enlisted the aid of the Visigoths to regain control of the territory. From 408 to 410 the Visigoths caused so much damage to Rome and the immediate periphery that nearly a decade later, the provinces in and around the city were only able to contribute one-seventh of their previous tax shares.\nIn 418, Honorius rewarded his Visigothic federates by giving them land in Gallia Aquitania on which to settle after they had attacked the four tribes\u2014Suebi, Asding and Siling Vandals, as well as Alans\u2014who had crossed the Rhine near Mogontiacum (modern Mainz) the last day of 406 and eventually were invited into Spain by a Roman usurper in the autumn of 409 (the latter two tribes were devastated). This was probably done under \"hospitalitas\", the rules for billeting army soldiers. The settlement formed the nucleus of the future Visigothic kingdom that would eventually expand across the Pyrenees and onto the Iberian peninsula. That Visigothic settlement proved paramount to Europe's future as had it not been for the Visigothic warriors who fought side by side with the Roman troops under general Flavius Aetius, it is perhaps possible that Attila would have seized control of Gaul, rather than the Romans being able to retain dominance.\nThe Visigoths' second great king, Euric, unified the various quarreling factions among the Visigoths and, in 475, concluded the peace treaty with the emperor Julius Nepos. In the treaty the emperor was called a friend (\"amicus\") to the Visigoths, while requiring them to address him as lord (\"dominus\"). Though the emperor did not legally recognize Gothic sovereignty, according to some views under this treaty the Visigothic kingdom became an independent kingdom. Between 471 and 476, Euric captured most of southern Gaul. According to historian J. B. Bury, Euric was probably the \"greatest of the Visigothic kings\" for he managed to secure territorial gains denied to his predecessors and even acquired access to the Mediterranean Sea. At his death, the Visigoths were the most powerful of the successor states to the Western Roman Empire and were at the very height of their power. Not only had Euric secured significant territory, he and his son, Alaric II, who succeeded him, adopted Roman administrative and bureaucratic governance, including Rome's tax gathering policies and legal codes.\nAt this point, the Visigoths were also the dominant power in the Iberian Peninsula, quickly crushing the Alans and forcing the Vandals into north Africa. By 500, the Visigothic Kingdom, centred at Toulouse, controlled Aquitania and Gallia Narbonensis and most of Hispania with the exception of the Kingdom of the Suebi in the northwest and small areas controlled by the Basques and Cantabrians. Any survey of western Europe taken during this moment would have led one to conclude that the very future of Europe itself \"depended on the Visigoths\". However, in 507, the Franks under Clovis I defeated the Visigoths in the Battle of Vouill\u00e9 and wrested control of Aquitaine. King Alaric II was killed in battle. French national myths romanticize this moment as the time when a previously divided Gaul morphed into the united kingdom of Francia under Clovis.\nVisigothic power throughout Gaul was not lost in its entirety due to the support from the powerful Ostrogothic king in Italy, Theodoric the Great, whose forces pushed Clovis I and his armies out of Visigothic territories. Theodoric the Great's assistance was not some expression of ethnic altruism, but formed part of his plan to extend his power across Spain and its associated lands.\nAfter Alaric II's death, Visigothic nobles spirited his heir, the child-king Amalaric, first to Narbonne, which was the last Gothic outpost in Gaul, and further across the Pyrenees into Hispania. The center of Visigothic rule shifted first to Barcelona, then inland and south to Toledo. From 511 to 526, the Visigoths were ruled by Theoderic the Great of the Ostrogoths as \"de jure\" regent for the young Amalaric. Theodoric's death in 526, however, enabled the Visigoths to restore their royal line and re-partition the Visigothic kingdom through Amalaric, who incidentally, was more than just Alaric II's son; he was also the grandson of Theodoric the Great through his daughter Theodegotho. Amalaric reigned independently for five years. Following Amalaric's assassination in 531, another Ostrogothic ruler, Theudis took his place. For the next seventeen years, Theudis held the Visigothic throne.\nSometime in 549, the Visigoth Athanagild sought military assistance from Justinian I and while this aide helped Athanagild win his wars, the Romans had much more in mind. Granada and southernmost Baetica were lost to representatives of the Byzantine Empire (to form the province of Spania) who had been invited in to help settle this Visigothic dynastic struggle, but who stayed on, as a hoped-for spearhead to a \"Reconquest\" of the far west envisaged by emperor Justinian I. Imperial Roman armies took advantage of Visigothic rivalries and established a government at C\u00f3rdoba.\nThe last Arian Visigothic king, Liuvigild, conquered most of the northern regions (Cantabria) in 574, the Suevic kingdom in 584, and regained part of the southern areas lost to the Byzantines, which King Suintila recovered in 624. Suintila reigned until 631. Generally speaking, the Visigothic monarchy in Hispania developed a sophisticated legal tradition that was fundamentally Roman in orientation. Rather than implementing a \"Germanic\" legal system, Visigothic kings built upon the legacy of imperial jurisprudence. Alaric II\u2019s promulgation of the \"Breviarium Alaricianum\" was based heavily on the \"Codex Theodosianus\", and his successors\u2014including Liuvigild, Chindaswinth, and Recceswinth\u2014continued to issue legal codifications that fused Roman civil law with Christian moral precepts. Far from representing a break with Roman law, these legal texts exemplify the adaptation and continuation of late Roman legal culture in a Gothic context, challenging older historiographical models that sought to sharply distinguish post-Roman \"barbarian\" governance from its imperial predecessor. \nOnly one historical source was written between the years 625 through 711, which comes from Julian of Toledo and only deals with the years 672 and 673. Wamba was the king of the Visigoths from 672 to 680. During his reign, the Visigothic kingdom encompassed all of Hispania and part of southern Gaul known as Septimania. Wamba was succeeded by King Ervig, whose rule lasted until 687. Collins observes that \"Ervig proclaimed Egica as his chosen successor\" on 14 November 687. In 700, Egica's son Wittiza followed him on the throne according to the \"Chronica Regum Visigothorum\".\nThe kingdom survived until 711, when King Roderic (Rodrigo) was killed while opposing an invasion from the south by the Umayyad Caliphate in the Battle of Guadalete. This marked the beginning of the Umayyad conquest of Hispania, when most of the Iberian Peninsula came under Islamic rule in the early 8th century.\nA Visigothic nobleman, Pelayo, defeated the Umayyad forces in the Battle of Covadonga in 718 and established the Kingdom of Asturias in the northern part of the peninsula. According to Joseph F. O'Callaghan, the remnants of the Hispano-Gothic aristocracy still played an important role in the society of Hispania. At the end of Visigothic rule, the assimilation of Hispano-Romans and Visigoths was occurring at a fast pace. Their nobility had begun to think of themselves as constituting one people, the \"gens Gothorum\" or the \"Hispani\". An unknown number of them fled and took refuge in Asturias or Septimania. In Asturias they supported Pelagius's uprising, and joining with the indigenous leaders, formed a new aristocracy. The population of the mountain region consisted of native Astures, Galicians, Cantabri, Basques and other groups unassimilated into Hispano-Gothic society. Other Visigoths who refused to adopt the Muslim faith or live under their rule fled north to the kingdom of the Franks, and Visigoths played key roles in the empire of Charlemagne a few generations later. In the early years of the Emirate of C\u00f3rdoba, a group of Visigoths who remained under Muslim dominance constituted the personal bodyguard of the Emir, al-Haras.\nDuring their long reign in Spain, the Visigoths were responsible for the only new cities founded in Western Europe between the 5th and 8th centuries. It is certain (through contemporary Spanish accounts) that they founded four: Reccopolis, Victoriacum (modern Vitoria-Gasteiz, though perhaps Iru\u00f1a-Veleia), Luceo and Olite. There is also a possible 5th city ascribed to them by a later Arabic source: \"Baiyara\" (perhaps modern Montoro). All of these cities were founded for military purposes and three of them in celebration of victory. Despite the fact that the Visigoths reigned in Spain for upwards of 250 years, there are few remnants of the Gothic language borrowed into Spanish.\nThe Visigoths as heirs of the Roman empire lost their language and intermarried with the Hispano-Roman population of Spain.\nThe medieval Spanish nobility has its most remote origin in the Visigothic Monarchy. After the Arab invasion of the peninsula in the eighth century, Christians were forced to retreat to the north of the peninsula where that primitive Visigoth nobility settled. Among these Christians who took refuge in the north were a large part of the nobles linked to the disappeared Visigoth monarchy of Don Rodrigo (King Roderic), and who were welcomed by the local population and later became part of the local nobility.\nGenetics.\nA genetic study published in \"Science\" in March 2019 analyzed the remains of eight Visigoths buried at , dating to the 6th century. The genetic analysis of these individuals revealed that 73% of their ancestry derives from 7th-8th century Northeast Iberian populations (described as approximately 3/4 Iron-Age Iberian and 1/4 Central/Eastern Mediterranean). Additionally, 23% of their ancestry was linked to Central/Northern European populations, while the remaining 4% was traced to supplementary Central/Eastern Mediterranean origins.\nCulture.\nLaw.\nThe Visigothic Code of Law (Latin: \"Forum Iudicum),\" also called \"Liber Iudiciorum\" (English: Book of the Judges) and \"Lex Visigothorum\" (English: Law of the Visigoths), is a set of laws first promulgated by king Chindasuinth (642\u2013653 AD) that had been part of aristocratic oral tradition and were set in writing in the year 654. This book survives in two separate codices preserved at el Escorial (Spain). It goes into more detail than a modern constitution commonly does and reveals a great deal about Visigothic social structure. The code abolished the old tradition of having different laws for Romans (\"leges romanae\") and Visigoths (\"leges barbarorum\"), and under which all the subjects of the Visigothic kingdom ceased being \"romani\" and \"gothi\" and instead became \"hispani\". All the kingdom's subjects were under the same jurisdiction, which eliminated social and legal differences and facilitated greater assimilation of the various population groups. The Visigothic Code marks the transition from Roman law to Germanic law.\nOne of the greatest contributions of the Visigoths to family law was their protection of the property rights of married women, which was continued by Spanish law and ultimately evolved into the community property system now in force throughout the majority of western Europe.\nReligion.\nBefore the Middle Ages, the Visigoths, as well as other Germanic peoples, followed what is now referred to as Germanic paganism. While the Germanic peoples were slowly converted to Christianity by varying means, many elements of the pre-Christian culture and indigenous beliefs remained firmly in place after the conversion process, particularly in the more rural and distant regions.\nThe Visigoths, Ostrogoths and Vandals were Christianized while they were still outside the bounds of the Roman Empire; however, they converted to Arianism rather than to the Nicene version (Trinitarianism) followed by most Romans, who considered them heretics. There was a religious gulf between the Visigoths, who had for a long time adhered to Arianism, and their Catholic subjects in Hispania. There were also deep sectarian splits among the Catholic population of the peninsula which contributed to the toleration of the Arian Visigoths on the peninsula. The Visigoths scorned to interfere among Catholics but were interested in decorum and public order. King Liuvigild (568\u2013586), attempted to restore political unity between the Visigothic-Arian elite and the Hispano-Roman Nicene Catholic population through a doctrinal settlement of compromise on matters of faith, but this failed. Sources indicate that the Iberian Visigoths maintained their Christian Arianism, especially the Visigothic elite until the end of Liuvigild's reign. When Reccared I converted to Catholicism, he sought to unify the kingdom under a single faith.\nWhile the Visigoths retained their Arian faith, the Jews were well tolerated. Previous Roman and Byzantine law determined their status, and it already sharply discriminated against them, but royal jurisdiction was in any case quite limited: local lords and populations related to Jews as they saw fit. We read of rabbis being asked by non-Jews to bless their fields, for example. Historian Jane Gerber relates that some of the Jews \"held ranking posts in the government or the army; others were recruited and organized for garrison service; still others continued to hold senatorial rank\". In general, then, they were well respected and well treated by the Visigothic kings, that is, until their transition from Arianism to Catholicism. Conversion to Catholicism across Visigothic society reduced much of the friction between the Visigoths and the Hispano-Roman population. However, the Visigothic conversion negatively impacted the Jews, who came under scrutiny for their religious practices.\nKing Reccared convened the Third Council of Toledo to settle religious disputations related to the religious conversion from Arianism to Catholicism. The discriminatory laws passed at this Council seem not to have been universally enforced, however, as indicated by several more Councils of Toledo that repeated these laws and extended their stringency. These entered canon law and became legal precedents in other parts of Europe as well. The culmination of this process occurred under King Sisibut, who officially decreed a forced Christian conversion upon all Jews residing in Spain. This mandate apparently achieved only partial success: similar decrees were repeated by later kings as central power was consolidated. These laws either prescribed forcible baptism of the Jews or forbade circumcision, Jewish rites, and the observance of the Sabbath and other festivals. Throughout the 7th century the Jews were persecuted for religious reasons, had their property confiscated, were subjected to ruinous taxes, forbidden to trade and, at times, dragged to the baptismal font. Many were obliged to accept Christianity but continued privately to observe the Jewish religion and practices. The decree of 613 set off a century of difficulty for Spanish Jewry, which was only ended by the Muslim conquest.\nThe political aspects of the imposition of Church power cannot be ignored in these matters. With the conversion of the Visigothic kings to Chalcedonian Christianity, the bishops increased their power, until, at the Fourth Council of Toledo in 633, they selected a king from among the royal family, a practice previously reserved for nobles. This was the same synod that spoke out against those who had been baptized but had relapsed into Judaism. As far as the Visigoths were concerned, the time for religious pluralism \"was past\". By the end of the 7th century, Catholic conversion made the Visigoths less distinguishable from the indigenous Roman citizens of the Iberian peninsula; when the last Visigothic strongholds fell to the Muslim armies, whose subsequent invasions transformed Spain from the beginning of the 8th century, their Gothic identity faded.\nIn the eighth through 11th centuries, the \"muwallad\" clan of the Banu Qasi claimed descent from the Visigothic Count Cassius.\nArchitecture.\nDuring their governance of Hispania, the Visigoths built several churches in the basilical or cruciform style that survive, including the churches of San Pedro de la Nave in El Campillo, Santa Mar\u00eda de Melque in San Mart\u00edn de Montalb\u00e1n, Santa Luc\u00eda del Trampal in Alcu\u00e9scar, Santa Comba in Bande, and Santa Mar\u00eda de Lara in Quintanilla de las Vi\u00f1as. The Visigothic crypt (the Crypt of San Antol\u00edn) in the Palencia Cathedral is a Visigothic chapel from the mid-7th century, built during the reign of Wamba to preserve the remains of the martyr Saint Antoninus of Pamiers, a Visigothic-Gallic nobleman brought from Narbonne to Visigothic Hispania in 672 or 673 by Wamba himself. These are the only remains of the Visigothic cathedral of Palencia.\nReccopolis, located near the tiny modern village of Zorita de los Canes in the province of Guadalajara, Castile-La Mancha, Spain, is an archaeological site of one of at least four cities founded in Hispania by the Visigoths. It is the only city in Western Europe to have been founded between the 5th and 8th centuries. The city's construction was ordered by the Visigothic king Liuvigild to honor his son Reccared and to serve as Reccared's seat as co-king in the Visigothic province of Celtiberia, to the west of Carpetania, where the main capital, Toledo, lay.\nGoldsmithery.\nIn Spain, an important collection of Visigothic metalwork was found in Guadamur, in the Province of Toledo, known as the Treasure of Guarrazar. This archeological find is composed of twenty-six votive crowns and gold crosses from the royal workshop in Toledo, with signs of Byzantine influence. According to Spanish archaeologists, this treasure represents the high point of Visigothic goldsmithery. The two most important votive crowns are those of Recceswinth and of Suintila, displayed in the National Archaeological Museum of Madrid; both are made of gold, encrusted with sapphires, pearls and other precious stones.\nThe discoverer of the second lot gave Spanish Queen Elizabeth II some of the pieces that she still had in her possession, including the crown of Suintila, this crown was stolen in 1921 and never recovered. There are several other small crowns and many votive crosses in the treasure.\nThese findings, along with others from some neighbouring sites and with the archaeological excavation of the Spanish Ministry of Public Works and the Royal Spanish Academy of History (April 1859), formed a group consisting of:\nThe aquiliform (eagle-shaped) fibulae that have been discovered in necropolises such as Durat\u00f3n, Madrona or Castiltierra (cities of Segovia), are an unmistakable example of the Visigothic presence in Spain. These fibulae were used individually or in pairs, as clasps or pins in gold, bronze and glass to join clothes, showing the work of the goldsmiths of Visigothic Hispania.\nThe Visigothic belt buckles, a symbol of rank and status characteristic of Visigothic women's clothing, are also notable as works of goldsmithery. Some pieces contain exceptional Byzantine-style lapis lazuli inlays and are generally rectangular in shape, with copper alloy, garnets and glass.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "32532", "revid": "8144267", "url": "https://en.wikipedia.org/wiki?curid=32532", "title": "Vectors", "text": ""}
{"id": "32533", "revid": "12336988", "url": "https://en.wikipedia.org/wiki?curid=32533", "title": "Euclidean vector", "text": "Geometric object that has length and direction\nIn mathematics, physics, and engineering, a Euclidean vector or simply a vector (sometimes called a geometric vector or spatial vector) is a geometric object that has magnitude (or length) and direction. Euclidean vectors can be added and scaled to form a vector space. A \"vector quantity\" is a vector-valued physical quantity, including units of measurement and possibly a support, formulated as a \"directed line segment\". A vector is frequently depicted graphically as an arrow connecting an \"initial point\" \"A\" with a \"terminal point\" \"B\", and denoted by formula_1\nA vector is what is needed to \"carry\" the point \"A\" to the point \"B\"; the Latin word means 'carrier'. It was first used by 18th century astronomers investigating planetary revolution around the Sun. The magnitude of the vector is the distance between the two points, and the direction refers to the direction of displacement from \"A\" to \"B\". Many algebraic operations on real numbers such as addition, subtraction, multiplication, and negation have close analogues for vectors, operations which obey the familiar algebraic laws of commutativity, associativity, and distributivity. These operations and associated laws qualify Euclidean vectors as an example of the more generalized concept of vectors defined simply as elements of a vector space.\nVectors play an important role in physics: the velocity and acceleration of a moving object and the forces acting on it can all be described with vectors. Many other physical quantities can be usefully thought of as vectors. Although most of them do not represent distances (except, for example, position or displacement), their magnitude and direction can still be represented by the length and direction of an arrow. The mathematical representation of a physical vector depends on the coordinate system used to describe it. Other vector-like mathematical objects that describe physical quantities, such as pseudovectors and tensors, transform in a similar way under changes of the coordinate system.\nHistory.\nThe vector concept, as it is known today, is the result of a gradual development over a period of more than 200 years. About a dozen people contributed significantly to its development. In 1835, Giusto Bellavitis abstracted the basic idea when he established the concept of equipollence. Working in a Euclidean plane, he made equipollent any pair of parallel line segments of the same length and orientation. Essentially, he realized an equivalence relation on the pairs of points (bipoints) in the plane, and thus erected the first space of vectors in the plane. The term \"vector\" was introduced by William Rowan Hamilton as part of a quaternion, which is a sum \"q\" = \"s\" + \"v\" of a real number \"s\" (also called \"scalar\") and a 3-dimensional \"vector\". Like Bellavitis, Hamilton viewed vectors as representative of classes of equipollent directed segments. As complex numbers use an imaginary unit to complement the real line, Hamilton considered the vector \"v\" to be the \"imaginary part\" of a quaternion:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The algebraically imaginary part, being geometrically constructed by a straight line, or radius vector, which has, in general, for each determined quaternion, a determined length and determined direction in space, may be called the vector part, or simply the vector of the quaternion.\nSeveral other mathematicians developed vector-like systems in the middle of the nineteenth century, including Augustin Cauchy, Hermann Grassmann, August M\u00f6bius, Comte de Saint-Venant, and Matthew O'Brien. Grassmann's 1840 work \"Theorie der Ebbe und Flut\" (Theory of the Ebb and Flow) was the first system of spatial analysis that is similar to today's system, and had ideas corresponding to the cross product, scalar product and vector differentiation. Grassmann's work was largely neglected until the 1870s. Peter Guthrie Tait carried the quaternion standard after Hamilton. His 1867 \"Elementary Treatise of Quaternions\" included extensive treatment of the nabla or del operator \u2207. In 1878, \"Elements of Dynamic\" was published by William Kingdon Clifford. Clifford simplified the quaternion study by isolating the dot product and cross product of two vectors from the complete quaternion product. This approach made vector calculations available to engineers\u2014and others working in three dimensions and skeptical of the fourth.\nJosiah Willard Gibbs, who was exposed to quaternions through James Clerk Maxwell's \"Treatise on Electricity and Magnetism\", separated off their vector part for independent treatment. The first half of Gibbs's \"Elements of Vector Analysis\", published in 1881, presents what is essentially the modern system of vector analysis. In 1901, Edwin Bidwell Wilson published \"Vector Analysis\", adapted from Gibbs's lectures, which banished any mention of quaternions in the development of vector calculus.\nOverview.\nIn physics and engineering, a vector is typically regarded as a geometric entity characterized by a magnitude and a relative direction. It is formally defined as a directed line segment, or arrow, in a Euclidean space. In pure mathematics, a vector is defined more generally as any element of a vector space. In this context, vectors are abstract entities which may or may not be characterized by a magnitude and a direction. This generalized definition implies that the above-mentioned geometric entities are a special kind of abstract vectors, as they are elements of a special kind of vector space called Euclidean space. This particular article is about vectors strictly defined as arrows in Euclidean space. When it becomes necessary to distinguish these special vectors from vectors as defined in pure mathematics, they are sometimes referred to as geometric, spatial, or Euclidean vectors.\nA Euclidean vector may possess a definite \"initial point\" and \"terminal point\"; such a condition may be emphasized calling the result a bound vector. When only the magnitude and direction of the vector matter, and the particular initial or terminal points are of no importance, the vector is called a free vector. The distinction between bound and free vectors is especially relevant in mechanics, where a force applied to a body has a point of contact (see resultant force and couple).\nTwo arrows formula_2 and formula_3 in space represent the same free vector if they have the same magnitude and direction: that is, they are equipollent if the quadrilateral \"ABB\u2032A\u2032\" is a parallelogram. If the Euclidean space is equipped with a choice of origin, then a free vector is equivalent to the bound vector of the same magnitude and direction whose initial point is the origin.\nThe term \"vector\" also has generalizations to higher dimensions, and to more formal approaches with much wider applications.\nFurther information.\nIn classical Euclidean geometry (i.e., synthetic geometry), vectors were introduced (during the 19th century) as equivalence classes under equipollence, of ordered pairs of points; two pairs (\"A\", \"B\") and (\"C\", \"D\") being equipollent if the points \"A\", \"B\", \"D\", \"C\", in this order, form a parallelogram. Such an equivalence class is called a \"vector\", more precisely, a Euclidean vector. The equivalence class of (\"A\", \"B\") is often denoted formula_4\nA Euclidean vector is thus an equivalence class of directed segments with the same magnitude (e.g., the length of the line segment (\"A\", \"B\")) and same direction (e.g., the direction from A to B). In physics, Euclidean vectors are used to represent physical quantities that have both magnitude and direction, but are not located at a specific place, in contrast to scalars, which have no direction. For example, velocity, forces and acceleration are represented by vectors.\nIn modern geometry, Euclidean spaces are often defined from linear algebra. More precisely, a Euclidean space E is defined as a set to which is associated an inner product space of finite dimension over the reals formula_5 and a group action of the additive group of formula_5 which is free and transitive (See Affine space for details of this construction). The elements of formula_7 are called translations. It has been proven that the two definitions of Euclidean spaces are equivalent, and that the equivalence classes under equipollence may be identified with translations.\nSometimes, Euclidean vectors are considered without reference to a Euclidean space. In this case, a Euclidean vector is an element of a normed vector space of finite dimension over the reals, or, typically, an element of the real coordinate space formula_8 equipped with the dot product. This makes sense, as the addition in such a vector space acts freely and transitively on the vector space itself. That is, formula_8 is a Euclidean space, with itself as an associated vector space, and the dot product as an inner product.\nThe Euclidean space formula_8 is often presented as \"the\" standard Euclidean space of dimension n. This is motivated by the fact that every Euclidean space of dimension n is isomorphic to the Euclidean space formula_11 More precisely, given such a Euclidean space, one may choose any point O as an origin. By Gram\u2013Schmidt process, one may also find an orthonormal basis of the associated vector space (a basis such that the inner product of two basis vectors is 0 if they are different and 1 if they are equal). This defines Cartesian coordinates of any point P of the space, as the coordinates on this basis of the vector formula_12 These choices define an isomorphism of the given Euclidean space onto formula_13 by mapping any point to the n-tuple of its Cartesian coordinates, and every vector to its coordinate vector.\nExamples in one dimension.\nSince the physicist's concept of force has a direction and a magnitude, it may be seen as a vector. As an example, consider a rightward force \"F\" of 15 newtons. If the positive axis is also directed rightward, then \"F\" is represented by the vector 15\u00a0N, and if positive points leftward, then the vector for \"F\" is \u221215\u00a0N. In either case, the magnitude of the vector is 15\u00a0N. Likewise, the vector representation of a displacement \u0394\"s\" of 4 meters would be 4\u00a0m or \u22124\u00a0m, depending on its direction, and its magnitude would be 4\u00a0m regardless.\nIn physics and engineering.\nVectors are fundamental in the physical sciences. They can be used to represent any quantity that has magnitude, has direction, and which adheres to the rules of vector addition. An example is velocity, the magnitude of which is speed. For instance, the velocity \"5 meters per second upward\" could be represented by the vector (0, 5) (in 2 dimensions with the positive \"y\"-axis as 'up'). Another quantity represented by a vector is force, since it has a magnitude and direction and follows the rules of vector addition. Vectors also describe many other physical quantities, such as linear displacement, displacement, linear acceleration, angular acceleration, linear momentum, and angular momentum. Other physical vectors, such as the electric and magnetic field, are represented as a system of vectors at each point of a physical space; that is, a vector field. Examples of quantities that have magnitude and direction, but fail to follow the rules of vector addition, are angular displacement and electric current. Consequently, these are not vectors.\nIn Cartesian space.\nIn the Cartesian coordinate system, a bound vector can be represented by identifying the coordinates of its initial and terminal point. For instance, the points \"A\" \n (1, 0, 0) and \"B\" \n (0, 1, 0) in space determine the bound vector formula_14 pointing from the point \"x\" \n 1 on the \"x\"-axis to the point \"y\" \n 1 on the \"y\"-axis.\nIn Cartesian coordinates, a free vector may be thought of in terms of a corresponding bound vector, in this sense, whose initial point has the coordinates of the origin \"O\" \n (0, 0, 0). It is then determined by the coordinates of that bound vector's terminal point. Thus the free vector represented by (1, 0, 0) is a vector of unit length\u2014pointing along the direction of the positive \"x\"-axis.\nThis coordinate representation of free vectors allows their algebraic features to be expressed in a convenient numerical fashion. For example, the sum of the two (free) vectors (1, 2, 3) and (\u22122, 0, 4) is the (free) vector\nformula_15\nEuclidean and affine vectors.\nIn the geometrical and physical settings, it is sometimes possible to associate, in a natural way, a \"length\" or magnitude and a direction to vectors. In addition, the notion of direction is strictly associated with the notion of an \"angle\" between two vectors. If the dot product of two vectors is defined\u2014a scalar-valued product of two vectors\u2014then it is also possible to define a length; the dot product gives a convenient algebraic characterization of both angle (a function of the dot product between any two non-zero vectors) and length (the square root of the dot product of a vector by itself). In three dimensions, it is further possible to define the cross product, which supplies an algebraic characterization of the area and orientation in space of the parallelogram defined by two vectors (used as sides of the parallelogram). In any dimension (and, in particular, higher dimensions), it is possible to define the exterior product, which (among other things) supplies an algebraic characterization of the area and orientation in space of the \"n\"-dimensional parallelotope defined by \"n\" vectors.\nIn a pseudo-Euclidean space, a vector's squared length can be positive, negative, or zero. An important example is Minkowski space (which is important to our understanding of special relativity).\nHowever, it is not always possible or desirable to define the length of a vector. This more general type of spatial vector is the subject of vector spaces (for free vectors) and affine spaces (for bound vectors, as each represented by an ordered pair of \"points\"). One physical example comes from thermodynamics, where many quantities of interest can be considered vectors in a space with no notion of length or angle.\nGeneralizations.\nIn physics, as well as mathematics, a vector is often identified with a tuple of components, or list of numbers, that act as scalar coefficients for a set of basis vectors. When the basis is transformed, for example by rotation or stretching, then the components of any vector in terms of that basis also transform in an opposite sense. The vector itself has not changed, but the basis has, so the components of the vector must change to compensate. The vector is called \"covariant\" or \"contravariant\", depending on how the transformation of the vector's components is related to the transformation of the basis. In general, contravariant vectors are \"regular vectors\" with units of distance (such as a displacement), or distance times some other unit (such as velocity or acceleration); covariant vectors, on the other hand, have units of one-over-distance such as gradient. If you change units (a special case of a change of basis) from meters to millimeters, a scale factor of 1/1000, a displacement of 1\u00a0m becomes 1000\u00a0mm\u2014a contravariant change in numerical value. In contrast, a gradient of 1\u00a0K/m becomes 0.001\u00a0K/mm\u2014a covariant change in value (for more, see covariance and contravariance of vectors). Tensors are another type of quantity that behave in this way; a vector is one type of tensor.\nIn pure mathematics, a vector is any element of a vector space over some field and is often represented as a coordinate vector. The vectors described in this article are a very special case of this general definition, because they are contravariant with respect to the ambient space. Contravariance captures the physical intuition behind the idea that a vector has \"magnitude and direction\".\nRepresentations.\nVectors are usually denoted in lowercase boldface, as in formula_16, formula_17 and formula_18, or in lowercase italic boldface, as in a. (Uppercase letters are typically used to represent matrices.) Other conventions include formula_19 or \"a\", especially in handwriting. Alternatively, some use a tilde (~) or a wavy underline drawn beneath the symbol, e.g. formula_20, which is a convention for indicating boldface type. If the vector represents a directed distance or displacement from a point \"A\" to a point \"B\" (see figure), it can also be denoted as formula_21 or \"AB\". In German literature, it was especially common to represent vectors with small fraktur letters such as formula_22.\nVectors are usually shown in graphs or other diagrams as arrows (directed line segments), as illustrated in the figure. Here, the point \"A\" is called the \"origin\", \"tail\", \"base\", or \"initial point\", and the point \"B\" is called the \"head\", \"tip\", \"endpoint\", \"terminal point\" or \"final point\". The length of the arrow is proportional to the vector's magnitude, while the direction in which the arrow points indicates the vector's direction.\nOn a two-dimensional diagram, a vector perpendicular to the plane of the diagram is sometimes desired. These vectors are commonly shown as small circles. A circle with a dot at its centre (Unicode U+2299 \u2299) indicates a vector pointing out of the front of the diagram, toward the viewer. A circle with a cross inscribed in it (Unicode U+2297 \u2297) indicates a vector pointing into and behind the diagram. These can be thought of as viewing the tip of an arrow head on and viewing the flights of an arrow from the back.\nIn order to calculate with vectors, the graphical representation may be too cumbersome. Vectors in an \"n\"-dimensional Euclidean space can be represented as coordinate vectors in a Cartesian coordinate system. The endpoint of a vector can be identified with an ordered list of \"n\" real numbers (\"n\"-tuple). These numbers are the coordinates of the endpoint of the vector, with respect to a given Cartesian coordinate system, and are typically called the \"scalar components\" (or \"scalar projections\") of the vector on the axes of the coordinate system.\nAs an example in two dimensions (see figure), the vector from the origin \"O\" = (0, 0) to the point \"A\" = (2, 3) is simply written as\nformula_23\nThe notion that the tail of the vector coincides with the origin is implicit and easily understood. Thus, the more explicit notation formula_24 is usually deemed not necessary (and is indeed rarely used).\nIn \"three dimensional\" Euclidean space (or R3), vectors are identified with triples of scalar components:\nformula_25\nalso written,\nformula_26\nThis can be generalised to \"n-dimensional\" Euclidean space (or R\"n\").\nformula_27\nThese numbers are often arranged into a column vector or row vector, particularly when dealing with matrices, as follows:\nformula_28\nAnother way to represent a vector in \"n\"-dimensions is to introduce the standard basis vectors. For instance, in three dimensions, there are three of them:\nformula_29\nThese have the intuitive interpretation as vectors of unit length pointing up the \"x\"-, \"y\"-, and \"z\"-axis of a Cartesian coordinate system, respectively. In terms of these, any vector a in R3 can be expressed in the form:\nformula_30\nor\nformula_31\nwhere a1, a2, a3 are called the vector components (or vector projections) of a on the basis vectors or, equivalently, on the corresponding Cartesian axes \"x\", \"y\", and \"z\" (see figure), while \"a\"1, \"a\"2, \"a\"3 are the respective scalar components (or scalar projections).\nIn introductory physics textbooks, the standard basis vectors are often denoted formula_32 instead (or formula_33, in which the hat symbol formula_34 typically denotes unit vectors). In this case, the scalar and vector components are denoted respectively \"ax\", \"ay\", \"az\", and a\"x\", a\"y\", a\"z\" (note the difference in boldface). Thus,\nformula_35\nThe notation e\"i\" is compatible with the index notation and the summation convention commonly used in higher level mathematics, physics, and engineering.\nDecomposition or resolution.\nAs explained above, a vector is often described by a set of vector components that add up to form the given vector. Typically, these components are the projections of the vector on a set of mutually perpendicular reference axes (basis vectors). The vector is said to be \"decomposed\" or \"resolved with respect to\" that set.\nThe decomposition or resolution of a vector into components is not unique, because it depends on the choice of the axes on which the vector is projected.\nMoreover, the use of Cartesian unit vectors such as formula_33 as a basis in which to represent a vector is not mandated. Vectors can also be expressed in terms of an arbitrary basis, including the unit vectors of a cylindrical coordinate system (formula_37) or spherical coordinate system (formula_38). The latter two choices are more convenient for solving problems which possess cylindrical or spherical symmetry, respectively.\nThe choice of a basis does not affect the properties of a vector or its behaviour under transformations.\nA vector can also be broken up with respect to \"non-fixed\" basis vectors that change their orientation as a function of time or space. For example, a vector in three-dimensional space can be decomposed with respect to two axes, respectively \"normal\", and \"tangent\" to a surface (see figure). Moreover, the \"radial\" and \"tangential components\" of a vector relate to the \"radius of rotation\" of an object. The former is parallel to the radius and the latter is orthogonal to it.\nIn these cases, each of the components may be in turn decomposed with respect to a fixed coordinate system or basis set (e.g., a \"global\" coordinate system, or inertial reference frame).\nProperties and operations.\nThe following section uses the Cartesian coordinate system with basis vectors\nformula_39\nand assumes that all vectors have the origin as a common base point. A vector a will be written as\nformula_40\nEquality.\nTwo vectors are said to be equal if they have the same magnitude and direction. Equivalently they will be equal if their coordinates are equal. So two vectors\nformula_41\nand\nformula_42\nare equal if\nformula_43\nOpposite, parallel, and antiparallel vectors.\nTwo vectors are \"opposite\" if they have the same magnitude but opposite direction; so two vectors\nformula_41\nand\nformula_42\nare opposite if\nformula_46\nTwo vectors are \"equidirectional\" (or \"codirectional\") if they have the same direction but not necessarily the same magnitude.\nTwo vectors are \"parallel\" if they have either the same or opposite direction, but not necessarily the same magnitude; two vectors are \"antiparallel\" if they have strictly opposite direction, but not necessarily the same magnitude.\nAddition and subtraction.\nThe sum of a and b of two vectors may be defined as\nformula_47\nThe resulting vector is sometimes called the resultant vector of a and b.\nThe addition may be represented graphically by placing the tail of the arrow b at the head of the arrow a, and then drawing an arrow from the tail of a to the head of b. The new arrow drawn represents the vector a + b, as illustrated below:\nThis addition method is sometimes called the \"parallelogram rule\" because a and b form the sides of a parallelogram and a + b is one of the diagonals. If a and b are bound vectors that have the same base point, this point will also be the base point of a + b. One can check geometrically that a + b = b + a and (a + b) + c = a + (b + c).\nThe difference of a and b is\nformula_48\nSubtraction of two vectors can be geometrically illustrated as follows: to subtract b from a, place the tails of a and b at the same point, and then draw an arrow from the head of b to the head of a. This new arrow represents the vector (-b) + a, with (-b) being the opposite of b, see drawing. And (-b) + a = a \u2212 b.\nScalar multiplication.\nA vector may also be multiplied, or re-\"scaled\", by any real number \"r\". In the context of conventional vector algebra, these real numbers are often called scalars (from \"scale\") to distinguish them from vectors. The operation of multiplying a vector by a scalar is called \"scalar multiplication\". The resulting vector is\nformula_49\nIntuitively, multiplying by a scalar \"r\" stretches a vector out by a factor of \"r\". Geometrically, this can be visualized (at least in the case when \"r\" is an integer) as placing \"r\" copies of the vector in a line where the endpoint of one vector is the initial point of the next vector.\nIf \"r\" is negative, then the vector changes direction: it flips around by an angle of 180\u00b0. Two examples (\"r\" = \u22121 and \"r\" = 2) are given below:\nScalar multiplication is distributive over vector addition in the following sense: \"r\"(a + b) = \"ra + \"rb for all vectors a and b and all scalars \"r\". One can also show that a \u2212 b = a + (\u22121)b.\nLength.\nThe \"length\", \"magnitude\" or \"norm\" of the vector a is denoted by \u2016a\u2016 or, less commonly, |a|, which is not to be confused with the absolute value (a scalar \"norm\").\nThe length of the vector a can be computed with the \"Euclidean norm\",\nformula_50\nwhich is a consequence of the Pythagorean theorem since the basis vectors e1, e2, e3 are orthogonal unit vectors.\nThis happens to be equal to the square root of the dot product, discussed below, of the vector with itself:\nformula_51\nUnit vector.\nA \"unit vector\" is any vector with a length of one; normally unit vectors are used simply to indicate direction. A vector of arbitrary length can be divided by its length to create a unit vector. This is known as \"normalizing\" a vector. A unit vector is often indicated with a hat as in \u00e2.\nTo normalize a vector a = (\"a\"1, \"a\"2, \"a\"3), scale the vector by the reciprocal of its length \u2016a\u2016. That is:\nformula_52\nZero vector.\nThe \"zero vector\" is the vector with length zero. Written out in coordinates, the vector is (0, 0, 0), and it is commonly denoted formula_53, 0, or simply 0. Unlike any other vector, it has an arbitrary or indeterminate direction, and cannot be normalized (that is, there is no unit vector that is a multiple of the zero vector). The sum of the zero vector with any vector a is a (that is, 0 + a = a).\nDot product.\nThe \"dot product\" of two vectors a and b (sometimes called the \"inner product\", or, since its result is a scalar, the \"scalar product\") is denoted by a\u00a0\u2219\u00a0b, and is defined as:\nformula_54\nwhere \"\u03b8\" is the measure of the angle between a and b (see trigonometric function for an explanation of cosine). Geometrically, this means that a and b are drawn with a common start point, and then the length of a is multiplied with the length of the component of b that points in the same direction as a.\nThe dot product can also be defined as the sum of the products of the components of each vector as\nformula_55\nCross product.\nThe \"cross product\" (also called the \"vector product\" or \"outer product\") is only meaningful in three or seven dimensions. The cross product differs from the dot product primarily in that the result of the cross product of two vectors is a vector. The cross product, denoted a\u00a0\u00d7\u00a0b, is a vector perpendicular to both a and b and is defined as\nformula_56\nwhere \"\u03b8\" is the measure of the angle between a and b, and n is a unit vector perpendicular to both a and b which completes a right-handed system. The right-handedness constraint is necessary because there exist \"two\" unit vectors that are perpendicular to both a and b, namely, n and (\u2212n).\nThe cross product a\u00a0\u00d7\u00a0b is defined so that a, b, and a\u00a0\u00d7\u00a0b also becomes a right-handed system (although a and b are not necessarily orthogonal). This is the right-hand rule.\nThe length of a\u00a0\u00d7\u00a0b can be interpreted as the area of the parallelogram having a and b as sides.\nThe cross product can be written as\nformula_57\nFor arbitrary choices of spatial orientation (that is, allowing for left-handed as well as right-handed coordinate systems) the cross product of two vectors is a pseudovector instead of a vector (see below).\nScalar triple product.\nThe \"scalar triple product\" (also called the \"box product\" or \"mixed triple product\") is not really a new operator, but a way of applying the other two multiplication operators to three vectors. The scalar triple product is sometimes denoted by (a b c) and defined as:\nformula_58\nIt has three primary uses. First, the absolute value of the box product is the volume of the parallelepiped which has edges that are defined by the three vectors. Second, the scalar triple product is zero if and only if the three vectors are linearly dependent, which can be easily proved by considering that in order for the three vectors to not make a volume, they must all lie in the same plane. Third, the box product is positive if and only if the three vectors a, b and c are right-handed.\nIn components (\"with respect to a right-handed orthonormal basis\"), if the three vectors are thought of as rows (or columns, but in the same order), the scalar triple product is simply the determinant of the 3-by-3 matrix having the three vectors as rows\nformula_59\nThe scalar triple product is linear in all three entries and anti-symmetric in the following sense:\nformula_60\nConversion between multiple Cartesian bases.\nAll examples thus far have dealt with vectors expressed in terms of the same basis, namely, the \"e\" basis {e1, e2, e3}. However, a vector can be expressed in terms of any number of different bases that are not necessarily aligned with each other, and still remain the same vector. In the \"e\" basis, a vector a is expressed, by definition, as\nformula_61\nThe scalar components in the \"e\" basis are, by definition,\nformula_62\nIn another orthonormal basis \"n\" = {n1, n2, n3} that is not necessarily aligned with \"e\", the vector a is expressed as\nformula_63\nand the scalar components in the \"n\" basis are, by definition,\nformula_64\nThe values of \"p\", \"q\", \"r\", and \"u\", \"v\", \"w\" relate to the unit vectors in such a way that the resulting vector sum is exactly the same physical vector a in both cases. It is common to encounter vectors known in terms of different bases (for example, one basis fixed to the Earth and a second basis fixed to a moving vehicle). In such a case it is necessary to develop a method to convert between bases so the basic vector operations such as addition and subtraction can be performed. One way to express \"u\", \"v\", \"w\" in terms of \"p\", \"q\", \"r\" is to use column matrices along with a direction cosine matrix containing the information that relates the two bases. Such an expression can be formed by substitution of the above equations to form\nformula_65\nDistributing the dot-multiplication gives\nformula_66\nReplacing each dot product with a unique scalar gives\nformula_67\nand these equations can be expressed as the single matrix equation\nformula_68\nThis matrix equation relates the scalar components of a in the \"n\" basis (\"u\",\"v\", and \"w\") with those in the \"e\" basis (\"p\", \"q\", and \"r\"). Each matrix element \"c\"\"jk\" is the direction cosine relating n\"j\" to e\"k\". The term \"direction cosine\" refers to the cosine of the angle between two unit vectors, which is also equal to their dot product. Therefore,\nformula_69\nBy referring collectively to e1, e2, e3 as the \"e\" basis and to n1, n2, n3 as the \"n\" basis, the matrix containing all the \"c\"\"jk\" is known as the \"transformation matrix from \"e\" to \"n\"\", or the \"rotation matrix from \"e\" to \"n\"\" (because it can be imagined as the \"rotation\" of a vector from one basis to another), or the \"direction cosine matrix from \"e\" to \"n\"\" (because it contains direction cosines). The properties of a rotation matrix are such that its inverse is equal to its transpose. This means that the \"rotation matrix from \"e\" to \"n\"\" is the transpose of \"rotation matrix from \"n\" to \"e\"\".\nThe properties of a direction cosine matrix, C are:\nThe advantage of this method is that a direction cosine matrix can usually be obtained independently by using Euler angles or a quaternion to relate the two vector bases, so the basis conversions can be performed directly, without having to work out all the dot products described above.\nBy applying several matrix multiplications in succession, any vector can be expressed in any basis so long as the set of direction cosines is known relating the successive bases.\nOther dimensions.\nWith the exception of the cross and triple products, the above formulae generalise to two dimensions and higher dimensions. For example, addition generalises to two dimensions as \nformula_70\nand in four dimensions as\nformula_71\nThe cross product does not readily generalise to other dimensions, though the closely related exterior product does, whose result is a bivector. In two dimensions this is simply a pseudoscalar\nformula_72\nA seven-dimensional cross product is similar to the cross product in that its result is a vector orthogonal to the two arguments; there is however no natural way of selecting one of the possible such products.\nPhysics.\nVectors have many uses in physics and other sciences.\nLength and units.\nIn abstract vector spaces, the length of the arrow depends on a dimensionless scale. If it represents, for example, a force, the \"scale\" is of physical dimension length/force. Thus there is typically consistency in scale among quantities of the same dimension, but otherwise scale ratios may vary; for example, if \"1 newton\" and \"5 m\" are both represented with an arrow of 2\u00a0cm, the scales are 1 m:50 N and 1:250 respectively. Equal length of vectors of different dimension has no particular significance unless there is some proportionality constant inherent in the system that the diagram represents. Also length of a unit vector (of dimension length, not length/force, etc.) has no coordinate-system-invariant significance.\nVector-valued functions.\nOften in areas of physics and mathematics, a vector evolves in time, meaning that it depends on a time parameter \"t\". For instance, if r represents the position vector of a particle, then r(\"t\") gives a parametric representation of the trajectory of the particle. Vector-valued functions can be differentiated and integrated by differentiating or integrating the components of the vector, and many of the familiar rules from calculus continue to hold for the derivative and integral of vector-valued functions.\nPosition, velocity and acceleration.\nThe position of a point x = (\"x\"1, \"x\"2, \"x\"3) in three-dimensional space can be represented as a position vector whose base point is the origin\nformula_73\nThe position vector has dimensions of length.\nGiven two points x = (\"x\"1, \"x\"2, \"x\"3), y = (\"y\"1, \"y\"2, \"y\"3) their displacement is a vector\nformula_74\nwhich specifies the position of \"y\" relative to \"x\". The length of this vector gives the straight-line distance from \"x\" to \"y\". Displacement has the dimensions of length.\nThe velocity v of a point or particle is a vector, its length gives the speed. For constant velocity the position at time \"t\" will be\nformula_75\nwhere x0 is the position at time \"t\" = 0. Velocity is the time derivative of position. Its dimensions are length/time.\nAcceleration a of a point is vector which is the time derivative of velocity. Its dimensions are length/time2.\nForce, energy, work.\nForce is a vector with dimensions of mass\u00d7length/time2 (N m s \u22122) and Newton's second law is the scalar multiplication\nformula_76\nWork is the dot product of force and displacement\nformula_77\nVectors, pseudovectors, and transformations.\nAn alternative characterization of Euclidean vectors, especially in physics, describes them as lists of quantities which behave in a certain way under a coordinate transformation. A \"contravariant vector\" is required to have components that \"transform opposite to the basis\" under changes of basis. The vector itself does not change when the basis is transformed; instead, the components of the vector make a change that cancels the change in the basis. In other words, if the reference axes (and the basis derived from it) were rotated in one direction, the component representation of the vector would rotate in the opposite way to generate the same final vector. Similarly, if the reference axes were stretched in one direction, the components of the vector would reduce in an exactly compensating way. Mathematically, if the basis undergoes a transformation described by an invertible matrix \"M\", so that a coordinate vector x is transformed to x\u2032 = \"M\"x, then a contravariant vector v must be similarly transformed via v\u2032 = \"M\"formula_78v. This important requirement is what distinguishes a contravariant vector from any other triple of physically meaningful quantities. For example, if \"v\" consists of the \"x\", \"y\", and \"z\"-components of velocity, then \"v\" is a contravariant vector: if the coordinates of space are stretched, rotated, or twisted, then the components of the velocity transform in the same way. On the other hand, for instance, a triple consisting of the length, width, and height of a rectangular box could make up the three components of an abstract vector, but this vector would not be contravariant, since rotating the box does not change the box's length, width, and height. Examples of contravariant vectors include displacement, velocity, electric field, momentum, force, and acceleration.\nIn the language of differential geometry, the requirement that the components of a vector transform according to the same matrix of the coordinate transition is equivalent to defining a \"contravariant vector\" to be a tensor of contravariant rank one. Alternatively, a contravariant vector is defined to be a tangent vector, and the rules for transforming a contravariant vector follow from the chain rule.\nSome vectors transform like contravariant vectors, except that when they are reflected through a mirror, they flip and gain a minus sign. A transformation that switches right-handedness to left-handedness and vice versa like a mirror does is said to change the \"orientation\" of space. A vector which gains a minus sign when the orientation of space changes is called a \"pseudovector\" or an \"axial vector\". Ordinary vectors are sometimes called \"true vectors\" or \"polar vectors\" to distinguish them from pseudovectors. Pseudovectors occur most frequently as the cross product of two ordinary vectors.\nOne example of a pseudovector is angular velocity. Driving in a car, and looking forward, each of the wheels has an angular velocity vector pointing to the left. If the world is reflected in a mirror which switches the left and right side of the car, the \"reflection\" of this angular velocity vector points to the right, but the actual angular velocity vector of the wheel still points to the left, corresponding to the minus sign. Other examples of pseudovectors include magnetic field, torque, or more generally any cross product of two (true) vectors.\nThis distinction between vectors and pseudovectors is often ignored, but it becomes important in studying symmetry properties.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32534", "revid": "45266726", "url": "https://en.wikipedia.org/wiki?curid=32534", "title": "Valhalla", "text": "Legendary enormous hall in Asgard\nIn Norse mythology, Valhalla ( , ; , lit.\u2009'Hall of the Slain') is described as a majestic hall located in Asgard and presided over by the god Odin. There were five possible realms the soul could travel to after death. The first was F\u00f3lkvangr, ruled by the goddess Freyja. The second was Hel, ruled by Hel, Loki's daughter. The third was that of the goddess R\u00e1n. The fourth was the Burial Mound where the dead could live. The fifth and last realm was Valhalla, ruled by Odin and was called the Hall of Heroes. The masses of those killed in combat (known as the einherjar), along with various legendary Germanic heroes and kings, live in Valhalla until Ragnar\u00f6k, when they will march out of its many doors to fight in aid of Odin against the j\u00f6tnar. Valhalla was idealized in Viking culture and gave the Scandinavians a widespread cultural belief that there is nothing more glorious than death in battle. The belief in a Viking paradise and eternal life in Valhalla with Odin may have given the Vikings a violent edge over the other raiders of their time period.\nValhalla is attested in the \"Poetic Edda\", compiled in the 13th century from earlier traditional sources, in the \"Prose Edda\" (written in the 13th century by Snorri Sturluson), in (also written in the 13th century by Snorri Sturluson), and in stanzas of an anonymous 10th-century poem commemorating the death of Eric Bloodaxe known as \"Eir\u00edksm\u00e1l\" as compiled in \"Fagrskinna\". Valhalla has inspired innumerable works of art, publication titles, and elements of popular culture and is synonymous with a martial (or otherwise) hall of the chosen dead. The name is rendered in modern Scandinavian languages as in Icelandic, while the Swedish and Norwegian form is ; in Faroese it is , and in Danish it is .\nEtymology.\nThe Modern English noun \"Valhalla\" derives from Old Norse , a compound noun composed of two elements: the masculine noun 'the slain' and the feminine noun which originally referred to a rock, rocks, or mountain; not a hall, thus meaning Valhalla was originally understood as the \"rock of the Slain\". The form \"Valhalla\" comes from an attempt to clarify the grammatical gender of the word. has cognates in other Germanic languages such as Old English 'the slain, slaughter, carnage', Old Saxon 'murder', Old High German 'battlefield, blood bath'. All of these forms descend from the Proto-Germanic masculine noun *\"walaz\". Among related Old Norse concepts, also appears as the first element of the noun 'chooser of the slain, valkyrie'.\nThe second element, , is a common Old Norse noun. It is cognate to Modern English \"hall\" and offers the same meaning. Both developed from Proto-Germanic *\"xall\u014d\" or *\"hall\u014d\", meaning 'covered place, hall', from the Proto-Indo-European root *\"kol-\". As philologists such as Calvert Watkins note, the same Indo-European root produced Old Norse , a proper noun employed for both the name of another afterlife location and a supernatural female entity as its overseer, as well as the modern English noun \"hell\". In Swedish folklore, some mountains traditionally regarded as abodes of the dead were also called . According to many researchers, the element derives from , \"rock\", and referred to an underworld, not a hall.\nAttestations.\n\"Poetic Edda\".\nValhalla is referenced at length in the \"Poetic Edda\" poem \"Gr\u00edmnism\u00e1l\", and \"Helgakvi\u00f0a Hundingsbana II\", while Valhalla receives lesser direct references in stanza 32 of the \"V\u00f6lusp\u00e1\", where the god Baldr's death is referred to as the \"woe of Valhalla\", and in stanzas 1 to 3 of \"Hyndlulj\u00f3\u00f0\", where the goddess Freyja states her intention of riding to Valhalla with Hyndla, in an effort to help \u00d3ttar, as well as in stanzas 6 through 7, where Valhalla is mentioned again during a dispute between the two.\n\"Gr\u00edmnism\u00e1l\".\nIn stanzas 8 to 10 of \"Gr\u00edmnism\u00e1l\", the god Odin (in the guise of Gr\u00edmnir) proclaims Valhalla is in the realm of Gla\u00f0sheimr. Odin describes Valhalla as shining and golden, and it \"rises peacefully\" as seen from afar. From Valhalla, every day Odin chooses from those killed in combat. Valhalla has spear-shafts for rafters, a roof thatched with shields, coats of mail are strewn over its benches, a wolf hangs in front of its west doors, and an eagle hovers above it.&lt;poem&gt;\n The hall is easily recognised by those who come to \u00d3\u00f0inn:\n Spear-shafts are the rafters, the hall is thatched with shields,\n And the benches are strewn with byrnies.\n The hall is easily recognised by those who come to \u00d3\u00f0inn:\n A warg hangs before the western door,\n And an eagle hovers above . . .\n Andhr\u00edmnir lets Saehr\u00edmnir, best of flesh,\n Be seethed in Eldhr\u00edmnir, the cauldron,\n Though few know what the Einherjar feast on.\n Battle-accustomed, glorious Host-Father feeds Geri and Freki;\n But weapon-stately \u00d3\u00f0inn lives on wine alone.\n Huginn and Muninn fly over the mighty earth every day;\n I fear for Huginn, that he not come back,\n But I look more for Muninn.\n Thundr roars loudly;\n Thj\u00f3\u00f0vitnir\u2019s fish sports in the flood;\n The river roars loudly,\n The battle-slain think it too strong to wade.\n That which stands on the holy fields,\n Before the holy doors,\n Is called Valgrind, the Slain-Gate;\n Those gates are old,\n And few know how they may be locked.\n Five hundred and forty doors:\n So I know to be in Valh\u00f6ll;\n Eight hundred Einherjar go out of one door,\n When they fare to battle the Wolf.\n The goat who stands on Host-Father\u2019s hall\n Is called Hei\u00f0r\u00fan,\n And bites off the limbs of Laera\u00f0r;\n She shall fill a cauldron with the shining mead,\n That drink will never be exhausted.\n The hart who stands on Host-Father\u2019s hall\n Is called Eikthyrnir,\n And bites off the limbs of Laera\u00f0r;\n And drops fall from his horns into Hvergelmir,\n To which all waters wend their way.\n Shaker and Mist I wish to have bear a horn to me;\n Skeggj\u00f6ld and Striker, Shrieker and Battle-Fetter,\n Loudness and Spear-Striker, Shield-Strength and Rede-Strength,\n And God-Inheritance,\n They bear ale to the Einherjar.\n&lt;/poem&gt;\nOdin, throughout this story is seen to have pet ravens that he sends out, and the warriors of his hall are dead men and ghosts who endlessly fight battles and endlessly die. There are also women who feed them and serve them alcohol and are the same spirits who chose them to die in the battles they fight. Valhalla in this story can be seen as a beautiful hall for the dead but it can also be seen as a lofty stylization of a battlefield after a fight. There are broken weapons and shields and dead bodies and ghosts cover the hall that gets ravaged by wolves and ravens. To the Vikings of the time, this was not only their desired afterlife, but a way to cope with the horrors of battle.\n\"Helgakvi\u00f0a Hundingsbana II\".\nIn stanza 38 of the poem \"Helgakvi\u00f0a Hundingsbana II\", the hero Helgi Hundingsbane dies and goes to Valhalla. In stanza 38, Helgi's glory there is described:\n&lt;poem&gt;\nSo was Helgi beside the chieftains\nlike the bright-growing ash beside the thorn-bush\nand the young stag, drenched in dew,\nwho surpasses all other animals\nand whose horns glow against the sky itself.\n&lt;/poem&gt;\nProse follows after this stanza, stating a burial-mound was made for Helgi. After Helgi arrived in Valhalla, he was asked by Odin to manage things with him. In stanza 39, Helgi, now in Valhalla, has his former enemy Hunding\u2014also in Valhalla\u2014do menial tasks; fetching foot-baths for all of the men there, kindling fire, tying dogs, keeping watch of horses, and feeding the pigs before he can get any sleep. In stanzas 40 to 42, Helgi returns to Midgard from Valhalla with a host of men. An unnamed maid of Sigr\u00fan, Helgi's valkyrie wife, sees Helgi and his large host of men riding into the mound. The maid asks if she is experiencing a delusion, if Ragnar\u00f6k is started, or if Helgi and his men were allowed to return.\nIn the following stanzas, Helgi responds none of these things occurred, and so Sigr\u00fan's maid goes home to Sigr\u00fan. The maid tells Sigr\u00fan the burial mound is opened, and Sigr\u00fan should go to Helgi there. Helgi asked her to come and tend his wounds after they opened and are bleeding. Sigr\u00fan goes into the mound, and finds Helgi is drenched in gore, his hair is thick with frost. Filled with joy at the re-union, Sigr\u00fan kisses him before he can remove his coat of mail, and asks how she can heal him. Sigr\u00fan makes a bed there, and the two sleep together in the enclosed burial mound. Helgi awakens, stating he must \"ride along the blood-red roads, to set the pale horse to tread the path of the sky,\" and return before the rooster Salg\u00f3fnir crows. Helgi and the host of men ride away, and Sigr\u00fan and her servant go back to their house. Sigr\u00fan orders her maid to wait for him by the mound the next night, but after she arrives at dawn, she finds he is still journeying. The prose narrative at the end of the poem relates Sigr\u00fan dies of sadness, but the two are thought to be re-born as Helgi Haddingjaskati and the valkyrie K\u00e1ra.\nVafthr\u00fa\u00f0nism\u00e1l.\nIn the story of Vafthr\u00fa\u00f0nism\u00e1l Odin disguises himself as a man named Gagnr\u00e1\u00f0 and visits the all knowing giant, Vafthr\u00fa\u00f0nir, to not only test his knowledge, but gain wisdom from the giant as well. Odin and Vafthr\u00fa\u00f0nir exchange questions and tests Odin on his knowledge of the afterlife and cosmology. Vafthr\u00fa\u00f0nir asks Odin about the topography of Valhalla in Stanzas 15 and 16&lt;poem&gt;\nVafthr\u00fa\u00f0nir said: Say this, Gagnr\u00e1\u00f0r,\nsince you want to test your talent on the floor:\nWhat is the river called that divides the earth\namong the sons of giants and among the gods?\n\u00d3\u00f0inn said: The river is called \u00cdfing,\nwhich divides the earth among the sons \nof giants and among the gods.\n&lt;/poem&gt;\nThen, it is Odin's turn to ask the giant questions but instead of asking questions on the afterlife, Odin asks more esoteric questions like the fate of the gods and the end of the world. Those that are chosen to live in Valhalla with Odin prepare every day for the end of the world, also known as Ragnar\u00f6k. These Vikings prepare for the battle of the end of the world everyday in the eternal battle and is the main characteristic to daily life in Valhalla. Stanzas 17 &amp; 18 of the poem describe the field in Valhalla where this battle takes place&lt;poem&gt;\nVaf\u00fer\u00fa\u00f0nir said:\nSay this, Gagnr\u00e1\u00f0r,\nsince you want to test your talent on the floor:\nWhat is the field called\nwhere Surtr and the sweet gods\nwill meet in battle?\n\u00d3\u00f0inn said:\nThe field is called V\u00edgr\u00ed\u00f0r,\nwhere Surtr and the sweet gods\nwill meet in battle.\nIt is a hundred leagues\nin every direction \u2014\nthat is the field determined for them.\n&lt;/poem&gt;\nThis poem also describes the picking of slain warriors and their entrance into Valhalla in stanza 41 that states&lt;poem&gt;\nVaf\u00fer\u00fa\u00f0nir said:\nAll the unique champions\nin \u00d3\u00f0inn\u2019s enclosed fields\nfight each other every day;\nthey choose the slain\nand ride from battle;\nthereafter they sit together in peace.\n&lt;/poem&gt;\nThe last question Odin asks, is what he himself whispered into the ear of his dying son, Baldr, at Baldr's funeral pyre. This question, revealed Odin's true identity since only he can know the answer to that question. Vafthr\u00fa\u00f0nir realizes he has been tricked, and the story concludes with the All-father, Odin, himself humbling the wise giant who must acknowledge his unparalleled wisdom. \n\"Prose Edda\".\nValhalla is referenced in the \"Prose Edda\" books \"Gylfaginning\" and \"Sk\u00e1ldskaparm\u00e1l\".\n\"Gylfaginning\".\nValhalla is first mentioned in chapter 2 of the \"Prose Edda\" book \"Gylfaginning\", where it is described partially in euhemerized form. In the chapter, King Gylfi sets out to Asgard in the guise of an old man going by the name of \"Gangleri\" to find the source of the power of the gods.\nThe narrative states the \u00c6sir prophesied his arrival and prepared grand illusions for him, so as Gangerli enters the fortress, he sees a hall of such a height, he has trouble seeing over it, and notices the roof of the hall is covered in golden shields, as if they were shingles. Snorri quotes a stanza by the skald \u00dej\u00f3\u00f0\u00f3lfr of Hvinir (c. 900). As he continues, Gangleri sees a man in the doorway of the hall juggling short swords, and keeping seven in the air simultaneously. Among other things, the man says the hall belongs to his king, and adds he can take Gangleri to the king. Gangleri follows him, and the door closes behind him. All around him, he sees many living areas, and throngs of people, some of which are playing games, some are drinking, and others are fighting with weapons. Gangleri sees three thrones, and three figures sitting upon them: High sitting on the lowest throne, Just-As-High sitting on the next highest throne, and Third sitting on the highest. The man guiding Gangleri tells him High is the king of the hall.\nIn chapter 20, Third states Odin mans Valhalla with the Einherjar: those killed in battle and become Odin's adopted sons. In chapter 36, High states valkyries serve drinks and see to the tables in Valhalla, and \"Gr\u00edmnism\u00e1l\" stanzas 40 to 41 are quoted in reference to this. High continues the valkyries are sent by Odin to every battle; they choose who is to die, and determine victory.\nIn chapter 38, Gangleri says: \"You say all men who have fallen in battle from the beginning of the world are now with Odin in Valhalla. With what does he feed them? I should think the crowd there is large.\" High responds this is indeed true, a huge amount are already in Valhalla, but yet this amount will seem to be too few before \"the wolf comes.\" High describes there are never too many to feed in Valhalla, for they feast from S\u00e6hr\u00edmnir (here described as a boar), and this beast is cooked every day and is again whole every night. \"Gr\u00edmnism\u00e1l\" stanza 18 is recounted. Gangleri asks if Odin eats the same food as the Einherjar, and High responds Odin needs nothing to eat\u2014Odin only consumes wine\u2014and he gives his food to his wolves Geri and Freki. \"Gr\u00edmnism\u00e1l\" stanza 19 is recounted. High additionally states, at sunrise, Odin sends his ravens Huginn and Muninn from Valhalla to fly throughout the entire world, and they return in time for the first meal there.\nIn chapter 39, Gangleri asks about the food and drinks the Einherjar consume, and asks if only water is available there. High replies of course, Valhalla has food and drinks fit for kings and jarls, for the mead consumed in Valhalla is produced from the udders of the goat Hei\u00f0r\u00fan, who in turn feeds on the leaves of the \"famous tree\" L\u00e6ra\u00f0r. The goat produces so much mead in a day, it fills a massive vat large enough for all of the Einherjar in Valhalla to satisfy their thirst from it. High further states the stag Eik\u00feyrnir stands atop Valhalla and chews on the branches of L\u00e6ra\u00f0r. So much moisture drips from his horns, it falls down to the well Hvelgelmir, resulting in numerous rivers.\nIn chapter 40, Gangleri muses Valhalla must be quite crowded, to which High responds Valhalla is massive and remains roomy despite the large amount of inhabitants, and then quotes \"Gr\u00edmnism\u00e1l\" stanza 23. In chapter 41, Gangleri says Odin seems to be quite a powerful lord, controlling quite a big army, but he wonders how the Einherjar keep busy while they are not drinking. High replies daily, after they dressed and put on their war gear, they go out to the courtyard and battle one-on-one combat for sport. Then, before mealtime, they ride home to Valhalla and drink. High quotes \"Vaf\u00fer\u00fa\u00f0nism\u00e1l\" stanza 41. In chapter 42, High describes \"right at the beginning, while the gods were settling\", they established Asgard, then built Valhalla. The death of the god Baldr is recounted in chapter 49, with the mistletoe used to kill Baldr is described as growing west of Valhalla.\n\"Sk\u00e1ldskaparm\u00e1l\".\nAt the beginning of \"Sk\u00e1ldskaparm\u00e1l\", a partially euhemerized account is given of \u00c6gir visiting the gods in Asgard and shimmering swords are brought out and used as their sole source of light as they drink. There, numerous gods feast, they have plenty of strong mead, and the hall has wall-panels covered with attractive shields. This location is confirmed as Valhalla in chapter 33.\nIn chapter 2, a quote from the anonymous 10th-century poem Eir\u00edksm\u00e1l is provided (see the \"Fagrskinna\" section below for more detail and another translation from another source):\nWhat sort of dream is that, Odin? I dreamed I rose up before dawn to clear up Val-hall for slain people. I aroused the Einheriar, bade them get up to strew the benches, clean the beer-cups, the valkyries to serve wine for the arrival of a prince.\nIn chapter 17 of \"Sk\u00e1ldskaparm\u00e1l\", the j\u00f6tunn Hrungnir is in a rage and, while attempting to catch up and attack Odin on his steed Sleipnir, ends up at the doors to Valhalla. There, the \u00c6sir invite him in for a drink. Hrungnir goes in, demands a drink, and becomes drunk and belligerent, stating that he will remove Valhalla and take it to the land of the j\u00f6tunn, J\u00f6tunheimr, among various other things. Eventually, the gods tire of his boasting and invoke Thor, who arrives. Hrungnir states that he is under the Aesir's protection as a guest and therefore he can't be harmed while in Valhalla. After an exchange of words, Hrungnir challenges Thor to a duel at the location of Griotunagardar, resulting in Hrungnir's death.\nIn chapter 34, the tree Glasir is stated as located in front of the doors of Valhalla. The tree is described as having foliage of red gold and being the most beautiful tree among both gods and men. A quote from a work by the 9th-century skald Bragi Boddason is presented that confirms the description.\n\"Heimskringla\".\nValhalla is mentioned in euhemerized form and as an element of remaining Norse pagan belief in . In chapter 8 of \"Ynglinga saga\", the \"historical\" Odin is described as ordaining burial laws over his country. These laws include that all the dead are to be burned on a pyre on a burial mound with their possessions, and their ashes are to be brought out to sea or buried in the earth. The dead would then arrive in Valhalla with everything that one had on their pyre, and whatever one had hidden in the ground. Valhalla is additionally referenced in the phrase \"visiting Odin\" in a work by the 10th-century skald \u00dej\u00f3\u00f0\u00f3lfr of Hvinir describing that, upon his death, King Vanlandi went to Valhalla.\nIn chapter 32 of \"H\u00e1konar saga G\u00f3\u00f0a\", Haakon I of Norway is given a pagan burial, which is described as sending him on his way to Valhalla. Verses from \"H\u00e1konarm\u00e1l\" are then quoted in support, themselves containing references to Valhalla.\n\"Fagrskinna\".\nIn chapter 8 of \"Fagrskinna\" a prose narrative states that after the death of her husband Eric Bloodaxe, Gunnhild Mother of Kings had a poem composed about him. The composition is by an anonymous author from the 10th century and is referred to as \"Eir\u00edksm\u00e1l\", and describes Eric Bloodaxe and five other kings arriving in Valhalla after their death. The poem begins with comments by Odin (as Old Norse \"\u00d3\u00f0inn\"):\n&lt;poem&gt;\n\"What kind of a dream is it,\" said \u00d3\u00f0inn,\nin which just before daybreak,\nI thought I cleared Valh\u01ebll,\nfor coming of slain men?\nI waked the Einherjar,\nbade valkyries rise up,\nto strew the bench,\nand scour the beakers,\nwine to carry,\nas for a king's coming,\nhere to me I expect\nheroes' coming from the world,\ncertain great ones,\nso glad is my heart.\n&lt;/poem&gt;\nThe god Bragi asks where a thundering sound is coming from, and says that the benches of Valhalla are creaking\u2014as if the god Baldr had returned to Valhalla\u2014and that it sounds like the movement of a thousand. Odin responds that Bragi knows well that the sounds are for Eric Bloodaxe, who will soon arrive in Valhalla. Odin tells the heroes Sigmund and Sinfj\u00f6tli to rise to greet Eric and invite him into the hall, if it is indeed he.\nSigmund asks Odin why he would expect Eric more than any other king, to which Odin responds that Eric has reddened his gore-drenched sword with many other lands. Eric arrives, and Sigmund greets him, tells him that he is welcome to come into the hall, and asks him what other lords he has brought with him to Valhalla. Eric says that with him are five kings, that he will tell them the name of them all, and that he, himself, is the sixth.\nWomen of Valhalla and their role in the afterlife.\nThe women of Valhalla and their role in the theology of the Norse afterlife is in stark contrast to the commonly male-dominated perceptions of Viking society, mythology, and cultural practices. Those chosen for Valhalla are often associated with heroic deeds in battle; the god Odin was said to have employed women \u2014 battle-maidens called valkyries \u2014 to carry the dead to his hall. These valkyries play a vital role in the functioning of Valhalla, and shape the Norse afterlife and fate of the dead. They are seen as active agents in the cosmic balance of life, death, and honor. \nValkyries are often described as \"Odin's Vultures\", whose purpose is to select the most glorious of men who die in battle. They are women of violence that were seen as precursors to both honor and horror. Valkyries were physically important to the processing of men into Valhalla, which inherently entwined their fate with Viking warriors and they were heavily associated with the death of men. The valkyries haunted their dreams and looked over the slaughter of battle, making them culturally dreaded creatures. Over time, this view of valkyries in Valhalla softened, making them into protective spirits. They are the women who serve the men of Valhalla in feasts and care for the warriors until Ragnar\u00f6k. This later shift from violent overseers to sustainers of life shows how the image of women changed within Norse culture with the introduction of Christianity.\nValhalla is also the only hall of the dead that is ruled by a male deity. All the other realms are tended to by female deities. Hel, the j\u00f6tunn and daughter of Loki, presides over the eponymous Hel, where those who die of illness or old age dwell. Freyja, the goddess of love and war, claims half of the fallen warriors in her realm of F\u00f3lkvangr. R\u00e1n, the sea goddess, gathers the drowned into her underwater hall. These female goddesses further enforce this image of women as the overseers of death. Women in Norse Mythology then, \"collect the dead, women portend death, they care for the dead and women keep the dead. In all respects except \u00d3\u00f0in\u2019s, it seems like an almost exclusively feminine role to keep\u201d.\nCultural practices.\nThe belief in Valhalla influenced many cultural practices in Norse society, specifically those surrounding death and commemoration. These practices during the death and burial of a Viking reflects the society's greater understanding of honor, legacy, and the afterlife. Valhalla and the practices that occurred were deeply tied to its role in immortalizing and honoring the dead. these customs later evolved with the introduction of Christianity and created a complex tradition of the Norse afterlife. \nHorse burial: transportation to Valhalla.\nHorses played a critical role in the burial and funeral processions of Viking burials. They were seen to be the dead's main transportation to Valhalla. In \"Egils saga Skallagr\u00edmssonar\", for instance, Skallagr\u00edmr is buried with his horse, weapons, and smith\u2019s tools, illustrating the belief in the horse\u2019s importance for the deceased\u2019s passage to Odin\u2019s hall. It is also noted that Old Norse sources mention only horses, not ships, as a means of traveling to and from Valhalla. This belief in horses being the main way of getting to Valhalla is also supported in the story, S\u00f6gubrot, where the character Harald Wartooth is buried with his horse and a wagon so he could ride to Valhalla. The riding of a horse to Valhalla is also mention in the story, \"Helgakvi\u00f0a Hundingsbana II\", where the hero Helgi rides to Valhalla after his burial and later returns on horseback to visit his living bride.\nDeath chants as appeals to Valhalla.\nDeath chants were poetic compositions made to appease Odin and to earn a dead loved one's place in Valhalla. These death chants recorded a loved one's deed and accounted their victories to prove their worthiness to the hall of heroes. The witnesses of these death chants were often daughters of the dying Vikings who acted at intermediaries by recording these poems in runes or orally. \u201cBy witnessing and recording these poems, they are in essence lending their fathers\u2019 deaths a certain amount of weight\u201d. These rituals ensured that the deeds of the fallen would remain influential, securing their place among the honored dead in Valhalla. This also once again placed women as a central role in death and the procession of death in Viking society. \nPolitical continuity through death.\nThe belief in Valhalla also committed to the deification of political leaders and heroes. Instead of being a hall for those that died in battle, it became a symbol of honor and continuity in a heritage-based society. As Gundarsson notes, \u201cThe purpose of the deification of a dead leader or hero is clear. It offers a sense of continuity\u201d, with rulers often seated on their forebears\u2019 burial mounds to evoke the authority of the dead. As Scandinavia transitioned into larger and more unified nations, the importance of the deification of political leaders grew and Valhalla became a resting place for kings and political heroes. So, to enter Valhalla was not to achieve a \"good death\" but to secure a legacy among the gods and kings. \nModern influence.\nThe concept of Valhalla continues to influence modern popular culture. Examples include the Walhalla temple built by Leo von Klenze for Ludwig I of Bavaria between 1830 and 1847 near Regensburg, Germany, and the Tresco Abbey Gardens Valhalla museum built by August Smith around 1830 to house ship figureheads from shipwrecks that occurred at the Isles of Scilly, England, near the museum.\nReferences to Valhalla appear in literature, art, and other forms of media. Examples include K. Ehrenberg's charcoal illustration \"Gastmahl in Walhalla (mit einziehenden Einheriern)\" (1880), Richard Wagner's depiction of Valhalla in his opera cycle \"Der Ring des Nibelungen\" (1848\u20131874), the Munich, Germany-based Germanic Neopagan magazine \"Walhalla\" (1905\u20131913), the book series Magnus Chase and the Gods of Asgard by Rick Riordan, the comic series \"Valhalla\" (1978\u20132009) by Peter Madsen, and its subsequent animated film of the same name (1986). Valhalla also gives its name to a thrill ride at Blackpool Pleasure Beach, UK.\nBefore Hunter S. Thompson became the counter-culture's Gonzo journalist, he lived in Big Sur, California, while writing his novel \"The Rum Diary.\" He wrote \"Big Sur is very like Valhalla\u2014a place that a lot of people have heard of, and that very few can tell you anything about\" (\"Proud Highway: Saga of a Desperate Southern Gentleman,\" chapter 20).\nIn the 2015 film \"\", the cult of the War Boys believe a heroic death in the service of dictator Immortan Joe will take them to Valhalla.\nA video game \"Assassin's Creed Valhalla\" was released in November 2020. The video game \"Apex Legends\" features a character named Bloodhound, who often references Valhalla and the Allfather, a commonly used kenning for the Norse god Odin. Valhalla is also referenced in the manga 'Heart Gear' by Tsuyoshi Takaki as a battle ground where the 'combat' gears take turns in fighting each other to the death as their leader, Odin, observes. Another video game, \"Overwatch 2,\" features two in game cosmetic skins that were inspired by Valhalla's Valkyries. These skins are both on the flying support hero, Mercy, who heals and resurrects her team. These Valkyrie inspired skins feature a voice line where Mercy says, \"till Valhalla\" when she uses one of her mass team healing ability. \nElton John's first album, \"Empty Sky\" (1969), contains a song called \"Valhalla\". Led Zeppelin's \"Immigrant Song\" from their third album, \"Led Zeppelin III\" (1970), contains the following Valhalla reference: \"The hammer of the gods/ Will drive our ships to new lands/ To fight the horde, sing and cry/ Valhalla, I am coming\". Judas Priest's seventeenth studio album \"Redeemer of Souls\" released in 2014 included the song \"Halls of Valhalla\", as lead singer Rob Halford describes as \"singing about being on the North Sea and heading to Denmark or Sweden searching for Valhalla\". Australian band Skegss's third album, \"Rehearsal\" (2021), contains a song called \"Valhalla\". Jethro Tull's album, \"Minstrel in the Gallery\" (1975), contains a song called \"Cold Wind to Valhalla\".\nOn 14 April 1989, Blind Guardian released \"Follow the Blind,\" track number 8 is titled \"Valhalla.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "32538", "revid": "40234806", "url": "https://en.wikipedia.org/wiki?curid=32538", "title": "Viking Age", "text": "Period of European history (about 800\u20131050)\nThe Viking Age (about \u00a0CE) was the period during the Middle Ages when Norsemen known as Vikings undertook large-scale raiding, colonising, conquest, and trading throughout Europe and reached North America. The Viking Age applies not only to their homeland of Scandinavia but also to any place significantly settled by Scandinavians during the period. Although few of the Scandinavians of the Viking Age were Vikings in the sense of being engaged in piracy, they are often referred to as \"Vikings\" as well as \"Norsemen\".\nVoyaging by sea from their homelands in Denmark, Norway, and Sweden, the Norse people settled in the British Isles, Ireland, the Faroe Islands, Iceland, Greenland, Normandy, and the Baltic coast and along the Dnieper and Volga trade routes in eastern Europe, where they were also known as Varangians. They also briefly settled in Newfoundland, becoming the first Europeans to reach North America. The Norse-Gaels, Normans, Rus' people, Faroese, and Icelanders emerged from these Norse colonies. The Vikings founded several kingdoms and earldoms in Europe: the Kingdom of the Isles (\"Su\u00f0reyjar\"), Orkney (\"Nor\u00f0reyjar\"), York (\"J\u00f3rv\u00edk\") and the Danelaw (\"Danal\u01ebg\"), Dublin (\"Dyflin\"), Normandy, and Kievan Rus' (\"Gar\u00f0ar\u00edki\"). The Norse homelands were also unified into larger kingdoms during the Viking Age, and the short-lived North Sea Empire included large swathes of Scandinavia and Britain. In 1021, the Vikings achieved the feat of reaching North America\u2014the date of which was not determined until a millennium later.\nSeveral factors drove this expansion. The Vikings were drawn by the growth of wealthy towns and monasteries overseas and weak kingdoms. They may also have been pushed to leave their homeland by overpopulation, lack of good farmland, and political strife arising from the unification of Norway. The aggressive expansion of the Carolingian Empire and forced conversion of the neighbouring Saxons to Christianity may also have been a factor. Sailing innovations had allowed the Vikings to sail farther and longer to begin with.\nInformation about the Viking Age is drawn largely from primary sources written by those the Vikings encountered, as well as archaeology, supplemented with secondary sources such as the Icelandic Sagas.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nContext.\nIn England, the Viking attack of 8 June 793 that destroyed the abbey on Lindisfarne, a centre of learning on an island off the north-east coast of England in Northumberland, is regarded as the beginning of the Viking Age. Judith Jesch has argued that the start of the Viking Age can be pushed back to 700\u2013750, as it was unlikely that the Lindisfarne attack was the first attack, and given archeological evidence that suggests contacts between Scandinavia and the British isles earlier in the century. The earliest raids were most likely small in scale, but expanded in scale during the 9th century.\nIn the Lindisfarne attack, monks were killed in the abbey, thrown into the sea to drown, or carried away as slaves along with the church treasures, giving rise to the traditional (but unattested) prayer\u2014\"\", \"Free us from the fury of the Northmen, Lord.\" Three Viking ships had beached in Weymouth Bay four years earlier (although due to a scribal error the \"Anglo-Saxon Chronicle\" dates this event to 787 rather than 789), but that incursion may have been a trading expedition that went wrong rather than a piratical raid. Lindisfarne was different. The Viking devastation of Northumbria's Holy Island was reported by the Northumbrian scholar Alcuin of York, who wrote: \"Never before in Britain has such a terror appeared\". Vikings were portrayed as wholly violent and bloodthirsty by their enemies. Robert of Gloucester's Chronicle, c. 1300, mentions Viking attacks on the people of East Anglia wherein they are described as \"wolves among sheep\".\nThe first challenges to the many negative depictions of Vikings in Britain emerged in the 17th century. Pioneering scholarly works on the Viking Age reached only a small readership there, while linguists traced the Viking Age origins of rural idioms and proverbs. New dictionaries and grammars of the Old Icelandic language appeared, enabling more Victorian scholars to read the primary texts of the Icelandic Sagas.\nIn Scandinavia, the 17th-century Danish scholars Thomas Bartholin and Ole Worm and Swedish scholar Olaus Rudbeck were the first to use runic inscriptions and Icelandic Sagas as primary historical sources. During the Enlightenment and Nordic Renaissance, historians such as the Icelandic-Norwegian Thormodus Torf\u00e6us, Danish-Norwegian Ludvig Holberg, and Swedish Olof von Dalin developed a more \"rational\" and \"pragmatic\" approach to historical scholarship.\nBy the latter half of the 18th century, while the Icelandic sagas were still used as important historical sources, the Viking Age had again come to be regarded as a barbaric and uncivilised period in the history of the Nordic countries. Scholars outside Scandinavia did not begin to extensively reassess the achievements of the Vikings until the 1890s, recognising their artistry, technological skills, and seamanship.\nBackground.\nThe Vikings who invaded western and eastern Europe were mainly pagans from the same area as present-day Denmark, Norway, and Sweden. They also settled in the Faroe Islands, Ireland, Iceland, peripheral Scotland (Caithness, the Hebrides and the Northern Isles), Greenland, and Canada.\nTheir North Germanic language, Old Norse, became the precursor to present-day Scandinavian languages. By 801, a strong central authority appears to have been established in Jutland, and the Danes were beginning to look beyond their own territory for land, trade, and plunder.\nIn Norway, mountainous terrain and fjords formed strong natural boundaries. Communities remained independent of each other, unlike the situation in lowland Denmark. By 800, some 30 small kingdoms existed in Norway.\nThe sea was the easiest way of communication between the Norwegian kingdoms and the outside world. In the eighth century, Scandinavians began to build ships of war and send them on raiding expeditions which started the Viking Age. The North Sea rovers were traders, colonisers, explorers, and plunderers who were notorious in England, Scotland, Ireland, Wales and other places in Europe for being brutal.\nProbable causes.\nMany theories are posited for the cause of the Viking invasions; the will to explore likely played a major role. At the time, England, Wales, and Ireland were vulnerable to attack, being divided into many different warring kingdoms in a state of internal disarray, while the Franks were well defended. Overpopulation, especially near the Scandes, was a possible reason, although some disagree with this theory. Technological advances like the use of iron and a shortage of women due to selective female infanticide also likely had an impact. Tensions caused by Frankish expansion to the south of Scandinavia, and their subsequent attacks upon the Viking peoples, may have also played a role in Viking pillaging. Harald I of Norway (\"Harald Fairhair\") had united Norway around this time and displaced many peoples. As a result, these people sought for new bases to launch counter-raids against Harald.\nDebate among scholars is ongoing as to why the Scandinavians began to expand from the eighth through 11th centuries. Various factors have been highlighted: demographic, economic, ideological, political, technological, and environmental models.\nDemographic models.\nBarrett considers that prior scholarship having examined causes of the Viking Age in terms of demographic determinism, the resulting explanations have generated a \"wide variety of possible models\". While admitting that Scandinavia did share in the general European population and settlement expansion at the end of the first millennium, he dismisses 'population pressure' as a realistic cause of the Viking Age. Bagge alludes to the evidence of demographic growth at the time, manifested in an increase of new settlements, but he declares that a warlike people do not require population pressure to resort to plundering abroad. He grants that although population increase was a factor in this expansion, it was not the incentive for such expeditions. According to Ferguson, the proliferation of the use of iron in Scandinavia at the time increased agricultural yields, allowing for demographic growth that strained the limited capacity of the land. As a result, many Scandinavians found themselves with no property and no status. To remedy this, these landless men took to piracy to obtain material wealth. The population continued to grow, and the pirates looked further and further beyond the borders of the Baltic, and eventually into all of Europe. Historian Anders Winroth has also challenged the \"overpopulation\" thesis, arguing that scholars are \"simply repeating an ancient clich\u00e9 that has no basis in fact.\"\nEconomic model.\nThe economic model states that the Viking Age was the result of growing urbanism and trade throughout mainland Europe. As the Islamic world grew, so did its trade routes, and the wealth which moved along them was pushed further and further north. In Western Europe, proto-urban centres such as those with names ending in \"wich\", the so-called -wich towns of Anglo-Saxon England, began to boom during the prosperous era known as the \"Long Eighth Century\". The Scandinavians, like many other Europeans, were drawn to these wealthier \"urban\" centres, which soon became frequent targets of Viking raids. The connection of the Scandinavians to larger and richer trade networks lured the Vikings into Western Europe, and soon the rest of Europe and parts of the Middle East. In England, hoards of Viking silver, such as the Cuerdale Hoard and the Vale of York Hoard, offer insight into this phenomenon. Barrett rejects this model, arguing that the earliest recorded Viking raids were in Western Norway and northern Britain, which were not highly economically integrated areas. He proposes a version of the economic model that points to new economic incentives stemming from a \"bulge\" in the population of young Scandinavian men, impelling them to engage in maritime activity due to limited economic alternatives.\nIdeological model.\nThis era coincided with the Medieval Warm Period (800\u20131300) and stopped with the start of the Little Ice Age (about 1250\u20131850). The start of the Viking Age, with the sack of Lindisfarne, also coincided with Charlemagne's Saxon Wars, or Christian wars with pagans in Saxony. Bruno Dum\u00e9zil theorises that the Viking attacks may have been in response to the spread of Christianity among pagan peoples. Because of the penetration of Christianity in Scandinavia, serious conflict divided Norway for almost a century.\nPolitical model.\nThe first of two main components to the political model is the external \"pull\" factor, which suggests that the weak political bodies of Britain and Western Europe made for an attractive target for Viking raiders. The reasons for these weaknesses vary, but generally can be simplified into decentralised polities, or religious sites. As a result, Viking raiders found it easy to sack and then retreat from these areas which were thus frequently raided. The second case is the internal \"push\" factor, which coincides with a period just before the Viking Age in which Scandinavia was undergoing a mass centralisation of power in the modern-day countries of Denmark, Sweden, and especially Norway. This centralisation of power forced hundreds of chieftains from their lands, which were slowly being appropriated by the kings and dynasties that began to emerge. As a result, many of these chiefs sought refuge elsewhere, and began harrying the coasts of the British Isles and Western Europe. Anders Winroth argues that purposeful choices by warlords \"propelled the Viking Age movement of people from Scandinavia.\"\nThese models constitute much of what is known about the motivations for and the causes of the Viking Age. In all likelihood, the beginning of this age was the result of some combination of the aforementioned hypotheses.\nThe Viking colonisation of islands in the North Atlantic has in part been attributed to a period of favourable climate (the Medieval Climactic Optimum), as the weather was relatively stable and predictable, with calm seas. Sea ice was rare, harvests were typically strong, and fishing conditions were good.\nOverview.\nThe earliest date given for the coming of Vikings to England is 789 during the reign of King Beorhtric of Wessex. According to the \"Anglo-Saxon Chronicle\" three Norwegian boats from Hordaland (Old Norse: \"H\u01ebr\u00f0alandi\") landed at the Isle of Portland off the coast of Dorset. They apparently were mistaken for merchants by a royal official, Beaduhard, a king's reeve who attempted to force them to come to the king's manor, whereupon they killed the reeve and his men. The beginning of the Viking Age in the British Isles is often set at 793. It was recorded in the \"Anglo\u2013Saxon Chronicle\" that the Northmen raided the important island monastery of Lindisfarne (the generally accepted date is actually 8 June, not January):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;A.D. 793. This year came dreadful fore-warnings over the land of the Northumbrians, terrifying the people most woefully: these were immense sheets of light rushing through the air, and whirlwinds, and fiery dragons flying across the firmament. These tremendous tokens were soon followed by a great famine: and not long after, on the sixth day before the ides of January in the same year, the harrowing inroads of heathen men made lamentable havoc in the church of God in Holy-island \"(Lindisfarne)\", by rapine and slaughter.\u2014\u200a\nIn 794, according to the \"Annals of Ulster\", a serious attack was made on Lindisfarne's mother-house of Iona, which was followed in 795 by raids upon the northern coast of Ireland. From bases there, the Norsemen attacked Iona again in 802, causing great slaughter amongst the \"C\u00e9li D\u00e9\" Brethren, and burning the abbey to the ground.\nThe Vikings primarily targeted Ireland until 830, as England and the Carolingian Empire were able to fight the Vikings off. However, after \u00a0CE, the Vikings had considerable success against England, the Carolingian Empire, and other parts of Western Europe. After 830, the Vikings exploited disunity within the Carolingian Empire, as well as pitting the English kingdoms against each other.\nThe Kingdom of the Franks under Charlemagne was particularly devastated by these raiders, who could sail up the Seine with near impunity. Near the end of Charlemagne's reign (and throughout the reigns of his sons and grandsons), a string of Norse raids began, culminating in a gradual Scandinavian conquest and settlement of the region now known as Normandy in 911. Frankish King Charles the Simple granted the Duchy of Normandy to Viking warleader Rollo (a chieftain of disputed Norwegian or Danish origins) in order to stave off attacks by other Vikings. Charles gave Rollo the title of duke. In return, Rollo swore fealty to Charles, converted to Christianity, and undertook to defend the northern region of France against the incursions of other Viking groups. Several generations later, the Norman descendants of these Viking settlers not only identified themselves as Norman, but also carried the Norman language (either a French dialect or a Romance language which can be classified as one of the O\u00efl languages along with French, Picard and Walloon), and their Norman culture, into England in 1066. With the Norman Conquest, they became the ruling aristocracy of Anglo\u2013Saxon England.\nThe clinker-built longships used by the Scandinavians were uniquely suited to both deep and shallow waters. They extended the reach of Norse raiders, traders, and settlers along coastlines and along the major river valleys of north-western Europe. Rurik also expanded to the east, and in 859 became ruler either by conquest or invitation by local people of the city of Novgorod (which means \"new city\") on the Volkhov River. His successors moved further, founding the early East Slavic state of Kievan Rus' with the capital in Kiev. This persisted until 1240, when the Mongols invaded Kievan Rus'.\nOther Norse people continued south to the Black Sea and then on to Constantinople. The eastern connections of these \"Varangians\" brought Byzantine silk, a cowrie shell from the Red Sea, and even coins from Samarkand, to Viking York.\nIn 884, an army of Danish Vikings was defeated at the Battle of Norditi (also called the Battle of Hilgenried Bay) on the Germanic North Sea coast by a Frisian army under Archbishop Rimbert of Bremen-Hamburg, which precipitated the complete and permanent withdrawal of the Vikings from East Frisia. In the 10th and 11th centuries, Saxons and Slavs began to use trained mobile cavalry successfully against Viking foot soldiers, making it hard for Viking invaders to fight inland.\nIn Scandinavia, the Viking Age is considered by some scholars to have ended with the establishment of royal authority and the establishment of Christianity as the dominant religion. Scholars have proposed different end dates for the Viking Age, but many argue it ended in the 11th century. The year 1000 is sometimes used, as that was the year in which Iceland converted to Christianity, marking the conversion of all of Scandinavia to Christianity. The death of Harthacnut, the Danish King of England, in 1042 has also been used as an end date. History does not often allow such clear-cut separation between arbitrary \"ages\", and it is not easy to pin down a single date that applies to all the Viking world. The Viking Age was not a \"monolithic chronological period\" across three or four hundred years, but was characterised by various distinct phases of Viking activity. It is unlikely that the Viking Age could be so neatly assigned a terminal event. The end of the Viking era in Norway is marked by the Battle of Stiklestad in 1030, in which \u00d3l\u00e1fr Haraldsson (later known as Olav the Holy), a fervent Christianiser who dealt harshly with those suspected of clinging to pagan cult, was killed. Although \u00d3l\u00e1fr's army lost the battle, Christianity continued to spread, and after his death he became one of the subjects of the three miracle stories given in the Manx Chronicle. In Sweden, the reign of king Olof Sk\u00f6tkonung (c.\u2009995\u20131020) is considered to be the transition from the Viking Age to the Middle Ages, because he was the first Christian king of the Swedes, and he is associated with a growing influence of the church in what is today southwestern and central Sweden. Norse beliefs persisted until the 12th century; Olof was the last king in Scandinavia to adopt Christianity.\nThe end of the Viking Age is traditionally marked in England by the failed invasion attempted by the Norwegian king Harald III (Haraldr Har\u00f0r\u00e1\u00f0i), who was defeated by Saxon King Harold Godwinson in 1066 at the Battle of Stamford Bridge; in Ireland, the capture of Dublin by Strongbow and his Hiberno-Norman forces in 1171; and 1263 in Scotland by the defeat of King H\u00e1kon H\u00e1konarson at the Battle of Largs by troops loyal to Alexander III. Godwinson was subsequently defeated within a month by another Viking descendant, William, Duke of Normandy. Scotland took its present form when it regained territory from the Norse between the 13th and the 15th centuries; the Western Isles and the Isle of Man remained under Scandinavian authority until 1266. Orkney and Shetland belonged to the king of Norway as late as 1469. Consequently, a \"long Viking Age\" may stretch into the 15th century.\nNorthern Europe.\nEngland.\nAccording to the \"Anglo-Saxon Chronicles\", Viking raiders struck England in 793 and raided Lindisfarne, the monastery that held Saint Cuthbert's relics, killing the monks and capturing the valuables. The raid marked the beginning of the \"Viking Age of Invasion\". Great but sporadic violence continued on England's northern and eastern shores, with raids continuing on a small scale across coastal England. While the initial raiding groups were small, a great amount of planning is believed to have been involved. The Vikings raided during the winter of 840\u2013841, rather than the usual summer, having waited on an island off Ireland.\nIn 850, the Vikings overwintered for the first time in England, on the island of Thanet, Kent. In 854, a raiding party overwintered a second time, at the Isle of Sheppey in the Thames estuary. In 864, they reverted to Thanet for their winter encampment.\nThe following year, the Great Heathen Army, led by brothers Ivar the Boneless, Halfdan and Ubba, and also by another Viking Guthrum, arrived in East Anglia. They proceeded to cross England into Northumbria and captured York, establishing a Viking community in Jorvik, where some settled as farmers and craftsmen. Most of the English kingdoms, being in turmoil, could not stand against the Vikings. In 867, Northumbria became the northern kingdom of the coalescing Danelaw, after its conquest by the Ragnarsson brothers, who installed an Englishman, Ecgberht, as a puppet king. By 870, the \"Great Summer Army\" arrived in England, led by a Viking leader called Bagsecg and his five earls. Aided by the Great Heathen Army (which had already overrun much of England from its base in Jorvik), Bagsecg's forces, and Halfdan's forces (through an alliance), the combined Viking forces raided much of England until 871, when they planned an invasion of Wessex. On 8 January 871, Bagsecg was killed at the Battle of Ashdown along with his earls. As a result, many of the Vikings returned to northern England, where Jorvic had become the centre of the Viking kingdom, but Alfred of Wessex managed to keep them out of his country. Alfred and his successors continued to drive back the Viking frontier and take York. A new wave of Vikings appeared in England in 947, when Eric Bloodaxe captured York.\nIn 1003, the Danish King Sweyn Forkbeard started a series of raids against England to avenge the St. Brice's Day massacre of England's Danish inhabitants, culminating in a full-scale invasion that led to Sweyn being crowned king of England in 1013. Sweyn was also king of Denmark and parts of Norway at this time. The throne of England passed to Edmund Ironside of Wessex after Sweyn's death in 1014. Sweyn's son, Cnut the Great, won the throne of England in 1016 through conquest. When Cnut the Great died in 1035 he was a king of Denmark, England, Norway, and parts of Sweden. Harold Harefoot became king of England after Cnut's death, and Viking rule of England ceased.\nThe Viking presence declined until 1066, when they lost their final battle with the English at Stamford Bridge. The death in the battle of King Harald Hardrada of Norway ended any hope of reviving Cnut's North Sea Empire, and it is because of this, rather than the Norman conquest, that 1066 is often taken as the end of the Viking Age. Nineteen days later, a large army containing and led by senior Normans, themselves mostly male-line descendants of Norsemen, invaded England and defeated the weakened English army at the Battle of Hastings. The army invited others from across Norman gentry and ecclesiastical society to join them. There were several unsuccessful attempts by Scandinavian kings to regain control of England, the last of which took place in 1086.\nIn 1152, Eystein II of Norway led a plundering raid down the east coast of Britain.\nIreland.\nIn 795, small bands of Vikings began plundering monastic settlements along the coast of Gaelic Ireland. The Annals of Ulster state that in 821 the Vikings plundered Howth and \"carried off a great number of women into captivity\". From 840 the Vikings began building fortified encampments, \"longphorts\", on the coast and overwintering in Ireland. The first were at Dublin and Linn Duachaill. Their attacks became bigger and reached further inland, striking larger monastic settlements such as Armagh, Clonmacnoise, Glendalough, Kells, and Kildare, and also plundering the ancient tombs of Br\u00fa na B\u00f3inne. Viking chief Thorgest is said to have raided the whole midlands of Ireland until he was killed by M\u00e1el Sechnaill I in 845.\nIn 853, Viking leader Amla\u00edb (Olaf) became the first king of Dublin. He ruled along with his brothers \u00cdmar (possibly Ivar the Boneless) and Auisle. Over the following decades, there was regular warfare between the Vikings and the Irish, and between two groups of Vikings: the Dubgaill and Finngaill (dark and fair foreigners). The Vikings also briefly allied with various Irish kings against their rivals. In 866, \u00c1ed Findliath burnt all Viking longphorts in the north, and they never managed to establish permanent settlements in that region. The Vikings were driven from Dublin in 902.\nThey returned in 914, now led by the U\u00ed \u00cdmair (House of Ivar). During the next eight years the Vikings won decisive battles against the Irish, regained control of Dublin, and founded settlements at Waterford, Wexford, Cork, and Limerick, which became Ireland's first large towns. They were important trading hubs, and Viking Dublin was the biggest slave port in western Europe.\nThese Viking territories became part of the patchwork of kingdoms in Ireland. Vikings intermarried with the Irish and adopted elements of Irish culture, becoming the Norse-Gaels. Some Viking kings of Dublin also ruled the kingdom of the Isles and York; such as Sitric C\u00e1ech, Gofraid ua \u00cdmair, Olaf Guthfrithson, and Olaf Cuaran. Sigtrygg Silkbeard was \"a patron of the arts, a benefactor of the church, and an economic innovator\" who established Ireland's first mint, in Dublin.\nIn \u00a0CE, M\u00e1el Sechnaill M\u00f3r defeated the Dublin Vikings and forced them into submission. Over the following thirty years, Brian Boru subdued the Viking territories and made himself High King of Ireland. The Dublin Vikings, together with Leinster, twice rebelled against him, but they were defeated in the battles of Glenmama (\u00a0CE) and Clontarf (\u00a0CE). After the battle of Clontarf, the Dublin Vikings could no longer \"single-handedly threaten the power of the most powerful kings of Ireland\". Brian's rise to power and conflict with the Vikings is chronicled in \"Cogad G\u00e1edel re Gallaib\" (\"The War of the Irish with the Foreigners\").\nScotland.\nWhile few records are known, the Vikings are thought to have led their first raids in Scotland on the holy island of Iona in 794, the year following the raid on the other holy island of Lindisfarne, Northumbria.\nIn 839, a large Norse fleet invaded via the River Tay and River Earn, both of which were highly navigable, and reached into the heart of the Pictish kingdom of Fortriu. They defeated Eog\u00e1n mac \u00d3engusa, king of the Picts, his brother Bran, and the king of the Scots of D\u00e1l Riata, \u00c1ed mac Boanta, along with many members of the Pictish aristocracy in battle. The sophisticated kingdom that had been built fell apart, as did the Pictish leadership, which had been stable for more than 100 years since the time of \u00d3engus mac Fergusa (The accession of Cin\u00e1ed mac Ailp\u00edn as king of both Picts and Scots can be attributed to the aftermath of this event).\nIn 870, the Britons of the Old North around the Firth of Clyde came under Viking attack as well. The fortress atop Alt Clut (\"Rock of the Clyde\", the Brythonic name for Dumbarton Rock, which had become the metonym for their kingdom) was besieged by the Viking kings Amla\u00edb and \u00cdmar. After four months, its water supply failed, and the fortress fell. The Vikings are recorded to have transported a vast prey of British, Pictish, and English captives back to Ireland. These prisoners may have included the ruling family of Alt Clut including the king Arthgal ap Dyfnwal, who was slain the following year under uncertain circumstances. The fall of Alt Clut marked a watershed in the history of the realm. Afterwards, the capital of the restructured kingdom was relocated about 12miles (20km) up the River Clyde to the vicinity of Govan and Partick (within present-day Glasgow), and became known as the Kingdom of Strathclyde, which persisted as a major regional political player for another 150 years.\nThe land that now comprises most of the Scottish Lowlands had previously been the northernmost part of the Anglo-Saxon kingdom of Northumbria, which fell apart with its Viking conquest; these lands were never regained by the Anglo-Saxons, or England. The upheaval and pressure of Viking raiding, occupation, conquest and settlement resulted in alliances among the formerly enemy peoples that comprised what would become present-day Scotland. Over the subsequent 300 years, this Viking upheaval and pressure led to the unification of the previously contending Gaelic, Pictish, British, and English kingdoms, first into the Kingdom of Alba, and finally into the greater Kingdom of Scotland. The Viking Age in Scotland came to an end after another 100 years. The last vestiges of Norse power in the Scottish seas and islands were completely relinquished after another 200 years.\nEarldom of Orkney.\nBy the mid-9th century, the Norsemen had settled in Shetland, Orkney (the Nordreys- \"Nor\u00f0reyjar\"), the Hebrides and Isle of Man, (the Sudreys- \"Su\u00f0reyjar\"\u2014this survives in the Diocese of Sodor and Man) and parts of mainland Scotland. The Norse settlers were to some extent integrating with the local Gaelic population (see Norse-Gaels) in the Hebrides and Man. These areas were ruled over by local Jarls, originally captains of ships or \"hersirs\". The Jarl of Orkney and Shetland, however, claimed supremacy.\nIn 875, King Harald Fairhair led a fleet from Norway to Scotland. In his attempt to unite Norway, he found that many of those opposed to his rise to power had taken refuge in the Isles. From here, they were raiding not only foreign lands but were also attacking Norway itself. After organising a fleet, Harald was able to subdue the rebels, and in doing so brought the independent Jarls under his control, many of the rebels having fled to Iceland. He found himself ruling not only Norway, but also the Isles, Man, and parts of Scotland.\nKings of the Isles.\nIn 876, the Norse-Gaels of Mann and the Hebrides rebelled against Harald. A fleet was sent against them led by Ketil Flatnose to regain control. On his success, Ketil was to rule the Sudreys as a vassal of King Harald. His grandson, Thorstein the Red, and Sigurd the Mighty, Jarl of Orkney, invaded Scotland and were able to exact tribute from nearly half the kingdom until their deaths in battle. Ketil declared himself King of the Isles. Ketil was eventually outlawed and, fearing the bounty on his head, fled to Iceland.\nThe Norse-Gaelic Kings of the Isles continued to act semi independently, in 973 forming a defensive pact with the Kings of Scotland and Strathclyde. In 1095, the King of Mann and the Isles Godred Crovan was killed by Magnus Barelegs, King of Norway. Magnus and King Edgar of Scotland agreed on a treaty. The islands would be controlled by Norway, but mainland territories would go to Scotland. The King of Norway nominally continued to be king of the Isles and Man. However, in 1156, The kingdom was split into two. The Western Isles and Man continued as to be called the \"Kingdom of Man and the Isles\", but the Inner Hebrides came under the influence of Somerled, a Gaelic speaker, who was styled 'King of the Hebrides'. His kingdom was to develop latterly into the Lordship of the Isles.\nIn eastern Aberdeenshire, the Danes invaded at least as far north as the area near Cruden Bay.\nThe Jarls of Orkney continued to rule much of northern Scotland until 1196, when Harald Maddadsson agreed to pay tribute to William the Lion, King of Scots, for his territories on the mainland.\nThe end of the Viking Age \"proper\" in Scotland is generally considered to be in 1266. In 1263, King Haakon IV of Norway, in retaliation for a Scots expedition to Skye, arrived on the west coast with a fleet from Norway and Orkney. His fleet linked up with those of King Magnus of Man and King Dougal of the Hebrides. After peace talks failed, his forces met with the Scots at Largs, in Ayrshire. The battle proved indecisive, but it did ensure that the Norse were not able to mount a further attack that year. Haakon died overwintering in Orkney, and by 1266, his son Magnus the Law-Mender ceded the Kingdom of Man and the Isles, with all territories on mainland Scotland to Alexander III, through the Treaty of Perth.\nOrkney and Shetland continued to be ruled as autonomous Jarldoms under Norway until 1468, when King Christian I pledged them as security on the dowry of his daughter, who was betrothed to James III of Scotland. Although attempts were made during the 17th and 18th centuries to redeem Shetland, without success, and Charles II ratifying the pawning in the Orkney and Shetland Act 1669, explicitly exempting them from any \"dissolution of His Majesty's lands\", they are currently considered as being officially part of the United Kingdom.\nWales.\nIncursions in Wales were decisively reversed at the Battle of Buttington in Powys, in 893, when a combined Welsh and Mercian army under \u00c6thelred, Lord of the Mercians, defeated a Danish band.\nWales was not colonised by the Vikings as heavily as eastern England. The Vikings did, however, settle in the south around St. David's, Haverfordwest, and Gower, among other places. Place names such as Skokholm, Skomer, and Swansea remain as evidence of the Norse settlement. The Vikings, however, did not subdue the Welsh mountain kingdoms.\nIceland.\nAccording to the Icelandic sagas, Iceland was discovered by Naddodd, a Viking from the Faroe Islands, after which it was settled by mostly Norwegians fleeing the oppressive rule of Harald Fairhair in \u00a0CE. While harsh, the land allowed for a pastoral farming life familiar to the Norse. According to the saga of Erik the Red, when Erik was exiled from Iceland, he sailed west and pioneered Greenland.\nKvenland.\nKvenland, known as Cwenland, K\u00e6nland, and similar terms in medieval sources, is an ancient name for an area in Scandinavia and Fennoscandia. A contemporary reference to Kvenland is provided in an Old English account written in the 9th century. It used the information provided by the Norwegian adventurer and traveller named Ohthere. Kvenland, in that or close to that spelling, is also known from Nordic sources, primarily Icelandic, but also one that was possibly written in the modern-day area of Norway.\nAll the remaining Nordic sources discussing Kvenland, using that or close to that spelling, date to the 12th and 13th centuries, but some of them\u2014in part at least\u2014are believed to be rewrites of older texts. Other references and possible references to Kvenland by other names or spellings are discussed in the main article of Kvenland.\nEstonia.\nDuring the Viking Age, Estonia was a Finnic area divided between two major cultural regions, a coastal and an inland one, corresponding to the historical cultural and linguistic division between Northern and Southern Estonian. These two areas were further divided between loosely allied regions. The Viking Age in Estonia is considered to be part of the Iron Age period which started around \u00a0CE and ended c. \u00a0CE. Some 16th-century Swedish chronicles attribute the Pillage of Sigtuna in 1187 to Estonian raiders.\nThe society, economy, settlement and culture of the territory of what is in the present-day the country of Estonia is studied mainly through archaeological sources. The era is seen to have been a period of rapid change. The Estonian peasant culture came into existence by the end of the Viking Age. The overall understanding of the Viking Age in Estonia is deemed to be fragmentary and superficial, because of the limited amount of surviving source material. The main sources for understanding the period are remains of the farms and fortresses of the era, cemeteries and a large amount of excavated objects.\nThe landscape of Ancient Estonia featured numerous hillforts, some later hillforts on Saaremaa heavily fortified during the Viking Age and on to the 12th century. There were a number of late prehistoric or medieval harbour sites on the coast of Saaremaa, but none have been found that are large enough to be international trade centres. The Estonian islands also have a number of graves from the Viking Age, both individual and collective, with weapons and jewellery. Weapons found in Estonian Viking Age graves are common to types found throughout Northern Europe and Scandinavia.\nCuronians.\nThe Curonians were known as fierce warriors, excellent sailors and pirates. They were involved in several wars and alliances with Swedish, Danish, and Icelandic Vikings.\nIn c.\u2009750, according to Norna-Gests \u00fe\u00e1ttr saga from c.\u20091157, Sigurd Hring (\"ring\"), a legendary king of Denmark and Sweden, fought against the invading Curonians and Kvens (Kv\u00e6nir) in the southern part of what today is Sweden:\n\"Sigurd Ring (Sigur\u00f0r) was not there, since he had to defend his land, Sweden (Sv\u00ed\u00fej\u00f3\u00f0), since Curonians (K\u00farir) and Kv\u00e6nir were raiding there.\"\nCuronians are mentioned among other participants of the Battle of Br\u00e1vellir.\nGrobin (Grobi\u0146a) was the main centre of the Curonians during the Vendel Age. From the 10th to 13th century, Palanga served as an important economical, political and cultural centre for the Curonians. Chapter 46 of Egils Saga describes one Viking expedition by the Vikings Thorolf and Egill Skallagr\u00edmsson in Courland. According to some opinions, they took part in attacking Sweden's main city Sigtuna in 1187. Curonians established temporary settlements near Riga and in overseas regions including eastern Sweden and the islands of Gotland and Bornholm.\nScandinavian settlements existed along the southeastern Baltic coast in Truso and Kaup (Old Prussia), Palanga (Samogitia, Lithuania) as well as Grobin (Courland, Latvia).\nEastern Europe.\nThe Varangians or \"Varyagi\" were Scandinavians, often Swedes, who migrated eastwards and southwards through what is now Belarus, Russia, and Ukraine, mainly in the 9th and 10th centuries. Engaging in trade, piracy, and mercenary activities, they roamed the river systems and portages of \"Gardariki\", reaching the Caspian Sea and Constantinople.\nContemporary English publications also use the name \"Viking\" for early Varangians in some contexts.\nThe term \"Varangian\" remained in usage in the Byzantine Empire until the 13th century, largely disconnected from its Scandinavian roots by then. Having settled Aldeigja (Ladoga) in the 750s, Scandinavian colonists were probably an element in the early ethnogenesis of the Rus' people, and likely played a role in the formation of the Rus' Khaganate. The Varangians are first mentioned by the \"Primary Chronicle\" as having exacted tribute from the Slavic and Finnic tribes in \u00a0CE. It was the time of rapid expansion of the Vikings in Northern Europe; England began to pay Danegeld in \u00a0CE, and the Curonians of Grobin faced an invasion by the Swedes at about the same date.\nThe text of the Primary Chronicle says that in 860\u2013862, the Finnic and Slavic tribes rebelled against the Varangian Rus', driving them back to Scandinavia, but soon started to conflict with each other. The disorder prompted the tribes to invite back the Varangian Rus' to \"Come and rule and reign over us\" and bring peace to the region. This was a somewhat bilateral relation with the Varangians defending the cities that they ruled. Led by Rurik and his brothers Truvor and Sineus, the Varangians settled around the town of Novgorod (Holmgar\u00f0r).\nIn the 9th century, the Rus' operated the Volga trade route, which connected northern Russia (\"Gardariki\") with the Middle East (\"Serkland\"). As the Volga route declined by the end of the century, the trade route from the Varangians to the Greeks rapidly overtook it in popularity. Apart from Ladoga and Novgorod, Gnezdovo and Gotland were major centres for Varangian trade.\nThe consensus among western scholars, disputed by Russian scholars, who believe them to be a Slavic tribe, is that the Rus' people originated in what is currently coastal eastern Sweden around the 8th century, and that their name has the same origin as that of Roslagen in Sweden. The maritime districts of East G\u00f6tland and Uppland were known in earlier times as Ro\u00feer or Ro\u00fein, and later as Roslagen. According to Thorsten Andersson, the Russian folk name \"Rus\"' ultimately derives from the noun ro\u00feer ('rowing'), a word also used in naval campaigns in the le\u00feunger (Old Norse: \"lei\u00f0angr\") system of organizing a coastal fleet. The Old Swedish place name Ro\u00ferin, in the older iteration \"Ro\u00feer\", contains the word \"ro\u00feer\" and is still used in the form of Roden as a historical name for the coastal areas of Svealand. In modern times the name still exists as Roslagen, the name of the coastal area of Uppland province. According to Stefan Brink, the name \"Rus\"' derives from the words \"ro\" (row) and \"rodd\" (a rowing session).\nThe term \"Varangian\" became more common from the 11th century onwards. In these years, Swedish men left to enlist in the Byzantine Varangian Guard in such numbers that a medieval Swedish law, V\u00e4stg\u00f6talagen, used in the province V\u00e4sterg\u00f6tland, declared that no one could inherit while staying in \"Greece\"\u2014the then Scandinavian term for the Byzantine Empire\u2014to stop the emigration, especially as two other European courts simultaneously also recruited Scandinavians: Kievan Rus' c.\u2009980\u20131060 and London 1018\u20131066 (the \u00deingali\u00f0).\nIn contrast to the notable Scandinavian influence in Normandy and the British Isles, Varangian culture did not survive to a great extent in the East. Instead, the Varangian ruling classes of the two powerful city-states of Novgorod and Kiev were thoroughly Slavicised by the beginning of the 11th century. Some evidence suggests that Old Norse may have been spoken amongst the Rus' later, however. Old East Norse was probably still spoken in Kievan Rus' at Novgorod until the 13th century, according to the \"Nationalencyklopedin\" (Swedish National Encyclopedia).\nCentral Europe.\nViking Age Scandinavian settlements were set up along the southern coast of the Baltic Sea, primarily for trade purposes. Their emergence appears to coincide with the settlement and consolidation of the coastal Slavic tribes in the respective areas. The archaeological record indicates that substantial cultural exchange between Scandinavian and Slavic traditions and technologies occurred. It is known that Slavic and Scandinavian craftsmen had different processes in crafts and productions. In the lagoons and delta of the eastern and southern Baltic there is evidence of Slavic boatbuilding practices somewhat divergent from the Viking tradition, and of a fusion of the two in a shipyard site from the Viking Age on the island of Falster in Denmark.\nSlavic-Scandinavian settlements on the Mecklenburgian coast include the maritime trading center Reric (Gro\u00df Str\u00f6mkendorf) on the eastern coast of Wismar Bay, and the multi-ethnic trade emporium Dierkow (near Rostock). Reric was set up around the year 700, but following later warfare between Obodrites and Danes, the inhabitants, who were subject to the Danish king, were resettled to Haithabu by him. Dierkow apparently belongs to the late 8th to the early 9th century.\nScandinavian settlements on the Pomeranian coast include Wolin (on the isle of Wolin), Ralswiek (on the isle of R\u00fcgen), Altes Lager Menzlin (on the lower Peene river), and Bardy-\u015awielubie near modern Ko\u0142obrzeg. Menzlin was set up in the mid-8th century. Wolin and Ralswiek began to prosper in the course of the 9th century. A merchants' settlement has also been suggested near Arkona, but no archeological evidence supports this theory. Menzlin and Bardy-\u015awielubie were vacated in the late 9th century, Ralswiek survived into the new millennium, but by the time written chronicles reported news of the island of R\u00fcgen in the 12th century, it had lost all its importance. Wolin, thought to be identical with the legendary Vineta and the semilegendary Jomsborg, base of the Jomsvikings, was destroyed in 1043 by Dano-Norwegian king Magnus the Good, according to the \"Heimskringla\". Castle building by the Slavs seems to have reached a high level on the southern Baltic coast in the 8th and 9th centuries, possibly explained by a threat coming from the sea or from the trade emporiums, as Scandinavian arrowheads found in the area indicate advances penetrating as far as the lake chains in the Mecklenburgian and Pomeranian hinterlands.\nWestern Europe.\nFrisia.\nFrisia was a region which spanned from around modern-day Bruges to the islands on the west coast of Jutland\u2014including large parts of the Low Countries. This region was progressively brought under Frankish control (Frisian-Frankish wars), but the Christianization of the local population and cultural assimilation was a slow process. However, several Frisian towns, most notably Dorestad were raided by Vikings. Rorik of Dorestad was a famous Viking raider in Frisia. On Wieringen the Vikings most likely had a base of operations. Viking leaders took an active role in Frisian politics, such as Godfrid, Duke of Frisia, as well as Rorik.\nFrance.\nThe French region of Normandy takes its name from the Viking invaders who were called \"Normanni\", which means 'men of the North'.\nThe first Viking raids began between 790 and 800 along the coasts of western France. They were carried out primarily in the summer, as the Vikings wintered in Scandinavia. Several coastal areas were lost to Francia during the reign of Louis the Pious (814\u2013840). But the Vikings took advantage of the quarrels in the royal family caused after the death of Louis the Pious to settle their first colony in the south-west (Gascony) of the kingdom of Francia, which was more or less abandoned by the Frankish kings after their two defeats at Roncevaux. The incursions in \u00a0CE caused severe damage to Rouen and Jumi\u00e8ges. The Viking attackers sought to capture the treasures stored at monasteries, easy prey given the monks' lack of defensive capacity. In \u00a0CE an expedition up the Seine reached Paris. The presence of Carolingian \"deniers\" of c.\u2009847, found in 1871 among a hoard at Mullaghboden, County Limerick, where coins were neither minted nor normally used in trade, probably represents booty from the raids of 843\u2013846.\nHowever, from 885 to 886, Odo of Paris (Eudes de Paris) succeeded in defending Paris against Viking raiders. His military success allowed him to replace the Carolingians. In 911, a band of Viking warriors attempted to siege Chartres but was defeated by Robert I of France. Robert's victory later paved way for the baptism, and settlement in Normandy, of Viking leader Rollo. Rollo reached an agreement with Charles the Simple to sign the Treaty of Saint-Clair-sur-Epte, under which Charles gave Rouen and the area of present-day Upper Normandy to Rollo, establishing the Duchy of Normandy. In exchange, Rollo pledged vassalage to Charles in 940, agreed to be baptised, and vowed to guard the estuaries of the Seine from further Viking attacks. During Rollo's baptism Robert I of France stood as his godfather. The Duchy of Normandy also annexed further areas in Northern France, expanding the territory which was originally negotiated.\nThe Scandinavian expansion included Danish and Norwegian as well as Swedish elements, all under the leadership of Rollo. By the end of the reign of Richard I of Normandy in 996 (aka Richard the Fearless / Richard sans Peur), all descendants of Vikings became, according to Cambridge Medieval History (Volume 5, Chapter XV), 'not only Christians but in all essentials Frenchmen'. During the Middle Ages, the Normans created one of the most powerful feudal states of Western Europe. The Normans conquered England and southern Italy in 11th century, and played a key role in the Crusades.\nSouthern Europe.\nItaly.\nIn 959, a major long-distance Viking expedition, under the command of two famed Vikings, Bj\u00f6rn Ironside and H\u00e1steinn, set out for Spain from their base on the Loire with the objective of sacking the city of Rome. They tried to land at Galicia and were driven off. Then they sailed down the west coast of the peninsula and burned the mosque at Seville, but were repelled by a large Muslim force there before entering the Mediterranean through the Straits of Gibraltar and burning the mosque at Algeciras, following which they headed south to Nekor on the coast of Morocco, plundered the city and defeated a Muslim force that attempted to stop them.\nAccording to an account by the Norman monk Dudo of Saint-Quentin, a Viking fleet under Bj\u00f6rn Ironside and H\u00e1steinn landed at the Ligurian port of Luni and sacked the city. The Vikings then moved another 60 miles down the Tuscan coast to the mouth of the Arno, sacking Pisa and then, following the river upstream, also the hill-town of Fiesole above Florence.\nMany Anglo-Danish and Varangian mercenaries fought in Southern Italy, including Harald Hardrada and William de Hauteville who conquered parts of Sicily between 1038 and 1040, and Edgar the \u00c6theling who fought in the Norman conquest of southern Italy. Runestones were raised in Sweden in memory of warriors who died in Langbar\u00f0aland (Land of the Lombards), the Old Norse name for southern Italy.\nSeveral Anglo-Danish and Norwegian nobles participated in the Norman conquest of southern Italy, like Edgar the \u00c6theling, who left England in 1086, and Jarl Erling Skakke, who won his nickname \"(\"Skakke\", meaning bent head)\" after a battle against Arabs in Sicily. On the other hand, many Anglo-Danish rebels fleeing William the Conqueror, joined the Byzantines in their struggle against the Robert Guiscard, duke of Apulia, in Southern Italy.\nSpain.\nAfter 842, the Vikings set up a permanent base at the mouth of the river Loire from whence they could strike as far as northern Spain. These Vikings were Hispanicised in all the Christian kingdoms, while they kept their ethnic identity and culture in al-Andalus.\nThe southern coast of the Mediterranean Sea, both sides of the Strait of Gibraltar, and much of the Iberian peninsula were under Muslim rule when Vikings first entered the Mediterranean in the 9th century. The Vikings launched their campaigns from their strongholds in Francia into this realm of Muslim influence; following the coastline of the Kingdom of Asturias they sailed through the Gibraltar strait (known to them as \"N\u01ebrvasund\", the 'Narrow Sound') into what they called \"Mi\u00f0jar\u00f0arhaf\", literally 'Middle of the earth' sea, with the same meaning as the Late Latin \"Mare Mediterr\u0101neum\".\nThe first Viking attacks in al-Andalus in 844 CE greatly affected the region. Medieval texts such as the \"Chronicon albeldense\" and the \"Annales Bertiniani\" tell of a Viking fleet that left Toulouse and made raids in Asturias and Galicia. According to the \"Historia silense\" it had 60 ships. Being repulsed in Galicia (\"Ghil\u012bs\u012ba\"), the fleet sailed southward around the peninsula, raiding coastal towns along the way.\nIn Irene Garc\u00eda Losqui\u00f1o's telling, these Vikings navigated their boats up the river Guadalquivir towards \"I\u0161b\u012bliya\" (Seville) and destroyed \"Qawra\" (Coria del R\u00edo), a small town about 15\u00a0km south of the city. Then they took \"I\u0161b\u012bliya\", from which they controlled the region for several weeks. Their attack on the city forced its inhabitants to flee to \"Qarm\u016bn\u00e2\" (Carmona), a fortified city. The Emirate of Qur\u1e6duba made great exertions to recover \"I\u0161b\u012bliya\", and succeeded with the assistance of \"Qur\u1e6duba\" (C\u00f3rdoba) and the Banu Qasi, who ruled over a semi-autonomous state in the Upper March of the Ebro Valley. Consequently, defensive walls were built at \"I\u0161b\u012bliya\", and the emir Abd al-Ra\u1e25m\u0101n II invested in the construction of a large fleet of ships to protect the entrance of the Guadalquivir and the coast of southern al-Andalus, after which Viking fleets had difficulties battling the Andalus\u012b armada.\nGwyn Jones writes that this Viking raid had occurred on 1 October 844, when most of the Iberian peninsula was controlled by the emirate. His account says a flotilla of about 80 Viking ships, after attacking Asturias, Galicia and Lisbon, had ascended the Guadalquivir to \"I\u0161b\u012bliya\", and besieged it for seven days, inflicting many casualties and taking numerous hostages with the intent to ransom them. Another group of Vikings had gone to \"Q\u0101dis\" (C\u00e1diz) to plunder while those in \"I\u0161b\u012bliya\" waited on \"Qubtil\" (\"Isla Menor\"), an island in the river, for the ransom money to arrive. Meantime, the emir of Qur\u1e6duba, Abd ar-Rahman II, prepared a military contingent to meet them, and on 11 November a pitched battle ensued on the grounds of \"Talayata\" (Tablada). The Vikings held their ground, but the results were catastrophic for the invaders, who suffered a thousand casualties; four hundred were captured and executed, some thirty ships were destroyed. It was not a total victory for the emir's forces, but the Viking survivors had to negotiate a peace to leave the area, surrendering their plunder and the hostages they had taken to sell as slaves, in exchange for food and clothing. According to the Arabist L\u00e9vi-Proven\u00e7al, over time, the few Norse survivors converted to Islam and settled as farmers in the area of \"Qawra\", \"Qarm\u016bn\u00e2\", and \"Moron\", where they engaged in animal husbandry and made dairy products (reputedly the origin of Sevillian cheese). Knutson and Caitlin write that L\u00e9vi-Proven\u00e7al offered no sources for the proposition of conversion to Islam by northern Europeans in al-Andalus and thus it \"remains unsubstantiated\".\nBy the year 859 a large Viking force again invaded al-Andalus, beginning a campaign along the coast of the Iberian Peninsula with smaller groups that assaulted various locations. They attacked I\u0161b\u012bliya (Seville), but were driven off and they returned down the Guadalquivir to the Strait of Gibraltar. The Vikings then sailed round Cape Gata and followed the coastline to the \"K\u016bra\" (cora) of Tudmir, raiding various settlements, as mentioned by the 10th-century historian Ibn Hayy\u0101n. They finally ventured inland, entering the mouth of the river Segura and sailing towards \"\u1e25i\u1e63n \u016ariy\u016bla\" (Orihuela), whose inhabitants had fled. The assailants sacked this important town, and according to the Arab sources, they attacked the fortress and burnt it to the ground. There is only brief mention in the historical record of this Viking army's attacks on south-eastern al-Andalus, including at \"al-Jaz\u012bra al-Khadr\u0101\" (Algeciras), \"\u016ariy\u016bla\", and the \"Juzur al-Baly\u0101r\" (\u062c\u0632\u064f\u0631 \u0627\u0644\u0628\u0644\u064a\u0627\u0631) (Balearic Islands).\nIbn Hayy\u0101n wrote about the Viking campaign of 859\u2013861 in al-Andalus, perhaps relying on the account given by Muslim historian A\u1e25mad al-R\u0101z\u012b, who tells of a Viking fleet of sixty-two ships that sailed up to I\u0161b\u012bliya and occupied \"al-Jaz\u012bra al-Khadr\u0101\". The Muslims seized two of their ships, laden with goods and coins, off the coast of \"Shid\u016bnah\" (Sidonia). The ships were destroyed and their Viking crews killed. The remaining vessels continued up the Atlantic coast and landed near (Pampeluna), called \"Banbal\u016bna\" in Arabic, where they took their emir Ghars\u012ba ibn Wanaqu (Garc\u00eda I\u00f1iquez) prisoner until in 861 he was ransomed for 70,000 dinars.\nAccording to the \"Annales Bertiniani\", Danish Vikings embarked on a long voyage in 859, sailing eastward through the Strait of Gibraltar then up the river Rh\u00f4ne, where they raided monasteries and towns and established a base in the Camargue. Afterwards they raided Nak\u016br in what is now Morocco, kidnapped women of the royal family, and returned them when the emir of C\u00f3rdoba paid their ransoms.\nThe Vikings made several incursions in the years 859, 966 and 971, with intentions more diplomatic than bellicose, although an invasion in 971 was repelled when the Viking fleet was totally annihilated. Vikings attacked Talayata again in 889 at the instigation of Kurayb ibn Khaldun of I\u0161b\u012bliya. In 1015, a Viking fleet entered the river Minho and sacked the episcopal city of Tui Galicia; no new bishop was appointed until 1070.\nPortugal.\nIn 844, a fleet of several dozen Viking longships with square brown sails appeared in the \"Mar da Palha\" (\"Sea of Straw\"), i.e., the mouth of the river Tagus. At the time, the city later called Lisbon was under Muslim rule and known in Arabic as \"al-Us\u0332h\u0332b\u016bna\" or \"al-\u02beI\u0161b\u016bnah\" (\u0627\u0644\u0623\u0634\u0628\u0648\u0646\u0629). After a thirteen-day siege in which they plundered the surrounding countryside, the Vikings conquered \"al-Us\u0332h\u0332b\u016bna\", but eventually retreated in the face of continued resistance by the townspeople led by their governor, Wahb Allah ibn Hazm.\nThe chronicler Ibn Hayy\u0101n, who wrote the most reliable early history of al-Andalus, in his \"Kit\u0101b almuqtabis\", quoted the Muslim historian Ahmad ibn Muhammad al-R\u0101z\u012b:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nNorth America.\nGreenland.\nThe Viking-Age settlements in Greenland were established in the sheltered fjords of the southern and western coast. They settled in three separate areas along roughly of the western coast. While harsh, the microclimates along some fjords allowed for a pastoral lifestyle similar to that of Iceland, until the climate changed for the worse with the Little Ice Age c.\u20091400.\nMainland North America.\nAccording to carbon-dating of excavated remains, between 990 and 1050 CE Vikings established a small settlement on the northern peninsula of present-day Newfoundland, near L'Anse aux Meadows. Conflict with indigenous peoples and lack of support from Greenland brought the Vinland colony to an end within a few years. The archaeological remains are now a UNESCO World Heritage Site.\nTechnology.\nViking naval technology was among the most advanced in all societies of the time; their other technological works were also well-regarded. The Vikings were equipped with the technologically superior longships; for purposes of conducting trade however, another type of ship, the \"knarr\", wider and deeper in draft, were customarily used. The Vikings were competent sailors, adept in land warfare as well as at sea, and they often struck at accessible and poorly defended targets, usually with near impunity. The effectiveness of these tactics earned Vikings a formidable reputation as raiders and pirates.\nThe Vikings used their longships to travel vast distances and attain certain tactical advantages in battle. They could perform highly efficient hit-and-run attacks, in which they quickly approached a target, then left as rapidly as possible before a counter-offensive could be launched. Because of the ships' negligible draft, the Vikings could sail in shallow waters, allowing them to invade far inland along rivers. The ships were agile, and light enough to be carried over land from one river system to another. \"Under sail, the same boats could tackle open water and cross the unexplored wastes of the North Atlantic.\" The ships' speed was also prodigious for the time, estimated at a maximum of . The use of the longships ended when technology changed, and ships began to be constructed using saws instead of axes, resulting in inferior vessels.\nWhile battles at sea were rare, they would occasionally occur when Viking ships attempted to board European merchant vessels in Scandinavian waters. When larger scale battles ensued, Viking crews would rope together all nearby ships and slowly proceed towards the enemy targets. While advancing, the warriors hurled spears, arrows, and other projectiles at the opponents. When the ships were sufficiently close, melee combat would ensue using axes, swords, and spears until the enemy ship could be easily boarded. The roping technique allowed Viking crews to remain strong in numbers and act as a unit, but this uniformity also created problems. A Viking ship in the line could not retreat or pursue hostile ships without breaking the formation and cutting the ropes, which weakened the overall Viking fleet and was a burdensome task to perform in the heat of battle. In general, these tactics enabled Vikings to quickly destroy the meagre opposition posted during raids.\nTogether with an increasing centralisation of government in the Scandinavian countries, the old system of \"leidang\"\u2014a fleet mobilisation system, where every \"skipreide\" (ship community) had to maintain one ship and a crew\u2014was discontinued as a purely military institution, as the duty to build and man a ship soon was converted into a tax. The Norwegian leidang was called under Haakon Haakonson for his 1263 expedition to Scotland during the Scottish\u2013Norwegian War, and the last recorded calling of it was in 1603. However, already by the 11th and 12th centuries, perhaps in response to the longships, European fighting ships were built with raised platforms fore and aft, from which archers could shoot down into the relatively low longships. This led to the defeat of longship navies in most subsequent naval engagements\u2014e.g., with the Hanseatic League.\nThe Vikings were also said to have fine weapons. Generally, Vikings used axes as weapons due to the lessened amount of iron required for their creations; swords were typically seen as a mark of wealth. Spears were also a common weapon among Vikings. Great amounts of time and artistry were expended in the creation of Viking weapons; ornamentation is commonly seen among them. Scandinavian architecture during the Viking Age most often involved wood, due to the abundance of the material. Longhouses, a form of home, often featuring ornamentation, are commonly seen as the defining building of the Viking Age.\nExactly how the Vikings navigated the open seas with such success is unclear. A study published by the Royal Society in its journal, \"Proceedings of the Royal Society A: Mathematical and Physical Sciences\", suggests that the Vikings made use of an optical compass as a navigation aid, using the light-splitting and polarisation-filtering properties of Iceland spar to find the location of the sun when it was not directly visible. While some evidence points to such use of calcite \"sunstones\" to find the sun's location, modern reproductions of Viking \"sky-polarimetric\" navigation have found these sun compasses to be highly inaccurate, and not usable in cloudy or foggy weather.\nThe archaeological find known as the Visby lenses from the Swedish island of Gotland may be components of a telescope. It appears to date from long before the invention of the telescope in the 17th century.\nReligion.\nFor most of the Viking Age, Scandinavian society generally followed Norse paganism. The traditions of this faith, including Valhalla and the \u00c6sir, are sometimes cited as a factor in the creation of Viking warrior culture. However, Scandinavia was eventually Christianised towards the later Viking Age, with early centres of Christianity especially in Denmark.\nTrade.\nSome of the most important trading ports founded by the Norse during the period include both existing and former cities such as Aarhus (Denmark), Ribe (Denmark), Hedeby (Germany), Vineta (Pomerania), Truso (Poland), Bj\u00f8rgvin (Norway), Kaupang (Norway), Skiringssal (Norway), Birka (Sweden), Bordeaux (France), York (England), Dublin (Ireland) and Aldeigjuborg (Russia).\nAs Viking ships carried cargo and trade goods throughout the Baltic area and beyond, their active trading centres grew into thriving towns. One important centre of trade was at Hedeby. Close to the border with the Franks, it was effectively a crossroads between the cultures, until its eventual destruction by the Norwegians in an internecine dispute around 1050. York was the centre of the kingdom of J\u00f3rv\u00edk from 866, and discoveries there (e.g., a silk cap, a counterfeit of a coin from Samarkand, and a cowry shell from the Red Sea or the Persian Gulf) suggest that Scandinavian trade connections in the 10th century reached beyond Byzantium. However, those items could also have been Byzantine imports, and there is no reason to assume that the Varangians travelled significantly beyond Byzantium and the Caspian Sea.\nViking trade routes extended far beyond Scandinavia. As Scandinavian ships penetrated southward on the rivers of Eastern Europe to acquire financial capital, they encountered the nomad peoples of the steppes, leading to the beginning of a trading system that connected Russia and Scandinavia with the northern routes of the Eurasian Silk Road network. During the Middle Ages, the Volga trade route connected Northern Europe and Northwestern Russia with the Caspian Sea, via the Volga River. The international trade routes that enabled the passage of goods by ship from Scandinavia to the east were mentioned in early medieval literature as the \"Austrrvegr\" passing through the eastern Baltic region. Ships headed to the river Volga sailed through the Gulf of Finland, while those destined for Byzantium might take one of several routes through present-day north-eastern Poland or the Baltic lands.\nThe Vikings catered to the demand for slaves in the southern slave markets in the Orthodox Eastern Roman Empire and the Muslim Umayyad Caliphate, both of whom desired slaves of a religion different from their own. The trade route from the Varangians to the Greeks connected Scandinavia, Kievan Rus' and the Eastern Roman Empire. The Rus' were of note as merchants who supplied honey, wax, and slaves to Constantinople. The Varangians served as mercenaries of Russian princes, then of the Swedish princes who founded and ruled Norse kingdoms in Eastern Europe such as at Kiev and Novgorod.\nCulture.\nThe Viking Age saw many of the earliest Scandinavian cultural developments. The traditional Icelandic Sagas, still often read today, are seen as characteristic literary works of Northern Europe. Old English works such as \"Beowulf\", written in the tradition of Germanic heroic legend, show Viking influences; in \"Beowulf\", this influence is seen in the language and setting of the poem. Another example of Viking Age cultural influence is the Old Norse influence in the English language; this influence is primarily a legacy of the various Viking invasions of England.\nWomen in Viking society.\nAccording to archaeologist Liv Helga Dommasnes writing in 1998, although archaeological sources pertinent to the study of women's roles in Scandinavia were most plentiful from the Viking Age compared to other historical eras, not many archaeologists took advantage of the opportunities they represented. She alludes to the fact that the picture commonly presented of Viking society during the Viking Age was of a society of men engaged in their various occupations or positions, with scant mention of the women and children who were also part of it.\nIn her reckoning, given this basic flaw in the modern image of Viking society, how knowledge of the past is organised must be considered. Accordingly, language is an essential part of this organisation of knowledge, and the concepts of modern languages are tools for understanding the realities of the past and for organising that knowledge, even though they are artefacts of our own time and perceived reality. Written sources, although scarce, appear to have been prioritised, even though it is understood that these written sources are biased. Almost all of them originate from other cultures, as literature from Viking societies is sparse. Since it unambiguously transmits meaning in literary terms, it is fairly clear that this meaning is not derived from the ideology of Viking Age people, but rather from that of early northern Christianity. Medieval studies scholar Gro Steinsland argues that the transformation from heathen to Christian religion in Viking society was a \"radical break\" rather than a gradual transition, and Dommasnes says this should have bearing on consideration of the transformation of late Viking Age traditions before they were recorded in 12th- or 13th-century literature. By this reasoning, changing cultural values necessarily greatly affected perceptions of women particularly and of gender roles generally.\nJudith Jesch, professor of Viking Age studies at the University of Nottingham, suggests in her \"Women in the Viking Age\" that \"If historians' emphasis on vikings as warriors made invisible the women in the background, then it is not always clear where the more visible female counterparts of the new urban vikings have come from.\" She says it is impossible to study the Vikings without a conception of the entire historical period they lived in, of the culture that produced them, and of other cultures they influenced. By her lights, not accounting for the doings of half the population would be ludicrous.\nPublished in 1991, \"Women in the Viking Age\" develops Jesch's thesis that the texts of the Icelandic sagas (\"\u00cdslendingas\u00f6gur\") are recordings of mythological narratives preserved in the forms in which they were written by 13th-century antiquaries in Iceland. They cannot be interpreted literally as the \"authentic voice of Vikings\", embodying as they do the preconceptions of those medieval Icelanders. These sagas, formerly believed to have been based on actual historical traditions, are now commonly regarded as imaginative creations. With their origins in oral traditions, there is little confidence in them as historical truth, but they express what they tell more directly than \"the dry bones of archaeology\" or the brief messages on runestones. The modern view of the Viking Age is completely entwined with knowledge imparted by the sagas, and they are the main source of a broadly held belief that women in the Viking Age were independent, assertive, and had agency.\nJesch describes the content of runic inscriptions as connecting people who live in modern times with women of the Viking Age similarly to archaeological evidence, often telling more about the lives of women than the material remains revealed in archaeological excavations. She considers these inscriptions as contemporary evidence originating within the culture instead of from the incomplete or prejudiced viewpoint of the cultural outsider, and sees most of them as narratives in a narrow sense that supply details illuminating the overall picture derived from archaeological sources. They allow actual persons to be identified and reveal information about them such as their family relationships, their names, and perhaps facts concerning their individual lives.\nBirgit Sawyer says her book \"The Viking-age Rune-stones\" aims to show that the corpus of runestones considered as a whole is a fruitful source of knowledge about the religious, political, social, and economic history of Scandinavia in the 10th and 11th centuries. Using data from her database she finds that runestones cast light on settlement patterns, communications, kinship and naming customs, and the evolution of language and poetry. Systematically researching the material leads to her hypothesis that runic inscriptions mirrored inheritance customs entailing not only lands or goods, but also rights, obligations, and rank in society. Although women in Viking society, like men, had tombstones over their graves, runestones were raised primarily to memorialise men, with the lives of few women being commemorated by runestones (Sawyer says only 7 per cent), and half of those were with men. Because there was a much larger per centage of women's graves with rich appointments in the Iron Age, the comparatively smaller number of runestones memorialising women indicates that the trend reflects changes in burial customs and religion only in part. Most of those honoured with runestones were men, and the emphasis was on those who sponsored the monuments. Typical medieval grave monuments name only the deceased, but Viking Age runestones prioritise the sponsors, first and foremost; therefore, they \"are monuments to the \"living\" as much as to the \"dead\"\".\nLanguage.\nThe 12th-century Icelandic \"Gray Goose Laws\" () state that Swedes, Norwegians, Icelanders, and Danes spoke the same language, (\"Danish tongue\"; speakers of Old East Norse would have said \"\"). Another term was (\"northern speech\"). Old Norse has developed into the modern North Germanic languages: Icelandic, Faroese, Norwegian, Danish, Swedish, and other North Germanic varieties of which Norwegian, Danish and Swedish retain considerable mutual intelligibility while Icelandic remains the closest to Old Norse. In present-day Iceland schoolchildren are able to read the 12th-century Icelandic sagas in the original language (in editions with normalised spelling).\nWritten sources of Old Norse from the Viking Age are rare: there are rune stones, but the inscriptions are mostly short. A good deal of the vocabulary, morphology, and phonology of the runic inscriptions (little is known definitely about their syntax) \"can be shown to develop regularly into Viking-Age, medieval and modern Scandinavian reflexes\", says Michael Barnes.\nAccording to David Arter, Old Norse was for a while during the Viking Age a \"lingua franca\" spoken not just in Scandinavia but also in the courts of the Scandinavian rulers in Ireland, Scotland, England, France and Russia. The Norse origin of some words used today is obvious, as in the word \"haar\" referring to the cold sea mist on the east coast of Scotland and England; it derives from the Old Norse \"ha\u00e1rr\".\nOld Norse influence on other languages.\nThe long-term linguistic effects of the Viking settlements in England were threefold: over a thousand Old Norse words eventually became part of Standard English; numerous places in the East and North-east of England have Danish names, and many English personal names are of Scandinavian origin. Scandinavian words that entered the English language included \"landing, score, beck, fellow, take, busting\", and \"steersman\". The vast majority of loan words did not appear in documents until the early 12th century; these included many modern words which used \"sk-\" sounds, such as \"skirt, sky,\" and \"skin\"; other words appearing in written sources at this time included \"again, awkward, birth, cake, dregs, fog, freckles, gasp, law, moss, neck, ransack, root, scowl, sister, seat, sly, smile, want, weak\" and \"window\" from Old Norse meaning \"wind-eye\". Some of the words that came into use are among the most common in English, such as \"to go, to come, to sit, to listen, to eat, both, same, get\" and \"give\". The system of personal pronouns was affected, with \"they, them\" and \"their\" replacing the earlier forms. Old Norse influenced the verb \"to be\"; the replacement of \"sindon\" by \"are\" is almost certainly Scandinavian in origin, as is the third-person-singular ending \"-s\" in the present tense of verbs.\nThere are more than 1,500 Scandinavian place names in England, mainly in Yorkshire and Lincolnshire (within the former boundaries of the \"Danelaw\"): over 600 end in \"-by\", the Scandinavian word for \"village\"\u2014for example \"Grimsby, Naseby\", and \"Whitby\"; many others end in \"-thorpe\" (\"farm\"), \"-thwaite\" (\"clearing\"), and \"-toft\" (\"homestead\").\nAccording to an analysis of names ending in \"-son\", the distribution of family names showing Scandinavian influence is still concentrated in the north and east, corresponding to areas of former Viking settlement. Early medieval records indicate that over 60% of personal names in Yorkshire and North Lincolnshire showed Scandinavian influence.\nGenetics.\nA genetic study published at bioRxiv in July 2019 and in \"Nature\" in September 2020 examined the population genomics of the Viking Age. The remains of four hundred forty-two ancient humans from across Europe and the North Atlantic were surveyed, stretching from the Bronze Age to the early modern period. In terms of Y-DNA composition, Viking individuals were similar to present-day Scandinavians. The most common Y-DNA haplogroup in the study was I1 (95 samples), R1b (84 samples) and R1a, especially (but not exclusively) of the Scandinavian R1a-Z284 subclade (61 samples). It was found that there was a notable foreign gene flow into Scandinavia in the years preceding the Viking Age and during the Viking Age itself. This gene flow entered Denmark and eastern Sweden, from which it spread into the rest of Scandinavia. The Y-DNA of Viking Age samples suggests that this may partly have been descendants of the Germanic tribes from the Migration Period returning to Scandinavia. The study also found that despite close cultural similarities, there were distinct genetic differences between regional populations in the Viking Age. These differences have persisted into modern times. Inland areas were found to be more genetically homogenous than coastal areas and islands such as \u00d6land and Gotland. These islands were probably important trade settlements. Consistent with historical records, the study found evidence of a major influx of Danish Viking ancestry into England, a Swedish influx into Estonia and Finland; and Norwegian influx into Ireland, Iceland and Greenland during the Viking Age. The Vikings were found to have left a profound genetic imprint in the areas they settled, which has persisted into modern times with, e.g., the contemporary population of the United Kingdom having up to 6% Viking DNA. The study also showed that some local people of Scotland were buried as Vikings and may have taken on Viking identities.\nMargaryan et al. 2020 examined the skeletal remains of 42 individuals from the Salme ship burials in Estonia. The skeletal remains belonged to warriors killed in battle who were later buried together with numerous valuable weapons and armour. DNA testing and isotope analysis revealed that the men came from central Sweden.\nMargaryan et al. 2020 examined an elite warrior burial from Bodzia (Poland) dated to 1010\u20131020. The cemetery in Bodzia is exceptional in terms of Scandinavian and Kievian Rus links. The Bodzia man (sample VK157, or burial E864/I) was not a simple warrior from the princely retinue, but he belonged to the princely family himself. His burial is the richest one in the whole cemetery; moreover, strontium analysis of his teeth enamel shows he was not local. It is assumed that he came to Poland with the Prince of Kiev, Sviatopolk the Accursed, and met a violent death in combat. This corresponds to the events of 1018 when Sviatopolk himself disappeared after having retreated from Kiev to Poland. It cannot be excluded that the Bodzia man was Sviatopolk himself, as the genealogy of the Rurikids at this period is extremely dubious, and the dates of birth of many princes of this dynasty may be quite approximative. The Bodzia man carried haplogroup I1-S2077 and had both Scandinavian ancestry and Russian admixture.\nThe genetic data from these areas affirmed conclusions previously drawn from historical and archaeological evidence."}
{"id": "32541", "revid": "9337959", "url": "https://en.wikipedia.org/wiki?curid=32541", "title": "Vitamin K", "text": "Fat-soluble vitamers\nVitamin K is a family of structurally similar, fat-soluble vitamers found in foods and marketed as dietary supplements. The human body requires vitamin\u00a0K for post-synthesis modification of certain proteins that are required for blood coagulation (\"K\"\u00a0from Danish \"koagulation\", for \"coagulation\") and for controlling binding of calcium in bones and other tissues. The complete synthesis involves final modification of these so-called \"Gla\u00a0proteins\" by the enzyme gamma-glutamyl carboxylase that uses vitamin\u00a0K as a cofactor.\nVitamin K is used in the liver as the intermediate VKH2 to deprotonate a glutamate residue and then is reprocessed into vitamin K through a vitamin K oxide intermediate. The presence of uncarboxylated proteins indicates a vitamin\u00a0K deficiency. Carboxylation allows them to bind (chelate) calcium ions, which they cannot do otherwise. Without vitamin\u00a0K, blood coagulation is seriously impaired, and uncontrolled bleeding occurs. Research suggests that deficiency of vitamin\u00a0K may also weaken bones, potentially contributing to osteoporosis, and may promote calcification of arteries and other soft tissues.\nChemically, the vitamin K family comprises 2-methyl-1,4-naphthoquinone (3-) derivatives. Vitamin K includes two natural vitamers: vitamin\u00a0K1 (phylloquinone) and vitamin\u00a0K2 (menaquinone). Vitamin K2, in turn, consists of a number of related chemical subtypes, with differing lengths of carbon side chains made of isoprenoid groups of atoms. The two most studied are menaquinone-4 (MK-4) and menaquinone-7 (MK-7).\nVitamin K1 is made by plants, and is found in highest amounts in green leafy vegetables, being directly involved in photosynthesis. It is active as a vitamin in animals and performs the classic functions of vitamin\u00a0K, including its activity in the production of blood-clotting proteins. Animals may also convert it to vitamin K2, variant MK-4. Bacteria in the gut flora can also convert K1 into K2. All forms of K2 other than MK-4 can only be produced by bacteria, which use these during anaerobic respiration. Vitamin K3 (menadione), a synthetic form of vitamin K, was used to treat vitamin\u00a0K deficiency, but because it interferes with the function of glutathione, it is no longer used in this manner in human nutrition.\nDefinition.\nVitamin K refers to structurally similar, fat-soluble vitamers found in foods and marketed as dietary supplements. \"Vitamin K\" includes several chemical compounds. These are similar in structure in that they share a quinone ring, but differ in the length and degree of saturation of the carbon tail and the number of repeating isoprene units in the side chain (see figures in Chemistry section). Plant-sourced forms are primarily vitamin K1. Animal-sourced foods are primarily vitamin K2. Vitamin K has several roles: an essential nutrient absorbed from food, a product synthesized and marketed as part of a multi-vitamin or as a single-vitamin dietary supplement, and a prescription medication for specific purposes.\nDietary recommendations.\nThe US National Academy of Medicine does not distinguish between K1 and K2\u00a0\u2013 both are counted as vitamin K. When recommendations were last updated in 1998, sufficient information was not available to establish an estimated average requirement or recommended dietary allowance, terms that exist for most vitamins. In instances such as these, the academy defines adequate intakes (AIs) as amounts that appear to be sufficient to maintain good health, with the understanding that at some later date, AIs will be replaced by more exact information. The current AIs for adult women and men ages 19 and older are 90 and 120\u00a0\u03bcg/day, respectively, for pregnancy is 90\u00a0\u03bcg/day, and for lactation is 90\u00a0\u03bcg/day. For infants up to 12 months, the AI is 2.0\u20132.5\u00a0\u03bcg/day; for children ages 1\u201318 years the AI increases with age from 30 to 75\u00a0\u03bcg/day. As for safety, the academy sets tolerable upper intake levels (known as \"upper limits\") for vitamins and minerals when evidence is sufficient. Vitamin K has no upper limit, as human data for adverse effects from high doses are not sufficient.\nIn the European Union, adequate intake is defined the same way as in the US. For women and men over age 18 the adequate intake is set at 70\u00a0\u03bcg/day, for pregnancy 70\u00a0\u03bcg/day, and for lactation 70\u00a0\u03bcg/day. For children ages 1\u201317 years, adequate intake values increase with age from 12 to 65\u00a0\u03bcg/day. Japan set adequate intakes for adult women at 65\u00a0\u03bcg/day and for men at 75\u00a0\u03bcg/day. The European Union and Japan also reviewed safety and concluded\u00a0\u2013 as had the United States\u00a0\u2013 that there was insufficient evidence to set an upper limit for vitamin K.\nFor US food and dietary supplement labeling purposes, the amount in a serving is expressed as a percentage of daily value. For vitamin K labeling purposes, 100% of the daily value was 80\u00a0\u03bcg, but on 27 May 2016 it was revised upwards to 120\u00a0\u03bcg, to bring it into agreement with the highest value for adequate intake. Compliance with the updated labeling regulations was required by 1 January 2020 for manufacturers with US$10\u00a0million or more in annual food sales, and by 1 January 2021 for manufacturers with lower volume food sales. A table of the old and new adult daily values is provided at Reference Daily Intake.\nFortification.\nAccording to the Global Fortification Data Exchange, vitamin K deficiency is so rare that no countries require that foods be fortified. The World Health Organization does not have recommendations on vitamin K fortification.\nSources.\nVitamin K1 is primarily from plants, especially leafy green vegetables. Small amounts are provided by animal-sourced foods. Vitamin K2 is primarily from animal-sourced foods, with poultry and eggs much better sources than beef, pork or fish. One exception to the latter is \"natt\u014d\", which is made from bacteria-fermented soybeans. It is a rich food source of vitamin K2 variant MK-7, made by the bacteria.\nVitamin K2.\nAnimal-sourced foods are a source of vitamin K2. The MK-4 form is from conversion of plant-sourced vitamin K1 in various tissues in the body.\n&lt;templatestyles src=\"Column/styles.css\"/&gt;\n&lt;templatestyles src = \"Column/styles.css\" /&gt;\n&lt;templatestyles src = \"Column/styles.css\" /&gt;\nVitamin K deficiency.\nBecause vitamin K aids mechanisms for blood clotting, its deficiency may lead to reduced blood clotting, and in severe cases, can result in increased bleeding and increased prothrombin time.\nNormal diets are usually not deficient in vitamin K, indicating that deficiency is uncommon in healthy children and adults. An exception may be infants who are at an increased risk of deficiency regardless of the vitamin status of the mother during pregnancy and breast feeding due to poor transfer of the vitamin to the placenta and low amounts of the vitamin in breast milk.\nSecondary deficiencies can occur in people who consume adequate amounts, but have malabsorption conditions, such as cystic fibrosis or chronic pancreatitis, and in people who have liver damage or disease. Secondary vitamin K deficiency can also occur in people who have a prescription for a vitamin K antagonist drug, such as warfarin. A drug associated with increased risk of vitamin K deficiency is cefamandole, although the mechanism is unknown.\nMedical uses.\nTreating vitamin deficiency in newborns.\nVitamin K1 is given as an injection to newborns to prevent vitamin K deficiency bleeding. The blood clotting factors of newborn babies are roughly 30\u201360% that of adult values; this appears to be a consequence of poor transfer of the vitamin across the placenta, and thus low fetal plasma vitamin K. Occurrence of vitamin K deficiency bleeding in the first week of the infant's life is estimated at between 1 in 60 and 1 in 250. \nHuman milk contains 0.85\u20139.2\u00a0\u03bcg/L (median 2.5\u00a0\u03bcg/L) of vitamin K1, while infant formula is formulated in range of 24\u2013175\u00a0\u03bcg/L. Late onset bleeding, with onset 2 to 12 weeks after birth, can be a consequence of exclusive breastfeeding, especially if there was no preventive treatment. Late onset prevalence reported at 35 cases per 100,000 live births in infants who had not received prophylaxis at or shortly after birth. Vitamin K deficiency bleeding occurs more frequently in the Asian population compared to the Caucasian population.\nBleeding in infants due to vitamin K deficiency can be severe, leading to hospitalization, brain damage, and death. Intramuscular injection, typically given shortly after birth, is more effective in preventing vitamin K deficiency bleeding than oral administration, which calls for weekly dosing up to three months of age.\nManaging warfarin therapy.\nWarfarin is an anticoagulant drug. It functions by inhibiting an enzyme that is responsible for recycling vitamin K to a functional state. As a consequence, proteins that should be modified by vitamin K are not, including proteins essential to blood clotting, and are thus not functional. The purpose of the drug is to reduce risk of inappropriate blood clotting, which can have serious, potentially fatal consequences. The proper anticoagulant action of warfarin is a function of vitamin K intake and drug dose. Due to differing absorption of the drug and amounts of vitamin K in the diet, dosing must be monitored and customized for each patient. Some foods are so high in vitamin K1 that medical advice is to avoid those (examples: collard greens, spinach, turnip greens) entirely, and for foods with a modestly high vitamin content, keep consumption as consistent as possible, so that the combination of vitamin intake and warfarin keep the anti-clotting activity in the therapeutic range.\nVitamin K is a treatment for bleeding events caused by overdose of the drug. The vitamin can be administered by mouth, intravenously or subcutaneously. Oral vitamin K is used in situations when a person's International normalized ratio is greater than 10 but there is no active bleeding. The newer anticoagulants apixaban, dabigatran and rivaroxaban are not vitamin K antagonists.\nTreating rodenticide poisoning.\nCoumarin is used in the pharmaceutical industry as a precursor reagent in the synthesis of a number of synthetic anticoagulant pharmaceuticals. One subset, 4-hydroxycoumarins, act as vitamin K antagonists. They block the regeneration and recycling of vitamin K. Some of the 4-hydroxycoumarin anticoagulant class of chemicals are designed to have high potency and long residence times in the body, and these are used specifically as second generation rodenticides (\"rat poison\"). Death occurs after a period of several days to two weeks, usually from internal hemorrhaging. For humans, and for animals that have consumed either the rodenticide or rats poisoned by the rodenticide, treatment is prolonged administration of large amounts of vitamin K. This dosing must sometimes be continued for up to nine months in cases of poisoning by \"superwarfarin\" rodenticides such as brodifacoum. Oral vitamin K1 is preferred over other vitamin K1 routes of administration because it has fewer side effects.\nMethods of assessment.\nAn increase in prothrombin time, a coagulation assay, has been used as an indicator of vitamin K status, but it lacks sufficient sensitivity and specificity for this application.\nSerum phylloquinone is the most commonly used marker of vitamin K status. Concentrations &lt;0.15\u00a0\u03bcg/L are indicative of deficiency. Disadvantages include exclusion of the other vitamin K vitamers and interference from recent dietary intake.\nVitamin K is required for the gamma-carboxylation of specific glutamic acid residues within the Gla domain of the 17 vitamin K\u2013dependent proteins. Thus, a rise in uncarboxylated versions of these proteins is an indirect but sensitive and specific marker for vitamin K deficiency.\nSynthetic forms.\nSome synthetic compounds also have vitamin K activity in humans. One synthetic drug with vitamin K activity still used in developed countries (the UK) is menadiol sodium diphosphate. Unlike natural vitamin K, it is water-soluble and can be absorbed without the help of bile salts.\nSide effects.\nNo known toxicity is associated with high oral doses of the vitamin K1 or vitamin K2 forms of vitamin K, so regulatory agencies from US, Japan and European Union concur that no tolerable upper intake levels needs to be set. However, vitamin K1 has been associated with severe adverse reactions such as bronchospasm and cardiac arrest when given intravenously. The reaction is described as a nonimmune-mediated anaphylactoid reaction, with incidence of 3 per 10,000 treatments. The majority of reactions occurred when polyoxyethylated castor oil was used as the solubilizing agent.\nNon-human uses.\nMenadione, a natural compound sometimes referred to as vitamin K3, is used in the pet food industry because once consumed it is converted to vitamin K2. The US Food and Drug Administration has banned this form from sale as a human dietary supplement because overdoses have been shown to cause allergic reactions, hemolytic anemia, and cytotoxicity in liver cells.\n4-amino-2-methyl-1-naphthol is a synthetic menadione analog often called vitamin K5. It has been used as a medicine for vitamin K deficiency. Research with K5 suggests it may inhibit fungal growth in fruit juices.\nChemistry.\nThe structure of phylloquinone, Vitamin K1, is marked by the presence of a phytyl sidechain. Vitamin K1 has an (E) trans double bond responsible for its biological activity, and two chiral centers on the phytyl sidechain. Vitamin K1 appears as a yellow viscous liquid at room temperature due to its absorption of violet light in the UV-visible spectra obtained by ultraviolet\u2013visible spectroscopy. The structures of menaquinones, vitamin K2, are marked by the polyisoprenyl side chain present in the molecule that can contain four to 13 isoprenyl units. MK-4 is the most common form. The large size of Vitamin K1 gives many different peaks in mass spectroscopy, most of which involve derivatives of the naphthoquinone ring base and the alkyl side chain.\nConversion of vitamin K1 to vitamin K2.\nIn animals, the MK-4 form of vitamin K2 is produced by conversion of vitamin K1 in the testes, pancreas, and arterial walls. While major questions still surround the biochemical pathway for this transformation, the conversion is not dependent on gut bacteria, as it occurs in germ-free rats and in parenterally administered K1 in rats. There is evidence that the conversion proceeds by removal of the phytyl tail of K1 to produce menadione (also referred to as vitamin K3) as an intermediate, which is then prenylated to produce MK-4.\nPhysiology.\nIn animals, vitamin K is involved in the carboxylation of certain glutamate residues in proteins to form gamma-carboxyglutamate (Gla) residues. The modified residues are often (but not always) situated within specific protein domains called Gla domains. Gla residues are usually involved in binding calcium, and are essential for the biological activity of all known Gla proteins.\n17 human proteins with Gla domains have been discovered; they play key roles in the regulation of three physiological processes:\nAbsorption.\nVitamin K is absorbed through the jejunum and ileum in the small intestine. The process requires bile and pancreatic juices. Estimates for absorption are on the order of 80% for vitamin K1 in its free form (as a dietary supplement) but much lower when present in foods. For example, the absorption of vitamin K from kale and spinach\u00a0\u2013 foods identified as having a high vitamin K content\u00a0\u2013 are on the order of 4% to 17% regardless of whether raw or cooked. Less information is available for absorption of vitamin K2 from foods.\nThe intestinal membrane protein Niemann\u2013Pick C1-like 1 (NPC1L1) mediates cholesterol absorption. Animal studies show that it also factors into absorption of vitamins E and K1. The same study predicts potential interaction between SR-BI and CD36 proteins as well. The drug ezetimibe inhibits NPC1L1 causing a reduction in cholesterol absorption in humans, and in animal studies, also reduces vitamin E and vitamin K1 absorption. An expected consequence would be that administration of ezetimibe to people who take warfarin (a vitamin K antagonist) would potentiate the warfarin effect. This has been confirmed in humans.\nBiochemistry.\nFunction in animals.\nVitamin K is distributed differently within animals depending on its specific homologue. Vitamin K1 is mainly present in the liver, heart and pancreas, while MK-4 is better represented in the kidneys, brain and pancreas. The liver also contains longer chain homologues MK-7 to MK-13.\nThe function of vitamin K2 in the animal cell is to add a carboxylic acid functional group to a glutamate (Glu) amino acid residue in a protein, to form a gamma-carboxyglutamate (Gla) residue. This is a somewhat uncommon posttranslational modification of the protein, which is then known as a \"Gla protein\". The presence of two \u2212COOH (carboxylic acid) groups on the same carbon in the gamma-carboxyglutamate residue allows it to chelate calcium ions. The binding of calcium ions in this way very often triggers the function or binding of Gla-protein enzymes, such as the so-called vitamin K\u2013dependent clotting factors discussed below.\nWithin the cell, vitamin K participates in a cyclic process. The vitamin undergoes electron reduction to a reduced form called vitamin K hydroquinone (quinol), catalyzed by the enzyme vitamin K epoxide reductase (VKOR). Another enzyme then oxidizes vitamin K hydroquinone to allow carboxylation of Glu to Gla; this enzyme is called gamma-glutamyl carboxylase or the vitamin K\u2013dependent carboxylase. The carboxylation reaction only proceeds if the carboxylase enzyme is able to oxidize vitamin K hydroquinone to vitamin K epoxide at the same time. The carboxylation and epoxidation reactions are said to be coupled. Vitamin K epoxide is then restored to vitamin K by VKOR. The reduction and subsequent reoxidation of vitamin K coupled with carboxylation of Glu is called the vitamin K cycle. Humans are rarely deficient in vitamin K because, in part, vitamin K2 is continuously recycled in cells.\nWarfarin and other 4-hydroxycoumarins block the action of VKOR. This results in decreased concentrations of vitamin K and vitamin K hydroquinone in tissues, such that the carboxylation reaction catalyzed by the glutamyl carboxylase is inefficient. This results in the production of clotting factors with inadequate Gla. Without Gla on the amino termini of these factors, they no longer bind stably to the blood vessel endothelium and cannot activate clotting to allow formation of a clot during tissue injury. As it is impossible to predict what dose of warfarin will give the desired degree of clotting suppression, warfarin treatment must be carefully monitored to avoid underdose and overdose.\nGamma-carboxyglutamate proteins.\nThe following human Gla-containing proteins (\"Gla proteins\") have been characterized to the level of primary structure: blood coagulation factors II (prothrombin), VII, IX, and X, anticoagulant protein C and protein S, and the factor X-targeting protein Z. The bone Gla protein osteocalcin, the calcification-inhibiting matrix Gla protein (MGP), the cell growth regulating growth arrest specific gene 6 protein, and the four transmembrane Gla proteins, the function of which is at present unknown. The Gla domain is responsible for high-affinity binding of calcium ions (Ca2+) to Gla proteins, which is often necessary for their conformation, and always necessary for their function.\nGla proteins are known to occur in a wide variety of vertebrates: mammals, birds, reptiles, and fish. The venom of a number of Australian snakes acts by activating the human blood-clotting system. In some cases, activation is accomplished by snake Gla-containing enzymes that bind to the endothelium of human blood vessels and catalyze the conversion of procoagulant clotting factors into activated ones, leading to unwanted and potentially deadly clotting.\nAnother interesting class of invertebrate Gla-containing proteins is synthesized by the fish-hunting snail \"Conus geographus\". These snails produce a venom containing hundreds of neuroactive peptides, or conotoxins, which is sufficiently toxic to kill an adult human. Several of the conotoxins contain two to five Gla residues. The Gla-modification signal is different from the vertebrate Gla domain.\nFunction in plants and cyanobacteria.\nVitamin K1 is an important chemical in green plants (including land plants and green algae) and some species of cyanobacteria, where it functions as an electron acceptor transferring one electron in photosystem I during photosynthesis. For this reason, vitamin K1 is found in large quantities in the photosynthetic tissues of plants (green leaves, and dark green leafy vegetables such as romaine lettuce, kale, and spinach), but it occurs in far smaller quantities in other plant tissues.\nDetection of VKORC1 homologues active on the K1-epioxide suggest that K1 may have a non-redox function in these organisms. In plants but not cyanobacteria, knockout of this gene show growth restriction similar to mutants lacking the ability to produce K1.\nFunction in other bacteria.\nMany bacteria, including \"Escherichia coli\" found in the large intestine, can synthesize vitamin K2 (MK-7 up to MK-11), but not vitamin K1. In the vitamin K2 (menaquinone)\u2013synthesizing bacteria, menaquinone transfers two electrons between two different small molecules during oxygen-independent metabolic energy production processes (anaerobic respiration). For example, a small molecule with an excess of electrons (also called an electron donor) such as lactate, formate, or NADH, with the help of an enzyme, passes two electrons to menaquinone. The menaquinone, with the help of another enzyme, then transfers these two electrons to a suitable oxidant, such as fumarate or nitrate (also called an electron acceptor). Adding two electrons to fumarate or nitrate converts the molecule to succinate or nitrite plus water, respectively. \nSome of these reactions generate a cellular energy source, ATP, in a manner similar to eukaryotic cell aerobic respiration, except the final electron acceptor is not molecular oxygen, but fumarate or nitrate. In aerobic respiration, the final oxidant is molecular oxygen, which accepts four electrons from an electron donor such as NADH to be converted to water. \"E. coli\", as facultative anaerobes, can carry out both aerobic respiration and menaquinone-mediated anaerobic respiration.\nHistory.\nIn 1929, Danish scientist Henrik Dam investigated the role of cholesterol by feeding chickens a cholesterol-depleted diet. He initially replicated experiments reported by scientists at the Ontario Agricultural College. McFarlane, Graham and Richardson, working on the chick feed program at OAC, used chloroform to remove all fat from chick chow. They noticed that chicks fed only fat-depleted chow developed hemorrhages and started bleeding from tag sites. Dam found that these defects could not be restored by adding purified cholesterol to the diet. It appeared that\u00a0\u2013 together with the cholesterol\u00a0\u2013 a second compound was extracted from the food, and this compound was called the coagulation vitamin. The new vitamin received the letter K because the initial discoveries were reported in a German journal, in which it was designated as \"Koagulationsvitamin\". Edward Adelbert Doisy of Saint Louis University did much of the research that led to the discovery of the structure and chemical nature of vitamin K. Dam and Doisy shared the 1943 Nobel Prize for medicine for their work on vitamin K1 and K2 published in 1939. Several laboratories synthesized the compound(s) in 1939.\nFor several decades, the vitamin K\u2013deficient chick model was the only method of quantifying vitamin K in various foods: the chicks were made vitamin K\u2013deficient and subsequently fed with known amounts of vitamin K\u2013containing food. The extent to which blood coagulation was restored by the diet was taken as a measure for its vitamin K content. Three groups of physicians independently found this: Biochemical Institute, University of Copenhagen (Dam and Johannes Glavind), University of Iowa Department of Pathology (Emory Warner, Kenneth Brinkhous, and Harry Pratt Smith), and the Mayo Clinic (Hugh Butt, Albert Snell, and Arnold Osterberg).\nThe first published report of successful treatment with vitamin K of life-threatening hemorrhage in a jaundiced patient with prothrombin deficiency was made in 1938 by Smith, Warner, and Brinkhous.\nThe precise function of vitamin K was not discovered until 1974, when prothrombin, a blood coagulation protein, was confirmed to be vitamin K dependent. When the vitamin is present, prothrombin has amino acids near the amino terminus of the protein as \u03b3-carboxyglutamate instead of glutamate, and is able to bind calcium, part of the clotting process.\nResearch.\nOsteoporosis.\nVitamin K is required for the gamma-carboxylation of osteocalcin in bone. The risk of osteoporosis, assessed via bone mineral density and fractures, was not affected for people on warfarin therapy\u00a0\u2013 a vitamin K antagonist. Studies investigating whether vitamin K supplementation reduces risk of bone fractures have shown mixed results.\nCardiovascular health.\nMatrix Gla protein is a vitamin K-dependent protein found in bone, but also in soft tissues such as arteries, where it appears to function as an anti-calcification protein. In animal studies, animals that lack the gene for MGP exhibit calcification of arteries and other soft tissues. In humans, Keutel syndrome is a rare recessive genetic disorder associated with abnormalities in the gene coding for MGP and characterized by abnormal diffuse cartilage calcification. These observations led to a theory that in humans, inadequately carboxylated MGP, due to low dietary intake of the vitamin, could result in increased risk of arterial calcification and coronary heart disease.\nIn meta-analyses of population studies, low intake of vitamin K was associated with inactive MGP, arterial calcification and arterial stiffness. Lower dietary intakes of vitamin K1 and vitamin K2 were also associated with higher coronary heart disease. When blood concentration of circulating vitamin K1 was assessed there was an increased risk in all cause mortality linked to low concentration. In contrast to these population studies, a review of randomized trials using supplementation with either vitamin K1 or vitamin K2 reported no role in mitigating vascular calcification or reducing arterial stiffness. The trials were too short to assess any impact on coronary heart disease or mortality.\nOther.\nPopulation studies suggest that vitamin K status may have roles in inflammation, brain function, endocrine function and an anti-cancer effect. For all of these, there is not sufficient evidence from intervention trials to draw any conclusions. From a review of observational trials, long-term use of vitamin K antagonists as anticoagulation therapy is associated with lower cancer incidence in general. There are conflicting reviews as to whether agonists reduce the risk of prostate cancer.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32543", "revid": "1317080399", "url": "https://en.wikipedia.org/wiki?curid=32543", "title": "Volvox", "text": "Genus of algae\nVolvox is a polyphyletic genus of chlorophyte green algae in the family Volvocaceae. \"Volvox\" species form spherical colonies of up to 50,000 cells, and for this reason they are sometimes called globe algae. First reported by Antonie van Leeuwenhoek in 1700, it is distinctive and easily identified in the microscope. It occurs in a variety of freshwater habitats and has a widespread, cosmopolitan distribution.\n\"Volvox\" diverged from unicellular ancestors approximately https://\u00a0million years ago. Colonies of \"Volvox\" are differentiated into somatic and reproductive cells, and are capable of both sexual and asexual reproduction. Additionally, its close relatives are diverse in body plan and reproductive strategy, ranging from unicellular organisms such as \"Chlamydomonas\" to simple colonial organisms such as \"Pandorina\" and \"Eudorina\". Because of this, \"Volvox\" and its relatives are used as model organisms in the classroom and laboratory to study biological processes such as cellular movement, sexual reproduction, and evolution of multicellularity.\nHistory of knowledge.\nAntonie van Leeuwenhoek first reported observations of \"Volvox\" in 1700. After some drawings and a fuller description by Henry Baker in 1753, Carl Linnaeus named the genus in his 1758 work \"Systema Naturae\"; Linnaeus named the genus \"Volvox\", with two species: \"V. globator\" and \"V. chaos\". The name comes from the Latin term \"volvere\", meaning \"to roll\", and -\"ox\", meaning \"fierce\". \"Volvox chaos\" is an amoeba now known as \"Chaos\" sp.\nLinnaeus' description of \"Volvox globator\" was vague enough that it could apply to any of the currently accepted species of \"Volvox\". The current circumscription of \"V. globator\" is based on Christian Gottfried Ehrenberg's descriptions; however, he mistakenly thought the asexual and sexual colonies of \"Volvox\" were different species, and placed the male colonies in a separate genus, \"Sphaerosira\". This confusion was cleared up by Samuel Friedrich Stein in 1878.\nIn the twentieth century, W. R. Shaw added several species to \"Volvox\", but also split off many species into several genera, namely \"Besseyosphaera\", \"Campbellosphaera\", \"Merrillosphaera\", \"Copelandosphaera\", and \"Janetosphaera\". Although most systematists did not accept these genera, they did accept them as sections within the genus \"Volvox\"; Gilbert Morgan Smith reduced this to four sections in total. More recently, phylogenetic studies revealed that \"Volvox\" was polyphyletic, consisting of several clades which partially aligned with the sections as defined by Smith. Therefore, in 2015 Hisayoshi Nozaki and colleagues emended the sections.\nDescription.\nMature colonies of \"Volvox\" are composed of hundreds, up to tens thousands of cells from two differentiated cell types: numerous flagellate somatic cells and a smaller number of germ cells lacking in soma that are embedded in the surface of a hollow sphere or coenobium containing an extracellular matrix made of glycoproteins.\nAdult somatic cells compose a single layer with the flagella facing outward, forming a hollow spheroid. The cells swim in a coordinated fashion, with distinct anterior and posterior poles. Each cell is enclosed in a gelatinous sheath, which is either distinct or confluent depending on the species. Cells are ovoid, spherical, or star-shaped, each with two equal flagella. The cells have a cup-shaped chloroplast with a single pyrenoid and an anterior eyespot that enables the colony to swim toward light. The cells of colonies in the more basal \"Euvolvox\" clade are interconnected by thin strands of cytoplasm, called protoplasmates. Cell number is specified during development and is dependent on the number of rounds of division.\nReproduction.\n\"Volvox\" is facultatively sexual and can reproduce both sexually and asexually. In the lab, asexual reproduction is most commonly observed; the relative frequencies of sexual and asexual reproduction in the wild is unknown. The switch from asexual to sexual reproduction can be triggered by environmental conditions and by the production of a sex-inducing pheromone. Desiccation-resistant diploid zygotes are produced following successful fertilization.\nAn asexual colony includes both somatic (vegetative) cells, which do not reproduce, and large, non-motile \"gonidia\" in the interior, which produce new colonies asexually through repeated division. In sexual reproduction two types of gametes are produced. \"Volvox\" species can be monoecious or dioecious. Male colonies release numerous sperm packets, while in female colonies single cells enlarge to become oogametes, or eggs.\nKirk and Kirk showed that sex-inducing pheromone production can be triggered in somatic cells by a short heat shock given to asexually growing organisms. The induction of sex by heat shock is mediated by oxidative stress that likely also causes oxidative DNA damage. It has been suggested that switching to the sexual pathway is the key to surviving environmental stresses that include heat and drought. Consistent with this idea, the induction of sex involves a signal transduction pathway that is also induced in \"Volvox\" by wounding.\nColony inversion.\nColony inversion is a special characteristic during development in the order Volvocaceae that results in new colonies having their flagella facing outwards. During this process the asexual reproductive cells (gonidia) first undergo successive cell divisions to form a concave-to-cup-shaped embryo or plakea composed of a single cell layer. Immediately after, the cell layer is inside out compared with the adult configuration\u2014the apical ends of the embryo protoplasts from which flagella are formed, are oriented toward the interior of the plakea. Then the embryo undergoes inversion, during which the cell layer inverts to form a spheroidal daughter colony with the apical ends and flagella of daughter protoplasts positioned outside. This process enables appropriate locomotion of spheroidal colonies of the Volvocaceae. The mechanism of inversion has been investigated extensively at the cellular and molecular levels using the model species, \"Volvox carteri\". Another species \"Volvox globator\" has a similar mode of colony inversion, but begins at the posterior instead of the anterior.\nHabitats.\n\"Volvox\" is a genus of freshwater algae found in ponds and ditches, even in shallow puddles. According to Charles Joseph Chamberlain,\n\"The most favorable place to look for it is in the deeper ponds, lagoons, and ditches which receive an abundance of rain water. It has been said that where you find \"Lemna\", you are likely to find \"Volvox\"; and it is true that such water is favorable, but the shading is unfavorable. Look where you find \"Sphagnum\", \"Vaucheria\", \"Alisma\", \"Equisetum fluviatile\", \"Utricularia\", \"Typha\", and \"Chara\". Dr. Nieuwland reports that \"Pandorina\", \"Eudorina\" and \"Gonium\" are commonly found as constituents of the green scum on wallows in fields where pigs are kept. The flagellate, \"Euglena\", is often associated with these forms.\"\nTaxonomy.\n\"Volvox\" is divided into four sections, which differ from each other by the morphology of their somatic cells, asexual spheroids and zygotes:\nIn practice gelatinous sheaths and delicate cytoplasmic connections are difficult to observe, and are only reliably visible after staining with a dye such as methylene blue.\nSpecies.\n\"Volvox\" contains the following species, according to AlgaeBase. In addition to these accepted species, there a number of dubious \"species\" described under the genus \"Volvox\" which are amoebae, and/or otherwise do not belong to the current definition of \"Volvox\".\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nVolvox\" sect. \"Besseyosphaera\nVolvox\" sect. \"Janetosphaera\nVolvox\" sect. \"Merrillosphaera\nVolvox\" sect. \"Volvox\nUnplaced to section\nAlthough the genus \"Volvox\" is easy to identify, species-level identification of \"Volvox\" can be difficult. Species are morphologically distinguished based on a variety of characters including zygote morphology, developmental characteristics, and sexual characteristics (e.g. dioicy or monoicy).\nEvolution.\n\"Volvox\" is polyphyletic. The section containing the type species, \"Volvox\" sect. \"Volvox\", is sister to the rest of the family. Other members of \"Volvox\" are dispersed within three clades, all nested within \"Eudorina\".\nAncestors of \"Volvox\" transitioned from single cells that initially resembled \"Chlamydomonas\" to form multicellular colonies at least https://\u00a0million years ago, during the Triassic period.\nGenera intermediate in morphology, such as \"Gonium\", contain 16 \"Chlamydomonas\"-like cells and are thought to represent intermediate stages in evolution. An estimate using DNA sequences from about 45 different species of volvocine green algae, including \"Volvox\", suggests that the transition from single cells to undifferentiated multicellular colonies took about 35 million years.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32544", "revid": "746004", "url": "https://en.wikipedia.org/wiki?curid=32544", "title": "Vermouth", "text": "Italian aromatized, fortified wine\nVermouth (, UK also ) is an Italian aromatized, fortified wine, flavored with various botanicals (roots, barks, flowers, seeds, herbs, and spices) and sometimes colored, produced mainly in Italy, France and Spain. The modern versions of the beverage were first produced in the mid- to late 18th century in Turin, Italy. While vermouth was traditionally used for medicinal purposes, it was later served as an ap\u00e9ritif, with fashionable caf\u00e9s in Turin serving it to guests around the clock. In the late 19th century, it became popular with bartenders as a key ingredient for cocktails, such as the martini, the Manhattan, the Rob Roy, and negroni. In addition to being consumed as an ap\u00e9ritif or cocktail ingredient, vermouth is sometimes used as an alternative to white wine in cooking.\nHistorically, the two main types of vermouth are sweet and dry. Responding to demand and competition, vermouth manufacturers have created additional styles, including extra-dry white, sweet white (\"blanc\" or \"bianco\"), red (\"rosso\"), amber, and \"ros\u00e9\".\nVermouth is produced by starting with a base of neutral grape wine or unfermented wine must. Each manufacturer adds additional alcohol and a proprietary mixture of dry ingredients, consisting of aromatic herbs, roots, and barks, to the base wine, base wine plus spirit, or spirit only \u2013 which may be redistilled before adding to the wine or unfermented wine must. After the wine is aromatized and fortified, the vermouth is sweetened with either cane sugar or caramelized sugar, depending on the style.\nItalian, French and Spanish companies produce most of the vermouth consumed throughout the world.\nEtymology and history.\nConsumption of wines fortified with herbs or roots is believed to have begun in China at least as early as the Shang and Western Zhou dynasties (1250\u20131000 BC). The extra ingredients were added to wine to make it a medicinal drink. Medicinal drinks made by the alcoholic fermentation of herbs and sugars are mentioned in early Indian texts on medicine, though this does not imply that European vermouths originated from ancient Chinese and Indian drinks. Recipes for infusing white wine date back to ancient Greece from around 400 BC. A popular ingredient was wormwood, based on the belief that it was effective at treating stomach disorders and intestinal parasites.\nIt was commonly used in Hungary at least since the 15th century with different species of artemisia plants, such as mugwort or wormwood and other spices such as mustard seeds, horseradish, elfdock, etc. Wormwood is called \"\u00fcr\u00f6m\" or \"irem\" in Hungarian, hence the drink is called \"\u00fcrm\u00f6s\" (wormwoodish) or https:// (wormwoodish wine). In the 16th century, it was used with imported spices, too, including cinnamon, clove, etc. It was well known for healing stomach and digestion problems.\nThe name \"vermouth\" is the French pronunciation of the German word \"Wermut\" for wormwood that has been used as an ingredient in the drink over its history. Fortified wines containing wormwood as a principal ingredient existed in Germany around the 16th century. Around this time, an Italian merchant named D'Alessio began producing a similar product in Piedmont as a \"wormwood wine\". D'Alessio's version of the libation contained other botanical ingredients in addition to wormwood. Competing brands developed shortly thereafter in eastern and southeastern France, containing their own proprietary mix of ingredients, including herbs, roots, bark, and spices. By the mid-17th century, the drink was being consumed in England under the name \"vermouth\", which has been the common name for the beverage until the present day.\nOver time, two distinct versions of vermouth became established, one pale, dry, and bitter, and the other red and sweeter. Merchant Antonio Benedetto Carpano introduced the first sweet vermouth in 1786 in Turin, Italy. The drink reportedly quickly became popular with the royal court of Turin. Around 1800 to 1813, the first pale, dry vermouth was produced in France by Joseph Noilly. However, not all pale vermouths produced over time have been dry, and not all red vermouths have been sweet.\nThe use of vermouth as a medicinal liquor waned by the end of the 18th century, but its use as an \"ap\u00e9ritif\" increased in Italy and France. By the late 19th century, vermouth was being used in cocktails. Bartenders found that it was an ideal mixer for many cocktails, including the Manhattan (beginning around 1880) and the precursors to the martini. In addition, the popular Vermouth cocktail, first appearing in 1868, consisted of chilled vermouth and a twist of lemon peel with the occasional addition of small amounts of bitters or maraschino. The popularity of vermouth-heavy cocktails in America, often using twice as much vermouth as gin or whiskey, continued through the 1880s and 1890s. Although the amount of vermouth used in cocktail recipes had somewhat declined, it has recently been experiencing a rise as a favorite among a new breed of bartenders, as a key ingredient in many cocktails. Vermouth gained popularity in the 1950s with help from the martini, which was being marketed by liquor companies. Product placement and celebrity endorsements from personalities such as Ernest Hemingway and Humphrey Bogart helped to increase the martini's profile. However, the most successful advertiser of the martini was the fictional character James Bond.\nThe popularity of vermouth in the United States and Great Britain declined after the mid-20th century, but was still used in those countries in many classic cocktails such as the Manhattan, albeit in smaller amounts. The drink is more popular in other parts of Europe (such as Italy, France, and Spain, where it is often consumed by itself as an \"ap\u00e9ritif\"). It is also very popular in Argentina, where\u2014due to major Italian immigration during the late 19th and early 20th centuries\u2014it is more than a drink; it is a cultural tradition among families, at the table and afterwards. Even such international brands as Cinzano have Argentinian-only products like https://, made with local grapes.\nIn the years since 2013, interest in vermouth has renewed in the US. Artisanal makers have created new brands of vermouth that do not seek to imitate European styles, and vermouth has been a fast-growing category within the wine trade.\nProduction, ingredients, and flavors.\nSeveral wine grapes, including Clairette blanche, Piquepoul, Bianchetta Trevigiana, Catarratto, and Trebbiano, are generally used as the base ingredients for vermouths. From these grapes, a low-alcohol white wine is produced by vermouth manufacturers. The wine may be aged for a short while before the addition of other ingredients. For sweet vermouths, sugar syrup is added before the wine is fortified with extra alcohol. The added alcohol is usually a neutral grape spirit, but may also come from vegetable sources such as sugar beets. The wine is then placed in large barrels or tanks to which the dry ingredients have already been added. The mixture is stirred at intervals until the dry ingredients have been absorbed and the drink is ready for bottling. Red vermouths can derive their color from botanicals, added red wine, or sometimes from caramel color. Rose-colored vermouth uses red and white wines as its base. Most vermouths are bottled at between 16% and 18% ABV, as compared with the 9\u201314% ABV of most unfortified wines.\nSpice ingredients often used in vermouths include cloves, cinnamon, quinine, citrus peel, cardamom, marjoram, chamomile, coriander, juniper, hyssop, ginger, and labdanum. The prohibition of wormwood as a drink ingredient in the early 20th century in some countries sharply reduced its use in vermouth, but small amounts of the herb are still sometimes included in artisan products. Vermouth brand recipes vary, with most manufacturers marketing their own unique flavor and version of the beverage. Vermouth manufacturers keep their recipes for the drink secret.\nSweet vermouths usually contain 10\u201315% sugar. The sugar content in dry vermouths generally does not exceed 4%. Dry vermouths usually are lighter in body than sweet vermouths.\nIn addition to pale and red vermouths, there exist golden and ros\u00e9 versions, but these are not as internationally popular. The region of Chamb\u00e9ry in France has received an \"appellation d'origine contr\u00f4l\u00e9e \"for its vermouths, which is where the \"blanc\" style originated and also includes a strawberry-flavored version called Chamb\u00e9ryzette. Lillet, St. Raphael, and Dubonnet are fortified wines similar to vermouth, but are usually considered separate products. The two predominant styles of vermouth \u2013 the red, Italian rosso and the dry, white vermouth from France \u2013 were created and commercialized more than two centuries ago.\nThe term \"Italian vermouth\" is often used to refer to red-colored, mildly bitter, and slightly sweet vermouths. These types of vermouths have also been called \"rosso\". The label \"French vermouth\" generally refers to pale, dry vermouths that are more bitter than sweet vermouths. The extra bitterness is often obtained by using nutmeg or bitter orange peel in the drink recipe. \"Blanc\" or \"Bianco\" is a name given to a type of pale, sweeter vermouth.\nAccording to Stuart Walton and Brian Glover, vermouth \"is as far removed from the natural produce of the vine as it is possible for a fortified wine to get.\"\nModern use.\nBeverage.\nVermouth is a common cocktail ingredient, particularly in martinis and Manhattans. When vermouth is drunk by itself it is normally consumed as an ap\u00e9ritif. Vermouth is used as an ingredient in many different cocktails, as people found it beneficial for lowering the alcohol content of cocktails with strong spirits as their base, for providing a pleasant herbal flavor and aroma, and for accentuating the flavors in the base liquor. As previously stated, vermouth is an ingredient in the martini, one of the most popular and well-known cocktails. At first, martinis used sweet vermouth. Around 1904, however, drier French vermouths began to be used in the cocktail. The term \"dry martini\" originally meant using drier vermouth as a mixer, not using less vermouth, as in the modern definition.\nSharon Tyler Herbst's book, \"The Ultimate A-To-Z Bar Guide\", lists 112 cocktails using dry vermouth and 82 containing sweet vermouth. Cocktails using either dry or sweet vermouth or both include the Americano, Bronx, Gibson, Malecon, Manhattan, Negroni, Rob Roy, and Rose. Variations of cocktail recipes using equal portions of dry and sweet vermouths are called \"perfect\", as in a \"Perfect Manhattan\".\nCooking.\nWhile vermouth can be used as a substitute for white wine in food recipes, because it is more flavorful than wine, it may be overwhelming when used in certain dishes. The herbs in dry vermouth make it an attractive ingredient in sauces for fish dishes or as a marinade for other meats, including pork and chicken.\nStoring.\nBecause vermouth is fortified, an opened bottle will not sour as quickly as white wine. Opened vermouth, however, will gradually deteriorate over time. Gourmets recommend that opened bottles of vermouth be consumed within one to three months and should be kept refrigerated to slow oxidation.\nNotable brands.\nThe Carpano family originated several notable brands of vermouth, including Punt e Mes, a deep red vermouth with sweet and bitter flavors, and the Antica Formula brand, a bitter, fuller-flavored version of vermouth. Distillerie Fratelli Branca of Milan bought 50% of the Giuseppe B. Carpano company in 1982 and acquired the company outright in 2001. Gancia, Drap\u00f2 Vermouth, Delmistero, 9diDANTE and Cocchi are other Italian producers.\nThe Cinzano family began production in 1757 in Turin. Their Bianco product is sweet, pale vermouth.\nDolin vermouth from Chamb\u00e9ry, France, has been made since 1815. Their product lineup carries both a traditional dry, two different kinds of sweet (red and blanco), and a strawberry (chamberyzette). Dolin is recognized as creating the blanc style.\nMartini &amp; Rossi, the top-selling international brand of vermouth, started in 1863 in Turin and produces both dry and sweet vermouths, but is mostly known for its Rosso. Cinzano and Martini &amp; Rossi also produce ros\u00e9 vermouths, which are mainly distributed in Italy and France.\nNoilly Prat, based in southern France, is primarily known for its dry, pale vermouths, but also produces a sweeter version. The company was founded by Joseph Noilly in 1813.\nEsquimalt Vermouth &amp; Ap\u00e9ritifs, on Vancouver Island, Canada, is the first producer outside Europe to win two gold medals at London's 2023 World Vermouth Awards. In the blind tasting competition, they were judged best for both Dry Vermouth, and also for Semi-Sweet Vermouth (for its Rosso). A year after the company began production, Esquimalt Vermouth &amp; Ap\u00e9ritifs won a gold medal at the 2020 San Francisco World Spirits Competition. The following year, 2021, they were awarded three double gold medals for their dry vermouth, the semisweet Rosso, and their Kina-Rouge.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32545", "revid": "282003", "url": "https://en.wikipedia.org/wiki?curid=32545", "title": "Vinland", "text": "Area of coastal Canada explored by Norse Vikings\nVinland, Vineland, or Winland () was an area of coastal North America explored by Vikings. Leif Erikson landed there around 1000\u00a0AD, nearly five centuries before the voyages of Christopher Columbus and John Cabot. The name appears in the Vinland Sagas and describes a land beyond Greenland, Helluland, and Markland. Much of the geographical content of the sagas corresponds to present-day knowledge of transatlantic travel and North America.\nIn 1960, archaeological evidence of the only known Norse site in North America, L'Anse aux Meadows, was found on the northern tip of the island of Newfoundland. Before the discovery of archaeological evidence, Vinland was known only from the sagas and medieval historiography. The 1960 discovery further proved the pre-Columbian Norse exploration of mainland North America. Archaeologists found butternuts at L'Anse aux Meadows, which indicates voyages into the Gulf of Saint Lawrence as far as northeastern New Brunswick. L'Anse aux Meadows has been hypothesized to be the camp \"Straumfj\u00f6r\u00f0\" mentioned in the \"Saga of Erik the Red\".\nName.\nVinland was the name given to part of North America by the Icelandic Norseman Leif Eriksson, about 1000\u00a0AD. It was also spelled \"Winland\", as early as Adam of Bremen's \"Descriptio insularum Aquilonis\" (\"Description of the Northern Islands\", ch. 39, in the 4th part of Gesta Hammaburgensis ecclesiae pontificum), written circa 1075. Adam's main source regarding \"Winland\" appears to have been king Svend Estridson, who had knowledge of the \"northern islands\". The etymology of the Old Norse root \"vin-\" is disputed; while it has usually been assumed to be \"wine\", some scholars give credence to the homophone \"vin\", meaning \"pasture\" or \"meadow\".\nAdam of Bremen implies that the name contains Old Norse \"v\u00edn\" (cognate with Latin \"vinum\") \"wine\" (rendered as Old Saxon or Old High German \"w\u012bn\"): \"Moreover, he has also reported one island discovered by many in that ocean, which is called \"Winland\", for the reason that grapevines grow there by themselves, producing the best wine.\" This etymology is retained in the 13th-century \"Gr\u0153nlendinga saga\", which provides a circumstantial account of the discovery of Vinland and its being named from the \"v\u00ednber\", i.e. \"wineberry\", a term for grapes. According to Birgitta Wallace, theories that the sagas' \"v\u00ednber\" refers to other berries such as cranberries or currants are insupportable. Kirsten Seaver also rejects the \"Pastureland\" interpretation and has written \"The notion that the first syllable was vin with a short vowel (meaning ~ 'green meadow') has been so thoroughly discarded that we are left with the incontrovertible, long-vowelled vin or 'wine'.\"\nThere is also a long-standing Scandinavian tradition of fermenting berries into wine. The discovery of butternuts at the site implies that the Norse explored Vinland further to the south, at least as far as St. Lawrence River and parts of New Brunswick, the northern limit for both butternut and wild grapes (\"Vitis riparia\").\nAnother proposal for the name's etymology, was introduced by Sven S\u00f6derberg in 1898 (first published in 1910). This suggestion involves interpreting the Old Norse name not as v\u00edn-land with the first vowel spoken as /i\u02d0/, but as vin-land, spoken as /\u026a/; a short vowel. Old Norse \"v\u00edn\" (from Proto-Norse \"winju\") has a meaning of \"meadow, pasture\".\nThis interpretation of Vinland as \"pasture-land\" rather than \"wine-land\" was accepted by Valter Jansson in his classic 1951 dissertation on the vin-names of Scandinavia, by way of which it entered popular knowledge in the later 20th century. It was rejected by Einar Haugen (1977), who argued that the \"vin\" element had changed its meaning from \"pasture\" to \"farm\" long before the Old Norse period. Names in \"vin\" were given in the Proto Norse period, and they are absent from places colonized in the Viking Age. Erik Wahlgren rejected the \"Pastureland\" interpretation, writing \"The simple fact is that Soderberg's thesis is quite untenable.\"\nThere is a runestone which may have contained a record of the Old Norse name slightly predating Adam of Bremen's \"Winland\". The \"H\u00f8nen Runestone\" was discovered in Norderhov, Norway, shortly before 1817, but it was subsequently lost. Its assessment depends on a sketch made by antiquarian L. D. Kl\u00fcwer (1823), now also lost but in turn copied by Wilhelm Frimann Koren Christie (1838). The Younger Futhark inscription was dated to c.\u00a01010\u20131050. The stone had been erected in memory of a Norwegian, possibly a descendant of Sigurd Syr. Sophus Bugge (1902) read part of the inscription as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u16a2\u16c1\u16bf\u16eb(\u16da)\u16c6(\u16d0)\u16c1\u16ad\u16eb\u16c1\u16cc\u16c6\n\"uin (l)a(t)i\u0105 isa\"\n\"V\u00ednlandi \u00e1 \u00edsa\"\n\"from Vinland over ice\".\nThis is highly uncertain; the same sequence is read by Magnus Olsen (1951) as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\n\u16a2\u16c1\u16bf\u16eb\u16b4\u16c6(\u16da\u16d0)\u16ad\u16eb\u16c1\u16cc\u16c6\n\"uin ka(lt)\u0105 isa\"\n\"vindkalda \u00e1 \u00edsa\"\n\"over the wind-cold ice\".\nThe Vinland sagas.\nThe main sources of information about the Norse voyages to Vinland are two Icelandic sagas: the \"Saga of Erik the Red\" and the \"Saga of the Greenlanders\". These stories were preserved by oral tradition until they were written down some 250 years after the events they describe. The existence of two versions of the story shows some of the challenges of using traditional sources for history, because they share a large number of story elements but use them in different ways. A possible example is the reference to two different men named Bjarni who are blown off course. A brief summary of the plots of the two sagas, given at the end of this article, shows other examples.\nThe sagas report that a considerable number of Vikings were in parties that visited Vinland. Thorfinn Karlsefni's crew consisted of 140 or 160 people according to the Saga of Erik the Red, 60 according to the Saga of the Greenlanders. Still according to the latter, Leif Ericson led a company of 35, Thorvald Eiriksson a company of 30, and Helgi and Finnbogi had 30 crew members.\nAccording to the Saga of Erik the Red, \u00deorfinnr \"Karlsefni\" \u00de\u00f3r\u00f0arson and a company of 160 men, going south from Greenland traversed an open stretch of sea, found Helluland, another stretch of sea, Markland, another stretch of sea, the headland of \"Kjalarnes\", the Wonderstrands, Straumfj\u00f6r\u00f0 and at last a place called \"H\u00f3p\", a bountiful place where no snow fell during winter. However, after several years away from Greenland, they chose to turn back to their homes when they realized that they would otherwise face an indefinite conflict with the natives.\nThis saga references the place-name Vinland in four ways. First, it is identified as the land found by Leif Erikson. Karlsefni and his men subsequently find \"v\u00edn-ber\" near the Wonderstrands. Later, the tale locates Vinland to the south of Markland, with the headland of \"Kjalarnes\" at its northern extreme. However, it also mentions that while at Straumfjord, some of the explorers wished to go in search for Vinland west of \"Kjalarnes\".\n\"Saga of the Greenlanders\".\nIn \"Gr\u00e6nlendinga saga\" or the 'Saga of the Greenlanders', Bjarni Herj\u00f3lfsson accidentally discovered the new land when traveling from Norway to visit his father, in the second year of Erik the Red's Greenland settlement (about 986\u00a0CE). When he managed to reach Greenland, making land at Herjolfsness, the site of his father's farm, he remained there for the rest of his father's life and didn't return to Norway until about 1000\u00a0CE. There, he told his overlord (the Earl, also named Erik) about the new land and was criticized for his long delay in reporting this. On his return to Greenland he retold the story and inspired Leif Eriksson to organize an expedition, which retraced in reverse the route Bjarni had followed, past a land of flat stones (Helluland) and a land of forests (Markland). After having sailed another two days across open sea, the expedition found a headland with an island just off the shore, with a nearby pool, accessible to ships at high tide, in an area where the sea was shallow with sandbanks. Here the explorers landed and established a base which can plausibly be matched to L'Anse aux Meadows; except that the winter was described as mild, not freezing. One day an old family servant, Tyrker, went missing and was found mumbling to himself. He eventually explained that he found grapes/currants. In the spring, Leif returned to Greenland with a shipload of timber, towing a boatload of grapes/currants. On the way home, he spotted another ship aground on the rocks, rescued the crew and later salvaged the cargo. A second expedition, one ship of about 40 men led by Leif's brother Thorvald, sets out in the autumn after Leif's return and stayed over three winters at the new base (\"Leifsb\u00fa\u00f0ir\" (-budir), meaning Leif's temporary shelters), exploring the west coast of the new land during the first summer, and the east coast during the second, running aground and losing the ship's keel on a headland they christen Keel Point (\"Kjalarnes\"). Further south, at a point where Thorvald wanted to establish a settlement, the Greenlanders encountered some of the local inhabitants (\"Skr\u00e6lingjar\") and killed them, following which they were attacked by a large force in hide boats, and Thorvald died from an arrow-wound. After the exploration party returned to base, the Greenlanders decided to return home the following spring.\nThorstein, Leif's brother, married Gudrid, widow of the captain rescued by Leif, then led a third expedition to bring home Thorvald's body, but drifted off course and spent the whole summer sailing the Atlantic. Spending the winter as a guest at a farm on Greenland with Gudrid, Thorstein died of disease, reviving just long enough to make a prophecy about her future as a Christian. The next winter, Gudrid married a visiting Icelander named Thorfinn Karlsefni, who agreed to undertake a major expedition to Vinland, taking livestock. On arrival, they soon found a beached whale which sustained them until spring. In the summer, they were visited by some of the local inhabitants who were scared by the Greenlanders' bull, but happy to trade goods for milk and other products. In autumn, Gudrid gave birth to a son, Snorri. Shortly after this, one of the local people tried to take a weapon and was killed. The explorers were then attacked in force, but managed to survive with only minor casualties by retreating to a well-chosen defensive position, a short distance from their base. One of the local people picked up an iron axe, tried it, and threw it away.\nThe explorers returned to Greenland in summer with a cargo of grapes/currants and hides. Shortly thereafter, a ship captained by two Icelanders arrived in Greenland, and Freydis, daughter of Eric the Red, persuaded them to join her in an expedition to Vinland. When they arrived at Vinland, the brothers stored their belongings in Leif Eriksson's houses, which angered Freydis and she banished them. She then visited them during the winter and asked for their ship, claiming that she wanted to go back to Greenland, which the brothers happily agreed to. Freydis went back and told her husband the exact opposite, which led to the killing, at Freydis' order, of all the Icelanders, including five women, as they lay sleeping. In the spring, the Greenlanders returned home with a good cargo, but Leif found out the truth about the Icelanders. That was the last Vinland expedition recorded in the saga.\n\"Saga of Erik the Red\".\nIn the other version of the story, \"Eir\u00edks saga rau\u00f0a\" or the \"Saga of Erik the Red\", Leif Ericsson accidentally discovered the new land when traveling from Norway back to Greenland after a visit to his overlord, King Olaf Tryggvason, who commissioned him to spread Christianity in the colony. Returning to Greenland with samples of grapes/currants, wheat and timber, he rescued the survivors from a wrecked ship and gained a reputation for good luck; his religious mission was a swift success. The next spring, Thorstein, Leif's brother, led an expedition to the new land, but drifted off course and spent the whole summer sailing the Atlantic. On his return, he met and married Gudrid, one of the survivors from a ship which made land at Herjolfsnes after a difficult voyage from Iceland. Spending the winter as a guest at a farm on Greenland with Gudrid, Thorstein died of disease, reviving just long enough to make a prophecy about her future as a far-traveling Christian. The next winter, Gudrid married a visiting Icelander named Thorfinn Karlsefni, who, with his business partner Snorri Thorbrandsson, agreed to undertake a major expedition to the new land, taking livestock with them. Also contributing ships for this expedition were another pair of visiting Icelanders, Bjarni Grimolfsson and Thorhall Gamlason, and Leif's brother and sister Thorvald and Freydis, with her husband Thorvard. Sailing past landscapes of flat stones (Helluland) and forests (Markland) they rounded a cape where they saw the keel of a boat (Kjalarnes), then continued past some extraordinarily long beaches (\"Fur\u00f0ustrandir\") before they landed and sent out two runners to explore inland. After three days, the pair returned with samples of grapes/currants and wheat. After they sailed a little farther, the expedition landed at an inlet next to an area of strong currents (Straumfj\u00f6r\u00f0), with an island just off shore (Straumsey), and they made camp. The winter months were harsh, and food was in short supply. One day an old family servant, Thorhall the Hunter (who had not become Christian), went missing and was found mumbling to himself. Shortly afterwards, a beached whale was found, which Thorhall claimed had been provided in answer to his praise of the pagan gods. The explorers found that eating it made them ill, so they prayed to the Christian God, and shortly afterwards the weather improved.\nWhen spring arrived, Thorhall Gamlason, the Icelander, wanted to sail north around Kjalarnes to seek Vinland, while Thorfinn Karlsefni preferred to sail southward down the east coast. Thorhall took only nine men, and his vessel is swept out into the ocean by contrary winds; he and his crew never returned. Thorfinn and Snorri, with Freydis (plus possibly Bjarni), sailed down the east coast with 40 men or more and established a settlement on the shore of a seaside lake, protected by barrier islands and connected to the open ocean by a river which was navigable by ships only at high tide. The settlement was known as \"H\u00f3p\", and the land abounded with grapes/currants and wheat. The teller of this saga was uncertain whether the explorers remained here over the next winter (said to be very mild) or for only a few weeks of summer. One morning they saw nine hide boats; the local people (\"Skr\u00e6lings\") examined the Norse ships and departed in peace. Later a much larger flotilla of boats arrived, and trade commenced (Karlsefni forbade the sale of weapons). One day, the local traders were frightened by the sudden arrival of the Greenlanders' bull, and they stayed away for three weeks. They then attacked in force, but the explorers managed to survive with only minor casualties, by retreating inland to a defensive position, a short distance from their camp. Pregnancy slowed Freydis down, so she picked up the sword of a fallen companion and brandished it against her bare breast, scaring the attackers into withdrawal. One of the local people picked up an iron axe, tried using it, but threw it away. The explorers subsequently abandoned the southern camp and sailed back to Straumsfjord, killing five natives they encountered on the way, lying asleep in hide sacks.\nKarlsefni, accompanied by Thorvald Eriksson and others, sailed around Kjalarnes and then south, keeping land on their left side, hoping to find Thorhall. After sailing for a long time, while moored on the south side of a west-flowing river, they were shot at by a one-footed man, and Thorvald died from an arrow-wound. Once they reached Markland, the men encountered five natives, of whom they kidnapped two boys, baptizing them and teaching them their own language. The explorers returned to Straumsfjord, but disagreements during the following winter led to the abandonment of the venture. On the way home, the ship of Bjarni the Icelander was swept into the Sea of Worms (Ma\u00f0kasj\u00e1r in Sk\u00e1lholtsb\u00f3k, Ma\u00f0ksj\u00e1r in Hauksb\u00f3k) by contrary winds. The marine worms destroyed the hull, and only those who escaped in the ship's worm-proofed boat survived. This was the last Vinland expedition recorded in the saga.\nMedieval geographers.\nAdam of Bremen.\nThe oldest commonly acknowledged surviving written record of Vinland appears in \"Descriptio insularum Aquilonis\" by Adam of Bremen written in about 1075. Adam was told about \"islands\" discovered by Norse sailors in the Atlantic by the Danish king Svend Estridsen.\nGalvano Fiamma.\nThe nearby Norse outpost of Markland was mentioned in the writings of Galvano Fiamma in his book, \"Cronica universalis\". He is believed to be the first Southern European to write about the New World.\"\"\nSigurd Stefansson.\nThe earliest map of Vinland was drawn by Sigurd Stefansson, a schoolmaster at Skalholt, Iceland, around 1570, which placed Vinland somewhere that can be Chesapeake Bay, St. Lawrence, or Cape Cod Bay.\nIn the early 14th century, a geography encyclopedia called \"Geographica Universalis\" was compiled at Malmesbury Abbey in England, which was in turn used as a source for one of the most widely circulated medieval English educational works, \"Polychronicon\" by Ranulf Higden, a few years later. Both these works, with Adam of Bremen as a possible source, were confused about the location of what they called \"Wintland\"\u2014the Malmesbury monk had it on the ocean east of Norway, while Higden put it west of Denmark but failed to explain the distance. Copies of \"Polychronicon\" commonly included a world map on which \"Wintland\" was marked in the Atlantic Ocean near Iceland, but again much closer to the Scandinavian mainland than in reality. The name was explained in both texts as referring to the savage inhabitants' ability to tie the wind up in knotted cords, which they sold to sailors who could then undo a knot whenever they needed a good wind. Neither mentioned grapes, and the Malmesbury work specifically states that little grows there but grass and trees, which reflects the saga descriptions of the area round the main Norse expedition base.\nMore geographically correct were Icelandic texts from about the same time, which presented a clear picture of the northern countries as experienced by Norse explorers: north of Iceland a vast, barren plain (which we now know to be the Polar ice-cap) extended from \"Biarmeland\" (northern Russia) east of the White Sea, to Greenland, then further west and south were, in succession, Helluland, Markland and Vinland. The Icelanders had no knowledge of how far south Vinland extended, and they speculated that it might reach as far as Africa.\nThe \"Historia Norwegiae\" (History of Norway), compiled around 15th\u201316th century, does not refer directly to Vinland and tries to reconcile information from Greenland with mainland European sources; in this text Greenland's territory extends so that it is \"almost touching the African islands, where the waters of ocean flood in\".\nLater Norse voyages.\nIcelandic chronicles record another attempt to visit Vinland from Greenland, over a century after the saga voyages. In 1121, Icelandic bishop Eric Gnupsson, who had been based on Greenland since 1112, \"went to seek Vinland\". Nothing more is reported of him, and three years later another bishop, Arnald, was sent to Greenland. No written records, other than inscribed stones, have survived in Greenland, so the next reference to a voyage also comes from Icelandic chronicles. In 1347, a ship arrived in Iceland, after being blown off course on its way home from Markland to Greenland with a load of timber. The implication is that the Greenlanders had continued to use Markland as a source of timber over several centuries.\nControversy over the location of Vinland.\nThe definition of Vinland is somewhat elusive. According to a 1969 article by Douglas McManis in the \"Annals of the Association of American Geographers\", &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The study of the early Norse voyages to North America is a field of research characterized by controversy and conflicting, often irreconcilable, opinions and conclusions. These circumstances result from the fact that details of the voyages exist only in two Icelandic sagas which contradict each other on basic issues and internally are vague and contain nonhistorical passages.\nThis leads him to conclude that \"there is not a Vinland, there are many Vinlands\". According to a 1970 reply by Matti Kaups in the same journal, &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Certainly there is a symbolic Vinland as described and located in the \"Groenlandinga saga\"; what seems to be a variant of this Vinland is narrated in \"Erik the Red's Saga\". There are, on the other hand, numerous more recent derivative Vinlands, each of which actually is but a suppositional spatial entity. (...) (e.g. Rafn's Vinland, Steensby's Vinland, Ingstad's Vinland, and so forth).\nIn geographical terms, Vinland is sometimes used to refer generally to all areas in Atlantic Canada. In the sagas, Vinland is sometimes indicated to not include the territories of Helluland and Markland, which appear to also be located in North America beyond Greenland. Moreover, some sagas establish vague links between Vinland and an island or territory that some sources refer to as \"Hv\u00edtramannaland\".\nAnother possibility is to interpret the name of Vinland as not referring to one defined location, but to every location where \"v\u00ednber\" could be found, i.e. to understand it as a common noun, vinland, rather than a toponym, Vinland. The Old Norse and Icelandic languages were, and are, very flexible in forming compound words.\nSixteenth century Icelanders realized that the \"New World\" which European geographers were calling \"America\" was the land described in their Vinland Sagas. The Sk\u00e1lholt Map, drawn in 1570 or 1590 but surviving only through later copies, shows \"Promontorium Winlandiae\" (\"promontory/cape/foreland of Vinland\") as a narrow cape with its northern tip at the same latitude as southern Ireland. (The scales of degrees in the map margins are inaccurate.) This effective identification of northern Newfoundland with the northern tip of Vinland was taken up by later Scandinavian scholars such as bishop Hans Resen.\nAlthough it is generally agreed, based on the saga descriptions, that Helluland includes Baffin Island, and Markland represents at least the southern part of the modern Labrador, there has been considerable controversy over the location of the actual Norse landings and settlement. Comparison of the sagas, as summarized below, shows that they give similar descriptions and names to different places. One of the few reasonably consistent pieces of information is that exploration voyages from the main base sailed down both the east and west coasts of the land; this was one of the factors which helped archaeologists locate the site at L'Anse aux Meadows, at the tip of Newfoundland's long northern peninsula.\nErik Wahlgren examines the question in his book \"The Vikings and America\", and points out clearly that L'Anse aux Meadows cannot be the location of V\u00ednland, as the location described in the sagas has both salmon in the rivers and the 'v\u00ednber' (meaning specifically 'grape', that according to Wahlgren the explorers were familiar with and would have thus recognized), growing freely.\nCharting the overlap of the limits of wild vine and wild salmon habitats, as well as nautical clues from the sagas, Wahlgren indicates a location in Maine or New Brunswick. He hazards a guess that Leif Erikson camped at Passamaquoddy Bay and Thorvald Erikson was killed in the Bay of Fundy.\nOn the other hand, Sir Wilfred Grenfell, a medical missionary and scholar living in Newfoundland and Labrador in the early 20th century wrote of the issue of the location of Vinland that,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;No reason has ever been shown why the Vikings would want to fare any farther than our beautifully wooded bays, with their endless berries, salmon, furs, and game, except that most people think of the east coast of Labrador as all barren, forbidding wastes, and forget that no part of it lies north of England and Scotland.\u2014\u200a\nOther clues appear to place the main settlement farther south, such as the mention of a winter with no snow and the reports in both sagas of grapes being found. A very specific indication in the Greenlanders' Saga of the latitude of the base has also been subject to misinterpretation. This passage states that in the shortest days of midwinter, the sun was still above the horizon at \"dagmal\" and \"eykt\", two specific times in the Norse day. Carl Christian Rafn, in the first detailed study of the Norse exploration of the New World, \"Antiquitates Americanae\" (1837), interpreted these times as equivalent to 7:30\u00a0a.m. and 4:30\u00a0p.m., which would put the base a long way south of Newfoundland. According to the 1880 Sephton translation of the saga, Rafn and other Danish scholars placed \"Kjalarnes\" at Cape Cod, Straumfj\u00f6r\u00f0 at Buzzards Bay, Massachusetts, and Straumsey at Martha's Vineyard.\nAn Icelandic law text gives a very specific explanation of \"eykt\", with reference to Norse navigation techniques. The eight major divisions of the compass were subdivided into three hours each, to make a total of 24, and \"eykt\" was the end of the second hour of the south-west division. In modern terms this would be 3:30\u00a0p.m. \"Dagmal\", the \"day-meal,\" is specifically distinguished from the earlier \"rismal\" (breakfast), and would thus be about 8:30\u00a0a.m.\nA 2012 article by J\u00f3nas Kristj\u00e1nsson in the scientific journal \"Acta Archeologica\", which assumes that the headland of \"Kjalarnes\" referred to in the Saga of Erik the Red is at L'Anse aux Meadows, suggests that Straumfj\u00f6r\u00f0 refers to Sop's Arm, Newfoundland, as no other fjord in Newfoundland was found to have an island at its mouth.\nL'Anse aux Meadows.\nNewfoundland marine insurance agent and historian William A. Munn (1864\u20131939), after studying literary sources in Europe, suggested in his 1914 book \"Location of Helluland, Markland &amp; Vinland from the Icelandic Sagas\" that the Vinland explorers \"went ashore at Lancey [\"sic\"] Meadows, as it is called to-day\". In 1960, the remains of a small Norse encampment were discovered by Helge and Anne Stine Ingstad at that exact spot, L'Anse aux Meadows in northern Newfoundland, and excavated during the 1960s and 1970s. It is most likely this was the main settlement of the sagas, a \"gateway\" for the Norse Greenlanders to the rich lands farther south. Many wooden objects were found at L'Anse aux Meadows, and radiocarbon dating confirms the site's occupation as being confined to a short period around 1000 CE. In addition, small pieces of jasper, known to have been used in the Norse world as fire-strikers, were found in and around the different buildings. When these were analyzed and compared with samples from jasper sources around the North Atlantic area, it was found that two buildings contained only Icelandic jasper pieces, while another contained some from Greenland; a single piece from the east coast of Newfoundland was found. These finds appear to confirm the saga claim that some Vinland exploration ships came from Iceland and that they ventured down the east coast of the new land. In 2021, wood from the site was shown to have been cut in 1021, using metal blades, which the local Indigenous people did not have.\nAlthough it is now generally accepted that L'Anse aux Meadows was the main base of the Norse explorers, the southernmost limit of Norse exploration remains a subject of intense speculation. Gustav Storm (1887) and Joseph Fischer (1902) both suggested Cape Breton; Samuel Eliot Morison (1971) the southern part of Newfoundland; Erik Wahlgren (1986) Miramichi Bay in New Brunswick; and Icelandic climate specialist Pall Bergthorsson (1997) proposed New York City. The insistence in all the main historical sources that grapes were found in Vinland suggests that the explorers ventured at least to the south side of the St. Lawrence River, as Jacques Cartier did 500 years later, finding both wild vines and nut trees. Three butternuts were found at L'Anse aux Meadows, another species which grows only as far north as the St. Lawrence.\nThe vinvi\u00f0ir (wine wood) the Norse were cutting down in the sagas may refer to the vines of \"Vitis riparia\", a species of wild grape that grows on trees. As the Norse were searching for lumber, a material that was needed in Greenland, they found trees covered with \"Vitis riparia\" south of L'Anse aux Meadows and called them vinvi\u00f0ir.\nL'Anse Aux Meadows was a small and short-lived encampment; perhaps it was primarily used for timber-gathering forays and boat repair, rather than permanent settlements like those in Greenland.\nVinland in Colonial Discourses.\nSverrir Jakobsson notes that there are no contemporary written records of journeys to Vinland - pointing out that the earliest mentions of the location occurred in 1070 and 1120. Jakobsson points out that there are contradictions between Eiriks saga rautha and the Graenlandinga saga and that their textual history suggests they were composed independently of each other and he is highly critical of treating the sagas as a cohesive unit. He also suggests that attempts at \"harmonizing the evidence of the sagas with the modern belief that journeys were directed towards North America\" has led to gaps in the scholarship surrounding the sagas. He notes references to Vinland in Icelandic manuscripts from around 1300 indicated Vinland as being in Africa. He treats this as being the influence of the medieval Catholic epistemology which only supported the existence of three continents. Based on this textual interpretation Jakobsson considers that the Norse travels to Vinland failed to discover America as they did not bring about the paradigmatic shift in Christian geography of later voyages to the New World.\nAccording to Christopher Crocker, the search for Vinland is appropriately contextualized as a form of colonial construction of history. He suggests that centering Norse expeditions to North America play into the Vanishing Indian trope and allow for the continued centering of European historical narratives farther back into the history of North America, at the expense of Indigenous people. He points out that the claims of Beothuck extinction which the Vinland narrative supported were used by British settlers to deny Mi'kmaq land claims. Anette Kolodny suggests that attempts to situate Vinland in New England \"owed much to the fact that, by 1850 and the decades beyond, New England was in decline, and this effort reflected the attempt to recapture glory for the region.\nLife in Vinland.\nThe main resources that the people of Vinland relied on were wheat, berries, wine and fish. However, the wheat in the Vinlandic context is sandwort and not traditional wheat, and the grapes mentioned are native North American grapes, because the European grape (\"Vitis vinifera\") and wheat (\"Triticum\" sp.) existing in the New World before the Viking arrival in the tenth century is highly unlikely. Both the sagas reference a river and a lake that had an abundance of fish. The sagas specifically mention salmon, and note how the salmon that was encountered was larger than any salmon they had seen before. \nBefore arriving in Vinland, the Norsemen imported their lumber from Norway while in Greenland and had occasional birch trees for firewood. Therefore, the timber they acquired in North America increased their supply of wood.\nOther possible Norse finds.\nAn authentic late-11th-century Norwegian silver penny, with a hole for stringing on a necklace, was found in Maine. Its discovery by an amateur archaeologist in 1957 is controversial; questions have been raised whether it was planted as a hoax. Numerous artifacts attributed to the Norse have been found in Canada, particularly on Baffin Island and in northern Labrador.\nOther claimed Norse artifacts in the area south of the St. Lawrence include a number of stones inscribed with runic letters. The Kensington Runestone was found in Minnesota, but is generally considered a hoax. The authenticity of the Spirit Pond runestones, recovered in Phippsburg, Maine, is also questioned. Other examples are the Heavener Runestone, the Shawnee Runestone, and the V\u00e9rendrye Runestone. The age and origin of these stones is debated, and so far none has been firmly dated or associated with clear evidence of a medieval Norse presence. In general, script in the runic alphabet does not in itself guarantee a Viking age or medieval connection, as it has been suggested that Dalecarlian runes have been used until the 20th century.\nPoint Rosee, on the southwest coast of Newfoundland, was thought to be the location of a possible Norse settlement. The site was discovered through satellite imagery in 2014 by Sarah Parcak. In their November 8, 2017, report, which was submitted to the Provincial Archaeology Office in St. John's, Newfoundland, Sarah Parcak and Gregory \"Greg\" Mumford wrote that they \"found no evidence whatsoever for either a Norse presence or human activity at Point Rosee prior to the historic period\" and that \"None of the team members, including the Norse specialists, deemed this area as having any traces of human activity.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32546", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=32546", "title": "Vietnamese cuisine", "text": "Culinary traditions of Vietnam\nVietnamese cuisine encompasses the foods and beverages originated from Vietnam. Meals feature a combination of five fundamental tastes (): sweet, salty, bitter, sour, and spicy. The distinctive nature of each dish reflects one or more elements (such as nutrients and colors), which are also based around a five-pronged philosophy. Vietnamese recipes use ingredients like lemongrass, ginger, mint, Vietnamese mint, brown sugar, long coriander, Saigon cinnamon, bird's eye chili, soy sauce, lime, and Thai basil leaves. Traditional Vietnamese cooking has often been characterised as using fresh ingredients, not using much dairy or oil, having interesting textures, and making use of herbs and vegetables. The cuisine is also low in sugar and is almost always naturally gluten-free, as many of the dishes are rice-based instead of wheat-based, made with rice noodles, \"b\u00e1nh tr\u00e1ng\" rice paper wrappers and rice flour.\nHistorical influences.\nBesides indigenous Vietnamese influences, which are the major core of Vietnamese food, owing to historical contact with China and centuries of sinicization, some Vietnamese dishes share similarities with Chinese cuisine. In culinary traditions, the Chinese introduced to Vietnam several dishes, including \"v\u1eb1n th\u1eafn\"/\"ho\u00e0nh th\u00e1nh\" (wonton), \"x\u00e1 x\u00edu\" (\"char siu\"), \"h\u00e1 c\u1ea3o\" (\"har gow\"), \"h\u1ee7 ti\u1ebfu\" (\"shahe fen\"), \"m\u00ec\" (wheat noodles), \"b\u00f2 b\u00eda\" (\"popiah\"), \"b\u00e1nh qu\u1ea9y\" (\"youtiao\"), mooncake and \"b\u00e1nh p\u00eda\" (Suzhou-style mooncake), \"b\u00e1nh t\u1ed5\" (\"nian gao\"), \"s\u1ee7i d\u00ecn\" (\"tang yuan\"), \"b\u00e1nh b\u00f2\", \"b\u00e1nh bao\" (\"baozi\"), \"c\u01a1m chi\u00ean D\u01b0\u01a1ng Ch\u00e2u\" (Yangzhou fried rice), and \"m\u00ec x\u00e0o\" (chow mein). The Vietnamese adopted these foods and added their own styles and flavors to the foods. Ethnic minorities in the mountainous region near the China\u2013Vietnam border also adopted some foods from China. Ethnic T\u00e0y and N\u00f9ng in L\u1ea1ng S\u01a1n province adopted \"th\u1ecbt l\u1ee3n quay\" (roasted pork) and \"kh\u00e2u nh\u1ee5c\" (braised pork belly) from China. Some New World vegetables, such as chili peppers and corn (maize), also made their way to Vietnam from the Ming dynasty.\nThe French introduced baguettes to Vietnam, which were combined with Vietnamese stuffing to become a popular fast food in Vietnam called \"b\u00e1nh m\u00ec th\u1ecbt\", known overseas as \"Vietnamese baguettes\". \"B\u00e1nh m\u00ec\" is just the bread, whereas \"th\u1ecbt\" implies meat or stuffing. The French also introduced Vietnam to onions, potatoes, broccoli, tomatoes, cauliflower, lettuce, tarragon, carrot, artichoke, asparagus, and coffee.\nThe western-introduced ingredients often have a name derived from a similar native Vietnamese ingredient, then adding the word \"t\u00e2y\" (meaning \"western\"). Onions are called \"h\u00e0nh t\u00e2y\" (literally \"western shallots\"), asparagus as \"m\u0103ng t\u00e2y\" (western bamboo shoots) and potatoes are called \"khoai t\u00e2y\" (western yam) in Vietnamese, which reflects their origin before arriving in Vietnam. French-influenced dishes are numerous and not limited to: \"sa l\u00e1t\" (salad), \"p\u00e2t\u00e9\", \"pat\u00ea s\u00f4\" (a Brittany pasty called \"p\u00e2t\u00e9 chaud\"), \"b\u00e1nh s\u1eebng tr\u00e2u/b\u00e1nh s\u1eebng b\u00f2\" (croissant), \"b\u00e1nh flan\", y\"a ua\" (yogurt), \"r\u00f4ti\" (rotisserie), \"b\u01a1\" (butter), \"v\u1ecbt n\u1ea5u cam\" (duck \u00e0 l'orange), \"\u1ed1p l\u1ebft\" (omelette), \"\u1ed1p la\" (\"\u0153ufs au plat\"), \"ph\u00e1 x\u00ed\" (farcies), \"b\u00edt t\u1ebft\" (beefsteak), \"s\u1ed1t vang\" (cooking with wine), \"d\u0103m b\u00f4ng\" (\"jambon\"), and \"x\u00fac x\u00edch\" (\"saucisse\"). Owing to influences from French colonial rule, the French Indochinese countries of Laos, Vietnam, and Cambodia have several shared dishes and beverages, including baguettes and coffee. The French also introduced the use of dairy products in Vietnamese-French fusion dishes.\nVietnamese cuisine also has influences from Champa, Malaysia and Cambodia. The use of coconut milk and various central dishes such as \"b\u00e1nh kh\u1ecdt\" were influenced by Cham cuisine. Spices including curries were also introduced to Vietnam by Malay and Indian traders. Though not common in the north, \"c\u00e0 ri\" is a quite popular dish in central and southern Vietnam. The most common form is chicken curry, and to a lesser extent, goat curry. Chicken curry is an indispensable dish in many social gathering events, such as weddings, funerals, graduations, and the yearly death anniversary of a loved one. Similar to Cambodia, curry in Vietnam is eaten either with bread, steamed rice, or round rice noodles (rice vermicelli). \"M\u1eafm b\u1ed3 h\u00f3c\" or prahok, adopted from ethnic Khmer in Southern Vietnam, is used as a central ingredient of a Vietnamese rice noodle soup called \"b\u00fan n\u01b0\u1edbc l\u00e8o\" which originated with ethnic Khmers in Vietnam and is not found in Cambodia.\nOwing to contact with previous communist countries from Eastern Europe, the Vietnamese adopted dishes such as stuffed cabbage soup, \"sa l\u00e1t Nga\" (Olivier salad) and \"bia Ti\u1ec7p\" (Czech beer).\nRegional cuisines.\nThe mainstream culinary traditions in all three regions of Vietnam share some fundamental features:\nWhile sharing some key features, Vietnamese culinary tradition differs from region to region.\nIn northern Vietnam, a colder climate limits the production and availability of spices. As a result, the foods there are often less spicy than those in other regions. Black pepper is used in place of chilies as the most popular ingredient to produce spicy flavors. In general, northern Vietnamese cuisine is not bold in any particular taste\u2014sweet, salty, spicy, bitter, or sour. Most northern Vietnamese foods feature light and balanced flavors that result from subtle combinations of many different flavoring ingredients. The use of meats such as pork, beef, and chicken were relatively limited in the past. Freshwater fish, crustaceans, and mollusks, such as prawns and shrimp, squid, crabs, clams, and mussels, are widely used. Many notable dishes of northern Vietnam are crab-centered (e.g., \"b\u00fan ri\u00eau\"). Being the cradle of Vietnamese civilization, northern Vietnam produces many signature dishes of Vietnam, such as \"b\u00fan ri\u00eau\" and \"b\u00e1nh cu\u1ed1n\", which were carried to central and southern Vietnam through Vietnamese migration. Other famous Vietnamese dishes that originated from the north, particularly from Hanoi, include \"b\u00fan ch\u1ea3\" (rice noodles with grilled marinated pork), \"ph\u1edf g\u00e0\" (chicken soup with rice noodles), \"ch\u1ea3 c\u00e1 L\u00e3 V\u1ecdng\" (rice noodles with grilled fish).\nThe abundance of spices produced by Central Vietnam's mountainous terrain makes this region's cuisine notable for its spicy food, which sets it apart from the two other regions of Vietnam, where foods are mostly not spicy. Once the capital of the last dynasty of Vietnam, Hu\u1ebf's culinary tradition features highly decorative and colorful food, reflecting the influence of ancient Vietnamese royal cuisine. The region's cuisine is also notable for its sophisticated meals consisting of many complex dishes served in small portions. Chili peppers and shrimp sauces are among the frequently used ingredients. Some Vietnamese signature dishes produced in central Vietnam are \"b\u00fan b\u00f2 Hu\u1ebf\" and \"b\u00e1nh kho\u00e1i\".\nThe warm weather and fertile soil of southern Vietnam create an ideal condition for growing a wide variety of fruits, vegetables, and livestock. As a result, foods in southern Vietnam are often vibrant and flavorful, with liberal uses of garlic, shallots, and fresh herbs. Sugar is added to food more than in the other regions. The preference for sweetness in southern Vietnam can also be seen through the widespread use of coconut milk in southern Vietnamese cuisine. Vast shorelines make seafood a natural staple for people in this region. Some signature seafood dishes from southern Vietnam include \"b\u00e1nh kh\u1ecdt\" and \"b\u00fan m\u1eafm\".\nMekong Delta cuisine relies heavily on fresh products which are abundant in the new land with heavy use of palm sugar, fermented fish, seafood and wild herbs and flowers. The history of the region being a newly settled area reflects on its cuisine; \"\u1ea9m th\u1ef1c kh\u1ea9n hoang\" or \"settlers' cuisine\" means dishes are prepared fresh from wild and newly-caught ingredients. The cuisine is also influenced by Khmer, Cham and Chinese settlers.\nThe cuisine of the Northern and Central Highlands regions is influenced by tribal traditions, with items such as \"th\u1eafng c\u1ed1\" (Hmong horse stew), dried meats, \"c\u01a1m lam\" and \"r\u01b0\u1ee3u c\u1ea7n\".\nRelation to Vietnamese philosophy.\nVietnamese cuisine always has five elements which are known for its balance in each of these features.\nFive-element correspondence.\nVietnamese cuisine is influenced by the Asian principle of five elements and \"mah\u0101bh\u016bta\".\nYin-yang balance.\nThe principle of yin and yang () is applied in composing a meal in a way that provides a balance that is beneficial for the body. While contrasting texture and flavors are important, the principle primarily concerns the \"heating\" and \"cooling\" properties of ingredients. Certain dishes are served in their respective seasons to provide contrasts in temperature and spiciness of the food and environment. Some examples are:\nFood in relation to lifestyle.\nVietnamese cuisine is reflective of the Vietnamese lifestyle, from the preparation to how the food is served. Going through long phases of war and political conflict, as well as cultural shifts, many Vietnamese people have been living in poverty. Therefore, the ingredients for Vietnamese food are often very inexpensive. Nonetheless, the way they are cooked together to create a yin\u2013yang balance makes the food simple in appearance but rich in flavor.\nBecause of economic conditions, maximizing the use of ingredients to save money has become a tradition in Vietnamese cooking. In earlier decades, and even nowadays in rural areas, every part of a cow is used, from the muscle meat to the intestines. The higher quality cuts from farmed animals (cows, pigs) would be cooked in stir-fry dishes and soups, while the secondary cuts would be used in blood sausages or for preparing broth. The same goes for vegetables like scallions: the leafy part is diced into small bits which are used to add flavor to the food while the crunchy stalk and roots are replanted.\n (fish sauce) is the most commonly used condiment in Vietnamese cooking. It is made from fermented raw fish and is served with most of the Vietnamese dishes. A traditional southern Vietnamese meal usually includes (plain white rice), (catfish in a clay pot), (sour soup with snakehead fish), and it would be incomplete without fish sauce served as a condiment. Cooking and then serving fish in the same clay pot has been proven to be an ancient tradition.\nThe foods from each region in Vietnam carry their distinctive and unique characteristics that reflect the geographical and living conditions of the people there. The traditional southern Vietnamese meal is made up of fresh ingredients that the fertile Mekong Delta could provide, such as , and a wide range of tropical fruit like mangosteen, mango, and dragon fruit. The southern-style diet includes vegetables, fish and tropical fruits as the main ingredients.\nCentral Vietnam is the region in which food is prepared with the strongest, boldest flavors. The coastline around the central Vietnam area is known for its salt and fish sauce industries; these two condiments are central to their daily diets.\nNorthern Vietnamese cuisine has a strong Chinese influence, and its most famous dish is . While plain rice is a staple in the southern Vietnamese diet, the north has a preference for noodles. Owing to the notable differences in climate and lifestyles throughout the three main regions of Vietnam, the foods vary. Northern Vietnamese cooking is the least bold and spicy in flavor compared to the foods from central and southern Vietnam.\nTypical Vietnamese family meal.\nDaily meals of Vietnamese people are quite different from Vietnamese foods served in restaurants or stalls. A typical meal for the average Vietnamese family would include:\nExcept individual bowls of rice, all dishes are communal and are to be shared in the middle of the table. It is also customary for younger people to ask/wait for the elders to eat first and for the woman who sits directly next to the rice pot to serve rice for other people. People should invite the others to enjoy the meal (somewhat similar to saying \"Enjoy your meal\"), in order from the elders to younger people. They also pick up food for each other as an action of care.\nFeast.\nA feast (, ) is a significant event for families or villages, usually up to twelve people for each table. A feast is prepared for weddings, funerals, and festivals, including the longevity-wishing ceremony. In a feast, ordinary foods are not served, but boiled rice is still used.\nA Vietnamese feast has two courses: the main course (, or salty dish) and dessert (, or sweet dish). All dishes, except for individual bowls of rice, are enjoyed collectively. All main course dishes are served simultaneously rather than one after another. The major dish of the main course is placed in the center of the tables, usually big pots of soup or a hot pot.\nA basic feast () consists of ten dishes: five in bowls (): (dried and fried pork skin), (cellophane noodles), (bamboo shoot), (meatball), or (bird or chicken stew dishes) and five on plates (): (Vietnamese sausage), , or (boiled chicken or duck), (Vietnamese salad) and (stir-fried dishes). This kind of feast is traditional and is organized only in northern Vietnam. Other variations are found in central and southern Vietnam.\nFour dishes essential in the feast of T\u1ebft are (spring rolls), (in northern Vietnam, refers to a spring roll called or ; in southern Vietnam, mainly refer to , fermented pork rolls), (stew dishes) and (noodle soup). At this time, the feast for offering ancestors includes sticky rice, boiled chicken, Vietnamese rice wine, and other foods preferred by ancestors. Gifts are given before guests leave the feast.\nRoyal cuisine.\nIn the Nguy\u1ec5n dynasty, the 50 best chefs from all over the kingdom were selected for the board to serve the king. There were three meals per day\u201412 dishes at breakfast and 66 dishes for lunch and dinner (including 50 main dishes and 16 sweets). An essential dish was bird's nest soup (). Other dishes included shark fin (), abalone (), deer's tendon (), bears' hands (), and rhinoceros' skin (). Water had to come from the well, the pagoda, the well (near the base of \"\" mountain), or from the source of the River. Rice was the variety from the imperial rice field. clay pots for cooking rice were used only a single time before disposal. No one was allowed to have any contact with the cooked dishes except for the cooks and board members. The dishes were first served to eunuchs, then the king's wives, after which they were offered to the king. The king enjoyed meals () alone in a comfortable, music-filled space.\nCultural importance.\nSalt is used as the connection between the worlds of the living and the dead. \"B\u00e1nh phu th\u00ea\" is used to remind new couples of perfection and harmony at their weddings. Food is often placed at the ancestral altar as an offering to the dead on special occasions (such as Lunar New Year). Cooking and eating play an extremely important role in Vietnamese culture.\nProverbs.\nThe word \"\u0103n\" (to eat) is included in a great number of proverbs and has a large range of semantic extensions.\nMany Vietnamese idioms reflect the sex-is-eating mapping:\nInternational popularity.\nOutside of Vietnam, Vietnamese cuisine is widely available in countries with strong Vietnamese immigrant communities, such as Australia, the United States, Canada, and France. Vietnamese cuisine is also popular in Japan, Korea, the Czech Republic, Slovakia, Germany, United Kingdom, Poland, Philippines and Russia, and in areas with dense Asian populations.\nTelevision shows featuring Vietnamese food have increased in popularity. Luke Nguyen from Australia currently features a television show, \"Luke Nguyen's Vietnam\", dedicated on showcasing and instructing how to cook Vietnamese dishes.\nOn \"The Great Food Truck Race\", a Vietnamese sandwich truck called Nom Nom Truck received the most money in the first five episodes.\nAnthony Bourdain wrote: You don't have to go looking for great food in Vietnam. Great food finds you. It's everywhere. In restaurants, cafes, little storefronts, in the streets; carried in makeshift portable kitchens on yokes borne by women vendors. Your cyclo-driver will invite you to his home; your guide will want to bring you to his favorite place. Strangers will rush up and offer you a taste of something they're proud of and think you should know about. It's a country filled with proud cooks\u2014and passionate eaters.\nGordon Ramsay visited Vietnam in his reality show \"Gordon's Great Escape\" \u2013 S02E02 (2011) and fell in love with the taste of the culinary here. Especially the dish called H\u1ee7 ti\u1ebfu M\u00ec by Mrs. D\u00ec Hai, prepped and served on a small boat in C\u00e1i R\u0103ng floating market, C\u1ea7n Th\u01a1. He even praised it as \"The greatest dish I have ever eaten\" when he brought it up as one of the dishes for the elimination challenge for the top 5 finalists of \"American MasterChef\" season 4 episode 21.\nIn 2024, CNN included ph\u1edf in its list of the \"20 Best Soups in the World,\" highlighting its rich broth and aromatic spices.\nCooking techniques.\nSome common Vietnamese culinary terms include:\nWraps and rolls.\n\"B\u00e1nh tr\u00e1ng\" can be understood as either of the following:\n Thin rice flour sheet dried into what is commonly called \"rice paper\", used in making spring roll (\"ch\u1ea3 gi\u00f2\"), and summer rolls (\"g\u1ecfi cu\u1ed1n\") by applying some water to soften the texture\n These are large, round, flat rice crackers, which, when heated, enlarge into round, easily shattered pieces. They can be eaten separately, although they are most commonly added into the vermicelli noodle dishes like \"cao l\u1ea7u\" and \"m\u00ec qu\u1ea3ng\". Many types of \"b\u00e1nh tr\u00e1ng\" exist, including the clear sesame seed ones, prawn-like cracker with dried spring onions, and sweet milk.\nSalads.\n\"N\u1ed9m\" (Northern dialects) or \"G\u1ecfi\" (Southern dialects) is Vietnamese salad; of the many varieties, the most popular include:\nPreserved dishes.\n\"Mu\u1ed1i\" (literally means \"salting\") and \"chua\" (literally means \"sour\" or \"fermenting\") are Vietnamese term for preserved dishes. Monsoon tropical climate with abundant rainfall gives the Vietnamese a generous year-round supply of vegetables. Animal husbandry never occurred in large scale in Vietnamese history, therefore, preserved dishes are mainly plant-based pickled dishes. Seafood is often made into a fermented form called \"m\u1eafm\" like fish sauce. \nM\u1eafm.\n\"M\u1eafm\" is a Vietnamese term for fermented fish, shrimp or other aquatic ingredients. It is used as main course, as an ingredient or as condiment. The types of fish most commonly used to make \"m\u1eafm\" are anchovies, catfish, snakeheads, and mackerels. The fish flesh remains intact (this is how it is different from \"n\u01b0\u1edbc m\u1eafm\"), and can be eaten cooked or uncooked, with or without vegetables and condiments. Fish sauce is literally called \"m\u1eafm water\" in Vietnamese and is the distilled liquid from the process of fermentation of m\u1eafm.\nFermented meat dishes.\n\"Nem chua\", a Vietnamese fermented meat served as is or fried, is made from pork meat, coated by fried rice (\"th\u00ednh g\u1ea1o\"), mixed with pork skin and then wrapped in country gooseberry leaves (\"l\u00e1 ch\u00f9m ru\u1ed9t\") or \"Erythrina orientalis\" leaves (\"l\u00e1 v\u00f4ng nem\"). The preservation process takes about three to five days.\nSausages.\nVietnamese sausage, \"gi\u00f2\", is usually made from fresh ground pork and beef. Sausage makers may use the meat, skin or ear. Fish sauce is added before banana leaves are used to wrap the mixture. The last step is boiling. For common sausage, 1\u00a0kg of meat is boiled for an hour. For \"ch\u1ea3 qu\u1ebf\", the boiled meat mixture will then be roasted with cinnamon.\nVegetarian dishes.\nVegetarian dishes in Vietnam often have the same names as their meat equivalents, e.g. \"ph\u1edf b\u00f2\", but with \"chay\" (vegetarian) sign in front, those dishes are served with tofu instead of meat. Nearly every soup, sandwich and street food has its vegetarian correspondent. Sometimes you can also see notations like \"ph\u1edf chay\", \"b\u00e1nh m\u00ec chay\" (vegetarian sandwich) or \"c\u01a1m chay\" (vegetarian rice). Vegetarian food in comparison the normal dishes are almost always cheaper, often half of the normal price. Vegetarian restaurants are mostly frequented by religious Vietnamese people and are rarely found in touristic areas. Vegetarian food is also eaten to earn luck during special holiday and festival, especially during Lunar New Year where Vietnamese culture serve vegetarian food regardless of their religion.\nM\u1ee9t.\nVietnamese use fruits in season. When the season is passing, they make candied fruit, called \"\u00f4 mai\", and fruit preserves, called \"m\u1ee9t\". The original taste of \"\u00f4 mai\" is sour, sweet, salty, and spicy. The most famous kind of \"\u00f4 mai\" is \"\u00f4 mai m\u01a1\", made from apricots harvested from the forest around Perfume Pagoda (\"Ch\u00f9a H\u01b0\u01a1ng\"), H\u00e0 T\u00e2y province. This \"\u00f4 mai\" consists of apricot covered by ginger, sugar, and liquorice root slivers.\nTofu.\nTofu (\"\u0111\u1eadu ph\u1ee5\") is widely used in Vietnamese cuisine. It is boiled, fried (sprinkled with ground shrimp or oil-dipped minced spring onion) or used as an ingredient in a variety of dishes.\nOther soybean products range from soy sauce (\"n\u01b0\u1edbc t\u01b0\u01a1ng\"; usually light soy sauce), fermented bean paste (\"t\u01b0\u01a1ng\"), and fermented bean curd (\"\u0111\u1eadu ph\u1ee5 nh\u1ef1\" or \"chao\") to douhua (soft tofu sweet soup; \"t\u00e0u h\u0169 n\u01b0\u1edbc \u0111\u01b0\u1eddng\" or \"t\u00e0o ph\u1edb\").\nB\u00f2 kho.\nBo kho is a dish made from beef with a stewing method, originating from the South of Vietnam. Originally, Southern Vietnamese people served Bo kho with many kinds of herbs to enhance the flavor of the dish. Although it is called \"kho\" (meaning \"to stew\"), the main cooking method of the dish is braising. The stewing method is used to marinate and tenderize the beef before braising.\nPh\u1edf.\nPh\u1edf is a traditional Vietnamese dish originating from Van Cu, Nam \u0110\u1ecbnh province. It is traditionally served with a variety of herbs to enhance its flavor. Nowadays, there are many different ways to prepare and flavor ph\u1edf. In Vietnam, there are different names to distinguish them: Northern ph\u1edf (in the North), Hu\u1ebf ph\u1edf (in the Central region), and Saigon ph\u1edf (in the South). In 2016, the Japanese chose April 4 of each year as Vietnam's Ph\u1edf Day in Japan. In Vietnam, on December 12, 2017, Tu\u1ed5i Tr\u1ebb newspaper cooperated with Acecook Vietnam Company to organize the first Ph\u1edf Day. This will be an annual traditional activity. Since 2018, \"Ph\u1edf Day\" will be organized as a community cultural and tourism activity.\nExotic dishes.\nThe use of ingredients typically uncommon or taboo in most countries is one of the quintessential attributes that make Vietnamese cuisine unique. While unusual ingredients can only be found in exotic restaurants in many countries, Vietnamese cuisine is deemed atypical in that the usage of these ingredients can play a customary role in daily family dishes regardless of social class.\nA common and inexpensive breakfast dish that can be found in any wet market, balut (\"h\u1ed9t v\u1ecbt l\u1ed9n\") is a fertilized duck egg with a nearly developed embryo inside, which is boiled and eaten in the shell. It is typically served with fresh herbs: \"rau r\u0103m\", salt, and black pepper; lime juice is another popular additive, when available. A more unusual version of balut dish\u2014fetus quail (\"tr\u1ee9ng c\u00fat l\u1ed9n\") is a snack favored by many Vietnamese students. Paddy crab and paddy snail are the main ingredients in \"b\u00fan ri\u00eau \u1ed1c\"\u2014a popular noodle dish\u2014and in some everyday soup dishes (\"canh\") and braised food (\"m\u00f3n bung\"). Family meals with silkworms (\"nh\u1ed9ng\"), banana flowers (\"hoa chu\u1ed1i\"), sparrows, doves, fermented fish and shrimp (\"m\u1eafm c\u00e1\", \"m\u1eafm t\u00f4m\", \"m\u1eafm t\u00e9p\") are not rare sights. Seasonal favorites include ragworms (\"r\u01b0\u01a1i\"), which are made into many dishes such as fried \"r\u01b0\u01a1i\" omelet (\"ch\u1ea3 r\u01b0\u01a1i\"), fermented \"r\u01b0\u01a1i\" sauce (\"m\u1eafm r\u01b0\u01a1i)\", steamed \"r\u01b0\u01a1i (r\u01b0\u01a1i h\u1ea5p)\", stir-fried \"r\u01b0\u01a1i\" with radish or bamboo shoot \"(\"r\u01b0\u01a1i x\u00e0o c\u1ee7 ni\u1ec5ng m\u0103ng t\u01b0\u01a1i hay c\u1ee7 c\u1ea3i\").\" Three-striped crab \"\" is popular in several southern provinces, including C\u00e0 Mau, S\u00f3c Tr\u0103ng and B\u1ea1c Li\u00eau; it is eaten fermented, stir-fried or steamed\".\"\nNorthern Vietnamese cuisine is also notable for its wide range of meat choices. Exotic meats such as dog meat, cat meat, rat meat, snake meat, soft-shell turtle, deer, and domestic goat are sold in street-side restaurants and generally paired with alcoholic beverages. A taboo in many Western countries and in southern Vietnam, consumption of dog meat and cat meat is common throughout the northern part of the country and is believed to raise the libido in men. Television chef Andrew Zimmern visited northern Vietnam in the 12th episode of his popular show \"Bizarre Foods with Andrew Zimmern\". Cobra beating heart and dried bones, silkworms, and bull penis are some of the dishes he sampled. He also tried porcupine.\nPaddy mouse meat\u2014barbecued, braised, stir- or deep-fried\u2014is a delicacy dish that can be found in Southern Vietnamese rural areas or even high-end city restaurants.\nCrocodiles were eaten by Vietnamese while they were taboo and off limits for Chinese.\nShark fins are imported in massive amounts by Vietnam.\nAnthony Bourdain, the host chef of Travel Channel's \"\", wrote in April 2005: \"...everything is used\u2014and nothing wasted in Vietnam.\" Animal parts that are often disposed of in many Western countries are used fully in Vietnamese cooking. Organs, including lungs, livers, hearts, intestines and bladders of pigs, cattle, and chickens are sold at even higher prices than their meat. Chicken testicles and undeveloped eggs are stir-fried with vegetables and served as an everyday dish.\nMany of the traditional northern Lunar New Year dishes such as \"th\u1ecbt \u0111\u00f4ng\", \"gi\u00f2 th\u1ee7\", and \"canh m\u0103ng m\u00f3ng gi\u00f2\" involve the use of pig heads, tongues, throats and feet. Pig and beef tails, as well as chicken heads, necks and feet, are Vietnamese favorite beer dishes. \"B\u00f3ng b\u00ec\", used as an ingredient in \"canh b\u00f3ng\"\u2014a kind of soup, is pig skin baked until popped. Steamed pig brains can be found almost everywhere. Also in the northern part of Vietnam, different kinds of animal blood can be made into a dish called \"ti\u1ebft canh\" by whisking the blood with fish sauce and cold water in a shallow dish along with finely chopped, cooked duck innards (such as gizzards), sprinkled with crushed peanuts and chopped herbs such as Vietnamese coriander, mint, etc. It is then cooled until the blood coagulates into a soft, jelly-like mixture and served raw.\nCoconut worms, or \"\u0111u\u00f4ng d\u1eeba\", is a delicacy found widely in the Tr\u00e0 Vinh province of Vietnam. They are the larvae form of the palm weevil and are eaten live within a salty fish sauce with chili peppers.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32548", "revid": "1043616464", "url": "https://en.wikipedia.org/wiki?curid=32548", "title": "Vaticanus", "text": "Vaticanus may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "32549", "revid": "1319846426", "url": "https://en.wikipedia.org/wiki?curid=32549", "title": "Voltage", "text": "Difference in electric potential between two points in space\nVoltage, also known as (electrical) potential difference, electric pressure, or electric tension, is the difference in electric potential between two points. In a static electric field, it corresponds to the work needed per unit of charge to move a positive test charge from the first point to the second point. In the International System of Units (SI), the derived unit for voltage is the \"volt\" (\"V\").\nThe voltage between points can be caused by the build-up of electric charge (e.g., a capacitor), and from an electromotive force (e.g., electromagnetic induction in a generator). On a macroscopic scale, a potential difference can be caused by electrochemical processes (e.g., cells and batteries), the pressure-induced piezoelectric effect, photovoltaic effect, and the thermoelectric effect. Since it is the difference in electric potential, it is a physical scalar quantity.\nA voltmeter can be used to measure the voltage between two points in a system. Often a common reference potential such as the ground of the system is used as one of the points. In this case, voltage is often mentioned at a point without completely mentioning the other measurement point. A voltage can be associated with either a source of energy or the loss, dissipation, or storage of energy.\nDefinition.\nThe SI unit of work per unit charge is the joule per coulomb, where 1 volt = 1 joule (of work) per 1 coulomb of charge. The old SI definition for \"volt\" used power and current; starting in 1990, the quantum Hall and Josephson effect were used, and in 2019 physical constants were given defined values for the definition of all SI units.\nVoltage is denoted symbolically by formula_1, simplified \"V\", especially in English-speaking countries. Internationally, the symbol \"U\" is standardized. \nThe electrochemical potential is the voltage that can be directly measured with a voltmeter. The Galvani potential that exists in structures with junctions of dissimilar materials, is also work per charge but cannot be measured with a voltmeter in the external circuit (see ).\nVoltage is defined so that negatively charged objects are pulled towards higher voltages, while positively charged objects are pulled towards lower voltages. Therefore, the conventional current in a wire or resistor always flows from higher voltage to lower voltage.\nHistorically, voltage has been referred to using terms like \"tension\" and \"pressure\". Even today, the term \"tension\" is still used, for example within the phrase \"high tension\" (HT) which is commonly used in the contexts of automotive electronics and systems using thermionic valves (vacuum tubes).\nElectrostatics.\nIn electrostatics, the voltage increase from point formula_2 to some point formula_3 is given by the change in electrostatic potential formula_4 from formula_2 to formula_3. By definition, this is:\nformula_7\nwhere formula_8 is the intensity of the electric field.\nIn this case, the voltage increase from point A to point B is equal to the work done per unit charge, against the electric field, to move the charge from A to B without causing any acceleration. Mathematically, this is expressed as the line integral of the electric field along that path. In electrostatics, this line integral is independent of the path taken.\nUnder this definition, any circuit where there are time-varying magnetic fields, such as AC circuits, will not have a well-defined voltage between nodes in the circuit, since the electric force is not a conservative force in those cases. However, at lower frequencies when the electric and magnetic fields are not rapidly changing, this can be neglected (see electrostatic approximation).\nElectrodynamics.\nThe electric potential can be generalized to electrodynamics, so that differences in electric potential between points are well-defined even in the presence of time-varying fields. However, unlike in electrostatics, the electric field can no longer be expressed only in terms of the electric potential. Furthermore, the potential is no longer uniquely determined up to a constant, and can take significantly different forms depending on the choice of gauge.\nIn this general case, some authors use the word \"voltage\" to refer to the line integral of the electric field, rather than to differences in electric potential. In this case, the voltage rise along some path formula_9 from formula_2 to formula_3 is given by:\nformula_12\nHowever, in this case the \"voltage\" between two points depends on the path taken.\nCircuit theory.\nIn circuit analysis and electrical engineering, lumped element models are used to represent and analyze circuits. These elements are idealized and self-contained circuit elements used to model physical components.\nWhen using a lumped element model, it is assumed that the effects of changing magnetic fields produced by the circuit are suitably contained to each element. Under these assumptions, the electric field in the region exterior to each component is conservative, and voltages between nodes in the circuit are well-defined, where\nformula_13\nas long as the path of integration does not pass through the inside of any component. The above is the same formula used in electrostatics. This integral, with the path of integration being along the test leads, is what a voltmeter will actually measure.\nIf uncontained magnetic fields throughout the circuit are not negligible, then their effects can be modelled by adding mutual inductance elements. In the case of a physical inductor though, the ideal lumped representation is often accurate. This is because the external fields of inductors are generally negligible, especially if the inductor has a closed magnetic path. If external fields are negligible, we find that\nformula_14\nis path-independent, and there is a well-defined voltage across the inductor's terminals. This is the reason that measurements with a voltmeter across an inductor are often reasonably independent of the placement of the test leads.\nVolt.\nThe volt (symbol: V) is the derived unit for electric potential, voltage, and electromotive force. The volt is named in honour of the Italian physicist Alessandro Volta (1745\u20131827), who invented the voltaic pile, possibly the first chemical battery.\nHydraulic analogy.\nA simple analogy for an electric circuit is water flowing in a closed circuit of pipework, driven by a mechanical pump. This can be called a \"water circuit\". The potential difference between two points corresponds to the pressure difference between two points. If the pump creates a pressure difference between two points, then water flowing from one point to the other will be able to do work, such as driving a turbine. Similarly, work can be done by an electric current driven by the potential difference provided by a battery. For example, the voltage provided by a sufficiently-charged automobile battery can \"push\" a large current through the windings of an automobile's starter motor. If the pump is not working, it produces no pressure difference, and the turbine will not rotate. Likewise, if the automobile's battery is very weak or \"dead\" (or \"flat\"), then it will not turn the starter motor.\nThe hydraulic analogy is a useful way of understanding many electrical concepts. In such a system, the work done to move water is equal to the \"pressure drop\" (compare p.d.) multiplied by the volume of water moved. Similarly, in an electrical circuit, the work done to move electrons or other charge carriers is equal to \"electrical pressure difference\" multiplied by the quantity of electrical charges moved. In relation to \"flow\", the larger the \"pressure difference\" between two points (potential difference or water pressure difference), the greater the flow between them (electric current or water flow). (See \"electric power\".)\nApplications.\nSpecifying a voltage measurement requires explicit or implicit specification of the points across which the voltage is measured. When using a voltmeter to measure voltage, one electrical lead of the voltmeter must be connected to the first point, one to the second point.\nA common use of the term \"voltage\" is in describing the voltage dropped across an electrical device (such as a resistor). The voltage drop across the device can be understood as the difference between measurements at each terminal of the device with respect to a common reference point (or ground). The voltage drop is the difference between the two readings. Two points in an electric circuit that are connected by an ideal conductor without resistance and not within a changing magnetic field have a voltage of zero. Any two points with the same potential may be connected by a conductor and no current will flow between them.\nAddition of voltages.\nThe voltage between \"A\" and \"C\" is the sum of the voltage between \"A\" and \"B\" and the voltage between \"B\" and \"C\". The various voltages in a circuit can be computed using Kirchhoff's circuit laws.\nWhen talking about alternating current (AC) there is a difference between instantaneous voltage and average voltage. Instantaneous voltages can be added for direct current (DC) and AC, but average voltages can be meaningfully added only when they apply to signals that all have the same frequency and phase.\nMeasuring instruments.\nInstruments for measuring voltages include the voltmeter, the potentiometer, and the oscilloscope. Analog voltmeters, such as moving-coil instruments, work by measuring the current through a fixed resistor, which, according to Ohm's law, is proportional to the voltage across the resistor. The potentiometer works by balancing the unknown voltage against a known voltage in a bridge circuit. The cathode-ray oscilloscope works by amplifying the voltage and using it to deflect an electron beam from a straight path, so that the deflection of the beam is proportional to the voltage.\nTypical voltages.\nA common voltage for flashlight batteries is 1.5\u00a0volts (DC).\nA common voltage for automobile batteries is 12\u00a0volts (DC).\nCommon voltages supplied by power companies to consumers are 110 to 120 volts (AC) in North America and 220 to 240\u00a0volts (AC) in most of Europe. The voltage in electric power transmission lines used to distribute electricity from power stations can be several hundred times greater than consumer voltages, typically 110 to 1200\u00a0kV (AC).\nThe voltage used in overhead lines to power railway locomotives is between 12\u00a0kV and 50\u00a0kV (AC) or between 0.75\u00a0kV and 3\u00a0kV (DC).\nGalvani potential vs. electrochemical potential.\nInside a conductive material, the energy of an electron is affected not only by the average electric potential but also by the specific thermal and atomic environment that it is in.\nWhen a voltmeter is connected between two different types of metal, it measures not the electrostatic potential difference, but instead something else that is affected by thermodynamics.\nThe quantity measured by a voltmeter is the negative of the difference of the electrochemical potential of electrons (Fermi level) divided by the electron charge and commonly referred to as the voltage difference, while the pure unadjusted electrostatic potential (not measurable with a voltmeter) is sometimes called Galvani potential.\nThe terms \"voltage\" and \"electric potential\" are ambiguous in that, in practice, they can refer to \"either\" of these in different contexts.\nHistory.\nThe term \"electromotive force\" was first used by Volta in a letter to Giovanni Aldini in 1798, and first appeared in a published paper in 1801 in \"Annales de chimie et de physique\". Volta meant by this a force that was not an electrostatic force, specifically, an electrochemical force. The term was taken up by Michael Faraday in connection with electromagnetic induction in the 1820s. However, a clear definition of voltage and method of measuring it had not been developed at this time. Volta distinguished electromotive force (emf) from \"tension\" (potential difference): the observed potential difference at the terminals of an electrochemical cell when it was open circuit must exactly balance the emf of the cell so that no current flowed.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "32550", "revid": "8524693", "url": "https://en.wikipedia.org/wiki?curid=32550", "title": "Vincent Alsop", "text": "English Nonconformist clergyman\nVincent Alsop (30 August 1630 \u2013 8 May 1703) was an English Nonconformist clergyman. His \"Mischief of Separation\" and \"Melius Inquirenduni\" became landmarks in the history of religious nonconformity.\nLife.\nAlsop was the son of the Rector of South Collingham, Nottinghamshire and was educated at St John's College, Cambridge. He received deacon's orders from a bishop, and settled as assistant-master in the free school of Oakham, Rutland. The Rev. Benjamin King took him under his wing, and he married King's daughter. He was thus converted to King's religious beliefs, and received ordination in the Presbyterian denomination, not being satisfied with that which he had from the bishop. He was presented to the living of Wilby, Northamptonshire, but lost it as a result of the Act of Uniformity 1662.\nAfter this he preached privately at Oakham and Wellingborough, and suffered accordingly. He was imprisoned for six months for praying with a sick person. A book against William Sherlock, dean of St Paul's, called \"Antisozzo (against Socinus)\", written in the vein of Andrew Marvell's \"The Rehearsal Transpros'd\", made him a name as a wit. He was also invited to succeed the venerable Thomas Cawton (the younger) as independent minister in Westminster. He accepted the call and drew great crowds to his chapel.\nHe published other books which showed a strong vein of wit, as well as great powers of reasoning. Even with John Goodman and Edward Stillingfleet for antagonists, he more than held his own. His \"Mischief of Impositions\" (1680) in answer to Stillingfleet's \"Mischief of Separation\", and \"Melius Inquirenduni\" (1679) in answer to Goodman's \"Compassionate Inquiry\", remain historical landmarks in the history of nonconformity.\nAs a result of the involvement of his son in alleged treasonable practices, he had to appeal to and obtained pardon from James II of England. This seems to have given a somewhat diplomatic character to his later years, inasmuch as, while remaining a nonconformist, he had a good deal to do with proposed political-ecclesiastical compromises.\nTwo polemical works once thought to be his \u2013 \"A Reply to the Reverend Dean of St. Paul's Reflections on the Rector of Sutton, &amp;c.\" (1681) and \"The Rector of Sutton Committed with the Dean of St. Paul's, or, A Defence of Dr. Stillingfleet's Irenicum\" (1680) \u2013 have also been attributed to the Nottingham Presbyterian John Barret.\nUpon Alsop's death, his significant personal library was sold at retail. No catalog survives.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32551", "revid": "20957809", "url": "https://en.wikipedia.org/wiki?curid=32551", "title": "Varuna", "text": "Hindu deity associated with water\nVaruna (; , IAST: ) is a Hindu god. He is one of the earliest deities in the pantheon, whose role underwent a significant transformation from the Vedic to the Puranic periods. In the early Vedic era, Varuna is seen as the god-sovereign, ruling the sky and embodying divine authority. He is also mentioned as the king of asuras, who gained the status of a deva, serving as the chief of the Adityas, a group of celestial deities. He maintains truth and \"\u1e5bta\", the cosmic and moral order, and was invoked as an omniscient ethical judge, with the stars symbolizing his watchful eyes or spies. Frequently paired with Mitra, Varuna represents the magical and speculative aspects of sovereignty, overseeing the relationship between gods and humans.\nThe transition from the Vedic to later periods saw Varuna's domain begin to shift from the firmament to waters. He became associated with celestial waters, marking the initial phase of his transformation. By the time of the \"Itihasa-Purana\", Varuna had transformed into the lord of all waters, ruling over oceans, rivers, streams, and lakes. Depicted as residing in a magnificent underwater palace, akin to Poseidon in Greek mythology, he is attended by river goddesses like Ganga and Yamuna. Varuna\u2019s earlier supremacy diminished, and he was relegated to a lesser role as a dikpala, or guardian of the western direction. He is depicted as a youthful man, mounted on Makara (crocodile-like creature) and holding a Pasha (noose, rope loop) and a pitcher in his hands. He is depicted as having multiple wives and children, the most notable of the latter being the sages Vasishtha and Agastya.\nVaruna is also mentioned in the Tamil grammar work \"Tolk\u0101ppiyam\", as Kadalon (), the god of sea and rain, and is furthermore present as a deity in Jainism. In Japanese Buddhist myth, Varuna is known as and ranks among the Twelve Devas (\"J\u016bniten\").\nEtymology.\nIn Hindu tradition, the theonym \"V\u00e1ru\u1e47a\" (Devanagari: \u0935\u0930\u0941\u0923) is described as a derivation from the verbal root \"v\u1e5b\" (\"to surround, to cover\" or \"to restrain, bind\") by means of a suffixal \"-u\u1e47a-\", for an interpretation of the name as \"he who covers or binds\", in reference to the cosmological ocean or river encircling the world, but also in reference to the \"binding\" by universal law or \"\u1e5ata\".\nGeorges Dum\u00e9zil (1934) made a cautious case for the identity of Varuna and the Greek god \"Ouranos\" at the earliest Indo-European cultural level.\nThe etymological identification of the name \"Ouranos\" with the Sanskrit \"Varu\u1e47a\" is based in the derivation of both names from the PIE root \"*\u016der\" with a sense of \"binding\" \u2013 the Indic king-god \"Varu\u1e47a\" binds the wicked, the Greek king-god \"Ouranos\" binds the Cyclopes. This derivation of the Greek name is now widely rejected in favour of derivation from the root *\"wers-\" \"to moisten, drip\" (Sanskrit v\u1e5b\u1e63 \"to rain, pour\").\nIn Vedas.\nSamhita.\nRigveda.\nIn the oldest Hindu scripture, \"Rigveda\" (c. 1900\u20131200 BCE), Varu\u1e47a is among the most prominent deities, appearing in numerous hymns, including 1.25, 2.27\u201330, 7.86\u201388, 8.8, and 9.73. Despite this frequent mention, he is the central focus of only ten hymns. Varu\u1e47a is portrayed in four principal aspects: as a universal monarch and sovereign of the sky, the upholder of \"\u1e5bta\" (cosmic order), a deity associated with water (\"\u0101pah\"), and a wielder of \"m\u0101y\u0101\" (cosmic illusion or creative power).\nThe \"Rigveda\" features Varuna as the god-king of the sky. He is described as a divine king (\"samraj\") with pure strength, abiding in the celestial firmament, where he sustains a radiant mass of light. He is credited with creating the sun\u2019s path and is invoked to dispel suffering, liberate from sin, and shield from evil (\"nir\u1e5bti\"). His realm includes the movement of constellations and the moon, which obey his divine ordinances. His omniscience is central to his identity: he observes all actions through celestial spies, residing in a thousand-gated palace upon a golden throne\u2014symbols of his pervasive awareness and authority.\nIn \"Rigveda\" 1.25, Varu\u1e47a is praised for his understanding of the paths of birds, the movement of ships and winds, and the secrets of time and space. Hymns characterize him as a sovereign deity, intimately acquainted with both the sacred and the profane. According to \"Rigveda\" 10.123, Varu\u1e47a's messenger is described as the \"Hira\u1e47yapak\u1e63a\" (golden-winged bird), interpreted by some as a reference to flamingos, based on their colorful plumage and proximity to aquatic habitats. The vulture is likewise mentioned as a messenger of Yama, suggesting symbolic parallels between the two birds.\nVaru\u1e47a's foremost role is as the enforcer of \"\u1e5bta\", the cosmic and moral order that governs both the natural world and human conduct. Hymns such as \"Rigveda\" VII.11.1 and II.29.8 present him as a vigilant upholder of truth, who punishes transgressors while showing mercy to the penitent. Ethical instructions against killing, deceit, and gambling are linked with his domain. His ordinances are described as unshakable, akin to a mountain. Concepts closely tied to \"\u1e5bta\"\u2014such as \"vrata\" (sacred vow) and \"dharman\" (duty, law)\u2014are frequently associated with Varu\u1e47a. In this context, \"vrata\" implies both divine commands and ethical imperatives, while \"dharman\" denotes sacrificial law or moral conduct. Varu\u1e47a is accordingly called \"Rivan\" (\"guide of moral order\") and \"P\u016btadak\u1e63a\" (\"possessor of pure will\").\nSin (\"\u1e5b\u1e47a\") is conceptualized as a breach of Varu\u1e47a\u2019s order, often attributed to human frailty. Hymns express remorse not only for individual wrongdoing but also for ancestral transgressions, suggesting a nascent idea of inherited guilt. Despite his role as punisher, Varu\u1e47a is often invoked for forgiveness, protection from evil, and relief from fear and dreams. He is described as both a judge and a healer, bearing \u201ca thousand remedies\u201d alongside weapons to punish sin.\nVaru\u1e47a\u2019s association with water is both cosmological and symbolic. He presides over \"Apah\", the primeval waters representing the matrix of creation. Hymns such as \"Rigveda\" VII.49.4 describe these waters as celestial and purifying. Varu\u1e47a is also called \"Sindhu-pati\" (\"lord of the ocean\"), sharing this title with Mitra. These waters are the source of the universe, acting as both creative womb and sacred energy. In later Vedic texts, the waters called Viraj are described as Varu\u1e47a\u2019s consorts, representing \"prak\u1e5bti\" (primordial matter), and Varu\u1e47a himself is termed an \"Asura\", denoting \"possessor of \"m\u0101y\u0101\"\" or vital force, without the later demonic connotation.\nVaru\u1e47a\u2019s use of \"m\u0101y\u0101\"\u2014his divine creative power\u2014is a recurring theme in the \"Rigveda\". It refers to his capacity to shape the cosmos and enforce \"\u1e5bta\". Hymns in Mandala VIII describe him as embracing night and measuring the earth with the sun. Through \"m\u0101y\u0101\", Varu\u1e47a becomes not only the enforcer of law but also a cosmic architect.\nCombined descriptions: \"Mitra\u2013Varu\u1e47a\".\nVaru\u1e47a is frequently paired with Mitra in the compound \"Mitra\u2013Varu\u1e47a\", appearing prominently in the \"Rigveda\". Together, they preside over moral and cosmic law, and are associated with ritual, rain, and natural cycles. Both deities are referred to as \"Asuras\" (e.g., RV 5.63.3), though also addressed as \"Devas\" (e.g., RV 7.60.12), reflecting fluid theological roles. According to myths, Varuna, being the king of the Asuras, was adopted or made the change to a Deva after the structuring of the primordial cosmos, imposed by Indra after he defeats Vritra.\nMitra\u2013Varu\u1e47a are described as youthful monarchs clad in glistening garments, residing in a golden palace with a thousand pillars and gates. They are lords of rivers, rain, and heavenly order, sending dew and bountiful waters, and punishing falsehood with disease. Their sun is described as their \"eye\", and their cosmic chariot moves across the sky via solar rays. Possessing divine spies and secret knowledge (\"m\u0101y\u0101\u0301\"), they maintain \"\u1e5bta\" and oversee oaths and societal order. According to myth, the sages Vashistha and Agastya were born from their shared semen, which they deposited into a pitcher after seeing the celestial nymph Urvashi.\nScholar Doris Srinivasan highlights the ambiguous and dualistic nature of Mitra\u2013Varu\u1e47a, comparing it to the Rudra-Shiva pairing. Both Varu\u1e47a and Rudra are described as omniscient guardians, capable of both wrath and grace. In \"Rigveda\" 5.70, the Mitra\u2013Varu\u1e47a pair is even called \"Rudra\". According to Samuel Macey and other scholars, Varuna had been the more ancient Indo-Aryan deity in 2nd millennium BCE, who gave way to Rudra in the Hindu pantheon, and Rudra-Shiva became both \"timeless and the god of time\".\nYajuraveda.\nIn the \"Yajurveda\" (c. 1200 and before 800 BCE), Varu\u1e47a maintains his exalted status as guardian of \"\u1e5bta\" and sovereign of the waters. He is portrayed as a moral overseer who casts his noose (\"p\u0101\u015ba\") upon transgressors and is invoked as both judge and healer. His role expands to include health and medicine, and he is referred to as the \u201cpatron deity of physicians.\u201d In the \"V\u0101jasaneyi Sa\u1e43hit\u0101\" (21.40), he is described as possessing \u201ca hundred, a thousand remedies,\u201d echoing earlier \"\u1e5agvedic\" hymns linking him to herbs and healing. His capacity and association with \"all comprehensive knowledge\" is also found in the \"Atharvaveda\" (~1000 BCE).\nVaru\u1e47a resides in celestial waters described as pure, nourishing, and maternal. These waters are identified with \"Mahatsalilam\" (the great waters), linked to Aditi\u2014the cosmic mother and creative force. As lord of these waters, Varu\u1e47a becomes a symbol of cosmic law, creation, and protection. The waters not only represent physical phenomena but also the metaphysical substratum of reality.\nHis association with law and conscience continues through imagery such as the \u201cthree bonds\u201d that bind the sinner\u2014interpreted as natural forces like cloud, lightning, and thunder\u2014symbolizing physical and moral consequences. Worshippers pray for release from these bonds and seek reconciliation with \"\u1e5bta\". As in earlier texts, Varu\u1e47a is revered with a mixture of fear and devotion, embodying both justice and mercy.\nIn \"Yajurveda\" 8.59, it is stated: \u201cIn fact, Varu\u1e47a is Vi\u1e63\u1e47u and Vi\u1e63\u1e47u is Varu\u1e47a, and hence the auspicious offering is to be made to these deities.\u201d This reflects theological fluidity in the identification of divine roles and emphasizes Varu\u1e47a\u2019s integration into broader Vedic pantheon.\nRitually, Varu\u1e47a is associated with the west and is offered a black ram with a white foot during sacrifices, symbolizing concealment and dominion over night.\nSamaveda.\nThough no original verses directly address Varuna in the \"Samaveda\" (c. 1200 to 1000 BCE), \"Rigvedic\" hymns to him are adapted into Saman melodies, indicating his continued reverence in ritual worship.\nAtharvaveda.\nIn the \"Atharvaveda\" (c. 1200\u2013900 BCE), Varu\u1e47a\u2019s portrayal evolves while retaining continuity with earlier depictions. Although scholars such as A.A. Macdonell have suggested that Varu\u1e47a appears here \"divested of his powers as a universal ruler,\" other interpretations challenge this view. Rather than a decline, Varu\u1e47a\u2019s role shifts toward a more metaphysical and moral presence, with water remaining a central element of his identity.\nThe \"Atharvavedic\" waters (\"\u0101pah\") are described as golden-hued, pure, and sacred. They function not only as physical substances but also as the womb of creation, giving rise to deities such as Savit\u1e5b and Agni. These waters embody the principle of becoming, and Varu\u1e47a, as their lord, governs the cosmic processes emerging from them.\nOne of the most prominent hymns dedicated to Varu\u1e47a is Book IV, Hymn 16, which emphasizes his omniscience and moral surveillance. He is said to possess \u201cspies with a thousand eyes\u201d who descend to observe all human actions. His oversight extends beyond earth and heaven to regions beyond the visible cosmos. The metaphor of Varu\u1e47a controlling the world like a gamester casting dice illustrates his dominion over fate and law.\nThis hymn also introduces magical and imprecatory themes, consistent with the \"Atharvaveda\u2019s\" ritualistic focus. Still, the theological depth remains intact: Varu\u1e47a punishes immorality not out of wrath, but in fulfillment of his cosmic duty to uphold \"\u1e5bta\". His moral authority is depicted as omnipresent and inescapable. Here, Varu\u1e47a's moral authority is reinforced by his role as enforcer of law through spiritual nooses (p\u0101\u015ba) cast upon the wicked.\nA notable development in the \"Atharvaveda\" is the explicit articulation of Varu\u1e47a\u2019s dual nature as both punisher and forgiver. In Book I, Hymn 10, a priest pleads for the release of a sinner, reflecting the idea that sin can result from ignorance or falsehood and can be absolved through penance. This reveals a sophisticated moral theology, wherein divine grace is attainable through sincere repentance.\nMax M\u00fcller praised this dualism, viewing Varu\u1e47a as one of the most theologically advanced constructs in early Indo-Aryan religion. Rooted in sky imagery yet imbued with ethical and cosmic dimensions, Varu\u1e47a is both transcendent and intimately connected with human conscience.\nVaru\u1e47a is again identified as \"M\u0101yin\"\u2014master of \"m\u0101y\u0101\", or divine creative power\u2014and called \"Asura\" in its original sense of \u201clord\u201d or \u201cmighty one.\u201d This emphasizes his possession of \"asu\" (vital power) and his role as an invisible force guiding the visible world. Yet, his identity as \"Ap\u0101m Adhipati\"\u2014the Lord of Waters\u2014remains constant. The waters, symbolic of purity, healing, and cosmic potential, reinforce his status as a protector of life and order in the \"Atharvaveda\".\nBrahmanas.\nIn the Brahmana texts, Varuna retains his Vedic stature as the sovereign of \"\u1e5bta\" (cosmic order) and is especially associated with the moral and ritual law. The \"Shatapatha Brahmana\" frequently describes Varuna as the deity who punishes violations of ritual precision through his noose (\"p\u0101\u015ba\") and cords, symbolic of cosmic and ethical consequences.\nA significant ceremony called the \"Varunapraghasa\" is detailed. The \"Varunapraghasa\" sacrifice, performed during the rainy season, underscores Varuna\u2019s association with cosmic law, where violations are metaphorically described as \"eating Varuna\u2019s barley,\" leading to divine punishment but also offering a path to redemption through ritual. Varuna\u2019s dual nature is reflected in offerings of white barley (symbolizing light and unity) and black rice (representing the punitive aspect of law), illustrating his role as both a unifier and a judge. As such, Varuna's function is twofold: he enforces cosmic and social law, and he grants atonement through sacrifice.\nThe \"Taittir\u012bya Br\u0101hma\u1e47a\" highlights Varuna\u2019s vigilance over truth (\"satya\") and falsehood (\"an\u1e5bta\"), emphasizing his immediate retribution against deceit. He is identified with the cosmic waters (\"\u0101pah\"), truth (\"satya\"), and darkness, all of which reflect dual aspects of creation and morality (pp. 88\u201390). Varuna is further described as \"Samvatsara\"\u2014the cosmic year\u2014and is associated with prana (life breath), Agni (fire), and as the holder of royal authority in the \"Rajasuya\" consecration rite.\nPhilosophical passages depict Varuna as enveloping the universe, akin to the cosmic waters that cover and permeate creation. This enveloping aspect (\"var\") forms the etymological basis for his name, portraying him as both metaphysical principle and divine legislator.\nAranyakas.\nReferences to Varuna in the \"Aranyakas\" are limited but conceptually profound. The \"Aitareya Aranyaka\" describes the creation of Varuna and the cosmic waters through the mind (\"manas\") of the Supreme Being. The waters and Varuna are said to serve their progenitor by yielding faith and preserving offspring through the law (\"dharma\").\nThis philosophical depiction aligns Varuna with \"prakriti\", the primordial substance of the universe, and suggests that he, like the waters, is an agent of Becoming\u2014emerging at the moment of the Supreme\u2019s creative desire. Thus, the \"Aranyakas\" treat Varuna not merely as a deity but as a metaphysical symbol representing the order and potential of existence.\nUpanishads.\nIn the \"Upanishads\", the metaphysical emphasis shifts toward monism, and Varuna is often absorbed into the concept of the \"brahman\", the Supreme Reality. While individual deities lose their independent theological status in favor of the unified Self (\"\u0101tman\"), Varuna is still employed as a symbolic and pedagogical figure.\nVaruna also finds a mention in the early Upanishads, where his role evolves. In verse 3.9.26 of the \"Brihadaranyaka Upanishad\" (~800 BCE), for example, he is stated to be the god of the western quarter, but one whose abode is water, whose world is the heart, soul is the fire and whose illumination is the mind. This establishes him as an intermediary symbol for the Self and its realization through inward knowledge. The cosmological hierarchy that begins with water and culminates in the heart is used to indicate that all arises from desire (\"k\u0101ma\") in the Supreme\u2019s mind. In the \"Katha Upanishad\", Aditi is identified to be same as the goddess earth and the mother of Varuna and Mitra along with other Vedic gods.\nThe \"Chandogya Upanishad\" includes Varuna in ritual prayers and refers to him as the source of sustenance and purity. The \"Maitri Upanishad\" portrays him as one of many manifestations of the inner Self (\"\u0101tman\"), acknowledging his place in the idealist ontology of the Upanishadic worldview.\nVaruna, addressed as Varuni explained \"Brahman\" in \"Taittiriya Upanishad\" to sage Bhrigu. First six anuvakas of Bhrigu Valli are called \"Bhargavi Varuni Vidya\", which means \"the knowledge Bhrigu got from (his father) Varuni\". It is in these anuvakas that sage Varuni advises Bhrigu with one of the oft-cited definition of Brahman, as \"that from which beings originate, through which they live, and in which they re-enter after death, explore that because that is Brahman\". This thematic, all encompassing, eternal nature of reality and existence develops as the basis for Bhrigu's emphasis on introspection, to help peel off the outer husks of knowledge, in order to reach and realize the innermost kernel of spiritual Self-knowledge.\nIn Itihasa-Puranas.\nMahabharata.\nIn the epic \"Mahabharata\" (c. 400 BCE - 400 CE), Varuna undergoes a notable transformation from his earlier Vedic portrayal. He is no longer depicted as the supreme sky god or an omnipotent sovereign administering cosmic order and morality, though his pairing with Mitra remains. The epic forgets his earlier associations with \"\u1e5bta\" (cosmic order) and ethical oversight, emphasizing instead his role within a new mythological framework.\nVaruna is still identified as the son of Aditi and fifth of the twelve Adityas, but his status is reduced as one of the Lokapalas, or guardians of the directions, specifically presiding over the western quarter\u2014a symbolic alignment with the setting sun and perhaps with darkness and night. In this context, Kashyapa, Varuna's father, installed Varuna as \"Salile\u015bvara,\" the sovereign of all forms of water, including rivers, lakes, and oceans.\nAs a water-god, Varuna is described being handsome, having the splendor of Lapis Lazuli. Unlike earlier texts where the waters (\"\u0101pa\u1e25\") held deep philosophical and metaphysical significance, the \"Mahabharata\" presents them in a more literal sense. Varuna resides beneath the waters, in a grand palace of pure white colour situated in \"Nagaloka\", the oceanic realm (\"samudra\"), described vividly in the \"Udyoga Parva\". There, adorned in radiant attire and gleaming jewels, he sits enthroned beside his queen, surrounded by aquatic beings, including n\u0101gas, daityas, s\u0101dhyas, and river goddesses including Ganga and Yamuna. According to the \"Sabha Parva\", Varuna also attends celestial assembly of the creator god, Brahma.\nThe \"Mahabharata\" expands Varuna's personal life. His chief-queen is most commonly identified as Varuni, who is depicted alongside him in his underwater palace. The \"Udyoga Parva\" refers to his beloved-wife as Gauri, while the \"Adi Parva\" names his spouse as Jyeshtha or Devi, the eldest daughter of Shukra. With Jyeshtha, Varuna is said to have fathered a son, Bala, and a daughter Sura, the wine goddess. The \"Vanaparva\" further mentions Vandin as another of Varuna\u2019s sons. The \"Udyoga Parva\" adds another son, Pushkara, who married the daughter of the Moon god. In the \"Udyoga Parva\", Varuna is also stated to have fathered the Kalinga king\u2014Shrutayudha\u2014from the river goddess Parnasha. Varuna also granted Shrutayudha a divine mace in response to prayers by Parnasha.\nThe \"Mahabharata\" also references Varuna\u2019s iconic weapon, the \"p\u0101\u015ba\" (noose), though without the symbolic judicial weight it carried in the Vedic tradition. He is briefly mentioned as \"P\u0101\u015babh\u1e5bt\", \"Ugrap\u0101\u015ba\", \"P\u0101\u015bin\", and \"P\u0101\u015bav\u0101n\", with the noose appearing merely as one of his divine attributes.\nVaruna appears in several narrative episodes throughout the epic. The \"Adi Parva\" recounts that during the burning of the Khandava forest, Varuna gifted Arjuna the celestial bow Gandiva, an inexhaustible quiver, and a monkey-bannered chariot, as well as the mace Kaumodaki to Krishna. Later, in the \"Mahaprasthanika Parva\", Arjuna returned the Gandiva by casting it into the sea, effectively returning it to Varuna.\nAnother episode in the \"Adi Parva\" tells how Varuna abducted Bhadra, the wife of the sage Utathya. In response, Utathya dried up the ocean until Varuna returned her. The same text also narrates that when Kashyapa took Varuna\u2019s sacred cow (\"homadhenu\") for a sacrifice, Varuna and Brahma cursed him to be reborn as a cowherd. The \"Shalya Parva\" states that Varuna performed a rajasuya sacrifice at Yamunatirtha and later provided the war god Skanda with an elephant and two followers named Yama and Atiyama.\nOther episodes include Varuna giving the sage Richika a thousand black-eared horses, testing King Nala alongside other deities, and granting Nala a boon that allowed him to assume any form, along with a garland of fragrant flowers. The \"Drona Parva\" also records that Varuna was once defeated in battle by Krishna, indicating the evolving hierarchy among deities in the epic tradition.\nRamayana.\nAs in the \"Mahabharata\", in the other major epic, the \"Ramayana\" (300 BCE - 300 CE), Varuna is depicted primarily as a Dikpala and as a water deity appointed by chief-god Brahma. Varuna appears weaker than in his earlier portrayals, being overpowered or sidelined by both the protagonist Rama\u2014an avatar of Vishnu\u2014and the antagonist Ravana, the demon king.\nOne of the most well-known episodes involving Varuna occurs in the \"Yuddha Kanda\" when Rama, preparing to invade the island Lanka to rescue his abducted wife Sita, seeks passage across the ocean. Rama performs a three-day penance to Varuna, the lord of oceans, but receives no reply. When Varuna initially remains silent, Rama, enraged, threatens to unleash his divine weapons, including the \"Brahmastra\", to evaporate the sea. Varuna then appears, recognizing Rama\u2019s authority and righteousness. He explains that his role as a guardian of natural order prevents him from parting the ocean, as it would disrupt natural balance. Instead, Varuna suggests constructing a bridge and pledges to stabilize the waters to aid the effort. Following this counsel, Rama entrusts the vanara architect Nala with building the bridge, known as \"Rama Setu\". Many sources claim it was Samudra, the personification of the oceans, who met Rama not the water god Varuna.\nIn the \"Uttara Kanda\", in an event taking place much before Rama's interaction, when Ravana\u2019s conquests spread across the realms, several deities assume animal forms to escape detection\u2014Varuna takes the form of a swan.\nThe \"Uttara Kanda\" \"also\" preserves the Vedic pairing of Varuna and Mitra in a myth recounting the birth of the sages Agastya and Vasishtha, though Vasishtha\u2019s role here is framed as a rebirth. After losing his original body, Vasishtha enters the vital essence of Mitra and Varuna. At that time, the celestial nymph Urvashi arrives in Varuna\u2019s realm, where Mitra holds temporary sway. Varuna desires her, and Urvashi reciprocates but remains bound by her prior promise to Mitra. Respecting this, Varuna releases his seed into a vessel fashioned by Brahma, which sanctifies the act as a symbolic consummation. Later, due to Urvashi\u2019s divided fidelity, Mitra\u2019s seed falls from her womb into the same vessel. From this vessel, containing the combined seed of Mitra and Varuna, Agastya and Vasishtha emerge, restoring the latter's body.\nIt also records that once during Varuna's absence in his realm, attending a musical event in Brahmaloka, Ravana confronts Varuna\u2019s sons and grandsons, including Go and Pushkara, defeats them. Other children of Varuna mentioned in the \"Ramayana\" include the vanara Sushena, who was conceived with the purpose of aiding Rama in future, and the goddess of wine, referred to here as Varuni instead of Sura; she emerged during the churning of the ocean and chose the companionship of the devas, as narrated in the \"Bala Kanda\".\nPuranas.\nBy the time of the \"Puranas\" (mostly composed between 300 CE and 1000 CE), ancient Vedic deities such as Indra and Varuna are often portrayed as having diminished in power and esteem. They are frequently shown as subordinate to other gods, particularly Vishnu, Krishna and Shiva, and are sometimes humiliated by the increasingly dominant and aggressive Asuras, the term which, unlike in the \"Vedas\", now only denotes to malevolent beings. In the \"Puranas\" (mostly composed between 300 CE and 1000 CE), the portrayal of Varuna remains broadly consistent with his depiction in the epics, but his divine attributes and roles are further elaborated, sometimes alluding to his Vedic associations. He continues to be described as the regent of the western direction and the guardian of the water element.\nDespite his decline in stature in later mythology, Varuna retains considerable moral authority in the \"Puranas\", punishing transgressors and upholding truth and cosmic law. In one narrative, King Harishchandra, having failed to fulfill a vow to Varuna after receiving a boon for a son, is afflicted with \"Mahodara\" (abdominal swelling) until the debt is resolved through a substitute offering. Similarly, Varuna punishes Nanda for entering sacred waters at an inauspicious time, but releases him upon Krishna\u2019s intervention, acknowledging Krishna\u2019s superior authority. The \"Bhagavata Purana\" further portrays Varuna as a warrior subordinate to Krishna, participating in divine battles alongside Indra, equipped with nooses and a mace. In one episode, Varuna confronts Krishna after the latter retrieves the Parijata tree from Indra\u2019s palace, only to retreat when defeated by Krishna\u2019s mount, Garuda. Elsewhere, in battles against demons like Kalanemi, Varuna is rendered motionless, likened to a drained ocean, while against Kujambha, he binds the demon\u2019s arms with his noose and subdues him with his mace. He is also credited with binding the asura king Bali.\nIconographically, Varuna is depicted as riding the mythical sea creature \"Makara\" and holding a noose (\"pasha\") in his hand. He often appears adorned with a white umbrella\u2014said to have emerged during the churning of the ocean\u2014and is described as having a conch-like or crystalline complexion, wearing garlands and bracelets. The \"Matsya Purana\" devotes considerable detail to Varuna\u2019s iconography. His idol is to be worshipped in rites such as \"Vastupasamanam\" before the construction of palaces, and he is invoked in the \"Graha Shanti\" rite through offerings of pearls, lotus flowers, and kusha grass. He is said to be propitiated with \"avabhritha\" baths and other ceremonial acts. In the \"Hayasirsha Pancharatra\", Varuna is described as seated on a swan, with two arms\u2014one offering protection and the other holding a serpent-noose\u2014surrounded by aquatic beings. Varuna is revered as a deity responsible for ensuring good and timely rainfall. Varuna's abode is described as being situated in the western direction on the summit of Mount Manasa, near the divine lake of Sukhi (according to the \"Vayu Purana\") or Sushila (in the \"Matsya Purana\"). This location lies on the Puskara island, beneath which the sun\u2019s chariot rotates around Mount Meru. At midnight in Samyamani, the sun is said to set in Varuna\u2019s city. The \"Devi Bhagavata Purana\" attests his capital city as \"\u015araddh\u0101vat\u012b\". Varuna's celestial garden, Ritumat, is described in the \"Puranas\" as a place of great beauty located on the Trikuta mountain. The garden is adorned with flowering trees and also features a resplendent lake filled with golden lotuses, lilies, and other aquatic flowers.\nRegarding his family, the \"Bhagavata Purana\" names Charsani as Varuna\u2019s beloved-wife and the mother of the sage Bhrigu. Other sources continue to name Varunani, Gauri or Jyeshtha as his consorts. Varuna's other children include Sushena, Vandi, Varuni, Bala, Sura, Adharmaka, Dakshasavarni (the ninth Manu), Pushkara, and Valmiki, the latter born from Varuna\u2019s semen on a termite mound. Although much reduced, Varuna's Vedic pairing with Mitra persists, notably in the vivid depiction of their shared infatuation with the celestial apsara Urvashi, portraying sages Agastya and Vasistha here as their reborn sons, either similar to the Vedic or the \"Ramayana\" version. Varuna\u2019s link to progeny is further emphasized in narratives like Vaivasvata Manu\u2019s sacrifice invoking Mitra and Varuna for offspring, and Harishchandra\u2019s prayer to Varuna for a son, which leads to the aforementioned vow and punishment.\nVaruna\u2019s broader mythological roles encompass divine benefaction and protection. He is associated with hidden treasures and performed a rajasuya sacrifice, a standard for Yudhishthira\u2019s own in the \"Mahabharata\". His gifts include a water-sprinkling white umbrella for King Prithu\u2019s coronation, a thousand white horses with black ears for Sage Richika to wed Satyavati, Varuni wine for Balarama, and \"nagapasha\" for Shiva\u2019s marriage to Parvati, where Varuna appears as a divine dignitary. During the churning of the ocean, Varuna continues to play a significant role, aligning with his aquatic dominion. The \"Bhagavata Purana\" credits him with protecting Kraumcha-dvipa, beyond Kusha-dvipa, surrounded by an ocean of milk. Its central mountain, Kraumcha, remains unscathed by Kartikeya\u2019s weapons due to Varuna\u2019s guardianship and the washing of its slopes by sacred waters.\nOther accounts.\nIn Tolkappiyam.\nThe Tolk\u0101ppiyam, a Tamil grammar work from the 3rd century BCE divides the people of ancient Tamilakam into five Sangam landscape divisions: \"kurinji, mullai, paalai, marutham\" and \"neithal\". Each landscape is designated with different gods. \"Neithal\" is described as a seashore landscape occupied by fishermen and seatraders, with the god of sea and rain, \"Varunan\" or \"Kadal\u014dn\". \"Varuna\" means water which denotes the ocean in the Tamil language.\nSri Lankan Tamils (Karaiyar caste).\nKaraiyar is a Sri Lankan Tamils caste found mainly on the northern and eastern coastal areas of Sri Lanka, and globally among the Tamil diaspora.\nThey are traditionally a seafaring community that is engaged in fishing, shipment and seaborne trade. They fish mostly in deep seas, and employ gillnet and seine fishing methods. The Karaiyars were the major maritime traders and boat owners who among other things, traded with pearls, chanks, tobacco, and shipped goods overseas to countries such as India, Myanmar and Indonesia. The community known for their maritime history, are also reputed as a warrior caste who contributed as army and navy soldiers of Tamil kings. They were noted as the army generals and navy captains of the Aryacakravarti dynasty. The Karaiyars emerged in the 1990s as strong representatives of Sri Lankan Tamil nationalism. The nuclear leadership of the Liberation Tigers of Tamil Eelam have background in the wealthier enterprising section of the Karaiyars.\nThe word \"Karaiyar\" is derived from the Tamil language words \"karai\" (\"coast\" or \"shore\") and \"yar\" (\"people\"). The term \"Kareoi\" mentioned by 2nd century CE writer Ptolemy, is identified with the Tamil word \"Karaiyar\". The Portuguese and Dutch sources mentions them under the term \"Careas\", \"Careaz\", or \"Carias,\" which are terms denoting \"Karaiyar\".\n\"Kurukulam\", \"Varunakulam\" and \"Arasakulam\" were historically one of the significant clans of the Karaiyars. Kurukulam, meaning \"clan of the \"Kuru\"\", may be a reference to their origin from Kurumandalam (meaning \"realm of Kuru's\") of Southern India. They attribute their origin myth from the Kuru kingdom, mentioned in the Hindu epic \"Mahabharata\". Some scholars derived \"Kurukulam\" from Kuru, the Tamil name for Jupiter. Varunakulam, meaning \"clan of \"Varuna\"\", is a reference to their maritime origin. Varuna is the god of sea and rain, mentioned in Vedic Literature, but also in Sangam literature as the principal deity of the \"Neithal Sangam landscape\" (i.e. littoral landscape). Arasakulam means \"clan of kings\". They used the Makara as emblem, the mount of their clan deity, the sea god Varuna, which was also seen on their flags.\nSindhi Hindus.\nJhulelal is believed by Sindhi Hindus to be an incarnation of Varuna. They celebrate the festival of Cheti Chand in his honor. The festival marks the arrival of spring and harvest, but in Sindhi community it also marks the birth of Uderolal in year 1007, after they prayed to Hindu god Varuna to save them from the persecution by tyrannical Muslim ruler named Mirkhshah. Uderolal morphed into a warrior and old man who preached and reprimanded Mirkhshah that Muslims and Hindus deserve the same religious freedoms. He, as Jhulelal, became the champion of the people in Sindh, from both religions. Among his Sufi Muslim followers, Jhulelal is known as \"Khwaja Khizir\" or \"Sheikh Tahit\". The Hindu Sindhi, according to this legend, celebrate the new year as Uderolal's birthday.\nFestivals.\nCheti Chand.\nThe Cheti Chand festival in the Hindu month of Chaitra marks the arrival of spring and harvest, but in Sindhi Hindu community, it also marks the mythical birth of Uderolal in the year 1007. Uderolal morphed into a warrior and old man who preached and reprimanded Mirkhshah that Muslims and Hindus deserve the same religious freedoms. He, as Jhulelal, became the saviour of the Sindhi Hindus, who according to this legend, celebrate the new year as Uderolal's birthday.\nChaliya saheb.\nChalio or Chaliho, also called Chaliho Sahib, is a forty-day-long festival celebrated by Sindhi Hindus to express their gratitude to Jhulelal for saving them from their impending conversion to Islam. The festival is observed every year in the months of July to August; dates vary according to the Hindu calendar. It is a thanksgiving celebration in honor of Varuna Deva for listening to their prayers.\nNarali Poornima.\nN\u0101rali Poornima is a ceremonial day observed by Hindu fishing communities in Maharashtra, India particularly around Mumbai and the Konkan coast. It is held on the full-moon day of the Hindu month of Shravan which falls around July or August. On this day offerings such as rice, flowers and coconuts are offered to Lord Varuna, the god of ocean and waters.\nBeyond Hinduism.\nBuddhism.\nTheravada.\nThe Pali Canon of the Theravada school recognizes Varu\u1e47a (Sanskrit; Pali: Varuna) as a king of the devas and companion of Sakka, Paj\u0101pati and Is\u0101na. In the battle against the Asuras, the devas of T\u0101vati\u1e43sa were asked to look upon the banner of Varuna in order to have all their fears dispelled (S.i.219).\nThe Tevijja Sutta mentions him among Indra, Soma, Is\u0101na, Paj\u0101pati, Yama and Mahiddhi as gods that are invoked by the brahmins.\nThe \u0100t\u0101n\u0101tiya Sutta lists him among the Yakkha chiefs.\nBuddhaghosa states (SA.i.262) that Varuna is equal in age and glory (vanna) with Sakka and takes the third seat in the assembly of devas.\nMahayana.\nIn East Asian Buddhism, Varuna is a dharmap\u0101la and often classed as one of the Twelve Devas (Japanese: , \u5341\u4e8c\u5929). He presides over the western direction.\nIn Japan, he is called \"Suiten\" (\u6c34\u5929 lit. \"water deva\"). He is included with the other eleven devas, which include Taishakuten (\u015aakra/Indra), F\u016bten (V\u0101yu), Emmaten (Yama), Rasetsuten (Nir\u1e5bti/R\u0101k\u1e63asa), Ishanaten (\u012a\u015b\u0101na), Bishamonten (Vai\u015brava\u1e47a/Kubera), Katen (Agni), Bonten (Brahm\u0101), Jiten (P\u1e5bthiv\u012b), Nitten (S\u016brya/\u0100ditya), and Gatten (Chandra).\nShinto.\nVaruna is also worshipped in Japan's Shinto religion. One of the Shinto shrines dedicated to him is the \"Suiteng\u016b\" (\"Palace of Suiten\") in Tokyo. After the Japanese emperor issued the \"Shinbutsu bunri\", the separation of Shinto and Buddhist practices as part of the Meiji Restoration, Varuna/Suiten was identified with the Japanese supreme God, Amenominakanushi.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32555", "revid": "50840630", "url": "https://en.wikipedia.org/wiki?curid=32555", "title": "Vladimir Markovnikov", "text": "Russian chemist (1837\u20131904)\nVladimir Vasilyevich Markovnikov, also Markownikoff (; 25 December\u00a0[O.S. 13 December]\u00a01837 \u2013 11 February 1904) was a Russian chemist, best known for having developed the Markovnikov's rule, that describes addition reactions of hydrogen halides and alkenes.\nEarly life and education.\nVladimir Markovnikov was born on December 25, 1837, in Chernorechye near Nizhny Novgorod, Russian Empire (now Dzerzhinsk, Nizhny Novgorod Oblast, Russian Federation). Soon after his birth, his father retired and settled in a family estate received as a dowry from his wife's family at marriage, in the village of Ivanovo, Knyagininsky district of the Nizhny Novgorod province, where Markovnikov spent his early childhood.\nHe joined the cameral department of the law faculty of Kazan Imperial University in 1856. He moved to the natural department of the university, where he attended the lectures of A. M. Butlerov. In 1860, after completing a university course, he was left to prepare for a professorship and was appointed laboratory assistant at a chemical laboratory. In 1864 he defended his master's thesis. In the spring of 1869, he defended his doctoral dissertation.\nPersonal life.\nMarkovnikov married Lyubov Dmitrievna Rychkova. They had two sons, Vladimir, a politician and Nikolai, an architect.\nCareer.\nAfter a conflict with that university, Markovnikov was appointed professor at the University of Odessa in 1871 and, two years later, at the University of Moscow, where he stayed the rest of his career. He was elected as a member to the American Philosophical Society in 1901.\nWork.\nMarkovnikov is best known for Markovnikov's rule, elucidated in 1869 to describe addition reactions of H-X (where 'X' represents a halogen) to alkenes. According to this rule, the nucleophilic X- binds to the carbon (C) atom with fewer hydrogen atoms, while the proton binds to the carbon atom with more hydrogen atoms bonded to it. Thus, hydrogen chloride (HCl) reacts with propene, CH3-CH=CH2 to produce 2-chloropropane CH3CHClCH3 rather than the isomeric 1-chloropropane CH3CH2CH2Cl. The rule is useful in predicting the molecular structures of products of addition reactions. Why hydrogen bromide exhibited both Markovnikov as well as reversed-order, or anti-Markovnikov, addition, however, was not understood until Morris S. Kharasch offered an explanation in 1933. It is also called The Peroxide effect sometimes.\nHughes has discussed the reasons for Markovnikov's lack of recognition during his lifetime. Although he published mostly in Russian which was not understood by most Western European chemists, the 1870 article in which he first stated his rule was written in German. However the rule was included in a 4-page addendum to a 26-page article on isomeric butyric acids, and based on very slight experimental evidence even by the standards of the time. Hughes concludes that the rule was an inspired guess, unjustified by the evidence of the time, but which turned out later to be correct (in most cases). A more recent assessment, based on a reading of Markovnikov's Magistr Khimii and Doktor Khimii dissertations, contradicts this view, and points out that Markovnikov's Rule arises logically from his dissertations.\nMarkovnikov also contributed to organic chemistry by finding carbon rings with more than six carbon atoms, a ring with four carbon atoms in 1879, and a ring with seven in 1889.\nMarkovnikov also showed that butyric and isobutyric acids have the same chemical formula (C4H8O2) but different structures; i.e., they are isomers.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32556", "revid": "44933079", "url": "https://en.wikipedia.org/wiki?curid=32556", "title": "Valkyrie (magazine)", "text": "Valkyrie is a UK role-playing magazine that was published between 1994 and 2003.\nPublication history.\nThe magazine was started in 1994. Angus Abranson was one of the people involved in the creation of \"Valkyrie\", and continued to report news for the magazine while he was working at Leisure Games. It was published by Partisan Press and edited originally by David \"Stig\" Renton (original editor of \"Role Player Independent\") and then taken over by Jay Forster. Renton held the post from 1994 to 1998 and Forster from 1999 to 2003.\nSome claimed that it was the successor to \"White Dwarf\" amongst the UK role-playing community, with numerous contributors from across the hobby, including Phil Masters and Marcus Rowland.\nThe magazine was resurrected as a quarterly with issue 19 and ran for several years before ceasing publication with issue 28. It folded in 2003.\nOn 15 September 2019, the first edition of an all new \"Valkyrie\" magazine was launched in 2019, but its ownership, contents, style and target market are completely different. In other words, apart from the name, the new magazine has nothing to do with the original.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32557", "revid": "50885723", "url": "https://en.wikipedia.org/wiki?curid=32557", "title": "Vulture", "text": "Common name for a type of bird\nA vulture is a bird of prey that scavenges on carrion. There are 23 extant species of vulture (including condors). Old World vultures include 16 living species native to Europe, Africa, and Asia; New World vultures are restricted to North and South America and consist of seven species.\nA particular characteristic of many vultures is a bald, unfeathered head. This bare skin is thought to keep the head clean when feeding, and also plays an important role in thermoregulation.\nVultures have been observed to hunch their bodies and tuck in their heads in the cold, and open their wings and stretch their necks in the heat. They also urinate on themselves as a means of cooling their bodies.\nA group of vultures in flight is called a \"kettle\", while the term \"committee\" refers to a group of vultures resting on the ground or in trees. A group of vultures that are feeding is termed a \"wake\".\nTaxonomy.\nAlthough New World vultures and Old World vultures share many resemblances, they are not very closely related. Rather, they share resemblance because of convergent evolution.\nEarly naturalists placed all vultures under one single biological group. Carl Linnaeus had assigned both Old World vultures and New World vultures in a \"Vultur\" genus, even including the harpy eagle. Soon anatomists split Old and New World vultures, with New World vultures being placed in a new suborder, \"Cathartae\", later renamed \"Cathartidae\" as per the Rules of Nomenclature (from Greek: \"carthartes\", meaning \"purifier\") by French ornithologist Fr\u00e9d\u00e9ric de Lafresnaye. The suborder was later recognised as a family, rather than a suborder.\nIn the late 20th century, some ornithologists argued that New World vultures are more closely related to storks on the basis of karyotype, morphological, and behavioral data. Thus some authorities placed them in Ciconiiformes with storks and herons; Sibley and Monroe (1990) even considered them a subfamily of the storks. This was criticized, and an early DNA sequence study was based on erroneous data and subsequently retracted. There was then an attempt to raise the New World vultures to the rank of an independent order, Cathartiformes, not closely associated with either the birds of prey or the storks and herons.\nOld World.\nThe Old World vultures found in Africa, Asia, and Europe belong to the family Accipitridae, which also includes eagles, kites, buzzards, and hawks. Old World vultures find carcasses exclusively by sight.\nThe 16 species in 9 genera are:\nNew World.\nThe New World vultures and condors found in warm and temperate areas of the Americas belong to the family Cathartidae. Recent DNA evidence suggests that they should be included within order Accipitriformes along with birds of prey including hawks, eagles, and Old World vultures . Several species have a good sense of smell, unusual for raptors, and are able to smell dead animals from great heights, up to a mile away. The seven species are:\nFeeding.\nVultures are scavengers, meaning that they eat dead animals. Outside of the oceans, vultures are the only known obligate scavengers. They rarely attack healthy animals, but may kill the wounded or sick. When a carcass has too thick a hide for its beak to open, it waits for a larger scavenger to eat first. Vast numbers have been seen upon battlefields. They gorge themselves when prey is abundant, until their crops bulge, and sit, sleepy or half torpid, to digest their food. These birds do not carry food to their young in their talons but disgorge it from their crops. The mountain-dwelling bearded vulture is the only vertebrate to specialize in eating bones; it carries bones to the nest for the young, and hunts some live prey.\nVultures are of great value as scavengers, especially in hot regions. Vulture stomach acid is exceptionally corrosive (pH=1.0), allowing them to safely digest putrid carcasses infected with botulinum toxin, hog cholera virus, and anthrax bacteria that would be lethal to other scavengers. New World vultures often vomit when threatened or approached. Contrary to some accounts, they do not \"projectile vomit\" on their attacker in defense, but to lighten their stomach load to ease take-off. The vomited meal residue may distract a predator, allowing the bird to escape.\nIn various regions of Africa, the dynamic interplay of vultures and predators such as lions, cheetahs, hyenas, and jackals significantly influences the continent's food web. These avian scavengers actively engage in competition with these predatory animals for sustenance, meticulously tracking their hunting activities.\nTraditionally, vultures are known to bide their time, patiently observing from a distance or high in the sky as predators bring down their prey and commence feeding. Once these formidable predators have satiated their hunger and moved away from their kills, the vultures swoop in, making the most of the leftovers.\nNew research has revealed that these birds can, in addition to sight, respond to auditory cues indicative of potential foraging opportunities.\nInteraction between vultures and predators is not strictly sequential or one-sided. Vultures, being opportunistic creatures, will often engage in risky behavior if a prime opportunity arises. Sometimes, when the predator numbers are low or distracted, these large birds might move in earlier, attempting to snatch morsels from the kill before the predators have fully vacated the scene. This daring strategy, while high-risk, underscores the fierce competition and survival instincts prevalent in the harsh realities of the African wild.\nNew World vultures also urinate straight down their legs; the uric acid kills bacteria accumulated from walking through carcasses, and also acts as evaporative cooling.\nConservation status.\nVultures in south Asia, mainly in India and Nepal, have declined dramatically since the early 1990s. It has been found that this decline was caused by residues of the drug diclofenac in livestock carcasses. The government of India has taken very late cognizance of this fact and has banned the drug for animals. It may take decades for vultures to come back to their earlier population level, if ever. Without them to pick corpses clean, feral dogs have multiplied, feeding on the carrion, and age-old practices like the sky burials of the Parsees are coming to an end, permanently reducing the supply of corpses. The same problem is also seen in Nepal where the government has taken some late steps to conserve the remaining vultures.\nThe vulture population is threatened across Africa and Eurasia. There are many human activities that threaten vultures such as poisoning and collisions with wind turbines. In central Africa there have been efforts to conserve the remaining vultures and bring their population numbers back up. The decline is largely due to the trade in vulture meat, \"it is estimated that more than of wild animal meat is traded\" and vultures take up a large percentage of this bushmeat due to the demand in the fetish market. The substantial drop in vulture populations in the continent of Africa is also said to be the result of both intentional and unintentional poisoning, with one study finding it to be the cause of 61% of the vulture deaths recorded.\nA recent study in 2016, reported that \"of the 22 vulture species, nine are critically endangered, three are endangered, four are near threatened, and six are least concern\".\nThe conservation status of vultures is of particular concern to humans. For example, the decline of vulture populations can lead to increased disease transmission and resource damage, through increased populations of disease vector and pest animal populations that scavenge carcasses opportunistically. Vultures control these pests and disease vectors indirectly through competition for carcasses.\nOn 20 June 2019, the corpses of 468 white-backed vultures, 17 white-headed vultures, 28 hooded vultures, 14 lappet-faced vultures and 10 cape vultures, altogether 537 vultures, besides 2 tawny eagles, were found in northern Botswana. It is suspected that they died after eating the corpses of three elephants that were poisoned by poachers, possibly to avoid detection by the birds, which help rangers to track poaching activity by circling above dead animals.\nIn myth and culture.\nIn Ancient Egyptian art, Nekhbet, a mythological goddess and patron of both the city of Nekheb and Upper Egypt was depicted as a vulture. Alan Gardiner identified the species that was used in divine iconography as a griffon vulture. Arielle P. Kozloff argues that the vultures in New Kingdom art, with their blue-tipped beaks and loose skin, better resemble the lappet-faced vulture. Many Great Royal Wives wore vulture crowns - a symbol of protection from the goddess Nekhbet.\nAncient Egyptians believed that all vultures were female and were spontaneously born from eggs without the intervention of a male, and therefore linked the birds to purity and motherhood, but also the eternal cycle of death and rebirth for their ability to transform the \"death\" they feed on \u2013 i.e. carrion and waste \u2013 into life.\nIn Pre-Columbian times, vultures were appreciated as extraordinary beings and had high iconographic status. They appear in many Mesoamerican myths, legends, and fables from civilizations such as the Maya and Aztecs, some depicting them negatively, others positively.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32558", "revid": "47211972", "url": "https://en.wikipedia.org/wiki?curid=32558", "title": "Volleyball", "text": "Team sport\nVolleyball is a team sport in which two teams of six players are separated by a net. Each team tries to score points by grounding a ball on the other team's court under organized rules. It has been a part of the official program of the Summer Olympic Games since Tokyo 1964. Beach volleyball was introduced to the program at the Atlanta 1996 Summer Olympics. The adapted version of volleyball at the Summer Paralympic Games is sitting volleyball.\nBasic play.\nThe complete set of rules is extensive, but play essentially proceeds as follows: a player on one of the teams begins a 'rally' by serving the ball (tossing or releasing it and then hitting it with a hand or arm), from behind the back boundary line of the court, over the net, and into the receiving team's court. The receiving team must not let the ball be grounded within their court. The team may touch the ball up to three times to return the ball to the other side of the court, but individual players may not touch the ball twice consecutively. Typically, the first two touches are used to set up for an attack. An attack is an attempt to direct the ball back over the net in such a way that the team receiving the ball is unable to pass the ball and continue the rally, thus, losing the point. The team that wins the rally is awarded a point and serves the ball to start the next rally. A few of the most common faults include:\nThe ball is usually played with the hands or arms, but players can legally strike or push (short contact) the ball with any part of the body.\nA number of consistent techniques have evolved in volleyball, including \"spiking\" and \"blocking\" (because those plays are made above the top of the net, the vertical jump is an athletic skill emphasized in the sport) as well as \"passing\", \"setting\", and specialized player positions. Offensive and defensive structures are also key plays.\nHistory.\nOrigins.\nWilliam G. Morgan invented the sport in 1895 while he was the YMCA physical education director in Holyoke, Massachusetts. Because he originally derived the game from badminton, he initially named the sport \"mintonette\". He was a one-time student of basketball inventor James Naismith and invented the game for his clients at the YMCA, most of whom were middle-aged businessmen for whom the physical demands of basketball were too great.\nThe first rules, written down by Morgan, called for a net high, a court, and any number of players. A match was composed of nine innings with three serves for each team in each inning, and no limit to the number of ball contacts for each team before sending the ball to the opponents' court. In case of a serving error, a second try was allowed. Hitting the ball into the net was considered a foul (with loss of the point or a side-out)\u2014except in the case of the first-try serve.\nAfter an observer, Alfred Halstead, noticed the volleying nature of the game at its first exhibition match in 1896, played at the International YMCA Training School (now called Springfield College), the game quickly became known as \"volleyball\" (it was originally spelled as two words: \"\"volley ball\"\"). Volleyball rules were slightly modified by the International YMCA Training School and the game spread around the country to various YMCAs.\nIn the early 1900s Spalding, through its publishing company American Sports Publishing Company, produced books with complete instruction and rules for the sport.\nRefinements and later developments.\nThe first official ball used in volleyball is disputed; some sources say Spalding created the first official ball in 1896, while others claim it was created in 1900. The rules evolved over time: in 1916, in the Philippines, the skill and power of the set and spike had been introduced, and four years later a \"three hits\" rule and a rule against hitting from the back row were established. In 1917, the game was changed from requiring 21 points to win to a smaller 15 points to win. In 1919, about 16,000 volleyballs were distributed by the American Expeditionary Forces to their troops and allies, which sparked the growth of volleyball in new countries.\nLike basketball, volleyball spread quickly due to its simplicity and promotion by the YMCA and YWCA. The first country outside the United States to adopt volleyball was Canada in 1900. During and after World War I, the presence of YMCA instructors in American forces led to the spread of volleyball in Europe, where clubs were established in France as well as several Soviet nations. An international federation, the F\u00e9d\u00e9ration Internationale de Volleyball (FIVB), was founded in 1947, and the first World Championships were held in 1949 for men and 1952 for women. The sport is now popular in Brazil, in Europe, where especially Italy, the Netherlands, and Eastern Europe have been major forces since the late 1980s, in Russia, in other countries, including China and the rest of Asia, and in the United States.\nBeach volleyball, a variation of the game played on sand and with only two players per team, became a FIVB-endorsed variation in 1987 and was added to the Olympic program at the 1996 Summer Olympics. Created by William G. Morgan in 1895, beach volleyball is a game of volleyball played by two teams of two players on an outdoor sandy court. Volleyball is also a sport at the Paralympics managed by World ParaVolley.\nNudists were early adopters of the game with regular organized play in clubs as early as the late 1920s. By the 1960s, a volleyball court had become standard in almost all nudist/naturist clubs. Recently a debate has arisen within the sport regarding the inclusion of transgender players. With transgender athletes including Tiffany Abreu joining professional volleyball teams alongside other non-transgender teammates, many professionals, sports analysts, and fans of volleyball either express concerns about the legitimacy and fairness of having transgender players on a team or convey support for the transgender players.\nVolleyball in the Olympics.\nVolleyball has been part of the Summer Olympics program for both men and women consistently since 1964.\nRules of the game.\nCourt dimensions.\nA volleyball court is , divided into equal square halves by a net with a width of . The top of the net is above the center of the court for men's competition, and for women's competition, varied for veterans and junior competitions.\nTypically in beach volleyball there is a playing area and a free zone area. The dimensions are 52\u20196\u201d x 26\u20193\u201d (including the free zone), and a minimum of 9\u201910 wide. The court includes 3 lines: net line, side line, and end line. In Beach volleyball scoring is similar to regular volleyball. 3 matches are being played.\nThe minimum height clearance for indoor volleyball courts is , although a clearance of is recommended.\nA line from and parallel to the net is considered the \"attack line\". This \"3 meter\" (or \"10-foot\") line divides the court into \"back row\" and \"front row\" areas and the back court and front court. These are in turn divided into 3 areas each: these are numbered as follows, starting from area \"1\", which is the position of the serving player:\nAfter a team gains the serve (also known as siding out), its members must rotate in a clockwise direction, with the player previously in area \"2\" moving to area \"1\" and so on, with the player from area \"1\" moving to area \"6\". Each player rotates only one time after the team gains possession of the service; the next time each player rotates will be after the other team wins possession of the ball and loses the point.\nThe team courts are surrounded by an area called the free zone, which is at least 3 meters wide and may be entered and played within by the players after the service of the ball. All lines marking the boundaries of the team court and the attack zone are drawn or painted within the dimensions of the area and are therefore part of the court or zone. If a ball touches a line, it is considered \"in.\" An antenna is placed on each side of the net, perpendicular to the sideline, serving as a vertical extension of the side boundary of the court. A ball passing over the net must pass completely between the antennae (or their theoretical extensions to the ceiling) without contacting them.\nThe ball.\nFIVB regulations state that the ball must be spherical, made of leather or synthetic leather, have a circumference of , a weight of and an interior air pressure of 0.30\u20130.325\u00a0kg/cm2 (4.26 to 4.61 psi; 294.3\nto 318.82 mbar or hPa). Other governing bodies have similar regulations.\nGameplay.\nEach team consists of six players. To get play started, a team is chosen to serve by coin toss. A player from the serving team throws the ball into the air and attempts to hit the ball so it passes over the net on a course such that it will land in the opposing team's court (the \"serve\"). The opposing team must use a combination of no more than three contacts with the volleyball to return the ball to the opponent's side of the net. These contacts usually consist first of the \"bump\" or \"pass\" so that the ball's trajectory is aimed towards the player designated as the \"setter\"; second of the \"set\" (usually an over-hand pass using wrists to push finger-tips at the ball) by the setter so that the ball's trajectory is aimed towards a spot where one of the players designated as an \"attacker\" can hit it, and third by the \"attacker\" who \"spikes\" (jumping, raising one arm above the head and hitting the ball so it will move quickly down to the ground on the opponent's court) to return the ball over the net. The team with possession of the ball that is trying to attack the ball as described is said to be on \"offence\".\nThe team on \"defence\" attempts to prevent the attacker from directing the ball into their court: players at the net jump and reach above the top (and if possible, across the plane) of the net to \"block\" the attacked ball. If the ball is hit around, above, or through the block, the defensive players arranged in the rest of the court attempt to control the ball with a \"dig\" (usually a fore-arm pass of a hard-driven ball). After a successful dig, the team transitions to offence.\nThe game continues in this manner, rallying back and forth until the ball touches the court within the boundaries or until an error is made. The most frequent errors that are made are either to fail to return the ball over the net within the allowed three touches, or to cause the ball to land outside the court. A ball is \"in\" if any part of it touches the inside of a team's court or a sideline or end-line, and a strong spike may compress the ball enough when it lands that a ball which at first appears to be going out may instead be in. Players may travel well outside the court to play a ball that has gone over a sideline or end-line in the air. A standard competitive volleyball match is played in a best-of-five sets format and typically goes on for about 90 minutes.\nOther common errors include a player touching the ball twice in succession, a player catching the ball, a player touching the net while attempting to play the ball, or a player penetrating under the net into the opponent's court. There are a large number of other errors specified in the rules, although most of them are infrequent occurrences. These errors include back-row or libero players spiking the ball or blocking (back-row players may spike the ball if they jump from behind the attack line), players not being in the correct position when the ball is served, attacking the serve in the front court and above the height of the net, using another player as a source of support to reach the ball, stepping over the back boundary line when serving, taking more than 8 seconds to serve, or playing the ball when it is above the opponent's court.\nScoring.\nA point is scored when the ball contacts the floor within the court boundaries or when an error is made: when the ball strikes one team's side of the court, the other team gains a point; and when an error is made, the team that did not make the error is awarded a point, in either case paying no regard to whether they served the ball or not. If any part of the ball hits the line, the ball is counted as in the court. The team that won the point serves for the next point. If the team which won the point served in the previous point, the same player serves again. If the team that won the point did not serve the previous point, the players of the team acquiring the serve rotate their position on the court in a clockwise manner. The game continues, with the first team to score 25 points by a two-point margin awarded the set. Matches are best-of-five sets and the fifth set, if necessary, is usually played to 15 points. (Scoring differs between leagues, tournaments, and levels; high schools sometimes play best-of-three to 25; in the NCAA matches are played best-of-five to 25 as of the 2008 season.)\nBefore 1999, points could be scored only when a team had the serve (\"side-out scoring\") and all sets went up to only 15 points. The FIVB changed the rules in 1999 (with the changes being compulsory in 2000) to use the current scoring system (formerly known as \"rally point system\"), primarily to make the length of the match more predictable and to make the game more spectator- and television-friendly. The final year of side-out scoring at the NCAA Division I Women's Volleyball Championship was 2000. Rally point scoring debuted in 2001, and games were played to 30 points through 2007. For the 2008 season, games were renamed \"sets\" and reduced to 25 points to win. Most high schools in the U.S. changed to rally scoring in 2003, and several states implemented it the previous year on an experimental basis.\nLibero.\nThe libero player was introduced internationally in 1998, and made its debut for NCAA competition in 2002. The libero is a player specialized in defensive skills: the libero must wear a contrasting jersey color from their teammates and cannot block or attack the ball when it is entirely above net height. When the ball is not in play, the libero can replace any back-row player, without prior notice to the officials. This replacement does not count against the substitution limit each team is allowed per set, although the libero may be replaced only by the player whom he or she replaced. Most U.S. high schools added the libero position from 2003 to 2005.\nThe modern-day libero often takes on the role of a second setter. When the setter digs the ball, the libero is typically responsible for the second ball and sets to the front-row attacker. The libero may function as a setter only under certain restrictions. To make an overhand set, the libero must be standing behind (and not stepping on) the 3-meter line; otherwise, the ball cannot be attacked above the net in front of the 3-meter line. An underhand pass is allowed from any part of the court. The libero is generally the most skilled defensive player on the team. Additionally, there is a libero tracking sheet, where the referees or officiating team keep track of whom the libero substitutes in and out for.\nUnder FIVB rules, a libero is not allowed to serve. By contrast, a libero can serve in NCAA volleyball, but only in a specific rotation. That is, the libero can only serve for one person, not for all of the people for whom he or she goes in. That rule change was implemented in 2004 and applied to high school and junior high play soon after.\nUnder FIVB rules, each team can designate two liberos at the beginning of play, only one of whom can be on the court at any time, and each libero can serve in one specific rotation. This rule was implemented in NCAA women's volleyball, effective with the fall 2024 season.\nRule changes.\nRule changes enacted in 2000 include allowing serves in which the ball touches the net, as long as it goes over the net into the opponents' court. Also, the service area was expanded to allow players to serve from anywhere behind the end line but still within the theoretical extension of the sidelines. Other changes were made to lighten up calls on faults for carries and double-touches, such as allowing multiple contacts by a single player (\"double-hits\") on a team's first contact provided that they are a part of a single play on the ball.\nIn 2008, the NCAA changed the minimum number of points needed to win any of the first four sets from 30 to 25 for women's volleyball (men's volleyball remained at 30 for another three years, switching to 25 in 2011). If a fifth (deciding) set is reached, the minimum required score remains at 15. In addition, the word \"game\" is now referred to as \"set\".\nThe \"Official Volleyball Rules\" are prepared and updated every few years by the FIVB's Rules of the Game and Refereeing Commission. The latest edition is usually available on the FIVB's website.\nSkills.\nCompetitive teams master six basic skills: serve, pass, set, attack, block and dig. Each of the skills consists of a number of specific techniques which have been introduced over the years and are now considered standard practice in high-level volleyball.\nServe.\nA player stands behind the inline and serves the ball in an attempt to drive it into the opponent's court. The main objective is to make it land inside the court; it is also desirable to set the ball's direction, speed and acceleration so that it becomes difficult for the receiver to handle it properly. A serve is called an \"ace\" when the ball either lands directly onto the opponent's court or the first opponent to touch the ball is unable to volley it (hit it upwards enough for a teammate to continue).\nIn contemporary volleyball, many types of serves are employed:\nPass.\nAlso called reception, the pass is the attempt by a team to properly handle the opponent's serve or any form of attack. Proper handling includes not only preventing the ball from touching the court but also making it reach the position where the setter is standing quickly and precisely.\nThe skill of passing involves fundamentally two specific techniques: underarm pass, or bump, where the ball touches the inside part of the joined forearms or platform, at waistline; and overhand pass, where it is handled with the fingertips, like a set, above the head. Either are acceptable in professional and beach volleyball; however, there are much tighter regulations on the overhand pass in beach volleyball. When a player passes a ball to their setter, it is ideal that the ball has relatively little spin to make it easier for the setter.\nSet.\nThe set is usually the second contact that a team makes with the ball. The main goal of setting is to put the ball in the air in such a way that it can be driven by an attack into the opponent's court. The setter coordinates the offensive movements of a team, and is the player who ultimately decides which player will attack the ball.\nAs with passing, one can distinguish between an overhand set and a bump set. Since the former allows for more control over the speed and direction of the ball, the bump is used only when the ball is too low to be properly handled with the fingertips or in beach volleyball, where rules regulating overhand setting are more stringent. In the case of a set, one also refers to a front set or back set, indicating whether the ball is passed in the direction the setter is facing or behind them. There is also a jump set, used when the ball is too close to the net. In this case, the setter usually jumps off their right foot straight up to avoid going into the net. The setter typically stands about two-thirds of the way from the left to the right side of the net and faces left (the larger portion of the net visible to the setter).\nSometimes a setter refrains from raising the ball for a teammate to perform an attack and tries to play it directly onto the opponent's court. This movement is called a \"dump\". This can only be performed when the setter is in the front row, otherwise it constitutes an illegal back court attack. The most common dumps are to 'throw' the ball behind the setter or in front of the setter to zones 2 and 4. More experienced setters toss the ball into the deep corners or spike the ball on the second hit.\nAs with a set or an overhand pass, the setter/passer must be careful to touch the ball with both hands at the same time. If one hand is noticeably late to touch the ball this could result in a less effective set, as well as the referee calling a 'double hit' and giving the point to the opposing team.\nAttack.\nThe attack, also known as the \"spike\", is usually the third contact a team makes with the ball. The object of attacking is to handle the ball so that it lands on the opponent's court and cannot be defended. A player makes a series of steps (the \"approach\"), jumps, and swings at the ball.\nIdeally, the contact with the ball is made at the apex of the hitter's jump. At the moment of contact, the hitter's arm is fully extended above their head and slightly forward, making the highest possible contact while maintaining the ability to deliver a powerful hit. The hitter uses arm swing, wrist snap, and a rapid forward contraction of the entire body to drive the ball. A 'bounce' is a slang term for a very hard/loud spike that follows an almost straight trajectory steeply downward into the opponent's court and bounces very high into the air. A \"kill\" is the slang term for an attack that is not returned by the other team thus resulting in a point.\nContemporary volleyball comprises a number of attacking techniques:\nBlock.\nBlocking refers to the actions taken by players standing at the net to stop or alter an opponent's attack. A block which is aimed at completely stopping an attack, thus making the ball remain in the opponent's court, is called an offensive block. A well-executed offensive block is performed by jumping and reaching to penetrate with one's arms and hands over the net and into the opponent's area. It requires anticipating the direction the ball will go once the attack takes place. It may also require calculating the best footwork to executing the \"perfect\" block.\nThe jump should be timed so as to intercept the ball's trajectory prior to it crossing over the plane of the net. Palms are held deflected downward roughly 45\u201360 degrees toward the interior of the opponents' court. A \"roof\" is a spectacular offensive block that redirects the power and speed of the attack straight down to the attacker's floor as if the attacker hit the ball into the underside of a peaked house roof. By contrast, it is called a defensive, or \"soft\" block if the goal is to control and deflect the hard-driven ball up so that it slows down and becomes easier to defend. A well-executed soft-block is performed by jumping and placing one's hands above the net with no penetration into the opponent's court and with the palms up and fingers pointing backwards.\nBlocking is also classified according to the number of players involved. Thus, there are single (or solo), double, and triple blocks.\nSuccessful blocking does not always result in a \"roof\" and many times does not even touch the ball. While it is obvious that a block was a success when the attacker is roofed, a block that consistently forces the attacker away from their 'power' or preferred attack into a more easily controlled shot by the defence is also a highly successful block. At the same time, the block position influences the positions where other defenders place themselves while opponent hitters are spiking.\nDig.\nDigging is the ability to prevent the ball from touching one's court after a spike or attack, particularly a ball that is nearly touching the ground. In many aspects, this skill is similar to passing, or bumping: overhand dig and bump are also used to distinguish between defensive actions taken with fingertips or with joined arms. It varies from passing, however, in that it is a much more reflex-based skill, especially at the higher levels. It is especially important while digging for players to stay on their toes; several players choose to employ a split step to make sure they are ready to move in any direction.\nSome specific techniques are more common in digging than in passing. A player may sometimes perform a \"dive\", i.e., throw their body in the air with a forward movement in an attempt to save the ball, and land on their chest. When the player also slides their hand under a ball which is almost touching the court it is called a \"pancake\". The pancake is frequently used in indoor volleyball, but rarely if ever in beach volleyball because the uneven and yielding nature of the sand court limits the chances that the ball will make good, clean contact with the hand. When used correctly, it is one of the more spectacular defensive volleyball plays.\nSometimes a player may also be forced to drop their body quickly to the floor to save the ball. In this situation, the player makes use of a specific rolling technique to minimize the chances of injuries.\nTeam play.\nVolleyball is essentially a game of transition from one of the above skills to the next, with choreographed team movement between plays on the ball. The team's movements are determined by the teams chosen serve receive system, offensive system, coverage system, and defensive system.\nThe serve-receive system is the formation used by the receiving team to attempt to pass the ball to the designated setter. Systems can consist of 5 receivers, 4 receivers, 3 receivers, and in some cases 2 receivers. The most popular formation at higher levels is a 3 receiver formation consisting of two left sides and a libero receiving every rotation. This allows middles and right sides to become more specialized at hitting and blocking. Offensive systems are the formations used by the offence to attempt to ground the ball into the opposing court (or otherwise score points). Formations often include designated player positions with skill specialization (see \"Player specialization\", below). Popular formations include the 4\u20132, 6\u20132, and 5-1 systems (see \"Formations\", below). There are also several different attacking schemes teams can use to keep the opposing defence off balance.\nCoverage systems are the formations used by the offence to protect their court in the case of a blocked attack. Executed by the 5 offensive players not directly attacking the ball, players move to assigned positions around the attacker to dig up any ball that deflects off the block back into their own court. Popular formations include the 2-3 system and the 1-2-2 system. In lieu of a system, some teams just use a random coverage with the players nearest the hitter.\nDefensive systems are formations used by the defense to prevent the ball from being grounded in their court by the opposing team. These systems outline which players are responsible for specific areas of the court depending on where the opposing team is attacking from. Popular systems include the 6-Up, 6-Back-Deep, and 6-Back-Slide defenses. Teams can also employ various blocking schemes to disrupt the opposing team\u2019s offense. When one player is ready to serve, some teams line up their other five players in a screen to obscure the receiving team\u2019s view. This action is only illegal if the server uses the screen, so the call is left to the referee\u2019s discretion based on the screen\u2019s impact on the receiving team\u2019s ability to pass the ball. The most common screening style involves a W formation designed to take up as much horizontal space as possible.\nStrategy.\nPlayer specialization.\nThere are five positions filled on every volleyball team at the elite level: setter, outside hitter (left-side hitter), middle hitter (middle blocker), opposite hitter (right-side hitter) and libero / defensive specialist. Each of the positions plays a specific, key role in winning a volleyball match.\nAt some levels where substitutions are unlimited, teams will make use of a defensive specialist in place of or in addition to a libero. This position does not have unique rules like the libero position, instead, these players are used to substitute out a poor back row defender using regular substitution rules. A defensive specialist is often used if you have a particularly poor back court defender in right side or left side, but your team is already using a libero to take out your middles. Most often, the situation involves a team using a right-side player with a big block who must be subbed out in the back row because they are not able to effectively play backcourt defence. Similarly, teams might use a serving specialist to sub out a poor server.\nFormations.\nThe three standard volleyball formations are known as \"4\u20132\", \"6\u20132\" and \"5\u20131\", which refers to the number of hitters and setters respectively. 4\u20132 is a basic formation used only in beginners' play, while 5\u20131 is by far the most common formation in high-level play.\n4\u20132.\nThe 4\u20132 formation has four hitters and two setters. The setters usually set from the middle front or right front position. The team will, therefore, have two front-row attackers at all times. In the international 4\u20132, the setters set from the right front position. The international 4\u20132 translates more easily into other forms of offence. The setters line up opposite each other in the rotation. The typical lineup has two outside hitters. By aligning like positions opposite themselves in the rotation, there will always be one of each position in the front and back rows. After service, the players in the front row move into their assigned positions, so that the setter is always in the middle front. Alternatively, the setter moves into the right front and has both a middle and an outside attacker; the disadvantage here lies in the lack of an offside hitter, allowing one of the other team's blockers to \"cheat in\" on a middle block.\nThe clear disadvantage with this offensive formation is that there are only two attackers, leaving a team with fewer offensive weapons.\nAnother aspect is to see the setter as an attacking force, albeit a weakened force, because when the setter is in the frontcourt they are able to 'tip' or 'dump', so when the ball is close to the net on the second touch, the setter may opt to hit the ball over with one hand. This means that the blocker who would otherwise not have to block the setter is engaged and may allow one of the hitters to have an easier attack.\n6\u20132.\nIn the 6\u20132 formation, a player always comes forward from the back row to set. The three front row players are all in attacking positions. As a result all six players act as hitters at one time or another, while two can act as setters. So the 6\u20132 formation is now a 4\u20132 system, but the back-row setter penetrates to set. The 6\u20132 lineup thus requires two setters, who line up opposite to each other in the rotation. In addition to the setters, a typical lineup will have two middle hitters and two outside hitters. By aligning like positions opposite themselves in the rotation, there will always be one of each position in the front and back rows. After service, the players in the front row move into their assigned positions.\nThe advantage of the 6\u20132 is that there are always three front-row hitters available, maximizing the offensive possibilities. However, not only does the 6\u20132 require a team to possess two people capable of performing the highly specialized role of setter, it also requires both of those players to be effective offensive hitters when not in the setter position. At the international level, only the Cuban National Women's Team employs this kind of formation. It is also used by NCAA teams in Division III men's play and women's play in all divisions, partially due to the variant rules used which allow more substitutions per set than the 6 allowed in the standard rules\u201412 in matches involving two Division III men's teams and 15 for all women's play.\n5\u20131.\nThe 5\u20131 formation has only one player who assumes setting responsibilities regardless of their position in the rotation. The team will, therefore, have three front-row attackers when the setter is in the back row and only two when the setter is in the front row, for a total of five possible attackers.\nThe player opposite the setter in a 5\u20131 rotation is called the \"opposite hitter\". In general, opposite hitters do not pass; they stand behind their teammates when the opponent is serving. The opposite hitter may be used as a third attack option (back-row attack) when the setter is in the front row: this is the normal option used to increase the attack capabilities of modern volleyball teams. Normally the opposite hitter is the most technically skilled hitter of the team. Back-row attacks generally come from the back-right position, known as zone 1, but are increasingly performed from back-centre in high-level play.\nThe big advantage of the system is that the setter always has 3 hitters with which to vary sets. If the setter performs well, the opponent's middle blocker may not have enough time to block with the outside blocker, increasing the chance for the attacking team to make a point.\nThere is another advantage, the same as that of a 4\u20132 formation: as a front-row player the setter is allowed to jump and \"dump\" the ball onto the opponent's side. Thus the setter can confuse the opponent's blocking players; they have the option to jump and dump or set to one of the hitters. A good setter knows and they are able to jump to dump or to set for a quick hit as well as when setting outside, thus they are able to confuse the opponent.\nThe 5\u20131 offence is a mix of 6\u20132 and 4\u20132: when the setter is in the front row, the offense looks like a 4\u20132; when the setter is in the back row, the offense looks like a 6\u20132.\nVariations and related games.\nThere are many variations on the basic rules of volleyball. By far the most popular of these is beach volleyball, which is played on sand with two people per team and rivals the main sport in popularity.\nSome games related to volleyball include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32559", "revid": "40151011", "url": "https://en.wikipedia.org/wiki?curid=32559", "title": "Vocative case", "text": "Grammatical case for noun addressed\nIn grammar, the vocative case (abbreviated VOC) is a grammatical case which is used for a noun that identifies a person (animal, object, etc.) being addressed or occasionally for the noun modifiers (determiners, adjectives, participles, and numerals) of that noun. A noun of address is an expression of direct address by which the identity of the party spoken to is set forth expressly within a sentence. For example, in the sentence \"I don't know, John,\" \"John\" is a noun of address that indicates the party being addressed, as opposed to the sentence \"I don't know John\", in which \"John\" is the direct object of the verb \"know\".\nHistorically, the vocative case was an element of the Indo-European case system and existed in Latin, Sanskrit, and Ancient Greek. In many modern Indo-European languages (English, Spanish, etc.) the vocative case has been absorbed by the nominative, but others still distinguish it, including the Baltic languages, some Celtic languages and most Slavic languages. Some linguists, such as Albert Thumb, argue that the vocative form is not a case but a special form of nouns not belonging to any case, as nouns of address are not related syntactically to other words in sentences. Pronouns usually lack vocative forms.\nIndo-European languages.\nComparison.\nDistinct vocative forms are assumed to have existed in all early Indo-European languages and survive in some. Here is, for example, the Indo-European word for \"wolf\" in various languages:\nThe elements separated with hyphens denote the stem, the so-called thematic vowel of the case and the actual suffix. In Latin, for example, the nominative case is and the vocative case is , but the accusative case is . The asterisks before the Proto-Indo-European words means that they are theoretical reconstructions and are not attested in a written source. The symbol \u25cc\u0329 (vertical line below) indicates a consonant serving as a vowel (it should appear directly below the \"l\" or \"r\" in these examples but may appear after them on some systems from issues of font display). All final consonants were lost in Proto-Slavic, so both the nominative and vocative Old Church Slavonic forms do not have true endings, only reflexes of the old thematic vowels.\nVocative singulars in Slavic languages appear to be irregular as a consequence of the Slavic first palatalization, which caused *k, *g and *x, when followed by an *e (as in the vocative suffix), to become \u010d, \u017e, and \u0161, respectively. Some modern Slavic languages have replaced these forms with a more regular vocative ending, so for example in Czech the usual masculine animate vocative is -e, except for roots ending in velar consonants, where it is now usually -u (e.g. &gt; , but &gt; ). This is an instance of the paradigmatic complexity introduced into Slavic by successive waves of palatalisation, with some languages retaining more complex or irregular paradigms (such as Czech), and others tending towards simplification and regularization (such as Russian, which has lost the vocative as a productive case entirely).\nBaltic languages.\nLithuanian.\nThe vocative is distinct in singular and identical to the nominative in the plural, for all inflected nouns. Nouns with a nominative singular ending in \"-a\" have a vocative singular usually identically written but distinct in accentuation.\nIn Lithuanian, the form that a given noun takes depends on its declension class and, sometimes, on its gender. There have been several changes in history, the last being the \"-ai\" ending formed between the 18th and 19th centuries. The older forms are listed under \"other forms\".\nSome nouns of the e- and a- stems declensions (both proper ones and not) are stressed differently: \"aik\u0161t\u0117\": \"aik\u0161te!\" (\"square\"); \"tauta\": \"tauta!\". In addition, nouns of e-stems have an ablaut of long vowel \u0117 in nominative and short vowel e in vocative. In pronunciation, \u0117 is close-mid vowel , and e is open-mid vowel .\nThe vocative of diminutive nouns with the suffix \"-(i)ukas\" most frequently has no ending: \"broli\u00f9k\" \"brother!\", etc. A less frequent alternative is the ending \"-ai\", which is also slightly dialectal: \"broli\u00f9kai\", etc.\nColloquially, some personal names with a masculine \"-(i)(j)o\" stem and diminutives with the suffixes \"-elis, -\u0117lis\" have an alternative vocative singular form characterized by a zero ending (i.e. the stem alone acts as the voc. sg.): \"Ad\u00f5m\" \"Adam!\" in addition to \"Ad\u00f5mai\", \"M\u00fdkol\" \"Michael!\" in addition to \"M\u00fdkolai\", \"vaik\u1ebdl\" \"kid!\" in addition to \"vaik\u1ebdli\", etc.\nCeltic languages.\nGoidelic languages.\nIrish.\nThe vocative case in Irish operates in a similar fashion to Scottish Gaelic. The principal marker is the vocative particle , which causes lenition of the following initial letter.\nIn the singular there is no special form, except for first declension nouns. These are masculine nouns that end in a broad (non-palatal) consonant, which is made slender (palatal) to build the singular vocative (as well as the singular genitive and plural nominative). Adjectives are also lenited. In many cases this means that (in the singular) masculine vocatives resemble the genitive and feminine vocatives resemble the nominative.\nThe vocative plural is usually the same as the nominative plural except, again, for first declension nouns. In the standard language first declension nouns show the vocative plural by adding . In the spoken dialects the vocative plural is often has the same form as the nominative plural (as with the nouns of other declensions) or the dative plural (e.g. = Men!)\nScottish Gaelic.\nThe vocative case in Scottish Gaelic follows the same basic pattern as Irish. The vocative case causes lenition of the initial consonant of nouns. Lenition changes the initial sound of the word (or name).\nIn addition, masculine nouns are slenderized if possible (that is, in writing, an 'i' is inserted before the final consonant) This also changes the pronunciation of the word.\nAlso, the particle is placed before the noun unless it begins with a vowel (or f followed immediately by a vowel, which becomes silent when lenited). Examples of the use of the vocative personal names (as in Irish):\nThe name \"Hamish\" is just the English spelling of (the vocative of and pronounced ), and thus is actually a Gaelic vocative. Likewise, the name \"Vairi\" is an English spelling of , the vocative for .\nManx.\nThe basic pattern is similar to Irish and Scottish. The vocative is confined to personal names, in which it is common. Foreign names (not of Manx origin) are not used in the vocative. The vocative case causes lenition of the initial consonant of names. It can be used with the particle \"\".\nThe name is actually the Manx vocative of (Mary).\nBrythonic languages.\nWelsh.\nWelsh lacks case declension but marks vocative constructions by lenition of the initial consonant of the word, with no obligatory particle. Despite its use being less common, it is still used in formal address: the common phrase means \"gentlemen and ladies\", with the initial consonant of undergoing a soft mutation; the same is true of (\"[dear] friends\") in which has been lenited. It is often used to draw attention to at public notices orally and written \u2013 teachers will say \"\" (mutation of 'children') and signage such as one right show mutation of 'students' to draw attention to the importance of the notice.\nGermanic languages.\nEnglish.\nThe vocative is not a grammatical case in English. Expressions for which the vocative would be used in languages which have that case, are nominative in English. In translations of languages that use the vocative case, translators have sometimes added the particle \"O\" before the noun, as is often seen in the King James Version of the Bible: for example the Greek \"\u1f40\u03bb\u03b9\u03b3\u03cc\u03c0\u03b9\u03c3\u03c4\u03bf\u03b9\", vocative masculine plural (in Matthew 8:26), is translated \"O ye of little faith\". While it is not strictly archaic, it is sometimes used to \"archaeise\" speech; it is often seen as very formal, and sees use in rhetoric and poetry, or as a comedic device to subvert modern speech. Another example is the recurrent use of the phrase \"O (my) Best Beloved\" by Rudyard Kipling in his \"Just So Stories\". \"O\" may be considered a form of clitic and should not be confused with the interjection \"oh\". However, as the Oxford English Dictionary points out, \"O\" and \"oh\" were originally used interchangeably.\nModern English commonly uses the objective case for nouns of address but sets them off from the rest of the sentences with pauses as interjections, rendered in writing as commas (the vocative comma). Two common examples of nouns of address in English are the phrases \"Mr. President\" and \"Madam Chairwoman\".\nSome traditional texts use \"Jesu\", the Latin vocative form of \"Jesus\". One of the best-known examples is \"Jesu, Joy of Man's Desiring\".\nGerman dialects.\nIn some German dialects, like the Ripuarian dialect of Cologne, it is common to use the (gender-appropriate) article before a person's name. In the vocative phrase then the article is, as in Venetian and Catalan, omitted. Thus, the determiner precedes nouns in all cases except the vocative. Any noun not preceded by an article or other determiner is in the vocative case. It is most often used to address someone or some group of living beings, usually in conjunction with an imperative construct. It can also be used to address dead matter as if the matter could react or to tell something astonishing or just happening such as \"Your nose is dripping.\"\nColognian examples:\nIcelandic.\nThe vocative case generally does not appear in Icelandic, but a few words retain an archaic vocative declension from Latin, such as the word , which is in the vocative. That comes from Latin, as the Latin for Jesus in the nominative is and its vocative is .\nThat is also the case in traditional English (without the accent) (see above):\nThe native words 'son' and 'friend' also sometimes appear in the shortened forms and in vocative phrases. Additionally, adjectives in vocative phrases are always weakly declined, but elsewhere with proper nouns, they would usually be declined strongly:\nNorwegian.\nNouns in Norwegian are not inflected for the vocative case, but adjectives qualifying those nouns are; adjectival adjuncts modifying vocative nouns are inflected for the definite (see: Norwegian language#Adjectives). The definite and plural inflections are in most cases identical, so it is more easily observable with adjectives that inflect for plural and definite differently, e.g. being when definite, but when plural, an instance of suppletion.\nIn several Norwegian dialects, north of an isogloss running from Oslo to Bergen, names in argument position are associated with proprial articles, e.g. gendered pronouns such as 'he' or 'she', which either precede or follow the noun in question. This is not the case when in vocative constructions.\nGreek.\nIn Ancient Greek, the vocative case is usually identical to the nominative case, with the exception of first-declension masculine nouns (ending in -\u03b1\u03c2 or -\u03b7\u03c2), second-declension non-neuter nouns (ending in -\u03bf\u03c2) and third-declension non-neuter nouns.\nIn the first declension, masculines in -\u1fb1\u03c2 have the vocative in -\u1fb1 (\u03bd\u03b5\u1fb1\u03bd\u03af\u1fb1); those in -\u03c4\u03b7\u03c2 have -\u1fb0 (\u03c0\u03bf\u03bb\u1fd6\u03c4\u03b1), all others in -\u03b7\u03c2 have -\u03b7 (\u1f08\u03c4\u03c1\u03b5\u03af\u03b4\u03b7) except names of nations and compounds: \u03a0\u03ad\u03c1\u03c3\u1fb0, \u03a3\u03ba\u03cd\u03b8\u1fb0, \u03b3\u03b5\u03c9-\u03bc\u03ad\u03c4\u03c1\u1fb0, \u03c0\u03b1\u03b9\u03b4\u03bf-\u03c4\u03c1\u03af\u03b2\u1fb0. has a recessive accent vocative . Second-declension masculine and feminine nouns have a regular vocative ending in -\u03b5. Third-declension nouns with one syllable ending in -\u03c2 have a vocative that is identical to the nominative (, night); otherwise, the stem (with necessary alterations, such as dropping final consonants) serves as the vocative (nom. , voc. ; nom. , gen. , voc. ). Irregular vocatives exist as well, such as nom. \u03a3\u03c9\u03ba\u03c1\u03ac\u03c4\u03b7\u03c2, voc. \u03a3\u03ce\u03ba\u03c1\u03b1\u03c4\u03b5\u03c2.\nIn Modern Greek, second-declension masculine nouns still have a vocative ending in -\u03b5. However, the accusative case is often used as a vocative in informal speech for a limited number of nouns, and always used for certain modern Greek person names: \"\" \"Come here, Christos\" instead of \"\". Other nominal declensions use the same form in the vocative as the accusative in formal or informal speech, with the exception of learned \"Katharevousa\" forms that are inherited from Ancient Greek (Demotic , \"Greek man\"), which have the same nominative and vocative forms instead.\nIranian languages.\nKurdish.\nKurdish has a vocative case. For instance, in the dialect of Kurmanji, it is created by adding the suffix at the end of masculine words and the suffix at the end of feminine ones. In the Jafi dialect of Sorani it is created by adding the suffix of at the end of names.\nInstead of the vocative case, forms of address may be created by using the grammatical particles (feminine) and (masculine):\nIndo-Aryan languages.\nHindi-Urdu.\nIn Hindi-Urdu (Hindustani), the vocative case has the same form as the nominative case for all singular nouns except for the singular masculine nouns that terminate in the vowel and for all nouns in their plural forms the vocative case is always distinct from the nominative case. Adjectives in \"Hindi-Urdu\" also have a vocative case form. In the absence of a noun argument, some adjectives decline like masculine nouns that do not end in . The vocative case has many similarities with the oblique case in Hindustani.\nSanskrit.\nIn Sanskrit, the vocative ( ) is morphologically distinct from the nominative only in the singular. In vowel-stem nouns, if there is a in the nominative, it is omitted and the stem vowel may be altered: and become , becomes , and become short and becomes . Consonant-stem nouns have no ending in the vocative:\nSlavic languages.\nOld Church Slavonic.\nOld Church Slavonic has a distinct vocative case for many stems of singular masculine and feminine nouns, otherwise it is identical to the nominative. When different from the nominative, the vocative is simply formed from the nominative by appending either ( : 'slave') or ( : 'fish'), but occasionally ( : 'border', : 'son', : 'physician') and '-i' ( : 'bone', : 'guest', : 'day', : 'stone') appear. Nouns ending with have a vocative ending of ( : 'father', : 'merchant'), likewise nouns ending with assume the vocative suffix ( : 'prince'). This is similar to Greek, Latin, Lithuanian, and Sanskrit, which also employ the \"-e\" suffix in vocatives.\nBulgarian.\nUnlike most other Slavic languages, Bulgarian has lost case marking for nouns. However, Bulgarian preserves vocative forms. Traditional male names usually have a vocative ending.\nMore-recent names and foreign names may have a vocative form but it is rarely used (, instead of simply Richard, sounds unusual or humorous to native speakers).\nVocative phrases like (Mr. Minister) have been almost completely replaced by nominative forms, especially in official writing. Proper nouns usually also have vocative forms, but they are used less frequently. Here are some proper nouns that are frequently used in vocative:\nVocative case forms also normally exist for female given names:\nExcept for forms that end in -, they are considered rude and are normally avoided. For female kinship terms, the vocative is always used:\nCzech.\nIn Czech, the vocative (, or \u2013 'the fifth case') usually differs from the nominative in masculine and feminine nouns in the singular.\nIt is a common dialectal feature of Czech to use the nominative with female names () or when following a title (, , ). It is particularly prevalent in regional dialects, such as those of Moravia, where it has been the only form in use for hundreds of years.\nThe full vocative remains part of the official standard propagated by the Czech government. In the Czech Republic and elsewhere in eastern Europe, language competence is often conflated with adherence to official norms, and the use of the nominative - while common - may therefore be stigmatised.\nPolish.\nIn Polish, the vocative () is formed with feminine nouns usually taking except those where the last consonant is soft e.g. , , , and , which take . Feminine nouns that end with , usually in the suffixes and , as well as feminine nouns that end with a soft consonant, usually words with the suffix , but also irregular words like take the ending . Feminine nouns that end with a hardened consonant e.g. take the ending . Masculine nouns generally follow the complex pattern of the locative case, with the exception of a handful of words such as 'God', 'father' and 'boy'. Neuter nouns and all plural nouns have the same form in the nominative and the vocative:\nThe latter form of the vocative of {{lang|pl|cz\u0142owiek}} {{gloss|human}} is now considered poetical.\nThe nominative is increasingly used instead of the vocative to address people with their proper names. In other contexts the vocative remains prevalent. It is used:\nThe vocative is also often employed in affectionate and endearing contexts such as {{lang|pl|Kocham Ci\u0119, Krzysiu!}} (\"I love you, Chris!\") or {{lang|pl|T\u0119skni\u0119 za Tob\u0105, moja \u017bono}} (\"I miss you, my wife.\"). In addition, the vocative form sometimes takes the place of the nominative in informal conversations: {{lang|pl|J\u00f3ziu przyszed\u0142}} instead of {{lang|pl|J\u00f3zio przyszed\u0142}} (\"Joey's arrived\"). When referring to someone by their first name, the nominative commonly takes the place of the vocative as well: {{lang|pl|Ania, chod\u017a tu!}} instead of {{lang|pl|Aniu, chod\u017a tu!}} (\"Anne, come here!\").\nRussian.\nHistoric vocative.\nThe historic Slavic vocative has been lost in Russian and is now used only in archaic expressions. Several of them, mostly of Old Church Slavonic origin, are common in colloquial Russian: \"{{lang|ru|\u0411\u043e\u0436\u0435!|italic=no}}\" ({{Transliteration|ru|Bo\u017ee}}, vocative of \"{{lang|ru|\u0411\u043e\u0433|italic=no}}\" {{Transliteration|ru|Bog}}, \"God\") and \"{{lang|ru|\u0411\u043e\u0436\u0435 \u043c\u043e\u0439!|italic=no}}\" ({{Transliteration|ru|Bo\u017ee moj}}, \"My God!\"), and \"{{lang|ru|\u0413\u043e\u0441\u043f\u043e\u0434\u0438!|italic=no}}\" ({{Transliteration|ru|Gospodi}}, vocative of \"{{lang|ru|\u0413\u043e\u0441\u043f\u043e\u0434\u044c|italic=no}}\" {{Transliteration|ru|Gospodj}}, \"Lord\"), which can also be expressed as \"{{lang|ru|\u0413\u043e\u0441\u043f\u043e\u0434\u0438 \u0418\u0438\u0441\u0443\u0441\u0435!|italic=no}}\" ({{Transliteration|ru|Gospodi Iisuse!}}, {{Transliteration|ru|Iisuse}} vocative of \"{{lang|ru|\u0418\u0438\u0441\u0443\u0441|italic=no}}\" {{Transliteration|ru|Iisus}}, \"Jesus\"). The vocative is also used in prayers: \"{{lang|ru|\u041e\u0442\u0447\u0435 \u043d\u0430\u0448!|italic=no}}\" ({{Transliteration|ru|Ot\u010de na\u0161}}, \"Our Father!\"), or the Russian version of the Jesus Prayer (\"\u0413\u043e\u0441\u043f\u043e\u0434\u0438 \u0418\u0438\u0441\u0443\u0441\u0435 \u0425\u0440\u0438\u0441\u0442\u0435\"). Such expressions are used to express strong emotions (much like English \"O my God!\"), and are often combined (\"{{lang|ru|\u0413\u043e\u0441\u043f\u043e\u0434\u0438, \u0411\u043e\u0436\u0435 \u043c\u043e\u0439|italic=no}}\"). More examples of the historic vocative can be found in other Biblical quotes that are sometimes used as proverbs: \"{{lang|ru|\u0412\u0440\u0430\u0447\u0443, \u0438\u0441\u0446\u0435\u043b\u0438\u0441\u044f \u0441\u0430\u043c|italic=no}}\" ({{Transliteration|ru|Vra\u010du, iscelisia sam}}, \"Physician, heal thyself\", nom. \"{{lang|ru|\u0432\u0440\u0430\u0447|italic=no}}\", {{Transliteration|ru|vra\u010d}}). Vocative forms are also used in modern Church Slavonic. The patriarch and bishops of the Russian Orthodox Church are addressed as \"{{lang|ru|\u0432\u043b\u0430\u0434\u044b\u043a\u043e|italic=no}}\" ({{Transliteration|ru|vladyko}}, hegemon, nom. \"{{lang|ru|\u0432\u043b\u0430\u0434\u044b\u043a\u0430|italic=no}}\", {{Transliteration|ru|vladyka}}). In the latter case, the vocative is often also incorrectly used for the nominative to refer to bishops and patriarchs. These Old Church Slavonic words that are present in the current Russian language are known as \"fossil words\".\nNew vocative.\nIn modern colloquial Russian, given names and a small family of terms often take a special \"shortened\" form that some linguists consider to be a re-emerging vocative case. It is used only for given names and nouns that end in {{lang|ru|-a|italic=no}} and {{lang|ru|-\u044f|italic=no}}, which are sometimes dropped in the vocative form: \"{{lang|ru|\u041b\u0435\u043d, \u0433\u0434\u0435 \u0442\u044b?|italic=no}}\" (\"Lena, where are you?\"). It is basically equivalent to \"{{lang|ru|\u041b\u0435\u043d\u0430, \u0433\u0434\u0435 \u0442\u044b?|italic=no}}\" but suggests a positive personal and emotional bond between the speaker and the person being addressed. Names that end in {{lang|ru|-\u044f|italic=no}} then acquire a soft sign: \"{{lang|ru|\u041e\u043b\u044c!|italic=no}}\" = \"{{lang|ru|\u041e\u043b\u044f!|italic=no}}\" (\"Olga!\"). In addition to given names, the form is often used with words like \"{{lang|ru|\u043c\u0430\u043c\u0430|italic=no}}\" (mom) and \"{{lang|ru|\u043f\u0430\u043f\u0430|italic=no}}\" (dad), which would be respectively shortened to \"{{lang|ru|\u043c\u0430\u043c|italic=no}}\" and \"{{lang|ru|\u043f\u0430\u043f|italic=no}}\". The plural form is used with words such as \"{{lang|ru|\u0440\u0435\u0431\u044f\u0442|italic=no}}\", \"{{lang|ru|\u0434\u0435\u0432\u0447\u0430\u0442|italic=no}}\" (nom: \"{{lang|ru|\u0440\u0435\u0431\u044f\u0442\u0430|italic=no}}\", \"{{lang|ru|\u0434\u0435\u0432\u0447\u0430\u0442\u0430|italic=no}}\" guys, gals).\nSuch usage differs from the historic vocative, which would be \"{{lang|ru|\u041b\u0435\u043d\u043e|italic=no}}\" and is not related.\nSerbo-Croatian.\nIn Serbo-Croatian languages, distinct vocatives exist only for singular masculine and feminine nouns. Nouns of the neuter gender and all nouns in plural have a vocative equal to the nominative. All vocative suffixes known from Old Church Slavonic also exist in Serbo-Croatian.\nThe vocative in Serbo-Croatian is formed according to one of three types of declension, which are classes of nouns with the same declension suffixes.\nFirst declension.\nThe first declension comprises masculine nouns that end with a consonant. These have a vocative suffix of either {{lang|sh|-e}} ({{lang|sh|doktor : doktore}} {{gloss|doctor}}) or {{lang|sh|-u}} ({{lang|sh|gospodar : gospodaru}} {{gloss|master}}).\nNouns terminating in {{lang|sh|-or}} have the {{lang|sh|-e}} vocative suffix: {{lang|sh|doktor : doktore}} {{gloss|doctor}}, {{lang|sh|major : majore}} {{gloss|major}}, {{lang|sh|majstor : majstore}} {{gloss|artisan}}, as well as nouns possessing an unsteady {{lang|sh|a}}: {{lang|sh|vetar : vetre}} {{gloss|wind}}, {{lang|sh|svekar : svekre}} {{gloss|father-in-law}}, and the noun {{lang|sh|car : care}} {{gloss|emperor}}. All other nouns in this class form the vocative with {{lang|sh|-u}}: {{lang|sh|gospodar : gospodaru}} {{gloss|master}}, {{lang|sh|pastir : pastiru}} {{gloss|shepherd}}, {{lang|sh|in\u017eenjer : in\u017eenjeru}} {{gloss|engineer}}, {{lang|sh|pisar : pisaru}} {{gloss|scribe}}, {{lang|sh|sekretar : sekretaru}} {{gloss|secretary}}.\nIn particular, masculine nouns ending with a palatal or prepalatal consonant {{lang|sh|j, lj, nj, \u010d, d\u017e, \u0107, \u0111}} or {{lang|sh|\u0161}} form vocatives with the {{lang|sh|-u}} suffix: {{lang|sh|heroj : heroju}} {{gloss|hero}}, {{lang|sh|prijatelj : prijatelju}} {{gloss|friend}}, {{lang|sh|konj : konju}} {{gloss|horse}}, {{lang|sh|voza\u010d : voza\u010du}} {{gloss|driver}}, {{lang|sh|mladi\u0107 : mladi\u0107u}} {{gloss|youngster}}, {{lang|sh|ko\u010dija\u0161 : ko\u010dija\u0161u}} {{gloss|coachman}}, {{lang|sh|mu\u017e : mu\u017eu}} {{gloss|husband}}.\nNouns ending with the velars {{lang|sh|-k, -g}} and {{lang|sh|-h}} are palatalized to {{lang|sh|-\u010d, -\u017e, -\u0161}} in the vocative: {{lang|cs|vojnik : vojni\u010de}} {{gloss|soldier}}, {{lang|cs|drug : dru\u017ee}} {{gloss|comrade}}, {{lang|sh|duh : du\u0161e}} {{gloss|ghost}}. A final {{lang|sh|-c}} becomes {{lang|sh|-\u010d}} in the vocative: {{lang|sh|stric : stri\u010de}} {{gloss|uncle}}, {{lang|sh|lovac : lov\u010de}} {{gloss|hunter}}. Likewise, a final {{lang|sh|-z}} becomes {{lang|sh|-\u017e}} in only two cases: {{lang|sh|knez : kne\u017ee}} {{gloss|prince}} and {{lang|sh|vitez : vite\u017ee}} {{gloss|knight}}.\nThe loss of the unsteady {{lang|sh|a}} can trigger a sound change by hardening consonants, as in {{lang|sh|vrabac : vrap\u010de}} {{gloss|sparrow}} (not {{lang|sh|*vrab\u010de}}), {{lang|sh|lisac : li\u0161\u010de}} {{gloss|male fox}} (not {{lang|sh|*lis\u010de}}) and {{lang|sh|\u017eenomrzac : \u017eenomr\u0161\u010de}} {{gloss|misogynist}} (not {{lang|sh|*\u017eenomrz\u010de}}). There may be a loss of {{lang|sh|-t}} before {{lang|sh|-c}} like in {{lang|sh|otac : o\u010de}} {{gloss|father}} (instead of {{lang|sh|*ot\u010de}}), {{lang|sh|svetac : sve\u010de}} {{gloss|saint}} (instead of {{lang|sh|*svet\u010de}}). When these phonetic alterations would substantially change the base noun, the vocative remains equal to the nominative, for example {{lang|sh|tetak}} {{gloss|uncle}}, {{lang|sh|ma\u010dak}} {{gloss|male cat}}, {{lang|sh|bratac}} {{gloss|cousin}}. This also holds true for foreign names ending with {{lang|sh|-k, -g}} and {{lang|sh|-h}} like {{lang|sh|D\u017eek}} {{gloss|Jack}}, {{lang|sh|Dag}} {{gloss|Doug}}, {{lang|sh|King, Hajnrih}}.\nMale names ending with {{lang|sh|-o}} and {{lang|sh|-e}} have a vocative equal to the nominative, for example: {{lang|sh|Marko, Mihailo, Danilo, \u0110or\u0111e, Pavle, Radoje}}.\nSecond declension.\nThe second declension affects nouns with the ending \"{{lang|sh|-a}}\". These are mainly of feminine but sometimes also of masculine gender. These nouns have a vocative suffix \"{{lang|sh|-o}}\": {{lang|sh|riba : ribo}} {{gloss|fish}}, {{lang|sh|sluga : slugo}} {{gloss|servant}}, {{lang|sh|kolega : kolego}} {{gloss|colleague}}, {{lang|sh|poslovo\u0111a : poslovo\u0111o}} {{gloss|manager}}.\nExemptions to this rule are male and female given names, which have a vocative equal to the nominative, e. g. {{lang|sh|Vera, Zorka, Olga, Marija, Gordana, Nata\u0161a, Nikola, Kosta, Ilija}} etc. However, this is different for twosyllabic names with an ascending accent such as female names {{lang|sh|N\u00e2da, Z\u00f4ra, M\u00eeca, N\u00eana}} and male names {{lang|sh|P\u00eara, B\u00f4\u017ea, P\u00e2ja}}, etc., which form vocatives with \"{{lang|sh|-o}}\": {{lang|sh|N\u00e2do, Z\u00f4ro, M\u00eeco, P\u00earo, B\u00f4\u017eo, P\u00e2jo}}, etc.\nDenominations of relatives like {{lang|sh|mama}} {{gloss|mom}}, {{lang|sh|tata}} {{gloss|dad}}, \"{{lang|sh|baba}}\" {{gloss|grandmother}}, {{lang|sh|deda}} {{gloss|grandfather}}, {{lang|sh|tetka}} {{gloss|aunt}} (parent's sister), \"{{lang|sh|ujna}}\" {{gloss|aunt}} (mother's brother's wife), \"{{lang|sh|strina}}\" {{gloss|aunt}} (father's brother's wife) have vocatives equal to the nominative. This also holds true for country names ending in \"{{lang|sh|-ska, -\u010dka, -\u0161ka}}\".\nNouns ending with the diminutive suffix \"-ica\" that consist of three or more syllables have a vocative with \"-e\": \"u\u010diteljica: u\u010diteljice\" \"female teacher\", \"drugarica: drugarice\" \"girlfriend\", \"tatica: tatice\" \"daddy\", \"mamica: mamice\" \"mommy\". This also applies to female names \"Danica: Danice\", \"Milica: Milice\", \"Zorica: Zorice\", and the male names \"Perica: Perice\", \"Tomica: Tomice\". Nouns of this class that can be applied to both males and females usually have a vocative ending of \"-ico\" (\"pijanica: pijanico\" \"drunkard\", \"izdajica: izdajico\" \"traitor\", \"kukavica: kukavico\" \"coward\"), but vocatives with \"-ice\" are also seen.\nThe use of vocative endings for names varies among Serbo-Croatian dialects. People in Croatia often use only nominative forms as vocatives, while others are more likely to use grammatical vocatives.\nThird declension.\nThe third declension affects feminine nouns ending with a consonant. The vocative is formed by appending the suffix \"{{lang|sh|-i}}\" to the nominative ({{lang|sh|re\u010d : re\u010di}} {{gloss|word}}, {{lang|sh|no\u0107 : no\u0107i}} {{gloss|night}}).\nSlovak.\nUntil the end of the 1980s, the existence of a distinct vocative case in Slovak was recognised and taught at schools. Today, the case is no longer considered to exist except for a few archaic examples of the original vocative remaining in religious, literary or ironic contexts:\nIn everyday use, the Czech vocative is sometimes retrofitted to certain words:\nAnother stamp of vernacular vocative is emerging, presumably under the influence of Hungarian for certain family members or proper names:\nUkrainian.\nUkrainian has retained the vocative case mostly as it was in Proto-Slavic:\nThere are some exceptions:\nIt is used even for loanwords and foreign names:\nIt is obligatory for all native names:\nIt is used for patronymics:\nLatin.\nIn Latin, the form of the vocative case of a noun is almost always the same as the nominative. Exceptions include singular non-neuter second-declension nouns that end in {{lang|la|-us}} in the nominative case. An example would be the famous line from Shakespeare, \"{{lang|la|Et tu, Brute?}}\" (commonly translated as \"And you, Brutus?\"): {{lang|la|Brute}} is the vocative case and {{lang|la|Brutus}} would be the nominative.\nNouns that end in {{lang|la|-ius}} end with {{lang|la|-\u012b}} instead of the expected {{lang|la|-ie}}. Thus, {{lang|la|Julius}} becomes {{lang|la|Jul\u012b}} and {{lang|la|filius}} becomes {{lang|la|fil\u012b}}. The shortening does not shift the accent so the vocative of {{lang|la|Vergilius}} is {{lang|la|Vergil\u012b}}, with accent on the second syllable even though it is short. Nouns that end in {{lang|la|-aius}} and {{lang|la|-eius}} have vocatives that end in {{lang|la|-a\u012b}} or {{lang|la|-e\u012b}} even though the {{lang|la|-i-}} in the nominative is consonantal.\nFirst-declension and second-declension adjectives also have distinct vocative forms in the masculine singular if the nominative ends in {{lang|la|-us}}, with the ending {{lang|la|-e}}. Adjectives that end in {{lang|la|-ius}} have vocatives in {{lang|la|-ie}} so the vocative of {{lang|la|eximius}} is {{lang|la|eximie}}.\nNouns and adjectives that end in {{lang|la|-eus}} do not follow the rules above. {{lang|la|Meus}} forms the vocative irregularly as {{lang|la|m\u012b}} or {{lang|la|meus}}, while Christian {{lang|la|Deus}} does not have a distinct vocative and retains the form {{lang|la|Deus}}. \"My God!\" in Latin is thus {{lang|la|m\u012b Deus!}}, but Jerome's Vulgate consistently used {{lang|la|Deus meus}} as a vocative. Classical Latin did not use a vocative of {{lang|la|deus}} either (in reference to pagan gods, the Romans used the suppletive form {{lang|la|dive}}).\nRomance languages.\nWest Iberian languages.\nPortuguese drops the article to form the vocative. The vocative is always between commas and, like in many other languages, a particle \"\u00d3\" is commonly used:\nIn Extremaduran and Fala, some post-tonical vowels open in vocative forms of nouns, a new development that is unrelated to the Latin vocative case.\nCatalan.\nCatalan drops the article to form the vocative.\nFrench.\nLike English, French sometimes uses (or historically used) a particle \"\u00d4\" to mark vocative phrases rather than by change to the form of the noun. A famous example is the title and first line of the Canadian national anthem, \"O Canada\" (French title: \"\u00d4 Canada\"), a vocative phrase addressing Canada.\nRomanian.\nThe vocative case in Romanian is partly inherited, occasionally causing other morphophonemic changes (see also the article on Romanian nouns):\nSince there is no \"-o\" vocative in Latin, it must have been borrowed from Slavic: compare the corresponding Bulgarian forms {{lang|bg|\u0441\u0435\u0441\u0442\u0440\u043e|italic=no}} ({{lang|uk-latn|sestro}}), {{lang|bg|\u043e\u0442\u043a\u0430\u0447\u0430\u043b\u043a\u043e|italic=no}} ({{lang|bg-latn|otkachalko}}), {{lang|bg|\u0415\u043b\u0435\u043d\u043e|italic=no}} ({{lang|bg-latn|Eleno}}).\nIn formal speech, the vocative often simply copies the nominative/accusative form even when it does have its own form. That is because the vocative is often perceived as very direct and so can seem rude.\nRomanesco dialect.\nIn Romanesco dialect the vocative case appears as a regular truncation immediately after the stress.\nCompare (vocative, always truncated)\n \"France', vie' qua!\"\n \"Francesco/Francesca, come here!\"\nwith (nominative, never truncated)\n \"Francesco/Francesca viene qua\"\n \"Francesco/Francesca comes here\"\nVenetian.\nVenetian has lost all case endings, like most other Romance languages. However, with feminine proper names the role of the vocative is played by the absence of the determiner: the personal article {{lang|vec|\u0142a / l'}} usually precedes feminine names in other situations, even in predicates. Masculine names and other nouns lack articles and so rely on prosody to mark forms of address:\nPredicative constructions:\nArabic.\nProperly speaking, Arabic has only three cases: nominative, accusative and genitive. However, a meaning similar to that conveyed by the vocative case in other languages is indicated by the use of the particle \"y\u0101\" ({{langx|ar|\u064a\u0627}}) placed before a noun inflected in the nominative case (or accusative if the noun is in construct form). In English translations, it is often translated literally as \"O\" instead of being omitted. A longer form used in Classical Arabic is {{lang|ar|\u0623\u064a\u0651\u0647\u0627}} \"{{Transliteration|ar|ALA|ayyuh\u0101}}\" (masculine), {{lang|ar|\u0623\u064a\u0651\u062a\u0647\u0627}} \"{{Transliteration|ar|ALA|ayyatuh\u0101}}\" (feminine), sometimes combined with \"y\u0101\". The particle \"y\u0101\" was also used in the old Castilian language because of Arabic influence via Mozarabic immigrations.\nMandarin.\nMandarin uses no special inflected forms for address. However, special forms and morphemes (that are not inflections) exist for addressing.\nMandarin has several particles that can be attached to the word of address to mark certain special vocative forces, where appropriate. A common one is \u554a({{lang-zh|c=\u554a|p=a}}) attached to the end of the address word. For example, \u65e5\u8bb0({{lang-zh|c=\u65e5\u8bb0|p=R\u00ecj\u00ec}}) \"diary\" becomes \u65e5\u8bb0\u554a ({{lang-zh|c=\u65e5\u8bb0\u554a|p=R\u00ecj\u00ec a}}).\nCertain specialized vocative morphemes also exist, albeit with limited applicabilities. For instance, the Beijing dialect of Mandarin Chinese, to express strong feelings (especially negative ones) to someone, a neutral tone suffix \"-ei\" may be attached to certain address words. It is most commonly applied to the word {{lang|cmn|\u5b59\u5b50}} (\"s\u016bnzi\", \"grandson\"), to form \"s\u016bnzei\", meaning approximately \"Hey you nasty one!\". Another example is {{lang|cmn|\u5c0f\u5b50}} (\"xi\u01ceozi\", lit. \"kid; young one\"), resulting in \"xi\u01ceozei\" \"Hey kiddo!\".\nJapanese.\nThe vocative case is present in Japanese as the particle {{lang|ja|\u3088}}. This usage is often literary or poetic. For example:\nIn conversational Japanese, this same particle is often used at the end of a sentence to indicate assertiveness, certainty or emphasis.\nGeorgian.\nIn Georgian, the vocative case is used to address the second-person singular and plural. For word roots that end with a consonant, the vocative case suffix is -\"o\", and for the words that end with a vowel, it is -\"v\" like in Old Georgian, but for some words, it is considered archaic. For example, \"kats-\" is the root for the word \"man\". If one addresses someone with the word, it becomes \"katso\".\nAdjectives are also declined in the vocative case. Just like nouns, consonant final stem adjectives take the suffix -\"o\" in the vocative case, and the vowel final stems are not changed:\n\"lamazi kali\" \"beautiful woman\" (nominative case)\n\"lamazo kalo!\" \"beautiful woman!\" (vocative case)\nIn the second phrase, both the adjective and the noun are declined. The personal pronouns are also used in the vocative case. \"Shen\" \"you\" (singular) and \"tkven\" \"you\" (plural) in the vocative case become \"she!\" and \"tkve\", without the -\"n\". Therefore, one could, for instance, say, with the declension of all of the elements:\n\"She lamazo kalo!\" \"you beautiful woman!\"\nKorean.\nThe vocative case in Korean is commonly used with first names in casual situations by using the vocative case marker {{lang|ko|(\ud638\uaca9 \uc870\uc0ac) \uc544}} ({{Transliteration|ko|a}}) if the name ends in a consonant and {{lang|ko|\uc57c}} ({{Transliteration|ko|ya}}) if the name ends with a vowel:\nIn formal Korean, the marker {{lang|ko|\uc5ec}} ({{Transliteration|ko|yeo}}) or {{lang|ko|\uc774\uc5ec}} ({{Transliteration|ko|iyeo}}) is used, the latter if the root ends with a consonant. Thus, a quotation of William S. Clark would be translated as follows:\nThe honorific infix {{lang|ko|\uc2dc}} ({{Transliteration|ko|si}}) is inserted in between the {{lang|ko|\uc774}} ({{Transliteration|ko|i}}) and {{lang|ko|\uc5ec}} ({{Transliteration|ko|yeo}}).\nIn Middle Korean, there were three honorific classes of the vocative case:\nHungarian.\nHungarian has a number of vocative-like constructions, even though it lacks an explicit vocative inflection.\nNoun phrases in a vocative context always take the zero article. While noun phrases can take zero articles for other reasons, the lack of an article otherwise expected marks a vocative construction. This is especially prominent in dialects of Hungarian where personal proper names and other personal animate nouns tend to take the appropriate definite article, similarly to certain dialects of German detailed above. For example:\nWith certain words such as {{lang|hu|bar\u00e1t}} (\"friend\"), {{lang|hu|h\u00f6lgy}} (\"lady\"), {{lang|hu|\u00far}} (\"gentleman, lord\"), vocation is, in addition to the zero article, always marked by the first person possessive:\nWords like {{lang|hu|testv\u00e9r}} (\"sibling, brother\") and other words of relation do not require the first person possessive, but it is readily used in common speech, especially in familiar contexts:\nThe second-person pronoun can be used to emphasize a vocation when appropriate: {{lang|hu|H\u00e1t mi\u00e9rt nem adtad oda neki, te bolond?}} (\"Why did you not give it to him, you fool?\"), {{lang|hu|Te Karcsi, nem l\u00e1ttad a szem\u00fcvegem?}} (\"Charlie, have you seen my glasses?\"), {{lang|hu|L\u00f3gtok ez\u00e9rt m\u00e9g, ti gazemberek.}} (\"You shall yet hang for this, crooks!\"), etc."}
{"id": "32563", "revid": "1308122664", "url": "https://en.wikipedia.org/wiki?curid=32563", "title": "Velodrome", "text": "Arena for track cycling\nA velodrome is an arena for track cycling. Modern velodromes feature steeply banked oval tracks, consisting of two 180-degree circular bends connected by two straights. The straights transition to the circular turn through a moderate easement curve.\nHistory.\nThe first velodromes were constructed during the late 1870s, the oldest of which is the Preston Park Velodrome, Brighton, United Kingdom, built in 1877 by the British Army. Some were purpose-built just for cycling, and others were built as part of facilities for other sports; many were built around athletics tracks or other grounds and any banking was shallow. Reflecting the then-lack of international standards, sizes varied and not all were built as ovals: for example, Preston Park is long and features four straights linked by banked curves, while the Portsmouth velodrome, in Portsmouth, has a single straight linked by one long curve. The oldest surviving regular velodrome two-straight oval tracks is from 1889, located in Brno, Czech Republic. Early surfaces included cinders or shale, though concrete, asphalt and tarmac later became more common.\nIndoor velodromes were also common particularly in the late 19th and early 20th century. For example, the V\u00e9lodrome d'hiver was built in Paris in 1909 and featured a indoor track with a wooden surface.\nInternational competitions such as the Olympic Games led to more standardisation: two-straight oval tracks quickly became the norm, and gradually lap lengths reduced. The V\u00e9lodrome de Vincennes, used for the 1900 (and 1924) Games was per lap, while Antwerp's V\u00e9lodrome d'Anvers Zuremborg, used in 1920, and Helsinki Velodrome, used in 1952, were both . By the 1960s up to 1989, tracks of length were commonly used for international competitions (e.g.: the Agust\u00edn Melgar Olympic Velodrome used for track cycling events at the 1968 Summer Olympics, and Leicester's Saffron Lane velodrome used at the 1970 and 1982 Track Cycling World Championships). Since 1990, such events are usually held on velodromes with laps. London's 2012 Olympic velodrome and a new velodrome in Turkmenistan's capital city Ashgabat both have a 250\u00a0m track and a 6,000-seat spectator capacity.\nTechnical aspects.\nBanking in the turns, called cant, allows riders to keep their bikes relatively perpendicular to the surface while riding at speed. When travelling through the turns at racing speed, which may exceed , the banking attempts to match the natural lean of a bicycle moving through that curve. At the ideal speed, the net force of the centrifugal force (outward) and gravity (downward) is angled down through the bicycle, perpendicular to the riding surface.\nRiders are not always travelling at full speed or at a specific radius. Most events have riders all over the track. Team races (like the Madison) have some riders at speed and others riding more slowly. In match sprints riders may come to a stop by performing a track stand in which they balance the bicycle on the sloped surface while keeping their feet locked into the pedals. For these reasons, the banking tends to be 10 to 15 degrees less than physics predicts. Also, the straights are banked 10 to 15 degrees more than physics would predict. These compromises make the track ridable at a range of speeds.\nFrom the straight, the curve of the track increases gradually into the circular turn. This section of decreasing radius is called the easement spiral or transition. It allows bicycles to follow the track around the corner at a constant radial position. Thus riders can concentrate on tactics rather than steering.\nBicycles and track design.\nBicycles for velodromes, better known as track bicycles, have no brakes. They employ a single fixed rear gear, or cog, that does not freewheel. This helps maximise speed, reduces weight, and avoids sudden braking while nevertheless allowing the rider to slow by pushing back against the pedals.\nModern velodromes are constructed by specialised designers. The Schuermann architects in Germany have built more than 125 tracks worldwide. Most of Schuermann's outdoor tracks are made of wood trusswork with a surface of strips of the rare rain-forest wood Afzelia. Indoor velodromes are built with less expensive pine surfaces.\nThe track is measured along a line up from the bottom. Olympic and World Championship velodromes must measure . Other events on the UCI International Calendar may be held in velodromes that measure between inclusive, with a length such that a whole or half number of laps give a distance of .\nThe velodrome at Calshot in Hampshire, England, is only and has especially steep banking because it was built to fit inside an aircraft hangar. The Forest City Velodrome in London, Ontario, Canada, is the world's shortest at . Built to fit a hockey arena, it too has steep banking.\nThe smaller the track, the steeper the banking. A track banks around 45\u00b0, while a track banks around 32\u00b0. Some older velodromes were built to imperial standards. The Dick Lane Velodrome in East Point, Georgia, United States, is .\nVelodrome tracks can be surfaced with different materials, including timber, synthetics and concrete. Shorter, newer, and Olympic quality tracks tend to be timber or synthetics; longer, older, or inexpensive tracks are concrete, macadam, or even cinder.\nTrack markings.\nImportant cycling events are usually held on tracks which have lines laid out in a specified arrangement. Some other tracks also follow these protocols, but others have a different arrangement of lines to suit their facility and to assist riders in holding a straight line and in avoiding drifting onto the flatter section below the bankings where they risk their tyres sliding out.\nBetween the infield (sometimes referred to as an apron) and the actual track is the blue band (called \"c\u00f4te d'azur\") which is typically 10% of the surface. The blue band is not technically a part of the track; although it is not illegal to ride there, moving into it to shortcut another rider results in disqualification. During time trials, pursuits or other timed events, the blue band is obstructed with sponges or other objects. The blue band is a warning to cyclists that they may scrape their pedal along the infield when in a curve, which can easily result in a crash.\n above the blue band is the black measurement line. The inner edge of this line defines the length of the track. above the inside of the track is the outside of the 5\u00a0cm wide red sprinter's line. The zone between black and red lines is sprinter's lane, which is the optimum route around the track. A rider leading in the sprinter's lane may not be passed on the inside; other riders must pass on the longer outside route.\nMinimum (or half the track width) above the inside of the track is the blue stayer's line. This line serves in races behind motorbikes as a separation line. Stayers below the blue line may not be overtaken on the inside. In Madison races (named after six-day races at Madison Square Garden in New York City, New York, and also known as \"the American\"), the team's relief rider rests above the stayer's line by riding slowly until his or her teammate comes around the track and throws him or her back into the race.\nThe finish line is black on a wide white band and near the end of the home straight. Red lines are marked in the exact centre of each straight as start and finish line for pursuit races. A white 200\u00a0m line marks before the finish.\nRace formats.\nThere are a variety of formats in velodrome races. A typical event will consist of several races of varying distances and structures. Common types of races include:\nTeam Sprint, sprint, Keirin, Kilo and flying laps are generally considered 'sprinters' races, which in track cycling equate to extremely powerful, muscular riders over short distances, resulting in some historic overlap between BMX riders and track sprinters, such as Chris Hoy. The other events are considered endurance events for riders with less outright power but greater aerobic ability, and such events have historically enjoyed an overlap with elite road racers, including road sprinters such as Mark Cavendish and Elia Viviani, Grand Tour legends Eddy Merckx, Fausto Coppi and more recent Tour de France winners Bradley Wiggins and Geraint Thomas.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32565", "revid": "11291818", "url": "https://en.wikipedia.org/wiki?curid=32565", "title": "Sildenafil", "text": "Drug for erectile dysfunction and hypertension\n&lt;templatestyles src=\"Infobox drug/styles.css\"/&gt;\nSildenafil, sold under the brand name Viagra among others, is a medication used to treat erectile dysfunction and pulmonary arterial hypertension. It is also sometimes used off-label for the treatment of certain symptoms in secondary Raynaud's phenomenon. It is unclear if it is effective for treating sexual dysfunction in females. It can be taken orally (swallowed by mouth), intravenously (injection into a vein), or through the sublingual route (dissolved under the tongue). Onset when taken orally is typically within twenty minutes and lasts for about two hours.\nCommon side effects include headaches, heartburn, and flushed skin. Caution is advised in those with cardiovascular disease. Rare but serious side effects include vision problems, hearing loss, and prolonged erection (priapism) that can lead to damage to the penis. Sildenafil should not be taken by people on nitric oxide donors such as nitroglycerin, as this may result in a serious drop in blood pressure.\nSildenafil acts by blocking phosphodiesterase 5 (PDE5), an enzyme that promotes breakdown of cGMP, which regulates blood flow in the penis. It requires sexual arousal to work, and does not by itself cause or increase sexual arousal. It also results in dilation of the blood vessels in the lungs.\nPfizer originally discovered the medication in 1989 while looking for a treatment for angina. It was approved for medical use in the United States and in the European Union in 1998. In 2023, it was the 151st most commonly prescribed medication in the United States, with more than 3million prescriptions. It is available as a generic medication. In the United Kingdom, it is available as a pharmacy medicine.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nMedical uses.\nErectile dysfunction.\nThe primary indication of sildenafil is treatment of erectile dysfunction (inability to sustain a satisfactory erection to complete sexual intercourse). Its use is now one of the standard treatments for erectile dysfunction, including for males with diabetes mellitus.\nAntidepressant-associated erectile dysfunction.\nTentative evidence suggests that sildenafil may help males who experience antidepressant-induced erectile dysfunction.\nPulmonary hypertension.\nWhile sildenafil improves some markers of disease in people with pulmonary arterial hypertension, it does not appear to affect the risk of death or serious side effects.\nRaynaud's phenomenon.\nSildenafil and other PDE5 inhibitors are used off-label to alleviate vasospasm and treat severe ischemia and ulcers in fingers and toes for people with secondary Raynaud's phenomenon; these drugs have moderate efficacy for reducing the frequency and duration of vasospastic episodes. As of 2016,[ [update]] their role more generally in Raynaud's was not clear.\nAltitude sickness.\nSildenafil has shown some potential for improving exercise performance at high altitudes. However, its overall efficacy is not clear. \nHigh-altitude pulmonary edema.\nSildenafil has been studied for high-altitude pulmonary edema (HAPE), but its use is currently not recommended for that indication.\nAdverse effects.\nIn clinical trials, the most common adverse effects of sildenafil use included headache, flushing, indigestion, nasal congestion, and impaired vision, including photophobia and blurred vision. Some sildenafil users have complained of seeing everything tinted blue (cyanopsia). This cyanopsia can be explained because sildenafil, while selective for PDE5, does have some affinity for PDE6, which is the phosphodiesterase found in the retina. Patients thus taking the drug may experience colorvision abnormalities. Some complained of blurriness and loss of peripheral vision. In July 2005, the US Food and Drug Administration (FDA) updated labeling for tadalafil (Cialis), vardenafil (Levitra), and sildenafil (Viagra) to reflect a small number of post-marketing reports of sudden vision loss, while acknowledging that \"...it is not possible to determine whether these oral medicines for erectile dysfunction were the cause of the loss of eyesight or whether the problem is related to other factors such as high blood pressure or diabetes, or to a combination of these problems.\" A careful review of pooled data from clinical trials containing well documented information about the dose and duration of exposure to the drug for a large number of patients, yields no evidence for an increased risk of non-arteritic anterior ischemic optic neuropathy or other adverse ocular events associated with PDE5 inhibitor use.\nRare but serious adverse effects found through postmarketing surveillance include prolonged erections, severe low blood pressure, myocardial infarction (heart attack), ventricular arrhythmias, stroke, increased intraocular pressure, and sudden hearing loss. In October 2007, the FDA announced that the labeling for all PDE5 inhibitors, including sildenafil, required a more prominent warning of the potential risk of sudden hearing loss.\nInteractions.\nCare should be exercised by people who are also taking protease inhibitors for the treatment of HIV infection. Protease inhibitors inhibit the metabolism of sildenafil, effectively multiplying the plasma levels of sildenafil, increasing the incidence and severity of side effects. Those using protease inhibitors are recommended to limit their use of sildenafil to no more than one 25\u00a0mg dose every 48 hours. Other drugs that interfere with the metabolism of sildenafil include erythromycin and cimetidine, both of which can also lead to prolonged plasma half-life levels.\nThe use of sildenafil and an \u03b11 blocker (typically prescribed for hypertension or for urologic conditions, such as benign prostatic hypertrophy) at the same time may lead to low blood pressure, but this effect does not occur if they are taken at least 4 hours apart.\nContraindications.\nContraindications include:\nSildenafil should not be used if sexual activity is inadvisable due to underlying cardiovascular risk factors.\nNon-medical use.\nRecreational use.\nSildenafil's popularity with young adults has increased over the years. Sildenafil's brand name, Viagra, is widely recognized in popular culture, and the drug's association with treating erectile dysfunction has led to its recreational use. The reasons behind such use include the belief that the drug increases libido, improves sexual performance, or permanently increases penis size. Studies on the effects of sildenafil when used recreationally are limited, but suggest it has little effect when used by those who do not have erectile dysfunction. In one study, a 25\u00a0mg dose was shown to cause no significant change in erectile quality, but did reduce the postejaculatory refractory time. This study also noted a significant placebo effect in the control group.\nUnprescribed recreational use of sildenafil and other PDE5 inhibitors is noted as particularly high among users of illegal drugs. Sildenafil is sometimes used to counteract the effects of other substances, often illicit. Some users mix it with methylenedioxymethamphetamine (MDMA, ecstasy), other stimulants, or opiates in an attempt to compensate for the common side effect of erectile dysfunction, a combination known as \"sextasy\", \"rockin' and rollin'\", \"hammerheading\", or \"trail mix\". Mixing it with amyl nitrite, another vasodilator, is particularly dangerous and potentially fatal.\nJet lag research.\nThe 2007 Ig Nobel Prize in aviation went to Patricia V. Agostino, Santiago A. Plano, and Diego A. Golombek of Universidad Nacional de Quilmes, Argentina, for their discovery that sildenafil helps treat jet lag recovery in hamsters.\nSports.\nProfessional athletes have been documented using sildenafil, believing the opening of their blood vessels will enrich their muscles. In turn, they believe it will enhance their performances.\nAnalogs.\nAcetildenafil and other synthetic structural analogs of sildenafil which are PDE5 inhibitors have been found as adulterants in a number of \"herbal\" aphrodisiac products sold over-the-counter. These analogs have not undergone any of the rigorous testing that drugs like sildenafil have passed, and thus have unknown side-effect profiles. Some attempts have been made to ban these drugs, but progress has been slow so far, as, even in those jurisdictions that have laws targeting designer drugs, the laws are drafted to ban analogs of illegal drugs of abuse, rather than analogs of prescription medicines. However, at least one court case has resulted in a product being taken off the market.\nThe US Food and Drug Administration (FDA) has banned numerous products claiming to be \"Eurycoma longifolia\" that, in fact, contain only analogs of sildenafil. Sellers of such fake herbals typically respond by just changing the names of their products.\nDetection in biological fluids.\nSildenafil and/or N-desmethylsildenafil, its major active metabolite, may be quantified in plasma, serum, or whole blood to assess pharmacokinetic status in those receiving the drug therapeutically, to confirm the diagnosis in potential poisoning victims, or to assist in the forensic investigation in a case of fatal overdose.\nMechanism of action.\nSildenafil protects cyclic guanosine monophosphate (cGMP) from degradation by cGMP-specific phosphodiesterase type 5 (PDE5) in the corpus cavernosum. Nitric oxide (NO) in the corpus cavernosum of the penis binds to guanylate cyclase receptors, which results in increased levels of cGMP, leading to smooth muscle relaxation (vasodilation) of the intimal cushions of the helicine arteries. This smooth muscle relaxation leads to vasodilation and increased inflow of blood into the spongy tissue of the penis, causing an erection. Robert F. Furchgott, Ferid Murad, and Louis Ignarro won the Nobel Prize in Physiology or Medicine in 1998 for their independent study of the metabolic pathway of nitric oxide in smooth muscle vasodilation.\nThe molecular mechanism of smooth muscle relaxation involves the enzyme CGMP-dependent protein kinase, also known as PKG. This kinase is activated by cGMP and it phosphorylates multiple targets in the smooth muscle cells, namely myosin light chain phosphatase, RhoA, IP3 receptor, phospholipase C, and others. Overall, this results in a decrease in intracellular calcium and desensitizing proteins to the effects of calcium, engendering smooth muscle relaxation.\nSildenafil is a potent and selective inhibitor of cGMP-specific phosphodiesterase type 5 (PDE5), which is responsible for degradation of cGMP in the corpus cavernosum. The molecular structure of sildenafil is similar to that of cGMP and acts as a competitive binding agent of PDE5 in the corpus cavernosum, resulting in more cGMP and increased penile response to sexual stimulation. Without sexual stimulation, and therefore lack of activation of the NO/cGMP system, sildenafil should not cause an erection. Other drugs that operate by the same mechanism include tadalafil (Cialis) and vardenafil (Levitra).\nSildenafil is broken down in the liver by hepatic metabolism using cytochrome p450 enzymes, mainly CYP450 3A4 (major route), but also by CYP2C9 (minor route) hepatic isoenzymes. The major product of metabolisation by these enzymes is N-desmethylated sildenafil, which is metabolised further. This metabolite also has an affinity for the PDE receptors, about 40% of that of sildenafil. Thus, the metabolite is responsible for about 20% of sildenafil's action. Sildenafil is excreted as metabolites predominantly in the feces (about 80% of administered oral dose) and to a lesser extent in the urine (around 13% of the administered oral dose). If taken with a high-fat meal, absorption is reduced; the time taken to reach the maximum plasma concentration increases by around one hour, and the maximum concentration itself is decreased by nearly one-third.\nChemical synthesis.\nThe preparation steps for synthesis of sildenafil are:\nHistory.\nSildenafil (compound UK-92,480) was synthesized by a group of pharmaceutical chemists led by Simon Campbell working at Pfizer's Sandwich, Kent, research facility in England. It was initially studied for use in hypertension (high blood pressure) and angina pectoris (a symptom of ischaemic heart disease). The first clinical trials were conducted in Morriston Hospital in Swansea. Phase I clinical trials under the direction of Ian Osterloh suggested the drug had little effect on angina, but it could induce marked penile erections. Pfizer therefore decided to market it for erectile dysfunction, rather than for angina; this decision became an often-cited example of drug repositioning. The drug was patented in 1996, approved for use in erectile dysfunction by the FDA on 27 March 1998, becoming the first oral treatment approved to treat erectile dysfunction in the United States, and offered for sale in the United States later that year. It soon became a great success: annual sales of Viagra peaked in 2008 at US$1.934 billion.\nSociety and culture.\nMarketing and sales.\nIn the US, even though sildenafil is available only by prescription from a doctor, it was advertised directly to consumers on TV (famously being endorsed by former United States Senator Bob Dole and football star Pel\u00e9). Numerous sites on the Internet offer Viagra for sale after an \"online consultation\", often a simple web questionnaire.\nViagra and other products for sexual dysfunction, termed \"sexuopharmaceuticals,\" proliferated new types of specialised marketing for such products. Viagra and similar prescription pharmaceuticals were promoted by images in media to the extent of becoming a cultural icon, at the time a relatively new phenomenon known to be permitted only in the United States and New Zealand and which is believed to have significantly contributed to norms regarding male sexuality. One author notes that although the effect of Viagra is only limited to penile blood vessels, advertisements routinely use imagery of couples hugging, smiling and dancing, with the author claiming that pharmaceutical companies were deceptive in the use of such advertisements.\nIn 2000, Viagra sales accounted for 92% of the global market for prescribed erectile dysfunction pills. By 2007, Viagra's global share had plunged to about 50% due to several factors, including the entry of Cialis and Levitra, along with several counterfeits and clones, and reports of vision loss in people taking PDE5 inhibitors. In 2008, the FDA forced Pfizer to remove Viva Cruiser, an advergame for Viagra, from appearing on Forbes, after the game failed to disclose risk information about the drug.\nIn February 2007, it was announced that Boots, the UK pharmacy chain, would try over-the-counter sales of Viagra in stores in Manchester, England. Males between the ages of 30 and 65 would be eligible to buy four tablets after a consultation with a pharmacist. In 2017, the Medicines and Healthcare products Regulatory Agency (MHRA) enacted legislation that expanded this nationwide, allowing a particular branded formulation of Sildenafil, Viagra Connect (50\u00a0mg), to be sold over the counter and without a prescription throughout the UK from early 2018. While the sale remains subject to a consultation with a pharmacist, the other restrictions from the trial have been removed, allowing customers over the age of 18 to purchase an unlimited number of pills.\nIn May 2013, Pfizer, which manufactures Viagra, told the Associated Press they will begin selling the drug directly to people on its website.\nPfizer's patents on Viagra expired outside the US in 2012; in the US they were set to expire, but Pfizer settled litigation with each of Mylan and Teva which agreed that both companies could introduce generics in the US in December 2017. In December 2017, Pfizer released its own generic version of Viagra.\nAs of 2018[ [update]], the US Food and Drug Administration has approved fifteen drug manufacturers to market generic sildenafil in the United States. Seven of these companies are based in India.\nThe patent for Pfizer's Viagra sildenafil to treat erectile dysfunction expired in April 2020.\nCounterfeits.\nCounterfeit Viagra, despite generally being cheaper, can contain harmful substances or substances that affect how Viagra works, such as blue printer ink, amphetamines, metronidazole, boric acid, and rat poison.\nViagra is one of the world's most counterfeited medicines. According to a 2012 Pfizer study, around 80% of sites claiming to sell Viagra were selling counterfeits.\nAn October 2023 release stated that erectile dysfunction medicines were the most seized drugs by the Interpol accounting for 22% of seizures. International networks may be active.\nRegional issues.\nUnited States.\nIn 1992, Pfizer filed a patent covering the substance sildenafil and its use to treat cardiovascular diseases. This would be marketed as Revatio. The patent was published in 1993 and expired in 2012. The patent on Revatio (indicated for pulmonary arterial hypertension rather than erectile dysfunction) expired in late 2012. Generic versions of this low-dose form of sildenafil have been available in the US from a number of manufacturers, including Greenstone, Mylan, and Watson, since early 2013. Health care providers may prescribe generic sildenafil for erectile dysfunction. For a time, the generic was not available in the same dosages as branded Viagra, so using dosages typically required for treating ED required patients to take multiple pills.\nIn 1994, Pfizer filed a patent covering the use of sildenafil to treat erectile dysfunction. This would be marketed as Viagra. This patent was published in 2002 and expired in 2019. Teva sued to have the latter patent invalidated, but Pfizer prevailed in an August 2011 federal district court case. An agreement with Pfizer allowed Teva to begin to provide the generic drug in December 2017.\nIn the United States, Pfizer received two patents for sildenafil: one for its indication to treat cardiovascular disease (marketed as Revatio) and another for its indication to treat erectile dysfunction (marketed as Viagra). The substance is the same under both brand names.\nSildenafil is available as a generic drug in the United States, labeled for pulmonary arterial hypertension, and to treat erectile dysfunction, as the patent expired in April 2020.\nIn the US, Revatio and Viagra are marketed by Viatris after Upjohn was spun off from Pfizer.\nBrazil.\nPfizer's patent on sildenafil citrate expired in Brazil in 2010.\nCanada.\nIn Canada, Pfizer's patent 2,324,324 for Revatio (sildenafil used to treat pulmonary hypertension) was found invalid by the Federal Court in June 2010, on an application by Ratiopharm Inc.\nOn 8 November 2012, the Supreme Court of Canada ruled that Pfizer's patent 2,163,446 on Viagra was invalid from the beginning because the company did not provide full disclosure in its application. The decision, \"Teva Canada Ltd. v. Pfizer Canada Inc.\", pointed to section 27(3)(b) of The Patent Act which requires that disclosure must include sufficient information \"to enable any person skilled in the art or science to which it pertains\" to produce it. It added further: \"As a matter of policy and sound statutory interpretation, patentees cannot be allowed to 'game' the system in this way. This, in my view, is the key issue in this appeal.\"\nTeva Canada launched Novo-Sildenafil, a generic version of Viagra, on the day the Supreme Court of Canada released its decision. To remain competitive, Pfizer then reduced the price of Viagra in Canada. However, on 9 November 2012, Pfizer filed a motion for a re-hearing of the appeal in the Supreme Court of Canada, on the grounds that the court accidentally exceeded its jurisdiction by voiding the patent. Finally, on 22 April 2013, the Supreme Court of Canada invalidated Pfizer's patent altogether.\nChina.\nManufacture and sale of sildenafil citrate drugs is common in China, where Pfizer's patent claim is not widely enforced.\nEgypt.\nEgypt approved Viagra for sale in 2002, but soon afterwards allowed local companies to produce generic versions of the drug, citing the interests of poor people who would not be able to afford Pfizer's price.\nEuropean Union.\nIn June 2013 Pfizer's patent on sildenafil citrate expired in some member countries of the European Union, including Austria, Denmark, France, Germany, Ireland, Italy, The Netherlands, Spain, Sweden, the United Kingdom, and Switzerland. A UK patent held by Pfizer on the use of PDE5 inhibitors (see below) as treatment of impotence was invalidated in 2000 because of obviousness; this decision was upheld on appeal in 2002.\nIndia.\nManufacture and sale of sildenafil citrate drugs known as \"generic Viagra\" is common in India, where Pfizer's patent claim does not apply. Brand names include Kamagra (Ajanta Pharma), Silagra (Cipla), Edegra (Sun Pharmaceutical), Penegra (Zydus Cadila), Manly (Cooper Pharma) and Zenegra (Alkem Laboratories).\nNew Zealand.\nSildenafil was reclassified in New Zealand in 2014 so it could be bought over the counter from a pharmacist. It is thought that this reduced sales over the Internet and was safer as males could be referred for medical advice if appropriate.\nSouth Korea.\nIn 1999 South Korea granted two patents to Pfizer related to sildenafil. The first document guaranteed sole production and sale of the substance until 2012, while the second gave Pfizer the exclusive use to treating erectile dysfunction with sildenafil until 2014. In 2011 Hanmi Pharmaceutical and CJ CheilJedang launched a suit against the exclusive use patent. The Korean Court system made a ruling against Pfizer in June 2012, allowing for the unhindered domestic production of generic prescription sildenafil.\nIn 2012, Viagra lost its position as the top selling erectile dysfunction treatment in South Korea. This development was credited largely \"due to the introduction of generic products.\" Generic sildenafil became publicly available in May. Sales of PalPal by Hanmi Pharmaceuticals totalled \u20a922 billion or about 86% the market share of Viagra that year. By 2017, there were over 50 generic sildenafil pills available. During that year Viagra sales slumped to 38% that of Palpal.\nUnited Kingdom.\nThere were 2,958,199 prescriptions for Sildenafil in 2016 in England, compared with 1,042,431 in 2006.\nIn 2018, Viagra Connect, a particular formulation of Sildenafil marketed by Pfizer, became available for sale without a prescription in the UK.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32566", "revid": "20542576", "url": "https://en.wikipedia.org/wiki?curid=32566", "title": "Voltaic pile", "text": "First electrical battery that could continuously provide an electric current to a circuit\nThe voltaic pile was the first electrical battery that could continuously provide an electric current to a circuit. It was invented by Italian chemist Alessandro Volta, who published his experiments in 1799. Its invention can be traced back to an argument between Volta and Luigi Galvani, Volta's fellow Italian scientist who had conducted experiments on frogs' legs. Use of the voltaic pile enabled a rapid series of other discoveries, including the electrical decomposition (electrolysis) of water into oxygen and hydrogen by William Nicholson and Anthony Carlisle (1800), and the discovery or isolation of the chemical elements sodium (1807), potassium (1807), calcium (1808), boron (1808), barium (1808), strontium (1808), and magnesium (1808) by Humphry Davy.\nThe entire 19th-century electrical industry was powered by batteries related to Volta's (e.g. the Daniell cell and Grove cell) until the advent of the dynamo (the electrical generator) in the 1870s.\nHistory.\nVolta's invention was built on Luigi Galvani's 1780s discovery that a circuit of two metals and a frog's leg can cause the frog's leg to respond. Volta demonstrated in 1794 that when two metals and brine-soaked cloth or cardboard are arranged in a circuit they too produce an electric current. In 1800, Volta stacked several pairs of alternating copper (or silver) and zinc discs (electrodes) separated by cloth or cardboard soaked in brine, which increased the total electromotive force. When the top and bottom contacts were connected by a wire, an electric current flowed through the voltaic pile and the connecting wire. This was the first \"true\" battery, that gave off continuous charge.\nMany scientific instruments that belonged to Alessandro Volta are preserved in the University History Museum of the University of Pavia, where Volta taught from 1778 to 1819; the piles on display, unfortunately, are not original, as the ones preserved in Pavia were lent on the occasion of the centenary of the invention and subsequently lost in a fire.\nApplications.\nOn 20 March 1800, Alessandro Volta wrote to the London Royal Society to describe the technique for producing electric current using his device. On learning of the voltaic pile, William Nicholson and Anthony Carlisle used it to discover the electrolysis of water. Humphry Davy showed that the electromotive force, which drives the electric current through a circuit containing a single voltaic cell, was caused by a chemical reaction, not by the voltage difference between the two metals. He also used the voltaic pile to decompose chemicals and to produce new chemicals. William Hyde Wollaston showed that electricity from voltaic piles had identical effects to those of electricity produced by friction. In 1802 Vasily Petrov used voltaic piles in the discovery and research of electric arc effects.\nHumphry Davy and Andrew Crosse were among the first to develop large voltaic piles. Davy used a 2000-pair pile made for the Royal Institution in 1808 to demonstrate carbon arc discharge and isolate five new elements: barium, calcium, boron, strontium and magnesium.\nElectrochemistry.\nBecause Volta believed that the electromotive force occurred at the contact between the two metals, Volta's piles had a different design than the modern design illustrated on this page. His piles had one extra disc of copper at the top, in contact with the zinc, and one extra disc of zinc at the bottom, in contact with the copper. Expanding on Volta's work and the electro-magnetism work of his mentor Humphry Davy, Michael Faraday utilized both magnets and the voltaic pile in his experiments with electricity. Faraday believed that all \"electricities\" being studied at the time (voltaic, magnetic, thermal, and animal) were one and the same. His work to prove this theory led him to propose two laws of electrochemistry which stood in direct conflict with the current scientific beliefs of the day as laid down by Volta thirty years earlier. Because of their contributions to the understanding of this field of study, Faraday and Volta are both considered to be among the fathers of electrochemistry. The words \"electrode\" and \"electrolyte\", used above to describe Volta's work, are due to Faraday.\nElectromotive force.\nThe strength of the pile is expressed in terms of its electromotive force, or emf, given in volts. Alessandro Volta's theory of contact tension considered that the emf, which drives the electric current through a circuit containing a voltaic cell, occurs at the contact between the two metals. Volta did not consider the electrolyte, which was typically brine in his experiments, to be significant. However, chemists soon realized that water in the electrolyte was involved in the pile's chemical reactions, and led to the evolution of hydrogen gas from the copper or silver electrode.\nThe modern, atomistic understanding of a cell with zinc and copper electrodes separated by an electrolyte is the following. When the cell is providing an electrical current through an external circuit, the metallic zinc at the surface of the zinc anode is oxidized and dissolves into the electrolyte as electrically charged ions (Zn2+), leaving two negatively charged electrons () behind in the metal:\nanode (oxidation): ZnZn2+ + 2 \nThis reaction is called oxidation. While zinc is entering the electrolyte, two positively charged hydrogen ions (H+) from the electrolyte accept two electrons at the copper cathode surface, become reduced and form an uncharged hydrogen molecule (H2):\ncathode (reduction): 2 H+ + 2 H2\nThis reaction is called reduction. The electrons used from the copper to form the molecules of hydrogen are made up by an external wire or circuit that connects it to the zinc. The hydrogen molecules formed on the surface of the copper by the reduction reaction ultimately bubble away as hydrogen gas.\nOne will observe that the global electro-chemical reaction does not immediately involve the electrochemical couple Cu2+/Cu (Ox/Red) corresponding to the copper cathode. The copper metal disk thus only serves here as a \"chemically inert\" noble metallic conductor for the transport of electrons in the circuit and does not chemically participate in the reaction in the aqueous phase. Copper does act as a catalyst for the hydrogen-evolution reaction, which otherwise could occur equally well (though at a slower rate in the absence of the catalyst) directly at the zinc electrode without current flow through the external circuit. The copper electrode could be replaced in the system by any sufficiently noble/inert and catalytically active metallic conductor (Ag, Pt, stainless steel, graphite, ...). The global reaction can be written as follows:\nZn + 2H+Zn2+ + H2\nThis is usefully stylized by means of the electro-chemical chain notation:\n(anode: oxidation) Zn | Zn2+ || 2H+ | H2 | Cu (cathode: reduction)\nin which a vertical bar each time represents an interface. The double vertical bar represents the interfaces corresponding to the electrolyte impregnating the porous cardboard disk.\nWhen no current is drawn from the pile, each cell, consisting of zinc/electrolyte/copper, generates 0.76 V with a brine electrolyte. The voltages from the cells in the pile add, so the six cells in the diagram above generate 4.56 V of electromotive force.\nDry piles.\nA number of high-voltage \"dry piles\" were invented between 1800 and the 1830s in an attempt to determine the source of electricity of the wet voltaic pile, and specifically to support Volta's hypothesis of contact tension. Indeed, Volta himself experimented with a pile whose cardboard discs had dried out, most likely accidentally.\nThe first to publish the discovery of a dry pile that produced a current was Johann Wilhelm Ritter in 1802, albeit in an obscure journal; over the next decade, it was announced repeatedly as a new discovery. One form of dry pile is the Zamboni pile. Francis Ronalds in 1814 was one of the first to realize that dry piles also worked through chemical reaction rather than metal-to-metal contact, even though corrosion was not visible due to the very small currents generated.\nThe dry pile could be referred to as the ancestor of the modern dry cell.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32567", "revid": "6941696", "url": "https://en.wikipedia.org/wiki?curid=32567", "title": "Volt", "text": "SI derived unit of voltage\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nThe volt (symbol: V), named after Alessandro Volta, is the unit of measurement of electric potential, electric potential difference (voltage), and electromotive force in the International System of Units (SI).\nDefinition.\nOne volt is defined as the electric potential between two points of a conducting wire when an electric current of one ampere dissipates one watt of power between those points. It can be expressed in terms of SI base units (m, kg, s, and A) as\n formula_1\nEquivalently, it is the potential difference between two points that will impart one joule of energy per coulomb of charge that passes through it. It can be expressed in terms of SI base units (m, kg, s, and A) as\n formula_2\nIt can also be expressed as amperes times ohms (current times resistance, Ohm's law), webers per second (magnetic flux per time), watts per ampere (power per current), or joules per coulomb (energy per charge), which is also equivalent to electronvolts per elementary charge:\n formula_3\nThe volt is named after Alessandro Volta. As with every SI unit named after a person, its symbol starts with an upper case letter (V), but when written in full, it follows the rules for capitalisation of a common noun; i.e., \"volt\" becomes capitalised at the beginning of a sentence and in titles but is otherwise in lower case.\nJosephson junction definition.\nHistorically the \"conventional\" volt, \"V\"90, defined in 1987 by the 18th General Conference on Weights and Measures and in use from 1990 to 2019, was implemented using the Josephson effect for exact frequency-to-voltage conversion, combined with the caesium frequency standard. Though the Josephson effect is still used to realize a volt, the constant used has changed slightly.\nFor the Josephson constant, \"K\"J = 2\"e\"/\"h\" (where \"e\" is the elementary charge and \"h\" is the Planck constant), a \"conventional\" value \"K\"J-90 = was used for the purpose of defining the volt. As a consequence of the 2019 revision of the SI, as of 2019 the Josephson constant has an exact value of \"K\"J = , which replaced the conventional value \"K\"J-90.\nThis standard is typically realized using a series-connected array of several thousand or tens of thousands of junctions, excited by microwave signals between 10 and 80\u00a0GHz (depending on the array design). Empirically, several experiments have shown that the method is independent of device design, material, measurement setup, etc., and no correction terms are required in a practical implementation.\nWater-flow analogy.\nIn the \"water-flow analogy\", sometimes used to explain electric circuits by comparing them with water-filled pipes, voltage (difference in electric potential) is likened to difference in water pressure, while current is proportional to the amount of water flowing. A resistor would be a reduced diameter somewhere in the piping or something akin to a radiator offering resistance to flow.\nThe relationship between voltage and current is defined (in ohmic devices like resistors) by Ohm's law. Ohm's law is analogous to the Hagen\u2013Poiseuille equation, as both are linear models relating flux and potential in their respective systems.\nCommon voltages.\nThe voltage produced by each electrochemical cell in a battery is determined by the chemistry of that cell (see ). Cells can be combined in series for multiples of that voltage, or additional circuitry added to adjust the voltage to a different level. Mechanical generators can usually be constructed to any voltage in a range of feasibility.\nNominal voltages of familiar sources:\nHistory.\nIn 1800, as the result of a professional disagreement over the galvanic response advocated by Luigi Galvani, Alessandro Volta developed the so-called voltaic pile, a forerunner of the battery, which produced a steady electric current. Volta had determined that the most effective pair of dissimilar metals to produce electricity was zinc and silver. In 1861, Latimer Clark and Sir Charles Bright coined the name \"volt\" for the unit of resistance. By 1873, the British Association for the Advancement of Science had defined the volt, ohm, and farad. In 1881, the International Electrical Congress, now the International Electrotechnical Commission (IEC), approved the volt as the unit for electromotive force. They made the volt equal to 108 cgs units of voltage, the cgs system at the time being the customary system of units in science. They chose such a ratio because the cgs unit of voltage is inconveniently small and one volt in this definition is approximately the emf of a Daniell cell, the standard source of voltage in the telegraph systems of the day. At that time, the volt was defined as the potential difference [i.e., what is nowadays called the \"voltage (difference)\"] across a conductor when a current of one ampere dissipates one watt of power.\nThe \"international volt\" was defined in 1893 as &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20441.434 of the emf of a Clark cell. This definition was abandoned in 1908 in favor of a definition based on the international ohm and international ampere until the entire set of \"reproducible units\" was abandoned in 1948.\nA 2019 revision of the SI, including defining the value of the elementary charge, took effect on 20 May 2019.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32568", "revid": "8390765", "url": "https://en.wikipedia.org/wiki?curid=32568", "title": "Vela (constellation)", "text": "Constellation in the southern celestial hemisphere\nVela is a constellation in the southern sky, which contains the Vela Supercluster. Its name is Latin for the sails of a ship, and it was originally part of a larger constellation, the ship \"Argo Navis\", which was later divided into three parts, the others being Carina and Puppis. With an apparent magnitude of 1.8, its brightest star is the hot blue multiple star Gamma Velorum, one component of which is the closest and brightest Wolf-Rayet star in the sky. Delta and Kappa Velorum, together with Epsilon and Iota Carinae, form the asterism known as the False Cross. 1.95-magnitude Delta is actually a triple or quintuple star system.\nHistory.\nArgo Navis was one of the 48 classical constellations listed by the 2nd-century astronomer Ptolemy, and represented the ship \"Argo\", used by Jason and the Argonauts on their quest for the Golden Fleece in Greek mythology. German cartographer Johann Bayer depicted the constellation on his \"Uranometria\" of 1603, and gave the stars Bayer designations from Alpha to Omega. However, his chart was inaccurate as the constellation was not fully visible from the Northern Hemisphere.\nArgo was more accurately charted and subdivided in 1752 by the French astronomer Nicolas Louis de Lacaille, forming Carina (the keel), Vela (the sails), and Puppis (the poop deck). Despite the division, Lacaille kept Argo's Bayer designations. Therefore, Carina has the Alpha, Beta and Epsilon originally assigned to Argo Navis, while Vela's brightest stars are Gamma and Delta, Puppis has Zeta as its brightest star, and so on.\nCharacteristics.\nVela is bordered by Antlia and Pyxis to the north, Puppis to the northwest, Carina to the south and southwest, and Centaurus to the east. Covering 500 square degrees, it ranks 32nd of the 88 modern constellations in size. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"Vel\".\nThe official constellation boundaries, as set by Eug\u00e8ne Delporte in 1930, are defined by a polygon of 14 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between 08h 13.3m and 11h 05.5m, while the declination coordinates are between \u221237.16\u00b0 and \u221257.17\u00b0.\nFeatures.\nStars.\nThe brightest star in the constellation, Gamma Velorum, is a complex multiple star system. The brighter component, known as Gamma2 Velorum, shines as a blue-white star of apparent magnitude 1.83. It is a spectroscopic binary made up of two very hot blue stars orbiting each other every 78.5 days and separated by somewhere between 0.8 and 1.6 Astronomical Units (AU). The brighter component is a hot blue main-sequence star of spectral type O7.5 and is around 280,000 times as luminous, is around 30 times as massive and is 17 times the diameter of the Sun with a surface temperature of 35,000 K. The second component is an extremely rare example of hot star known as a Wolf\u2013Rayet star, and is the closest and brightest example in the sky. It has a surface temperature of 57,000 and is around 170,000 times as luminous as the Sun, though it radiates most of its energy in the ultraviolet spectrum. Gamma1 is a blue-white star of spectral type B2III and apparent magnitude 4.3. The two pairs are separated by 41 arcseconds, easily separable in binoculars. Parallax measurements give a distance of 1,116 light-years, meaning that they are at least 12,000 AU apart. Further afield are 7.3-magnitude Gamma Velorum C and 9.4-magnitude Gamma Velorum D, lying 62 and 93 arcseconds south-southeast from Gamma2. These stars are the most prominent members of Vela OB2, an extended association of young stars.\nThe next brightest star is Delta Velorum or Alsephina, also a multiple star system and one of the brightest eclipsing binaries in the sky. Together with Kappa Velorum or Markeb, Iota Carinae or Aspidiske and Epsilon Carinae or Avior, it forms the diamond-shaped asterism known as the False Cross\u2014so called because it is sometimes mistaken for the Southern Cross, causing errors in astronavigation. Appearing as a white star of magnitude 1.95, Delta is actually a triple or possibly quintuple star system located around 80 light-years from the Solar System. Delta A has a magnitude of 1.99 and is an eclipsing binary composed of two A-type white stars (Delta Aa and Ab) which orbit each other every 45.2 days and lie 0.5 AU from each other, with a resulting drop in magnitude of 0.4 when the dimmer one passes.in front of the brighter. Delta B is a 5.1 magnitude yellow G-class star of similar dimensions to the Sun which ranges between 26 and 72 AU away from the brighter pair, taking 142 years to complete a revolution. Further out still, at a distance of 1700 AU, are two red dwarfs of magnitudes 11 and 13. If they are part of the multiple system, they take 28000 years to complete an orbit. Also called Markeb, Kappa appears as a blue-white star of spectral type B2IV-V and magnitude 2.47 but is in fact a spectroscopic binary. The two orbit around each other with a period of 116.65 days, but the size, mass and nature of the companion are as yet unclear.\nThe orange-hued Lambda Velorum, or Suhail, is the third-brightest star in the constellation. A supergiant of spectral type K4Ib-II, it varies between magnitudes 2.14 and 2.3, and lies 545 light-years distant. It has around 11,000 times the luminosity, 9 to 12 times the mass and 207 times the diameter of the Sun.\nAH Velorum is a Cepheid variable located less than a degree to the northeast of Gamma. A yellow-white supergiant of spectral type F7Ib-II, it pulsates between magnitudes 5.5 and 5.89 over 4.2 days. Also lying close to Gamma, V Velorum is a Cepheid of spectral type F6-F9II ranging from magnitude 7.2 to 7.9 over 4.4 days. AI Velorum is located 2.8 degrees north-northeast of Gamma, a Delta Scuti variable of spectral type A2p-F2pIV/V that ranges between magnitudes 6.15 and 6.76 in around 2.7 hours.\nV390 Velorum is an aged star that has been found to be surrounded by a dusty disk. An RV Tauri variable, it has a spectral type of F3e and ranges between magnitudes 9.01 and 9.27 over nearly 95 days.\nOmicron Velorum is a blue-white subgiant of spectral type B3III-IV located around 495 light-years from the Solar System. A slowly pulsating B star, it ranges between magnitudes 3.57 and 3.63 over 2.8 days. It is the brightest star in, and gives its name to, the Omicron Velorum Cluster, also known as IC 2391, an open cluster located around 500 light-years away.\nSeven star systems have been found to have planets. HD 75289 is a Sun-like star of spectral type G0V with a hot Jupiter planetary companion that takes only about 3.51 days to revolve at an orbital distance of 0.0482 AU. WASP-19 is a star of apparent magnitude 12.3 located 815 light-years away, which has a hot Jupiter-like planet that orbits every 0.7 days. HD 73526 is a Sun-like star of spectral type G6V that has two planets around double the mass of Jupiter each with orbits of 187 and 377 days, respectively.\nHD 85390 is an orange dwarf of spectral type K1.5V lying around 111 light-years distant with a planet 42 times as massive as Earth orbiting every 788 days.\nHD 93385 is a Sun-like star of spectral type G2/G3V located around 138 light-years away that is orbited by two super-Earths with periods of 13 and 46 days and masses 8.3 and 10.1 times that of Earth, respectively.\nBrown dwarfs.\nThe discovery of a binary brown dwarf system named Luhman 16 only 6.6 light-years away, the third-closest system to the Solar System, was announced on 11 March 2013.\nDeep-sky objects.\nOf the deep-sky objects of interest in Vela is a planetary nebula known as NGC 3132, nicknamed the 'Eight-Burst Nebula' or 'Southern Ring Nebula' (see accompanying photo). It lies on the border of the constellation with Antlia. NGC 2899 is an unusual red-hued example. This constellation has 32 more planetary nebulae.\nThe Gum Nebula is a faint emission nebula, believed to be the remains of a million-year-old supernova. Within it lies the smaller and younger Vela Supernova Remnant. This is the nebula of a supernova explosion that is believed to have been visible from Earth around 10,000 years ago. The remnant contains the Vela Pulsar, the first pulsar to be identified optically. Nearby is NGC 2736, also known as the Pencil Nebula.\nHH-47 is a Herbig-Haro Object, a young star around 1,400 light-years from the Sun that is ejecting material at tremendous speed (up to a million kilometres per hour) into its surrounds. This material glows as it hits surrounding gas.\nNGC 2670 is an open cluster located in Vela. It has an overall magnitude of 7.8 and is 3,200 light-years from Earth. The stars of NGC 2670, a Trumpler class II 2 p and Shapley class-d cluster, are in a conformation suggesting a bow and arrow. Its class indicates that it is a poor, loose cluster, though detached from the star field. It is somewhat concentrated at its center, and its less than 50 stars range moderately in brightness.\nLocated 2 degrees south of Gamma Velorum, NGC 2547 is an open cluster containing around 50 stars of magnitudes 7 to 15.\nNGC 3201 is a globular cluster discovered by James Dunlop on May 28, 1826. Its stellar population is inhomogeneous, varying with distance from the core. The effective temperature of the stars shows an increase with greater distance, with the redder and cooler stars tending to be located closer to the core. As of 2010, is one of only two clusters (including Messier 4) that shows a definite inhomogeneous population.\nRCW 36 is a star-forming region in Vela, and one of the nearest sites of massive star formation. This star-forming region has given rise to a cluster of several hundred young stars that power an HII region. The star-forming region lies in Clump 6 in the Vela Molecular Ridge Cloud C.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32569", "revid": "51029584", "url": "https://en.wikipedia.org/wiki?curid=32569", "title": "Vitellius", "text": "Roman emperor in AD 69\nAulus Vitellius ( ; ; 24 September 15\u00a0\u2013 20 December 69) was Roman emperor for eight months, from 19 April to 20 December AD 69. Vitellius became emperor following the quick succession of the previous emperors Galba and Otho, in a year of civil war known as the Year of the Four Emperors. Vitellius added the honorific \"Germanicus\" to his name instead of \"Caesar\" upon his accession. Like his predecessor, Otho, Vitellius attempted to rally public support to his cause by honoring and imitating Nero who remained popular in the empire.\nOriginally from Campania, likely from Nuceria Alfaterna, he was born to the Vitellia gens, a relatively obscure family in ancient Rome. He was a noble companion of Tiberius' retirement on Capri and there befriended Caligula. He was elected consul in 48, and served as proconsular governor of Africa in either 60 or 61. In 68, he was chosen to command the army of Germania Inferior by emperor Galba. He was later proclaimed emperor in January by the armies of Germania Inferior and Superior, beginning a revolt against Galba. Galba was assassinated by Otho, and Vitellius then faced Otho in battle. He defeated Otho at the Battle of Bedriacum, and was recognized emperor by the Roman Senate.\nHis claim to the throne was soon challenged by legions stationed in the eastern provinces, who proclaimed their commander Vespasian emperor instead. War ensued, leading to a crushing defeat for Vitellius at the Second Battle of Bedriacum in northern Italy. Once he realised his support was wavering, Vitellius prepared to abdicate in favor of Vespasian. He was not allowed to do so by his supporters, resulting in a brutal battle for Rome between Vitellius' forces and the armies of Vespasian. He was executed in Rome by Vespasian's soldiers on 20 December 69.\nEarly life.\nAulus Vitellius was born on 24 September 15, in Nuceria Alfaterna, Campania. He was the son of Lucius Vitellius and his wife Sextilia, and had one brother, who was also named Lucius Vitellius. Suetonius recorded two different accounts of the origins of the gens Vitellia, one making them descendants of past rulers of Latium, the other describing their origins as lowly.\nSuetonius makes the sensible remark that both accounts might have been made by either flatterers or enemies of Vitellius\u2014except that both were in circulation before Vitellius became emperor. Since his father was a member of the equestrian class and achieved the senatorial rank only later in his lifetime, Vitellius became the first emperor not to be born in the senatorial family. Suetonius also recorded that when Vitellius was born his horoscope so horrified his parents that his father tried to prevent Aulus from becoming a consul.\nIn his youth, he was one of the noble companions of Tiberius' retirement on Capri. Shortly thereafter, Vitellius was able to befriend the young Caligula, due to their common passion for chariots and games of dice.\nPublic service.\nPolitical and military career.\nHe was consul in 48, and proconsular governor of Africa in either 60 or 61, in which capacity he is said to have acquitted himself with credit. At the end of 68, Galba, to the general astonishment, selected him to command the army of Germania Inferior, and here Vitellius made himself popular with his subalterns and with the soldiers by outrageous prodigality and excessive good nature, which soon proved fatal to order and discipline.\nBid for power.\nHe owed his elevation to the throne to Caecina and Fabius Valens, commanders of two legions on the Rhine. Through these two men a military revolution was speedily accomplished; they refused to renew their vows of allegiance to Emperor Galba on 1 January 69. Vitellius was proclaimed emperor at Cologne on the following day, and then again on the day after. More accurately, he was proclaimed emperor of the armies of Germania Inferior and Superior. The armies of Gaul, Britannia and Raetia sided with them shortly afterwards. By the time that they marched on Rome, however, it was Otho, and not Galba, whom they had to confront.\nIn fact, he was never acknowledged as emperor by the entire Roman world, though at Rome the Senate accepted him and decreed to him the imperial honours on 19 April. He advanced into Italy at the head of a licentious and rough soldiery, and Rome became the scene of riot and massacre, gladiatorial shows and extravagant feasting. To reward his victorious legionaries, Vitellius expanded the existing Praetorian Guard and installed his own men from his Rhine army.\nEmperor.\nAdministration.\nSuetonius, whose father had fought for Otho at Bedriacum, gives an unfavourable account of Vitellius' brief administration: he describes him as unambitious and notes that Vitellius showed indications of a desire to govern wisely, but that Valens and Caecina encouraged him in a course of vicious excesses which threw his better qualities into the background. He is even reported to have starved his own mother to death\u2014to fulfill a prophecy by a Chattian seeress that he would rule longer if his mother died first; alternatively there is a report that his mother asked for poison to commit suicide\u2014a request he granted. Suetonius additionally remarks that Vitellius' besetting sins were luxury and cruelty. Other writers, namely Tacitus and Cassius Dio, disagree with some of Suetonius' assertions, even though their own accounts are scarcely positive ones.\nDespite his short reign he made two important government contributions which outlasted him. Tacitus describes them both in his \"Histories\":\nVitellius also banned astrologers from Rome and Italy on 1 October 69. Some astrologers responded to his decree by anonymously publishing a decree of their own: \"Decreed by all astrologers in blessing on our State Vitellius will be no more on the appointed date.\" In response, Vitellius executed any astrologers he came across.\nFurthermore, Vitellius continued Otho's policies in regard to Nero's memory, in that he honored the dead emperor and sacrificed to his spirit. He also had Nero's songs performed in public, and attempted to imitate Nero, who remained extremely popular among the lower classes of the Roman Empire.\nReputation.\nSuetonius is particularly responsible for giving Vitellius the reputation of being an obese glutton, using emetics so as to be able to indulge in banquets four times a day, and often having himself invited over to a different noble's house for each one. One of the most famous of these feasts was offered Vitellius by his brother Lucius, at which, it is said, there were served up no less than two thousand choice fishes, and seven thousand birds. Yet even this supper he himself outdid, at a feast which he gave upon the first use of a dish which had been made for him, and which, for its extraordinary size, he called \"The Shield of Minerva\". In this dish there were tossed up together the livers of pike, the brains of pheasants and peacocks, with the tongues of flamingos, and the entrails of lampreys, which had been brought in ships of war as far as from Parthia and the Spanish Straits. A noted gourmet of that time, Marcus Gavius Apicius, named after the emperor a less exotic dish of peas or broad beans mashed with sweet and sour ingredients. Edward Gibbon, in \"The History of the Decline and Fall of the Roman Empire\", refers to \"the beastly Vitellius\" among \"the unworthy successors of Augustus\", adding in a footnote:Vitellius consumed in mere eating at least six millions of our money, in about seven months. It is not easy to express his vices with dignity, or even decency. Tacitus fairly calls him a hog; but it is by substituting for a coarse word a very fine image.\nChallenges.\nIn July 69, Vitellius learned that the armies of the eastern provinces had proclaimed a rival emperor: their commander, Titus Flavius Vespasianus. As soon as it was known that the armies of the East, Dalmatia, and Illyricum had declared for Vespasianus, Vitellius sent several legions under Caecina to prevent the Eastern armies from entering Italy, but Caecina, dissatisfied with Vitellius's poor administration, attempted without success to defect to Vespasian. This undermined the morale of the Vitellian legions, and they were decisively defeated at the Second Battle of Bedriacum. Fabius Valens was then sent by Vitellius to rally supporting armies in Gaul, but forces loyal to Vespasian captured and executed him soon after. Vitellius, now deserted by many of his adherents, prepared to abdicate the title of emperor.\nAbdication and death.\nTacitus' \"Histories\" state that Vitellius awaited Vespasian's army at Mevania. The terms of abdication had actually been agreed upon with Marcus Antonius Primus, the commander of the sixth legion serving in Pannonia and one of Vespasian's chief supporters. However, as he was on his way to deposit the insignia of empire in the Temple of Concord, the Praetorian Guard refused to allow him to carry out the agreement, and forced him to return to the palace.\nOn the entrance of Vespasian's troops into Rome, Vitellius' supporters (mostly civilians) organized heavy resistance, resulting in a brutal battle. Entrenched on the city's buildings, they threw stones, javelins, and tiles on Vespasian's soldiers who consequently suffered heavy casualties in the urban fighting. Cassius Dio claims that 50,000 people died in the battle for Rome. Large parts of the city were destroyed, including the Temple of Jupiter Optimus Maximus. Vitellius was eventually dragged out of a hiding-place (according to Tacitus a door-keeper's lodge), driven to the fatal Gemonian stairs, and there struck down by Vespasian's supporters. \"Yet I was once your emperor,\" were his last words. His body was thrown into the Tiber according to Suetonius; Cassius Dio's account is that Vitellius was beheaded and his head paraded around Rome, and his wife attended to his burial. His brother and son were also killed.\nSuetonius, in writing of Vitellius' execution, offers his physical description: \"...He was in fact abnormally tall, with a face usually flushed from hard drinking, a huge belly, and one thigh crippled from being struck once by a four-horse chariot, when he was in attendance on Gaius as he was driving...\"\nAccording to Suetonius more than fifty years later, several years before Vitellius' death there was a prediction that he would fall into the power of a man from Gaul. Marcus Antonius Primus was from Toulouse in Gaul, and his nickname was Becco which means \"rooster's beak\": Gallus means both \"a cock\" and \"a Gaul\".\nPersonal life.\nHe married firstly a woman named Petronia, who was the daughter of an ex-consul. They had a son, Aulus Vitellius Petronianus, who was blind in one eye. He was the universal heir of his mother and grandfather, but Vitellius had him killed in 69 in order to inherit his fortune. He married secondly, around the year 50, a woman named Galeria Fundana, perhaps the granddaughter of Gaius Galerius, Prefect of Egypt in 23. They had two children, a son, who was named as heir and was given the title \"Germanicus\", and a daughter, Vitellia, who married Decimus Valerius Asiaticus.\nPortrayals.\nIn coinage.\nAs Vitellius was not recognised emperor by the Senate until 19 April 69\u2014soon after Otho's suicide\u2014he had to rely on other mints for his coin supply until his arrival at Rome. He first used the Spanish mint of Tarraco (now Tarragona) from January 69, then the mint of Lugdunum (now Lyon, France) a bit later. Taracco produced much more coins than Lugdunum, which might have not even struck bronze coinage. These two mints closed at the beginning of summer 69, by which time the mint of Rome had taken over.\nEvery coin of Vitellius features the title \"Germanicus\", referring to the legions of the Rhine that supported his bid for power. Regardless of the mint, this title was progressively shortened to \"Germ\" on the coins. Numismatist C. H. V. Sutherland notes that the prevalence of the title indicates that Vitellius used it almost like a cognomen. The coins Vitellius minted before his official proclamation as Emperor on 19 April do not bear the title \"Augustus\", while the title \"Pontifex Maximus\" appears on coins minted after his election at this title on 18 July.\nThe last type of coin minted by Vitellius were aurei and denarii with the goddess Victory building a trophy, likely alluding to his hopeful victory against the incoming armies of Vespasian.\nIn art.\nBusts from the time of Vitellius, particularly the one in the Capitoline Museums, represent him as broad-faced with several double chins, and it is this type which informs paintings of the emperor from the Renaissance on. There were once other ancient busts claimed to be of Vitellius which later scholarship has proved to be of someone else. The features of the Grimani Vitellius particularly, according to Mary Beard, were once used by painters to suggest that the character who bears them is destined to come to a bleak end. Another such bust figures in Michiel Sweerts' Baroque genre piece of a young art student drawing a copy.\nThe Grimani portrait bust also served as the model for one by Giovanni Battista and Nicola Bonanome (ca.1565), one of a series of The Twelve Caesars that were once fashionable in large households. The series was also a popular subject for paintings, of which there have been examples by Titian, Peter Paul Rubens, Otto van Veen, and many others.\nSeveral 19th-century French artists pictured the violent end of Vitellius. That by Georges Rochegrosse (1883) depicts him being dragged by the populace down the steep Gemonian stairs, stretching from high on the canvas to its foot [see above]. There he appears bound and surrounded by a gesticulating mob with hooting ragamuffins at their head. The stairs are covered with the rubbish with which the deposed emperor has been pelted and, as Suetonius describes the scene, a long blade is held at his throat so that he cannot look down. Others paintings show the moment of his execution, of which there are examples by Charles-Gustave Housez, Paul-Jacques-Aim\u00e9 Baudry (1847), Jules-Eug\u00e8ne Lenepveu (1847), and an engraving by Edouard Vimont (1876\u20131930).\nMuch as the appearance of Vitellius prefigured approaching doom in earlier centuries, Thomas Couture pictures him in shadow to the left of centre in the painting \"The Romans in their Decadence\" (1847). This was shown prophetically at the Paris Salon in the year before the French Revolution of 1848 toppled the July Monarchy.\nIn literature.\nThe earliest fictional appearance of a Vitellius was of the Roman Consul in Syria, Lucius Vitellius (the father of Aulus), who intervened in Judaean affairs in the time of Pontius Pilate. It is he who figures in Gustave Flaubert's novella \"H\u00e9rodias\" (1877) and in \"H\u00e9rodiade\", the 1881 opera based on it by Jules Massenet. The same character also makes an appearance in the 1930 novel by Iwan Naschiwin (1874\u20131940), \"A Certain Jesus: the Gospel According to Thomas : an Historical Novel of the First Century\".\nThe son of Lucius, Aulus Vitellius, played a minor part in Henryk Sienkiewicz's novel \"Quo Vadis\", set at the end of Nero's reign. Although he survived as a character in the 1900 Broadway production, and in the Italian films based on it of 1913 and 1924, he disappeared from later adaptations. But some later novels deal with incidents in the military career of this Vitellius. In Simon Scarrow's Eagles of the Empire series, he is introduced as a rival to Vespasian during the Roman invasion of Britain. And in later chapters of Henry Venmore-Rowland's novel \"The Last Caesar\" (2012) he figures as the newly appointed Governor of Lower Germania and something of a glutton.\nNaturally Vitellius is a character in the rash of recent novels dealing with the Year of the Four Emperors. He is in the background in Kate Quinn's novel \"Daughters of Rome\" (2011), and shares a section of Steven Saylor's \"Empire: The Novel of Imperial Rome\" (2010). His fall features in M C Scott's \"Rome, The Art of War\" (2013), and he also appears in James Mace's two-part series, \"The Year of the Four Emperors\".\nBust portraits.\nSeveral busts have been thought to depict Vitellius, but these identifications are usually based on vague resemblances with coin portraits. In reality it's almost impossible to identify most busts with any particular emperor, specially with one as short-lived as Vitellius.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "32570", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=32570", "title": "Vespasian", "text": "Roman emperor from AD 69 to 79\nVespasian (; ; 17 November AD 9 \u2013 23 June 79) was Roman emperor from 69 to 79. The last emperor to reign in the Year of the Four Emperors, he founded the Flavian dynasty, which ruled the empire for 27 years. His fiscal reforms and consolidation of the empire brought political stability and a vast building program.\nVespasian was the first emperor from an equestrian family who rose only later in his lifetime into the senatorial rank as the first of his family to do so. He rose to prominence through military achievement: he served as legate of Legio II Augusta during the Roman invasion of Britain in 43, and later led the suppression of the Jewish rebellion of 66\u201370.\nWhile he was engaged in the campaign in Judaea, Emperor Nero died by suicide in June 68, plunging Rome into a year of civil war known as the Year of the Four Emperors. After Galba and Otho perished in quick succession, Vitellius became emperor in April 69. The Roman legions of Egypt and Judaea reacted by declaring Vespasian, their commander, the emperor on 1 July 69. In his bid for imperial power, Vespasian joined forces with Mucianus, the governor of Syria, and Primus, a general in Pannonia, leaving his son Titus to command the besieging forces at Jerusalem. Primus and Mucianus led the Flavian forces against Vitellius, while Vespasian took control of Egypt. On 20 December 69, Vitellius was defeated, and the following day Vespasian was declared emperor by the Senate.\nLittle information survives about the government during Vespasian's ten-year rule. He reformed the financial system of the Roman Empire after the campaign against Judaea ended successfully, and initiated several ambitious construction projects, including the building of the Flavian Amphitheatre, better known today as the Colosseum. Through his general Agricola, Vespasian increased imperial expansion in Britain. Vespasian is often credited with restoring political stability to Rome following the chaotic reigns of his predecessors. After he died in 79, he was succeeded by his eldest son Titus, thus becoming the first Roman emperor to be succeeded by his natural son and establishing the Flavian dynasty.\nEarly life.\nVespasian (born Titus Flavius Vespasianus, pronounced ) was born in a village north-east of Rome called Falacrinae. His family was relatively undistinguished and lacking in pedigree. Vespasian was the son of Titus Flavius Sabinus, a Roman moneylender, debt collector, and tax collector. His mother, Vespasia Polla, also belonged to the equestrian order in society, with her father rising to the rank of prefect of the camp and her brother becoming a Senator.\nHe was educated in the countryside, in Cosa, near what is today Ansedonia, Italy, under the guidance of his paternal grandmother, so much so that even when he became emperor, he often returned to the places of his childhood, having left the former villa exactly as it had been.\nEarly in his life he was somewhat overshadowed by his older brother, Titus Flavius Sabinus, who had entered public life and pursued the \"cursus honorum,\" holding an important military command in the Danube.\nMilitary and political career.\nEarly career.\nIn preparation for a praetorship, Vespasian needed two periods of service in the minor magistracies, one military and the other public. Vespasian served in the military in Thracia for about three years. On his return to Rome in about 30 AD, he obtained a post in the \"vigintivirate\", the minor magistracies, most probably in one of the posts in charge of street cleaning. His early performance was so unsuccessful that Emperor Caligula reportedly stuffed handfuls of muck down his toga to correct the uncleaned Roman streets, formally his responsibility.\nDuring the period of the ascendancy of Sejanus, there is no record of Vespasian engaging in any significant political activity. After completion of a term in the vigintivirate, Vespasian was entitled to stand for election as quaestor, a senatorial office. However, his lack of political or family influence meant that Vespasian served as quaestor in one of the provincial posts in Crete, rather than as assistant to important men in Rome.\nNext he needed to gain a praetorship, carrying the \"Imperium\", but non-patricians and the less well-connected had to serve in at least one intermediary post as an \"aedile\" or tribune. Vespasian failed at his first attempt to gain an aedileship but was successful in his second attempt, becoming an aedile in 38. Despite his lack of significant family connections or success in office, he achieved praetorship in either 39 or 40, at the youngest age permitted (30), during a period of political upheaval in the organisation of elections. His long-standing relationship with freed-woman Antonia Caenis, confidential secretary to Antonia Minor (the Emperor's grandmother) and part of the circle of courtiers and servants around the Emperor, may have contributed to his success.\nInvasion of Britannia.\nUpon the accession of Claudius as emperor in 41, Vespasian was appointed legate of Legio II \"Augusta\", stationed in Germania, thanks to the influence of the Imperial freedman Narcissus. In 43, Vespasian and the II \"Augusta\" participated in the Roman invasion of Britain, and he distinguished himself under the overall command of Aulus Plautius. After participating in crucial early battles on the rivers Medway and Thames, he was sent to reduce the south west, penetrating through regions later known as the counties of Hampshire, Wiltshire, Dorset, Somerset, Devon and Cornwall with the probable objectives of securing the south coast ports and harbours along with the tin mines of Cornwall and the silver and lead mines of Somerset.\nVespasian marched from Noviomagus Reginorum (Chichester) to subdue the hostile Durotriges and Dumnonii tribes, and captured twenty \"oppida\" (towns, or more probably hill forts, including Hod Hill and Maiden Castle in Dorset). He also invaded Vectis (now the Isle of Wight), finally setting up a fortress and legionary headquarters at Isca Dumnoniorum (Exeter). During this time he injured himself and had not fully recovered until he went to Egypt. These successes earned him triumphal regalia (\"ornamenta triumphalia\") on his return to Rome.\nLater political career.\nHis success as the legate of a legion earned him a consulship in 51, after which he retired from public life, having incurred the enmity of Claudius' wife, Agrippina, who was the most powerful and influential figure in her husband's reign. He came out of retirement in 63 when he was sent as governor to Africa Province. According to Tacitus (ii.97), his rule was \"infamous and odious\" but according to Suetonius (\"Vesp.\" 4), he was \"upright and, highly honourable\". On one occasion, Suetonius writes, Vespasian was pelted with turnips.\nVespasian used his time in North Africa wisely. Usually, governorships were seen by ex-consuls as opportunities to extort huge amounts of money to regain the wealth they had spent on their previous political campaigns. Corruption was so rife that it was almost expected that a governor would come back from these appointments with his pockets full. However, Vespasian used his time in North Africa making friends instead of money, something that would be far more valuable in the years to come. During his time in North Africa, he found himself in financial difficulties and was forced to mortgage his estates to his brother. To revive his fortunes he turned to the mule trade and gained the nickname \"mulio\" (muleteer).\nReturning from Africa, Vespasian toured Greece in Nero's retinue, but lost Imperial favor after paying insufficient attention (some sources suggest he fell asleep) during one of the Emperor's recitals on the lyre, and found himself in the political wilderness.\nFirst Jewish Revolt.\nIn 66 AD, Vespasian was appointed to suppress the Jewish revolt underway in Judea. The fighting there had killed the previous governor and routed Cestius Gallus, the governor of Syria, when he tried to restore order. Two legions, with eight cavalry squadrons and ten auxiliary cohorts, were therefore dispatched under the command of Vespasian while his elder son, Titus, arrived from Alexandria with another.\nDuring this time he became the patron of Flavius Josephus, a Jewish resistance leader captured at the Siege of Yodfat, who would later write his people's history in Greek. Ultimately, thousands of Jews were killed and the Romans destroyed many towns in re-establishing control over Judea; they also took Jerusalem in 70. Vespasian is remembered by Josephus (writing as a Roman citizen), in his \"Antiquities of the Jews\", as a fair and humane official, in contrast with the notorious Herod Agrippa II whom Josephus goes to great lengths to demonize.\nWhile under the emperor's patronage, Josephus wrote that after the Roman Legio X Fretensis, accompanied by Vespasian, destroyed Jericho on 21 June 68, Vespasian took a group of Jews who could not swim (possibly Essenes from Qumran), fettered them, and threw them into the Dead Sea to test the sea's legendary buoyancy. Indeed, the captives bobbed up to the surface after being thrown in the water from the boats.\nAt the conclusion of the Jewish war, Josephus discussed a prophecy from sacred scripture that about the time when Jerusalem and the Second Temple would be taken, a man from their own nation would become \"governor of the habitable earth\", as in the Messiah. Josephus interpreted the prophecy as denoting the government of Vespasian. Tacitus agreed that the prophecy discussed Vespasian (as well as Titus), but that \"the common people, with the usual blindness of ambition, had interpreted these mighty destinies of themselves, and could not be brought even by disasters to believe the truth.\"\nYear of the Four Emperors (69).\nAfter the death of Nero in 68, Rome saw a succession of short-lived emperors and a year of civil wars. Galba was murdered by supporters of Otho, who was defeated by Vitellius. Otho's supporters, looking for another candidate to support, settled on Vespasian. According to Suetonius, a prophecy ubiquitous in the Eastern provinces claimed that from Judaea would come the future rulers of the world. Vespasian eventually believed that this prophecy applied to him, and found a number of omens and oracles that reinforced this belief.\nAlthough Vespasian and Titus resolved to challenge for the Principate in February 69, they made no move until later in the year. Throughout the early months of 69, Vespasian convened frequently with the Eastern generals. Gaius Licinius Mucianus was a notable ally. Governor of Syria and commander of three legions, Mucianus also held political connections to many of the most powerful Roman military commanders from Illyricum to Britannia by virtue of his service to the famous Neronian general Gnaeus Domitius Corbulo. In May 69, Mucianus formally implored Vespasian to challenge Vitellius. His appeal was followed by Vespasian's official proclamation as Emperor in early July. Under instructions from the prefect Tiberius Alexander, the legions at Alexandria took an oath of loyalty to Vespasian on 1 July. They were swiftly followed by Vespasian's Judaean legions on 3 July and thereafter by Mucianus' Syrian legions on 15 July.\nVitellius, the occupant of the throne, had the veteran legions of Gaul and the Rhineland. But the feeling in Vespasian's favour quickly gathered strength, and the armies of Moesia, Pannonia, and Illyricum soon declared for him. The \"praefectus Aegypti\", who had been governor since Nero's reign, proclaimed Vespasian emperor at Alexandria on 1 July 69 AD.\nWhile Vespasian himself was in Egypt, his troops entered Italy from the northeast under the leadership of Marcus Antonius Primus. They defeated Vitellius' army (which had awaited him in Mevania) at Bedriacum (or Betriacum), sacked Cremona and advanced on Rome. Vitellius hastily arranged a peace with Antonius, but the Emperor's Praetorian Guard forced him to retain his seat. After furious fighting, Antonius' army entered Rome. In the resulting confusion, the Capitol was destroyed by fire and both Vitellius and Vespasian's brother Sabinus were killed. At Alexandria, Vespasian immediately sent supplies of urgently needed grain to Rome, along with an edict assuring he would reverse the laws of Nero, especially those relating to treason.\nHe was the first emperor since Augustus to appear in Egypt. While there, he visited the Temple of Serapis where he reportedly experienced a vision, and he performed healing miracles. He was hailed as pharaoh and proclaimed the son of the creator-deity Amun (Zeus-Ammon) in the style of the ancient pharaohs, and an incarnation of Serapis in the manner of the Ptolemies.\nEmperor (69\u201379).\nAftermath of the civil war.\nVespasian was declared emperor by the Senate while he was in Egypt on 21 December 69 through the passage of the \"Lex de imperio Vespasiani\"; the Egyptians had declared him emperor in the summer. In the short-term, administration of the empire was given to Mucianus, who was aided by Vespasian's son, Domitian. Mucianus started off Vespasian's rule with tax reform that was to restore the empire's finances. After Vespasian arrived in Rome in mid-70, Mucianus continued to press Vespasian to collect as many taxes as possible.\nVespasian and Mucianus renewed old taxes and instituted new ones, increased the tribute of the provinces, and kept a watchful eye upon the treasury officials.\nBefore Vespasian, Emperor Nero introduced a urine tax on public toilets under the name of \"vectigal urinae\" in the 1st century AD (see Pay toilet). However, the tax was removed after a while and it was Vespasian's new imposition of this tax around AD 70 which we still remember to this day, possibly giving origin to the Latin proverb \"Pecunia non olet\" (\"Money does not stink\"): Writing about Vespasian in their history books, Dio Cassius and Suetonius mentioned \"When [Vespasian's] son Titus blamed him for even laying a tax upon urine, he applied to his nose a piece of the money he received in the first instalment, and asked him if it stunk. And he replying no, 'And yet,' said he, 'it is derived from urine\". Since then, this phrase \"Money does not stink\" has been used to whitewash dubious or illegal origin of money.\nTurmoil through the Empire.\nIn early 70 Vespasian was still in Egypt, the source of Rome's grain supply, and had not yet left for Rome. According to Tacitus, his trip was delayed due to bad weather. Modern historians theorize that Vespasian had been and was continuing to consolidate support from the Egyptians before departing. During this period, protests erupted in Alexandria over his new tax policies and grain shipments were held up. Vespasian eventually restored order and grain shipments to Rome resumed. Notably Titus attended the consecration of a new Apis bull at Memphis in 70, and Vespasian's reign saw imperial patronage given to Egyptian temples: at the Dakhla Oasis in the Western Desert as well as Esna, Kom Ombo, Medinet Habu, Silsila in the Nile Valley.\nIn addition to the uprising in Egypt, unrest and civil war continued in the rest of the empire in 70. Judea had been rebelling since 66. Vespasian's son, Titus, finally subdued the rebellion with the capture of Jerusalem and destruction of the Jewish Temple in 70. According to Eusebius, Vespasian then ordered all descendants of the royal line of David to be hunted down, causing the Jews to be persecuted from province to province. Several modern historians have suggested that Vespasian, already having been told by Josephus that he was prophesied to become emperor whilst in Judaea, was probably reacting to other widely known Messianic prophecies circulating at the time, to suppress any rival claimants arising from that dynasty. The Jewish temple at Leontopolis was sacked in 73.\nIn January 70, an uprising occurred in Gaul and Germany, known as the second Batavian Rebellion. This rebellion was headed by Gaius Julius Civilis and Julius Sabinus. Sabinus, claiming he was descended from Julius Caesar, declared himself Emperor of Gaul. The rebellion defeated and absorbed two Roman legions before it was suppressed by Vespasian's son-in-law, Quintus Petillius Cerialis, by the end of 70.\nArrival in Rome and consolidation of power.\nIn mid-70, Vespasian first went to Rome, dating his tribunician years from 1 July 69. Vespasian immediately embarked on a series of efforts to stay in power and prevent future revolts. He offered gifts to many in the military and much of the public. Soldiers loyal to Vitellius were dismissed or punished. Vespasian also restructured the Senatorial and Equestrian orders, removing his enemies and adding his allies. Regional autonomy of Greek provinces was repealed.\nPropaganda campaign.\nWe know from Suetonius that the \"unexpected and still quite new emperor was lacking \"auctoritas\" [] and a certain \"maiestas\" []\". Many modern historians note the increased amount of propaganda that appeared during Vespasian's reign. A component of the propaganda was the theology of victory, which legitimized the right to rule through successful conquest. This revolved around Vespasian's victory in Judea. Stories of a supernatural emperor who was destined to rule circulated in the empire. Nearly one-third of all coins minted in Rome under Vespasian celebrated military victory or peace. The word \"vindex\" was removed from coins so as not to remind the public of rebellious Vindex. Construction projects bore inscriptions praising Vespasian and condemning previous emperors. A temple of peace was constructed in the forum as well.\nConstruction and conspiracies.\nBetween 71 and 79, much of Vespasian's reign is a mystery. Historians report that Vespasian ordered the construction of several buildings in Rome. Additionally, he survived several conspiracies against him. Vespasian helped rebuild Rome after the civil war. He added the temple of Peace and the temple to the Deified Claudius. In 75, he erected a colossal statue of Apollo, begun under Nero, and he dedicated a stage of the theatre of Marcellus. He also began construction of the Colosseum, using funds from the spoils of the Jewish Temple after the Siege of Jerusalem. Suetonius claims that Vespasian was met with \"constant conspiracies\" against him. Only one conspiracy is known specifically, though. In 78 or 79, Eprius Marcellus and Aulus Caecina Alienus attempted to kill Vespasian. Why these men turned against Vespasian is not known.\nRoman expansion in Britain.\nAgricola was appointed to the command of the \"Legio XX Valeria Victrix\", stationed in Britain, in place of Marcus Roscius Coelius, who had stirred up a mutiny against the governor, Marcus Vettius Bolanus. Britain had revolted during the year of civil war, and Bolanus was a mild governor. Agricola reimposed discipline on the legion and helped to consolidate Roman rule. In 71, Bolanus was replaced by a more aggressive governor, Quintus Petillius Cerialis, and Agricola was able to display his talents as a commander in campaigns against the Brigantes in northern England.\nDeath.\nIn his ninth consulship Vespasian had a slight illness in Campania and, returning at once to Rome, he left for Aquae Cutiliae and the country around Reate, where he spent every summer; however, his illness worsened and he developed severe diarrhea.\nWith the feeling of death overwhelming him on his deathbed, he incited: \"Vae, puto deus fio.\" (\"Dear me, I think I'm becoming a god\"). Then, according to Suetonius' \"The Twelve Caesars\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Taken on a sudden with such an attack of diarrhoea that he all but swooned, he said: \"An emperor ought to die standing,\" and while he was struggling to get on his feet, he died in the arms of those who tried to help him, on the ninth day before the Kalends of July [June 23], at the age of sixty-nine years, seven months and seven days.\u2014\u200a He died on June 23, 79 AD, and was succeeded by his sons Titus and then Domitian.\nLegacy.\nVespasian was known for his wit and his amiable manner alongside his commanding personality and military prowess. He could be liberal to impoverished Senators and equestrians and to cities and towns desolated by natural calamity. He was especially generous to men of letters and rhetors, several of whom he pensioned with salaries of as much as 1,000 gold pieces a year. Quintilian is said to have been the first public teacher who enjoyed this imperial favor. Pliny the Elder's work, the \"Natural History\", was written during Vespasian's reign, and dedicated to Vespasian's son Titus.\nVespasian distrusted philosophers in general. It was the talk of philosophers, who liked to glorify the Republic, that provoked Vespasian into reviving the obsolete penal laws against this profession as a precautionary measure.\nHe was also noted for his benefactions to the people. Much money was spent on public works and the restoration and beautification of Rome: the Temple of Peace (also known as the Forum of Vespasian), new public baths and the great show piece, the Colosseum.\nVespasian slightly debased the denarius during his reign, reducing the silver purity from 93.5% to 90%. The silver weight dropped from 2.97\u00a0grams to 2.87\u00a0grams.\nIn modern Romance languages, urinals are named after him (for example, \"vespasiano\" in Italian, and \"vespasienne\" in French), probably in reference to a tax he placed on urine collection.\nForging History.\nVespasian approved histories written under his reign, ensuring biases against him were removed. He also gave financial rewards to writers. The ancient historians who lived through the period such as Tacitus, Suetonius and Josephus speak suspiciously well of Vespasian while condemning the emperors who came before him. Tacitus admits that his status was elevated by Vespasian, Josephus identifies Vespasian as a patron and saviour. Meanwhile, Pliny the Elder dedicated his \"Natural Histories\" to Vespasian's son, Titus.\nThose who spoke against Vespasian were punished. A number of Stoic philosophers were accused of corrupting students with inappropriate teachings and were expelled from Rome. Helvidius Priscus, a pro-Republic philosopher, was executed for his teachings. Numerous other philosophers and writers had their works seized, destroyed and denounced for being deemed too critical of Vespasian's reign, some even posthumously.\nAccording to Suetonius' version of events, however, Vespasian \"bore the frank language of his friends, the quips of pleaders, and the impudence of the philosophers with the greatest patience\" as it was only Helvidius Priscus to be put to death after he repeatedly affronted the Emperor with studied insults which he initially tried to ignore; the philosopher Demetrius for example was banished to an island and when Vespasian heard that Demetrius was still criticizing him, sending the exiled philosopher the message: \"You are doing everything to force me to kill you, but I do not slay a barking dog.\"\nFamily and personal life.\nAncestors and relatives.\nHis paternal grandfather, Titus Flavius Petro, became the first to distinguish himself, rising to the rank of centurion and fighting at Pharsalus for Pompey in 48 BC. Subsequently, he became a debt collector. Petro's son, Titus Flavius Sabinus, worked as a customs official in the province of Asia and became a moneylender on a small scale among the Helvetii. He earned a reputation as a scrupulous and honest \"tax-farmer\". Sabinus married up in status, to Vespasia Polla, whose father had risen to the rank of prefect of the camp and whose brother became a Senator.\nSabinus and Vespasia had three children, the eldest of whom, a girl, died in infancy. The elder boy, Titus Flavius Sabinus, entered public life and pursued the \"cursus honorum\". Vespasian on the other hand, seemed far less likely to be successful, initially not wishing to pursue high public office. He followed in his brother's footsteps when driven to it by his mother's taunting.\nMarriage and children.\nDuring this period he married Flavia Domitilla, the daughter of Flavius Liberalis from Ferentium and formerly the mistress of Statilius Capella, a Roman equestrian from Sabratha in Africa. They had two sons, Titus Flavius Vespasianus (born 39) and Titus Flavius Domitianus (born 51), and a daughter, Domitilla (born c.\u200945). His wife Domitilla and his daughter Domitilla both died before Vespasian became Emperor in 69. After the death of his wife, Vespasian's long-standing mistress, Antonia Caenis, became his wife in all but formal status, a relationship that continued until she died in 75.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
