{"id": "36752", "revid": "48227547", "url": "https://en.wikipedia.org/wiki?curid=36752", "title": "World Bank Group", "text": "Group making loans to developing countries\nThe World Bank Group (WBG) is a family of five international organizations that make leveraged loans to developing countries. It is the largest and best-known development bank in the world and an observer at the United Nations Development Group. The bank is headquartered in Washington, D.C., in the United States. It provided around $98.83\u00a0billion in loans and assistance to \"developing\" and transition countries in the 2021 fiscal year. The bank's stated mission is to achieve the twin goals of ending extreme poverty and building shared prosperity. Total lending as of 2015 for the last 10 years through Development Policy Financing was approximately $117\u00a0billion. Its five organizations have been established over time:\nThe first two are sometimes collectively referred to as the World Bank. They provide loans and grants to the governments of low- and middle-income countries for the purpose of pursuing economic development. These activities include fields such as human development (e.g. education, health), agriculture and rural development (e.g. irrigation and rural services), environmental protection (e.g. pollution reduction, establishing and enforcing regulations), infrastructure (e.g. roads, urban regeneration, and electricity), large industrial construction projects, and governance (e.g. anti-corruption, legal institutions development). The IBRD and IDA provide loans at preferential rates to member countries, as well as grants to the poorest countries. Loans or grants for specific projects are often linked to wider policy changes in the sector or the country's economy as a whole. For example, a loan to improve coastal environmental management may be linked to the development of new environmental institutions at national and local levels and the implementation of new regulations to limit pollution. Furthermore, the World Bank Group is recognized as a leading funder of climate investments in developing countries.\nThe World Bank was established along with the International Monetary Fund at the 1944 Bretton Woods Conference. Initially, its loans helped rebuild countries devastated by World War II. Over time, it has shifted its focus to development, with a stated mission of eradicating extreme poverty and boosting shared prosperity.\nThe World Bank is a member of the United Nations Sustainable Development Group. It is governed by its 189 member countries, though the United States, as its largest shareholder, has traditionally appointed its president. The current president is Ajay Banga, appointed in June 2023. The Bank's lending and operational decisions are made by a president and a board of 25 executive directors. The largest voting powers are held by the U.S. (15.85%), Japan (6.84%), China (4.42%), Germany (4.00%), France (3.75%) and the United Kingdom (3.75%).\nThe Bank's activities span all sectors of development. It provides financing, policy advice, and technical assistance to governments, and also focuses on private sector development through its sister organizations. The Bank's work is guided by environmental and social safeguards to mitigate harm to people and the environment. In addition to its lending operations, it serves as one of the world's largest centers of development research and knowledge, publishing numerous reports and hosting an Open Knowledge Repository. Current priorities include financing for climate action and responding to global crises like the COVID-19 pandemic.\nThe World Bank has been criticized for the harmful effects of its policies and for its governance structure. Critics argue that the loan conditions attached to its structural adjustment programs in the 1980s and 1990s were detrimental to the social welfare of developing nations. The Bank has also been criticized for being dominated by wealthy countries, and for its environmental record on certain projects.\nHistory.\nThe World Bank was created at the 1944 Bretton Woods Conference (1\u201322 July 1944), along with the International Monetary Fund (IMF). The president of the World Bank is traditionally an American. The World Bank and the IMF are both based in Washington, D.C., and work closely with each other.\nAlthough many countries were represented at the Bretton Woods Conference, the United States and United Kingdom were the most powerful in attendance and dominated the negotiations. The intention behind the founding of the World Bank was to provide temporary loans to low-income countries that could not obtain loans commercially. The bank may also make loans and demand policy reforms from recipients.\nThe agreement at Bretton Woods implied that both the World Bank and IMF would be headquartered in the United States. US Treasury Secretary Henry Morgenthau Jr. intended them to be located in New York, but his successor Fred M. Vinson unilaterally decided that they would be in Washington, D.C. instead, noting that \"the institutions would be fatally prejudiced in American opinion if they were placed in New York, since they would then come under the taint of 'international finance'\". The World Bank Group came into formal existence on 27 December 1946, following international ratification of the Bretton Woods agreements. The Conference also provided the foundation of the Osiander Committee in 1951, responsible for the preparation and evaluation of the World Development Report. Commencing operations on 25 June 1946, the bank approved its first loan on 9 May 1947 (US$250 million to France for postwar reconstruction - in real terms, the largest loan the bank has issued to date).\nIn its early years, the bank made a slow start for two reasons: it was underfunded, and there were leadership struggles between the US executive director and the president of the organization. When the Marshall Plan went into effect in 1947, many European countries began receiving aid from other sources. Faced with this competition, the World Bank shifted its focus to non-European allies. Until 1968, its loans were earmarked for the construction of infrastructure works, such as seaports, highway systems, and power plants, that would generate enough income to enable a borrower country to repay the loan. In 1960, the International Development Association was formed (as opposed to a UN fund named SUNFED), providing soft loans to developing countries.\nBefore 1974, the reconstruction and development loans the World Bank made were relatively small. Its staff was aware of the need to instill confidence in the bank. Fiscal conservatism ruled, and loan applications had to meet strict criteria.\nThe first country to receive a World Bank loan was France in 1947. The bank's president at the time, John McCloy, chose France over two other applicants, Poland and Chile. The loan was for US$250\u00a0million, half the amount requested, and came with strict conditions. France had to agree to produce a balanced budget and give priority of debt repayment to the World Bank over other governments. World Bank staff closely monitored the use of the funds to ensure that the French government met the conditions. In addition, before the loan was approved, the United States Department of State told the French government that its members associated with the Communist Party would first have to be removed. The French government complied and removed the Communist coalition government\u2014the so-called tripartite. Within hours, the loan to France was approved.\nFrom 1974 to 1980, the bank concentrated on meeting the basic needs of people in the developing world. The size and number of loans to borrowers greatly increased, as loan targets expanded from infrastructure into social services and other sectors.\nThese changes can be attributed to Robert McNamara, who was appointed to the presidency in 1968 by Lyndon B. Johnson. McNamara implored bank treasurer Eugene Rotberg to seek out new sources of capital outside of the northern banks that had been the primary sources of funding. Rotberg used the global bond market to increase the capital available to the bank. One consequence of the period of poverty alleviation lending was the rapid rise of debt of developing countries. From 1976 to 1980, developing world debt rose at an average annual rate of 20%.\nThe World Bank Administrative Tribunal was established in 1980, to decide on disputes between the World Bank Group and its staff where allegation of non-observance of contracts of employment or terms of appointment had not been honored.\nMcNamara was succeeded by U.S. President Jimmy Carter's nominee, Alden W. Clausen, in 1980. Clausen replaced many members of McNamara's staff and crafted a different mission emphasis. His 1982 decision to replace the bank's Chief Economist, Hollis B. Chenery, with Anne Krueger was an example of this new focus. Krueger was known for her criticism of development funding and for describing developing countries' governments as \"rent-seeking states\".\nDuring the 1980s, the bank emphasized lending to service debt of developing countries, and structural adjustment policies designed to streamline the economies of developing nations. UNICEF reported in the late 1980s that the structural adjustment programs of the World Bank had been responsible for \"reduced health, nutritional and educational levels for tens of millions of children in Asia, Latin America, and Africa\".\nMembership.\nThe International Bank for Reconstruction and Development (IBRD) has 189 member countries, while the International Development Association (IDA) has 174. Each member state of IBRD should also be a member of the International Monetary Fund (IMF) and only members of IBRD are allowed to join other institutions within the bank (such as IDA). The five United Nations member states that are not members of the World Bank are Andorra, Cuba, Liechtenstein, Monaco, and North Korea. Kosovo is not a member of the UN, but is a member of the IMF and the World Bank Group, including the IBRD and IDA. Other non-members are Palestine, the Holy See (Vatican City), Taiwan, and the following de facto states: Abkhazia, Northern Cyprus, the Sahrawi Arab Democratic Republic, Somaliland, South Ossetia, and Transnistria.\nThe Republic of China joined the World Bank on December 27, 1945. After the Chinese Civil War, the government fled to Taiwan and continued its membership in the WBG until April 16, 1980, when the People's Republic of China replaced the ROC. Since then, it uses the name \"Taiwan, China\".\nAll of the 188 UN members and Kosovo that are WBG members participate at a minimum in the IBRD. As of May 2016, all of them also participate in some of the other four organizations (IDA, IFC, MIGA, and ICSID).\nWBG members by the number of organizations in which they participate:\nVoting power.\nIn 2010, voting powers at the World Bank were revised to increase the voice of developing countries, notably China. The countries with most voting power are now the United States (15.85%), Japan (6.84%), China (4.42%), Germany (4.00%), the United Kingdom (3.75%), France (3.75%), India (2.91%), Russia (2.77%), Saudi Arabia (2.77%) and Italy (2.64%). Under the changes, known as 'Voice Reform \u2013 Phase 2', countries other than China that saw significant gains included South Korea, Turkey, Mexico, Singapore, Greece, Czech Republic, Hungary, Brazil, India, and Spain. Most developed countries' voting power was reduced, along with a few developing countries such as Nigeria. The voting powers of the United States, Russia and Saudi Arabia remained unchanged.\nThe changes were brought about to make voting more universal in regards to standards, rule-based objective indicators, and transparency among other things. Now, developing countries have an increased voice in the \"Pool Model\", backed especially by Europe. Additionally, voting power is based on economic size in addition to the International Development Association contributions.\nList of 20 largest countries by voting power in each World Bank institution.\nThe following table shows the subscriptions of the top 20 member countries of the World Bank by voting power in the following World Bank institutions as of December 2014 or March 2015: the International Bank for Reconstruction and Development (IBRD), the International Finance Corporation (IFC), the International Development Association (IDA), and the Multilateral Investment Guarantee Agency (MIGA). Member countries are allocated votes at the time of membership and subsequently for additional subscriptions to capital (one vote for each share of capital stock held by the member).\nOrganizational structure.\nTogether with four affiliated agencies created between 1957 and 1988, the IBRD is part of the World Bank Group. The group's headquarters are in Washington, D.C. It is an international organization owned by member governments; although it makes profits, they are used to support continued efforts in poverty reduction.\nTechnically the World Bank is part of the United Nations system, but its governance structure is different: each institution in the World Bank Group is owned by its member governments, which subscribe to its basic share capital, with votes proportional to shareholding. Membership gives certain voting rights that are the same for all countries but there are also additional votes that depend on financial contributions to the organization. The president of the World Bank is nominated by the president of the United States and elected by the bank's Board of Governors. As of 15 November 2009, the United States held 16.4% of total votes, Japan 7.9%, Germany 4.5%, the United Kingdom 4.3%, and France 4.3%. As changes to the bank's Charter require an 85% supermajority, the U.S. can block any major change in the bank's governing structure. Because the U.S. exerts formal and informal influence over the bank as a result of its vote share, control over the presidency, and the bank's headquarters location in Washington, D.C., friends and allies of the U.S. receive more projects with more lenient terms.\nWorld Bank Group agencies.\nThe World Bank Group consists of\nThe term \"World Bank\" generally refers to just the IBRD and IDA, whereas the term \"World Bank Group\" or \"WBG\" is used to refer to all five institutions collectively.\nThe World Bank Institute is the capacity development branch of the World Bank, providing learning and other capacity-building programs to member countries.\nThe IBRD has 189 member governments, and the other institutions have between 153 and 184. The institutions of the World Bank Group are all run by a board of governors meeting once a year. Each member country appoints a governor, generally its minister of finance. Daily, the World Bank Group is run by a board of 25 executive directors to whom the governors have delegated certain powers. Each director represents either one country (for the largest countries), or a group of countries. Executive directors are appointed by their respective governments or the constituencies.\nThe agencies of the World Bank are each governed by their Articles of Agreement that serves as the legal and institutional foundation for all their work.\nThe activities of the IFC and MIGA include investment in the private sector and providing insurance, respectively.\nPresidency.\nTraditionally, the bank president has been a U.S. citizen nominated by the president of the United States, the bank's largest shareholder. The nominee is subject to confirmation by the executive directors, to serve a five-year, renewable term.\nCurrent president.\nAjay Banga is the current and 14th president of the World Bank Group.\nManaging director.\nThe World Bank Group has several Managing Directors, each with different areas of responsibility. These responsibilities include organizational strategy; budget and strategic planning; information technology; shared services; Corporate Procurement; General Services and Corporate Security; the Sanctions System; and the Conflict Resolution and Internal Justice System. \nExtractive Industries Review.\nAfter longstanding criticisms from civil society of the bank's involvement in the oil, gas, and mining sectors, the World Bank in July 2001 launched an independent review called the \"Extractive Industries Review\" (EIR\u2014not to be confused with Environmental Impact Report). The review was headed by an \"Eminent Person\", Emil Salim (former Environment Minister of Indonesia). Salim held consultations with a wide range of stakeholders in 2002 and 2003. The EIR recommendations were published in January 2004 in a final report, \"Striking a Better Balance\". The report concluded that fossil fuel and mining projects do not alleviate poverty, and recommended that World Bank involvement with these sectors be phased out by 2008 to be replaced by investment in renewable energy and clean energy. The World Bank published its Management Response to the EIR in September 2004 after extensive discussions with the board of directors. The Management Response did not accept many of the EIR report's conclusions, but the EIR served to alter the World Bank's policies on oil, gas, and mining in important ways, as the World Bank documented in a recent follow-up report. One area of particular controversy concerned the rights of indigenous peoples. Critics point out that the Management Response weakened a key recommendation that indigenous peoples and affected communities should have to provide 'consent for projects to proceed; instead, there would be 'consultation'. Following the EIR process, the World Bank issued a revised Policy on Indigenous Peoples.\nMethods.\nThe World Bank plays a significant role in global economic governance due to its broad mandate, its vast resource base, its frequent and regular interactions with governments as clients, and its many publications and databases. In 2020, the World Bank's total commitments amounted to USD 77.1 billion and it operated in 145 countries. World Bank projects cover a range of areas from building schools to fighting disease, providing water and electricity, and environmental protection.\nAs a guideline to the World Bank's operations in any particular country, a Country Assistance Strategy is produced in cooperation with the local government and any interested stakeholders and may rely on analytical work performed by the bank or other parties.\nThe World Bank's negative pledge clause prohibits its debtor countries from using public assets to repay other creditors before they repay the World Bank.134\nEnvironmental and social safeguards.\nTo ensure that World Bank-financed operations do not compromise these goals but instead add to their realisation, the following environmental, social, and legal safeguards were defined: Environmental Assessment, Indigenous Peoples, Involuntary Resettlement, Physical Cultural Resources, Forests, Natural Habitats, Pest Management, Safety of Dams, Projects in Disputed Areas, Projects on International Waterways, and Performance Standards for Private Sector Activities.\nAt the World Bank's 2012 annual meeting in Tokyo, a review of these safeguards was initiated, which was welcomed by several civil society organisations. As a result, the World Bank developed a new Environmental and Social Framework, which has been in implementation since 1 October 2018.\nThe World Bank or the World Bank Group is also a sitting observer in the United Nations Sustainable Development Group.\nLoans for environmental protection.\nBeginning in 1989, in response to harsh criticism from many groups, the bank began including environmental groups and NGOs in its loans to mitigate the past effects of its development policies that had prompted the criticism. It also formed an implementing agency, in accordance with the Montreal Protocols, to stop ozone-depletion damage to the Earth's atmosphere by phasing out the use of 95% of ozone-depleting chemicals, with a target date of 2015. Since then, in accordance with its so-called \"Six Strategic Themes\", the bank has put various additional policies into effect to preserve the environment while promoting development. For example, in 1991, the bank announced that to protect against deforestation, especially in the Amazon, it would not finance any commercial logging or infrastructure projects that harm the environment.\nPoverty reduction strategies.\nFor the poorest developing countries in the world, the bank's assistance plans are based on poverty reduction strategies; by combining an analysis of local groups with an analysis of the country's financial and economic situation the World Bank develops a plan pertaining to the country in question. The government then identifies the country's priorities and targets for the reduction of poverty, and the World Bank instigates its aid efforts correspondingly.\nForty-five countries pledged US$25.1 billion in \"aid for the world's poorest countries\", aid that goes to the World Bank International Development Association (IDA), which distributes the loans to eighty poorer countries. Wealthier nations sometimes fund their own aid projects, including those for diseases. Robert B. Zoellick, the former president of the World Bank, said when the loans were announced on 15 December 2007, that IDA money \"is the core funding that the poorest developing countries rely on\".\nWorld Bank organizes the Development Marketplace Awards, a grant program that surfaces and funds development projects with potential for development impact that are scalable or replicable. The grant beneficiaries are social enterprises with projects that aim to deliver social and public services to groups with the lowest incomes.\nEfforts to reduce inequality.\nIn 2013 the bank adopted the concept of \"shared prosperity\" as one of the World Bank's \"Twin Goals\" for that year, with the other one focusing on poverty reduction, aiming to reduce the share of people in extreme poverty to 3 percent of the global population by 2030. The bank defined \"shared prosperity\" as increasing the income of the bottom 40 percent of the population in each country. As a result, reducing inequality, in this definition, had become an integral part of the World Bank's objectives.\nThe World Bank has been criticized for not embracing the reduction of inequality (be it economic inequality within a country, or international inequality between countries) as a goal. Instead, the bank has taken an instrumental approach to the issue, in which inequality policies were seen as useful as long as they contributed to reducing (extreme) poverty or promoting average economic growth.\nAs part of the \"2030 Agenda\", Sustainable Development Goal 10 (SDG 10) aim to reduce inequalities within countries and among countries. World Bank officials participated in the negotiations for SDG 10 in the years prior to 2015. They advocated for the adoption of the bank's own preferred benchmarks. The World Bank is also one of nine custodian agencies for SDG 10.\nThe bank has stated its ambition to help catalyze the SDGs through \"thought leadership, global convening, and country-level uptake\". However, scholars have stated that the World Bank strategically uses the power of the Sustainable Development Goals (SDGs) in its favor to reinforce its own policies or interests while minimizing the chance of being itself reshaped or transformed by these goals.\nUnited Nations Department of Global Communications.\nBased on an agreement between the United Nations and the World Bank in 1981, \"Development Business\" became the official source for World Bank Procurement Notices, Contract Awards, and Project Approvals.\nIn 1998, the agreement was renegotiated, and included in this agreement was a joint venture to create an online version of the publication. Today, \"Development Business\" is the primary publication for all major multilateral development banks, U.N. agencies, and several national governments, many of which have made the publication of their tenders and contracts in \"Development Business\" a mandatory requirement.\nOpen data and open knowledge repository.\nThe World Bank collects and processes large amounts of data and generates them on the basis of economic models. These data and models have gradually been made available to the public in a way that encourages reuse, whereas the recent publications describing them are available as open access under a Creative Commons Attribution License, for which the bank received the SPARC Innovator 2012 award.\nThe World Bank hosts the Open Knowledge Repository as an official open access repository for its research outputs and knowledge products. The World Bank's repository is listed in the Registry of Research Data Repositories re3data.org.\nThe World Bank also endorses the Principles for Digital Development.\nInternational Health Partnership.\nTogether with the World Health Organization, the World Bank administers the International Health Partnership (IHP+). IHP+ is a group of partners committed to improving the health of citizens in developing countries. Partners work together to put international principles for aid effectiveness and development cooperation into practice in the health sector. IHP+ mobilizes national governments, development agencies, civil society, and others to support a single, country-led national health strategy in a well-coordinated way.\nCOVID-19 pandemic.\nIn September 2020, during the COVID-19 pandemic, the World Bank announced a $12 billion plan to supply \"low and middle income countries\" with a vaccine once it was approved. In June 2022, the bank reported that $10.1 billion had been allocated to supply 78 countries with the vaccine\nThe US Treasury has committed $667 million for the World Bank's global Pandemic Fund, a third of the $2 billion the fund hopes to raise. The Pandemic Fund, established in September 2022, is a collaborative initiative among countries, implementing partners, philanthropies, and civil society organizations. It aims to fund investments that address critical gaps in pandemic prevention, preparedness, and response capacities at national, regional, and global levels, with a particular focus on low- and middle-income countries.\nThe World Bank has been criticized for the slow response of its Pandemic Emergency Financing Facility (PEF), a fund that was created to provide money to help manage pandemic outbreaks. The terms of the PEF, which is financed by bonds sold to private investors, prevent any money from being released from the fund until 12 weeks after the outbreak was initially detected (23 March). The COVID-19 pandemic met all other requirements for the funding to be released in January 2020.\nResponse to climate change.\nWorld Bank President Jim Yong Kim said in 2012:\nA 4-degree warmer world can, and must be, avoided\u2014we need to hold warming below 2 degrees\u00a0... Lack of action on climate change threatens to make the world our children inherit a completely different world than we are living in today. Climate change is one of the single biggest challenges facing development, and we need to assume the moral responsibility to take action on behalf of future generations, especially the poorest.\nIn December 2017, Kim announced the World Bank would no longer finance fossil fuel development. In 2019, the International Consortium of Investigative Journalists reported that the bank continues to finance fossil fuel infrastructure and that the bank \"has yet to meaningfully shift away from fossil fuels.\" Civil society groups, including Extinction Rebellion, joined with EU finance ministers in November 2019 to call for an end to World Bank funding of fossil fuels.\nIn 2023, U.S. president Joe Biden nominated Ajay Banga for president of the World Bank partly due to Banga's support for climate action. The previous president David Malpass faced criticism for challenging the scientific consensus on climate change. The same year, the UN operationalized the Fund for Responding to Loss and Damage, which the World Bank hosts to provide climate finance directly to vulnerable frontline communities.\nIn 2025, the bank faced criticism from environmental and animal welfare activists for continuing to finance greenhouse gas intensive industrial animal agriculture operations despite promising to align its investments with the 2015 Paris Agreement. Between 2018 and 2024, activists say the bank invested $650 million in such projects.\nGrants table.\nThe following table lists the top 15 DAC 5 Digit Sectors to which the World Bank has committed funding, as recorded in its International Aid Transparency Initiative (IATI) publications. The World Bank states on the IATI Registry website that the amounts \"will cover 100% of IBRD and IDA development flows\" but will not cover other development flows.\nCriticisms and controversy.\nThe World Bank has long been criticized by non-governmental organizations, such as the indigenous rights group Survival International, and academics, including Henry Hazlitt, Ludwig Von Mises, and its former Chief Economist Joseph Stiglitz. \nStiglitz is equally critical of the International Monetary Fund, the US Treasury Department, and the US and other developed country trade negotiators. Hazlitt argued that the World Bank along with the monetary system it was designed within would promote world inflation and \"a world in which international trade is State-dominated\" when they were being advocated. Stiglitz argued that the free market reform policies that the bank advocates are often harmful to economic development if implemented badly, too quickly (\"shock therapy\"), in the wrong sequence or in weak, uncompetitive economies.\nWorld Bank loan agreements can also force procurements of goods and services at uncompetitive, non-free-market, prices. Other critical writers, such as John Perkins, label the international financial institutions as 'illegal and illegitimate and a cog of coercive American diplomacy in carrying out financial terrorism.\nDefenders of the World Bank contend that no country is forced to borrow its money. The bank provides both loans and grants. Even the loans are concessional since they are given to countries that have no access to international capital markets. Furthermore, the loans, both to poor and middle-income countries, are below market-value interest rates. The World Bank argues that it can help development more through loans than grants because money repaid on the loans can then be lent for other projects.\nThe IFC and MIGA and their way of evaluating the social and environmental impact of their projects has also been criticized. Critics state that even though IFC and MIGA have more of these standards than the World Bank, they mostly rely on private-sector clients to monitor their implementation and miss an independent monitoring institution in this context. This is why an extensive review of the institutions' implementation strategy of social and environmental standards is demanded.\nOne of the most common criticisms of the World Bank has been the way it is governed. While the World Bank represents 188 countries, it is run by a small number of economically powerful countries. These countries (which also provide most of the institution's funding) choose the bank's leadership and senior management, and their interests dominate. Titus Alexander argues that the unequal voting power of western countries and the World Bank's role in developing countries makes it similar to the South African Development Bank under apartheid, and therefore a pillar of global apartheid.\nIn the 1990s, the World Bank and the IMF forged the Washington Consensus, policies that included deregulation and liberalization of markets, privatization and the downscaling of government. Though the Washington Consensus was conceived as a policy that would best promote development, it was criticized for ignoring equity, employment, and how reforms like privatization were carried out. Stiglitz argued that the Washington Consensus placed too much emphasis on GDP growth and not enough on the permanence of growth or on whether growth contributed to better living standards.\nThe United States Senate Committee on Foreign Relations report criticized the World Bank and other international financial institutions for focusing too much \"on issuing loans rather than on achieving concrete development results within a finite period of time\" and called on the institution to \"strengthen anti-corruption efforts\".\nJames Ferguson has argued that the main effect of many development projects carried out by the World Bank and similar organizations is not the alleviation of poverty. Instead, the projects often serve to expand the exercise of bureaucratic state power. His case studies of development projects in Thaba-Tseka show that the World Bank's characterization of the economic conditions in Lesotho was flawed, and the bank ignored the political and cultural character of the state in crafting its projects. As a result, the projects failed to help the poor but succeeded in expanding the government bureaucracy.\nCriticism of the World Bank and other organizations often takes the form of protesting, such as the World Bank Oslo 2002 Protests, the 2007 October Rebellion, and the 1999 Battle of Seattle. Such demonstrations have occurred all over the world, even among the Brazilian Kayapo people.\nAnother source of criticism has been the tradition of having an American head the bank, implemented because the United States provides the majority of World Bank funding. \"When economists from the World Bank visit poor countries to dispense cash and advice,\" observed \"The Economist\" in 2012, \"they routinely tell governments to reject cronyism and fill each important job with the best candidate available. It is good advice. The World Bank should take it.\"\nIn 2021, an independent inquiry of the World Bank's \"Doing Business\" reports by the law firm WilmerHale found that World Bank leaders, including then-Chief Executive Kristalina Georgieva and then-President Jim Yong Kim, pressured staff members of the bank to alter data to inflate the rankings for China, Saudi Arabia, Azerbaijan and the United Arab Emirates.\nIn September 2023, it was revealed that the World Bank had poured billions of dollars into fossil fuel projects in 2022. Campaigners estimated that about $3.7bn in trade finance was supplied to oil and gas projects despite the World Bank's green pledges.\nAllegations of corruption.\nhttp:// is charged with the investigation of internal fraud and corruption, including complaint intake, investigation, and investigation reports.\nStructural adjustment.\nThe effect of structural adjustment policies on poor countries has been one of the most significant criticisms of the World Bank. The 1979 energy crisis plunged many countries into economic crisis. The World Bank responded with structural adjustment loans, which distributed aid to struggling countries while enforcing policy changes in order to reduce inflation and fiscal imbalance. Some of these policies included encouraging production, investment and labour-intensive manufacturing, changing real exchange rates, and altering the distribution of government resources. Structural adjustment policies were most effective in countries with an institutional framework that allowed these policies to be implemented easily. For some countries, particularly in Sub-Saharan Africa, economic growth regressed and inflation worsened.\nBy the late 1980s, some international organizations began to believe that structural adjustment policies were worsening life for the world's poor, due to a reduction in social spending and an increase in the price of food, as subsidies were lifted. It also have been criticized for being Debt-trap diplomacy. The World Bank changed structural adjustment loans, allowing for social spending to be maintained, and encouraging a slower change to policies such as transfer of subsidies and price rises. In 1999, the World Bank and the IMF introduced the Poverty Reduction Strategy Paper approach to replace structural adjustment loans.\nFairness of assistance conditions.\nSome critics, most prominently the author Naomi Klein, are of the opinion that the World Bank Group's loans and aid have unfair conditions attached to them that reflect the interests, financial power and political doctrines (notably the Washington Consensus) of the bank and the countries that are most influential within it. Among other allegations, Klein says the Group's credibility was damaged \"when it forced school fees on students in Ghana in exchange for a loan; when it demanded that Tanzania privatise its water system; when it made telecom privatisation a condition of aid for Hurricane Mitch; when it demanded labour 'flexibility' in Sri Lanka in the aftermath of the Asian tsunami; when it pushed for eliminating food subsidies in post-invasion Iraq\".\nA study of the period 1970\u20132004 found that a less-developed country would on average receive more World Bank projects during any period when it occupied one of the rotating seats on the UN Security Council.\nSovereign immunity.\nThe World Bank requires sovereign immunity from countries it deals with. Sovereign immunity waives a holder from all legal liability for their actions. It is proposed that this immunity from responsibility is a \"shield which The World Bank wants to resort to, for escaping accountability and security by the people\". As the United States has veto power, it can prevent the World Bank from taking action against its interests.\nCronyism and Elite Capture.\nCriticism was also leveled under the presidency of Jim Yong Kim, particularly regarding financial management and staff morale. Reports of a controversial $94,000 bonus awarded to the Bank's CFO, Bertrand Badr\u00e9 (2013\u20132016), at his request on top of a tax-free salary of $379,000, while significant staff cuts and austerity measures were being implemented, drew criticism from within and outside the organization. This bonus, revealed by Senior Country Officer Fabrice Houdart amidst a broader effort by Kim to implement cost-cutting reforms, sparked debates over transparency, ethics, and the organization's commitment to its own principles, further exacerbating concerns about trust and leadership within the World Bank. Badr\u00e9 renounced the bonus and left the Bank shortly after.\nThe World Bank was the subject of a scandal with its then-president Paul Wolfowitz and his aide, Shaha Riza, in 2007.\nAccording to reports citing a recording of a 2018 staff meeting shared by a whistleblower, World Bank staff were informed Robert Malpass, a recent economics graduate of Cornell University and the son of David Malpass, then US Under Secretary of the Treasury for International Affairs and later President of the World Bank Group, would be hired as an analyst in July of that year. On the recording, staff were reportedly told Robert Malpass was a \"prince\" and an \"important little fellow\" who could go \"running to daddy.\" Bank officials also believed David Malpass was more influential than then-US Treasury Secretary Steven Mnuchin, who they said \"has little or no clue on things.\" In April 2018, the US Treasury had changed its position to back a $13 billion capital infusion for the bank.\nMalpass served as undersecretary of the US Treasury in the Trump administration before being appointed by Trump in February 2019 to be World Bank's president. Before Malpass became president, his son Robert had joined the International Finance Corporation (IFC), a branch of the World Bank Group that lends money to private sector businesses and whose USD 5.5 billion funding from a USD 13 billion World Bank capital increase was secured by the US Treasury at the time that David Malpass was the Treasury's undersecretary.\nCriticism of specific loans and programs in Africa.\nAlmost 45% of all the World Bank's resources are going to Africa, despite this the region continues to face significant financing gaps and development challenges.\nOn 9 August 2023, the World Bank announced it was suspending new loans to Uganda because it claims that a new anti-homosexuality act, enacted in May 2023, contradicts its core values on human rights. The World Bank joined the United States in imposing sanctions against Uganda over the anti-homosexuality law. Uganda dismissed the move by the World Bank as unjust and hypocritical.\nThe World Bank funded a program in Tanzania supposed to help nature conservation. The program was criticized because it led to severe violation of human rights toward the Maasai people.\nInvestments.\nThe World Bank Group has also been criticized for investing in projects with human rights issues.\nThe Compliance Advisor/Ombudsman (CAO) criticized a loan the bank made to the palm oil company Dinant after the 2009 Honduran coup d'\u00e9tat. There have been numerous killings of Campesinos in the region where Dinant was operating.\nOther controversial investments include loans to the Chixoy Hydroelectric Dam in Guatemala while it was under military dictatorship, and to Goldcorp (then Glamis Gold) for the construction of the Marlin Mine.\nIn 2019, the Congressional-Executive Commission on China questioned the World Bank about a loan in Xinjiang, China, that was used to buy high-end security gear, including surveillance equipment. The bank launched an internal investigation in response to the allegation. In August 2020, U.S. lawmakers questioned the continued disbursement of the loan.\nPeople.\nPresidents.\nThe president of the bank is the president of the entire World Bank Group. The president is responsible for chairing meetings of the boards of directors and for overall management of the bank.\nTraditionally, based on a tacit understanding between the United States and Europe, the president of the World Bank has been selected from candidates nominated by the United States, the largest shareholder in the bank. The World Bank tends to lend more readily to countries that are friendly with the United States, not because of direct U.S. influence but because of the employees of the World Bank. The nominee is subject to confirmation by the board of executive directors to serve a five-year, renewable term. While most World Bank presidents have had banking experience, some have not.\nOn 23 March 2012, U.S. president Barack Obama announced that the United States would nominate Jim Yong Kim as the next president of the bank. Jim Yong Kim was elected on 27 April 2012 and reelected to a second five-year term in 2017. He announced his resignation effective 1 February 2019 and was replaced on an interim basis by now-former World Bank CEO Kristalina Georgieva, then by David Malpass on 9 April 2019. Malpass faced criticism in 2023 as he had \"sparked outcry by appearing to question the role of humans in climate change\".\nIn 2023, a new president was appointed: Ajay Banga. His term began on 2 June 2023. He was supported by the American president Joe Biden partly because he supports climate action. He is also expected to help low-income countries deal with debts. He is the first Indian American to lead the bank. \nVice presidents and boards of directors.\nThe vice presidents of the bank are its principal managers, in charge of regions, sectors, networks and functions. There are two executive vice presidents, three senior vice presidents, and 24 vice presidents.\nThe boards of directors consist of the World Bank Group president and 25 executive directors. The president is the presiding officer, and ordinarily has no vote except to break a tie. The executive directors as individuals cannot exercise any power or commit or represent the bank unless the boards specifically authorized them to do so. With the term beginning 1 November 2010, the number of executive directors increased by one, to 25.\nStaff.\nIn 2020, the World Bank had 12,300 full-time staff, and it operated in 145 countries.\nPoliticians who were World Bank employees.\nSome notable politicians who worked for the World Bank include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36753", "revid": "6689490", "url": "https://en.wikipedia.org/wiki?curid=36753", "title": "Magic Johnson", "text": "American basketball player and entrepreneur (born 1959)\nEarvin \"Magic\" Johnson Jr. (born August 14, 1959) is an American businessman and former professional basketball player. Often regarded as the greatest point guard of all time, Johnson spent his entire career with the Los Angeles Lakers in the National Basketball Association (NBA). After winning a national championship with the Michigan State Spartans in 1979, Johnson was selected first overall in the 1979 NBA draft by the Lakers, then led the team to five NBA championships during their \"Showtime\" era. Johnson retired abruptly in 1991 after announcing that he had contracted HIV, but returned to play in the 1992 All-Star Game, winning the All-Star MVP Award. He retired again after fellow players protested his return, but returned in 1996, at age 36, to play 32\u00a0games for the Lakers before retiring for the third and final time.\nKnown for his extraordinary court vision, passing abilities, and leadership, Johnson was one of the most dominant players of his era. He received three NBA Most Valuable Player Awards, three NBA Finals MVP awards, nine All-NBA First Team designations, and twelve All-Star Game selections. He led the league in regular-season assists four times. Johnson holds the NBA records for average assists per game in the regular season (11.19) and in the playoffs (12.35 assists per game). He also holds the NBA playoffs records for most career assists and triple-doubles. Johnson was the co-captain of the 1992 United States men's Olympic basketball team (\"The Dream Team\"), which won the Olympic gold medal in Barcelona. Johnson is one of eight players to achieve the basketball Triple Crown. After leaving the NBA in 1991, he formed the Magic Johnson All-Stars, a barnstorming team that traveled around the world playing exhibition games.\nJohnson was honored as one of the 50 Greatest Players in NBA History in 1996 and selected to the NBA 75th Anniversary Team in 2021, and became a two-time inductee into the Naismith Memorial Basketball Hall of Fame\u2014being enshrined in 2002 for his individual career and as a member of the Dream Team in 2010. His friendship and rivalry with Boston Celtics star Larry Bird, whom he faced in the 1979 NCAA finals and three NBA championship series, are well-documented.\nSince his retirement, Johnson has been an advocate for HIV/AIDS prevention and safe sex, as well as an entrepreneur, philanthropist, broadcaster, and motivational speaker. Johnson is a former part-owner of the Lakers and was the team's president of basketball operations in the late 2010s. He is a founding member of Guggenheim Baseball Management, the managing entity of the Los Angeles Dodgers (MLB). He is part of ownership groups of the Los Angeles Sparks (WNBA), Los Angeles FC (MLS), the Washington Commanders (NFL), and the Washington Spirit (NWSL). Johnson has won 16 championships during his career: one in college, five as an NBA player, and ten as an owner. In 2025, Johnson received the Presidential Medal of Freedom, the highest civilian award of the United States. As of May 2025, his net worth is estimated at US$1.5\u00a0billion by \"Forbes\".\nEarly life.\nEarvin Johnson Jr. was born in Lansing, Michigan, to General Motors assembly worker Earvin Sr. and school janitor Christine. Johnson, who had six siblings and three half-siblings by his father's previous marriage, was influenced by his parents' strong work ethic. His mother spent many hours after work each night cleaning their home and preparing the next day's meals, while his father did janitorial work at a used car lot and collected garbage, all while never missing a day at General Motors. Johnson would often help his father on the garbage route, and he was teased by neighborhood children who called him \"Garbage Man\". His mother raised him in the Seventh-day Adventist Church.\nJohnson came to love basketball as a young man. His favorite basketball player growing up was Bill Russell, whom he admired more for his many championships than his athletic ability. He also idolized players such as Earl Monroe and Marques Haynes, and practiced \"all day\". Johnson came from an athletic family. His father played high school basketball in his home state of Mississippi, and Johnson learned the finer points about the game from him. Johnson's mother, originally from North Carolina, had also played basketball as a child, and she grew up watching her brothers play the game.\nBy the time he had reached the eighth grade, Johnson had begun to think about a future in basketball. He had become a dominant junior high player, once scoring 48 points in a game. Johnson looked forward to playing at Sexton High School, a school with a very successful basketball team and history that also happened to be only five blocks from his home. His plans underwent a dramatic change when he learned that he would be bused to the predominantly white Everett High School instead of going to Sexton, which was predominantly black. Johnson's sister Pearl and brother Larry had bused to Everett the previous year and did not have a pleasant experience. There were incidents of racism, with rocks being thrown at buses carrying black students and white parents refusing to send their children to school. Larry was kicked off the basketball team after a confrontation during practice, prompting him to beg his brother not to play. Johnson did join the basketball team but became angry after several days when his new teammates ignored him during practice, not even passing the ball to him. He nearly got into a fight with another player before head coach George Fox intervened. Eventually, Johnson accepted his situation and the small group of black students looked to him as their leader. When recalling the events in his autobiography, \"My Life\", he talked about how his time at Everett had changed him:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;As I look back on it today, I see the whole picture very differently. It's true that I hated missing out on Sexton. And the first few months, I was miserable at Everett. But being bused to Everett turned out to be one of the best things that ever happened to me. It got me out of my own little world and taught me how to understand white people, how to communicate and deal with them.\nHigh school career.\nJohnson was first dubbed \"Magic\" at 15, when he recorded a triple-double of 36\u00a0points, 18\u00a0rebounds, and 16\u00a0assists as a sophomore at Everett. After the game, Fred Stabley Jr., a sports writer for the \"Lansing State Journal\", gave him the moniker despite the belief of Johnson's mother, a devout Christian, that the name was sacrilegious. In his final high school season, Johnson led Everett to a 27\u20131 win\u2013loss record while averaging 28.8\u00a0points and\u00a016.8 rebounds per game, and took his team to an overtime victory in the state championship game. Johnson dedicated the championship victory to his best friend Reggie Chastine, who was killed in a car accident the previous summer. He gave Chastine much of the credit for his development as a basketball player and as a person, saying years later, \"I doubted myself back then.\" Johnson and Chastine were almost always together, playing basketball or riding around in Chastine's car. Upon learning of Chastine's death, Magic ran from his home, crying uncontrollably. Johnson, who finished his high school career with two All-State selections, was considered at the time to be the best high school player ever to come out of Michigan. He was also named to the inaugural McDonald's All-American team, which played in the 1977 Capital Classic.\nCollege career.\nAlthough Johnson was recruited by several top-ranked colleges such as Indiana and UCLA, he decided to play close to home. His college decision came down to Michigan and Michigan State in East Lansing. He ultimately decided to attend Michigan State when coach Jud Heathcote told him he could play the point guard position. The talent already on Michigan State's roster also drew him to the program.\nJohnson did not initially aspire to play professionally, focusing instead on his communication studies major and desire to become a television commentator. Playing with future NBA draftees Greg Kelser, Jay Vincent, and Mike Brkovich, Johnson averaged 17.0\u00a0points, 7.9\u00a0rebounds, and 7.4\u00a0assists per game as a freshman, and led the Spartans to a 25\u20135\u00a0record, the Big Ten Conference title, and a berth in the 1978 NCAA tournament. The Spartans reached the Elite Eight, but lost narrowly to eventual national champion Kentucky.\nDuring the 1978\u201379 season, Michigan State again qualified for the NCAA tournament, where they advanced to the championship game and faced Indiana State, which was led by senior Larry Bird. In what was the most-watched college basketball game ever, Michigan State defeated Indiana State 75\u201364, and Johnson was voted Most Outstanding Player of the Final Four. He was selected to the 1978\u201379 All-American team for his performance that season. After two years in college, during which he averaged 17.1\u00a0points, 7.6\u00a0rebounds, and 7.9\u00a0assists per game, Johnson entered the 1979 NBA draft. Jud Heathcote stepped down as coach of the Spartans after the 1994\u201395 season, and on June 8, 1995, Johnson returned to the Breslin Center to play in the Jud Heathcote All-Star Tribute Game. He led all scorers with 39 points.\nProfessional career.\nRookie season in the NBA (1979\u20131980).\nJohnson was drafted first overall in 1979 by the Los Angeles Lakers. Johnson said that what was \"most amazing\" about joining the Lakers was the chance to play alongside Kareem Abdul-Jabbar, the team's 7\u00a0ft 2\u00a0in (2.18\u00a0m) center who became the leading scorer in NBA history. Despite Abdul-Jabbar's dominance, he had failed to win a championship with the Lakers, and Johnson was expected to help them achieve that goal. Johnson wore No. 32 with the Lakers because the No. 33 he had worn at Michigan State was already taken by Abdul-Jabbar. Lakers coach Jack McKinney had the rookie Johnson, who some analysts thought should play forward, be a point guard, even though incumbent Norm Nixon was already one of the best in the league. Johnson averaged 18.0\u00a0points, 7.7\u00a0rebounds, and 7.3\u00a0assists per game for the season, was selected to the NBA All-Rookie Team, and was named an NBA All-Star Game starter.\nThe Lakers compiled a 60\u201322\u00a0record in the regular season and reached the 1980 NBA Finals, where they faced the Philadelphia 76ers, who were led by forward Julius Erving. The Lakers took a 3\u20132\u00a0lead in the series, but Abdul-Jabbar, who averaged 33\u00a0points a game in the series, sprained his ankle in Game 5 and could not play in Game 6. Coach Paul Westhead, who had replaced McKinney early in the season after he had a near-fatal bicycle accident, decided to start Johnson at center in Game 6; Johnson recorded 42\u00a0points, 15\u00a0rebounds, 7\u00a0assists, and 3 steals in a 123\u2013107 win, while playing guard, forward, and center at different times during the game. Johnson became the only rookie to win the NBA Finals MVP award, with his performance in the clutch regarded among the best in NBA history. He also became one of four players to win NCAA and NBA championships in consecutive years.\nUps and downs (1980\u20131983).\nEarly in the 1980\u201381 season, Johnson was sidelined after he suffered torn cartilage in his left knee. He missed 45\u00a0games, and said that his rehabilitation was the \"most down\" he had ever felt. Johnson returned before the start of the 1981 playoffs, but the Lakers' then-assistant and future head coach Pat Riley later said Johnson's much-anticipated return made the Lakers a \"divided team\". The 54-win Lakers faced the 40\u201342 Houston Rockets in the first round of playoffs, where Houston upset the Lakers 2\u20131 after Johnson airballed a last-second shot in Game 3.\nIn 1981, after the 1980\u201381 season, Johnson signed a 25-year, $25\u00a0million contract with the Lakers (), which was the highest-paying contract in sports history up to that point. Early in the 1981\u201382 season, Johnson had a heated dispute with Westhead, who Johnson said made the Lakers \"slow\" and \"predictable\". After Johnson demanded to be traded, Lakers owner Jerry Buss fired Westhead and replaced him with Riley. Although Johnson denied responsibility for Westhead's firing, he was booed across the league, even by Laker fans. Buss was also unhappy with the Lakers' offense and had intended on firing Westhead days before the Westhead\u2013Johnson altercation, but assistant GM Jerry West and GM Bill Sharman had convinced Buss to delay his decision. Despite his off-court troubles, Johnson averaged 18.6\u00a0points, 9.6\u00a0rebounds, 9.5\u00a0assists, and a league-high 2.7\u00a0steals per game, and was voted a member of the All-NBA Second Team. He also joined Wilt Chamberlain and Oscar Robertson as the only NBA players to tally at least 700\u00a0points, 700\u00a0rebounds, and 700\u00a0assists in the same season. The Lakers advanced through the 1982 playoffs and faced Philadelphia for the second time in three years in the 1982 NBA Finals. After a triple-double from Johnson in Game 6, the Lakers defeated the Sixers 4\u20132, as Johnson won his second NBA Finals MVP award. During the championship series against the Sixers, Johnson averaged 16.2\u00a0points on .533\u00a0shooting, 10.8\u00a0rebounds, 8.0\u00a0assists, and 2.5\u00a0steals per game. Johnson later said that his third season was when the Lakers first became a great team, and he credited their success to Riley.\nDuring the 1982\u201383 NBA season, Johnson's first of nine consecutive double-double seasons, he averaged 16.8\u00a0points, 10.5\u00a0assists, and 8.6\u00a0rebounds per game, and earned his first All-NBA First Team nomination. The Lakers again reached the Finals, and for a third time faced the Sixers, who featured center Moses Malone as well as Erving. With Johnson's teammates Nixon, James Worthy, and Bob McAdoo all hobbled by injuries, the Lakers were swept by the Sixers, and Malone was crowned the Finals MVP. In a losing effort against Philadelphia, Johnson averaged 19.0\u00a0points on .403\u00a0shooting, 12.5\u00a0assists, and 7.8\u00a0rebounds per game.\nBattles against the Celtics (1983\u20131987).\nPrior to Johnson's fifth season, West\u2014who had become the Lakers general manager\u2014traded Nixon to free Johnson from sharing the ball-handling responsibilities. Johnson averaged another double-double season, with 17.6\u00a0points, 13.1\u00a0assists, and 7.3\u00a0rebounds per game. The Lakers reached the Finals for the third year in a row, where Johnson's Lakers and Bird's Celtics met for the first time in the postseason. The Lakers won the first game, and led by two points in Game 2 with 18\u00a0seconds to go, but after a layup by Gerald Henderson, Johnson failed to get a shot off before the final buzzer sounded, and the Lakers lost 124\u2013121 in overtime. In Game 3, Johnson responded with 21\u00a0assists in a 137\u2013104 win, but he made several crucial errors late in the contest during Game 4. In the final minute of the game, Johnson had the ball stolen by Celtics center Robert Parish, and then missed two free throws that could have won the game. The Celtics won Game 4 in overtime, and the teams split the next two games. In the decisive Game 7 in Boston, as the Lakers trailed by three points in the final minute, opposing point guard Dennis Johnson stole the ball from Johnson, a play that effectively ended the series. Friends Isiah Thomas and Mark Aguirre consoled him that night, talking until the morning in his Boston hotel room amidst fan celebrations on the street. During the Finals, Johnson averaged 18.0\u00a0points on .560\u00a0shooting, 13.6\u00a0assists, and 7.7\u00a0rebounds per game. Johnson later described the series as \"the one championship we should have had but didn't get\".\nIn the 1984\u201385 regular season, Johnson averaged 18.3\u00a0points, 12.6\u00a0assists, and 6.2\u00a0rebounds per game, and led the Lakers into the 1985 NBA Finals, where they faced the Celtics again. The series started poorly for the Lakers when they allowed an NBA Finals record 148\u00a0points to the Celtics in a 34-point loss in Game 1. However, Abdul-Jabbar, who was now 38\u00a0years old, scored 30\u00a0points and grabbed 17\u00a0rebounds in Game 2, and his 36\u00a0points in a Game 5 win were instrumental in establishing a 3\u20132 lead for Los Angeles. After the Lakers defeated the Celtics in six games, Abdul-Jabbar and Johnson, who averaged 18.3\u00a0points on .494\u00a0shooting, 14.0\u00a0assists, and 6.8\u00a0rebounds per game in the championship series, said the Finals win was the highlight of their careers.\nJohnson again averaged a double-double in the 1985\u201386 NBA season, with 18.8\u00a0points, 12.6\u00a0assists, and 5.9\u00a0rebounds per game. The Lakers advanced to the Western Conference Finals, but were unable to defeat the Houston Rockets, who advanced to the Finals in five games. In the next season, Johnson averaged a career-high of 23.9\u00a0points, as well as 12.2\u00a0assists and 6.3\u00a0rebounds per game, and earned his first regular season MVP award. The Lakers met the Celtics for the third time in the NBA Finals, and in Game 4 Johnson hit a last-second hook shot over Celtics big men Parish and Kevin McHale to win the game 107\u2013106. The game-winning shot, which Johnson dubbed his \"junior, junior, junior sky-hook\", helped Los Angeles defeat Boston in six games. Johnson was awarded his third Finals MVP title after averaging 26.2\u00a0points on .541\u00a0shooting, 13.0\u00a0assists, 8.0\u00a0rebounds, and 2.33\u00a0steals per game.\nRepeat and falling short (1987\u20131991).\nBefore the 1987\u201388 NBA season, Lakers coach Pat Riley publicly promised that they would defend the NBA title, even though no team had won consecutive titles since the Celtics did so in the 1969 NBA Finals. Johnson had another productive season with averages of 19.6\u00a0points, 11.9\u00a0assists, and 6.2\u00a0rebounds per game despite missing 10 games with a groin injury. In the 1988 playoffs, the Lakers swept the San Antonio Spurs in 3 games, then survived two 4\u20133\u00a0series against the Utah Jazz and Dallas Mavericks to reach the Finals and face Thomas and the Detroit Pistons, who with players such as Bill Laimbeer, John Salley, Vinnie Johnson, and Dennis Rodman were known as the \"Bad Boys\" for their physical style of play. Johnson and Thomas greeted each other with a kiss on the cheek before the opening tip of Game 1, which they called a display of brotherly love. After the teams split the first six games, Lakers forward and Finals MVP James Worthy had his first career triple-double of 36\u00a0points, 16\u00a0rebounds, and 10\u00a0assists, and led his team to a 108\u2013105\u00a0win. Despite not being named MVP, Johnson had a strong championship series, averaging 21.1\u00a0points on .550\u00a0shooting, 13\u00a0assists, and 5.7\u00a0rebounds per game. It was the fifth and final NBA championship of his career.\nIn the 1988\u201389 NBA season, Johnson's 22.5\u00a0points, 12.8\u00a0assists, and 7.9\u00a0rebounds per game earned him his second MVP award, and the Lakers reached the 1989 NBA Finals, in which they again faced the Pistons. However, after Johnson went down with a hamstring injury in Game 2, the Lakers were no match for the Pistons, who swept them 4\u20130.\nPlaying without Abdul-Jabbar for the first time, Johnson won his third MVP award after a strong 1989\u201390 NBA season in which he averaged 22.3\u00a0points, 11.5\u00a0assists, and 6.6\u00a0rebounds per game. However, the Lakers bowed out to the Phoenix Suns in the Western Conference semifinals, which was the Lakers' earliest playoffs elimination in nine years. Mike Dunleavy became the Lakers' head coach in 1990\u201391, when Johnson had grown to be the league's third-oldest point guard. He had become more powerful and stronger than in his earlier years, but was also slower and less nimble. Under Dunleavy, the offense used more half-court sets, and the team had a renewed emphasis on defense. Johnson performed well during the season, with averages of 19.4\u00a0points, 12.5\u00a0assists, and 7\u00a0rebounds per game, and the Lakers reached the 1991 NBA Finals. There they faced the Chicago Bulls, led by shooting guard Michael Jordan, a five-time scoring champion regarded as the finest player of his era. Although the series was portrayed as a matchup between Johnson and Jordan, Bulls forward Scottie Pippen defended effectively against Johnson. Despite two triple-doubles from Johnson during the series, Finals MVP Jordan led his team to a 4\u20131\u00a0win. In the last championship series of his career, Johnson averaged 18.6\u00a0points on .431\u00a0shooting, 12.4\u00a0assists, and 8\u00a0rebounds per game.\nHIV announcement and Olympics (1991\u20131992).\nJohnson played with the Lakers in the McDonald's Open in Paris, France, in October 1991, and was named the tournament MVP after helping the Lakers win gold. However, after a physical examination before the 1991\u201392 NBA season, Johnson discovered that he had tested positive for HIV. In a press conference held on November 7, 1991, Johnson made a public announcement that he would retire immediately. He stated that his wife, Cookie, and their unborn child did not have HIV, and that he would dedicate his life to \"battle this deadly disease\".\nJohnson initially said that he did not know how he contracted the disease, but later acknowledged that it was through having numerous sexual partners during his playing career. He admitted to having \"harems of women\" and talked openly about his sexual activities because \"he was convinced that heterosexuals needed to know that they, too, were at risk\". At the time, only a small percentage of HIV-positive American men had contracted it from heterosexual sex, and it was initially rumored that Johnson was gay or bisexual, although he denied both. Johnson later accused Isiah Thomas of spreading the rumors, a claim Thomas denied.\nJohnson's HIV announcement became a major news story in the United States, and in 2004 was named as ESPN's seventh-most memorable moment of the previous 25 years. Many articles praised Johnson as a hero, and the then-U.S. president George H. W. Bush said, \"For me, Magic is a hero, a hero for anyone who loves sports.\"\nDespite his retirement, Johnson was voted by fans as a starter for the 1992 NBA All-Star Game at Orlando Arena, although his former teammates Byron Scott and A.C. Green said that Johnson should not play, and several NBA players, including Utah Jazz forward Karl Malone, argued that they would be at risk of contamination if Johnson sustained an open wound while on court. Johnson led the West to a 153\u2013113\u00a0win and was crowned All-Star MVP after recording 25\u00a0points, 9\u00a0assists, and 5\u00a0rebounds. The game ended after he made a last-minute three-pointer, and players from both teams ran onto the court to congratulate Johnson.\nJohnson was chosen to compete in the Barcelona 1992 Summer Olympics for the U.S. national team, dubbed the \"Dream Team\" because of the NBA stars on the roster. The Dream Team, which along with Johnson included fellow Hall of Famers such as Bird, Michael Jordan, and Charles Barkley, was considered unbeatable. After qualifying for the Olympics with a gold medal at the 1992 Tournament of the Americas, the Dream Team dominated in Olympic competition, winning the gold medal with an 8\u20130 record, beating their opponents by an average of 43.8 points per game. Johnson averaged 8.0 points per game during the Olympics, and his 5.5 assists per game was second on the team. Johnson played infrequently because of knee problems, but he received standing ovations from the crowd, and used the opportunity to inspire HIV-positive people.\nPost-Olympics and later life.\nBefore the 1992\u201393 NBA season, Johnson announced his intention to stage an NBA comeback. After practicing and playing in several pre-season games, he retired again before the start of the regular season, citing controversy over his return sparked by opposition from several active players. In an August 2011 interview, Johnson said that in retrospect he wished that he had never retired after being diagnosed with HIV, saying, \"If I knew what I know now, I wouldn't have retired.\" Johnson said that despite the physical, highly competitive practices and scrimmages leading up to the 1992 Olympics, some of those same teammates still expressed concerns about his return to the NBA. He said that he retired because he \"didn't want to hurt the game.\"\nDuring his retirement, Johnson has written a book on safe sex, run several businesses, worked for NBC as a commentator, and toured Asia, Australia, and New Zealand with a basketball team of former college and NBA players. In 1985, Johnson created \"A Midsummer Night's Magic\", a yearly charity event which included a celebrity basketball game and a black tie dinner. The proceeds went to the United Negro College Fund, and Johnson held this event for twenty years, ending in 2005. \"A Midsummer Night's Magic\" eventually came under the umbrella of the Magic Johnson Foundation, which he founded in 1991. The 1992 event, which was the first one held after Johnson's appearance in the 1992 Olympics, raised over $1.3 million for UNCF. Johnson joined Shaquille O'Neal and celebrity coach Spike Lee to lead the blue team to a 147\u2013132 victory over the white team, which was coached by Arsenio Hall.\nReturn to the Lakers as coach and player (1994, 1996).\nJohnson returned to the NBA as coach for the Lakers near the end of the 1993\u201394 NBA season, replacing Randy Pfund, and Bill Bertka, who served as an interim coach for two games. Johnson, who took the job at the urging of owner Jerry Buss, admitted \"I've always had the desire (to coach) in the back of my mind.\" He insisted that his health was not an issue, while downplaying questions about returning as a player, saying, \"I'm retired. Let's leave it at that.\" Amid speculation from general manager Jerry West that he may only coach until the end of the season, Johnson took over a team that had a 28\u201338 record, and won his first game as head coach, a 110\u2013101 victory over the Milwaukee Bucks. He was coaching a team that had five of his former teammates on the roster: Vlade Divac, Elden Campbell, Tony Smith, Kurt Rambis, James Worthy, and Michael Cooper, who was brought in as an assistant coach. Johnson, who still had a guaranteed player contract that would pay him $14.6 million during the 1994\u201395 NBA season, signed a separate contract to coach the team that had no compensation. The Lakers played well initially, winning five of their first six games under Johnson, but after losing the next five games, Johnson announced that he was resigning as coach after the season. The Lakers finished the season on a ten-game losing streak, and Johnson's final record as a head coach was 5\u201311. Stating that it was never his dream to coach, he chose instead to purchase a 5% share of the team in June 1994.\nAt the age of 36, Johnson attempted another comeback as a player when he rejoined the Lakers during the 1995\u201396 NBA season. During his retirement, Johnson began intense workouts to help his fight against HIV, raising his bench press from 135 to 300 pounds, and increasing his weight to 255 pounds. He officially returned to the team on January 29, 1996, and played his first game the following day against the Golden State Warriors. Coming off the bench, Johnson had 19 points, 8 rebounds, and 10 assists to help the Lakers to a 128\u2013118 victory. On February 14, Johnson recorded the final triple-double of his career, when he scored 15 points, along with 10 rebounds and 13 assists in a victory against the Atlanta Hawks. Playing power forward, he averaged 14.6\u00a0points, 6.9\u00a0assists, and 5.7\u00a0rebounds per game in 32\u00a0games, and finished tied for 12th place with Charles Barkley in voting for the MVP Award. The Lakers had a record of 22\u201310 in the games Johnson played, and he considered his final comeback \"a success.\" While Johnson played well in 1996, there were struggles both on and off the court. Cedric Ceballos, upset over a reduction in his playing time after Johnson's arrival, left the team for several days. He missed two games and was stripped of his title as team captain. Nick Van Exel received a seven-game suspension for bumping referee Ron Garretson during a game on April 9. Johnson was publicly critical of Van Exel, saying his actions were \"inexcusable.\" Johnson was himself suspended five days later, when he bumped referee Scott Foster, missing three games. He also missed several games due to a calf injury. Despite these difficulties, the Lakers finished with a record of 53\u201329 and fourth seed in the NBA Playoffs. Although they were facing the defending NBA champion Houston Rockets, the Lakers had home court advantage in the five-game series. The Lakers played poorly in a Game 1 loss, prompting Johnson to express frustration with his role in coach Del Harris' offense. Johnson led the way to a Game 2 victory with 26 points, but averaged only 7.5 points per game for the remainder of the series, which the Rockets won three games to one.\nAfter the Lakers lost to the Houston Rockets in the first round of the playoffs, Johnson initially expressed a desire to return to the team for the 1996\u201397 NBA season, but he also talked about joining another team as a free agent, hoping to see more playing time at point guard instead of power forward. A few days later, Johnson changed his mind and retired permanently, saying, \"I am going out on my terms, something I couldn't say when I aborted a comeback in 1992.\"\nMagic Johnson All-Stars.\nDetermined to play competitive basketball despite being out of the NBA, Johnson formed the Magic Johnson All-Stars, a barnstorming team composed of former NBA and college players. In 1994, Johnson joined with former pros Mark Aguirre, Reggie Theus, John Long, Earl Cureton, Jim Farmer, and Lester Conner, as his team played games in Australia, Israel, South America, Europe, New Zealand, and Japan. They also toured the United States, playing five games against teams from the CBA. In the final game of the CBA series, Johnson had 30 points, 17 rebounds, and 13 assists, leading the All-Stars to a 126\u2013121 victory over the Oklahoma City Cavalry. By the time he returned to the Lakers in 1996, the Magic Johnson All-Stars had amassed a record of 55\u20130, and Johnson was earning as much as $365,000 per game. Johnson played with the team frequently over the next several years, with possibly the most memorable game occurring in November 2001. At the age of 42, Johnson played with the All-Stars against his alma mater, Michigan State. Although he played in a celebrity game to honor coach Jud Heathcoate in 1995, this was Johnson's first meaningful game played in his hometown of Lansing in 22 years. Playing in front of a sold-out arena, Johnson had a triple-double and played the entire game, but his all-star team lost to the Spartans by two points. Johnson's half-court shot at the buzzer would have won the game, but it fell short. On November 1, 2002, Johnson returned to play a second exhibition game against Michigan State. Playing with the Canberra Cannons of Australia's National Basketball League instead of his usual group of players, Johnson's team defeated the Spartans 104\u201385, as he scored 12 points and had 10 assists and 10 rebounds.\nBrief period in Scandinavia.\nIn 1999, Johnson joined the Swedish squad M7 Bor\u00e5s (now known as 'Bor\u00e5s Basket'), and was undefeated in five games with the team. Johnson also became a co-owner of the club; however, the project failed after one season and the club was forced into reconstruction. He later joined the Danish team The Great Danes.\nRivalry with Larry Bird.\nJohnson and Bird were first linked as rivals after Johnson's Michigan State Spartans squad defeated Bird's Indiana State Sycamores team in the 1979 NCAA finals. The rivalry continued in the NBA, and reached its climax when Boston and Los Angeles met in three out of four NBA Finals from 1984 to 1987, with the Lakers winning two out of three Finals. Johnson asserted that for him, the 82-game regular season was composed of 80 normal games, and two Lakers\u2013Celtics games. Similarly, Bird admitted that Johnson's daily box score was the first thing he checked in the morning.\nSeveral journalists hypothesized that the Johnson\u2013Bird rivalry was so appealing because it represented many other contrasts, such as the clash between the Lakers and Celtics, between Hollywood flashiness (\"Showtime\") and Boston/Indiana blue collar grit (\"Celtic Pride\"), and between black and white people. The rivalry was also significant because it drew national attention to the faltering NBA. Prior to Johnson and Bird's arrival, the NBA had gone through a decade of declining interest and low TV ratings. With the two future Hall of Famers, the league won a whole generation of new fans, drawing both traditionalist adherents of Bird's dirt court Indiana game and those appreciative of Johnson's public park flair. According to sports journalist Larry Schwartz of ESPN, Johnson and Bird saved the NBA from bankruptcy.\nDespite their on-court rivalry, Johnson and Bird became close friends during the filming of a 1984 Converse shoe advertisement that depicted them as enemies. Johnson appeared at Bird's retirement ceremony in 1992, and described Bird as a \"friend forever\"; during Johnson's Hall of Fame ceremony, Bird formally inducted his old rival.\nIn 2009, Johnson and Bird collaborated with journalist Jackie MacMullan on a non-fiction book titled \"When the Game Was Ours\". The book detailed their on-court rivalry and friendship with one another. The following year, HBO developed a documentary about their rivalry titled \"\", which was directed by Ezra Edelman.\nLegacy.\nIn 905\u00a0NBA games, Johnson tallied 17,707\u00a0points, 6,559\u00a0rebounds, and 10,141\u00a0assists, translating to career averages of 19.5\u00a0points, 7.2\u00a0rebounds, and 11.2\u00a0assists per game, the highest assists per game average in NBA history. Johnson shares the single-game playoff record for assists (24), holds the Finals record for assists in a game (21), and has the most playoff assists (2,346). He is the only player to average 12 assists in an NBA Finals series, achieving it six times. He holds the All-Star Game single-game record for assists (22), and the All-Star Game record for career assists (127). Johnson is one of only eight players in the history of basketball to achieve the Triple Crown \u2014 winning an NCAA championship, NBA championship, and Olympic gold medal.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"Magic is head-and-shoulders above everybody else [...] I've never seen [anybody] as good as him.\"\n\u2014Larry Bird\nJohnson introduced a fast-paced style of basketball called \"Showtime\", described as a mix of \"no-look passes off the fast break, pin-point alley-oops from halfcourt, spinning feeds and overhand bullets under the basket through triple teams.\" Fellow Lakers guard Michael Cooper said, \"There have been times when [Johnson] has thrown passes and I wasn't sure where he was going. Then one of our guys catches the ball and scores, and I run back up the floor convinced that he must've thrown it through somebody.\" Johnson could dominate a game without scoring, running the offense and distributing the ball with flair. In the 1982 NBA Finals, he was named the Finals MVP averaging just 16.2 points, the lowest average of any Finals MVP award recipient in the three-point shot era.\nJohnson was exceptional because he played point guard despite being 6\u00a0ft 9\u00a0in (2.06\u00a0m), a size reserved normally for frontcourt players. His career 138\u00a0triple-double games places him fourth all-time behind Russell Westbrook, Oscar Robertson, and Nikola Joki\u0107. Johnson is the only player in NBA Finals history to have triple-doubles in multiple series-clinching games.\nFor his feats, Johnson was voted as one of the 50 Greatest Players of All Time by the NBA in 1996, and selected to the NBA 75th Anniversary Team in 2021. The Naismith Memorial Basketball Hall of Fame inducted him in 2002. ESPN's \"SportsCentury\" ranked Johnson No. 17 in their \"50 Greatest Athletes of the 20th Century\" In 2006, ESPN.com rated Johnson the greatest point guard of all time, stating, \"It could be argued that he's the one player in NBA history who was better than Michael Jordan.\" Bleacher Report also listed Johnson first in its all-time NBA point guard rankings. In 2022, to commemorate the NBA's 75th anniversary, \"The Athletic\" ranked their top 75 players of all time, and named Johnson as the 5th greatest player in NBA history, and the highest ranked point guard. Several of his achievements in individual games have also been named among the top moments in the NBA. At the 2019 NBA Awards, Johnson received the NBA Lifetime Achievement Award (shared with Bird). In 2022, the NBA began awarding MVPs for the conference finals; the Western Conference Finals MVP trophy is named after Johnson, while the Eastern Conference trophy is named after Bird.\nAwards and honors.\nBasketball Triple Crown\nNBA\nUSA Basketball\nNCAA\nHigh school\nHalls of Fame\nOwnership\nMedia and entertainment\nNational\nExecutive career.\nOn February 21, 2017, Johnson replaced Jim Buss as the president of basketball operations for the Los Angeles Lakers. Under Johnson, the Lakers sought to acquire multiple star players and cleared existing players, including future All-Star D'Angelo Russell, off of their roster in an attempt to free up room under the league's salary cap. The franchise reached an agreement with free agent LeBron James on a four-year contract in 2018, but efforts to trade for Anthony Davis during the 2018\u201319 season proved unsuccessful. The Lakers did not reach the playoffs during Johnson's executive tenure. In an impromptu news conference on April 9, 2019, Johnson resigned from the Lakers, citing his desire to return to his role as an NBA ambassador.\nTeam ownership.\nIn January 2012, Johnson joined with Guggenheim Partners and Stan Kasten in a bid for ownership of the Los Angeles Dodgers baseball team. In March 2012, Johnson's ownership group was announced as the winner of the proceedings to buy the Dodgers. The Johnson-led group, which also includes movie executive Peter Guber, paid $2\u00a0billion for the Dodgers. Johnson is considered the face of the ownership group while the controlling owner is Mark Walter. The Dodgers won the 2020, 2024, and 2025 World Series.\nJohnson and Guber were also partners in the Dayton Dragons, a Class-A minor league baseball team based in Dayton, Ohio, that sold out more than 1,000 consecutive games, a record for professional sports. Johnson and Guber sold their stake in the Dragons in 2014. Together with Guggenheim, Johnson was also involved in buying the Los Angeles Sparks of the WNBA in 2014. As such, in 2014, Johnson was named one of ESPNW's Impact 25. He won the WNBA championship as the owner in 2016. Johnson announced co-ownership of a Major League Soccer (MLS) expansion franchise, Los Angeles FC, which began play in 2018 and won the MLS Cup in 2022.\nIn 2023, Johnson invested $240million in a group headed by Josh Harris that purchased the Washington Commanders of the National Football League (NFL) for $6.05billion. A lifelong fan of the NFL, he considered it a \"dream\" and the greatest achievement of his business career. Johnson had previously held talks with other groups interested in buying the Miami Dolphins and Las Vegas Raiders before meeting and joining Harris on an unsuccessful bid on the Denver Broncos in 2022. In September 2024, Johnson joined the ownership group of the Washington Spirit of the National Women's Soccer League (NWSL).\nPersonal life.\nJohnson first fathered a son in 1981 when Andre Johnson was born to Melissa Mitchell. Although Andre was raised by his mother, he visited Johnson each summer, and later worked for Magic Johnson Enterprises as a marketing director.\nIn 1991, Johnson married Earlitha \"Cookie\" Kelly in a small wedding in Lansing which included guests Thomas, Aguirre, and Herb Williams. Johnson and Cookie have one son, Earvin III (\"EJ\"), who is openly gay and a star on the reality show \"Rich Kids of Beverly Hills\". The couple adopted a daughter, Elisa, in 1995. Johnson resides in Beverly Hills and has a vacation home in Dana Point, California.\nJohnson is a Christian and has said his faith is \"the most important thing\" in his life.\nRelationship with Jerry Buss.\nJohnson had a close relationship with Lakers owner Jerry Buss, whom he saw as a mentor and father figure. Calling Buss his \"second father\" and \"one of [his] best friends\", Johnson spent five hours visiting Buss at the hospital just a few months before his 2013 death from cancer. Speaking to media just hours after Buss had died, Johnson was emotional, saying, \"Without Dr. Jerry Buss, there is no Magic.\" Buss acquired the team from Jack Kent Cooke in 1979, shortly before he drafted Johnson with the #1 pick in the 1979 NBA draft. Buss took a special interest in Johnson, introducing him to important Los Angeles business contacts and showing him how the Lakers organization was run, before eventually selling Johnson a stake in the team in 1994. Johnson credits Buss with giving him the business knowledge that enabled him to become part owner of the Los Angeles Dodgers.\nBuss supported Johnson as he revealed his diagnosis of HIV in 1991, and he never hesitated to keep Johnson close to the organization, bringing him in as part-owner, and even as a coach. Johnson had never seriously considered coaching, but he agreed to take the head coaching position with the Lakers in 1994 at Buss' request. In 1992, Buss had given Johnson a contract that paid him $14 million a year, as payback for all the years he was not the league's highest-paid player. Although Johnson's retirement prior to the 1992\u201393 NBA season voided this contract, Buss insisted that he still be paid. It was this arrangement that allowed Johnson to coach the team without receiving any additional salary. After Johnson ended his coaching stint, Buss sold him a 4% stake in the Lakers for $10 million, and Johnson served as a team executive.\nMedia figure and business interests.\nIn 1997, his production company Magic Johnson Entertainment signed a deal with Fox. In 1998, Johnson hosted a late night talk show on the Fox network called \"The Magic Hour\", but the show was canceled after two months because of low ratings. Shortly after the cancellation of his talk show, Johnson started a record label. The label, initially called Magic 32 Records, was renamed Magic Johnson Music when Johnson signed a joint venture with MCA in 2000. Magic Johnson Music signed R&amp;B artist Avant as its first act. Johnson also co-promoted Janet Jackson's Velvet Rope Tour through his company Magicworks. He has also worked as a motivational speaker, and was an NBA commentator for Turner Network Television for seven years, before becoming a studio analyst for ESPN's \"NBA Countdown\" in 2008.\nJohnson runs Magic Johnson Enterprises, a conglomerate that has a net worth of $700\u00a0million; its subsidiaries include Magic Johnson Productions, a promotional company; Magic Johnson Theaters, a nationwide chain of movie theaters; and Magic Johnson Entertainment, a film studio. In 2006, Johnson created a contract food service with Sodexo USA called Sodexo-Magic. In 2004, Johnson and his partner Ken Lombard sold Magic Johnson Theaters to Loews Cineplex Entertainment. The first Magic Johnson Theater located in the Baldwin Hills Crenshaw Plaza, closed in 2010 and re-opened in 2011 as Rave Cinema 15. In 2012, Johnson launched a cable TV network called Aspire, featuring programming targeted at black audiences, similar to networks such as Black Entertainment Television (BET) and TV One.\nJohnson began thinking of life after basketball while still playing for the Lakers. He wondered why so many athletes had failed at business, and sought advice. During his seventh season in the NBA, he had a meeting with Michael Ovitz, CEO of Creative Artists Agency. Ovitz encouraged him to start reading business magazines and to use every connection available to him. Johnson learned everything he could about business, often meeting with corporate executives during road trips. Johnson's first foray into business, a high-end sporting goods store named Magic 32, failed after only one year, costing him $200,000. The experience taught him to listen to his customers and find out what products they wanted. Johnson has become a leading voice on how to invest in urban communities, creating redevelopment opportunities in underserved areas, most notably through his movie theaters and his partnership with Starbucks. He went to Starbucks CEO Howard Schultz with the idea that he could successfully open the coffee shops in urban areas. After showing Schultz the tremendous buying power of minorities, Johnson was able to purchase 125 Starbucks stores, which reported higher than average per capita sales. The partnership, called Urban Coffee Opportunities, placed Starbucks in locations such as Detroit, Washington, D.C., Harlem, and the Crenshaw District of Los Angeles. Johnson sold his remaining interest in the stores back to the company in 2010, ending a successful twelve-year partnership. He has also made investments in urban real estate through the Canyon-Johnson and Yucaipa-Johnson funds. Another major project is with insurance services company Aon Corp. In 2005\u20132007, Johnson was a part of a syndicate that bought the Williamsburgh Savings Bank Tower, then the tallest building in Brooklyn, for $71 million and converted the 512-foot high landmark structure from an office building into luxury condominiums. According to \"Forbes\", Johnson became a billionaire in 2023, making him one of the richest celebrities.\nIn 1990, Johnson and Earl Graves Sr. obtained a large interest in the Washington, D.C. PepsiCo bottling operation, making it the company's largest minority-owned facility in the U.S. Johnson became a minority owner of the Lakers in 1994, having reportedly paid more than $10\u00a0million for part ownership. He also held the title of team vice president. Johnson sold his ownership stake in the Lakers in October 2010 to Patrick Soon-Shiong, a Los Angeles surgeon and professor at UCLA, but continued as an unpaid vice president of the team. In February 2017, Johnson returned to the Lakers as an advisor to Jeanie Buss.\nIn the wake of the Donald Sterling controversy, limited media reports indicated that Johnson had expressed an interest in purchasing the Los Angeles Clippers franchise.\nIn 2015, Johnson completed his planned acquisition for a \"majority, controlling interest\" in EquiTrust Life Insurance Company, which manages $14.5 billion in annuities, life insurance and other financial products.\nHe is an investor for aXiomatic eSports, the ownership company of Team Liquid.\nOn October 8, 2025, the Pasadena Tournament of Roses Association named Johnson the Grand Marshal of the 2026 Rose Parade. He will preside over the parade and participate in the pre-game ceremony at the 2026 Rose Bowl.\nPolitics.\nJohnson is a supporter of the Democratic Party. In 2006, he publicly endorsed Phil Angelides for Governor of California. He supported Hillary Clinton during her 2008 presidential campaign, and in 2010, he endorsed Barbara Boxer in her race for re-election to the U.S. Senate. In 2012, he endorsed Barack Obama for president. He endorsed and appeared in campaign ads for unsuccessful Los Angeles mayoral candidate Wendy Greuel in 2013. In 2015, he once again endorsed Hillary Clinton in her second presidential campaign. He hosted a fundraiser for Hillary Clinton's presidential campaign on August 22, 2016.\nHIV activism.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I think sometimes we think, \"Well, only gay people can get it; it's not going to happen to me\", and here I am saying that it can happen to anybody.\u2014\u200a\nJohnson was one of the first sports stars to go public about having HIV. AIDS activist Elizabeth Glaser, to whom Johnson had been introduced by a friend, convinced Johnson to go public about his diagnosis. \"She made me promise before she died that I would become the face of the disease and really go out and help people and educate people about it\", Johnson recalled in a 2011 interview with \"Frontline\".\nAfter announcing his infection in November 1991, Johnson created the Magic Johnson Foundation to help combat HIV, although he later diversified the foundation to include other charitable goals. In 1992, he joined the National Commission on AIDS, a committee appointed by members of Congress and the Bush Administration. Johnson left after eight months, saying that the White House had \"utterly ignored\" the work of the panel, and had opposed the commission's recommendations, which included universal healthcare and the expansion of Medicaid to cover all low-income people with AIDS. He was also the main speaker for the United Nations (UN) World AIDS Day Conference in 1999, and has served as a United Nations Messenger of Peace.\nHIV had been associated with intravenous drug users and homosexuals, but Johnson's campaigns sought to show that the risk of infection was not limited to those groups. Johnson stated that his aim was to \"help educate all people about what [HIV] is about\" and teach others not to \"discriminate against people who have HIV and AIDS\". Johnson was later criticized by the AIDS community for his decreased involvement in publicizing the spread of the disease.\nA number of research papers have been written on the \"Magic Johnson effect\", the effect Johnson's HIV announcement had on various populations, particularly those outside the stereotypes of who got infected with HIV \u2013 that is, heterosexuals. Johnson's announcement was a \"public-health catalyst\", according to a West Virginia University paper, \"rapidly correcting the public's understanding of who was at risk of infection\". The paper argues there was a \"large but temporary increase in the number of AIDS diagnoses for heterosexual men following the announcement\" and suggests that, for some of those people, Johnson's announcement \"prolonged patients' lifespans as a result of earlier access to medical care\". A paper published in \"AIDS Education and Prevention\" found that \"the announcement by Magic Johnson that he had been infected with HIV was associated with increased concern about HIV and with attitude and behavior changes that would lead to reduced risk\".\nTo prevent his HIV infection from progressing to AIDS, Johnson takes a daily combination of antiretroviral drugs, blocking and containing the virus. He has advertised GlaxoSmithKline's drugs, and partnered with Abbott Laboratories to publicize the fight against AIDS in African American communities.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\nBiographies.\nJohnson's autobiography is Other biographies include:"}
{"id": "36754", "revid": "42117739", "url": "https://en.wikipedia.org/wiki?curid=36754", "title": "International Finance Corporation", "text": "World Bank Group member financial institution\nThe International Finance Corporation (IFC) is an international financial institution headquartered in Washington, D.C., and a member of the World Bank Group. Established in 1956 as the private-sector arm of the World Bank Group, the IFC provides investment, advisory, and asset-management services to support private-sector development in developing countries. Its goal is to help people achieve better living standards by mobilizing financial resources for private enterprises.\nHistory.\nThe World Bank and International Monetary Fund were designed by delegates at the Bretton Woods conference in 1944. The World Bank, then consisting of only the International Bank for Reconstruction and Development, became operational in 1946. Robert L. Garner joined the World Bank in 1947 as a senior executive and expressed his view that private business could play an important role in international development. In 1950, Garner and his colleagues proposed establishing a new institution for the purpose of making private investments in the less developed countries served by the World Bank. The U.S. government encouraged the idea of an international corporation working in tandem with the World Bank to invest in private enterprises without accepting guarantees from governments, without managing those enterprises, and by collaborating with third party investors. When describing the IFC in 1955, World Bank President Eugene R. Black said that the IFC would only invest in private firms, rather than make loans to governments, and it would not manage the projects in which it invests.\nThe concept was nonetheless controversial in the US, where some business interests were uncomfortable with the public ownership of private firms. Nonetheless, in 1956, the International Finance Corporation became operational under the leadership of Garner. It initially had 12 staff members and $100 million (equivalent to $\u00a0million in 2024) in capital. The corporation made its inaugural investment in 1957 by making a $2 million (equivalent to $\u00a0million in 2024) loan to a Brazil-based affiliate of Siemens &amp; Halske (now Siemens AG).\nIn 2007, IFC bought 18% stake in the Indian Financial firm, Angel Broking. In December 2015, IFC supported Greek banks with 150 million euros by buying shares in four of them: Alpha Bank (60 million), Eurobank (50 million), Piraeus Bank (20 million) and National Bank of Greece (20 million).\nThe International Finance Corporation (IFC) has partnered with Mohinani Group to support plastic recycling efforts in Ghana and Nigeria. IFC will provide a $37 million loan to Mohinani Group\u2019s subsidiaries, Polytank Ghana Limited and Sonnex Packaging Nigeria, to establish PET recycling plants in both countries. Each plant will produce 15,000 tons of recycled PET (rPET) resins annually, reducing reliance on virgin plastics and lowering greenhouse gas emissions. The initiative is expected to create over 4,000 jobs and generate annual import savings of approximately $21 million per country. IFC will also offer advisory services to enhance environmental and social practices. This project aligns with IFC\u2019s climate change and economic development strategies for Ghana and Nigeria, as well as the World Bank Group\u2019s Climate Change Action Plan 2021-2025.\nGovernance.\nThe IFC is owned and governed by its member countries but has its own executive leadership and staff that conduct its normal business operations. It is a corporation whose shareholders are member governments that provide paid-in capital and have the right to vote on its matters. Originally, it was more financially integrated with the World Bank Group, but later, the IFC was established separately and eventually became authorized to operate as a financially autonomous entity and make independent investment decisions.\nThe IFC is governed by its Board of Governors which meets annually and consists of one governor per member country (most often the country's finance minister or treasury secretary). Each member typically appoints one governor and also one alternate. Although corporate authority rests with the Board of Governors, the governors delegate most of their corporate powers and their authority over daily matters such as lending and business operations to the board of directors. The IFC's Board of Directors consists of 25 executive directors who meet regularly and work at the IFC's headquarters, and is chaired by the President of the World Bank Group. The executive directors collectively represent all 186 member countries. When the IFC's Board of Directors votes on matters brought before it, each executive director's vote is weighted according to the total share capital of the member countries represented by that director.\nIFC is currently led by Makhtar Diop who was appointed as the institution's Managing Director and Executive Vice President in February 2021. Prior to this appointment, he was the World Bank's Vice President for Infrastructure, where he led the Bank's global efforts to build sustainable infrastructure in developing and emerging economies.\nAlthough the IFC coordinates its activities in many areas with the other World Bank Group institutions, it generally operates independently as it is a separate entity with legal and financial autonomy, established by its own Articles of Agreement. The corporation operates with a staff of over 3,400 employees, of which half are stationed in field offices across its member nations.\nFunctions.\nInvestment services.\nThe IFC's investment services consist of loans, equity, trade finance, syndicated loans, structured and securitized finance, client risk management services, treasury services, and liquidity management. In its fiscal year 2010, the IFC invested $12.7 billion in 528 projects across 103 countries. Of that total investment commitment, approximately 39% ($4.9 billion) was invested into 255 projects across 58 member nations of the World Bank's International Development Association (IDA).\nThe IFC makes loans to businesses and private projects generally with maturities of seven to twelve years. It determines a suitable repayment schedule and grace period for each loan individually to meet borrowers' currency and cash flow requirements. The IFC may provide longer-term loans or extend grace periods if a project is deemed to warrant it. Leasing companies and financial intermediaries may also receive loans from the IFC.\nThough loans have traditionally been denominated in hard currencies, the IFC has endeavored to structure loan products in local currencies. Its disbursement portfolio included loans denominated in 25 local currencies in 2010, and 45 local currencies in 2011, funded largely through swap markets. Local financial markets development is one of IFC's strategic focus areas. In line with its AAA rating, it has strict concentration, liquidity, asset-liability and other policies. The IFC committed to approximately $5.7 billion in new loans in 2010, and $5 billion in 2011.\nAlthough the IFC's shareholders initially only allowed it to make loans, the IFC was authorized in 1961 to make equity investments, the first of which was made in 1962 by taking a stake in FEMSA, a former manufacturer of auto parts in Spain that is now part of Bosch Spain. The IFC invests in businesses' equity either directly or via private-equity funds, generally from five up to twenty percent of a company's total equity. IFC's private-equity portfolio currently stands at roughly $3.0 billion committed to about 180 funds. The portfolio is widely distributed across all regions including Africa, East Asia, South Asia, Eastern Europe, Latin America and the Middle East, and recently has invested in Small Enterprise Assistance Funds' (SEAF) Caucasus Growth Fund, Aureos Capital's Kula Fund II (Papua New Guinea, Fiji, Pacific Islands) and Leopard Capital's Haiti Fund. Other equity investments made by the IFC include preferred equity, convertible loans, and participation loans. The IFC prefers to invest for the long-term, usually for a period of eight to fifteen years, before exiting through the sale of shares on a domestic stock exchange, usually as part of an initial public offering. When the IFC invests in a company, it does not assume an active role in management of the company.\nThrough its Global Trade Finance Program, the IFC guarantees trade payment obligations of more than 200 approved banks in over 80 countries to mitigate risk for international transactions. The Global Trade Finance Program provides guarantees to cover payment risks for emerging market banks regarding promissory notes, bills of exchange, letters of credit, bid and performance bonds, supplier credit for capital goods imports, and advance payments. The IFC issued $3.46 billion in more than 2,800 guarantees in 2010, of which over 51% targeted IDA member nations. In its fiscal year 2011, the IFC issued $4.6 billion in more than 3,100 guarantees. In 2009, the IFC launched a separate program for crisis response, known as its Global Trade Liquidity Program, which provides liquidity for international trade among less developed countries. Since its establishment in 2009, the Global Trade Liquidity Program assisted with over $15 billion in trade in 2011.\nThe IFC operates a Syndicated Loan Program in an effort to mobilize capital for development goals. The program was created in 1957 and as of 2011[ [update]] has channeled approximately $38 billion from over 550 financial institutions toward development projects in over 100 different emerging markets. The IFC syndicated a total of $4.7 billion in loans in 2011, twice that of its $2 billion worth of syndications in 2010. Due to banks retrenching from lending across borders in emerging markets, in 2009 the IFC started to syndicate parallel loans to the international financial institutions and other participants.\nTo service clients without ready access to low-cost financing, the IFC relies on structured or securitized financial products such as partial credit guarantees, portfolio risk transfers, and Islamic finance. The IFC committed $797 million in the form of structured and securitized financing in 2010. For companies that face difficulty in obtaining financing due to a perception of high credit risk, the IFC securitizes assets with predictable cash flows, such as mortgages, credit cards, loans, corporate debt instruments, and revenue streams, in an effort to enhance those companies' credit.\nFinancial derivative products are made available to the IFC's clients strictly for hedging interest rate risk, exchange rate risk, and commodity risk exposure. It serves as an intermediary between emerging market businesses and international derivatives market makers to increase access to risk management instruments.\nThe IFC fulfills a treasury role by borrowing international capital to fund lending activities. It is usually one of the first institutions to issue bonds or to do swaps in emerging markets denominated in those markets' local currencies. The IFC's new international borrowings amounted to $8.8 billion in 2010 and $9.8 billion in 2011. The IFC Treasury actively engages in liquidity management in an effort to maximize returns and assure that funding for its investments is readily available while managing risks to the IFC.\nAdvisory services.\nIn 2011, its evaluation report recognized that its investments performed well and reduced poverty, but recommended that the corporation define poverty and expected outcomes more explicitly to better-understand its effectiveness and approach poverty reduction more strategically. The corporation's total investments in 2011 amounted to $18.66 billion. It committed $820 million to advisory services for 642 projects in 2011, and held $24.5 billion worth of liquid assets. In addition to its investment activities the IFC provides a range of advisory services to support corporate decision-making regarding business, environment, social impact, and sustainability. The IFC's corporate advice targets governance, managerial capacity, scalability, and corporate responsibility. It prioritizes the encouragement of reforms that improve the trade friendliness and ease of doing business in an effort to advise countries on fostering a suitable investment climate. It also offers advice to governments on infrastructure development and public-private partnerships. The IFC attempts to guide businesses toward more sustainable practices particularly with regards to having good governance, supporting women in business, and proactively combating climate change. The International Finance Corporation has stated that cities in emerging markets can attract more than $29 trillion in climate-related sectors by 2030.\nAsset management company.\nThe IFC established IFC Asset Management Company LLC (IFC AMC) in 2009 as a wholly owned subsidiary to manage all capital funds to be invested in emerging markets. The AMC manages capital mobilized by the IFC as well as by third parties such as sovereign or pension funds, and other development financing organizations. Despite being owned by the IFC, the AMC has investment decision autonomy and is charged with a fiduciary responsibility to the four individual funds under its management. It also aims to mobilize additional capital for IFC investments as it can make certain types of investments which the IFC cannot. As of 2011[ [update]], the AMC managed the IFC Capitalization Fund (Equity) Fund, L.P., the IFC Capitalization (Subordinated Debt) Fund, L.P., the IFC African, Latin American, and Caribbean Fund, L.P., and the Africa Capitalization Fund, Ltd. The IFC Capitalization (Equity) Fund holds $1.3 billion in equity, while the IFC Capitalization (Subordinated Debt) Fund is valued at $1.7 billion. The IFC African, Latin American, and Caribbean Fund (referred to as the IFC ALAC Fund) was created in 2010 and is worth $1 billion. As of \u00a02012[ [update]], the ALAC Fund has invested a total of $349.1 million into twelve businesses. The Africa Capitalization Fund was set up in 2011 to invest in commercial banks in both Northern and Sub-Saharan Africa and its commitments totaled $181.8 million in March 2012. As of 2018[ [update]], Marcos Brujis is CEO of the AMC.\nFinancial performance.\nThe IFC prepares consolidated financial statements in accordance with United States GAAP which are audited by KPMG. It reported income before grants to IDA members of $2.18 billion in fiscal year 2011, up from $1.95 billion in fiscal 2010 and $299 million in fiscal 2009. The increase in income before grants is ascribed to higher earnings from the IFC's investments and also from higher service fees. The IFC reported a partial offset from lower liquid asset trading income, higher administrative costs, and higher advisory service expenses. The IFC made $600 million in grants to IDA countries in fiscal 2011, up from $200 million in fiscal 2010 and $450 million in fiscal 2009. The IFC reported a net income of $1.58 billion in fiscal year 2011. In previous years, the IFC had reported a net loss of $151 million in fiscal 2009 and $1.75 billion in fiscal 2010. The IFC's total capital amounted to $20.3 billion in 2011, of which $2.4 billion was paid-in capital from member countries, $16.4 billion was retained earnings, and $1.5 billion was accumulated other comprehensive income. The IFC held $68.49 billion in total assets in 2011.\nThe IFC's return on average assets (GAAP basis) decreased from 3.1% in 2010 to 2.4% in 2011. Its return on average capital (GAAP basis) decreased from 10.1% in 2010 to 8.2% in 2011. The IFC's cash and liquid investments accounted for 83% of its estimated net cash requirements for fiscal years 2012 through 2014. Its external funding liquidity level grew from 190% in 2010 to 266% in 2011. It has a 2.6:1 debt-to-equity ratio and holds 6.6% in reserves against losses on loans to its disbursement portfolio. The IFC's deployable strategic capital decreased from 14% in 2010 to 10% in 2011 as a share of its total resources available, which grew from $16.8 billion in 2010 to $17.9 billion in 2011.\nIn 2011, the IFC reported total funding commitments (consisting of loans, equity, guarantees, and client risk management) of $12.18 billion, slightly lower than its $12.66 billion in commitments in 2010. Its core mobilization, which consists of participation and parallel loans, structured finance, its Asset Management Company funds, and other initiatives, grew from $5.38 billion in 2010 to $6.47 billion in 2011. The IFC's total investment program was reported at a value of $18.66 billion for fiscal year 2011. Its advisory services portfolio included 642 projects valued at $820 million in 2011, compared to 736 projects at $859 million in 2010. The IFC held $24.5 billion in liquid assets in 2011, up from $21 billion in 2010.\nThe IFC received credit ratings of AAA from Standard &amp; Poor's in December 2012 and AAA from Moody's Investors Service in November 2012. S&amp;P rated the IFC as having a strong financial standing with adequate capital and liquidity, cautious management policies, a high level of geographic diversification, and anticipated treatment as a preferred creditor given its membership in the World Bank Group. It noted that the IFC faces a weakness relative to other multilateral institutions of having higher risks due to its mandated emphasis on private sector investing and its income heavily affected by equity markets.\nSustainability.\nSince 2009, the IFC has set development goals to expand sustainable agriculture, improve healthcare and education, increase access to microfinance, advance infrastructure, support small business growth, and invest in climate-related projects.\nThe IFC Sustainability Framework outlines IFC's approach to sustainable development and risk management. Its environmental and social standards are used as benchmarks by many corporations, investors, financial intermediaries, stock exchanges, regulators, and governments.\nThe IFC has faced criticism from environmental and animal welfare activists for continuing to support industrial animal agriculture operations despite promising to align its financing activities with the Paris Agreement climate and sustainability goals.\nGreen buildings in less developed countries.\nThe IFC has created a mass-market certification system for fast growing emerging markets called EDGE (\"Excellence in Design for Greater Efficiencies\"). IFC and the World Green Building Council have partnered to accelerate green building growth in less developed counties. The target is to scale up green buildings over a seven-year period until 20% of the property market is saturated. Certification occurs when the EDGE standard is met, which requires 20% less energy, water, and materials than conventional homes.\nCriticism.\nIFC comes under frequent criticism from NGOs that it is not able to track its money because of its use of financial intermediaries. For example, a report by Oxfam International and other NGOs in 2015, \"The Suffering of Others\", found the IFC was not performing enough due diligence and managing risk in many of its investments in third-party lenders.\nOther criticism focuses on IFC working excessively with large companies or wealthy individuals already able to finance their investments without help from public institutions such as IFC, and such investments do not have an adequate positive development impact. An example often cited by NGOs and critical journalists is IFC granting financing to a Saudi prince for a five-star hotel in Ghana.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36755", "revid": "3159626", "url": "https://en.wikipedia.org/wiki?curid=36755", "title": "International Development Association", "text": "International financial institution, member of the World Bank Group\nThe International Development Association (IDA) () is a development finance institution which offers concessional loans and grants to the world's poorest developing countries. The IDA is a member of the World Bank Group and is headquartered in Washington, D.C. in the United States. It was established in 1960 to complement the existing International Bank for Reconstruction and Development by lending to developing countries which suffer from the lowest gross national income, from troubled creditworthiness, or from the lowest per capita income. Together, the International Development Association and International Bank for Reconstruction and Development are collectively generally known as the World Bank, as they follow the same executive leadership and operate with the same staff.\nThe association shares the World Bank's mission of reducing poverty and aims to provide affordable development financing to countries whose credit risk is so prohibitive that they cannot afford to borrow commercially or from the Bank's other programs. The IDA's stated aim is to assist the poorest nations in growing more quickly, equitably, and sustainably to reduce poverty. The IDA is the single largest provider of funds to economic and human development projects in the world's poorest nations. From 2000 to 2010, it financed projects which recruited and trained 3 million teachers, immunized 310 million children, funded $792 million in loans to 120,000 small and medium enterprises, built or restored 118,000 kilometers of paved roads, built or restored 1,600 bridges, and expanded access to improved water to 113 million people and improved sanitation facilities to 5.8 million people. The IDA has issued a total US$238 billion in loans and grants since its launch in 1960. Thirty-six of the association's borrowing countries have graduated from their eligibility for its concessional lending. However, nine of these countries have relapsed and have not re-graduated.\nHistory.\nBackground.\nDuring the 1940s and 1950s, low-income developing countries began to realize that they could no longer afford to borrow capital and needed more-favorable lending terms than offered by the International Bank for Reconstruction and Development (IBRD). At the onset of his inaugural term in 1949, then-president of the United States Harry S. Truman assembled an advisory group to suggest ways to accomplish his Point Four Program, of which a significant component was an effort to strengthen developing countries, especially those nearest to the Eastern Bloc, to dissuade them from aligning with other communist states. The advisory group recommended an international mechanism that would function somewhere in between providing strictly-loaned and strictly-granted funds. The UN and United States government published reports expressing support for the creation of a multilateral, concessional lending program for the poorest developing countries. However, the United States was largely unresponsive and ultimately distracted by its involvement in the Korean War and unconvinced that development needed greater financial stimulation.\nDeveloping countries grew increasingly frustrated with not being able to afford IBRD lending and perceived the Marshall Plan as a comparatively generous gift to European nations. In the late 1940s and early 1950s, developing countries began calling for the United Nations (UN) to create a development agency that would offer technical support and concessional financing, with a particular desire that the agency adhere to other UN bodies' convention of each country having one vote as opposed to a weighted vote. However, the United States ultimately opposed proposals of that nature. As the United States grew more concerned over the growth of the Cold War, it made a concession in 1954 at the behest of its Department of State by backing the conception of the International Finance Corporation (IFC). Despite the launch of the IFC in 1956, developing countries persisted in demanding the creation of a new concessional financing mechanism and the idea gained traction within the IBRD. Then-President of the IBRD Eugene R. Black, Sr. began circulating the notion of an International Development Association, as opposed to an idea of a concessional named the Special United Nations Fund for Economic Development (SUNFED) governed by the United Nations. Paul Hoffman, the Marshall Plan's former Administrator, proposed the idea of a soft-loan facility within the World Bank, where the US would have a preponderant voice in the allocation of such loans. Democratic senator Mike Monroney of Oklahoma supported this idea. As Chairman of the Senate Subcommittee on International Finance, Monroney proposed a resolution recommending a study of the potential establishment of an International Development Association to be affiliated with the IBRD. Monroney's proposal was more preferred received within the United States than the SUNFED. The resolution passed the senate in 1958, and then-U.S. treasury secretary Robert B. Anderson encouraged other countries to conduct similar studies. In 1959, the World Bank's Board of Governors approved a U.S.-born resolution calling for the drafting of the articles of agreement. SUNFED later became the Special Fund and merged with the Expanded Programme of Technical Assistance to form the United Nations Development Programme.\nFounding.\nBy the end of January 1960, fifteen countries signed the articles of agreement which established the International Development Association. The association launched in September of that same year with an initial budget of $913 million ($7.1 billion in 2012 dollars). Over the next eight months following its launch, the IDA grew to 51 member states and loaned $101 million ($784.2 million in 2012 dollars) to four developing countries.\n1960 - 1979.\nBy 1978, the IAD had grown it's available resources to approximately $18.1 billion ($89.4 billion in 2025 dollars) split between approximately $1.1 billion ($5.4 billion in 2025 dollars) in recurring funding from member governments and approximately $15.6 billion ($77.1 billion in 2025 dollars) in supplementary contributions. The primary focus of this lending was for \"Agriculture and rural development\" representing approximately $1.34 billion ($6.6 billion in 2025 dollars) or 58% of all credits, for uses such as establishing dairy cooporatives in India or grain storage and marking systems in Ethiopia. \n1980 - 1999.\nInn 1983, the UN reported that more than 50 countries were eligible to receive loans from IDA with a gross national product of less than $796 per person ($2,821 in 2025 dollars). Loans at the time were interest free, but carried service charges of .75 % on disbursed amounts and .5% on undispersed balances. The loans had 10-year grace periods and were then repayable over 50-year terms. The number of countries eligible to receive funds grew to 81 countries by the end of 1999, with lending reaching $6.8 billion ($13.2 billion in 2025 dollars).\n2000 - 2019.\nIDA grew to $8.7 billion ($14.4 in 2025 dollars) in 2005, covering 160 projects in 66 countries. Of these, the largest commitments were for projects in Africa totaling $3.9 billion ($6.4 in 2025 dollars). Total membership in the IDA stood at 165 countries by the end of the 2005 fiscal year.\nCurrent Events.\nOn October 18, 2024, Suriname became the most recent and 175th borrowing member of the IDA. Subsequently, the World Bank Group approved $22.2 million for The Suriname Preparedness and Enhancing Resilient Communities Project. This project is intended to provide support for flood prevention in and around Suriname's capital Paramaribo, as well as the communities of Saramacca and Wanica.\nIn September 2025, World Bank President Ajay Banga indicated he would be interested in allowing private investors access to securitized risk tranches of loans from the IDA if they could be pooled with those of other development banks, but acknowledged it would be difficult. This is in response to the World Bank offering $500mn in tranches from loans made by the International Finance Corporation to private investors earlier in 2025 to compensate for reduced funding from nations like the UK and US. Banga also noted the IDA still gained $24bn in donor funding during its last round in 2024.\nGovernance and operations.\nThe IDA is governed by the World Bank's Board of Governors which meets annually and consists of one governor per member country (most often the country's finance minister or treasury secretary). The Board of Governors delegates most of its authority over daily matters such as lending and operations to the Board of Directors. The Board of Directors consists of 25 executive directors and is chaired by the president of the World Bank Group. The executive directors collectively represent all 187 member states of the World Bank, although decisions regarding IDA matters concern only the IDA's 172 member states. The president oversees the IDA's overall direction and daily operations. As of May 2024[ [update]], Ajay Banga serves as the President of the World Bank Group. The association and IBRD operate with a staff of approximately 10,000 employees.\nThe IDA is evaluated by the Bank's Independent Evaluation Group. In 2009, the group identified weaknesses in the set of controls used to protect against fraud and corruption in projects supported by IDA lending. In 2011, the group recommended the Bank provide recognition and incentives to staff and management for implementing activities which implement the Paris Declaration on Aid Effectiveness principles of harmonization and alignment, promote greater use of sector-wide approaches to coordination, and explain the reasons why when a country's financial management system is not used so that the client country may address those shortcomings. It also recommended that the Bank collaborate with development partners to strengthen country-level leadership of development assistance coordination by offering greater financial and technical support. Development economists, such as William Easterly, have conducted research which ranked the IDA as featuring the most transparency and best practices among donors of development aid.\nResearchers from the Center for Global Development expect that the IDA's collection of eligible borrowing countries will decrease by half by the year 2025 (marking the 65th anniversary of the association's establishment) due to graduations and that remaining borrowers will consist primarily of African countries and will face substantial population declines. These changes will imply a need for the association to carefully examine its financial models and business operations to determine an appropriate strategy going forward. The center recommended that the World Bank leadership begin discussing the long-term future of the IDA.\nMembership.\nThe IDA has 173 member countries which pay contributions every three years as replenishments of its capital. On 12 December 2008, Samoa joined UNIDO as its 173rd member. The IDA lends to 75 borrowing countries, over half of which (39) are in Africa. Membership in the IDA is available to only the countries who are members of the World Bank, particularly the IBRD. Throughout its lifetime, 44 borrowing countries have graduated from the association, although 9 of these countries have relapsed as borrowers after not sustaining their graduate status.\nTo be eligible for support from the IDA, countries are assessed by their poverty and their lack of creditworthiness for commercial and IBRD borrowing. The association assesses countries based on their per capita income, lack of access to private capital markets, and policy performance in implementing pro-growth and anti-poverty economic or social reforms. As of 2019[ [update]], to borrow from the IDA's concessional lending programs, a country's gross national income (GNI) per capita must not exceed $1,145.\nIDA borrowing countries.\nThe following 75 countries are IDA borrowing countries.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCountries that graduated from IDA lending.\nThe following countries have graduated from their eligibility for IDA lending.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCountries relapsed to IDA lending.\nThe following countries have relapsed to their eligibility for IDA lending and have not yet re-graduated or have instead become partially eligible (also referred to as a \"blend country\").\nReplenishment rounds.\nThe IDA is a unique part of the World Bank as it requires continuous replenishment of its resources. Member countries replenish its funds through contributions in addition to supplementary funds provided by the International Bank for Reconstruction and Development and the International Finance Corporation (IFC). Whereas the IBRD acquires most of its funds by raising capital on international financial markets, the IDA heavily depends on contributions from its member states. The IDA received 2 billion in special drawing rights ($3 billion USD) from the IBRD and IFC. \nApproximately half of the IDA's resources come from the 45 donating member countries. In its early years, the IDA received most of its replenishments from the United Kingdom and United States but, because they were not always reliable sources of funding, other developed nations began to step in and fill the economic gaps not met by these two countries. Every three years, member nations that provide funds to the IDA gather together to replenish the IDA's resources. These funds come primarily from well-developed countries including the United States, Japan, France, Germany, and the United Kingdom with 58% from the US, 22% from France, and 8% from the UK. As of 2025, there have been 21 IDA replenishment rounds. Fifty-one member countries participated in the IDA's 16th replenishment of US$49.3 billion. The IDA's loans and grants are usually not paid in full to the borrower at the outset, but rather disbursed incrementally as needed by the project. Most of the donor countries such as the United States commit letters of credit to the IDA which bear no interest and are not able to be transferred or revoked, and which are exchanged for cash as needed for project disbursal. Other countries pay their contributions in full on the date of commitment to the IDA so that it may cover its operating expenses. Donors receive no return of funds and repayments from borrowers are again loaned to future projects.\nAlthough the IDA's funds are now regularly replenished, this does not happen without some financial and political challenges for the donating countries. When donor countries convene to negotiate the replenishments, there is often intense discussion about redefining the association's goals and objectives or IDA reform. Due to delays in the United States Congress impeding the approval of IDA funding, the association's members implemented a set of policy triggers outlining the commitment threshold necessary for replenishment to take effect. The threshold imposed a requirement that an aggregate share of 85% in voting stock is necessary for executing a replenishment. The threshold was implemented with the aim to compel the United States to participate in replenishment rounds. Though countries intended for the triggers to hold the United States to its commitments, the threshold ultimately provided the United States a de facto veto power over replenishment and capital increase negotiations due to its ability to bring replenishment negotiations to an impasse by threatening to withhold support. The U.S. has used this influence to further its long-term foreign policy objectives and short-term political and economic goals by imposing conditionality on replenishment negotiations.\nLending.\nThe IDA lends to countries with the aim to finance projects that will develop infrastructure and improve education, healthcare, access to clean water and sanitation facilities, and environmental responsibility. It is considered to be the soft lending window of the World Bank, while the IBRD is considered to be the hard lending window. The association offers grants and loans with maturities ranging from 25 to 40 years, grace periods of 5 to 10 years, and interest rates of 2.8% or 1.25% depending on whether the borrower is a blend country \u2013 a country also eligible for IBRD loans \u2013 and to which degree it is eligible. Regular IDA-eligible borrowers may take advantage of no-interest loans. Financial resources are allocated to eligible countries based on their success at implementing pro-growth and a poverty-reducing domestic policies. The IDA uses the World Bank's Country Policy and Institutional Assessment (CPIA) development indicator to determine each country's place in a resource allocation index. It then prioritizes its lending to those countries which are indicated to be most promising in terms of favorable policies and aid effectiveness. The IDA adopted the Crisis Response Window in 2007 to enable the rapid provision of emergency financing in response to crises. The association adopted the Immediate Response Mechanism in 2011 to provide IDA borrowers with immediate access to withdraw undisbursed portions of their loans, should a crisis arise that meets the mechanism's criteria.\nAfrica.\nBecause African countries face some of the most severe poverty and underdevelopment, and because 39 of those countries are the IDA's poorest member states, the association allocates approximately half of the IDA's resources toward financing projects in those countries. As of 2012, its efforts to improve the region, the IDA has helped bring electricity to an additional 66 million Africans since 1997, helped build or restore 240,000 kilometers of paved roads, and helped enroll an additional 15 million African children in school since 2002. The IDA was approved in May 2012 to provide US$50 million worth of credit to the Women Entrepreneur Development Project as part of an effort to help women in Ethiopia participate in business as skilled employees or leaders. Although the positive outcomes of the IDA's efforts in Africa had been historically slow, the large allocation of funding to African countries led to positive outcomes particularly within agriculture and infrastructure development efforts.\nAsia.\nThe IDA's efforts in Asia have been particularly successful. Numerous Asian countries have graduated from the IDA lending program, including the Philippines, China, South Korea, Thailand, and India. Of the association's borrowing countries, approximately 20 are in Asia. The association's efforts in South Asia have focused primarily on projects for education, healthcare, transportation, agriculture, and energy. Due to rapid growth in Asian countries' populations, some pockets of poverty have emerged. To mitigate this effect, the IDA adopted an economic plan of action which established organizations to improve education and healthcare, with a focus on reducing poverty across Asian nations in ways that are compatible with local culture.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36756", "revid": "42", "url": "https://en.wikipedia.org/wiki?curid=36756", "title": "ICFTU", "text": ""}
{"id": "36760", "revid": "43736825", "url": "https://en.wikipedia.org/wiki?curid=36760", "title": "International Confederation of Free Trade Unions", "text": "International trade union federation\nThe International Confederation of Free Trade Unions (ICFTU) was an international trade union. It came into being on 7 December 1949 following a split within the World Federation of Trade Unions (WFTU), and was dissolved on 31 October 2006 when it merged with the World Confederation of Labour (WCL) to form the International Trade Union Confederation (ITUC).\nPrior to being dissolved, the ICFTU had a membership of 157 million members in 225 affiliated organisations in 148 countries and territories.\nHistory.\nIn 1949, early in the Cold War, alleging Communist domination of the WFTU's central institutions, a large number of non-communist national trade union federations (including the U.S. Congress of Industrial Organizations (CIO), the British TUC, the French FO, the Italian CISL and the Spanish UGT) seceded and created the rival ICFTU at a conference in London attended by representatives of nearly 48 million members in 53 countries.\nThroughout its existence, the ICFTU had internal disputes over what approach to hold to communism.\nFrom the 1950s the ICFTU actively recruited new members from the developing regions of first Asia and subsequently Africa. Following the collapse of Communist party government in the Soviet Union and eastern Europe, the Federation's membership has risen steeply from 87 million in 1988 and 100 million in 1992, as trade union federations from former Soviet bloc countries joined the ICFTU.\nIn 1975 former CIA agent Philip Agee revealed in his book \"\" that the ICFTU was a \"Labor center set up and controlled by the CIA to oppose the World Federation of Trade Unions (WFTU).\"\nThe ICFTU was formally dissolved on 31 October 2006 when it merged with the World Confederation of Labour (WCL) to form the International Trade Union Confederation (ITUC).\nOrganisation.\nThe ICFTU had four regional organisations. APRO covered Asia and the Pacific, AFRO in Africa, and ORIT for the Americas. Until 1969, the ERO covered Europe, but it became increasingly marginal and was dissolved. The ICFTU later maintained close links with the European Trade Union Confederation (ETUC), which included all ICFTU European affiliates). It also worked closely with many Global Union Federations, which link together national unions from a particular trade or industry at international level.\nCentral to the ICFTU's work was the struggle to defend workers' rights. The ICFTU lobbied for the ratification of the so-called \"core labour standards\"\u2014eight key conventions of the International Labour Organization concerning freedom of association, the abolition of child labour and forced labour and the elimination of discrimination in the workplace.\nThe ICFTU has staff which are devoted entirely to the monitoring and defence of workers rights, and they issue\u2014almost on a daily basis\u2014alerts and calls to action. The ICFTU published its \"Annual Survey of Violations of Trade Union Rights\" every June, the publication of which was usually accompanied by extensive press coverage of the violations of trade union rights around the world. The report often focused on the numbers of people killed for being members of unions.\nIn its constitution, the organisation pledged itself to \"champion the cause of human freedom, promote equality of opportunity for all people, seek to eliminate everywhere in the world any form of discrimination or subjugation based on race, religion, sex or origin, oppose and combat totalitarianism and aggression in any form\".\nThat constitution listed no fewer than seventeen aims of the organisation and it has been argued that the ICFTU from its very beginning set itself goals that would be impossible to achieve\u2014particularly with a small staff and budget. For example, the organisation's constitution required it \"to carry out a programme of trade union and workers' education\" as well as to give \"assistance to those suffering from the consequences of natural and industrial disasters\".\nIn 2004 Australian union leader Sharan Burrow was elected as the first female president of the ICFTU.\nAnnual survey of violations of trade union rights.\nICFTU published an annual report which documents violations by governments, industries, and military and police forces against both workers and related trade unions.\n2006 report.\nReleased on 7 June 2006 the report reprised the year 2005. The press release from ICFTU OnLine reports,\n\"115 trade unionists were murdered for defending workers' rights in 2005, while more than 1,600 were subjected to violent assaults and some 9,000 arrested ... Nearly 10,000 workers were sacked for their trade union involvement, and almost 1,700 detained.\"\nThe report is divided into five regional sections, with detailed reports by country.\nAfrica.\nICFTU wrote that, \"One of the most striking features of the violations that took place in Africa is the failure of governments to respect the rights of their own employees, both through the restrictions in law on organising, collective bargaining and strike action, and repression in practice.\" The report continues on to detail violations such as the lack of the right to organise unions in the public service in ; the police use of stun guns, rubber bullets and tear gas at workers' strikes and protests in South Africa; and the death of a drivers' union member during a demonstration by striking minibus and lorry drivers.\nAmericas.\nThe report of violence in the Americas details a total of 80 deaths, more than half of the number reported worldwide. 70 of those deaths were in Colombia, while an additional 260 Colombian workers received death threats. In Ecuador 44 workers at the San Jose plantation were fired for forming a union. In Canada a collective agreement was imposed by law on members of the BCTF.\nAsia and Pacific.\nICFTU singled out Bangladesh, Cambodia, China, India, South Korea and the Philippines as having \"particularly\" violent episodes. In Bangladesh three trade unionists were killed when police intervened in a Sinha Textile Mill protest. In South Korea, Kim Tae-hwan from the Federation of Korean Trade Unions was run over and killed while on the picket line.\nIn the Philippines, Diosdado Fortuna, leader of the Food and Drug Industry Union, was shot dead by two unidentified gunmen, Victoria Ramonte of the Andres Soriano College Employees' Union was stabbed to death, and Ricardo Ramos, President of the Sugar Workers' Union was shot and killed.\nEurope.\nThe report on Europe begins by noting \"Strong resistance to the creation of independent trade unions was a common trait across Central and Eastern Europe, both by employers and the State.\" Examples include an organised government attempt to coerce workers to leave independent trade unions in . Belarus is highlighted as wanting to return to Soviet-era trade union centres, with the ensuing close ties to the government.\nThe death of one trade unionist in Russia is reported. Although there are no details concerning the exact circumstances, he had previously received threats, and his house had been set on fire.\nMiddle East.\nIn Iraq, during the first two months of 2005 Hadi Salih, international secretary of the Iraqi Federation of Trade Unions (IFTU) was brutally tortured and killed. Talib Khadim and Saady Edan, both also from the IFTU were attacked and kidnapped. Two attempts were made on the life of the president of the IFTU's Kirkuk branch. Ali Hassan Abd of the Oil and Gas Workers' Union was shot and killed in front of his children, and Ahmed Adris Abas of the Transport and Communications Union, was shot dead.\nThe report also details the difficulties faced by migrant workers in many countries, such as Kuwait, Lebanon, Oman, Qatar and Saudi Arabia, where they are a major portion of the labour force, but have few rights.\nQatar is singled out as a source of good news, with the country adopting a new labour code which, although still below international standards, allowed for the establishment of free trade unions.\n1949: Jacobus Hendrik Oldenbroek\n1960: Omer Becu\n1967: Harm Buiter\n1972: Otto Kersten\n1982: John Vanderveken\n1992: Enzo Friso\n1995: Bill Jordan\n2002: Guy Ryder\n1949: Paul Finet\n1951: Vincent Tewson\n1953: Omer Becu\n1957: Arne Geijer\n1965: Bruno Storti\n1972: Donald MacDonald\n1975: P. P. Narayanan\n1992: Roy Trotman\n2000: Fackson Shamenda\n2004: Sharan Burrow\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36762", "revid": "50982702", "url": "https://en.wikipedia.org/wiki?curid=36762", "title": "Ilona Staller", "text": "Hungarian-Italian former pornographic actress, politician, and singer (born 1951)\nIlona Anna Staller (born 26 November 1951), known by her stage name Cicciolina, is a Hungarian-Italian former porn star, politician, and singer. Staller gained fame in the early 1970s through her radio show \"Voulez-vous coucher avec moi?\" and became widely recognized by her stage name Cicciolina. She appeared in numerous films and gained attention for being the first to bare her breasts on live Italian television in 1978. Staller ventured into politics and was elected to the Italian Parliament in 1987, campaigning on a libertarian platform with the Radical Party.\nThroughout her career, Staller made provocative offers, such as offering to have sex with Saddam Hussein and Osama bin Laden in exchange for peace. Staller also had a brief marriage to American artist Jeff Koons, with whom she had a son.\nEarly life.\nStaller was born in Budapest during the era of the Hungarian People's Republic. Her father, L\u00e1szl\u00f3 Staller, left the family when she was 3. She was raised by her mother, who was a midwife, and her stepfather, who was an official in the Hungarian Ministry of the Interior. In 1964, at age 12, she began working as a model for the Hungarian news agency Magyar T\u00e1virati Iroda. In her memoirs and in a 1999 TV interview, she claimed that she had provided the Hungarian authorities with information on American diplomats staying at a Budapest luxury hotel where she worked as a maid in the 1960s.\nDuring her hotel work when she was 20, Staller met a 25-year-old Italian national named Salvatore Martiniongiene, whom she later married. Initially, she had accepted the marriage proposal, but she changed her mind before the wedding and threw the ring on the snow. Staller's stepfather forced her to marry him to avoid embarrassment. During the ceremony, the priest reportedly noticed that Staller was the saddest bride he had ever met. The couple lived in Milan, near the Central Station, in modest conditions. Her work as a model allowed her to divorce after a year of marriage.\nPornography and show business.\nNaturalized through marriage and settled in Italy, Staller met pornographer Riccardo Schicchi in the early 1970s. Starting in 1973, she gained fame with her radio show called \"Voulez-vous coucher avec moi?\" on Radio Luna. For that program, she adopted the name Cicciolina, and she referred to her male fanbase and later the male members of the Italian Parliament as \"\" (\"little tubby boys\").\nStaller appeared in several films from 1970 but made her debut under her own name in 1975 with \"La liceale\" (also known as \"The Teasers\"), where she played alongside Gloria Guida as her lesbian classmate. In 1978, during the RAI show \"C'era due Volte\", Staller's breasts were the first to be bared live on Italian TV. In 1983, she appeared in her first hardcore pornographic film, \"Telefono rosso\" (\"Red Telephone\"). Staller produced the film together with Schicchi's company, Diva Futura. Her memoirs were published as \"Confessioni erotiche di Cicciolina\" (\"Erotic Confessions of Cicciolina\") by Olympia Press of Milan in 1987. That same year, she appeared in \"Carne bollente\", titled \"The Rise and Fall of the Roman Empress\" in the United States, co-starring John Holmes. The film caused controversy when it was later revealed that Holmes had tested positive for HIV prior to appearing in it.\nIn 1987, invited by the Portuguese magazine \"Tal &amp; Qual\", Staller visited the Assembly of the Republic and posed topless, leading to the suspension of the session and official complaints from members of CDS \u2013 People's Party. The only person who talked to Staller was Nat\u00e1lia Correia. Staller has appeared nude in \"Playboy\" editions in several countries. Her first \"Playboy\" appearance was in Argentina in March 1988. She also appeared in the U.S. edition in September 1990, and in Hungary (June 2005), Serbia (July 2005), and Mexico (September 2005). Staller appeared in the film \"Replikator\" (1996) and had a role in the Brazilian soap opera \"Xica da Silva\" as Princess Ludovica di Castelgandolfo di Genova, also in 1996. In 2008, Staller participated as a contestant on the Argentine version of \"Strictly Come Dancing\" called \"Bailando por un Sue\u00f1o\".\nPolitical life.\nIn 1979, Staller was presented as a female candidate to the Italian Parliament by the Lista del Sole, Italy's first Green party. In 1985, she switched to the Radical Party, campaigning on a libertarian platform against nuclear energy and NATO membership, as well as for human rights. She was elected to the Italian Parliament in 1987, with approximately 20,000 votes. While in office and before the outset of the Gulf War, she offered to have sex with Iraqi leader Saddam Hussein in return for peace in the region. She was not re-elected at the end of her term in 1992.\nIn 1991, Staller was among the founders of another Italian political movement, called Love Party, which was spearheaded by friend and fellow porn star Moana Pozzi. In January 2002, she began exploring the possibility of campaigning in Hungary, her country of birth, to represent Budapest's industrial K\u0151b\u00e1nya district in the Hungarian Parliament; however, she failed to collect enough petition signatures for a non-partisan candidacy. In the same year, she ran in the local elections in Monza, Lombardy, promising to convert a prominent building into a gambling casino but was not elected. In 2004, she announced plans to run for mayor of Milan with a similar promise. She renewed her offer to have sex with Saddam Hussein in October 2002, when Iraq was resisting international pressure to allow inspections for weapons of mass destruction, and she made the same offer to Osama bin Laden in April 2006.\nIn September 2011, it was revealed that Staller was eligible for and would be receiving a yearly pension of \u20ac39,000 from the Italian state as a result of her five years in the country's parliament. Reacting to the controversy raised by the news, Staller, who started receiving the pension in November 2011, when she turned 60, stated: \"I earned it and I'm proud of it.\" In 2012, Staller founded the Democracy, Nature, Love party. Its objectives included the legalization of same-sex marriage, the reopening of former brothels, a guaranteed minimum wage for young people, improvements to the judiciary, and the elimination of the privileges of the rich political caste. On a proposal by blogger Luca Bagatin, who said that Staller was \"a friend I had always respected and was intrigued by the idea of relaunching the secular area with a 'radical' and 'far-left' program\", Staller was the unsuccessful candidate, in the 2013 Rome municipal election in Rome held on 26 and 27 May 2013, as part of the Republicans and Liberals list.\nIn 2020, Staller relaunched her Democracy, Nature, Love party and said that she had appealed a new law that reduced her parliamentary pension from \u20ac3,100 to \u20ac1,000.\nMusical career.\nStaller has recorded several songs, mostly from live performances, with explicit lyrics being sung to a children's melody. Her most famous song is \"Muscolo rosso\", a song entirely dedicated to \"il cazzo\", which means \"the dick\" in Italian. Because of its extensive use of profanity, the song could not be released in Italy, but became a hit in other countries, especially in France. The song gained considerable popularity in the internet era, when many Italian speakers were able to hear it for the first time. Several unreleased songs were recorded during her RCA period and the Diva Futura agency period. Some of these unreleased songs were subsequently used during her TV shows and live performances or as soundtracks in her porn movies.\nPersonal life.\nStaller was the muse of American artist Jeff Koons, who persuaded her to collaborate on a series of sculptures and photographs of them having sex in many positions, settings, and costumes, which were exhibited under the title \"Made in Heaven\" and made waves at the 1990 Venice Biennale. Staller married Koons in 1991. In 1992, they had a son but separated the following year, partly because Staller refused to stop making porn. Their marriage ended in 1994. In violation of a United States court order, as Koons had custody of their son, Staller left the United States for Italy, taking their then-two-year-old son. In 2008, Staller filed suit against Koons for failing to pay child support. In 2024, Staller said that she has reported her son to the police for drug abuse several times.\nStaller is an accomplished chess player, having learned from her father while growing up in Hungary. In July 2021, it was announced she would demonstrate her ability in an exhibition match, taking on four top players simultaneously.\nIn popular culture.\nIn 1980, an erotic comics series, \"La Cicciolina\", was made by Lucio Filippucci and Giovanni Romanini, based on Staller. Italian metal band Bulldozer released the tracks \"Ilona the Very Best\" on their 1987 album IX and \"Ilona Had Been Elected\" on their 1988 album Neurodeliri in dedication to her. In 1994, Later in 2005, Japanese metal band Abigail released the compilation \"Abigail Loves Ilona, as She Is the Very Best\" featuring a photograph of Ilona as the album art, and includes several Bulldozer covers.\nBrazilian musician Fausto Fawcett wrote a song in tribute to Cicciolina, titled \"Cicciolina (O Cio Eterno)\", featured on his 1989 album \"Imp\u00e9rio dos Sentidos\". British band Pop Will Eat Itself released a song called \"Touched by the Hand of Cicciolina\" as an unofficial World Cup single in July 1990. The song reached number 28 on the UK Singles Chart. The 1991 \"Machines of Loving Grace\" album paid tribute to Staller and named a song after her. Chilean punk band Los Peores de Chile released a song titled \"Chicholina\" in 1994, which had heavy TV and radio airplay, receiving critical acclaim by the national music press at the time, in live shows, the band says Ilona is a God.\nFinnish singer Erika Vikman released a song titled \"Cicciolina\" on 26 January 2020. It was selected as one of six entries that competed to represent Finland in the Eurovision Song Contest 2020. The song finished in second place in the national selection. In the 2020 Spanish television series \"Veneno\", Staller, played by Miriam Giovanelli, was portrayed attending to a party in Gran Canaria in 1996, where she met Spanish personality La Veneno. Also in 2020, electronic music duo Brutalismus 3000 released a song titled \"Cicciolina\", the first track of their album named \"Amore Hardcore\". In the song, they refer to Staller and her life. In 2023, Oska Wald from the band Chuckamuck released a song entitled \"Pizza Amore\", in which he refers to a fictional pizza called \"Pizza Cicciolina\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36768", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=36768", "title": "Pope Gregory I", "text": "64th Bishop of Rome; head of the Roman Catholic Church from AD 590 to 604\nPope Gregory I (; ; c.\u2009540 \u2013 12 March 604), commonly known as Saint Gregory the Great (; ), was the 64th Bishop of Rome from 3 September 590 until his death on 12 March 604. He is known for instituting the first recorded large-scale mission from Rome, the Gregorian mission, to convert the then largely pagan Anglo-Saxons to Christianity. Gregory is also well known for his writings, which were more prolific than those of any of the previous popes. The epithet Saint Gregory the Dialogist has been attached to him in Eastern Christianity because of his \"Dialogues\". English translations of Eastern texts sometimes list him as Gregory \"Dialogos\" from the Greek (\"dialogos\", conversation), or the Anglo-Latinate equivalent \"Dialogus\". He is the second of the three Popes listed in the \"Annuario Pontificio\" with the title \"the Great\", alongside Popes Leo I and Nicholas I.\nA Roman senator's son, and himself the prefect of Rome at 30, Gregory lived in a monastery that he established on his family estate before becoming a papal ambassador and then pope. Before becoming Pope, he challenged the theological views of Patriarch Eutychius of Constantinople before the emperor Tiberius II. Although he was the first pope from a monastic background, his prior political experiences may have helped him to be a talented administrator. During his papacy, his administration greatly surpassed that of the emperors Maurice and Theodosius in improving the welfare of the people of Rome. Gregory regained papal authority in Spain and France and sent missionaries to England, including Augustine of Canterbury and Paulinus of York. The realignment of barbarian allegiance to Rome from their Arian Christian alliances shaped medieval Europe. Gregory saw Franks, Lombards, and Visigoths align with Rome in religion. He also combated the Donatist heresy, popular particularly in North Africa at the time.\nThroughout the Middle Ages, he was known as \"the Father of Christian Worship\" because of his exceptional efforts in revising the Roman worship of his day. His contributions to the development of the Divine Liturgy of the Presanctified Gifts, still in use in the Byzantine Rite, were so significant that he is generally recognized as its \"de facto\" author.\nGregory is honored, along with Augustine, Jerome and Ambrose, as one of the four Great Latin Church Fathers, and is a Doctor of the Church. He is considered a saint in the Catholic Church, Eastern Orthodox Church, Anglican Communion, various Lutheran denominations, and other Protestant denominations. Immediately after his death, Gregory was canonized by popular acclaim. John Calvin, a Protestant reformer, admired Gregory greatly, and declared in his \"Institutes\" that Gregory was the last good pope. Gregory is the patron saint of musicians and teachers.\nEarly life.\nGregory was born c.\u2009540 in Rome, at that time recently reconquered by the Eastern Roman Empire from the Ostrogoths. His parents named him \"Gregorius\", which according to \u00c6lfric of Eynsham in \"An Homily on the Birth-Day of S. Gregory,\" \"is a Greek Name, which signifies in the Latin Tongue, \"Vigilantius\", that is in English, Watchful\". The medieval writer who provided this etymology did not hesitate to apply it to the life of Gregory. \u00c6lfric states, \"He was very diligent in God's Commandments.\"\nGregory was born into a wealthy noble Roman family with close connections to the church. His father, Gordianus, a patrician who served as a senator and for a time was the Prefect of the City of Rome, also held the position of Regionarius in the church, though nothing further is known about that position. Gregory's mother, Silvia, was well-born, and had a married sister, Pateria, in Sicily. His mother and two paternal aunts, Trasilla and Emiliana, are honored by Catholic and Orthodox churches as saints. Gregory's great-great-grandfather had been Pope Felix III. Gregory's election to the throne of St. Peter made his family the most distinguished clerical dynasty of the period.\nThe family owned and resided in a \"villa suburbana\" on the Clivus Scauri on the Caelian Hill, (now the Via di San Gregorio). It branched from the road having the former palaces of the Roman emperors on the Palatine Hill opposite. The north of the street runs into the Colosseum; the south, the Circus Maximus. In Gregory's day, the ancient buildings were in ruins and were privately owned. Villas covered the area. Gregory's family also owned working estates in Sicily and around Rome. Gregory later had portraits of his parents frescoed in their former home on the Caelian and these were described 300 years later by John the Deacon. Gordianus was tall with a long face and light eyes. He wore a beard. Silvia was tall, had a round face, blue eyes and a cheerful look. They had another son whose name and fate are unknown.\nGregory was born into a period of upheaval in Italy. From 542 the Plague of Justinian swept through the provinces of the empire, including Italy. The plague caused famine, panic, and sometimes rioting. In some parts of the country, over a third of the population was wiped out or destroyed, with heavy spiritual and emotional effects on the people of the empire. Politically, although the Western Roman Empire had long since vanished in favor of the Gothic kings of Italy, during the 540s Italy was gradually retaken from the Goths by Justinian I, emperor of the Eastern Roman Empire ruling from Constantinople. As the fighting was mainly in the north, the young Gregory probably saw little of it. Rome was sacked and vacated by Totila in 546, destroying most of its population, but in 549 he invited those who were still alive to return to the empty and ruined streets. It has been hypothesized that young Gregory and his parents retired during that intermission to their Sicilian estates, to return in 549. The war was over in Rome by 552, and a subsequent invasion of the Franks was defeated in 554.\nLike most young men of his position in Roman society, Gregory was well educated, learning grammar, rhetoric, the sciences, literature, and law; he excelled in all these fields. Gregory of Tours reported that \"in grammar, dialectic and rhetoric ... he was second to none\". He wrote correct Latin but did not read or write Greek. He knew Latin authors, natural science, history, mathematics and music and had such a \"fluency with imperial law\" that he may have trained in it \"as a preparation for a career in public life\". He became a government official, advancing quickly in rank to become, like his father, Prefect of Rome, the highest civil office in the city, when only thirty-three years old.\nThe monks of the Monastery of St. Andrew, established by Gregory at the ancestral home on the Caelian, had a portrait of him made after his death, which John the Deacon also saw in the 9th century. He reports the picture of a man who was \"rather bald\" and had a \"tawny\" beard like his father's and a face that was intermediate in shape between his mother's and father's. The hair that he had on the sides was long and carefully curled. His nose was \"thin and straight\" and \"slightly aquiline\". \"His forehead was high.\" He had thick, \"subdivided\" lips and a chin \"of a comely prominence\" and \"beautiful hands\".\nIn the modern era, Gregory is often depicted as a man at the border, poised between the Roman and Germanic worlds, between East and West, and above all, perhaps, between the ancient and medieval epochs.\nMonastic years.\nOn his father's death, Gregory converted his family villa into a monastery dedicated to Andrew the Apostle (after his death it was rededicated as San Gregorio Magno al Celio). In his life of contemplation, Gregory concluded that \"in that silence of the heart, while we keep watch within through contemplation, we are as if asleep to all things that are without.\"\nGregory had a deep respect for the monastic life and particularly the vow of poverty. Thus, when it came to light that a monk lying on his death bed had stolen three gold pieces, Gregory, as a remedial punishment, forced the monk to die alone, then threw his body and coins on a manure heap to rot with a condemnation, \"Take your money with you to perdition.\" Gregory believed that punishment of sins can begin, even in this life before death. However, in time, after the monk's death, Gregory had 30 Masses offered for the man to assist his soul before the final judgment. He viewed being a monk as the \"ardent quest for the vision of our Creator.\" His three paternal aunts were nuns renowned for their sanctity. However, after the eldest two, Trasilla and Emiliana, died after seeing a vision of their ancestor Pope Felix III, the youngest soon abandoned the religious life and married the steward of her estate. Gregory's response to this family scandal was that \"many are called but few are chosen.\" Gregory's mother is herself a saint.\nEventually, Pope Pelagius II ordained Gregory a deacon and solicited his help in trying to heal the schism of the Three Chapters in northern Italy. However, this schism was not healed until well after Gregory was gone.\nApocrisiariate (579\u2013585).\nIn 579, Pelagius II chose Gregory as his \"apocrisiarius\" (ambassador to the imperial court in Constantinople), a post Gregory would hold until 586. Gregory was part of the Roman delegation (both lay and clerical) that arrived in Constantinople in 578 to ask the emperor for military aid against the Lombards. With the Byzantine military focused on the East, these entreaties proved unsuccessful; in 584, Pelagius II wrote to Gregory as \"apocrisiarius\", detailing the hardships that Rome was experiencing under the Lombards and asking him to ask Emperor Maurice to send a relief force. Maurice, however, had long ago determined to limit his efforts against the Lombards to intrigue and diplomacy, pitting the Franks against them. It soon became obvious to Gregory that the Byzantine emperors were unlikely to send such a force, given their more immediate difficulties with the Persians in the East and the Avars and Slavs to the North.\nControversy with Eutychius.\nAccording to Ekonomou, \"if Gregory's principal task was to plead Rome's cause before the emperor, there seems to have been little left for him to do once imperial policy toward Italy became evident. Papal representatives who pressed their claims with excessive vigor could quickly become a nuisance and find themselves excluded from the imperial presence altogether\". Gregory had already drawn an imperial rebuke for his lengthy canonical writings on the subject of the legitimacy of John III Scholasticus, who had occupied the Patriarchate of Constantinople for twelve years prior to the return of Eutychius (who had been driven out by Justinian). Gregory turned to cultivating connections with the Byzantine elite of the city, where he became extremely popular with the city's upper class, \"especially aristocratic women\". Ekonomou surmises that \"while Gregory may have become spiritual father to a large and important segment of Constantinople's aristocracy, this relationship did not significantly advance the interests of Rome before the emperor\". Although the writings of John the Deacon claim that Gregory \"labored diligently for the relief of Italy\", there is no evidence that his tenure accomplished much towards any of the objectives of Pelagius II.\nIn Constantinople, Gregory took issue with the aged Eutychius of Constantinople, who had recently published a treatise, now lost, on the General Resurrection. Eutychius maintained that the resurrected body \"will be more subtle than air, and no longer palpable\".\nGregory's theological disputes with Patriarch Eutychius would leave a \"bitter taste for the theological speculation of the East\" with Gregory that continued to influence him well into his own papacy. According to Western sources, Gregory's very public debate with Eutychius culminated in an exchange before Tiberius II where Gregory cited a biblical passage in support of the view that Christ was corporeal and palpable after his Resurrection; allegedly as a result of this exchange, Tiberius II ordered Eutychius's writings burned. Ekonomou views this argument, though exaggerated in Western sources, as Gregory's \"one achievement of an otherwise fruitless \"apokrisiariat\"\". Gregory relied on Scripture because he could not read the untranslated Greek authoritative works. Shortly after both Gregory and Eutychius became ill; Gregory recovered, but Eutychius died on 5 April 582, at age 70. On his deathbed Eutychius recanted impalpability and Gregory dropped the matter.\nPapacy.\nGregory left Constantinople for Rome in 585, returning to his monastery on the Caelian Hill. Gregory was elected by acclamation to succeed Pelagius II in 590, when the latter died of the plague spreading through the city. Gregory was approved by an Imperial \"iussio\" from Constantinople the following September (as was the norm during the Byzantine Papacy).\nGregory was more inclined to remain retired into the monastic lifestyle of contemplation. In texts of all genres, especially those produced in his first year as pope, Gregory bemoaned the burden of office and mourned the loss of the undisturbed life of prayer he had once enjoyed as a monk.\nWhen he became pope in 590, among his first acts was writing a series of letters disavowing any ambition to the throne of Peter and praising the contemplative life of the monks. At that time, for various reasons, the Holy See had not exerted effective leadership in the West since the pontificate of Gelasius I. The episcopacy in Gaul was drawn from the great territorial families, and identified with them: the parochial horizon of Gregory's contemporary, Gregory of Tours, may be considered typical; in Visigothic Spain the bishops had little contact with Rome; in Italy the territories which had \"de facto\" fallen under the administration of the papacy were beset by the violent Lombard dukes and the rivalry of the Byzantines in the Exarchate of Ravenna and in the south.\nPope Gregory had strong convictions on missions: \"Almighty God places good men in authority that He may impart through them the gifts of His mercy to their subjects. And this we find to be the case with the British over whom you have been appointed to rule, that through the blessings bestowed on you the blessings of heaven might be bestowed on your people also.\" He is credited with re-energizing the Church's missionary work among the non-Christian peoples of northern Europe. He is most famous for sending a mission, often called the Gregorian mission, under Augustine of Canterbury, prior of Saint Andrew's, where he had possibly succeeded Gregory, to evangelize the pagan Anglo-Saxons of Britain. It seems that the pope had never forgotten the Anglo-Saxon slaves whom he had once seen in the Roman Forum. The mission was successful, and it was from England that missionaries later set out for the Netherlands and Germany. The preaching of non-heretical Christian faith and the elimination of all deviations from it was a key element in Gregory's worldview, and it constituted one of the major continuing policies of his pontificate. Pope Gregory the Great urged his followers on the value of bathing as a bodily need.\nIt is said he was declared a saint immediately after his death by \"popular acclamation\".\nIn his official documents, Gregory was the first to make extensive use of the term \"Servant of the Servants of God\" () as a papal title, thus initiating a practice that was to be followed by most subsequent popes.\nAlms.\nThe Church had a practice from early times of passing on a large portion of the donations it received from its members as alms. Gregory is known for his extensive administrative system of charitable relief of the poor at Rome. The poor were predominantly refugees from the incursions of the Lombards. The philosophy under which he devised this system is that the wealth belonged to the poor and the church was only its steward. He received lavish donations from the wealthy families of Rome, who, following his own example, were eager, by doing so, to expiate their sins. He gave alms equally as lavishly both individually and en masse. He wrote in letters: \"I have frequently charged you\u00a0... to act as my representative\u00a0... to relieve the poor in their distress\" and \"I hold the office of steward to the property of the poor\".\nIn Gregory's time, the Church in Rome received donations of many different kinds: consumables such as food and clothing; investment property: real estate and works of art; and capital goods, or revenue-generating property, such as the Sicilian latifundia, or agricultural estates. The Church already had a system for circulating the consumables to the poor: associated with each of the main city churches was a deacon. He was given a building from which the poor could apply for assistance at any time.\nThe circumstances in which Gregory became pope in 590 were of ruination. The Lombards held the greater part of Italy. Their depredations had brought the economy to a standstill. They camped nearly at the gates of Rome. The city itself was crowded with refugees from all walks of life, who lived in the streets and had few of the necessities of life. The seat of government was far from Rome in Constantinople and appeared unable to undertake the relief of Italy. \nIn 590, Gregory could not wait for Constantinople any longer. He organized the resources of the church into an administration for general relief. In doing so, he evidenced a talent and intuitive understanding of the principles of accounting, which was not to be invented for centuries. The church already had basic accounting documents: every expense was recorded in journals called \"regesta\", \"lists\" of amounts, recipients and circumstances. Revenue was recorded in \"polyptici\", \"books\". Many of these polyptici were ledgers recording the operating expenses of the church and the assets, the \"patrimonia\". A central papal administration, the \"notarii\", under a chief, the \"primicerius notariorum\", kept the ledgers and issued \"brevia patrimonii\", or lists of property for which each \"rector\" was responsible.\nGregory began by aggressively requiring his churchmen to seek out and relieve needy persons and reprimanded them if they did not. In a letter to a subordinate in Sicily he wrote: \"I asked you most of all to take care of the poor. And if you knew of people in poverty, you should have pointed them out\u00a0... I desire that you give the woman, Pateria, forty solidi for the children's shoes and forty bushels of grain\". Soon he was replacing administrators who would not cooperate with those who would and at the same time adding more in a build-up to a great plan that he had in mind. He understood that expenses must be matched by income. To pay for his increased expenses he liquidated the investment property and paid the expenses in cash according to a budget recorded in the polyptici. The churchmen were paid four times a year and also personally given a golden coin for their trouble.\nMoney, however, was no substitute for food in a city that was on the brink of famine. The church now owned between of revenue-generating farmland divided into large sections called . It produced goods of all kinds, which were sold, but Gregory intervened and had the goods shipped to Rome for distribution in the . He gave orders to step up production, set quotas and put an administrative structure in place to carry it out. At the bottom was the who produced the goods. Some were or owned slaves. He turned over part of his produce to a from whom he leased the land. The latter reported to an , who reported to a , who reported to a . Grain, wine, cheese, meat, fish, and oil began to arrive at Rome in large quantities, where it was given away for nothing as alms.\nDistributions to qualified persons were monthly. However, a certain proportion of the population lived in the streets or were too ill or infirm to pick up their monthly food supply. Gregory sent out a small army of charitable persons, mainly monks, every morning with prepared food to them. It is said that he would not dine until the indigent were fed. When he did dine he shared the family table, which he had saved (and which still exists), with 12 indigent guests. To the needy living in wealthy homes he sent meals he had cooked with his own hands as gifts to spare them the indignity of receiving charity. Hearing of the death of an indigent in a back room, he was depressed for days, entertaining for a time the conceit that he had failed in his duty and was a murderer.\nThese and other good deeds and charitable frame of mind completely won the hearts and minds of the Roman people. They now looked to the papacy for government, ignoring the state at Constantinople. The office of urban prefect went without candidates.\nWorks.\nLiturgical reforms.\nJohn the Deacon wrote that Pope Gregory I made a general revision of the liturgy of the Pre-Tridentine Mass, \"removing many things, changing a few, adding some\". In his own letters, Gregory remarks that he moved the \"Pater Noster\" (Our Father) to immediately after the Roman Canon and immediately before the Fraction. This position is still maintained today in the Roman Liturgy. The pre-Gregorian position is evident in the Ambrosian Rite. Gregory added material to the \"Hanc Igitur\" of the Roman Canon and established the nine \"Kyries\" (a vestigial remnant of the litany which was originally at that place) at the beginning of Mass. He forbade deacons to perform any of the musical portions of the Mass other than singing the Gospel.\nSacramentaries directly influenced by Gregorian reforms are referred to as \"Sacrementaria Gregoriana\". Roman and other Western liturgies since this era have a number of prayers that change to reflect the feast or liturgical season; these variations are visible in the collects and prefaces as well as in the Roman Canon itself.\nDivine Liturgy of the Presanctified Gifts.\nIn the Eastern Orthodox Church and Eastern Catholic Churches, Gregory is credited as the primary influence in constructing the more penitential Divine Liturgy of the Presanctified Gifts, a fully separate form of the Divine Liturgy in the Byzantine Rite adapted to the needs of the season of Great Lent. Its Roman Rite equivalent is the Mass of the Presanctified used only on Good Friday. The Syriac Liturgy of the Presanctified Gifts continues to be used in the Malankara Rite, a variant of the West Syrian Rite historically practiced in the Malankara Church of India, and now practiced by the several churches that descended from it and at some occasions in the Assyrian Church of the East.\nGregorian chant.\nThe mainstream form of Western plainchant, standardized in the late 9th century, was attributed to Pope Gregory I and so took the name of Gregorian chant. The earliest such attribution is in John the Deacon's 873 biography of Gregory, almost three centuries after the pope's death, and the chant that bears his name \"is the result of the fusion of Roman and Frankish elements which took place in the Franco-German empire under Pepin, Charlemagne and their successors\".\nWritings.\nGregory is commonly credited with founding the medieval papacy and so many attribute the beginning of medieval spirituality to him.\nGregory is the only pope between the fifth and the eleventh centuries whose correspondence and writings have survived enough to form a comprehensive corpus. Some of his writings are:\nGregory wrote over 850 letters in the last 13 years of his life (590\u2013604) that give us an accurate picture of his work. A truly autobiographical presentation is nearly impossible for Gregory. The development of his mind and personality remains speculative.\nOpinions of the writings of Gregory vary. \"His character strikes us as an ambiguous and enigmatic one\", historian Norman Cantor observed. \"On the one hand he was an able and determined administrator, a skilled and clever diplomat, a leader of the greatest sophistication and vision; but on the other hand, he appears in his writings as a superstitious and credulous monk, hostile to learning, crudely limited as a theologian, and excessively devoted to saints, miracles, and relics\".\nIdentification of three figures in the Gospels.\nGregory was among those who identified Mary Magdalene with Mary of Bethany, whom John 12:1-8 recounts as having anointed Jesus with precious ointment, an event that some interpret as being the same as the anointing of Jesus performed by a woman that Luke (alone among the synoptic Gospels) recounts as a sinner. Preaching on the passage in the Gospel of Luke, Gregory remarked: \"This woman, whom Luke calls a sinner and John calls Mary, I think is the Mary from whom Mark reports that seven demons were cast out.\" Within the general populace they are still believed to refer to the same person.\nIconography.\nIn art, Gregory is usually shown in full pontifical robes with the tiara and double cross, despite his actual habit of dress. Earlier depictions are more likely to show a monastic tonsure and plainer dress. Orthodox icons traditionally show St. Gregory vested as a bishop holding a Gospel Book and blessing with his right hand. It is recorded that he permitted his depiction with a square halo, then used for the living. A dove is his attribute, from the well-known story attributed to his friend Peter the Deacon, who tells that when the pope was dictating his homilies on Ezechiel a curtain was drawn between his secretary and himself. As, however, the pope remained silent for long periods at a time, the servant made a hole in the curtain and, looking through, beheld a dove seated upon Gregory's head with its beak between his lips. When the dove withdrew its beak, the pope spoke and the secretary took down his words; but when he became silent, the servant again applied his eye to the hole and saw the dove replaced its beak between his lips.\nRibera's oil painting of \"Saint Gregory the Great\" (c.\u20091614) is from the Giustiniani collection. The painting is conserved in the Galleria Nazionale d'Arte Antica, Rome. The face of Gregory is a caricature of the features described by John the Deacon: total baldness, outthrust chin, beak-like nose, whereas John had described partial baldness, a mildly protruding chin, slightly aquiline nose and strikingly good looks. In this picture also Gregory has his monastic back on the world, which the real Gregory, despite his reclusive intent, was seldom allowed to have.\nThis scene is shown as a version of the traditional Evangelist portrait (where the Evangelists' symbols are also sometimes shown dictating) from the tenth century onwards. An early example is the dedication miniature from an eleventh-century manuscript of Gregory's \"Moralia in Job\". The miniature shows the scribe, Bebo of Seeon Abbey, presenting the manuscript to the Holy Roman Emperor, Henry II. In the upper left the author is seen writing the text under divine inspiration. Usually the dove is shown whispering in Gregory's ear for a clearer composition.\nThe late medieval subject of the Mass of St. Gregory shows a version of a 7th-century story that was elaborated in later hagiography. Gregory is shown saying Mass when Christ as the Man of Sorrows appears on the altar. The subject was most common in the 15th and 16th centuries, and reflected growing emphasis on the Real Presence, and after the Protestant Reformation was an assertion of the doctrine against Protestant theology.\nMemorials.\nRelics.\nThe relics of Saint Gregory are enshrined in St. Peter's Basilica in Rome.\nLives.\nIn Britain, appreciation for Gregory remained strong even after his death, with him being called \"Gregorius noster\" (\"our Gregory\") by the British. It was in Britain, at a monastery in Whitby, that the first full-length life of Gregory was written, c.\u2009713, by a monk or, possibly, a nun. Appreciation of Gregory in Rome and Italy itself, however, did not come until later. The first \"vita\" of Gregory written in Italy was not produced until Johannes Hymonides (aka John the Deacon) in the 9th century.\nMonuments.\nThe namesake church of San Gregorio al Celio (largely rebuilt from the original edifices during the 17th and 18th centuries) remembers his work. One of the three oratories annexed, the oratory of Saint Silvia, is said to lie over the tomb of Gregory's mother.\nIn England, Gregory (along with Augustine of Canterbury) is revered as the apostle of the land and the source of the nation's conversion.\nThrone.\nAn ancient marble chair, which is believed to be the chair of Pope Gregory the Great, is kept in the church San Gregorio Magno al Celio in Rome.\nMusic.\nItalian composer Ottorino Respighi composed a piece named \"St. Gregory the Great\" \"(San Gregorio Magno)\" that features as the fourth and final part of his \"Church Windows\" (\"Vetrate di Chiesa\") works, written in 1925.\nFeast day.\nThe current General Roman Calendar, revised in 1969 as instructed by the Second Vatican Council, celebrates Saint Gregory the Great on 3 September. Before that, it assigned his feast day to 12 March, the day of his death in 604. Following the imposition of Pope John XXIII's Code of Rubrics in 1961, celebration of Saint Gregory's feast day was made practically impossible, as John XXIII's reforms forbade the full observance of most feasts during Lent, during which 12 March invariably falls. For this reason, Saint Gregory's feast day was moved to 3 September, the day of his episcopal consecration in 590, as part of the liturgical reforms of Pope Paul VI.\nThe Eastern Orthodox Church and those Eastern Catholic Churches which follow the Byzantine Rite continue to commemorate Saint Gregory on 12 March which is during Great Lent, the only time when the Divine Liturgy of the Presanctified Gifts, which names Saint Gregory as its author, is used.\nOther churches also honour Gregory the Great:\nA traditional procession is held in \u017bejtun, Malta, in honour of Saint Gregory (San Girgor) on Easter Wednesday, which most often falls in April, the range of possible dates being 25 March to 28 April.\nThe feast day of Saint Gregory also serves as a commemorative day for the former pupils of Downside School, called Old Gregorians. Traditionally, OG ties are worn by all of the society's members on this day.\nWritten works.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nModern editions.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nTranslations.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "36769", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=36769", "title": "Anita Harding", "text": "Irish-British neurologist\nAnita Elizabeth Harding (17 September 1952 \u2013 11 September 1995) was an Irish-British neurologist, and Professor of Clinical Neurology at the Institute of Neurology of the University of London. She is known for the discovery with Ian Holt and John Morgan-Hughes of the \"first identification of a mitochondrial DNA mutation in human disease and the concept of tissue heteroplasmy of mutant mitochondrial DNA\", published in \"Nature\" in 1986. In 1985 she established the first neurogenetics research group in the United Kingdom at the UCL Institute of Neurology.\nBiography.\nBorn in Ireland, Harding was educated at the King Edward VI High School for Girls and the Royal Free Hospital Medical School, where she qualified in 1975. She married neurology professor P.K. Thomas two years later, and trained as a neurologist. She pursued further clinical training at Hammersmith Hospital and the National Hospital for Neurology and Neurosurgery, and worked with laboratories in Cardiff and the United States to learn the burgeoning field of neurogenetics. In 1985 she established the first neurogenetics research group in the United Kingdom at the UCL Institute of Neurology (UCLIN) in Queen Square, London while still a lecturer at that institution. In 1986 she was a senior lecturer at the UCLIN; a position she held for nine years.\nIn 1988 Harding played an instrumental role in the establishment of the European Neurological Society. She died of colorectal cancer, 6 days before her 43rd birthday and shortly before she was to take up the chair in Clinical Neurology at the UCLIN. A person with great charm and wit, she referred to herself as the \"wobbly doctor\". On learning of her terminal condition, she is reported to have said \"[A]t least I won't have to buy Windows 95\".\nIn 1996, she was posthumously awarded the ABN Medal by the Association of British Neurologists. In 2019, the journal \"Nature\" named their custom typeface in her honor.\nWork.\nHarding made several significant contributions in the field of inherited neurologic disorders. Her major achievements were:\nShe also worked extensively on the population genetics of disorders with ethnic distribution. She published over 200 articles, and edited 3 books. Together with Dr. Mary Davis, Anita Harding established one of the biggest service labs for molecular analysis of neurogenetic disorders in the UK.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36770", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=36770", "title": "Tony Buzan", "text": "English author and educational consultant Tony Buzan (1942\u20132019)\nAnthony Peter \"Tony\" Buzan (; 2 June 1942 \u2013 13 April 2019) was an English author and educational consultant.\nBuzan popularised the idea of mental literacy, radiant thinking, and a technique called mind mapping, inspired by techniques used by Leonardo da Vinci, Albert Einstein, and Joseph D. Novak's \"concept mapping\" techniques. \nEarly life.\nBuzan was born in Palmers Green, Enfield, Middlesex, and was an alumnus of Kitsilano Secondary School in Vancouver. His brother is the academic Barry Buzan. Buzan completed his undergraduate studies in psychology, English, mathematics and science at the University of British Columbia, and was a charter student at Simon Fraser University in 1965\u201366 where he spent a year as a graduate student and the inaugural president of the Simon Fraser Student Society. During his time at SFU, Buzan became very involved in Mensa, going on to become editor of the \"International Journal of Mensa\".\nCareer.\nHe was a promoter of mnemonic systems and mind mapping techniques. He launched his own software programme to support mind mapping called iMindMap in December 2006 with Welsh entrepreneur, Chris Griffiths. The Buzan Organisation holds trademarks on the phrase \"Mind Maps\" in the context of self-improvement educational courses in the UK, the USA and Germany.\nFollowing his 1970s series \"Use Your Head\" for the BBC, many of his ideas were set down in a series of five books: \"Use Your Memory\", \"Master Your Memory\", \"Use Your Head\", \"The Speed Reading Book\" and \"The Mind Map Book\". He was author or co-author of more than 80 books altogether. His five BBC books had, by 2003, sold over 3 million copies.\nAs a popular psychology author, Tony Buzan wrote on subjects relating to the brain, \"genius quotient (GQ)\", spiritual intelligence, memory, creativity and speed reading. He was the founder and President of the Brain Foundation (not to be confused with various medical-related bodies with the same name) and also the Brain Trust Charity, the World Memory Championships and the World Championships of the Brain. He was a co-founder of London's Mind Body Spirit Festival as well as the Mind Sports Olympiad, and World Brain Day.\nHe died aged 76 at John Radcliffe Hospital, Oxford of a heart attack.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36771", "revid": "74131", "url": "https://en.wikipedia.org/wiki?curid=36771", "title": "Battle of the Chesapeake", "text": "1781 naval battle of the American Revolutionary War\nThe Battle of the Chesapeake, also known as the Battle of the Virginia Capes or simply the Battle of the Capes, was a crucial naval battle in the American Revolutionary War that took place near the mouth of the Chesapeake Bay on 5 September 1781. The combatants were a British fleet led by Rear Admiral Sir Thomas Graves and a French fleet led by Rear Admiral Fran\u00e7ois Joseph Paul, the Comte de Grasse. The battle was strategically decisive, in that it prevented the Royal Navy from reinforcing or evacuating the besieged forces of Lieutenant General Lord Cornwallis at Yorktown, Virginia. The French were able to achieve control of the sea lanes against the British and provided the Franco-American army with siege artillery and French reinforcements. These proved decisive in the Siege of Yorktown, effectively securing independence for the Thirteen Colonies.\nAdmiral de Grasse had the option to attack British forces in either New York or Virginia; he opted for Virginia, arriving at the Chesapeake at the end of August. Admiral Graves learned that de Grasse had sailed from the West Indies for North America and that French Admiral de Barras had also sailed from Newport, Rhode Island. He concluded that they were going to join forces at the Chesapeake. He sailed south from Sandy Hook, New Jersey, outside New York Harbor, with 19 ships of the line and arrived at the mouth of the Chesapeake early on 5 September to see de Grasse's fleet already at anchor in the bay. De Grasse hastily prepared most of his fleet for battle\u201424 ships of the line\u2014and sailed out to meet him. The two-hour engagement took place after hours of maneuvering. The lines of the two fleets did not completely meet; only the forward and center sections fully engaged. The battle was consequently fairly evenly matched, although the British suffered more casualties and ship damage, and it broke off when the sun set. The British tactics have been a subject of debate ever since.\nThe two fleets sailed within view of each other for several days, but de Grasse preferred to lure the British away from the bay where de Barras was expected to arrive carrying vital siege equipment. He broke away from the British on 13 September and returned to the Chesapeake, where de Barras had since arrived. Graves returned to New York to organize a larger relief effort; this did not sail until 19 October, two days after Cornwallis surrendered.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[The] Battle of the Chesapeake was a tactical victory for the French by no clearcut margin, but it was a strategic victory for the French and Americans that sealed the principal outcome of the war.\u2014\u200a\nBackground.\nDuring the early months of 1781, both pro-British and rebel separatist forces began concentrating in Virginia, a state that had previously not had action other than naval raids. The British forces were led at first by the turncoat Benedict Arnold, and then by William Phillips before General Charles, Earl Cornwallis, arrived in late May with his southern army to take command.\nIn June, Cornwallis marched to Williamsburg, where he received a confusing series of orders from General Sir Henry Clinton that culminated in a directive to establish a fortified deep-water port (which would allow resupply by sea). In response to these orders, Cornwallis moved to Yorktown in late July, where his army began building fortifications. The presence of these British troops, coupled with General Clinton's desire for a port there, made control of the Chesapeake Bay an essential naval objective for both sides.\nOn 21 May, Generals George Washington and Rochambeau, respectively the commanders of the Continental Army and the Exp\u00e9dition Particuli\u00e8re, met at the Vernon House in Newport, Rhode Island to discuss potential operations against the British and Loyalists. They considered either an assault or siege on the principal British base at New York City, or operations against the British forces in Virginia. Since either of these options would require the assistance of the French fleet, then in the West Indies, a ship was dispatched to meet with French Lieutenant g\u00e9n\u00e9ral de Grasse who was expected at Cap-Fran\u00e7ais (now known as Cap-Ha\u00eftien, Haiti), outlining the possibilities and requesting his assistance. Rochambeau, in a private note to de Grasse, indicated that his preference was for an operation against Virginia. The two generals then moved their forces to White Plains, New York, to study New York's defenses and await news from de Grasse.\nArrival of the fleets.\nDe Grasse arrived at Cap-Fran\u00e7ais on 15 August. He immediately dispatched his response to Rochambeau's note, which was that he would make for the Chesapeake. Taking on 3,200 troops, De Grasse sailed from Cap-Fran\u00e7ais with his entire fleet, 28 ships of the line. Sailing outside the normal shipping lanes to avoid notice, he arrived at the mouth of the Chesapeake Bay on 30 August, and disembarked the troops to assist in the land blockade of Cornwallis. Two British frigates that were supposed to be on patrol outside the bay were trapped inside the bay by De Grasse's arrival; this prevented the British in New York from learning the full strength of de Grasse's fleet until it was too late.\nBritish Admiral George Brydges Rodney, who had been tracking De Grasse around the West Indies, was alerted to the latter's departure, but was uncertain of the French admiral's destination. Believing that de Grasse would return a portion of his fleet to Europe, Rodney detached Rear Admiral Sir Samuel Hood with 14 ships of the line and orders to find de Grasse's destination in North America. Rodney, who was ill, sailed for Europe with the rest of his fleet in order to recover, refit his fleet, and to avoid the Atlantic hurricane season.\nSailing more directly than de Grasse, Hood's fleet arrived off the entrance to the Chesapeake on 25 August. Finding no French ships there, he then sailed for New York. Meanwhile, his colleague and commander of the New York fleet, Rear Admiral Sir Thomas Graves, had spent several weeks trying to intercept a convoy organized by John Laurens to bring much-needed supplies and hard currency from France to Boston. When Hood arrived at New York, he found that Graves was in port (having failed to intercept the convoy), but had only five ships of the line that were ready for battle.\nDe Grasse had notified his counterpart in Newport, Barras, of his intentions and his planned arrival date. Barras sailed from Newport on 27 August with 8 ships of the line, 4 frigates, and 18 transports carrying French armaments and siege equipment. He deliberately sailed via a circuitous route in order to minimize the possibility of a battle with the British, should they sail from New York in pursuit. Washington and Rochambeau, in the meantime, had crossed the Hudson on 24 August, leaving some troops behind as a ruse to delay any potential move on the part of General Clinton to mobilize assistance for Cornwallis.\nNews of Barras' departure led the British to realize that the Chesapeake was the probable target of the French fleets. By 31 August, Graves had moved his five ships of the line out of New York Harbor to meet with Hood's force. Taking command of the combined fleet, now 19 ships, Graves sailed south, and arrived at the mouth of the Chesapeake on 5 September. His progress was slow; the poor condition of some of the West Indies ships (contrary to claims by Admiral Hood that his fleet was fit for a month of service) necessitated repairs en route. Graves was also concerned about some ships in his own fleet; \"Europe\" in particular had difficulty manoeuvring.\nBattle lines form.\nFrench and British patrol frigates each spotted the other's fleet around 9:30 am; both at first underestimated the size of the other fleet, leading each commander to believe the other fleet was the smaller fleet of Admiral de Barras. When the true size of the fleets became apparent, Graves assumed that de Grasse and Barras had already joined forces, and prepared for battle; he directed his line toward the bay's mouth, assisted by winds from the north-northeast.\nDe Grasse had detached a few of his ships to blockade the York and James Rivers farther up the bay, and many of the ships at anchor were missing officers, men, and boats when the British fleet was sighted. He faced the difficult proposition of organizing a line of battle while sailing against an incoming tide, with winds and land features that would require him to do so on a tack opposite that of the British fleet. At 11:30 am, 24 ships of the French fleet cut their anchor lines and began sailing out of the bay with the noon tide, leaving behind the shore contingents and ships' boats. Some ships were so seriously undermanned, missing as many as 200 men, that not all of their guns could be manned. De Grasse had ordered the ships to form into a line as they exited the bay, in order of speed and without regard to its normal sailing order. Admiral Louis de Bougainville's \"Auguste\" was one of the first ships out. With a squadron of three other ships Bougainville ended up well ahead of the rest of the French line; by 3:45 pm the gap was large enough that the British could have cut his squadron off from the rest of the French fleet.\nBy 1:00 pm, the two fleets were roughly facing each other, but sailing on opposite tacks. In order to engage, and to avoid some shoals (known as the Middle Ground) near the mouth of the bay, Graves around 2:00 pm ordered his whole fleet to wear, a manoeuvre that reversed his line of battle, but enabled it to line up with the French fleet as its ships exited the bay. This placed the squadron of Hood, his most aggressive commander, at the rear of the line, and that of Admiral Francis Samuel Drake in the vanguard.\nAt this point, both fleets were sailing generally east, away from the bay, with winds from the north-northeast. The two lines were approaching at an angle so that the leading ships of the vans of both lines were within range of each other, while the ships at the rear were too far apart to engage. The French had a firing advantage, since the wind conditions meant they could open their lower gun ports, while the British had to leave theirs closed to avoid water washing onto the lower decks. The French fleet, which was in a better state of repair than the British fleet, outnumbered the British in the number of ships and total guns, and had heavier guns capable of throwing more weight. In the British fleet, and , two ships of the West Indies squadron that were among the most heavily engaged, were in quite poor condition. Graves at this point did not press the potential advantage of the separated French van; as the French centre and rear closed the distance with the British line, they also closed the distance with their own van. One British observer wrote, \"To the astonishment of the whole fleet, the French center were permitted without molestation to bear down to support their van.\"\nThe need for the two lines to actually reach parallel lines so they might fully engage led Graves to give conflicting signals. Critically, these were interpreted\nby Admiral Hood, directing the rear squadron, in a way that was contrary to Graves' intentions. None of the options for closing the angle between the lines presented a favourable option to the British commander: any manoeuvre to bring ships closer would limit their firing ability to their bow guns, and potentially expose their decks to raking or enfilading fire from the enemy ships. Graves hoisted two signals: one for \"line ahead\", under which the ships would slowly close the gap and then straighten the line when parallel to the enemy, and one for \"close action\", which normally indicated that ships should turn to directly approach the enemy line, turning when the appropriate distance was reached. This combination of signals resulted in the piecemeal arrival of his ships into the range of battle. Hood interpreted the instruction to maintain line of battle to take precedence over the signal for close action, and as a consequence his squadron did not close rapidly and never became significantly engaged in the action.\nBattle.\nIt was about 4:00 pm, over 6 hours since the two fleets had first sighted each other, when the British\u2014who had the weather gage, and therefore the initiative\u2014opened their attack. The battle began with opening fire against the \"Marseillois\", its counterpart near the head of the line. The action very quickly became general, with the van and center of each line fully engaged. The French, in a practice they were known for, tended to aim at British masts and rigging, with the intent of crippling their opponent's mobility. The effects of this tactic were apparent in the engagement: and HMS \"Intrepid\", at the head of the British line, became virtually impossible to manage, and eventually fell out of the line. The rest of Admiral Drake's squadron also suffered heavy damage, but the casualties were not as severe as those taken on the first two ships. The angle of approach of the British line also played a role in the damage they sustained; ships in their van were exposed to raking fire when only their bow guns could be brought to bear on the French.\nThe French van also took a beating, although it was less severe. Captain de Boades of the \"R\u00e9fl\u00e9chi\" was killed in the opening broadside of Admiral Drake's \"Princessa\", and the four ships of the French van were, according to a French observer, \"engaged with seven or eight vessels at close quarters.\" The \"Diad\u00e8me\", according to a French officer \"was utterly unable to keep up the battle, having only four thirty-six-pounders and nine eighteen-pounders fit for use\" and was badly shot up; she was rescued by the timely intervention of the \"Saint-Esprit\".\nThe \"Princessa\" and Bougainville's \"Auguste\" at one point were close enough that the French admiral considered a boarding action; Drake managed to pull away, but this gave Bougainville the chance to target the \"Terrible\". Her foremast, already in bad shape before the battle, was struck by several French cannonballs, and her pumps, already overtaxed in an attempt to keep her afloat, were badly damaged by shots \"between wind and water\".\nAround 5:00 pm the wind began to shift, to British disadvantage. De Grasse gave signals for the van to move further ahead so that more of the French fleet might engage, but Bougainville, fully engaged with the British van at musket range, did not want to risk \"severe handling had the French presented the stern.\" When he did finally begin pulling away, British leaders interpreted it as a retreat: \"the French van suffered most, because it was obliged to bear away.\" Rather than follow, the British hung back, continuing to fire at long range; this prompted one French officer to write that the British \"only engaged from far off and simply in order to be able to say that they had fought.\" Sunset brought an end to the firefight, with both fleets continuing on a roughly southeast tack, away from the bay.\nThe center of both lines was engaged, but the level of damage and casualties suffered was noticeably less. Ships in the rear squadrons were almost entirely uninvolved; Admiral Hood reported that three of his ships fired a few shots. The ongoing conflicting signals left by Graves, and discrepancies between his and Hood's records of what signals had been given and when, led to immediate recriminations, written debate, and an eventual formal inquiry.\nStandoff.\nThat evening, Graves did a damage assessment. He noted that \"the French had not the appearance of near so much damage as we had sustained\", and that five of his fleet were either leaking or virtually crippled in their mobility. De Grasse wrote that \"we perceived by the sailing of the English that they had suffered greatly.\" Nonetheless, Graves maintained a windward position through the night, so that he would have the choice of battle in the morning. Ongoing repairs made it clear to Graves that he would be unable to attack the next day. On the night of 6 September he held council with Hood and Drake. During this meeting Hood and Graves supposedly exchanged words concerning the conflicting signals, and Hood proposed turning the fleet around to make for the Chesapeake. Graves rejected the plan, and the fleets continued to drift eastward, away from Cornwallis. On 8 and 9 September the French fleet at times gained the advantage of the wind, and briefly threatened the British with renewed action. French scouts spied Barras' fleet on 9 September, and de Grasse turned his fleet back toward the Chesapeake Bay that night. Arriving on 12 September, he found that Barras had arrived two days earlier. Graves ordered the \"Terrible\" to be scuttled on 11 September due to her leaky condition, and was notified on 13 September that the French fleet was back in the Chesapeake; he still did not learn that de Grasse's line had not included the fleet of Barras, because the frigate captain making the report had not counted the ships. In a council held that day, the British admirals decided against attacking the French, due to \"the truly lamentable state we have brought ourself.\" Graves then turned his battered fleet toward New York, arriving off Sandy Hook on 20 September.\nAftermath.\nThe British fleet's arrival in New York set off a flurry of panic amongst the Loyalist population. The news of the defeat was also not received well in London. King George III wrote (well before learning of Cornwallis's surrender) that \"after the knowledge of the defeat of our fleet [...] I nearly think the empire ruined.\"\nThe French success left them firmly in control of the Chesapeake Bay, completing the encirclement of Cornwallis. In addition to capturing a number of smaller British vessels, de Grasse and Barras assigned their smaller vessels to assist in the transport of Washington's and Rochambeau's forces from Head of Elk to Yorktown.\nIt was not until 23 September that Graves and Clinton learned that the French fleet in the Chesapeake numbered 36 ships. This news came from a dispatch sneaked out by Cornwallis on 17 September, accompanied by a plea for help: \"If you cannot relieve me very soon, you must be prepared to hear the worst.\" After effecting repairs in New York, Admiral Graves sailed from New York on 19 October with 25 ships of the line and transports carrying 7,000 troops to relieve Cornwallis. It was two days after Cornwallis surrendered at Yorktown. General Washington acknowledged to de Grasse the importance of his role in the victory: \"You will have observed that, whatever efforts are made by the land armies, the navy must have the casting vote in the present contest.\" The eventual surrender of Cornwallis led to peace two years later and British recognition of a new, independent United States of America.\nAdmiral de Grasse returned with his fleet to the West Indies. In a major engagement that ended Franco-Spanish plans for the capture of Jamaica in 1782, he was defeated and taken prisoner by Rodney in the Battle of the Saintes. His flagship \"Ville de Paris\" was lost at sea in a storm while being conducted back to England as part of a fleet commanded by Admiral Graves. Graves, despite the controversy over his conduct in this battle, continued to serve, rising to full admiral and receiving an Irish peerage.\nAnalysis.\nMany aspects of the battle have been the subject of both contemporary and historical debate, beginning right after the battle. On 6 September, Admiral Graves issued a memorandum justifying his use of the conflicting signals, indicating that \"[when] the signal for the line of battle ahead is out at the same time with the signal for battle, it is not to be understood that the latter signal shall be rendered ineffectual by a too strict adherence to the former.\" Hood, in commentary written on the reverse of his copy, observed that this eliminated any possibility of engaging an enemy who was disordered, since it would require the British line to also be disordered. Instead, he maintained, \"the British fleet should be as compact as possible, in order to take the critical moment of an advantage opening ...\" Others criticise Hood because he \"did not wholeheartedly aid his chief\", and that a lesser officer \"would have been court-martialled for not doing his \"utmost\" to engage the enemy.\"\nOne contemporary writer critical of the scuttling of the \"Terrible\" wrote that \"she made no more water than she did before [the battle]\", and, more acidly, \"If an able officer had been at the head of the fleet, the \"Terrible\" would not have been destroyed.\" Admiral Rodney was critical of Graves' tactics, writing, \"by contracting his own line he might have brought his nineteen against the enemy's fourteen or fifteen, [...] disabled them before they could have received succor, [... and] gained a complete victory.\" Defending his own behaviour in not sending his full fleet to North America, he also wrote that \"[i]f the admiral in America had met Sir Samuel Hood near the Chesapeake\", that Cornwallis's surrender might have been prevented.\nUnited States Navy historian Frank Chadwick believed that de Grasse could have thwarted the British fleet simply by staying put; his fleet's size would have been sufficient to impede any attempt by Graves to force a passage through his position. Historian Harold Larrabee points out that this would have exposed Clinton in New York to blockade by the French if Graves had successfully entered the bay; if Graves did not do so, Barras (carrying the siege equipment) would have been outnumbered by Graves if de Grasse did not sail out in support.\nAccording to scientist/historian Eric Jay Dolin, the dreaded hurricane season of 1780 in the Caribbean (a year earlier) may have also played a crucial role in the outcome of the 1781 naval battle. The Great Hurricane of 1780 in October was perhaps the deadliest Atlantic hurricane on record. An estimated 22,000 people died throughout the Lesser Antilles with the loss of countless ships from many nations. The Royal Navy's loss of 15 warships with 9 severely damaged crucially affected the balance of the American Revolutionary War, especially during Battle of Chesapeake Bay. An outnumbered British Navy losing to the French proved decisive in Washington's Siege of Yorktown, forcing Cornwallis to surrender and effectively securing independence for the United States of America.\nMemorial.\nAt the Cape Henry Memorial located at Joint Expeditionary Base Fort Story in Virginia Beach, Virginia, there is a monument commemorating the contribution of de Grasse and his sailors to the cause of American independence. The memorial and monument are part of the Colonial National Historical Park and are maintained by the National Park Service.\nOrder of battle.\nFrench line.\nSources consulted (including de Grasse's memoir, and works either dedicated to the battle or containing otherwise detailed orders of battle, like Larrabee (1964) and Morrissey (1997)) do not list per-ship casualties for the French fleet. Larrabee reports the French to have suffered 209 casualties; Bougainville recorded 10 killed and 58 wounded aboard \"Auguste\" alone.\nThe exact order in which the French lined up as they exited the bay is also uncertain. Larrabee notes that many observers wrote up different sequences when the line was finally formed, and that Bougainville recorded several different configurations.\nThe 74-gun \"Glorieux\" and \"Vaillant\", as well the other frigates, remained at the mouth of the various rivers that they were guarding.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "36772", "revid": "2842084", "url": "https://en.wikipedia.org/wiki?curid=36772", "title": "Jimmy Shea", "text": "American skeleton racer (born 1968)\nJames Edmound Shea Jr. (born June 10, 1968) is an American skeleton racer who won the gold medal at the 2002 Winter Olympics in Salt Lake City.\nBiography.\nShea was the third generation of his family to take part in Winter Games. His father competed in Nordic combined and cross-country skiing events in the 1964 Winter Olympics, and his grandfather, Jack Shea, won two gold medals in the 1932 Winter Olympics at Lake Placid in speed skating. His grandfather also recited the athlete's oath at the 1932 opening ceremony.\nHe was born and raised in West Hartford, Connecticut, and moved to Lake Placid, New York, in his late teens. He became the first American to win a World Cup race and a World Championship in the sport, and has won more World Cup victories than any other American. He retired in October 2005.\nAt the FIBT World Championships, Shea earned a complete set of medals in the men's skeleton event with a gold in 1999, a silver in 1997, and a bronze in 2000 (tied for bronze with Austria's Alexander M\u00fcller). His best overall seasonal finish in the men's Skeleton World Cup was third twice (1998\u201399, 2000\u201301).\nShea founded The Shea Family Foundation which raises money to help kids in sports. He currently serves on the Utah Board of Economic Development.\nShea has two daughters and a son and lives in Park City, Utah. In 2021, he was sentenced to two years of court-supervised probation for sexual misconduct.\n2002 Olympics.\nAlong with his father, Jim Shea Sr., he passed the Olympic Torch to Cammi Granato and Picabo Street who then passed it to the 1980 U.S. Men's Hockey Team, who then ignited the Olympic Cauldron.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36773", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=36773", "title": "Rubrik's cube", "text": ""}
{"id": "36774", "revid": "3145267", "url": "https://en.wikipedia.org/wiki?curid=36774", "title": "Burrows-wheeler", "text": ""}
{"id": "36777", "revid": "1152308", "url": "https://en.wikipedia.org/wiki?curid=36777", "title": "Burrows\u2013Wheeler transform", "text": "Algorithm used in data compression\nThe Burrows\u2013Wheeler transform (BWT) rearranges a character string into runs of similar characters, in a manner that can be reversed to recover the original string. Since compression techniques such as move-to-front transform and run-length encoding are more effective when such runs are present, the BWT can be used as a preparatory step to improve the efficiency of a compression algorithm, and is used this way in software such as bzip2. The algorithm can be implemented efficiently using a suffix array thus reaching linear time complexity.\nIt was invented by David Wheeler in 1983, and later published by him and Michael Burrows in 1994. Their paper included a compression algorithm, called the Block-sorting Lossless Data Compression Algorithm or BSLDCA, that compresses data by using the BWT followed by move-to-front coding and Huffman coding or arithmetic coding.\nDescription.\nThe transform is done by constructing a matrix (known as the Burrows-Wheeler Matrix) whose rows are the circular shifts of the input text, sorted in lexicographic order, then taking the final column of that matrix.\nTo allow the transform to be reversed, one additional step is necessary: either the index of the original string in the Burrows-Wheeler Matrix must be returned along with the transformed string (the approach shown in the original paper by Burrows and Wheeler) or a special end-of-text character must be added at the start or end of the input text before the transform is executed.\nExample.\nGiven an input string codice_1 (step 1 in the table below), rotate it \"N\" times (step 2), where codice_2 is the length of the codice_3 string considering also the red codice_4 character representing the start of the string and the red codice_5 character representing the 'EOF' pointer; these rotations, or circular shifts, are then sorted lexicographically (step 3). The output of the encoding phase is the last column codice_6 after step 3, and the index (0-based) codice_7 of the row containing the original string codice_3, in this case codice_9.\nIt is not necessary to use both codice_5 and codice_4, but at least one must be used, else we cannot invert the transform, since all circular permutations of a string have the same Burrows\u2013Wheeler transform.\nPseudocode.\nThe following pseudocode gives a simple (though inefficient) way to calculate the BWT and its inverse. It assumes that the input string codice_12 contains a special character 'EOF' which is the last character and occurs nowhere else in the text.\n function BWT (\"string\" s)\n create a table, where the rows are all possible rotations of s\n sort rows alphabetically\n return (last column of the table)\n function inverseBWT (\"string\" s)\n create empty table\n repeat length(s) times\n // first insert creates first column\n insert s as a column of table before first column of the table\n sort rows of the table alphabetically\n return (row that ends with the 'EOF' character)\nExplanation.\nIf the original string had several substrings that occurred often, then the BWT-transformed string will have several places where a single character is repeated many times in a row, creating more-easily-compressible data. For instance, consider transforming an English text frequently containing the word \"the\":\nFor example:\nSorting the rotations of this text groups rotations starting with \"he \" together, and the last character of such a rotation (which is also the character before the \"he \") will usually be \"t\" (though perhaps occasionally not, such as if the text contained \"ache \"), so the result of the transform will contain a run, or runs, of many consecutive \"t\" characters. Similarly, rotations beginning with \"e \" are grouped together, but \"e \" is often preceded by \"h\", so we see the output above contains a run of five consecutive \"h\" characters.\nThus it can be seen that the success of this transform depends upon one value having a high probability of occurring before a sequence, so that in general it needs fairly long samples (a few kilobytes at least) of appropriate data (such as text).\nThe remarkable thing about the BWT is not that it generates a more easily encoded output\u2014an ordinary sort would do that\u2014but that it does this \"reversibly\", allowing the original document to be re-generated from the last column data.\nThe inverse can be understood this way. Take the final table in the BWT algorithm, and erase all but the last column. Given only this information, you can easily reconstruct the first column. The last column tells you all the characters in the text, so just sort these characters alphabetically to get the first column. Then, the last and first columns (of each row) together give you all \"pairs\" of successive characters in the document, where pairs are taken cyclically so that the last and first character form a pair. Sorting the list of pairs gives the first \"and second\" columns. To obtain the third column, the last column is again prepended to the table, and the rows are sorted lexicographically. Continuing in this manner, you can reconstruct the entire list. Then, the row with the \"end of file\" character at the end is the original text. Reversing the example above is done like this:\nOptimization.\nA number of optimizations can make these algorithms run more efficiently without changing the output. There is no need to represent the table in either the encoder or decoder. In the encoder, each row of the table can be represented by a single pointer into the strings, and the sort performed using the indices. In the decoder, there is also no need to store the table, and the decoded string can be generated one character at a time from left to right. Comparative sorting can even be avoided in favor of linear sorting, with performance proportional to the alphabet size and string length. A \"character\" in the algorithm can be a byte, or a bit, or any other convenient size.\nOne may also make the observation that mathematically, the encoded string can be computed as a simple modification of the suffix array, and suffix arrays can be computed with linear time and memory. The BWT can be defined with regards to the suffix array SA of text T as (1-based indexing):\nformula_1\nThere is no need to have an actual 'EOF' character. Instead, a pointer can be used that remembers where in a string the 'EOF' would be if it existed. In this approach, the output of the BWT must include both the transformed string, and the final value of the pointer. The inverse transform then shrinks it back down to the original size: it is given a string and a pointer, and returns just a string.\nA complete description of the algorithms can be found in Burrows and Wheeler's paper, or in a number of online sources. The algorithms vary somewhat by whether EOF is used, and in which direction the sorting was done. In fact, the original formulation did not use an EOF marker.\nBijective variant.\nSince any rotation of the input string will lead to the same transformed string, the BWT cannot be inverted without adding an EOF marker to the end of the input or doing something equivalent, making it possible to distinguish the input string from all its rotations. Increasing the size of the alphabet (by appending the EOF character) makes later compression steps awkward.\nThere is a bijective version of the transform, by which the transformed string uniquely identifies the original, and the two have the same length and contain exactly the same characters, just in a different order.\nThe bijective transform is computed by factoring the input into a non-increasing sequence of Lyndon words; such a factorization exists and is unique by the Chen\u2013Fox\u2013Lyndon theorem, and may be found in linear time and constant space. The algorithm sorts the rotations of all the words; as in the Burrows\u2013Wheeler transform, this produces a sorted sequence of \"n\" strings. The transformed string is then obtained by picking the final character of each string in this sorted list. The one important caveat here is that strings of different lengths are not ordered in the usual way; the two strings are repeated forever, and the infinite repeats are sorted. For example, \"ORO\" precedes \"OR\" because \"OROORO...\" precedes \"OROROR...\".\nFor example, the text \"^BANANA$\" is transformed into \"ANNBAA^$\" through these steps (the red $ character indicates the EOF pointer) in the original string. The EOF character is unneeded in the bijective transform, so it is dropped during the transform and re-added to its proper place in the file.\nThe string is broken into Lyndon words so the words in the sequence are decreasing using the comparison method above. (Note that we're sorting '^' as succeeding other characters.) \"^BANANA\" becomes (^) (B) (AN) (AN) (A).\nUp until the last step, the process is identical to the inverse Burrows\u2013Wheeler process, but here it will not necessarily give rotations of a single sequence; it instead gives rotations of Lyndon words (which will start to repeat as the process is continued). Here, we can see (repetitions of) four distinct Lyndon words: (A), (AN) (twice), (B), and (^). (NANA... doesn't represent a distinct word, as it is a cycle of ANAN...)\nAt this point, these words are sorted into reverse order: (^), (B), (AN), (AN), (A). These are then concatenated to get\n^BANANA\nThe Burrows\u2013Wheeler transform can indeed be viewed as a special case of this bijective transform; instead of the traditional introduction of a new letter from outside our alphabet to denote the end of the string, we can introduce a new letter that compares as preceding all existing letters that is put at the beginning of the string. The whole string is now a Lyndon word, and running it through the bijective process will therefore result in a transformed result that, when inverted, gives back the Lyndon word, with no need for reassembling at the end.\nFor example, applying the bijective transform gives:\nThe bijective transform includes eight runs of identical\ncharacters. These runs are, in order: codice_13,\ncodice_14,\ncodice_13,\ncodice_16,\ncodice_17,\ncodice_18,\ncodice_17,\nand\ncodice_20.\nIn total, 18 characters are used in these runs.\nDynamic Burrows\u2013Wheeler transform.\nWhen a text is edited, its Burrows\u2013Wheeler transform will change. Salson \"et al.\" propose an algorithm that deduces the Burrows\u2013Wheeler transform of an edited text from that of the original text, doing a limited number of local reorderings in the original Burrows\u2013Wheeler transform, which can be faster than constructing the Burrows\u2013Wheeler transform of the edited text directly.\nSample implementation.\nThis Python implementation sacrifices speed for simplicity: the program is short, but takes more than the linear time that would be desired in a practical implementation. It essentially does what the pseudocode section does.\nUsing the STX/ETX control codes to mark the start and end of the text, and using codice_21 to construct the codice_22th rotation of codice_12, the forward transform takes the last character of each of the sorted rows:\nfrom curses.ascii import STX, ETX\ndef bwt(s: str, start=chr(STX), end=chr(ETX)) -&gt; str:\n r\"\"\"\n Apply Burrows\u2013Wheeler transform to input string.\n \u00bb&gt; bwt('BANANA')\n '\\x03ANNB\\x02AA'\n \u00bb&gt; bwt('BANANA', start='^', end='$')\n 'ANNB^AA$'\n \u00bb&gt; bwt('BANANA', start='%', end='$')\n 'A$NNB%AA'\n assert (\n start not in s and end not in s\n ), \"Input string cannot contain STX and ETX characters\"\n s = f\"{start}{s}{end}\" # Add start and end of text marker\n # Table of rotations of string\n table = sorted(f\"{s[i:]}{s[:i]}\" for i, c in enumerate(s))\n last_column = [row[-1:] for row in table] # Last characters of each row\n return \"\".join(last_column) # Convert list of characters into string\nThe inverse transform repeatedly inserts codice_24 as the left column of the table and sorts the table. After the whole table is built, it returns the row that ends with ETX, minus the STX and ETX.\ndef inverse_bwt(r: str, start=chr(STX), end=chr(ETX)) -&gt; str:\n r\"\"\"\n Apply inverse Burrows\u2013Wheeler transform.\n \u00bb&gt; inverse_bwt('\\x03ANNB\\x02AA')\n 'BANANA'\n \u00bb&gt; inverse_bwt('ANNB^AA$', start='^', end='$')\n 'BANANA'\n \u00bb&gt; inverse_bwt('A$NNB%AA', start='%', end='$')\n 'BANANA'\n str_len = len(r)\n table = [\"\"] * str_len # Make empty table\n for _ in range(str_len):\n table = sorted(rc + tc for rc, tc in zip(r, table)) # Add a column of r\n # Iterate over and check whether last character ends with ETX or not\n s = next((row for row in table if row.endswith(end)), \"\")\n # Retrieve data from array and get rid of start and end markers\n return s.rstrip(end).strip(start)\nFollowing implementation notes from Manzini, it is equivalent to use a simple null character suffix instead. The sorting should be done in colexicographic order (string read right-to-left), i.e. in Python. (The above control codes actually fail to satisfy EOF being the last character; the two codes are actually the \"first\". The rotation holds nevertheless.)\nBWT applications.\nAs a lossless compression algorithm the Burrows\u2013Wheeler transform offers the important quality that its encoding is reversible and hence the original data may be recovered from the resulting compression. The lossless quality of Burrows algorithm has provided for different algorithms with different purposes in mind. To name a few, Burrows\u2013Wheeler transform is used in algorithms for sequence alignment, image compression, data compression, etc. The following is a compilation of some uses given to the Burrows\u2013Wheeler Transform.\nBWT for sequence alignment.\nThe advent of next-generation sequencing (NGS) techniques at the end of the 2000s decade has led to another application of the Burrows\u2013Wheeler transformation. In NGS, DNA is fragmented into small pieces, of which the first few bases are sequenced, yielding several millions of \"reads\", each 30 to 500 base pairs (\"DNA characters\") long. In many experiments, e.g., in ChIP-Seq, the task is now to align these reads to a reference genome, i.e., to the known, nearly complete sequence of the organism in question (which may be up to several billion base pairs long). A number of alignment programs, specialized for this task, were published, which initially relied on hashing (e.g., Eland, SOAP, or Maq). In an effort to reduce the memory requirement for sequence alignment, several alignment programs were developed (Bowtie, BWA, and SOAP2) that use the Burrows\u2013Wheeler transform.\nBWT for image compression.\nThe Burrows\u2013Wheeler transformation has proved to be fundamental for image compression applications. For example, Showed a compression pipeline based on the application of the Burrows\u2013Wheeler transformation followed by inversion, run-length, and arithmetic encoders. The pipeline developed in this case is known as Burrows\u2013Wheeler transform with an inversion encoder (BWIC). The results shown by BWIC are shown to outperform the compression performance of well-known and widely used algorithms like Lossless JPEG and JPEG 2000. BWIC is shown to outperform those in terms of final compression size of radiography medical images on the order of 5.1% and 4.1% respectively. The improvements are achieved by combining BWIC and a pre-BWIC scan of the image in a vertical snake order fashion. More recently, additional works have shown the implementation of the Burrows\u2013Wheeler Transform in conjunction with the known move-to-front transform (MTF) achieve near lossless compression of images. \nBWT for compression of genomic databases.\nCox et al. presented a genomic compression scheme that uses BWT as the algorithm applied during the first stage of compression of several genomic datasets including the human genomic information. Their work proposed that BWT compression could be enhanced by including a second stage compression mechanism called same-as-previous encoding (\"SAP\"), which makes use of the fact that suffixes of two or more prefix letters could be equal. With the compression mechanism BWT-SAP, Cox et al. showed that in the genomic database ERA015743, 135.5\u00a0GB in size, the compression scheme BWT-SAP compresses the ERA015743 dataset by around 94%, to 8.2\u00a0GB.\nBWT for sequence prediction.\nBWT has also been proved to be useful on sequence prediction which is a common area of study in machine learning and natural-language processing. In particular, Ktistakis et al. proposed a sequence prediction scheme called SuBSeq that exploits the lossless compression of data of the Burrows\u2013Wheeler transform. SuBSeq exploits BWT by extracting the FM-index and then performing a series of operations called backwardSearch, forwardSearch, neighbourExpansion, and getConsequents in order to search for predictions given a suffix. The predictions are then classified based on a weight and put into an array from which the element with the highest weight is given as the prediction from the SuBSeq algorithm. SuBSeq has been shown to outperform state of the art algorithms for sequence prediction both in terms of training time and accuracy.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36778", "revid": "17216044", "url": "https://en.wikipedia.org/wiki?curid=36778", "title": "Matthias the Apostle", "text": "Apostle of Jesus (died circa AD 80)\nMatthias (; Koine Greek: , , from Hebrew ; ; died c.\u2009AD 80) was, according to the Acts of the Apostles, chosen by God through the apostles to replace Judas Iscariot following the latter's betrayal of Jesus and his subsequent death. His calling as an apostle is unique, in that he was elected by fellow disciples following Jesus' Ascension into Heaven, though Matthias knew Jesus throughout his earthly ministry.\nBiography.\nThere is no mention of a Matthias among the lists of disciples or followers of Jesus in the three synoptic gospels, but according to Acts, he had been with Jesus from his baptism by John until his Ascension. In the days following, Peter proposed that the assembled disciples, who numbered about 120, nominate two men to replace Judas. They chose Joseph called Barsabbas (whose surname was Justus) and Matthias. Then they prayed, \"Thou, Lord, which knowest the hearts of all [men], shew whether of these two thou hast chosen, That he may take part of this ministry and apostleship, from which Judas by transgression fell, that he might go to his own place.\" Then they cast lots, and the lot fell to Matthias; so he was numbered with the eleven apostles.\nNo further information about Matthias is to be found in the canonical New Testament. Even his name is variable: the Syriac version of Eusebius calls him throughout not Matthias but \"Tolmai\", not to be confused with Bartholomew (which means Son of Tolmai), who was one of the twelve original Apostles; Clement of Alexandria refers once to Zacchaeus in a way which could be read as suggesting that some identified him with Matthias; the \"Clementine Recognitions\" identify him with Barnabas; Adolf Bernhard Christoph Hilgenfeld thinks he is the same as Nathanael in the Gospel of John.\nMinistry and death.\nAll information concerning the ministry and death of Matthias is vague and contradictory. The tradition of the Greeks says that St. Matthias spread Christianity around Cappadocia and on the coasts of the Caspian Sea, residing chiefly near the port Hyssus. \nAccording to Nicephorus (\"Historia eccl.\", 2, 40), Matthias first preached the Gospel in Judaea, then in Aethiopia (by the region of Colchis, now in modern-day Georgia) and was crucified. An extant Coptic \"Acts of Andrew and Matthias\", places his activity similarly in \"the city of the cannibals\" in Aethiopia. A marker placed in the ruins of the Roman fortress at Gonio (Apsaros) in the modern Georgian region of Adjara claims that Matthias is buried at that site.\nThe \"Synopsis of Dorotheus\" contains this tradition: \"Matthias preached the Gospel to barbarians and meat-eaters in the interior of Ethiopia, where the sea harbor of Hyssus is, at the mouth of the river \nPhasis. He died at Sebastopolis, and was buried there, near the Temple of the Sun.\"\nAlternatively, another tradition maintains that Matthias was stoned at Jerusalem by the local populace, and then was beheaded (cf. Tillemont, \"M\u00e9moires pour servir \u00e0 l'histoire ecclesiastique des six premiers si\u00e8cles\", I, 406\u20137). According to Hippolytus of Rome, Matthias died of old age in Jerusalem.\nClement of Alexandria observed (\"Stromateis\" vi.13.):\nNot that they became apostles through being chosen for some distinguished peculiarity of nature, since also Judas was chosen along with them. But they were capable of becoming apostles on being chosen by Him who foresees even ultimate issues. Matthias, accordingly, who was not chosen along with them, on showing himself worthy of becoming an apostle, is substituted for Judas.\nWritings.\nSurviving fragments of the lost Gospel of Matthias attribute it to Matthias, but Early Church Fathers attributed it to heretical writings in the 2nd century.\nVeneration.\nThe feast of Saint Matthias was included in the Roman Calendar in the 11th century and celebrated on the sixth day to the Calends of March (24 February usually, but 25 February in leap years). In the revision of the General Roman Calendar in 1969, his feast was transferred to 14 May, so as not to celebrate it in Lent but instead in Eastertide close to the Solemnity of the Ascension, the event after which the Acts of the Apostles recounts that Matthias was selected to be ranked with the Twelve Apostles.\nThe Eastern Rites of the Eastern Orthodox Church celebrate his feast on 9 August. Yet the Western Rite parishes of the Orthodox Church continues the old Roman Rite of 24 and 25 February in leap years.\nThe Church of England's \"Book of Common Prayer\", as well as other older common prayer books in the Anglican Communion, celebrates Matthias on 24 February. According to the newer \"Common Worship\" liturgy, Matthias is remembered in the Church of England with a Festival on 14 May, although he may be celebrated on 24 February, if desired. In the Episcopal Church as well as some in the Lutheran Church, including the Lutheran Church\u2013Missouri Synod and the Lutheran Church\u2013Canada, his feast remains on 24 February. In \"Evangelical Lutheran Worship\", used by the Evangelical Lutheran Church in America as well as the Evangelical Lutheran Church in Canada, the feast date for Matthias is on 14 May.\nIt is claimed that St Matthias the Apostle's remains were brought to Italy through Empress Helena, mother of Emperor Constantine I (the Great); part of these relics were interred in the Abbey of Santa Giustina, Padua, and the remaining in the Abbey of St. Matthias, Trier, Germany. According to Greek sources, the remains of the apostle are buried in the castle of Gonio-Apsaros, Georgia.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36781", "revid": "836838", "url": "https://en.wikipedia.org/wiki?curid=36781", "title": "GEGL", "text": "Image processing programming library\nThe Generic Graphics Library (GEGL) is a programming library under development for image processing applications. It is mainly developed for GIMP in order to add support for higher bit depth images, and non-destructive editing. It was partially implemented in GIMP 2.6, with more added in 2.8, and is now a central part in 2.10. Many Filters are ready, but also much work in progress. Target is full support of all important filters in roadmap in Version 3.0. It is also used by GNOME's https:// and https://.\nDesign.\nGEGL is modelled after a directed acyclic graph, where each \"node\" represents an image \"operation\" (called \"operators\" or \"ops\"), and each \"edge\" represents an \"image\". Operations can in general take several input images and give several output images, which corresponds to having several incoming edges (images) and several outgoing edges (images) at a given node (operation). The system uses an on-demand model, doing work only as required. This allows features such as having very quick previews while editing, and once the user has finished making changes, GEGL will repeat the same operations in full resolution for the final image in the background.\nOperations.\nAn operation (op) is a node within a GEGL graph responsible for one action; ops can be:\nGEGL also has a notion of meta operations, where one operation can be constructed from other operations (e.g. \"unsharp mask\" is a combination of \"add\", \"multiply\", \"subtract\" and \"gaussian blur\" ops).\nbabl.\nbabl, a support library for GEGL, provides a generic way to deal with color-space conversions;\nbabl operates abstracting the fundamental color operations so that GEGL need not be aware of them. Through babl, GEGL provides an optimized and powerful (optionally with SIMD support) treatment of arbitrary color data; this enables dependent applications to efficiently support a wide range of color spaces (from 8-bit RGB to full floating point CMYK) with minimal extra application code.\nOpenRaster.\nOpenRaster is an XML file format used for saving raster graphics. GEGL's lead developer \u00d8yvind Kol\u00e5s has helped specifying OpenRaster so that it is capable of saving a GEGL graph.\nHistory.\nGEGL was originally conceived as a GIMP core replacement in 2000 by Rhythm &amp; Hues software engineers, finally in 2006 the external API was deemed stable enough and capable of replacing the GIMP core. On 20 December 2007, it was added to the development version of GIMP. Some of GIMP's tools have already been converted to GEGL operations; mostly tools which modify colors, brightness or contrast have been converted. \nVersion 0.2.0 is Part of Gimp 2.8.xy and Series 0.3.xy is Part of 2.9.x and in 2.10.0 Release Candidates. 0.4.0 is first Version for Version 2.10.0 of Gimp. Actual Version 0.4.xy is also base of development Version 2.99.x for stable 3.0 series of Gimp.\n0.5 (or higher like 1.0) will be the line of 3.0 stable series.\nAs of unstable 2.9.x series, all of GIMP's core relies on GEGL, and almost half of filters have been replaced with GEGL operations. Target is 100% of canvas filters in GEGL in 2.10 and later.\nHistorically, the GEGL mascot, a five-legged goat created by George (Ji\u0159\u00ed) Lebl,\nfound life as an easter egg in GNOME desktops.\nOpenCL.\nSome of GEGL's operations are available in OpenCL-based hardware-accelerated version. A 3rd party effort, called GEGL-OpenCL, of converting more operations to OpenCL was started by Stream HPC in 2016. The project was stagnant starting May 2017, but was revived in the summer of 2019.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36782", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=36782", "title": "Benford's law", "text": "Observation that in many real-life datasets, the leading digit is likely to be small\nBenford's law, also known as the Newcomb\u2013Benford law, the law of anomalous numbers, or the first-digit law, is an observation that in many real-life sets of numerical data, the leading digit is likely to be small. In sets that obey the law, the number 1 appears as the leading significant digit about 30% of the time, while 9 appears as the leading significant digit less than 5% of the time. Uniformly distributed digits would each occur about 11.1% of the time. Benford's law also makes predictions about the distribution of second digits, third digits, digit combinations, and so on. \nBenford's law may be derived by assuming the dataset values are uniformly distributed on a logarithmic scale. The graph to the right shows Benford's law for base 10. Although a decimal base is most common, the result generalizes to any integer base greater than 2. Further generalizations published in 1995 included analogous statements for both the \"n\"th leading digit and the joint distribution of the leading \"n\" digits, the latter of which leads to a corollary wherein the significant digits are shown to be a statistically dependent quantity.\nIt has been shown that this result applies to a wide variety of data sets, including electricity bills, street addresses, stock prices, house prices, population numbers, death rates, lengths of rivers, and physical and mathematical constants. Like other general principles about natural data\u2014for example, the fact that many data sets are well approximated by a normal distribution\u2014there are illustrative examples and explanations that cover many of the cases where Benford's law applies, though there are many other cases where Benford's law applies that resist simple explanations. Benford's law tends to be most accurate when values are distributed across multiple orders of magnitude, especially if the process generating the numbers is described by a power law (which is common in nature).\nThe law is named after physicist Frank Benford, who stated it in 1938 in an article titled \"The Law of Anomalous Numbers\", although it had been previously stated by Simon Newcomb in 1881.\nThe law is similar in concept, though not identical in distribution, to Zipf's law.\nDefinition.\nA set of numbers is said to satisfy Benford's law if the leading digit\u00a0d () occurs with probability\n formula_1\nThe leading digits in such a set thus have the following distribution:\nThe quantity &amp;NoBreak;&amp;NoBreak; is proportional to the space between d and on a logarithmic scale. Therefore, this is the distribution expected if the \"logarithms\" of the numbers (but not the numbers themselves) are uniformly and randomly distributed.\nFor example, a number x, constrained to lie between 1 and 10, starts with the digit 1 if , and starts with the digit 9 if . Therefore, x starts with the digit 1 if , or starts with 9 if log\u00a09\u00a0\u2264\u00a0log\u00a0\"x\"\u00a0&lt;\u00a0log\u00a010. The interval [log\u00a01,\u00a0log\u00a02] is much wider than the interval [log\u00a09,\u00a0log\u00a010] (0.30 and 0.05 respectively); therefore if log x is uniformly and randomly distributed, it is much more likely to fall into the wider interval than the narrower interval, i.e. more likely to start with 1 than with 9; the probabilities are proportional to the interval widths, giving the equation above (as well as the generalization to other bases besides decimal).\nBenford's law is sometimes stated in a stronger form, asserting that the fractional part of the logarithm of data is typically close to uniformly distributed between 0 and 1; from this, the main claim about the distribution of first digits can be derived.\nIn other bases.\nAn extension of Benford's law predicts the distribution of first digits in other bases besides decimal; in fact, any base \"b\"\u00a0\u2265\u00a02. The general form is\n formula_2\nFor \"b\" = 2, 1 (the binary and unary) number systems, Benford's law is true but trivial: All binary and unary numbers (except for 0 or the empty set) start with the digit 1. (On the other hand, the generalization of Benford's law to second and later digits is not trivial, even for binary numbers.)\nExamples.\nExamining a list of the heights of the 58 tallest structures in the world by category shows that 1 is by far the most common leading digit, \"irrespective of the unit of measurement\" (see \"scale invariance\" below):\nAnother example is the leading digit of 2\"n\". The sequence of the first 96 leading digits (1, 2, 4, 8, 1, 3, 6, 1, 2, 5, 1, 2, 4, 8, 1, 3, 6, 1,\u00a0... (sequence in the OEIS)) exhibits closer adherence to Benford's law than is expected for random sequences of the same length, because it is derived from a geometric sequence.\nHistory.\nThe discovery of Benford's law goes back to 1881, when the Canadian-American astronomer Simon Newcomb noticed that in logarithm tables the earlier pages (that started with 1) were much more worn than the other pages. Newcomb's published result is the first known instance of this observation and includes a distribution on the second digit as well. Newcomb proposed a law that the probability of a single number \"N\" being the first digit of a number was equal to log(\"N\"\u00a0+\u00a01)\u00a0\u2212\u00a0log(\"N\").\nThe phenomenon was again noted in 1938 by the physicist Frank Benford, who tested it on data from 20 different domains and was credited for it. His data set included the surface areas of 335 rivers, the sizes of 3259 US populations, 104 physical constants, 1800 molecular weights, 5000 entries from a mathematical handbook, 308 numbers contained in an issue of \"Reader's Digest\", the street addresses of the first 342 persons listed in \"American Men of Science\" and 418 death rates. The total number of observations used in the paper was 20,229. This discovery was later named after Benford (making it an example of Stigler's law).\nIn 1995, Ted Hill proved the result about mixed distributions mentioned below.\nExplanations.\nBenford's law tends to apply most accurately to data that span several orders of magnitude. As a rule of thumb, the more orders of magnitude that the data evenly covers, the more accurately Benford's law applies. For instance, one can expect that Benford's law would apply to a list of numbers representing the populations of United Kingdom settlements. But if a \"settlement\" is defined as a village with population between 300 and 999, then Benford's law will not apply.\nConsider the probability distributions shown below, referenced to a log scale. In each case, the total area in red is the relative probability that the first digit is 1, and the total area in blue is the relative probability that the first digit is\u00a08. For the first distribution, the size of the areas of red and blue are approximately proportional to the widths of each red and blue bar. Therefore, the numbers drawn from this distribution will approximately follow Benford's law. On the other hand, for the second distribution, the ratio of the areas of red and blue is very different from the ratio of the widths of each red and blue bar. Rather, the relative areas of red and blue are determined more by the heights of the bars than the widths. Accordingly, the first digits in this distribution do not satisfy Benford's law at all.\nThus, real-world distributions that span several orders of magnitude rather uniformly (e.g., stock-market prices and populations of villages, towns, and cities) are likely to satisfy Benford's law very accurately. On the other hand, a distribution mostly or entirely within one order of magnitude (e.g., IQ scores or heights of human adults) is unlikely to satisfy Benford's law very accurately, if at all. However, the difference between applicable and inapplicable regimes is not a sharp cut-off: as the distribution gets narrower, the deviations from Benford's law increase gradually.\nKrieger\u2013Kafri entropy explanation.\nIn 1970 Wolfgang Krieger proved what is now called the Krieger generator theorem. The Krieger generator theorem might be viewed as a justification for the assumption in the Kafri ball-and-box model that, in a given base formula_3 with a fixed number of digits 0, 1,\u00a0..., \"n\",\u00a0..., formula_4, digit \"n\" is equivalent to a Kafri box containing \"n\" non-interacting balls. Other scientists and statisticians have suggested entropy-related explanations for Benford's law.\nMultiplicative fluctuations.\nMany real-world examples of Benford's law arise from multiplicative fluctuations. For example, if a stock price starts at $100, and then each day it gets multiplied by a randomly chosen factor between 0.99 and 1.01, then over an extended period the probability distribution of its price satisfies Benford's law with higher and higher accuracy.\nThe reason is that the \"logarithm\" of the stock price is undergoing a random walk, so over time its probability distribution will get more and more broad and smooth (see above). (More technically, the central limit theorem says that multiplying more and more random variables will create a log-normal distribution with larger and larger variance, so eventually it covers many orders of magnitude almost uniformly.) To be sure of approximate agreement with Benford's law, the distribution has to be approximately invariant when scaled up by any factor up to 10; a log-normally distributed data set with wide dispersion would have this approximate property.\nUnlike multiplicative fluctuations, \"additive\" fluctuations do not lead to Benford's law: They lead instead to normal probability distributions (again by the central limit theorem), which do not satisfy Benford's law. By contrast, that hypothetical stock price described above can be written as the \"product\" of many random variables (i.e. the price change factor for each day), so is \"likely\" to follow Benford's law quite well.\nMultiple probability distributions.\nAnton Formann provided an alternative explanation by directing attention to the interrelation between the distribution of the significant digits and the distribution of the observed variable. He showed in a simulation study that long-right-tailed distributions of a random variable are compatible with the Newcomb\u2013Benford law, and that for distributions of the ratio of two random variables the fit generally improves. For numbers drawn from certain distributions (IQ scores, human heights) the Benford's law fails to hold because these variates obey a normal distribution, which is known not to satisfy Benford's law, since normal distributions can't span several orders of magnitude and the Significand of their logarithms will not be (even approximately) uniformly distributed. However, if one \"mixes\" numbers from those distributions, for example, by taking numbers from newspaper articles, Benford's law reappears. This can also be proven mathematically: if one repeatedly \"randomly\" chooses a probability distribution (from an uncorrelated set) and then randomly chooses a number according to that distribution, the resulting list of numbers will obey Benford's law. A similar probabilistic explanation for the appearance of Benford's law in everyday-life numbers has been advanced by showing that it arises naturally when one considers mixtures of uniform distributions.\nInvariance.\nIn a list of lengths, the distribution of first digits of numbers in the list may be generally similar regardless of whether all the lengths are expressed in metres, yards, feet, inches, etc. The same applies to monetary units.\nThis is not always the case. For example, the height of adult humans almost always starts with a 1 or 2 when measured in metres and almost always starts with 4, 5, 6, or 7 when measured in feet. But in a list of lengths spread evenly over many orders of magnitude\u2014for example, a list of 1000 lengths mentioned in scientific papers that includes the measurements of molecules, bacteria, plants, and galaxies\u2014it is reasonable to expect the distribution of first digits to be the same no matter whether the lengths are written in metres or in feet.\nWhen the distribution of the first digits of a data set is scale-invariant (independent of the units that the data are expressed in), it is always given by Benford's law.\nFor example, the first (non-zero) digit on the aforementioned list of lengths should have the same distribution whether the unit of measurement is feet or yards. But there are three feet in a yard, so the probability that the first digit of a length in yards is 1 must be the same as the probability that the first digit of a length in feet is 3, 4, or\u00a05; similarly, the probability that the first digit of a length in yards is 2 must be the same as the probability that the first digit of a length in feet is 6, 7, or\u00a08. Applying this to all possible measurement scales gives the logarithmic distribution of Benford's law.\nBenford's law for first digits is base invariant for number systems. There are conditions and proofs of sum invariance, inverse invariance, and addition and subtraction invariance.\nApplications.\nAccounting fraud detection.\nIn 1972, Hal Varian suggested that the law could be used to detect possible fraud in lists of socio-economic data submitted in support of public planning decisions. Based on the plausible assumption that people who fabricate figures tend to distribute their digits fairly uniformly, a simple comparison of first-digit frequency distribution from the data with the expected distribution according to Benford's law ought to show up any anomalous results.\nUse in criminal trials.\nIn the United States, evidence based on Benford's law has been admitted in criminal cases at the federal, state, and local levels.\nElection data.\nWalter Mebane, a political scientist and statistician at the University of Michigan, was the first to apply the second-digit Benford's law-test (2BL-test) in election forensics. Such analysis is considered a simple, though not foolproof, method of identifying irregularities in election results. Scientific consensus to support the applicability of Benford's law to elections has not been reached in the literature. A 2011 study by the political scientists Joseph Deckert, Mikhail Myagkov, and Peter C. Ordeshook argued that Benford's law is problematic and misleading as a statistical indicator of election fraud. Their method was criticized by Mebane in a response, though he agreed that there are many caveats to the application of Benford's law to election data.\nBenford's law has been used as evidence of fraud in the 2009 Iranian elections. An analysis by Mebane found that the second digits in vote counts for President Mahmoud Ahmadinejad, the winner of the election, tended to differ significantly from the expectations of Benford's law, and that the ballot boxes with very few invalid ballots had a greater influence on the results, suggesting widespread ballot stuffing. Another study used bootstrap simulations to find that the candidate Mehdi Karroubi received almost twice as many vote counts beginning with the digit 7 as would be expected according to Benford's law, while an analysis from Columbia University concluded that the probability that a fair election would produce both too few non-adjacent digits and the suspicious deviations in last-digit frequencies as found in the 2009 Iranian presidential election is less than 0.5 percent. Benford's law has also been applied for forensic auditing and fraud detection on data from the 2003 California gubernatorial election, the 2000 and 2004 United States presidential elections, and the 2009 German federal election. The Benford's Law Test was found to be \"worth taking seriously as a statistical test for fraud,\" although \"the test is not sensitive to distortions we know significantly affected many votes. In particular, the test does not indicate problems for Florida in 2000.\"\nBenford's law has also been misapplied to claim election fraud. When applying the law to Joe Biden's election returns for Chicago, Milwaukee, and other localities in the 2020 United States presidential election, the distribution of the first digit did not follow Benford's law. The misapplication was a result of looking at data that was tightly bound in range, which violates the assumption inherent in Benford's law that the range of the data be large. The first digit test was applied to precinct-level data, but because precincts rarely receive more than a few thousand votes or fewer than several dozen, Benford's law cannot be expected to apply. According to Mebane, \"It is widely understood that the first digits of precinct vote counts are not useful for trying to diagnose election frauds.\"\nMacroeconomic data.\nSimilarly, the macroeconomic data the Greek government reported to the European Union before entering the eurozone was shown to be probably fraudulent using Benford's law, albeit years after the country joined.\nPrice digit analysis.\nResearchers have used Benford's law to detect psychological pricing patterns, in a Europe-wide study in consumer product prices before and after euro was introduced in 2002. The idea was that, without psychological pricing, the first two or three digits of price of items should follow Benford's law. Consequently, if the distribution of digits deviates from Benford's law (such as having a lot of 9's), it means merchants may have used psychological pricing.\nWhen the euro replaced local currencies in 2002, for a brief period of time, the price of goods in euro was simply converted from the price of goods in local currencies before the replacement. As it is essentially impossible to use psychological pricing simultaneously on both price-in-euro and price-in-local-currency, during the transition period, psychological pricing would be disrupted even if it used to be present. It can only be re-established once consumers have gotten used to prices in a single currency again, this time in euro.\nAs the researchers expected, the distribution of first price digit followed Benford's law, but the distribution of the second and third digits deviated significantly from Benford's law before the introduction, then deviated less during the introduction, then deviated more again after the introduction.\nGenome data.\nThe number of open reading frames and their relationship to genome size differs between eukaryotes and prokaryotes with the former showing a log-linear relationship and the latter a linear relationship. Benford's law has been used to test this observation with an excellent fit to the data in both cases.\nScientific fraud detection.\nA test of regression coefficients in published papers showed agreement with Benford's law. As a comparison group subjects were asked to fabricate statistical estimates. The fabricated results conformed to Benford's law on first digits, but failed to obey Benford's law on second digits.\nAcademic publishing networks.\nTesting the number of published scientific papers of all registered researchers in Slovenia's national database was shown to strongly conform to Benford's law. Moreover, the authors were grouped by scientific field, and tests indicate natural sciences exhibit greater conformity than social sciences.\nEcological application.\nA 2025 PLOS ONE journal article argues Benford probability distribution of species in certain ecological systems can detect impending transitions of the system.\nStatistical tests.\nAlthough the chi-squared test has been used to test for compliance with Benford's law it has low statistical power when used with small samples.\nThe Kolmogorov\u2013Smirnov test and the Kuiper test are more powerful when the sample size is small, particularly when Stephens's corrective factor is used. These tests may be unduly conservative when applied to discrete distributions. Values for the Benford test have been generated by Morrow. The critical values of the test statistics are shown below:\nThese critical values provide the minimum test statistic values required to reject the hypothesis of compliance with Benford's law at the given significance levels.\nTwo alternative tests specific to this law have been published: First, the max (m) statistic is given by\n formula_5\nThe leading factor formula_6 does not appear in the original formula by Leemis; it was added by Morrow in a later paper.\nSecondly, the distance (d) statistic is given by\n formula_7\nwhere FSD is the first significant digit and N is the sample size. Morrow has determined the critical values for both these statistics, which are shown below:\nMorrow has also shown that for any random variable X (with a continuous PDF) divided by its standard deviation (\u03c3), some value A can be found so that the probability of the distribution of the first significant digit of the random variable formula_8 will differ from Benford's law by less than The value of A depends on the value of \u03b5 and the distribution of the random variable.\nA method of accounting fraud detection based on bootstrapping and regression has been proposed.\nIf the goal is to conclude agreement with the Benford's law rather than disagreement, then the goodness-of-fit tests mentioned above are inappropriate. In this case the specific tests for equivalence should be applied. An empirical distribution is called equivalent to the Benford's law if a distance (for example total variation distance or the usual Euclidean distance) between the probability mass functions is sufficiently small. This method of testing with application to Benford's law is described in Ostrovski.\nRange of applicability.\nDistributions known to obey Benford's law.\nSome well-known infinite integer sequences provably satisfy Benford's law exactly (in the asymptotic limit as more and more terms of the sequence are included). Among these are the Fibonacci numbers, the factorials, the powers of\u00a02, and the powers of almost any other number.\nLikewise, some continuous processes satisfy Benford's law exactly (in the asymptotic limit as the process continues through time). One is an exponential growth or decay process: If a quantity is exponentially increasing or decreasing in time, then the percentage of time that it has each first digit satisfies Benford's law asymptotically (i.e. increasing accuracy as the process continues through time).\nDistributions known to disobey Benford's law.\nThe square roots and reciprocals of successive natural numbers do not obey this law. Prime numbers in a finite range follow a Generalized Benford's law, that approaches uniformity as the size of the range approaches infinity. Lists of local telephone numbers violate Benford's law. Benford's law is violated by the populations of all places with a population of at least 2500 individuals from five US states according to the 1960 and 1970 censuses, where only 19\u2009% began with digit 1 but 20\u2009% began with digit 2, because truncation at 2500 introduces statistical bias. The terminal digits in pathology reports violate Benford's law due to rounding.\nDistributions that do not span several orders of magnitude will not follow Benford's law. Examples include height, weight, and IQ scores.\nCriteria for distributions expected and not expected to obey Benford's law.\nA number of criteria, applicable particularly to accounting data, have been suggested where Benford's law can be expected to apply.\nBenford's law compliance theorem.\nMathematically, Benford's law applies if the distribution being tested fits the \"Benford's law compliance theorem\". The derivation says that Benford's law is followed if the Fourier transform of the logarithm of the probability density function is zero for all integer values. Most notably, this is satisfied if the Fourier transform is zero (or negligible) for \"n\"\u00a0\u2265\u00a01. This is satisfied if the distribution is wide (since wide distribution implies a narrow Fourier transform). Smith summarizes the matter: \nBenford's law is followed by distributions that are wide compared with unit distance along the logarithmic scale. Likewise, the law is not followed by distributions that are narrow compared with unit distance\u00a0\u2026 If the distribution is wide compared with unit distance on the log axis, it means that the spread in the set of numbers being examined is much greater than ten.\nIn short, Benford's law requires that the numbers in the distribution being measured have a spread across at least an order of magnitude.\nTests with common distributions.\nBenford's law was empirically tested against the numbers (up to the 10th digit) generated by a number of important distributions, including the uniform distribution, the exponential distribution, the normal distribution, and others.\nThe uniform distribution, as might be expected, does not obey Benford's law. In contrast, the ratio distribution of two uniform distributions is well-described by Benford's law.\nNeither the normal distribution nor the ratio distribution of two normal distributions (the Cauchy distribution) obey Benford's law. Although the half-normal distribution does not obey Benford's law, the ratio distribution of two half-normal distributions does. Neither the right-truncated normal distribution nor the ratio distribution of two right-truncated normal distributions are well described by Benford's law. This is not surprising as this distribution is weighted towards larger numbers.\nBenford's law also describes the exponential distribution and the ratio distribution of two exponential distributions well. The fit of chi-squared distribution depends on the degrees of freedom (df) with good agreement with df = 1 and decreasing agreement as the df increases. The \"F\"-distribution is fitted well for low degrees of freedom. With increasing dfs the fit decreases but much more slowly than the chi-squared distribution. The fit of the log-normal distribution depends on the mean and the variance of the distribution. The variance has a much greater effect on the fit than does the mean. Larger values of both parameters result in better agreement with the law. The ratio of two log normal distributions is a log normal so this distribution was not examined.\nOther distributions that have been examined include the Muth distribution, Gompertz distribution, Weibull distribution, gamma distribution, log-logistic distribution and the exponential power distribution all of which show reasonable agreement with the law. The Gumbel distribution \u2013 a density increases with increasing value of the random variable \u2013 does not show agreement with this law.\nGeneralization to digits beyond the first.\nIt is possible to extend the law to digits beyond the first. In particular, for any given number of digits, the probability of encountering a number starting with the string of digits \"n\" of that length\u00a0\u2013 discarding leading zeros\u00a0\u2013 is given by\n formula_9\nThus, the probability that a number starts with the digits 3,\u00a01,\u00a04 (some examples are 3.14, 3.142, \u03c0, 314280.7, and 0.00314005) is log10(1\u00a0+\u00a01/314)\u00a0\u2248\u00a00.00138, as in the box with the log-log graph on the right. \u00a0\nThis result can be used to find the probability that a particular digit occurs at a given position within a number. For instance, the probability that a \"2\" is encountered as the second digit is\n formula_10.\nThe probability that \"d\" (\"d\"\u00a0=\u00a00,\u00a01,\u00a0...,\u00a09) is encountered as the \"n\"-th (\"n\"\u00a0&gt;\u00a01) digit is\n formula_11\nThe distribution of the \"n\"-th digit, as \"n\" increases, rapidly approaches a uniform distribution with 10% for each of the ten digits, as shown below. Four digits is often enough to assume a uniform distribution of 10% as \"0\" appears 10.0176% of the time in the fourth digit, while \"9\" appears 9.9824% of the time.\nMoments.\nAverage and moments of random variables for the digits 1 to 9 following this law have been calculated:\nFor the two-digit distribution according to Benford's law these values are also known:\nA table of the exact probabilities for the joint occurrence of the first two digits according to Benford's law is available, as is the population correlation between the first and second digits: \"\u03c1\" = 0.0561.\nIn popular culture.\nBenford's law has appeared as a plot device in some twenty-first century popular entertainment. \nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "36783", "revid": "253171", "url": "https://en.wikipedia.org/wiki?curid=36783", "title": "983", "text": "Calendar year\nYear 983 (CMLXXXIII) was a common year starting on Monday of the Julian calendar.\nEvents.\n&lt;onlyinclude&gt;\nBy topic.\nReligion.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36786", "revid": "21802707", "url": "https://en.wikipedia.org/wiki?curid=36786", "title": "Little Ice Age", "text": "Climatic cooling after the Medieval Warm Period (16th\u201319th centuries)\nThe Little Ice Age (LIA) was a period of regional cooling, particularly pronounced in the North Atlantic region. It was not a true ice age of global extent. The term was introduced into scientific literature by Fran\u00e7ois E. Matthes in 1939. The period has been conventionally defined as extending from the 16th to the 19th centuries, but some experts prefer an alternative time-span from about 1300 to about 1850.\nThe NASA Earth Observatory notes three particularly cold intervals. One began about 1650, another about 1770, and the last in 1850, all of which were separated by intervals of slight warming. The Intergovernmental Panel on Climate Change Third Assessment Report considered that the timing and the areas affected by the LIA suggested largely independent regional climate changes, rather than a globally synchronous increased glaciation. At most, there was modest cooling of the Northern Hemisphere during the period.\nSeveral causes have been proposed: cyclical lows in solar radiation, heightened volcanic activity, changes in the ocean circulation, variations in Earth's orbit and axial tilt (orbital forcing), inherent variability in global climate, and decreases in the human population (such as from the massacres by Genghis Khan, the Black Death and the epidemics emerging in the Americas upon European contact).\nAreas involved.\nThe Intergovernmental Panel on Climate Change Third Assessment Report (TAR) of 2001 described the areas that were affected:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe IPCC Fourth Assessment Report (AR4) of 2007 discusses more recent research and gives particular attention to the Medieval Warm Period:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nDating.\nThere is no consensus on when the Little Ice Age began, but a series of events before the known climatic minima have often been referenced. In the 13th century, pack ice began advancing southwards in the North Atlantic, as did glaciers in Greenland. Anecdotal evidence suggests expanding glaciers almost worldwide. Based on radiocarbon dating of roughly 150 samples of dead plant material with roots intact that were collected from beneath ice caps on Baffin Island and Iceland, Miller \"et al.\" (2012) state that cold summers and ice growth began abruptly between 1275 and 1300, followed by \"a substantial intensification\" from 1430 to 1455.\nIn contrast, a climate reconstruction based on glacial length shows no great variation from 1600 to 1850 but a strong retreat thereafter.\nTherefore, any of several dates ranging over 400 years may indicate the beginning of the Little Ice Age:\nThe Little Ice Age ended in the latter half of the 19th century or in the early 20th century.\nThe 6th report of the IPCC describes the coldest period in the last millennium as: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;a multi-centennial period of relatively low temperature beginning around the 15th century, with GMST averaging \u20130.03 [\u20130.30 to 0.06] \u00b0C between 1450 and 1850 relative to 1850\u20131900.The definitions for the beginning and end of the LIA differ considerably, depending on the region and dataset used. The LIA in the Northern Hemisphere \u00a0started between 1200 and 1400 AD. In the Southern Hemisphere the beginning of the LIA was delayed by about two centuries.\nBy region.\nEurope.\nWinter.\nIn 2021, historian Christian Pfister and climatologist Heinz Wanner published a reconstruction of seasonal temperatures in Central Europe using temperature indices (historical climatology) based on documentary data. After CE 1500, the reconstruction is based on an article by Czech geographer Petr Dobrovolny, which includes monthly, seasonal and annual temperature estimates for Germany, Switzerland and the Czech lands based on temperature indices up to 1759 and subsequent temperature measurements.\nReconstructions of seasonal temperatures in Central Europe from 1000 to 1999 show that winters were generally cold until the end of the 19th century. A reconstruction of winter temperatures on a year-by-year basis from 1170 onward reveals a different picture of the Little Ice Age. For example, in the 13th century, winters were predominantly cold only in the first third of the century, as well as between 1270 and 1280. During the 14th century, cold winters were the norm, except for the 48 years between 1340 and 1377. The 15th century was almost entirely cold, except for the 1470s. Until 1520, winters remained mostly cold.. Afterwards, the cold and warm seasons were balanced until 1540. After that, cold winters became the norm, with particularly severe winters occurring between 1565 and 1573 and again from 1587 to 1595. Overall, winter seasons were around 0.9 \u00b0C (\u00b10.69 \u00b0C) below the 1961\u20131990 average. In the 17th century, winter temperatures were 1.2\u00b0C (\u00b10.69\u00b0C) below average. In the 18th century, they were 0.9\u00b0C (\u00b10.69\u00b0C) below average. In the 19th century, they were 1.2\u00b0C below average based on thermometric measurements. In the 20th century, they were 0.2\u00b0C below the 1961\u20131990 average, with positive values dominating from 1950 onwards. Conclusion: The duration and intensity of cold spells in winter have increased since the 14th century, peaking in the 15th, 17th, and 19th centuries. The gradual decline in winter temperatures until the early 20th century, compared to the 1961\u20131990 measurement period, was one manifestation of the end of the Little Ice Age in Central Europe due to Global Warming.\nSummer.\nCentral European\u00a0 summers were slightly cooler than warm ones sin the 14th century. The years from 1324 to 1340 and from 1380 to 1399 were predominantly warm, whereas the years from 1314 to 1322 and from 1355 to 1370 were mostly cold. The latter cold period triggered an advance of the Alpine glaciers, reaching its peak in the 1380s. Cold summers predominated in the 15th century. After a relatively warm period until 1424, the trend reversed. Seven cold summers occurred in the 1450s alone, presumably in connection with the eruption of a tropical volcano (Kuwae). Also notable is the sequence of three hot summers between 1471 and 1473. In the 16th century, estimated temperatures were 0.2 \u00b0C (\u00b10.49 \u00b0C) below the 1961\u20131990 average. Due to ten hot and dry summers, temperatures from 1534 to 1567 were 0.3 \u00b0C (\u00b10.49 \u00b0C) above average, causing the glaciers to melt back somewhat. Subsequently, temperatures fell in conjunction with high summer precipitation, reaching a low point in the 1590s and triggering the widespread advance of Alpine glaciers. In the 17th century, estimated temperatures were 0.2\u00b0C (\u00b10.49\u00b0C) lower than the average for the period 1961\u20131990. Until around 1630 and from 1670 to 1685, extremes of cold and warmth dominated, with warm summers occurring mid-century. After 1675, temperatures fell by an average of 0.6 \u00b0C until the turn of the century. Cod, which is sensitive to cold temperatures, disappeared from the waters around the Faroe Islands. The English climatologist and historian Hubert Lamb concluded that cold Arctic water had spread southwards.Warm summers prevailed in the 18th century, particularly between 1718 and 1731. Temperatures remained relatively low between 1760 and 1779, triggering an advance of the Alpine glaciers Cold summers prevailed in the 19th century. Average temperatures in Central Europe were 0.6 \u00b0C below the 1961\u20131990 average. The first half of the century was predominantly cold, leading to glacier advances. In the 20th century, summers in Central Europe remained cold until 1927. Temperatures then rose until the warm decade from 1943 to 1952, after which they fluctuated around the 1901\u20131960 average. The long-term process of glacier retreat began with the slow man-made warming of the late 19th century and accelerated with the more rapid warming that occurred after 1990.\nConclusion: The advances and retreats of Alpine glaciers during the Little Ice Age mainly followed summer temperatures over the course of a few decades. \nDrangaj\u00f6kull, Iceland's northernmost glacier, reached its maximum extent during the LIA around 1665 or 1765.\nThe Baltic Sea froze over twice, in 1303 and 1306\u20131307, and years followed of \"unseasonable cold, storms and rains, and a rise in the level of the Caspian Sea\". The Little Ice Age brought colder winters to parts of Europe and North America. Farms and villages in the Swiss Alps were destroyed by encroaching glaciers during the mid-17th century. Canals and rivers in Great Britain and the Netherlands were frequently frozen deeply enough to support ice skating and winter festivals. As trade needed to continue during the prolonged winter often spanning 5 months, merchants equipped their boer style boats with planks and skates (runners), hence the iceboat was born. The first River Thames frost fair was in 1608 and the last in 1814. Changes to the bridges and the addition of the Thames Embankment have affected the river's flow and depth and greatly diminish the possibility of further freezes.\nIn early 1658, a Swedish army took advantage of the extremely cold winter to march through Denmark and across the Great Belt to attack Copenhagen from the west.\nSea ice surrounding Iceland extended for miles in every direction and closed harbors to shipping. The population of Iceland fell by half, but that may have been caused by skeletal fluorosis after the eruption of Laki in 1783. Iceland also suffered failures of cereal crops and people moved away from a grain-based diet. \nAfter Greenland's climate became colder and stormier around 1250, the diet of the Norse Viking settlements there steadily shifted away from agricultural sources. By around 1300, seal hunting provided over three quarters of their food. By 1350, there was reduced demand for their exports, and trade with Europe fell away. The last document from the settlements dates from 1412, and over the following decades, the remaining Europeans left in what seems to have been a gradual withdrawal, which was caused mainly by economic factors such as increased availability of farms in Scandinavian countries. Greenland was largely cut off by ice from 1410 to the 1720s.\nBetween 1620 and 1740, the Yzeron Basin in the Massif Central of France witnessed a phase of decreased fluvial activity. This decline in fluvial activity is believed to be linked to a multidecennial phase of droughts in the western Mediterranean.\nIn southwestern Europe, a negative North Atlantic oscillation (NAO) combined with increased aridity caused an increase in wind-driven sediment deposition during the LIA.\nIn his 1995 book, the early climatologist Hubert Lamb said that in many years, \"snowfall was much heavier than recorded before or since, and the snow lay on the ground for many months longer than it does today.\" In Lisbon, Portugal, snowstorms were much more frequent than today, and one winter in the 17th century produced eight snowstorms. Many springs and summers were cold and wet but with great variability between years and groups of years. That was particularly evident during the \"Grindelwald Fluctuation\" (1560\u20131630); the rapid cooling phase was associated with more erratic weather, including increased storminess, unseasonal snowstorms, and droughts. Crop practices throughout Europe had to be altered to adapt to the shortened and less reliable growing season, and there were many years of scarcity and famine. One was the Great Famine of 1315\u20131317, but that may have been before the Little Ice Age. According to Elizabeth Ewan and Janay Nugent, \"Famines in France 1693\u201394, Norway 1695\u201396 and Sweden 1696\u201397 claimed roughly 10 percent of the population of each country. In Estonia and Finland in 1696\u201397, losses have been estimated at a fifth and a third of the national populations, respectively.\" Viticulture disappeared from some northern regions, and storms caused serious flooding and loss of life. Some of them resulted in the permanent loss of large areas of land from the Danish, German, and Dutch coasts.\nThe violinmaker Antonio Stradivari produced his instruments during the Little Ice Age. The colder climate may have caused the wood that was used in his violins to be denser than in warmer periods and to contribute to the tone of his instruments. According to the science historian James Burke, the period inspired such novelties in everyday life as the widespread use of buttons and button-holes, as well as knitting of custom-made undergarments for the better covering and insulating of the body. Chimneys were invented to replace open fires in the centre of communal halls to allow houses with multiple rooms to have the separation of masters from servants.\n\"The Little Ice Age\", by the anthropologist Brian Fagan of the University of California at Santa Barbara, describes the plight of European peasants from 1300 to 1850: famines, hypothermia, bread riots and the rise of despotic leaders brutalizing an increasingly dispirited peasantry. In the late 17th century, agriculture had dropped off dramatically: \"Alpine villagers lived on bread made from ground nutshells mixed with barley and oat flour.\" Historian Wolfgang Behringer has linked intensive witch-hunting episodes in Europe to agricultural failures during the Little Ice Age.\n\"The Frigid Golden Age\", by the environmental historian Dagomar Degroot of Georgetown University, points out that some societies thrived, but others faltered during the Little Ice Age. In particular, the Little Ice Age transformed environments around the Dutch Republic and made them easier to exploit in commerce and conflict. The Dutch were resilient, even adaptive, in the face of weather that devastated neighboring countries. Merchants exploited harvest failures, military commanders took advantage of shifting wind patterns, and inventors developed technologies that helped them profit from the cold. The 17th-century Dutch Golden Age therefore owed much to its people's flexibility in coping with the changing climate.\nCultural responses.\nHistorians have argued that cultural responses to the consequences of the Little Ice Age in Europe consisted of violent scapegoating. The prolonged cold, dry periods brought drought upon many European communities and resulted in poor crop growth, poor livestock survival, and increased activity of pathogens and disease vectors. Disease intensified under the same conditions that unemployment and economic difficulties arose: prolonged cold, dry seasons. Disease and unemployment generated a lethal positive feedback loop. Although the communities had some contingency plans, such as better crop mixes, emergency grain stocks, and international food trade, they did not always prove effective. Communities often lashed out via violent crimes, including robbery and murder. Accusations of sexual offenses also increased, such as adultery, bestiality, and rape. Europeans sought explanations for the famine, disease, and social unrest that they were experiencing, and they blamed the innocent. Evidence from several studies indicate that increases in violent actions against marginalized groups, which were held responsible for the Little Ice Age, overlap with the years of particularly cold, dry weather.\nOne example of the violent scapegoating occurring during the Little Ice Age was the resurgence of witchcraft trials. Oster (2004) and Behringer (1999) argue that the resurgence was brought by the climatic decline. Prior to the Little Ice Age, witchcraft was considered an insignificant crime, and victims (the supposed witches) were rarely accused. But beginning in the 1380s, just as the Little Ice Age began, European populations began to link magic and weather-making. The first systematic witch hunts began in the 1430s, and by the 1480s, it was widely believed that witches should be held accountable for poor weather. Witches were blamed for direct and indirect consequences of the Little Ice Age: livestock epidemics, cows that gave too little milk, late frosts, and unknown diseases. In general, the number of witchcraft trials rose as the temperature dropped, and trials decreased when temperature increased. The peaks of witchcraft persecutions overlap with the hunger crises that occurred in 1570 and 1580, the latter lasting a decade. The trials targeted primarily poor women, many of them widows. Not everybody agreed that witches should be persecuted for weather-making, but such arguments focused primarily not upon whether witches existed but upon whether witches had the capability to control the weather. The Catholic Church in the Early Middle Ages argued that witches could not control the weather because they were mortals, not God, but by the mid-13th century, most people agreed with the idea that witches could control natural forces.\nJewish populations were also blamed for climatic deterioration during the Little Ice Age. The Western European states experienced waves of anti-Semitism, directed against the main religious minority in their otherwise Christian societies. There was no direct link made between Jews and the weather; they were blamed only for indirect consequences such as disease. Outbreaks of the Black Death were often blamed on Jews. In Western European cities during the 1300s, Jewish populations were murdered to stop the spread of the plague. Rumors spread that Jews were either poisoning wells themselves, or telling lepers to poison the wells. To escape persecution, some Jews converted to Christianity, while others migrated to the Ottoman Empire, Italy or the Holy Roman Empire, where they experienced greater toleration.\nSome populations blamed the cold periods and the resulting famine and disease during the Little Ice Age on a general divine displeasure. Particular groups took the brunt of the burden in attempts to cure it. In Germany, regulations were imposed upon activities such as gambling and drinking, which disproportionately affected the lower class and women were forbidden from showing their knees. Other regulations affected the wider population, such as prohibiting dancing, sexual activities and moderating food and drink intake. In Ireland, Catholics blamed the Reformation for the bad weather. The \"Annals of Loch C\u00e9\", in its entry for 1588, describes a midsummer snowstorm as \"a wild apple was not larger than each stone of it\" and blames it on the presence of a \"wicked, heretical, bishop in Oilfinn\", the Protestant Bishop of Elphin, John Lynch.\nDepictions of winter in European painting.\nWilliam James Burroughs analyzes the depiction of winter in paintings, as does Hans Neuberger. Burroughs asserts that it occurred almost entirely from 1565 to 1665 and was associated with the climatic decline from 1550 onwards. Burroughs claims that there had been almost no depictions of winter in art, and he \"hypothesizes that the unusually harsh winter of 1565 inspired great artists to depict highly original images and that the decline in such paintings was a combination of the 'theme' having been fully explored and mild winters interrupting the flow of painting.\" Wintry scenes, which entail technical difficulties in painting, have been regularly and well handled since at least the early 15th century by artists in illuminated manuscript cycles that show the \"Labours of the Months\", typically placed on the calendar pages of books of hours. January and February are typically shown as snowy, as in \"February\" in the famous cycle in the , painted in 1412\u20131416 and illustrated below. Since landscape painting had not yet developed as an independent genre in art, the absence of other winter scenes is not remarkable. On the other hand, snowy winter landscapes, particularly stormy seascapes, became artistic genres in the Dutch Golden Age painting during the coldest and stormiest decades of the Little Ice Age. Most modern scholars believe them to be full of symbolic messages and metaphors, which would have been clear to contemporary viewers.\nAll of the famous winter landscape paintings by Pieter Bruegel the Elder, such as \"The Hunters in the Snow\" and the \"Massacre of the Innocents\", are thought to have been painted around 1565. His son Pieter Brueghel the Younger (1564\u20131638) also painted many snowy landscapes, but according to Burroughs, he \"slavishly copied his father's designs. The derivative nature of so much of this work makes it difficult to draw any definite conclusions about the influence of the winters between 1570 and 1600\". Bruegel the Elder painted \"Hunters in the Snow\" in Antwerp, so the mountains in the picture probably mean it was based on drawings or memories from crossing of the Alps during his trip to Rome in 1551\u20131552. It is one of 5 known surviving paintings, probably from a series of 6 or 12, known as \"the Twelve Months\", that Breugel was commissioned to paint by a wealthy patron in Antwerp, Nicolaes Jonghelinck (\"Hunters in the Snow\" being for January): none of the other four that survive show a snow-covered landscape and both \"The Hay Harvest\" (July) and \"The Harvesters\" (August) depict warm summer days. Even \"The Return of the Herd\" (thought to be the painting for November) and \"The Gloomy Day\" (known to be for February) show landscapes free of snow.\nBurroughs says that snowy subjects return to Dutch Golden Age painting with works by Hendrick Avercamp from 1609 onwards. There is a hiatus between 1627 and 1640, which is before the main period of such subjects from the 1640s to the 1660s. That relates well with climate records for the later period. The subjects are less popular after about 1660, but that does not match any recorded reduction in severity of winters and may reflect only changes in taste or fashion. In the later period between the 1780s and 1810s, snowy subjects again became popular. Neuberger analyzed 12,000 paintings, held in American and European museums and dated between 1400 and 1967, for cloudiness and darkness. His 1970 publication shows an increase in such depictions that corresponds to the Little Ice Age, which peaks between 1600 and 1649.\nPaintings and contemporary records in Scotland demonstrate that curling, ice skating and icesailing were popular outdoor winter sports, with curling dating to the 16th century and becoming widely popular in the mid-19th century. An outdoor curling pond constructed in Gourock in the 1860s remained in use for almost a century, but increasing use of indoor facilities, problems of vandalism, and milder winters led to the pond being abandoned in 1963.\nGeneral Crisis of the seventeenth century.\nThe General Crisis of the seventeenth century in Europe was a period of inclement weather, crop failure, economic hardship, extreme intergroup violence, and high mortality linked to the Little Ice Age. Episodes of social instability track the cooling with a time lapse of up to 15 years, and many developed into armed conflicts, such as the Thirty Years' War (1618\u20131648). The war started as a war of succession to the Bohemian throne. Animosity between Protestants and Catholics in the Holy Roman Empire (most of which is now in Germany, Austria, and the Czech Republic) added fuel to the fire. It soon escalated to a huge conflict that involved all the major European powers and devastated much of Germany. When the war ended, some regions of the Holy Roman Empire had seen their population drop by as much as 70%.\nNorth America.\nEarly European explorers and settlers of North America reported exceptionally severe winters. In southwestern Alaska, preexisting flexibility in foraging habits among the native people lent itself to high adaptability to the LIA. Both Europeans and indigenous peoples suffered excess mortality in Maine during the winter of 1607\u20131608, and extreme frost was meanwhile reported in the Jamestown, Virginia, settlement. Native Americans formed leagues in response to food shortages. The journal of Pierre de Troyes, Chevalier de Troyes, who led an expedition to James Bay in 1686, recorded that the bay was still littered with so much floating ice that he could hide behind it in his canoe on 1 July. In the winter of 1780, New York Harbor froze, which allowed people to walk from Manhattan Island to Staten Island.\nThe extent of mountain glaciers had been mapped by the late 19th century. In the north and the south temperate zones, Equilibrium Line Altitude (the boundaries separating zones of net accumulation from those of net ablation) were about lower than they were in 1975. Southwestern Alaska experienced a temperature nadir around 135 BP, and in south-central Alaska, mountain hemlock forests severely declined. In Glacier National Park, the last episode of glacier advance came in the late 18th and the early 19th centuries. In 1879, the famed naturalist John Muir found that Glacier Bay ice had retreated . In Chesapeake Bay, Maryland, large temperature excursions were possibly related to changes in the strength of the North Atlantic thermohaline circulation. \nBecause the Little Ice Age took place during the European colonization of the Americas, it discouraged many early colonists, who had expected the climate of North America to be similar to the climate of Europe at similar latitudes. They found that North America, at least in what would become Canada and the northern United States, had hotter summers and colder winters than Europe. That effect was aggravated by the Little Ice Age, and unpreparedness led to the collapse of many early European settlements in North America.\nHistorians agree that when colonists settled at Jamestown, it was one of the coldest periods in the last 1000 years. Drought was also a problem in North America during the Little Ice Age, and the settlers arrived in Roanoke during the largest drought of the past 800 years. Tree ring studies by the University of Arkansas discovered that many colonists arrived at the beginning of a seven-year drought. The droughts also decreased the Native American populations and led to conflict because of food scarcity. English colonists at Roanoke forced Native Americans of Ossomocomuck to share their depleted supplies with them. That led to warfare between the two groups, and Native American towns were destroyed. That cycle would repeat itself many times at Jamestown. The combination of fighting and cold weather also led to the spread of diseases. The colder weather helped the parasites brought by Europeans in mosquitoes to develop faster. That in turn led to many malaria deaths among Native Americans.\nThomas Gorges wrote that between 1637 and 1645, colonists in Maine (then part of Massachusetts) experienced horrendous weather conditions. In June 1637, temperatures were so high that numerous European settlers died; travelers were forced to travel at night to stay cool. Gorges also wrote that the winter of 1641\u20131642 was \"piercingly Intolerable\" and that no Englishman or Native American had ever seen anything like it. He also stated that the Massachusetts Bay had frozen as far as one could see, and that horse carriages now roamed where ships used to be. He stated that the summers of 1638 and 1639 were very short, cold, and wet, which compounded food scarcity for a few years. To make matters worse, creatures like caterpillars and pigeons fed on crops and devastated harvests. Every year about which Gorges wrote featured unusual weather patterns, including high precipitation, drought, and extreme cold or heat.\nMany inhabitants of North America had their own theories about the extreme weather. The colonist Ferdinando Gorges blamed the cold weather on cold ocean winds. Humphrey Gilbert tried to explain Newfoundland's icy and foggy weather by saying that the Earth drew cold vapors from the ocean and drew them west. Many others had their own theories for North America being so much colder than Europe; their observations and hypotheses offer insight on the Little Ice Age's effects in North America.\nMesoamerica.\nAn analysis of several climate proxies undertaken in Mexico's Yucat\u00e1n Peninsula, which was linked by its authors to Maya and Aztec chronicles relating periods of cold and drought, supports the existence of the Little Ice Age in the region. Cold and drought led to a terrible famine in the Aztec Empire in 1454 and the Chilam Balam Book of Mani mentions a decrease in temperature between 1441 and 1460 during the final years of Mayapan.\nAnother study conducted in several sites in Mesoamerica like Los Tuxtlas and Lake Pompal in Veracruz, Mexico show a decrease in human activity in the area during the Little Ice Age. That was proven by studying charcoal fragments and the amount of maize pollen taken from sedimentary samples by using a nonrotatory piston corer. The samples also showed volcanic activity which caused forest regeneration between 650 and 800. The instances of volcanic activity near Lake Pompal indicate varying temperatures, not a continuous coldness, during the Little Ice Age in Mesoamerica.\nAtlantic Ocean.\nIn the North Atlantic, sediments accumulated since the end of the last ice age, which occurred nearly 12,000 years ago, show regular increases in the amount of coarse sediment grains deposited from icebergs melting in the now-open ocean, indicating a series of cooling events that recur every 1,500 years or so. The most recent cooling event was the Little Ice Age. The same cooling events are detected in sediments accumulating off Africa, but the cooling events appear to be larger: . \u03b418O values from chironomid remains in the Azores reflect the cooling of the LIA.\nAsia.\nAlthough the original designation of a Little Ice Age referred to the reduced temperature of Europe and North America, there is some evidence of extended periods of cooling outside those regions although it is not clear whether they are related or independent events. Mann states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;While there is evidence that many other regions outside Europe exhibited periods of cooler conditions, expanded glaciation, and significantly altered climate conditions, the timing and nature of these variations are highly variable from region to region, and the notion of the Little Ice Age as a globally synchronous cold period has all but been dismissed.\nIn China, warm-weather crops such as oranges were abandoned in Jiangxi Province, where they had been grown for centuries. Also, the two periods of most frequent typhoon strikes in Guangdong coincide with two of the coldest and driest periods in northern and central China (1660\u20131680, 1850\u20131880). Scholars have argued that one of the reasons for the fall of the Ming dynasty may have been the droughts and famines that were caused by the Little Ice Age.\nThere are debates on the start date and the periods of Little Ice Age's effects. Most scholars agree on categorizing the Little Ice Age period into three distinct cold periods: in 1458\u20131552, 1600\u20131720, and 1840\u20131880. According to data from the U.S. National Oceanic and Atmospheric Administration, the eastern monsoon area of China was the earliest to experience the effects of the Little Ice Age, from 1560 to 1709. In the western region of China surrounding the Tibetan Plateau, the effects of the Little Ice Age lagged behind the eastern region, with significant cold periods from 1620 to 1749. As the Medieval Warm Period transitioned into the Little Ice Age, the East Asian Summer Monsoon (EASM) became much weaker and the summer monsoon limit (SML) migrated southeastwards. Southwestern China became significantly colder and drier as a result of the weakening of the EASM caused by the decreased pressure gradient resulting from the cooling of the southern Eurasian landmass, while northwestern China, dominated by westerlies, saw an increase in precipitation.\nThe temperature changes were unprecedented for the farming communities in China. According to Coching Chu's 1972 study, the Little Ice Age from the end of the Ming dynasty to the start of the Qing dynasty (1650\u20131700) was one of the coldest periods in recorded Chinese history. Many major droughts during the summer months were recorded, and significant freezing events occurred during the winter months. That greatly worsened the food supply during the Ming dynasty.\nThis period of Little Ice Age corresponded to the period's major historical events. The Jurchen people lived in Northern China and formed a tributary state to the Ming dynasty and its Wanli Emperor. From 1573 to 1620, Manchuria experienced famine caused by extreme snowfall, which depleted agriculture production and devastated the livestock population. Scholars have argued that it had been caused by the temperature drops during the Little Ice Age. Despite the lack of food production, the Wanli Emperor ordered the Jurchens to pay the same amount of tribute each year. That led to anger and sowed seeds to the rebellion against the Ming dynasty. In 1616, Jurchens established the Later Jin dynasty. Led by Hong Taiji and Nurhaci, the Later Jin dynasty moved South and achieved decisive victories in battles against the Ming dynasty's military, such as during the 1618 Battle of Fushun.\nAfter the earlier defeats and the death of the Wanli Emperor, the Chongzhen Emperor took over China and continued the war effort. From 1632 to 1641, the Little Ice Age began to cause drastic climate changes in the Ming dynasty's territories. For example, rainfall in the Huabei region dropped by 11% to 47% from the historical average. Meanwhile, the Shaanbei region, along the Yellow River experienced six major floods, which ruined cities such as Yan'an. The climate factored heavily in weakening the government's control over China and accelerated the fall of the Ming dynasty. In 1644, Li Zicheng led the Later Jin's forces into Beijing, overthrew the Ming dynasty, and established the short-lived Shun dynasty which were soon overthrown by Qing dynasty.\nDuring the early years of the Qing dynasty, the Little Ice Age continued to have a significant impact on Chinese society. During the rule of the Kangxi Emperor (1661\u20131722), most Qing territories were still much colder than the historical average. However, the Kangxi Emperor pushed reforms and managed to increase the socio-economic recovery from the natural disasters. He benefited partly from the peacefulness of the early Qing dynasty. That essentially marked the end of the Little Ice Age in China and led to a more prosperous era of Chinese history that is known as the High Qing era.\nIn the Himalayas, the general assumption is that the cooling events were synchronous with those in Europe during the Little Ice Age because of the characteristics of moraines. However, applications of Quaternary dating methods such as surface exposure dating have shown that glacial maxima occurred between 1300 and 1600, slightly earlier than the recorded coldest period in the Northern Hemisphere. Many large Himalayan glacial debris fields have remained close to their limits since the Little Ice Age. The Himalayas also experienced an increase in snowfall at higher altitudes, which results in a southward shift in the Indian summer monsoon and an increase in precipitation. Overall, the increase in winter precipitation may have caused some glacial movements. Since the end of the Little Ice Age, there has been an almost continuous retreat of glaciers to present.\nThe region in Balochistan became colder, and its native Baloch people started a mass migration and began to settle along the Indus River in Sindh and Punjab.\nOn Rebun Island, a rapid cooling event occurred around 390 BP (as measured from pollen samples in 2018) amidst a longer-term trend of cooling; this cooling event marked the onset of the Little Ice Age in the region.\nAfrica.\nThe Little Ice Age influenced the African climate from the 14th to the 19th centuries. Despite variances throughout the continent, a general trend of declining temperatures in Africa led to an average cooling of 1\u00a0\u00b0C.\nIn Ethiopia and North Africa, permanent snow was reported on mountain peaks at levels at which it does not occur today. Timbuktu, an important city on the trans-Saharan caravan route, was flooded at least 13 times by the Niger River, but there are no records of similar flooding before or since that time.\nSeveral paleoclimatic studies of Southern Africa have suggested significant changes in relative changes in climate and environmental conditions. In Southern Africa, sediment cores retrieved from Lake Malawi show colder conditions between 1570 and 1820, which \"further support, and extend, the global expanse of the Little Ice Age\". A novel 3,000-year temperature reconstruction method, based on the rate of stalagmite growth in a cold cave in South Africa, further suggests a cold period from 1500 to 1800 \"characterizing the South African Little Ice Age\". The \u03b418O stalagmite record temperature reconstruction over a 350-year period (1690\u20131740) suggests that South Africa may have been the coldest region in Africa and have cooled by as much as 1.4\u00a0\u00b0C in summer. Also, the solar magnetic and Ni\u00f1o-Southern Oscillation cycles may have been key drivers of climate variability in the subtropical region. Periglacial features in the eastern Lesotho Highlands might have been reactivated by the Little Ice Age. Another archaeological reconstruction of Southern Africa reveals the rise of Great Zimbabwe because of ecological advantages from the increased rainfall over other competitor societies, such as the Mapungubwe. Pollen records derived from rock hyrax middens in the Cederberg Mountains of southwestern South Africa indicate an increase in humidity in the region at the start of the LIA.\nOther than temperature variability, data from equatorial East Africa suggest impacts to the hydrologic cycle in the late 1700s. Historical data reconstructions from ten major African lakes indicate that an episode of *drought and desiccation\" occurred throughout East Africa. The period showed drastic reductions in the depths of lakes, which were transformed into desiccated puddles. It is very likely that locals could cross Lake Chad, among others, and that bouts of \"intense droughts were ubiquitous\". That indicates local societies were probably launched into long migrations and warfare with neighboring tribes, since agriculture was made virtually useless by the dry soil.\nAntarctica.\nKreutz et al. (1997) compared results from studies of West Antarctic ice cores with the Greenland Ice Sheet Project Two GISP2; they suggested a synchronous global cooling. An ocean sediment core from the eastern Bransfield Basin in the Antarctic Peninsula shows centennial events, which the authors link to the Little Ice Age and to the Medieval Warm Period. The authors note that \"other unexplained climatic events comparable in duration and amplitude to the LIA and MWP events also appear\".\nThe Siple Dome (SD) had a climate event with an onset time that is coincident with that of the Little Ice Age in the North Atlantic, based on a correlation with the GISP2 record. The Little Ice Age is the most dramatic climate event in the SD Holocene glaciochemical record. The Siple Dome ice core also contained its highest rate of melt layers (up to 8%) between 1550 and 1700, most likely because of warm summers. Law Dome ice cores show lower levels of CO2 mixing ratios from 1550 to 1800, which Etheridge and Steele believe to be \"probably as a result of colder global climate\".\nSediment cores in Bransfield Basin, Antarctic Peninsula, have neoglacial indicators by diatom and sea-ice taxa variations during the Little Ice Age. Stable isotope records from the Mount Erebus Saddle ice core site suggests that the Ross Sea region experienced average temperatures 1.6 \u00b1 1.4\u00a0\u00b0C cooler during the Little Ice Age than the last 150 years.\nAustralia and New Zealand.\nDue to its location in the Southern Hemisphere, Australia did not experience a regional cooling like that of Europe or North America. Instead, the Australian Little Ice Age was characterized by humid, rainy climates, which were followed by drying and aridification in the 19th century.\nAs studied by Tibby et al. (2018), lake records from Victoria, New South Wales, and Queensland suggest that conditions in the east and the south-east of Australia were wet and unusually cool from the 16th to the early 19th centuries. That corresponds with the \"peak\" of the global Little Ice Age from 1594 to 1722. For example, North Stradbroke Island's Swallow Lagoon data reveals a period of persistent wetness from 1500 to 1850 CE (exceeding 300 mm above average), followed by a significant decrease in rainfall after 1891. The rainfalls significantly reduced after around 1890. Similarly, the hydrological records of Lake Surprise's salinity levels reveal high humidity levels around from 1440 to 1880, and an increase in salinity from 1860 to 1880 points to a negative change to the once-humid climate. The mid-19th century marked a notable change to eastern Australia's rainfall and humidity patterns.\nTibby et al. (2018) note that in eastern Australia, the paleoclimatic changes of the Little Ice Age in the late 1800s coincided with the agricultural changes resulting from European colonization. After the 1788 establishment of British colonies in the Australia, which were concentrated primarily in the eastern regions and cities like Sydney and later Melbourne and Brisbane, the British introduced new agricultural practices like pastoralism. Such practices required widespread deforestation and clearance of vegetation. Pastoralism and the clearing of land are captured in works of art such as the 1833 painting by the prominent landscape artist John Glover \"Patterdale Landscape with Cattle\".\nOver the next century, the deforestation led to a loss of biodiversity, wind and water-based soil erosion, and soil salinity. Furthermore, as argued by Gordan et al. (2003), such land and vegetation clearance in Australia resulted in a 10% reduction in the transport of water vapor to the atmosphere. That occurred in Western Australia as well, where 19th-century land clearing resulted in reduced rainfall over the region. By 1850 to 1890, those human agricultural practices, which were concentrated in eastern Australia, had most likely amplified the drying and aridification that marked the end of the Little Ice Age.\nIn the north, evidence suggests fairly dry conditions, but coral cores from the Great Barrier Reef show rainfall similar to today but with less variability. A study that analyzed isotopes in Great Barrier Reef corals suggested that increased water vapor transport from the southern tropical oceans to the poles contributed to the Little Ice Age. Borehole reconstructions from Australia suggest that over the last 500 years, the 17th century was the coldest on the continent. The borehole temperature reconstruction method further indicates that the warming of Australia over the past five centuries is only around half that of the warming experienced by the Northern Hemisphere, which further proves that Australia did not reach the same depths of cooling as the continents in the north.\nOn the west coast of the Southern Alps of New Zealand, the Franz Josef Glacier advanced rapidly during the Little Ice Age and reached its maximum extent in the early 18th century. That was one of the few cases of a glacier thrusting into a rainforest. Evidence suggests, corroborated by tree ring proxy data, that the glacier contributed to a temperature anomaly over the course of the Little Ice Age in New Zealand. Based on dating of a yellow-green lichen of the \"Rhizocarpon\" subgenus, the Mueller Glacier, on the eastern flank of the Southern Alps within Aoraki / Mount Cook National Park, is considered to have been at its maximum extent between 1725 and 1730.\nPacific islands.\nSea-level data for the Pacific islands suggest that sea level in the region fell, possibly in two stages, between 1270 and 1475. That was associated with a 1.5\u00a0\u00b0C fall in temperature, as determined from oxygen-isotope analysis, and an observed increase in the frequency of El Ni\u00f1o. Tropical Pacific coral records indicate the most frequent and intense El Ni\u00f1o\u2013Southern Oscillation activity was in the mid-17th century. Foraminiferal 18 O records indicate that the Indo-Pacific Warm Pool was warm and saline between 1000 and 1400, with temperatures approximating current conditions, but that it cooled from 1400 onwards and reached its lowest temperatures in 1700. That is consistent with the transition from the mid-Holocene warming to the Little Ice Age. The nearby southwestern Pacific, however, experienced warmer-than-average conditions over the course of the Little Ice Age, which is thought to be from the increased trade winds, which increased the evaporation and the salinity in the region. The dramatic temperature differences between the higher latitudes and the equator are thought to have resulted in drier conditions in the subtropics. Independent multiproxy analyses of Raraku Lake (sedimentology, mineralology, organic and inorganic geochemistry, etc.) indicate that Easter Island was subject to two phases of arid climate that led to drought. The first occurred between 500 and 1200, and the second occurring during the Little Ice Age from 1570 to 1720. In between both arid phases, the island enjoyed a humid period from 1200 to 1570. That coincided with the peak of the Rapa Nui civilization.\nSouth America.\nTree-ring data from Patagonia show cold episodes from 1270 and 1380 and from 1520 to 1670, during the events in the Northern Hemisphere. Eight sediment cores taken from Puyehue Lake have been interpreted as showing a humid period from 1470 to 1700, which the authors describe as a regional marker of the onset of the Little Ice Age. A 2009 paper details cooler and wetter conditions in southeastern South America between 1550 and 1800 by citing evidence obtained via several proxies and models. 18O records from three Andean ice cores show a cool period from 1600 to 1800.\nAlthough it is only anecdotal evidence, the Antonio de Vea expedition entered San Rafael Lake in 1675 through R\u00edo T\u00e9mpanos (Spanish for \"Ice Floe River\"). The Spanish mentioned no ice floe but stated that the San Rafael Glacier did not reach far into the lagoon. In 1766, another expedition noticed that the glacier reached the lagoon and calved into large icebergs. Hans Steffen visited the area in 1898 and noticed that the glacier penetrated far into the lagoon. Such historical records indicate a general cooling in the area between 1675 and 1898: \"The recognition of the LIA in northern Patagonia, through the use of documentary sources, provides important, independent evidence for the occurrence of this phenomenon in the region.\" As of 2001, the borders of the glacier had significantly retreated from those of 1675.\nIt has been suggested that all glaciers of Gran Campo Nevado next to the Strait of Magellan reached their largest extent of the whole Holocene epoch during the Little Ice Age.\nIt has been proposed that the Little Ice Age, locally lasting from the 17th to the 19th centuries, may have decreased the productivity of marine ecosystems and the navigability of the Patagonian fjords and channels, being thus detrimental to the sea-faring Kaw\u00e9sqar.\nMiddle East.\nThe Ottoman Empire was one of the largest and most powerful empires in the world during this period, with territories in three continents and a range of climates and ecosystems. The Little Ice Age affected its economy, society, and culture from the early 14th century, as it rose from a small group of soldiers to a major world power, until the mid-19th century, with its most intense phase between the 16th and 17th centuries. The effects of the Little Ice Age on the Ottoman Empire were significant, leading to changes in agricultural practices, increased food prices, and social unrest. Each ancient Middle Eastern empire had a primary food-growing region: the Byzantines had Anatolia and Syria; the Abbasids had the lower Tigris-Euphrates region, Khurasan, and Bukhara; and the Ottomans had Egypt. The Ottoman Empire had grown and distributed sufficient grain along the Danube, the Black Sea, and the Nile. The cooling climate disrupted agriculture, shortening the growing season and decreasing crop yields, and led to food shortages and famines. This was exacerbated by extreme weather events, such as droughts, floods, and storms, which further reduced crop yields. \nIn 1265, 1277 and 1297\u20131298, Byzantine sources describe extreme cold, then harsh winters in 1298-1299 throughout the Middle East. This was followed by a drought in Asia Minor during 1302-1304, along with flooding on the Sangarious River in summer 1302. \nDue to the expansion of the Ottoman Empire in the late 16th century, the population of the empire reached around 30 million people, which led to a shortage of land and an increase in tax. The second half of the 16th century saw rising prices in both the Middle East and Europe. The large population and lack of supplies created a strain on the Ottoman government. \nDuring the 1590s, a wave of extremely cold winters began, and the longest drought in the Middle East in six centuries marked the beginning of the Little Ice Age. Settled peasants were unwilling or unable to leave their traditional lands during the climate shifts, and often rose into revolt against the established authorities, unlike nomads who could easily move. Nevertheless, the Little Ice Age led to significant migrations, as some regions became uninhabitable while others became more attractive, which changed the demographics and political economy of the empire.\nThe drought and cold led to a series of uprisings collectively known as the Celali Rebellion, c. 1596\u20131610. (In February 1621, the Bosphorus Strait in Istanbul froze over completely.) The rebellion became the longest-lasting internal challenge to state power in the Ottoman Empire's six centuries of existence. The demand of the rebels was not to overthrow the Ottoman government but to replace certain regional governors. The Ottoman Empire did not fully recover from the Little Ice Age for around a hundred years, and were left with a large population loss.\nCentral England temperature series.\nThe Central England temperature (CET) is the longest instrumental temperature record in existence anywhere in the world, and extends back continuously from the present day to 1659. Hence it starts in the middle of the Little Ice Age (LIA), however the LIA interval is defined. CET holds some very important implications for our understanding of the LIA. The CET data show that during the LIA there was an increased occurrence of exceptionally cold winters and these years coincided with years when frost fairs were held on the Thames and when exceptionally low temperatures were reported elsewhere in Europe. It also agrees well with paleoclimate estimates in average trends. However, winters were not unremittingly cold during the LIA in the CET record. For example, the coldest winter (defined by the average temperature for December, January and February) in the whole CET data series is 1684 (the year of one of the most famous frost fairs) yet the fifth warmest winter in the whole CET data series to date occurred just two years later, in 1686. Furthermore, summer temperatures are not greatly depressed during the LIA and when they are these lower temperatures correlate highly with volcanic eruptions. Hence the CET data strongly argue that the LIA, at least in Europe, should be regarded as a period of enhanced occurrence of exceptionally cold winters and hence lower average temperatures and not as an interval of unremitting cold.\nPossible causes.\nScientists have tentatively identified seven possible causes of the Little Ice Age: orbital cycles, decreased solar activity, increased volcanic activity, altered ocean current flows, fluctuations in the human population in different parts of the world causing reforestation or deforestation, and the inherent variability of global climate.\nOrbital cycles.\nOrbital forcing from cycles in the Earth's orbit around the Sun has for the past 2,000 years caused a long-term northern hemisphere cooling trend, which continued through the Middle Ages and the Little Ice Age. The rate of Arctic cooling is roughly 0.02\u00a0\u00b0C per century. That trend could be extrapolated to continue into the future and possibly lead to a full ice age, but the 20th-century instrumental temperature record shows a sudden reversal of that trend, with a rise in global temperatures attributed to greenhouse gas emissions.\nSolar activity.\nSolar activity includes any disturbances on the Sun such as sunspots and solar flares associated with the variable magnetic field of the solar surface and solar atmosphere (corona). Because Alfv\u00e9n's theorem applies, the coronal magnetic field is dragged out into the heliosphere by the solar wind. Irregularities in this heliospheric magnetic field shield Earth from galactic cosmic rays by scattering them, which allows scientists to track solar activity in the past by analyzing both the carbon-14 or beryllium-10 isotopes generated by cosmic rays hitting the atmosphere and which are deposited in terrestrial reservoirs such as tree rings and ice sheets. In the intervals 1400\u20131550 (the Sp\u00f6rer Minimum) and 1645\u20131715 (the Maunder Minimum) there were very low recorded levels of solar activity and they are both within, or at least overlapped with, the LIA for most definitions. However, solar activity deduced from cosmogenic isotopes was as high between the Sp\u00f6rer Minimum and the Maunder Minimum as it was in about 1940, yet this interval is also within the LIA. Hence any relationship between solar activity and the LIA is far from a simple one.\nA drop in solar activity circa 1230 AD as measured by biogenic silica corrected ignition residue (IR-BSi) has been suggested by one study as a forcing potentially responsible for initiating the LIA, with the authors noting that this drop in solar output preceded the onset of significant volcanism.\nA study by Dmitri Mauquoy et al. confirmed that at the beginning of the Sp\u00f6rer Minimum, the carbon-14 production rate rose rapidly. These authors argued this rise coincided with a sharp drop in temperatures deduced from European peat bogs. This temperature drop is also seen in mean northern hemisphere temperatures deduced from a wide variety of paleoclimate indicators but the timing of the onset of the Sp\u00f6rer Minimum is actually some 50 years earlier. A 50-year response lag is possible but is not consistent with subsequent variations in inferred solar activity and average northern hemisphere temperature. For example, the peak in solar activity between the Sp\u00f6rer Minimum and the Maunder Minimum is 50 years after the only peak in average northern hemisphere temperature that it could be associated with.\nA study by Judith Lean in 1999 also pointed to a relationship between the Sun and the Little Ice Age. Her research found that there was a 0.13% total solar irradiance (TSI) increase (1.8\u00a0Wm\u22121) over 1650\u20131790 which could have raised the temperature of the Earth by 0.3\u00a0\u00b0C. In the calculated correlation coefficients of the global temperature response to their reconstruction of the solar forcing over three different periods, they found an average coefficient of 0.79 (i.e. 62% of the variation could be explained by the TSI) which indicates a possible relationship between the two components. Lean's team also formulated an equation in which the temperature change is 0.16\u00a0\u00b0C increase in temperature for every 0.1% increase in total solar irradiance. However, the main problem with quantifying the longer-term trends in TSI lies in the stability of the absolute radiometry measurements made from space, which has improved since the pioneering work of Judith Lean discussed above, but still remains a problem. Analysis comparing trends in modern observations of TSI and cosmic ray fluxes shows that the uncertainties mean that it is possible that TSI was actually higher in the Maunder Minimum than present-day levels, but uncertainties are high with best estimates of the difference between the modern-day TSI and the Maunder-Minimum TSI in the range \u00b10.5\u00a0Wm\u22121 but with a 2\u00a0\u03c3 uncertainty range of \u00b11\u00a0Wm\u22121.\nAt the center of the LIA, during the Sp\u00f6rer Minimum and the Maunder Minimum, sunspots were minimal and cosmogenic isotope deposition (carbon-14 and beryllium-10) was increased in these minima as a result. However, detailed studies from multiple paleoclimate indicators show that the lower Northern Hemisphere temperatures in the Little Ice Age began before the start of the Maunder Minimum but after the start of the Sp\u00f6rer Minimum and persisted until after the Maunder Minimum (and even after the much weaker Dalton Minimum) had ceased. The return to more active solar conditions between these two grand solar minima had no obvious effect on either global or Northern Hemisphere temperatures. The Central England Temperature provide evidence that low solar activity may have contributed to the LIA through the increased occurrence of cold winters, at least in Europe, but colder summers are more correlated with volcanic activity. Comparison of TSI records with Greenland ice core \u03b418O trends suggests that solar activity only accounted for 55% of the observed trend variance. Numerical climate modelling indicates that volcanic activity was the greater driver of the overall lower temperatures in the LIA, as seen in a variety of paleoclimate proxies.\nVolcanic activity.\nIn a 2012 paper, Miller \"et al.\" link the Little Ice Age to an \"unusual 50-year-long episode with four large sulfur-rich explosive eruptions, each with global sulfate loading &gt;60 Tg\" and notes that \"large changes in solar irradiance are not required.\"\nThroughout the LIA, there was heightened volcanic activity. When a volcano erupts, its ash reaches high into the atmosphere and can spread to cover the whole earth. The ash cloud blocks out some of the incoming solar radiation, which leads to worldwide cooling for up to two years after an eruption. Also emitted by eruptions is sulfur in the form of sulfur dioxide. When sulfur dioxide reaches the stratosphere, the gas turns into sulfuric and sulfurous acid particles, which reflect the Sun's rays. That further reduces the amount of radiation reaching the Earth's surface.\nA recent study found that an especially severe tropical volcanic eruption in 1257, possibly Mount Samalas (pre-caldera edifice of the active Rinjani) near Mount Rinjani, both in Lombok, Indonesia, followed by three smaller eruptions in 1268, 1275, and 1284, did not allow the climate to recover. That may have caused the initial cooling, and the 1452/1453 mystery eruption triggered a second pulse of cooling. The cold summers can be maintained by sea-ice/ocean feedbacks long after volcanic aerosols are removed.\nOther volcanoes that erupted during the era and may have contributed to the cooling include Billy Mitchell (c.\u00a01580), Huaynaputina (1600), Mount Parker (1641), Long Island (Papua New Guinea) (ca.\u00a01660), and Laki (1783). The 1815 eruption of Tambora, also in Indonesia, blanketed the atmosphere with ash, and the following year came to be known as the Year Without a Summer, when frost and snow were reported in June and July in both New England and Northern Europe.\nOcean circulation.\nIn the early 2000s, a slowing of thermohaline circulation was proposed as an explanation for the LIA, specifically, through the weakening of the North Atlantic Gyre. The circulation could have been interrupted by the introduction of a large amount of fresh water into the North Atlantic and might have been caused by a period of warming before the LIA that is known as the Medieval Warm Period. Some researchers have thus classified the LIA as a Bond event. In 2005 there was some concern that a shutdown of thermohaline circulation could happen again as a result of the present warming.\nMore recent research indicates that the overall Atlantic Meridional Overturning Circulation may already be weaker now than it was during the LIA, or perhaps even over the past millennium. While there is still a robust debate about the present-day AMOC strength, these findings make the link between AMOC and the LIA unlikely. However, some research instead suggests that a far more localized disruption of the North Subpolar Gyre convection was involved in the LIA. This is potentially relevant for the near future, as a minority of climate models project a permanent collapse of this convection under some scenarios of future climate change.\nThe Black Death in Europe.\nThe Black Death is estimated to have killed 30% to 60% of the European population. In total, the plague may have reduced the world population from an estimated 475 million to 350\u2013375 million in the 14th century. It took 200 years for the world population to recover to its previous level. William Ruddiman \"et al.\" proposed that those large population reductions in Europe, East Asia, and the Middle East caused a decrease in agricultural activity that allowed reforestation to cause additional carbon dioxide uptake from the atmosphere, leading to LIA cooling.\nMongol invasions.\nA 2011 study by the Carnegie Institution's Department of Global Ecology asserts that the Mongol invasions and conquests, which lasted almost two centuries, contributed to global cooling by depopulating vast regions and replacing cultivated land by carbon-absorbing forest.\nDestruction of native populations and biomass of the Americas.\nWilliam Ruddiman further hypothesized that a reduced population in the Americas after European contact started in the 16th century could have had a similar effect. Similarly, Koch and others in 1990 suggested that as European conquest and disease brought by Europeans killed as many as 90% of Indigenous Americans, around 50 million hectares of land may have returned to a wilderness state, causing increased carbon dioxide uptake. Other researchers have supported depopulation in the Americas as a factor and have asserted that humans cleared considerable amounts of forest to support agriculture there before the arrival of Europeans brought on a population collapse.\nRichard Nevle, Robert Dull and colleagues further suggested not only that anthropogenic forest clearance played a role in reducing the amount of carbon sequestered in Neotropical forests but also that human-set fires played a central role in reducing biomass in Amazonian and Central American forests before the arrival of the Europeans and the concomitant spread of diseases during the Columbian exchange. Dull and Nevle calculated that reforestation in the tropical biomes of the Americas alone from 1500 to 1650 accounted for net carbon sequestration of 2\u20135 Pg. Brierley conjectured that the European arrival in the Americas caused mass deaths from epidemic disease, which caused much abandonment of farmland. That caused much forest to return, which sequestered more CO2. A study of sediment cores and soil samples further suggests that CO2 uptake via reforestation in the Americas could have contributed to the LIA. The depopulation is linked to a drop in CO2 levels observed at Law Dome, Antarctica.\nHowever, the hypothesis is criticized on the grounds that the kind of agroforestry practiced by the pre-Columbian farmers in South America did not actually result in a large-scale deforestation typical for modern agriculture so the reforestation should not have had such a huge effect.\nInherent variability of climate.\nSpontaneous fluctuations in global climate might explain the past variability. It is very difficult to know what the true level of variability from internal causes might be given the existence of other forces, as noted above, whose magnitude may not be known. One approach to evaluating internal variability is the use of long integrations of coupled ocean-atmosphere global climate models. They have the advantage that the external forcing is known to be zero, but the disadvantage is that they may not fully reflect reality. The variations may result from chaos-driven changes in the oceans, the atmosphere, or interactions between the two. Two studies have concluded that the demonstrated inherent variability was not great enough to account for the Little Ice Age. The severe winters of 1770 to 1772 in Europe, however, have been attributed to an anomaly in the North Atlantic oscillation.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36787", "revid": "51008662", "url": "https://en.wikipedia.org/wiki?curid=36787", "title": "Budapest", "text": "Capital and largest city of Hungary\nBudapest is the capital and most populous city of Hungary. It is Hungary's primate city with 1.7 million inhabitants and its greater metro area has a population of about 3.3 million, representing one-third of the country's population and producing above 40% of the country's economic output. Budapest is the political, economic, and cultural center of the country, among the ten largest cities in the European Union and the second largest urban area in Central and Eastern Europe. Budapest stands on the River Danube and is strategically located at the center of the Pannonian Basin, lying on ancient trade routes linking the hills of Transdanubia with the Great Plain.\nBudapest is a global city, consistently ranked among the 50 most important cities in the world, belongs to the narrow group of cities with a GDP over US$100 billion, named a global cultural capital as having high-quality human capital, and is among the 35 most liveable cities in the world. The city is home to over 30 universities with more than 150,000 students, most of them attending large public research universities that are highly ranked worldwide in their fields, such as E\u00f6tv\u00f6s Lor\u00e1nd University in natural sciences, Budapest University of Technology in engineering and technology, MATE in life sciences, and Semmelweis University in medicine. Budapest also hosts various international organizations, including several UN agencies, the WHO Budapest Centre, IOM regional centre, the EU headquarters of EIT and CEPOL, as well as the first foreign office of China Investment Agency. Budapest opened the first underground transit line on the European continent in 1896, which is still in use as M1 Millennium Underground, and today the fixed-track metro and tram network forms the backbone of Budapest's public transport system and transports 2.2 million people daily, making it a significant urban transit system.\nThe history of Budapest began with an early Celtic settlement transformed by the Romans into the town of Aquincum, capital of Lower Pannonia in the 1st century. Following the foundation of Hungary in the late 9th century, the area was pillaged by the Mongols in 1241. It became royal seat in 1361, with Buda becoming one of the European centers of renaissance culture by the 15th century under Matthias Corvinus. The siege of Buda in 1541 was followed by nearly 150 years of Ottoman rule, and after the reconquest of Buda in 1686, the region entered a new age of prosperity, with Pest-Buda becoming a global city after the unification of Buda, Pest and \u00d3buda in 1873. By this time, Budapest had become the co-capital of the Austro-Hungarian Empire, a great power that dissolved in 1918 following World War I. The city was also the focal point of the Hungarian Revolution of 1848, Battle of Budapest in 1945, and Hungarian Revolution of 1956.\nThe historic center of Budapest along the Danube is classified as a World Heritage Site due to its numerous notable monuments of classical architecture, from the 13th-century Matthias Church to 19th-century landmarks such as Hungarian Parliament, State Opera House, the Museum of Fine Arts and St. Stephen's Basilica. Budapest has been a popular spa destination since Roman times and is considered the spa capital of Europe, with more than 100 medicinal geothermal springs and the largest thermal water cave system. The city is home to the second-largest synagogue and third-largest parliament building in the world, , nearly ten Michelin-starred restaurants, and named among the 50 best food cities globally for its focus on distinctive Hungarian cuisine. Budapest is also renowned for its nightlife, with ruin bars playing a significant role in it, moreover the city has become a center for Hollywood film production in recent years. Budapest regularly hosts , with the practically 70,000-seat Pusk\u00e1s Ar\u00e9na serving as one of the venues, which hosted most recently the 2023 UEFA Europa League final, 2020 UEFA Super Cup, will host 2026 UEFA Champions League final and city hosted the 2023 World Athletics Championships, 2017 and 2022 World Aquatics Championships. Budapest attracted 6 million international overnight visitors in 2024, making it one of the most popular destinations in Europe.\nEtymology and pronunciation.\nThe previously separate cities of Buda, \u00d3buda, and Pest were officially unified in 1873 and given the new name \"Budapest\". Before this, the towns together had sometimes been referred to colloquially as \"Pest-Buda\". \"Pest\" is often used \"pars pro toto\" for the entire city in contemporary colloquial Hungarian, although it is also used to refer to all parts of the city east of the Danube. Conversely, \"Buda\" colloquially means all districts to the Danube's west\u2014including the former \u00d3buda. The Danube islands\u2014including Csepel, the city's XXI. district\u2014are part of neither Buda nor Pest.\nAll varieties of English pronounce the \"-s-\" as in the English word \"pest\". The \"-u\" in \"Buda-\" is pronounced either /u/ like \"food\" (as in ) or /ju/ like \"cue\" (as in ). In Hungarian, the \"-s-\" is pronounced /\u0283/ as in \"wash\"; in IPA: .\nThe origins of the names \"Buda\" and \"Pest\" are obscure. Buda was\nLinguistically, however, a German origin through the Slavic derivative \u0432\u043e\u0434\u0430 (\"voda\", water) is not possible, and there is no certainty that a Turkic word really comes from the word \"buta\" ~ \"buda\" 'branch, twig'.\nAccording to a legend recorded in chronicles from the Middle Ages, \"Buda\" comes from the name of its founder, Bleda, brother of Hunnic ruler Attila.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Attila went in the city of Sicambria in Pannonia, where he killed Buda, his brother, and he threw his corpse into the Danube. For while Attila was in the west, his brother crossed the boundaries in his reign, because he named Sicambria after his own name Buda's Castle. And though King Attila forbade the Huns and the other peoples to call that city Buda's Castle, but he called it Attila's Capital, the Germans who were terrified by the prohibition named the city as Eccylburg, which means Attila Castle, however, the Hungarians did not care about the ban and call it \u00d3buda [Old Buda] and call it to this day.\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Scythians are certainly an ancient people and the strength of Scythia lies in the east, as we said above. And the first king of Scythia was Magog, son of Japhet, and his people were called Magyars [Hungarians] after their King Magog, from whose royal line the most renowned and mighty King Attila descended, who, in the 451st year of Our Lord's birth, coming down from Scythia, entered Pannonia with a mighty force and, putting the Romans to flight, took the realm and made a royal residence for himself beside the Danube above the hot springs, and he ordered all the old buildings that he found there to be restored and he built them in a circular and very strong wall that in the Hungarian language is now called Budav\u00e1r [Buda Castle] and by the Germans Etzelburg [Attila Castle]\u2014\u200a\nThere are several theories about Pest. One states that the name derives from Roman times, since there was a local fortress (Contra-Aquincum) called by Ptolemy \"Pession\" (\"\u03a0\u03ad\u03c3\u03c3\u03b9\u03bf\u03bd\", iii.7.\u00a7\u00a02). Another has it that Pest originates in the Slavic word for cave, \"\u043f\u0435\u0449\u0435\u0440\u0430\", or \"pe\u0161tera\". A third cites \"\u043f\u0435\u0449\", or \"pe\u0161t\", referencing a cave where fires burned or a limekiln.\nHistory.\nEarly history.\nThe first settlement on the territory of Budapest was built by Celts before 1\u00a0AD. It was later occupied by the Romans. The Roman settlement \u2013 Aquincum \u2013 became the main city of Pannonia Inferior in 106\u00a0AD. At first it was a military settlement, and gradually the city rose around it, making it the focal point of the city's commercial life. Today this area corresponds to the \u00d3buda district within Budapest. The Romans constructed roads, amphitheaters, baths and houses with heated floors in this fortified military camp. The Roman city of Aquincum is the best-conserved of the Roman sites in Hungary. The archaeological site was turned into a museum with indoor and open-air sections. Meanwhile, settlement in the area east of the Danube, which was not part of the Roman Empire, remained Germanic and Sarmatian in character.\nThe Magyar tribes led by \u00c1rp\u00e1d, forced out of their original homeland north of Bulgaria by Tsar Simeon after the Battle of Southern Buh, settled in the territory at the end of the 9th century displacing the founding Bulgarian settlers of the towns of Buda and Pest, and a century later officially founded the Kingdom of Hungary. Research places the probable residence of the \u00c1rp\u00e1ds as an early place of central power near what became Budapest. The Mongol invasion in the 13th century quickly proved it is difficult to defend a plain. King B\u00e9la IV of Hungary, therefore, ordered the construction of reinforced stone walls around the towns and set his own royal palace on the top of the protecting hills of Buda. German settlers were invited to rebuild and inhabit both Buda and Pest. In 1361 it became the capital of Hungary.\nThe cultural role of Buda was particularly significant during the reign of King Matthias Corvinus. The Italian Renaissance had a great influence on the city. His library, the Bibliotheca Corviniana, was Europe's greatest collection of historical chronicles and philosophic and scientific works in the 15th century, and second in size only to the Vatican Library. After the foundation of the first Hungarian university in P\u00e9cs in 1367 (University of P\u00e9cs), the second one was established in \u00d3buda in 1395 (University of \u00d3buda). The first Hungarian book was printed in Buda in 1473. Buda had about 5,000 inhabitants around the year 1500.\nThe Ottomans conquered Buda in 1526, as well as in 1529, and finally occupied it in 1541. The Ottoman Rule lasted for more than 150 years. The Ottoman Turks constructed many prominent bathing facilities within the city. Some of the baths that the Turks erected during their rule are still in use 500 years later, including Rudas Baths and Kir\u00e1ly Baths. By 1547 the number of Christians was down to about a thousand, and by 1647 it had fallen to only about seventy. \nContemporary history after Unification.\nThe 19th century was dominated by the Hungarian struggle for independence and modernisation. The national insurrection against the Habsburgs began in the Hungarian capital in 1848 and was defeated one and a half years later, with the help of the Russian Empire. 1867 was the year of Reconciliation that brought about the birth of Austria-Hungary. This made Budapest the twin capital of a dual monarchy. It was this compromise which opened the second great phase of development in the history of Budapest, lasting until World War I. In 1849 the Chain Bridge linking Buda with Pest was opened as the first permanent bridge across the Danube and in 1873 Buda and Pest were officially merged with the third part, \u00d3buda (Old Buda), thus creating the new metropolis of Budapest. The dynamic Pest grew into the country's administrative, political, economic, trade and cultural hub. Ethnic Hungarians overtook Germans in the second half of the 19th century due to mass migration from the overpopulated rural Transdanubia and Great Hungarian Plain. Between 1851 and 1910 the proportion of Hungarians increased from 35.6% to 85.9%, Hungarian became the dominant language, and German was crowded out. The proportion of Jews peaked in 1900 with 23.6%. Due to the prosperity and the large Jewish community of the city at the start of the 20th century, Budapest was often called the \"Jewish Mecca\" or \"Judapest\". Budapest also became an important center for the Aromanian diaspora during the 19th century. In 1918, Austria-Hungary lost the war and collapsed; Hungary declared itself an independent republic (Republic of Hungary). In 1920 the Treaty of Trianon partitioned the country, and as a result, Hungary lost over two-thirds of its territory, and about two-thirds of its inhabitants, including 3.3\u00a0million out of 15 million ethnic Hungarians.\nIn 1944, a year before the end of World War II, Budapest was partly destroyed by British and American air raids (first attack 4 April 1944). From 24 December 1944 to 13 February 1945, the city was besieged during the Battle of Budapest. Budapest sustained major damage caused by the attacking Soviet and Romanian troops and the defending German and Hungarian troops. More than 38,000 civilians died during the conflict. All bridges were destroyed by the Germans. The stone lions that have decorated the Chain Bridge since 1852 survived the devastation of the war.\nBetween 20% and 40% of Greater Budapest's 250,000 Jewish inhabitants died through Nazi and Arrow Cross Party, during the German occupation of Hungary, from 1944 to early 1945. \nSwiss diplomat Carl Lutz rescued tens of thousands of Jews by issuing Swiss protection papers and designating numerous buildings, including the now famous Glass House (\u00dcvegh\u00e1z) at Vad\u00e1sz Street 29, to be Swiss protected territory. About 3,000 Hungarian Jews found refuge at the Glass House and in a neighboring building. Swedish diplomat Raoul Wallenberg saved the lives of tens of thousands of Jews in Budapest by giving them Swedish protection papers and taking them under his consular protection. Wallenberg was abducted by the Russians on 17 January 1945 and never regained freedom. Giorgio Perlasca, an Italian citizen, saved thousands of Hungarian Jews posing as a Spanish diplomat. Some other diplomats also abandoned diplomatic protocol and rescued Jews. There are two monuments for Wallenberg, one for Carl Lutz and one for Giorgio Perlasca in Budapest.\nFollowing the capture of Hungary from Nazi Germany by the Red Army, Soviet military occupation ensued, which ended only in 1991. The Soviets exerted significant influence on Hungarian political affairs. In 1949, Hungary was declared a communist People's Republic (People's Republic of Hungary). The new Communist government considered the buildings like the Buda Castle symbols of the former regime, and during the 1950s the palace was gutted and all the interiors were destroyed (also see Stalin era). On 23 October 1956 citizens held a large peaceful demonstration in Budapest demanding democratic reform. The demonstrators went to the Budapest radio station and demanded to publish their demands. The regime ordered troops to shoot into the crowd. Hungarian soldiers gave rifles to the demonstrators who were now able to capture the building. This initiated the Hungarian Revolution of 1956. The demonstrators demanded to appoint Imre Nagy to be Prime Minister of Hungary. To their surprise, the central committee of the \"Hungarian Working People's Party\" did so that same evening. This uprising was an anti-Soviet revolt that lasted from 23 October until 11 November. After Nagy had declared that Hungary was to leave the Warsaw Pact and become neutral, Soviet tanks and troops entered the country to crush the revolt. Fighting continued until mid November, leaving more than 3000 dead. A monument was erected at the fiftieth anniversary of the revolt in 2006, at the edge of the City Park. Its shape is a wedge with a 56 angle degree made in rusted iron that gradually becomes shiny, ending in an intersection to symbolize Hungarian forces that temporarily eradicated the Communist leadership.\nFrom the 1960s to the late 1980s Hungary was often satirically referred to as \"the happiest barrack\" within the Eastern bloc, and much of the wartime damage to the city was finally repaired. Work on Erzs\u00e9bet Bridge, the last to be rebuilt, was finished in 1964. In the early 1970s, Budapest Metro's east\u2013west M2 line was first opened, followed by the M3 line in 1976. In 1987, Buda Castle and the banks of the Danube were included in the UNESCO list of World Heritage Sites. Andr\u00e1ssy Avenue (including the Millennium Underground Railway, H\u0151s\u00f6k tere, and V\u00e1rosliget) was added to the UNESCO list in 2002. In the 1980s, the city's population reached 2.1\u00a0million. In recent times a significant decrease in population occurred mainly due to a massive movement to the neighbouring agglomeration in Pest county, i.e., suburbanisation.\nIn the last decades of the 20th century the political changes of 1989\u201390 (Fall of the Iron Curtain) concealed changes in civil society and along the streets of Budapest. The monuments of the dictatorship were removed from public places, into Memento Park. In the first 20 years of the new democracy, the development of the city was managed by its mayor, G\u00e1bor Demszky.\nIn October 2019, opposition candidate Gergely Kar\u00e1csony won the Budapest mayoral election, meaning the first electoral blow for Hungary's nationalist prime minister Viktor Orb\u00e1n since coming to power in 2010.\nGeography.\nTopography.\nBudapest, strategically placed at the centre of the Pannonian Basin, lies on an ancient route linking the hills of Transdanubia with the Great Plain. By road it is south-east of Vienna, south of Warsaw, south-west of Moscow, north of Athens, north-east of Rome, north-east of Milan, south-east of Prague, north-east of Zagreb, north-east of Split and north-west of Istanbul.\nThe area of Budapest lies in Central Hungary, surrounded by settlements of the agglomeration in Pest county. The capital extends in the north\u2013south, east\u2013west direction respectively. The Danube enters the city from the north; later it encircles two islands, \u00d3buda Island and Margaret Island. The third island Csepel Island is the largest of the Budapest Danube islands, however only its northernmost tip is within city limits. The river that separates the two parts of the city is wide at its narrowest point in Budapest. Pest lies on the flat terrain of the Great Plain while Buda is rather hilly.\nThe wide Danube was always fordable at this point because of a small number of islands in the middle of the river. The city has marked topographical contrasts: Buda is built on the higher river terraces and hills of the western side, while the considerably larger Pest spreads out on a flat and featureless sand plain on the river's opposite bank. Pest's terrain rises with a slight eastward gradient, so the easternmost parts of the city lie at the same altitude as Buda's smallest hills, notably Gell\u00e9rt Hill and Castle Hill.\nThe Buda hills consist mainly of limestone and dolomite, the water created speleothems, the most famous ones being the P\u00e1lv\u00f6lgyi cave (total length ) and the Szeml\u0151hegyi cave (total length ). The hills were formed in the Triassic Period. The highest point of the hills and of Budapest is J\u00e1nos Hill, at above sea level. The lowest point is the line of the Danube which is above sea level. Budapest is also rich in green areas. Of the occupied by the city, is green area, park and forest. The forests of Buda hills are environmentally protected.\nThe city's importance in terms of traffic is very central, because many major European roads and European railway lines lead to Budapest. The Danube was and is still an important water-way and this region in the centre of the Carpathian Basin lies at the cross-roads of trade routes. Budapest is one of only three capital cities in the world which has thermal springs (the others being Reykjav\u00edk in Iceland and Sofia in Bulgaria). Some 125 springs produce of thermal water a day, with temperatures ranging up to 58\u00a0\u00b0C. Some of these waters have been claimed to have medicinal effects due to their high mineral contents.\nClimate.\nBudapest has a transitional climate between a humid temperate climate (K\u00f6ppen: \"Cfa\", Trewartha: \"Doak\"), and a humid continental climate (K\u00f6ppen: \"Dfa\", Trewartha: \"Dcao\"), with warm to hot summers and chilly winters. Winter (November until early March) can be cold and the city receives little sunshine. Snowfall is fairly frequent in most years, and nighttime temperatures of are not uncommon between mid-December and mid-February. The spring months (March and April) see variable conditions, with a rapid increase in the average temperature. The weather in late March and in April is often very agreeable during the day and fresh at night. Budapest's long summer \u2013 lasting from May until mid-September \u2013 is warm or very warm. Sudden heavy showers also occur, particularly in May and June. The autumn in Budapest (mid-September until late October) is characterised by little rain and long sunny days with moderate temperatures. Temperatures often turn abruptly colder in late October or early November.\nMean annual precipitation in Budapest is around . On average, there are 84 days with precipitation and 1988 hours of sunshine (of a possible 4383) each year. The city lies on the boundary between Zone 6 and Zone 7 in terms of the hardiness zone.\nArchitecture.\nBudapest has architecturally noteworthy buildings in a wide range of styles and from distinct time periods, from the ancient times as Roman City of Aquincum in \u00d3buda (District III), which dates to around 89 AD, to the most modern Palace of Arts, the contemporary arts museum and concert hall.\nMost buildings in Budapest are relatively low: in the early 2010s there were around 100 buildings higher than . The number of high-rise buildings is kept low by building legislation, which is aimed at preserving the historic cityscape and to meet the requirements of the World Heritage Site. Strong rules apply to the planning, authorisation and construction of high-rise buildings and consequently much of the inner city does not have any. Some planners would like to see an easing of the rules for the construction of skyscrapers, and the possibility of building skyscrapers outside the city's historic core has been raised.\nIn the chronological order of architectural styles Budapest is represented on the entire timeline, starting with the Roman City of Aquincum representing ancient architecture.\nThe next determinative style is the Gothic architecture in Budapest. The few remaining Gothic buildings can be found in the Castle District. Buildings of note are no. 18, 20 and 22 on Orsz\u00e1gh\u00e1z Street, which date back to the 14th century and No. 31 \u00dari Street, which has a Gothic fa\u00e7ade that dates back to the 15th century. Other buildings with Gothic features are the Inner City Parish Church, built in the 12th century, and the Mary Magdalene Church, completed in the 15th century. The most characteristic Gothic-style buildings are actually Neo-Gothic, like the most well-known Budapest landmarks, the Hungarian Parliament Building and the Matthias Church, where much of the original material was used (originally built in Romanesque style in 1015).\nThe next chapter in the history of human architecture is Renaissance architecture. One of the earliest places to be influenced by the Renaissance style of architecture was Hungary, and Budapest in particular. The style appeared following the marriage of King Matthias Corvinus and Beatrice of Naples in 1476. Many Italian artists, craftsmen and masons came to Buda with the new queen. Today, many of the original renaissance buildings disappeared during the varied history of Buda, but Budapest is still rich in renaissance and neo-renaissance buildings, like the famous Hungarian State Opera House, St. Stephen's Basilica and the Hungarian Academy of Sciences.\nDuring the Turkish occupation (1541\u20131686), Islamic culture flourished in Budapest; multiple mosques and baths were built in the city. These were great examples of Ottoman architecture, which was influenced by Muslims from around the world including Turkish, Iranian, Arabian and to a larger extent, Byzantine architecture as well as Islamic traditions. After the Holy League conquered Budapest, they replaced most of the mosques with churches and minarets were turned into bell towers and cathedral spires. At one point the distinct sloping central square in Budapest became a bustling Oriental bazaar, which was filled with \"the chatter of camel caravans on their way to Yemen and India\". Budapest is in fact one of the few places in the world with functioning original Turkish bathhouses dating back to the 16th century, like Rudas Baths or Kir\u00e1ly Baths. Budapest is home to the northernmost place where the tomb of influential Islamic Turkish Sufi Dervish, G\u00fcl Baba is found. Various cultures converged in Hungary seemed to coalesce well with each other, as if all these different cultures and architecture styles are digested into Hungary's own way of cultural blend. A precedent to show the city's self-conscious is the top section of the city's main square, named as Szechenyi. When Turks came to the city, they built mosques here which was aggressively replaced with Gothic church of St. Bertalan. The rationale of reusing the base of the former Islamic building mosque and reconstruction into Gothic Church but Islamic style architecture over it is typically Islamic are still visible. An official term for the rationale is spolia. The mosque was called the djami of Pasha Gazi Kassim, and djami means congregational or Friday mosque in Arabic. After Turks and Muslims were expelled and massacred from Budapest, the site was reoccupied by Christians and reformed into a church, the Inner City Parish Church (Budapest). The minaret and Turkish entranceway were removed. The shape of the architecture is its only hint of exotic past\u2014\"two surviving prayer niches facing Mecca and an ecumenical symbol atop its cupola: a cross rising above the Turkish crescent moon\".\nAfter 1686, the Baroque architecture designated the dominant style of art in catholic countries from the 17th century to the 18th century. There are many Baroque-style buildings in Budapest and one of the finest examples of preserved Baroque-style architecture is the Church of St. Anna in Batthyh\u00e1ny square. An interesting part of Budapest is the less touristy \u00d3buda, the main square of which also has some beautiful preserved historic buildings with Baroque fa\u00e7ades. The Castle District is another place to visit where the best-known landmark Buda Royal Palace and many other buildings were built in the Baroque style.\nThe Classical architecture and Neoclassical architecture are the next in the timeline. Budapest had not one but two architects that were masters of the Classicist style. Mih\u00e1ly Pollack (1773\u20131855) and J\u00f3zsef Hild (1789\u20131867), built many beautiful Classicist-style buildings in the city. Some of the best examples are the Hungarian National Museum, the Lutheran Church of Budav\u00e1r (both designed by Pollack) and the seat of the Hungarian president, the S\u00e1ndor Palace. The most iconic and widely known Classicist-style attraction in Budapest is the Sz\u00e9chenyi Chain Bridge. Budapest's two most beautiful Romantic architecture buildings are the Great Synagogue in Doh\u00e1ny Street and the Vigad\u00f3 Concert Hall on the Danube Promenade, both designed by architect Frigyes Feszl (1821\u20131884). Another noteworthy structure is the Budapest Western Railway Station, which was designed by August de Serres and built by the Eiffel Company of Paris in 1877.\nArt Nouveau came into fashion in Budapest by the exhibitions which were held in and around 1896 and organised in connection with the Hungarian Millennium celebrations. Art Nouveau in Hungary (\"Szecesszi\u00f3\" in Hungarian) is a blend of several architectural styles, with a focus on Hungary's specialities. One of the leading Art Nouveau architects, \u00d6d\u00f6n Lechner (1845\u20131914), was inspired by Indian and Syrian architecture as well as traditional Hungarian decorative designs. One of his most beautiful buildings in Budapest is the Museum of Applied Arts. Another examples for Art Nouveau in Budapest is the Gresham Palace in front of the Chain Bridge, the Hotel Gell\u00e9rt, the Franz Liszt Academy of Music or Budapest Zoo and Botanical Garden.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nIt is one of the world's outstanding urban landscapes and illustrates the great periods in the history of the Hungarian capital.\n\"UNESCO\"\nThe second half of the 20th century also saw, under the communist regime, the construction of blocks of flats (panelh\u00e1z), as in other Eastern European countries. In the 21st century, Budapest faces new challenges in its architecture. The pressure towards the high-rise buildings is unequivocal among today's world cities, but preserving Budapest's unique cityscape and its very diverse architecture, along with green areas, forces Budapest to balance between them. The Contemporary architecture has wide margin in the city. Public spaces attract heavy investment by business and government also, so that the city has gained entirely new (or renovated and redesigned) squares, parks and monuments, for example the city central Kossuth Lajos square, De\u00e1k Ferenc square and Liberty Square. Numerous landmarks have been created in the last decade in Budapest, like the National Theatre, Palace of Arts, R\u00e1k\u00f3czi Bridge, Megyeri Bridge, Budapest Airport Sky Court among others, and millions of square meters of new office buildings and apartments. But there are still large opportunities in real estate development in the city.\nDistricts.\nContemporary Budapest is divided into 23 districts (, sg.: \"ker\u00fclet\"), each with a mayor and municipal government elected separately from the general municipal government. The districts and the general municipal government have constitutionally and legally defined, non-overlapping areas of competence. Each district has a municipally recognized name, some of which correspond to how locals call that area or neighborhood (e.g., Belv\u00e1ros, V. district; Ter\u00e9zv\u00e1ros, VI. district), others which (e.g., \u00dajbuda, XI. district) are neologisms. Street signs display the district and that neighborhood's colloquial name. The latter are often the names of villages that were gradually annexed to the city (e.g., Sashalom, Budafok) or of superseded administrative units of former boroughs.\nAfter the unification of Buda, Pest, and \u00d3buda in 1873, Budapest initially had 10 districts. It was during the interwar period that 's 1934-1944 mayoral administration first seriously considered annexing peripheral towns and villages. This only came about, however, after the rise of state communism in Hungary. In 1950, for reasons of social and industrial policy\u2014including the Hungarian Working People's Party's desire to proletarianize the traditionally right-wing suburbs\u20147 cities with county rights and 16 towns were annexed to the capital to form contemporary Greater Budapest (). This reorganized the city into 22 districts, a number that grew to 23 after Soroks\u00e1r seceded from Pesterzs\u00e9bet in 1994. The contemporary city thus consists of 6 districts in Buda, 16 in Pest, and Csepel. Today, districts I., II., XI., and XII. in Buda and V., VI., VII., VIII., and IX. in Pest make up the city center in its broadest sense, corresponding roughly to the 1873 municipal boundaries.\nBudapest's districts are numbered according to three concentric semicircles. The I. district is a small area in central Buda, including the Castle Quarter. District II. is in Buda to the castle's northwest while district III. stretches along the northernmost part of Buda and includes the former \u00d3buda. District IV. continues this semicircle in northernmost Pest, but the V. district is in the very center of Pest and inaugurates a new circle that then loops back through Pest to Buda as the VI., VII., VIII., IX., XI., and XII. districts. Districts XIII., XIV., XV., XVI., XVII., XVIII., XIX., XX., XXI., and XXII. form yet another semicircle in outermost Pest. Districts X. and XXIII. form irregularities within the overall pattern.\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nBudapest is the most populous city in Hungary and one of the largest cities in the European Union, with a growing number of inhabitants, estimated at 1,763,913 in 2019, whereby inward migration exceeds outward migration. These trends are also seen throughout the Budapest metropolitan area, which is home to 3.3\u00a0million people. This amounts to about 34% of Hungary's population. In 2014, the city had a population density of , rendering it the most densely populated of all municipalities in Hungary. The population density of Elisabethtown-District VII is , which has the highest population density figure in Hungary and one of the highest in the world. For comparison, the density in Manhattan is 25,846/km2.\nBudapest is the fourth most \"dynamically growing city\" by population in Europe, and the Euromonitor predicts a population increase of almost 10% between 2005 and 2030. The European Observation Network for Territorial Development and Cohesion says Budapest's population will increase by 10% to 30% only due to migration by 2050. A constant inflow of migrants in recent years has fuelled population growth in Budapest. Productivity gains and the relatively large economically active share of the population explain why household incomes have increased in Budapest to a greater extent than in other parts of Hungary. Higher incomes in Budapest are reflected in the lower share of expenditure the city's inhabitants allocate to necessary spending such as on food and non-alcoholic drinks.\nAccording to the 2016 microcensus, there were 1,764,263 people living in Budapest in 907,944 dwellings. Some 1.6\u00a0million persons from the metropolitan area may be within Budapest's boundaries during working hours, and during special events. This fluctuation in the population is caused by hundreds of thousands of suburban residents who travel to the city for work, education, health care, and special events.\nBy ethnicity there were 1,697,039 (96.2%) Hungarians, 34,909 (2%) Germans, 16,592 (0.9%) Romani, 9,117 (0.5%) Romanians and 5,488 (0.3%) Slovaks. In Hungary people can declare multiple ethnic identities, hence the sum may exceed 100%. The share of ethnic Hungarians in Budapest (96.2%) is slightly lower than the national average (98.3%) due to the international migration.\nAccording to the 2011 census, 1,712,153 people (99.0%) speak Hungarian, of whom 1,692,815 people (97.9%) speak it as a first language, while 19,338 people (1.1%) speak it as a second language. Other spoken (foreign) languages were: English (536,855 speakers, 31.0%), German (266,249 speakers, 15.4%), French (56,208 speakers, 3.3%) and Russian (54,613 speakers, 3.2%).\nAccording to the same census, 1,600,585 people (92.6%) were born in Hungary, 126,036 people (7.3%) outside Hungary while the birthplace of 2,419 people (0.1%) was unknown. Although only 1.7% of the population of Hungary in 2009 were foreigners, 43% of them lived in Budapest, making them 4.4% of the city's population (up from 2% in 2001). Nearly two-thirds of foreigners living in Hungary were under 40 years old. The primary motivation for this age group living in Hungary was employment.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nBudapest is home to one of the most populous Christian communities in Central Europe, numbering 698,521 people (40.4%) in 2011. According to the 2011 census, there were 501,117 (29.0%) Roman Catholics, 146,756 (8.5%) Calvinists, 30,293 (1.8%) Lutherans, 16,192 (0.9%) Greek Catholics, 7,925 (0.5%) Jews and 3,710 (0.2%) Orthodox in Budapest. 395,964 people (22.9%) were irreligious while 585,475 people (33.9%) did not declare their religion. The city is also home to one of the largest Jewish communities in Europe.\nEconomy.\nBudapest is a significant economic hub, classified as a Beta + world city in the study by the Globalization and World Cities Research Network and it is the second fastest-developing urban economy in Europe as GDP per capita in the city increased by 2.4 per cent and employment by 4.7 per cent compared to the previous year in 2014. On national level, Budapest is the primate city of Hungary regarding business and the economy, accounting for 39% of the national income. The city had a gross metropolitan product of more than $100\u00a0billion in 2015, making it one of the largest regional economies in the European Union. According to Eurostat GDP, per capita in purchasing power parity is 147% of the EU average in Budapest, which means \u20ac37,632 ($42,770) per capita. Budapest is also among the Top 100 GDP performing cities in the world, measured by PricewaterhouseCoopers. The city was named as the 52nd most important business centre in the world in the Worldwide Centres of Commerce Index, ahead of Beijing, S\u00e3o Paulo and Shenzhen and ranking 3rd (out of 65 cities) on the MasterCard Emerging Markets Index. The city is 48th on the UBS \"The most expensive and richest cities in the world\" list, standing before cities such as Prague, Shanghai, Kuala Lumpur and Buenos Aires.\nIn a global city competitiveness ranking by the EIU, Budapest stands before Tel Aviv, Lisbon, Moscow and Johannesburg among others.\nThe city is a major centre for banking and finance, real estate, retailing, trade, transportation, tourism, new media as well as traditional media, advertising, legal services, accountancy, insurance, fashion and the arts in Hungary and regionally. Budapest is home not only to almost all national institutions and government agencies, but also to many domestic and international companies. In 2014 there were 395.804 companies registered in the city. Most of these entities are headquartered in Budapest's Central Business District, in District V and District XIII. The retail market of the city (and the country) is also concentrated in the downtown area, among others, in the two largest shopping centres in Central and Eastern Europe, the 186,000 sqm WestEnd City Center and the 180,000 sqm Arena Plaza.\nBudapest has notable innovation capabilities as a technology and start-up hub. Many start-ups are headquartered and begin their business in the city. Some of the best known examples are Prezi, LogMeIn and NNG. Budapest is the highest ranked Central and Eastern European city in the Innovation Cities' Top 100 index. A good indicator of the city's potential for innovation and research, is that the European Institute of Innovation and Technology chose Budapest for its headquarters, along with the UN, whose Regional Representation for Central Europe office is in the city, responsible for UN operations in seven countries. Moreover, the global aspect of the city's research activity is shown through the establishment of the European Chinese Research Institute in the city. Other important sectors also include, natural science research, information technology and medical research, non-profit institutions, and universities. The leading business schools and universities in Budapest, the Budapest Business School, the CEU Business School and Corvinus University of Budapest offer a whole range of courses in economics, finance and management in English, French, German and Hungarian. The unemployment rate in Budapest is by far the lowest within Hungary. It was 2.7%, with many thousands of employed foreign citizens.\nBudapest is among the 25 most visited cities in the world, welcoming more than 4.4\u00a0million international visitors each year, therefore the traditional and the congress tourism industry also deserve a mention, as they contribute greatly to the city's economy. The capital is home to many convention centres and there are thousands of restaurants, bars, coffee houses and party places, besides a full range of hotels. As regards restaurants, examples can be found of the highest quality Michelin-starred restaurants, such as Onyx, Costes, Tanti and Borkonyha. The city ranked as the most liveable city in Central and Eastern Europe on EIU's quality of life index in 2010.\nFinance and corporate location.\nThe Budapest Stock Exchange, a key institution of publicly offered securities in Hungary and Central and Eastern Europe, is situated in Budapest's CBD at Liberty Square. BSE also trades other securities such as government bonds and derivatives as well as stock options. Large Hungarian multinational corporations headquartered in Budapest are listed on the BSE, for instance the Fortune Global 500 firms MOL Group, the OTP Bank, FHB Bank, Gedeon Richter, Magyar Telekom, CIG Pannonia, Zwack Unicum and more. Nowadays nearly all branches of industry can be found in Budapest. Although there is no particularly special industry in the city's economy, the financial centre role of the city is strong, with nearly 40 major banks being represented in the city including as well as those like Bank of China, KDB Bank and Hanwha Bank, which are unique in the region.\nMany international banks and financial service providers also support the financial industry of Budapest, firms such as Citigroup, Morgan Stanley, GE Capital, Deutsche Bank, Sberbank, ING Group, Allianz, KBC Group, UniCredit and MSCI among others. Another particularly strong industry in the capital city is the biotechnology and pharmaceutical industry. There are also traditionally strong domestic companies in Budapest such as Egis, Gedeon Richter, Chinoin as well as international biotechnology corporations such as Pfizer, Teva, Novartis, Sanofi, which also have R&amp;D and production divisions here. Further high-tech industries, involved in software development and engineering are notable as well. Nokia, Ericsson, Bosch, Microsoft and IBM employ thousands of engineers in research and development in the city. Game design is also strongly represented with headquarters of domestic companies Digital Reality, Black Hole and the studios of Crytek and Gameloft. Apart from the above, there are regional headquarters of global firms such as Alcoa, General Motors, General Electric, ExxonMobil, BP, BT, Flextronics, Panasonic, Huawei, Knorr-Bremse, Liberty Global, Tata Consultancy, Aegon, WizzAir, TriGr\u00e1nit, MVM Group and Graphisoft. There is a base for major international companies including, but not limited to, Nissan CEE, Volvo, Saab and Ford.\nPolitics and government.\nAs the capital of Hungary, Budapest is the seat of the country's national government. The President of Hungary resides at the S\u00e1ndor Palace in the District I (Buda Castle District), while the office of the Hungarian Prime Minister is in the Carmelite Monastery in the Castle District. Government ministries are all located in various parts of the city, most of them are in the District V, Leopoldtown. The National Assembly is seated in the Hungarian Parliament, which also located in the District V. The President of the National Assembly, the third-highest public official in Hungary, is also seated in the largest building in the country, in the Hungarian Parliament.\nHungary's highest courts are located in Budapest. The Curia (supreme court of Hungary), the highest court in the judicial order, which reviews criminal and civil cases, is located in the District V, Leopoldtown. Under the authority of its president it has three departments: criminal, civil and administrative-labour law departments. Each department has various chambers. The Curia guarantees the uniform application of law. The decisions of the Curia on uniform jurisdiction are binding for other courts. The second most important judicial authority, the National Judicial Council, is also housed in the District V, with the tasks of controlling the financial management of the judicial administration and the courts and giving an opinion on the practice of the president of the National Office for the Judiciary and the Curia deciding about the applications of judges and court leaders, among others. The Constitutional Court of Hungary is one of the highest level actors independent of the politics in the country. The Constitutional Court serves as the main body for the protection of the Constitution, its tasks being the review of the constitutionality of statutes. The Constitutional Court performs its tasks independently. With its own budget and its judges being elected by Parliament it does not constitute a part of the ordinary judicial system. The constitutional court passes on the constitutionality of laws, and there is no right of appeal on these decisions.\nBudapest hosts the main and regional headquarters of many international organizations as well, including United Nations High Commissioner for Refugees, Food and Agriculture Organization of the United Nations, European Institute of Innovation and Technology, European Police Academy, International Centre for Democratic Transition, Institute of International Education, International Labour Organization, International Organization for Migration, International Red Cross, Regional Environmental Center for Central and Eastern Europe, Danube Commission and even others. The city is also home to more than 100 embassies and representative bodies as an international political actor.\nEnvironmental issues have a high priority among Budapest's politics. Institutions such as the Regional Environmental Center for Central and Eastern Europe, located in Budapest, are very important assets. To decrease the use of cars and greenhouse gas emissions, the city has worked to improve public transportation, and nowadays the city has one of the highest mass transit usage in Europe. Budapest has one of the best public transport systems in Europe with an efficient network of buses, trolleys, trams and subway. Budapest has an above-average proportion of people commuting on public transport or walking and cycling for European cities. Riding on bike paths is one of the best ways to see Budapest \u2013 there are about of bicycle paths in the city, fitting into the EuroVelo system.\nCrime in Budapest is investigated by different bodies. United Nations Office on Drugs and Crime notes in their 2011 Global Study on Homicide that, according to criminal justice sources, the homicide rate in Hungary, calculated based on UN population estimates, was 1.4 in 2009, compared to Canada's rate of 1.8 that same year.\nThe homicide rate in Budapest is below the EU capital cities' average according to WHO also. However, organised crime is associated with the city, the Institute of Defence in a UN study named Budapest as one of the \"global epicentres\" of illegal pornography, money laundering and contraband tobacco, and also a negotiation center for international crime group leaders.\nCity governance.\nBudapest has been a metropolitan municipality with a mayor-council form of government since its consolidation in 1873, but Budapest also holds a special status as a county-level government, and also special within that, as holds a capital-city territory status. In Budapest, the central government is responsible for the urban planning, statutory planning, public transport, housing, waste management, municipal taxes, correctional institutions, libraries, public safety, recreational facilities, among others. The Mayor is responsible for all city services, police and fire protection, enforcement of all city and state laws within the city, and administration of public property and most public agencies. Besides, each of Budapest' twenty-three districts has its own town hall and a directly elected council and the directly elected mayor of district.\nThe Mayor of Budapest is Gergely Kar\u00e1csony who was elected on 13 October 2019. The mayor and members of General Assembly are elected to five-year terms.\nThe Budapest General Assembly is a unicameral body consisting of 33 members, which consist of the 23 mayors of the districts, 9 from the electoral lists of political parties, plus Mayor of Budapest (the Mayor is elected directly). Each term for the mayor and assembly members lasts five years. Submitting the budget of Budapest is the responsibility of the Mayor and the deputy-mayor in charge of finance. The latest, 2014 budget was approved with 18 supporting votes from ruling Fidesz and 14 votes against by the opposition lawmakers.\nMain sights and tourism.\nBudapest is widely known for its well-kept pre-war cityscape, with a great variety of streets and landmarks in classical architecture.\nThe most well-known sight of the capital is the neo-Gothic Parliament, the biggest building in Hungary with its length, also holding (since 2001) the Hungarian Crown Jewels.\nSaint Stephen's Basilica is the most important religious building of the city, where the Holy Right Hand of Hungary's first king, Saint Stephen is on display as well.\nHungarian cuisine and caf\u00e9 culture can be seen and tasted in many places, like Gerbeaud Caf\u00e9, the \"Sz\u00e1z\u00e9ves\", \"Biarritz\", \"Fortuna\", \"Alab\u00e1rdos\", \"Arany Szarvas\", \"Gundel\" and the world-famous M\u00e1ty\u00e1s-pince restaurants and beer bars.\nThere are Roman remains at the Aquincum Museum, and historic furniture at the Nagyt\u00e9t\u00e9ny Castle Museum, just 2 of 223 museums in Budapest. Another historical museum is the House of Terror, hosted in the building that was the venue of the Nazi Headquarters. The Castle Hill, the River Danube embankments and the whole of Andr\u00e1ssy \u00fat have been officially recognized as UNESCO World Heritage Sites.\nCastle Hill and the Castle District; there are three churches here, six museums, and a host of interesting buildings, streets and squares. The former Royal Palace is one of the symbols of Hungary \u2013 and has been the scene of battles and wars ever since the 13th century. Nowadays it houses two museums and the National Sz\u00e9chenyi Library. The nearby S\u00e1ndor Palace contains the offices and official residence of the President of Hungary. The seven-hundred-year-old Matthias Church is one of the jewels of Budapest, it is in neo-Gothic style, decorated with coloured shingles and elegant pinnacles. Next to it is an equestrian statue of the first king of Hungary, King Saint Stephen, and behind that is the Fisherman's Bastion, built in 1905 by the architect Frigyes Schulek, the Fishermen's Bastions owes its name to the namesake corporation that during the Middle Ages was responsible of the defence of this part of ramparts, from where opens out a panoramic view of the whole city. Statues of the Turul, the mythical guardian bird of Hungary, can be found in both the Castle District and the Twelfth District.\nIn Pest, arguably the most important sight is Andr\u00e1ssy \u00fat. This Avenue is an elegant long tree-lined street that covers the distance from De\u00e1k Ferenc t\u00e9r to the Heroes Square. This Avenue overlooks many important sites. It is a UNESCO World Heritage Site. As far as Kod\u00e1ly k\u00f6r\u00f6nd and Oktogon both sides are lined with large shops and flats built close together. Between there and Heroes' Square the houses are detached and altogether grander. Under the whole runs continental Europe's oldest Underground railway, most of whose stations retain their original appearance. Heroes' Square is dominated by the Millenary Monument, with the Tomb of the Unknown Soldier in front. To the sides are the Museum of Fine Arts and the Kunsthalle Budapest, and behind City Park opens out, with Vajdahunyad Castle. One of the jewels of Andr\u00e1ssy \u00fat is the Hungarian State Opera House. Statue Park, a theme park with striking statues of the Communist era, is located just outside the main city and is accessible by public transport.\nThe Doh\u00e1ny Street Synagogue is the largest synagogue in Europe, and the second largest active synagogue in the world. The synagogue is located in the Jewish district taking up several blocks in central Budapest bordered by Kir\u00e1ly utca, Wessel\u00e9nyi utca, Grand Boulevard and Bajcsy Zsilinszky road. It was built in moorish revival style in 1859 and has a seating capacity of 3,000. Adjacent to it is a sculpture reproducing a weeping willow tree in steel to commemorate the Hungarian victims of the Holocaust.\nThe city is also home to the largest medicinal bath in Europe (Sz\u00e9chenyi Medicinal Bath) and the third largest Parliament building in the world, once the largest in the world. Other attractions are the bridges of the capital. Seven bridges provide crossings over the Danube, and from north to south are: the \u00c1rp\u00e1d Bridge (built in 1950 at the north of Margaret Island); the Margaret Bridge (built in 1901, destroyed during the war by an explosion and then rebuilt in 1948); the Chain Bridge (built in 1849, destroyed during World War II and then rebuilt in 1949); the Elisabeth Bridge (completed in 1903 and dedicated to the murdered Queen Elisabeth, it was destroyed by the Germans during the war and replaced with a new bridge in 1964); the Liberty Bridge (opened in 1896 and rebuilt in 1989 in Art Nouveau style); the Pet\u0151fi Bridge (completed in 1937, destroyed during the war and rebuilt in 1952); the R\u00e1k\u00f3czi Bridge (completed in 1995). Most remarkable for their beauty are the Margaret Bridge, the Chain Bridge and the Liberty Bridge. The world's largest panorama photograph was created in (and of) Budapest in 2010.\nTourists visiting Budapest can receive free maps and information from the nonprofit Budapest Festival and Tourism Center at its info-points. The info centers also offer the Budapest Card which allows free public transit and discounts for several museums, restaurants and other places of interest. Cards are available for 24-, 48- or 72-hour durations. The city is also well known for its ruin bars both day and night.\nSquares.\nIn Budapest there are many smaller and larger squares, the most significant of which are Heroes' Square, Kossuth Square, Liberty Square, St. Stephen's Square, Ferenc De\u00e1k Square, V\u00f6r\u00f6smarty Square, Erzs\u00e9bet Square, St. George's Square and Sz\u00e9chenyi Istv\u00e1n Square. The Heroes' Square at the end of Andr\u00e1ssy Avenue is the largest and most influential square in the capital, with the Millennium Monument in the center, and the Museum of Fine Arts and The Hall of Art. Kossuth Square is a symbolic place of the Hungarian statehood, the Hungarian Parliament Building, the Palace of Justice and the Ministry of Agriculture. The Liberty Square is located in the Belv\u00e1ros-Lip\u00f3tv\u00e1ros District (Inner City District), as one of Budapest's most beautiful squares. There are buildings such as the Hungarian National Bank, the embassy of the United States, the Stock Exchange Palace, as well as numerous statues and monuments such as the Soviet War Memorial, the Statue of Ronald Reagan or the controversial Monument to the victims of the German occupation. In the St. Stephen's Square is the St. Stephen's Basilica, the square is connected by a walking street, the Zr\u00ednyi Street, to the Sz\u00e9chenyi Istv\u00e1n Square at the foot of The Chain Bridge. The Hungarian Academy of Sciences and the Gresham Palace and the Ministry of Interior are also located here. De\u00e1k Ferenc Square is a central square of the capital, a major transport hub, where three Budapest subways meet. Here is the oldest and best known Evangelical Church of Budapest, the De\u00e1k Ferenc Square Lutheran Church. V\u00f6r\u00f6smarty Square is located in Belv\u00e1ros-Lip\u00f3tv\u00e1ros District (Inner City District) behind the Vigad\u00f3 of Pest as one of the endpoints of V\u00e1ci Street. The Confectionery Gerbeaud is here, and the annual Christmas Fair is held in the Square, as well as is the centre of the Holiday Book Week.\nParks and gardens.\nBudapest has many municipal parks and most have playgrounds for children and seasonal activities like skating in the winter and boating in the summer. Access from the city center is quick and easy with the Millennium Underground. Budapest has a complex park system, with various lands operated by the Budapest City Gardening Ltd. The wealth of greenspace afforded by Budapest's parks is further augmented by a network of open spaces containing forest, streams, and lakes that are set aside as natural areas which lie not far from the inner city, including the Budapest Zoo and Botanical Garden (established in 1866) in the City Park.\nThe most notable and popular parks in Budapest are the City Park which was established in 1751 (302 acres) along with Andr\u00e1ssy Avenue, the Margaret Island in the Danube (), the People's Park, the R\u00f3mai Part, and the Kopaszi Dam.\nThe Buda Hills also offer a variety of outdoor activities and views. A place frequented by locals is Normafa, offering activities for all seasons. With a modest ski run, it is also used by skiers and snowboarders \u2013 if there is enough snowfall in winter.\nIslands.\nA number of islands can be found on the Danube in Budapest:\nThe islands of Palotai Island, N\u00e9p Island, and H\u00e1ros Island also formerly existed within the city, but have been joined to the mainland.\nThe \u00cdns\u00e9g Rock () is a reef in the Danube close to the shore under the Gell\u00e9rt Hill. It is only exposed during drought periods when the river level is very low.\nJust outside the city boundary to the north lies the large Szentendre Island () and the much smaller Lupa Island ().\nSpas.\nOne of the reasons the Romans first colonised the area immediately to the west of the River Danube and established their regional capital at Aquincum (now part of \u00d3buda, in northern Budapest) is so that they could use and enjoy the thermal springs. There are still ruins visible today of the enormous baths that were built during that period. The new baths that were constructed during the Turkish period (1541\u20131686) served both bathing and medicinal purposes, and some of these are still in use to this day.\nBudapest gained its reputation as a city of spas in the 1920s, following the first realisation of the economic potential of the thermal waters in drawing in visitors. Indeed, in 1934 Budapest was officially ranked as a \"City of Spas\". Today, the baths are mostly frequented by the older generation, as, with the exception of the \"Magic Bath\" and \"Cinetrip\" water discos, young people tend to prefer the lidos which are open in the summer.\nConstruction of the Kir\u00e1ly Baths started in 1565, and most of the present-day building dates from the Turkish period, including most notably the fine cupola-topped pool.\nThe Rudas Baths are centrally placed \u2013 in the narrow strip of land between Gell\u00e9rt Hill and the River Danube \u2013 and also an outstanding example of architecture dating from the Turkish period. The central feature is an octagonal pool over which light shines from a diameter cupola, supported by eight pillars.\nThe Gell\u00e9rt Baths and Hotel were built in 1918, although there had once been Turkish baths on the site, and in the Middle Ages a hospital. In 1927, the Baths were extended to include the wave pool, and the effervescent bath was added in 1934. The well-preserved Art Nouveau interior includes colourful mosaics, marble columns, stained glass windows and statues.\nThe Luk\u00e1cs Baths are also in Buda and are also Turkish in origin, although they were only revived at the end of the 19th century. This was also when the spa and treatment centre were founded. There is still something of an atmosphere of fin-de-si\u00e8cle about the place, and all around the inner courtyard there are marble tablets recalling the thanks of patrons who were cured there. Since the 1950s it has been regarded as a centre for intellectuals and artists.\nThe Sz\u00e9chenyi Baths are one of the largest bathing complexes in all Europe, and the only \"old\" medicinal baths to be found in the Pest side of the city. The indoor medicinal baths date from 1913 and the outdoor pools from 1927. There is an atmosphere of grandeur about the whole place with the bright, largest pools resembling aspects associated with Roman baths, the smaller bath tubs reminding one of the bathing culture of the Greeks, and the saunas and diving pools borrowed from traditions emanating in northern Europe. The three outdoor pools (one of which is a fun pool) are open all year, including winter. Indoors there are over ten separate pools, and a whole host of medical treatments is also available. The Sz\u00e9cheny Baths are built in modern Renaissance style.\nInfrastructure and transportation.\nAirport.\nBudapest is served by Budapest Ferenc Liszt International Airport (BUD) (named after Franz Liszt, the notable Hungarian composer), one of the busiest airports in Central and Eastern Europe, located east-southeast of the centre of Budapest, in the District XVIII. The airport offers international connections among all major European cities, and also to North America, Africa, Asia and the Middle East. As Hungary's busiest airport, it handles nearly all of the country's air passenger traffic. Budapest Liszt Ferenc handled around 250 scheduled flights daily in 2013, and an ever-rising number of charters. London, Brussels, Frankfurt, Munich, Paris, and Amsterdam are the busiest international connections respectively, while Toronto, Montreal, Dubai, Doha and Alicante are the most unusual in the region. Today the airport serves as a base for Ryanair, Wizz Air, Budapest Aircraft Service, LOT Polish Airlines and Smartwings Hungary among others. The airport is accessible via public transportation from the city centre by the Metro line 3 and then the airport bus 200E and 100E.\nAs part of a strategic development plan, \u20ac561\u00a0million have been spent on expanding and modernising the airport infrastructure until December 2012. Most of these improvements are already completed, the postponed ones are the new cargo area and new piers for terminal 2A and 2B, but these development are on standby also, and will start immediately, when the airport traffic will reach the appropriate level. SkyCourt, the newest, state-of-the-art building between the 2A and 2B terminals with 5 levels. Passenger safety checks were moved here along with new baggage classifiers and the new Mal\u00e9v and SkyTeam business lounges, as well as the first MasterCard lounge in Europe.\nPublic transportation.\nPublic transit in Budapest is provided by the Centre for Budapest Transport (BKK, \"Budapesti K\u00f6zleked\u00e9si K\u00f6zpont\"), one of the largest transportation authorities in Europe. BKK operates 4 metro lines (including the historic Line 1, the oldest underground railway in continental Europe), 5 suburban railway lines, 33 tram lines, 15 trolleybus lines, 264 bus lines (including 40 night routes), 4 boat services, and \"BuBi\", a smart bicycle sharing network. On an average weekday, BKK lines transports 3.9\u00a0million riders; in 2011, it handled a total of 1.4\u00a0billion passengers. In 2014, the 65% of the passenger traffic in Budapest was by public transport and 35% by car. The aim is 80%\u201320% by 2030 in accordance with the strategy of BKK.\nPeople aged 65 and over and under 14 travel free.\nThe development of complex intelligent transportation system in the city is advancing; the application of smart traffic lights is widespread, they are GPS and computer controlled and give priority to the GPS connected public transport vehicles automatically, as well as the traffic is measured and analyzed on the roads and car drivers informed about the expected travel time and traffic by intelligent displays (EasyWay project). Public transport users are immediately notified of any changes in public transport online, on smartphones and on PIDS displays, as well car drivers can keep track of changes in traffic and road management in real-time online and on smartphones through the \"BKK Info\". As well all vehicles can be followed online and on smartphones in real-time throughout the city with the \"Fut\u00e1r\" PIDS system, while the continuous introducing of integrated e-ticket system will help the measurement of passenger numbers on each line and the intelligent control of service frequency.\nThe development of \"Fut\u00e1r\", the citywide real-time passenger information system and real-time route planner is finished already and now all of the public transport vehicle is connected via satellite system. The real-time information of trams, buses and trolleybuses are available for both the operators in the control room and for all the passengers in all stops on smartphone and on city street displays. The implementation of latest generation automated fare collection and e-ticket system with NFC compatibility and reusable contactless smart cards for making electronic payments in online and offline systems in Budapest is started in 2014, the project is implemented and operated by the operator of Hong Kong Octopus card jointly with one of the leading European companies of e-ticket and automated fare collection, Scheidt &amp; Bachmann. The deployment of 300 new digital contactless ticket vending machine will be finished by the end of 2014 in harmonization with the e-ticket system. In 2022, \"Fut\u00e1r\" was rebranded as \"BudapestGo.\"\nTram lines no. 4 and 6 are the busiest city tram lines in the world, with one of the world's longest trams (54-metre long Siemens Combino) running at 2\u20133-minute intervals at peak time and 4\u20135 minutes off-peak. Day services are usually from 4am until between 11pm and 0:30am. Hungarian State Railways operates an extensive network of commuter rail services, their importance in the suburban commuter passenger traffic is significant, but in travel within the city is limited. The organiser of public transport in Budapest is the municipal corporation \"Centre for Budapest Transport\" (Budapesti K\u00f6zleked\u00e9si K\u00f6zpont \u2013 BKK), that is responsible for planning and organising network and services, planning and developing tariff concepts, attending to public service procurer duties, managing public service contracts, operating controlling and monitoring systems, setting and monitoring service level agreements related to public transport, attending to customer service duties, selling and monitoring tickets and passes, attending to integrated passenger information duties, unified Budapest-centric traffic control within public transport, attending to duties related to river navigation, plus the management of Budapest roads, operating taxi stations, unified control of bicycle traffic development in the capital, preparing parking strategy and developing an operational concept, preparation of road traffic management, developing an optimal traffic management system, organising and co-ordinating road reconstruction and more, in short, everything which is related to transport in the city.\nRoads and railways.\nBudapest is the most important Hungarian road terminus, all of the major highways and railways end within the city limits. The road system in the city is designed in a similar manner to that of Paris, with several ring roads, and avenues radiating out from the center. Ring road M0 around Budapest is nearly completed, with only one section missing on the west side due to local disputes. The ring road is in length, and once finished it will be of highway in length.\nThe city is a vital traffic hub because all major European roads and European railway lines lead to Budapest. The Danube was and is still today an important water-way and this region in the centre of the Carpathian Basin lies at the cross-roads of trade routes.\nHungarian main line railways are operated by Hungarian State Railways. There are three main railway station in Budapest, Keleti (\"Eastern\"), Nyugati (\"Western\") and D\u00e9li (\"Southern\"), operating both domestic and international rail services. Budapest is one of the main stops of the Orient Express on its Central and Eastern European route. There is also a suburban rail service in and around Budapest, three lines of which are operated under the name H\u00c9V.\nPorts, shipping and others.\nThe river Danube flows through Budapest on its way from (Germany) to the Black Sea. The river is easily navigable and so Budapest historically has a major commercial port at Csepel District and at New Pest District also. The Pest side is also a famous port place with international shipping ports for cargo and for passenger ships. In the summer months, a scheduled hydrofoil service operates on the Danube connecting the city to Vienna.\nBKK (through the operator BKV) also provides public transport with boat service within the borders of the city. Two routes, marked D11 and D12, connect the two banks with Margaret Island and \u00d3buda Island, from R\u00f3maif\u00fcrd\u0151 (Buda side, north to \u00d3buda Island) or \u00c1rp\u00e1d Bridge (Pest side) to R\u00e1k\u00f3czi Bridge, with a total of 18 stops, while route D2 circulates in the downtown. Line D14 is a ferry service, connecting Kir\u00e1lyerd\u0151 on the Csepel Island with Moln\u00e1r Island on the Pest side, south to the city centre. In addition, several companies provides sightseeing boat trips and also an amphibious vehicle (bus and boat) operates constantly.\nWater quality in Budapest harbours improved dramatically in the recent years, treatment facilities processed 100% of generated sewage in 2010. Budapesters regularly kayak, canoe, jet-ski and sail on the Danube, which has continuously become a major recreational site for the city.\nSpecial vehicles in Budapest, besides metros, include suburban rails, trams and boats. There are a couple of less common vehicles in Budapest, like the trolleybus on several lines in Pest, the Castle Hill Funicular between the Chain Bridge and Buda Castle, the cyclecar for rent in Margaret Island, the chairlift, the Budapest Cog-wheel Railway and children's railway. The latter three vehicles run among Buda hills.\nCulture and contemporary life.\nThe culture of Budapest is reflected by Budapest's size and variety. Most Hungarian cultural movements first emerged in the city. Budapest is an important center for music, film, theatre, dance and visual art. Artists have been drawn into the city by opportunity, as the city government funds the arts with adequate financial resources.\nBudapest was named \"City of Design\" in December 2015 and has been a member of UNESCO Creative Cities Network since then.\nMuseums and galleries.\nBudapest is packed with museums and galleries. The city glories in 223 museums and galleries, which presents several memories, next to the Hungarian ones as well those of universal and European culture and science. Here are the greatest examples among them: the Hungarian National Museum, the Hungarian National Gallery, the Museum of Fine Arts (where can see the pictures of Hungarian painters, like Victor Vasarely, Mih\u00e1ly Munk\u00e1csy and a great collection about Italian art, Dutch art, Spanish art and British art from before the 19th century and French art, British art, German art, Austrian art after the 19th century), the House of Terror, the Budapest Historical Museum, the Aquincum Museum, the Semmelweis Museum of Medical History, the Memento Park, Museum of Applied Arts and the contemporary arts exhibition Palace of Arts Budapest. In Budapest there are 837 monuments, which represent most of the European artistic styles. The classical and unique Hungarian Art Nouveau buildings are prominent.\nLibraries.\nMany libraries have unique collections in Budapest, such as the National Sz\u00e9ch\u00e9nyi Library, which keeps historical relics from the age before the printing of books. The Metropolitan Szab\u00f3 Ervin Library plays an important role in the general education of the capital's population. Other libraries: The Library of the Hungarian Academy of Sciences, E\u00f6tv\u00f6s University Library, the Parliamentary Library, Library of the Hungarian Central Statistical Office and the National Library of Foreign Literature.\nOpera and theatres.\nIn Budapest there are forty theatres, seven concert halls and an opera house. Outdoor festivals, concerts and lectures enrich the cultural offer of summer, which are often held in historical buildings. The largest theatre facilities are the Budapest Operetta and Musical Theatre, the J\u00f3zsef Attila Theatre, the Katona J\u00f3zsef Theatre, the Mad\u00e1ch Theatre, the Hungarian State Opera House, the National Theatre, the Vigad\u00f3 Concert Hall, Radn\u00f3ti Mikl\u00f3s Theatre, the Comedy Theatre and the Palace of Arts, known as \"MUPA\". The Budapest Opera Ball is an annual Hungarian society event taking place in the building of the Budapest Opera (\"Operah\u00e1z\") on the last Saturday of the carnival season, usually late February.\nCasinos.\nThere are 11 casinos in Hungary (11 is the maximum number of casinos allowed by law), and five of them are located in the capital. All five of these casinos were owned by LVC Diamond J\u00e1t\u00e9kkaszin\u00f3 \u00dczemeltet\u0151 Kft, the gambling company of late Andr\u00e1s Vajna (better known as Andy Vajna) until his death in 2017. The biggest casino in Budapest and in all of Hungary is the Las Vegas Casino at the Corvin promenade.\nPerforming arts and festivals.\nSeveral annual festivals take place in Budapest. The Sziget Festival is one of the largest outdoor music festival in Europe. The Budapest Spring Festival includes concerts at several venues across the city. The Caf\u00e9 Budapest Contemporary Arts Festival (formerly the Budapest Autumn Festival) brings free music, dance, art, and other cultural events to the streets of the city. The Budapest Wine Festival and Budapest P\u00e1linka Festival, occurring each May, are gastronomy festivals focusing on culinary pleasures. The Budapest Pride (or Budapest Pride Film and Cultural Festival) occurs annually across the city, and usually involves a parade on the Andr\u00e1ssy Avenue. Other festivals include the Budapest Fringe Festival, which brings more than 500 artists in about 50 shows to produce a wide range of works in alternative theatre, dance, music and comedy outside the mainstream. The LOW Festival is a contemporary cultural festival held in Hungary in the cities Budapest and P\u00e9cs from February until March; the name of the festival alludes to the Low Countries, the region encompassing the Netherlands and Flanders. The Budapest Jewish Summer Festival, in late August, is one of the largest in Europe.\nThere are many symphony orchestras in Budapest, with the Budapest Philharmonic Orchestra being the preeminent one. It was founded in 1853 by Ferenc Erkel and still presents regular concerts in the Hungarian State Opera House and National Theatre. Budapest also has one of the more active jazz scenes in Central Europe.\nThe dance tradition of the Carpathian Basin is a unique area of the European dance culture, which is also a special transition between the Balkans and Western Europe regions. The city is home to several authentic Hungarian folk dance ensembles which range from small ensembles to professional troupes. Budapest is one of the few cities in the world with a high school for learning folk dance.\nFashion.\nBudapest is home to a fashion week twice a year, where the city's fashion designers and houses present their collections and provide a meeting place for the fashion industry representatives. Budapest Fashion Week additionally a place for designers from other countries may present their collections in Budapest. Hungarian models, like Barbara Palvin, Enik\u0151 Mihalik, Di\u00e1na M\u00e9sz\u00e1ros, Vikt\u00f3ria V\u00e1mosi usually appearing at these events along international participants. Fashion brands like Zara, H&amp;M, Mango, ESPRIT, Douglas AG, Lacoste, Tommy Hilfiger, Guess, Nike and other retail fashion brands are common across the city's shopping malls and on the streets.\nMajor luxury fashion brands such as Louis Vuitton, Burberry, Furla, Gucci, Versace, Zegna, Max Mara, Michael Kors, Karl Lagerfeld and Hugo Boss, or luxury watch brands such as Rolex, Hublot, Omega, Breitling, Tissot and TAG Heuer, can be found among the city's most prestigious shopping streets, the Fashion Street, V\u00e1ci Street and Andr\u00e1ssy Avenue in Budapest's main upscale fashion district, the Leopoldtown.\nMedia.\nBudapest is a prominent location for the Hungarian entertainment industry, with many films, television series, books, and other media set there. Budapest is the largest centre for film and television production in Hungary. In 2011, it employed more than 50,000 people and generated 63.9% of revenues of the media industry in the country.\nBudapest is the media centre of Hungary, and the location of the main headquarters of Hungarian Television and other local and national TV and radio stations, such as M1, M2, Duna TV, Duna World, RTL Klub, TV2 (Hungary), Euronews, Comedy Central, MTV Hungary, VIVA Hungary, Viasat 3, Cool TV, and Pro4, and politics and news channels such as H\u00edr TV, ATV, and Echo TV. Documentary channels include Discovery Channel, Discovery Science, Discovery World, National Geographic Channel, Nat Geo Wild, Spektrum TV, and BBC Entertainment. This is less than a quarter of the channels broadcast from Budapest; for the whole picture see Television in Hungary.\nIn 2012, in Hungary there were 7.2\u00a0million internet users (72% of the population) and 2.3\u00a0million subscriptions for mobile broadband.\nCuisine.\nIn the modern age, Budapest developed its own peculiar cuisine, based on products of the nearby region, such as lamb, pork and vegetables special to the region. Modern Hungarian cuisine is a synthesis of ancient Asiatic components mixed with French, Germanic, Italian, and Slavic elements. The food of Hungary can be considered a melting pot of the continent, with a culinary base formed from its own, original Magyar cuisine. Considerable numbers of Saxons, Armenians, Italians, Jews and Serbs settled in the Hungarian basin and in Transylvania, also contributing with different new dishes. Elements of ancient Turkish cuisine were adopted during the Ottoman era, in the form of sweets (for example different nougats, like white nougat called \"t\u00f6r\u00f6km\u00e9z\"), quince (\"birsalma\"), Turkish delight, Turkish coffee or rice dishes like pilaf, meat and vegetable dishes like the eggplant, used in eggplant salads and appetizers, stuffed peppers and stuffed cabbage called \"t\u00f6lt\u00f6tt k\u00e1poszta\". Hungarian cuisine was influenced by Austrian cuisine under the Austro-Hungarian Empire, dishes and methods of food preparation have often been borrowed from Austrian cuisine, and vice versa.\nBudapest restaurants reflect diversity, with menus carrying traditional regional cuisine, fusions of various culinary influences, or innovating in the leading edge of new techniques. Budapest' food shops also have a solid reputation for supplying quality specialised culinary products and supplies, reputations that are often built up over generations. These include many shop and served in several Michelin-starred restaurants.\nIn fiction.\nThe 1906 novel \"The Paul Street Boys\", the 1937 novel \"Journey by Moonlight\", the 1957 book \"The Bridge at Andau\", the 1975 novel \"Fateless\", the 1977 novel \"The End of a Family Story\", the 1986 book \"Between the Woods and the Water\", the 1992 novel \"Under the Frog\", the 1987 novel \"The Door\", the 2002 novel \"Prague\", the 2003 book \"Budapeste\", the 2004 novel \"Ballad of the Whisky Robber\", the 2005 novels \"Parallel Stories\" and \"The Historian\", the 2012 novel \"Budapest Noir\" are set, amongst others, partly or entirely in Budapest. Some of the better known feature films set in Budapest are \"Kontroll\", \"The District!\", \"Gloomy Sunday\", \"Sunshine\", \"An American Rhapsody\", \"As You Desire Me\", \"The Good Fairy\", \"Hanna's War\", \"The Journey\", \"Ladies in Love\", \"Music Box\", \"The Shop Around the Corner\", \"Zoo in Budapest\", \"Underworld\", \"\" and \"Spy\". Budapest, Hungary's capital, has long been a favorite destination for Hollywood filmmakers, drawn to its enchanting ambiance, timeless charm, and breathtaking landmarks. Budapest has also served as a muse for some of the most distinctive directors and films such as \"Love and Death\", \"Evita\", \"The Phantom of the Opera\", \"Blade Runner 2049\", \"The Martian\", \"Spy\", \"Atomic Blonde\", \"Red Sparrow\", \"A Good Day to Die Hard\". \"The Grand Budapest Hotel\" (2014) is a Wes Anderson film. It was filmed in Germany, and set in the fictional Republic of Zubrowka, which is in the alpine mountains of Hungary.\nSports.\nBudapest hosted many global sporting events in the past, among others the 1994 IAAF World Cross Country Championships, 1997 World Amateur Boxing Championships, 2000 World Fencing Championships, 2001 World Allround Speed Skating Championships, Bandy World Championship 2004, 2008 World Interuniversity Games, 2008 World Modern Pentathlon Championships, 2010 ITU World Championship Series, 2011 IIHF World Championship, 2012 European Speed Skating Championships, 2013 World Fencing Championships, 2013 World Wrestling Championships, 2014 World Masters Athletics Championships, 2017 World Aquatics Championships, and 2017 World Judo Championships, only in the last two-decade. Besides these, Budapest was the home of many European-level tournaments, like 2006 European Aquatics Championships, 2010 European Aquatics Championships, 2010 UEFA Futsal Championship, 2013 European Judo Championships, 2013 European Karate Championships and will be the host of 2023 World Championships in Athletics and 4 matches in the UEFA Euro 2020, which was held in the 67,215-seat new multi-purpose Pusk\u00e1s Ferenc Stadium, to mention a few.\nIn 2015, the Assembly of the Hungarian Olympic Committee and the Assembly of Budapest decided to bid for the 2024 Summer Olympics. Budapest has lost several bids to host the games, in 1916, 1920, 1936, 1944, and 1960 to Berlin, Antwerp, London, and Rome, respectively. The Hungarian Parliament also voted to support the bid on 28 January 2016, later Budapest City Council approved list of venues and Budapest became an official candidate for the 2024 Summer Olympic Games. However, they withdrew their bid later on.\nNumerous Olympic, World, and European Championship winners and medalists reside in the city, which follows from Hungary's 8th place among all the nations of the world in the All-time Olympic Games medal table.\nHungarians have always been avid sports people: during the history of the Summer Olympic Games, Hungarians have brought home 476 medals, of which 167 are gold. The top events in which Hungarians have excelled are fencing, swimming, water polo, canoeing, wrestling and track &amp; field sports. Beside classic sports, recreational modern sports such as bowling, pool billiard, darts, go-carting, wakeboarding and squash are very popular in Budapest, and extreme sports are also gaining ground. Furthermore, the Budapest Marathon and Budapest Half Marathon also attract many people every year. The city's largest football stadium is named after Ferenc Pusk\u00e1s, recognised as the top scorer of the 20th century and for whom FIFA Pusk\u00e1s Award was named.\nOne of Budapest's most popular sport is football and it has many Hungarian League football club, including in the top level Nemzeti Bajnoks\u00e1g I league, like Ferencv\u00e1rosi TC (32 Hungarian League titles), MTK Budapest FC (23 titles), \u00dajpest FC (20 titles), Budapest Honv\u00e9d FC (14 titles), Vasas SC (6 titles), Csepel SC (4 titles), Budapesti TC (2 titles).\nThe Hungarian Grand Prix in Formula One has been held at the Hungaroring just outside the city, a circuit which has FIA Grade 1 license. Since 1986, the race has been a round of the FIA Formula One World Championship. At the 2013 Hungarian Grand Prix, it was confirmed that Hungary will continue to host a Formula 1 race until 2021. The track was completely resurfaced for the first time in early 2016, and it was announced the Grand Prix's deal was extended for a further five years, until 2026.\nBudapest is home to two four-star UEFA stadiums: Pusk\u00e1s Ar\u00e9na, Groupama Ar\u00e9na, and two three-star UEFA stadiums: Hidegkuti N\u00e1ndor Stadion and Bozsik Ar\u00e9na (currently under renovations to upgrade to UEFA's four-star category).\nBudapest will be the home of the headquarters of the World Aquatics after moving from Lausanne by the 2027 World Aquatics Championships.\nEducation.\nBudapest is home to over 35 higher education institutions, many of which are universities. Under the Bologna Process, many offered qualifications are recognised in countries across Europe. Medicine, dentistry, pharmaceuticals, veterinary programs, and engineering are among the most popular fields for foreigners to undertake in Budapest. Most universities in Budapest offer courses in English, as well as in other languages like German, French, and Dutch, aimed specifically at foreigners. Many students from other European countries spend one or two semesters in Budapest through the Erasmus Programme.\nInternational relations.\nBudapest has quite a few sister cities and many partner cities around the world.\nLike Budapest, many of them are the most influential and largest cities of their country and region, most of them are the primate city and political, economical, cultural capital of their country. The Mayor of Budapest says the aim of improving sister city relationships is to allow and encourage a mutual exchange of information and experiences, as well as co-operation, in the areas of city management, education, culture, tourism, media and communication, trade and business development.\nPartnerships around the world.\nSome of the city's districts are also twinned to small cities or districts of other big cities; for details see the article List of districts in Budapest.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36790", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=36790", "title": "Artery", "text": "Blood vessels that carry blood away from the heart\nAn artery (from gre \" \"\u1f00\u03c1\u03c4\u03b7\u03c1\u03af\u03b1\" (art\u0113r\u00ed\u0101)\") is a blood vessel in humans and most other animals that takes oxygenated blood away from the heart in the systemic circulation to one or more parts of the body. Exceptions that carry deoxygenated blood are the pulmonary arteries in the pulmonary circulation that carry blood to the lungs for oxygenation, and the umbilical arteries in the fetal circulation that carry deoxygenated blood to the placenta. It consists of a multi-layered artery wall wrapped into a tube-shaped channel.\nArteries contrast with veins, which carry deoxygenated blood back towards the heart; or in the pulmonary and fetal circulations carry oxygenated blood to the lungs and fetus respectively.\nStructure.\nThe anatomy of arteries can be separated into gross anatomy, at the macroscopic level, and microanatomy, which must be studied with a microscope. The arterial system of the human body is divided into systemic arteries, carrying blood from the heart to the whole body, and pulmonary arteries, carrying deoxygenated blood from the heart to the lungs.\nLarge arteries (such as the aorta) are composed of many different types of cells, namely endothelial, smooth muscle, fibroblast, and immune cells. As with veins, the arterial wall consists of three layers called tunics, namely the \"tunica intima\", \"tunica media\", and \"tunica externa\", from innermost to outermost. The \"externa\", alternatively known as the \"tunica adventitia\", is composed of collagen fibers and elastic tissue\u2014with the largest arteries containing vasa vasorum, small blood vessels that supply the walls of large blood vessels. Most of the layers have a clear boundary between them, however the tunica externa has a boundary that is ill-defined. Normally its boundary is considered when it meets or touches the connective tissue. Inside this layer is the \"tunica media\", which is made up of smooth muscle cells, elastic tissue (also called \"connective tissue proper\") and collagen fibres. The innermost layer, which is in direct contact with the flow of blood, is the \"tunica intima\". The elastic tissue allows the artery to bend and fit through places in the body. This layer is mainly made up of endothelial cells (and a supporting layer of elastin rich collagen in elastic arteries). The hollow internal cavity in which the blood flows is called the lumen.\nDevelopment.\nArterial formation begins and ends when endothelial cells begin to express arterial specific genes, such as ephrin B2.\nFunction.\nArteries form part of the circulatory system. They carry blood that is oxygenated after it has been pumped from the heart. Coronary arteries also aid the heart in pumping blood by sending oxygenated blood to the heart, allowing the muscles to function. Arteries carry oxygenated blood away from the heart to the tissues, except for pulmonary arteries, which carry blood to the lungs for oxygenation (usually veins carry deoxygenated blood to the heart but the pulmonary veins carry oxygenated blood as well). There are two types of unique arteries. The pulmonary artery carries blood from the heart to the lungs, where it receives oxygen. It is unique because the blood in it is not \"oxygenated\", as it has not yet passed through the lungs. The other unique artery is the umbilical artery, which carries deoxygenated blood from a fetus to its mother.\nArteries have a blood pressure higher than other parts of the circulatory system. The pressure in arteries varies during the cardiac cycle. It is highest when the heart contracts and lowest when heart relaxes. The variation in pressure produces a pulse, which can be felt in different areas of the body, such as the radial pulse. Arterioles have the greatest collective influence on both local blood flow and on overall blood pressure. They are the primary \"adjustable nozzles\" in the blood system, across which the greatest pressure drop occurs. The combination of heart output (cardiac output) and systemic vascular resistance, which refers to the collective resistance of all of the body's arterioles, are the principal determinants of arterial blood pressure at any given moment.\nArteries have the highest pressure and have narrow lumen diameter.\nSystemic arteries are the arteries (including the peripheral arteries), of the systemic circulation, which is the part of the cardiovascular system that carries oxygenated blood away from the heart, to the body, and returns deoxygenated blood back to the heart. Systemic arteries can be subdivided into two types\u2014muscular and elastic\u2014according to the relative compositions of elastic and muscle tissue in their tunica media as well as their size and the makeup of the internal and external elastic lamina. The larger arteries (&gt;10\u00a0 mm diameter) are generally elastic and the smaller ones (0.1\u201310\u00a0mm) tend to be muscular. Systemic arteries deliver blood to the arterioles, and then to the capillaries, where nutrients and gasses are exchanged.\nAfter traveling from the aorta, blood travels through peripheral arteries into smaller arteries called arterioles, and eventually to capillaries. Arterioles help in regulating blood pressure by the variable contraction of the smooth muscle of their walls, and deliver blood to the capillaries. This smooth muscle contraction is primarily influenced by activity of the sympathetic vasomotor nerves innervating the arterioles. Enhanced sympathetic activation prompts vasoconstriction, reducing the lumen diameter. A reduced lumen diameter consequently elevates the blood pressure within the arterioles. Conversely, decreased sympathetic activity within the vasomotor nerves causes vasodilation of the vessels thereby decreasing blood pressure. \nAorta.\nThe aorta is the root systemic artery (i.e., main artery). In humans, it receives blood directly from the left ventricle of the heart via the aortic valve. As the aorta branches and these arteries branch, in turn, they become successively smaller in diameter, down to the arterioles. The arterioles supply capillaries, which in turn empty into venules. The first branches off of the aorta are the coronary arteries, which supply blood to the heart muscle itself. These are followed by the branches of the aortic arch, namely the brachiocephalic artery, the left common carotid, and the left subclavian arteries.\nCapillaries.\nThe capillaries are the smallest of the blood vessels and are part of the microcirculation. The microvessels have a width of a single cell in diameter to aid in the fast and easy diffusion of gasses, sugars and nutrients to surrounding tissues. Capillaries have no smooth muscle surrounding them and have a diameter less than that of red blood cells; a red blood cell is typically 7 micrometers outside diameter, capillaries typically 5 micrometers inside diameter. The red blood cells must distort in order to pass through the capillaries.\nThese small diameters of the capillaries provide a relatively large surface area for the exchange of gasses and nutrients.\nClinical significance.\nSystemic arterial pressures are generated by the forceful contractions of the heart's left ventricle. High blood pressure is a factor in causing arterial damage. Healthy resting arterial pressures are relatively low, mean systemic pressures typically being under above surrounding atmospheric pressure (about at sea level). To withstand and adapt to the pressures within, arteries are surrounded by varying thicknesses of smooth muscle which have extensive elastic and inelastic connective tissues. The pulse pressure, being the difference between systolic and diastolic pressure, is determined primarily by the amount of blood ejected by each heart beat, stroke volume, versus the volume and elasticity of the major arteries.\nA blood squirt, also known as an arterial gush, is the effect when an artery is cut due to the higher arterial pressures. Blood is spurted out at a rapid, intermittent rate, that coincides with the heartbeat. The amount of blood loss can be copious, can occur very rapidly, and be life-threatening.\nOver time, factors such as elevated arterial blood sugar (particularly as seen in diabetes mellitus), lipoprotein, cholesterol, high blood pressure, stress and smoking, are all implicated in damaging both the endothelium and walls of the arteries, resulting in atherosclerosis. Atherosclerosis is a disease marked by the hardening of arteries. This is caused by an atheroma or plaque in the artery wall and is a build-up of cell debris, that contain lipids, (cholesterol and fatty acids), calcium and a variable amount of fibrous connective tissue.\nAccidental intra-arterial injection either iatrogenically or through recreational drug use can cause symptoms such as intense pain, paresthesia and necrosis. It usually causes permanent damage to the limb; often amputation is necessary.\nHistory.\nAmong the Ancient Greeks before Hippocrates, all blood vessels were called \u03a6\u03bb\u03ad\u03b2\u03b5\u03c2, \"phlebes\". The word \"arteria\" then referred to the windpipe. Herophilos was the first to describe anatomical differences between the two types of blood vessel. While Empedocles believed that the blood moved to and fro through the blood vessels, there was no concept of the capillary vessels that join arteries and veins, and there was no notion of circulation. Diogenes of Apollonia developed the theory of \"pneuma\", originally meaning just air but soon identified with the soul itself, and thought to co-exist with the blood in the blood vessels. The arteries were thought to be responsible for the transport of air to the tissues and to be connected to the trachea. This was as a result of finding the arteries of cadavers devoid of blood. \nIn medieval times, it was supposed that arteries carried a fluid, called \"spiritual blood\" or \"vital spirits\", considered to be different from the contents of the veins. This theory went back to Galen. In the late medieval period, the trachea, and ligaments were also called \"arteries\".\nWilliam Harvey described and popularized the modern concept of the circulatory system and the roles of arteries and veins in the 17th century. \nAlexis Carrel at the beginning of the 20th century first described the technique for vascular suturing and anastomosis and successfully performed many organ transplantations in animals; he thus actually opened the way to modern vascular surgery that was previously limited to vessels' permanent ligation.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36791", "revid": "29323357", "url": "https://en.wikipedia.org/wiki?curid=36791", "title": "Todd Rundgren", "text": "American musician (born 1948)\nTodd Harry Rundgren (born June 22, 1948) is an American musician, singer, songwriter, and record producer who has performed a diverse range of styles as a solo artist and as a member of the bands Nazz and Utopia. He is known for his sophisticated and often unorthodox music, his occasionally lavish stage shows, and his later experiments with interactive art. He also produced music videos and was an early adopter and promoter of various computer technologies, such as using the Internet as a means of music distribution in the late 1990s.\nA native of Upper Darby, Pennsylvania, Rundgren began his professional career in the mid-1960s, forming the psychedelic band Nazz in 1967. After two years, he left Nazz to pursue a solo career and immediately scored his first US top 40 hit with \"We Gotta Get You a Woman\" (1970). His best-known songs include \"Hello It's Me\" and \"I Saw the Light\" from \"Something/Anything?\" (1972), which get frequent air time on classic rock radio stations, the 1978 \"Can We Still Be Friends\", and the 1983 single \"Bang the Drum All Day\", which is featured in many sports arenas, commercials, and movie trailers. Although lesser known, \"Couldn't I Just Tell You\" (1972) was influential to many artists in the power pop genre. His 1973 album \"A Wizard, a True Star\" remains an influence on later generations of bedroom musicians.\nRundgren is considered a pioneer in the fields of electronic music, progressive rock, music videos, computer software, and Internet music delivery. He organized the first interactive television concert in 1978, designed the first color graphics tablet in 1980, and created the first interactive album, \"No World Order\", in 1993.\nAdditionally, he was one of the first acts to be prominent as both an artist and producer. His notable production credits include Badfinger's \"Straight Up\" (1971), Grand Funk Railroad's \"We're an American Band\" (1973), the New York Dolls' \"New York Dolls\" (1973), Meat Loaf's \"Bat Out of Hell\" (1977), and XTC's \"Skylarking\" (1986). He was inducted into the Rock and Roll Hall of Fame in 2021.\nEarly influences and Nazz.\nTodd Harry Rundgren was born in Philadelphia on June 22, 1948, the son of Ruth (n\u00e9e Fleck; April 29, 1922 \u2013 April 6, 2016) and Harry W. Rundgren (1917\u20131996). His father was of Swedish descent and his mother was of Austrian and German descent. He grew up in the bordering town of Upper Darby Township, Pennsylvania and taught himself how to play guitar with little help. As a child, Rundgren was fascinated by his parents' small record collection, which consisted of show tunes and symphonic pieces, and especially by the operettas of Gilbert and Sullivan. Later, he grew infatuated with the music of the Beatles, the Rolling Stones, the Ventures, and the Yardbirds, as well as the Philadelphia soul of Gamble &amp; Huff, the Delfonics, and the O'Jays. At the age of 17, he formed his first band, Money, with then-best friend and roommate Randy Reed and Reed's younger brother.\nAfter graduating from Upper Darby High School in 1966, Rundgren moved to Philadelphia and began his career in Woody's Truck Stop, a blues rock group in the style of Paul Butterfield Blues Band. Rundgren stayed with the band for eight months, and in the process, they became the most popular group in Philadelphia. He and bassist Carson Van Osten left before they released the eponymous first album to form the rock band Nazz in 1967. By then, Rundgren had lost interest in the blues and wanted to pursue a recording career with original songs in the style of newer records by the Beatles and the Who. As a member of the Nazz, he learned his craft as a songwriter and vocal arranger, and was determined to equal the artistry of the Beatles.\nIn 1968, after recording four demo discs, the Nazz were signed by Atlantic Records subsidiary Screen Gems Columbia (SGC). They were flown to Los Angeles to produce their first album at ID Sound studio. Rundgren had no prior production experience and remembered that the producer, Bill Traut, \"just whipped through the mixes in a day or two ... So I got it into my head, 'Well, he's gone now, so why don't we just mix it again, more like the way we want it?' Our engineer didn't mind if we went and just started diddling around on the board ... It was pretty much trial and error.\" He took an experimental approach to the recordings, employing techniques such as varispeed and flanging, and despite having no formal training, scored music charts for string and horn arrangements. Engineer James Lowe, whom Rundgren recruited for his involvement with arranger Van Dyke Parks, believed that Rundgren had become the de facto leader of Nazz, and that a producer's credit was wrongfully withheld from him.\nNazz gained minor recognition with their debut single, July 1968's \"Open My Eyes\" backed with \"Hello It's Me\", both songs penned by Rundgren. They subsequently released three albums: \"Nazz\" (October 1968), \"Nazz Nazz\" (April 1969), and \"Nazz III\" (1971). In March 1968, New York singer-songwriter Laura Nyro released her second album, \"Eli and the Thirteenth Confession\". When Rundgren heard the record, he was struck by \"all the major seventh chords and variations on augmented and suspended chords\", and it had an immediate impact on his songwriting, especially as he began to compose more on piano. He elaborated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I know for a fact that her influences were the more sophisticated side of R&amp;B, like Jerry Ragovoy and Mann &amp; Weil and Carole King. ... and she also had her own very original and very jazz-influenced way of seeing things. It was that extra layer that made her influential. A lot of those chords she got from other people. But beyond the elements of her composition, I always thought it was the way she played her own material that really sold it. ... I met her right after \"Eli and the Thirteenth Confession\". I actually had arranged a meeting, just because I was so infatuated with her and I wanted to meet the person who had produced all this music. ... after I met her the first time, she asked me if I wanted to be her band leader. But the Nazz had just signed a record contract and I couldn't skip out on the band, even though it was incredibly tempting.\nThe rest of the band struggled to accommodate his changing tastes, and tensions between all the band members had begun to build up in the interval between recording their first and second albums as a result of their shared living quarters. Tensions further increased during the recording of Nazz's second album, as the other members bridled at the formerly unassuming Rundgren asserting complete control of the sessions as the producer. By the time \"Nazz Nazz\" was released, Rundgren and Van Osten had both left the Nazz, so the track selection was done without any input from them. \"Nazz III\", which included leftover tracks from the \"Nazz Nazz\" sessions, was likewise released without Rundgren's involvement.\nProduction beginnings.\nAfter departing Nazz, the 21-year-old Rundgren briefly considered working as a computer programmer, and then decided that his calling was as a producer. He moved to New York in the summer of 1969 and involved himself with the clubs of Greenwich Village, particularly Steve Paul's Scene, and met a number of Manhattan musicians and fashion designers. Michael Friedman, formerly the assistant of Nazz manager John Kurland, offered Rundgren a job as staff engineer and producer under Albert Grossman, which Rundgren accepted. Grossman, known for his management of folk rock acts, had just founded Ampex Records, a joint business venture with the tape company of the same name, and built Bearsville Studios, near Woodstock. Bearsville soon became its own record imprint. Grossman promised to Rundgren that he would become the \"highest-paid producer in the world\", which later came true.\nRundgren said he was initially relegated to \"various old folk artists that they had who needed an upgrade: people like Ian &amp; Sylvia, James Cotton, and other artists in Albert's stable.\" Shortly after producing the eponymous 1969 album by Great Speckled Bird, he was promoted as Bearsville's house engineer. Accompanied by Robbie Robertson and Levon Helm of the Band, he traveled to Canada to record Jesse Winchester's eponymous 1970 debut album. Immediately afterward, he said, \"the Band asked me to engineer their \"Stage Fright\" sessions. I think \"Jesse Winchester\" was a kind of run-through for that, because I was pretty quick to get the sounds and they liked that.\" Released in August 1970, \"Stage Fright\" reached number 5 on the \"Billboard\" 200, the highest chart showing the Band had to that point. Rundgren was dubbed Bearsville's \"boy wonder\".\nHis work for the Band was followed by a second album for Winchester (which was then shelved for two years) and the album \"Taking Care of Business\" by the James Cotton Blues Band (1970). This project resulted in Rundgren meeting Cotton's keyboard player Mark \"Moogy\" Klingman, who in turn introduced Rundgren to keyboard player Ralph Schuckett, both of whom worked extensively with Rundgren over the next few years. Rundgren was to produce Janis Joplin's third and ultimately final album, \"Pearl\" (1971), but plans fell through, as the two artists could not get along with each other.\nSolo career.\n1970\u20131984: Bearsville era.\n\"Runt\" and \"Ballad of Todd Rundgren\".\nFollowing a period where he thought he would never return to being a performing artist, Rundgren approached Grossman with the idea of what would become his debut solo record, \"Runt\". Although his general attitude for any project was to \"make the record [I] wanted to make and then hope the label can find a way to promote it\", Rundgren ensured that any loss to Grossman would be minimal: \"I didn't get an actual advance for \"Runt\". I just asked for a recording budget to pay the studio costs. ... I had no idea how much money I even had in the bank. If I needed cash, I would show up at the accountants and they would just give me hundreds or thousands of dollars.\"\nReleased in mid-1970, \"Runt\" was not originally credited to Rundgren due to his anxieties about starting a full-fledged solo career, and instead bore the moniker \"Runt\". The album featured a bright sound and songs inspired by Laura Nyro. It was recorded with the 17-year-old bassist Tony Fox Sales and his 14-year-old brother Hunt Sales on drums. \"Nazz\" engineer James Lowe returned for the sessions and recalled that Rundgren seemed \"more able to really lead a group. If you go back and listen to it, it's very sophisticated material, especially for a guy so young.\" Lead single \"We Gotta Get You a Woman\" reached number 20 on the \"Billboard\" charts. As he prepared a follow-up LP, he produced \"Halfnelson\", the debut album by the band that would later become Sparks. Members Ron and Russell Mael later credited Rundgren with launching Sparks' career.\nRundgren's industry reputation grew substantially as a result of his success with \"Runt\", and for the first time in his life, he began using recreational drugs. Initially this was limited to marijuana. He said that the drug gave him \"a whole different sensibility about time and space and order\" that influenced the writing for his second album, \"Runt. The Ballad of Todd Rundgren\". The material was mostly piano ballads and still largely based on Nyro's template, but a more conscious effort by Rundgren was made to refine his music and choice of subject matter, and to distinguish himself from his influences. Released June 1971, \"The Ballad of Todd Rundgren\" bore two singles, \"Be Nice to Me\" and \"A Long Time, a Long Way To Go\", neither of which repeated the success of \"We Gotta Get You a Woman\". While initial reviews of \"Ballad\" were mixed, it came to be regarded as one of the greatest singer-songwriter albums of the era.\n\"Something/Anything?\".\nIn late 1971, Rundgren was recruited to finish Badfinger's third album \"Straight Up\", a project George Harrison had abandoned to organize the Concert for Bangladesh, in London. The album was a hit and its two singles were similarly successful, although Rundgren was not credited for the first (\"Day After Day\") and thus did not receive production royalties for that single. Rundgren said that the song \"didn't sound much like what [Harrison had] done\" and speculated that the credit to Harrison \"may or may not have been something purposeful, just some by-product of a general Beatle hubris\". The \"Straight Up\" sessions lasted two weeks in September, after which Rundgren returned to Los Angeles to work on his third solo album, originally planned as a single LP.\nAs with \"Ballad\", much of the newer material was written or conceived under the influence of marijuana. However, by this time, he had also begun experimenting with Ritalin. He recalled, \"my songwriting process had become almost too second-nature. I was writing songs formulaically, almost without thinking, knocking [them out], reflexively, in about 20 minutes.\" The use of Ritalin also helped him focus on the process as he worked up to 12 hours a day to beat the three-week deadline. To keep up the pace, he installed an eight-track recorder, mixer, and synthesizers into his living room so that he could continue recording after leaving the studio. For the first time in his career, Rundgren recorded every part by himself, including bass, drums, and vocals. About \"an album and a half\" was completed this way. He then decided to stretch the project into a double LP and quickly recorded the last few tracks with musicians, live in the studio.\n\"Something/Anything?\", the first album officially issued under the name \"Todd Rundgren\", was released in February 1972, shortly after Bearsville had signed a long-term distribution deal with Warner Bros. Records. The album included many songs that would become his best-known. Included among straightforward pop songs are extended jams and studio banter, such as the spoken-word track \"Intro\", in which he teaches the listener about recording flaws for an egg hunt-type game he calls \"Sounds of the Studio\". Magazine ads depicted a smiling Rundgren daring the reader to \"ignore me\". The album peaked at number 29 on the \"Billboard\" 200 and was certified gold in three years. Lead single \"I Saw the Light\" peaked at number 16 on the \"Billboard\" Hot 100. \"Hello It's Me\", which followed late in 1973, reached number 5.\nAccording to music critic Colin Larkin, \"Something/Anything?\" has since been \"rightly regarded as one of the landmark releases of the early 70s\". \"Couldn't I Just Tell You\" was influential to artists in the power pop genre. Music journalist Paul Lester called the recording a \"masterclass in compression\" and said that Rundgren \"staked his claim to powerpop immortality [and] set the whole ball rolling\". Musician Scott Miller's 2010 book \"\" calls the song \"likely the greatest power pop recording ever made\", with lyrics \"somehow both desperate and lighthearted at the same time\", and a guitar solo having \"truly amazing dexterity and inflection\". In 2003, \"Something/Anything?\" was ranked number 173 on \"Rolling Stone\" magazine's list of the \"500 Greatest Albums of All Time\".\n\"A Wizard, a True Star\", \"Todd\", and Utopia.\nSubsequent albums, beginning with \"A Wizard, a True Star\" and the spin-off group Utopia, saw a dramatic shift away from straightforward three-minute pop. After the success of \"Something/Anything?\", Rundgren felt uncomfortable that he was being increasingly tagged as \"the male Carole King\". \"With all due respect to Carole King,\" he said, \"It wasn't what I was hoping to create as a musical legacy for myself.\" Now relocated back to New York and experimenting with a host of psychedelic drugs, he began to think that the writing on \"Something/Anything?\" was largely formulaic and borne from laziness, and sought to create a \"more eclectic and more experimental\" follow-up album. His music tastes also started to lean toward the progressive rock of Frank Zappa, Yes, and the Mahavishnu Orchestra. In 2017, while giving a commencement speech at the Berklee College of Music, he described the record as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... my act of tyranny after having achieved commercial success. ... I threw out all the rules of record making and decided I would try to imprint the chaos in my head onto a record without trying to clean it up for everyone else's benefit. The result was a complete loss of about half of my audience at that point ... This became the model for my life after that.\nThe sound and structure of \"Wizard\" was heavily informed by Rundgren's hallucinogenic experiences. It was envisioned as a hallucinogenic-inspired \"flight plan\" with all the tracks segueing seamlessly into each other, starting with a \"chaotic\" mood and ending with a medley of his favorite soul songs. He said: \"With drugs I could suddenly abstract my thought processes in a certain way, and I wanted to see if I could put them on a record. A lot of people recognized it as the dynamics of a psychedelic trip\u2014it was almost like painting with your head.\" Rundgren and Moogy Klingman established a professional recording studio, Secret Sound, to accommodate the \"Wizard\" sessions. The studio was designed to Rundgren's specifications and was created so that he could freely indulge in sound experimentation without having to worry about hourly studio costs, although he maintained that the album still felt \"kind of rushed through because the studio wasn't finished\". Some of the other influences on the album included musical theater, jazz, and funk.\n\"A Wizard, a True Star\" was released in March 1973. At Rundgren's behest, no singles were issued from the album, as he wanted the tracks to be heard in the context of the LP. Its release coincided with the success of the \"Hello It's Me\" single, which gave Rundgren a reputation as a ballad singer, in marked contrast to the content on \"Wizard\". Although critical reception to the album was mixed, \"Wizard\" became highly influential to musicians in the ensuing decades. In 2003, music journalist Barney Hoskyns called the record \"the greatest album of all time ... a dizzying, intoxicating rollercoaster ride of emotions and genre mutations [that] still sounds more bravely futuristic than any ostensibly cutting-edge electro-pop being made in the 21st Century.\" In 2018, \"Pitchfork\"'s Sam Sodomsky wrote that the \"fingerprints\" of \"Wizard\" remained \"evident on bedroom auteurs to this day\".\nIn the weeks following the album's release, Rundgren produced Grand Funk Railroad's \"We're an American Band\" and the New York Dolls' self-titled debut album, which were among the most significant LPs of the year. The former album reached number two on the US charts, while the latter became a seminal forerunner of punk rock, although Rundgren never became known as a \"punk producer\". Rundgren also prepared a technologically ambitious stage show with a band later to be known as Utopia Mark I, consisting of Tony Sales, Hunt Sales, keyboardist Dave Mason, and synthesizer specialist Jean-Yves \"M Frog\" Labat. The tour began in April and was cancelled after only a couple weeks on the road.\nOnce Rundgren was finished with his production duties, he began formulating plans for an improved configuration of Utopia, but first returned to Secret Sound to record the more synthesizer-heavy double album \"Todd\", which was more material drawing on his hallucinogenic experiences. This time, he had also formed a fascination with religion and spirituality, reading books by authors such as Madame Blavatsky, Rudolf Steiner, and Jiddu Krishnamurti. Originally scheduled for release in December 1973, \"Todd\" was delayed to the next February due to a vinyl shortage caused by the 1973 oil crisis.\nDuring the making of \"Todd\", Rundgren took note of the \"fusion jazz sensibility\" between session musicians Kevin Ellman (drums) and John Siegler (bass). Rundgren chose them, along with Klingman and keyboardist Ralph Shuckett, to be the new configuration of Utopia. This line-up performed their first show at Central Park on August 25, 1973, sharing the bill with the Brecker Brothers and Hall &amp; Oates. Utopia played more shows throughout November and December, performing material from \"Something/Anything?\" and \"Wizard\" after a solo opening set by Rundgren on piano playing along to a pre-recorded track. On December 7, Rundgren appeared by himself on \"The Midnight Special\" performing \"Hello It's Me\" while dressed in jarringly flamboyant glam attire to the chagrin of some of his bandmates and Bearsville executive Paul Fishkin, who recalled that Rundgren looked \"like a fucking drag queen\".\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nIf I get that one minute of total illumination then I don't care if my whole career goes down the drain. I'd know there was an answer to everything\u2014to existence, to death.\n\u2014Todd Rundgren, September 1974\nUtopia embarked on their first successful tour between March and April 1974, after which Rundgren produced Hello People's \"The Handsome Devils\" and Hall &amp; Oates' \"War Babies\". The band's debut record came in the form of the LP titled \"Todd Rundgren's Utopia\" (November 1974). It marked Rundgren's first full-fledged venture into the progressive rock genre. Utopia released several more albums between 1975 and 1985. Although they gradually rebranded toward a rock-pop sound, \"Todd Rundgren's Utopia\" remained their highest album chart showing at number 34. Keyboardist Roger Powell recalled that Bearsville wished Utopia would have \"just gone away\", however, \"Todd's contract called for a certain number of albums over a certain number of years, so he decided that every other album would be a solo album and the next one a Utopia album.\" \n\"Initiation\", \"Faithful\", and \"Hermit of Mink Hollow\".\n\"A Wizard, a True Star\" included \"Rock N Roll Pussy\", a song aimed at former Beatle John Lennon. In 1974, Rundgren and Lennon were embroiled in a minor feud over comments Rundgren made in the February edition of \"Melody Maker\" magazine. In the article, he accused Lennon of striking a waitress at the Troubadour in Hollywood and called him a \"fucking idiot\" proselytizing revolution and \"acting like an ass\". In September, the magazine published Lennon's response, in which he denied the charges and referred to the musician as \"Turd Runtgreen\": \"I have never claimed to be a revolutionary. But I am allowed to sing about anything I want! Right?\" Later, Rundgren said, \"John and I realized we were being used and I got a phone call from him one day and we just said: 'Let's drop this now.'\"\n\"Initiation\" (1975) showed more experimentation with synthesizers, and displayed the musical influence of the avant-garde jazz fusion of contemporary acts such as the Mahavishnu Orchestra and Frank Zappa. Once again the original LP issue saw Rundgren pushing the medium to its physical limits, with the side-long suite \"A Treatise on Cosmic Fire\" clocking in at over 35\u00a0minutes.\nReleased in May 1976, \"Faithful\" saw Rundgren celebrating his tenth year as a professional musician. The album featured one side of original songs and one side of covers of significant songs from 1966, including the Yardbirds' \"Happenings Ten Years Time Ago\", the Beach Boys' \"Good Vibrations\", and two Lennon-penned Beatles songs. The arrangements of the covers were intended to sound as close to the originals as possible, and Rundgren's original songs were written as a reflection of his 1960s influences. He cited the song \"The Verb 'To Love'\" as the point in which he made the conscious decision to stop writing superficial love songs and \"seek out all other kinds of subject matter to write about\". Despite the lack of sales and promotion for \"Faithful\", lead single \"Good Vibrations\" received regular airplay on American radio.\nFollowing the completion of \"Faithful\", Rundgren spent two months on an eastern spiritual retreat, visiting Iran, Afghanistan, India, Nepal, Sri Lanka, Bali, Thailand, Japan, and Hawaii. He also opened Utopia Sound Studios in Lake Hill, New York, just outside of Woodstock, and bought a home nearby, as well as an adjoining property to be taken over as accommodation for artists who used the studio. The Lake Hill complex on Mink Hollow Road remained Rundgren's base for the next six years. In the interim until his next solo effort, he recorded three albums with Utopia. The first, \"Disco Jets\", was a tongue-in-cheek collection of instrumental disco tracks left unreleased until 2001. \"Ra\" (February 1977) was a concept album based on Egyptian mythology, which prefaced a lavish tour involving an extravagant stage set with a giant pyramid and Sphynx head. \"Oops! Wrong Planet\" (September 1977), recorded immediately after the tour, signaled the start of a more pop-oriented direction for the group.\nBy late 1977, Rundgren was in the midst of separating from then-girlfriend Bebe Buell and their infant daughter Liv Tyler. Rundgren recalled leaving his home in New York City and sequestering himself at Mink Hollow, \"after I discovered that I didn't want to cohabit any longer with Bebe, in any sense of the word ... A fortunate by-product of being so out of everything all the time and always being the odd man out ... is that you have plenty of time for self-examination.\" He intended the songs on his next solo album to be performed on piano with minimal arrangements, apart from the bass, drums and voices. In that sense, he stated that the songwriting process appeared to be \"fairly conventional\".\n\"Hermit of Mink Hollow\" was released in May 1978. Popularly viewed as his most immediately accessible work since \"Something/Anything?\", it received more public attention and radio airplay than most of Rundgren's efforts since \"A Wizard, a True Star\" and was heralded as a \"return to form\" after the string of prog records with Utopia. In the US, the LP peaked at number 36, while single \"Can We Still Be Friends\" reached number 29. The song became Rundgren's most-covered, with versions by Robert Palmer, Rod Stewart, Colin Blunstone, and Mandy Moore. To promote the work, Rundgren undertook an American tour playing at smaller venues including The Bottom Line in New York and The Roxy in Los Angeles. These shows resulted in the double live album \"Back to the Bars\", which featured a mixture of material from his solo work and Utopia, performed with backing musicians including Utopia, Spencer Davis, Daryl Hall and John Oates and Stevie Nicks.\nIn 1980, Utopia recorded a Beatles parody album in the form of \"Deface the Music\". It included \"Everybody Else Is Wrong\", another song perceived to have been aimed at Lennon. Later that year, Lennon was killed by Mark David Chapman, an obsessive Rundgren fan who was incensed by Lennon's remarks on religion. When he was apprehended, Chapman was wearing a promotional T-shirt for \"Hermit of Mink Hollow\" and had left a copy of \"Runt. The Ballad of Todd Rundgren\" in his hotel room. Rundgren was not aware of the connections until \"way after the fact\". When asked about the \"Melody Maker\" feud, Chapman stated he was not aware of the musicians' interactions in the press until years after they occurred.\n\"Healing\" and \"Tortured Artist Effect\".\nThe year 1981 saw the album-long concept work \"Healing\". His music video for the song \"Time Heals\" was among the first videos aired on MTV, and a video he produced for RCA, accompanied by Gustav Holst's \"The Planets\", was used as a demo for their videodisc players. Rundgren's experience with computer graphics dates back to 1981, when he developed one of the first computer paint programs, dubbed the Utopia Graphics System; it ran on an Apple II with Apple's digitizer tablet. He is also the co-developer of the computer screensaver system Flowfazer.\nDuring this period, Rundgren's Mink Hollow home was robbed. He and his girlfriend were tied up in the home by the robbers as part of the crime. \nThe new wave-tinged \"The Ever Popular Tortured Artist Effect\" (1982) included a cover of the Small Faces' hit \"Tin Soldier\". \"Bang The Drum All Day\", an album single, was a minor chart hit. It later became more prominent and was adopted as an unofficial theme by several professional sports franchises, notably the Green Bay Packers. Disc Jockey Geno Michellini of KLOS in Los Angeles used \"Bang The Drum All Day\" as an unofficial kick-off to the weekend on Friday afternoons. \"Bang The Drum All Day\" was also featured in a Carnival Cruise television advertising campaign. It is now considered one of Rundgren's most popular songs. \"Tortured Artist\" marked the end of Rundgren's tenure with Bearsville Records.\n1980s\u20131990s: \"A Cappella\", \"Nearly Human\", and \"2nd Wind\".\nRundgren signed with Warner Bros. Records, who issued his next album, \"A Cappella\" (1985), which was recorded using Rundgren's multi-tracked voice, accompanied by arrangements constructed entirely from programmed vocal samples. Rundgren scored four episodes of the popular children's television show \"Pee-wee's Playhouse\" in 1986.\n\"Nearly Human\" (1989) and \"2nd Wind\" (1991) were both recorded live\u2014the former in the studio, the latter in a theater before a live audience, who were instructed to remain silent. Each song on these albums was recorded as a complete single take with no later overdubbing. Both albums marked, in part, a return to his Philly soul roots. \"2nd Wind\" also included several excerpts from Rundgren's musical \"Up Against It\", which was adapted from the screenplay (originally titled \"Prick Up Your Ears\"), that British playwright Joe Orton had originally offered to the Beatles for their never-made follow-up to \"Help!\".\nRundgren was an early adopter of the NewTek Video Toaster and made several videos with it. The first, for \"Change Myself\" from \"2nd Wind\", was widely distributed as a demo reel for the Toaster. Later, he set up a company to produce 3D animation using the Toaster; this company's first demo, \"Theology\" (a look at religious architecture through the ages featuring music by former Utopia bandmate Roger Powell) also became a widely circulated item among Toaster users.\nIn 1989, Rundgren hit the road with \"Nearly Human\u20142nd Wind\" band, which included brass and a trio of backup singers (one of whom, Michele Gray, Rundgren married). He also toured during 1992 with Ringo Starr's second All-Starr band.\nA brief 1992 tour of Japan reunited the Rundgren/Powell/Sulton/Wilcox lineup, and \"\" was released on Rhino Records.\n1990s\u20132000s: TR-I, PatroNet, and \"Liars\".\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nAs the 90s began, Rundgren was already moving away from conventional notions of what a rock producer or recording artist should be ... While Rundgren would continue to produce records for himself, and others, many of the innovative and individual technologies and business models he embraced and/or pioneered over the next 20 years would have such an empowering effect on future artists as to render redundant record producers, big studios, and even record labels.\n\u2014Paul Myers, \"A Wizard, a True Star: Todd Rundgren in the Studio\"\nThe mid-1990s saw Rundgren recording under the pseudonym TR-i (\"Todd Rundgren interactive\") for two albums. The first of these, 1993's \"No World Order\", consisted of hundreds of seconds-long snippets of music, that could be combined in various ways to suit the listener. Initially targeted for the Philips CD-i platform, \"No World Order\" featured interactive controls for tempo, mood, and other parameters, along with pre-programmed mixes by Rundgren himself, Bob Clearmountain, Don Was and Jerry Harrison. The disc was also released for PC and Macintosh and in two versions on standard audio CD, the continuous mix disc \"No World Order\" and, later, the more song-oriented \"No World Order Lite\". The music itself was quite a departure from Rundgren's previous work, with a dance/techno feel and much rapping by Rundgren. The follow-up, \"The Individualist\" (1995), featured interactive video content, that could be viewed or in one case, played; it was a simple video game along with the music, which was more rock-oriented than \"No World Order\".\nIn 1994, Rundgren composed the film score for the comedy film \"Dumb and Dumber\", and contributed the song \"Can We Still Be Friends?\" to the soundtrack.\nRundgren returned to recording under his own name for \"With a Twist...\" (1997), an album of bossa-nova covers of his older material. His PatroNet work, which trickled out to subscribers over more than a year, was released in 2000 as \"One Long Year\". In 2004, Rundgren released \"Liars\", a concept album about \"paucity of truth\", that features a mixture of his older and newer sounds.\nAs the Internet gained mass acceptance, Rundgren, along with longtime manager Eric Gardner and Apple digital music exec Kelli Richards, started PatroNet, which offered fans (patrons) access to his works-in-progress and new unreleased tracks in exchange for a subscription fee, cutting out record labels. The songs from Rundgren's first PatroNet run were later released as the album \"One Long Year\". Since then, Rundgren has severed his connections with major record labels and continues to offer new music direct to subscribers via his website, although he also continues to record and release CDs through independent labels. As of 2022, the PatroNet.com website was not active.\n2000s\u20132010s.\nIn the aftermath of the September 11 attacks, Rundgren created the score for the film \"A Face to a Name\", directed by Douglas Sloan. The film depicted numerous photographs of missing New Yorkers that were displayed on Bellevue Hospital's 'wall of prayers' following the attacks. The film was part of a special screening at the Woodstock Film Festival in 2002.\nIn late 2005, the Boston-based band the Cars were planning to re-form despite bassist Benjamin Orr's death and lack of interest on the part of former lead singer Ric Ocasek. Rumors followed that Rundgren had joined Elliot Easton and Greg Hawkes in rehearsals for a possible new Cars lineup. Initial speculation pointed to the New Cars being fleshed out with Clem Burke of Blondie and Art Alexakis of Everclear. Eventually the group completed their lineup with former Rundgren bassist Kasim Sulton and studio drummer Prairie Prince of the Tubes, who had played on XTC's Rundgren-produced \"Skylarking\" and who has recorded and toured with Rundgren.\nIn early 2006, the new lineup played a few private shows for industry professionals, played live on \"The Tonight Show with Jay Leno\" and made other media appearances before commencing a 2006 summer tour with the re-formed Blondie. Rundgren referred to the project as \"an opportunity ... for me to pay my bills, play to a larger audience, work with musicians I know and like, and ideally have some fun for a year.\" The New Cars' first single, \"Not Tonight\", was released on March 20, 2006. A live album/greatest hits collection, \"The New Cars: It's Alive\", was released in June 2006. The album includes classic Cars songs (and two Rundgren hits) recorded live plus three new studio tracks (\"Not Tonight\", \"Warm\", and \"More\")\nIn April 2011, \"Todd Rundgren's Johnson\", a collection of Robert Johnson covers, which had been recorded more than a year earlier, was released. In another 2011, an album of covers, \"(re)Production\", features Rundgren performing tracks he had previously produced for other acts, including Grand Funk Railroad's \"Walk Like a Man\" and XTC's \"Dear God\".\nIn 2017, Rundgren released \"White Knight\", which features collaborations with Trent Reznor, Robyn, Daryl Hall, Joe Walsh and Donald Fagen.\nIn December 2018, Cleopatra Press published his self-penned memoir, \"The Individualist: Digressions, Dreams, and Dissertations\". The book contains 181 chapters, each one page long, and each consisting of three paragraphs. He said that \"I realized that I have to do this or somebody else will do it. I'm getting to the point where I could at some point not be able to do it myself, and then someone else would do it and I wouldn't be happy with the result.\" Its coverage ends at Rundgren's 50th birthday in 1998, which was the same time he began writing the book. Since then, he said, \"my life has been a lot more boring ... I'm not doing as much record production as I used to, so interesting tales that go along with those projects don't exist anymore.\" On October 21, 2019, he stopped by the Library of Congress and signed a braille copy\u2014which was produced for him by a fan and National Library Service for the Blind and Print Disabled patron who is blind.\nRundgren toured in late 2019 with Micky Dolenz, Jason Scheff, Christopher Cross and Joey Molland of Badfinger in celebration of the Beatles' self-titled 1968 album on the \"It Was Fifty Years Ago Today \u2013 A Tribute to the Beatles' White Album\".\n2020s.\nRundgren collaborated with Weezer frontman Rivers Cuomo in 2020, releasing the single \"Down With The Ship\". In December, he released his English translation of the 1978 song \"Flappie\", originally by Dutch comedian Youp van 't Hek. That April, he reunited with Sparks 50 years after producing their debut album, releasing a single \"Your Fandango\". In September 2022, he released the album \"Space Force\".\nHe provided additional vocals along with the Sunday Service Choir, on the track \"My Soul\", by hip hop superduo \u00a5$, from their album \"Vultures 2\", released on 3 August 2024.\nStyle and recognition.\nAs a solo artist.\nWriting for AllMusic, music critic Stephen Thomas Erlewine recognizes Rundgren thus:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Todd Rundgren's best-known songs \u2013 the Carole King pastiche \"I Saw the Light\", the ballads \"Hello, It's Me\" and \"Can We Still Be Friends\", and the goofy novelty \"Bang on the Drum All Day\" \u2013 suggest that he is a talented pop craftsman ... but at his core, Rundgren is a rock &amp; roll maverick. Once he had a taste of success with his 1972 masterwork \"Something/Anything?\", Rundgren chose to abandon stardom and, with it, conventional pop music. He began a course through uncharted musical territory, becoming a pioneer not only in electronic music and prog rock, but in music video, computer software, and Internet music delivery as well.\nAs a solo artist from 1972 to 1978, Rundgren scored four US Top 40 singles on the \"Billboard\" Hot 100, including one Top 10 hit with \"Hello, It's Me\", and three US Top 40 albums on the \"Billboard\" 200. He is one of the first acts to be prominent both as an artist and as a producer. and he was also influential in the fields of power pop, lo-fi, overdubbing, and experimental music. Rundgren performed in an eclectic variety of styles, so much so that his singles often contrasted with other tracks from the LPs from which they derived, which curtailed his mass appeal. Of his early incorporation of digital technology, he said \"I wasn't the first to start recording digitally, because it was so expensive. But once the technology came down to where I could afford it, then I went digital.\" Rundgren said that adapting his sound to meet commercial expectations was also never an issue for him since he already made \"so much money from production\", a rare luxury for an artist.\nAs a producer.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nIf it weren't for my musical career, I probably would have ended up attending college to become a computer programmer.\n\u2014Todd Rundgren\nComparisons are sometimes drawn between Rundgren and producer/artists Brian Wilson and Brian Eno. Biographer Paul Myers attributes the recording studio to be Rundgren's \"ultimate instrument\". Rundgren acknowledged that, in the case of his own records, he does not think \"as a producer\", but uses the studio to \"assist in creating a performance\". His recording processes continued in the same tradition as multitrack recording innovator Les Paul as well as the studio experiments of the Beatles and the Beach Boys.\nAccording to biographer Myers, Rundgren himself came to inspire \"a generation of self-contained geniuses like Prince ... Ironically, some of his innovations would come to liberate the recording artist in such a way as to lessen the perceived value, or need, for a record producer at all.\" Rundgren's influence is also cited to Hall &amp; Oates, Bj\u00f6rk and Daft Punk. \"Slate\" writer Marc Weingarten identified \"A Cappella\" as the precedent for Bj\u00f6rk's \"all vocals, all the time\" experiment \"Med\u00falla\" (2004) and said that, overall, \"The two [artists] share more common ground than their fans might think.\"\nRundgren's production work for other artists were largely one-off affairs. Exceptions were Grand Funk Railroad, the New York Dolls, the Tubes, Hello People, and the Pursuit of Happiness. He described his typical function as being a \"'songcraft' agitator\". In cases where the act's songs were unfinished, he would complete them and decline a writer's credit. Some of his collaborators frequently characterize him as a \"genius\", but also \"sarcastic\" and \"aloof\". His most notorious production was for XTC's 1986 album \"Skylarking\", known for the creative tensions and disagreements that arose during its sessions. The album is sometimes regarded as both the pinnacle of Rundgren's production career and of the career of XTC. He commented that, in spite of the turmoil surrounding its making, the record \"ultimately ... sounds like we were having a great time doing it. And at times we \"were\" having a good time.\" All three members expressed admiration for the end product.\nThe Fool guitar.\nDuring the mid-to-late 1970s, Rundgren regularly played the eye-catching psychedelic Gibson SG (known variously as \"Sunny\" or \"The Fool\"), which Eric Clapton had played in Cream. After he had stopped using it ca. 1968, Clapton gave the guitar to George Harrison, who subsequently 'loaned' it to British singer Jackie Lomax. In 1972, after meeting at a recording session, Lomax sold the guitar to Rundgren for $500 with an option to buy it back, which he never took up. Rundgren played it extensively during the early years of Utopia before retiring the instrument for a short time in the mid to late 1970s, which in that time he had the guitar restored having a lacquer finish applied to protect the paint and replaced the tailpiece and bridge to stabilize tuning, bringing the guitar back out on tour during the 1980 Deface the Music tour and using it on and off throughout the 1980s until 1993 when he permanently retired the guitar, eventually auctioning it off in 1999; he now uses a reproduction given to him in 1988 by a Japanese fan.\nPersonal life.\nRundgren began a relationship with model Bebe Buell in 1972. During a break in their relationship, Buell had a brief relationship with Aerosmith lead vocalist Steven Tyler, which resulted in an unplanned pregnancy. Buell gave birth to Liv Tyler on July 1, 1977. Buell initially claimed that Rundgren was the biological father and named the child Liv Rundgren. Shortly after Liv's birth, Rundgren and Buell ended their romantic relationship, but Rundgren remained committed to Liv. At age eleven, Liv learned that her biological father was Steven Tyler. \nAccording to Liv Tyler, \"Todd basically decided when I was born that I needed a father so he signed my birth certificate. He knew that there was a chance that I might not be his, but ...\" Buell\u2019s stated reason for claiming that Rundgren was Liv's father was that Tyler was too heavily addicted to drugs at the time of Liv's birth.\nTyler maintains a close relationship with Rundgren. \"I'm so grateful to him, I have so much love for him. You know, when he holds me it feels like Daddy. And he's very protective and strong.\"\nRundgren had a long-term relationship with Karen Darvin, with whom he had two sons, Rex (born 1980) and Randy (born 1985). Rex was a minor league baseball player (infielder) for nine seasons. Darvin had previously been in a relationship with Bruce Springsteen.\nRundgren married Michele Gray in 1998. Gray was a dancer with the Tubes in 1985 when Utopia opened for them. Shortly thereafter, she began performing with Rundgren as a backup singer, including his \"A Cappella\" tour later that year. She also sang on the tour for his album \"Nearly Human\" which led to a number of appearances on \"Late Night with David Letterman\" as one of \"The World's Most Dangerous Backup Singers\". Together, they have a son, named Rebop, and an adoptive son, named Keoni.\nPaul Myers, in his 2010 book on Rundgren, \"A Wizard, a True Star: Todd Rundgren in the Studio\", reported that Rundgren diagnosed himself with attention-deficit disorder.\nDiscography.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36796", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=36796", "title": "Paclitaxel", "text": "Medication used for cancer\n&lt;templatestyles src=\"Infobox drug/styles.css\"/&gt;\nPaclitaxel, sold under the brand name Taxol among others, is a chemotherapy medication used to treat ovarian cancer, esophageal cancer, breast cancer, lung cancer, Kaposi's sarcoma, cervical cancer, and pancreatic cancer. It is administered by intravenous injection. There is also an albumin-bound formulation.\nCommon side effects include hair loss, bone marrow suppression, numbness, allergic reactions, muscle pains, and diarrhea. Other side effects include heart problems, increased risk of infection, and lung inflammation. There are concerns that use during pregnancy may cause birth defects. Paclitaxel is in the taxane family of medications. It works by interference with the normal function of microtubules during cell division.\nPaclitaxel was isolated in 1971 from the Pacific yew and approved for medical use in 1993. It is on the World Health Organization's List of Essential Medicines. It has been made from precursors, and through cell culture.\nMedical use.\nPaclitaxel is approved in the UK for ovarian, breast, lung, bladder, prostate, melanoma, esophageal, and other types of solid tumor cancers as well as Kaposi's sarcoma.\nIt is recommended in National Institute for Health and Care Excellence (NICE) guidance of June 2001 for non-small-cell lung cancer in patients unsuitable for curative treatment, and in first-line and second-line treatment of ovarian cancer. In September 2001, NICE recommended paclitaxel for the treatment of advanced breast cancer after the failure of anthracyclic chemotherapy, but that its first-line use should be limited to clinical trials. In September 2006, NICE recommended paclitaxel should \"not\" be used in the adjuvant treatment of early node-positive breast cancer.\nIt is approved in the United States for the treatment of breast, pancreatic, ovarian, Kaposi's sarcoma and non-small-cell lung cancers.\nSimilar compounds.\nAlbumin-bound paclitaxel (brand name Abraxane, also called nab-paclitaxel) is an alternative formulation where paclitaxel is bound to albumin nanoparticles. Much of the clinical toxicity of paclitaxel is associated with the solvent Cremophor EL in which it is dissolved for delivery.\nAbraxis BioScience developed Abraxane, in which paclitaxel is bonded to albumin as an alternative delivery agent to the often toxic solvent delivery method. This was approved by the FDA in January 2005, for the treatment of breast cancer after failure of combination chemotherapy for metastatic disease or relapse within six months of adjuvant chemotherapy. It has since been approved for locally advanced or metastatic non-small cell lung cancer and metastatic adenocarcinoma of the pancreas as well.\nTaxanes, including paclitaxel, 10-deacetylbaccatin III, baccatin III, paclitaxel C, and 7-epipaclitaxel, have been found in the leaves and shells of hazel. The finding of these compounds in shells, which are considered discarded material and are mass-produced by many food industries, is of interest for the future availability of paclitaxel.\nRestenosis.\nPaclitaxel is used as an antiproliferative agent for the prevention of restenosis (recurrent narrowing) of coronary and peripheral stents; locally delivered to the wall of the artery, a paclitaxel coating limits the growth of neointima (scar tissue) within stents. Paclitaxel drug-eluting stents for coronary artery placement are sold under the trade name Taxus by Boston Scientific in the United States. Paclitaxel drug-eluting stents for femoropopliteal artery placement are also available.\nSide effects.\nCommon side effects include nausea and vomiting, loss of appetite, change in taste, thinned or brittle hair, pain in the joints of the arms or legs lasting two to three days, changes in the color of the nails, and tingling in the hands or toes. More serious side effects such as unusual bruising or bleeding, pain, redness or swelling at the injection site, hand-foot syndrome, change in normal bowel habits for more than two days, fever, chills, cough, sore throat, difficulty swallowing, dizziness, shortness of breath, severe exhaustion, skin rash, facial flushing, female infertility by ovarian damage, and chest pain can also occur. Neuropathy may also occur.\nDexamethasone is given prior to paclitaxel infusion to mitigate some of the side effects.\nA number of these side effects are associated with the excipient used, Cremophor EL, a polyoxyethylated castor oil. Allergies to cyclosporine, teniposide, and other drugs delivered in polyoxyethylated castor oil may increase the risk of adverse reactions to paclitaxel.\nMechanism of action.\nPaclitaxel is one of several cytoskeletal drugs that target tubulin. Paclitaxel-treated cells have defects in mitotic spindle assembly, chromosome segregation, and cell division. Unlike other tubulin-targeting drugs, such as colchicine, that inhibit microtubule assembly, paclitaxel stabilizes the microtubule polymer and protects it from disassembly. Chromosomes are thus unable to achieve a metaphase spindle configuration. This blocks the progression of mitosis and prolonged activation of the mitotic checkpoint triggers apoptosis or reversion to the G0-phase of the cell cycle without cell division.\nThe ability of paclitaxel to inhibit spindle function is generally attributed to its suppression of microtubule dynamics, but other studies have demonstrated that suppression of dynamics occurs at concentrations lower than those needed to block mitosis. At the higher therapeutic concentrations, paclitaxel appears to suppress microtubule detachment from centrosomes, a process normally activated during mitosis. Paclitaxel binds to the beta-tubulin subunits of microtubules.\nChemistry.\nThe nomenclature for paclitaxel is structured on a tetracyclic 17-atom skeleton. There are a total of 11 stereocenters. The active stereoisomer is (\u2212)-paclitaxel (shown here).\nProduction.\nBark processing.\nFrom 1967 to 1993, almost all paclitaxel produced was derived from bark of the Pacific yew, \"Taxus brevifolia\", the harvesting of which kills the tree in the process. The processes used were descendants of the original isolation method of Monroe Wall and Mansukh Wani; by 1987, the U.S. National Cancer Institute (NCI) had contracted Hauser Chemical Research of Boulder, Colorado, to handle bark on the scale needed for phase II and III trials. While both the size of the wild population of the Pacific yew and the magnitude of the eventual demand for paclitaxel were uncertain, it was clear that an alternative, sustainable source of the natural product would be needed. Initial attempts to broaden its sourcing used needles from the tree, or material from other related \"Taxus\" species, including cultivated ones, but these attempts were challenged by the relatively low and often highly variable yields obtained. Early in the 1990s, coincident with increased sensitivity to the ecology of the forests of the Pacific Northwest, paclitaxel was extracted on a clinically useful scale from these sources.\nSemisynthesis.\nConcurrently, synthetic chemists in the U.S. and France had been interested in paclitaxel, beginning in the late 1970s. As noted, by 1992 extensive efforts were underway to accomplish the total synthesis of paclitaxel, efforts motivated by the desire to generate new chemical understanding rather than to achieve practical commercial production. In contrast, the French group of Pierre Potier at the Centre national de la recherche scientifique (CNRS) addressed the matter of overall process yield, showing that it was feasible to isolate relatively large quantities of the compound 10-deacetylbaccatin from the European yew, \"Taxus baccata\", which grew on the CNRS campus and whose needles were available in large quantity. By virtue of its structure, 10-deacetylbaccatin was seen as a viable starting material for a short semisynthesis to produce paclitaxel. By 1988, Poitier and collaborators had published a semisynthetic route from needles of the European yew to paclitaxel.\nThe view of the NCI, however, was that even this route was not practical. The group of Robert A. Holton had also pursued a practical semisynthetic production route; by late 1989, Holton's group had developed a semisynthetic route to paclitaxel with twice the yield of the Potier process. The main innovation was \"Ojima\u2212Holton coupling\", a ring-opening method independently discovered by Holton and Ojima. Florida State University, where Holton worked, signed a deal with Bristol-Myers Squibb (BMS) to license their semisynthesis and future patents. In 1992, Holton patented an improved process with an 80% yield, and BMS took the process in-house and started to manufacture paclitaxel in Ireland from 10-deacetylbaccatin isolated from the needles of the European yew. In early 1993, BMS announced that it would cease reliance on Pacific yew bark by the end of 1995, effectively terminating ecological controversy over its use. This announcement also made good their commitment to develop an alternative supply route, made to the NCI in their cooperative research and development agreement (CRADA) application of 1989.\nAs of 2013, BMS was using the semisynthetic method utilizing needles from the European yew to produce paclitaxel. Another company which worked with BMS until 2012, Phyton Biotech, Inc., uses plant cell fermentation (PCF) technology. By cultivating a specific \"Taxus\" cell line in fermentation tanks, they no longer need ongoing sourcing of material from actual yew tree plantations. Paclitaxel is then captured directly from the suspension broth by a resin allowing concentration to highly enriched powder containing about 40% paclitaxel. The compound is then purified by one chromatographic step followed by crystallization. Compared to the semisynthesis method, PCF eliminates the need for many hazardous chemicals and saves a considerable amount of energy.\nIn 1993, paclitaxel was discovered as a natural product in \"Taxomyces andreanae\", a newly described endophytic fungus living in the yew tree. It has since been reported in a number of other endophytic fungi, including \"Nodulisporium sylviforme\", \"Alternaria taxi\", \"Cladosporium cladosporioides\" MD2, \"Metarhizium anisopliae\", \"Aspergillus candidus\" MD3, \"Mucor rouxianus\", \"Chaetomella raphigera\", \"Phyllosticta tabernaemontanae\", \"Phomopsis\", \"Pestalotiopsis pauciseta\", \"Phyllosticta citricarpa\", \"Podocarpus\" sp., \"Fusarium solani\", \"Pestalotiopsis terminaliae\", \"Pestalotiopsis breviseta\", \"Botryodiplodia theobromae\", \"Gliocladium\" sp., \"Alternaria alternata\" var. \"monosporus\", \"Cladosporium cladosporioides\", \"Nigrospora\" sp. and \"Pestalotiopsis versicolor\". However, there has been contradictory evidence for its production by endophytes, with other studies finding independent production is unlikely.\nBiosynthesis.\nTaxol is a tetracyclic diterpene, and the biosynthesis of diterpenes starts with an FPP molecule being elongated by the addition of an IPP molecule in order to form geranylgeranyl diphosphate (GGPP). The biosynthesis of Taxol contains nineteen steps. These 19 steps can be considered in several steps, with the first step being the formation of the taxane skeleton, which then undergoes a series of oxygenations. Following the oxygenations, two acetylations and a benzoylation occur on the intermediate. The oxygenation of the taxane core is believed to occur on C5 and C10, C2 and C9, C13 followed by C7, and a C1 hydroxylation later on in the pathway. Later in the pathway, an oxidation at C9 forms a ketone functional group and an oxetane, forming the intermediate baccatin III. The final steps of the pathway include the formation of a C13-side chain which is attached to baccatin III. The biosynthesis of Taxol is illustrated in more detail in the figure, with steps 1-7 all occurring in the enzyme taxadiene synthase (TS on the figure). Taxol's biosynthesis begins with E,E,E-GGPP losing pyrophosphate via an SN1 mechanism (step 1 in the figure). The double-bond attacks the cation via electrophilic addition, yielding a tertiary cation and creating the first ring closure (step 2). Another electrophilic attack occurs, further cyclizing the structure by creating the first 6-membered ring and creating another tertiary cation (step 3). An intramolecular proton transfer occurs, attacking the verticillyl cation (step 4) and creating a double bond, yielding a tertiary cation. An electrophilic cyclization occurs in step 5, and an intramolecular proton transfer attacks the taxenyl cation (step 6). This forms the fused ring structure intermediate known as taxadiene. Taxadiene then undergoes a series of 10 oxidations via NADPH, forming the intermediate taxadiene-5\u03b1-acetoxy-10\u03b2-ol (multiple steps later in the figure). A series of hydroxylations and esterficiations occur, forming the intermediate 10-deacetyl-baccatin III, which undergoes a further series of esterifications and a side-chain hydroxylation. This finally yields the product paclitaxel.\nTotal synthesis.\nBy 1992, at least thirty academic research teams globally were working to achieve a total synthesis of this natural product, with the synthesis proceeding from simple natural products and other readily available starting materials. This total synthesis effort was motivated primarily by the desire to generate new chemical understanding, rather than with an expectation of the practical commercial production of paclitaxel. The first laboratories to complete the total synthesis from much less complex starting materials were the research groups of Robert A. Holton, who had the first article to be accepted for publication, and of K. C. Nicolaou who had the first article to appear in print (by a week, on 7 February 1994). Though the Holton submission preceded the Nicolaou by a month (21 December 1993 versus 24 January 1994), the near coincidence of the publications arising from each of these massive, multiyear efforts\u201411\u201318 authors appearing on each of the February 1994 publications\u2014has led the ending of the race to be termed a \"tie\" or a \"photo finish\", though each group has argued that their synthetic strategy and tactics were superior.\nAs of 2006, five additional research groups had reported total syntheses of paclitaxel: Wender et al. in 1997, and Kuwajima et al. and Mukaiyama et al. in 1998 with further linear syntheses, and Danishefsky et al. in 1996 and Takahashi et al. in 2006 with further convergent syntheses. As of that date, all strategies had aimed to prepare a 10-deacetylbaccatin-type core containing the ABCD ring system, followed generally by last stage addition of the \"tail\" to the 13-hydroxyl group.\nWhile the \"political climate surrounding [paclitaxel] and [the Pacific yew] in the early 1990s ... helped bolster [a] link between total synthesis and the [paclitaxel] supply problem,\" and though total synthesis activities were a requisite to explore the structure-activity relationships of paclitaxel via generation of analogs for testing, the total synthesis efforts were never seen \"as a serious commercial route\" to provide significant quantities of the natural product for medical testing or therapeutic use.\nHistory.\nThe discovery of paclitaxel began in 1962 as a result of a NCI-funded screening program. A number of years later it was isolated from the bark of the Pacific yew, \"Taxus brevifolia\", hence its name \"taxol\".\nThe discovery was made by Monroe E. Wall and Mansukh C. Wani at the Research Triangle Institute, Research Triangle Park, North Carolina, in 1971. These scientists isolated the natural product from the bark of the Pacific yew tree, determined its structure and named it \"taxol\", and arranged for its first biological testing. The compound was then developed commercially by BMS, who had the generic name assigned as \"paclitaxel\".\nPlant screening program.\nIn 1955, the NCI in the United States set up the Cancer Chemotherapy National Service Center (CCNSC) to act as a public screening center for anticancer activity in compounds submitted by external institutions and companies. Although the majority of compounds screened were of synthetic origin, one chemist, Jonathan Hartwell, who was employed there from 1958 onwards, had experience with natural product derived compounds, and began a plant screening operation.\nAfter some years of informal arrangements, in July 1960, the NCI commissioned the United States Department of Agriculture (USDA) botanists to collect samples from about 1,000 plant species per year. On 21 August 1962, one of those botanists, Arthur S. Barclay, collected bark from a single Pacific yew tree in a forest north of the town of Packwood, Washington, as part of a four-month trip to collect material from over 200 different species. The material was then processed by a number of specialist CCNSC subcontractors, and one of the tree's samples was found to be cytotoxic in a cellular assay on 22 May 1964.\nAccordingly, in late 1964 or early 1965, the fractionation and isolation laboratory run by Monroe E. Wall in Research Triangle Park, North Carolina, began work on fresh \"Taxus\" samples, isolating the active ingredient in September 1966 and announcing their findings at an April 1967 American Chemical Society meeting in Miami Beach. They named the pure compound taxol in June 1967. Wall and his colleague Wani published their results, including the chemical structure, in 1971.\nThe NCI continued to commission work to collect more \"Taxus\" bark and to isolate increasing quantities of taxol. By 1969, of crude extract had been isolated from almost of bark, although this ultimately yielded only of pure material, but for several years, no use was made of the compound by the NCI. In 1975, it was shown to be active in another \"in vitro\" system; two years later, a new department head reviewed the data and finally recommended taxol be moved on to the next stage in the discovery process. This required increasing quantities of purified taxol, up to , and in 1977 a further request for of bark was made.\nIn 1978, two NCI researchers published a report showing that taxol was mildly effective in leukaemic mice. In November 1978, taxol was shown to be effective in xenograft studies. Meanwhile, taxol began to be well known in the cell biology, as well as the cancer communities, with a publication in early 1979 by Susan B. Horwitz, a molecular pharmacologist at Albert Einstein College of Medicine, showing that taxol had a previously unknown mechanism of action involving the stabilization of microtubules. Together with formulation problems, this increased interest from researchers meant that, by 1980, the NCI envisaged needing to collect of bark. Animal toxicology studies were completed by June 1982, and in November, the NCI applied for the IND necessary to begin clinical trials in humans.\nEarly clinical trials, supply and the transfer to BMS.\nPhase I clinical trials began in April 1984, and the decision to start Phase II trials was made a year later. These larger trials needed more bark and collection of a further 12,000 pounds was commissioned, which enabled some phase II trials to begin by the end of 1986. But by then it was recognized that the demand for taxol might be substantial and that more than 60,000 pounds of bark might be needed as a minimum. This unprecedentedly large amount brought ecological concerns about the impact on yew populations into focus for the first time, as local politicians and foresters expressed unease at the program.\nThe first public report from a phase II trial in May 1988 showed promising effects in melanoma and refractory ovarian cancer. At this point, Gordon Cragg of the NCI's Natural Product Branch calculated the isolation of enough taxol to treat all the ovarian cancer and melanoma cases in the US would require the destruction of 360,000 trees annually. For the first time, serious consideration was given to the problem of supply.\nBecause of the practical and, in particular, the financial scale of the program needed, the NCI decided to seek association with a pharmaceutical company, and in August 1989, it published a Cooperative Research and Development Agreement (CRADA) offering its current stock and supply from current bark stocks, and proprietary access to the data so far collected, to a company willing to commit to providing the funds to collect further raw material, isolate taxol, and fund a large proportion of clinical trials. In the words of Goodman and Welsh, authors of a substantial scholarly book on taxol, \"The NCI was thinking, not of collaboration, ... but of a hand-over of taxol (and its problems)\".\nAlthough the offer was widely advertised, only four companies responded to the CRADA, including the American firm Bristol-Myers Squibb (BMS),\nwhich was selected as the partner in December 1989. The choice of BMS later became controversial and was the subject of Congressional hearings in 1991 and 1992. While it seems clear the NCI had little choice but to seek a commercial partner, there was also controversy about the terms of the deal, eventually leading to a report by the General Accounting Office in 2003, which concluded the NIH had failed to ensure value for money. In related CRADAs with the USDA and Department of the Interior, Bristol-Myers Squibb was given exclusive first refusal on all Federal supplies of \"Taxus brevifolia\".\nThis exclusive contract lead to some criticism for giving BMS a \"cancer monopoly\".\nEighteen months after the CRADA, BMS filed a new drug application (NDA), which was given FDA approval at the very end of 1992.\nAlthough there was no patent on the compound, the provisions of the Waxman-Hatch Act gave Bristol-Myers Squibb five years exclusive marketing rights.\nIn 1990, BMS applied to trademark the name taxol as \"Taxol(R)\". This was controversially approved in 1992. At the same time, paclitaxel replaced taxol as the generic (INN) name of the compound. Critics, including the journal \"Nature\", argued the name taxol had been used for more than two decades and in more than 600 scientific articles and suggested the trademark should not have been awarded and the BMS should renounce its rights to it. BMS argued changing the name would cause confusion among oncologists and possibly endanger the health of patients. BMS has continued to defend its rights to the name in the courts.\nBMS has also been criticized for misrepresentation by Goodman and Walsh, who quote from a company report saying \"It was not until 1971 that ... testing ... enabled the isolation of paclitaxel, initially described as 'compound 17\". This quote is, strictly speaking, accurate: the objection seems to be that this misleadingly neglects to explain that it was the scientist doing the isolation who named the compound taxol and it was not referred to in any other way for more than twenty years. Annual sales peaked in 2000 (the same year that several of BMS's Taxol patents were invalidated via legal challenge from generic manufacturers), reaching US$1.6 billion; paclitaxel became available in generic form in 2000.\nSociety and culture.\nLegal status.\nPaclitaxel was approved for medical use in the European Union in 2008.\nIn November 2023, the Committee for Medicinal Products for Human Use (CHMP) of the European Medicines Agency adopted a positive opinion, recommending the granting of a marketing authorization for the medicinal product Naveruclif, intended for the treatment of metastatic breast cancer, metastatic adenocarcinoma of the pancreas and non-small cell lung cancer. The applicant for this medicinal product is Accord Healthcare S.L.U. Naveruclif was approved for medical use in the European Union in January 2024.\nIn May 2024, the CHMP adopted a positive opinion, recommending the granting of a marketing authorization for the medicinal product Apexelsin, intended for the treatment of metastatic breast cancer, metastatic adenocarcinoma of the pancreas and non-small cell lung cancer. The applicant for this medicinal product is WhiteOak Pharmaceutical B.V. Apexelsin was approved for medical use in the European Union in July 2024.\nEconomics.\nAs of 2006[ [update]], the cost to the NHS per patient in early breast cancer, assuming four cycles of treatment, was about \u00a34,000 (approx. $6,000).\nResearch.\nCaffeine has been speculated to inhibit paclitaxel-induced apoptosis in colorectal cancer cells.\nIn 2016, \"in vitro\" multi-drug resistant mouse tumor cells were treated with paclitaxel encased in exosomes. Doses 98% less than common dosing had the same effect. Also, dye-marked exosomes were able to mark tumor cells, potentially aiding in diagnosis.\nAside from its direct clinical use, paclitaxel is also used extensively in biological and biomedical research as a microtubule stabilizer. In general, \"in vitro\" assays involving microtubules, such as motility assays, rely on paclitaxel to maintain microtubule integrity in the absence of the various nucleating factors and other stabilizing elements found in the cell. For example, it is used for \"in vitro\" tests of drugs that aim to alter the behavior of microtubule motor proteins, or for studies of mutant motor proteins.\nPaclitaxel has also been used \"in vitro\" to inhibit insulin fibrillation. In a molar ratio of 10:1 (insulin:paclitaxel), it hindered insulin fibrillation near 70%. Isothermal titration calorimetry (ITC) findings indicated a spontaneous tendency of paclitaxel to interact with insulin through hydrogen bonds and van der Waals forces. The inhibitory role of paclitaxel is attributed to its impact on the colloidal stability of protein solution, as it was observed that paclitaxel inhibited lysozyme fibrillation by inducing the formation of \"off-pathway\" oligomeric intermediates, subsequently increasing the colloidal stability.\nPaclitaxel is sometimes used for \"in vivo\" studies as well. It can be fed to test organisms, such as fruit flies, or injected into individual cells, to inhibit microtubule disassembly or to increase the number of microtubules in the cell. Paclitaxel induces remyelination in a demyelinating mouse \"in vivo\" and inhibits human peptidylarginine deiminase 2 (hPAD2) \"in vitro\" though its methyl ester side chain. In 1999, Angiotech Pharmaceuticals Inc. began phase II clinical trials of micellar paclitaxel as treatment for secondary progressive multiple sclerosis, but reported in 2002 that the results showed no statistical significance.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "36797", "revid": "11104410", "url": "https://en.wikipedia.org/wiki?curid=36797", "title": "Occam's razor", "text": "Philosophical problem-solving principle\nIn philosophy, Occam's razor (also spelled Ockham's razor or Ocham's razor; ) is the problem-solving principle that recommends searching for explanations constructed with the smallest possible set of elements. It is also known as the principle of parsimony or the law of parsimony (). Attributed to William of Ockham, a 14th-century English philosopher and theologian, it is frequently cited as , which translates as \"Entities must not be multiplied beyond necessity\", although Occam never used these exact words. Popularly, the principle is sometimes paraphrased as \"of two competing theories, the simpler explanation of an entity is to be preferred.\"\nThis philosophical razor advocates that when presented with competing hypotheses about the same prediction and both hypotheses have equal explanatory power, one should prefer the hypothesis that requires the fewest assumptions, and that this is not meant to be a way of choosing between hypotheses that make different predictions. Similarly, in science, Occam's razor is used as an abductive heuristic in the development of theoretical models rather than as a rigorous arbiter between candidate models.\nHistory.\nThe phrase \"Occam's razor\" did not appear until a few centuries after William of Ockham's death in 1347. Libert Froidmont, in his 1649 \"Philosophia Christiana de Anima\" (\"On Christian Philosophy of the Soul\"), gives him credit for the phrase, speaking of \"novacula occami\". Ockham did not invent this principle, but its fame \u2013 and its association with him \u2013 may be due to the frequency and effectiveness with which he used it. Ockham stated the principle in various ways, but the most popular version \u2013 \"Entities are not to be multiplied without necessity\" () \u2013 was formulated by the Irish Franciscan philosopher John Punch in his 1639 commentary on the works of Duns Scotus.\nFormulations before William of Ockham.\nThe origins of what has come to be known as Occam's razor are traceable to the works of earlier philosophers such as John Duns Scotus (1265\u20131308), Robert Grosseteste (1175\u20131253), Maimonides (Moses ben-Maimon, 1138\u20131204), and even Aristotle (384\u2013322\u00a0BC). Aristotle writes in his \"Posterior Analytics\", \"We may assume the superiority [all other things being equal] of the demonstration which derives from fewer postulates or hypotheses.\" Ptolemy () stated, \"We consider it a good principle to explain the phenomena by the simplest hypothesis possible.\"\nPhrases such as \"It is vain to do with more what can be done with fewer\" and \"A plurality is not to be posited without necessity\" were commonplace in 13th-century scholastic writing. Robert Grosseteste, in \"Commentary on\" [Aristotle's] \"the Posterior Analytics Books\" (\"Commentarius in Posteriorum Analyticorum Libros\") (c.\u20091217\u20131220), declares: \"That is better and more valuable which requires fewer, other circumstances being equal ... For if one thing were demonstrated from many and another thing from fewer equally known premises, clearly that is better which is from fewer because it makes us know quickly, just as a universal demonstration is better than particular because it produces knowledge from fewer premises. Similarly in natural science, in moral science, and in metaphysics the best is that which needs no premises and the better that which needs the fewer, other circumstances being equal.\"The \"Summa Theologica\" of Thomas Aquinas (1225\u20131274) states that \"it is superfluous to suppose that what can be accounted for by a few principles has been produced by many.\" Aquinas uses this principle to construct an objection to God's existence, an objection that he in turn answers and refutes generally (cf. \"quinque viae\"), and specifically, through an argument based on causality. Hence, Aquinas acknowledges the principle that today is known as Occam's razor, but prefers causal explanations to other simple explanations (cf. also Correlation does not imply causation).\nWilliam of Ockham.\nWilliam of Ockham (\"circa\" 1287\u20131347) was an English Franciscan friar and theologian, an influential medieval philosopher and a nominalist. His popular fame as a great logician rests chiefly on the maxim attributed to him and known as Occam's razor. The term \"razor\" refers to distinguishing between two hypotheses either by \"shaving away\" unnecessary assumptions or cutting apart two similar conclusions.\nWhile it has been claimed that Occam's razor is not found in any of William's writings, one can cite statements such as (\"Plurality must never be posited without necessity\"), which occurs in his theological work on the \"Sentences of Peter Lombard\" (\"Quaestiones et decisiones in quattuor libros Sententiarum Petri Lombardi\"; ed. Lugd., 1495, i, dist. 27, qu. 2, K).\nNevertheless, the precise words sometimes attributed to William of Ockham, (Entities must not be multiplied beyond necessity), are absent in his extant works; this particular phrasing comes from John Punch, who described the principle as a \"common axiom\" (\"axioma vulgare\") of the Scholastics. William of Ockham himself seems to restrict the operation of this principle in matters pertaining to miracles and God's power, considering a plurality of miracles possible in the Eucharist simply because it pleases God.\nThis principle is sometimes phrased as (\"Plurality should not be posited without necessity\"). In his \"Summa Totius Logicae\", i. 12, William of Ockham cites the principle of economy, (\"It is futile to do with more things that which can be done with fewer\"; Thorburn, 1918, pp.\u00a0352\u201353; Kneale and Kneale, 1962, p.\u00a0243.)\nLater formulations.\nTo quote Isaac Newton, \"We are to admit no more causes of natural things than such as are both true and sufficient to explain their appearances. Therefore, to the same natural effects we must, as far as possible, assign the same causes.\" In the sentence hypotheses non fingo (\"I contrive no hypotheses\"), Newton affirms the success of this approach.\nBertrand Russell offers a particular version of Occam's razor: \"Whenever possible, substitute constructions out of known entities for inferences to unknown entities.\"\nAround 1960, Ray Solomonoff founded the theory of universal inductive inference, the theory of prediction based on observations\u00a0\u2013 for example, predicting the next symbol based upon a given series of symbols. The only assumption is that the environment follows some unknown but computable probability distribution. This theory is a mathematical formalization of Occam's razor.\nAnother technical approach to Occam's razor is ontological parsimony. Parsimony means spareness and is also referred to as the Rule of Simplicity. This is considered a strong version of Occam's razor. A variation used in medicine is called the \"Zebra\": a physician should reject an exotic medical diagnosis when a more commonplace explanation is more likely, derived from Theodore Woodward's dictum \"When you hear hoofbeats, think of horses not zebras\".\nErnst Mach formulated the stronger version of Occam's razor into physics, which he called the Principle of Economy stating: \"Scientists must use the simplest means of arriving at their results and exclude everything not perceived by the senses.\"\nThis principle goes back at least as far as Aristotle, who wrote \"Nature operates in the shortest way possible.\" The idea of parsimony or simplicity in deciding between theories, though not the intent of the original expression of Occam's razor, has been assimilated into common culture as the widespread layman's formulation that \"the simplest explanation is usually the correct one.\"\nJustifications.\nAesthetic.\nPrior to the 20th century, it was a commonly held belief that nature itself was simple and that simpler hypotheses about nature were thus more likely to be true. Thomas Aquinas made this argument in the 13th century, writing, \"If a thing can be done adequately by means of one, it is superfluous to do it by means of several; for we observe that nature does not employ two instruments [if] one suffices.\"\nBeginning in the 20th century, epistemological justifications based on induction, logic, pragmatism, and especially probability theory have become more popular among philosophers.\nEmpirical.\nOccam's razor has gained strong empirical support in helping to converge on better theories (see Uses section below for some examples).\nIn the related concept of overfitting, excessively complex models are affected by statistical noise (a problem also known as the bias\u2013variance tradeoff), whereas simpler models may capture the underlying structure better and may thus have better predictive performance. It is, however, often difficult to deduce which part of the data is noise (cf. model selection, test set, minimum description length, Bayesian inference, etc.).\nTesting the razor.\nThe razor's statement that \"other things being equal, simpler explanations are generally better than more complex ones\" is amenable to empirical testing. Another interpretation of the razor's statement would be that \"simpler hypotheses are generally better than the complex ones\". The procedure to test the former interpretation would compare the track records of simple and comparatively complex explanations. If one accepts the first interpretation, the validity of Occam's razor as a tool would then have to be rejected if the more complex explanations were more often correct than the less complex ones (while the converse would lend support to its use). If the latter interpretation is accepted, the validity of Occam's razor as a tool could possibly be accepted if the simpler hypotheses led to correct conclusions more often than not.\nEven if some increases in complexity are sometimes necessary, there still remains a justified general bias toward the simpler of two competing explanations. To understand why, consider that for each accepted explanation of a phenomenon, there is always an infinite number of possible, more complex, and ultimately incorrect, alternatives. This is so because one can always burden a failing explanation with an ad hoc hypothesis. Ad hoc hypotheses are justifications that prevent theories from being falsified.\nFor example, if a man, accused of breaking a vase, makes supernatural claims that leprechauns were responsible for the breakage, a simple explanation might be that the man did it, but ongoing ad hoc justifications (e.g., \"... and that's not me breaking it on the film; they tampered with that, too\") could successfully prevent complete disproof. This endless supply of elaborate competing explanations, called saving hypotheses, cannot be technically ruled out \u2013 except by using Occam's razor.\nAny more complex theory might still possibly be true. A study of the predictive validity of Occam's razor found 32 published papers that included 97 comparisons of economic forecasts from simple and complex forecasting methods. None of the papers provided a balance of evidence that complexity of method improved forecast accuracy. In the 25 papers with quantitative comparisons, complexity increased forecast errors by an average of 27 percent.\nMathematical.\nOne justification of Occam's razor is a direct result of basic probability theory. By definition, all assumptions introduce possibilities for error; if an assumption does not improve the accuracy of a theory, its only effect is to increase the probability that the overall theory is wrong.\nThere have also been other attempts to derive Occam's razor from probability theory, including notable attempts made by Harold Jeffreys and E. T. Jaynes. The probabilistic (Bayesian) basis for Occam's razor is elaborated by David J. C. MacKay in chapter 28 of his book \"Information Theory, Inference, and Learning Algorithms\", where he emphasizes that a prior bias in favor of simpler models is not required.\nWilliam H. Jefferys and James O. Berger (1991) generalize and quantify the original formulation's \"assumptions\" concept as the degree to which a proposition is unnecessarily accommodating to possible observable data. They state, \"A hypothesis with fewer adjustable parameters will automatically have an enhanced posterior probability, due to the fact that the predictions it makes are sharp.\" The use of \"sharp\" here is not only a tongue-in-cheek reference to the idea of a razor, but also indicates that such predictions are more accurate than competing predictions. The model they propose balances the precision of a theory's predictions against their sharpness, preferring theories that sharply make correct predictions over theories that accommodate a wide range of other possible results. This, again, reflects the mathematical relationship between key concepts in Bayesian inference (namely marginal probability, conditional probability, and posterior probability).\nThe bias\u2013variance tradeoff is a framework that incorporates the Occam's razor principle in its balance between overfitting (associated with lower bias but higher variance) and underfitting (associated with lower variance but higher bias).\nOther philosophers.\nKarl Popper.\nKarl Popper argues that a preference for simple theories need not appeal to practical or aesthetic considerations. Our preference for simplicity may be justified by its falsifiability criterion: we prefer simpler theories to more complex ones \"because their empirical content is greater; and because they are better testable\". The idea here is that a simple theory applies to more cases than a more complex one, and is thus more easily falsifiable. This is again comparing a simple theory to a more complex theory where both explain the data equally well.\nElliott Sober.\nThe philosopher of science Elliott Sober once argued along the same lines as Popper, tying simplicity with \"informativeness\": The simplest theory is the more informative, in the sense that it requires less information to a question. He has since rejected this account of simplicity, purportedly because it fails to provide an epistemic justification for simplicity. He now believes that simplicity considerations (and considerations of parsimony in particular) do not count unless they reflect something more fundamental. Philosophers, he suggests, may have made the error of hypostatizing simplicity (i.e., endowed it with a \"sui generis\" existence), when it has meaning only when embedded in a specific context (Sober 1992). If we fail to justify simplicity considerations on the basis of the context in which we use them, we may have no non-circular justification: \"Just as the question 'why be rational?' may have no non-circular answer, the same may be true of the question 'why should simplicity be considered in evaluating the plausibility of hypotheses?'\"\nRichard Swinburne.\nRichard Swinburne argues for simplicity on logical grounds:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... the simplest hypothesis proposed as an explanation of phenomena is more likely to be the true one than is any other available hypothesis, that its predictions are more likely to be true than those of any other available hypothesis, and that it is an ultimate \"a priori\" epistemic principle that simplicity is evidence for truth.\u2014\u200a\nAccording to Swinburne, since our choice of theory cannot be determined by data (see Underdetermination and Duhem\u2013Quine thesis), we must rely on some criterion to determine which theory to use. Since it is absurd to have no logical method for settling on one hypothesis amongst an infinite number of equally data-compliant hypotheses, we should choose the simplest theory: \"Either science is irrational [in the way it judges theories and predictions probable] or the principle of simplicity is a fundamental synthetic a priori truth.\"\nLudwig Wittgenstein.\nFrom the \"Tractatus Logico-Philosophicus\":\n (If everything in the symbolism works as though a sign had meaning, then it has meaning.)\nand on the related concept of \"simplicity\":\nUses.\nScience and the scientific method.\nIn science, Occam's razor is used as a heuristic to guide scientists in developing theoretical models rather than as an arbiter between published models. In physics, parsimony was an important heuristic in the development and application of the principle of least action by Pierre Louis Maupertuis and Leonhard Euler, in Albert Einstein's formulation of special relativity, and in the development of quantum mechanics by Max Planck, Werner Heisenberg and Louis de Broglie.\nIn chemistry, Occam's razor is often an important heuristic when developing a model of a reaction mechanism. Although it is useful as a heuristic in developing models of reaction mechanisms, it has been shown to fail as a criterion for selecting among some selected published models. In this context, Einstein himself expressed caution when he formulated Einstein's Constraint: \"It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.\" An often-quoted version of this constraint (which cannot be verified as posited by Einstein himself) reduces this to \"Everything should be kept as simple as possible, but not simpler.\"\nIn the scientific method, Occam's razor is not considered an irrefutable principle of logic or a scientific result; the preference for simplicity in the scientific method is based on the falsifiability criterion. For each accepted explanation of a phenomenon, there may be an extremely large, perhaps even incomprehensible, number of possible and more complex alternatives. Since failing explanations can always be burdened with \"ad hoc\" hypotheses to prevent them from being falsified, simpler theories are preferable to more complex ones because they tend to be more testable. As a logical principle, Occam's razor would demand that scientists accept the simplest possible theoretical explanation for existing data. However, science has shown repeatedly that future data often support more complex theories than do existing data. Science prefers the simplest explanation that is consistent with the data available at a given time, but the simplest explanation may be ruled out as new data become available. That is, science is open to the possibility that future experiments might support more complex theories than demanded by current data and is more interested in designing experiments to discriminate between competing theories than favoring one theory over another based merely on philosophical principles.\nWhen scientists use the idea of parsimony, it has meaning only in a very specific context of inquiry. Several background assumptions are required for parsimony to connect with plausibility in a particular research problem. The reasonableness of parsimony in one research context may have nothing to do with its reasonableness in another. It is a mistake to think that there is a single global principle that spans diverse subject matter.\nIt has been suggested that Occam's razor is a widely accepted example of extraevidential consideration, even though it is entirely a metaphysical assumption. Most of the time, however, Occam's razor is a conservative tool, cutting out \"crazy, complicated constructions\" and assuring \"that hypotheses are grounded in the science of the day\", thus yielding \"normal\" science: models of explanation and prediction. There are, however, notable exceptions where Occam's razor turns a conservative scientist into a reluctant revolutionary. For example, Max Planck interpolated between the Wien and Jeans radiation laws and used Occam's razor logic to formulate the quantum hypothesis, even resisting that hypothesis as it became more obvious that it was correct.\nAppeals to simplicity were used to argue against the phenomena of meteorites, ball lightning, continental drift, and reverse transcriptase. One can argue for atomic building blocks for matter, because it provides a simpler explanation for the observed reversibility of both and chemical reactions as simple separation and rearrangements of atomic building blocks. At the time, however, the atomic theory was considered more complex because it implied the existence of invisible particles that had not been directly detected. Ernst Mach and the logical positivists rejected John Dalton's atomic theory until the reality of atoms was more evident in Brownian motion, as shown by Albert Einstein.\nIn the same way, postulating the aether is more complex than transmission of light through a vacuum. At the time, however, all known waves propagated through a physical medium, and it seemed simpler to postulate the existence of a medium than to theorize about wave propagation without a medium. Likewise, Isaac Newton's idea of light particles seemed simpler than Christiaan Huygens's idea of waves, so many favored it. In this case, as it turned out, neither the wave \u2013 nor the particle \u2013 explanation alone suffices, as light behaves like waves and like particles.\nThree axioms presupposed by the scientific method are realism (the existence of objective reality), the existence of natural laws, and the constancy of natural law. Rather than depend on provability of these axioms, science depends on the fact that they have not been objectively falsified. Occam's razor and parsimony support, but do not prove, these axioms of science. The general principle of science is that theories (or models) of natural law must be consistent with repeatable experimental observations. This ultimate arbiter (selection criterion) rests upon the axioms mentioned above.\nIf multiple models of natural law make exactly the same testable predictions, they are equivalent and there is no need for parsimony to choose a preferred one. For example, Newtonian, Hamiltonian and Lagrangian classical mechanics are equivalent. Physicists have no interest in using Occam's razor to say the other two are wrong. Likewise, there is no demand for simplicity principles to arbitrate between wave and matrix formulations of quantum mechanics. Science often does not demand arbitration or selection criteria between models that make the same testable predictions.\nBiology.\nBiologists or philosophers of biology use Occam's razor in either of two contexts both in evolutionary biology: the units of selection controversy and systematics. George C. Williams in his book \"Adaptation and Natural Selection\" (1966) argues that the best way to explain altruism among animals is based on low-level (i.e., individual) selection as opposed to high-level group selection. Altruism is defined by some evolutionary biologists (e.g., R. Alexander, 1987; W. D. Hamilton, 1964) as behavior that is beneficial to others (or to the group) at a cost to the individual, and many posit individual selection as the mechanism that explains altruism solely in terms of the behaviors of individual organisms acting in their own self-interest (or in the interest of their genes, via kin selection). Williams was arguing against the perspective of others who propose selection at the level of the group as an evolutionary mechanism that selects for altruistic traits (e.g., D. S. Wilson &amp; E. O. Wilson, 2007). The basis for Williams's contention is that of the two, individual selection is the more parsimonious theory. In doing so he is invoking a variant of Occam's razor known as Morgan's Canon: \"In no case is an animal activity to be interpreted in terms of higher psychological processes, if it can be fairly interpreted in terms of processes which stand lower in the scale of psychological evolution and development.\" (Morgan 1903).\nHowever, more recent biological analyses, such as Richard Dawkins's \"The Selfish Gene\", have contended that Morgan's Canon is not the simplest and most basic explanation. Dawkins argues the way evolution works is that the genes propagated in most copies end up determining the development of that particular species, i.e., natural selection turns out to select specific genes, and this is really the fundamental underlying principle that automatically gives individual and group selection as emergent features of evolution.\nZoology provides an example. Muskoxen, when threatened by wolves, form a circle with the males on the outside and the females and young on the inside. This is an example of a behavior by the males that seems to be altruistic. The behavior is disadvantageous to them individually but beneficial to the group as a whole; thus, it was seen by some to support the group selection theory. Another interpretation is kin selection: if the males are protecting their offspring, they are protecting copies of their own alleles. Engaging in this behavior would be favored by individual selection if the cost to the male musk ox is less than half of the benefit received by his calf \u2013 which could easily be the case if wolves have an easier time killing calves than adult males. It could also be the case that male musk oxen would be individually less likely to be killed by wolves if they stood in a circle with their horns pointing out, regardless of whether they were protecting the females and offspring. That would be an example of regular natural selection \u2013 a phenomenon called \"the selfish herd\".\nSystematics is the branch of biology that attempts to establish patterns of relationship among biological taxa, today generally thought to reflect evolutionary history. It is also concerned with their classification. There are three primary camps in systematics: cladists, pheneticists, and evolutionary taxonomists. Cladists hold that classification should be based on synapomorphies (shared, derived character states), pheneticists contend that overall similarity (synapomorphies and complementary symplesiomorphies) is the determining criterion, while evolutionary taxonomists say that both genealogy and similarity count in classification (in a manner determined by the evolutionary taxonomist).\nIt is among the cladists that Occam's razor is applied, through the method of \"cladistic parsimony\". Cladistic parsimony (or maximum parsimony) is a method of phylogenetic inference that yields phylogenetic trees (more specifically, cladograms). Cladograms are branching, diagrams used to represent hypotheses of relative degree of relationship, based on synapomorphies. Cladistic parsimony is used to select as the preferred hypothesis of relationships the cladogram that requires the fewest implied character state transformations (or smallest weight, if characters are differentially weighted). Critics of the cladistic approach often observe that for some types of data, parsimony could produce the wrong results, regardless of how much data is collected (this is called statistical inconsistency, or long branch attraction). However, this criticism is also potentially true for any type of phylogenetic inference, unless the model used to estimate the tree reflects the way that evolution actually happened. Because this information is not empirically accessible, the criticism of statistical inconsistency against parsimony holds no force. For a book-length treatment of cladistic parsimony, see Elliott Sober's \"Reconstructing the Past: Parsimony, Evolution, and Inference\" (1988). For a discussion of both uses of Occam's razor in biology, see Sober's article \"Let's Razor Ockham's Razor\" (1990).\nOther methods for inferring evolutionary relationships use parsimony in a more general way. Likelihood methods for phylogeny use parsimony as they do for all likelihood tests, with hypotheses requiring fewer differing parameters (i.e., numbers or different rates of character change or different frequencies of character state transitions) being treated as null hypotheses relative to hypotheses requiring more differing parameters. Thus, complex hypotheses must predict data much better than do simple hypotheses before researchers reject the simple hypotheses. Recent advances employ information theory, a close cousin of likelihood, which uses Occam's razor in the same way. The choice of the \"shortest tree\" relative to a not-so-short tree under any optimality criterion (smallest distance, fewest steps, or maximum likelihood) is always based on parsimony.\nFrancis Crick has commented on potential limitations of Occam's razor in biology. He advances the argument that because biological systems are the products of (an ongoing) natural selection, the mechanisms are not necessarily optimal in an obvious sense. He cautions: \"While Ockham's razor is a useful tool in the physical sciences, it can be a very dangerous implement in biology. It is thus very rash to use simplicity and elegance as a guide in biological research.\" This is an ontological critique of parsimony.\nIn biogeography, parsimony is used to infer ancient vicariant events or migrations of species or populations by observing the geographic distribution and relationships of existing organisms. Given the phylogenetic tree, ancestral population subdivisions are inferred to be those that require the minimum amount of change.\nReligion.\nIn the philosophy of religion, Occam's razor is sometimes applied to the existence of God. William of Ockham himself was a Christian. He believed in God, and in the authority of Christian scripture; he writes that \"nothing ought to be posited without a reason given, unless it is self-evident (literally, known through itself) or known by experience or proved by the authority of Sacred Scripture.\" Ockham believed that an explanation has no sufficient basis in reality when it does not harmonize with reason, experience, or the Bible. Unlike many theologians of his time, though, Ockham did not believe God could be logically proven with arguments. To Ockham, science was a matter of discovery; theology was a matter of revelation and faith. He states: \"Only faith gives us access to theological truths. The ways of God are not open to reason, for God has freely chosen to create a world and establish a way of salvation within it apart from any necessary laws that human logic or rationality can uncover.\"\nThomas Aquinas, in the \"Summa Theologica\", uses a formulation of Occam's razor to construct an objection to the idea that God exists, which he refutes directly with a counterargument:\nFurther, it is superfluous to suppose that what can be accounted for by a few principles has been produced by many. But it seems that everything we see in the world can be accounted for by other principles, supposing God did not exist. For all natural things can be reduced to one principle which is nature; and all voluntary things can be reduced to one principle which is human reason, or will. Therefore there is no need to suppose God's existence.\nIn turn, Aquinas answers this with the \"quinque viae\", and addresses the particular objection above with the following answer:\nSince nature works for a determinate end under the direction of a higher agent, whatever is done by nature must needs be traced back to God, as to its first cause. So also whatever is done voluntarily must also be traced back to some higher cause other than human reason or will, since these can change or fail; for all things that are changeable and capable of defect must be traced back to an immovable and self-necessary first principle, as was shown in the body of the Article.\nRather than argue for the necessity of a god, some theists base their belief upon grounds independent of, or prior to, reason, making Occam's razor irrelevant. This was the stance of S\u00f8ren Kierkegaard, who viewed belief in God as a leap of faith that sometimes directly opposed reason. This is also the doctrine of Gordon Clark's presuppositional apologetics, with the exception that Clark never thought the leap of faith was contrary to reason (see also Fideism).\nVarious arguments in favor of God establish God as a useful or even necessary assumption. Contrastingly some anti-theists hold firmly to the belief that assuming the existence of God introduces unnecessary complexity (e.g., the Ultimate Boeing 747 gambit from Dawkins's \"The God Delusion\").\nAnother application of the principle is to be found in the work of George Berkeley (1685\u20131753). Berkeley was an idealist who believed that all of reality could be explained in terms of the mind alone. He invoked Occam's razor against materialism, stating that matter was not required by his metaphysics and was thus eliminable. One potential problem with this belief is that it's possible, given Berkeley's position, to find solipsism itself more in line with the razor than a God-mediated world beyond a single thinker.\nOccam's razor may also be recognized in the apocryphal story about an exchange between Pierre-Simon Laplace and Napoleon. It is said that in praising Laplace for one of his recent publications, the emperor asked how it was that the name of God, which featured so frequently in the writings of Lagrange, appeared nowhere in Laplace's. At that, he is said to have replied, \"It's because I had no need of that hypothesis.\" Though some points of this story illustrate Laplace's atheism, more careful consideration suggests that he may instead have intended merely to illustrate the power of methodological naturalism, or even simply that the fewer logical premises one assumes, the stronger is one's conclusion.\nPhilosophy of mind.\nIn his article \"Sensations and Brain Processes\" (1959), J. J. C. Smart invoked Occam's razor with the aim to justify his preference of the mind\u2013brain identity theory over spirit\u2013body dualism. Dualists state that there are two kinds of substances in the universe: physical (including the body) and spiritual, which is non-physical. In contrast, identity theorists state that everything is physical, including consciousness, and that there is nothing nonphysical. Though it is impossible to appreciate the spiritual when limiting oneself to the physical, Smart maintained that identity theory explains all phenomena by assuming only a physical reality. Subsequently, Smart has been severely criticized for his use (or misuse) of Occam's razor and ultimately retracted his advocacy of it in this context. Paul Churchland (1984) states that by itself Occam's razor is inconclusive regarding duality. In a similar way, Dale Jacquette (1994) stated that Occam's razor has been used in attempts to justify eliminativism and reductionism in the philosophy of mind. Eliminativism is the thesis that the ontology of folk psychology including such entities as \"pain\", \"joy\", \"desire\", \"fear\", etc., are eliminable in favor of an ontology of a completed neuroscience.\nPenal ethics.\nIn penal theory and the philosophy of punishment, parsimony refers specifically to taking care in the distribution of punishment in order to avoid excessive punishment. In the utilitarian approach to the philosophy of punishment, Jeremy Bentham's \"parsimony principle\" states that any punishment greater than is required to achieve its end is unjust. The concept is related but not identical to the legal concept of proportionality. Parsimony is a key consideration of the modern restorative justice, and is a component of utilitarian approaches to punishment, as well as the prison abolition movement. Bentham believed that true parsimony would require punishment to be individualised to take account of the sensibility of the individual \u2013 an individual more sensitive to punishment should be given a proportionately lesser one, since otherwise needless pain would be inflicted. Later utilitarian writers have tended to abandon this idea, in large part due to the impracticality of determining each alleged criminal's relative sensitivity to specific punishments.\nProbability theory and statistics.\nMarcus Hutter's universal artificial intelligence builds upon Solomonoff's mathematical formalization of the razor to calculate the expected value of an action.\nThere are various papers in scholarly journals deriving formal versions of Occam's razor from probability theory, applying it in statistical inference, and using it to come up with criteria for penalizing complexity in statistical inference. Papers have suggested a connection between Occam's razor and Kolmogorov complexity.\nOne of the problems with the original formulation of the razor is that it only applies to models with the same explanatory power (i.e., it only tells us to prefer the simplest of equally good models). A more general form of the razor can be derived from Bayesian model comparison, which is based on Bayes factors and can be used to compare models that do not fit the observations equally well. These methods can sometimes optimally balance the complexity and power of a model. Generally, the exact Occam factor is intractable, but approximations such as Akaike information criterion, Bayesian information criterion, Variational Bayesian methods, false discovery rate, and Laplace's method are used. Many artificial intelligence researchers are now employing such techniques, for instance through work on Occam Learning or more generally on the Free energy principle.\nStatistical versions of Occam's razor have a more rigorous formulation than what philosophical discussions produce. In particular, they must have a specific definition of the term \"simplicity\", and that definition can vary. For example, in the Kolmogorov\u2013Chaitin minimum description length approach, the subject must pick a Turing machine whose operations describe the basic operations \"believed\" to represent \"simplicity\" by the subject. However, one could always choose a Turing machine with a simple operation that happened to construct one's entire theory and would hence score highly under the razor. This has led to two opposing camps: one that believes Occam's razor is objective, and one that believes it is subjective.\nObjective razor.\nThe minimum instruction set of a universal Turing machine requires approximately the same length description across different formulations, and is small compared to the Kolmogorov complexity of most practical theories. Marcus Hutter has used this consistency to define a \"natural\" Turing machine of small size as the proper basis for excluding arbitrarily complex instruction sets in the formulation of razors. Describing the program for the universal program as the \"hypothesis\", and the representation of the evidence as program data, it has been formally proven under Zermelo\u2013Fraenkel set theory that \"the sum of the log universal probability of the model plus the log of the probability of the data given the model should be minimized.\" Interpreting this as minimising the total length of a two-part message encoding model followed by data given model gives us the minimum message length (MML) principle.\nOne possible conclusion from mixing the concepts of Kolmogorov complexity and Occam's razor is that an ideal data compressor would also be a scientific explanation/formulation generator. Some attempts have been made to re-derive known laws from considerations of simplicity or compressibility.\nAccording to J\u00fcrgen Schmidhuber, the appropriate mathematical theory of Occam's razor already exists, namely, Solomonoff's theory of optimal inductive inference and its extensions. See discussions in David L. Dowe's \"Foreword re C. S. Wallace\" for the subtle distinctions between the algorithmic probability work of Solomonoff and the MML work of Chris Wallace, and see Dowe's \"MML, hybrid Bayesian network graphical models, statistical consistency, invariance and uniqueness\" both for such discussions and for (in section 4) discussions of MML and Occam's razor. For a specific example of MML as Occam's razor in the problem of decision tree induction, see Dowe and Needham's \"Message Length as an Effective Ockham's Razor in Decision Tree Induction\".\nMathematical arguments against Occam's razor.\nThe no free lunch (NFL) theorems for inductive inference prove that Occam's razor must rely on ultimately arbitrary assumptions concerning the prior probability distribution found in our world. Specifically, suppose one is given two inductive inference algorithms, A and B, where A is a Bayesian procedure based on the choice of some prior distribution motivated by Occam's razor (e.g., the prior might favor hypotheses with smaller Kolmogorov complexity). Suppose that B is the anti-Bayes procedure, which calculates what the Bayesian algorithm A based on Occam's razor will predict \u2013 and then predicts the exact opposite. Then there are just as many actual priors (including those different from the Occam's razor prior assumed by A) in which algorithm B outperforms A as priors in which the procedure A based on Occam's razor comes out on top. In particular, the NFL theorems show that the \"Occam factors\" Bayesian argument for Occam's razor must make ultimately arbitrary modeling assumptions.\nSoftware development.\nIn software development, the rule of least power argues the correct programming language to use is the one that is simplest while also solving the targeted software problem. In that form the rule is often credited to Tim Berners-Lee since it appeared in his design guidelines for the original Hypertext Transfer Protocol. Complexity in this context is measured either by placing a language into the Chomsky hierarchy or by listing idiomatic features of the language and comparing according to some agreed to scale of difficulties between idioms. Many languages once thought to be of lower complexity have evolved or later been discovered to be more complex than originally intended; so, in practice this rule is applied to the relative ease of a programmer to obtain the power of the language, rather than the precise theoretical limits of the language.\nArtificial intelligence.\nScientists have discovered that deep neural networks (DNN) prefer simpler mathematical functions while learning. This simplicity bias enables DNNs to overcome overfitting \u2013 a scenario where the model gets overwhelmed with noise due to the presence of too many parameters.\nControversial aspects.\nOccam's razor is not an embargo against the positing of any kind of entity, or a recommendation of the simplest theory come what may. Occam's razor is used to adjudicate between theories that have already passed \"theoretical scrutiny\" tests and are equally well-supported by evidence. Furthermore, it may be used to prioritize empirical testing between two equally plausible but unequally testable hypotheses; thereby minimizing costs and wastes while increasing chances of falsification of the simpler-to-test hypothesis.\nAnother contentious aspect of the razor is that a theory can become more complex in terms of its structure (or syntax), while its ontology (or semantics) becomes simpler, or vice versa. Quine, in a discussion on definition, referred to these two perspectives as \"economy of practical expression\" and \"economy in grammar and vocabulary\", respectively.\nGalileo Galilei lampooned the \"misuse\" of Occam's razor in his \"Dialogue\". The principle is represented in the dialogue by Simplicio. The telling point that Galileo presented ironically was that if one really wanted to start from a small number of entities, one could always consider the letters of the alphabet as the fundamental entities, since one could construct the whole of human knowledge out of them.\nInstances of using Occam's razor to justify belief in less complex and more simple theories have been criticized as using the razor inappropriately. For instance Francis Crick stated that \"While Occam's razor is a useful tool in the physical sciences, it can be a very dangerous implement in biology. It is thus very rash to use simplicity and elegance as a guide in biological research.\"\nAnti-razors.\nOccam's razor has met some opposition from people who consider it too extreme or rash. Walter Chatton (c.\u20091290\u20131343) was a contemporary of William of Ockham who took exception to Occam's razor and Ockham's use of it. In response he devised his own \"anti-razor\": \"If three things are not enough to verify an affirmative proposition about things, a fourth must be added and so on.\" Although there have been several philosophers who have formulated similar anti-razors since Chatton's time, no one anti-razor has perpetuated as notably as Chatton's anti-razor, although this could be the case of the Late Renaissance Italian motto of unknown attribution (\"Even if it is not true, it is well conceived\") when referred to a particularly artful explanation.\nAnti-razors have also been created by Gottfried Wilhelm Leibniz (1646\u20131716), Immanuel Kant (1724\u20131804), and Karl Menger (1902\u20131985). Leibniz's version took the form of a principle of plenitude, as Arthur Lovejoy has called it: the idea being that God created the most varied and populous of possible worlds. Kant felt a need to moderate the effects of Occam's razor and thus created his own counter-razor: \"The variety of beings should not rashly be diminished.\"\nKarl Menger found mathematicians to be too parsimonious with regard to variables so he formulated his Law Against Miserliness, which took one of two forms: \"Entities must not be reduced to the point of inadequacy\" and \"It is vain to do with fewer what requires more.\" A less serious but even more extremist anti-razor is 'Pataphysics, the \"science of imaginary solutions\" developed by Alfred Jarry (1873\u20131907). Perhaps the ultimate in anti-reductionism, \"'Pataphysics seeks no less than to view each event in the universe as completely unique, subject to no laws but its own.\" Variations on this theme were subsequently explored by the Argentine writer Jorge Luis Borges in his story/mock-essay \"Tl\u00f6n, Uqbar, Orbis Tertius\". Physicist R. V. Jones contrived Crabtree's Bludgeon, which states that \"[n]o set of mutually inconsistent observations can exist for which some human intellect cannot conceive a coherent explanation, however complicated.\"\nRecently, American physicist Igor Mazin argued that because high-profile physics journals prefer publications offering exotic and unusual interpretations, the Occam's razor principle is being replaced by an \"Inverse Occam's razor\", implying that the simplest possible explanation is usually rejected.\nOther.\nSince 2012[ [update]], \"The Skeptic\" magazine annually awards the Ockham Awards, or simply the Ockhams, named after Occam's razor, at QED. The Ockhams were introduced by editor-in-chief Deborah Hyde to \"recognise the effort and time that have gone into the community's favourite skeptical blogs, skeptical podcasts, skeptical campaigns and outstanding contributors to the skeptical cause.\" The trophies, designed by Neil Davies and Karl Derrick, carry the upper text \"\"Ockham's\" and the lower text \"The Skeptic. Shaving away unnecessary assumptions since 1285.\"\" Between the texts, there is an image of a double-edged safety razorblade, and both lower corners feature an image of William of Ockham's face.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "36806", "revid": "37005538", "url": "https://en.wikipedia.org/wiki?curid=36806", "title": "Cotton", "text": "Plant fiber from the genus Gossypium\nCotton (from ar \" qutn\") is a soft, fluffy staple fiber that grows in a boll, or protective case, around the seeds of the cotton plants of the genus \"Gossypium\" in the mallow family Malvaceae. The fiber is almost pure cellulose, and can contain minor percentages of waxes, fats, pectins, and water. Under natural conditions, the cotton bolls will increase the dispersal of the seeds.\nThe plant is a shrub native to tropical and subtropical regions around the world, including the Americas, Africa, Egypt and India. The greatest diversity of wild cotton species is found in Mexico, followed by Australia and Africa. Cotton was independently domesticated in the Old and New Worlds.\nThe fiber is most often spun into yarn or thread and used to make a soft, breathable, and durable textile. The use of cotton for fabric is known to date to prehistoric times; the presence of \"Gossypium barbadense\" has been identified at a site in Nanchoc District, Peru, and dated to the 7th-6th millennia BC, while indigo blue dyed textile fragments. dated to the 4th-3rd millennia BC, having been found at Huaca Prieta, in Peru, Fragments of a cotton thread, used to connect a string of eight copper beads, and dated to the sixth millennium BC has been found at Mehrgarh, Kachi, Pakistan.\nAlthough cultivated since antiquity, it was the invention of the cotton gin that lowered the cost of production and led to its widespread use, and it is the most widely used natural fiber cloth in clothing today.\nCurrent estimates for world production are about 25 million tonnes or 110 million bales annually, accounting for 2.5% of the world's arable land. India is the world's largest producer of cotton. The United States has been the largest exporter for many years.\nTypes.\nThere are four commercially grown species of cotton, all domesticated in antiquity:\nHybrid varieties are also cultivated. The two New World cotton species account for the vast majority of modern cotton production, but the two Old World species were widely used before the 1900s. While cotton fibers occur naturally in colors of white, brown, pink and green, fears of contaminating the genetics of white cotton have led many cotton-growing locations to ban the growing of colored cotton varieties.\nEtymology.\nThe word \"cotton\" has Arabic origins, derived from the Arabic word ( or ) which is ultimately derived from the Hebrew \u05db\u05bb\u05bc\u05ea\u05b9\u05bc\u05e0\u05b6\u05ea \"kutt\u1e53n\u0115\u1e6f\", ironically meaning a clothing made of linen. This was the usual word for cotton in medieval Arabic. Marco Polo in chapter 2 in his book, describes a province he calls Khotan in Turkestan, today's Xinjiang, where cotton was grown in abundance. The word entered the Romance languages in the mid-12th century, and English a century later. Cotton fabric was known to the ancient Romans as an import, but cotton was rare in the Romance-speaking lands until imports from the Arabic-speaking lands in the later medieval era at transformatively lowered prices.\nHistory.\nEarly history.\nAmericas.\nThe presence of the indigenous species \"Gossypium barbadense\" has been identified at a site in Nanchoc District, Peru, and dated to the 7th\u20136th millennia BC, while indigo blue dyed textile fragments, dated to the 4th\u20133rd millennia BC, having been found at Huaca Prieta, Peru. Cultivation of the indigenous cotton species \"G. barbadense\" from a find in Ancon, Peru has been dated to c.\u20094200 BC, and was the backbone of the development of coastal cultures such as the Norte Chico, Moche, and Nazca. Cotton was grown upriver, made into nets, and traded with fishing villages along the coast for large supplies of fish. The Spanish who came to Mexico and Peru in the early 16th century found the people growing cotton and wearing clothing made of it.\nCotton bolls from in a cave near Tehuac\u00e1n, Mexico, have been dated to as early as 5500 BC. The domestication of \"Gossypium hirsutum\", in Mexico, is dated to between around 3400 and 2300 BC. During this time, people between the R\u00edo Santiago and the R\u00edo Balsas grew, spun, wove, dyed, and sewed cotton. What they did not use themselves, they sent to their Aztec rulers as tribute, on the scale of ~ annually.\nSouth Asia.\nThe earliest evidence of the use of cotton in the Old World, in the form of a few fibres of mineralised cotton thread, was found in a string of eight copper beads at the Neolithic site of Mehrgarh, at the foot of the Bolan Pass, Balochistan, Pakistan. Fragments of cotton textiles and spindle whorls, dated to the 3rd millennia BC, have also been found at Mohenjo-daro, in Sindh, Pakistan, and other sites of the Bronze Age Indus Valley civilization, which is a likely site for the first cultivation of \"Gossypium arboreum\", and cotton may have been an important export from it.\nLevant.\nMicroremains of cotton fibers, some dyed, have been found at Tel Tsaf in the Jordan Valley dated 5,200 BCE. They may be the remnants of ancient clothing, fabric containers, or cordage. Research suggest the cotton might come from wild species in South Asia, and traded with the Indus Valley Civilisation.\nIran.\nIn Iran (Persia), the history of cotton dates back to the Achaemenid era (5th century BC); however, there are few sources about the planting of cotton in pre-Islamic Iran. Cotton cultivation was common in Merv, Ray and Pars. In Persian poems, especially Ferdowsi's \"Shahname\", there are references to cotton (\"panbe\" in Persian). Marco Polo (13th century) refers to the major products of Persia, including cotton. John Chardin, a French traveler of the 17th century who visited Safavid Persia, spoke approvingly of the vast cotton farms of Persia.\nArabia.\nThe Greeks and the Arabs were not familiar with cotton until the wars of Alexander the Great, as his contemporary Megasthenes told Seleucus I Nicator of \"there being trees on which wool grows\" in \"Indica\". This may be a reference to \"tree cotton\", \"Gossypium arboreum,\" which is native to the Indian subcontinent.\nAccording to the \"Columbia Encyclopedia\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Cotton has been spun, woven, and dyed since prehistoric times. It clothed the people of ancient India, Egypt, and China. Hundreds of years before the Christian era, cotton textiles were woven in India with matchless skill, and their use spread to the Mediterranean countries.\nKingdom of Kush.\nCotton (\"Gossypium herbaceum\" Linnaeus) may have been domesticated 5000 BC in eastern Sudan near the Middle Nile Basin region, where cotton cloth was being produced. Around the 4th century BC, the cultivation of cotton and the knowledge of its spinning and weaving in Mero\u00eb reached a high level. The export of textiles was one of the sources of wealth for Mero\u00eb. Ancient Nubia had a \"culture of cotton\" of sorts, evidenced by physical evidence of cotton processing tools and the presence of cattle in certain areas. Some researchers propose that cotton was important to the Nubian economy for its use in contact with the neighboring Egyptians. Aksumite King Ezana boasted in his inscription that he destroyed large cotton plantations in Mero\u00eb during his conquest of the region.\nIn the Meroitic Period (beginning 3rd century BCE), many cotton textiles have been recovered, preserved due to favorable arid conditions. Most of these fabric fragments come from Lower Nubia, and the cotton textiles account for 85% of the archaeological textiles from Classic/Late Meroitic sites. Due to these arid conditions, cotton, a plant that usually thrives moderate rainfall and richer soils, requires extra irrigation and labor in Sudanese climate conditions. Therefore, a great deal of resources would have been required, likely restricting its cultivation to the elite. In the first to third centuries CE, recovered cotton fragments all began to mirror the same style and production method, as seen from the direction of spun cotton and technique of weaving. Cotton textiles also appear in places of high regard, such as on funerary stelae and statues.\nChina.\nDuring the Han dynasty (207 BC - 220 AD), cotton was grown by Chinese peoples in the southern Chinese province of Yunnan.\nMiddle Ages.\nEastern world.\nEgyptians grew and spun cotton in the first seven centuries of the Christian era.\nHandheld roller cotton gins had been used in India since the 6th century, and was then introduced to other countries from there. Between the 12th and 14th centuries, dual-roller gins appeared in India and China. The Indian version of the dual-roller gin was prevalent throughout the Mediterranean cotton trade by the 16th century. This mechanical device was, in some areas, driven by water power.\nThe earliest clear illustrations of the spinning wheel come from the Islamic world in the eleventh century. The earliest unambiguous reference to a spinning wheel in India is dated to 1350, suggesting that the spinning wheel was likely introduced from Iran to India during the Delhi Sultanate.\nEurope.\nDuring the late medieval period, cotton became known as an imported fiber in northern Europe, without any knowledge of how it was derived, other than that it was a plant. Because Herodotus had written in his \"Histories\", Book III, 106, that in India trees grew in the wild producing wool, it was assumed that the plant was a tree, rather than a shrub. This aspect is retained in the name for cotton in several Germanic languages, such as German \"Baumwolle\", which translates as \"tree wool\" (\"Baum\" means \"tree\"; \"Wolle\" means \"wool\"). Noting its similarities to wool, people in the region could only imagine that cotton must be produced by plant-borne sheep. John Mandeville, writing in 1350, stated as fact that \"There grew there [India] a wonderful tree which bore tiny lambs on the endes of its branches. These branches were so pliable that they bent down to allow the lambs to feed when they are hungry.\" (See Vegetable Lamb of Tartary.)\nCotton manufacture was introduced to Europe during the Muslim conquest of the Iberian Peninsula and Sicily. The knowledge of cotton weaving was spread to northern Italy in the 12th century, when Sicily was conquered by the Normans, and consequently to the rest of Europe. The spinning wheel, introduced to Europe circa 1350, improved the speed of cotton spinning. By the 15th century, Venice, Antwerp, and Haarlem were important ports for cotton trade, and the sale and transportation of cotton fabrics had become very profitable.\nEarly modern period.\nMughal India.\nUnder the Mughal Empire, which ruled in the Indian subcontinent from the early 16th century to the early 18th century, Indian cotton production increased, in terms of both raw cotton and cotton textiles. The Mughals introduced agrarian reforms such as a new revenue system that was biased in favour of higher value cash crops such as cotton and indigo, providing state incentives to grow cash crops, in addition to rising market demand.\nThe largest manufacturing industry in the Mughal Empire was cotton textile manufacturing, which included the production of piece goods, calicos, and muslins, available unbleached and in a variety of colours. The cotton textile industry was responsible for a large part of the empire's international trade. India had a 25% share of the global textile trade in the early 18th century. Indian cotton textiles were the most important manufactured goods in world trade in the 18th century, consumed across the world from the Americas to Japan. The most important center of cotton production was the Bengal Subah province, particularly around its capital city of Dhaka.\nThe worm gear roller cotton gin, which was invented in India during the early Delhi Sultanate era of the 13th\u201314th centuries, came into use in the Mughal Empire some time around the 16th century, and is still used in India through to the present day. Another innovation, the incorporation of the crank handle in the cotton gin, first appeared in India some time during the late Delhi Sultanate or the early Mughal Empire. The production of cotton, which may have largely been spun in the villages and then taken to towns in the form of yarn to be woven into cloth textiles, was advanced by the diffusion of the spinning wheel across India shortly before the Mughal era, lowering the costs of yarn and helping to increase demand for cotton. The diffusion of the spinning wheel, and the incorporation of the worm gear and crank handle into the roller cotton gin, led to greatly expanded Indian cotton textile production during the Mughal era.\nIt was reported that, with an Indian cotton gin, which is half machine and half tool, one man and one woman could clean of cotton per day. With a modified Forbes version, one man and a boy could produce per day. If oxen were used to power 16 of these machines, and a few people's labour was used to feed them, they could produce as much work as 750 people did formerly.\nEgypt.\nIn the early 19th century, a Frenchman named M. Jumel proposed to the great ruler of Egypt, Mohamed Ali Pasha, that he could earn a substantial income by growing an extra-long staple Maho (\"Gossypium barbadense\") cotton, in Lower Egypt, for the French market. Mohamed Ali Pasha accepted the proposition and granted himself the monopoly on the sale and export of cotton in Egypt; and later dictated cotton should be grown in preference to other crops.\nEgypt under Muhammad Ali in the early 19th century had the fifth most productive cotton industry in the world, in terms of the number of spindles per capita. The industry was initially driven by machinery that relied on traditional energy sources, such as slave labour, animal power, water wheels, and windmills, which were also the principal energy sources in Western Europe up until around 1870. It was under Muhammad Ali in the early 19th century that steam engines were introduced to the Egyptian cotton industry.\nBy the time of the American Civil war annual exports had reached $16 million (120,000 bales), which rose to $56 million by 1864, primarily due to the loss of the Confederate supply on the world market. Exports continued to grow even after the reintroduction of US cotton, produced now by a paid workforce, and Egyptian exports reached 1.2 million bales a year by 1903.\nBritain.\nEast India Company.\nThe English East India Company (EIC) introduced the British to cheap calico and chintz cloth on the restoration of the monarchy in the 1660s. Initially imported as a novelty side line, from its spice trading posts in Asia, the cheap colourful cloth proved popular and overtook the EIC's spice trade by value in the late 17th century. The EIC embraced the demand, particularly for calico, by expanding its factories in Asia and producing and importing cloth in bulk, creating competition for domestic woollen and linen textile producers. The impacted weavers, spinners, dyers, shepherds and farmers objected and the calico question became one of the major issues of National politics between the 1680s and the 1730s. Parliament began to see a decline in domestic textile sales, and an increase in imported textiles from places like China and India. Seeing the East India Company and their textile importation as a threat to domestic textile businesses, Parliament passed the 1700 Calico Act, blocking the importation of cotton cloth. As there was no punishment for continuing to sell cotton cloth, smuggling of the popular material became commonplace. In 1721, dissatisfied with the results of the first act, Parliament passed a stricter addition, this time prohibiting the sale of most cottons, imported and domestic (exempting only thread Fustian and raw cotton). The exemption of raw cotton from the prohibition initially saw 2 thousand bales of cotton imported annually, to become the basis of a new indigenous industry, initially producing Fustian for the domestic market, though more importantly triggering the development of a series of mechanised spinning and weaving technologies, to process the material. This mechanised production was concentrated in new cotton mills, which slowly expanded until by the beginning of the 1770s seven thousand bales of cotton were imported annually, and pressure was put on Parliament, by the new mill owners, to remove the prohibition on the production and sale of pure cotton cloth, as they could easily compete with anything the EIC could import.\nThe acts were repealed in 1774, triggering a wave of investment in mill-based cotton spinning and production, doubling the demand for raw cotton within a couple of years, and doubling it again every decade, into the 1840s.\nIndian cotton textiles, particularly those from Bengal, continued to maintain a competitive advantage up until the 19th century. In order to compete with India, Britain invested in labour-saving technical progress, while implementing protectionist policies such as bans and tariffs to restrict Indian imports. At the same time, the East India Company's rule in India contributed to its deindustrialization, opening up a new market for British goods, while the capital amassed from Bengal after its 1757 conquest was used to invest in British industries such as textile manufacturing and greatly increase British wealth. British colonization also forced open the large Indian market to British goods, which could be sold in India without tariffs or duties, compared to local Indian producers who were heavily taxed, while raw cotton was imported from India without tariffs to British factories which manufactured textiles from Indian cotton, giving Britain a monopoly over India's large market and cotton resources. India served as both a significant supplier of raw goods to British manufacturers and a large captive market for British manufactured goods. Britain eventually surpassed India as the world's leading cotton textile manufacturer in the 19th century.\nIndia's cotton-processing sector changed during EIC expansion in India in the late 18th and early 19th centuries. From focusing on supplying the British market to supplying East Asia with raw cotton. As the Artisan produced textiles were no longer competitive with those produced Industrially, and Europe preferring the cheaper slave produced, long staple American, and Egyptian cottons, for its own materials.\nIndustrial Revolution.\nThe advent of the Industrial Revolution in Britain provided a great boost to cotton manufacture, as textiles emerged as Britain's leading export. In 1738, Lewis Paul and John Wyatt, of Birmingham, England, patented the roller spinning machine, as well as the flyer-and-bobbin system for drawing cotton to a more even thickness using two sets of rollers that traveled at different speeds. Later, the invention of the James Hargreaves' spinning jenny in 1764, Richard Arkwright's spinning frame in 1769 and Samuel Crompton's spinning mule in 1775 enabled British spinners to produce cotton yarn at much higher rates. From the late 18th century on, the British city of Manchester acquired the nickname \"Cottonopolis\" due to the cotton industry's omnipresence within the city, and Manchester's role as the heart of the global cotton trade.\nProduction capacity in Britain and the United States was improved by the invention of the modern cotton gin by the American Eli Whitney in 1793. Before the development of cotton gins, the cotton fibers had to be pulled from the seeds tediously by hand. By the late 1700s, a number of crude ginning machines had been developed. However, to produce a bale of cotton required over 600 hours of human labor, making large-scale production uneconomical in the United States, even with the use of humans as slave labor. The gin that Whitney manufactured (the Holmes design) reduced the hours down to just a dozen or so per bale. Although Whitney patented his own design for a cotton gin, he manufactured a prior design from Henry Odgen Holmes, for which Holmes filed a patent in 1796. Improving technology and increasing control of world markets allowed British traders to develop a commercial chain in which raw cotton fibers were (at first) purchased from colonial plantations, processed into cotton cloth in the mills of Lancashire, and then exported on British ships to captive colonial markets in West Africa, India, and China (via Shanghai and Hong Kong).\nBy the 1840s, India was no longer capable of supplying the vast quantities of cotton fibers needed by mechanized British factories, while shipping bulky, low-price cotton from India to Britain was time-consuming and expensive. This, coupled with the emergence of American cotton as a superior type (due to the longer, stronger fibers of the two domesticated native American species, \"Gossypium hirsutum\" and \"Gossypium barbadense\"), encouraged British traders to purchase cotton from plantations in the United States and in the Caribbean. By the mid-19th century, \"King Cotton\" had become the backbone of the southern American economy. In the United States, cultivating and harvesting cotton became the leading occupation of slaves.\nDuring the American Civil War, American cotton exports slumped due to a Union blockade on Southern ports, and because of a strategic decision by the Confederate government to cut exports, hoping to force Britain to recognize the Confederacy or enter the war. The Lancashire Cotton Famine prompted the main purchasers of cotton, Britain and France, to turn to Egyptian cotton. British and French traders invested heavily in cotton plantations. The Egyptian government of Viceroy Isma'il took out substantial loans from European bankers and stock exchanges. After the American Civil War ended in 1865, British and French traders abandoned Egyptian cotton and returned to cheap American exports, sending Egypt into a deficit spiral that led to the country declaring bankruptcy in 1876, a key factor behind Egypt's occupation by the British Empire in 1882.\nDuring this time, cotton cultivation in the British Empire, especially Australia and India, greatly increased to replace the lost production of the American South. Through tariffs and other restrictions, the British government discouraged the production of cotton cloth in India; rather, the raw fiber was sent to England for processing. The Indian Mahatma Gandhi described the process:\nUnited States.\nIn the United States, growing Southern cotton generated significant wealth and capital for the antebellum South, as well as raw material for Northern textile industries. Before 1865 the cotton was largely produced through the labor of enslaved African Americans. It enriched both the Southern landowners and the new textile industries of the Northeastern United States and northwestern Europe. In 1860 the slogan \"Cotton is king\" characterized the attitude of Southern leaders toward this monocrop in that Europe would support an independent Confederate States of America in 1861 in order to protect the supply of cotton it needed for its very large textile industry.\nRussell Griffin of California was a farmer who farmed one of the biggest cotton operations. He produced over sixty thousand bales.\nCotton remained a key crop in the Southern economy after slavery ended in 1865. Across the South, sharecropping evolved, in which landless farmers worked land owned by others in return for a share of the profits. Some farmers rented the land and bore the production costs themselves. Until mechanical cotton pickers were developed, cotton farmers needed additional labor to hand-pick cotton. Picking cotton was a source of income for families across the South. Rural and small town school systems had split vacations so children could work in the fields during \"cotton-picking.\"\nDuring the middle 20th century, employment in cotton farming fell, as machines began to replace laborers and the South's rural labor force dwindled during the World Wars. Cotton remains a major export of the United States, with large farms in California, Arizona and the Deep South. To acknowledge cotton's place in the history and heritage of Texas, the Texas Legislature designated cotton the official \"State Fiber and Fabric of Texas\" in 1997.\nThe Moon.\nChina's Chang'e 4 spacecraft took cotton seeds to the Moon's far side. On 15 January 2019, China announced that a cotton seed sprouted, the first \"truly otherworldly plant in history\". Inside the Von K\u00e1rm\u00e1n Crater, the capsule and seeds sit inside the Chang'e 4 lander.\nCultivation.\nSuccessful cultivation of cotton requires a long frost-free period, plenty of sunshine, and a moderate rainfall, usually from . Soils usually need to be fairly heavy, although the level of nutrients does not need to be exceptional. In general, these conditions are met within the seasonally dry tropics and subtropics in the Northern and Southern hemispheres, but a large proportion of the cotton grown today is cultivated in areas with less rainfall that obtain the water from irrigation. Production of the crop for a given year usually starts soon after harvesting the preceding autumn. Cotton is naturally a perennial but is grown as an annual to help control pests. Planting time in spring in the Northern hemisphere varies from the beginning of February to the beginning of June. The area of the United States known as the South Plains is the largest contiguous cotton-growing region in the world. While dryland (non-irrigated) cotton is successfully grown in this region, consistent yields are only produced with heavy reliance on irrigation water drawn from the Ogallala Aquifer. Since cotton is somewhat salt and drought tolerant, this makes it an attractive crop for arid and semiarid regions. As water resources get tighter around the world, economies that rely on it face difficulties and conflict, as well as potential environmental problems. For example, improper cropping and irrigation practices have led to desertification in areas of Uzbekistan, where cotton is a major export. In the days of the Soviet Union, the Aral Sea was tapped for agricultural irrigation, largely of cotton, and now salination is widespread.\nCotton can also be cultivated to have colors other than the yellowish off-white typical of modern commercial cotton fibers. Naturally colored cotton can come in red, green, and several shades of brown.\nWater footprint.\nThe water footprint of cotton fibers is substantially larger than for most other plant fibers. Cotton is also known as a thirsty crop; on average, globally, cotton requires 8,000\u201310,000 liters of water for one kilogram of cotton, and in dry areas, it may require even more such as in some areas of India, it may need 22,500 liters.\nGenetic modification.\nGenetically modified (GM) cotton was developed to reduce the heavy reliance on pesticides. The bacterium \"Bacillus thuringiensis\" (Bt) naturally produces a chemical harmful only to a small fraction of insects, most notably the larvae of moths and butterflies, beetles, and flies, and harmless to other forms of life. The gene coding for Bt toxin has been inserted into cotton, causing cotton, called Bt cotton, to produce this natural insecticide in its tissues. In many regions, the main pests in commercial cotton are lepidopteran larvae, which are killed by the Bt protein in the transgenic cotton they eat. This eliminates the need to use large amounts of broad-spectrum insecticides to kill lepidopteran pests (some of which have developed pyrethroid resistance). This spares natural insect predators in the farm ecology and further contributes to noninsecticide pest management.\nHowever, Bt cotton is ineffective against many cotton pests, such as plant bugs, stink bugs, and aphids; depending on circumstances it may still be desirable to use insecticides against these. A 2006 study done by Cornell researchers, the Center for Chinese Agricultural Policy and the Chinese Academy of Science on Bt cotton farming in China found that after seven years these secondary pests that were normally controlled by pesticide had increased, necessitating the use of pesticides at similar levels to non-Bt cotton and causing less profit for farmers because of the extra expense of GM seeds. However, a 2009 study by the Chinese Academy of Sciences, Stanford University and Rutgers University refuted this. They concluded that the GM cotton effectively controlled bollworm. The secondary pests were mostly miridae (plant bugs) whose increase was related to local temperature and rainfall and only continued to increase in half the villages studied. Moreover, the increase in insecticide use for the control of these secondary insects was far smaller than the reduction in total insecticide use due to Bt cotton adoption. A 2012 Chinese study concluded that Bt cotton halved the use of pesticides and doubled the level of ladybirds, lacewings and spiders. The International Service for the Acquisition of Agri-biotech Applications (ISAAA) said that, worldwide, GM cotton was planted on an area of 25 million hectares in 2011. This was 69% of the worldwide total area planted in cotton.\nGM cotton acreage in India grew at a rapid rate, increasing from 50,000 hectares in 2002 to 10.6 million hectares in 2011. The total cotton area in India was 12.1 million hectares in 2011, so GM cotton was grown on 88% of the cotton area. This made India the country with the largest area of GM cotton in the world. A long-term study on the economic impacts of Bt cotton in India, published in the Journal PNAS in 2012, showed that Bt cotton has increased yields, profits, and living standards of smallholder farmers. The U.S. GM cotton crop was 4.0 million hectares in 2011 the second largest area in the world, the Chinese GM cotton crop was third largest by area with 3.9 million hectares and Pakistan had the fourth largest GM cotton crop area of 2.6 million hectares in 2011. The initial introduction of GM cotton proved to be a success in Australia\u00a0\u2013 the yields were equivalent to the non-transgenic varieties and the crop used much less pesticide to produce (85% reduction). The subsequent introduction of a second variety of GM cotton led to increases in GM cotton production until 95% of the Australian cotton crop was GM in 2009 making Australia the country with the fifth largest GM cotton crop in the world. Other GM cotton growing countries in 2011 were Argentina, Myanmar, Burkina Faso, Brazil, Mexico, Colombia, South Africa and Costa Rica.\nCotton has been genetically modified for resistance to glyphosate a broad-spectrum herbicide discovered by Monsanto which also sells some of the Bt cotton seeds to farmers. There are also a number of other cotton seed companies selling GM cotton around the world. About 62% of the GM cotton grown from 1996 to 2011 was insect resistant, 24% stacked product and 14% herbicide resistant.\nCotton has gossypol, a toxin that makes it inedible. However, scientists have silenced the gene that produces the toxin, making it a potential food crop. On 17 October 2018, the USDA deregulated GE low-gossypol cotton.\nOrganic production.\nOrganic cotton is generally understood as cotton from plants not genetically modified and that is certified to be grown without the use of any synthetic agricultural chemicals, such as fertilizers or pesticides. Its production also promotes and enhances biodiversity and biological cycles. In the United States, organic cotton plantations are required to enforce the National Organic Program (NOP). This institution determines the allowed practices for pest control, growing, fertilizing, and handling of organic crops. As of 2007, 265,517 bales of organic cotton were produced in 24 countries, and worldwide production was growing at a rate of more than 50% per year. Organic cotton products are now available for purchase at limited locations. These are popular for baby clothes and diapers; natural cotton products are known to be both sustainable and hypoallergenic.\nPests and weeds.\nThe cotton industry relies heavily on chemicals, such as fertilizers, insecticides and herbicides, although a very small number of farmers are moving toward an organic model of production. Under most definitions, organic products do not use transgenic \"Bt\" cotton which contains a bacterial gene that codes for a plant-produced protein that is toxic to a number of pests especially the bollworms. For most producers, \"Bt\" cotton has allowed a substantial reduction in the use of synthetic insecticides, although in the long term resistance may become problematic.\nGlobal pest problems.\nSignificant global pests of cotton include various species of bollworm, such as \"Pectinophora gossypiella\". Sucking pests include cotton stainers, the chili thrips, \"Scirtothrips dorsalis\"; the cotton seed bug, \"Oxycarenus hyalinipennis\". Defoliators include the fall armyworm, \"Spodoptera frugiperda\".\nCotton yield is threatened by the evolution of new biotypes of insects and of new pathogens. Maintaining good yield requires strategies to slow these adversaries' evolution.\nNorth American insect pests.\nHistorically, in North America, one of the most economically destructive pests in cotton production has been the boll weevil. Boll weevils are beetles who ate cotton in the 1950s, that slowed the production of the cotton industry drastically. \"This bone pile of short budgets, loss of market share, failing prices, abandoned farms, and the new immunity of boll weevils generated a feeling of helplessness\" Boll Weevils first appeared in Beeville, Texas wiping out field after field of cotton in south Texas. This swarm of Boll Weevils swept through east Texas and spread to the eastern seaboard, leaving ruin and devastation in its path, causing many cotton farmers to go out of business.\nDue to the US Department of Agriculture's highly successful Boll Weevil Eradication Program (BWEP), this pest has been eliminated from cotton in most of the United States. This program, along with the introduction of genetically engineered Bt cotton, has improved the management of a number of pests such as cotton bollworm and pink bollworm. Sucking pests include the cotton stainer, \"Dysdercus suturellus\" and the tarnish plant bug, \"Lygus lineolaris\". A significant cotton disease is caused by \"Xanthomonas citri\" subsp. \"malvacearum\".\nHarvesting.\nMost cotton in the United States, Europe and Australia is harvested mechanically, either by a cotton picker, a machine that removes the cotton from the boll without damaging the cotton plant, or by a cotton stripper, which strips the entire boll off the plant. Cotton strippers are used in regions where it is too windy to grow picker varieties of cotton, and usually after application of a chemical defoliant or the natural defoliation that occurs after a freeze. Cotton is a perennial crop in the tropics, and without defoliation or freezing, the plant will continue to grow.\nCotton continues to be picked by hand in developing countries and in Xinjiang, China, allegedly by forced labor. Xinjiang produces over 20% of the world's cotton.\nCompetition from synthetic fibers.\nThe era of manufactured fibers began with the development of rayon in France in the 1890s. Rayon is derived from a natural cellulose and cannot be considered synthetic, but requires extensive processing in a manufacturing process, and led the less expensive replacement of more naturally derived materials. A succession of new synthetic fibers were introduced by the chemicals industry in the following decades. Acetate in fiber form was developed in 1924. Nylon, the first fiber synthesized entirely from petrochemicals, was introduced as a sewing thread by DuPont in 1936, followed by DuPont's acrylic in 1944. Some garments were created from fabrics based on these fibers, such as women's hosiery from nylon, but it was not until the introduction of polyester into the fiber marketplace in the early 1950s that the market for cotton came under threat. The rapid uptake of polyester garments in the 1960s caused economic hardship in cotton-exporting economies, especially in Central American countries, such as Nicaragua, where cotton production had boomed tenfold between 1950 and 1965 with the advent of cheap chemical pesticides. Cotton production recovered in the 1970s, but crashed to pre-1960 levels in the early 1990s.\nCompetition from natural fibers.\nHigh water and pesticide use in cotton cultivation has prompted sustainability concerns and created a market for natural fiber alternatives. Other cellulose fibers, such as hemp, are seen as more sustainable options because of higher yields per acre with less water and pesticide use than cotton. Cellulose fiber alternatives have similar characteristics but are not perfect substitutes for cotton textiles with differences in properties like tensile strength and thermal regulation.\nUses.\nCotton is used to make a number of textile products. These include terrycloth for highly absorbent bath towels and robes; denim for blue jeans; cambric, popularly used in the manufacture of blue work shirts (from which the term \"blue-collar\" is derived) and corduroy, seersucker, and cotton twill. Socks, underwear, and most T-shirts are made from cotton. Bed sheets often are made from cotton. It is a preferred material for sheets as it is hypoallergenic, easy to maintain and non-irritant to the skin. Cotton also is used to make yarn used in crochet and knitting. Fabric also can be made from recycled or recovered cotton that otherwise would be thrown away during the spinning, weaving, or cutting process. While many fabrics are made completely of cotton, some materials blend cotton with other fibers, including rayon and synthetic fibers such as polyester. It can either be used in knitted or woven fabrics, as it can be blended with elastine to make a stretchier thread for knitted fabrics, and apparel such as stretch jeans. Cotton can be blended also with linen producing fabrics with the benefits of both materials. Linen-cotton blends are wrinkle resistant and retain heat more effectively than only linen, and are thinner, stronger and lighter than only cotton.\nIn addition to the textile industry, cotton is used in fishing nets, coffee filters, tents, explosives manufacture (see nitrocellulose), cotton paper, and in bookbinding. Fire hoses were once made of cotton.\nCottonseed.\nThe cottonseed which remains after the cotton is ginned is used to produce cottonseed oil, which, after refining, can be consumed by humans like any other vegetable oil. The cottonseed meal that is left generally is fed to ruminant livestock; the gossypol remaining in the meal is toxic to monogastric animals. Cottonseed hulls can be added to dairy cattle rations for roughage. During the American slavery period, cotton root bark was used in folk remedies as an abortifacient, that is, to induce a miscarriage. Gossypol was one of the many substances found in all parts of the cotton plant and it was described by the scientists as 'poisonous pigment'. It also appears to inhibit the development of sperm or even restrict the mobility of the sperm. Also, it is thought to interfere with the menstrual cycle by restricting the release of certain hormones.\nCotton linters.\nCotton linters are fine, silky fibers which adhere to the seeds of the cotton plant after ginning. These curly fibers typically are less than long. The term also may apply to the longer textile fiber staple lint as well as the shorter fuzzy fibers from some upland species. Linters are traditionally used in the manufacture of paper and as a raw material in the manufacture of cellulose. In the UK, linters are referred to as \"cotton wool\".\nA less technical use of the term \"cotton wool\", in the UK and Ireland, is for the refined product known as \"absorbent cotton\" (or, often, just \"cotton\") in U.S. usage: fluffy cotton in sheets or balls used for medical, cosmetic, protective packaging, and many other practical purposes. The first medical use of cotton wool was by Sampson Gamgee at the Queen's Hospital (later the General Hospital) in Birmingham, England.\nLong staple cotton.\nLong staple (LS cotton) is cotton of a longer fibre length and therefore of higher quality, while Extra-long staple cotton (ELS cotton) has longer fibre length still and of even higher quality. The name \"Egyptian cotton\" is broadly associated high quality cottons and is often an LS or (less often) an ELS cotton. Nowadays the name \"Egyptian cotton\" refers more to the way cotton is treated and threads produced rather than the location where it is grown. The American cotton variety \"Pima\" cotton is often compared to Egyptian cotton, as both are used in high quality bed sheets and other cotton products. While Pima cotton is often grown in the American southwest, the Pima name is now used by cotton-producing nations such as Peru, Australia and Israel. Not all products bearing the Pima name are made with the finest cotton: American-grown ELS Pima cotton is trademarked as \"Supima\" cotton. \"Kasturi\" cotton is a brand-building initiative for Indian long staple cotton by the Indian government. The PIB issued a press release announcing the same.\nOrnamental use.\nCottons have been grown as ornamentals or novelties due to their showy flowers and snowball-like fruit. For example, Jumel's cotton, once an important source of fiber in Egypt, started as an ornamental. However, agricultural authorities such as the Boll Weevil Eradication Program in the United States discourage using cotton as an ornamental, due to concerns about these plants harboring pests injurious to crops.\nInternational trade.\nThe largest producers of cotton, as of 2017, are India and China, with annual production of about and , respectively; most of this production is consumed by their respective textile industries. The largest exporters of raw cotton are the United States, with sales of $4.9 billion, and Africa, with sales of $2.1 billion. The total international trade is estimated to be $12 billion. Africa's share of the cotton trade has doubled since 1980. Neither area has a significant domestic textile industry, textile manufacturing having moved to developing nations in Eastern and South Asia such as India and China. In Africa, cotton is grown by numerous small holders. Dunavant Enterprises, based in Memphis, Tennessee, is the leading cotton broker in Africa, with hundreds of purchasing agents. It operates cotton gins in Uganda, Mozambique, and Zambia. In Zambia, it often offers loans for seed and expenses to the 180,000 small farmers who grow cotton for it, as well as advice on farming methods. Cargill also purchases cotton in Africa for export.\nThe 25,000 cotton growers in the United States are heavily subsidized at the rate of $2 billion per year although China now provides the highest overall level of cotton sector support. The future of these subsidies is uncertain and has led to anticipatory expansion of cotton brokers' operations in Africa. Dunavant expanded in Africa by buying out local operations. This is only possible in former British colonies and Mozambique; former French colonies continue to maintain tight monopolies, inherited from their former colonialist masters, on cotton purchases at low fixed prices.\nTo encourage trade and organize discussion about cotton, World Cotton Day is celebrated every October 7.\nCotton is included within World Trade Organization (WTO) activities within two \"complementary tracks\":\nAn agreement on trade in cotton formed part of the ministerial declaration concluding the World Trade Organization Ministerial Conference of 2005.\nProduction.\nIn 2022, world production of cotton was 69.7 million tonnes, led by China with 26% of the total. Other major producers were India (22%) and the United States (12%) (table).\nThe five leading exporters of cotton in 2019 are (1) India, (2) the United States, (3) China, (4) Brazil, and (5) Pakistan.\nIn India, the states of Maharashtra (26.63%), Gujarat (17.96%) and Andhra Pradesh (13.75%) and also Madhya Pradesh are the leading cotton producing states, these states have a predominantly tropical wet and dry climate.\nIn the United States, the state of Texas led in total production as of 2004, while the state of California had the highest yield per acre.\nFair trade.\nCotton is an enormously important commodity throughout the world. It provides livelihoods for up to 1 billion people, including 100 million smallholder farmers who cultivate cotton. However, many farmers in developing countries receive a low price for their produce, or find it difficult to compete with developed countries.\nThis has led to an international dispute (see Brazil\u2013United States cotton dispute):\nOn 27 September 2002, Brazil requested consultations with the US regarding prohibited and actionable subsidies provided to US producers, users and/or exporters of upland cotton, as well as legislation, regulations, statutory instruments and amendments thereto providing such subsidies (including export credits), grants, and any other assistance to the US producers, users and exporters of upland cotton.\nOn 8 September 2004, the Panel Report recommended that the United States \"withdraw\" export credit guarantees and payments to domestic users and exporters, and \"take appropriate steps to remove the adverse effects or withdraw\" the mandatory price-contingent subsidy measures.\nWhile Brazil was fighting the US through the WTO's Dispute Settlement Mechanism against a heavily subsidized cotton industry, a group of four least-developed African countries\u00a0\u2013 Benin, Burkina Faso, Chad, and Mali\u00a0\u2013 also known as \"Cotton-4\" have been the leading protagonist for the reduction of US cotton subsidies through negotiations. The four introduced a \"Sectoral Initiative in Favour of Cotton\", presented by Burkina Faso's President Blaise Compaor\u00e9 during the Trade Negotiations Committee on 10 June 2003.\nIn addition to concerns over subsidies, the cotton industries of some countries are criticized for employing child labor and damaging workers' health by exposure to pesticides used in production. The Environmental Justice Foundation has campaigned against the prevalent use of forced child and adult labor in cotton production in Uzbekistan, the world's third largest cotton exporter.\nThe international production and trade situation has led to \"fair trade\" cotton clothing and footwear, joining a rapidly growing market for organic clothing, fair fashion or \"ethical fashion\". The fair trade system was initiated in 2005 with producers from Cameroon, Mali and Senegal, with the Association Max Havelaar France playing a lead role in the establishment of this segment of the fair trade system in conjunction with Fairtrade International and the French organisation (\"D\u00e9veloppement des Agro-Industries du Sud\").\nTrading.\nCotton is bought and sold by investors and price speculators as a tradable commodity on two different commodity exchanges in the United States of America.\nCritical temperatures.\nA temperature range of is the optimal range for mold development. At temperatures below , rotting of wet cotton stops. Damaged cotton is sometimes stored at these temperatures to prevent further deterioration.\nEgypt has a unique climatic temperature that the soil and the temperature provide an exceptional environment for cotton to grow rapidly.\nFiber properties.\nDepending upon the origin, the chemical composition of cotton is as follows:\nMorphology.\nCotton has a more complex structure among the other crops. A matured cotton fiber is a single, elongated complete dried multilayer cell that develops in the surface layer of cottonseed. It has the following parts.\nDead cotton.\nDead cotton is a term that refers to unripe cotton fibers that do not absorb dye. Dead cotton is immature cotton that has poor dye affinity and appears as white specks on a dyed fabric. When cotton fibers are analyzed and assessed through a microscope, dead fibers appear differently. Dead cotton fibers have thin cell walls. In contrast, mature fibers have more cellulose and a greater degree of cell wall thickening\nGenome.\nThere is a public effort to sequence the genome of cotton. It was started in 2007 by a consortium of public researchers. Their aim is to sequence the genome of cultivated, tetraploid cotton. \"Tetraploid\" means that its nucleus has two separate genomes, called A and D. The consortium agreed to first sequence the D-genome wild relative of cultivated cotton (\"G. raimondii\", a Central American species) because it is small and has few repetitive elements. It has nearly one-third of the bases of tetraploid cotton, and each chromosome occurs only once. Then, the A genome of \"G. arboreum\" would be sequenced. Its genome is roughly twice that of \"G. raimondii\". Part of the difference in size is due to the amplification of \"retrotransposons\" (GORGE). After both diploid genomes are assembled, they would be used as models for sequencing the genomes of tetraploid cultivated species. Without knowing the diploid genomes, the euchromatic DNA sequences of AD genomes would co-assemble, and their repetitive elements would assemble independently into A and D sequences respectively. There would be no way to untangle the mess of AD sequences without comparing them to their diploid counterparts.\nThe public sector effort continues with the goal to create a high-quality, draft genome sequence from reads generated by all sources. The effort has generated Sanger reads of BACs, fosmids, and plasmids, as well as 454 reads. These later types of reads will be instrumental in assembling an initial draft of the D genome. In 2010, the companies Monsanto and Illumina completed enough Illumina sequencing to cover the D genome of \"G. raimondii\" about 50x. They announced that they would donate their raw reads to the public. This public relations effort gave them some recognition for sequencing the cotton genome. Once the D genome is assembled from all of this raw material, it will undoubtedly assist in the assembly of the AD genomes of cultivated varieties of cotton, but much work remains.\nAs of 2014, at least one assembled cotton genome had been reported.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36807", "revid": "19896941", "url": "https://en.wikipedia.org/wiki?curid=36807", "title": "Football Hall of Fame", "text": "Football Hall of Fame may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nCanadian football.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "36808", "revid": "47673415", "url": "https://en.wikipedia.org/wiki?curid=36808", "title": "Heart", "text": "Organ found in humans and other animals\nThe heart is a muscular organ found in humans and other animals. This organ pumps blood through the blood vessels. The heart and blood vessels together make up the circulatory system. The pumped blood carries oxygen and nutrients to the tissue, while carrying metabolic waste such as carbon dioxide to the lungs. In humans, the heart is approximately the size of a closed fist and is located between the lungs, in the middle compartment of the chest, called the mediastinum.\nIn humans, the heart is divided into four chambers: upper left and right atria and lower left and right ventricles. Commonly, the right atrium and ventricle are referred together as the right heart and their left counterparts as the left heart. In a healthy heart, blood flows one way through the heart due to heart valves, which prevent backflow. The heart is enclosed in a protective sac, the pericardium, which also contains a small amount of fluid. The wall of the heart is made up of three layers: epicardium, myocardium, and endocardium. \nThe heart pumps blood with a rhythm determined by a group of pacemaker cells in the sinoatrial node. These generate an electric current that causes the heart to contract, traveling through the atrioventricular node and along the conduction system of the heart. In humans, deoxygenated blood enters the heart through the right atrium from the superior and inferior venae cavae and passes to the right ventricle. From here, it is pumped into pulmonary circulation to the lungs, where it receives oxygen and gives off carbon dioxide. Oxygenated blood then returns to the left atrium, passes through the left ventricle and is pumped out through the aorta into systemic circulation, traveling through arteries, arterioles, and capillaries\u2014where nutrients and other substances are exchanged between blood vessels and cells, losing oxygen and gaining carbon dioxide\u2014before being returned to the heart through venules and veins. The adult heart beats at a resting rate close to 72 beats per minute.\nCardiovascular diseases were the most common cause of death globally as of 2008, accounting for 30% of all human deaths. Of these more than three-quarters are a result of coronary artery disease and stroke. Risk factors include: smoking, being overweight, little exercise, high cholesterol, high blood pressure, and poorly controlled diabetes, among others. Cardiovascular diseases do not frequently have symptoms but may cause chest pain or shortness of breath. Diagnosis of heart disease is often done by the taking of a medical history, listening to the heart-sounds with a stethoscope, as well as with ECG, and echocardiogram which uses ultrasound. Specialists who focus on diseases of the heart are called cardiologists, although many specialties of medicine may be involved in treatment.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nStructure.\nLocation and shape.\nThe human heart is situated in the mediastinum, at the level of thoracic vertebrae T5\u2013T8. A double-membraned sac called the pericardium surrounds the heart and attaches to the mediastinum. The back surface of the heart lies near the vertebral column, and the front surface, known as the sternocostal surface, sits behind the sternum and rib cartilages. The upper part of the heart is the attachment point for several large blood vessels\u2014the venae cavae, aorta and pulmonary trunk. The upper part of the heart is located at the level of the third costal cartilage. The lower tip of the heart, the apex, lies to the left of the sternum (8 to 9\u00a0cm from the midsternal line) between the junction of the fourth and fifth ribs near their articulation with the costal cartilages.\nThe largest part of the heart is usually slightly offset to the left side of the chest (levocardia). In a rare congenital disorder (dextrocardia) the heart is offset to the right side and is felt to be on the left because the left heart is stronger and larger, since it pumps to all body parts. Because the heart is between the lungs, the left lung is smaller than the right lung and has a cardiac notch in its border to accommodate the heart.\nThe heart is cone-shaped, with its base positioned upwards and tapering down to the apex. An adult heart has a mass of 250\u2013350 grams (9\u201312\u00a0oz). The heart is often described as the size of a fist: 12\u00a0cm (5\u00a0in) in length, 8\u00a0cm (3.5\u00a0in) wide, and 6\u00a0cm (2.5\u00a0in) in thickness, although this description is disputed, as the heart is likely to be slightly larger. Well-trained athletes can have much larger hearts due to the effects of exercise on the heart muscle, similar to the response of skeletal muscle.\nChambers.\nThe heart has four chambers, two upper atria, the receiving chambers, and two lower ventricles, the discharging chambers. The atria open into the ventricles via the atrioventricular valves, present in the atrioventricular septum. This distinction is visible also on the surface of the heart as the coronary sulcus. There is an ear-shaped structure in the upper right atrium called the right atrial appendage, or auricle, and another in the upper left atrium, the left atrial appendage. The right atrium and the right ventricle together are sometimes referred to as the right heart. Similarly, the left atrium and the left ventricle together are sometimes referred to as the left heart. The ventricles are separated from each other by the interventricular septum, visible on the surface of the heart as the anterior longitudinal sulcus and the posterior interventricular sulcus.\nThe fibrous cardiac skeleton gives structure to the heart. It forms the atrioventricular septum, which separates the atria from the ventricles, and the fibrous rings, which serve as bases for the four heart valves. The cardiac skeleton also provides an important boundary in the heart's electrical conduction system since collagen cannot conduct electricity. The interatrial septum separates the atria, and the interventricular septum separates the ventricles. The interventricular septum is much thicker than the interatrial septum since the ventricles need to generate greater pressure when they contract.\nValves.\nThe heart has four valves, which separate its chambers. One valve lies between each atrium and ventricle, and one valve rests at the exit of each ventricle.\nThe valves between the atria and ventricles are called the atrioventricular valves. Between the right atrium and the right ventricle is the tricuspid valve. The tricuspid valve has three cusps, which connect to chordae tendinae and three papillary muscles named the anterior, posterior, and septal muscles, after their relative positions. The mitral valve lies between the left atrium and left ventricle. It is also known as the bicuspid valve due to its having two cusps, an anterior and a posterior cusp. These cusps are also attached via chordae tendinae to two papillary muscles projecting from the ventricular wall.\nThe papillary muscles extend from the walls of the heart to valves by cartilaginous connections called chordae tendinae. These muscles prevent the valves from falling too far back when they close. During the relaxation phase of the cardiac cycle, the papillary muscles are also relaxed and the tension on the chordae tendineae is slight. As the heart chambers contract, so do the papillary muscles. This creates tension on the chordae tendineae, helping to hold the cusps of the atrioventricular valves in place and preventing them from being blown back into the atria.\nTwo additional semilunar valves sit at the exit of each of the ventricles. The pulmonary valve is located at the base of the pulmonary artery. This has three cusps which are not attached to any papillary muscles. When the ventricle relaxes blood flows back into the ventricle from the artery and this flow of blood fills the pocket-like valve, pressing against the cusps which close to seal the valve. The semilunar aortic valve is at the base of the aorta and also is not attached to papillary muscles. This too has three cusps which close with the pressure of the blood flowing back from the aorta.\nRight heart.\nThe right heart consists of two chambers, the right atrium and the right ventricle, separated by a valve, the tricuspid valve.\nThe right atrium receives blood almost continuously from the body's two major veins, the superior and inferior venae cavae. A small amount of blood from the coronary circulation also drains into the right atrium via the coronary sinus, which is immediately above and to the middle of the opening of the inferior vena cava. In the wall of the right atrium is an oval-shaped depression known as the fossa ovalis, which is a remnant of an opening in the fetal heart known as the foramen ovale. Most of the internal surface of the right atrium is smooth, the depression of the fossa ovalis is medial, and the anterior surface has prominent ridges of pectinate muscles, which are also present in the right atrial appendage.\nThe right atrium is connected to the right ventricle by the tricuspid valve. The walls of the right ventricle are lined with trabeculae carneae, ridges of cardiac muscle covered by endocardium. In addition to these muscular ridges, a band of cardiac muscle, also covered by endocardium, known as the moderator band reinforces the thin walls of the right ventricle and plays a crucial role in cardiac conduction. It arises from the lower part of the interventricular septum and crosses the interior space of the right ventricle to connect with the inferior papillary muscle. The right ventricle tapers into the pulmonary trunk, into which it ejects blood when contracting. The pulmonary trunk branches into the left and right pulmonary arteries that carry the blood to each lung. The pulmonary valve lies between the right heart and the pulmonary trunk.\nLeft heart.\nThe left heart has two chambers: the left atrium and the left ventricle, separated by the mitral valve.\nThe left atrium receives oxygenated blood back from the lungs via one of the four pulmonary veins. The left atrium has an outpouching called the left atrial appendage. Like the right atrium, the left atrium is lined by pectinate muscles. The left atrium is connected to the left ventricle by the mitral valve.\nThe left ventricle is much thicker as compared with the right, due to the greater force needed to pump blood to the entire body. Like the right ventricle, the left also has trabeculae carneae, but there is no moderator band. The left ventricle pumps blood to the body through the aortic valve and into the aorta. Two small openings above the aortic valve carry blood to the heart muscle; the left coronary artery is above the left cusp of the valve, and the right coronary artery is above the right cusp.\nWall.\nThe heart wall is made up of three layers: the inner endocardium, middle myocardium and outer epicardium. These are surrounded by a double-membraned sac called the pericardium.\nThe innermost layer of the heart is called the endocardium. It is made up of a lining of simple squamous epithelium and covers heart chambers and valves. It is continuous with the endothelium of the veins and arteries of the heart, and is joined to the myocardium with a thin layer of connective tissue. The endocardium, by secreting endothelins, may also play a role in regulating the contraction of the myocardium.\nThe middle layer of the heart wall is the myocardium, which is the cardiac muscle\u2014a layer of involuntary striated muscle tissue surrounded by a framework of collagen. The cardiac muscle pattern is elegant and complex, as the muscle cells swirl and spiral around the chambers of the heart, with the outer muscles forming a figure 8 pattern around the atria and around the bases of the great vessels and the inner muscles, forming a figure 8 around the two ventricles and proceeding toward the apex. This complex swirling pattern allows the heart to pump blood more effectively.\nThere are two types of cells in cardiac muscle: muscle cells which have the ability to contract easily, and pacemaker cells of the conducting system. The muscle cells make up the bulk (99%) of cells in the atria and ventricles. These contractile cells are connected by intercalated discs which allow a rapid response to impulses of action potential from the pacemaker cells. The intercalated discs allow the cells to act as a syncytium and enable the contractions that pump blood through the heart and into the major arteries. The pacemaker cells make up 1% of cells and form the conduction system of the heart. They are generally much smaller than the contractile cells and have few myofibrils which gives them limited contractibility. Their function is similar in many respects to neurons. Cardiac muscle tissue has autorhythmicity, the unique ability to initiate a cardiac action potential at a fixed rate\u2014spreading the impulse rapidly from cell to cell to trigger the contraction of the entire heart.\nThere are specific proteins expressed in cardiac muscle cells. These are mostly associated with muscle contraction, and bind with actin, myosin, tropomyosin, and troponin. They include MYH6, ACTC1, TNNI3, CDH2 and PKP2. Other proteins expressed are MYH7 and LDB3 that are also expressed in skeletal muscle.\nPericardium.\nThe pericardium is the sac that surrounds the heart. The tough outer surface of the pericardium is called the fibrous membrane. This is lined by a double inner membrane called the serous membrane that produces pericardial fluid to lubricate the surface of the heart. The part of the serous membrane attached to the fibrous membrane is called the parietal pericardium, while the part of the serous membrane attached to the heart is known as the visceral pericardium. The pericardium is present in order to lubricate its movement against other structures within the chest, to keep the heart's position stabilised within the chest, and to protect the heart from infection.\nCoronary circulation.\nHeart tissue, like all cells in the body, needs to be supplied with oxygen, nutrients and a way of removing metabolic wastes. This is achieved by the coronary circulation, which includes arteries, veins, and lymphatic vessels. Blood flow through the coronary vessels occurs in peaks and troughs relating to the heart muscle's relaxation or contraction.\nHeart tissue receives blood from two arteries which arise just above the aortic valve. These are the left main coronary artery and the right coronary artery. The left main coronary artery splits shortly after leaving the aorta into two vessels, the left anterior descending and the left circumflex artery. The left anterior descending artery supplies heart tissue and the front, outer side, and septum of the left ventricle. It does this by branching into smaller arteries\u2014diagonal and septal branches. The left circumflex supplies the back and underneath of the left ventricle. The right coronary artery supplies the right atrium, right ventricle, and lower posterior sections of the left ventricle. The right coronary artery also supplies blood to the atrioventricular node (in about 90% of people) and the sinoatrial node (in about 60% of people). The right coronary artery runs in a groove at the back of the heart and the left anterior descending artery runs in a groove at the front. There is significant variation between people in the anatomy of the arteries that supply the heart. The arteries divide at their furthest reaches into smaller branches that join at the edges of each arterial distribution.\nThe coronary sinus is a large vein that drains into the right atrium, and receives most of the venous drainage of the heart. It receives blood from the great cardiac vein (receiving the left atrium and both ventricles), the posterior cardiac vein (draining the back of the left ventricle), the middle cardiac vein (draining the bottom of the left and right ventricles), and small cardiac veins. The anterior cardiac veins drain the front of the right ventricle and drain directly into the right atrium.\nSmall lymphatic networks called plexuses exist beneath each of the three layers of the heart. These networks collect into a main left and a main right trunk, which travel up the groove between the ventricles that exists on the heart's surface, receiving smaller vessels as they travel up. These vessels then travel into the atrioventricular groove, and receive a third vessel which drains the section of the left ventricle sitting on the diaphragm. The left vessel joins with this third vessel, and travels along the pulmonary artery and left atrium, ending in the inferior tracheobronchial node. The right vessel travels along the right atrium and the part of the right ventricle sitting on the diaphragm. It usually then travels in front of the ascending aorta and then ends in a brachiocephalic node.\nNerve supply.\nThe heart receives nerve signals from the vagus nerve and from nerves arising from the sympathetic trunk. These nerves act to influence, but not control, the heart rate. Sympathetic nerves also influence the force of heart contraction. Signals that travel along these nerves arise from two paired cardiovascular centres in the medulla oblongata. The vagus nerve of the parasympathetic nervous system acts to decrease the heart rate, and nerves from the sympathetic trunk act to increase the heart rate. These nerves form a network of nerves that lies over the heart called the cardiac plexus.\nThe vagus nerve is a long, wandering nerve that emerges from the brainstem and provides parasympathetic stimulation to a large number of organs in the thorax and abdomen, including the heart. The nerves from the sympathetic trunk emerge through the T1\u2013T4 thoracic ganglia and travel to both the sinoatrial and atrioventricular nodes, as well as to the atria and ventricles. The ventricles are more richly innervated by sympathetic fibers than parasympathetic fibers. Sympathetic stimulation causes the release of the neurotransmitter norepinephrine (also known as noradrenaline) at the neuromuscular junction of the cardiac nerves. This shortens the repolarisation period, thus speeding the rate of depolarisation and contraction, which results in an increased heart rate. It opens chemical or ligand-gated sodium and calcium ion channels, allowing an influx of positively charged ions. Norepinephrine binds to the beta\u20131 receptor.\nDevelopment.\nThe heart is the first functional organ to develop and starts to beat and pump blood at about three weeks into embryogenesis. This early start is crucial for subsequent embryonic and prenatal development.\nThe heart derives from splanchnopleuric mesenchyme in the neural plate which forms the cardiogenic region. Two endocardial tubes form here that fuse to form a primitive heart tube known as the tubular heart. Between the third and fourth week, the heart tube lengthens, and begins to fold to form an S-shape within the pericardium. This places the chambers and major vessels into the correct alignment for the developed heart. Further development will include the formation of the septa and the valves and the remodeling of the heart chambers. By the end of the fifth week, the septa are complete, and by the ninth week, the heart valves are complete.\nBefore the fifth week, there is an opening in the fetal heart known as the foramen ovale. The foramen ovale allowed blood in the fetal heart to pass directly from the right atrium to the left atrium, allowing some blood to bypass the lungs. Within seconds after birth, a flap of tissue known as the septum primum that previously acted as a valve closes the foramen ovale and establishes the typical cardiac circulation pattern. A depression in the surface of the right atrium remains where the foramen ovale was, called the fossa ovalis.\nThe embryonic heart begins beating at around 22 days after conception (5 weeks after the last normal menstrual period, LMP). It starts to beat at a rate near to the mother's which is about 75\u201380 beats per minute (bpm). The embryonic heart rate then accelerates and reaches a peak rate of 165\u2013185 bpm early in the early 7th week (early 9th week after the LMP). After 9 weeks (start of the fetal stage) it starts to decelerate, slowing to around 145 (\u00b125) bpm at birth. There is no difference in female and male heart rates before birth.\nPhysiology.\nBlood flow.\nThe heart functions as a pump in the circulatory system to provide a continuous flow of blood throughout the body. This circulation consists of the systemic circulation to and from the body and the pulmonary circulation to and from the lungs. Blood in the pulmonary circulation exchanges carbon dioxide for oxygen in the lungs through the process of respiration. The systemic circulation then transports oxygen to the body and returns carbon dioxide and relatively deoxygenated blood to the heart for transfer to the lungs.\nThe right heart collects deoxygenated blood from two large veins, the superior and inferior venae cavae. Blood collects in the right and left atrium continuously. The superior vena cava drains blood from above the diaphragm and empties into the upper back part of the right atrium. The inferior vena cava drains the blood from below the diaphragm and empties into the back part of the atrium below the opening for the superior vena cava. Immediately above and to the middle of the opening of the inferior vena cava is the opening of the thin-walled coronary sinus. Additionally, the coronary sinus returns deoxygenated blood from the myocardium to the right atrium. The blood collects in the right atrium. When the right atrium contracts, the blood is pumped through the tricuspid valve into the right ventricle. As the right ventricle contracts, the tricuspid valve closes and the blood is pumped into the pulmonary trunk through the pulmonary valve. The pulmonary trunk divides into pulmonary arteries and progressively smaller arteries throughout the lungs, until it reaches capillaries. As these pass by alveoli carbon dioxide is exchanged for oxygen. This happens through the passive process of diffusion.\nIn the left heart, oxygenated blood is returned to the left atrium via the pulmonary veins. It is then pumped into the left ventricle through the mitral valve and into the aorta through the aortic valve for systemic circulation. The aorta is a large artery that branches into many smaller arteries, arterioles, and ultimately capillaries. In the capillaries, oxygen and nutrients from blood are supplied to body cells for metabolism, and exchanged for carbon dioxide and waste products. Capillary blood, now deoxygenated, travels into venules and veins that ultimately collect in the superior and inferior vena cavae, and into the right heart.\nCardiac cycle.\nThe cardiac cycle is the sequence of events in which the heart contracts and relaxes with every heartbeat. The period of time during which the ventricles contract, forcing blood out into the aorta and main pulmonary artery, is known as systole, while the period during which the ventricles relax and refill with blood is known as diastole. The atria and ventricles work in concert, so in systole when the ventricles are contracting, the atria are relaxed and collecting blood. When the ventricles are relaxed in diastole, the atria contract to pump blood to the ventricles. This coordination ensures blood is pumped efficiently to the body.\nAt the beginning of the cardiac cycle, the ventricles are relaxing. As they do so, they are filled by blood passing through the open mitral and tricuspid valves. After the ventricles have completed most of their filling, the atria contract, forcing further blood into the ventricles and priming the pump. Next, the ventricles start to contract. As the pressure rises within the cavities of the ventricles, the mitral and tricuspid valves are forced shut. As the pressure within the ventricles rises further, exceeding the pressure with the aorta and pulmonary arteries, the aortic and pulmonary valves open. Blood is ejected from the heart, causing the pressure within the ventricles to fall. Simultaneously, the atria refill as blood flows into the right atrium through the superior and inferior vena cavae, and into the left atrium through the pulmonary veins. Finally, when the pressure within the ventricles falls below the pressure within the aorta and pulmonary arteries, the aortic and pulmonary valves close. The ventricles start to relax, the mitral and tricuspid valves open, and the cycle begins again.\nCardiac output.\nCardiac output (CO) is a measurement of the amount of blood pumped by each ventricle (stroke volume) in one minute. This is calculated by multiplying the stroke volume (SV) by the beats per minute of the heart rate (HR). So that: CO = SV x HR.\nThe cardiac output is normalized to body size through body surface area and is called the cardiac index.\nThe average cardiac output, using an average stroke volume of about 70mL, is 5.25 L/min, with a normal range of 4.0\u20138.0 L/min. The stroke volume is normally measured using an echocardiogram and can be influenced by the size of the heart, physical and mental condition of the individual, sex, contractility, duration of contraction, preload and afterload.\nPreload refers to the filling pressure of the atria at the end of diastole, when the ventricles are at their fullest. A main factor is how long it takes the ventricles to fill: if the ventricles contract more frequently, then there is less time to fill and the preload will be less. Preload can also be affected by a person's blood volume. The force of each contraction of the heart muscle is proportional to the preload, described as the Frank-Starling mechanism. This states that the force of contraction is directly proportional to the initial length of muscle fiber, meaning a ventricle will contract more forcefully, the more it is stretched.\nAfterload, or how much pressure the heart must generate to eject blood at systole, is influenced by vascular resistance. It can be influenced by narrowing of the heart valves (stenosis) or contraction or relaxation of the peripheral blood vessels.\nThe strength of heart muscle contractions controls the stroke volume. This can be influenced positively or negatively by agents termed inotropes. These agents can be a result of changes within the body, or be given as drugs as part of treatment for a medical disorder, or as a form of life support, particularly in intensive care units. Inotropes that increase the force of contraction are \"positive\" inotropes, and include sympathetic agents such as adrenaline, noradrenaline and dopamine. \"Negative\" inotropes decrease the force of contraction and include calcium channel blockers.\nElectrical conduction.\nThe normal rhythmical heart beat, called sinus rhythm, is established by the heart's own pacemaker, the sinoatrial node (also known as the sinus node or the SA node). Here an electrical signal is created that travels through the heart, causing the heart muscle to contract. The sinoatrial node is found in the upper part of the right atrium near to the junction with the superior vena cava. The electrical signal generated by the sinoatrial node travels through the right atrium in a radial way that is not completely understood. It travels to the left atrium via Bachmann's bundle, such that the muscles of the left and right atria contract together. The signal then travels to the atrioventricular node. This is found at the bottom of the right atrium in the atrioventricular septum, the boundary between the right atrium and the left ventricle. The septum is part of the cardiac skeleton, tissue within the heart that the electrical signal cannot pass through, which forces the signal to pass through the atrioventricular node only. The signal then travels along the bundle of His to left and right bundle branches through to the ventricles of the heart. In the ventricles the signal is carried by specialized tissue called the Purkinje fibers which then transmit the electric charge to the heart muscle.\nHeart rate.\nThe normal resting heart rate is called the sinus rhythm, created and sustained by the sinoatrial node, a group of pacemaking cells found in the wall of the right atrium. Cells in the sinoatrial node do this by creating an action potential. The cardiac action potential is created by the movement of specific electrolytes into and out of the pacemaker cells. The action potential then spreads to nearby cells.\nWhen the sinoatrial cells are resting, they have a negative charge on their membranes. A rapid influx of sodium ions causes the membrane's charge to become positive; this is called depolarisation and occurs spontaneously. Once the cell has a sufficiently high charge, the sodium channels close and calcium ions then begin to enter the cell, shortly after which potassium begins to leave it. All the ions travel through ion channels in the membrane of the sinoatrial cells. The potassium and calcium start to move out of and into the cell only once it has a sufficiently high charge, and so are called voltage-gated. Shortly after this, the calcium channels close and potassium channels open, allowing potassium to leave the cell. This causes the cell to have a negative resting charge and is called repolarisation. When the membrane potential reaches approximately \u221260 mV, the potassium channels close and the process may begin again.\nThe ions move from areas where they are concentrated to where they are not. For this reason sodium moves into the cell from outside, and potassium moves from within the cell to outside the cell. Calcium also plays a critical role. Their influx through slow channels means that the sinoatrial cells have a prolonged \"plateau\" phase when they have a positive charge. A part of this is called the absolute refractory period. Calcium ions also combine with the regulatory protein troponin C in the troponin complex to enable contraction of the cardiac muscle, and separate from the protein to allow relaxation.\nThe adult resting heart rate ranges from 60 to 100 bpm. The resting heart rate of a newborn can be 129 beats per minute (bpm) and this gradually decreases until maturity. An athlete's heart rate can be lower than 60 bpm. During exercise the rate can be 150 bpm with maximum rates reaching from 200 to 220 bpm.\nInfluences.\nThe normal sinus rhythm of the heart, giving the resting heart rate, is influenced by a number of factors. The cardiovascular centres in the brainstem control the sympathetic and parasympathetic influences to the heart through the vagus nerve and sympathetic trunk. These cardiovascular centres receive input from a series of receptors including baroreceptors, sensing the stretching of blood vessels and chemoreceptors, sensing the amount of oxygen and carbon dioxide in the blood and its pH. Through a series of reflexes these help regulate and sustain blood flow.\nBaroreceptors are stretch receptors located in the aortic sinus, carotid bodies, the venae cavae, and other locations, including pulmonary vessels and the right side of the heart itself. Baroreceptors fire at a rate determined by how much they are stretched, which is influenced by blood pressure, level of physical activity, and the relative distribution of blood. With increased pressure and stretch, the rate of baroreceptor firing increases, and the cardiac centers decrease sympathetic stimulation and increase parasympathetic stimulation. As pressure and stretch decrease, the rate of baroreceptor firing decreases, and the cardiac centers increase sympathetic stimulation and decrease parasympathetic stimulation. There is a similar reflex, called the atrial reflex or Bainbridge reflex, associated with varying rates of blood flow to the atria. Increased venous return stretches the walls of the atria where specialized baroreceptors are located. However, as the atrial baroreceptors increase their rate of firing and as they stretch due to the increased blood pressure, the cardiac center responds by increasing sympathetic stimulation and inhibiting parasympathetic stimulation to increase heart rate. The opposite is also true. Chemoreceptors present in the carotid body or adjacent to the aorta in an aortic body respond to the blood's oxygen, carbon dioxide levels. Low oxygen or high carbon dioxide will stimulate firing of the receptors.\nExercise and fitness levels, age, body temperature, basal metabolic rate, and even a person's emotional state can all affect the heart rate. High levels of the hormones epinephrine, norepinephrine, and thyroid hormones can increase the heart rate. The levels of electrolytes including calcium, potassium, and sodium can also influence the speed and regularity of the heart rate; low blood oxygen, low blood pressure and dehydration may increase it.\nClinical significance.\nDiseases.\nCardiovascular diseases, which include diseases of the heart, are the leading cause of death worldwide. The majority of cardiovascular disease is noncommunicable and related to lifestyle and other factors, becoming more prevalent with ageing. Heart disease is a major cause of death, accounting for an average of 30% of all deaths in 2008, globally. This rate varies from a lower 28% to a high 40% in high-income countries. Doctors that specialise in the heart are called cardiologists. Many other medical professionals are involved in treating diseases of the heart, including doctors, cardiothoracic surgeons, intensivists, and allied health practitioners including physiotherapists and dieticians.\nIschemic heart disease.\nCoronary artery disease, also known as ischemic heart disease, is caused by atherosclerosis\u2014a build-up of fatty material along the inner walls of the arteries. These fatty deposits known as atherosclerotic plaques narrow the coronary arteries, and if severe may reduce blood flow to the heart. If a narrowing (or stenosis) is relatively minor then the patient may not experience any symptoms. Severe narrowings may cause chest pain (angina) or breathlessness during exercise or even at rest. The thin covering of an atherosclerotic plaque can rupture, exposing the fatty centre to the circulating blood. In this case a clot or thrombus can form, blocking the artery, and restricting blood flow to an area of heart muscle causing a myocardial infarction (a heart attack) or unstable angina. In the worst case this may cause cardiac arrest, a sudden and utter loss of output from the heart. Obesity, high blood pressure, uncontrolled diabetes, smoking and high cholesterol can all increase the risk of developing atherosclerosis and coronary artery disease.\nHeart failure.\nHeart failure is defined as a condition in which the heart is unable to pump enough blood to meet the demands of the body. Patients with heart failure may experience breathlessness especially when lying flat, as well as ankle swelling, known as peripheral oedema. Heart failure is the result of many diseases affecting the heart, but is most commonly associated with ischemic heart disease, valvular heart disease, or high blood pressure. Less common causes include various cardiomyopathies. Heart failure is frequently associated with weakness of the heart muscle in the ventricles (systolic heart failure), but can also be seen in patients with heart muscle that is strong but stiff (diastolic heart failure). The condition may affect the left ventricle (causing predominantly breathlessness), the right ventricle (causing predominantly swelling of the legs and an elevated jugular venous pressure), or both ventricles. Patients with heart failure are at higher risk of developing dangerous heart rhythm disturbances or arrhythmias.\nCardiomyopathies.\nCardiomyopathies are diseases affecting the muscle of the heart. Some cause abnormal thickening of the heart muscle (hypertrophic cardiomyopathy), some cause the heart to abnormally expand and weaken (dilated cardiomyopathy), some cause the heart muscle to become stiff and unable to fully relax between contractions (restrictive cardiomyopathy) and some make the heart prone to abnormal heart rhythms (arrhythmogenic cardiomyopathy). These conditions are often genetic and can be inherited, but some such as dilated cardiomyopathy may be caused by damage from toxins such as alcohol. Some cardiomyopathies such as hypertrophic cardiomopathy are linked to a higher risk of sudden cardiac death, particularly in athletes. Many cardiomyopathies can lead to heart failure in the later stages of the disease.\nValvular heart disease.\nHealthy heart valves allow blood to flow easily in one direction, and prevent it from flowing in the other direction. A diseased heart valve may have a narrow opening (stenosis), that restricts the flow of blood in the forward direction. A valve may otherwise be leaky, allowing blood to leak in the reverse direction (regurgitation). Valvular heart disease may cause breathlessness, blackouts, or chest pain, but may be asymptomatic and only detected on a routine examination by hearing abnormal heart sounds or a heart murmur. In the developed world, valvular heart disease is most commonly caused by degeneration secondary to old age, but may also be caused by infection of the heart valves (endocarditis). In some parts of the world rheumatic heart disease is a major cause of valvular heart disease, typically leading to mitral or aortic stenosis and caused by the body's immune system reacting to a streptococcal throat infection.\nCardiac arrhythmias.\nWhile in the healthy heart, waves of electrical impulses originate in the sinus node before spreading to the rest of the atria, the atrioventricular node, and finally the ventricles (referred to as a normal sinus rhythm), this normal rhythm can be disrupted. Abnormal heart rhythms or arrhythmias may be asymptomatic or may cause palpitations, blackouts, or breathlessness. Some types of arrhythmia such as atrial fibrillation increase the long term risk of stroke.\nSome arrhythmias cause the heart to beat abnormally slowly, referred to as a bradycardia or bradyarrhythmia. This may be caused by an abnormally slow sinus node or damage within the cardiac conduction system (heart block). In other arrhythmias the heart may beat abnormally rapidly, referred to as a tachycardia or tachyarrhythmia. These arrhythmias can take many forms and can originate from different structures within the heart\u2014some arise from the atria (e.g. atrial flutter), some from the atrioventricular node (e.g. AV nodal re-entrant tachycardia) whilst others arise from the ventricles (e.g. ventricular tachycardia). Some tachyarrhythmias are caused by scarring within the heart (e.g. some forms of ventricular tachycardia), others by an irritable focus (e.g. focal atrial tachycardia), while others are caused by additional abnormal conduction tissue that has been present since birth (e.g. Wolff-Parkinson-White syndrome). The most dangerous form of heart racing is ventricular fibrillation, in which the ventricles quiver rather than contract, and which if untreated is rapidly fatal.\nPericardial disease.\nThe sac which surrounds the heart, called the pericardium, can become inflamed in a condition known as pericarditis. This condition typically causes chest pain that may spread to the back, and is often caused by a viral infection (glandular fever, cytomegalovirus, or coxsackievirus). Fluid can build up within the pericardial sac, referred to as a pericardial effusion. Pericardial effusions often occur secondary to pericarditis, kidney failure, or tumours, and frequently do not cause any symptoms. However, large effusions or effusions which accumulate rapidly can compress the heart in a condition known as cardiac tamponade, causing breathlessness and potentially fatal low blood pressure. Fluid can be removed from the pericardial space for diagnosis or to relieve tamponade using a syringe in a procedure called pericardiocentesis.\nCongenital heart disease.\nSome people are born with hearts that are abnormal and these abnormalities are known as congenital heart defects. They may range from the relatively minor (e.g. patent foramen ovale, arguably a variant of normal) to serious life-threatening abnormalities (e.g. hypoplastic left heart syndrome). Common abnormalities include those that affect the heart muscle that separates the two side of the heart (a \"hole in the heart\", e.g. ventricular septal defect). Other defects include those affecting the heart valves (e.g. congenital aortic stenosis), or the main blood vessels that lead from the heart (e.g. coarctation of the aorta). More complex syndromes are seen that affect more than one part of the heart (e.g. Tetralogy of Fallot).\nSome congenital heart defects allow blood that is low in oxygen that would normally be returned to the lungs to instead be pumped back to the rest of the body. These are known as cyanotic congenital heart defects and are often more serious. Major congenital heart defects are often picked up in childhood, shortly after birth, or even before a child is born (e.g. transposition of the great arteries), causing breathlessness and a lower rate of growth. More minor forms of congenital heart disease may remain undetected for many years and only reveal themselves in adult life (e.g., atrial septal defect).\nChannelopathies.\nChannelopathies can be categorized based on the organ system they affect. In the cardiovascular system, the electrical impulse required for each heart beat is provided by the electrochemical gradient of each heart cell. Because the beating of the heart depends on the proper movement of ions across the surface membrane, cardiac ion channelopathies form a major group of heart diseases. Cardiac ion channelopathies may explain some of the cases of sudden death syndrome and sudden arrhythmic death syndrome. Long QT syndrome is the most common form of cardiac channelopathy.\nDiagnosis.\nHeart disease is diagnosed by the taking of a medical history, a cardiac examination, and further investigations, including blood tests, echocardiograms, electrocardiograms, and imaging. Other invasive procedures such as cardiac catheterisation can also play a role.\nExamination.\nThe cardiac examination includes inspection, feeling the chest with the hands (palpation) and listening with a stethoscope (auscultation). It involves assessment of signs that may be visible on a person's hands (such as splinter haemorrhages), joints and other areas. A person's pulse is taken, usually at the radial artery near the wrist, in order to assess for the rhythm and strength of the pulse. The blood pressure is taken, using either a manual or automatic sphygmomanometer or using a more invasive measurement from within the artery. Any elevation of the jugular venous pulse is noted. A person's chest is felt for any transmitted vibrations from the heart, and then listened to with a stethoscope.\nHeart sounds.\nTypically, healthy hearts have only two audible heart sounds, called S1 and S2. The first heart sound S1, is the sound created by the closing of the atrioventricular valves during ventricular contraction and is normally described as \"lub\". The second heart sound, S2, is the sound of the semilunar valves closing during ventricular diastole and is described as \"dub\". Each sound consists of two components, reflecting the slight difference in time as the two valves close. S2 may split into two distinct sounds, either as a result of inspiration or different valvular or cardiac problems. Additional heart sounds may also be present and these give rise to gallop rhythms. A third heart sound, S3 usually indicates an increase in ventricular blood volume. A fourth heart sound S4 is referred to as an atrial gallop and is produced by the sound of blood being forced into a stiff ventricle. The combined presence of S3 and S4 give a quadruple gallop.\nHeart murmurs are abnormal heart sounds which can be either related to disease or benign, and there are several kinds. There are normally two heart sounds, and abnormal heart sounds can either be extra sounds, or \"murmurs\" related to the flow of blood between the sounds. Murmurs are graded by volume, from 1 (the quietest), to 6 (the loudest), and evaluated by their relationship to the heart sounds, position in the cardiac cycle, and additional features such as their radiation to other sites, changes with a person's position, the frequency of the sound as determined by the side of the stethoscope by which they are heard, and site at which they are heard loudest. Murmurs may be caused by damaged heart valves or congenital heart disease such as ventricular septal defects, or may be heard in normal hearts. A different type of sound, a pericardial friction rub can be heard in cases of pericarditis where the inflamed membranes can rub together.\nBlood tests.\nBlood tests play an important role in the diagnosis and treatment of many cardiovascular conditions.\nTroponin is a sensitive biomarker for a heart with insufficient blood supply. It is released 4\u20136 hours after injury and usually peaks at about 12\u201324 hours. Two tests of troponin are often taken\u2014one at the time of initial presentation and another within 3\u20136 hours, with either a high level or a significant rise being diagnostic. A test for brain natriuretic peptide (BNP) can be used to evaluate for the presence of heart failure, and rises when there is increased demand on the left ventricle. These tests are considered biomarkers because they are highly specific for cardiac disease. Testing for the MB form of creatine kinase provides information about the heart's blood supply, but is used less frequently because it is less specific and sensitive.\nOther blood tests are often taken to help understand a person's general health and risk factors that may contribute to heart disease. These often include a full blood count investigating for anaemia, and basic metabolic panel that may reveal any disturbances in electrolytes. A coagulation screen is often required to ensure that the right level of anticoagulation is given. Fasting lipids and fasting blood glucose (or an HbA1c level) are often ordered to evaluate a person's cholesterol and diabetes status, respectively.\nElectrocardiogram.\nUsing surface electrodes on the body, it is possible to record the electrical activity of the heart. This tracing of the electrical signal is the electrocardiogram (ECG) or (EKG). An ECG is a bedside test and involves the placement of ten leads on the body. This produces a \"12 lead\" ECG (three extra leads are calculated mathematically, and one lead is electrically ground, or earthed).\nThere are five prominent features on the ECG: the P wave (atrial depolarisation), the QRS complex (ventricular depolarisation) and the T wave (ventricular repolarisation). As the heart cells contract, they create a current that travels through the heart. A downward deflection on the ECG implies cells are becoming more positive in charge (\"depolarising\") in the direction of that lead, whereas an upward inflection implies cells are becoming more negative (\"repolarising\") in the direction of the lead. This depends on the position of the lead, so if a wave of depolarising moved from left to right, a lead on the left would show a negative deflection, and a lead on the right would show a positive deflection. The ECG is a useful tool in detecting rhythm disturbances and in detecting insufficient blood supply to the heart. Sometimes abnormalities are suspected, but not immediately visible on the ECG. Testing when exercising can be used to provoke an abnormality or an ECG can be worn for a longer period such as a 24-hour Holter monitor if a suspected rhythm abnormality is not present at the time of assessment.\nImaging.\nSeveral imaging methods can be used to assess the anatomy and function of the heart, including ultrasound (echocardiography), angiography, CT, MRI, and PET, scans. An echocardiogram is an ultrasound of the heart used to measure the heart's function, assess for valve disease, and look for any abnormalities. Echocardiography can be conducted by a probe on the chest (transthoracic), or by a probe in the esophagus (transesophageal). A typical echocardiography report will include information about the width of the valves noting any stenosis, whether there is any backflow of blood (regurgitation) and information about the blood volumes at the end of systole and diastole, including an ejection fraction, which describes how much blood is ejected from the left and right ventricles after systole. Ejection fraction can then be obtained by dividing the volume ejected by the heart (stroke volume) by the volume of the filled heart (end-diastolic volume). Echocardiograms can also be conducted under circumstances when the body is more stressed, in order to examine for signs of lack of blood supply. This cardiac stress test involves either direct exercise, or where this is not possible, injection of a drug such as dobutamine.\nCT scans, chest X-rays and other forms of imaging can help evaluate the heart's size, evaluate for signs of pulmonary oedema, and indicate whether there is fluid around the heart. They are also useful for evaluating the aorta, the major blood vessel which leaves the heart.\nTreatment.\nDiseases affecting the heart can be treated by a variety of methods including lifestyle modification, drug treatment, and surgery.\nIschemic heart disease.\nNarrowings of the coronary arteries (ischemic heart disease) are treated to relieve symptoms of chest pain caused by a partially narrowed artery (angina pectoris), to minimise heart muscle damage when an artery is completely occluded (myocardial infarction), or to prevent a myocardial infarction from occurring. Medications to improve angina symptoms include nitroglycerin, beta blockers, and calcium channel blockers, while preventative treatments include antiplatelets such as aspirin and statins, lifestyle measures such as stopping smoking and weight loss, and treatment of risk factors such as high blood pressure and diabetes.\nIn addition to using medications, narrowed heart arteries can be treated by expanding the narrowings or redirecting the flow of blood to bypass an obstruction. This may be performed using a percutaneous coronary intervention, during which narrowings can be expanded by passing small balloon-tipped wires into the coronary arteries, inflating the balloon to expand the narrowing, and sometimes leaving behind a metal scaffold known as a stent to keep the artery open.\nIf the narrowings in coronary arteries are unsuitable for treatment with a percutaneous coronary intervention, open surgery may be required. A coronary artery bypass graft can be performed, whereby a blood vessel from another part of the body (the saphenous vein, radial artery, or internal mammary artery) is used to redirect blood from a point before the narrowing (typically the aorta) to a point beyond the obstruction.\nValvular heart disease.\nDiseased heart valves that have become abnormally narrow or abnormally leaky may require surgery. This is traditionally performed as an open surgical procedure to replace the damaged heart valve with a tissue or metallic prosthetic valve. In some circumstances, the tricuspid or mitral valves can be repaired surgically, avoiding the need for a valve replacement. Heart valves can also be treated percutaneously, using techniques that share many similarities with percutaneous coronary intervention. Transcatheter aortic valve replacement is increasingly used for patients consider very high risk for open valve replacement.\nCardiac arrhythmias.\nAbnormal heart rhythms (arrhythmias) can be treated using antiarrhythmic drugs. These may work by manipulating the flow of electrolytes across the cell membrane (such as calcium channel blockers, sodium channel blockers, amiodarone, or digoxin), or modify the autonomic nervous system's effect on the heart (beta blockers and atropine). In some arrhythmias such as atrial fibrillation which increase the risk of stroke, this risk can be reduced using anticoagulants such as warfarin or novel oral anticoagulants.\nIf medications fail to control an arrhythmia, another treatment option may be catheter ablation. In these procedures, wires are passed from a vein or artery in the leg to the heart to find the abnormal area of tissue that is causing the arrhythmia. The abnormal tissue can be intentionally damaged, or ablated, by heating or freezing to prevent further heart rhythm disturbances. Whilst the majority of arrhythmias can be treated using minimally invasive catheter techniques, some arrhythmias (particularly atrial fibrillation) can also be treated using open or thoracoscopic surgery, either at the time of other cardiac surgery or as a standalone procedure. A cardioversion, whereby an electric shock is used to stun the heart out of an abnormal rhythm, may also be used.\nCardiac devices in the form of pacemakers or implantable defibrillators may also be required to treat arrhythmias. Pacemakers, comprising a small battery powered generator implanted under the skin and one or more leads that extend to the heart, are most commonly used to treat abnormally slow heart rhythms. Implantable defibrillators are used to treat serious life-threatening rapid heart rhythms. These devices monitor the heart, and if dangerous heart racing is detected can automatically deliver a shock to restore the heart to a normal rhythm. Implantable defibrillators are most commonly used in patients with heart failure, cardiomyopathies, or inherited arrhythmia syndromes.\nHeart failure.\nAs well as addressing the underlying cause for a patient's heart failure (most commonly ischemic heart disease or hypertension), the mainstay of heart failure treatment is with medication. These include drugs to prevent fluid from accumulating in the lungs by increasing the amount of urine a patient produces (diuretics), and drugs that attempt to preserve the pumping function of the heart (beta blockers, ACE inhibitors and mineralocorticoid receptor antagonists).\nIn some patients with heart failure, a specialised pacemaker known as cardiac resynchronisation therapy can be used to improve the heart's pumping efficiency. These devices are frequently combined with a defibrillator. In very severe cases of heart failure, a small pump called a ventricular assist device may be implanted which supplements the heart's own pumping ability. In the most severe cases, a cardiac transplant may be considered.\nHistory.\nAncient.\nHumans have known about the heart since ancient times, although its precise function and anatomy were not clearly understood. From the primarily religious views of earlier societies towards the heart, ancient Greeks are considered to have been the primary seat of scientific understanding of the heart in the ancient world. Aristotle considered the heart to be the organ responsible for creating blood; Plato considered the heart as the source of circulating blood and Hippocrates noted blood circulating cyclically from the body through the heart to the lungs. Erasistratos (304\u2013250 BCE) noted the heart as a pump, causing dilation of blood vessels, and noted that arteries and veins both radiate from the heart, becoming progressively smaller with distance, although he believed they were filled with air and not blood. He also discovered the heart valves.\nThe Greek physician Galen (2nd century CE) knew blood vessels carried blood and identified venous (dark red) and arterial (brighter and thinner) blood, each with distinct and separate functions. Galen, noting the heart as the hottest organ in the body, concluded that it provided heat to the body. The heart did not pump blood around, the heart's motion sucked blood in during diastole and the blood moved by the pulsation of the arteries themselves. Galen believed the arterial blood was created by venous blood passing from the left ventricle to the right through 'pores' between the ventricles. Air from the lungs passed from the lungs via the pulmonary artery to the left side of the heart and created arterial blood.\nThese ideas went unchallenged for almost a thousand years.\nPre-modern.\nThe earliest descriptions of the coronary and pulmonary circulation systems can be found in the \"Commentary on Anatomy in Avicenna's Canon\", published in 1242 by Ibn al-Nafis. In his manuscript, al-Nafis wrote that blood passes through the pulmonary circulation instead of moving from the right to the left ventricle as previously believed by Galen. His work was later translated into Latin by Andrea Alpago.\nIn Europe, the teachings of Galen continued to dominate the academic community and his doctrines were adopted as the official canon of the Church. Andreas Vesalius questioned some of Galen's beliefs of the heart in \"De humani corporis fabrica\" (1543), but his magnum opus was interpreted as a challenge to the authorities and he was subjected to a number of attacks. Michael Servetus wrote in \"Christianismi Restitutio\" (1553) that blood flows from one side of the heart to the other via the lungs.\nModern.\nA breakthrough in understanding the flow of blood through the heart and body came with the publication of \"De Motu Cordis\" (1628) by the English physician William Harvey. Harvey's book completely describes the systemic circulation and the mechanical force of the heart, leading to an overhaul of the Galenic doctrines. Otto Frank (1865\u20131944) was a German physiologist; among his many published works are detailed studies of this important heart relationship. Ernest Starling (1866\u20131927) was an important English physiologist who also studied the heart. Although they worked largely independently, their combined efforts and similar conclusions have been recognized in the name \"Frank\u2013Starling mechanism\".\nAlthough Purkinje fibers and the bundle of His were discovered as early as the 19th century, their specific role in the electrical conduction system of the heart remained unknown until Sunao Tawara published his monograph, titled \"Das Reizleitungssystem des S\u00e4ugetierherzens\", in 1906. Tawara's discovery of the atrioventricular node prompted Arthur Keith and Martin Flack to look for similar structures in the heart, leading to their discovery of the sinoatrial node several months later. These structures form the anatomical basis of the electrocardiogram, whose inventor, Willem Einthoven, was awarded the Nobel Prize in Medicine or Physiology in 1924.\nThe first heart transplant in a human ever performed was by James Hardy in 1964, using a chimpanzee heart, but the patient died within 2 hours. The first human to human heart transplantation was performed in 1967 by the South African surgeon Christiaan Barnard at Groote Schuur Hospital in Cape Town. This marked an important milestone in cardiac surgery, capturing the attention of both the medical profession and the world at large. However, long-term survival rates of patients were initially very low. Louis Washkansky, the first recipient of a donated heart, died 18 days after the operation while other patients did not survive for more than a few weeks. The American surgeon Norman Shumway has been credited for his efforts to improve transplantation techniques, along with pioneers Richard Lower, Vladimir Demikhov and Adrian Kantrowitz. As of March 2000, more than 55,000 heart transplantations have been performed worldwide. The first successful transplant of a heart from a genetically modified pig to a human in which the patient lived for a longer time, was performed January 7, 2022 in Baltimore by heart surgeon Bartley P. Griffith, recipient was David Bennett (57) this successfully extended his life until 8 March 2022 (1 month and 30 days).\nBy the middle of the 20th century, heart disease had surpassed infectious disease as the leading cause of death in the United States, and it is currently the leading cause of deaths worldwide. Since 1948, the ongoing Framingham Heart Study has shed light on the effects of various influences on the heart, including diet, exercise, and common medications such as aspirin. Although the introduction of ACE inhibitors and beta blockers has improved the management of chronic heart failure, the disease continues to be an enormous medical and societal burden, with 30 to 40% of patients dying within a year of receiving the diagnosis.\nSociety and culture.\nSymbolism.\nAs one of the vital organs, the heart was long identified as the center of the entire body, the seat of life, or emotion, or reason, will, intellect, purpose or the mind. The heart is an emblematic symbol in many religions, signifying \"truth, conscience or moral courage in many religions\u2014the temple or throne of God in Islamic and Judeo-Christian thought; the divine centre, or atman, and the third eye of transcendent wisdom in Hinduism; the diamond of purity and essence of the Buddha; the Taoist centre of understanding.\"\nIn the Hebrew Bible, the word for heart, \"lev\", is used in these meanings, as the seat of emotion, the mind, and referring to the anatomical organ. It is also connected in function and symbolism to the stomach.\nAn important part of the concept of the soul in Ancient Egyptian religion was thought to be the heart, or \"ib\". The \"ib\" or metaphysical heart was believed to be formed from one drop of blood from the child's mother's heart, taken at conception. To ancient Egyptians, the heart was the seat of emotion, thought, will, and intention. This is evidenced by Egyptian expressions which incorporate the word \"ib\", such as \"Awi-ib\" for \"happy\" (literally, \"long of heart\"), \"Xak-ib\" for \"estranged\" (literally, \"truncated of heart\"). In Egyptian religion, the heart was the key to the afterlife. It was conceived as surviving death in the nether world, where it gave evidence for, or against, its possessor. The heart was therefore not removed from the body during mummification, and was believed to be the center of intelligence and feeling, and needed in the afterlife. It was thought that the heart was examined by Anubis and a variety of deities during the \"Weighing of the Heart\" ceremony. If the heart weighed more than the feather of Maat, which symbolized the ideal standard of behavior. If the scales balanced, it meant the heart's possessor had lived a just life and could enter the afterlife; if the heart was heavier, it would be devoured by the monster Ammit.\nThe Chinese character for \"heart\", \u5fc3, derives from a comparatively realistic depiction of a heart (indicating the heart chambers) in seal script. The Chinese word \"x\u012bn\" also takes the metaphorical meanings of \"mind\", \"intention\", or \"core\", and is often translated as \"heart-mind\" as the ancient Chinese believed the heart was the center of human cognition. In Chinese medicine, the heart is seen as the center of \u795e \"sh\u00e9n\" \"spirit, consciousness\". The heart is associated with the small intestine, tongue, governs the six organs and five viscera, and belongs to fire in the five elements.\nThe Sanskrit word for heart is \"h\u1e5bd\" or \"h\u1e5bdaya\", found in the oldest surviving Sanskrit text, the Rigveda. In Sanskrit, it may mean both the anatomical object and \"mind\" or \"soul\", representing the seat of emotion. \"Hrd\" may be a cognate of the word for heart in Greek, Latin, and English.\nMany classical philosophers and scientists, including Aristotle, considered the heart the seat of thought, reason, or emotion, often disregarding the brain as contributing to those functions. The identification of the heart as the seat of emotions in particular is due to the Roman physician Galen, who also located the seat of the passions in the liver, and the seat of reason in the brain.\nThe heart also played a role in the Aztec system of belief. The most common form of human sacrifice practiced by the Aztecs was heart-extraction. The Aztec believed that the heart (\"tona\") was both the seat of the individual and a fragment of the Sun's heat (\"istli\"). To this day, the Nahua consider the Sun to be a heart-soul (\"tona-tiuh\"): \"round, hot, pulsating\".\nIndigenous leaders from Alaska to Australia came together in 2020 to deliver a message to the world that humanity needs to shift from the mind to the heart, and let our heart be in charge of what we do. The message was made into a film, which highlighted that humanity must open their hearts to restore balance to the world. Kumu Sabra Kauka, a Hawaiian studies educator and tradition bearer summed up the message of the film saying \"Listen to your heart. Follow your path. May it be clear, and for the good of all.\" The film was led by Illarion Merculieff from the Aleut (Unangan) tribe. Merculieff has written that Unangan Elders referred to the heart as a \"source of wisdom\", \"a deeper portal of profound interconnectedness and awareness that exists between humans and all living things\".\nIn Catholicism, there has been a long tradition of veneration of the heart, stemming from worship of the wounds of Jesus Christ which gained prominence from the mid sixteenth century. This tradition influenced the development of the medieval Christian devotion to the Sacred Heart of Jesus and the parallel veneration of the Immaculate Heart of Mary, made popular by John Eudes. There are also many references to the heart in the Christian Bible, including \"Blessed are the pure in heart, for they will see God\", \"Above all else, guard your heart, for everything you do flows from it\", \"For where your treasure is, there your heart will be also\", \"For as a man thinks in his heart, so shall he be.\"\nThe expression of a broken heart is a cross-cultural reference to grief for a lost one or to unfulfilled romantic love.\nThe notion of \"Cupid's arrows\" is ancient, due to Ovid, but while Ovid describes Cupid as wounding his victims with his arrows, it is not made explicit that it is the \"heart\" that is wounded. The familiar iconography of Cupid shooting little heart symbols is a Renaissance theme that became tied to Valentine's Day.\nIn certain Trans-New Guinea languages, such as Foi and Momoona, the heart and seat of emotions are colexified, meaning they share the same word.\nCuisine.\nAnimal hearts are widely consumed as a type of offal. As they are almost entirely muscle, they are high in protein. They are often included in dishes with other internal organs, for example in the pan-Ottoman kokoretsi.\nChicken hearts are considered to be giblets, and are often grilled on skewers; examples of this are Japanese \"h\u0101to yakitori\", Brazilian \"churrasco de cora\u00e7\u00e3o\", and Indonesian chicken heart satay. They can also be pan-fried, as in Jerusalem mixed grill. In Egyptian cuisine, they can be used, finely chopped, as part of stuffing for chicken. Many recipes combined them with other giblets, such as the Mexican \"pollo en menudencias\" and the Russian \"ragu iz kurinyikh potrokhov\".\nThe hearts of beef, pork, and mutton can generally be interchanged in recipes. As heart is a hard-working muscle, it makes for \"firm and rather dry\" meat, so is generally slow-cooked. Another way of dealing with toughness is to julienne the meat, as in Chinese stir-fried heart.\nBeef heart is valued for its high meat quality and low price, being commonly disregarded in conventional meat pricing. It can be cut into steaks, comparable in quality to the more expensive cuts of meat from the same animal, though it is distinguished by a lack of a discernible grain. It was historically eaten in the United States as a cost-saving measure, but is today also eaten as an independently desirable ingredient. Beef heart may be grilled or braised. In the Peruvian \"anticuchos de coraz\u00f3n\", barbecued beef hearts are grilled after being tenderized through long marination in a spice and vinegar mixture. An Australian recipe for \"mock goose\" is actually braised stuffed beef heart.\nPork heart can be stewed, poached, braised, or made into sausage. The Balinese \"oret\" is a sort of blood sausage made with pig heart and blood. A French recipe for \"c\u0153ur de porc \u00e0 l'orange\" is made of braised heart with an orange sauce.\nOther animals.\nVertebrates.\nThe size of the heart varies among the different animal groups, with hearts in vertebrates ranging from those of the smallest mice (12\u00a0mg) to the blue whale (600\u00a0kg). In vertebrates, the heart lies in the middle of the ventral part of the body, surrounded by a pericardium. which in some fish may be connected to the peritoneum. In all vertebrates, the heart has an asymmetric orientation, almost always on the left side. According to one theory, this is caused by a developmental axial twist in the early embryo.\nThe sinoatrial node is found in all amniotes but not in more primitive vertebrates. In these animals, the muscles of the heart are relatively continuous, and the sinus venosus coordinates the beat, which passes in a wave through the remaining chambers. Since the sinus venosus is incorporated into the right atrium in amniotes, it is likely homologous with the SA node. In teleosts, with their vestigial sinus venosus, the main centre of coordination is, instead, in the atrium. The rate of heartbeat varies enormously between different species, ranging from around 20 beats per minute in codfish to around 600 in hummingbirds and up to 1,200 bpm in the ruby-throated hummingbird.\nDouble circulatory systems.\nAdult amphibians and most reptiles have a double circulatory system, meaning a circulatory system divided into arterial and venous parts. However, the heart itself is not completely separated into two sides. Instead, it is separated into three chambers\u2014two atria and one ventricle. Blood returning from both the systemic circulation and the lungs is returned, and blood is pumped simultaneously into the systemic circulation and the lungs. The double system allows blood to circulate to and from the lungs which deliver oxygenated blood directly to the heart.\nIn reptiles, other than snakes, the heart is usually situated around the middle of the thorax. In terrestrial and arboreal snakes, it is usually located nearer to the head; in aquatic species the heart is more centrally located. There is a heart with three chambers: two atria and one ventricle. The form and function of these hearts are different from mammalian hearts due to the fact that snakes have an elongated body, and thus are affected by different environmental factors. In particular, the snake's heart relative to the position in their body has been influenced greatly by gravity. Therefore, snakes that are larger in size tend to have a higher blood pressure due to gravitational change. The ventricle is incompletely separated into two-halves by a wall (septum), with a considerable gap near the pulmonary artery and aortic openings. In most reptilian species, there appears to be little, if any, mixing between the bloodstreams, so the aorta receives, essentially, only oxygenated blood. The exception to this rule is crocodiles, which have a four-chambered heart.\nIn the heart of lungfish, the septum extends partway into the ventricle. This allows for some degree of separation between the de-oxygenated bloodstream destined for the lungs and the oxygenated stream that is delivered to the rest of the body. The absence of such a division in living amphibian species may be partly due to the amount of respiration that occurs through the skin; thus, the blood returned to the heart through the venae cavae is already partially oxygenated. As a result, there may be less need for a finer division between the two bloodstreams than in lungfish or other tetrapods. Nonetheless, in at least some species of amphibian, the spongy nature of the ventricle does seem to maintain more of a separation between the bloodstreams. Also, the original valves of the conus arteriosus have been replaced by a spiral valve that divides it into two parallel parts, thereby helping to keep the two bloodstreams separate.\nFull division.\nArchosaurs (crocodilians and birds) and mammals show complete separation of the heart into two pumps for a total of four heart chambers; it is thought that the four-chambered heart of archosaurs evolved independently from that of mammals. In crocodilians, there is a small opening, the foramen of Panizza, at the base of the arterial trunks and there is some degree of mixing between the blood in each side of the heart, during a dive underwater; thus, only in birds and mammals are the two streams of blood\u2014those to the pulmonary and systemic circulations\u2014permanently kept entirely separate by a physical barrier.\nFish.\nThe heart evolved no less than 380\u00a0million years ago in fish. Fish have what is often described as a two-chambered heart, consisting of one atrium to receive blood and one ventricle to pump it. However, the fish heart has entry and exit compartments that may be called chambers, so it is also sometimes described as three-chambered or four-chambered, depending on what is counted as a chamber. The atrium and ventricle are sometimes considered \"true chambers\", while the others are considered \"accessory chambers\".\nPrimitive fish have a four-chambered heart, but the chambers are arranged sequentially so that this primitive heart is quite unlike the four-chambered hearts of mammals and birds. The first chamber is the sinus venosus, which collects deoxygenated blood from the body through the hepatic and cardinal veins. From here, blood flows into the atrium and then to the powerful muscular ventricle where the main pumping action will take place. The fourth and final chamber is the conus arteriosus, which contains several valves and sends blood to the \"ventral aorta\". The ventral aorta delivers blood to the gills where it is oxygenated and flows, through the dorsal aorta, into the rest of the body. (In tetrapods, the ventral aorta has divided in two; one half forms the ascending aorta, while the other forms the pulmonary artery).\nIn the adult fish, the four chambers are not arranged in a straight row but instead form an S-shape, with the latter two chambers lying above the former two. This relatively simple pattern is found in cartilaginous fish and in the ray-finned fish. In teleosts, the conus arteriosus is very small and can more accurately be described as part of the aorta rather than of the heart proper. The conus arteriosus is not present in any amniotes, presumably having been absorbed into the ventricles over the course of evolution. Similarly, while the sinus venosus is present as a vestigial structure in some reptiles and birds, it is otherwise absorbed into the right atrium and is no longer distinguishable.\nInvertebrates.\nArthropods and most mollusks have an open circulatory system. In this system, deoxygenated blood collects around the heart in cavities (sinuses). This blood slowly permeates the heart through many small one-way channels. The heart then pumps the blood into the hemocoel, a cavity between the organs. The heart in arthropods is typically a muscular tube that runs the length of the body, under the back and from the base of the head. Instead of blood the circulatory fluid is haemolymph which carries the most commonly used respiratory pigment, copper-based haemocyanin as the oxygen transporter. Haemoglobin is only used by a few arthropods.\nIn some other invertebrates such as earthworms, the circulatory system is not used to transport oxygen and so is much reduced, having no veins or arteries and consisting of two connected tubes. Oxygen travels by diffusion and there are five small muscular vessels that connect these vessels that contract at the front of the animals that can be thought of as \"hearts\".\nSquids and other cephalopods have two \"gill hearts\" also known as branchial hearts, and one \"systemic heart\". The branchial hearts have two atria and one ventricle each, and pump to the gills, whereas the systemic heart pumps to the body.\nOnly the chordates (including vertebrates) and the hemichordates have a central \"heart\", which is a vesicle formed from the thickening of the aorta and contracts to pump blood. This suggests a presence of it in the last common ancestor of these groups (may have been lost in the echinoderms).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n\"This article incorporates text from the CC BY book: http://\"\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36811", "revid": "3932984", "url": "https://en.wikipedia.org/wiki?curid=36811", "title": "Subset sum problem", "text": "Decision problem in computer science\nThe subset sum problem (SSP) is a decision problem in computer science. In its most general formulation, there is a multiset formula_1 of integers and a target-sum formula_2, and the question is to decide whether any subset of the integers sum to precisely formula_2\".\" The problem is known to be NP-complete. Moreover, some restricted variants of it are NP-complete too, for example:\nSSP can also be regarded as an optimization problem: find a subset whose sum is at most \"T\", and subject to that, as close as possible to \"T\". It is NP-hard, but there are several algorithms that can solve it reasonably quickly in practice.\nSSP is a special case of the knapsack problem and of the multiple subset sum problem.\nComputational hardness.\nThe run-time complexity of SSP depends on two parameters: \nAs both \"n\" and \"L\" grow large, SSP is NP-hard. The complexity of the best known algorithms is exponential in the smaller of the two parameters \"n\" and \"L\". The problem is NP-hard even when all input integers are positive (and the target-sum \"T\" is a part of the input). This can be proved by a direct reduction from 3SAT. It can also be proved by reduction from 3-dimensional matching (3DM):\nThe following variants are also known to be NP-hard:\nThe analogous counting problem #SSP, which asks to enumerate the number of subsets summing to the target, is #P-complete.\nExponential time algorithms.\nThere are several ways to solve SSP in time exponential in \"n\".\nInclusion\u2013exclusion.\nThe most na\u00efve algorithm would be to cycle through all subsets of \"n\" numbers and, for every one of them, check if the subset sums to the right number. The running time is of order formula_8, since there are formula_9 subsets and, to check each subset, we need to sum at most \"n\" elements.\nThe algorithm can be implemented by depth-first search of a binary tree: each level in the tree corresponds to an input number; the left branch corresponds to excluding the number from the set, and the right branch corresponds to including the number (hence the name Inclusion-Exclusion). The memory required is formula_10. The run-time can be improved by several heuristics:\nHorowitz and Sahni.\nIn 1974, Horowitz and Sahni published a faster exponential-time algorithm, which runs in time formula_11, but requires much more space - formula_12. The algorithm splits arbitrarily the \"n\" elements into two sets of formula_13 each. For each of these two sets, it stores a list of the sums of all formula_14 possible subsets of its elements. Each of these two lists is then sorted. Using even the fastest comparison sorting algorithm, Mergesort for this step would take time formula_15. However, given a sorted list of sums for formula_16 elements, the list can be expanded to two sorted lists with the introduction of a (formula_17)th element, and these two sorted lists can be merged in time formula_18. Thus, each list can be generated in sorted form in time formula_19. Given the two sorted lists, the algorithm can check if an element of the first array and an element of the second array sum up to \"T\" in time formula_19. To do that, the algorithm passes through the first array in decreasing order (starting at the largest element) and the second array in increasing order (starting at the smallest element). Whenever the sum of the current element in the first array and the current element in the second array is more than \"T\", the algorithm moves to the next element in the first array. If it is less than \"T\", the algorithm moves to the next element in the second array. If two elements that sum to \"T\" are found, it stops. (The sub-problem for two elements sum is known as two-sum.)\nSchroeppel and Shamir.\nIn 1981, Schroeppel and Shamir presented an algorithm based on Horowitz and Sanhi, that requires similar runtime - formula_21, much less space - formula_22. Rather than generating and storing all subsets of \"n\"/2 elements in advance, they partition the elements into 4 sets of \"n\"/4 elements each, and generate subsets of \"n\"/2 element pairs dynamically using a min heap, which yields the above time and space complexities since this can be done in formula_23 and space formula_24 given 4 lists of length k.\nDue to space requirements, the HS algorithm is practical for up to about 50 integers, and the SS algorithm is practical for up to 100 integers.\nHowgrave-Graham and Joux.\nIn 2010, Howgrave-Graham and Joux presented a probabilistic algorithm that runs faster than all previous ones - in time formula_25 using space formula_26. It solves only the decision problem, cannot prove there is no solution for a given sum, and does not return the subset sum closest to \"T\".\nThe techniques of Howgrave-Graham and Joux were subsequently extended bringing the time complexity to formula_27. A more recent generalization lowered the time complexity to formula_28.\nPseudo-polynomial time dynamic programming solutions.\nSSP can be solved in pseudo-polynomial time using dynamic programming. Suppose we have the following sequence of elements in an instance:\nformula_29\nWe define a \"state\" as a pair (\"i\", \"s\") of integers. This state represents the fact that\n\"there is a nonempty subset of formula_30 which sums to s.\"\nEach state (\"i\", \"s\") has two next states:\nStarting from the initial state (0, 0), it is possible to use any graph search algorithm (e.g. BFS) to search the state (\"N\", \"T\"). If the state is found, then by backtracking we can find a subset with a sum of exactly \"T\".\nThe run-time of this algorithm is at most linear in the number of states. The number of states is at most \"N\" times the number of different possible sums. Let A be the sum of the negative values and B the sum of the positive values; the number of different possible sums is at most \"B\"-\"A\", so the total runtime is in formula_34. For example, if all input values are positive and bounded by some constant \"C\", then \"B\" is at most \"N C\", so the time required is formula_35.\nThis solution does not count as polynomial time in complexity theory because formula_36 is not polynomial in the \"size\" of the problem, which is the number of bits used to represent it. This algorithm is polynomial in the values of A and B, which are exponential in their numbers of bits. However, Subset Sum encoded in \"unary\" is in P, since then the size of the encoding is linear in B-A. Hence, Subset Sum is only \"weakly\" NP-Complete.\nFor the case that each formula_37 is positive and bounded by a fixed constant C, in 1999, Pisinger found a linear time algorithm having time complexity formula_38 (note that this is for the version of the problem where the target sum is not necessarily zero, as otherwise the problem would be trivial). In 2015, Koiliaris and Xu found a deterministic formula_39 algorithm for the subset sum problem where T is the sum we need to find. In 2017, Bringmann found a randomized formula_40 time algorithm.\nIn 2014, Curtis and Sanches found a simple recursion highly scalable in SIMD machines having formula_41 time and formula_42 space, where p is the number of processing elements, formula_43 and formula_44 is the lowest integer. This is the best theoretical parallel complexity known so far.\nA comparison of practical results and the solution of hard instances of the SSP is discussed by Curtis and Sanches.\nPolynomial time approximation algorithms.\nSuppose all inputs are positive. An approximation algorithm to SSP aims to find a subset of \"S\" with a sum of at most \"T\" and at least \"r\" times the optimal sum, where \"r\" is a number in (0,1) called the \"approximation ratio\".\nSimple 1/2-approximation.\nThe following very simple algorithm has an approximation ratio of 1/2:\nWhen this algorithm terminates, either all inputs are in the subset (which is obviously optimal), or there is an input that does not fit. The first such input is smaller than all previous inputs that are in the subset and the sum of inputs in the subset is more than \"T\"/2 otherwise the input also is less than T/2 and it would fit in the set. Such a sum greater than T/2 is obviously more than OPT/2.\nFully-polynomial time approximation scheme.\nThe following algorithm attains, for every formula_45, an approximation ratio of formula_46. Its run time is polynomial in n and formula_47. Recall that \"n\" is the number of inputs and \"T\" is the upper bound to the subset sum.\n initialize a list \"L\" to contain one element 0.\n for each \"i\" from 1 to \"n\" do\n let \"Ui\" be a list containing all elements \"y\" in \"L\", and all sums \"xi\" + \"y\" for all \"y\" in \"L\".\n sort \"Ui\" in ascending order\n make \"L\" empty \n let \"y\" be the smallest element of \"Ui\"\n add \"y\" to \"L\"\n for each element \"z\" of \"Ui\" in increasing order do\n // Trim the list by eliminating numbers close to one another\n // and throw out elements greater than the target sum \"T\".\n if \"y\" + \"\u03b5 T\"/\"n\" &lt; \"z\" \u2264 \"T\" then\n \"y\" = \"z\"\n add \"z\" to \"L\"\n return the largest element in \"L.\"\nNote that without the trimming step (the inner \"for each\" loop), the list \"L\" would contain the sums of all formula_9 subsets of inputs. The trimming step does two things:\nThese properties together guarantee that the list L contains no more than formula_50 elements; therefore the run-time is polynomial in formula_50.\nWhen the algorithm ends, if the optimal sum is in L, then it is returned and we are done. Otherwise, it must have been removed in a previous trimming step. Each trimming step introduces an additive error of at most formula_49, so n steps together introduce an error of at most formula_53. Therefore, the returned solution is at least formula_54 which is at least formula_55 .\nThe above algorithm provides an \"exact\" solution to SSP in the case that the input numbers are small (and non-negative). If any sum of the numbers can be specified with at most P bits, then solving the problem approximately with formula_56 is equivalent to solving it exactly. Then, the polynomial time algorithm for approximate subset sum becomes an exact algorithm with running time polynomial in n and formula_57 (i.e., exponential in P).\nKellerer, Mansini, Pferschy and Speranza and Kellerer, Pferschy and Pisinger present other FPTASes for subset sum.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36812", "revid": "50527836", "url": "https://en.wikipedia.org/wiki?curid=36812", "title": "Pericles", "text": "Athenian statesman, orator and general (c.495\u2013429 BC)\nPericles (; ; c.\u2009495\u2013429 BC) was a Greek statesman and general during the Golden Age of Athens. He was prominent and influential in Ancient Athenian politics, particularly between the Greco-Persian Wars and the Peloponnesian War, and was acclaimed by Thucydides, a contemporary historian, as \"the first citizen of Athens\". Pericles turned the Delian League into an Athenian empire and led his countrymen during the first two years of the Peloponnesian War. The period during which he led Athens as its preeminent orator and statesman, roughly from 461 to 429 BC, is sometimes known as the \"Age of Pericles\", but the period thus denoted can include times as early as the Persian Wars or as late as the following century.\nPericles promoted the arts and literature, and it was principally through his efforts that Athens acquired the reputation of being the educational and cultural center of the ancient Greek world. He started an ambitious project that generated most of the surviving structures on the Acropolis, including the Parthenon. This project beautified and protected the city, exhibited its glory, and gave work to its people. Pericles also fostered Athenian democracy to such an extent that critics called him a populist. Pericles was descended, through his mother, from the powerful and historically influential Alcmaeonid family. He, along with several members of his family, succumbed to the Plague of Athens in 429 BC, which weakened the city-state during a protracted conflict with Sparta.\nEarly years.\nPericles was born c.\u2009495 BC, in Athens, Greece. He was the son of the politician Xanthippus, who, though ostracized in 485\u2013484 BC, returned to Athens to command the Athenian contingent in the Greek victory at Mycale just five years later. Pericles's mother, Agariste, was a member of the powerful and controversial noble family of the Alcmaeonidae, and her familial connections played a crucial role in helping start his political career. Agariste was the great-granddaughter of the tyrant of Sicyon, Cleisthenes, and the niece of the Athenian reformer Cleisthenes. Pericles belonged to the Attic \"phyle\" (clan) of Acamantis. His early years were quiet; the introverted young Pericles avoided public appearances, instead preferring to devote his time to his studies.\nAccording to Herodotus and Plutarch, Agariste dreamed, a few nights before Pericles's birth, that she had borne a lion. Legends say that Philip II of Macedon had a similar dream before the birth of his son, Alexander the Great. One interpretation of the dream treats the lion as a traditional symbol of greatness, but the story may also allude to the unusually large size of Pericles's skull, which became a popular target of contemporary comedians (who called him \"Squill-head\", after the squill or sea-onion). Although Plutarch claims that this deformity was the reason that Pericles was always depicted wearing a helmet, this is not the case; the helmet was actually the symbol of his official rank as strategos (general).\nHis family's nobility and wealth allowed him to fully pursue his inclination toward education. He learned music from the masters of the time (Damon or Pythocleides could have been his teacher) and he is considered to have been the first politician to attribute importance to philosophy. He enjoyed the company of the philosophers Protagoras, Zeno of Elea, and Anaxagoras. Anaxagoras, in particular, became a close friend and influenced him greatly.\nPericles's manner of thought and rhetorical charisma may have possibly been in part products of Anaxagoras's emphasis on emotional calm in the face of trouble, and skepticism about divine phenomena. His proverbial calmness and self-control are also often regarded as products of Anaxagoras's influence.\nPolitical career until 431 BC.\nEntering politics.\nIn the spring of 472 BC, Pericles presented \"The Persians\" of Aeschylus at the Greater Dionysia as a liturgy, demonstrating that he was one of the wealthier men of Athens. Simon Hornblower has argued that Pericles's selection of this play, which presents a nostalgic picture of Themistocles's famous victory at Salamis, shows that the young politician was supporting Themistocles against his political opponent Cimon, whose faction succeeded in having Themistocles ostracized shortly afterward.\nPlutarch says that Pericles stood first among the Athenians for forty years. If this was so, Pericles must have taken up a position of leadership by the early 460s BC, which would be in his early or mid-thirties. Throughout these years he endeavored to protect his privacy and to present himself as a model for his fellow citizens. For example, he would often avoid banquets, trying to be frugal.\nIn 463 BC, Pericles was the leading prosecutor of Cimon, the leader of the conservative faction who was accused of neglecting Athens's vital interests in Macedon. Although Cimon was acquitted, this confrontation proved that Pericles's major political opponent was vulnerable.\nOstracizing Cimon.\nAround 461 BC, the leadership of the democratic party decided it was time to take aim at the Areopagus, a traditional council controlled by the Athenian aristocracy, which had once been the most powerful body in the state. The leader of the party and mentor of Pericles, Ephialtes, proposed a reduction of the Areopagus's powers. The Ecclesia (the Athenian Assembly) adopted Ephialtes's proposal without opposition. This reform signaled the beginning of a new era of \"radical democracy\".\nThe democratic party gradually became dominant in Athenian politics, and Pericles seemed willing to follow a populist policy to cajole the public. According to Aristotle, Pericles's stance can be explained by the fact that his principal political opponent, Cimon, was both rich and generous, and was able to gain public favor by lavishly handing out portions of his sizable personal fortune. The historian Loren J. Samons II argues, however, that Pericles had enough resources to make a political mark by private means, had he so chosen.\nIn 461 BC, Pericles achieved the political elimination of this opponent using ostracism. The accusation was that Cimon betrayed his city by aiding Sparta.\nAfter Cimon's ostracism, Pericles continued to promote a populist social policy. He first proposed a decree that permitted the poor to watch theatrical plays without paying, with the state covering the cost of their admission. With other decrees he lowered the property requirement for the archonship in 458\u2013457 BC and bestowed generous wages on all citizens who served as jurymen in the Heliaia (the supreme court of Athens) some time just after 454\u00a0BC. His most controversial measure, however, was a law of 451 BC limiting Athenian citizenship to those of Athenian parentage on both sides.\nSuch measures impelled Pericles's critics to hold him responsible for the gradual degeneration of the Athenian democracy. The 19th century Greek historian Constantine Paparrigopoulos, argued that Pericles sought for the expansion and stabilization of all democratic institutions. Accordingly, he enacted legislation granting the lower classes access to the political system and the public offices, from which they had previously been barred.\nAccording to Samons, Pericles believed that it was necessary to raise the \"demos\", in which he saw an untapped source of Athenian power and the crucial element of Athenian military dominance. (The fleet, backbone of Athenian power since the days of Themistocles, was manned almost entirely by members of the lower classes).\nCimon, in contrast, apparently believed that no further free space for democratic evolution existed. He was certain that democracy had reached its peak and Pericles's reforms were leading to the stalemate of populism. According to Paparrigopoulos, history vindicated Cimon, because Athens, after Pericles's death, sank into the abyss of political turmoil and demagogy. Paparrigopoulos maintained that an unprecedented regression descended upon the city, whose glory perished as a result of Pericles's populist policies.\nAccording to another historian, Justin Daniel King, radical democracy benefited people individually, but harmed the state. In contrast, Donald Kagan asserted that the democratic measures Pericles put into effect provided the basis for an unassailable political strength. After all, Cimon finally accepted the new democracy and did not oppose the citizenship law, after he returned from exile in 451\u00a0BC.\nLeading Athens.\nEphialtes's murder in 461 BC paved the way for Pericles to consolidate his authority. Without opposition after the expulsion of Cimon, the unchallengeable leader of the democratic party became the unchallengeable ruler of Athens. He remained in power until his death in 429\u00a0BC.\nFirst Peloponnesian War.\nPericles made his first military excursions during the First Peloponnesian War, which was caused in part by Athens's alliance with Megara and Argos and the subsequent reaction of Sparta. In 454 BC he attacked Sicyon and Acarnania. He then unsuccessfully tried to conquer Oeniadea on the Corinthian gulf, before returning to Athens. In 451 BC, Cimon returned from exile and negotiated a five years' truce with Sparta after a proposal of Pericles, an event which indicates a shift in Pericles's political strategy. Pericles may have realized the importance of Cimon's contribution during the ongoing conflicts against the Peloponnesians and the Persians. Anthony J. Podlecki argues, however, that Pericles's alleged change of position was invented by ancient writers to support \"a tendentious view of Pericles' shiftiness\".\nPlutarch states that Cimon struck a power-sharing deal with his opponents, according to which Pericles would carry through the interior affairs and Cimon would be the leader of the Athenian army, campaigning abroad. If it were actually made, this bargain would constitute a concession on Pericles's part that he was not a great strategist. Kagan's view is that Cimon adapted himself to the new conditions and promoted a political marriage between Periclean liberals and Cimonian conservatives.\nIn the mid-450s the Athenians launched an unsuccessful attempt to aid an Egyptian revolt against Persia, which led to a prolonged siege of a Persian fortress in the Nile Delta. The campaign culminated in disaster; the besieging force was defeated and destroyed. In 451\u2013450 BC the Athenians sent troops to Cyprus. Cimon defeated the Persians in the Battle of Salamis-in-Cyprus, but died of disease in 449\u00a0BC. Pericles is said to have initiated both expeditions in Egypt and Cyprus, although some researchers, such as Karl Julius Beloch, argue that the dispatch of such a great fleet conforms with the spirit of Cimon's policy.\nComplicating the account of this period is the issue of the Peace of Callias, which allegedly ended hostilities between the Greeks and the Persians. The very existence of the treaty is hotly disputed, and its particulars and negotiation are ambiguous. Ernst Badian believes that a peace between Athens and Persia was first ratified in 463 BC (making the Athenian interventions in Egypt and Cyprus violations of the peace), and renegotiated at the conclusion of the campaign in Cyprus, taking force again by 449\u2013448\u00a0BC.\nJohn Fine, in contrast, suggests that the first peace between Athens and Persia was concluded in 450\u2013449\u00a0BC, due to Pericles's calculation that ongoing conflict with Persia was undermining Athens's ability to spread its influence in Greece and the Aegean. Kagan believes that Pericles used Callias, a brother-in-law of Cimon, as a symbol of unity and employed him several times to negotiate important agreements.\nIn the spring of 449 BC, Pericles proposed the Congress Decree, which led to a meeting (\"Congress\") of all Greek states to consider the question of rebuilding the temples destroyed by the Persians. The Congress failed because of Sparta's stance, but Pericles's intentions remain unclear. Some historians think that he wanted to prompt a confederation with the participation of all the Greek cities; others think he wanted to assert Athenian pre-eminence. According to the historian Terry Buckley the objective of the Congress Decree was a new mandate for the Delian League and for the collection of \"phoros\" (taxes).\nDuring the Second Sacred War Pericles led the Athenian army against Delphi and reinstated Phocis in its sovereign rights on the oracle. In 447 BC Pericles engaged in his most admired excursion, the expulsion of barbarians from the Thracian peninsula of Gallipoli, to establish Athenian colonists in the region. At this time, however, Athens was seriously challenged by a number of revolts among its subjects. In 447 BC the oligarchs of Thebes conspired against the democratic faction. The Athenians demanded their immediate surrender, but after the Battle of Coronea, Pericles was forced to concede the loss of Boeotia to recover the prisoners taken in that battle. With Boeotia in hostile hands, Phocis and Locris became untenable and quickly fell under the control of hostile oligarchs.\nIn 446 BC, a more dangerous uprising erupted. Euboea and Megara revolted. Pericles crossed over to Euboea with his troops, but was forced to return when the Spartan army invaded Attica. Through bribery and negotiations, Pericles defused the imminent threat, and the Spartans returned home. When Pericles was later audited for the handling of public money, an expenditure of 10 talents was not sufficiently justified, since the official documents just referred that the money was spent for a \"very serious purpose\". Nonetheless, the \"serious purpose\" (namely the bribery) was so obvious to the auditors that they approved the expenditure without official meddling and without even investigating the mystery.\nAfter the Spartan threat had been removed, Pericles crossed back to Euboea to crush the revolt there. He then punished the landowners of Chalcis, who lost their properties. The residents of Histiaea, meanwhile, who had butchered the crew of an Athenian trireme, were uprooted and replaced by 2,000 Athenian settlers. The crisis was brought to an official end by the Thirty Years' Peace (winter of 446\u2013445\u00a0BC), in which Athens relinquished most of the possessions and interests on the Greek mainland which it had acquired since 460\u00a0BC, and both Athens and Sparta agreed not to attempt to win over the other state's allies.\nFinal battle with the conservatives.\nIn 444 BC, the conservative and the democratic factions confronted each other in a fierce struggle. The ambitious new leader of the conservatives, Thucydides (not to be confused with the historian of the same name), accused Pericles of profligacy, criticizing the way he spent the money for the ongoing building plan. Thucydides initially managed to incite the passions of the ecclesia regarding these charges in his favor. However, when Pericles took the floor, his resolute arguments put Thucydides and the conservatives firmly on the defensive. Finally, Pericles proposed to reimburse the city for all questionable expenses from his private property, with the proviso that he would make the inscriptions of dedication in his own name. His stance was greeted with applause, and Thucydides was soundly, if unexpectedly, defeated. In 442\u00a0BC, the Athenian public voted to ostracize Thucydides from the city for 10 years and Pericles was once again the unchallenged ruler of the Athenian political arena.\nAthens's rule over its alliance.\nPericles wanted to stabilize Athens's dominance over its alliance and to enforce its pre-eminence in Greece. The process by which the Delian League transformed into an Athenian empire is generally considered to have begun well before Pericles's time, as various allies in the league chose to pay tribute to Athens instead of manning ships for the league's fleet, but the transformation was speeded and brought to its conclusion by Pericles.\nThe final steps in the shift to empire may have been triggered by Athens's defeat in Egypt, which challenged the city's dominance in the Aegean and led to the revolt of several allies, such as Miletus and Erythrae. Either because of a genuine fear for its safety after the defeat in Egypt and the revolts of the allies, or as a pretext to gain control of the League's finances, Athens transferred the treasury of the alliance from Delos to Athens in 454\u2013453\u00a0BC.\nBy 450\u2013449 BC the revolts in Miletus and Erythrae were quelled and Athens restored its rule over its allies. Around 447 BC Clearchus proposed the Coinage Decree, which imposed Athenian silver coinage, weights and measures on all of the allies. According to one of the decree's most stringent provisions, surplus from a minting operation was to go into a special fund, and anyone proposing to use it otherwise was subject to the death penalty.\nIt was from the alliance's treasury that Pericles drew the funds necessary to enable his ambitious building plan, centered on the \"Periclean Acropolis\", which included the Propylaea, the Parthenon and the golden statue of Athena, sculpted by Pericles's friend, Phidias. In 449 BC Pericles proposed a decree allowing the use of 9,000 talents to finance the major rebuilding program of Athenian temples. Angelos Vlachos, a Greek Academician, points out the use of the alliance's treasury, initiated and executed by Pericles, as one of the largest embezzlements in human history; this misappropriation financed, however, some of the most marvellous artistic creations of the ancient world.\nSamian War.\nThe Samian War was one of the last significant military events before the Peloponnesian War. After Thucydides's ostracism, Pericles was re-elected yearly to the generalship, the only office he ever officially occupied, although his influence was so great as to make him the \"de facto\" ruler of the state. In 440 BC Samos went to war against Miletus over control of Priene, an ancient city of Ionia on the foot-hills of Mycale. Worsted in the war, the Milesians came to Athens to plead their case against the Samians.\nWhen the Athenians ordered the two sides to stop fighting and submit the case to arbitration in Athens, the Samians refused. In response, Pericles passed a decree dispatching an expedition to Samos, \"alleging against its people that, although they were ordered to break off their war against the Milesians, they were not complying\".\nIn a naval battle the Athenians led by Pericles and nine other generals defeated the forces of Samos and imposed on the island an Athenian administration. When the Samians revolted against Athenian rule, Pericles compelled the rebels to capitulate after a tough siege of eight months, which resulted in substantial discontent among the Athenian sailors. Pericles then quelled a revolt in Byzantium and, when he returned to Athens, gave a funeral oration to honor the soldiers who died in the expedition.\nBetween 438 and 436 BC Pericles led Athens's fleet in Pontus and established friendly relations with the Greek cities of the region. Pericles focused also on internal projects, such as the fortification of Athens (the building of the \"middle wall\" about 440\u00a0BC), and on the creation of new cleruchies, such as Andros, Naxos and Thurii (444\u00a0BC) as well as Amphipolis (437\u2013436\u00a0BC).\nPersonal attacks.\nPericles and his friends were never immune from attack, as preeminence in democratic Athens was not equivalent to absolute rule. Just before the eruption of the Peloponnesian War, Pericles and two of his closest associates, Phidias and his companion, Aspasia, faced a series of personal and judicial attacks.\nPhidias, who had been in charge of all building projects, was first accused of embezzling gold meant for the statue of Athena and then of impiety, because, when he wrought the battle of the Amazons on the shield of Athena, he carved out a figure that suggested himself as a bald old man, and also inserted a very fine likeness of Pericles fighting with an Amazon.\nAspasia, who was noted for her ability as a conversationalist and adviser, was accused of corrupting the women of Athens to satisfy Pericles's perversions. The accusations against her were probably nothing more than unproven slanders, but the whole experience was very bitter for Pericles. Although Aspasia was acquitted thanks to a rare emotional outburst of Pericles, his friend Phidias died in prison according to Plutarch; however, he is also credited with the later statue of Zeus at Olympia, therefore this is debated, and another friend of his, Anaxagoras, was attacked by the ecclesia for his religious beliefs.\nBeyond these initial prosecutions, the ecclesia attacked Pericles himself by asking him to justify his ostensible profligacy with, and maladministration of, public money. According to Plutarch, Pericles was so afraid of the oncoming trial that he did not let the Athenians yield to the Lacedaemonians. Beloch also believes that Pericles deliberately brought on the war to protect his political position at home. Thus, at the start of the Peloponnesian War, Athens found itself in the awkward position of entrusting its future to a leader whose pre-eminence had just been seriously shaken for the first time in over a decade.\nPeloponnesian War.\nThe causes of the Peloponnesian War have been much debated, but many ancient historians lay the blame on Pericles and Athens. Plutarch seems to believe that Pericles and the Athenians incited the war, scrambling to implement their belligerent tactics \"with a sort of arrogance and a love of strife\". Thucydides hints at the same thing, believing the reason for the war was Sparta's fear of Athenian power and growth. However, as he is generally regarded as an admirer of Pericles, Thucydides has been criticized for bias against Sparta.\nPrelude to the war.\nPericles was convinced that the war against Sparta, which could not conceal its envy of Athens's pre-eminence, was inevitable if unfortunate. Therefore, he did not hesitate to send troops to Corcyra to reinforce the Corcyraean fleet, which was fighting against Corinth. In 433 BC the enemy fleets confronted each other at the Battle of Sybota and a year later the Athenians fought Corinthian colonists at the Battle of Potidaea; these two events contributed greatly to Corinth's lasting hatred of Athens. During the same period, Pericles proposed the Megarian decree, which resembled a modern trade embargo. According to the provisions of the decree, Megarian merchants were excluded from the market of Athens and the ports in its empire. This ban strangled the Megarian economy and strained the fragile peace between Athens and Sparta, which was allied with Megara. According to George Cawkwell, a praelector in ancient history, with this decree Pericles breached the Thirty Years' Peace \"but, perhaps, not without the semblance of an excuse\". The Athenians' justification was that the Megarians had cultivated the sacred land consecrated to Demeter and had given refuge to runaway slaves, a behavior which the Athenians considered to be impious.\nAfter consultations with its allies, Sparta sent a deputation to Athens demanding certain concessions, such as the immediate expulsion of the Alcmaeonidae family including Pericles and the retraction of the Megarian Decree, threatening war if the demands were not met. The obvious purpose of these proposals was the instigation of a confrontation between Pericles and the people; this event, indeed, would come about a few years later. At that time, the Athenians unhesitatingly followed Pericles's instructions. In the first legendary oration Thucydides puts in his mouth, Pericles advised the Athenians not to yield to their opponents' demands, since they were militarily stronger. Pericles was not prepared to make unilateral concessions, believing that \"if Athens conceded on that issue, then Sparta was sure to come up with further demands\". Consequently, Pericles asked the Spartans to offer a \"quid pro quo\". In exchange for retracting the Megarian Decree, the Athenians demanded from Sparta to abandon their practice of periodic expulsion of foreigners from their territory (xenelasia) and to recognize the autonomy of its allied cities, a request implying that Sparta's hegemony was also ruthless. The terms were rejected by the Spartans, and with neither side willing to back down, the two cities prepared for war. According to Athanasios G. Platias and Constantinos Koliopoulos, professors of strategic studies and international politics, \"rather than to submit to coercive demands, Pericles chose war\". Another consideration that may well have influenced Pericles's stance was the concern that revolts in the empire might spread if Athens showed itself weak.\nFirst year of the war (431 BC).\nIn 431 BC, while peace already was precarious, Archidamus\u00a0II, Sparta's king, sent a new delegation to Athens, demanding that the Athenians submit to Sparta's demands. This deputation was not allowed to enter Athens, as Pericles had already passed a resolution according to which no Spartan deputation would be welcomed if the Spartans had previously initiated any hostile military actions. The Spartan army was at this time gathered at Corinth, and, citing this as a hostile action, the Athenians refused to admit their emissaries. With his last attempt at negotiation thus declined, Archidamus invaded Attica, but found no Athenians there; Pericles, aware that Sparta's strategy would be to invade and ravage Athenian territory, had previously arranged to evacuate the entire population of the region to within the walls of Athens.\nNo definite record exists of how exactly Pericles managed to convince the residents of Attica to agree to move into the crowded urban areas. For most, the move meant abandoning their land and ancestral shrines and completely changing their lifestyle. Therefore, although they agreed to leave, many rural residents were far from happy with Pericles's decision. Pericles also gave his compatriots some advice on their present affairs and reassured them that, if the enemy did not plunder his farms, he would offer his property to the city. This promise was prompted by his concern that Archidamus, who was a friend of his, might pass by his estate without ravaging it, either as a gesture of friendship or as a calculated political move aimed to alienate Pericles from his constituents.\nIn any case, seeing the pillage of their farms, the Athenians were outraged, and they soon began to indirectly express their discontent towards their leader, who many of them considered to have drawn them into the war. Even when in the face of mounting pressure, Pericles did not give in to the demands for immediate action against the enemy or revise his initial strategy. He also avoided convening the ecclesia, fearing that the populace, outraged by the unopposed ravaging of their farms, might rashly decide to challenge the vaunted Spartan army in the field. As meetings of the assembly were called at the discretion of its rotating presidents, the \"prytani\" (singular, \"prytaneis\"), Pericles had no formal control over their scheduling; rather, the respect in which Pericles was held by the prytanies was apparently sufficient to persuade them to do as he wished. While the Spartan army remained in Attica, Pericles sent a fleet of 100 ships to loot the coasts of the Peloponnese and charged the cavalry to guard the ravaged farms close to the walls of the city. When the enemy retired and the pillaging came to an end, Pericles proposed a decree according to which the authorities of the city should put aside 1,000 talents and 100 ships, in case Athens was attacked by naval forces. According to the most stringent provision of the decree, even proposing a different use of the money or ships would entail the penalty of death. During the autumn of 431 BC, Pericles led the Athenian forces that invaded Megara and a few months later (winter of 431\u2013430 BC) he delivered his monumental and emotional Funeral Oration, honoring the Athenians who died for their city.\nLast military operations and death.\nIn 430 BC, the army of Sparta looted Attica for a second time, but Pericles was not daunted and refused to revise his initial strategy. Unwilling to engage the Spartan army in battle, he again led a naval expedition to plunder the coasts of the Peloponnese, this time taking 100 Athenian ships with him. According to Plutarch, just before the sailing of the ships an eclipse of the sun frightened the crews, but Pericles used the astronomical knowledge he had acquired from Anaxagoras to calm them. In the summer of the same year an epidemic broke out and devastated the Athenians. The exact identity of the disease is uncertain; typhus or typhoid fever are suspected, but this has been the source of much debate. In any case, the city's plight, caused by the epidemic, triggered a new wave of public uproar, and Pericles was forced to defend himself in an emotional final speech, a rendition of which is presented by Thucydides. This is considered to be a monumental oration, revealing Pericles's virtues but also his bitterness towards his compatriots' ingratitude. Temporarily, he managed to tame the people's resentment and to ride out the storm, but his internal enemies' final bid to undermine him came off; they managed to deprive him of the generalship and to fine him at an amount estimated between 15 and 50 talents. Ancient sources mention Cleon, a rising and dynamic protagonist of the Athenian political scene during the war, as the public prosecutor in Pericles's trial.\nNevertheless, within just a year, in 429 BC, the Athenians not only forgave Pericles but also re-elected him as strategos. He was reinstated in command of the Athenian army and led all its military operations during 429 BC, having once again under his control the levers of power. In that year, however, Pericles witnessed in the epidemic the death of both Paralus and Xanthippus, his legitimate sons from his first wife. According to Plutarch, Pericles was overwhelmed with grief and wept copiously for his loss. He himself died of the plague later in the year.\nJust before his death, Pericles's friends were concentrated around his bed, enumerating his virtues during peace and underscoring his nine war trophies. Pericles, though moribund, heard them and interrupted them, pointing out that they forgot to mention his fairest and greatest title to their admiration; \"for\", said he, \"no living Athenian ever put on mourning because of me\". Pericles lived during the first two and a half years of the Peloponnesian War and, according to Thucydides, his death was a disaster for Athens, since his successors were inferior to him; they preferred to incite all the bad habits of the rabble and followed an unstable policy, endeavoring to be popular rather than useful. With these bitter comments, Thucydides not only laments the loss of a man he admired, but he also heralds the flickering of Athens's unique glory and grandeur.\nPausanias (c. 150 AD) records (I.29) seeing the tomb of Pericles along a road near the Academy.\nPersonal life.\nPericles, following Athenian custom, was first married to one of his closest relatives, with whom he had two sons, Paralus and Xanthippus, but around 445\u00a0BC, Pericles divorced his wife. He offered her to another husband, with the agreement of her male relatives. The name of his first wife is not known; the only information about her is that she was the wife of Hipponicus, before being married to Pericles, and the mother of Callias from this first marriage.\nAfter Pericles divorced his wife, he had a long-term relationship with Aspasia of Miletus, with whom he had a son, Pericles the Younger. While Aspasia was held in high regard by many of Athens's socialites, her status as a non-Athenian led many to attack their relationship. Even Pericles's son, Xanthippus, who had political ambitions, did not hesitate to slander his father. Nonetheless, such objections did not greatly undermine the popularity of the couple and Pericles readily fought back against accusations that his relationship with Aspasia was corrupting of Athenian society.\nHis sister and both his legitimate sons, Xanthippus and Paralus, died during the Plague of Athens. Just before his death, the Athenians allowed a change in the law of 451 BC that made his half-Athenian son with Aspasia, Pericles the Younger, a citizen, and legitimate heir, a striking decision considering that Pericles himself had proposed the law confining citizenship to those of Athenian parentage on both sides.\nAssessments.\nPericles marked a whole era and inspired conflicting judgments about his significant decisions. The fact that he was at the same time a vigorous statesman, general and orator only tends to make an objective assessment of his actions more difficult.\nPolitical leadership.\nSome contemporary scholars call Pericles a populist, a demagogue and a hawk, while other scholars admire his charismatic leadership. According to Plutarch, after assuming the leadership of Athens, \"he was no longer the same man as before, nor alike submissive to the people and ready to yield and give in to the desires of the multitude as a steersman to the breezes\". It is told that when his political opponent, Thucydides, was asked by Sparta's king, Archidamus, whether he or Pericles was the better fighter, Thucydides answered without any hesitation that Pericles was better, because even when he was defeated, he managed to convince the audience that he had won. In matters of character, Pericles was above reproach in the eyes of the ancient historians, since \"he kept himself untainted by corruption, although he was not altogether indifferent to money-making\".\nThucydides (the historian), an admirer of Pericles, maintains that Athens was \"in name a democracy but, in fact, governed by its first citizen\". Through this comment, the historian illustrates what he perceives as Pericles's charisma to lead, convince and, sometimes, to manipulate. Although Thucydides mentions the fining of Pericles, he does not mention the accusations against Pericles but instead focuses on Pericles's integrity. On the other hand, in one of his dialogues, Plato rejects the glorification of Pericles and declares: \"as I know, Pericles made the Athenians slothful, garrulous and avaricious, by starting the system of public fees\".\nPlutarch mentions other criticism of Pericles's leadership: \"many others say that the people were first led on by him into allotments of public lands, festival-grants, and distributions of fees for public services, thereby falling into bad habits, and becoming luxurious and wanton under the influence of his public measures, instead of frugal and self-sufficing\".\nThucydides argues that Pericles \"was not carried away by the people, but he was the one guiding the people\". His judgement is not unquestioned; some 20th-century critics, such as Malcolm F. McGregor and John S. Morrison, proposed that he may have been a charismatic public face acting as an advocate on the proposals of advisors, or the people themselves. According to King, by increasing the power of the people, the Athenians left themselves with no authoritative leader. During the Peloponnesian War, Pericles's dependence on popular support to govern was obvious.\nMilitary achievements.\nFor more than 20 years Pericles led many expeditions, mainly naval ones. Being always cautious, he never undertook of his own accord a battle involving much uncertainty and peril and he did not accede to the \"vain impulses of the citizens\". He based his military policy on Themistocles's principle that Athens's predominance depends on its superior naval power and believed that the Peloponnesians were near-invincible on land. Pericles also tried to minimize the advantages of Sparta by rebuilding the walls of Athens, which, it has been suggested, radically altered the use of force in Greek international relations.\nDuring the Peloponnesian War, Pericles initiated a defensive \"grand strategy\" whose aim was the exhaustion of the enemy and the preservation of the \"status quo\". According to Platias and Koliopoulos, Athens as the strongest party did not have to beat Sparta in military terms and \"chose to foil the Spartan plan for victory\". The two basic principles of the \"Periclean Grand Strategy\" were the rejection of appeasement (in accordance with which he urged the Athenians not to revoke the Megarian Decree) and the avoidance of overextension. According to Kagan, Pericles's vehement insistence that there should be no diversionary expeditions may well have resulted from the bitter memory of the Egyptian campaign, which he had allegedly supported. His strategy is said to have been \"inherently unpopular\", but Pericles managed to persuade the Athenian public to follow it. It is for that reason that Hans Delbr\u00fcck called him one of the greatest statesmen and military leaders in history. Although his countrymen engaged in several aggressive actions soon after his death, Platias and Koliopoulos argue that the Athenians remained true to the larger Periclean strategy of seeking to preserve, not expand, the empire, and did not depart from it until the Sicilian Expedition. For his part, Ben X. de Wet concludes his strategy would have succeeded had he lived longer.\nCritics of Pericles's strategy, however, have been just as numerous as its supporters. A common criticism is that Pericles was always a better politician and orator than strategist. Donald Kagan called the Periclean strategy \"a form of wishful thinking that failed\", Barry S. Strauss and Josiah Ober have stated that \"as strategist he was a failure and deserves a share of the blame for Athens' great defeat\", and Victor Davis Hanson believes that Pericles had not worked out a clear strategy for an effective offensive action that could possibly force Thebes or Sparta to stop the war. Kagan criticizes the Periclean strategy on four counts: first that by rejecting minor concessions it brought about war; second, that it was unforeseen by the enemy and hence lacked credibility; third, that it was too feeble to exploit any opportunities; and fourth, that it depended on Pericles for its execution and thus was bound to be abandoned after his death. Kagan estimates Pericles's expenditure on his military strategy in the Peloponnesian War to be about 2,000 talents annually, and based on this figure concludes that he would have only enough money to keep the war going for three years. He asserts that since Pericles must have known about these limitations he probably planned for a much shorter war. Others, such as Donald W. Knight, conclude that the strategy was too defensive and would not succeed.\nIn contrast, Platias and Koliopoulos reject these criticisms and state that \"the Athenians lost the war only when they dramatically reversed the Periclean grand strategy that explicitly disdained further conquests\". Hanson stresses that the Periclean strategy was not innovative, but could lead to a stagnancy in favor of Athens. It is a popular conclusion that those succeeding him lacked his abilities and character.\nOratorical skill.\nModern commentators of Thucydides, with other modern historians and writers, take varying stances on the issue of how much of the speeches of Pericles, as given by this historian, do actually represent Pericles's own words and how much of them is free literary creation or paraphrase by Thucydides. Since Pericles never wrote down or distributed his orations, no historians are able to answer this with certainty; Thucydides recreated three of them from memory and, thereby, it cannot be ascertained that he did not add his own notions and thoughts.\nAlthough Pericles was a main source of his inspiration, some historians have noted that the passionate and idealistic literary style of the speeches Thucydides attributes to Pericles is completely at odds with Thucydides's own cold and analytical writing style. This might, however, be the result of the incorporation of the genre of rhetoric into the genre of historiography. That is to say, Thucydides could simply have used two different writing styles for two different purposes.\nIoannis Kakridis and Arnold Gomme were two scholars who debated the originality of Pericles's oratory and last speech. Kakridis believes that Thucydides altered Pericles words. Some of his strongest arguments included in the Introduction of the speech, (Thuc.11.35). Kakridis proposes that it is impossible to imagine Pericles deviating away from the expected funeral orator addressing the mourning audience of 430 after the Peloponnesian war. The two groups addressed were the ones who were prepared to believe him when he praised the dead, and the ones who did not. Gomme rejects Kakridis's position, defending the fact that \"Nobody of men has ever been so conscious of envy and its workings as the Greeks, and that the Greeks and Thucydides in particular had a passion for covering all ground in their generalizations, not always relevantly.\"\nKagan states that Pericles adopted \"an elevated mode of speech, free from the vulgar and knavish tricks of mob-orators\" and, according to Diodorus Siculus, he \"excelled all his fellow citizens in skill of oratory\". According to Plutarch, he avoided using gimmicks in his speeches, unlike the passionate Demosthenes, and always spoke in a calm and tranquil manner. The biographer points out, however, that the poet Ion reported that Pericles's speaking style was \"a presumptuous and somewhat arrogant manner of address, and that into his haughtiness there entered a good deal of disdain and contempt for others\".\nGorgias, in Plato's homonymous dialogue, uses Pericles as an example of powerful oratory. In Menexenus, however, Socrates (through Plato) casts aspersions on Pericles's rhetorical fame, claiming ironically that, since Pericles was educated by Aspasia, a trainer of many orators, he would be superior in rhetoric to someone educated by Antiphon. He also attributes authorship of the Funeral Oration to Aspasia and attacks his contemporaries' veneration of Pericles.\nSir Richard C. Jebb concludes that \"unique as an Athenian statesman, Pericles must have been in two respects unique also as an Athenian orator; first, because he occupied such a position of personal ascendancy as no man before or after him attained; secondly, because his thoughts and his moral force won him such renown for eloquence as no one else ever got from Athenians\".\nAncient Greek writers call Pericles \"Olympian\" and extol his talents; referring to him \"thundering and lightning and exciting Greece\" and carrying the weapons of Zeus when orating. According to Quintilian, Pericles would always prepare assiduously for his orations and, before going on the rostrum, he would always pray to the gods, so as not to utter any improper word.\nPericles and the city gods.\nNothing was more alien to the Greeks than the notion of a Separation between church and state. In Athens, the community provided a tight framework for religious manifestations while, symmetrically, religion was deeply embedded in civic life. Within this context, participation in the rituals was an action highly political in the broadest sense of the term.\nTo analyze Pericles's relations with gods, one has to position oneself at the intersection of the general and the particular, where what was personal and what was shared by the whole community came together. On the one hand, the career of the \"strategos\" will illuminate the Athenians' collective relationship to all that was divine. As a reelected \"strategos\" and a persuasive orator, Pericles was the spokesman of a civic religion that was undergoing a mutation. He was implicated in a policy of making constant offerings and of launching huge architectural religious works not only on the Acropolis but also throughout Attica; and, furthermore, he was engaged in such activities at a time when city was introducing profound changes into its religious account of its origins\u2014that is, autochthony\u2014within a context of strained diplomatic relations.\nOn the other hand, the ancient sources made it possible to glimpse the personal relations that Pericles had developed with gods. These were relations of proximity in the first place: he was sometimes depicted as a prot\u00e9g\u00e9 of goddess Athena, but in Attic comedies he was also assimilated to god Zeus, in an analogy that was in no way flattering. But then, there were also relations that emphasized distance: some philosophical accounts presented him as a man close to the sophists or even as a freethinker. Finally, there were relations involving irreverence: some later and less trustworthy sources made much of several trials for impiety in which those close to him were involved, and this raises the question of religious tolerance in fifth-century Athens and, in particular, how far individuals enjoyed freedom of thought when faced with the civic community.\nLegacy.\nPericles's most visible legacy can be found in the literary and artistic works of the Golden Age, much of which survive to this day. The Acropolis, though in ruins, still stands and is a symbol of modern Athens. Paparrigopoulos wrote that these masterpieces are \"sufficient to render the name of Greece immortal in our world\".\nIn politics, Victor L. Ehrenberg argues that a basic element of Pericles's legacy is Athenian imperialism, which denies true democracy and freedom to the people of all but the ruling state. The promotion of such an arrogant imperialism is said to have ruined Athens. Pericles and his \"expansionary\" policies have been at the center of arguments promoting democracy in oppressed countries.\nOther analysts maintain an Athenian humanism illustrated in the Golden Age. The freedom of expression is regarded as the lasting legacy deriving from this period. Pericles is lauded as \"the ideal type of the perfect statesman in ancient Greece\" and his Funeral Oration is nowadays synonymous with the struggle for participatory democracy and civic pride.\nIn 1932, botanist Albert Charles Smith published \"Periclesia\", a monotypic genus of flowering plants from Ecuador belonging to the family Ericaceae and named after Pericles.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nPrimary sources (Greek and Roman).\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nSecondary sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "36814", "revid": "573348", "url": "https://en.wikipedia.org/wiki?curid=36814", "title": "Athenian Acropolis", "text": ""}
{"id": "36816", "revid": "43933683", "url": "https://en.wikipedia.org/wiki?curid=36816", "title": "The Three Stooges", "text": "American slapstick comedy trio (1922\u20131970)\nThe Three Stooges were an American vaudeville and comedy troupe active from 1922 until 1970, best remembered for their 190 short-subject films by Columbia Pictures. Their hallmark styles were physical, farce, and slapstick comedy. Six Stooges appeared over the act's run (with only three working at any given time). The two constants were:\nThe \"third stooge\" was played in turn by:&lt;br&gt;\nThe act began in 1922 as part of a vaudeville comedy act consisting originally of Ted Healy and Moe Howard. Over time, they were joined by Moe's brother, Shemp Howard, and then Larry Fine. The troupe became known as \"Ted Healy and His Stooges\" (\"stooges\" being a show-business term for on-stage assistants). The foursome appeared in one feature film, \"Soup to Nuts\", before Shemp left to pursue a solo career. He was replaced by Moe's younger brother, Jerome \"Curly\" Howard, in 1932. Two years later, after appearing in several movies, the trio left Healy and signed on to appear in their own short-subject comedies for Columbia Pictures, now billed as \"The Three Stooges\". From 1934 to 1946, Moe, Larry, and Curly starred in more than 90 short comedies for Columbia.\nCurly suffered a debilitating stroke in May 1946. Shemp returned, reconstituting the original lineup, until his death of a heart attack on November 22, 1955, three years and ten months after Curly's death of a cerebral hemorrhage. Film actor Joe Palma stood in (shot from behind to obscure his face) to complete four Shemp-era shorts under contract. The procedure of disguising one actor as another outside of stunt shots became known as the \"fake Shemp\". Columbia contract player Joe Besser joined as the third Stooge for two years (1956\u20131957), departing in 1958 to nurse his ill wife after Columbia terminated its shorts division. The studio then released all the shorts via Screen Gems, Columbia's television studio and distribution unit. Screen Gems then syndicated the shorts to television, whereupon the Stooges became one of the most popular comedy acts of the early 1960s.\nComic actor Joe DeRita became \"Curly Joe\" in 1958, replacing Besser for a new series of full-length theatrical films. With intense television exposure in the United States, the act regained momentum throughout the 1960s as popular kids' fare, until Larry's paralyzing stroke in the midst of filming a pilot for a \"Three Stooges\" TV series in January 1970. He died in January 1975 after a further series of strokes. Unsuccessful attempts were made in 1970 and 1975 to revive the act with longtime supporting actor Emil Sitka in Fine's role, but they were each cut short\u2014the first by a movie deal falling through and Moe's wife persuading him to retire, the second by Moe's death.\nHistory.\nTed Healy and His Stooges (1922\u20131934).\nThe Three Stooges began in 1922 as part of a raucous vaudeville act called \"Ted Healy and His Stooges\". The act was also known as \"Ted Healy and His Southern Gentlemen\" and \"Ted Healy and His Racketeers\". Moe Howard joined Healy's act in 1922, and his brother Shemp Howard came aboard a few months later. After several shifts and changes in the Stooges membership, violinist-comedian Larry Fine also joined the group sometime between 1925 and 1928. In the act, lead comedian Healy would attempt to sing or tell jokes while his noisy assistants would keep interrupting him, causing Healy to retaliate with verbal and physical abuse.\nIn 1930, Ted Healy and His Stooges (plus comedian Fred Sanborn) appeared in \"Soup to Nuts\", their first Hollywood feature film, released by Fox Film Corporation. The film was not a critical success, but the Stooges' performances were singled out as memorable, leading Fox to offer the trio a contract, minus Healy. This enraged Healy, who told studio executives the Stooges were his employees, whereupon the offer was withdrawn. Howard, Fine, and Howard learned of the offer and subsequent withdrawal, and left Healy to form their own act (billed as \"Howard, Fine &amp; Howard\" or \"Three Lost Souls\"). The act quickly took off with a tour of the theater circuit. Healy attempted to stop the new act with legal action, claiming that they were using his copyrighted material. Accounts exist of Healy threatening to bomb theaters if Howard, Fine, and Howard ever performed there, which worried Shemp so much that he almost left the act; reportedly, only a pay raise kept him on board.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nHealy tried to save his act by hiring replacement stooges, but they were inexperienced and not as well-received as their predecessors. Healy reached a new agreement with his former Stooges in 1932, with Moe now acting as business manager, and they were booked in a production of Jacob J. Shubert's \"The Passing Show of 1932\". During rehearsals, Healy received a more lucrative offer and found a loophole in his contract allowing him to leave the production. Shemp, fed up with Healy's abrasiveness, bad temper, and heavy drinking, decided to quit the act and toured in his own comedy revue for several months.\nShemp had been working for the Vitaphone studio in Brooklyn, New York since 1931. He first appeared in movie comedies playing small roles and bits in the Roscoe Arbuckle shorts, and gradually worked his way up to star comedian. Shemp stayed with Vitaphone through 1937.\nWith Shemp gone, Healy and the two remaining stooges (Moe and Larry) needed a replacement, so Moe suggested his younger brother Jerry Howard. Healy reportedly took one look at Jerry, who had long chestnut-red hair and a handlebar mustache, and remarked that Jerry did not look like he was funny. Jerry left the room and returned a few minutes later with his head shaved (although his mustache remained for a time), saying: \"Boy, do I look girly.\" Healy heard \"Curly\", and the name stuck. Other accounts have been given for how the Curly character actually came about.\nMetro-Goldwyn-Mayer (MGM) signed Healy and his stooges to a movie contract in 1933. They appeared in feature films and short subjects together, individually, or with various combinations of actors. The trio was featured in a series of musical comedy shorts, beginning with \"Nertsery Rhymes\". It was one of a few shorts to be made with an early two-color Technicolor process. These also included one featuring Curly without Healy or the other Stooges, \"Roast Beef and Movies\" (1934), and the recently rediscovered Technicolor short \"Hello Pop!\". \"Jail Birds of Paradise\" (1934) was also shot in Technicolor, but as of 2022, no print has been found. The short films were built around recycled Technicolor film footage of production numbers cut from MGM musicals, such as \"Children of Pleasure\", \"Lord Byron of Broadway\", and the unfinished \"March of Time\" (all 1930). The studio concluded the series with standard, black-and-white two-reel subjects: \"Beer and Pretzels\" (1933) \"Plane Nuts\" (1933), and \"The Big Idea\" (1934).\nHealy and company also appeared in several MGM feature films as comic relief, including:\nHealy and the Stooges also appeared together in \"Myrt and Marge\" for Universal Pictures.\nIn 1934, the team's contract expired with MGM, and the Stooges' professional association with Healy came to an end. According to Moe Howard's autobiography, the split was precipitated by Healy's alcoholism and abrasiveness. Their final film with Healy was MGM's \"Hollywood Party\" (1934). Healy and the Stooges went on to separate successes, with Healy dying under mysterious circumstances in 1937.\nColumbia years (1934\u20131958).\nMoe, Larry, and Curly (1934\u20131946).\nIn 1934, the trio\u2014now officially named \"The Three Stooges\"\u2014contracted with Columbia Pictures for a series of two-reel comedy short subjects. Moe wrote in his autobiography that they each received $600 per week (equal to $ today) on a one-year contract with a renewable option; in the Ted Okuda\u2013Edward Watz book \"The Columbia Comedy Shorts\", the Stooges are said to have received $1,000 among them for their first Columbia effort, \"Woman Haters\" (1934), and then signed a term contract for $7,500 per film (equal to $ today), to be divided among the trio.\nWithin their first year at Columbia, theater bookings for the Stooges films took off. Columbia Pictures president Harry Cohn was able to use the Stooges as leverage, as the demand for their films was so great that he eventually refused to supply exhibitors with the trio's shorts unless they also agreed to book some of the studio's mediocre B movies. Cohn also saw to it that the Stooges remained unaware of their popularity. During their 23 years at Columbia, the Stooges were never completely aware of their drawing power. Their contracts with the studio included an open option that had to be renewed yearly, and Cohn would tell them that the short subjects were in decline, which was not a complete fabrication (Cohn's yearly mantra was \"the market for comedy shorts is dying out, fellas\").\nThe Stooges thought that their days were numbered and would sweat it out each year, with Cohn renewing their contract at the last moment. This deception kept the insecure Stooges unaware of their true value, resulting in them having second thoughts about asking for a better contract without a yearly option. Cohn's scare tactics worked for all 23 years that the Stooges were at Columbia; the team never once asked for or received a salary increase.\nAfter they stopped making the shorts in December 1957, Moe learned of Cohn's tactics, what a valuable commodity the Stooges had been for the studio, and how many millions more the act could have earned. Columbia offered theater owners an entire program of two-reel comedies (15\u201325 titles annually) featuring such stars as Buster Keaton, Andy Clyde, Charley Chase, and Hugh Herbert, but the Stooge shorts were the most popular of all.\nThe Stooges' release schedule was eight short subjects per year, filmed within a 40-week period; for the remaining 12 weeks, they were free to pursue other employment, time that was either spent with their families or touring the country with their live act. The Stooges appeared in 190 film shorts and five features while at Columbia, outlasting every one of their contemporaries employed in the short-film genre. Del Lord directed more than three dozen Stooge films, Jules White directed dozens more, and his brother Jack White directed several under the pseudonym \"Preston Black\". Silent-comedy star Charley Chase also shared directorial responsibilities with Lord and White.\nThe Stooge films made between 1935 and 1941 captured the team at their peak, according to film historians Ted Okuda and Edward Watz, authors of \"The Columbia Comedy Shorts\"; nearly every film produced became a classic in its own right. \"Hoi Polloi\" (1935) adapted the premise of \"Pygmalion\", with a stuffy professor making a bet that he can transform the uncultured trio into refined gentlemen; the plotline worked so well that it was reused twice, as \"Half-Wits Holiday\" (1947) and \"Pies and Guys\" (1958). \"Three Little Beers\" (1935) featured the Stooges running amok on a golf course to win prize money. \"Disorder in the Court\" (1936) features the team as star witnesses in a murder trial. \"Violent Is the Word for Curly\" (1938) was a quality Chase-directed short that featured the musical interlude \"Swingin' the Alphabet\".\nIn \"A Plumbing We Will Go\" (1940)\u2014one of the team's quintessential comedies\u2014the Stooges are cast as plumbers who nearly destroy a socialite's mansion, causing water to exit every appliance in the home, including an early television set. This was remade twice, as \"Vagabond Loafers\" and \"Scheming Schemers\". Other entries of the era are considered among the team's finest work, including \"Uncivil Warriors\" (1935), \"A Pain in the Pullman\" and \"False Alarms\" (both 1936), \"Grips, Grunts and Groans\", \"The Sitter Downers\", \"Dizzy Doctors\" (all 1937), \"Tassels in the Air\" (1938), \"We Want Our Mummy\" (1939), \"Nutty but Nice\" (1940), and \"An Ache in Every Stake\" and \"In the Sweet Pie and Pie\" (both 1941).\nWith the onset of World War II, the Stooges released several entries that poked fun at the rising Axis powers. \"You Nazty Spy!\" (1940) and its sequel \"I'll Never Heil Again\" (1941) lampooned Hitler and the Nazis at a time when America was still neutral. Moe was cast as \"Moe Hailstone\", an Adolf Hitler-like character, with Curly playing a Hermann G\u00f6ring character, replete with medals, and Larry a Joseph Goebbels-type propaganda minister. Moe, Larry, and director Jules White considered \"You Nazty Spy!\" their best film. Yet, these efforts indulged in a deliberately formless, non-sequitur style of verbal humor that was not the Stooges' forte, according to Okuda and Watz.\nOther wartime entries have their moments, such as \"They Stooge to Conga\" (considered the most violent Stooge short), \"Higher Than a Kite\", \"Back from the Front\" (all 1943), \"Gents Without Cents\" (1944) and the anti-Japanese \"The Yoke's on Me\" (also 1944). However, taken in bulk, the wartime films are considered less funny than what preceded them. \"No Dough Boys\" (1944) is often considered the best of these farces. The team, made up as Japanese soldiers for a photo shoot, is mistaken for genuine saboteurs by a Nazi ringleader (Vernon Dent, the Stooges' primary foil). The highlight of the film features the Stooges engaging in nonsensical gymnastics for a skeptical group of enemy agents expecting renowned acrobats.\nWartime also brought on rising production costs that resulted in fewer elaborate gags and outdoor sequences, Del Lord's stock in trade; as a result, the quality of the team's films, particularly those directed by Lord, began to slip after 1942. According to Okuda and Watz, entries such as \"Loco Boy Makes Good\", \"What's the Matador?\", \"Sock-a-Bye Baby\" (all 1942), \"I Can Hardly Wait\" and \"A Gem of a Jam\" (both 1943) are considered to be lesser-quality works than previous films. \"Spook Louder\" (1943), a remake of Mack Sennett's \"The Great Pie Mystery\" (1931), is sometimes considered one of their weakest shorts because of its repetitious and rehashed jokes. \"Three Smart Saps\" (1942), was an improvement, reworking a routine from Harold Lloyd's \"The Freshman\" (1925), in which Curly's loosely stitched suit begins to fall apart at the seams while he is on the dance floor.\nThe Stooges made occasional supporting appearances in feature films. Most of the Stooges' peers had either made the transition from shorts to feature films (Laurel and Hardy, The Ritz Brothers) or starred in their own feature films from the onset (Marx Brothers, Abbott and Costello). However, Moe believed that the team's slapstick style worked better in short form. In 1935, Columbia proposed to star them in their own full-length feature, but Moe rejected the idea, saying, \"It's a hard job inventing, rewriting, or stealing gags for our two-reel comedies for Columbia Pictures without having to make a seven-reeler (feature film). We can make short films out of material needed for a starring feature, and then we wouldn't know whether it would be funny enough to click.\"\nFilm critics have cited Curly as the most popular member of the team. His childlike mannerisms, natural comedic charm, and uncouth, juvenile humor made him a hit with audiences, particularly women and children. However, Curly having to shave his head for the act led him to feel unappealing to women. To mask his insecurities, he ate and drank to excess and caroused whenever the Stooges made personal appearances, which was around seven months of each year. His weight ballooned in the 1940s, and his blood pressure became dangerously high. Curly's wild lifestyle and constant drinking eventually caught up with him in 1945, and his performances suffered.\nDuring a five-month hiatus from August 1945 through January 1946, the trio committed themselves to making a feature film at Monogram, followed by two months of live appearances in New York City, with performances seven days a week. Curly also entered a disastrous third marriage in October 1945, leading to a separation in January 1946 and divorce in July 1946, at great cost to his already fragile health. Upon the Stooges' return to Los Angeles in late November 1945, Curly was a shell of his former self. They had two months to rest before reporting back to Columbia in late January 1946, but Curly's condition was irreversible. They had only 24 days of work over the next three months, but eight weeks of time off could not help the situation. In those last six shorts, ranging from \"Monkey Businessmen\" (1946) through \"Half-Wits Holiday\" (1947), Curly was seriously ill, struggling to get through even the most basic scenes.\nDuring the final day of filming \"Half-Wits Holiday\" (1947) on May 6, 1946, Curly suffered a debilitating stroke on the set, ending his 14-year career. They hoped for a full recovery, but Curly never appeared in a film again except for a single cameo appearance in the third film after Shemp returned to the trio, \"Hold That Lion!\" (1947). It was the only film that contained all four of the original Stooges (the three Howard brothers and Larry) on screen simultaneously. According to Jules White, this came about when Curly visited the set one day, and White had him do this bit for fun. Curly's cameo appearance was recycled in the remake \"Booty and the Beast\", released in 1953.\nIn 1949, Curly filmed a brief scene for \"Malice in the Palace\" (1949) as the restaurant's cook, but it was not used. Jules White's copy of the script contained the dialogue for this missing scene, and a production still of Curly does exist, appearing on both the film's original one-sheet and lobby card. Larry played the role of the cook in the final print.\nShemp's return (1946\u20131955).\nMoe asked his older brother Shemp to take Curly's place, but Shemp was hesitant to rejoin the Stooges, as he was enjoying a successful solo career. He realized, however, that not rejoining the Stooges would mean the end of Moe and Larry's film careers. Shemp wanted assurances that rejoining them would be only temporary and that he could leave the Stooges once Curly recovered. However, Curly's health continued to deteriorate, and it became clear that he could not return. As a result, Shemp resumed being a Stooge full-time for nearly a decade. Curly remained ill until his death of a cerebral hemorrhage from additional strokes on January 18, 1952.\nShemp appeared with the Stooges in 76 shorts and a low-budget Western comedy feature titled \"Gold Raiders\" (1951) in which the screen time was evenly divided with cowboy hero George O'Brien. Shemp's return improved the quality of the films, as the previous few had been marred by Curly's sluggish performances. Entries such as \"Out West\" (1947), \"Squareheads of the Round Table\" (1948), and \"Punchy Cowpunchers\" (1950) proved that Shemp could hold his own. New director Edward Bernds, who joined the team in 1945 when Curly was failing, sensed that routines and plotlines that worked well with Curly as the comic focus did not fit Shemp's persona, and allowed the comedian to develop his own Stooge character. Jules White, however, persisted in employing the \"living cartoon\" style of comedy that reigned during the Curly era, forcing either Shemp or Moe to perform lackluster imitations of gags and mannerisms that originated from Curly. Most acutely, it created the \"Curly vs. Shemp\" debate that overshadowed the act upon Curly's departure. The Stooges lost some of their charm and inherent appeal to children after Curly retired\u2014Curly, Larry, and Moe behaved like three cartoon characters, while Shemp, Larry, and Moe behaved like three vaudevillians\u2014but some excellent films were produced with Shemp, an accomplished solo comedian who often performed best when allowed to improvise on his own.\nThe films from the Shemp era contrast sharply with those from the Curly era, largely owing to the individual directing styles of Edward Bernds and Jules White. From 1947 to 1952, Bernds hit a string of successes, including \"Fright Night\" (1947), \"The Hot Scots\", \"Mummy's Dummies\", \"Crime on Their Hands\" (all 1948), \"Three Arabian Nuts\" (1951), and \"Gents in a Jam\" (1952). Three of the team's finest efforts were directed by Bernds: \"Brideless Groom\" (1947), \"Who Done It?\" (1949), and \"Punchy Cowpunchers\" (Bernds's own favorite, 1950). White also contributed a few fair entries, such as \"Hold That Lion!\" (1947), \"Hokus Pokus\" (1949), \"Scrambled Brains\" (1951), \"A Missed Fortune\", and \"Corny Casanovas\" (both 1952).\nAnother benefit from the Shemp era was that Larry was given more time on screen. Throughout most of the Curly era, Larry was relegated to a background role, but by the time that Shemp rejoined the Stooges, Larry was allotted equal time, even becoming the focus of several films, in particular \"Fuelin' Around\" (1949) and \"He Cooked His Goose\" (1952).\nThe Stooge shorts were always welcome in theaters\u2014more specifically, those theaters that still found room for two-reel comedies in their programs. Many exhibitors singled out these slapstick comedies as their most popular short-subject attraction. In annual surveys of theater owners, the Stooge two-reelers generally placed among the top five live-action shorts series, behind the \"Pete Smith Specialties\" and the \"March of Time\" and \"This Is America\" documentaries. The Stooge series might well have placed even higher, as the trade journal \"Showmen's Trade Review\" commented in 1948: \"The Three Stooges series fails to appear higher than it does simply because the double-feature policy precludes the wide exhibition this series might otherwise get. Perhaps the greatest tribute to the Stooges comedies is the fact that they have appeared among the Leading Short Subjects for 10 years. Some may come, some may go, but the Three Stooges seem to go on forever making people laugh and forget their troubles.\"\nTelevision debut.\nThe Three Stooges made their first appearance on television (in person, not their old films) in 1948. They were guest stars on Milton Berle's popular \"Texaco Star Theater\" and Morey Amsterdam's \"The Morey Amsterdam Show\". By 1949, the team filmed a pilot for ABC-TV for their own weekly television series, titled \"Jerks of All Trades\". Columbia Pictures blocked the series from going into production, but allowed the Stooges to make television guest appearances. The team went on to appear on \"Camel Comedy Caravan\" (also known as \"The Ed Wynn Show\"), \"The Kate Smith Hour\", \"The Colgate Comedy Hour\", \"The Frank Sinatra Show\", and \"The Eddie Cantor Comedy Theatre\", among others.\nChanges in film production.\nIn 1952, the Stooges lost some key players at Columbia Pictures. The studio decided to downsize its short-subject division, resulting in producer Hugh McCollum being discharged and director Edward Bernds resigning out of loyalty to McCollum, and having had creative differences with Jules White. Screenwriter Elwood Ullman, who had worked closely with Bernds, also resigned. Bernds's departure left only White to direct the Stooges' remaining Columbia comedies. Not long after, the quality of the team's output markedly declined, with producer-director White now assuming complete control over production. \"DVD Talk\" critic Stuart Galbraith IV commented that \"the Stooges' shorts became increasingly mechanical...and frequently substituted violent sight gags for story and characterization.\" Production was also significantly faster, with the former four-day filming schedules now tightened to two or three days. In another cost-cutting measure, White created a \"new\" Stooge short by borrowing footage from old ones, setting it in a slightly different storyline and filming a few new scenes, often with the same actors in the same costumes. White was initially very subtle when recycling older footage; he would reuse only a single sequence of old film, re-edited so cleverly that it was not easy to detect. The later shorts were cheaper and the recycling more obvious, with as much as 75% of the running time consisting of old footage. White came to rely so much on older material that he could film the \"new\" shorts in a single day. New footage filmed to link older material suffered from White's heavy-handed directing style and penchant for telling his actors how to act. Shemp, in particular, disliked working with White after 1952, when White was the Stooges' only director.\nFacing a shutdown.\nIn 1956, after other studios had abandoned short-subject production, Jules White and Columbia had the field to themselves. However, by this time most theaters and drive-ins were using a double-feature or even triple-feature policy, leaving no room for two-reel comedies. White acknowledged the trend by winding down his activities. He made only 14 new comedies for the 1955-56 season: eight with the Three Stooges, two with Andy Clyde, two with Wally Vernon and Eddie Quillan, and two with Joe Besser, all low-budget remakes of older comedies. White explained to historian David Bruskin, \"I saw what was happening around me and realized what we were doing was repeating ourselves and, for the most part, using big chunks of previous films.\" White planned to shut down the entire department after the 1956 quota had been completed. \nHastening White's decision was the sudden death of Shemp Howard. On November 22, 1955, Shemp went out with friends to a boxing match at the Hollywood Legion Stadium. While returning home in a taxi that evening, Shemp died of a massive cerebral hemorrhage (as confirmed by Shemp's daughter-in-law; not a heart attack, as has been reported) at the age of 60. Moe was stunned and contemplated disbanding the Stooges, but Columbia had promised exhibitors eight Stooge shorts for the year and only four had been completed, forcing producer Jules White to manufacture four more shorts \"with Shemp\". Old footage of Shemp was combined with new footage of Columbia supporting player Joe Palma doubling for him (see Fake Shemp). These last four films were \"Rumpus in the Harem\", \"Hot Stuff\", \"Scheming Schemers\", and \"Commotion on the Ocean\" (all released in 1956). \nWhite saw little point in carrying the series any further. The Stooges and Andy Clyde had been with White since 1934, but White saw the writing on the wall. \"I used to get the sales news on how the films were doing. I was watching this and so was Columbia. It was time to go to the office and say, 'Look, fellows, we've done well up to here. Why don't we leave them laughing?'\" White canceled all of his comedy-shorts series in 1956, but Harry Cohn insisted on keeping the Stooge comedies coming. In his own way, Cohn was sentimental about the team; Larry Fine recalled that Cohn once told the Stooges, \"As long as I'm president, you've got a job at Columbia.\"\nMoe Howard and Larry Fine had been carrying the short-subject series as a two-man team, with Shemp Howard seen entirely in older footage. Larry suggested that he and Moe could continue working as \"The Two Stooges.\" Columbia flatly refused, having promoted the team as \"The Three Stooges\" for decades, and Moe was forced to recruit a third Stooge. Several comedians were considered, including burlesque comic and former Ted Healy stooge Paul \"Mousie\" Garner, and noted African-American comedian Mantan Moreland, but Columbia insisted on a comedian already under contract to the studio. They agreed on Joe Besser.\nJoe Besser replaces Shemp (1956\u20131958).\nJoe Besser appeared in the final 16 Stooge shorts. He had been starring in his own short-subject comedies for the studio since 1949 and appeared in supporting roles in feature films. Despite Besser's prolific film and stage career, the Stooge entries featuring him have often been considered the team's weakest. Besser was a talented comic, and was quite popular as \"Stinky\" on \"The Abbott and Costello Show\", but his whining mannerisms and resistance to slapstick punishment did not fit the Stooges' established format of continuous physical comedy. His presence, though, did create verbal friction between Moe and Larry, improving their mutually insulting banter. \nBesser had observed how one side of Larry Fine's face appeared \"calloused\", so he had a clause in his contract specifically prohibiting him from being hit beyond an infrequent tap, though this restriction was later lifted. \"I usually played the kind of character who would hit others back,\" Besser recalled.\nThe Besser Stooge shorts were of inconsistent quality, alternating between fresh, original material and tired rehashes. Fully half of these shorts contained all-new scripts, experimenting with science-fiction, fantasy, and musical-comedy formats. The other eight scripts were remakes, based on earlier Stooge comedies. Budgets were lower than ever, and Moe and Larry's advanced ages prohibited them from performing much of their trademark physical comedy. Besser had suggested that Moe and Larry comb their hair back to give them a more gentlemanly appearance; while both Moe and Jules White approved of the idea, they used it sparingly. Their other films\u2014remakes of older comedies\u2014required the familiar Stooge haircuts to match the older footage.\nIn general, the remakes among the Besser shorts had the traditional Stooges knockabout, such as 1958's \"Pies and Guys\" (a scene-for-scene remake of \"Half-Wits Holiday\", which itself was a reworking of the earlier \"Hoi Polloi\"), \"Guns a Poppin\" (1957), \"Rusty Romeos\" (1957), and \"Triple Crossed\" (1959). In contrast, \"Hoofs and Goofs\" and \"Horsing Around\", both featuring a trained horse, and \"Muscle Up a Little Closer\" (all 1957) mostly resembled the sitcoms of the era. \"A Merry Mix Up\" (1957) cast the Stooges as three sets of triplets, and \"Oil's Well That Ends Well\" (1958) had no supporting cast at all, with the Stooges working entirely by themselves for the only time in their Columbia career. The musical \"Sweet and Hot\" (1958) deserves some credit for straying from the norm. The American science-fiction craze also led to three entries focusing on space travel: \"Space Ship Sappy\", \"Outer Space Jitters\" (both 1957), and \"Flying Saucer Daffy\" (1958).\nJules White finally closed the comedy-shorts unit on December 20, 1957. His final Stooge comedy was \"Flying Saucer Daffy\", filmed December 19\u201320, 1957. By the year's end, the Three Stooges were fired from Columbia Pictures after 24 years of employment.\nNo formal goodbyes or congratulatory celebrations occurred in recognition of their work and of the money that their comedies had earned for the studio. Moe visited Columbia several weeks after the dismissal to say goodbye to several executives, but was refused entry without the current year's studio pass. He later stated that it was a crushing blow to his pride.\nThe studio had enough completed Stooge films to be released over the next 18 months, though not in the order in which they were produced. The final Stooge release, \"Sappy Bull Fighters\", did not reach theaters until June 4, 1959. With no active contract in place, Moe and Larry discussed plans for a personal-appearance tour. In the meantime, Besser's wife suffered a minor heart attack and he preferred to stay local, leading him to withdraw from the act.\nComeback with Joe DeRita (1958\u20131970).\nAfter Besser's departure, Moe and Larry began looking for potential replacements. Larry suggested former Ted Healy stooge Paul \"Mousie\" Garner, but based on his tryout performance, Moe later remarked that he was \"completely unacceptable.\" Weeks later, Larry came across burlesque performer Joe DeRita, who had starred in his own series of shorts at Columbia back in the 1940s, and thought he would be a good fit.\nThe early days of television provided movie studios a place to unload a backlog of short films that they thought no longer marketable, and the Stooge films seemed perfect for the burgeoning genre. ABC had even expressed interest as far back as 1949, purchasing exclusive rights to 30 of the trio's shorts and commissioning a pilot for a potential series, \"Jerks of All Trades\". However, the success of television revivals for such names as Laurel and Hardy, Woody Woodpecker, Popeye, Tom and Jerry, and the \"Our Gang\" series in the late 1950s led Columbia to cash in again on the Stooges. In September 1958, Columbia's television subsidiary Screen Gems offered a package consisting of 78 Stooge shorts (primarily from the Curly era), which were well received.\nAn additional 40 shorts hit the market in April 1959. By September 1959, all 190 Stooge shorts were airing regularly. With so many films available for broadcast, daily television airings provided heavy exposure aimed squarely at children. Parents who had grown up seeing the same films in the theaters began to watch alongside their children. \nAfter the Curly-era shorts were found to be the most popular, Moe suggested that DeRita shave his head to accentuate his slight resemblance to Curly Howard. He adopted first a crew cut and later a completely shaven head, thus becoming \"Curly Joe\". Howard, Fine, and DeRita found themselves in great demand for personal appearances and guest shots on television. DeRita made his first nationwide appearance with the Stooges on Sunday, January 11, 1959, on the Steve Allen variety show on NBC; the Stooges re-created their \"Stand-In\" sketch, with Moe and Larry making a western movie and Curly Joe (who did not speak) as the hapless double who takes all the punishment. \nColumbia, which was still releasing Stooge shorts to theaters, cashed in on the Stooges' spectacular show-business comeback by signing the team for new feature-length films. The first, \"Have Rocket, Will Travel\" (1959), was produced by the Stooges' agent, Harry Romm. The second got off the ground when Columbia's New York office asked Jules White to prepare a new Three Stooges feature film for theaters. The result was \"Stop! Look! and Laugh!\", released in 1960. \"The Original Three Stooges\" were seen entirely in old short-subject extracts with Curly Howard, and new footage was filmed with ventriloquist Paul Winchell and animal act The Marquis Chimps.\nWhite shrugged it off as a quickie patchwork: \"I got a free trip to New York out of it. \"Stop! Look! and Laugh!\" took an awful lot of know-how and care to put together. I worked on the thing for over a month. We used to run four or five Stooges films in the evening at my house for I don't know how many months.\"\nThe Stooges were hired by Twentieth Century-Fox to co-star in a Technicolor feature with Olympic skater Carol Heiss; \"Snow White and the Three Stooges\" (1961), co-written by Noel Langley of \"The Wizard of Oz\", fell short of box office expectations, ultimately losing $2,300,000 when the domestic and international returns were tallied. The Stooges resumed making their new kiddie-matin\u00e9e features, which were now produced independently by Moe's son-in-law Norman Maurer and released through Columbia: \"The Three Stooges Meet Hercules\" (1962), \"The Three Stooges in Orbit\" (1962), \"The Three Stooges Go Around the World in a Daze\" (1963), and \"The Outlaws is Coming!\" (1965).\nThe team had an extremely brief cameo in the film \"It's a Mad, Mad, Mad, Mad World\" (1963), appearing as firemen. They appeared in a larger capacity in 1963 in \"4 for Texas\" starring Frank Sinatra and Dean Martin. Throughout the early 1960s, the Stooges were one of the most popular and highest-paid live acts in America. They played theaters, summer festivals, fairgrounds, and other venues, and twice performed as the featured act at the Canadian National Exhibition. In 1968, they toured Hawaii where they starred in the International 3-Ring Circus at the Honolulu International Center.\nThe Stooges also tried their hand at another weekly television series in 1960 titled \"The Three Stooges Scrapbook\", filmed in color and with a laugh track. The first episode, \"Home Cooking\", featured the boys rehearsing for a new television show. Like \"Jerks of All Trades\" in 1949, the pilot did not sell, though Norman Maurer was able to reuse the footage (reprocessed in black and white) for the first 10 minutes of \"The Three Stooges in Orbit\".\nThe trio also filmed 41 short comedy skits for \"The New 3 Stooges\" in 1965, which features a series of 156 animated cartoons produced for television. The Stooges appeared in live-action color footage, which preceded and followed each animated adventure in which they voiced their respective characters.\nDuring this period, the Stooges appeared on numerous television shows, including \"The Steve Allen Show\", \"Here's Hollywood\", \"Masquerade Party\", \"The Ed Sullivan Show\", \"Danny Thomas Meets the Comics\", \"The Joey Bishop Show\", \"Off to See the Wizard\", and \"Truth or Consequences\".\nFinal years (1970\u20131975).\nIn late 1969, Howard, Fine, and DeRita began production on another half-hour pilot, this time for a syndicated 39-episode TV series titled \"Kook's Tour\", a combination travelogue-sitcom that had the \"retired\" Stooges traveling to various parts of the world with the episodes filmed on location. On January 9, 1970, during production of the pilot, Larry suffered a paralyzing stroke, ending his acting career along with plans for the television series. The pilot was unfinished and several key shots were missing, but producer Norman Maurer edited the available footage and made the pilot a 52-minute special that was released to the home-movie and Cartrivision videocassette home-video markets in 1973. It is the last film in which the Stooges appeared and the last known performance of the team.\nFollowing Larry Fine's stroke, plans were made for Emil Sitka (a longtime \"straight man\" in the Stooges films) to replace him in a new feature film, written by Moe Howard's grandson, Jeffrey Scott [Maurer], titled \"Make Love, Not War\". Moe Howard, Joe DeRita, and Emil Sitka were cast as POWs in a World War II Japanese prison camp, plotting an escape with fellow prisoners. The film would have been a departure from typical Stooge fare, with dark-edged humor and scenes of war violence, but insufficient funding prevented production from advancing beyond the script stage.\nAlso in 1970, Joe DeRita recruited vaudeville veterans Frank Mitchell and Mousie Garner to tour as \"The New Three Stooges\". Garner had worked with Ted Healy as one of his \"replacement stooges\" decades earlier and was briefly considered as Joe Besser's replacement in 1958. Mitchell had appeared in two of the Stooges' short subjects in 1953, and had been part of the knockabout team of Mitchell and Durant. The act fared poorly, with minimal bookings. In 1973, DeRita performed as the comic in a burlesque revivial show in Las Vegas. By this time, Moe's wife had prevailed on him to retire from performing slapstick due to his age. For the next several years, Moe appeared regularly on talk shows and did speaking engagements at colleges and universities, while DeRita quietly retired.\nLarry suffered another stroke in mid-December 1974, and another one in January 1975, even more severe. After slipping into a coma, he died a week later from a cerebral hemorrhage on January 24, 1975.\nShortly after Larry's death, the Stooges were scheduled to co-star in the R-rated comedy \"Blazing Stewardesses,\" featuring Moe and Curly Joe with Emil Sitka in the middle spot as Harry, Larry's brother. The team was signed and publicity shots were taken, but one week prior to March's filming date, Moe was diagnosed with lung cancer and the Stooges had to back out; he died on May 4, 1975. Producer Sam Sherman briefly considered having former Stooge Joe Besser appear in his place, but ultimately decided against it. Another veteran comedy team, The Ritz Brothers, Harry and Jimmy, replaced the Stooges and performed much of their own schtick, including the precision dance routine first seen in \"Sing, Baby, Sing\" (1936), co-starring original Stooge leader Ted Healy.\nAs for the remaining original replacement stooges, Joe Besser died of heart failure on March 1, 1988, followed by Joe DeRita's death of pneumonia on July 3, 1993. Emil Sitka was announced as a Stooge, but never performed as such beyond posing for a few publicity photographs in character; he died on January 16, 1998, six months after being disabled by a stroke. As for the new three stooges, Frank Mitchell died of cardiac arrest on January 24, 1991, followed by Mousie Garner's death of a heart attack on August 8, 2004.\nLegacy and perspective.\nOver 60 years since their last short film was released, the Three Stooges remain popular. Their films have never left American television since first appearing in 1958. Authors Ted Okuda and Edward Watz assess the Stooges as hard-working comedians who were never critics' favorites, a durable act that endured several personnel changes in careers that would have permanently sidelined a less persistent act. They would not have lasted as long as they did as a unit without Moe Howard's guiding hand.\nOkuda and Watz's book \"The Columbia Comedy Shorts\" puts the Stooges' act in critical perspective:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nBeginning in the 1980s, the Stooges finally began to receive critical recognition. The release of nearly all their films on DVD by 2010 allowed critics of Joe Besser and Joe DeRita\u2014often the recipients of significant fan backlash\u2014to appreciate both men's unique styles of comedy. The DVD market has also allowed fans to view the entire Stooge film corpus as distinct periods in their long career, rather than unfairly comparing one Stooge to another (the Curly vs. Shemp debate continues to this day, with Joe Besser not even mentioned in the same breath).\nThe team appeared in 220 films, but authors Okuda and Watz agree that their series of 190 two-reel comedies for Columbia is their enduring legacy. In 1984, American television personality Steve Allen said, \"Although they never achieved widespread critical acclaim, they did succeed in accomplishing what they had always intended to do: They made people laugh.\"\nSocial commentary, satire, and use of language.\nAlthough the Three Stooges' slapstick comedy was primarily arranged around basic plots dealing with mundane issues of daily life, a number of their shorts featured social commentary or satire. They were often antiheroical commentators on class divisions and economic hardships of the Great Depression in the United States. They were usually under- or unemployed and sometimes homeless or living in shanty towns.\nThe language used by the Three Stooges was more slang-laden than that of typical feature films of the period and deliberately affected a lower-class status with use of crude terms, ethnic mannerisms, and inside jokes.\nAn example is the use of the initials A.K. for big shots and pretentious people. A.K. was an inside joke which stood for \"Alte Kocker\" (an elderly person who is defecating), a Yiddish idiom that means an old man or woman of diminished capacity who can no longer do things they used to do.\nMuch of the seeming \"gibberish\" that the Stooges sometimes spoke was actually the Yiddish language of their Jewish ancestry. The most famous example occurs 15 minutes into the 1938 short \"Mutts to You\". Moe and Larry were impersonating Chinese laundrymen in an attempt to fool the local cop. While being questioned, Larry says \"\"Ech bin \"a China \"Boychic\" from Slobatkya-Gebernya \"hak mir nisht Ken Tshaynik\" and I don't mean \"Efsher\"\". This translates as \"I'm a China boy from Slobatkya Gebernya [a made-up area in eastern Russia], so stop annoying me and I don't mean maybe.\"\nA third \"in-Yiddish\" joke is in the episode \"Pardon My Scotch\", when the liquor supplier prepares to consume the Stooges' volatile concoction, and they wish him well in a triad pattern saying \"Over the river,\" \"Skip the gutter,\" and concluding with \"\"Ver geharget\",\" a Yiddish expression meaning \"get killed\" or \"drop dead\".\nOne important area of political commentary was in the area of the rise of totalitarianism in Europe, notably in the directly satirical \"You Nazty Spy!\" and \"I'll Never Heil Again\", both released before United States' entry into World War II, despite an industry Production Code that advocated avoiding social and political issues and the negative portrayal of foreign countries.\nIn their classic 1940 short \"No Census, No Feelings\", the Stooges refer to Will H. Hays and his position as Hollywood's censor, when Moe tells Curly, \"We have a job now, we're working for the census\", and Curly replies, \"You mean Will Hays?\"\nFilmography.\nThe Three Stooges appeared in 220 films through their career. Of those, 190 short films were made for Columbia Pictures, for which the trio are best known today. Their first Columbia film, \"Woman Haters\", premiered on May 5, 1934. Their contract was extended each year until the final one expired on December 31, 1957. Columbia continued to release the Stooge shorts filmed in 1957; the final release, \"Sappy Bull Fighters\", premiered on June 4, 1959.\nC3 Entertainment, Inc..\nIn 1959, Comedy III Productions (later, C3 Entertainment) was formed by Moe, Larry, and Joe DeRita to manage all business and merchandise transactions. Now controlled by DeRita's heirs, it has diversified into a brand-management company licensing personality rights to various nostalgia acts, including the Stooges.\nTelevision.\nA handful of Three Stooges shorts first aired on television in 1949, on the ABC network. By 1958, Screen Gems packaged 78 shorts for national syndication; the package was gradually enlarged to encompass the entire library of 190 shorts. In 1959, KTTV in Los Angeles purchased the Three Stooges films for air, but by the early 1970s, rival station KTLA began airing the Stooges films, keeping them in the schedule until early 1994. The Family Channel ran the shorts as part of their \"Stooge TV\" block from February 19, 1996, to January 2, 1998. In the late 1990s, AMC had held the rights to the Three Stooges shorts, originally airing them under a programming block called \"Stooges Playhouse\". In 1999, it was replaced with a program called \"N.Y.UK (New Yuk University of Knuckleheads)\", which starred actor/comedian Leslie Nielsen. The program would show three random Stooge shorts. Nielsen hosts the program as a college instructor, known as the Professor of Stoogelogy, who teaches to the students lectures on the Three Stooges before the Stooges' shorts air. The block aired several shorts often grouped by a theme, such as similar schtick used in different films. Although the block was discontinued after AMC revamped their format in 2002, the network still ran Stooges shorts occasionally. The AMC run ended when Spike TV (now Paramount Network) picked them up in 2004, airing them in their \"Stooges Slap-Happy Hour\" every Saturday and Sunday mornings. On June 6, 2005, the network began running the \"Stooges Slap-Happy\" as a one-hour summer comedy block, which ended on September 2, 2005. By 2007, the network had discontinued the block. Although Spike did air Stooges shorts for a brief time after the block was canceled, as of late April 2008, the Stooges had disappeared from the network's schedule entirely. The Three Stooges returned on December 31, 2009, on AMC, starting with the \"Countdown with the Stooges\" New Year's Eve marathon. AMC planned to put several episodes on their website in 2010. As of 2009 AMC still airs The Three Stooges every weekday midnights and mornings. Also as of 2022 AMC's other sister channel BBC America also airs The Three Stooges on midnights each weekday. The \"Stooges\" shorts were best known in Chicago as a part of a half-hour, late-afternoon show on WGN-TV hosted by Bob Bell as \"Andy Starr\" in the 1960s. In the 1990s, Stooges films were aired as part of The Koz Zone movie segment on Chicago television.\nSince the 2000s, Columbia and its television division's successor, Sony Pictures Television, has preferred to license the Stooges shorts to cable networks, which left the films off local broadcast TV for several years until they were licensed to nationally broadcast classic TV networks. The last time the Stooges were offered in traditional broadcast syndication was in 1999, when Columbia TriStar Television Distribution put together a new package of 130 half-hour episodes compiling the shorts into themed installments, with new interstitial material created by Evolution Media and voiced by Jeff Bennett (in a similar fashion to the Screen Gems Network, a syndicated block of classic television series also offered around the same time by CTTD with Evolution's involvement).\nTwo stations in Chicago and Boston, however, signed long-term syndication contracts with Columbia years ago and had declined to terminate them. WMEU-CD in Chicago aired all 190 Three Stooges shorts on Saturday afternoons and Sunday evenings until 2014. WSBK-TV in Boston aired Stooges shorts and feature films, including an annual New Year's Eve marathon until their contract expired in September 2022; WSBK wanted to renew the contract, but Sony was unwilling to do so. KTLA in Los Angeles dropped the shorts in 1994, but brought them back in 2007 as part of a special retro-marathon commemorating the station's 60th anniversary. Since that time, the station's original 16\u00a0mm Stooges film prints have aired occasionally as part of minimarathons on holidays. Antenna TV, a network broadcasting on the digital subchannels of local broadcast stations (owned by Tribune Broadcasting, which also owns KTLA), began airing the Stooges shorts upon the network's January 1, 2011, launch, which ran in multi-hour blocks on weekends through December 29, 2012; most of the Three Stooges feature films are also broadcast on the network, through Antenna TV's distribution agreement with Sony Pictures Entertainment (whose Columbia Pictures subsidiary released most of the films). While the network stopped airing Stooges shorts regularly from 2013 to 2015, they were occasionally shown as filler if a movie ran short, as well as in holiday marathons. The shorts returned to Antenna TV's regular lineup on January 10, 2015. In 2019, the Three Stooges were picked up by MeTV as part of their lineup.\nColumbia's library of 190 Stooge shorts has been modified for television distribution. Sony no longer offers the shorts on motion-picture film, and now includes only 100 titles in the television package. All 190 shorts, however, have been released to home video.\nSome films have been colorized by two separate companies. The first colorized DVD releases, distributed by Sony Pictures Home Entertainment, were prepared by West Wing Studios in 2004, using actual costumes and props for reference. The following year, Legend Films colorized the public-domain shorts \"Malice in the Palace\", \"Sing a Song of Six Pants\", \"Disorder in the Court\", and \"Brideless Groom\". \"Disorder in the Court\" and \"Brideless Groom\" also appear on two of West Wing's colorized releases. In any event, the Columbia-produced shorts (aside from the public domain films) are handled by Sony Pictures Entertainment, while the MGM Stooges shorts are owned by Warner Bros. via their Turner Entertainment division. Sony previously offered 21 of the shorts on their streaming platform Crackle, along with 11 minisodes. Meanwhile, the rights to the Stooges' feature films rest with the studios that originally produced them (Columbia/Sony for the Columbia films, and The Walt Disney Company for the Fox Film/20th Century Fox films). In January 2024, C3 Entertainment announced that it licensed all 190 Columbia shorts from Sony Pictures Television to establish a new streaming channel, the Three Stooges+ Channel, which would also offer other Three Stooges content.\nAMC at one time would air what became known as mini-episodes: five-minute chunks from the Columbia shorts, broadcast with their original theatrical titles.\nSeries overview.\n&lt;onlyinclude&gt;&lt;/onlyinclude&gt;\nHome media.\nBetween 1980 and 1985, Columbia Pictures Home Entertainment and RCA/Columbia Pictures Home Video released 13 Three Stooges volumes in various formats. The original 13 volume titles were later reissued on VHS by its successor, Columbia TriStar Home Video, between 1993 and 1996, with a DVD reissue between 2000 and 2004.\n\"The Three Stooges Collection\".\nOn October 30, 2007, Sony Pictures Home Entertainment released a two-disc DVD set titled \"The Three Stooges Collection, Volume One: 1934\u20131936\". The set contains shorts from the first three years the Stooges worked at Columbia Pictures, marking the first time that all 19 shorts were released in their original theatrical order to DVD. Additionally, every short was remastered in high definition, a first for the Stooge films. Previous DVD releases were based on themes (wartime, history, work, etc.), and sold poorly.\nThe chronological series proved successful, and Sony wasted little time preparing the next set for release. \"Volume Two: 1937\u20131939\" was released on May 27, 2008, followed by \"Volume Three: 1940\u20131942\" three months later on August 26, 2008. Demand exceeded supply, proving to Sony that they had a hit on their hands. In response, \"Volume Four: 1943\u20131945\" was released on October 7, 2008, a mere two months after its predecessor. Volume Four, and \"Volume Five: 1946\u20131948\" was belatedly released on March 17, 2009 after delays during the Great Recession. \"Volume Five\" is the first in the series to feature Shemp Howard with the Stooges and the final volume to feature Curly Howard. \"Volume Six: 1949\u20131951\" was released June 16, 2009, and \"Volume Seven: 1952\u20131954\" was released on November 10, 2009. \"Volume Seven\" included 3-D glasses for the two shorts: \"Spooks!\" and \"Pardon My Backfire\". As of 2013, the three-dimensional versions of the two shorts in this volume have been removed. \"Volume Eight: 1955\u20131959\" was released on June 1, 2010. This was the final volume of the Stooges collection, bringing the series to a close. \"Volume Eight\" comprised three discs, and was the only volume to feature Joe Besser and the final volume to feature Shemp Howard. With the release of the eighth volume, for the first time in history, all 190 Three Stooges short subjects had become available to the public, uncut and unedited.\nTwo years later, on June 5, 2012, these discs were reissued in a DVD boxed set entitled \"The Three Stooges: The Ultimate Collection\"\u2014now with a ninth volume (three discs) entitled \"Rare Treasures from the Columbia Picture Vault\". This volume is not available separately, and comprises two feature films and three cartoons featuring all three Stooges, and also some of their solo work (14 shorts featuring Shemp Howard, 10 shorts featuring Joe Besser, and four shorts featuring Joe DeRita). The 2012 Ultimate Collection consists of all 8 individual original boxsets as they sold before, plus the 3 bonus discs, housed in a thin cardboard box with embossed artwork. On October 18, 2016, The Three Stooges: The Complete DVD Collection was released. It had all the DVDs from volumes 1 through 8 but it did not include the \"Rare Treasures from the Columbia Picture Vault\" discs. The packaging is much smaller as all 17 of the original discs are stacked on a spindle. All eight volumes are also available on iTunes. On June 15, 2020, iTunes released The Three Stooges: The Complete Series, which features all 190 shorts in an entire collection.\nOn July 23, 2024, 100 of the shorts were released on Blu-ray for the 100th anniversary (this boxset omits 90 shorts which are still only available on DVD at present time).\nMusic.\nThree feature-length Columbia releases were actually packages of older Columbia shorts. \"Columbia Laff Hour\" (introduced in 1956) was a random assortment that included the Stooges among other Columbia comedians like Andy Clyde, Hugh Herbert, and Vera Vague; the content and length varied from one theater to the next. \"Three Stooges Fun-o-Rama\" (introduced in 1959) was an all-Stooges show capitalizing on their TV fame, again with shorts chosen at random for individual theaters. \"The Three Stooges Follies\" (1974) was similar to \"Laff Hour\", with a trio of Stooge comedies augmented by Buster Keaton and Vera Vague shorts, a Batman serial chapter, and a Kate Smith musical.\nMuseum.\nGary Lassin, grandnephew-in-law of Larry Fine, opened the Stoogeum in 2004 in Spring House, Pennsylvania, north of Philadelphia. It features three floors of exhibits and an 85-seat theater. Peter Seely, editor of the book \"Stoogeology: Essays on the Three Stooges,\" said that the Stoogeum has \"more stuff than I even imagined existed.\" Some 2,500 people visit it yearly, many during the annual Three Stooges Fan Club gathering in April.\nIn other media.\nComic books.\nOver the years, several Three Stooges comics were produced.\nPhonograph records.\nBeginning in 1959, the Three Stooges began appearing in a series of novelty records. Their first recording was a 45 rpm single of the title song from \"Have Rocket, Will Travel.\" The trio released additional singles and LPs on the Golden, Peter Pan, and Coral labels, mixing comedy adventure albums and off-beat renditions of children's songs and stories. Their final recording was the 1966 \"Yogi Bear and the Three Stooges Meet the Mad, Mad, Mad Dr. No-No\", which incorporated the Three Stooges into the cast of the Yogi Bear cartoons.\nRadio.\nSirius XM Radio aired a special about the Stooges hosted by Tom Bergeron on Friday, July 31, 2009, at 2:00 pm on the Sirius Howard 101 channel. Bergeron had conducted the interviews at the age of 16 when he was still in high school in 1971. The television host had the tapes in storage for many years and was convinced on air during an interview with Howard Stern to bring them in and turn them into a special.\nAfter finding \"the lost tapes\", Bergeron brought them into Stern's production studio. He stated that the tapes were so old that the tapes with the Larry Fine interviews began to shred as Stern's radio engineers ran them on their tape players. They really had only one shot, but the tapes were saved.\n\"The Lost Stooges Tapes\" was hosted by Tom Bergeron, with modern commentary on the almost 40-year-old interviews that he had conducted with Larry Fine and Moe Howard. At the times of these interviews, Moe was still living at home, while Larry had suffered a stroke and was living in a senior citizen's home.\nTelevision.\n\"The New Three Stooges\" (1965\u201366).\nIn addition to the unsuccessful television series pilots \"Jerks of All Trades\", \"The Three Stooges Scrapbook\", and the incomplete \"Kook's Tour\", the Stooges appeared in an animated series, \"The New Three Stooges\", which ran from 1965 to 1966. This series featured a mix of 41 live-action segments that were used as wraparounds to 156 animated Stooges shorts. \"The New Three Stooges\" became the only regularly scheduled television show for the Stooges. Unlike other films shorts that aired on television, like the \"Looney Tunes\", \"Tom and Jerry\", and \"Popeye\", the film shorts of the Stooges never had a regularly scheduled national television program in which to air. When Columbia/Screen Gems licensed the film library to television, the shorts aired in any fashion the local stations chose (examples: late-night \"filler\" material between the end of the late movie and the channel's sign-off time; in \"marathon\" sessions running shorts back-to-back for one, one-and-a-half, or two hours; etc.) By the 1970s, some local stations showed a Columbia short and a \"New Three Stooges\" cartoon in the same broadcast.\n\"The Robonic Stooges\" (1977\u201378).\nAnother animated series also produced by Hanna-Barbera, titled \"The Robonic Stooges\", originally seen as a featured segment on \"The Skatebirds\" (CBS, 1977\u20131978), featuring Moe, Larry, and Curly (voiced by Paul Winchell, Joe Baker, and Frank Welker, respectively) as bionic cartoon superheroes with extendable limbs, similar to the later \"Inspector Gadget\". \"The Robonic Stooges\" later aired as a separate half-hour series, retitled \"The Three Robonic Stooges\" (each half-hour featured two segments of \"The Three Robonic Stooges\" and one segment of \"Woofer &amp; Whimper, Dog Detectives\", the latter re-edited from episodes of \"Clue Club\", an earlier Hanna-Barbera cartoon series).\n\"The Three Stooges\" (TBA).\nOn June 9, 2015, C3 Entertainment announced it is partnering with London-based production company Cake Entertainment and animation house Titmouse, Inc. to produce a new animated Three Stooges series, consisting of 52 11-minute episodes. Christy Karacas (co-creator of \"Superjail!\") directed the pilot episode, with Earl and Robert Benjamin, Chris Prynoski, Tom van Waveren, and Edward Galton executive producing. The series was to be launched to potential buyers at the market of the Annecy International Animated Film Festival.\nOther appearances.\nIn the October 13, 1967, \"Who's Afraid of Mother Goose?\" episode of ABC's \"World-of-Disney\"-like anthology series \"Off to See the Wizard\", the Three Stooges made a short appearance as \"the three men in a tub\".\nTwo episodes of Hanna-Barbera's \"The New Scooby-Doo Movies\" aired on CBS featuring animated Stooges as guest stars: the premiere, \"Ghastly Ghost Town\" (September 9, 1972) and \"The Ghost of the Red Baron\" (November 18, 1972).\nIn a 1980 episode of \"M*A*S*H\", Charles Winchester shows disrespect for three Korean doctors by calling them \"Moe, Larry, and Curly\", and says that they are \"highly respected individuals in the States\". After Winchester throws out his back and is unable to relieve the pain through conventional methods, Colonel Potter has the Korean doctors try acupuncture (much to Winchester's dismay), which cures Winchester. After the treatment, one of the doctors tells Winchester \"Not bad for Three Stooges, huh?\", having caught on to his mistreatment of them.\nIn the episode \"Beware the Creeper\" of \"The New Batman Adventures\", the Joker retreats to his hideout after a quick fight with Batman. He yells out for his three henchmen \"Moe? Larr? Cur?\", only to find that they are not there. Shortly after that, Batman comes across these three goons in a pool hall; they have distinctive accents and hairstyles similar to those of Moe, Larry, and Curly. These henchmen are briefly seen throughout the rest of the season.\nTelevision film (2000).\nIn 2000, long-time Stooge fan Mel Gibson executive-produced a TV film (\"The Three Stooges\") about the lives and careers of the comedians. Playing Moe was Paul Ben-Victor, Evan Handler was Larry, John Kassir was Shemp, and Michael Chiklis was Curly. It was filmed in Australia and was produced for and broadcast on ABC. It was based on Michael Fleming's authorized biography of the Stooges, \"The Three Stooges: From Amalgamated Morons to American Icons\". Its unflattering portrayal of Ted Healy led Healy's son to give media interviews calling the film inaccurate. Additional errors of fact included the portrayal that Moe Howard was down on his luck after Columbia canceled their contract and worked as a gofer at the studio, where his brothers, Larry, and he had formerly worked as actors. In reality, Moe was the most careful with his money, which he invested well. His wife Helen and he owned a comfortable house in Toluca Lake, in which they raised their children.\nFilm.\n\"It's a Mad, Mad, Mad, Mad World\" (1963).\nThe Three Stooges (in their Curly Joe period) made a brief cameo appearance as airport firemen in the 1963 film \"It's a Mad, Mad, Mad, Mad World\". An epic comedy with an all-star cast, this film contains many cameo appearances by famous comedians.\n\"The Three Stooges\" (2012).\nA film featuring the Three Stooges, titled \"The Three Stooges\", started production on March 14, 2011, with 20th Century Fox and was directed by the Farrelly brothers. The film had been in what one critic has dubbed \"development hell\". The Farrellys, who wanted to make the film since 1996, said that they were not going to do a biopic or remake, but instead new Three Stooges episodes set in the present day. The film is broken up into three continuous episodes that revolves around the Stooges characters.\nCasting the title characters proved difficult for the studio. Originally slated were Sean Penn to play Larry, Benicio del Toro to play Moe, and Jim Carrey to play Curly. Both Penn and del Toro left the project, but returned while no official confirmation had been made about Jim Carrey. When del Toro was interviewed on MTV News for \"The Wolfman\", he spoke about playing Moe. He was later asked who was going to play Larry and Curly in the film and commented that he still thought that Sean Penn and Jim Carrey were going to play them, though he added, \"Nothing is for sure yet.\"\nA story in \"The Hollywood Reporter\" stated that Will Sasso would play Curly in the upcoming comedy and that Hank Azaria was the frontrunner to play Moe. Sasso was ultimately cast as Curly; Sean Hayes of \"Will &amp; Grace\" was cast as Larry Fine, while Chris Diamantopoulos was cast as Moe. Jane Lynch later joined the cast, playing a nun. The film was released on April 13, 2012, and grossed over $54 million worldwide. The film received mixed reviews, but Diamantopoulos, Hayes, and Sasso were praised for their performances as Moe, Larry, and Curly.\nSequel.\nOn May 7, 2015, a sequel was announced, with Sean Hayes, Chris Diamantopoulos, and Will Sasso all reprising their roles. Cameron Fay has been hired to write the script. Production was scheduled to begin in 2018.\n\"The Three Little Stooges\" (TBA).\nOn February 3, 2016, C3 announced a new comedy/adventure film titled \"The Three Little Stooges\". It was to star Gordy De StJeor, Liam Dow, and Luke Clark as 12-year-old versions of Moe, Larry, and Curly. The first film, which set the foundation for future films and television spin-offs, was set to begin production in November 2017, and was expected to be released in 2018. The screenplay was written by Harris Goldberg, with Sean McNamara set to direct. The film's budget is $5.8 million. On July 19, 2017, C3 began seeking crowdfunding to pay for a portion of the budget. In August 2017, they exceeded their minimum goal of $50,000.\nVideo games.\nIn 1984, Gottlieb released an arcade game featuring the Stooges trying to find three kidnapped brides.\nLater in 1987, game developer Cinemaware released a successful Three Stooges computer game, available for Apple IIGS, Amiga, Commodore 64, MS-DOS, and Nintendo Entertainment System. Based on the Stooges earning money by doing odd jobs to prevent the foreclosure of an orphanage, it incorporated audio from the original films and was popular enough to be reissued for the Game Boy Advance in 2002, and for PlayStation in 2004.\nThe Three Stooges also have a slot-game adaptation created by Realtime Gaming.\nVCR game.\nA VCR game was released by Pressman Toy Corporation in 1986, which used a number of classic Stooges clips.\nIn foreign languages.\nIn most other languages, the Three Stooges are known by some corresponding variant of their English name. In Chinese, however, the trio is known idiomatically as \"S\u0101nge Ch\u00f2u P\u00edji\u00e0ng\" () or \"Hu\u00f3b\u01ceo S\u0101nr\u00e9nz\u01d4\" (\u6d3b\u5bf6\u4e09\u4eba\u7d44). \"S\u0101nge Ch\u00f2u P\u00edji\u00e0ng\", literally \"Three Smelly Shoemakers\", which derives from a saying in the \"Romance of the Three Kingdoms\": \"S\u0101ng\u00e8 ch\u00f2u p\u00edji\u00e0ng sh\u00e8nggu\u00f2 y\u012bg\u00e8 Zh\u016bg\u011b Li\u00e0ng\" (\u4e09\u500b\u81ed\u76ae\u5320\uff0c\u52dd\u904e\u4e00\u500b\u8af8\u845b\u4eae) or \"Three smelly shoemakers (are enough to) overcome one Zhuge Liang [a hero of the story]\", i.e. three inferior people can overpower a superior person when they combine their strength. \"Hu\u00f3b\u01ceo S\u0101nr\u00e9nz\u01d4\" translates as \"Trio of Buffoons\". Likewise in Japanese they are known as \"San Baka Taish\u014d\" () meaning \"Three Idiot Generals\" or \"Three \"Baka\" Generals\".\nIn Spanish, they are known as ' or, roughly, \"The Three Crackpots\". In French and German usage, the name of the trio is partially translated as ' (though the French version of the movie adaptation used a fully translated name, \"Les Trois Corniauds\") and ' respectively. In Italy they are known as '. In Thai, the trio is known as (RTGS:\u00a0, ) or \"3 \u0e1e\u0e35\u0e48\u0e19\u0e49\u0e2d\u0e07\u0e08\u0e2d\u0e21\u0e22\u0e38\u0e48\u0e07\" (RTGS:\u00a0, ). In Portuguese, they are known as ' in Brazil, and ' in Portugal, \"estarola\" being a direct translation of \"stooge\", while \"pateta\" being more related to \"goofy\". In Persian the trio are dubbed as \"\u0633\u0647 \u06a9\u0644\u0647 \u067e\u0648\u06a9\". In Turkish, they are dubbed as \"\u00dc\u00e7 Ahbap \u00c7avu\u015f\" (\"The Three Cronies\").\nAwards and nominations.\nTheir Men in Black (1934 film) received the comedy nomination Academy Award for Best Live Action Short Film.\nIn 1993, the Three Stooges won the MTV Lifetime Achievement Award.\nThey received a star on the Hollywood Walk of Fame at 1560 Vine Street on August 30, 1983.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36819", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=36819", "title": "Laetitia Casta", "text": "French actress and model\nLaetitia Marie Laure Casta (; born 11 May 1978) is a French model and actress.\nCasta became a \"GUESS? Girl\" in 1993 and gained further recognition as a Victoria's Secret Angel from 1998 to 2000 and as a spokesperson for cosmetics company L'Or\u00e9al. She has appeared on over 250 covers of such popular magazines as \"Cosmopolitan\", \"Vogue\", \"Rolling Stone\", \"Elle\" and \"Glamour\", and has walked runways for designers such as Yves Saint Laurent, Jean-Paul Gaultier, Chanel, Dior, Dolce &amp; Gabbana, Paco Rabanne, Kenzo, Louis Vuitton, Christian Lacroix, Roberto Cavalli, Jacquemus, Ralph Lauren and Vivienne Westwood.\nAs an actress, Casta appeared in such films as \"Asterix and Obelix vs. Caesar\" (1999), \"Born in 68\" (2008), \"Face\" (2009), \"\" (2010), which earned her a nomination for the C\u00e9sar Award for Best Supporting Actress, \"Arbitrage\" (2012), \"A Faithful Man\" (2018) and \"The Crusade\" (2021).\nEarly life.\nLaetitia Casta was born in Pont-Audemer, Normandy. Her mother, Line Blin, is from Normandy. Her father, Dominique Casta, is from Corsica. Casta has an older brother, Jean-Baptiste, and a younger sister, Marie-Ange. She spent her childhood in Normandy and Corsica.\nLaetitia has one quarter Italian ancestry from her father.\nCareer.\nModeling.\nCasta's modeling career reportedly began when she was discovered at age 15 by the photographer Fr\u00e9d\u00e9ric Cresseaux, after winning a village beauty pageant during a family holiday in her father's native Corsica She had been unknowingly signed up for the pageant by her brother Jean-Baptiste.\nCasta has been the L'Or\u00e9al Paris brand ambassador since 1998. She has been featured in Pantene, Guess?, Tommy Hilfiger, Valentino, Givenchy, Ralph Lauren, Cacharel, Lolita Lempicka, Chanel, Dolce and Gabbana, Nina Ricci, Swarovski, Yves Saint Laurent, Louis Vuitton, Roberto Cavalli, Jacquemus, J. Crew, Tiffany &amp; Co., Loewe, Bvlgari, Giorgio Armani, H&amp;M, Miu Miu, Pepe Jeans, Escada, Alberta Ferretti and XOXO ad campaigns. She has appeared on more than 250 magazine covers including \"Harper's Bazaar\", \"Elle\", \"Marie Claire\", \"Glamour\", \"Cosmopolitan\", \"Vanity Fair\", \"i-D\", \"Rolling Stone\" and \"Vogue\" (Paris, Espa\u00f1a, Germany, Russia and Turkey). Casta was the last muse of fashion designer Yves Saint Laurent, serving as the bride in his fashion shows from 1998 to 2001. She walked down the annual Victoria's Secret Fashion Show in 1997, 1998, 1999, and 2000. She was one of the company's signature Victoria' Secret Angels from 1998 to 2000. She claims that her career with Victoria's Secret ended because she was \"too much of [a] rebel\". She also appeared in \"Sports Illustrated Swimsuit Issue\" three consecutive times, as well at the Pirelli Calendar 1999 by Herb Ritts, 2000 by Annie Leibovitz and 2019 by Albert Watson.\nShe is the face of fragrances Chanel's \"Allure\", Givenchy's \"Forbidden flower\", Lolita Lempicka's \"Lolita\", Cacharel's \"Promise\", Bulgari's \"BLV II\", Ralph Lauren's \"Notorious\", Yves Saint Laurent's \"Baby doll\" and \"Paris\", Nina Ricci's \"L'Extase\" and D&amp;G's \"Pour Femme\". The Parisians could follow her Adventures in the Galeries Lafayette by Jean-Paul Goude. For Christmas 2011, Peter Lindbergh shot \"True Love\", the very thought of Casta at the summit of Manhattan and between the snowy lions of marble of the New York Public Library for Tiffany &amp; Co.\nOn 10 March 2010, in Paris, she opened the Louis Vuitton fall/winter 2010 fashion show. On 27 September 2010, she closed the Roberto Cavalli spring/summer 2011 fashion show in Milan. On 18 January 2020, in Paris, she opened Jacquemus fall/winter 2020 fashion show. In September 2020, Casta appeared in the fall/winter ad campaign for Yves Saint Laurent and for Valentino.\nShe was ranked as an \"Industry Icon\" by models.com, and was ranked as a \"New Super\" .\nActing.\nHer first role was as Falbala in \"Asterix &amp; Obelix Take On Caesar\" directed by Claude Zidi, a live-action adaptation of the comic book \"Asterix\", in which Obelix, portrayed by G\u00e9rard Depardieu, plays Casta's love interest. Casta appeared in \"Les Ames Fortes\", directed by Raul Ruiz. Her performance as Brigitte Bardot in the movie \"Gainsbourg (Vie heroique)\" earned her a Cesar Award nomination. Casta served as a jury member at the 69th Venice International Film Festival in 2012.\nMarianne controversy.\nIn 1999, Casta was ranked first in a national survey ordered by the French Mayors' Association to decide who should be the new model for the bust of \"Marianne\", an allegorical symbol of the French Republic, which stands inside every French town hall. Casta became the focus of a controversy when, after being selected to be Marianne, newspapers in Britain and France reported that she had relocated to London where taxes on high earners are lower. Casta's father said she went to London for professional reasons; on a TV show, she also said that she rented a flat in London to be near her boyfriend. The French minister of the interior spoke about Casta on the radio; comparing the advantages of living in France with regard to the drawbacks of London after political opponents used Casta's relocation to London as an opportunity to criticise the government.\nPolitical involvement.\nOn 6 April 2008, Casta demonstrated in a White March of nonviolent protest to ask for the immediate release of Ingrid Betancourt, presidential candidate kidnapped since 2002 by the FARC.\nOn 30 April 2002, she attended the demonstration \"Vive la R\u00e9publique\" after the first round election of the 2002 presidential election.\nShe was appointed as a UNICEF Goodwill Ambassador on 9 December 2016.\nPersonal life.\nOn 19 October 2001, Casta gave birth to a daughter, whose father was her boyfriend, the photographer Stephane Sednaoui. Casta was engaged to Italian actor Stefano Accorsi, with whom she has a son born in 2006 and a daughter born in 2009.\nIn June 2017, Casta married her boyfriend of two years, French actor Louis Garrel; in 2021, she gave birth to a son.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "36820", "revid": "28821812", "url": "https://en.wikipedia.org/wiki?curid=36820", "title": "Mt. Vesuvius", "text": ""}
{"id": "36821", "revid": "14423536", "url": "https://en.wikipedia.org/wiki?curid=36821", "title": "Sutter's Mill", "text": "Location of gold discovery that started the California gold rush in 1848\nSutter's Mill was a water-powered sawmill on the bank of the South Fork American River in the foothills of the Sierra Nevada in California. It was named after its owner John Sutter. A worker constructing the mill, James W. Marshall, found gold there in 1848. This discovery set off the California gold rush (1848\u20131855), a major event in the history of the United States.\nThe mill was later reconstructed in the original design and today forms part of Marshall Gold Discovery State Historic Park in Coloma, California. A meteorite fall in 2012 landed close to the mill; the recovered fragments were named the Sutter's Mill meteorite.\nHistory.\nThe territory of Alta California, which includes modern-day California, was settled by the Viceroyalty of New Spain from 1683 onwards. It became part of an independent Mexico in 1821. John Sutter, a German-Swiss settler, arrived in the region in 1839. He established a colony at New Helvetia (now part of Sacramento), in the Central Valley. The United States conquered the region during the Mexican\u2013American War (1846\u20131848): California was overrun by US forces in 1846 and a ceasefire in the region was agreed in January 1847. A peace treaty for the wider war had not yet been completed when Sutter decided to begin construction of a sawmill in the forest about 30 miles northeast of his existing colony. Sutter employed James Wilson Marshall, a carpenter originally from New Jersey, to supervise construction of the new building.\nOn January 24, 1848, while working on construction of the mill, Marshall found flakes of gold in the South Fork American River. On February 2, 1848, before news of the discovery had arrived, the Treaty of Guadalupe Hidalgo was signed in Mexico City. This peace treaty formally transferred sovereignty over the region to the United States. Two workers at the mill, Henry Bigler and Azariah Smith, were veterans of the Mormon Battalion and recorded their experience in journals. Bigler recorded the date when gold was discovered, January 24, 1848, in his diary. Sutter's claim to the US government for mineral rights was investigated by Joseph Libbey Folsom, who issued confirmation of the gold discovery in June. The first flake found by Marshall was shipped to President James K. Polk in Washington D.C., arriving in August 1848. It is now on display in the National Museum of American History, part of the Smithsonian Institution.\nAs news of the gold spread, settlers flocked to the new US territory of California. The population expanded from 14,000 non-natives in 1848 to 224,000 in 1852. There were over 80,000 newcomers in 1849 and another 91,000 in 1850. Many settled at the new town of Coloma, California, which sprung up close to Sutter's Mill. Numerous further discoveries of gold in California were made. During the next seven years, approximately 300,000 people came to California (half by land and half by sea) to seek their fortunes from either mining for gold or selling supplies to the prospectors. This California gold rush permanently changed the territory, both through mass immigration and the economic effects of the gold. California became a US state in 1850.\nIndians fled Sutter's Mill, leaving no one to harvest wheat. Miners plundered his livestock and stole his millstones, and Sutter went bankrupt.\nCurrent status.\nThe site of the mill is part of the Marshall Gold Discovery State Historic Park, registered as California Historical Landmark number 530.\nOn September 8, 1965, a groundbreaking was held to begin the construction of a replica of the original structure, based on Marshall's own drawings and a photograph of the mill taken circa 1850. The replica was nearly completed by the following year, and while not built at the exact spot as the original, it was designed to be moved there if the river returned to its 1848 stream bed. The newly completed replica was officially dedicated on January 21, 1968. In 2014, the 1960s structure was replaced with a new replica, built closer to the original site.\nMeteorite.\nOn April 22, 2012 a meteor entered the Earth's atmosphere and exploded, showering meteorite fragments over parts of California and Nevada. The first samples of this meteorite fall were recovered close to Sutter's Mill, so it was named the Sutter's Mill meteorite. Several dozen fragments were eventually identified, with a total weight of about a kilogram(\u22482.2 pounds). The meteorite is classified as a carbonaceous chondrite and contains some of the oldest known material in the Solar System.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36822", "revid": "44217690", "url": "https://en.wikipedia.org/wiki?curid=36822", "title": "Sutter's Fort", "text": "Historic park in Sacramento, California\nSutter's Fort was a 19th-century agricultural and trade colony in the Mexican \"Alta California\" province. Established in 1839, the site of the fort was originally part of a utopian colonial project called New Helvetia (\"New Switzerland\") by its builder John Sutter, though construction of the fort proper would not begin until 1841. The fort was the first non-Indigenous community in the California Central Valley, and saw grave mistreatment of Indigenous laborers in plantation or feudal style conditions. The fort is famous for its association with the Donner Party, the California gold rush, and the formation of the city of Sacramento, surrounding the fort. It is notable for its proximity to the end of the California and Siskiyou Trails, which it served as a waystation.\nIn modern times, the adobe structure has been restored to its original condition () and is now administered by California Department of Parks and Recreation. It was designated a National Historic Landmark in 1961.\nHistory.\nTo build his colony, John Sutter secured a 50,000-acre land grant in the Central Valley from the Mexican governor. The main building of the fort, a two-story adobe structure built between 1841 and 1843, was constructed using Indigenous forced labor. It is the only original surviving structure at the reconstructed Sutter's Fort State Historic Park. On January 28, 1848, James Marshall met privately with John Sutter inside this building to show him the gold found during the construction of Sutter's Mill along the American River four days earlier. Sutter built the original fort with walls thick and between 15 and high. Pioneers began settling at Sutter's Fort around 1841. Following the start of the California Gold Rush, the fort was largely deserted by the 1850s and fell into disrepair.\nConstruction.\nThe party led by John Sutter landed on the bank of the American River in August 1839. The group included three Europeans and a Native American boy, probably to serve as interpreter. Some of the first people brought to the colony were Native Hawaiian workers, called Kanakas. Sutter had entered a contract with the governor of Hawaii to import and use the labor of these eight men and two women for three years. Once the first camp was set up, Sutter used local Miwok, Nisenan, and \"missionized\" Native Californians to build the first building, a three-room adobe.\nAgricultural colony.\nOnce the fort was built, Sutter established an agricultural colony with labor structures similar to Southern plantations and European feudalism. The colony relied on ranching and growing wheat crops. European colonists oversaw Native Californian and Native Hawaiian workers, who were often gravely mistreated. Sutter employed a caste system to ensure that the minority European settlers maintained control over the colony. Although some of the laborers worked voluntarily, many were subjected to brutal conditions that resembled enslavement or serfdom.\nDecline.\nAfter gold was discovered at Sutter's Mill (also owned by John Sutter) in Coloma on January 24, 1848, the fort was abandoned.\nPreservation.\nIn 1891, the Native Sons of the Golden West, who sought to safeguard many of the landmarks of California's pioneer days, purchased and rehabilitated Sutter's Fort when the City of Sacramento sought to demolish it. Repair efforts were completed in 1893 and the fort was given by the Native Sons of the Golden West to the State of California. In 1947, the fort was transferred to the authority of California State Parks as Sutter's Fort State Historic Park.\nMost of the original neighborhood structures were initially built in the late 1930s as residences, many of which have been converted to commercial uses such as private medical practices. The history of the neighborhood is largely residential.\nGeography and hydrology.\nSutter's Fort is located on level ground at an elevation of approximately above mean sea datum. The slope elevation decreases northward toward the American River and westward toward the Sacramento River. Slope elevation gradually increases to the south and east, away from the rivers. All surface drainage flows toward the Sacramento River. Groundwater in the vicinity flows south-southwest toward the Sacramento Delta. However, after peak rainfall, the Sacramento River swells and the groundwater flow can actually reverse away from the river.\nSutter's Landing.\nSutter's Landing is the spot the Captain John A. Sutter landed in August 1839 at the American River after coming up the Sacramento River from Yerba Buena at . After landing, Sutter built a base camp, then Sutter's Fort. The site of the landing is California Historical Landmark #591 that was listed on May 22, 1957.\nColoma Road.\nThe old Coloma Road opened in 1847, it ran from Sutter's Fort to the city of Coloma. Marshall traveled the road to tell of his gold find to Captain John A. Sutter. During the 49ers gold rush thousands of miners traveled the road heading out to look for gold and claims. Coloma Road at Sutter's Fort is a California Historical Landmark No. 745. There are two other Coloma Road California Historical Landmarks: Coloma Road, Rescue California Historical Landmark, No. 748, in Coloma and California Historical Landmark No. 747 at Marshall Gold Discovery State Historic Park. California's first stage line, California Stage Company, traveled the road starting in 1849, the line was founded by James E. Birch.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36823", "revid": "50141841", "url": "https://en.wikipedia.org/wiki?curid=36823", "title": "BWT", "text": "BWT may refer to \nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "36826", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=36826", "title": "Dekker's algorithm", "text": "Mutual exclusion algorithm\nDekker's algorithm is the first known correct solution to the mutual exclusion problem in concurrent programming where processes only communicate via shared memory. The solution was attributed to Dutch mathematician Th. J. Dekker by Edsger W. Dijkstra in an unpublished paper on sequential process descriptions and his manuscript on cooperating sequential processes. It allows two threads to share a single-use resource without conflict, using only shared memory for communication.\nIt avoids the strict alternation of a naive turn-taking algorithm, and was one of the first mutual exclusion algorithms to be invented.\nOverview.\nIf two processes attempt to enter a critical section at the same time, the algorithm will allow only one process in, based on whose turn it is. If one process is already in the critical section, the other process will busy wait for the first process to exit. This is done by the use of two flags, wants_to_enter[0] and wants_to_enter[1], which indicate an intention to enter the critical section on the part of processes 0 and 1, respectively, and a variable turn that indicates who has priority between the two processes.\nDekker's algorithm can be expressed in pseudocode, as follows.\nProcesses indicate an intention to enter the critical section which is tested by the outer while loop. If the other process has not flagged intent, the critical section can be entered safely irrespective of the current turn. Mutual exclusion will still be guaranteed as neither process can become critical before setting their flag (implying at least one process will enter the while loop). This also guarantees progress as waiting will not occur on a process which has withdrawn intent to become critical. Alternatively, if the other process's variable was set, the while loop is entered and the turn variable will establish who is permitted to become critical. Processes without priority will withdraw their intention to enter the critical section until they are given priority again (the inner while loop). Processes with priority will break from the while loop and enter their critical section.\nDekker's algorithm guarantees mutual exclusion, freedom from deadlock, and freedom from starvation. Let us see why the last property holds. Suppose p0 is stuck inside the while wants_to_enter[1] loop forever. There is freedom from deadlock, so eventually p1 will proceed to its critical section and set turn = 0 (and the value of turn will remain unchanged as long as p0 doesn't progress). Eventually p0 will break out of the inner while turn \u2260 0 loop (if it was ever stuck on it). After that it will set wants_to_enter[0] to true and settle down to waiting for wants_to_enter[1] to become false (since turn = 0, it will never do the actions in the while loop). The next time p1 tries to enter its critical section, it will be forced to execute the actions in its while wants_to_enter[0] loop. In particular, it will eventually set wants_to_enter[1] to false and get stuck in the while turn \u2260 1 loop (since turn remains 0). The next time control passes to p0, it will exit the while wants_to_enter[1] loop and enter its critical section.\nIf the algorithm were modified by performing the actions in the while wants_to_enter[1] loop without checking if turn = 0, then there is a possibility of starvation. Thus all the steps in the algorithm are necessary.\nNotes.\nOne advantage of this algorithm is that it doesn't require special test-and-set (atomic read/modify/write) instructions and is therefore highly portable between languages and machine architectures. One disadvantage is that it is limited to two processes and makes use of busy waiting instead of process suspension. (The use of busy waiting suggests that processes should spend a minimum amount of time inside the critical section.)\nModern operating systems provide mutual exclusion primitives that are more general and flexible than Dekker's algorithm. However, in the absence of actual contention between the two processes, the entry and exit from critical section is extremely efficient when Dekker's algorithm is used.\nMany modern CPUs execute their instructions in an out-of-order fashion; even memory accesses can be reordered (see memory ordering). This algorithm won't work on SMP machines equipped with these CPUs without the use of memory barriers.\nAdditionally, many optimizing compilers can perform transformations that will cause this algorithm to fail regardless of the platform. In many languages, it is legal for a compiler to detect that the flag variables wants_to_enter[0] and wants_to_enter[1] are never accessed in the loop. It can then remove the writes to those variables from the loop, using a process called loop-invariant code motion. It would also be possible for many compilers to detect that the \"turn\" variable is never modified by the inner loop, and perform a similar transformation, resulting in a potential infinite loop. If either of these transformations is performed, the algorithm will fail, regardless of architecture.\nTo alleviate this problem, volatile variables should be marked as modifiable outside the scope of the currently executing context. For example, in C, C++, C# or Java, one would annotate these variables as 'volatile'. Note however that the C/C++ \"volatile\" attribute only guarantees that the compiler generates code with the proper ordering; it does not include the necessary memory barriers to guarantee in-order \"execution\" of that code. C++11 atomic variables can be used to guarantee the appropriate ordering requirements \u2014 by default, operations on atomic variables are sequentially consistent so if the wants_to_enter and turn variables are atomic a naive implementation will \"just work\". Alternatively, ordering can be guaranteed by the explicit use of separate fences, with the load and store operations using a relaxed ordering.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36827", "revid": "49941710", "url": "https://en.wikipedia.org/wiki?curid=36827", "title": "Mutual exclusion", "text": "In computing, restricting data to be accessible by one thread at a time\nIn computer science, mutual exclusion is a property of concurrency control, which is instituted for the purpose of preventing race conditions. It is the requirement that one thread of execution never enters a critical section while a concurrent thread of execution is already accessing said critical section, which refers to an interval of time during which a thread of execution accesses a shared resource or shared memory.\nThe shared resource is a data object, which two or more concurrent threads are trying to modify (where two concurrent read operations are permitted but, no two concurrent write operations or one read and one write are permitted, since it leads to data inconsistency). Mutual exclusion algorithms ensure that if a process is already performing write operation on a data object [critical section] no other process/thread is allowed to access/modify the same object until the first process has finished writing upon the data object [critical section] and released the object for other processes to read and write upon.\nThe requirement of mutual exclusion was first identified and solved by Edsger W. Dijkstra in his seminal 1965 paper \"Solution of a problem in concurrent programming control\", which is credited as the first topic in the study of concurrent algorithms.\nA simple example of why mutual exclusion is important in practice can be visualized using a singly linked list of four items, where the second and third are to be removed. The removal of a node that sits between two other nodes is performed by changing the \"next\" pointer of the previous node to point to the next node (in other words, if node i is being removed, then the \"next\" pointer of node \"i\" \u2013 1 is changed to point to node \"i\" + 1, thereby removing from the linked list any reference to node i). When such a linked list is being shared between multiple threads of execution, two threads of execution may attempt to remove two different nodes simultaneously, one thread of execution changing the \"next\" pointer of node \"i\" \u2013 1 to point to node \"i\" + 1, while another thread of execution changes the \"next\" pointer of node i to point to node \"i\" + 2. Although both removal operations complete successfully, the desired state of the linked list is not achieved: node \"i\" + 1 remains in the list, because the \"next\" pointer of node \"i\" \u2013 1 points to node \"i\" + 1.\nThis problem (called a \"race condition\") can be avoided by using the requirement of mutual exclusion to ensure that simultaneous updates to the same part of the list cannot occur.\nThe term mutual exclusion is also used in reference to the simultaneous writing of a memory address by one thread while the aforementioned memory address is being manipulated or read by one or more other threads.\nProblem description.\nThe problem which mutual exclusion addresses is a problem of resource sharing: how can a software system control multiple processes' access to a shared resource, when each process needs exclusive control of that resource while doing its work? The mutual-exclusion solution to this makes the shared resource available only while the process is in a specific code segment called the critical section. It controls access to the shared resource by controlling each mutual execution of that part of its program where the resource would be used.\nA successful solution to this problem must have at least these two properties:\nDeadlock freedom can be expanded to implement one or both of these properties:\nEvery process's program can be partitioned into four sections, resulting in four states. Program execution cycles through these four states in order:\nIf a process wishes to enter the critical section, it must first execute the trying section and wait until it acquires access to the critical section. After the process has executed its critical section and is finished with the shared resources, it needs to execute the exit section to release them for other processes' use. The process then returns to its non-critical section.\nEnforcing mutual exclusion.\nHardware solutions.\nOn uni-processor systems, the simplest solution to achieve mutual exclusion is to disable interrupts during a process's critical section. This will prevent any interrupt service routines from running (effectively preventing a process from being preempted). Although this solution is effective, it leads to many problems. If a critical section is long, then the system clock will drift every time a critical section is executed because the timer interrupt is no longer serviced, so tracking time is impossible during the critical section. Also, if a process halts during its critical section, control will never be returned to another process, effectively halting the entire system. A more elegant method for achieving mutual exclusion is the busy-wait.\nBusy-waiting is effective for both uniprocessor and multiprocessor systems. The use of shared memory and an atomic test-and-set instruction provide the mutual exclusion. A process can test-and-set on a location in shared memory, and since the operation is atomic, only one process can set the flag at a time. Any process that is unsuccessful in setting the flag can either go on to do other tasks and try again later, release the processor to another process and try again later, or continue to loop while checking the flag until it is successful in acquiring it. Preemption is still possible, so this method allows the system to continue to function\u2014even if a process halts while holding the lock.\nSeveral other atomic operations can be used to provide mutual exclusion of data structures; most notable of these is compare-and-swap (CAS). CAS can be used to achieve wait-free mutual exclusion for any shared data structure by creating a linked list where each node represents the desired operation to be performed. CAS is then used to change the pointers in the linked list during the insertion of a new node. Only one process can be successful in its CAS; all other processes attempting to add a node at the same time will have to try again. Each process can then keep a local copy of the data structure, and upon traversing the linked list, can perform each operation from the list on its local copy.\nSoftware solutions.\nIn addition to hardware-supported solutions, some software solutions exist that use busy waiting to achieve mutual exclusion. Examples include:\nThese algorithms do not work if out-of-order execution is used on the platform that executes them. Programmers have to specify strict ordering on the memory operations within a thread.\nIt is often preferable to use synchronization facilities provided by an operating system's multithreading library, which will take advantage of hardware solutions if possible but will use software solutions if no hardware solutions exist. For example, when the operating system's lock library is used and a thread tries to acquire an already acquired lock, the operating system could suspend the thread using a context switch and swap it out with another thread that is ready to be run, or could put that processor into a low power state if there is no other thread that can be run. Therefore, most modern mutual exclusion methods attempt to reduce latency and busy-waits by using queuing and context switches. However, if the time that is spent suspending a thread and then restoring it can be proven to be always more than the time that must be waited for a thread to become ready to run after being blocked in a particular situation, then spinlocks are an acceptable solution (for that situation only).\nBound on the mutual exclusion problem.\nOne binary test&amp;set register is sufficient to provide the deadlock-free solution to the mutual exclusion problem. But a solution built with a test&amp;set register can possibly lead to the starvation of some processes which become caught in the trying section. In fact, formula_1 distinct memory states are required to avoid lockout. To avoid unbounded waiting, \"n\" distinct memory states are required.\nRecoverable mutual exclusion.\nMost algorithms for mutual exclusion are designed with the assumption that no failure occurs while a process is running inside the critical section. However, in reality such failures may be commonplace. For example, a sudden loss of power or faulty interconnect might cause a process in a critical section to experience an unrecoverable error or otherwise be unable to continue. If such a failure occurs, conventional, non-failure-tolerant mutual exclusion algorithms may deadlock or otherwise fail key liveness properties. To deal with this problem, several solutions using crash-recovery mechanisms have been proposed.\nTypes of mutual exclusion devices.\nThe solutions explained above can be used to build the synchronization primitives below:\nMany forms of mutual exclusion have side-effects. For example, classic semaphores permit deadlocks, in which one process gets a semaphore, another process gets a second semaphore, and then both wait till the other semaphore to be released. Other common side-effects include starvation, in which a process never gets sufficient resources to run to completion; priority inversion, in which a higher-priority thread waits for a lower-priority thread; and high latency, in which response to interrupts is not prompt.\nMuch research is aimed at eliminating the above effects, often with the goal of guaranteeing non-blocking progress. No perfect scheme is known. Blocking system calls used to sleep an entire process. Until such calls became threadsafe, there was no proper mechanism for sleeping a single thread within a process (see polling).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36828", "revid": "56299", "url": "https://en.wikipedia.org/wiki?curid=36828", "title": "Mutex", "text": "Computing synchronization primitive for enforcing mutual exclusion"}
{"id": "36829", "revid": "1019026021", "url": "https://en.wikipedia.org/wiki?curid=36829", "title": "Concurrent programming", "text": ""}
{"id": "36832", "revid": "45179772", "url": "https://en.wikipedia.org/wiki?curid=36832", "title": "Organisation for the Prohibition of Chemical Weapons", "text": "Intergovernmental organisation\nThe Organisation for the Prohibition of Chemical Weapons (OPCW) is an intergovernmental organisation and the implementing body for the Chemical Weapons Convention (CWC), which entered into force on 29 April 1997. The OPCW, with its 193 member states, has its seat in The Hague, Netherlands; it oversees the global endeavour for the permanent and verifiable elimination of chemical weapons.\nThe organisation promotes and verifies the adherence to the Chemical Weapons Convention, which prohibits the use of chemical weapons and requires their destruction. Verification consists both of evaluation of declarations by member states and onsite inspections.\nThe organisation was awarded the 2013 Nobel Peace Prize \"for its extensive efforts to eliminate chemical weapons\". Nobel Committee chairman Thorbj\u00f8rn Jagland said, \"The conventions and the work of the OPCW have defined the use of chemical weapons as a taboo under international law\".\nHistory.\nThe Hague was chosen as the location for the seat of the organisation after a successful lobby of the Dutch government, competing against Vienna and Geneva. The organisation has its headquarters next to the World Forum Convention Centre (where it holds its yearly Conference of States Parties) and an equipment store and laboratory facility in Rijswijk. The headquarters were officially opened by Queen Beatrix of the Netherlands on 20 May 1998. and consist of an eight-story building built in a semi-circle. A \"permanent memorial to all victims\" is present at the back of the building and is open to the public.\nThe OPCW headquarters building was designed by American architect Gerhard Kallmann of Kallmann McKinnell &amp; Wood.\nThe first Director-General only served about one year of his second term, after which, in April 2002, he was removed from office on grounds of lack of confidence by the member states. It was argued by \"The Guardian\"'s columnist George Monbiot that Director-General Jos\u00e9 Bustani was being forced out by the U.S. government, despite the convention insisting the OPCW \"shall not seek or receive instructions from any government\"; the US had tried to persuade Brazil to recall Bustani. Monbiot wrote that the U.S. had tried other measures, although the convention also indicates that states should \"not seek to influence\" staff. In line with his mandate, Bustani wanted Iraq to sign the convention thus allowing international chemical weapons monitors into Iraq and thus potentially impeding the U.S. push for war against Iraq. The U.S. gave three main arguments for the removal of Bustani's from his position: \"polarising and confrontational conduct\", \"mismanagement issues\" and \"advocacy of inappropriate roles for the OPCW\". The removal was subsequently determined to be improper by an Administrative Tribunal of the International Labour Organization and consequently Bustani was awarded \u20ac50,000 in moral damages, his pay for the remainder of his second term, and his legal costs.\nOn 11 October 2013, the Norwegian Nobel Committee announced that the OPCW had been awarded the Nobel Peace Prize for \"extensive work to eliminate chemical weapons\". The committee further indicated how \"Recent events in Syria, where chemical weapons have again been put to use, have underlined the need to enhance the efforts to do away with such weapons.\" In the year ending September 2014, the OPCW had overseen the destruction of some 97 per cent of Syria's declared chemical weapons. \nIn 2014, The OPCW\u2013The Hague Award was established to honour select individuals and institutions by highlighting their exceptional contributions towards the goal of a world permanently free of chemical weapons. The award was created as a legacy of the OPCW winning the 2013 Nobel Peace Prize. The OPCW\u2014The Hague Award fund was created using the approximately \u20ac900,000 monetary prize which accompanied the Nobel Peace Prize, and is also supported financially by the City of The Hague, where the OPCW is based.\nOn 13 April 2018, the OPCW became the target of an attempted cyberattack by Russian GRU agents. The agents were detained by Dutch Intelligence agents with hacking equipment in their possession. The agents were later expelled from the country. The British Culture Secretary Jeremy Wright alleged that the attempted cyberattack was meant to interfere with the OPCW investigation into the 2018 Salisbury poisonings.\nIn June 2018, the OPCW voted to expand its own powers, allowing itself to assign blame for a contravention of its regulations.\nIn November 2019, a unanimous agreement of OPCW member states allowed the addition of the Novichok agents to \"list of controlled substances\" of the CWC \"in one of the first major changes to the treaty since it was agreed in the 1990s\" in response to the 2018 poisonings in the UK.\nOrganisational structure.\nThe activities of the OPCW and its core organisational structure are described in the Chemical Weapons Convention (whose members are all in OPCW). The principal body is the Conference of the States Parties (CSP), which normally is convened yearly, and in which all countries can participate, with equal voting rights. Countries are generally represented in the conference by a permanent representative to the organisation, which in most cases is also the ambassador to the Netherlands. The conference decides on all main topics regarding the organisation (for example, taking retaliation measures) and the convention (approving guidelines, imposing retaliating measures against members).\nThe Executive Council (EC) is the executive organ of the organisation and consists of 41 states parties, which are appointed by the conference on a two-year term. The council amongst others oversees the budget and cooperates with the General Secretariat on all matters related to the convention.\nThe Technical Secretariat (TS) applies most of the activities mandated by the council and is the body where most of the employees of the organisation work. The main activities of the OPCW are performed by the inspection and the verification divisions.\nAll states parties make contributions to the OPCW budget, based on a modified UN scale of assessments. The OPCW budget for 2020 is \u20ac70,958,760\nPowers.\nThe OPCW has the power to report on whether chemical weapons were used in an attack it has investigated.\n\"The OPCW has the power to send inspectors to any signatory country to search for evidence of production of banned chemicals. It also can send experts to help countries to investigate crime scenes where chemical agents may have been used.\"\nIn June 2018 following the Skripal poisoning the UK convinced other members despite the Russian opposition that the OPCW needed to grant itself new powers to assign blame for attacks. The vote was won by a margin of 82 to 24, which exceeded the two-thirds majority needed for the motion to pass.\nInspections.\nChemical weapons destruction facilities.\nAt all operational chemical weapons destruction facilities, 24/7 inspections by the OPCW take place on site to verify the success of the destruction as well as the amounts of weapons being destroyed. In light of the hazardous environment in which the inspections take place, they are generally performed by evaluation via CCTV-systems.\nIndustry inspections.\nInspections are designed to verify compliance of States Parties with the requirements imposed on production and use of scheduled chemicals and to verify that industrial activities of member states have been correctly declared according to the obligation set by the CWC. The intensity and frequency of the inspections is dependent on the type of chemical produced (in descending order: Schedule 1, Schedule 2, Schedule 3 or DOC, see Scheduled Chemicals), but is regardless of the standing of the member state.\nFor Schedule 1 and 2 facilities, a mass balance is prepared to identify whether all produced chemicals can be accounted for and whether the amounts are consistent with the declarations made by member states. Furthermore, at Schedule 2 and 3 facilities clues are investigated whether, contrary to the declaration and to the rules in the convention, Schedule 1 chemicals are produced. At Schedule 3 and DOC, the main aim is to check the declaration and to verify the absence of Schedule 2 and Schedule 1 production units. The time limit Schedule 2 inspections is 96 hours while Schedule 3 and DOC inspections can take a maximum of 24 hours. There is no time limit on Schedule 1 inspections.\nChallenge inspections and investigations of alleged use.\nIn case of allegation of use of chemical weapons or the prohibited production, a fact-finding inspection can be employed according to the convention. None of those activities have taken place, although the OPCW contributed to investigations of alleged use of chemical weapons in Syria as part of a United Nations mission. The OPCW only undertakes these inspections on request of another member state, after verification of the presented proof. To avoid misuse, a majority of three-quarters can block a challenge inspection request.\nRelations with the United Nations.\nWhile the OPCW is not a specialised agency of the United Nations, it cooperates both on policy and practical issues as a related organisation. On 7 September 2000, the OPCW and the United Nations signed a cooperation agreement outlining how they were to coordinate their activities. The inspectors furthermore travel on the United Nations Laissez-Passer in which a sticker is placed explaining their position, and privileges and immunities. The United Nations Regional Groups also operate at the OPCW to govern the rotations on the Executive Council and provide informal discussion platform.\nMembership.\nAll 193 parties to the Chemical Weapons Convention are automatically members of the OPCW. Other states which are eligible to become members are UN member states: Israel is a signatory state that has not ratified the Convention; and Egypt, North Korea and South Sudan, which have neither signed nor acceded to the Convention. Palestine was the most recent state to submit its instrument of accession to the Convention. On 21 April 2021, Syria was stripped of its voting rights at the OPCW after Syrian forces were found to have repeatedly used poison gas during the Syrian civil war. A two-thirds majority of members voted to immediately revoke Syria's privileges at the agency.\nLeadership.\nThe Organisation is currently led by Director-General Ambassador Fernando Arias of Spain.\nThe Director-General is directly appointed by the Conference for a maximum of two four-year terms. A historical list of Directors-General is shown below.\nThe appointment of Ambassador Arias followed a consensus recommendation by the OPCW Executive Council in October 2017.\nAmbassador Arias is a career diplomat with extensive experience in multilateral diplomacy. Previously, he served as Ambassador of Spain to the Netherlands and the Permanent Representative of Spain to the OPCW. He also has served as Permanent Representative of Spain to the United Nations in New York and Ambassador of Spain to Mali, Mauritania, former Yugoslav Republic of Macedonia, and Bulgaria.\nFindings by the Administrative Tribunal of the International Labour Organization.\nIn 2002, the United States convened an extraordinary session of the Conference of the States Parties of the OPCW to request the dismissal of Jos\u00e9 Bustani, then Director General of the OPCW. Bustani was dismissed following the vote, held on 22 April 2002, with 48 states voting in favor, 7 against and 43 abstaining. Subsequently, Bustani accused the United States of having provoked his impeachment because he had succeeded in convincing Saddam Hussein to ratify the Chemical Weapons Convention, which implied inspection of the Iraqi arsenal by OPCW investigators and would have thwarted the American plan of an invasion of Iraq. He also lodged a complaint before the Administrative Tribunal of the International Labour Organization, which, by a judgment of 16 July 2003, quashed the dismissal and condemned the OPCW to compensation for material and moral damage. Bustani did not seek to be reinstated in office.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36834", "revid": "45266726", "url": "https://en.wikipedia.org/wiki?curid=36834", "title": "International Fund for Agricultural Development", "text": "Specialised agency of the United Nations\nThe International Fund for Agricultural Development (IFAD) is an international financial institution and a specialised agency of the United Nations that works to address poverty and hunger in rural areas of developing countries. It is the only multilateral development organization that focuses solely on rural economies and food security.\nIFAD is involved in over 200 projects across nearly 100 countries. It funds and sponsors initiatives that improve land and water management, develop rural infrastructure, train and educate farmers in more efficient technologies, build up resilience against climate change, enhancing market accessibility, and more.\nIFAD has 180 member states with the Organization of the Petroleum Exporting Countries (OPEC) and members of the Organisation for Economic Co-operation and Development (OECD). As of 2021, since its foundation, IFAD has provided US$23.2 billion in loans and grants and coordinated an addition US$31 billion in international and domestic co-financing.\nHistory.\nIn the early 1970s, global food shortages led to widespread famine, malnutrition, and mortality, particularly affecting the Sahel region of Africa. The world required long-term, coordinated approaches to the structural issues that were causing destitution and food shortages. IFAD was established as an international financial institution in 1977 through United Nations General Assembly Resolution 32/107 (15 December 1977) as one of the major outcomes of the 1974 World Food Conference. The conference highlighted the vital importance of addressing food insecurity and poverty in emerging countries' rural communities. IFAD officially opened its headquarters in Rome, Italy and convened its first governing council with 120 member states and it is a member of the United Nations Development Group.\nVision.\nThe International Fund for Agricultural Development (IFAD) envisions rural communities that are inclusive, prosperous, and resilient, free from poverty and hunger. Acknowledging that agriculture is the primary livelihood for millions of rural people, IFAD addresses the challenges these communities face, such as climate adaptation, economic instability, and food insecurity.\nThrough strategic partnerships and financing, IFAD supports initiatives that enable rural populations to enhance productivity, access resources, and build resilience. Its vision includes fostering innovation and advancing policies that promote equity, with a focus on empowering groups often overlooked, such as women, Indigenous Peoples, and youth.\nCriticism and debates.\nIFAD, alongside other United Nations Specialized Agencies and international aid agencies, has been subject to a wide array of criticism from different actors.\nApproach to food insecurity and poverty alleviation.\nSee also : Washington Consensus\nIFAD is often perceived as being in line with dominant economic ideologies, and has seen critiques for falling short in reducing food insecurity and hunger by not addressing structural challenges of the world economy. The legacy of neo-liberal policies pushed for by international development agencies has often drawn criticism, and although IFAD specifically targets small-scale actors, prevalent debates about agriculture and aid effectiveness extend to the role played by institutions such as IFAD. Many scholars oppose the status quo and call for a change in the approach to food insecurity as illustrated with the quote \u201cThe global food system, driven by neoliberal economic policies, has transformed agriculture into an instrument for economic development, often at the expense of local communities' food security and autonomy\u201d.\nFinancialization of agriculture.\nThe financialization of agriculture refers to the rising involvement of finance in agriculture, which can take the form of access to credit markets, commodification and trade of agricultural products, evolving regulations (to allow new financial agreements between actors) and more. IFAD has targeted financialization as a way of supporting food production and allowing markets to deliver solutions. As such, some scholars have been vocal in their criticism of financialization and its shortcomings, by exacerbating inequalities (concentrating wealth among financial elites and agribusiness corporations), heightening the fragility of the food system to shocks (economic and environmental), stifling collective action to build ecologically sound food systems, and leaving small-scale farmers more exposed to price volatility due to contracted loans and financial derivatives. Moreover, many have pointed to the commodification and trade of agricultural assets as a reason for rising food prices around the world.\nTechnocracy.\nIFAD has sometimes been branded by local actors and critiques as Technocratic, offering one-size fits all solutions to specific contexts. International development endeavors are often characterized by their multilateral nature, and the omission of local actors and/or conflicting viewpoints may undermine poverty alleviation efforts.\nInterpretation of mandate and constituent instruments.\nIn 2009, a report published by Rutsel Martha (general counsel of legal affairs at IFAD) titled \"Mandate issues in the activities of the International Fund for Agricultural Development (IFAD)\" looked at the issues regarding the institutions interpretations of its law's: \"Every action of an international organization, including IFAD, expresses or implies some interpretation of the organization\u2019s law, in particular its constituent instrument. In other words, IFAD\u2019s actions, like those of other international organizations, imply a view about the meaning of its law, and are therefore quintessentially interpretative of the legal regulations that govern its existence and operations\". In this sense, multiple occasions have revealed how IFAD relies on interpretations and auxiliary instruments to address its mission of alleviating food insecurity. For example, it bypassed the original prerogative stating \"the Fund can only finance its developing Member States and intergovernmental organizations in which those States participate\" to extend financing to NGO's under certain conditions.\nIn the late 1990s and early 2000s, IFAD again bypassed its original mandate via legal instruments to deliver programs in the West Bank and Gaza Strip, under accords with the Palestinian authority which was not a recognized member state. The chairman of the 21st session of the governing council in his closing statement stated: \"\u201cThe long arms of hunger and poverty know no legal or political boundaries, yet development aid very often faces constraints that limit its outreach. During this Session we have overcome just such a constraint by establishing a Fund for Gaza and the West Bank, a territory that is not a Member State of IFAD. There is indeed satisfaction in overcoming bounds and in reaching out to PEOPLE not to boundaries\u201d. In response to this, the United States representative stated that although \u201cthe United States supports international efforts to assist the Palestinian people, not only to improve day-to-day lives, but also to build a constituency for peace\", because of \"US legal restrictions, our contributions and assistance cannot be used for the proposed IFAD special fund\". This situation revealed how IFAD is subject to judicial and political challenges, which can undermine its mission. Rustel Martha wrote of the incident that it highlighted \"the fact that when organizations embark on activities which cannot be clearly identified as having been authorized by the constituent instrument, it may place membership contribution at risk\".\nStructure.\nThe International Fund for Agricultural Development (IFAD) relies on three key entities for governance: the governing council, the executive board, and the president.\nGoverning Council.\nThe IFAD is governed by its primary decision-making body, the Governing Council, which holds full powers to make decisions. This council is composed of representatives from all IFAD Member States and gathers on an annual basis. It is attended by official delegates such as Governors, Alternate Governors, and other appointed advisors. Observers, including representatives from non-member states seeking membership, the Holy See, the Sovereign Order of Malta, and approved UN agencies, intergovernmental and non-governmental organizations, are also invited to attend.\nThe Governing Council has full authority over the fund's operations and makes decisions on important matters such as the approval of new members, the election of the President, issues concerning the permanent seat, the administrative budget, and the establishment of policies, criteria, and regulations.\nSessions of the Governing Council are led by the Chairperson of the Bureau, which is made up of one Chairperson and two Vice-chairpersons, all elected from among the Governors of member states for a two-year period. The President also participates in Governing Council meetings without voting rights.\nExecutive Board.\nThe general operations of the fund are managed by the Executive Board, which exercises authority either directly provided by Agreement of Establishing the IFAD or delegated by the Governing Council. The Board is made up of 18 members and as many as 18 alternate members, all elected from the fund's members at the annual session of the Governing Council. Each member serves a three-year term within allocated Lists and Sub-Lists. The fund's president chairs the executive board, attending its meetings without voting privileges.\nCurrent framework of the Executive Board.\nSource:\nPresident.\nThe president of the IFAD is appointed by the Governing Council with a two-thirds majority vote and serves a term of four years, renewable once. Under exceptional circumstances, the term may be extended by up to six months on the recommendation of the executive board. The president oversees the fund's operations, including organizing the staff and managing appointments and dismissals, following regulations set by the executive board.\nThe president may appoint a vice-president to assist with assigned responsibilities and serves as the fund's legal representative. The current president of the IFAD is Alvaro Lario from Spain, who took over from Gilbert Houngbo in late 2022. His term of office began on 1 October 2022, and will run until 31 March 2027. As of 2024, \u00c1lvaro Lario, who serves as the president of IFAD, took on the additional role of chair of UN-Water, the United Nations Inter-Agency Mechanism on All Freshwater Related Issues, Including Sanitation.\nMembership.\n\"Membership of the Fund shall be open to any State member of the United Nations, or of any of its specialized agencies, or of the International Atomic Energy Agency. Membership shall also be open to any groupings of States whose members have delegated to it powers in fields falling within the competence of the fund, and which is able to fulfil all the obligations of a Member of the Fund\" (Art. 3, sec. 1 of the Agreement Establishing IFAD).\nIFAD currently has 180 member states, categorized into three main groups that reflect the economic diversity and development priorities of its members.\nList A includes high-income countries that contribute significantly to IFAD's financial resources. These nations have declared themselves ineligible for IFAD financing and do not qualify for Official Development Assistance (ODA) as defined by the Organisation for Economic Co-operation and Development (OECD). Their role is crucial in providing funding for global agricultural development initiatives.\nList B includes member states from the Organization of the Petroleum Exporting Countries (OPEC) that also contribute to IFAD's resources. This category comprises oil-rich countries that may be eligible for particular agricultural development initiatives, demonstrating development aid.\nList C includes developing nations eligible for IFAD money and services, many of which also contribute to the organization's resources. This list is divided into three regional sub-lists: C1 (countries in Africa), C2 (countries in Europe, Asia, and the Pacific) and C3 (countries in Latin America and Caribbean).\nList A \u2013 29 member states.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nList B \u2013 12 member states.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSublist C1 \u2013 50 member states.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSublist C2 \u2013 57 member states.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSublist C3 \u2013 32 member states.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36835", "revid": "17619453", "url": "https://en.wikipedia.org/wiki?curid=36835", "title": "Auger electron spectroscopy", "text": "Analytical technique used specifically in the study of surfaces\nAuger electron spectroscopy (AES; pronounced in French) is a common analytical technique used specifically in the study of surfaces and, more generally, in the area of materials science. It is a form of electron spectroscopy that relies on the Auger effect, based on the analysis of energetic electrons emitted from an excited atom after a series of internal relaxation events. The Auger effect was discovered independently by both Lise Meitner and Pierre Auger in the 1920s. Though the discovery was made by Meitner and initially reported in the journal \"Zeitschrift f\u00fcr Physik\" in 1922, Auger is credited with the discovery in most of the scientific community. Until the early 1950s Auger transitions were considered nuisance effects by spectroscopists, not containing much relevant material information, but studied so as to explain anomalies in X-ray spectroscopy data. Since 1953 however, AES has become a practical and straightforward characterization technique for probing chemical and compositional surface environments and has found applications in metallurgy, gas-phase chemistry, and throughout the microelectronics industry.\nElectron transitions and the Auger effect.\nThe Auger effect is an electronic process at the heart of AES resulting from the inter- and intrastate transitions of electrons in an excited atom. When an atom is probed by an external mechanism, such as a photon or a beam of electrons with energies in the range of several\u00a0eV to\u00a050 keV, a core state electron can be removed leaving behind a hole. As this is an unstable state, the core hole can be filled by an outer shell electron, whereby the electron moving to the lower energy level loses an amount of energy equal to the difference in orbital energies. The transition energy can be coupled to a second outer shell electron, which will be emitted from the atom if the transferred energy is greater than the orbital binding energy. An emitted electron will have a kinetic energy of:\nformula_1\nwhere formula_2, formula_3, formula_4 are respectively the core level, first outer shell, and second outer shell electron binding energies (measured from the vacuum level) which are taken to be positive. The apostrophe (tic) denotes a slight modification to the binding energy of the outer shell electrons due to the ionized nature of the atom; often, however, this energy modification is ignored in order to ease calculations. Since orbital energies are unique to an atom of a specific element, analysis of the ejected electrons can yield information about the chemical composition of a surface. Figure 1 illustrates two schematic views of the Auger process.\nThe types of state-to-state transitions available to electrons during an Auger event are dependent on several factors, ranging from initial excitation energy to relative interaction rates, yet are often dominated by a few characteristic transitions. Because of the interaction between an electron's spin and orbital angular momentum (spin-orbit coupling) and the concomitant energy level splitting for various shells in an atom, there are a variety of transition pathways for filling a core hole. Energy levels are labeled using a number of different schemes such as the j-j coupling method for heavy elements (\"Z\" \u2265 75), the Russell\u2013Saunders L-S method for lighter elements (\"Z\" &lt; 20), and a combination of both for intermediate elements. The j-j coupling method, which is historically linked to X-ray notation, is almost always used to denote Auger transitions. Thus for a formula_5 transition, formula_6 represents the core level hole, formula_7 the relaxing electron's initial state, and formula_8 the emitted electron's initial energy state. Figure 1(b) illustrates this transition with the corresponding spectroscopic notation. The energy level of the core hole will often determine which transition types will be favored. For single energy levels, i.e. \"K\", transitions can occur from the L levels, giving rise to strong KLL type peaks in an Auger spectrum. Higher level transitions can also occur, but are less probable. For multi-level shells, transitions are available from higher energy orbitals (different \"n, \u2113\" quantum numbers) or energy levels within the same shell (same \"n\", different \"\u2113\" number). The result are transitions of the type LMM and KLL along with faster Coster\u2013Kronig transitions such as LLM. While Coster\u2013Kronig transitions are faster, they are also less energetic and thus harder to locate on an Auger spectrum. As the atomic number Z increases, so too does the number of potential Auger transitions. The strongest electron\u2013electron interactions are between levels that are close together, giving rise to characteristic peaks in an Auger spectrum. KLL and LMM peaks are some of the most commonly identified transitions during surface analysis. Finally, valence band electrons can also fill core holes or be emitted during KVV-type transitions.\nSeveral models, both phenomenological and analytical, have been developed to describe the energetics of Auger transitions. One of the most tractable descriptions, put forth by Jenkins and Chung, estimates the energy of Auger transition ABC as:\nformula_9\nformula_10 are the binding energies of the formula_11th level in element of atomic number \"Z\" and formula_12 are the energies of the same levels in the next element up in the periodic table. While useful in practice, a more rigorous model accounting for effects such as screening and relaxation probabilities between energy levels gives the Auger energy as:\nformula_13\nwhere formula_14 is the energy of interaction between the \"B\" and \"C\" level holes in a final atomic state \"x\" and the \"R\"'s represent intra- and extra-atomic transition energies accounting for electronic screening. Auger electron energies can be calculated based on measured values of the various formula_15 and compared to peaks in the secondary electron spectrum in order to identify chemical species. This technique has been used to compile several reference databases used for analysis in current AES setups.\nExperimental setup and quantification.\nInstrumentation.\nSurface sensitivity in AES arises from the fact that emitted electrons usually have energies ranging from 50\u00a0eV to 3\u00a0keV and at these values, electrons have a short mean free path in a solid. The escape depth of electrons is therefore localized to within a few nanometers of the target surface, giving AES an extreme sensitivity to surface species. Because of the low energy of Auger electrons, most AES setups are run under ultra-high vacuum (UHV) conditions. Such measures prevent electron scattering off of residual gas atoms as well as the formation of a thin \"gas (adsorbate) layer\" on the surface of the specimen, which degrades analytical performance. A typical AES setup is shown schematically in figure 2. In this configuration, focused electrons are incident on a sample and emitted electrons are deflected into a cylindrical mirror analyzer (CMA). In the detection unit, Auger electrons are multiplied and the signal sent to data processing electronics. Collected Auger electrons are plotted as a function of energy against the broad secondary electron background spectrum. The detection unit and data processing electronics are collectively referred to as the electron energy analyzer.\nSince the intensity of the Auger peaks may be small compared to the noise level of the background, AES is often run in a derivative mode that serves to highlight the peaks by modulating the electron collection current via a small applied AC voltage. Since this formula_16, the collection current becomes formula_17. Taylor expanding gives:\nformula_18\nUsing the setup in figure 2, detecting the signal at frequency \u03c9 will give a value for formula_19 or formula_20. Plotting in derivative mode also emphasizes Auger fine structure, which appear as small secondary peaks surrounding the primary Auger peak. These secondary peaks, not to be confused with high energy satellites, which are discussed later, arise from the presence of the same element in multiple different chemical states on a surface (i.e. Adsorbate layers) or from relaxation transitions involving valence band electrons of the substrate. Figure 3 illustrates a derivative spectrum from a copper nitride film clearly showing the Auger peaks. The peak in derivative mode is not the true Auger peak, but rather the point of maximum slope of \"N(E)\", but this concern is usually ignored.\nQuantitative analysis.\nSemi-quantitative compositional and element analysis of a sample using AES is dependent on measuring the yield of Auger electrons during a probing event. Electron yield, in turn, depends on several critical parameters such as electron-impact cross-section and fluorescence yield. Since the Auger effect is not the only mechanism available for atomic relaxation, there is a competition between radiative and non-radiative decay processes to be the primary de-excitation pathway. The total transition rate, \u03c9, is a sum of the non-radiative (Auger) and radiative (photon emission) processes. The Auger yield, formula_21, is thus related to the fluorescence (x-ray) yield, formula_22, by the relation,\nformula_23\nwhere formula_24 is the X-ray transition probability and formula_25 is the Auger transition probability. Attempts to relate the fluorescence and Auger yields to atomic number have resulted in plots similar to figure 4. A clear transition from electron to photon emission is evident in this chart for increasing atomic number. For heavier elements, x-ray yield becomes greater than Auger yield, indicating an increased difficulty in measuring the Auger peaks for large Z-values. Conversely, AES is sensitive to the lighter elements, and unlike X-ray fluorescence, Auger peaks can be detected for elements as light as lithium (\"Z\" = 3). Lithium represents the lower limit for AES sensitivity since the Auger effect is a \"three state\" event necessitating at least three electrons. Neither H nor He can be detected with this technique. For K-level based transitions, Auger effects are dominant for \"Z\" &lt; 15 while for L- and M-level transitions, AES data can be measured for \"Z\" \u2264 50. The yield limits effectively prescribe a cutoff for AES sensitivity, but complex techniques can be utilized to identify heavier elements, such as uranium and americium, using the Auger effect.\nAnother critical quantity that determines yield of Auger electrons at a detector is the electron impact cross-section. Early approximations (in cm2) of the cross-section were based on the work of Worthington and Tomlin,\nformula_26\nwith \"b\" acting as a scaling factor between 0.25 and 0.35, and \"C\" a function of the primary electron beam energy, formula_27. While this value of formula_28 is calculated for an isolated atom, a simple modification can be made to account for matrix effects:\nformula_29\nwhere \u03b1 is the angle to the surface normal of the incident electron beam; \"rm\" can be established empirically and encompasses electron interactions with the matrix such as ionization due to backscattered electrons. Thus the total yield can be written as:\nformula_30\nHere \"Nx\" is the number of \"x\" atoms per volume, \u03bb the electron escape depth, \u03b8 the analyzer angle, \"T\" the transmission of the analyzer, \"I(t)\" the electron excitation flux at depth \"t\", d\u03a9 the solid angle, and \u03b4t is the thickness of the layer being probed. Encompassed in these terms, especially the Auger yield, which is related to the transition probability, is the quantum mechanical overlap of the initial and final state wave functions. Precise expressions for the transition probability, based on first-order perturbation Hamiltonians, can be found in Thompson and Baker. Often, all of these terms are not known, so most analyses compare measured yields with external standards of known composition. Ratios of the acquired data to standards can eliminate common terms, especially experimental setup characteristics and material parameters, and can be used to determine element composition. Comparison techniques work best for samples of homogeneous binary materials or uniform surface layers, while elemental identification is best obtained from comparison of pure samples.\nUses.\nThere are a number of electron microscopes that have been specifically designed for use in Auger spectroscopy; these are termed scanning Auger microscopes (SAMs) and can produce high resolution, spatially resolved chemical images. SAM images are obtained by stepping a focused electron beam across a sample surface and measuring the intensity of the Auger peak above the background of scattered electrons. The intensity map is correlated to a gray scale on a monitor with whiter areas corresponding to higher element concentration. In addition, sputtering is sometimes used with Auger spectroscopy to perform depth profiling experiments. Sputtering removes thin outer layers of a surface so that AES can be used to determine the underlying composition. Depth profiles are shown as either Auger peak height vs. sputter time or atomic concentration vs. depth. Precise depth milling through sputtering has made profiling an invaluable technique for chemical analysis of nanostructured materials and thin films. AES is also used extensively as an evaluation tool on and off fab lines in the microelectronics industry, while the versatility and sensitivity of the Auger process makes it a standard analytical tool in research labs. Theoretically, Auger spectra can also be utilized to distinguish between protonation states. When a molecule is protonated or deprotonated, the geometry and electronic structure is changed, and AES spectra reflect this. In general, as a molecule becomes more protonated, the ionization potentials increase and the kinetic energy of the emitted outer shell electrons decreases.\nDespite the advantages of high spatial resolution and precise chemical sensitivity attributed to AES, there are several factors that can limit the applicability of this technique, especially when evaluating solid specimens. One of the most common limitations encountered with Auger spectroscopy are charging effects in non-conducting samples. Charging results when the number of secondary electrons leaving the sample is different from the number of incident electrons, giving rise to a net positive or negative electric charge at the surface. Both positive and negative surface charges severely alter the yield of electrons emitted from the sample and hence distort the measured Auger peaks. To complicate matters, neutralization methods employed in other surface analysis techniques, such as secondary ion mass spectrometry (SIMS), are not applicable to AES, as these methods usually involve surface bombardment with either electrons or ions (i.e. flood gun). Several processes have been developed to combat the issue of charging, though none of them is ideal and still make quantification of AES data difficult. One such technique involves depositing conductive pads near the analysis area to minimize regional charging. However, this type of approach limits SAM applications as well as the amount of sample material available for probing. A related technique involves thinning or \"dimpling\" a non-conductive layer with Ar+ ions and then mounting the sample to a conductive backing prior to AES. This method has been debated, with claims that the thinning process leaves elemental artifacts on a surface and/or creates damaged layers that distort bonding and promote chemical mixing in the sample. As a result, the compositional AES data is considered suspect. The most common setup to minimize charging effects includes use of a glancing angle (~10\u00b0) electron beam and a carefully tuned bombarding energy (between 1.5 keV and 3 keV). Control of both the angle and energy can subtly alter the number of emitted electrons vis-\u00e0-vis the incident electrons and thereby reduce or altogether eliminate sample charging.\nIn addition to charging effects, AES data can be obscured by the presence of characteristic energy losses in a sample and higher order atomic ionization events. Electrons ejected from a solid will generally undergo multiple scattering events and lose energy in the form of collective electron density oscillations called plasmons. If plasmon losses have energies near that of an Auger peak, the less intense Auger process may become dwarfed by the plasmon peak. As Auger spectra are normally weak and spread over many eV of energy, they are difficult to extract from the background and in the presence of plasmon losses; deconvolution of the two peaks becomes extremely difficult. For such spectra, additional analysis through chemical sensitive surface techniques like x-ray photoelectron spectroscopy (XPS) is often required to disentangle the peaks. Sometimes an Auger spectrum can also exhibit \"satellite\" peaks at well-defined off-set energies from the parent peak. Origin of the satellites is usually attributed to multiple ionization events in an atom or ionization cascades in which a series of electrons is emitted as relaxation occurs for core holes of multiple levels. The presence of satellites can distort the true Auger peak and/or small peak shift information due to chemical bonding at the surface. Several studies have been undertaken to further quantify satellite peaks.\nDespite these sometimes substantial drawbacks, Auger electron spectroscopy is a widely used surface analysis technique that has been successfully applied to many diverse fields ranging from gas phase chemistry to nanostructure characterization. A new class of high-resolving electrostatic energy analyzers, face-field analyzers (FFA) can be used for remote electron spectroscopy of distant surfaces or surfaces with large roughness or even with deep dimples. These instruments are designed as if to be specifically used in combined scanning electron microscopes (SEMs). \"FFA\" in principle have no perceptible end-fields, which usually distort focusing in most of analysers known, for example, well known CMA.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "36836", "revid": "1553768", "url": "https://en.wikipedia.org/wiki?curid=36836", "title": "IFRCS", "text": ""}
{"id": "36838", "revid": "5862", "url": "https://en.wikipedia.org/wiki?curid=36838", "title": "Red Crescent", "text": ""}
{"id": "36839", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=36839", "title": "Quaternian", "text": ""}
{"id": "36840", "revid": "33299132", "url": "https://en.wikipedia.org/wiki?curid=36840", "title": "P. J. O'Rourke", "text": "American political satirist and journalist (1947\u20132022)\nPatrick Jake O'Rourke (November 14, 1947 \u2013 February 15, 2022) was an American author, journalist, and political satirist who wrote twenty-two books on subjects as diverse as politics, cars, etiquette, and economics. His books \"Parliament of Whores\"\u00a0and\u00a0\"Give War a Chance\"\u00a0both reached No. 1 on \"The New York Times\"\u00a0bestseller list.\nAfter beginning his career writing for the\u00a0\"National Lampoon\", O'Rourke went on to serve as foreign affairs desk chief for\u00a0\"Rolling Stone\"\u00a0where he reported from far-flung places. Later he wrote for a number of publications, including\u00a0\"The Atlantic\",\u00a0the \"Daily Beast\", the\u00a0\"Wall Street Journal\",\u00a0and the\u00a0\"Weekly Standard\",\u00a0and was a longtime panelist on NPR's\u00a0\"Wait Wait... Don't Tell Me!\".\nThe \"Forbes Media Guide Five Hundred, 1994\" states, \"O'Rourke's original reporting, irreverent humor, and crackerjack writing makes for delectable reading. He never minces words or pulls his punches, whatever the subject.\"\nEarly life and education.\nO'Rourke was born in Toledo, Ohio, on November 14, 1947, the son of Delphine (n\u00e9e Loy), a housewife, and Clifford Bronson O'Rourke, a car salesman. O'Rourke had Irish ancestry that traces back to County Roscommon. He graduated from Toledo's DeVilbiss High School in 1965, received his undergraduate degree from Miami University in 1969 and earned a Master of Arts in English at Johns Hopkins University. Many of O'Rourke's essays recount that during his student days he was a leftist, anti-war hippie, but that in the 1970s his political views underwent a \"volte-face\". He emerged as a political observer and humorist rooted in libertarian conservatism.\nCareer.\nO'Rourke wrote articles for several publications, including \"A.J. at N.Y.U.\" for \"The Rip Off Review of Western Culture\", an underground magazine/comic book, in 1972, as well as pieces for the Baltimore underground newspaper \"Harry\" and the \"New York Ace\", before joining \"National Lampoon\" in 1973, where he served as editor-in-chief, among other roles, and authored articles such as \"Foreigners Around the World\" and \"How to Drive Fast on Drugs While Getting Your Wing-Wang Squeezed and Not Spill Your Drink\".\nO'Rourke received a writing credit for \"National Lampoon's Lemmings\" which helped launch the careers of Chevy Chase and Christopher Guest. He also co-wrote \"National Lampoon's 1964 High School Yearbook\" with Douglas Kenney. This inspired the cult comedy, \"Animal House\", which launched the career of John Belushi.\nGoing freelance in 1981, O'Rourke had his work published in \"Playboy,\" \"Vanity Fair,\" \"Car and Driver\", and \"Rolling Stone\". He became foreign-affairs desk chief at \"Rolling Stone\", where he remained until 2001. In 1996, he served as the conservative commentator in the point-counterpoint segment of \"60 Minutes\". During the Bosnian genocide, O'Rourke referred to the American public's lack of interest in Bosnia as a way to joke about \"the unspellables killing the unpronounceables\".\nO'Rourke published over 20 books, including three \"New York Times\" bestsellers. \"Parliament of Whores\" and \"Give War a Chance\" reached No. 1 on \"The New York Times\" Best Seller list. He also wrote \"Modern Manners\" and \"Holidays in Hell.\" O'Rourke was a \"Real Time Real Reporter\" for \"Real Time with Bill Maher\" covering the 2008 presidential election. In the UK, he was known as the face of a long-running series of television advertisements for British Airways in the 1990s.\nO'Rourke also worked on screenplays in Hollywood, including Rodney Dangerfield's \"Easy Money\".\nIn 2009, O'Rourke described the nascent presidency of Barack Obama as \"the Carter administration in better sweaters\". However, in 2016, he endorsed presidential candidate Hillary Clinton over Donald Trump. O'Rourke stated that his endorsement included her \"lies and empty promises\" and added \"She's wrong about absolutely everything, but she's wrong within normal parameters\".\nPersonal life.\nFrom 1990 to 1993, O'Rourke was married to Amy Lumet, a daughter of movie director Sidney Lumet and a granddaughter of Lena Horne. In 1995, he married Tina Mallon; they had three children: daughters Elizabeth and Olivia and son Clifford. In an interview with the \"New Statesman\" published in January 2012, O'Rourke said, \"Despite my name, I wasn't raised a Catholic. My mother was a Protestant, of a traditional American, vague kind: she belonged to the church that the nice people in the neighbourhood went to. My wife is a Catholic, the kids are Catholic, so I'm a Catholic fellow-traveller.\"\nIn September 2008, O'Rourke announced that he had been diagnosed with treatable rectal cancer, from which he expected \"a 95% chance of survival\". \nDeath.\nO'Rourke died from lung cancer at his home in Sharon, New Hampshire, on February 15, 2022, at the age of 74.\nWriting.\nO'Rourke was a proponent of gonzo journalism; one of his earliest and best-regarded pieces was \"How to Drive Fast on Drugs While Getting Your Wing-Wang Squeezed and Not Spill Your Drink\", a \"National Lampoon\" article in March 1979. The article was republished in two of his books, \"Republican Party Reptile\" (1987) and \"Driving Like Crazy\" (2009).\nO'Rourke's best-received book is \"Parliament of Whores,\" subtitled \"A Lone Humorist Attempts to Explain the Entire U.S. Government\", whose main argument, according to the author, \"is that politics are boring\". He described himself as a libertarian.\nO'Rourke typed his manuscripts on an IBM Selectric typewriter, though he denied being a Luddite, asserting that his short attention span would have made focusing on writing on a computer difficult.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36842", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=36842", "title": "Gossypium", "text": "Genus of flowering plants in the mallow family Malvaceae\nGossypium () is a genus of flowering plants in the tribe Gossypieae of the mallow family, Malvaceae, from which cotton is harvested. It is native to tropical and subtropical regions of the Old and New Worlds. There are about 50 \"Gossypium\" species, making it the largest genus in the tribe Gossypieae, and new species continue to be discovered. The name of the genus is derived from the Arabic word \"goz\", which refers to a soft substance. \nCotton is the primary natural fibre used by humans today, amounting to about 80% of world natural fibre production. Where cotton is cultivated, it is a major oilseed crop and a main protein source for animal feed. Cotton is thus of great importance for agriculture, industry and trade, especially for tropical and subtropical countries in Africa, South America and Asia. Consequently, the genus \"Gossypium\" has long attracted the attention of scientists.\nThe origin of the genus \"Gossypium\" is dated to around 5\u201310\u00a0million years ago. \"Gossypium\" species are distributed in arid to semiarid regions of the tropics and subtropics. Generally shrubs or shrub-like plants, the species of this genus are extraordinarily diverse in morphology and adaptation, ranging from fire-adapted, herbaceous perennials in Australia to trees in Mexico. Most wild cottons are diploid, but a group of five species from America and Pacific islands are tetraploid, apparently due to a single hybridization event around 1.5 to 2 million years ago. The tetraploid species are \"G. hirsutum\", \"G. tomentosum\", \"G. mustelinum\", \"G. barbadense\", and \"G. darwinii\".\nCultivated cottons are perennial shrubs, most often grown as annuals. Plants are 1\u20132\u00a0m high in modern cropping systems, sometimes higher in traditional, multiannual cropping systems, now largely disappearing. The leaves are broad and lobed, with three to five (or rarely seven) lobes. The seeds are contained in a capsule called a \"boll\", each seed surrounded by fibres of two types. These fibres are the more commercially interesting part of the plant and they are separated from the seed by a process called ginning. At the first ginning, the longer fibres, called staples, are removed and these are twisted together to form yarn for making thread and weaving into high quality textiles. At the second ginning, the shorter fibres, called \"linters\", are removed, and these are woven into lower quality textiles (which include the eponymous lint). Commercial species of cotton plant are \"G. hirsutum\" (97% of world production), \"G. barbadense\" (1\u20132%), \"G. arboreum\" and \"G. herbaceum\" (together, ~1%). Many varieties of cotton have been developed by selective breeding and hybridization of these species. Experiments are ongoing to cross-breed various desirable traits of wild cotton species into the principal commercial species, such as resistance to insects and diseases, and drought tolerance. Cotton fibres occur naturally in colours of white, brown, green, and some mixing of these.\nSpecies.\n55 species are accepted.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n\"Gossypium\" genome.\nA public genome sequencing effort of cotton was initiated in 2007 by a consortium of public researchers. They agreed on a strategy to sequence the genome of cultivated, allotetraploid cotton. \"Allotetraploid\" means that the genomes of these cotton species comprise two distinct subgenomes, referred to as the At and Dt (the 't' for tetraploid, to distinguish them from the A and D genomes of the related diploid species). The strategy is to sequence first the D-genome relative of allotetraploid cottons, \"G. raimondii\", a wild South American (Peru, Ecuador) cotton species, because of its smaller size due essentially to less repetitive DNA (retrotransposons mainly). It has nearly one-third the number of bases of tetraploid cotton (AD), and each chromosome is only present once. The A genome of \"G. arboreum\", the 'Old-World' cotton species (grown in India in particular), would be sequenced next. Its genome is roughly twice the size of \"G. raimondii\"'s. Once both A and D genome sequences are assembled, then research could begin to sequence the actual genomes of tetraploid cultivated cotton varieties. This strategy is out of necessity; if one were to sequence the tetraploid genome without model diploid genomes, the euchromatic DNA sequences of the AD genomes would co-assemble and the repetitive elements of AD genomes would assemble independently into A and D sequences, respectively. Then there would be no way to untangle the mess of AD sequences without comparing them to their diploid counterparts.\nThe public sector effort continues with the goal to create a high-quality, draft genome sequence from reads generated by all sources. The public-sector effort has generated Sanger reads of BACs, fosmids, and plasmids, as well as 454 reads. These later types of reads will be instrumental in assembling an initial draft of the D genome. In 2010, two companies (Monsanto and Illumina), completed enough Illumina sequencing to cover the D genome of \"G. raimondii\" about 50x. They announced they would donate their raw reads to the public. This public relations effort gave them some recognition for sequencing the cotton genome. Once the D genome is assembled from all of this raw material, it will undoubtedly assist in the assembly of the AD genomes of cultivated varieties of cotton, but a lot of hard work remains.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36843", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=36843", "title": "ICRM", "text": "ICRM may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "36844", "revid": "3145267", "url": "https://en.wikipedia.org/wiki?curid=36844", "title": "Rutherford backscattering", "text": ""}
{"id": "36845", "revid": "753665", "url": "https://en.wikipedia.org/wiki?curid=36845", "title": "Henry Dunant", "text": "Swiss co-founder of the Red Cross (1828\u20131910)\nHenry Dunant (; born Jean-Henri Dunant; 8 May 1828\u00a0\u2013 30 October 1910), also known as Henri Dunant, was a Swiss humanitarian, businessman, social activist, and co-founder of the Red Cross. His humanitarian efforts won him the first Nobel Peace Prize in 1901.\nDunant was born in Geneva to a devout Calvinist family and had business interests in French Algeria and Tunisia. In 1859, while on his way to petition Napoleon III, he witnessed the aftermath of the Battle of Solferino in northern Italy. Horrified by the suffering of the wounded and the lack of care they received, Dunant took the initiative to organize the local population in providing aid for the soldiers. After returning to Geneva, he recorded his experiences in the book \"A Memory of Solferino\", in which he advocated the formation of an organization that would provide relief for the wounded without discrimination in times of war. In February 1863, Dunant was a member of a five-person committee that sought to put his plan into action, which in effect founded the organization that would become the International Committee of the Red Cross. A year later, he took part in a diplomatic conference organized by the Swiss government that led to the signing of the First Geneva Convention.\nDunant became embroiled in a business scandal in 1867 which resulted in his bankruptcy and expulsion from the International Committee. He spent the next decades in poverty and obscurity, living in various places across Europe before settling in the Swiss village of Heiden. In 1895, Dunant was rediscovered by a journalist, which brought him renewed attention and support, and in 1901 he was awarded the first Nobel Peace Prize alongside French pacifist Fr\u00e9d\u00e9ric Passy. He died in Heiden in 1910.\nEarly life and education.\nDunant was born in Geneva, Switzerland, in 1828 as the first son of businessman Jean-Jacques Dunant and Antoinette Dunant-Colladon. His family was devoutly Calvinist and had significant influence in Geneva society. His parents stressed the value of social work, and his father was active in helping orphans and parolees, while his mother worked with the sick and the poor.\nDunant grew up during the period of religious awakening known as the \"R\u00e9veil\", and at age 18 he joined the Geneva Society for Almsgiving. In the following year, together with friends, he founded the so-called \"Thursday Association\", a loose band of young men that met to study the Bible and help the poor, and he spent much of his free time engaged in prison visits and social work. On 30 November 1852, he founded the Geneva chapter of the YMCA and three years later he took part in the Paris meeting devoted to the founding of its international organization.\nIn 1849, at age 21, Dunant left the Coll\u00e8ge de Gen\u00e8ve due to poor grades and began an apprenticeship with the money-changing firm \"Lullin et Sautter\". After its successful conclusion, he stayed as an employee of the bank.\nAlgeria.\nIn 1853, Dunant visited Algeria, Tunisia, and Sicily, on assignment with a company devoted to the \"colonies of Setif\" (\"Compagnie genevoise des Colonies de S\u00e9tif\"). Despite little experience, he successfully fulfilled the assignment. Inspired by the trip, he wrote his first book with the title \"An Account of the Regency in Tunis\" (\"Notice sur la R\u00e9gence de Tunis\"), published in 1858.\nIn 1856, he created a business to operate in foreign colonies, and, after being granted a land concession by French-occupied Algeria, a corn-growing and trading company called the Financial and Industrial Company of Mons-Dj\u00e9mila Mills (\"Soci\u00e9t\u00e9 financi\u00e8re et industrielle des Moulins des Mons-Dj\u00e9mila\"). However, the land and water rights were not clearly assigned, and the colonial authorities were not especially cooperative. As a result, in 1859 Dunant decided to appeal directly to French emperor Napol\u00e9on III, who was with his army in Lombardy at the time. France was fighting on the side of Piedmont-Sardinia against Austria in the Austro-Sardinian War. Napoleon's headquarters were located in the small city of Solferino. Dunant wrote a flattering book full of praise for Napoleon III with the intention to present it to the emperor and then travelled to Solferino to meet with him personally.\nBattle of Solferino.\nDunant arrived in Solferino on the evening of 24 June 1859, on the same day a battle between the two sides had occurred nearby. Forty thousand wounded, dying and dead remained on the battlefield, and there appeared to be little attempt to provide care. Shocked, Dunant himself took the initiative to organize the civilian population, especially the women and girls, to provide assistance to the injured and sick soldiers. They lacked sufficient materials and supplies, and Dunant himself organized the purchase of needed materials and helped erect makeshift hospitals. He convinced the population to service the wounded without regard to their side in the conflict as per the slogan \"Tutti fratelli\" (All are brothers) coined by the women of the nearby city Castiglione delle Stiviere. He also succeeded in gaining the release of Austrian doctors captured by the French and British.\nRed Cross founding history.\nAfter returning to Geneva early in July, Dunant decided to write a book about his experiences, which he titled \"Un Souvenir de Solferino\" (\"A Memory of Solferino\"). It was published in 1862 in an edition of 1,600 copies and was printed at Dunant's own expense. In the book, he described the battle, its costs, and the chaotic circumstances afterwards. He also developed the idea that in the future a neutral organization should exist to provide care to wounded soldiers. He distributed the book to many leading political and military figures in Europe.\nDunant also began to travel through Europe to promote his ideas. His book was largely positively received, and the President of the Geneva Society for Public Welfare, jurist Gustave Moynier, made the book and its suggestions the topic of the 9 February 1863 meeting of the organization. Dunant's recommendations were examined and positively assessed by the members. They created a five-person Committee to further pursue the possibility of their implementation and made Dunant one of the members. The others were Moynier, the Swiss army general Henri Dufour, and doctors Louis Appia and Th\u00e9odore Maunoir. Their first meeting on 17 February 1863 is now considered the founding date of the International Committee of the Red Cross.\nFrom early on, Moynier and Dunant had increasing disagreements and conflicts regarding their respective visions and plans. Moynier considered Dunant's idea to establish neutrality protections for care providers unfeasible and advised Dunant not to insist upon this concept. However, Dunant continued to advocate this position in his travels and conversations with high-ranking political and military figures. This intensified the personal conflict between Moynier, who took a rather pragmatic approach to the project, and Dunant, who was the idealist among the five.\nIn October 1863, 14 states took part in a meeting in Geneva organized by the committee to discuss improving care for wounded soldiers. Dunant was a protocol leader during the meeting. A year later, on 22 August 1864, a diplomatic conference organized by the Swiss government led to the signing of the First Geneva Convention by 12 states. Dunant was in charge of organizing accommodation for the attendees.\nForgotten period.\nDunant's businesses in Algeria had suffered. In April 1867, the bankruptcy of the financial firm \"Cr\u00e9dit Genevois\" led to a scandal involving Dunant. He declared bankruptcy. The social outcry in Geneva, a city deeply rooted in Calvinist traditions, also led to calls for him to separate himself from the International Committee. Already on 25 August 1867, he resigned as Secretary and, on 8 September 1867, he was fully removed from the committee. Dunant was condemned by the Geneva Trade Court on 17 August 1868 for deceptive practices in the bankruptcies. Due to their investments in the firm, his family and many of his friends were also heavily affected by the downfall of the company.\nIn February 1868, Dunant's mother died. Later that year he was expelled from the YMCA, because he was the Geneva founder of it, and they felt his business failure tainted the group. In March 1867, he left his home city of Geneva, and would not return for the rest of his life. In the following years, Moynier likely used his influence to attempt to ensure that Dunant would not receive assistance and support from his friends. For example, the gold medal prize of \"Sciences Morales\" at the Paris World's Fair did not go to Dunant as originally planned but to Moynier, Dufour, and Dunant together so that the prize money would only go to the committee as a whole. Napol\u00e9on III's offer to take over half of Dunant's debts if Dunant's friends would secure the other half was also thwarted by Moynier's efforts.\nDunant moved to Paris, where he lived in meagre conditions. However, he continued to pursue his humanitarian ideas and plans. During the Franco-Prussian War (1870\u20131871), he founded the Common Relief Society (\"Allgemeine F\u00fcrsorgegesellschaft\") and soon after the Common Alliance for Order and Civilisation (\"Allgemeine Allianz f\u00fcr Ordnung und Zivilisation\"). He argued for disarmament negotiations and for the erection of an international court to mediate international conflicts. Later he worked for the creation of a world library, an idea which had echoes in future projects such as UNESCO.\nIn his continued pursuit and advocacy of his ideas, he further neglected his personal situation and income, falling further into debt and being shunned by his acquaintances. Despite being appointed an honorary member of the national Red Cross societies of Austria, the Netherlands, Sweden, Prussia and Spain, he was nearly forgotten in the official discourse of the Red Cross Movement, even as it was rapidly expanding to new countries. He lived in poverty, moving to various places between 1874 and 1886, including Stuttgart, Rome, Corfu, Basel, and Karlsruhe. In Stuttgart, he met the T\u00fcbingen University student Rudolf M\u00fcller with whom he would have a close friendship. In 1881, together with friends from Stuttgart, he went to the small Swiss resort village Heiden for the first time. In 1887 while living in London, he began to receive some monthly financial support from some distant family members. This enabled him to live a somewhat more secure existence, and he moved to Heiden in July. He spent the rest of his life there, and after 30 April 1892, he lived in a hospital and nursing home led by Dr. Hermann Altherr.\nIn Heiden, he met the young teacher Wilhelm Sonderegger and his wife Susanna; they encouraged him to record his life experiences. Sonderegger's wife founded a branch of the Red Cross in Heiden and in 1890 Dunant became its honorary president. With Sonderegger, Dunant hoped to further promote his ideas, including publishing a new edition of his book. However, their friendship later was strained by Dunant's unjustified accusations that Sonderegger, with Moynier in Geneva, was somehow conspiring against Dunant. Sonderegger died in 1904 at age 42. Despite their strained relationship, Dunant was deeply moved by the unexpected death. Wilhelm and Susanna Sonderegger's admiration for Dunant, felt by both even after Dunant's allegations, was passed on to their children. In 1935, their son Ren\u00e9 published a compilation of letters from Dunant to his father.\nReturn to public memory.\nIn September 1895, Georg Baumberger, the chief editor of the St. Gall newspaper \"Die Ostschweiz\", wrote an article about the Red Cross founder, whom he had met and conversed with during a walk in Heiden a month earlier. The article entitled \"Henri Dunant, the founder of the Red Cross\", appeared in the German Illustrated Magazine \"\u00dcber Land und Meer\", and the article was soon reprinted in other publications throughout Europe. The article struck a chord, and he received renewed attention and support. He received the Swiss Binet-Fendt Prize and a note from Pope Leo XIII. Because of support from Russian tsarist widow Maria Feodorovna and other donations, his financial situation improved remarkably.\nIn 1897, Rudolf M\u00fcller, who was now working as a teacher in Stuttgart, wrote a book about the origins of the Red Cross, altering the official history to stress Dunant's role. The book also contained the text of \"A Memory of Solferino\". Dunant began an exchange of correspondence with Bertha von Suttner and wrote numerous articles and writings. He was especially active in writing about women's rights, and in 1897 facilitated the founding of a \"Green Cross\" women's organization whose only section was briefly active in Brussels.\nNobel Peace Prize.\nIn 1901, Dunant was awarded the first-ever Nobel Peace Prize for his role in founding the International Red Cross Movement and initiating the Geneva Convention. By public and private means, M\u00fcller, and later Norwegian military physician Hans Daae (who had received a copy of M\u00fcller's book), advocated Dunant's case to the Nobel committee over the course of 4 years. The award was jointly given to French pacifist Fr\u00e9d\u00e9ric Passy, founder of the Peace League and active with Dunant in the Alliance for Order and Civilization. The official congratulations which he received from the International Committee finally represented the rehabilitation of Dunant's reputation:\n\"There is no man who more deserves this honour, for it was you, forty years ago, who set on foot the international organization for the relief of the wounded on the battlefield. Without you, the Red Cross, the supreme humanitarian achievement of the nineteenth century would probably have never been undertaken.\"\nMoynier and the International Committee as a whole had also been nominated for the prize. Although Dunant was supported by a broad spectrum in the selection process, he was still a controversial candidate. Some argued that the Red Cross and the Geneva Convention had made war more attractive and imaginable by eliminating some of its suffering. Therefore, M\u00fcller, in a letter to the committee, argued that the prize should be divided between Dunant and Passy, who for some time in the debate had been the leading candidate to be the sole recipient of the prize. M\u00fcller also suggested that if a prize were to be warranted for Dunant, it should be given immediately because of his advanced age and ill health.\nBy dividing the prize between Passy, a pacifist, and Dunant, a humanitarian, the Nobel Committee set a precedent for the conditions of the Nobel Peace Prize selection which would have significant consequences in later years. A section of Nobel's will had indicated that the prize should go to an individual who had worked to reduce or eliminate standing armies, or directly to promote peace conferences, which made Passy a natural choice for his peace work. On the other hand, the arguably distinct bestowal for humanitarian effort alone was seen by some as a wide interpretation of Nobel's will. However, another part of Nobel's testament marked the prize for the individual who had best enhanced the \"brotherhood of people,\" which could be interpreted more generally as seeing humanitarian work like Dunant's as connected to peacemaking as well. Many recipients of the Nobel Peace Prize in later years can be assigned to either of these two categories first roughly established by the Nobel committee's decision in 1901.\nHans Daae succeeded in placing Dunant's part of the prize money, 104,000 Swiss Francs, in a Norwegian Bank and preventing access by his creditors. Dunant himself never spent any of the money during his lifetime, continuing to live simply and reserving it for bequests in his will to those who cared for him and charitable causes.\nDeath and legacy.\nAmong several other awards in the following years, in 1903 Dunant was given an honorary doctorate by the medical faculty of the University of Heidelberg. He lived in the nursing home in Heiden until his death. In the final years of his life, he suffered from depression and paranoia about pursuit by his creditors and Moynier. There were even days when Dunant insisted that the cook of the nursing home first taste his food before his eyes to protect him against possible poisoning. In his final years, he spurned and attacked Calvinism and organized religion generally. He was said to be agnostic.\nAccording to his nurses, the final act of his life was to send a copy of M\u00fcller's book to the Italian queen with a personal dedication. He died on 30 October 1910, and his final words were \"Where has humanity gone?\"\nAccording to his wishes, he was buried without ceremony in the Sihlfeld Cemetery in Z\u00fcrich. In his will, he donated funds to secure a \"free bed\" in the Heiden nursing home always to be available for a poor citizen of the region and deeded some money to friends and charitable organizations in Norway and Switzerland. The remaining funds went to his creditors partially relieving his debt; his inability to fully erase his debts was a major burden to him until his death.\nHis birthday, 8 May, is celebrated as the World Red Cross and Red Crescent Day. The former nursing home in Heiden now houses the Henry Dunant Museum. In Geneva and other places there are numerous streets, squares, and schools named after him. The Henry Dunant Medal, awarded every two years by the standing commission of the International Red Cross and Red Crescent Movement is its highest decoration.\nHis life is represented, with some fictional elements, in the film \"D'homme \u00e0 hommes\" (1948), starring Jean-Louis Barrault, and the period of his life when the Red Cross was founded in the international film coproduction \"Henry Dunant: Red on the Cross\" (2006). In 2010 the Takarazuka Revue staged a musical based on his time in Solferino and the founding of the Red Cross entitled \"Dawn at Solferino, or Where has Humanity Gone?\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\nEnglish books.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nGerman books.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "36846", "revid": "37052726", "url": "https://en.wikipedia.org/wiki?curid=36846", "title": "Jean Henri Dunant", "text": ""}
{"id": "36847", "revid": "38005489", "url": "https://en.wikipedia.org/wiki?curid=36847", "title": "Sports governing body", "text": "Sports organization\nA sports governing body is a sports organization that has a regulatory or sanctioning function.\nSports governing bodies come in various forms and have a variety of regulatory functions, including disciplinary procedure for rule infractions and deciding on rule\nchanges in the sport that they govern. Governing bodies have different scopes. They may cover a range of sport at an internationally acceptable level, such as the International Olympic Committee and the International Paralympic Committee, or only a single sport at a national level, such as the Rugby Football League. National bodies will largely have to be affiliated with international bodies for the same sport. The first international federations were formed at the end of the 19th century.\nTypes of sports governing bodies.\nEvery sport has a different governing body that can define the way that the sport operates through its affiliated clubs and societies. This is because sports have different levels of difficulty and skill, so they can try to organize the people playing their sport by ability and by age. There are several different types of sport governing bodies.\nInternational sports federations.\nInternational sports federations are non-governmental non-profit organizations for a given sport (or a group of similar sport disciplines, such as aquatics or skiing) and administers its sport at the highest level. These federations work to create a common set of rules, promote their sport, and organize international competitions. International sports federations represent their sport at the Olympic level where applicable.\nAbout 30 international sport federations are located in Switzerland, with about 20 or so in the Lausanne area, where the International Olympic Committee is located.\nInternational federations for sports that do not participate in the Olympic Games are managed by equivalent organizations to the International Olympic Committee, such as the SportAccord.\nInternational federations are typically organized with legislative and executive branches at the top. The legislative body is usually referred to as a congress or general assembly of the international federation and is responsible for defining its sports policies. It consists of all of the national federations, each of which receives one vote. On the other hand, the executive branch, which is often referred to as the council or executive committee, consists of elected members by the legislative branch and is responsible for directing, managing, and representing their federation.\nTrusts.\nTrusts are organizations or groups that have control over the money that will be used to help someone else, such as the Youth Sport Trust.\nNational governing bodies.\nNational governing bodies have the same objectives as those of an international federation, but within the scope of one country, or even part of a country, as the name implies. They support local clubs and are often responsible for national teams. National Olympic Committees and National Paralympic Committees are both a type of national federation, as they are responsible for a country's participation in the Olympic Games and in the Paralympic Games respectively. A national governing body (NGB) however can be different from a national federation due to government recognition requirements. Also, national governing bodies can be a supraorganization representing a range of unrelated organizations operating in a particular sport, as evident in the example of the Northern Ireland Federation of Sub-Aqua Clubs.\nEvent organizers.\nMulti-sport event organizers are responsible for the organization of an event that includes more than one sport. The best-known example is the International Olympic Committee (IOC), the organizer of the modern Olympic Games. General sports organizations are responsible for sports-related topics, usually for a certain group, such as the Catholic or Jewish sports groups. General sports organizations and multi-sport events also exist for other groups such as the Invictus Games for military veterans.\nProfessional leagues.\nProfessional sports leagues are usually the highest level of play in sport, specifically if they consist of the best players around the world in a certain sport. Because of this, they usually work with national or international federations, but there is usually a separation between the different federations. Most North American professional leagues usually do not have amateur divisions, as the amateur divisions are mostly run in separate leagues. Also, most professional leagues are related to other leagues, as players usually attempt to play in the league with the highest level of play. Because of this, promotion and relegation can occur; or, in league systems without promotion and relegation, clubs in professional leagues can have a team in the minor leagues. This enables them to shuffle players who are not doing well to the minor leagues, which will inspire them to contribute more to the team by playing better.\nCriticisms.\nA 2014 study by the Institute for Human Rights and Business (IHRB) criticized major international sports governing bodies including the International Olympic Committee and FIFA for not having sufficient provisions for human and labor rights.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36848", "revid": "329633", "url": "https://en.wikipedia.org/wiki?curid=36848", "title": "ECOWAS", "text": "Formation of international cooperation among African States\nThe Economic Community of West African States (ECOWAS; also known as CEDEAO in French and Portuguese) is a regional political and economic union of twelve countries of West Africa. Collectively, the present and former members comprise an area of and have an estimated population of over 424.34 million.\nConsidered one of the pillar regional blocs of the continent-wide African Economic Community (AEC), the stated goal of ECOWAS is to achieve \"collective self-sufficiency\" for its member states by creating a single large trade bloc by building a full economic and trading union. Additionally, ECOWAS aims to raise living standards and promote economic development. The union was established on 28 May 1975, with the signing of the Treaty of Lagos, with its stated mission to promote economic integration across the region. A revised version of the treaty was agreed and signed on 24 July 1993 in Cotonou, the largest city in Benin.\nECOWAS's published principles include equality and inter-dependence of member states, solidarity, self-reliance, cooperation and harmonization of policies, nonaggression, promotion of human rights, economic and social justice, and democratic governance.\nNotably among ECOWAS's protocols and plans are the ECOWAS Free Movement of Persons, Residences and Establishment Protocol and the Ecotour Action Plan 2019\u20132029. The \"Free Movement of Persons Protocol\" permits citizens the right to enter and reside in any member state's territory, and the \"Ecotour Action Plan\" aims to develop and integrate the tourist industry of each member state.\nECOWAS also serves as a peacekeeping force in the region, with member states occasionally sending joint military forces to intervene in the bloc's member countries at times of political instability and unrest.\nIn 2024, the military governments of Niger, Burkina Faso, and Mali jointly announced their withdrawal from the bloc, after having been suspended following respective military takeovers in these countries. The withdrawal took effect on 29 January 2025. The three later went on to form the Alliance of Sahel States, with the end goal of establishing a federation.\nMember states.\nECOWAS currently has 12 member states: five French-speaking, five English-speaking, and two Portuguese-speaking. All current members joined the community as founding members in May 1975, except Cape Verde which joined in 1977.\nMorocco officially requested to join ECOWAS in February 2017. The application was endorsed in principle at the Summit of Heads of State in June 2017. However, Morocco's bid for membership was stalled as West African economic actors feared goods imported through Morocco's free trade agreements would flood the market of states within ECOWAS.\nStates that have withdrawn or been suspended.\nArabic-speaking Mauritania was one of the founding members of ECOWAS in 1975 and decided to withdraw in December 2000. Mauritania signed a new associate-membership agreement in August 2017.\nMali was suspended from ECOWAS on 30 May 2021, following its second military coup within nine months. Guinea was also suspended on 8 September 2021, shortly after a military coup took place in the country. Sanctions were placed on both countries on 16 September. On 10 January 2022, Mali announced its decision to close its borders and recalled several ambassadors with ECOWAS in response to sanctions imposed for deferring elections for four years. On 28 January 2022, Burkina Faso was suspended from ECOWAS following a military coup. Niger was suspended from ECOWAS after the 2023 coup d'\u00e9tat and threatened with military intervention if President Mohamed Bazoum was not restored to office, causing the Nigerien crisis. Additionally, ECOWAS closed all land and air borders between other member states and Niger and instituted a no-fly zone on all commercial flights to and from Niger. The suspension removed all commercial and financial transactions and froze Niger's assets in ECOWAS central banks. On 16 September 2023, Niger, Mali, and Burkina Faso formed a military alliance, the Alliance of Sahel States (AES), following ECOWAS's threat to intervene to restore civilian rule in Niger. On 21 November 2023, Niger's military government asked the ECOWAS regional court to order the lifting of sanctions imposed on the country. Until the coup, aid from countries like the United States and international organizations like ECOWAS accounted for almost half of Niger's annual budget. Following Niger's ECOWAS suspension, Niger's neighbours closed their borders to the country and 70 percent of its electricity, coming from Nigeria, was cut off. While these sanctions and consequences that have followed have affected the individuals and economy of Niger, the government is not backing down. As a result of the suspension, children have not been able to attend school due to lack of supplies, and businesses are shutting down due to rising costs. Further, the ECOWAS lawyer pointed out that the Nigerien government is not recognized by ECOWAS and therefore does not have the power to ask the regional court for a removal of these sanctions.\nOn 28 January 2024, Niger, Mali, and Burkina Faso announced via a joint statement that they were withdrawing from ECOWAS \"without delay\". The three nations, all of which are currently ruled by military juntas, accused ECOWAS of implementing \"inhumane\" sanctions in order to reverse the coups in each nation. Under the ECOWAS protocol, immediate withdrawal is not possible, and the three member states could remain in the bloc for up to a year. ECOWAS said in a statement that \"Burkina Faso, Niger and Mali remain important members of the Community and the Authority remains committed to finding a negotiated solution to the political impasse.\"\nOn 24 February 2024, ECOWAS announced that it was lifting some sanctions against Niger, Mali and Burkina Faso. For Niger this included the border closures, the freezing of central bank and state assets, the suspension of commercial transactions, and the no-fly-zone for commercial flights to and from Niger. However, the political sanctions and targeted sanctions would remain in force. The communiqu\u00e9 said this was done for humanitarian reasons, but it was seen as a gesture of appeasement to dissuade the three junta-led states from withdrawing from the bloc. ECOWAS also lifted sanctions on Guinea and Guinea-Bissau.\nIn December 2024, ECOWAS heads of state of the member countries met to finalize the decision regarding the withdrawal of Mali, Niger and Burkina Faso, united under the AES. President of Senegal, Basirou Diomaye Faye, stated on 8 December 2024 that he was continuing to discuss with the three countries remaining in ECOWAS, while maintaining the Alliance of Sahel States, which he recognized as a security response in the Sahel region. On 12 December 2024, ECOWAS President Bola Tinubu confirmed the political will of ECOWAS leaders to reintegrate the three countries from the Alliance of Sahel States. On 15 December 2024, the Conference of Heads of State of ECOWAS adopted an exit transition period for Niger, Burkina Faso, Mali, which begins on 29 January 2025 and ends on 29 July 2025. During this transition period, ECOWAS has indicated that any exit would be reversible. The AES rejected the proposal. Celebrations were held in the three countries to mark the formal exit on 29 January. ECOWAS noted the withdrawal, while calling for the continuance of existing arrangements for the free movement of people and goods, including requesting its own members still accept documents from the departing countries.\nThe Foreign Ministers of the Alliance of Sahel States met on 26 January 2025, in Ouagadougou \"in anticipation of future talks with ECOWAS\", The Ministers reached a consensus on the overall approach to future negotiations with ECOWAS, in the best interest of the Sahelian populations. From 29 January 2025, begins the beginning of a six-month \"transition period\" after the official separation with the three Sahelian countries. The three Sahelian countries rejected any possibility of reversing their decision.\nIn June 2025, the heads of state of ECOWAS met to finalize the formalities for the countries' exit from the alliance of Sahel states.\nOn 29 November 2025 Guinea-Bissau was suspended by ECOWAS following a coup d'\u00e9tat.\nStatistics for population, nominal GDP and purchasing power parity GDP listed below are taken from World Bank estimates for 2015, published in December 2016. Area data is taken from a 2012 report compiled by the United Nations Statistics Division.\nHistory.\nECOWAS was formed initially from the region's former French, British and Portuguese colonies, and independent Liberia, following post-colonial independence throughout the region (particularly in the 1960s and 1970s). At independence, many African states were challenged in increasing economic development. Because these states could not address problems individually, there was a need for a regional approach and thus ECOWAS was founded. ECOWAS was formed to provide regional economic cooperation, but has since evolved to include political and military cooperation, as well.\nThe union was established on 28 May 1975, with the signing of the Treaty of Lagos, with its stated mission to promote economic integration across the region. A revised version of the treaty was agreed and signed on 24 July 1993 in Cotonou. Considered one of the pillar regional blocs of the continent-wide African Economic Community (AEC), the stated goal of ECOWAS is to achieve \"collective self-sufficiency\" for its member states by creating a single large trade bloc by building a full economic and trading union.\nECOWAS also serves as a peacekeeping force in the region, with member states occasionally sending joint military forces to intervene in the bloc's member countries at times of political instability and unrest. ECOWAS facilitates peacekeeping through systematic collaboration with civil society, cooperation with development policies, and other activities with the goal to meet sub-regional security challenges. It has played an important role in monitoring transitional election in West Africa, and these mediation efforts have even been recognized within and outside the continent of Africa. In recent years these included interventions in Ivory Coast in 2003, Liberia in 2003, Guinea-Bissau in 2012, Mali in 2013, The Gambia in 2017, and Guinea-Bissau in 2022. Since its creation, ECOWAS has sent peacekeeping forces seven times.\nIn 2011, ECOWAS adopted its development blueprint for the next decade, \"Vision 2020\", and, to accompany it, a Policy on Science and Technology (ECOPOST). However, it has had trouble achieving the goals outlined in the policy.\nCovering a region known as a \"coup belt\", ECOWAS, since the 1990s, has attempted to defend the region's shift towards democracy against authoritarian attacks. According to the BBC, since 1990, 78% of the 27 coups in sub-Saharan Africa have taken place in former French colonies. This has led some to question whether French influence in Africa has a destabilising effect. The transition governments in Mali and Burkina Faso cancelled military agreements that allow for French troops to operate on their territory, and in the case of Mali, removed French as an official language. However, the group has been cited for mild and ineffective responses in the early 2020s, when three member countries experienced military coups d'\u00e9tat \u2013 two in Mali, one in Guinea, and two in Burkina Faso. When a fourth member, Niger, experienced a coup d'\u00e9tat in July 2023, ECOWAS was vocal in its condemnation and raised the possibility of military action if the deposed president was not reinstated by 7 August 2023. Due to the Nigerien military's refusal to restore civilian rule, ECOWAS activated its standby force composed of all other members except for Mali, Burkina Faso, Guinea and Cape Verde.\nOn 6 July 2024, the military leaders of Niger, Mali, and Burkina Faso signed a new pact to form a confederation, a political union of sovereign states. The confederation's stated goal is to provide mutual defense, pool resources to build energy and communications infrastructure, establish a common market, implement a monetary union under proposed currency \"the Sahel\", allow free movement of persons, enable industrialization, and invest in agriculture, mines and energy sectors, with the end goal of federalizing into a single sovereign state. The move is seen as a strong move away from ECOWAS, which has been pressing for a return to civilian rule.\nStructure.\nOverall.\nECOWAS consists of two operating institutions to implement policies: the ECOWAS Commission and the ECOWAS Bank for Investment and Development (EBID) \u2013 formerly known as the Fund for Cooperation, until it was renamed in 2001.\nIn addition, ECOWAS includes the following institutions: ECOWAS Commission, Community Court of Justice, Community Parliament, ECOWAS Bank for Investment and Development (EBID), West African Health Organisation (WAHO), and the Inter-Governmental Action Group against Money Laundering and Terrorism Financing in West Africa (GIABA).\nECOWAS includes two sub-regional blocks:\nECOWAS operates in three co-official languages\u2014French, English, and Portuguese.\nRegional security co-operation.\nECOWAS nations signed a non-aggression protocol in 1990 along with two earlier agreements in 1978 and 1981. They also signed a Protocol on Mutual Defence Assistance in Freetown, Sierra Leone, on 29 May 1981, that provided for the establishment of an Allied Armed Force of the Community.\nCommunity Parliament.\nThe Community Parliament consists of 115 members, distributed based on the population of each member state. This body is headed by the Speaker of the Parliament, who is above the Secretary General.\nExpanded ECOWAS Commission.\nFor the third time since its inception in 1975, ECOWAS is undergoing institutional reforms. The first was when it revised its treaty on 24 July 1993; the second was in 2007 when the Secretariat was transformed into a Commission. As of July 2013, ECOWAS now has six new departments (Human Resources Management; Education, Science and Culture; Energy and Mines; Telecommunications and IT; Industry and Private Sector Promotion). Finance and Administration to Sierra Leone has been decoupled, to give the incoming Ghana Commissioner the new portfolio of Administration and Conferences.\nCommunity Court of Justice.\nECOWAS Community Court of Justice was created by a protocol signed in 1991 and was later included in Article 6 of the Revised Treaty of the Community in 1993. However, the Court did not officially begin operations until the 1991 protocol came into effect on 5 November 1996. The jurisdiction of the court is outlined in Article 9 and Articles 76 of the Revised Treaty and allows rulings on disputes between states over interpretations of the Revised Treaty. It also provides ECOWAS Council with advisory opinions on legal issues (Article 10). Like its companion courts, the European Court of Human Rights and East African Court of Justice, it has jurisdiction to rule on fundamental human rights breaches.\nSporting and cultural exchange.\nECOWAS nations organise a broad array of cultural and sports events under the auspices of the body, including the CEDEAO Cup in football, the 2012 ECOWAS Games and the Miss CEDEAO beauty pageant.\nThe Community Heads of State and Government adopted African Traditional Wrestling as the Community sport, and through its specialised agency in charge of youth and sports development, the Ouagadougou-based ECOWAS Youth and Sports Development Centre (EYSDC), has consistently organised the yearly ECOWAS African Wrestling Tournament mainly in Dakar (Senegal) and Niamey (Niger) based on a harmonized African wrestling code.\nThe Community, through the EYSDC, also organized 2 editions of ECOWAS International Cycling tour, taking close to 100 riders from all member states, from Lagos to Accra and then from Lagos to Abidjan. In addition to the sports and well-being objective of the tour, the race also served to demonstrate and put into practice ECOWAS protocol on free movement of goods and persons.\nIn 2019, the EYSDC instituted ECOWAS Abuja International Marathon. The first edition brought together international marathoners from West Africa, Kenya, Ethiopia and Cameroon.\nSimilarly, the Community, through its specialised agency, promotes regional sports development by offering sponsorship to regional sports federations and specialized disciplines such as the West African Deaf Sports Union (WADSU), the West African Liaison Office of the International Council for Military Sports (WALO-CISM), the Region 2 of the African Athletics Federation, and the West African University Games (WAUG), among others.\nYouth.\nThe ECOWAS Youth Policy Strategic Plan of Action (SPAO) is a 10-year plan that aims to promote youth development and empowerment in the Economic Community of West African States (ECOWAS). The SPAO was adopted in 2016 and is based on the pillars of education and training, employment and entrepreneurship, health and well-being, peace and security, and governance and participation.\nThe SPAO identifies a number of challenges facing youth in ECOWAS, including high unemployment rates, lack of access to education and training, and poor health outcomes. The plan sets out a number of strategies to address these challenges, including investing in education and training, creating jobs and supporting entrepreneurship, improving access to health care, promoting peace and security, and strengthening youth participation in governance.\nEconomic integration.\nWest African Economic and Monetary Union (UEMOA).\nFormed in 1994 on the basis of earlier arrangements whose roots lie in the colonial era of French West Africa, the West African Economic and Monetary Union, often referred to by its French acronym UEMOA, brings together eight West African states of which seven were French colonies until the late 1950s. The member countries use the West African CFA franc as their currency and share common institutions including the Central Bank of West African States, Banking Commission of the West African Monetary Union, Financial Markets Authority of the West African Monetary Union, and (together with other African countries of the Franc Zone) Regional Insurance Control Commission.\nWest African Monetary Zone.\nFormed in 2000, the West African Monetary Zone (WAMZ) is a group of six countries within ECOWAS that plan to introduce a common currency called the eco. The six member states of WAMZ are Gambia, Ghana, Guinea, Nigeria and Sierra Leone who founded the organisation together in 2000 and Liberia who joined on 16 February 2010. Apart from Guinea, which is francophone, they are all English-speaking countries. Along with Mauritania, Guinea opted out of the CFA franc currency shared by all other former French colonies in West and Central Africa.\nThe WAMZ attempts to establish a strong stable currency to rival the CFA franc, whose exchange rate is tied to that of the euro and is guaranteed by the French Treasury. The eventual goal is for the CFA franc and eco to merge, giving all of West and Central Africa a single, stable currency. The launch of the new currency is being developed by the West African Monetary Institute based in Accra, Ghana.\nWith the exit of Mali, Niger and Burkina Faso from the body, two structural options for a single currency could emerge: the \"Sahel\" for the AES and the \"Eco\" for the ECOWAS member countries.\nThe Free Movement of Persons, Residence and Establishment Protocol.\nIn May 1979, ECOWAS adopted a Free Movement of Persons, Residence and Establishment Protocol, which permits citizens to enter, reside, and establish economic activities in the territory of member states. There were three phases of implementation to achieve the goals of the protocol. Over the course of five years, Phase I eliminated the need for visas for stays of up to 90 days within the ECOWAS territory. Phase II attempted to extend residency to citizens in host ECOWAS states to seek income-earning employment after obtaining an ECOWAS residence card. Phase II also required member states to grant migrant workers equal treatment in areas such as employment, participation, social and cultural activities, and in certain cases of job loss, re-employment, and training. Phase III centered on the facilitation and establishment of business through the right of citizens to manage economic activities in countries other than their country of origin. However, this right has not been fully established in the ECOWAS region. While these three phases promoting freedom of movement within the ECOWAS region is more advanced than in any other regional grouping in Africa, only the first phase has been fully implemented by all ECOWAS countries. The complete implementation of the 90-day visa-free window enhanced human mobility in the region, creating positive effects on trade and economic development.\nIn December 2000, the ECOWAS passport was introduced as a common passport that functions as an international travel document, and member states are currently in the process of implementing a joint visa for non-ECOWAS citizens. Additionally, ECOWAS has worked to ease the movement of people transported in private and commercial vehicles by implementing policies that enable vehicles to enter and reside in a State for up to ninety days. Most ECOWAS states have instituted an ECOWAS brown card, which provides prompt, fair, and immediate compensation for any motor accident which occurs outside a motorist's home-country.\nWhile monitoring committees exist to ensure all three phases of the protocol are successfully implemented, their work is vague and has not been credited with effective and efficient production of data. The largest challenges assosicated within the implementation of the protocol occur due to lack of commitment and enforceability. More so, there is a lack of access to readily available migrant information in the ECOWAS region. This poses a barrier to freedom of movement as immigration officials in member states are unaware that individuals who hold valid travel documents can enter their country freely. Therefore, West African migrants, who are entitled to enter through regular channels, leave their countries without proper travel documents and enter other countries illegally. This illegal and irregular entry poses a barrier towards gaining reliable travel statistics.\nFor example, Francophone countries in the region have issued national identity cards that can be used similarly to a passport. These cards permit citizens to cross borders after presenting their identity cards. However, Anglophone countries have only just begun distributing a similar form of identification. Consequently, immigration officials in Anglophone countries commonly reject Francophone national identity cards and do not permit Francophone citizens to cross into their borders. Further, these structural barriers are exasperated between different social classes. Middle-class individuals typically experience a smoother border-crossing process than working-class individuals and impoverished citizens who do not have travel documents and are not fluent in the language of the countries they are crossing into.\nTransport.\nA Trans-ECOWAS project, established in 2007, plans to upgrade railways in this zone.\nTourism.\nIn 2019, ECOWAS unveiled its Ecotour Action Plan 2019 \u2013 2029. It focuses on tourism heritage protection and development and on the development of standards, regulations, and control systems. The plan includes five programs for implementation, and detailed mechanisms for monitoring and evaluation. Ecotourism is not specifically developed, yet it has been mentioned that the program has the opportunity to create linkages between institutions and stakeholder collaboration to suit ecotourism projects that prioritize community, biodiversity, and socioeconomics. The Ecotour Plan prioritizes local development, especially in generating skilled and unskilled jobs for marginalized individuals, and aims to make the ECOWAS region a first-class tourist destination in Africa. During its creation, ECOWAS ministers also called on ecotourism programs to protect threatened biodiversity in the Guinean Forests, which span into seven ECOWAS member states. Similar to the Free Movement of People Protocol, Ecotour aims to integrate aviation and ground transportation. ECOWAS hopes that this regional approach will allow states to fight against pandemics such as COVID-19 to restore tourism and ecosystems. Ecotour works to create increasing returns to its members' economies by lowering transport costs, developing hospitality training centers and creating a more integrated use of digital technology.\nAs of March 2023, Council members mentioned that phases one and two of the Ecotour Action Plan have come to an end and that the community is moving into phase three and four, which focuses on the development of tourist accommodations establishments, and a proposal for a regional mechanism to enforce tourist regulations. By the end of phase five, ECOWAS hopes to have unified accommodations in hotels, ecolodges, motels, apart hotels, and hostels. In April 2023, tourism experts met to amend the new text for tourist accommodations in the ECOWAS region. This phase is critical to the success of the Ecotour plan as the lack of a regulatory system has been a barrier to the development of the tourism sector, despite its ability to increase member states' economies. During this conference, ministers improved the tourism industry by adopting standards for hotel services. Massandj\u00e9 Toure-Liste, the ECOWAS Commission's Commissioner for Economic Affairs and Agriculture, pointed out the improvements in the tourist sector due to the African Continental Free Trade Area, a trade agreement signed by 44 members of the African Union which creates a single market for goods and services. Toure-Liste praised the trade area for providing development opportunities, economic growth, and boosting regional integration.\nRepatriation of cultural artefacts.\nECOWAS has emerged as a key regional actor in the movement to repatriate cultural property removed during colonial and post-colonial conflicts. In 2019, its Ministers of Culture adopted a Regional Action Plan for the return of African cultural artefacts to their countries of origin, marking a formal commitment to correct historical injustices and to safeguard regional heritage.\nWest Africa's museums, palaces and sacred sites suffered extensive plunder under European colonial regimes. Artefacts ranging from royal regalia to ritual objects were extracted and dispersed across Europe and North America. This loss of cultural patrimony weakened local identities and deprived future generations of tangible links to their past. By the late twentieth century, ECOWAS member states recognised that repatriating such objects was essential to restoring cultural continuity and promoting tourism and education in the region.\nIndividual member states initiated bilateral requests for return of artefacts as early as the 1960s, but these efforts often lacked coordination and leverage. In December 2018, ECOWAS Heads of State adopted a Political Declaration in Abuja instructing the Commission to develop a regional mechanism for repatriation, reflecting a consensus that joint action would carry greater weight in negotiations with former colonial powers. Critics warned that without legal force, the plan risked being a symbolic gesture.\nOn 17 July 2019 in Cotonou, Benin, ECOWAS Ministers of Culture validated the 2019\u20132023 Regional Action Plan for the return of cultural artefacts. The Plan sets out six strategic objectives, including establishing a legal framework, mobilising financing, strengthening governance and mapping artefact inventories held abroad. In May 2021, ECOWAS Commissioner Mamadou Traor\u00e9 led advocacy talks with Liberian authorities to encourage ratification of the 1970 UNESCO Convention and the 1995 UNIDROIT Convention on Stolen or Illegally Exported Cultural Objects, underscoring ECOWAS's role in driving member-state compliance with international norms.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36849", "revid": "205121", "url": "https://en.wikipedia.org/wiki?curid=36849", "title": "Henri Dunant", "text": ""}
{"id": "36852", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=36852", "title": "Pelegainisim", "text": ""}
{"id": "36853", "revid": "147617", "url": "https://en.wikipedia.org/wiki?curid=36853", "title": "Freemason", "text": ""}
{"id": "36854", "revid": "11308236", "url": "https://en.wikipedia.org/wiki?curid=36854", "title": "Pawe\u0142 Jasienica", "text": "Polish historian, journalist and soldier\nPawe\u0142 Jasienica was the pen name of Leon Lech Beynar (10 November 1909 \u2013 19 August 1970), a Polish historian, journalist, essayist and soldier.\nDuring World War II, Jasienica (then, Leon Beynar) fought in the Polish Army, and later, the Home Army resistance. Near the end of the war, he was also working with the anti-Soviet resistance, which later led to him taking up a new name, Pawe\u0142 Jasienica, to hide from the communist government of the People's Republic of Poland. He was associated with the \"Tygodnik Powszechny\" weekly and several other newspapers and magazines. He is best known for his 1960s books on Polish history\u2014on the Kingdom of Poland under the Piast dynasty, the Jagiellon dynasty, and the elected kings of the Polish\u2013Lithuanian Commonwealth. Those books, still popular, played an important role in popularizing Polish history among several generations of readers.\nJasienica became an outspoken critic of the censorship in the People's Republic of Poland, and as a notable dissident, he was persecuted by the government. He was subject to significant invigilation (oversight) by the security services, and his second wife was in fact an agent of the communist secret police. For a brief period marking the end of his life, his books were prohibited from being distributed or printed.\nLife.\nYouth.\nBeynar was born on 10 November 1909 in Simbirsk, Russia, to Polish parents, Miko\u0142aj Beynar and Helena Maliszewska. His paternal grandfather, Ludwik Beynar, fought in the January Uprising and married a Spanish woman, Joanna Adela Feugas. His maternal grandfather, Wiktor Maliszewski, fought in the November uprising. Both of his grandfathers eventually settled in the Russian Empire. His father, Miko\u0142aj, worked as an agronomist. Beynar's family lived in Russia and Ukraine\u2014they moved from Simbirsk to a location near Bila Tserkva and Uman, then to Kyiv until the Russian Revolution of 1917, after which they decided to settle in the independent Poland. After a brief stay in Warsaw, during the Polish\u2013Soviet War, his family settled in Opat\u00f3w, and in 1924, moved to Grodno.\nBeynar graduated from \"gymnasium\" (secondary school) in Wilno (Vilnius) and graduated in history from Stefan Batory University in Wilno (his thesis concerned the January Uprising). At the university he was an active member of several organizations including \"Klub Intelektualist\u00f3w\" (Intellectuals' Club) and \"Akademicki Klub W\u0142\u00f3cz\u0119g\u00f3w\" (Academic Club of Vagabonds). After graduating, he finished training for the officer cadet (\"podchor\u0105\u017cy\") in the Polish Army. From 1928 to 1937 he lived in Grodno, where he worked as a history teacher in a gymnasium; later he was employed as an announcer for Polish Radio Wilno. Here also, Beynar embarked on his career as author and essayist, writing for a Vilnius conservative newspaper, (The Word). On 11 November 1934 he married W\u0142adys\u0142awa Adamowicz, and in 1938 his daughter Ewa was born. In 1935 he published his first history book \u2013 about King Sigismund II Augustus, \"Zygmunt August na ziemiach dawnego Wielkiego Ksi\u0119stwa\" (Sigismund Augustus on the Lands of the Former Grand Duchy [of Lithuania]).\nWorld War II.\nDuring World War II, Beynar was a soldier in the Polish Army, fighting the German \"Wehrmacht\" when it invaded Poland in September 1939. He commanded a platoon near Sandomierz and was eventually taken prisoner by the Germans. While in a temporary prisoner-of-war camp in Opat\u00f3w, he was able to escape with the help of some old school friends from the time his family lived there in the early 1920s. He joined the Polish underground organization, \"Zwi\u0105zek Walki Zbrojnej\" (Association for Armed Combat), later transformed into the \"Armia Krajowa\" (\"AK\"; the Home Army), and continued the fight against the Germans. In the resistance he had the rank of lieutenant, worked in the local Wilno headquarters and was an editor of an underground newspaper \"Pobudka\". He was also involved in the underground teaching. In July 1944 he took part in the operation aimed at the liberation of Wilno from the Germans (Operation Ostra Brama). In the wake of this operation, around 19\u201321 August, his partisan unit, like many others, was intercepted and attacked by the Soviets. He was taken prisoner; sources vary as to whether he was to be exiled to Siberia or conscripted into the Polish People's Army. Either way he escaped and rejoined AK partisans (the Home Army 5th Wilno Brigade). For a while, he was an aide to Major Zygmunt Szendzielarz (\"\u0141upaszko\") and was member of the anti-Soviet resistance, \"Wolno\u015b\u0107 i Niezawis\u0142o\u015b\u0107\" (\"WiN\", Freedom and Independence). He was promoted to the rank of captain. Wounded in August 1945, he left the Brigade before it was destroyed by the Soviets, and avoided the fate of most of its officers who were sentenced to death. While recovering from his wounds, he found shelter in the village of Jasienica.\nPost-war.\nAfter recovering from his wounds in 1945, Beynar decided to leave the resistance, and instead began publishing in an independent Catholic weekly \"Tygodnik Powszechny\". It was then that he took the pen-name Jasienica (from the name of the place where he had received treatment for his injuries) in order not to endanger his wife, who was still living in Soviet-controlled Vilnius, Lithuania. Soon he became a member of the weekly's staff and then an editor. In 1948 he was arrested by the Polish secret police () but after several weeks was released after the intervention of Boles\u0142aw Piasecki from the PAX Association. In gratitude to Piasecki, thereafter he worked with PAX, leaving \"Tygodnik Powszechny\" for PAX in 1950. In 1950, he became a director of the Polish Caritas charity. Jasienica became a member of the Crooked Circle Club, which espoused free speech and open discussion. His essays were published in \"Dzi\u015b i Jutro\", \"S\u0142owo Powszechne\", \"\u017bycie Warszawy\", \"Po Prostu\". From at least this period until his death he would live in Warsaw. His wife W\u0142adys\u0142awa died 29 March 1965.\nOver time, he became increasingly involved in various dissident organizations. In December 1959, he became a vice president of the Union of Polish Writers (\"Zwi\u0105zek Literat\u00f3w Polskich\", ZLP). He also published in the magazine \"\u015awiat\" (1951\u20131969). In 1962 he was the last president of the literary discussion society, Crooked Circle Club. In 1966 he was a vice president of the PEN Club. While in the late 1940s and 1950s he focused mostly on journalistic activity, later he turned to writing popular history in book format. In the 1960s he wrote his most famous works, historical books about history of Poland \u2013 the Kingdom of Poland in the times of the Piast dynasty, the Jagiellonian dynasty, and the era of elected kings (the Polish\u2013Lithuanian Commonwealth). His book on Jagiellonian Poland was recognized as the best book of the year by the readers.\nJasienica was, however, very outspoken in his criticism of the censorship in the People's Republic of Poland. On 29 February 1968 during a ZLP meeting, Jasienia presented a harsh critique of the government. These acts, and in particular his signing of the dissident in 1964 against censorship and his involvement in the 1968 protests led to his being labeled a political dissident, for which he suffered government persecution. Partly as a response to government's persecution of Jasienica, in 1968 the satirist Janusz Szpota\u0144ski dedicated one of his anti-government poems, \"Ballada o \u0141upaszce\" (The Ballad of \u0141upaszko), written while Szpota\u0144ski was in Mokot\u00f3w Prison, to the writer. In the aftermath of the 1968 events, Polish communist media, and communist leader, W\u0142adys\u0142aw Gomu\u0142ka, on 19 March 1968, alleged that in 1948 Jasienica was freed because he collaborated with the communist regime; this allegation caused much controversy and damaged Jasienica's reputation. He was subject to much invigilation (oversight) by the security services. In December 1969, five years after his first wife's death, he remarried. This marriage proved to be highly controversial as it was discovered after his death that his second wife, Zofia Darowska O\u2019Bretenny, had been a secret police informant before their marriage, and continued to write reports about him throughout their marriage. From 1968 until his death, his books were prohibited from being distributed or printed.\nJasienica died from cancer on 19 August 1970 in Warsaw. Some publicists later speculated to what extent his death was caused by \"hounding from the party establishment\". He is buried in Warsaw's Pow\u0105zki Cemetery. His funeral was attended by many dissidents and became a political manifestation; Adam Michnik recalls seeing Antoni S\u0142onimski, Stefan Kisielewski, Stanis\u0142aw Stomma, Jerzy Andrzejewski, Jan J\u00f3zef Lipski and W\u0142adys\u0142aw Bartoszewski. Bohdan Cywi\u0144ski read a letter from Antoni Go\u0142ubiew.\nWork.\nJasienica book publishing begun with a historical book, \"Zygmunt August na ziemiach dawnego Wielkiego Ksi\u0119stwa\" (Sigismund Augustus in the lands of the former Grand Duchy; 1935). He is best known for his highly acclaimed and popular historical books from the 1960s about Piast Poland, Jagiellon Poland and the Polish\u2013Lithuanian Commonwealth: \"Polska Piast\u00f3w\" (Piast Poland, 1960), \"Polska Jagiellon\u00f3w\" (Jagiellon Poland, 1963) and the trilogy \"Rzeczpospolita Obojga Narod\u00f3w\" (The Commonwealth of Both Nations, 1967\u20131972). This trilogy made him one of the most popular Polish history writers. Throughout his life he avoided writing about modern history, to minimize the influence that the official, communist Marxist historiography would have on his works. This was also one of the reasons for the popularity of his works, which were seen as a rare, legally obtainable alternative to the official version of history. His books, publication of which resumed once again after his death, were labeled as \"best-selling\", and became the most reprinted postwar history of Poland.\nHis (Two ways, 1959) about the January Uprising of the 1860s represent the latest historical period he has tackled. His other popular historical books include , (Three chroniclers; 1964), a book about three medieval chroniclers of Polish history (Thietmar of Merseburg, Gallus Anonymus and Wincenty Kad\u0142ubek), in which he discusses the Polish society through ages; and (Last of the Family; 1965) about the last queen of the Jagiellon dynasty, Anna Jagiellonka. His (1978; Thoughts on Civil War) were the last book he has finished; unlike the majority of his other works, this book is ostensibly about the civil war (Chouannerie) in Brittany, France. This work does however contains numerous arguments applicable to more modern Polish history; arguments that Jasienica thought would not be allowed by the censors if the book discussed Polish history.\nIn addition to historical books, Jasienica, wrote a series of essays about archeology \u2013 (Slavic genealogy; 1961) and (Archeological excerpts: reports; 1956), journalistic travel reports () and science and technology (). Those works were mostly created around the 1950s and 1960s.\nHis (Memoirs) was the work that he began shortly before his death, and that was never completely finished.\nIn 2006, Polish journalist and former dissident Adam Michnik said that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I belong to the generation '68, a generation that has special debt to Pawe\u0142 Jasienica \u2013 in fact he paid with his life for daring to defend us, the youth. I want for somebody to be able to write, at some point, that in my generation there were people who stayed true to his message. Those who never forgot about his beautiful life, his wise and brave books, his terrible tragedy.\nPolish historian Henryk Samsonowicz echoes Michnik's essay in his introduction to a recent (2008) edition of \"Trzej kronikarze\", describing Jasienica as a person who did much to popularize Polish history. Hungarian historian Bal\u00e1zs Trencs\u00e9nyi notes that \"Jasienica's impact of the formation of the popular interpretation of Polish history is hard to overestimate\". British historian Norman Davies, himself an author of a popular account of Polish history (\"God's Playground\"), notes that Jasienica, while more of \"a historical writer than an academic historian\", had \"formidable talents\", gained \"much popularity\" and that his works would find no equals in the time of communist Poland. Samsonowicz notes that Jasienica \"was a brave writer\", going against prevailing system, and willing to propose new hypotheses and reinterpret history in innovative ways. Michnik notes how Jasienica was willing to write about Polish mistakes, for example in the treatment of Cossacks. Ukrainian historian Stephen Velychenko also positively commented on Jasienica's extensive coverage of the Polish-Ukrainian history. Both Michnik and Samsonowicz note how Jasienica's works contain hidden messages in which Jasienica discusses more contemporary history, such as in his \"Rozwa\u017cania...\".\nBibliography.\nSeveral of Jasienica's books have been translated into English by Alexander Jordan and published by the American Institute of Polish Culture, based in Miami, Florida.\nMedals:\nAwards:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n\u00a0 Wikiquote has quotations related to: "}
{"id": "36856", "revid": "47784746", "url": "https://en.wikipedia.org/wiki?curid=36856", "title": "Vertebrate", "text": "Subphylum of chordates\nVertebrates (), also called craniates, are animals with a vertebral column and a cranium. The vertebral column surrounds and protects the spinal cord, while the cranium protects the brain. \nThe vertebrates make up the subphylum Vertebrata ( ) with some 65,000 species, by far the largest ranked grouping in the phylum Chordata. The vertebrates include mammals, birds, amphibians, and various classes of fish and reptiles. The fish include the jawless Agnatha, and the jawed Gnathostomata. The jawed fish include both the cartilaginous fish and the bony fish. Bony fish include the lobe-finned fish, which gave rise to the tetrapods, the animals with four limbs. Despite their success, vertebrates still only make up less than five percent of all described animal species.\nThe first vertebrates appeared in the Cambrian explosion some 518 million years ago. Jawed vertebrates evolved in the Ordovician or Silurian; bony fishes appeared in the Silurian and diversified widely in the Devonian. The first tetrapods appeared towards the end of the Devonian, and the first amphibians appeared on land in the Carboniferous. During the Triassic, mammals and dinosaurs appeared, the latter giving rise to birds in the Jurassic. Extant species are roughly equally divided between fishes of all kinds, and tetrapods. Populations of many species have been in steep decline since 1970 because of land-use change, overexploitation of natural resources, climate change, pollution and the impact of invasive species.\nCharacteristics.\nUnique features.\nVertebrates belong to Chordata, a phylum characterised by five synapomorphies (unique characteristics): namely a notochord, a hollow nerve cord along the back, a post-anal tail, an endostyle (often as a thyroid gland), and pharyngeal gills arranged in pairs. Vertebrates share these characteristics with other chordates. \nVertebrates are distinguished from all other animals, including other chordates, by multiple synapomorphies: namely a vertebral column; a skull of bone or cartilage; a large brain divided into 3 or more sections, a muscular heart with multiple chambers; an inner ear with semicircular canals; sense organs including the eyes, ears, and nose; and digestive organs including the intestines, liver, pancreas, and stomach.\nPhysical.\nVertebrates (and other chordates) belong to the Bilateria, a group of animals with mirror symmetrical bodies. They move, typically by swimming, using muscles along the back, supported by a strong but flexible skeletal structure, the spine or vertebral column. The name 'vertebrate' derives from the Latin , 'jointed', from \"vertebra\", 'joint', in turn from Latin , 'to turn'.\nAs embryos, vertebrates still have a notochord. In all but the jawless fishes, it is replaced with a vertebral column (made of bone or cartilage) during development. Vertebrate embryos have pharyngeal arches; in adult fish, these support the gills, while in adult tetrapods they develop into other structures. \nIn the embryo, a layer of cells along the back folds and fuses into a hollow neural tube. This develops into the spinal cord, and at its front end, the brain. The brain receives information about the world through nerves which carry signals from sense organs in the skin and body. Because the ancestors of vertebrates usually moved forwards, the front of the body encountered stimuli before the rest of the body, favouring cephalisation, the evolution of a head containing sense organs and a brain to process the sensory information.\nVertebrates have a tubular gut that extends from the mouth to the anus. The vertebral column typically continues beyond the anus to form an elongated tail.\nThe ancestral vertebrates, and most extant species, are aquatic and carry out gas exchange in their gills. The gills are finely-branched structures which bring the blood close to the water. They are positioned just behind the head, supported by cartilaginous or bony branchial arches. In jawed vertebrates, the first gill arch pair evolved into the jaws. In amphibians and some primitive bony fishes, the larvae have external gills, branching off from the gill arches. Oxygen is carried from the gills to the body in the blood, and carbon dioxide is returned to the gills, in a closed circulatory system driven by a chambered heart. The tetrapods have lost the gills of their fish ancestors; they have adapted the swim bladder (that fish use for buoyancy) into lungs to breathe air, and the circulatory system is adapted accordingly. At the same time, they adapted the bony fins of the lobe-finned fishes into two pairs of walking legs, carrying the weight of the body via the shoulder and pelvic girdles. \nVertebrates vary in size from the smallest frog species such as \"Brachycephalus pulex\", with a minimum adult snout\u2013vent length of to the blue whale, at up to and weighing some 150 tonnes.\nMolecular.\nMolecular markers known as conserved signature indels in protein sequences have been identified and provide distinguishing criteria for the vertebrate subphylum. Five molecular markers are exclusively shared by all vertebrates and reliably distinguish them from all other animals; these include protein synthesis elongation factor-2, eukaryotic translation initiation factor 3, adenosine kinase and a protein related to ubiquitin carboxyl-terminal hydrolase). A specific relationship between vertebrates and tunicates is supported by two molecular markers, the proteins Rrp44 (associated with the exosome complex) and serine C-palmitoyltransferase. These are exclusively shared by species from these two subphyla, but not by cephalochordates.\nEvolutionary history.\nCambrian explosion: first craniates.\nVertebrates originated during the Cambrian explosion at the start of the Paleozoic, which saw a rise in animal diversity. The earliest known vertebrates belong to the Chengjiang biota and lived about 518 million years ago. These include \"Haikouichthys\", \"Myllokunmingia\", \"Zhongjianichthys\", and probably \"Yunnanozoon\". Unlike other Cambrian animals, these groups had the basic vertebrate body plan: a notochord, rudimentary vertebrae, and a well-defined head and tail, but lacked jaws. As such, one perspective is that \"Haikouichthys\" and other Myllokunmingiidae probably represent basal stem group craniates rather than actual vertebrates.\nA vertebrate group of uncertain phylogeny, small eel-like conodonts, are known from microfossils of their paired tooth segments from the late Cambrian to the end of the Triassic. Zoologists have debated whether teeth mineralized first, given the hard teeth of the soft-bodied conodonts, and then bones, or vice versa, but it seems that the mineralized skeleton came first.\nPaleozoic: from fish to amphibians.\nThe first jawed vertebrates may have appeared in the late Ordovician (~445 mya) or Silurian, and became common in the Devonian period, often known as the \"Age of Fishes\". The bony fishes appeared in the Silurian; they became common in the Devonian. By the middle of the Devonian, a lineage of bony fishes, the sarcopterygii, with both gills and air-breathing lungs adapted to life in swampy pools, used their muscular paired fins to propel themselves on land. The fins, already possessing bones and joints, evolved into the two pairs of walking legs of the first tetrapods in the Famennian stage of the Devonian. These tetrapods established themselves on land as amphibians in the next geological period, the Carboniferous. A group of vertebrates, the amniotes, with membranes around the embryo allowing it to survive on dry land, branched from amphibious tetrapods in the Carboniferous.\nMesozoic: from reptiles to mammals and birds.\nAt the onset of the Mesozoic, all larger vertebrate groups were devastated after the largest mass extinction in earth history. The following recovery phase saw the emergence of many new vertebrate groups that are still around today, and this time has been described as the origin of modern ecosystems. On the continents, the ancestors of modern lissamphibians, turtles, crocodilians, lizards, and mammals appeared, as well as dinosaurs, which gave rise to birds later in the Mesozoic. In the seas, various groups of marine reptiles evolved, as did new groups of fish. At the end of the Mesozoic, another extinction event extirpated dinosaurs (other than birds) and many other vertebrate groups.\nCenozoic: Age of Mammals.\nThe Cenozoic, the current era, is sometimes called the \"Age of Mammals\", because of the dominance of the terrestrial environment by that group. Placental mammals have predominantly occupied the Northern Hemisphere, with marsupial mammals in the Southern Hemisphere.\nApproaches to classification.\nTaxonomic history.\nVertebrata.\nIn 1801, Jean-Baptiste Lamarck defined the vertebrates as a taxonomic group, a phylum distinct from the invertebrates he was studying. He described them as consisting of four classes, namely fish, reptiles, birds, and mammals, but treated the cephalochordates and tunicates as molluscs. In 1866, Ernst Haeckel called both his Craniata (vertebrates) and his Acrania (cephalochordates) Vertebrata. In 1877, Ray Lankester grouped the craniates, cephalochordates, and urochordates (tunicates) as Vertebrata. In 1880\u20131881, Francis Maitland Balfour placed the Vertebrata as a subphylum within the chordates. In 2018, Naoki Irie and colleagues proposed making Vertebrata a full phylum.\nCyclostomes and craniates.\nIn 1758, Linnaeus classified hagfishes as Vermes, not vertebrates.\nIn 1806, Andr\u00e9 Marie Constant Dum\u00e9ril grouped hagfishes and lampreys in the taxon Cyclostomi, characterized by horny teeth borne on a tongue-like apparatus, a large notochord as adults, and pouch-shaped gills (Marsupibranchii). The cyclostomes were seen as either degenerate cartilaginous fishes or primitive vertebrates. In 1889, Edward Drinker Cope coined the name Agnatha (\"jawless\") for a group that included the cyclostomes and fossil groups in which jaws could not be observed. Vertebrates were subsequently divided into two major sister-groups: the Agnatha and the Gnathostomata (jawed vertebrates). In 1927, Erik Stensi\u00f6 suggested that the two groups of living agnathans (i.e. the cyclostomes) arose independently from fossil agnathans. \nIn 1977, S\u00f8ren L\u00f8vtrup argued that lampreys are more closely related to gnathostomes, based on characters such as radial muscles in the fins, true lymphocytes, neuromasts in the inner ear, and a cerebellum. This implied that Vertebrata and Craniata were distinct taxa. The validity of the taxon \"Craniata\" was examined in 2002 by Delarbre et al. using mtDNA sequencing, concluding that Myxini is more closely related to Hyperoartia than to Gnathostomata - i.e., that modern jawless fishes form a clade called Cyclostomata. This implies that Vertebrata should return to its old content (Gnathostomata + Cyclostomata) and the name Craniata is a junior synonym of Vertebrata. In 2010, the debate concluded when the French paleontologist Philippe Janvier stated that he accepted that both vertebrates and cyclostomes were monophyletic, and that \"the intuitions of 19th century zoologists were correct in assuming that [cyclostomes] (notably, hagfishes) are strongly degenerate and have lost many characters over time.\"\nTraditional taxonomy.\nConventional evolutionary taxonomy groups extant vertebrates into seven classes based on traditional interpretations of gross anatomical and physiological traits. The commonly held classification lists three classes of fish and four of tetrapods. This ignores some of the natural relationships between the groupings. For example, the birds derive from a group of reptiles, so \"Reptilia\" excluding Aves is not a natural grouping; it is described as paraphyletic and shown in quotation marks.\nIn addition to these, there are two classes of extinct armoured fishes, Placodermi and Acanthodii.\nOther ways of classifying the vertebrates have been devised, particularly with emphasis on the phylogeny of early amphibians and reptiles. An example based on work by M.J. Benton in 2004 is given here (\u2020 = extinct, \"\" = paraphyletic):\nWhile this traditional taxonomy is orderly, most of the groups are paraphyletic, meaning that the structure does not accurately reflect the natural evolved grouping. For instance, descendants of the first reptiles include modern reptiles, mammals and birds; the agnathans have given rise to the jawed vertebrates; the bony fishes have given rise to the land vertebrates; a group of amphibians, the labyrinthodonts, have given rise to the reptiles (traditionally including the mammal-like synapsids), which in turn have given rise to the mammals and birds. Most scientists working with vertebrates use a classification based purely on phylogeny, organized by their known evolutionary history.\nExternal phylogeny.\nThe closest relatives of vertebrates have been debated over the years. It was once thought that the Cephalochordata was the sister taxon to Vertebrata. This group, Notochordata, was taken to be sister to the Tunicata. Since 2006, analysis has shown that the tunicates + vertebrates form a clade, the Olfactores, with Cephalochordata as its sister (the Olfactores hypothesis), as shown in the following phylogenetic tree.\nInternal phylogeny.\nThe internal phylogeny of extant vertebrates is shown in the tree.\nThe placement of hagfishes within the vertebrates has been controversial. Their lack of proper vertebrae (among other characteristics of jawless lampreys and jawed vertebrates) led authors of phylogenetic analyses based on morphology to place them outside Vertebrata. Molecular data however indicates that they are vertebrates, being most closely related to lampreys. An older view is that they are a sister group of vertebrates in the common taxon of Craniata. In 2019, Tetsuto Miyashita and colleagues reconciled the two types of analysis, supporting the Cyclostomata hypothesis using only morphological data.\nA wider issue is the position of fossil agnathans, such as the Myllokunmingiida. Tetsuto Miyashita and colleagues in 2019 place them tentatively as part of the Vertebrata total group, outside the Vertebrata crown group that led to all extant vertebrates. These fossils have a cranium (a skull of bone or cartilage) but at most a rudimentary vertebral column, so they can be viewed as part of a craniate clade that also includes the crown group vertebrates which possess a full vertebral column.\nDiversity.\nSpecies by group.\nDescribed and extant vertebrate species are split roughly evenly but non-phylogenetically between non-tetrapod \"fish\" and tetrapods. The following table lists the number of described extant species for each vertebrate class as estimated in the IUCN Red List of Threatened Species, 2014.3. Paraphyletic groups are shown in quotation marks.\nThe IUCN estimates that 1,305,075 extant invertebrate species have been described, which means that less than 5% of the described animal species in the world are vertebrates.\nRecent population trends.\nThe Living Planet Index, following 16,704 populations of 4,005 species of vertebrates, shows a decline of 60% between 1970 and 2014. Since 1970, freshwater species declined 83%, and tropical populations in South and Central America declined 89%. The authors note that \"An average trend in population change is not an average of total numbers of animals lost.\" According to WWF, this could lead to a sixth major extinction event. The five main causes of biodiversity loss are land-use change, overexploitation of natural resources, climate change, pollution and invasive species.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36857", "revid": "49992021", "url": "https://en.wikipedia.org/wiki?curid=36857", "title": "Thrace", "text": "Geographical and historical region in Southeast Europe\nThrace (, ; ; ; ) is a geographical and historical region in Southeast Europe roughly corresponding to the province of Thrace in the Roman Empire. Bounded by the Balkan Mountains to the north, the Aegean Sea to the south, and the Black Sea to the east, it comprises present-day southeastern Bulgaria (Northern Thrace), northeastern Greece (Western Thrace), and the European part of Turkey (East Thrace). Lands also inhabited by ancient Thracians extended in the north to modern-day Northern Bulgaria and Romania and to the west into Macedonia.\nEtymology.\nThe word \"Thrace\", from ancient Greek \"Thrake\" (\u0398\u03c1\u1fb4\u03ba\u03b7), referred originally to the Thracians (ancient Greek \"Thrakes\" \u0398\u03c1\u1fb7\u03ba\u03b5\u03c2), an ancient people inhabiting Southeast Europe. The name \"Europe\" (ancient Greek \u0395\u1f50\u03c1\u03ce\u03c0\u03b7), also at first referred to this region, before that term expanded to include its modern sense.\nIt has been suggested that the name \"Thrace\" derives from the name of the principal river of the region, the Hebros. The river's name may be derived from the Indo-European \"arg\" \"white river\" (the opposite of Vardar, meaning \"black river\"). According to an alternative theory, Hebros means \"goat\" in Thracian.\nSixth century geographer Stephanus of Byzantium claimed that, long before the ancient Greeks started referring to the region as \"Thrace\", it was known as Aria (\u0391\u03c1\u03b9\u03b1) and Perki (\u03a0\u03b5\u03c1\u03ba\u03b7).\nIn Turkish, Thrace is commonly referred to as \"Rumeli\", meaning \"Land of the Romans\", which was the name traditionally given by Turkic societies to the Byzantine Empire and Orthodox Christians.\nIn Greek mythology, Thrace is named after the heroine and sorceress Thrace, who was the daughter of Oceanus and Parthenope, and sister of Europa.\nGeography.\nBorders.\nThe historical boundaries of Thrace have varied. The ancient Greeks employed the term \"Thrace\" to refer to all of the territory which lay north of Thessaly inhabited by the Thracians, a region which \"had no definite boundaries\" and to which other regions (like Macedonia and even Scythia) were added. In one ancient Greek source, the very Earth is divided into \"Asia, Libya, Europa and Thracia\". As the Greeks gained knowledge of world geography, \"Thrace\" came to designate the area bordered by the Danube on the north, by the Euxine Sea (Black Sea) on the east, by northern Macedonia in the south, and by Illyria to the west. This largely coincided with the Thracian Odrysian kingdom, whose borders varied over time. After the Macedonian conquest, this region's former border with Macedonia was shifted from the Struma River to the Mesta River. This usage lasted until the Roman conquest. Henceforth, (classical) Thrace referred only to the tract of land largely covering the same extent of space as the modern geographical region. In its early period, the Roman province of Thrace was of this extent, but after the administrative reforms of the late 3rd century, Thracia's much reduced territory became the six small provinces which constituted the Diocese of Thrace. The medieval Byzantine theme of Thrace contained only what today is East Thrace.\nCities.\nThe largest cities of Thrace are: Istanbul, Plovdiv, \u00c7orlu, Tekirda\u011f, Burgas, Edirne, Stara Zagora, Sliven, Yambol, Haskovo, Komotini, Alexandroupoli, Xanthi, and K\u0131rklareli.\nDemographics and religion.\nMost of the Bulgarian and Greek population are Orthodox Christians, while most of the Turkish inhabitants of Thrace are Sunni Muslims. There are also communities of Muslim Pomaks and Romani, while in Western Thrace, the province of East Macedonia and Thrace in Northeastern Greece, there are small numbers of Greek Muslims integrated into the communities of Pomaks and Western Thrace Turks.\nAncient Greek mythology.\nAncient Greek mythology provides the Thracians with a mythical ancestor Thrax, the son of the war-god Ares, who was said to reside in Thrace. The Thracians appear in Homer's \"Iliad\" as Trojan allies, led by Acamas and Peiros. Later in the \"Iliad\", Rhesus, another Thracian king, makes an appearance. Cisseus, father-in-law to the Trojan elder Antenor, is also given as a Thracian king.\nHomeric Thrace was vaguely defined, and stretched from the River Axios in the west to the Hellespont and Black Sea in the east. The Catalogue of Ships mentions three separate contingents from Thrace: Thracians led by Acamas and Peiros, from Aenus; Cicones led by Euphemus, from southern Thrace, near Ismaros; and from the city of Sestus, on the Thracian (northern) side of the Hellespont, which formed part of the contingent led by Asius. Ancient Thrace was home to numerous other tribes, such as the Edones, Bisaltae, Cicones, and Bistones in addition to the tribe that Homer specifically calls the \"Thracians\".\nGreek mythology is replete with Thracian kings, including Diomedes, Tereus, Lycurgus, Phineus, Tegyrius, Eumolpus, Polymnestor, Poltys, and Oeagrus (father of Orpheus).\nThrace is mentioned in Ovid's \"Metamorphoses\", in the episode of Philomela, Procne, and Tereus: Tereus, the King of Thrace, lusts after his sister-in-law, Philomela. He kidnaps her, holds her captive, rapes her, and cuts out her tongue. Philomela manages to get free, however. She and her sister, Procne, plot to get revenge, by killing her son Itys (by Tereus) and serving him to his father for dinner. At the end of the myth, all three turn into birds \u2013 Procne into a swallow, Philomela into a nightingale, and Tereus into a hoopoe.\nThe city of Dicaea in Thrace was named after the son of Poseidon, Dicaeus.\nHistory.\nAncient and Roman history.\nIndigenous Thracians were divided into numerous tribes. The first Greek colonies in coastal Thrace were founded in the 8th century BC.\nThe first to take greater control of Thrace, in part or whole, were the Achaemenian Persians in the late 6th century BC. The region was incorporated into their empire as the Satrapy of Skudra, after the Scythian campaign of Darius the Great. Thracian soldiers were used in Persian armies and are depicted in carvings of the Persepolis and Naqsh-e Rostam. Persians' presence in Thracia lasted up untile the rise of the Delian league. In the 4th century BC most of Thrace was conquered by Philip II of Macedon and his son Alexander the Great. Notably, Thracian troops are known to have accompanied Alexander when he crossed the Hellespont which abuts Thrace, during the invasion of the Achaemenid Empire. It then passed to Lysimachus when Alexander's empire was divided between his generals. Lysimachus ruled as king up until his defeat from Seleucus I Nicator in 281 BC at the battle of Corupedium. \nThracians recorded no collective name for themselves; terms such as \"Thrace\" and \"Thracians\" were assigned by the Greeks.\nDivided into separate tribes, the Thracians did not form any lasting political organizations until the founding of the Odrysian state in the 4th century BC. Like Illyrians, the locally ruled Thracian tribes of the mountainous regions maintained a warrior tradition, while the tribes based in the plains were purportedly more peaceable. Recently discovered funeral mounds in Bulgaria suggest that Thracian kings did rule regions of Thrace with distinct Thracian national identity.\nDuring this period, a subculture of celibate ascetics called the Ctistae lived in Thrace, where they served as philosophers, priests, and prophets.\nSections of Thrace particularly in the south started to become hellenized before the Peloponnesian War as Athenian and Ionian colonies were set up in Thrace before the war. Spartan and other Doric colonists followed them after the war. The special interest of Athens to Thrace is underlined by the numerous finds of Athenian silverware in Thracian tombs. In 168 BC, after the Third Macedonian War and the subjugation of Macedonia to the Romans, Thrace also lost its independence and became a tributary to Rome. Towards the end of the 1st century BC Thrace lost its status as a client kingdom as the Romans began to directly appoint their kings. This situation lasted until 46 AD, when the Romans finally turned Thrace into a Roman province (Romana provincia Thracia).\nDuring the Roman domination, within the geographical borders of ancient Thrace, there were two separate Roman provinces, namely Thrace (\"provincia Thracia\") and Lower Moesia (\"Moesia inferior\"). Later, in the times of Diocletian, the two provinces were joined and formed the so-called \"Dioecesis Thracia\". The establishment of Roman colonies and mostly several Greek cities, as was Nicopolis, Topeiros, Traianoupolis, Plotinoupolis, and Hadrianoupolis resulted from the Roman Empire's urbanization. The Roman provincial policy in Thrace favored mainly not the Romanization but the Hellenization of the country, which had started as early as the Archaic period through the Greek colonisation and was completed by the end of Roman antiquity. As regards the competition between the Greek and Latin language, the very high rate of Greek inscriptions in Thrace extending south of Haemus Mountains proves the complete language Hellenization of this region. The boundaries between the Greek and Latin speaking Thrace are placed just above the northern foothills of Haemus Mountains.\nDuring the imperial period many Thracians \u2013 particularly members of the local aristocracy of the cities \u2013 had been granted the right of the Roman citizenship (civitas Romana) with all its privileges. Epigraphic evidence show a large increase in such naturalizations in the times of Trajan and Hadrian, while in 212 AD the emperor Caracalla granted, with his well-known decree (constitutio Antoniniana), the Roman citizenship to all the free inhabitants of the Roman Empire.\nDuring the same period (in the 1st\u20132nd century AD), a remarkable presence of Thracians is testified by the inscriptions outside the borders (extra fines) both in the Greek territory and in all the Roman provinces, especially in the provinces of Eastern Roman Empire.\nMedieval history.\nBy the mid-5th century, as the Western Roman Empire began to crumble, Thracia fell from the authority of Rome and into the hands of Germanic tribal rulers. With the fall of the Western Roman Empire, Thracia turned into a battleground territory for the better part of the next 1,000 years. The surviving eastern portion of the Roman Empire in the Balkans, later known as the Byzantine Empire, retained control over Thrace until the 7th century when the northern half of the entire region was incorporated into the First Bulgarian Empire and the remainder was reorganized in the Thracian theme. The Empire regained the lost regions in the late 10th century until the Bulgarians regained control of the northern half at the end of the 12th century. Throughout the 13th century and the first half of the 14th century, the region was changing in the hands of the Bulgarian and the Byzantine Empire (excluding Constantinople). In 1265, the area suffered a Mongol raid from the Golden Horde, led by Nogai Khan, and between 1305 and 1307 the area was raided by the Catalan company.\nOttoman period.\nIn 1352, the Ottoman Turks conducted their first incursion into the region subduing it completely within a matter of two decades and ruled it for five centuries in general peace. In 1821, several parts of Thrace, such as Lavara, Maroneia, Sozopolis, Aenos, Callipolis, and Samothraki rebelled during the Greek War of Independence.\nModern history.\nWith the Congress of Berlin in 1878, Northern Thrace was incorporated into the semi-autonomous Ottoman province of Eastern Rumelia, which united with Bulgaria in 1885. The rest of Thrace was divided among Bulgaria, Turkey and Greece at the beginning of the 20th century, following the Balkan Wars, World War I and the Greco-Turkish War. In Summer 1934, up to 10,000 Jews were maltreated, bereaved, and then forced to quit the region (see 1934 Thrace pogroms). From Bulgaria and Romania between 1934 and 1938 a large wave of Muslim immigrants called \"G\u00f6\u00e7menler\" went to East Thrace.\nToday, \"Thracian\" is a geographical term used in Bulgaria, Turkey, and Greece.\nLegacy.\nThe Trakiya Heights in Antarctica \"are named after the historical region.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "36858", "revid": "2666701", "url": "https://en.wikipedia.org/wiki?curid=36858", "title": "Wheat", "text": "Genus of grass cultivated for grain\nWheat is a group of wild and domesticated grasses of the genus Triticum (). They are cultivated for their cereal grains, which are staple foods around the world. Well-known wheat species and hybrids include the most widely grown common wheat (\"T. aestivum\"), spelt, durum, emmer, einkorn, and Khorasan or Kamut. The archaeological record suggests that wheat was first cultivated in the regions of the Fertile Crescent around 9600 BC.\nWheat is grown on a larger area of land than any other food crop ( in 2021). World trade in wheat is greater than that of all other crops combined. In 2021, world wheat production was , making it the second most-produced cereal after maize (known as corn in North America and Australia; wheat is often called corn in other countries including Britain). Since 1960, world production of wheat and other grain crops has tripled and is expected to grow further through the middle of the 21st century. Global demand for wheat is increasing because of the usefulness of gluten to the food industry.\nWheat is an important source of carbohydrates. Globally, it is the leading source of vegetable proteins in human food, having a protein content of about 13%, which is relatively high compared to other major cereals but relatively low in protein quality (supplying essential amino acids). When eaten as the whole grain, wheat is a source of multiple nutrients and dietary fibre. In a small part of the general population, gluten \u2013 which comprises most of the protein in wheat \u2013 can trigger coeliac disease, noncoeliac gluten sensitivity, gluten ataxia, and dermatitis herpetiformis.\nDescription.\nWheat is a stout grass of medium to tall height. Its stem is jointed and usually hollow, forming a straw. There can be many stems on one plant. It has long narrow leaves, their bases sheathing the stem, one above each joint. At the top of the stem is the flower head, containing some 20 to 100 flowers. Each flower contains both male and female parts. The flowers are wind-pollinated, with over 99% of pollination events being self-pollinations and the rest cross-pollinations. The flower is housed in a pair of small leaflike glumes. The two (male) stamens and (female) stigmas protrude outside the glumes. The flowers are grouped into spikelets, each with between two and six flowers. Each fertilised carpel develops into a wheat grain or berry; botanically a caryopsis fruit, it is often called a seed. The grains ripen to a golden yellow; a head of grain is called an ear.\nLeaves emerge from the shoot apical meristem in a telescoping fashion until the transition to reproduction i.e. flowering. The last leaf produced by a wheat plant is known as the flag leaf. It is denser and has a higher photosynthetic rate than other leaves, to supply carbohydrate to the developing ear. In temperate countries the flag leaf, along with the second and third highest leaves on the plant, supply the majority of carbohydrate in the grain; their condition is critical for crop yield. Wheat is unusual in having more stomata on the upper (adaxial) side of the leaf, than on the under (abaxial) side. It has been theorised that this might be an effect of having been cultivated longer than any other plant. Winter wheat generally produces up to 15 leaves per shoot, and spring wheat up to 9; winter crops may have up to 35 tillers (shoots) per plant (depending on cultivar).\nWheat roots are among the deepest of arable crops, extending as far down as . While the roots of a wheat plant are growing, the plant accumulates an energy store in its stem, in the form of fructans, which helps the plant to yield under drought and disease pressure, but there is a trade-off between root growth and stem non-structural carbohydrate reserves. Root growth is likely to be prioritised in drought-adapted crops, while stem non-structural carbohydrate is prioritised in varieties developed for countries where disease is a bigger issue.\nDepending on variety, wheat may be awned or not. Producing awns incurs a cost in grain number, but wheat awns photosynthesise more efficiently than leaves with regards to water usage, so awns are much more frequent in varieties of wheat grown in hot drought-prone countries than those in temperate countries. For this reason, awned varieties could become more widespread due to climate change. In Europe, wheat's climate resilience has declined.\nHistory.\nDomestication.\nHunter-gatherers in West Asia harvested wild wheats for thousands of years before they were domesticated, perhaps as early as 21,000\u00a0BC, but they formed a minor component of their diets. In this phase of pre-domestication cultivation, early cultivars were spread around the region and slowly developed the traits that came to characterise their domesticated forms.\nRepeated harvesting and sowing of the grains of wild grasses led to the creation of domestic strains, as mutant forms ('sports') of wheat were more amenable to cultivation. In domesticated wheat, grains are larger, and the seeds (inside the spikelets) remain attached to the ear by a toughened rachis during harvesting. In wild strains, a more fragile rachis allows the ear to shatter easily, dispersing the spikelets. Selection for larger grains and non-shattering heads by farmers might not have been deliberately intended, but simply have occurred because these traits made gathering the seeds easier; nevertheless such 'incidental' selection was an important part of crop domestication. As the traits that improve wheat as a food source involve the loss of the plant's natural seed dispersal mechanisms, highly domesticated strains of wheat cannot survive in the wild.\nWild einkorn wheat (\"T. monococcum\" subsp. \"boeoticum\") grows across Southwest Asia in open parkland and steppe environments. It comprises three distinct races, only one of which, native to Southeast Anatolia, was domesticated. The main feature that distinguishes domestic einkorn from wild is that its ears do not shatter without pressure, making it dependent on humans for dispersal and reproduction. It also tends to have wider grains. Wild einkorn was collected at sites such as Tell Abu Hureyra (c.\u200910,700\u20139000\u00a0BC) and Mureybet (c.\u20099800\u20139300\u00a0BC), but the earliest archaeological evidence for the domestic form comes after c.\u20098800 BC in southern Turkey, at \u00c7ay\u00f6n\u00fc, Cafer H\u00f6y\u00fck, and possibly Neval\u0131 \u00c7ori. Genetic evidence indicates that it was domesticated in multiple places independently.\nWild emmer wheat (\"T. turgidum\" subsp. \"dicoccoides\") is less widespread than einkorn, favouring the rocky basaltic and limestone soils found in the hilly flanks of the Fertile Crescent. It is more diverse, with domesticated varieties falling into two major groups: hulled or non-shattering, in which threshing separates the whole spikelet; and free-threshing, where the individual grains are separated. Both varieties probably existed in prehistory, but over time free-threshing cultivars became more common. Wild emmer was first cultivated in the southern Levant, as early as 9600\u00a0BC. Genetic studies have found that, like einkorn, it was domesticated in southeastern Anatolia, but only once. The earliest secure archaeological evidence for domestic emmer comes from \u00c7ay\u00f6n\u00fc, c.\u20098300\u20137600 BC, where distinctive scars on the spikelets indicated that they came from a hulled domestic variety. Slightly earlier finds have been reported from Tell Aswad in Syria, c.\u20098500\u20138200 BC, but these were identified using a less reliable method based on grain size.\nEarly farming.\nEinkorn and emmer are considered two of the founder crops cultivated by the first farming societies in Neolithic West Asia. These communities also cultivated naked wheats (\"T. aestivum\" and \"T. durum\") and a now-extinct domesticated form of Zanduri wheat (\"T. timopheevii\"), as well as a wide variety of other cereal and non-cereal crops. Wheat was relatively uncommon for the first thousand years of the Neolithic (when barley predominated), but became a staple after around 8500\u00a0BC. Early wheat cultivation did not demand much labour. Initially, farmers took advantage of wheat's ability to establish itself in annual grasslands by enclosing fields against grazing animals and re-sowing stands after they had been harvested, without the need to systematically remove vegetation or till the soil. They may also have exploited natural wetlands and floodplains to practice d\u00e9crue farming, sowing seeds in the soil left behind by receding floodwater. It was harvested with stone-bladed sickles. The ease of storing wheat and other cereals led farming households to become gradually more reliant on it over time, especially after they developed individual storage facilities that were large enough to hold more than a year's supply.\nWheat grain was stored after threshing, with the chaff removed. It was then processed into flour using ground stone mortars. Bread made from ground einkorn and the tubers of a form of club rush (\"Bolboschoenus glaucus\") was made as early as 12,400\u00a0BC. At \u00c7atalh\u00f6y\u00fck (c.\u20097100\u20136000\u00a0BC), both wholegrain wheat and flour was used to prepare bread, porridge and gruel. Apart from food, wheat may also have been important to Neolithic societies as a source of straw, which could be used for fuel, wicker-making, or wattle and daub construction.\nSpread.\nDomestic wheat was quickly spread to regions where its wild ancestors did not grow naturally. Emmer was introduced to Cyprus as early as 8600 BC and einkorn c.\u20097500 BC; emmer reached Greece by 6500 BC, Egypt shortly after 6000 BC, and Germany and Spain by 5000 BC. \"The early Egyptians were developers of bread and the use of the oven and developed baking into one of the first large-scale food production industries.\" By 4000 BC, wheat had reached the British Isles and Scandinavia. Wheat was also cultivated in India around 3500 BC. Wheat likely appeared in China's lower Yellow River around 2600 BC.\nThe oldest evidence for hexaploid wheat is through DNA analysis of wheat seeds from around 6400\u20136200 BC at \u00c7atalh\u00f6y\u00fck. As of 2023,[ [update]] the earliest known wheat with sufficient gluten for yeasted breads is from a granary at Assiros in Macedonia dated to 1350 BC. Wheat continued to spread across Europe and to the Americas in the Columbian exchange. In the British Isles, wheat straw (thatch) was used for roofing in the Bronze Age, remaining in common use until the late 19th century. White wheat bread was historically a high status food, but during the nineteenth century it became in Britain an item of mass consumption, displacing oats, barley and rye from diets in the North of the country. After 1860, the expansion of wheat production in the United States flooded the world market, lowering prices by 40%, and made a major contribution to the nutritional welfare of the poor.\nEvolution.\nPhylogeny.\nSome wheat species are diploid, with two sets of chromosomes, but many are stable polyploids, with four sets (tetraploid) or six (hexaploid). Einkorn is diploid (AA, two complements of seven chromosomes, 2n=14). Most tetraploid wheats (e.g. emmer and durum wheat) are derived from wild emmer. Wild emmer is itself the result of a hybridization between two diploid wild grasses, \"T. urartu\" and a wild goatgrass such as \"Ae. speltoides\". The hybridization that formed wild emmer (AABB, four complements of seven chromosomes in two groups, 4n=28) occurred in the wild, long before domestication, and was driven by natural selection. Hexaploid wheats evolved in farmers' fields as wild emmer hybridized with another goatgrass, \"Ae. squarrosa\" or \"Ae. tauschii\", to make the hexaploid wheats including bread wheat.\nA 2007 molecular phylogeny of the wheats gives the following not fully-resolved cladogram of major cultivated species; the large amount of hybridisation makes resolution difficult. Markings like \"6N\" indicate the polyploidy of each species:\nTaxonomy.\nDuring 10,000 years of cultivation, numerous forms of wheat, many of them hybrids, have developed under a combination of artificial and natural selection. This complexity and diversity of status has led to much confusion in the naming of wheats.\nThe wild species of wheat, along with the domesticated varieties einkorn, emmer and spelt, have hulls. This more primitive morphology (in evolutionary terms) consists of toughened glumes that tightly enclose the grains, and (in domesticated wheats) a semi-brittle rachis that breaks easily on threshing. The result is that when threshed, the wheat ear breaks up into spikelets. To obtain the grain, further processing, such as milling or pounding, is needed to remove the hulls or husks. Hulled wheats are often stored as spikelets because the toughened glumes give good protection against pests of stored grain. In free-threshing (or naked) forms, such as durum wheat and common wheat, the glumes are fragile and the rachis tough. On threshing, the chaff breaks up, releasing the grains.\nAs a food.\nGrain classes.\nClassification of wheat greatly varies by the producing country. \nArgentina's grain classes were formerly related to the production region or port of shipment: \"Rosafe\" (grown in Santa Fe province, shipped through Rosario), \"Bahia Blanca\" (grown in Buenos Aires and La Pampa provinces and shipped through Bahia Blanca), \"Buenos Aires\" (shipped through the port of Buenos Aires). While mostly similar to the US Hard Red Spring wheat, the classification caused inconsistencies, so Argentina introduced three new classes of wheat, with all names using a prefix \"Trigo Dura Argentina\" (TDA) and a number. \nThe grain classification in Australia is within the purview of its National Pool Classification Panel. Australia chose to measure the protein content at 11% moisture basis.\nThe decisions on the wheat classification in Canada are coordinated by the Variety Registration Office of the Canadian Food Inspection Agency. As in the US system, the eight classes in Western Canada and six classes in Eastern Canada are based on colour, season, and hardness. Uniquely, Canada requires that the varieties should allow for purely visual identification.\nThe classes used in the United States are named by colour, season, and hardness.\nFood value and uses.\nWheat is a staple cereal worldwide. Raw wheat berries can be ground into flour or, using hard durum wheat only, can be ground into semolina; germinated and dried creating malt; crushed or cut into cracked wheat; parboiled (or steamed), dried, and de-branned into groats, then crushed into bulgur. If the raw wheat is broken into parts at the mill, the outer husk or bran is removed. Wheat is a major ingredient in baked foods, such as bread, rolls, crackers, biscuits, pancakes, pasta, pies, pastries, pizza, cakes, cookies, and muffins; in fried foods, such as doughnuts; in breakfast cereals, gravy, porridge, and muesli; in semolina; and in drinks such as beer, vodka, and boza (a fermented beverage). In manufacturing wheat products, gluten is valuable to impart viscoelastic functional qualities in dough, enabling the preparation of processed foods such as bread, noodles, and pasta.\nNutrition.\nRaw red winter wheat is 13% water, 71% carbohydrates including 12% dietary fiber, 13% protein, and 2% fat (table). Some 75\u201380% of the protein content is as gluten. In a reference amount of , wheat provides of food energy and is a rich source (20% or more of the Daily Value, DV) of multiple dietary minerals, such as manganese, phosphorus, magnesium, zinc, and iron (table). The B vitamins, niacin (36% DV), thiamine (33% DV), and vitamin B6 (23% DV), are present in significant amounts (table).\nWheat is a significant source of vegetable proteins in human food, having a relatively high protein content compared to other major cereals. However, wheat proteins have a low quality for human nutrition, according to the DIAAS protein quality evaluation method. Though they contain adequate amounts of the other essential amino acids, at least for adults, wheat proteins are deficient in the essential amino acid lysine. Because the gluten proteins present in endosperm are particularly poor in lysine, white flours are more deficient in lysine than are whole grains. Plant breeders have sought to develop lysine-rich wheat varieties, without success, as of 2017[ [update]]. Supplementation with proteins from other food sources (mainly legumes) is used to compensate for this deficiency.\nHealth advisories.\nConsumed worldwide by billions of people, wheat is a significant food for human nutrition, particularly in the least developed countries where wheat products are primary foods. When eaten as the whole grain, wheat supplies multiple nutrients and dietary fiber recommended for children and adults.\nIn genetically susceptible people, wheat gluten can trigger coeliac disease. Coeliac disease affects about 1% of the general population in developed countries. The only known effective treatment is a strict lifelong gluten-free diet. While coeliac disease is caused by a reaction to wheat proteins, it is not the same as a wheat allergy. Other diseases triggered by eating wheat are non-coeliac gluten sensitivity (estimated to affect 0.5% to 13% of the general population), gluten ataxia, and dermatitis herpetiformis.\nCertain short-chain carbohydrates present in wheat, FODMAPs (mainly fructose polymers), may be the cause of non-coeliac gluten sensitivity. As of 2019[ [update]], FODMAPs explain certain gastrointestinal symptoms, such as bloating, but not the extra-digestive symptoms of non-coeliac gluten sensitivity.\nOther wheat proteins, amylase-trypsin inhibitors, appear to activate the innate immune system in coeliac disease and non-coeliac gluten sensitivity. These proteins are part of the plant's natural defense against insects and may cause intestinal inflammation in humans.\nProduction and consumption.\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nIn 2023, world wheat production was 799 million tonnes, led by China, India, and Russia which collectively provided 42.4% of the world total. As of 2019[ [update]], the largest exporters were Russia (32 million tonnes), United States (27), Canada (23) and France (20), while the largest importers were Indonesia (11 million tonnes), Egypt (10.4) and Turkey (10.0). \nIn 2021, wheat was grown on worldwide, more than any other food crop.\nWorld trade in wheat is greater than for all other crops combined.\nGlobal demand for wheat is increasing due to the unique viscoelastic and adhesive properties of gluten proteins, which facilitate the production of processed foods, whose consumption is increasing as a result of the worldwide industrialization process and westernization of diets.\n19th century.\nWheat became a central agriculture endeavor in the worldwide British Empire in the 19th century, and remains of great importance in Australia, Canada and India. In Australia, with vast lands and a limited work force, expanded production depended on technological advances, especially irrigation and machinery. By the 1840s there were 900 growers in South Australia. They used \"Ridley's Stripper\", a reaper-harvester perfected by John Ridley in 1843, to remove the heads of grain. In Canada, modern farm implements made large scale wheat farming possible from the late 1840s. By 1879, Saskatchewan was the center, followed by Alberta, Manitoba and Ontario, as the spread of railway lines allowed easy exports to Britain. By 1910, wheat made up 22% of Canada's exports, rising to 25% in 1930 despite the sharp decline in prices during the Great Depression. Efforts to expand wheat production in South Africa, Kenya and India were stymied by low yields and disease. However, by 2000 India had become the second largest producer of wheat in the world. In the 19th century the American wheat frontier moved rapidly westward. By the 1880s 70% of American exports went to British ports. The first successful grain elevator was built in Buffalo in 1842. The cost of transport fell rapidly. In 1869 it cost 37 cents to transport a bushel of wheat from Chicago to Liverpool; in 1905 it was 10 cents.\nLate 20th century yields.\nIn the 20th century, global wheat output expanded about 5-fold, but until about 1955 most of this reflected increases in wheat crop area, with lesser (about 20%) increases in yield per unit area. After 1955 however, there was a ten-fold increase in the rate of wheat yield improvement per year, and this allowed global wheat production to increase. Thus technological innovation and scientific crop management with synthetic nitrogen fertilizer, irrigation and wheat breeding were the main drivers of wheat output growth in the second half of the century. There were some significant decreases in wheat crop area, for instance in North America. Better seed storage and germination ability (and hence a smaller requirement to retain harvested crop for next year's seed) is another 20th-century technological innovation. In medieval England, farmers saved one-quarter of their wheat harvest as seed for the next crop, leaving only three-quarters for food and feed consumption. By 1999, the global average seed use of wheat was about 6% of output.\n21st century.\nIn the 21st century, global warming is reducing wheat yield in some places. War and tariffs have disrupted trade. Between 2007 and 2009, concern was raised that wheat production would peak, in the same manner as oil, possibly causing sustained price rises. However, at that time global per capita food production had been increasing steadily for decades.\nAgronomy.\nGrowing wheat.\nWheat is an annual crop. It can be planted in autumn and harvested in early summer as winter wheat in climates that are not too severe, or planted in spring and harvested in autumn as spring wheat. It is normally planted after tilling the soil by ploughing and then harrowing to kill weeds and create an even surface. The seeds are then scattered on the surface, or drilled into the soil in rows. \nWinter wheat lies dormant during a winter freeze; it requires a long period below 4\u00b0C, and suffers heat stress and low yield if temperatures rise above 32\u00b0C. Winter wheat needs to develop to a height of 10 to 15 cm before the cold intervenes, so as to be able to survive the winter; it requires a period with the temperature at or near freezing, its dormancy then being broken by the thaw or rise in temperature. \nSpring wheat does not undergo dormancy. It grows best at between 21 and 24\u00b0C, but can tolerate a range between 4\u00b0C and 35\u00b0C. Germination below 4\u00b0C or maturation above 35\u00b0C reduce crop yield. \nWheat requires a deep soil, preferably a loam with organic matter, and available minerals including soil nitrogen, phosphorus, and potassium. An acid and peaty soil is not suitable. It needs some 30 to 38 cm of rain in the growing season to form a good crop of grain.\nThe farmer may intervene while the crop is growing to add fertilizer, water by irrigation, or pesticides such as herbicides to kill broad-leaved weeds or insecticides to kill insect pests. The farmer may assess soil minerals, soil water, weed growth, or the arrival of pests to decide timely and cost-effective corrective actions, and crop ripeness and water content to select the right moment to harvest. Harvesting involves reaping, cutting the stems to gather the crop; and threshing, breaking the ears to release the grain; both steps are carried out by a combine harvester. The grain is then dried so that it can be stored safe from mould fungi.\nCrop development.\nWheat normally needs between 110 and 130 days between sowing and harvest, depending upon climate, seed type, and soil conditions. Optimal crop management requires that the farmer have a detailed understanding of each stage of development in the growing plants. In particular, spring fertilizers, herbicides, fungicides, and growth regulators are typically applied only at specific stages of plant development. For example, it is currently recommended that the second application of nitrogen is made when the ear (not visible at this stage) is about 1 cm in size (Z31 on Zadoks scale). Knowledge of stages is important to identify periods of higher risk from the climate. Farmers benefit from knowing when the 'flag leaf' (last leaf) appears, as it represents about 75% of photosynthesis during the grain filling period, and so should be preserved from disease or insect attacks to ensure a good yield. Several systems exist to identify crop stages, with the Feekes and Zadoks scales being the most widely used. Each scale describes successive stages reached by the crop during the season. For example, the stage of pollen formation from the mother cell, and the stages between anthesis and maturity, are vulnerable to high temperatures, made worse by water stress.\nFarming techniques.\nTechnological advances in soil preparation and seed placement at planting time, use of crop rotation and fertilizers to improve plant growth, and advances in harvesting have combined to promote wheat as a viable crop. When the use of seed drills replaced broadcasting sowing of seed in the 18th century, productivity increased. Yields per unit area increased as crop rotations were applied to land that had long been in cultivation, and the use of fertilizers became widespread.\nImproved husbandry has more recently included pervasive automation, starting with the use of threshing machines, and progressing to large and costly machines like the combine harvester which greatly increased productivity. At the same time, better varieties such as Norin 10 wheat, developed in Japan in the 1930s, or the dwarf wheat developed by Norman Borlaug in the Green Revolution, greatly increased yields.\nSome large wheat grain-producing countries have significant losses after harvest at the farm, because of poor roads, inadequate storage technologies, inefficient supply chains and farmers' inability to bring the produce into retail markets dominated by small shopkeepers. Some 10% of total wheat production is lost at farm level, another 10% is lost because of poor storage and road networks, and more is lost at the retail level.\nIn the Punjab region of the Indian subcontinent, as well as North China, irrigation has been a major contributor to increased output. More widely over the last 40 years, a massive increase in fertilizer use together with increased availability of semi-dwarf varieties in developing countries, has greatly increased yields per hectare. In developing countries, use of (mainly nitrogenous) fertilizer increased 25-fold in this period. However, farming systems rely on much more than fertilizer and breeding to improve productivity. A good illustration of this is Australian wheat growing in the southern winter cropping zone, where, despite low rainfall (300\u00a0mm), wheat cropping is successful even with relatively little use of nitrogenous fertilizer. This is achieved by crop rotation with leguminous pastures. The inclusion of a canola crop in the rotations has boosted wheat yields by a further 25%. In these low rainfall areas, better use of available soil-water (and better control of soil erosion) is achieved by retaining the stubble after harvesting and by minimizing tillage.\nPests and diseases.\nPests and diseases consume 21.47% of the world's wheat crop annually.\nDiseases.\nThere are many wheat diseases, mainly caused by fungi, bacteria, and viruses. Plant breeding to develop new disease-resistant varieties, and sound crop management practices are important for preventing disease. Fungicides, used to prevent the significant crop losses from fungal disease, can be a significant variable cost in wheat production. Estimates of the amount of wheat production lost owing to plant diseases vary between 10 and 25% in Missouri. A wide range of organisms infect wheat, of which the most important are viruses and fungi. \nPathogens and wheat are in a constant process of coevolution. Spore-producing wheat rusts are substantially adapted towards successful spore propagation, i.e. increasing their basic reproduction number (R0).\nThe main wheat-disease categories are:\nA historically significant disease of cereals including wheat, though commoner in rye is ergot; it is unusual among plant diseases in also causing sickness in humans who ate grain contaminated with the fungus involved, \"Claviceps purpurea\".\nAnimal pests.\nAmong insect pests of wheat is the wheat stem sawfly,\na chronic pest in the Northern Great Plains of the United States and in the Canadian Prairies.\nWheat is the food plant of the larvae of some Lepidoptera (butterfly and moth) species including the flame, rustic shoulder-knot, setaceous Hebrew character and turnip moth. Early in the season, many species of birds and rodents feed upon wheat crops. These animals can cause significant damage to a crop by digging up and eating newly planted seeds or young plants. They can also damage the crop late in the season by eating the grain from the mature spike. Recent post-harvest losses in cereals amount to billions of dollars per year in the United States alone, and damage to wheat by various borers, beetles and weevils is no exception. Rodents can also cause major losses during storage, and in major grain growing regions, field mice numbers can sometimes build up explosively to plague proportions because of the ready availability of food. To reduce the amount of wheat lost to post-harvest pests, Agricultural Research Service scientists have developed an \"insect-o-graph\", which can detect insects in wheat that are not visible to the naked eye. The device uses electrical signals to detect the insects as the wheat is being milled. The new technology is so precise that it can detect 5\u201310 infested seeds out of 30,000 good ones.\nBreeding objectives.\nIn traditional agricultural systems, wheat populations consist of landraces, informal and often diverse farmer-maintained populations. Landraces of wheat continue to be important outside America and Europe. Formal wheat breeding began in the nineteenth century, when single line varieties were created by selecting seed from a plant with desired properties. Modern wheat breeding developed early in the twentieth century, linked to the development of Mendelian genetics. The standard method of breeding inbred wheat cultivars is by crossing two lines using hand emasculation, then selfing or inbreeding the progeny. Selections are identified genetically ten or more generations before release as a cultivar.\nMajor breeding objectives include high grain yield, good quality, disease- and insect resistance and tolerance to abiotic stresses, including mineral, moisture and heat tolerance. Wheat has been the subject of mutation breeding, with the use of gamma-, x-rays, ultraviolet light, and harsh chemicals. Since 1960, hundreds of varieties have been created through these methods, mostly in populous countries such as China. Bread wheat with high grain iron and zinc content has been developed through gamma radiation breeding, and through conventional selection breeding. International wheat breeding is led by the International Maize and Wheat Improvement Center in Mexico. ICARDA is another major public sector international wheat breeder, but it was forced to relocate from Syria to Lebanon in the Syrian Civil War.\nFor higher yields.\nThe presence of certain versions of wheat genes has been important for crop yields. Genes for the 'dwarfing' trait, first used by Japanese wheat breeders to produce Norin 10 short-stalked wheat, have had a huge effect on wheat yields worldwide, and were major factors in the success of the Green Revolution in Mexico and Asia, an initiative led by Norman Borlaug. Dwarfing genes enable the carbon that is fixed in the plant during photosynthesis to be diverted towards seed production, and reduce lodging, when a tall ear stalk falls over in the wind. By 1997, 81% of the developing world's wheat area was planted to semi-dwarf wheats, giving both increased yields and better response to nitrogenous fertilizer.\n\"T. turgidum\" subsp. \"polonicum\", known for its longer glumes and grains, has been bred into main wheat lines for its grain size effect, and likely has contributed these traits to \"T. petropavlovskyi\" and the Portuguese landrace group \"Arrancada\". As with many plants, MADS-box influences flower development, and more specifically, as with other agricultural Poaceae, influences yield. Despite that importance, as of 2021[ [update]] little research has been done into MADS-box and other such spikelet and flower genetics in wheat specifically.\nThe world record wheat yield is about , reached in New Zealand in 2017. A project in the UK, led by Rothamsted Research has aimed to raise wheat yields in the country to by 2020, but in 2018 the UK record stood at , and the average yield was just .\nFor disease resistance.\nWild grasses in the genus \"Triticum\" and related genera, and grasses such as rye have been a source of many disease-resistance traits for cultivated wheat breeding since the 1930s. Some resistance genes have been identified against \"Pyrenophora tritici-repentis\", especially races 1 and 5, those most problematic in Kazakhstan. Wild relative, \"Aegilops tauschii\" is the source of several genes effective against TTKSK/Ug99 - \"Sr33\", \"Sr45\", \"Sr46\", and \"SrTA1662\".\n&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Resistance to Fusarium head blight (FHB, Fusarium ear blight) is an important breeding target. Marker-assisted breeding panels involving kompetitive allele specific PCR can be used. A KASP genetic marker for a pore-forming toxin-like gene provides FHB resistance.\nIn 2003 the first resistance genes against fungal diseases in wheat were isolated. In 2021, novel resistance genes were identified in wheat against powdery mildew and wheat leaf rust.\nModified resistance genes have been tested in transgenic wheat and barley plants.\nTo create hybrid vigour.\nBecause wheat self-pollinates, creating hybrid seed to provide heterosis, hybrid vigour (as in F1 hybrids of maize), is extremely labour-intensive; the high cost of hybrid wheat seed has kept farmers from adopting them widely despite nearly 90 years of effort. Commercial hybrid wheat seed has been produced using chemical hybridizing agents, plant growth regulators that interfere with pollen development, or naturally occurring cytoplasmic male sterility systems. Hybrid wheat has been a limited commercial success in France, the United States and South Africa.\nSynthetic hexaploids made by crossing the wild goatgrass wheat ancestor \"Aegilops tauschii\", and other \"Aegilops\", with durum wheats are being deployed, increasing the genetic diversity of cultivated wheats.\nFor gluten content.\nModern bread wheat varieties have been cross-bred to contain greater amounts of gluten. However, a 2020 study found no changes in albumin/globulin and gluten content between 1891 and 2010.\nFor water efficiency.\nStomata (or leaf pores) are involved in both uptake of carbon dioxide gas from the atmosphere and water vapor losses from the leaf due to water transpiration. Basic physiological investigation of these gas exchange processes has yielded carbon isotope based method used for breeding wheat varieties with improved water-use efficiency. These varieties can improve crop productivity in rain-fed dry-land wheat farms.\nFor insect resistance.\nThe complex genome of wheat has made its improvement difficult. Comparison of hexaploid wheat genomes using a range of chromosome pseudomolecule and molecular scaffold assemblies in 2020 has enabled the resistance potential of its genes to be assessed. Findings include the identification of \"a detailed multi-genome-derived nucleotide-binding leucine-rich repeat protein repertoire\" which contributes to disease resistance, while the gene \"Sm1\" provides a degree of insect resistance, for instance against the orange wheat blossom midge.\nGenomics.\nDecoding the genome.\nIn 2010, 95% of the genome of Chinese Spring line 42 wheat was decoded. This genome was released in a basic format for scientists and plant breeders to use but was not fully annotated. In 2012, an essentially complete gene set of bread wheat was published. Random shotgun libraries of total DNA and cDNA from the \"T. aestivum\" cv. Chinese Spring (CS42) were sequenced to generate 85 Gb of sequence (220\u00a0million reads) and identified between 94,000 and 96,000 genes. In 2018, a more complete Chinese Spring genome was released by a different team. In 2020, 15 genome sequences from various locations and varieties around the world were reported, with examples of their own use of the sequences to localize particular insect and disease resistance factors. &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Wheat Blast Resistance is controlled by R genes which are highly race-specific.\nGenetic engineering.\nFor decades, the primary genetic modification technique has been non-homologous end joining. However, since its introduction, the &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;CRISPR/&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Cas9 tool has been extensively used, for example:\nIn art.\nThe Dutch artist Vincent van Gogh created the series \"Wheat Fields\" between 1885 and 1890, consisting of dozens of paintings made mostly in different parts of rural France. They depict wheat crops, sometimes with farm workers, in varied seasons and styles, sometimes green, sometimes at harvest. \"Wheatfield with Crows\" was one of his last paintings, and is considered to be among his greatest works.\nIn 1967, the American artist Thomas Hart Benton made his oil on wood painting \"Wheat\", showing a row of uncut wheat plants, occupying almost the whole height of the painting, between rows of freshly-cut stubble. The painting is held by the Smithsonian American Art Museum.\nIn 1982, the American conceptual artist Agnes Denes grew a two-acre field of wheat at Battery Park, Manhattan. The ephemeral artwork has been described as an act of protest. The harvested wheat was divided and sent to 28 world cities for an exhibition entitled \"The International Art Show for the End of World Hunger\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "36859", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=36859", "title": "Celtic", "text": "Celtic, Celtics or Keltic may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
